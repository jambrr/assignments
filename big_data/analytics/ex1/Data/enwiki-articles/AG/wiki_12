<doc id="39927" url="https://en.wikipedia.org/wiki?curid=39927" title="1443">
1443

__NOTOC__
Year 1443 (MCDXLIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39928" url="https://en.wikipedia.org/wiki?curid=39928" title="1444">
1444

__NOTOC__
Year 1444 (MCDXLIV) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39929" url="https://en.wikipedia.org/wiki?curid=39929" title="1445">
1445

__NOTOC__
Year 1445 (MCDXLV) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39930" url="https://en.wikipedia.org/wiki?curid=39930" title="1446">
1446

__NOTOC__
Year 1446 (MCDXLVI) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39931" url="https://en.wikipedia.org/wiki?curid=39931" title="1447">
1447

__NOTOC__
Year 1447 (MCDXLVII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39932" url="https://en.wikipedia.org/wiki?curid=39932" title="1448">
1448

__NOTOC__
Year 1448 (MCDXLVIII) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39934" url="https://en.wikipedia.org/wiki?curid=39934" title="1449">
1449

__NOTOC__
Year 1449 (MCDXLIX) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39936" url="https://en.wikipedia.org/wiki?curid=39936" title="Necrosis">
Necrosis

Necrosis (from the Greek νέκρωσις "death, the stage of dying, the act of killing" from νεκρός "dead") is a form of cell injury which results in the premature death of cells in living tissue by autolysis.
Necrosis is caused by factors external to the cell or tissue, such as infection, toxins, or trauma which result in the unregulated digestion of cell components.
In contrast, apoptosis is a naturally occurring programmed and targeted cause of cellular death.
While apoptosis often provides beneficial effects to the organism, necrosis is almost always detrimental and can be fatal.
Cellular death due to necrosis does not follow the apoptotic signal transduction pathway, but rather various receptors are activated, and result in the loss of cell membrane integrity and an uncontrolled release of products of cell death into the extracellular space.
This initiates in the surrounding tissue an inflammatory response which prevents nearby phagocytes from locating and eliminating the dead cells by phagocytosis. For this reason, it is often necessary to remove necrotic tissue surgically, a procedure known as debridement. Untreated necrosis results in a build-up of decomposing dead tissue and cell debris at or near the site of the cell death. A classic example is gangrene.
Classification.
Structural signs that indicate irreversible cell injury and the progression of necrosis include dense clumping and progressive disruption of genetic material, and disruption to membranes of cells and organelles.
Morphological patterns.
There are six distinctive morphological patterns of necrosis:
Causes.
Necrosis may occur due to external or internal factors.
External factors may involve mechanical trauma (physical damage to the body which causes cellular breakdown), damage to blood vessels (which may disrupt blood supply to associated tissue), and ischemia. Thermal effects (extremely high or low temperature) can result in necrosis due to the disruption of cells.
In frostbite, crystals form, increasing the pressure of remaining tissue and fluid causing the cells to burst. Under extreme conditions tissues and cells die through an unregulated process of destruction of membranes and cytosol.
Internal factors causing necrosis include: trophoneurotic disorders; injury and paralysis of nerve cells. Pancreatic enzymes (lipases) are the major cause of fat necrosis.
Necrosis can be activated by components of the immune system, such as the complement system; bacterial toxins; activated natural killer cells; and peritoneal macrophages.Pathogen-induced necrosis programs in cells with immunological barriers (intestinal mucosa) may alleviate invasion of pathogens through surfaces affected by inflammation. Toxins and pathogens may cause necrosis; toxins such as snake venoms may inhibit enzymes and cause cell death. Necrotic wounds have also resulted from the stings of "Vespa mandarinia."
Pathological conditions are characterized by inadequate secretion of cytokines. Nitric oxide (NO) and reactive oxygen species (ROS) are also accompanied by intense necrotic death of cells. A classic example of a necrotic condition is ischemia which leads to a drastic depletion of oxygen, glucose, and other trophic factors and induces massive necrotic death of endothelial cells and non-proliferating cells of surrounding tissues (neurons, cardiomyocytes, renal cells, etc.). Recent cytological data indicates that necrotic death occurs not only during pathological events but it is also a component of some physiological process.
Activation-induced death of primary T-lymphocytes and other important constituents of the immune response are caspase-independent and necrotic by morphology; hence, current researchers have demonstrated that the occurrence of necrotic cell death can not only occur during pathological processes but also during normal processes such as tissue renewal, embryogenesis, and immune response.
Pathogenesis.
Until recently, necrosis was thought to be an unregulated process. There are two broad pathways in which necrosis may occur in an organism.
The first of these two pathways initially involves oncosis, where swelling of the cells occur. The cell then proceeds to blebbing, and this is followed by pyknosis, in which nuclear shrinkage transpires. In the final step of this pathway the nucleus is dissolved into the cytoplasm, which is referred to as karyolysis.
The second pathway is a secondary form of necrosis that is shown to occur after apoptosis and budding. Cellular changes of necrosis occur in this secondary form of apoptosis, where the nucleus breaks into fragments, which is known as karyorrhexis.
Cellular changes.
The nucleus changes in necrosis, and characteristics of this change are determined by manner in which its DNA breaks down:
Plasma alterations are also seen in necrosis. Plasma membranes appear discontinuous when viewed with an electron microscope. This discontinuous membrane is caused by cell blebbing and the loss of microvilli.
Treatment.
There are many causes of necrosis, and as such treatment is based upon how the necrosis came about. Treatment of necrosis typically involves two distinct processes: Usually, the underlying cause of the necrosis must be treated before the dead tissue itself can be dealt with.
Even after the initial cause of the necrosis has been halted, the necrotic tissue will remain in the body. The body's immune response to apoptosis, which involves the automatic breaking down and recycling of cellular material, is not triggered by necrotic cell death due to the apoptotic pathway being disabled.
In plants.
If calcium is deficient, pectin cannot be synthesized, and therefore the cell walls cannot be bonded and thus an impediment of the meristems. This will lead to necrosis of stem and root tips and leaf edges. For example, necrosis of tissue can be found in the Arabidopsis thaliana due to plant pathogens.

</doc>
<doc id="39938" url="https://en.wikipedia.org/wiki?curid=39938" title="History of New Zealand">
History of New Zealand

The history of New Zealand dates back at least 700 years to when it was discovered and settled by Polynesians, who developed a distinct Māori culture centred on kinship links and land. The first European explorer to sight New Zealand was Abel Janszoon Tasman on 13 December 1642. Captain James Cook, who reached New Zealand in October 1769 on the first of his three voyages, was the first European explorer to circumnavigate and map New Zealand. From the late 18th century, the country was regularly visited by explorers and other sailors, missionaries, traders and adventurers. In 1840 the Treaty of Waitangi was signed between the British Crown and various Māori chiefs, bringing New Zealand into the British Empire and giving Māori "equal rights" with British citizens. There was extensive British settlement throughout the rest of the century. War and the imposition of a European economic and legal system led to most of New Zealand's land passing from Māori to Pākehā (European) ownership, and most Māori subsequently became impoverished.
From the 1890s the New Zealand parliament enacted a number of progressive initiatives, including women's suffrage and old age pensions. The country remained an enthusiastic member of the British Empire, and 110,000 men fought in World War I (see New Zealand Expeditionary Force). After the war New Zealand signed the Treaty of Versailles (1919), joined the League of Nations, and pursued an independent foreign policy, while its defence was still controlled by Britain.
When World War II broke out in 1939, New Zealanders contributed to the defence of the British Empire; the country contributed some 120,000 troops. From the 1930s the economy was highly regulated and an extensive welfare state was developed. Meanwhile, Māori culture underwent a renaissance, and from the 1950s Māori began moving to the cities in large numbers. This led to the development of a Māori protest movement which in turn led to greater recognition of the Treaty of Waitangi in the late 20th century.
The country's economy suffered in the aftermath of the 1973 global energy crisis, the loss of New Zealand's biggest export market upon Britain's entry to the European Economic Community, and rampant inflation. In the 1980s the economy was largely deregulated and a number of socially liberal policies, such as decriminalisation of homosexuality, were put in place. Foreign policy involved support for Britain in the world wars, and close relations after 1940 with the United States and Australia. Foreign policy after 1980 became more independent especially in pushing for a nuclear-free region. Subsequent governments have generally maintained these policies, although tempering the free market ethos somewhat. In 1984, the Fourth Labour government was elected amid a constitutional and economic crisis. The economic reforms were led by finance minister Roger Douglas (finance minister (1984–1988), who enacted fundamental, radically neo-liberal and unexpectedly pro-free market reforms known as Rogernomics.
Polynesian foundation.
New Zealand was originally settled by Polynesians from Eastern Polynesia. The most current reliable evidence strongly indicates that initial settlement of New Zealand occurred around 1280 CE. Previous dating of some Kiore (Polynesian rat) bones at 50 – 150 CE has now been shown to have been unreliable; new samples of bone (and now also of unequivocally rat-gnawed woody seed cases) match the 1280 CE date of the earliest archaeological sites and the beginning of sustained, anthropogenic deforestation.
The descendants of these settlers became known as the Māori, forming a distinct culture of their own. The separate settlement of the tiny Chatham Islands in the east of New Zealand about 1500 CE produced the Moriori people; linguistic evidence indicates that the Moriori were mainland Māori who ventured eastward.
The original settlers quickly exploited the abundant large game in New Zealand, such as moa, which were large flightless ratites pushed to extinction by about 1500. As moa and other large game became scarce or extinct, Māori culture underwent major change, with regional differences. In areas where it was possible to grow taro and kūmara, horticulture became more important. This was not possible in the south of the South Island, but wild plants such as fernroot were often available and cabbage trees were harvested and cultivated for food. Warfare also increased in importance, reflecting increased competition for land and other resources. In this period, fortified pā became more common, although there is debate about the actual frequency of warfare. As elsewhere in the Pacific, cannibalism was part of warfare.
Leadership was based on a system of chieftainship, which was often but not always hereditary, although chiefs (male or female) needed to demonstrate leadership abilities to avoid being superseded by more dynamic individuals. The most important units of pre-European Māori society were the whānau or extended family, and the hapū or group of whānau. After these came the iwi or tribe, consisting of groups of hapū. Related hapū would often trade goods and co-operate on major projects, but conflict between hapū was also relatively common. Traditional Māori society preserved history orally through narratives, songs, and chants; skilled experts could recite the tribal genealogies ("whakapapa") back for hundreds of years. Arts included whaikōrero (oratory), song composition in multiple genres, dance forms including haka, as well as weaving, highly developed wood carving, and tā moko (tattoo).
New Zealand has no native land mammals (apart from some rare bats) so birds, fish and sea mammals were important sources of protein. Māori cultivated food plants which they had brought with them from Polynesia, including sweet potatoes (called kūmara), taro, gourds, and yams. They also cultivated the cabbage tree, a plant endemic to New Zealand, and exploited wild foods such as fern root, which provided a starchy paste.
Early contact period.
Explorers and other visitors.
The first Europeans known to reach New Zealand were the crew of Dutch explorer Abel Tasman who arrived in his ships "Heemskerck" and "Zeehaen". Tasman anchored at the northern end of the South Island in Golden Bay (he named it Murderers' Bay) in December 1642 and sailed northward to Tonga following an attack by local Māori. Tasman sketched sections of the two main islands' west coasts. Tasman called them "Staten Landt", after the "States General of the Netherlands", and that name appeared on his first maps of the country. In 1645 Dutch cartographers changed the name to "Nova Zeelandia" in Latin, from "Nieuw Zeeland", after the Dutch province of "Zeeland". It was subsequently Anglicised as "New Zealand" by British naval captain James Cook of HM Bark "Endeavour" who visited the islands more than 100 years after Tasman during 1769–1770. Cook returned to New Zealand on both of his subsequent voyages.
Various claims have been made that New Zealand was reached by other non-Polynesian voyagers before Tasman, but these are not widely accepted. Peter Trickett, for example, argues in "Beyond Capricorn" that the Portuguese explorer Cristóvão de Mendonça reached New Zealand in the 1520s, and the Tamil bell discovered by missionary William Colenso has given rise to a number of theories,
From the 1790s, the waters around New Zealand were visited by British, French and American whaling, sealing and trading ships. Their crews traded European goods, including guns and metal tools, for Māori food, water, wood, flax and sex. Māori were reputed to be enthusiastic and canny traders. Although there were some conflicts, such as the killing of French explorer Marc-Joseph Marion du Fresne in 1792 and the destruction of the "Boyd" in 1809, most contact between Māori and European was peaceful. From the early 19th century missionaries began settling in New Zealand and attempting to convert Māori to Christianity and control the considerably lawless European visitors.
Māori response.
The effect of contact on Māori varied. In some inland areas life went on more or less unchanged, although a European metal tool such as a fish-hook or hand axe might be acquired through trade with other tribes. At the other end of the scale, tribes that frequently encountered Europeans, such as Ngā Puhi in Northland, underwent major changes.
Pre-European Māori had no distance weapons except for tao (spears) and the introduction of the musket had an enormous impact on Māori warfare. Tribes with muskets would attack tribes without them, killing or enslaving many. As a result, guns became very valuable and Māori would trade huge quantities of goods for a single musket. From 1805 to 1843 the Musket Wars raged until a new balance of power was achieved after most tribes had acquired muskets. In 1835, the peaceful Moriori of the Chatham Islands were attacked, enslaved, and nearly exterminated by mainland Ngāti Mutunga and Ngāti Tama Māori. In the 1901 census, only 35 Moriori were recorded although the numbers subsequently increased.
Around this time, many Māori converted to Christianity. The reasons for this have been hotly debated, and may include social and cultural disruption caused by the Musket Wars and European contact. Other factors may have been the appeal of a religion that promotes peace and forgiveness, a desire to emulate the Europeans and to gain a similar abundance of material goods, and the Māori's polytheistic culture that easily accepted the new God.
European settlement.
European settlement increased through the early decades of the 19th century, with numerous trading stations established, especially in the North. The first full-blooded European infant in the territory, Thomas King, was born in 1815 at Hohi in the Bay of Islands. Kerikeri, founded in 1822, and Bluff founded in 1823, both claim to be the oldest European settlements in New Zealand after the CMS mission station at Hohi, which was established in December 1814.
Many Europeans bought land from Māori, but misunderstanding and different concepts of land ownership led to conflict and bitterness. In 1839, the New Zealand Company announced plans to buy large tracts of land and establish colonies in New Zealand. This alarmed the missionaries, who called for British control of European settlers in New Zealand.
British sovereignty.
In 1788 the colony of New South Wales had been founded. According to the future Governor, Captain Arthur Phillip's amended Commission, dated 25 April 1787 the colony of New South Wales included "all the islands adjacent in the Pacific Ocean within the latitudes of 10°37'S and 43°39'S " which included most of New Zealand except for the southern half of the South Island. In 1825 with Van Diemen's Land becoming a separate colony, the southern boundary of New South Wales was altered to the islands adjacent in the Pacific Ocean with a southern boundary of 39°12'S which included only the northern half of the North Island. However, these boundaries had no real impact as the New South Wales administration had little interest in New Zealand.
In response to complaints from missionaries, about lawless sailors and adventurers in New Zealand, the British government appointed James Busby as Official Resident in 1832. In 1834 he encouraged Māori chiefs to assert their sovereignty with the signing of the "Declaration of Independence" in 1835. This was acknowledged by King William IV. Busby was provided with neither legal authority nor military support and was thus ineffective in controlling the European population.
Treaty of Waitangi.
In 1839, the New Zealand Company announced its plans to establish colonies in New Zealand. This and the increased commercial interests of merchants in Sydney and London spurred the British to take stronger action. Captain William Hobson was sent to New Zealand to persuade Māori to cede their sovereignty to the British Crown. In reaction to the New Zealand Company's moves, on 15 June 1839 a new Letters patent was issued to expand the territory of New South Wales to include all of New Zealand. Governor of New South Wales George Gipps was appointed Governor over New Zealand. This was the first clear expression of British intent to annexe New Zealand.
On 6 February 1840, Hobson and about forty Māori chiefs signed the Treaty of Waitangi at Waitangi in the Bay of Islands. Copies of the Treaty were subsequently taken around the country to be signed by other chiefs. A significant number refused to sign or were not asked but, in total, more than five hundred Māori eventually signed.
The Treaty gave Māori sovereignty over their lands and possessions and all of the rights of British citizens. What it gave the British in return depends on the language-version of the Treaty that is referred to. The English version can be said to give the British Crown sovereignty over New Zealand but in the Māori version the Crown receives "kawanatanga", which, arguably, is a lesser power (see interpretations of the Treaty). Dispute over the true meaning and the intent of either party remains an issue.
Britain was motivated by the desire to forestall other European powers (France established a very small settlement at Akaroa in the South Island later in 1840), to facilitate settlement by British subjects and, possibly, to end the lawlessness of European (predominantly British and American) whalers, sealers and traders. Officials and missionaries had their own positions and reputations to protect.
Māori chiefs were motivated by a desire for protection from foreign powers, the establishment of governorship over European settlers and traders in New Zealand, and to allow for wider settlement that would increase trade and prosperity for Māori.
Hobson died in September 1842. Robert FitzRoy, the new governor, took some legal steps to recognise Māori custom. However, his successor, George Grey, promoted rapid cultural assimilation and reduction of the land ownership, influence and rights of the Māori. The practical effect of the Treaty was, in the beginning, only gradually felt, especially in predominantly Māori regions.
Colonial period.
The European population of New Zealand grew explosively from fewer than 1000 in 1831 to 500,000 by 1881. Some 400,000 settlers came from Britain, of whom 300,000 stayed permanently. Most were young people and 250,000 babies were born. The passage of 120,000 was paid by the colonial government. After 1880 immigration reduced, and growth was due chiefly to the excess of births over deaths.
Administered at first as a part of the Australian colony of New South Wales, New Zealand became a colony in its own right on 1 July 1841. It was divided into three provinces that were reorganised in 1846 and in 1853, when they acquired their own legislatures, and then abolished in 1876. The country rapidly gained some measure of self-government through the New Zealand Constitution Act 1852, which established central and provincial government.
The Māori tribes at first sold the land to the settlers, but the government voided the sales in 1840. Now only the government was allowed to purchase land from Māori, who received cash. The government bought practically all the useful land, then resold it to the New Zealand Company, which promoted immigration, or leased it for sheep runs. The Company resold the best tracts to British settlers; its profits were used to pay the travel of the immigrants from Britain.
Because of the vast distances involved, the first settlers were self-sufficient farmers. By the 1840s, however, large scale sheep ranches were exporting large quantities of wool to the textile mills of England. Most of the first settlers were brought over by a programme operated by the New Zealand Company (inspired by Edward Gibbon Wakefield) and were located in the central region on either side of Cook Strait, and at Wellington, Wanganui, New Plymouth and Nelson. These settlements had access to some of the richest plains in the country and after refrigerated ships appeared in 1882, they developed into closely settled regions of small-scale farming. Outside these compact settlements were the sheep runs. Pioneer pastoralists, often men with experience as squatters in Australia, leased lands from the government at the annual rate of £5 plus £1 for each 1,000 sheep above the first 5,000. The leases were renewed automatically, which gave the wealthy pastoralists a strong landed interest and made them a powerful political force. In all between 1856 and 1876, 8.1 million acres were sold for £7.6 million, and 2.2 million acres were given free to soldiers, sailors and settlers.
Gold discoveries in Otago (1861) and Westland (1865), caused a worldwide gold rush that more than doubled the population in a short period, from 71,000 in 1859 to 164,000 in 1863. The value of trade increased fivefold from £2 million to £10 million. As the gold boom ended Premier Julius Vogel borrowed money from British investors and launched in 1870 an ambitious programme of public works and infrastructure investment, together with a policy of assisted immigration. Successive governments expanded the program with offices across Britain that enticed settlers and gave them and their families one-way tickets.
Wakefield's vision.
British writer Edward Gibbon Wakefield (1796–1862) exerted a far-reaching influence. His plans for systematic British colonisation focused on a free labour system, in contrast to slavery that existed in the United States and convict labour in Australia. Inspired by evangelical religion and abolitionism, Wakefield's essays (1829 to 1849), condemned both slavery and indentured and convict labour, as immoral, unjust, and inefficient. Instead, he proposed a government sponsored system in which the price of farm land was set at a high enough level to prevent urban workers from easily purchasing it and thus leaving the labour market. His colonisation programs were over-elaborate and operated on a much smaller scale than he hoped for, but his ideas influenced law and culture, especially his vision for the colony as the embodiment of post-Enlightenment ideals, the notion of New Zealand as a model society, and the sense of fairness in employer-employee relations.
Women.
Although norms of masculinity were dominant, strong minded women originated a feminist movement starting in the 1860s, well before women gained the right to vote in 1893. Middle class women employed the media (especially newspapers) to communicate with each other and define their priorities. Prominent feminist writers included Mary Taylor, Mary Colclough (pseud. Polly Plum), and Ellen Ellis. The first signs of a politicised collective female identity came in crusades to pass the Contagious Diseases Prevention Act.
Feminists by the 1880s were using the rhetoric of "white slavery" to reveal men's sexual and social oppression of women. By demanding that men take responsibility for the right of women to walk the streets in safety, New Zealand feminists deployed the rhetoric of white slavery to argue for women's sexual and social freedom. Middle class women successfully mobilised to stop prostitution, especially during the First World War.
Māori women developed their own form of feminism, derived from Māori nationalism rather than European sources.
In 1893 Elizabeth Yates was elected mayor of Onehunga, making her the first woman in the British Empire to hold the office. She was an able administrator: she cut the debt, reorganised the fire brigade, and improved the roads and sanitation. Many men were hostile however, and she was defeated for re-election. Hutching argues that after 1890 women were increasingly well organised through the National Council of Women, the Women's Christian Temperance Union (WCTU), the Women's International League, and the Housewives Union, and others. By 1910 they were campaigning for peace, and against compulsory military training, and conscription. They demanded arbitration and the peaceful resolution of international disputes. The women argued that womenhood (thanks to motherhood) was the repository of superior moral values and concerns and from their domestic experience they knew best how to resolve conflicts.
Schools.
Prior to 1877 schools were operated by the provincial government, churches, or by private subscription. Education was not a requirement and many children did not attend any school, especially farm children whose labour was important to the family economy. The quality of education provided varied substantially depending on the school. The Education Act of 1877 created New Zealand's first free national system of primary education, establishing standards that educators should meet, and making education compulsory for children aged 5 to 15.
Immigration.
From 1840 there was considerable European settlement, primarily from England and Wales, Scotland and Ireland; and to a lesser extent the United States, India, China, and various parts of continental Europe, including the province of Dalmatia in what is now Croatia, and Bohemia in what is now the Czech Republic. Already a majority of the population by 1859, the number of white settlers (called "Pākehā" by Māori) increased rapidly to reach a million by 1911.
In the 1870s and 1880s, several thousand Chinese men, mostly from Guangdong, migrated to New Zealand to work on the South Island goldfields. Although the first Chinese migrants had been invited by the Otago Provincial government they quickly became the target of hostility from white settlers and laws were enacted specifically to discourage them from coming to New Zealand.
Māori adaptation and resistance.
Māori had welcomed Pākehā for the trading opportunities and guns they brought. However it soon became clear that they had underestimated the number of settlers that would arrive in their lands. "Iwi" (tribes) whose land was the base of the main settlements quickly lost much of their land and autonomy through government acts. Others prospered – until about 1860 the city of Auckland bought most of its food from Māori who grew and sold it themselves. Many "iwi" owned flour mills, ships and other items of European technology, some exported food to Australia for a brief period during the 1850s gold rush. Although race relations were generally peaceful in this period, there were conflicts over who had ultimate power in particular areas – the Governor or the Māori chiefs. One such conflict was the Northern or Flagstaff War of the 1840s, during which Kororareka was sacked.
As the "Pākehā" population grew, pressure grew on Māori to sell more land. Land is not only an economic resource, but also one basis of Māori identity and a connection with their ancestor's bones. Land was used communally,but under the mana of chiefs. In Māori culture there was no such idea as selling land until the arrival of Europeans. The means of acquiring land was to defeat another hapu or iwi in battle and seize their land. Te Rauparaha seized the land of many lower North Island and upper South Island iwi during the musket wars. Land was usually not given up without discussion and consultation. When an iwi was divided over the question of selling this could lead to great difficulties as at Waitara.
Pākehā had little understanding of all that and accused Māori of holding onto land they did not use efficiently. Competition for land was one important cause of the New Zealand Wars of the 1860s and 1870s, in which the Taranaki and Waikato regions were invaded by colonial troops and Māori of these regions had some of their land taken from them. The wars and confiscation left bitterness that remains to this day. After the conclusion of the Land Wars some iwi, especially in the Waikato, such as Ngati Haua sold land freely. However, only the chiefs and their whanau benefited from this income. The 2013 Ngati Haua treaty settlement recognised that many Ngati Haua had not received any benefit from the large payments in the 1870s hence the government was paying compensation.
Some iwi sided with the government and, later, fought with the government. They were motivated partly by the thought that an alliance with the government would benefit them, and partly by old feuds with the iwi they fought against. One result of their co-operation strategy was the establishment of the four Māori seats in parliament, in 1867.
After the wars, some Māori began a strategy of passive resistance, most famously at Parihaka in Taranaki. Most, such as NgaPuhi and Arawa continued co-operating with Pākehā. For example, tourism ventures were established by Te Arawa around Rotorua. Resisting and co-operating iwi both found that Pākehā desire for land remained. In the last decades of the century, most iwi lost substantial amounts of land through the activities of the Native Land Court. This was set up to give Māori land European-style titles and to establish exactly who owned it. Due to its Eurocentric rules, the high fees, its location remote from the lands in question, and unfair practices by some Pākehā land agents, its main effect was to allow Māori to sell their land without restraint from other tribal members.
The combination of war, confiscations, disease, assimilation and intermarriage, land loss leading to poor housing and alcohol abuse, and general disillusionment, caused a fall in the Māori population from around 86,000 in 1769 to around 70,000 in 1840 and around 48,000 by 1874, hitting a low point of 42,000 in 1896. Subsequently their numbers began to recover.
South Island.
While the North Island was convulsed by the Land Wars, the South Island, with its low Māori population, was generally peaceful. In 1861 gold was discovered at Gabriel's Gully in Central Otago, sparking a gold rush. Dunedin became the wealthiest city in the country and many in the South Island resented financing the North Island's wars. In 1865 Parliament defeated a proposal to make the South Island independent by 17 to 31.
The South Island contained most of the Pākehā population until around 1900 when the North Island again took the lead and has supported an ever greater majority of the country's total population through the 20th century and into the 21st.
Scottish immigrants dominated the South Island and evolved ways to bridge the old homeland and the new. Many local Caledonian societies were formed. They organised sports teams to entice the young and preserved an idealised Scottish national myth (based on Robert Burns) for the elderly. They gave Scots a path to assimilation and cultural integration as Scottish New Zealanders.
1890–1914.
Politics.
The prewar era saw the advent of party politics, with the establishment of the Liberal Government. The landed gentry and aristocracy ruled Britain at this time. New Zealand never had an aristocracy but it did have wealthy landowners who largely controlled politics before 1891. The Liberal Party set out to change that by a policy it called "populism." Richard Seddon had proclaimed the goal as early as 1884: "It is the rich and the poor; it is the wealthy and the landowners against the middle and labouring classes. That, Sir, shows the real political position of New Zealand." The Liberal strategy was to create a large class of small land-owning farmers who supported Liberal ideals. The First Liberal government also established the basis of the later welfare state, with old age pensions, developed a system for settling industrial disputes, which was accepted by both employers and trade unions. In 1893 it extended voting rights to women, making New Zealand the first country in the world to enact universal female suffrage.
To obtain land for farmers the Liberal government from 1891 to 1911 purchased 3.1 million acres of Māori land. The government also purchased 1.3 million acres from large estate holders for subdivision and closer settlement by small farmers. The Advances to Settlers Act of 1894 provided low-interest mortgages, while the Agriculture Department disseminated information on the best farming methods.
The 1909 Native Land Act allowed the Māori to sell land to private buyers. Māori still owned five million acres by 1920; they leased three million acres and used one million acres for themselves. The Liberals proclaimed success in forging an egalitarian, antimonopoly land policy. The policy built up support for the Liberal party in rural North Island electorates. By 1903 the Liberals were so dominant that there was no longer an organised opposition in Parliament.
New Zealand gained international attention for its reforms, especially how the state regulated labour relations. Of special note were innovations in the areas of maximum hour regulations, minimum wage laws, and compulsory arbitration procedures. The goal was to encourage unions but discourage strikes and class conflict. The impact was especially strong on the reform movement in the United States.
Coleman argues that the Liberals in 1891 lacked a clear-cut ideology to guide them. Instead they approached the nation's problems pragmatically, keeping in mind the constraints imposed by democratic public opinion. To deal with the issue of land distribution, they worked out innovative solutions to access, tenure, and a graduated tax on unimproved values.
Economy.
Major changes occurred during this decade. The economy grew from one based on wool and local trade to the export of wool, cheese, butter and frozen beef and mutton to Britain, a change enabled by the invention of refrigerated steamships in 1882. Refrigerated shipping remained the basis of New Zealand's economy until the 1970s. New Zealand's highly productive agriculture gave it probably the world's highest standard of living, with fewer at the rich and poor ends of the scale.
In the 1880–1914 era the banking system was weak and there was little foreign investment, so businessmen had to build up their own capital. Historians have debated whether the "long depression" of the late 19th century stifled investment, but the New Zealanders found a way around adverse conditions. Hunter has studied the experiences of 133 entrepreneurs who started commercial enterprises between 1880 and 1910. The successful strategy was to deploy capital economising techniques, and reinvesting profits rather than borrowing. The result was slow but stable growth that avoided bubbles and led to long-lived family owned firms.
Dominion and Realm.
New Zealand initially expressed interest in joining the proposed Federation of the Australian colonies, attending the 1891 National Australia Convention in Sydney. Interest in the proposed Australian Federation faded and New Zealand decided against joining the Commonwealth of Australia in 1901, and instead changed from being a colony to a separate "dominion" in 1907, equal in status to Australia and Canada.
Prohibition.
In New Zealand, prohibition was a moralistic reform movement begun in the mid-1880s by the Protestant evangelical and Nonconformist churches and the Woman's Christian Temperance Union and after 1890 by the Prohibition League. It never achieved its goal of national prohibition. It was a middle-class movement which accepted the existing economic and social order; the effort to legislate morality assumed that individual redemption was all that was needed to carry the colony forward from a pioneering society to a more mature one. However, both the Church of England and the largely Irish Catholic Church rejected prohibition as an intrusion of government into the church's domain, while the growing labour movement saw capitalism rather than alcohol as the enemy. Reformers hoped that the women's vote, in which New Zealand was a pioneer, would swing the balance, but the women were not as well organised as in other countries. Prohibition had a majority in a national referendum in 1911, but needed a 60% majority to pass. The movement kept trying in the 1920s, losing three more referenda by close votes; it managed to keep in place a 6 pm closing hour for pubs and Sunday closing. The Depression and war years effectively ended the movement.
First World War.
The country remained an enthusiastic member of the British Empire, and 110,000 men fought in World War I (see New Zealand Expeditionary Force). 16,688 died. Conscription had been in force since 1909, and while it was opposed in peacetime there was less opposition during the war. The labour movement was pacifistic, opposed the war, and alleged that the rich were benefitting at the expense of the workers. It formed the Labour Party in 1916. Māori tribes that had been close to the government sent their young men to volunteer. Unlike in Britain, relatively few women became involved. Women did serve as nurses; 640 joined the services and 500 went overseas.
New Zealand forces captured Western Samoa from Germany in the early stages of the war, and New Zealand administered the country until Samoan Independence in 1962. However Samoans greatly resented the imperialism, and blamed inflation and the catastrophic 1918 flu epidemic on New Zealand rule.
The heroism of the soldiers in the failed Gallipoli campaign made their sacrifices iconic in New Zealand memory, and secured the psychological independence of the nation.
1920s.
After the war New Zealand signed the Treaty of Versailles (1919) joined the League of Nations and pursued an independent foreign policy, while its defence was still controlled by Britain. New Zealand depended on Britain's Royal Navy for its military security during the 1920s and 1930s. Officials in Wellington trusted Conservative Party governments in London, but not Labour. When the British Labour Party took power in 1924 and 1929, the New Zealand government felt threatened by Labour's foreign policy because of its reliance upon the League of Nations. The League was distrusted and Wellington did not expect to see the coming of a peaceful world order under League auspices. What had been the Empire's most loyal dominion became a dissenter as it opposed efforts the first and second British Labour governments to trust the League's framework of arbitration and collective security agreements.
The governments of the Reform and United parties between 1912 and 1935 followed a "realistic" foreign policy. They made national security a high priority, were sceptical of international institutions, and showed no interest on the questions of self-determination, democracy, and human rights. However the opposition Labour Party was more idealistic and proposed a liberal internationalist outlook on international affairs.
The Labour Party emerged as a force in 1919 with a Socialist platform. It won about 25% of the vote. However its appeals to working class solidarity were not effective because a large fraction of the working class voted for conservative candidates of the Liberal and Reform parties. (They merged in 1936 to form the National Party.) As a consequence the Labour party was able to jettison its support for socialism in 1927 (a policy made official in 1951), as it expanded its reach into middle class constituencies. The result was a jump in strength to 35% in 1931, 47% in 1935, and peaking at 56% in 1938. From 1935 the First Labour Government showed a limited degree of idealism in foreign policy, for example opposing the appeasement of Germany and Japan.
Depression.
Like most other countries, New Zealand was hard hit by the Great Depression of the 1930s, which affected the country via its international trade, with farming export drops then going on to affect the money supply and in turn consumption, investment and imports. The country was most affected around 1930–1932, when average farm incomes for a short time dipped below zero, and the unemployment rates peaked. Though actual unemployment numbers were not officially counted, the country was affected especially strongly in the North Island.
Unlike later years, there were no public benefit ('dole') payments – the unemployed were given 'relief work', much of which was however not very productive, partly because the size of the problem was unprecedented. Women also increasingly registered as unemployed, while Māori received government help through other channels such as the land development schemes organised by Apirana Ngata. In 1933, 8.5% of the unemployed were organised in work camps, while the rest received work close to their homes. Typical occupations in relief work were road work (undertaken by 45% of all part-time and 19% of all full-time relief workers in 1934, with park improvement works (17%) and farm work (31%) being the other two most common types of work for part-time and full-time relief workers respectively).
Labour in power.
Attempts by the United-Reform Coalition to deal with the situation with spending cuts and relief work were ineffective and unpopular. In 1935, the First Labour Government was elected, and the post-depression decade showed that average Labour support in New Zealand had roughly doubled comparable to pre-depression times. By 1935 economic conditions had improved somewhat, and the new government had more positive financial conditions. Prime Minister Michael Joseph Savage proclaimed that: "Social Justice must be the guiding principle and economic organization must adapt itself to social needs."
The new government quickly set about implementing a number of significant reforms, including a reorganisation of the social welfare system and the creation of the state housing scheme. Labour also gained Māori votes by working closely with the Rātana movement. Savage was idolised by the working classes, and his portrait hung on the walls of many houses around the country. The newly created welfare state promised government support to individuals "from the cradle to the grave", according to the Labour slogan. It included free health care and education, and state assistance for the elderly, infirm, and unemployed. The opposition attacked the Labour Party's more left-wing policies, and accused it of undermining free enterprise and hard work. The Reform Party and the United Party merged to become the National Party, and would be Labour's main rival in future years. However the welfare state system was retained and expanded by successive National and Labour governments until the 1980s.
Second World War.
When World War II broke out in 1939, New Zealanders saw their proper role as defending their proud place in the British Empire. It contributed some 120,000 troops. They mostly fought in North Africa, Greece/Crete, and Italy, relying on the Royal Navy and later the United States to protect New Zealand from the Japanese forces. Japan had no interest in New Zealand in the first place; it had already over-reached when it invaded New Guinea in 1942. (There were a few highly publicised but ineffective Japanese scouting incursions.) The 3rd New Zealand Division fought in the Solomons in 1943–44, but New Zealand's limited manpower meant 2 Divisions could not be maintained, and it was disbanded and its men returned to civilian life or used to reinforce the 2nd Division in Italy.
The armed forces peaked at 157,000 in September 1942; 135,000 served abroad, and 10,100 died.
Cooperation with the United States set a direction of policy which resulted in the ANZUS Treaty between New Zealand, America and Australia in 1951, as well as participation in the Korean War.
Fedorowich and Bridge argue that the demands of War produced long-term consequences for New Zealand's relationship with the government in London. The key component was the office of the high commissioner. By 1950 it was the main line of communications between the British and New Zealand governments.
Home front.
New Zealand, with a population of 1.7 million, including 99,000 Māori, was highly mobilised during the war. The Labour party was in power and promoted unionisation and the welfare state. Agriculture expanded, sending record supplies of meat, butter and wool to Britain. When American forces arrived, they were fed as well.
The nation spent £574 million on the war, of which 43% came from taxes, 41% from loans and 16% from American Lend Lease. It was an era of prosperity as the national income soared from £158 million in 1937 to £292 million in 1944. Rationing and price controls kept inflation to only 14% during 1939–45.
Montgomerie shows that the war dramatically increased the roles of women, especially married women, in the labour force. Most of them took traditional female jobs. Some replaced men but the changes here were temporary and reversed in 1945. After the war, women left traditional male occupations and many women gave up paid employment to return home. There was no radical change in gender roles but the war intensified occupational trends under way since the 1920s.
Post-war.
Mainstream New Zealand culture was deeply British and conservative, with the concept of "fairness" holding a central role. From the 1890s, the economy had been based almost entirely on the export of frozen meat and dairy products to Britain, and in 1961, the share of New Zealand exports going to the United Kingdom was still at slightly over 51%, with approximately 15% more going to other European countries. This system was irreparably damaged by Britain joining the European Economic Community in 1973, at a time of global economic upheaval regarding energy prices. Britain's accession to the European Community forced New Zealand to not only find new markets, but also re-examine its national identity and place in the world.
Māori urbanisation.
Māori always had a high birth rate; that was neutralised by a high death rate until modern public health measures became effective in the 20th century when tuberculosis deaths and infant mortality declined sharply. Life expectancy grew from 49 years in 1926 to 60 years in 1961 and the total numbers grew rapidly. Many Māori served in the Second World War and learned how to cope in the modern urban world; others moved from their rural homes to the cities to take up jobs vacated by Pākehā servicemen. The shift to the cities was also caused by their strong birth rates in the early 20th century, with the existing rural farms in Māori ownership having increasing difficulty in providing enough jobs. Māori culture had meanwhile undergone a renaissance thanks in part to politician Apirana Ngata. World War II saw the beginning of a mass Māori migration to the cities, and by the 1980s 80% of the Māori population was urban, in contrast to only 20% before the war. The migration led to better pay, higher standards of living and longer schooling, but also exposed problems of racism and discrimination. By the late 1960s, a protest movement had emerged to combat racism, promote Māori culture and seek fulfilment of the Treaty of Waitangi.
Urbanisation proceeded rapidly across the land. In the late 1940s, town planners noted that the country was "possibly the third most urbanised country in the world", with two-thirds of the population living in cities or towns. There was also increasing concern that this trend was badly managed, with it being noted that there was an "ill-defined urban pattern that appears to have few of the truly desirable urban qualities and yet manifests no compensating rural characteristics."
The "Muldoon years": 1975–1984.
The country's economy suffered in the aftermath of the 1973 global energy crisis, the loss of New Zealand's biggest export market upon Britain's entry to the European Economic Community, and rampant inflation. Rob Muldoon, Prime Minister from 1975 to 1984, and his Third National government responded to the crises of the 1970s by attempting to preserve the New Zealand of the 1950s. He attempted to maintain New Zealand's "cradle to the grave" welfare state, which dated to 1935. His government sought to give retirees 80% of the current wage, which would require large-scale borrowing; critics said it would bankrupt the treasury. Muldoon's response to the crisis also involved imposing a total freeze on wages, prices, interest rates and dividends across the national economy. His conservatism and antagonistic style exacerbated an atmosphere of conflict in New Zealand, most violently expressed during the 1981 Springbok Tour. In the 1984 elections Labour promised to calm down the increasing tensions, while making no specific promises; it scored a landslide victory.
However, Muldoon's Government was not entirely backward looking. Some innovations did take place, for example the Closer Economic Relations (CER) free-trade programme with Australia to liberalise trade, starting in 1982. The aim of total free trade between the two countries was achieved in 1990, five years ahead of schedule. Also, in 1983 the term "dominion" was replaced with "realm" by letters patent.
Contemporary history.
The radical 1980s reforms.
In 1984, the Fourth Labour government was elected amid a constitutional and economic crisis. Unexpectedly, the Labour government between 1984–1990 launched a major policy of restructuring the economy radically reducing the role of government. A political scientist reports:
"Between 1984 and 1993, New Zealand underwent radical economic reform, moving from what had probably been the most protected, regulated and state-dominated system of any capitalist democracy to an extreme position at the open, competitive, free-market end of the spectrum."
The economic reforms were led by finance minister Roger Douglas (finance minister (1984–1988), who enacted fundamental, radically neo-liberal and unexpectedly pro-free market reforms known as Rogernomics. This involved removing many of the favours and barriers that had long insulated the economy from world trends. It involved floating the New Zealand dollar, cutting government spending, reducing most taxes and introducing a sales tax (GST), and removing most subsidies. Rogernomics resembled the contemporaneous policies of Margaret Thatcher in Britain and Ronald Reagan in the US Rogernomics was a rapid programme of deregulation and public-asset sales. Subsidies were phased out to farmers and consumers. High finance was partly deregulated. Restrictions on foreign exchange were relaxed and the dollar was allowed to float and seek its natural level on the world market. The tax on high incomes was cut in half from 65% to 33%. The shares exchange entered a bubble, which then burst. Shares had a total value of $50 billion in 1987 and only $15 billion in 1991; Belich says that at one point the crash was "the worst in world." Overall the economic growth fell from 2% a year to 1%.
Strong criticism of Rogernomics came from the left, especially from Labour's traditional union and leftist support-base; Lange broke with Douglas's policies in 1987; both men were forced out and Labour was in confusion.
Other fourth Labour government innovations included greater recognition of the Treaty of Waitangi through the Waitangi Tribunal, Homosexual Law Reform, the Constitution Act 1986 and the New Zealand Bill of Rights.
The Fourth Labour Government also revolutionised New Zealand's foreign policy, making the country a nuclear-free zone and effectively leaving the ANZUS alliance. Immigration policy was liberalised, allowing an influx of immigrants from Asia. Previously most immigrants to New Zealand had been European and especially British, apart from some migrants from other Pacific Islands such as Samoa.
Continuing reform under National.
Voters unhappy with the rapid speed and far-reaching extent of reforms elected a National government in 1990, led by Jim Bolger. However the new government continued the economic reforms of the previous Labour government, in what was known as Ruthanasia. Unhappy with what seemed to be a pattern of governments failing to reflect the mood of the electorate, New Zealanders in 1992 and 1993 voted to change the electoral system to Mixed Member Proportional (MMP), a form of proportional representation. New Zealand's first MMP election was held in 1996. Following the election National was returned to power in coalition with the New Zealand First Party.
With the end of the Cold War in 1991, the nation's foreign policy turned increasingly to issues of its nuclear-free status and other military issues; its adjustment to neoliberalism in international trade relations; and its involvement in humanitarian, environmental, and other matters of international diplomacy.
21st century.
The Fifth Labour government led by Helen Clark was elected in 1999. It maintained most of the previous governments' economic reforms – restricting government intervention in the economy much more so than previous governments – while putting more of an emphasis on social policy and outcomes. For example, employment law was modified to give more protection to workers, and the student loan system was changed to eliminate interest payments for New Zealand resident students and graduates. Helen Clark's Labour government remained in power for nine years before being replaced in 2008 by New Zealand's Fifth National government led by John Key.
New Zealand retains strong but informal links to Britain, with many young New Zealanders travelling to Britain for their "OE" (overseas experience) due to favourable working visa arrangements with Britain. Despite New Zealand's immigration liberalisation in the 1980s, Britons are still the largest group of migrants to New Zealand, due in part to recent immigration law changes which privilege fluent speakers of English. One constitutional link to Britain remains – New Zealand's head of State, the Queen in Right of New Zealand, is a British resident. However, British imperial honours were discontinued in 1996, the Governor-General has taken a more active role in representing New Zealand overseas, and appeals from the Court of Appeal to the Judicial Committee of the Privy Council were replaced by a local Supreme Court of New Zealand in 2003. There is public debate about whether New Zealand should become a republic, and public sentiment is divided on the issue.
Foreign policy has been essentially independent since the mid-1980s. Under Prime Minister Clark, foreign policy reflected the priorities of liberal internationalism. She stressed the promotion of democracy and human rights; the strengthening of the role of the United Nations; the advancement of anti-militarism and disarmament; and the encouragement of free trade. She sent troops to the Afghanistan War, but did not contribute combat troops to the Iraq War although some medical and engineering units were sent.
John Key led the National Party to victory in both the November 2008 and the November 2011 general elections. Key leads the Fifth National Government of New Zealand which entered government at the beginning of the late-2000s recession in 2008. In his first term, Key's government implemented a GST rise and personal tax cuts. In February 2011, a major earthquake in Christchurch, the nation's second largest city, significantly impacted the national economy and the government formed the Canterbury Earthquake Recovery Authority in response. In its second term, Key's government announced a policy of partial privatisation of state-owned assets. In foreign policy, Key announced the withdrawal of New Zealand Defence Force personnel from their deployment in the war in Afghanistan, signed the Wellington Declaration with the United States and pushed for more nations to join the Trans-Pacific Strategic Economic Partnership.
Tourism and agriculture are now the major industries that contribute to New Zealand's economy. The traditional agricultural products of meat, dairy and wool has been supplemented by other products such as fruit, wine and timber.

</doc>
<doc id="39942" url="https://en.wikipedia.org/wiki?curid=39942" title="Jennifer Aniston">
Jennifer Aniston

Jennifer Joanna Aniston (born February 11, 1969) is an American actress, producer, and businesswoman. She is the daughter of actor John Aniston and actress Nancy Dow. Aniston gained worldwide recognition for portraying Rachel Green on the popular television sitcom "Friends" (1994–2004), a role which earned her a Primetime Emmy Award, a Golden Globe Award, and a Screen Actors Guild Award. The character was widely popular during the airing of the series and became recognized as one of the 100 greatest female characters in United States television.
Aniston has played the female protagonist in a number of comedies and romantic comedy films. Her box office hits include "Bruce Almighty" (2003), "The Break-Up" (2006), "Marley & Me" (2008), "Just Go with It" (2011), "Horrible Bosses" (2011) and "We're the Millers" (2013), each of which have grossed over 200 million in worldwide receipts. Her most critically acclaimed roles were in "The Good Girl" (2002), for which she was nominated for an Independent Spirit Award for Best Female Lead, and the drama "Cake" (2014), for which she received nominations for the Golden Globe Award and the Screen Actors Guild Award for Best Actress. Her other films include "Along Came Polly" (2004) and "He's Just Not That Into You" (2009). In 2008, she co-founded the production company Echo Films.
In 2012, Aniston received a star on the Hollywood Walk of Fame. She is one of the highest paid actresses in Hollywood and as of 2014, her net worth is estimated to be 150 million. She has also been included in magazines' lists of the world's most beautiful women. In 2004, Aniston was named "The Most Beautiful Woman" by "People" magazine, and "Men's Health" magazine voted her the "Sexiest Woman of All Time" in 2011. Divorced from actor Brad Pitt, to whom she was married for five years, she has been married to actor Justin Theroux since 2015.
Early life.
Aniston was born February 11, 1969, in Sherman Oaks, Los Angeles, California to actors John Aniston and Nancy Dow. Her father is Greek and a native of Crete, while her mother was born in New York City. One of her maternal great-grandfathers was an Italian immigrant and her mother's other ancestry is English, Scottish, Irish and a small amount of Greek. Aniston has two half-brothers, John Melick, her maternal older half-brother, and Alex Aniston, her younger paternal half-brother. Aniston's godfather was actor Telly Savalas, one of her father's best friends.
As a child, Aniston lived in Greece for a year with her family. They then moved to Eddystone, Pennsylvania, where they lived with her grandmother Stella Anastassakis in a three-bedroom home. While living in Eddystone, Aniston was enrolled at a local elementary school. She and her family later moved to New York City. Despite her father's television career, Aniston was discouraged from watching TV, though she found ways around the prohibition. When she was six, Aniston began attending a Waldorf school. During that time, Aniston's father and mother split when she was nine years old. Her father is best known for his role as Victor Kiriakis on the NBC daytime drama "Days of Our Lives", which he originated in 1985. Her mother appeared in two 1960s TV series, "The Wild Wild West" and "The Beverly Hillbillies".
Having discovered acting at eleven at the Waldorf school, Aniston enrolled and graduated at Manhattan's Fiorello H. LaGuardia High School of Music & Art and Performing Arts, where she joined the school's drama society.
In 2015, Aniston spoke about a childhood incident that led to lifelong fear of water. She stated during a special event for her film "Cake" (2015), "I basically have a real fear of going underwater. I was a kid and I was riding this tricycle around a swimming pool and I drove my tricycle into the swimming pool and I didn't let go and my brother tried to (help). So, I can't go underwater and no one will believe me. I honestly can’t." The incident led to filming a swimming pool scene 30 times on the set of the film with director Daniel Barnz before getting it right.
Career.
1988–93: Career beginnings.
Aniston worked in Off-Broadway productions such as "For Dear Life" and "Dancing on Checker's Grave", and supported herself with several part-time jobs, which included working as a telemarketer, waitress, and bike messenger. In 1989, Aniston appeared on "The Howard Stern Show", as a spokesmodel for "Nutrisystem". That year, Aniston moved back to Los Angeles.
Aniston was cast in her first television role in 1990, starring as a regular on the short-lived series "Molloy". She then co-starred in "Ferris Bueller", a television adaptation of the movie "Ferris Bueller's Day Off" (1986), and like "Molloy" also quickly canceled. Aniston then appeared in two more failed television comedy series, "The Edge" and "Muddling Through". Other roles included the horror film "Leprechaun" (1993), the TV movie "Camp Cucamonga"(1990), and guest roles on "Quantum Leap", "Herman's Head", and "Burke's Law".
1994–02: Television breakthrough and rising film career.
Depressed over her four unsuccessful television shows, Aniston approached Warren Littlefield at a Los Angeles gas station asking for reassurance about her career. The head of NBC entertainment encouraged Aniston to continue acting, and a few months later helped cast her for "Friends", a sitcom that was set to debut on NBC's 1994–1995 fall lineup. The producers of the show originally wanted Aniston to audition for the role of Monica Geller, but Courteney Cox was considered to be better suited to the role. Thus, Aniston was cast as Rachel Green. She was also offered a spot as a featured player on "Saturday Night Live", but turned it down to do "Friends". She played the character of Rachel from 1994 until the show ended in 2004.
The program was successful and Aniston, along with her co-stars, gained world-wide reputation among television viewers. Aniston received a salary of 1 million per episode for the last two seasons of "Friends", as well as five Emmy nominations (two for Supporting Actress, three for Lead Actress), including a win for Outstanding Lead Actress in a Comedy Series. She was also nominated for two Golden Globe Awards and won, in 2003, the Golden Globe Award for Best Actress – Television Series Musical or Comedy. According to the "Guinness World Book of Records" (2005), Aniston (along with her female costars) became the highest paid TV actress of all time with her 1 million-per-episode paycheck for the tenth season of "Friends". Her relationship with Ross Geller, portrayed by David Schwimmer in the show was widely popular among audiences and the couple were frequently voted as TV's favorite couple by polls and magazines.
Following a four-year hiatus from cinema, Aniston returned to film work in 1996, when she performed in the ensemble cast of the independent films "She's the One" (1996), and "Dream for an Insomniac" (1998). Aniston's first starring vehicle was the film "Picture Perfect" (1997), in which she starred opposite Kevin Bacon and Jay Mohr. While the film received mixed reviews, Aniston's performance was more warmly received, with many critics suggesting that she had screen presence. She starred in the cult film "Office Space" (1999) for director Mike Judge. She appeared in "The Object of My Affection" (1998), a comedy-drama about a woman who falls for a gay man (played by Paul Rudd).
She gained critical acclaim for her performance in the low-budget film "The Good Girl" (2002), playing an unglamorous cashier who cheats on her husband. The latter film opened in relatively few theaters – under 700 in total – taking 14 million in the U.S. box office. In 2002, film critic Roger Ebert declared the role as her breakthrough film, stating that, "after languishing in a series of overlooked movies that ranged from the entertaining "Office Space" to the disposable "Picture Perfect" (1997), Jennifer Aniston has at last decisively broken with her "Friends" image in an independent film of satiric fire and emotional turmoil. It will no longer be possible to consider her in the same way."
2003–11: Film career.
Aniston's biggest box office success to date was her appearance in the comedy "Bruce Almighty" (2003), in which she played the girlfriend of Jim Carrey's title character. Aniston then starred in the romantic comedy film "Along Came Polly" (2004) opposite Ben Stiller. Aniston appeared in two major studio films, the thriller "Derailed" (2005), and the rom-com "Rumor Has It..." (2005). Aniston appeared in the low-budget drama "Friends with Money" (2006), which was first shown at the Sundance Film Festival and received a limited release. Aniston's next film was the romantic comedy "The Break-Up" (2006) alongside Vince Vaughn which received mixed reviews. "The A.V. Club"s Keith Phipps gave the film a negative review stating, "It’s like watching the 'we were on a break' episode of Friends stretched to feature length, and without the blessed relief of commercial breaks or the promise of Seinfeld around the corner." "CinemaBlend" gave the film a positive review stating, "In an era of formulaic romantic movies that bear no resemblance to reality, " The Break-Up" offers a refreshing flipside." It was released on June 2 and grossed approximately 39.17 million during its opening weekend. The film was successful at the box office grossing 204 million worldwide.
Aniston directed a hospital emergency room-set short film called "Room 10" (2006), starring Robin Wright and Kris Kristofferson as part of "Glamour"s Reel Moments film series. Aniston noted that she was inspired to direct by actress Gwyneth Paltrow, who also directed a short film in 2006.
In 2007, Aniston guest starred in an episode of Courteney Cox Arquette's series "Dirt", playing Arquette's rival, Tina Harrod. She appeared in the third episode of Season 3 of NBC's "30 Rock" playing Liz Lemon's old college roommate who stalks Jack Donaghy.
On December 25, 2008, the comedy-drama "Marley & Me", in which Aniston starred alongside Owen Wilson, was released. It set a record for the largest Christmas Day box office ever with 14.75 million in ticket sales. It earned a total of 51.7 million over the four-day weekend and placed number one at the box office, a position it maintained for two weeks. The total worldwide gross was 242.7 million. Her next film in wide release, the romantic comedy-drama "He's Just Not That Into You" (2009), where she starred opposite Ben Affleck, opened in February. The movie grossed $178.8 million globally and ranked at number one at the United States box office for its opening weekend. While the film received mixed reviews, Aniston, along with Affleck, Ginnifer Goodwin, and Jennifer Connelly, were often praised by critics as being the stand-outs in the film.
On July 16, 2009, Aniston received an Emmy nomination in the category of Outstanding Guest Actress in a Comedy Series for her role on "30 Rock". Aniston was a guest star on the season 2 premiere of ABC's sitcom "Cougar Town", playing a psychiatrist. Her announcement to appear on "Cougar Town" garnered excitement and was dubbed as her return to television. "The A.V. Club" wrote, "Aniston plays Jules' therapist, and the part is more or less a twist on the old, 'The psychiatrist is crazier than the patient!' gimmick, though the show has a lot of fun with the idea that the therapist is obviously batshit [...] It's a funny bit, and it highlights just how much Jennifer Aniston is built to be a TV star." Numerous media outlets also praised her performance.
In March 2010, Aniston appeared in the romantic comedy action film "The Bounty Hunter", which costarred Gerard Butler. The film was panned by critics. "The Hollywood Reporter" described it as a "mishmash ends up as a thoroughly unfunny adult cartoon." 
It was a modest box office success, garnering over 130 million worldwide. A lukewarm box-office reception greeted her next film, the romantic comedy "The Switch" (2010), in which she co-starred with Jason Bateman. The film's opening weekend drew what "The Hollywood Reporter" dubbed "a dispiriting 8.4 million." The film received generally mixed reviews, with review site Metacritic showing 13 out of 30 critics delivering a positive verdict.
By June 20, 2010, Aniston's movies had grossed more than 1 billion in the United States and over 1.7 billion worldwide. Aniston's romantic comedy "Just Go with It" (2011), with Adam Sandler, was released on Valentine's Day weekend. The story is about a plastic surgeon, played by Sandler, who asks his office manager, played by Aniston, to pose as his wife, to prove his honesty to his much younger girlfriend, played by Brooklyn Decker. Aniston starred in the comedy movie "Horrible Bosses" (2011), with Colin Farrell, Jason Bateman, Charlie Day, and Jamie Foxx, directed by Seth Gordon. The film focuses on a trio of employees who plot to murder their titular tyrannical supervisors. Aniston played one of the bosses, a sexually aggressive dentist who harasses Charlie Day's character. She reprised her role in the sequel "Horrible Bosses 2" (2014).
2012–present.
Aniston appeared in the comedy "Wanderlust" (2012) with Paul Rudd, with whom she co-starred in the movie "The Object of My Affection" (1998) and also "Friends". The script for "Wanderlust", bought by Universal Pictures, was written by Rudd, Ken Marino, and David Wain, with the latter also directing the film, and was produced by Judd Apatow. The movie was about a married couple who join a commune after losing their money and deciding modern life is not for them. "Wanderlust" received mixed reviews and was a box office failure, grossing only $21 million worldwide, against a production budget of $35 million.
Aniston starred with Jason Sudeikis in EUE/Screen Gems Productions' "We're the Millers" (2013), filmed in the summer of 2012 in Wilmington, North Carolina and in the state of New Mexico. The film, a comedy about a drug dealer with a fake family, received mixed reviews from critics. "We're the Millers" was a financial success grossing 269 million against a budget of 37 million. Aniston played the role of Mickey Dawson in "Life of Crime" (2014), a film adaptation of Elmore Leonard's 1978 novel "The Switch". Catherine Shoard of "The Guardian" described her performance as "endearingly comic" and Eric Kohn of "Indie Wire" wrote that her role in the film outshone every recent film performance by her stating, "Aniston tops any of her recent performances with a spirited turn that harkens back to her neurotic days on Friends." The movie was released in the US to positive reviews. The cast include Tim Robins, John Hawkes, Mos Def, Isla Fisher, Will Forte and Mark Boone Junior.
Aniston starred in the film "Cake" (2014), directed by Daniel Barnz, portraying an astringent woman named Claire Simmons who struggles with chronic pain. The film received mixed reviews, however Aniston's performance was highly praised, dubbed by some critics as "Oscar-worthy." The Toronto International Film Festival called her performance "heartbreakingly good", Gregory Ellwood of "HitFix" stated, "It's really on most people's radar for being a rare dramatic turn for Jennifer Aniston, and she doesn't disappoint." He further stated, "Aniston makes you believe in Claire's pain. She makes you believe this character is at her lowest point and only she can pull herself out of it. [...] It's a complete performance from beginning to end and she deserves the appropriate accolades for it." For her portrayal, Aniston was nominated for the Broadcast Film Critics Association Award for Best Actress, Golden Globe Award for Best Actress in a Motion Picture – Drama, and Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Leading Role. The movie also starred Adriana Barraza, Anna Kendrick, Sam Worthington, Felicity Huffman and William H. Macy.
In 2015, she played Jane Claremont in "She's Funny That Way" directed by Peter Bogdanovich. The movie was produced by Wes Anderson and Noah Baumbach, and starred Owen Wilson, Imogen Poots, Kathryn Hahn, Rhys Ifans and Will Forte. 
Aniston starred in the romantic comedy "Mother's Day" (2016), directed by Garry Marshall and co-starring Julia Roberts, Kate Hudson, Timothy Olyphant and Jason Sudeikis. The film was released in April 2016. In December 2015, she started shooting the war drama film "The Yellow Birds", directed by Alexandre Moors, starring alongside Alden Ehrenreich, Tye Sheridan, Jack Huston and Toni Collette.
Other work and business ventures.
Aniston has appeared in various commercials and music videos throughout her career. In 1996, she was in Tom Petty and The Heartbreakers music video for "Walls". In 2001, Aniston was in Melissa Etheridge's music video for "I Want To Be In Love". She was cast in a Heineken commercial which was later banned in the U.S. due to branding issues. Aniston has also been in commercials for L'Oreal hair products. In 1995, Aniston and her "Friends" co-star Matthew Perry shot a 60-minute instructional video for the release of Microsoft's Windows 95 operating system. Along with Brad Pitt and Brad Grey, CEO of Paramount Pictures, Aniston founded the film production company Plan B Entertainment in 2002, although she and Grey withdrew in 2005. In 2008, she and producer Kristin Hahn formed the production company Echo Films.
Thanks to a contract sign with Elizabeth Arden, Inc., Aniston worked for over a year on a new perfume, which was released on July 21, 2010, at Harrods in London. Original plans called for the perfume to be named "Lolavie by Jennifer Aniston", but to avoid confusion with a similarly named perfume, the name was changed to simply "Jennifer Aniston". In an interview following the launch, Aniston said that she would also like to create a fragrance for men. In 2014, she launched her second perfume named "J by Jennifer Aniston", and in 2015 launched her third perfume named "Near Dusk by Jennifer Aniston".
Since 2007, Aniston has worked in a publicity campaign for the drink SmartWater; on March 7, 2011, she released a YouTube video, titled "Jennifer Aniston Goes Viral", for SmartWater, which tripled online interest in the product within 24 hours of its release.
In January 2013, Aniston became the new spokesperson and face of Aveeno Skincare. The commercials began airing in May 2013. She is also a spokesperson and co-owner of hair care brand Living Proof. In 2015, she became the new face of Emirates airline in a deal reported to be roughly 5 million.
Philanthropy.
Aniston is a supporter of Friends of El Faro, a grassroots non-profit organization that helps raise money for Casa Hogar Sion, an orphanage in Tijuana, Mexico. She has appeared in many TV commercials for St. Jude's Children's Research Hospital, which she supports. She also hosted September 2008's Stand Up to Cancer show. In the "It Can't Wait" campaign to free Burma, Aniston directed and starred in a video.
On April 14, 2007, Aniston received GLAAD's Vanguard Award for her contributions to increased visibility and understanding of the lesbian, gay, bisexual and transgender (LGBT) community. On Earth Day 2010, she joined Courteney Cox, Woody Harrelson, Ben Stiller and others,
in "The Cove PSA: My Friend is...", an effort to stop the slaughter of dolphins and protect the Japanese people from the toxic levels of mercury found in dolphin meat. Other charities that Aniston has supported include AmeriCares, Clothes Off Our Back, Feeding America, EB Medical Research Foundation, Project A.L.S., OmniPeace, and Rape, Abuse & Incest National Network.
Aniston donated 500,000 to Doctors Without Borders, Haitian health care provider Partners in Health and AmeriCares, and also participated in the Hope for Haiti Now telethon.
In 2013, she was named the Entertainment Industry Foundation (EIF) ambassador for the Saks Fifth Avenue Key To The Cure campaign, which raises funds for the EIF Women's Cancer Research Fund to support research into the detection, treatment, and cures for women's cancers.
In 2015, she supported the Comic Relief, Inc. charity.
Personal life.
Relationships.
In 1995, Aniston dated musician Adam Duritz. She also dated actor Tate Donovan from late 1995 until 1998.
Aniston's high-profile relationship with actor Brad Pitt was frequently publicized in the press. She married Pitt, after two years of dating, on July 29, 2000 in a lavish Malibu wedding. For a few years, their marriage was considered the rare Hollywood success, but on January 7, 2005 they announced their separation and finalized their divorce on October 2, 2005. During their divorce proceedings there was intense speculation in the media that Pitt had been unfaithful to Aniston with his "Mr. & Mrs. Smith" co-star Angelina Jolie, whom he started dating soon after the split. In the following months, the public's reaction toward the divorce was reported in the press, and "Team Aniston" and "Team Jolie" T-shirts appeared throughout the country. The divorce made the front-pages of tabloid magazines for years, and it still continues to be discussed in the media. Aniston commented on the divorce in a January 2015 interview with "The Hollywood Reporter ", stating that "Nobody did anything wrong... It was just like, sometimes things ."
In 2005, media reports speculated that the split was due to Aniston's refusal to have children with Pitt. Aniston denied that this was the cause of their split in an August 2005 "Vanity Fair" magazine interview, stating, "I've never in my life said I didn't want to have children. I did and I do and I will... I would never give up that experience for a career." Aniston also revealed that her divorce prompted her to reach out to her mother, Nancy, from whom she was estranged for nearly a decade. They initially became estranged when Nancy talked about her daughter on a television show and later wrote a book entitled, "From Mother and Daughter to Friends: A Memoir" (1999). Aniston has also stated she was devastated by the death of her longtime therapist, whose work helped make her separation from Pitt easier. Aniston said her relationship with Pitt, which she does not regret, was "seven very intense years together" and that "it was a beautiful, complicated relationship".
Aniston dated actor Vince Vaughn from 2005 to December 2006. She subsequently dated musician John Mayer from 2008 to 2009.
Aniston started a relationship with actor, director and screenwriter Justin Theroux in May 2011. In January 2012, Aniston and Theroux purchased a home in Los Angeles's Bel-Air neighborhood for roughly 22 million. They became engaged on August 10, 2012 and were married on August 5, 2015 at their Bel Air estate.
Health and fitness.
Aniston practices yoga and a Budokan karate. In 2014, Aniston spoke of her Transcendental Meditation practice. When asked what the number one thing which has kept her looking so amazing is, she replied, "I'd say a little over a year ago I started doing TM and that's really changed everything. Starting your day off with that and ending with that is pretty powerful."
In January 2015, Aniston revealed that she was diagnosed with dyslexia in her 20s which affected her education and self-esteem. As a result, she does not read a lot. However, being diagnosed with the disorder changed her life. She stated, "I thought I wasn't smart. I just couldn't retain anything. Now I had this great discovery. I felt like all of my childhood trauma-dies, tragedies, dramas were explained."
In the media.
Wealth.
In 2007, "Forbes" rated Aniston as one of the top 20 richest women in entertainment and estimated her net worth to be about 110 million. Aniston was also included in the annual Star Salary Top 10 of trade magazine "The Hollywood Reporter" for 2006. According to "Forbes", in October 2007, Aniston was the top-selling celebrity face of the entertainment industry. She was also Hollywood's most profitable actress. Aniston has been on the "Forbes" Celebrity 100 list, based on "earnings and fame", every year since 2001, topping the list in 2003. For the year of 2008, "Forbes" listed Aniston's earnings as 27 million.
In 2014, Aniston ranked 3rd on "Forbes" Top Earning Actresses, earning US$31 million in that year. Her net worth is estimated to be 150 million as of 2014.
Public image.
In 2005, Aniston became the first-ever "GQ" Woman of the Year. She has frequently appeared on "People"s annual list of The Most Beautiful, and was number-one in 2004. She also topped the magazine's Best Dressed List in 2006. She has been a regular on "FHM"s 100 Sexiest Women list since 1996, ranking at number 79 in 2012, number 81 in 2010, number 24 in 2009 and number 27 in 2008. In 2011, "The Daily Telegraph" reported the most sought after body parts of the rich and famous revealed by two Hollywood plastic surgeons who carried out a survey among their patients to build up the picture of what the perfect woman would look like. Under the category of the most sought after body shape, Aniston was voted in the top three, alongside Gisele Bündchen and Penélope Cruz. In the same year, readers of "Men's Health" magazine voted Aniston the "Sexiest Woman of All Time".
Although Aniston disliked the hairstyle she wore during her first two years on "Friends", "The Rachel" became very popular among women. Aniston received a star on the Hollywood Walk of Fame on February 22, 2012. The star is located at 6270 Hollywood Boulevard, in front of The W Hollywood Hotel. It is recognized as STAR 2, 462nd.
On "Forbes" list of the 100 Most Powerful Actresses in Hollywood, she was ranked number-8 in 2009, number-2 in both 2011 and 2012, and number-3 in 2013.
Accolades.
Aniston's accolades include a Primetime Emmy Award, a Golden Globe Award, and a Screen Actors Guild Award.

</doc>
<doc id="39943" url="https://en.wikipedia.org/wiki?curid=39943" title="History of Malta">
History of Malta

Malta has been inhabited since settlements from Sicily arrived around 5200 BC. Malta's location has historically given it great strategic importance as a naval base, and a succession of powers, including the Phoenicians, Romans, Moors, Normans, Sicilians, Spanish, Order of St. John, French and British, have ruled the islands. Malta became an independent state in 1964, and a republic in 1974. Since 2004 the country has been a member state of the European Union.
Geology and prehistory.
Malta stands on an underwater ridge that extends from North Africa to Sicily. At some time in the distant past Malta was submerged, as shown by marine fossils embedded in rock in the highest points of Malta. As the ridge was pushed up and the Strait of Gibraltar closed through tectonic activity, the sea level was lower, and Malta was on a bridge of dry land that extended between the two continents, surrounded by large lakes. Some caverns in Malta have revealed bones of elephants, hippopotami, and other large animals now found in Africa, while others have revealed animals native to Europe.
Neolithic and Temple period.
People first arrived in Malta around 5200 BC. These first Neolithic people probably arrived from Sicily (about north), and were mainly farming and fishing communities, with some evidence of hunting activities. They apparently lived in caves and open dwellings. During the centuries that followed there is evidence of further contacts with other cultures, which left their influence on the local communities, evidenced by their pottery designs and colours.
One of the most notable periods of Malta's history is the temple period, starting around 3600 BC. The Ġgantija Temple in Gozo is one of the oldest free-standing buildings in the world. The name of the complex stems from the Maltese word "ġgant", which reflects the magnitude of the temple's size. Many of the temples are in the form of five semicircular rooms connected at the centre. It has been suggested that these might have represented the head, arms and legs of a deity, since one of the commonest kinds of statue found in these temples is a fat woman — a symbol of fertility. The Temple period lasted until about 2500 BC, at which point the civilization that raised these huge monoliths seems to have disappeared. There is much speculation about what might have happened and whether they were completely wiped out or assimilated.
Bronze Age.
After the Temple period came the Bronze Age. From this period there are remains of a number of settlements and villages, as well as dolmens — altar-like structures made out of very large slabs of stone. They are claimed to belong to a population certainly different from that which built the previous megalithic temples. It is presumed the population arrived from Sicily because of the similarity to the constructions found in the largest island of the Mediterranean sea. One surviving menhir, which was used to build temples, still stands at Kirkop; it is one of the few still in good condition. Among the most interesting and mysterious remnants of this era are the so-called cart ruts as they can be seen at a place on Malta called Clapham Junction. These are pairs of parallel channels cut into the surface of the rock, and extending for considerable distances, often in an exactly straight line. Their exact use is unknown. One suggestion is that beasts of burden used to pull carts along, and these channels would guide the carts and prevent the animals from straying. The society that built these structures eventually died out or at any rate disappeared.
Antiquity.
Phoenicians and Carthage.
Phoenicians possibly from Tyre began to colonize the islands in approximately the 8th century BC as an outpost from which they expanded sea explorations and trade in the Mediterranean. Phoenician tombs have been found in Rabat, Malta and the town of the same name on Gozo, which suggest that the main urban centres at the time were present-day Mdina on Malta and the Cittadella on Gozo. The former settlement was known as "Maleth" meaning "safe haven", and the whole island began to be referred to by that name.
The Maltese Islands fell under the hegemony of Carthage in around the 6th century BC, along with most other Phoenician colonies in the western Mediterranean. By the late 4th century BC, Malta had become a trading post linking southern Italy and Sicily to Tripolitania. This resulted in the introduction of Hellenistic features in architecture and pottery, although Malta was never a Greek colony. Hellenistic architectural features can be seen in the Punic temple at Tas-Silġ and a tower in Żurrieq. The Greek language also began to be used in Malta, as evidenced by the bilingual Phoenician and Greek inscriptions found on the Cippi of Melqart. In the 18th century, French scholar Jean-Jacques Barthélemy deciphered the extinct Phoenician alphabet using the inscriptions on these cippi.
In 255 BC, the Romans raided Malta during the First Punic War, devastating much of the island.
Roman rule.
According to Latin historian Livy, the Maltese Islands passed into the hands of the Romans at the start of the Second Punic War in the year 218 BC. As written by Livy, the commander of the Punic garrison on the Island surrendered without resistance to Tiberius Sempronius Longus, one of the two consuls for that year who was on his way to North Africa. The archipelago was part of the province of Sicily, but by the 1st century AD it had its own senate and people's assembly. By this time, both Malta and Gozo minted distinctive coins based on Roman weight measurements.
In the Roman period, the Punic city of "Maleth" became known as "Melite", and it became the administrative hub of the Island. Its size grew to its maximum extent, occupying the entire area of present-day Mdina and large parts of Rabat, extending to what is now the church of St Paul. Remains show that the city was surrounded by thick defensive walls and was also protected by a protective ditch that ran along the same line of St Rita Street, which was built directly above it. Remains hint that a religious centre with a number of temples was built on the highest part of the promontory. The remains of one impressive residence known as the "Domvs Romana" have been excavated, revealing well preserved Pompeian style mosaics. This "domus" seems to have been the residence of a rich Roman aristocrat, and it is believed to have been built in the 1st century BC and abandoned in the 2nd century AD.
The islands prospered under Roman rule, and were eventually distinguished as a Municipium and a Foederata Civitas. Many Roman antiquities still exist, testifying to the close link between the Maltese inhabitants and Sicily. Throughout the period of Roman rule, Latin became Malta's official language, and Roman religion was introduced in the islands. Despite this, the local Punic-Hellenistic culture and language is thought to have survived until at least until the 1st century AD.
In AD 60, the Acts of the Apostles records that Saint Paul was shipwrecked on an island named Melite, which many Bible scholars and Maltese conflate with Malta; there is a tradition that the shipwreck took place on the shores of the aptly named "St. Paul's Bay".
Malta remained part of the Roman Empire until the early 6th century AD. The Vandals and later the Ostrogoths might have briefly occupied the islands in the 5th century, but there is no archaeological evidence to support this.
Ancient Egytians and ancient Greeks have also inhabited the Maltese islands.
Byzantine rule.
In 533, Byzantine general Belisarius briefly landed at Malta while on his way from Sicily to North Africa, and by 535, the island was integrated into the Byzantine province of Sicily. During the Byzantine period, the main settlements remained the city of Melite on mainland Malta and the Citadel on Gozo, while Marsaxlokk, Marsaskala, Marsa and Xlendi are believed to have served as harbours. The relatively high quantity of Byzantine ceramics found in Malta suggests that the island might have had an important strategic role within the empire from the 6th to 8th centuries.
From the late 7th century onwards, the Mediterranean was being threatened by Muslim expansion. At this point, the Byzantines probably improved the defences of Malta, as can be seen by defensive walls built around the monastery at Tas-Silġ around the 8th century. The Byzantines might have also built the retrenchment which reduced Melite to one-third of its original size.
Middle Ages.
Arab period.
In 870 AD, Malta was occupied by Muslims from North Africa. According to Al-Himyarī, Aghlabids led by Halaf al-Hādim besieged the Byzantine city of Melite, which was ruled by governor Amros (probably Ambrosios). Al-Hādim was killed in the fighting, and Sawāda Ibn Muḥammad was sent from Sicily to continue the siege following his death. The duration of the siege is unknown, but it probably lasted for some weeks or months. After Melite fell to the invaders, the inhabitants were massacred, the city was destroyed and its churches were looted. Marble from Melite's churches was used to build the castle of Sousse.
According to Al-Himyarī, Malta remained almost uninhabited until it was resettled in around 1048 or 1049 by a Muslim community and their slaves, who rebuilt the city of Melite as Medina, making it "a finer place than it was before." However, archaeological evidence suggests that Melite/Medina was already a thriving Muslim settlement by the beginning of the 11th century, so Al-Himyarī's account might be unreliable.
In around 1053–54, the Byzantines besieged Medina but they were repelled by its defenders.
Although their rule was relatively short, the Arabs left a significant impact on Malta. In addition to their language, Siculo-Arabic, cotton, oranges and lemons and many new techniques in irrigation were introduced. Some of these, like the "noria" (waterwheel), are still used, unchanged, today. Many place names in Malta date to this period.
Norman Kingdom of Sicily rule.
Between 1194 and 1530, the Kingdom of Sicily ruled the Maltese islands and a process of full latinisation started in Malta.
In 1091, Count Roger I of Sicily, made an initial attempt to establish Norman rule of Malta and was greeted by the few native Christians. In 1127, his son Roger II of Sicily succeeded. This marked the gradual change from a Moorish cultural influence to a European one. In 1191, Tancred of Sicily appointed Margaritus of Brindisi the first Count of Malta. Until 1224, however, there remained a strong Muslim segment of society.
After the Norman conquest, the population of the Maltese islands kept growing mainly through immigration from the north (Sicily and Italy), with the exile to Malta of the entire male population of the town of Celano (Italy) in 1223, the stationing of a Norman and Sicilian garrison on Malta in 1240 and the settlement in Malta of noble families from Sicily between 1372 and 1450. As a consequence of this, one major academic study found that "the contemporary males of Malta most likely originated from Southern Italy, including Sicily and up to Calabria."
Malta was part of the Kingdom of Sicily for nearly 440 years. During this period, Malta was sold and resold to various feudal lords and barons and was dominated successively by the rulers of Swabia, Anjou, the Crown of Aragon, the Crown of Castile, and Spain. Eventually the Crown of Aragon, which then ruled Malta, joined with Castile in 1479, and Malta became part of the Spanish Empire.
Malta's administration thus fell in the hands of local nobility who formed a governing body called the "Università."
In September 1429, Hafsid Saracens attempted to capture Malta but were repelled by the Maltese. The invaders pillaged the countryside and took about 3000 inhabitants as slaves.
Hospitaller rule (1530–1798).
Early years.
In the early 16th century, the Ottoman Empire started spreading over the region, reaching South East Europe. The Spanish king Charles V feared that if Rome fell to the Turks, it would be the end of Christian Europe. In 1522, Suleiman I drove the Knights Hospitaller of St. John out of Rhodes. They dispersed to their commanderies in Europe. Wanting to protect Rome from invasion from the south, in 1530, Charles V handed over the island to these knights.
For the next 275 years, these famous "Knights of Malta" made the island their domain and made the Italian language official. They built towns, palaces, churches, gardens and fortifications and embellished the island with numerous works of art and enhanced cultural heritage.
The order of the Knights of St. John was originally established to set up outposts along the route to the Holy Land, to assist pilgrims going in either direction. Owing to the many confrontations that took place, one of their main tasks was to provide medical assistance, and even today the eight-pointed cross is still in wide use in ambulances and first aid organisations. In return for the many lives they saved, the Order received many newly conquered territories that had to be defended. Together with the need to defend the pilgrims in their care, this gave rise to the strong military wing of the knights. Over time, the Order became strong and rich. From hospitallers first and military second, these priorities reversed. Since much of the territory they covered was around the Mediterranean region, they became notable seamen.
From Malta the knights resumed their seaborne attacks of Ottoman shipping, and before long the Sultan Suleyman the Magnificent ordered a final attack on the Order. By this time the Knights had occupied the city of Birgu, which had excellent harbours to house their fleet. Also Birgu was one of the two major urban places at that time, the other most urban place being Mdina the old capital city of Malta. The defences around Birgu were enhanced and new fortifications built on the other point where now there is Senglea. Also a small fort was built at the tip of the peninsula where the city of Valletta now stands and was named Fort Saint Elmo.
Great Siege.
On 18 May 1565, Suleiman the Magnificent laid siege to Malta. By the time the Ottoman fleet arrived the Knights were as ready as they could be. First the Ottomans attacked the newly built fort of St. Elmo and after a whole month of fighting the fort was in rubble and the soldiers kept fighting until the Turks ended their lives. After this they started attacking Birgu and the fortifications at Senglea but to no gain.
After a protracted siege ended on 8 September of the same year, which became known in history as the Great Siege, the Ottoman Empire conceded defeat as the approaching winter storms threatened to prevent them from leaving. The Ottoman Empire had expected an easy victory within weeks. They had 40,000 men arrayed against the Knights' nine thousand, most of them Maltese soldiers and simple citizens bearing arms. Their loss of thousands of men was very demoralising. The Ottomans made no further significant military advances in Europe and the Sultan died a few years later.
After the siege.
The year after, the Order started work on a new city with fortifications like no other, on the Sciberras Peninsula which the Ottomans had used as a base during the siege. It was named Valletta after Jean Parisot de Valette, the Grand Master who had seen the Order through its victory. Since the Ottoman Empire never attacked again, the fortifications were never put to the test, and today remain one of the best-preserved fortifications of this period.
Unlike other rulers of the island, the Order of St. John did not have a "home country" outside the island. The island became their home, so they invested in it more heavily than any other power. Besides, its members came from noble families, and had amassed considerable fortune due to their services in the route to the Holy Land. The architectural and artistic remains of this period remain among the greatest of Malta's history, especially in their "prize jewel" — the city of Valletta.
However, as their main "raison d'être" had ceased to exist, the Order's glory days were over.
French occupation (1798–1800).
Over the years, the power of the knights declined; their reign ended in 1798 when Napoleon Bonaparte's expeditionary fleet stopped off there en route to his Egyptian expedition. Napoleon asked for safe harbour to resupply his ships, and when they refused to supply him with water, Napoleon Bonaparte sent a division to scale the hills of Valletta. Grand Master Hompesch capitulated on 11 June. The following day a treaty was signed by which the order handed over sovereignty of the island of Malta to the French Republic. In return the French Republic agreed to "employ all its credit at the congress of Rastatt to procure a principality for the Grand Master, equivalent to the one he gives up".
During his very short stay (six days), Napoleon accomplished quite a number of reforms, notably the creation of a new administration with a Government Commission, the creation of twelve municipalities, the setting up of a public finance administration, the abolition of all feudal rights and privileges, the abolition of slavery and the granting of freedom to all Turkish slaves (2000 in all). On the judicial level, a family code was framed and twelve judges were nominated. Public education was organised along principles laid down by Bonaparte himself, providing for primary and secondary education. Fifteen primary schools were founded and the university was replaced by an ’Ecole centrale’ in which there were eight chairs, all very scientific in outlook: notably, arithmetic and stereometry, algebra and stereotomy, geometry and astronomy, mechanics and physics, navigation, chemistry, etc.
He then sailed for Egypt leaving a substantial garrison in Malta. Since the Order had also been growing unpopular with the local Maltese, the latter initially viewed the French with optimism. This illusion did not last long. Within months the French were closing convents and seizing church treasures, most notably the sword of Jean de Valette which is to date still exhibited in the Louvre, in Paris. The Maltese people rebelled, and the French garrison of General Claude-Henri Belgrand de Vaubois retreated into Valletta. After several failed attempts by the locals to retake Valletta, the British were asked for their assistance. Rear Admiral Lord Horatio Nelson decided on a total blockade in 1799. The French garrison surrendered in 1800.
Malta in the British Empire (1800–1964).
British Malta in the 19th and early 20th centuries.
In 1800, Malta voluntarily became part of the British Empire as a protectorate. Under the terms of the 1802 Treaty of Amiens, Britain was supposed to evacuate the island, but failed to keep this obligation – one of several mutual cases of non-adherence to the treaty, which eventually led to its collapse and the resumption of war between Britain and France.
Although initially the island was not given much importance, its excellent harbours became a prized asset for the British, especially after the opening of the Suez Canal in 1869. The island became a military and naval fortress, the headquarters of the British Mediterranean fleet.
Home rule was refused to the Maltese until 1921 although a partly elected legislative council was created as early as 1849 (the first Council of Government under British rule had been held in 1835), and the locals sometimes suffered considerable poverty. This was due to the island being overpopulated and largely dependent on British military expenditure which varied with the demands of war. Throughout the 19th century, the British administration instituted several liberal constitutional reforms which were generally resisted by the Church and the Maltese elite who preferred to cling to their feudal privileges. Political organisations, like the Nationalist Party, were created or had as one of their aims, the protection of the Italian language in Malta.
In 1813 Malta was granted the Bathurst Constitution; in 1814 it was declared free of the plague, while the 1815 Congress of Vienna reaffirmed the British rule under the 1814 Treaty of Paris. In 1819, the local Italian-speaking "Università" was dissolved.
The year 1828 saw the revocation of the right of sanctuary, following the Vatican Church-State proclamation. Three years later, the See of Malta was made independent of the See of Palermo. In 1839, press censorship was abolished, and the construction of St. Paul's Anglican Cathedral began.
Following the 1846 Carnival riots, in 1849 a Council of Government with elected members under British rule was set up. In 1870 a referendum was held on ecclesiastics serving on Council of Government, and in 1881 an Executive Council under British rule was created; in 1887, the Council of Government was entrusted with "dual control" under British rule. A backlash came in 1903, with the Return to the 1849 form of Council of Government under British rule.
The last quarter of the century saw technical and financial progress in line with the Belle Epoque: the following years saw the foundation of the Anglo-Egyptian Bank (1882) and the beginning of operation of the Malta Railway (1883); the first definitive postage stamps were issued in 1885, and in 1904 tram service began.
In 1886 Surgeon Major David Bruce discovered the microbe causing the Malta Fever, and in 1905 Themistocles Zammit discovered the fever's sources.
Finally, in 1912, Dun Karm Psaila wrote his first poem in Maltese.
Between 1915 and 1918, during World War I, Malta became known as "the Nurse of the Mediterranean" due to the large number of wounded soldiers who were accommodated in Malta.
Malta in the Interwar period.
In 1919, the "Sette Giugno" (7 June) riots over the excessive price of bread led to greater autonomy for the locals during the 1920s. After Filippo Sciberras had convened a National Assembly, in 1921 self-government was granted under British rule. Malta obtained a bicameral parliament with a Senate (later abolished in 1949) and an elected Legislative Assembly. Joseph Howard was named Prime Minister. In 1923 the "Innu Malti" was played for the first time in public, and the same year Francisco Buhagiar became Prime Minister, followed in 1924 by Sir Ugo Pasquale Mifsud and in 1927 by Sir Gerald Strickland.
The 1930s saw a period of instability in the relations between the Maltese political elite, the Maltese Catholic church, and the British rulers; the 1921 Constitution was suspended twice. First in 1930–32, following a clash between the governing Constitutional Party Church and the latter's subsequent imposition of mortal sin on voters of the party and its allies, thus making a free and fair election impossible. Again, in 1933 the Constitution was withdrawn over the Government's budgetary vote for the teaching of Italian in elementary schools, after just 13 months of a Nationalist administration. Malta thus reverted to the Crown Colony status it held in 1813.
Before the arrival of the British, the official language since 1530 (and the one of the handful of educated elite) had been Italian, but this was downgraded by the increased use of English. In 1934 Maltese was declared an official language, which brought the number up to three. Two years later, the Letters Patent of the 1936 constitution declared that Maltese and English were the only official languages. Thereby legally settling the long-standing 'language question' that dominated Maltese politics for over half a century.
In 1934, only about 15% of the population could speak Italian fluently. This meant that out of 58,000 males qualified by age to be jurors, only 767 could qualify by language, as only Italian had until then been used in the courts.
In 1936 the Constitution was revised to provide for the nomination of members to Executive Council under British rule (similar to the 1835 constitution) and in 1939 to provide again for a partly elected Council of Government under British rule.
British Malta during the Second World War.
Before World War II, Valletta was the location of the Royal Navy's Mediterranean Fleet's headquarters. However, despite Winston Churchill's objections, the command was moved to Alexandria, Egypt, in April 1937 fearing it was too susceptible to air attacks from Europe. At the time of the Italian declaration of war (10 June 1940), Malta had a garrison of less than four thousand soldiers and about five weeks of food supplies for the population of about three hundred thousand. In addition, Malta's air defences consisted of about forty-two anti-aircraft guns (thirty-four "heavy" and eight "light") and four Gloster Gladiators, for which three pilots were available.
Being a British colony, situated close to Sicily and the Axis shipping lanes, Malta was bombarded by the Italian and German air forces. Malta was used by the British to launch attacks on the Italian navy and had a submarine base. It was also used as a listening post, reading German radio messages including Enigma traffic.
The first air raids against Malta occurred on 11 June 1940; there were six attacks that day. The island's biplanes were unable to defend due to the Luqa Airfield being unfinished; however, the airfield was ready by the seventh attack. Initially, the Italians would fly at about 5,500 m, then they dropped down to three thousand metres (in order to improve the accuracy of their bombs). Mabel Strickland would state, "The Italians decided they didn't like Gladiators and AA guns, so they dropped their bombs twenty miles off Malta and went back.". However, it was later proven that in fact, Italian bombing had been quite accurate and devastating to the island as a whole, and the words attributed to Mabel Strickland are today seen in the context of an increasingly desperate British propaganda exercise in the face of relentless Italian attacks.
By the end of August, the Gladiators were reinforced by twelve Hawker Hurricanes which had arrived via HMS "Argus". During the first five months of combat, the island's aircraft destroyed or damaged about thirty-seven Italian aircraft, while suffering even greater losses than the Italians. Italian fighter pilot Francisco Cavalera observed, "Malta was really a big problem for us—very well-defended.". Nevertheless, the Italian bombing campaign was causing serious damage to the island's infrastructure and the ability of the British Navy to operate effectively in the Mediterranean.
On Malta, 330 people had been killed and 297 were seriously wounded from the war's inception until December 1941. In January 1941, the German X. "Fliegerkorps" arrived in Sicily as the Afrika Korps arrived in Libya. Over the next four months 820 people were killed and 915 seriously wounded.
On 15 April 1942, King George VI awarded the George Cross (the highest civilian award for gallantry) "to the island fortress of Malta — its people and defenders." Franklin D. Roosevelt arrived on 8 December 1943, and presented a United States Presidential Citation to the people of Malta on behalf of the people of United States. He presented the scroll on 8 December, but dated it 7 December for symbolic reasons. In part it read: "Under repeated fire from the skies, Malta stood alone and unafraid in the center of the sea, one tiny bright flame in the darkness – a beacon of hope for the clearer days which have come." (The complete citation now stands on a plaque on the wall of the Grand Master's Palace on Republic Street in the town square of Valletta.)
In 1942, a convoy code-named Operation Pedestal was sent to relieve Malta. Five ships, including the tanker SS "Ohio", managed to arrive in the Grand Harbour, with enough supplies for Malta to survive. In the following year Franklin D. Roosevelt and Winston Churchill visited Malta. George VI also arrived in Grand Harbour for a visit.
During the Second World War, Ugo Mifsud and George Borg Olivier were the only remaining Nationalist members of parliament of Malta. Ugo Mifsud fainted after delivering a very passionate defence against the deportation to concentration camps in Uganda of Enrico Mizzi and 49 other Italian Maltese accused of pro-Italian political activities. He died a few days later.
In 1943, the Allies launched the invasion of Sicily from Malta. The invasion was coordinated from the Lascaris War Rooms in Valletta. Following the Armistice of Cassibile later in 1943, a large part of the Italian Navy surrendered to the British in Malta.
The Malta Conference was held in 1945, in which Churchill and Roosevelt met prior to the Yalta Conference with Joseph Stalin.
The 1946 National Assembly resulted in a new constitution in 1947. This restored Malta's self-government, with Paul Boffa as Prime Minister. On September 5th, 1947, universal suffrage for Women in Malta was granted. That year, Agatha Barbara was the first woman elected as a Maltese Member of Parliament.
From Home Rule to independence.
After the Second World War, the islands achieved self-rule, with the Malta Labour Party (MLP) of Dom Mintoff seeking either full integration with the UK or else "self-determination" (independence) and the Partit Nazzjonalista (PN) of George Borg Olivier favouring independence, with the same "dominion status" that Canada, Australia and New Zealand enjoyed.
The 1953 Coronation incident (where, initially, no invitation was sent for a Maltese delegation to attend the Coronation of Queen Elizabeth II), temporarily united Maltese politicians. After MLP's electoral victory in 1955, in December Round Table Talks were held in London, on the future of Malta, namely the Integration proposal put forward by Mintoff. It was attended by the new Prime Minister Dom Mintoff, Borg Olivier and other Maltese politicians, along with the British Colonial Secretary, Alan Lennox-Boyd. The British government agreed to offer the islands their own representation in British Parliament, with three seats in the House of Commons, with the Home Office taking over responsibility for Maltese affairs from the Colonial Office.
Under the proposals, the Maltese Parliament would retain responsibility over all affairs except defence, foreign policy, and taxation. The Maltese were also to have social and economic parity with the UK, to be guaranteed by the British Ministry of Defence (MoD) the islands' main source of employment.
A UK integration referendum was held on 11 and 12 February 1956, in which 77.02% of voters were in favour of the proposal, but owing to a boycott by the Nationalist Party and the Church, only 59.1% of the electorate voted, thereby rendering the result inconclusive.
There were also concerns expressed by British MPs that the representation of Malta at Westminster would set a precedent for other colonies, and influence the outcome of general elections.
In addition, the decreasing strategic importance of Malta to the Royal Navy meant that the British government was increasingly reluctant to maintain the naval dockyards. Following a decision by the Admiralty to dismiss 40 workers at the dockyard, Mintoff declared that "representatives of the Maltese people in Parliament declare that they are no longer bound by agreements and obligations toward the British government..." (the 1958 "Caravaggio incident") In response, the Colonial Secretary sent a cable to Mintoff, stating that he had "recklessly hazarded" the whole integration plan.
Under protest, Dom Mintoff resigned as Prime Minister along with all the MLP deputies on 21 April 1958. Georgio Borg Olivier was offered to form an alternative government by Governor Laycock but refused. This led to the Governor declaring a state of emergency thus suspending the constitution and Malta was placed under direct colonial administration from London. The MLP had now fully abandoned support for integration (when Mintoff's demands for financial guarantees were not accepted) and now advocated full independence from the British Crown. In 1959, an Interim Constitution provided for an Executive Council under British rule.
While France had implemented a similar policy in its colonies, some of which became overseas departments, the status offered to Malta from Britain constituted a unique exception. Malta was the only British colony where integration with the UK was seriously considered, and subsequent British governments have ruled out integration for remaining overseas territories, such as Gibraltar.
In 1961, the Blood Commission provided for a new constitution allowing for a measure of self-government and recognising the "State" of Malta. Giorgio Borg Olivier became Prime Minister the following year, when the Stolper report was delivered.
History of independent Malta (1964–).
Nationalist governments (1964–1971).
Following the passage of the "Malta Independence Act 1964" by the British Parliament and the approval of a new Maltese constitution by 54.5% of voters in a refendum, the State of Malta () was formed on 21 September 1964 as an independent constitutional monarchy, with Elizabeth II as Queen of Malta and Head of State. This is celebrated as Independence Day or "Jum l-Indipendenza" in Maltese. On 1 December 1964, Malta was admitted to the United Nations.
In the first two post-independence electoral rounds, in 1962 and 1966 the Nationalist Party emerged as the largest party, gaining a majority of the Parliamentary seats.
In 1965 Malta joined the Council of Europe, and in 1970, Malta signed an Association Treaty with the European Economic Community.
Labour governments (1971–1987).
The elections of 1971 saw the Labour Party (MLP) under Dom Mintoff win by just over 4,000 votes.
The Labour government immediately set out to re-negotiate the post-Independence military and financial agreements with the United Kingdom. The government also undertook nationalization programmes and the expansion of the public sector and the welfare state. Employment laws were updated with gender equality being introduced in salary pay. Concerning civil law, civil marriage was introduced and homosexuality and adultery were decriminalised (1973); capital punishment for murder was abolished in 1971. The following year, Malta entered into a Military Base Agreement with the United Kingdom and other NATO countries.
Under Mintoff's premiership, Malta began establishing close cultural and economic ties with Muammar Gaddafi's Libya, as well as diplomatic and military ties with North Korea.
Through a package of constitutional reforms agreed to with the Nationalist opposition, Malta became a republic on 13 December 1974, with the last Governor-General, Sir Anthony Mamo, as its first President. The "Ġieħ ir-Repubblika" Act, promulgated the following year, abolished all titles of nobility in Malta and mandated that they cease to be recognised.
The Party was confirmed in office in the 1976 elections. Between 1976 and 1981 Malta went through difficult times and the Labour government demanded that the Maltese were to tighten their belts in order to overcome the difficulties Malta was facing. There were shortages of essential items; the water and electricity supplies were systematically suspended for two or three days a week. Political tensions increased, notably on Black Monday when following an attempted assassination of the Prime Minister, the premises of the "Times of Malta" were burned and the house of the Leader of Opposition was attacked.
On 1 April 1979 the last British forces left the island after the end of the economic pact to stabilise the Maltese economy. This is celebrated as Freedom Day ("Jum Il-Ħelsien") on 31 March. Celebrations start with a ceremony in Floriana near the War Memorial. A popular event on this memorable day is the traditional regatta. The regatta is held at the Grand Harbour and the teams taking part in it give it their best shot to win the much coveted aggregate Regatta Shield.
The 1981 general elections saw the Nationalist Party (NP) gaining an absolute majority of votes, yet the Labour winning the majority of Parliamentary seats under the Single Transferable Vote and Mintoff remained Prime Minister, leading to a political crisis. The Nationalists, now led by Eddie Fenech Adami, refused to accept the electoral result and also refused to take their seats in parliament for the first years of the legislature, mounting a campaign demanding that Parliament should reflect the democratic will of the people. Despite this, the Labour government remained in power for the full five-year term. Mintoff resigned as Prime Minister and Party leader and appointed Karmenu Mifsud Bonnici as his successor in 1984.
The Mifsud Bonnici years were characterised by political tensions and violence. After a five-year debate, Fenech Adami, through the intervention of Dom Mintoff, reached an agreement with Karmenu Mifsud Bonnici to improve the constitution. Constitutional amendments were made voted and made effective in January 1987 which guaranteed that the party with an absolute majority of votes would be given a majority of parliamentary seats in order to govern. This paved the way for the return of the Nationalist Party to government later that year.
The accession process to the European Union (1987–2004).
The general elections that followed in 1987 saw the Nationalist Party achieve such a majority of votes. The new Nationalist administration of Edward Fenech Adami sought to improve Malta's ties with Western Europe and the United States.
The Nationalist Party advocated Malta's membership in the European Union presenting an application on 16 July 1990. This became a divisive issue, with Labour opposing membership.
A wide-raging programme of liberalisation and public investments meant the confirmation in office of the Nationalists with a larger majority in the 1992 elections. In 1993, local councils were re-established in Malta.
General elections were held in Malta on 26 October 1996; although the Labour received the most votes, the Nationalists won the most seats. The 1987 constitutional amendments had to be used for the second time, and the Labour Party was awarded an additional four seats to ensure they had a majority in Parliament.
Malta's EU application was subsequently frozen.
A split in the Labour Party in 1998, between the PM Sant and the former PM Mintoff (died in 2012) resulted in the government losing the majority. Notwithstanding the President of the Republic's preference for a negotiated solution, all attempts proved futile, and he had no other option but to accept Sant and his government's resignation and a call for early elections.
On being returned to office in the 1998 elections with a wide 13,000 vote margin, the Nationalist Party reactivated the EU membership application. Malta was formally accepted as a candidate country at the Helsinki European Council of December 1999.
In 2000, capital punishment was abolished also from the military code of Malta.
EU accession negotiations were concluded late in 2002 and a referendum on membership in 2003 saw 90.86% casting a valid vote of which 53.65% were "yes" votes. Labour stated that it would not be bound by this result were it returned to power in the following general election that year. In the circumstances, elections were called and the Nationalist Party won another mandate, electing as PM Lawrence Gonzi. The accession treaty was signed and ratified and Malta joined the EU on 1 May 2004. A consensus on membership was subsequently achieved with Labour saying it would respect this result. Joe Borg was appointed as first Maltese European commissioner in the first Barroso Commission.
Malta in the European Union (2004–).
In the context of EU membership, Malta joined the eurozone on 1 January 2008; the 2008 election confirmed Gonzi in the premiership, while in 2009 George Abela became President of Malta.
On 28 May 2011, Maltese voted 'yes' in the consultative divorce referendum. At that time, Malta was one of only three countries in the world, along with the Philippines and the Vatican City, in which divorce was not permitted. As a consequence of the referendum outcome, a law allowing divorce under certain conditions was enacted in the same year.
Following a corruption scandal John Dalli had to resign and was replaced by Tonio Borg as Maltese commissioner in 2012. A snap election was called for March 2013 after the Gonzi government lost the Parliamentary majority.
See also.
General:

</doc>
<doc id="39945" url="https://en.wikipedia.org/wiki?curid=39945" title="Negro league baseball">
Negro league baseball

The Negro leagues were United States professional baseball leagues comprising teams predominantly made up of African Americans and, to a lesser extent, Latin Americans. The term may be used broadly to include professional black teams outside the leagues and it may be used narrowly for the seven relatively successful leagues beginning in 1920 that are sometimes termed "Negro Major Leagues".
In 1885 the Cuban Giants formed the first black professional baseball team. The first league, the National Colored Base Ball League, was organized strictly as a minor league but failed in 1887 after only two weeks owing to low attendance. The Negro American League of 1951 is considered the last major league season and the last professional club, the Indianapolis Clowns, operated as a humorous sideshow rather than competitively from the mid-1960s to 1980s.
History of the Negro leagues.
Amateur era.
Because blacks were not being accepted into the major and minor baseball leagues, they formed their own teams and had made professional teams by the 1880s. The first known baseball game between two black teams was held on November 15, 1859, in New York City. The Henson Base Ball Club of Jamaica, Queens, defeated the Unknowns of Weeksville, Brooklyn, 54 to 43.
Immediately after the end of the American Civil War in 1865 and during the Reconstruction period that followed, a black baseball scene formed in the East and Mid-Atlantic states. Comprising mainly ex-soldiers and promoted by some well-known black officers, teams such as the Jamaica Monitor Club, Albany Bachelors, Philadelphia Excelsiors and Chicago Uniques started playing each other and any other team that would play against them.
By the end of the 1860s, the black baseball mecca was Philadelphia, which had an African-American population of 22,000. Two former cricket players, James H. Francis and Francis Wood, formed the Pythian Base Ball Club. They played in Camden, New Jersey, at the landing of the Federal Street Ferry, because it was difficult to get permits for black baseball games in the city. Octavius Catto, the promoter of the Pythians, decided to apply for membership in the National Association of Base Ball Players, normally a matter of sending delegates to the annual convention; beyond that, a formality. At the end of the 1867 season "the National Association of Baseball Players voted to exclude any club with a black player." In some ways "Blackball" thrived under segregation, with the few black teams of the day playing not only each other but white teams as well. "Black teams earned the bulk of their income playing white independent 'semipro' clubs."
Professional baseball.
Baseball featuring African American players became professionalized by the 1870s. The first known professional black baseball player was Bud Fowler, who appeared in a handful of games with a Chelsea, Massachusetts club in April 1878 and then pitched for the Lynn, Massachusetts team in the International Association.
Moses Fleetwood Walker and his brother, Welday Wilberforce Walker, were the first two black players in the major leagues. They both played for the 1884 Toledo Blue Stockings in the American Association. Then in 1886 second baseman Frank Grant joined the Buffalo Bisons of the International League, the strongest minor league, and hit .340, third highest in the league. Several other black American players joined the International League the following season, including pitchers George Stovey and Robert Higgins, but 1888 was the last season blacks were permitted in that or any other high minor league.
The first nationally-known black professional baseball team was founded in 1885 when three clubs, the Keystone Athletics of Philadelphia, the Orions of Philadelphia, and the Manhattans of Washington, D.C., merged to form the Cuban Giants.
The success of the Cubans led to the creation of the first recognized "Negro league" in 1887 – the National Colored Base Ball League. It was organized strictly as a minor league and founded with six teams: Baltimore Lord Baltimores, Boston Resolutes, Louisville Falls Citys, New York Gorhams, Philadelphia Pythians, and Pittsburgh Keystones. Two more joined before the season but never played a game, the Cincinnati Browns and Washington Capital Cities. The league, led by Walter S. Brown of Pittsburgh, applied for and was granted official minor league status and thus "protection" under the major league-led National Agreement. This move prevented any team in organized baseball from signing any of the NCBBL players, which also locked the players to their particular teams within the league. The reserve clause would have tied the players to their clubs from season to season but the NCBBL failed. One month into the season, the Resolutes folded. A week later, only three teams were left.
Because the original Cuban Giants were a popular and business success, many similarly named teams came into existence — including the Cuban X-Giants, a splinter and a powerhouse around 1900; the Genuine Cuban Giants, the renamed Cuban Giants, the Columbia Giants, the Brooklyn Royal Giants, and so on. The early "Cuban" teams were all composed of African Americans rather than Cubans; the purpose was to increase their acceptance with white patrons as Cuba was on very friendly terms with the US during those years. Beginning in 1899 several Cuban baseball teams played in North America, including the All Cubans, the Cuban Stars (West), the Cuban Stars (East), and the New York Cubans. Some of them included white Cuban players and some were Negro Leagues members.
The few players on the white minor league teams were constantly dodging verbal and physical abuse from both competitors and fans. Then the Compromise of 1877 removed the remaining obstacles from the South's enacting the Jim Crow laws. To make matters worse, on July 14, 1887, Cap Anson's Chicago White Stockings were scheduled to play the Newark Giants of the International League, which had Fleet Walker and George Stovey on its roster. After Anson marched his team onto the field, military style as was his custom, he demanded that the blacks not play. Newark capitulated, and later that same day, league owners voted to refuse future contracts to blacks, citing the "hazards" imposed by such athletes.
In 1888, the Middle States League was formed and it admitted two all-black teams to its otherwise all-white league, the Cuban Giants and their arch-rivals, the New York Gorhams. Despite the animosity between the two clubs, they managed to form a traveling team, the Colored All Americans. This enabled them to make money barnstorming while fulfilling their league obligations. In 1890, the Giants returned to their independent, barnstorming identity, and by 1892, they were the only black team in the East still in operation on a full-time basis.
Frank Leland.
Also in 1888, Frank Leland got some of Chicago's black businessmen to sponsor the black amateur Union Base Ball Club. Through Chicago's city government, Leland obtained a permit and lease to play at the South Side Park, a 5,000 seat facility. Eventually his team went pro and became the Chicago Unions.
After his stint with the Gorhams, Bud Fowler caught on with a team out of Findlay, Ohio. While his team was playing in Adrian, Michigan, Fowler was persuaded by two white local businessmen, L. W. Hoch and Rolla Taylor to help them start a team financed by the Page Woven Wire Fence Company, the Page Fence Giants. The Page Fence Giants went on to become a powerhouse team that had no home field. Barnstorming through the Midwest, they would play all comers. Their success became the prototype for black baseball for years to come.
After the 1898 season, the Page Fence Giants were forced to fold because of finances. Alvin H. Garrett, a black businessman in Chicago, and John W. Patterson, the left fielder for the Page Fence Giants, reformed the team under the name of the Columbia Giants. In 1901 the Giants folded because of a lack of a place to play. Leland bought the Giants in 1905 and merged it with his Unions (despite the fact that not a single Giant player ended up on the roster), and named them the Leland Giants.
Rube Foster.
The Philadelphia Giants, owned by Walter Schlichter, a white businessman, rose to prominence in 1903 when they lost to the Cuban X-Giants in their version of the "Colored Championship". Leading the way for the Cubans was a young pitcher by the name of Andrew "Rube" Foster. The following season, Schlichter, in the finest blackball tradition, hired Foster away from the Cubans, and beat them in their 1904 rematch. Philadelphia remained on top of the blackball world until Foster left the team in 1907 to play and manage the Leland Giants (Frank Leland renamed his Chicago Union Giants the Leland Giants in 1905).
Around the same time, Nat Strong, a white businessmen, started using his ownership of baseball fields in the New York City area to become the leading promoter of blackball on the East coast. Just about any game played in New York, Strong would get a cut. Strong eventually used his leverage to almost put the Brooklyn Royal Giants out of business, and then he bought the club and turned it into a barnstorming team.
When Foster joined the Leland Giants, he demanded that he be put in charge of not only the on-field activities, but the bookings as well. Foster immediately turned the Giants into "the" team to beat. He indoctrinated them to take the extra base, to play hit and run on nearly every pitch, and to rattle the opposing pitcher by taking them deep into the count. He studied the mechanics of his pitchers and could spot the smallest flaw, turning his average pitchers into learned craftsmen. Foster also was able to turn around the business end of the team as well, by demanding and getting 40 percent of the gate instead of the 10 percent that Frank Leland was getting.
By the end of the 1909, Foster demanded that Leland step back from all baseball operations or he (Foster) would leave. When Leland would not give up complete control, Foster quit, and in a heated court battle, got to keep the rights to the Leland Giants' name. Leland took the players and started a new team named the Chicago Giants, while Foster took the Leland Giants and started to encroach on Nat Strong's territory.
As early as 1910, Foster started talking about reviving the concept of an all-black league. The one thing he was insistent upon was that black teams should be owned by black men. This put him in direct competition with Strong. After 1910, Foster renamed his team the Chicago American Giants to appeal to a larger fan base. During the same year, J. L. Wilkinson started the All Nations traveling team. The All Nations team would eventually become one of the best-known and popular teams of the Negro leagues, the Kansas City Monarchs.
On April 6, 1917, the United States entered World War I. Manpower needed by the defense plants and industry accelerated the migration of blacks from the South to the North. This meant a larger and more affluent fan base with more money to spend. By the end of the war in 1919, Foster was again ready to start a Negro baseball league.
On February 13 and 14, 1920, talks were held in Kansas City, Missouri that established the Negro National League and its governing body the National Association of Colored Professional Base Ball Clubs. The league was initially composed of eight teams: Chicago American Giants, Chicago Giants, Cuban Stars, Dayton Marcos, Detroit Stars, Indianapolis ABC's, Kansas City Monarchs and St. Louis Giants. Foster was named league president and controlled every aspect of the league, including which players played on which teams, when and where teams played, and what equipment was used (all of which had to be purchased from Foster). Foster, as booking agent of the league, took a five percent cut of all gate receipts.
Golden age.
On May 2, 1920, the Indianapolis ABCs beat the Chicago American Giants (4–2) in the first game played in the inaugural season of the Negro National League, played at Washington Park in Indianapolis. But, because of the Chicago Race Riot of 1919, the National Guard still occupied the Giants' home field, Schorling's Park (formerly South Side Park). This forced Foster to cancel all the Giants' home games for almost a month and threatened to become a huge embarrassment for the league. On March 2, 1920 the Negro Southern League was founded in Atlanta, Georgia. In 1921, the Negro Southern League joined Foster's National Association of Colored Professional Base Ball Clubs. As a dues-paying member of the association, it received the same protection from raiding parties as any team in the Negro National League.
Foster then admitted John Connors' Atlantic City Bacharach Giants as an associate member to move further into Nat Strong's territory. Connors, wanting to return the favor of helping him against Strong, raided Ed Bolden's Hilldale Daisies team. Bolden saw little choice but to team up with Foster's nemesis, Nat Strong. Within days of calling a truce with Strong, Bolden made an about-face and signed up as an associate member of Foster's Negro National League.
On December 16, 1922, Bolden once again shifted sides and, with Strong, formed the Eastern Colored League as an alternative to Foster's Negro National League, which started with six teams: Atlantic City Bacharach Giants, Baltimore Black Sox, Brooklyn Royal Giants, New York Cuban Stars, Hilldale, and New York Lincoln Giants. The National League was having trouble maintaining continuity among its franchises: three teams folded and had to be replaced after the 1921 season, two others after the 1922 season, and two more after the 1923 season. Foster replaced the defunct teams, sometimes promoting whole teams from the Negro Southern League into the NNL. Finally Foster and Bolden met and agreed to an annual Negro League World Series beginning in 1924.
1925 saw the St. Louis Stars come of age in the Negro National League. They finished in second place during the second half of the year due in large part to their pitcher turned center fielder, Cool Papa Bell, and their shortstop, Willie Wells. A gas leak in his home nearly asphyxiated Rube Foster in 1926, and his increasingly erratic behavior led to him being committed to an asylum a year later. While Foster was out of the picture, the owners of the National League elected William C. Hueston as new league president. In 1927, Ed Bolden suffered a similar fate as Foster, by committing himself to a hospital because the pressure was too great. The Eastern League folded shortly after that, marking the end of the Negro League World Series between the NNL and the ECL.
After the Eastern League folded following the 1927 season, a new eastern league, the American Negro League, was formed to replace it. The makeup of the new ANL was nearly the same as the Eastern League, the exception being that the Homestead Grays joined in place of the now-defunct Brooklyn Royal Giants. The ANL lasted just one season. In the face of harder economic times, the Negro National League folded after the 1931 season. Some of its teams joined the only Negro league then left, the Negro Southern League.
On March 26, 1932 the Chicago "Defender" announced the end of Negro National League.
Satchel Paige, Josh Gibson, and Gus Greenlee.
Just as Negro league baseball seemed to be at its lowest point and was about to fade into history, along came Cumberland Posey and his Homestead Grays. Posey, Charlie Walker, John Roesnik, George Rossiter, John Drew, Lloyd Thompson and L.R. Williams got together in January 1932 and founded the East-West League. Eight cities were included in the new league: "Pittsburgh, Philadelphia, Detroit, Baltimore, Cleveland, Newark, New York, and Washington, D.C.". By May 1932, the Detroit Wolves were about to collapse, and instead of letting the team go, Posey kept pumping money into it. By June the Wolves had disintegrated and all the rest of the teams, except for the Grays, were beyond help, so Posey had to terminate the league.
Across town from Posey, Gus Greenlee, a reputed gangster and numbers runner, had just purchased the Pittsburgh Crawfords. Greenlee's main interest in baseball was to use it as a way to launder money from his numbers games. But, after learning about Posey's money-making machine in Homestead, he became obsessed with the sport and his Crawfords. On August 6, 1931, Satchel Paige made his first appearance as a Crawford. With Paige on his team, Greenlee took a huge risk by investing $100,000 in a new ballpark to be called Greenlee Field. On opening day, April 30, 1932, the pitcher-catcher battery was made up of the two most marketable icons in all of blackball: Satchel Paige and Josh Gibson.
In 1933, Greenlee, riding the popularity of his Crawfords, became the next man to start a Negro league. In February 1933, Greenlee and delegates from six other teams met at Greenlee's Crawford Grill to ratify the constitution of the National Organization of Professional Baseball Clubs. The name of the new league was the same as the old league Negro National League which had disbanded a year earlier in 1932. The members of the new league were the Pittsburgh Crawfords, Columbus Blue Birds, Indianapolis ABCs, Baltimore Black Sox, Brooklyn Royal Giants, Cole's American Giants (formerly the Chicago American Giants) and Nashville Elite Giants. Greenlee also came up with the idea to duplicate the Major League Baseball All-Star Game, except, unlike the big league method in which the sportswriters chose the players, the fans voted for the participants. The first game, known as the East-West All-Star Game, was held September 10, 1933 at Comiskey Park in Chicago before a crowd of 20,000.
World War II.
With the Japanese Attack on Pearl Harbor on December 7, 1941, the United States was thrust into World War II. Remembering World War I, black America vowed it would not be shut out of the beneficial effects of a major war effort: economic boom and social unification.
Just like the major leagues, the Negro leagues saw many stars miss one or more seasons while fighting overseas. While many players were over 30 and considered "too old" for service, Monte Irvin, Larry Doby and Leon Day of Newark; Ford Smith, Hank Thompson, Joe Greene, Willard Brown and Buck O'Neil of Kansas City; Lyman Bostock of Birmingham; and Lick Carlisle and Howard Easterling of Homestead all served. But the white majors were barely recognizable, while the Negro leagues reached their highest plateau. Millions of black Americans were working in war industries and, making good money, they packed league games in every city. Business was so good that promoter Abe Saperstein (famous for the Harlem Globetrotters) started a new circuit, the Negro Midwest League, a minor league similar to the Negro Southern League. The Negro World Series was revived in 1942, this time pitting the winners of the eastern Negro National League and midwestern Negro American League. It continued through 1948 with the NNL winning four championships and the NAL three.
In 1946, Saperstein partnered with Jesse Owens to form another Negro League, the West Coast Baseball Association (WCBA); Saperstein was league president and Owens was vice-president and the owner of the league's Portland (Oregon) Rosebuds franchise. The WCBA disbanded after only two months.
Integration era.
Judge Kenesaw M. Landis, the first Commissioner of Major League Baseball, was an intractable opponent of integrating the white majors. During his quarter-century tenure, he blocked all attempts at integrating the game. A popular story has it that in , Bill Veeck planned to buy the moribund Philadelphia Phillies and stock them with Negro League stars. Supposedly, when Landis and National League president Ford Frick learned of Veeck's plan, they scuttled it by engineering the Phillies' sale to William B. Cox. However, this story is arguably false, based on press accounts of the time; notably, Philadelphia's black press mentioned nothing about any prospective Veeck purchase.
After Landis' death in 1944, Happy Chandler was named his successor. Chandler was open to integrating the game, even at the risk of losing his job as Commissioner. He later said in his biography that he could not in good conscience tell black players they couldn't play baseball with whites when they'd fought for their country.
In March 1945, the white majors created the Major League Committee on Baseball Integration. Its members included Joseph P. Rainey, Larry MacPhail and Branch Rickey. Because MacPhail, who was an outspoken critic of integration, kept stalling, the committee never met. Under the guise of starting an all-black league, Rickey sent scouts all around the United States, Mexico and Puerto Rico, looking for the perfect candidate to break the color line. His list eventually was narrowed down to three, Roy Campanella, Don Newcombe and Jackie Robinson.
On August 28, 1945, Jackie Robinson met with Rickey in Brooklyn, where Rickey gave Robinson a "test" by berating him and shouting racial epithets that Robinson would hear from day one in the white game. Having passed the test, Robinson signed the contract which stipulated that from then on, Robinson had no "written or moral obligations" to any other club. By the inclusion of this clause, precedent was set that would raze the Negro leagues as a functional commercial enterprise.
To throw off the press and keep his intentions hidden, Rickey got heavily involved in Gus Greenlee's newest foray into black baseball, the United States League. Greenlee started the league in 1945 as a way to get back at the owners of the Negro National League teams for throwing him out. Rickey saw the opportunity as a way to convince people that he was interested in cleaning up blackball, not integrating it. In midsummer 1945, Rickey, almost ready with his Robinson plan, pulled out of the league. The league folded after the end of the 1946 season.
Pressured by civil rights groups, the Fair Employment Practices Act was passed by the New York State Legislature in 1945. This followed the passing of the Quinn-Ives Act banning discrimination in hiring. At the same time, NYC Mayor La Guardia formed the Mayor's Commission on Baseball to study integration of the major leagues. All this led to Rickey announcing the signing of Robinson much earlier than he would have liked. On October 23, 1945, Montreal Royals president Hector Racine announced that, "We are signing this boy."
Early in 1946, Rickey signed four more black players, Campanella, Newcombe, John Wright and Roy Partlow, this time with much less fanfare. After the integration of the major leagues in 1947, marked by the appearance of Jackie Robinson with the Brooklyn Dodgers that April, interest in Negro league baseball waned. Black players who were regarded as prospects were signed by major league teams, often without regard for any contracts that might have been signed with Negro league clubs. Negro league owners who complained about this practice were in a no-win situation: they could not protect their own interests without seeming to interfere with the advancement of players to the majors. By 1948, the Dodgers, along with Veeck's Cleveland Indians had integrated.
The Negro leagues also "integrated" around the same time, as Eddie Klep became the first white man to play for the Cleveland Buckeyes during the 1946 season.
These moves came despite strong opposition from the owners; Rickey was the only one of the 16 owners to support integrating the sport in January 1947. Chandler's decision to overrule them may have been a factor in his ouster in 1951 in favor of Ford Frick.
End of the Negro leagues.
Some proposals were floated to bring the Negro leagues into "organized baseball" as developmental leagues for black players, but that was recognized as contrary to the goal of full integration. So the Negro leagues, once among the largest and most prosperous black-owned business ventures, were allowed to fade into oblivion.
First a trickle and then a flood of players signed with Major League Baseball teams. Most signed minor league contracts and many languished, shuttled from one bush league team to another despite their success at that level. But they were in Organized Baseball, that part of the industry organized by the major leagues.
The Negro National League folded after the 1948 season when the Grays withdrew to resume barnstorming, the Eagles moved to Houston, Texas, and the New York Black Yankees folded. The Grays folded one year later after losing $30,000 in the barnstorming effort. So the Negro American League was the only "major" Negro League operating in 1949. Within two years it had been reduced to minor league caliber and it played its last game in 1958.
The last All-Star game was held in 1962, and by 1966 the Indianapolis Clowns were the last Negro league team still playing. The Clowns continued to play exhibition games into the 1980s, but as a humorous sideshow rather than a competitive sport.
Negro major leagues.
While organized leagues were common in black baseball, there were only seven leagues that are considered to be of the top quality of play at the time of their existence. None materialized prior to 1920 and by 1950, due to integration, they were in decline. Even though teams were league members, most still continued to barnstorm and play non-league games against local or semi-pro teams. Those games, sometimes approaching 100 per season, did not count in the official standings or statistics. However, some teams were considered "associate" teams and games played against them did count, but an associate team held no place in the league standings.
Colored and Negro World Series.
The NNL(I) and ECL champions met in a World Series, usually referred to as the "Colored World Series", from 1924 to 1927 (1924, 1925, 1926, 1927).
The NNL(II) and NAL also met in a World Series, usually referred to as the "Negro World Series" from 1942 to 1948 (1942, 1943, 1944, 1945, 1946, 1947, 1948).
Negro minor leagues.
Early professional leagues cannot be called major or minor. Until the twentieth century, not one completed even half of its planned season.
Eventually, some teams were able to survive and even profit by barnstorming small towns and playing local semi-pro teams as well as league games.
Early Negro leagues were unable to attract and retain top talent due to financial, logistical and contractual difficulties. Some early dominant teams did not join a league since they could pull in larger profits independently. The early leagues were specifically structured as minor leagues. With the integration of Organized Baseball, beginning 1946, all leagues simply lost elite players to white leagues, and historians do not consider any Negro league "major" after 1950.
At least nine leagues from the major-league era (post-1900) are recognized as Negro minor leagues, as is the one of two 1940s majors that continued after 1950:
† The Negro Southern League was considered a "de facto" major league in 1932 because it was the only league to play a full season schedule, and many players (and a few teams) from the original Negro National League played there. A new Negro National League was established in traditionally "major" cities for 1933, also attracting the elite players and teams from the NSL.
‡ The Negro American League is considered a major league from 1937 until integration diminished the quality of play around 1950. Riley's "Biographical Encyclopedia" draws the line between 1950 and 1951.
The Negro leagues and the Hall of Fame.
In his Baseball Hall of Fame induction speech in 1966, Ted Williams made a strong plea for inclusion of Negro league stars in the Hall. After the publication of Robert Peterson's landmark book "Only the Ball was White" in 1970, the Hall of Fame found itself under renewed pressure to find a way to honor Negro league players who would have been in the Hall had they not been barred from the major leagues due to the color of their skin.
At first, the Hall of Fame planned a "separate but equal" display, which would be similar to the Ford C. Frick Award for baseball commentators, in that this plan meant that the Negro league honorees would not be considered members of the Hall of Fame. This plan was criticized by the press, the fans and the players it was intended to honor, and Satchel Paige himself insisted that he would not accept anything less than full-fledged induction into the Hall of Fame. The Hall relented and agreed to admit Negro league players on an equal basis with their Major League counterparts in 1971. A special Negro league committee selected Satchel Paige in 1971, followed by (in alphabetical order) Cool Papa Bell, Oscar Charleston, Martín Dihigo, Josh Gibson, Monte Irvin, Judy Johnson, Buck Leonard and John Henry Lloyd. (Of the nine, only Irvin and Paige spent any time in the major leagues.) The Veterans Committee later selected Ray Dandridge, as well as choosing Rube Foster on the basis of meritorious service.
Other members of the Hall who played in both the Negro leagues and Major League Baseball are Hank Aaron, Ernie Banks, Roy Campanella, Larry Doby, Willie Mays, and Jackie Robinson. Except for Doby, their play in the Negro leagues was a minor factor in their selection: Aaron, Banks, and Mays played in Negro leagues only briefly and after the leagues had declined with the migration of many black players to the integrated minor leagues; Campanella (1969) and Robinson (1962) were selected before the Hall began considering performance in the Negro leagues.
From 1995 to 2001, the Hall made a renewed effort to honor luminaries from the Negro leagues, one each year. There were seven selections: Leon Day, Bill Foster, Bullet Rogan, Hilton Smith, Turkey Stearnes, Willie Wells, and Smokey Joe Williams.
In February 2006, a committee of twelve baseball historians elected 17 more people from black baseball to the National Baseball Hall of Fame, twelve players and five executives.
Effa Manley, co-owner (with her husband Abe Manley) and business manager of the Newark Eagles (New Jersey) club in Negro National League, is the first woman elected to the Baseball Hall of Fame.
The committee reviewed the careers of 29 Negro league and 10 Pre-Negro league candidates. The list of 39 had been pared from a roster of 94 candidates by a five-member screening committee in November, 2005. The voting committee was chaired by Fay Vincent, Major League Baseball's eighth Commissioner and an Honorary Director of the National Baseball Hall of Fame and Museum.
Last Negro leaguers.
Hank Aaron was the last Negro league player to hold a regular position in Major League Baseball.
Minnie Miñoso was the last Negro league player to play in a Major League game when he appeared in two games for the Chicago White Sox in 1980.
Buck O'Neil was the most recent former Negro league player to appear in a professional game when he made two appearances (one for each team) in the Northern League All-Star Game in 2006.
2008 Major League draft.
On June 5, 2008, Major League Baseball held a special draft of the surviving Negro league players to acknowledge and rectify their exclusion from the major leagues on the basis of race. The idea of the special draft was conceived by Hall of Famer Dave Winfield. Each major league team drafted one player from the Negro leagues. Bobo Henderson, Joe B. Scott, Mule Miles, Lefty Bell, James "Red" Moore, Mack "The Knife" Pride and Charley Pride (who went on to a legendary career in country music), were among the players selected. Also drafted, by the New York Yankees, was Emilio Navarro, who, at 102 years of age at the time of the draft, was believed to be the oldest living professional ballplayer.
Museum.
The Negro Leagues Baseball Museum is located in the 18th and Vine District in Kansas City, Missouri.
Postage stamp recognition.
On July 17, 2010, the U.S. Postal Service issued a se-tenant pair of 44-cent U.S. commemorative postage stamps, to honor the all-black professional baseball leagues that operated from 1920 to about 1960. The stamps were formally issued at the Negro Leagues Baseball Museum, during the celebration of the museum's twentieth anniversary. One of the stamps depicts Rube Foster.

</doc>
<doc id="39946" url="https://en.wikipedia.org/wiki?curid=39946" title="Charles XV of Sweden">
Charles XV of Sweden

Charles XV & IV also Carl ("Carl Ludvig Eugen"); Swedish and Norwegian: "Karl" (3 May 1826 – 18 September 1872) was King of Sweden ("Charles XV") and Norway ("Charles IV") from 1859 until his death.
Though known as King Charles XV in Sweden (and also on contemporary Norwegian coins), he was actually the ninth Swedish king by that name, as his predecessor Charles IX (reigned 1604–1611) had adopted a numeral according to a fictitious history of Sweden.
Biography.
He was born in Stockholm Palace, Stockholm, and dubbed Duke of Skåne at birth. He was the eldest son of King Oscar I and Josephine of Leuchtenberg. He was given his first officer's commission in 1841 by his grandfather, Charles XIV John. After his father's accession to the throne in 1844, he was made a chancellor of the universities of Uppsala and Lund, and in 1853 chancellor of Royal Swedish Academy of Arts. On 11 February 1846 he was made an honorary member of the Royal Swedish Academy of Sciences.
The Crown Prince was Viceroy of Norway briefly in 1856 and 1857. He became Regent on 25 September 1857, and king on the death of his father on 8 July 1859. As grandson of Augusta of Bavaria, he was a descendant of Gustav I of Sweden and Charles IX of Sweden, whose blood returned to the throne after being lost in 1818 when Charles XIII of Sweden died.
On 19 June 1850 he married in Stockholm Louise of the Netherlands, niece of William II of the Netherlands through her father and niece of William I of Prussia, German Emperor, through her mother. The couple were personally quite dissimilar; Princess Louise was in love with her husband, whereas he preferred other women. His well-known mistresses included the countess Josephine Sparre, Wilhelmine Schröder and the actresses Hanna Styrell and Elise Hwasser, the latter the most celebrated actress in Sweden during his reign, and the Crown Prince neglected his shy wife. On the other hand, his relationship to his only daughter, Louise, was warm and close.
As Crown Prince, Charles' brusque manner led many to regard his future accession with some apprehension, yet he proved to be one of the most popular of Scandinavian kings and a constitutional ruler in the best sense of the word. His reign was remarkable for its manifold and far-reaching reforms. Sweden's existing communal law (1862), ecclesiastical law (1863) and criminal law (1864) were enacted appropriately enough under the direction of a king whose motto was: "Land skall med lag byggas" - "With law shall the land be built". Charles also helped Louis De Geer to carry through his reform of the Parliament of Sweden in 1866. He also declared the freedom of women by passing the law of legal majority for unmarried women in 1858 – his sister Princess Eugenie became the first woman who was declared mature.
Charles was an advocate of Scandinavianism and the political solidarity of the three northern kingdoms, and his friendship with Frederick VII of Denmark, it is said, led him to give half promises of help to Denmark on the eve of the war of 1864, which, in the circumstances, were perhaps misleading and unjustifiable. In view, however, of the unpreparedness of the Swedish army and the difficulties of the situation, Charles was forced to observe a strict neutrality. He died in Malmö on 18 September 1872.
Charles XV attained some eminence as a painter and as a poet. He was followed on both the thrones of Norway and Sweden by his brother Oscar II.
In 1872, Charles XV had controversial plans to enter a non-morganatic marriage with the Polish countess Marya Krasińska through the assistance of Ohan Demirgian, plans that aroused opposition both in the royal house and government and which were interrupted only by his death.
A few weeks before Charles' death, his daughter Louise (then the Crown Princess of Denmark) gave birth to her second son. The young Prince of Denmark became christened as grandfather Charles' namesake. In 1905 this grandson, Prince Carl of Denmark, ascended the throne of Norway, becoming thus his maternal grandfather's successor in that country, and assumed the reign name Haakon VII. The present king, Harald V of Norway, is Charles' great-great-grandson, through his father and mother.
No subsequent king of Sweden to this day is Charles' descendant. However, his descendants are or have been on the thrones of Denmark, Luxembourg, Greece, Belgium and Norway.
Issue.
By his wife, Louise of the Netherlands, Charles had two children, a son who died in infancy and a daughter who married the King of Denmark. The early death of his only legitimate son meant that he was succeeded on the throne of Sweden by his younger brother Oscar II.
Charles also sired an illegitimate son, Carl Johan Bolander, (4 February 1854 - 28 July 1903), the father of Bishop Nils Bolander and daughter, Ellen Svensson Hammar (28 October 1865 - 1931), and it has been widely rumored that he had many more extramarital children.

</doc>
<doc id="39948" url="https://en.wikipedia.org/wiki?curid=39948" title="1301">
1301

__NOTOC__
Year 1301 (MCCCI) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39949" url="https://en.wikipedia.org/wiki?curid=39949" title="1302">
1302

__NOTOC__
Year 1302 (MCCCII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39950" url="https://en.wikipedia.org/wiki?curid=39950" title="1303">
1303

__NOTOC__
Year 1303 (MCCCIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39951" url="https://en.wikipedia.org/wiki?curid=39951" title="1304">
1304

__NOTOC__
Year 1304 (MCCCIV) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39952" url="https://en.wikipedia.org/wiki?curid=39952" title="1305">
1305

__NOTOC__
Year 1305 (MCCCV) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39953" url="https://en.wikipedia.org/wiki?curid=39953" title="1306">
1306

__NOTOC__
Year 1306 (MCCCVI) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39954" url="https://en.wikipedia.org/wiki?curid=39954" title="1309">
1309

__NOTOC__
Year 1309 (MCCCIX) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39955" url="https://en.wikipedia.org/wiki?curid=39955" title="1312">
1312

__NOTOC__
Year 1312 (MCCCXII) was a leap year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39956" url="https://en.wikipedia.org/wiki?curid=39956" title="1311">
1311

__NOTOC__
Year 1311 (MCCCXI) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39957" url="https://en.wikipedia.org/wiki?curid=39957" title="1310">
1310

__NOTOC__
Year 1310 (MCCCX) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39958" url="https://en.wikipedia.org/wiki?curid=39958" title="1314">
1314

__NOTOC__
Year 1314 (MCCCXIV) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39959" url="https://en.wikipedia.org/wiki?curid=39959" title="1315">
1315

__NOTOC__
Year 1315 (MCCCXV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39960" url="https://en.wikipedia.org/wiki?curid=39960" title="1316">
1316

__NOTOC__
Year 1316 (MCCCXVI) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39961" url="https://en.wikipedia.org/wiki?curid=39961" title="1317">
1317

__NOTOC__
Year 1317 (MCCCXVII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39962" url="https://en.wikipedia.org/wiki?curid=39962" title="1318">
1318

__NOTOC__
Year 1318 (MCCCXVIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39963" url="https://en.wikipedia.org/wiki?curid=39963" title="1319">
1319

__NOTOC__
Year 1319 (MCCCXIX) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39964" url="https://en.wikipedia.org/wiki?curid=39964" title="1321">
1321

__NOTOC__
Year 1321 (MCCCXXI) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39965" url="https://en.wikipedia.org/wiki?curid=39965" title="1324">
1324

__NOTOC__
Year 1324 (MCCCXXIV) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39966" url="https://en.wikipedia.org/wiki?curid=39966" title="1325">
1325

__NOTOC__
Year 1325 (MCCCXXV) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39967" url="https://en.wikipedia.org/wiki?curid=39967" title="1327">
1327

__NOTOC__
Year 1327 (MCCCXXVII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39968" url="https://en.wikipedia.org/wiki?curid=39968" title="1328">
1328

__NOTOC__
Year 1328 (MCCCXXVIII) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39970" url="https://en.wikipedia.org/wiki?curid=39970" title="1329">
1329

__NOTOC__
Year 1329 (MCCCXXIX) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39971" url="https://en.wikipedia.org/wiki?curid=39971" title="1330">
1330

__NOTOC__
Year 1330 (MCCCXXX) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39972" url="https://en.wikipedia.org/wiki?curid=39972" title="1332">
1332

__NOTOC__
Year 1332 (MCCCXXXII) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39973" url="https://en.wikipedia.org/wiki?curid=39973" title="1335">
1335

__NOTOC__
Year 1335 (MCCCXXXV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39974" url="https://en.wikipedia.org/wiki?curid=39974" title="1337">
1337

__NOTOC__
Year 1337 (MCCCXXXVII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Date unknown.
</onlyinclude>

</doc>
<doc id="39975" url="https://en.wikipedia.org/wiki?curid=39975" title="1339">
1339

__NOTOC__
Year 1339 (MCCCXXXIX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39976" url="https://en.wikipedia.org/wiki?curid=39976" title="1298">
1298

__NOTOC__
Year 1298 (MCCXCVIII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Technology.
</onlyinclude>

</doc>
<doc id="39977" url="https://en.wikipedia.org/wiki?curid=39977" title="1296">
1296

__NOTOC__
Year 1296 (MCCXCVI) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39978" url="https://en.wikipedia.org/wiki?curid=39978" title="1295">
1295

__NOTOC__
Year 1295 (MCCXCV) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39979" url="https://en.wikipedia.org/wiki?curid=39979" title="1294">
1294

__NOTOC__
Year 1294 (MCCXCIV) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39980" url="https://en.wikipedia.org/wiki?curid=39980" title="1293">
1293

__NOTOC__
Year 1293 (MCCXCIII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Education.
</onlyinclude>

</doc>
<doc id="39981" url="https://en.wikipedia.org/wiki?curid=39981" title="1292">
1292

__NOTOC__
Year 1292 (MCCXCII) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39982" url="https://en.wikipedia.org/wiki?curid=39982" title="1291">
1291

__NOTOC__
Year 1291 (MCCXCI) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Markets.
</onlyinclude>

</doc>
<doc id="39983" url="https://en.wikipedia.org/wiki?curid=39983" title="1290">
1290

__NOTOC__
Year 1290 (MCCXC) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="39984" url="https://en.wikipedia.org/wiki?curid=39984" title="1276">
1276

__NOTOC__
Year 1276 (MCCLXXVI) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
It is the only Year of Four Popes.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="39985" url="https://en.wikipedia.org/wiki?curid=39985" title="1275">
1275

__NOTOC__
Year 1275 (MCCLXXV) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="39986" url="https://en.wikipedia.org/wiki?curid=39986" title="1274">
1274

__NOTOC__
Year 1274 (MCCLXXIV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By area.
Europe.
Italy.
</onlyinclude>

</doc>
<doc id="39987" url="https://en.wikipedia.org/wiki?curid=39987" title="1273">
1273

__NOTOC__
Year 1273 (MCCLXXIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="39988" url="https://en.wikipedia.org/wiki?curid=39988" title="1272">
1272

__NOTOC__
Year 1272 (MCCLXXII) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39989" url="https://en.wikipedia.org/wiki?curid=39989" title="1271">
1271

__NOTOC__
Year 1271 (MCCLXXI) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="39990" url="https://en.wikipedia.org/wiki?curid=39990" title="1270">
1270

__NOTOC__
Year 1270 (MCCLXX) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Europe.
</onlyinclude>
Births.
"possible"

</doc>
<doc id="39991" url="https://en.wikipedia.org/wiki?curid=39991" title="1216">
1216

__NOTOC__
Year 1216 (MCCXVI) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="39992" url="https://en.wikipedia.org/wiki?curid=39992" title="1217">
1217

__NOTOC__
Year 1217 (MCCXVII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By area.
Europe.
</onlyinclude>

</doc>
<doc id="39993" url="https://en.wikipedia.org/wiki?curid=39993" title="1218">
1218

__NOTOC__
Year 1218 (MCCXVIII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="39994" url="https://en.wikipedia.org/wiki?curid=39994" title="1219">
1219

__NOTOC__
Year 1219 (MCCXIX) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Technology.
</onlyinclude>

</doc>
<doc id="39995" url="https://en.wikipedia.org/wiki?curid=39995" title="1213">
1213

__NOTOC__
Year 1213 (MCCXIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39996" url="https://en.wikipedia.org/wiki?curid=39996" title="1212">
1212

__NOTOC__
Year 1212 (MCCXII) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="39997" url="https://en.wikipedia.org/wiki?curid=39997" title="1211">
1211

__NOTOC__
Year 1211 (MCCXI) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="39998" url="https://en.wikipedia.org/wiki?curid=39998" title="1210">
1210

__NOTOC__
Year 1210 (MCCX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="39999" url="https://en.wikipedia.org/wiki?curid=39999" title="1208">
1208

__NOTOC__
Year 1208 (MCCVIII) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Arts and culture.
</onlyinclude>

</doc>
<doc id="40000" url="https://en.wikipedia.org/wiki?curid=40000" title="1207">
1207

__NOTOC__
Year 1207 (MCCVII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40001" url="https://en.wikipedia.org/wiki?curid=40001" title="1206">
1206

__NOTOC__
Year 1206 (MCCVI) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Technics.
</onlyinclude>

</doc>
<doc id="40002" url="https://en.wikipedia.org/wiki?curid=40002" title="1203">
1203

__NOTOC__
Year 1203 (MCCIII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar. It was also the first year to have all digits different from each other since 1098.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40003" url="https://en.wikipedia.org/wiki?curid=40003" title="1201">
1201

__NOTOC__
Year 1201 (MCCI) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40004" url="https://en.wikipedia.org/wiki?curid=40004" title="1195">
1195

__NOTOC__
Year 1195 (MCXCV) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40005" url="https://en.wikipedia.org/wiki?curid=40005" title="1194">
1194

__NOTOC__
Year 1194 (MCXCIV) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40006" url="https://en.wikipedia.org/wiki?curid=40006" title="1193">
1193

__NOTOC__
Year 1193 (MCXCIII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40007" url="https://en.wikipedia.org/wiki?curid=40007" title="1191">
1191

__NOTOC__
Year 1191 (MCXCI) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40008" url="https://en.wikipedia.org/wiki?curid=40008" title="1190">
1190

__NOTOC__
Year 1190 (MCXC) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40009" url="https://en.wikipedia.org/wiki?curid=40009" title="1169">
1169

__NOTOC__
Year 1169 (MCLXIX) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Arts.
</onlyinclude>

</doc>
<doc id="40010" url="https://en.wikipedia.org/wiki?curid=40010" title="1167">
1167

__NOTOC__
Year 1167 (MCLXVII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40011" url="https://en.wikipedia.org/wiki?curid=40011" title="1166">
1166

__NOTOC__
Year 1166 (MCLXVI) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40012" url="https://en.wikipedia.org/wiki?curid=40012" title="1162">
1162

__NOTOC__
Year 1162 (MCLXII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="40014" url="https://en.wikipedia.org/wiki?curid=40014" title="1160">
1160

__NOTOC__
Year 1160 (MCLX) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Education.
</onlyinclude>

</doc>
<doc id="40015" url="https://en.wikipedia.org/wiki?curid=40015" title="Skeleton at the 2002 Winter Olympics">
Skeleton at the 2002 Winter Olympics

Skeleton returned to the program of the Winter Olympic Games for the first time in 54 years at the 2002 Games in Salt Lake City. This was the first time Olympic competitions in skeleton were held during an Olympics outside of St. Moritz. Both men and women competed, with medals awarded after five runs down the course. Both events were contested on February 20.

</doc>
<doc id="40017" url="https://en.wikipedia.org/wiki?curid=40017" title="Ice hockey at the 2002 Winter Olympics">
Ice hockey at the 2002 Winter Olympics

Ice hockey at the 2002 Winter Olympics was held at the E Center in West Valley City and Peaks Ice Arena in Provo, Utah. Both the men's and women's tournaments were won by Canada, defeating the host USA in both games.
Men's tournament.
The men's tournament marked the second Olympic Games where the National Hockey League took a break to allow all its players the opportunity to play.
Fourteen countries played in the tournament. Six hockey powers (Canada, the Czech Republic, Finland, Russia, Sweden, and the United States) were automatically admitted to the final eight. The other eight countries (Austria, Belarus, France, Germany, Latvia, Slovakia, Switzerland, and Ukraine) played in a preliminary round in two pools. The winners of those pools, Belarus and Germany, advanced to the final round with the six hockey powers.
The biggest surprise of the tournament was Belarus, 0–3–0 in Group D play, knocking off 3–0–0 Sweden in quarterfinal play. After that upset, the Swedish media held their players responsible for the loss, even going as far to publish their NHL salaries. The players responded by not returning to Sweden during the NHL break, although that was unlikely since the Olympics were held in the same continent as their NHL teams and play resumed soon after the Olympics ended.
Another major surprise was the silver-medal finish of Team USA, which was not considered a contender as it was steeped heavily in over-30 veterans. Although it retained most of the players from the 1998 team which had performed below expectations, this time it was coached by Herb Brooks, who had been responsible for the "Miracle on Ice" over the Soviet Union during the 1980 Winter Olympics. Despite being close to the ends of their NHL careers, Mike Richter and Phil Housley put up phenomenal performances. Brett Hull, John LeClair and Mike Modano formed the "Divine Line" which led the tournament in scoring. USA and Russia played to a 2–2 tie in their group game, drawing some comparisons to the famous 1980 Miracle game. Ending up, USA finished second behind Sweden in the round robin results.
USA and Russia met again in the semi-finals of the tournament. The USA's victory over Russia came coincidentally on the 22-year anniversary of the "Miracle on Ice", the upset of the Soviet Union team, at Lake Placid in 1980 (also a Friday). The Americans stormed out to a 3–0 lead for the first two periods, before withstanding a furious two-goal rally from the Russians to advance. Russian coach Slava Fetisov, one of the stars for the 1980 Soviet squad, complained about the selection of NHL referees to officiate Olympic matches (a stipulation by the NHL if most Olympic players are NHLers) and charged that officials were trying to fix a Canada–USA final for North American audiences. However, Russian goalie Nikolai Khabibulin thought that the refereeing was fair, having faced 38 shots in the first two periods and 49 overall.
Canada had a lackluster start, losing 5–2 to Sweden, only managing to defeat Germany by a score of 3–2, and drawing with the Czech Republic. These performances prompted an emotional response from Team Canada manager Wayne Gretzky, in particular the referee's failure to call a clear hit from behind on Canada's Theoren Fleury in the game against the Czech Republic. However, Canada improved in the elimination round, defeating Finland 2–1, and easily sweeping surprise semi-finalist Belarus 7–1.
Canada and the US faced off in the final. For both nations, the gold-medal game came coincidentally on the anniversary of each nation's last gold medal in men's Olympic hockey. Canada last won 50 years previously at the 1952 Winter Olympics when they tied the US 3-3 (Olympic ice hockey previously only had a round-robin portion). The US won their last gold medal when they defeated Finland two days after "The Miracle on Ice" in 1980. Both games, coincidentally, were played on a Sunday.
The Canada-USA final was tied at 2–2, however Canada then scored three goals to win 5–2. It was only the second time and first in 70 years that the US men's hockey team lost an Olympic game on home soil. The first loss came against Canada (a 2-1 OT loss) in their first game at the 1932 Winter Olympics in Lake Placid.
Thanks to the much-anticipated Canada–USA matchup in the final in front of a North American home crowd, TV ratings for this match were the highest in Olympic history to that time. In the United States, NBC's live coverage of the gold medal hockey game drew a 10.7 rating, the highest-rated hockey game, Olympic or NHL, since the 1980 Winter Olympics and was the largest network hockey audience in the U.S. in 22 years. In Canada, the CBC said that the game drew 10.6 million viewers, making the game was the most-watched CBC Sports program. As the final seconds ticked away, veteran CBC Sports commentator Bob Cole called: "Now after 50 years, it's time for Canada to stand up and cheer. Stand up and cheer everybody! The Olympics Salt Lake City, 2002, men's ice hockey, gold medal: Canada!" The CBC also said that the 10.6 million viewers broke the previous record of 4.957 million viewers for Game 7 of the 1994 Stanley Cup Finals.
During the final, the legend of the lucky loonie was born when Canadian icemaker Trent Evans buried a one dollar coin (Loonie) under centre ice and both the Canadian men's and women's teams won gold.
Steve Yzerman and Brendan Shanahan became the second and third players to win the Olympic Gold Medal in hockey (with Team Canada) and the Stanley Cup (with the Detroit Red Wings) in the same year, the first to win an Olympic Gold and Stanley Cup was Ken Morrow in 1980. Chris Chelios and Brett Hull became the second and third players to win Olympic Silver Medal in hockey (with Team USA) and Stanley Cup in the same year (Sergei Fedorov was the first in 1998).
The format of the tournament was the same one used in the 1998 tournament in Nagano. It was controversial because the National Hockey League clubs would not release their players for the preliminary round. This severely hampered the campaigns of Germany and Slovakia, although the former country managed to qualify for the final group stage. Also the final group stage was criticized as being meaningless since all of the teams qualified for the quarter-finals. The format was changed for the 2006 tournament in an effort to address these criticisms.
Qualifying.
The final standings at the end of the 1999 IIHF World Championship were used to determine the path to the Olympic tournament. The top six places were given direct entry to the first round, places seven and eight were given direct entry to the preliminary round, and all other participants were seeded in qualifying tournaments to fill the remaining six spots. This chart shows the seeding path for all nations, in detail.
Preliminary round.
Group A.
Top team (shaded) advanced to the first round.
All times are local (UTC-7).
Group B.
Top team (shaded) advanced to the first round.
All times are local (UTC-7).
Consolation round.
13th place match.
All times are local (UTC-7).
11th place match.
All times are local (UTC-7).
9th place match.
All times are local (UTC-7).
First round.
Group C.
All times are local (UTC-7).
Group D.
All times are local (UTC-7).
Final round.
Quarter-finals.
All times are local (UTC-7).
Semi-finals.
All times are local (UTC-7).
Bronze medal game.
All times are local (UTC-7).
Gold medal game.
All times are local (UTC-7).
Women's tournament.
Qualification.
The qualification process, and seedings for the Olympic tournament, came from the final standings of the 2000 IIHF Women's World Championship. The top six nations were given direct entry to the Olympics, the final two spots were contested in a qualification tournament. The nations ranked seven through ten played a round robin in Engelberg Switzerland February 8–11, 2001.
Format.
The eight teams will be split into two divisions of four teams and each team will play three preliminary games. Following the completion of the preliminary round, the top two teams from each division will advance to the medal round and compete in a playoff to determine the gold medalist. The other four will play classification games. Each team is allowed to have between 15 to 18 skaters (forwards and defensemen).
Participating nations.
A total of eight national teams competed in the women's ice hockey tournament.
Officiating Controversy.
The gold medal game played on February 1, 2002 was marred with controversy as referee Stacey Livingston awarded the American team with eight successive power plays.

</doc>
<doc id="40019" url="https://en.wikipedia.org/wiki?curid=40019" title="Yankee Stadium (1923)">
Yankee Stadium (1923)

Yankee Stadium was a stadium located in the Bronx, a borough of New York City. It was the home ballpark of the New York Yankees, one of the city's Major League Baseball (MLB) franchises, from 1923 to 1973 and from 1976 to 2008. The stadium hosted 6,581 Yankees regular season home games during its 85-year history. It was also the former home of the New York Giants football team from 1956 through the first part of the 1973–74 football season. The stadium's nickname, "The House That Ruth Built", is derived from Babe Ruth, the legendary baseball superstar whose prime years coincided with the stadium's opening and the beginning of the Yankees' winning history. It has also been known as ""The Big Ballpark in The Bronx"", ""The Stadium"", and ""The Cathedral of Baseball"".
The stadium was built from 1922 to 1923 for $2.4 million ($32 million in 2014 dollars). The stadium's construction was paid for entirely by Yankees owner Jacob Ruppert, who was eager to have his own stadium after sharing the Polo Grounds with the New York Giants baseball team the previous 10 years. Yankee Stadium opened for the 1923 MLB season and at the time, it was hailed as a one-of-a-kind facility in the country for its size. Over the course of its history, it became one of the most famous venues in the United States, having hosted a variety of events and historic moments during its existence. While many of these moments were baseball-related—including World Series games, no-hitters, perfect games and historic home runs—the stadium also hosted boxing matches, concerts, Jehovah's Witnesses conventions (see record attendance) and three Papal Masses. The stadium went through many alterations and playing surface configurations over the years. The condition of the facility worsened in the 1960s and 1970s, prompting its closing for renovation from 1974 to 1975. The renovation significantly altered the appearance of the venue and reduced the distance of the outfield fences.
In 2006, the Yankees began building a new $2.3 billion stadium in public parkland adjacent to the stadium. The price included $1.2 billion in public subsidies. The design includes a replica of the frieze along the roof that was in Yankee Stadium. Monument Park, a Hall of Fame for prominent former Yankees, was relocated to the new stadium. Yankee Stadium closed following the 2008 baseball season and the new stadium opened in 2009, adopting the "Yankee Stadium" moniker. Yankee Stadium was demolished in 2010, two years after it closed. The 8-acre site was converted into a park called "Heritage Field". The congested neighborhood was left without parkland for five years. The new stadium is located on 25 acres of what had been known as Macombs Dam Park.
History.
Planning and construction.
The Yankees had played at the Polo Grounds in northern Manhattan since 1913, sharing the venue with the New York Giants. However, relations between the two teams were rocky, with the Giants harboring resentment towards the Yankees. For the 1920 season, the Yankees acquired star slugger Babe Ruth and in his first year with his new team, the Yankees drew 1.3 million fans to the Polo Grounds, outdrawing the Giants. By the middle of 1920, the Giants had issued an eviction notice to the Yankees, which was soon rescinded. In 1921, the Yankees won their first American League pennant (but lost the then-best-of-nine 1921 World Series to the Giants in eight games, all played at the Polo Grounds). This exacerbated Giants owner Charles Stoneham's resentment of the Yankees and reinforced his insistence that the Yankees find another place to play their home games. The Giants derisively suggested that the Yankees relocate "to Queens or some other out-of-the-way place".
Tillinghast L'Hommedieu Huston and Jacob Ruppert, the Yankees' owners since January 1915, decided to build their own stadium. They did so at considerable financial risk and speculation. Baseball teams typically played in 30,000-seat facilities, but Huston and Ruppert invoked Ruth's name when asked how the Yankees could justify a ballpark with 60,000 seats. The doubt over the Yankees' lasting power was amplified by baseball's sagging popularity after the 1919 Black Sox Scandal, in which eight Chicago White Sox players were expelled for conspiring with gamblers to fix that year's World Series. Many people also felt three baseball teams could not prosper in New York City, but Huston and Ruppert were confident the Yankees could thrive amongst the more established New York Giants and Brooklyn Dodgers of the National League (which proved more than true, as both would eventually relocate to California following the 1957 season). The total bill for construction of the stadium was $2.5 million.
Huston and Ruppert explored many areas for Yankee Stadium. Of the other sites being considered, the Hebrew Orphan Asylum, at Amsterdam Avenue between 136th and 138th streets in Manhattan, nearly became reality. Consideration was also given to building atop railroad tracks on the West Side of Manhattan (an idea revived in 1998) and to Long Island City, in Queens. The area Huston and Ruppert settled on was a lumberyard in the Bronx within walking distance from and in sight of, Coogan's Bluff. The Polo Grounds was located on the Manhattan side of the Harlem River, at 155th Street and Eighth Avenue. Huston and Ruppert purchased the lumberyard from William Waldorf Astor for $600,000, equal to $ today. Construction began May 5, 1922 and Yankee Stadium opened to the public less than a year later. The stadium's walls were built of "an extremely hard and durable concrete that was developed by Thomas Edison", with total of of concrete used in the original structure.
1923–1973.
Yankee Stadium officially opened on Wednesday, April 18, 1923, with the Yankees' first home game, against the Boston Red Sox. According to the "New York Evening Telegram", "everything smelled of ... fresh paint, fresh plaster and fresh grass". At 3 pm, the composer-conductor John Philip Sousa led the Seventh ("Silk-Stocking") Regiment Band in playing "The Star-Spangled Banner". After a parade of the players and dignitaries, Babe Ruth was presented with a case containing a symbolically big bat. New York Governor Al Smith threw out the first pitch directly into the glove of catcher Wally Schang rather than the customary couple of feet wide. The Yankees went on to defeat Ruth's former team, the Boston Red Sox, by a score of 4–1, with Ruth hitting a three-run home run into the right-field stands. Asked later for his opinion of the stadium, he replied, "Some ball yard."
Upon opening, Fred Lieb of the "New York Evening Telegram" dubbed it "The House That Ruth Built". The Yankees also won their first World Series during the Stadium's inaugural season. Future Yankee manager Casey Stengel hit the first post-season home run in stadium history while playing with the opposing New York Giants. The only other team to do so prior to the 2006 St. Louis Cardinals in (the new) Busch Stadium had been the Pittsburgh Pirates, who won the 1909 World Series in Forbes Field's inaugural season; and the Boston Red Sox, who won the 1912 World Series in Fenway Park's first year. The Yankees accomplished this feat yet again in the New Yankee Stadium in the 2009 World Series.
The Stadium was the first facility in North America with three tiers, although the triple deck originally extended only to the left and right field corners. The concrete lower deck extended well into left field, with the obvious intention of extending the upper deck over it, which was accomplished during the 1926–27 off-season. As originally built, the stadium seated 58,000. For the stadium's first game, the announced attendance was 74,217 (with another 25,000 turned away); however, Yankees business manager Ed Barrow later admitted that the actual attendance was closer to 60,000. Regardless of what the figure was, it was undoubtedly more than the 42,000 fans who attended game five of the 1916 World Series at Braves Field, baseball's previous attendance record. However, during the 1920s and 1930s, the Yankees' popularity was such that crowds in excess of 80,000 were not uncommon. It was referred to as "the Yankee Stadium" (with the "s" in "stadium" sometimes lowercase) until the 1950s.
Yankee Stadium underwent more extensive renovations from 1936 through 1938. The wooden bleachers were replaced with concrete, shrinking the "death valley" area of left and center substantially, although the area was still much deeper than in most ballparks; and the second and third decks were extended to short right center. Runways were left between the bleachers and the triple-deck on each end, serving as bullpens. By 1938, the Stadium had assumed the "classic" shape that it would retain for the next 35 years. In April 1945, Yankees president Larry MacPhail announced that after the War, the Yankees would install an additional tier of bleachers to increase stadium capacity to 100,000. In addition to the bleachers, he also planned to add 2,000 additional box-seats by lowering the field and shortening the distance from the backstop to home-plate from . However, the plans fell through and the expansion did not take place.
The stadium was owned by the Yankees until December 17, 1953 when the ballclub's co-owners Dan Topping and Del Webb sold it and Blues Stadium for $6.5 million ($57,676,180 in 2016 dollars) to Arnold Johnson, who also dealt the land under the Bronx venue to the Knights of Columbus for $2 million ($17,746,517 in 2016 dollars). After he purchased the Philadelphia Athletics and transferred the franchise to Kansas City on November 8, 1954, Johnson sold Yankee Stadium to John W. Cox on March 22, 1955. Cox, a 1927 graduate of Rice University, donated the ballpark to his alma mater on July 19, 1962.
In the 1966–67 offseason, during the period in which Rice owned the stadium, the concrete exterior was painted white, and the interior was painted blue. The metal frieze circling the upper deck was painted white.
1974–75 renovations and beyond.
In 1970, newly reelected Mayor John Lindsay approached team president Michael Burke of CBS, which owned the Yankees, with an offer to spend $25 million on improvements to Yankee Stadium. (Six years earlier, the Mets' new home, Shea Stadium, had opened in Queens at a similar public cost.) By this time, it was obvious that the stadium had significant structural issues; concrete chunks were seen falling from the stands.
Burke floated two proposals to build a new stadium on the same site in the Bronx; one included a dome. CBS also asked for 10,000 additional parking spaces and road improvements to alleviate traffic. In August 1971, the New York Giants football team announced that it would leave Yankee Stadium for a new football-only stadium in the Meadowlands Sports Complex under development in New Jersey. In 1971, the city of New York forced (via eminent domain) Rice to sell the stadium for a mere $2.5 million (equivalent to $ today). That December, after significant lobbying by Lindsay, the Board of Estimate approved $24 million ($140 million in 2014 dollars) for the city to renovate Yankee Stadium. The figure included $3.5 million for the purchase of the stadium and the 8-acre piece of land from Rice University and the Knights of Columbus. At the time, New York City was on the brink of bankruptcy. In January 1973, CBS sold the Yankees to a group led by George Steinbrenner for $10 million. Yankee Stadium closed for renovation on September 30, 1973. The Yankees would play all of their 1974 and 1975 home games at Shea Stadium. When the renovated stadium opened on April 15, 1976, the cost had ballooned to $160 million ($672 million in 2014 dollars). The cost was originally borne by New York City and is now being paid off by New York State.
The outside shell of the stadium remained the same, with its original limestone painted over. Among the more noticeable changes after the renovation was the removal of 118 columns reinforcing each tier of the stadium's grandstand. The stadium's roof, including its distinctive metal frieze, was replaced by the new upper shell and new lights were added. A white painted concrete replica of the frieze was added atop the wall encircling the bleachers. The playing field was lowered by about seven feet and moved outward slightly. Escalators and ramps were added in three sections to make the upper deck more accessible. The original wooden stadium seats were replaced with wider plastic ones and the upper deck expanded upward nine rows, excluding the walkway. A new upper concourse was built above the old and original concourse exits were closed in by new seating. A new middle tier was built featuring a larger press box and 16 luxury boxes. About one-third of the bleacher seats were eliminated, their middle section converted to a blacked-out batter's eye. A wall was built behind the bleachers blocking the views from Gerard Avenue and the elevated subway platform above River Avenue. On this wall, the Yankees erected the first instant replay display in baseball, referred to in literature as a "telescreen". All told, the Stadium was reduced to a listed capacity of 57,545. The Stadium's playing field was drastically altered. "Death Valley" was reduced by more than while the right-field home-run porch was moved out. Monuments once in play were moved to a newly created Monument Park. In 1985, the left field fence was moved in and the stadium assumed its final dimensions in 1988. Although it was essentially the same structure, the renovations were significant enough that some sources consider them two different stadiums. The ESPN Sports Almanac, for instance, calls the original stadium "Yankee Stadium I" and the renovated stadium "Yankee Stadium II".
Replacement, closing, and demolition.
After years of speculation that the Yankees would build a new ballpark to replace Yankee Stadium, construction on a new facility began on August 16, 2006 with a groundbreaking ceremony across the street in Macombs Dam Park, the site of the new stadium. This all but sealed the fate of Yankee Stadium and the Yankees played their final two seasons in the stadium in 2007 and 2008 while the new venue was being built.
After the final game in the Stadium's history was played on September 21, 2008, public tours of Yankee Stadium continued until November 23, 2008. November 9, 2008 was the last day the public tours included Monument Park and the retired number area. On November 12, 2008 construction workers began removing memorials from Monument Park for relocation to the new facility. On November 8, 2008 former Yankees Scott Brosius, Paul O'Neill, David Cone and Jeff Nelson, all members of the 1998 World Series championship team, joined 60 children from two Bronx based youth groups Youth Force 2020 and the ACE Mentor Program in ceremoniously digging up home plate, the pitcher's mound pitching plate (rubber) and the surrounding dirt of both areas and transporting them to comparable areas of new Yankee Stadium.
An official closing ceremony was reportedly discussed to occur in November 2008, but was scrapped when the organization decided the final event should be a baseball game. Yankee officials said that while the team had contemplated a final ceremony (with any proceeds going to charity), talk of a concert was just media speculation.
The front office staff vacated the premises on January 23, 2009. Demolition began in March 2009 with the removal of the playing field. On May 13, 2009, the process of removing seats began and was completed on June 8. On September 3 and 4, the iconic white facade was dismantled.
On November 4, 2009, construction workers began tearing down the outfield bleachers, marking the first major structural demolition of the old ballpark. On November 12, demolition work began on the field level grandstand. By the end of November, most of the grandstand and bleachers at field level were gone. By the first week of December, demolition of the midlevel loge seats had begun. By January 2010, the loge level was gone and demolition began on the left field escalator bank adjacent to Gate 2. In February 2010, demolition work began on the upper deck and the outfield wall; the final part of the outfield wall (the Continental Airlines ad, the out-of-town scoreboard and the remaining part of the advertising panel to its right) was taken down February 24, 2010. By March 25, the entire upper deck was taken down.
Following an unsuccessful attempt to save Gate 2 (the only portion of the original Yankee Stadium that mostly remained unaltered after the venue's renovation), demolition of the outer walls of the stadium began on March 29. Demolition of the original Yankee Stadium was completed on May 13, 2010.
A park complex called Heritage Field was constructed on the old stadium site, accounting for 40% of the original parkland that is now occupied by the new Stadium. The groundbreaking ceremony for Heritage Field took place on June 29, 2010. Heritage Field was officially opened in April 2012. At its opening, a blue outline showing the location of the original Yankee Stadium diamond was interwoven into the grass, showing that second base on the new field is in the approximate location of home plate of the original diamond.
Features.
Design.
Yankee Stadium was the first three-tiered sports facility in the United States and one of the first baseball parks to be given the lasting title of "stadium." Baseball teams typically played in a "park" or a "field". The word "stadium" deliberately evoked ancient Greece, where a "stade" was a unit of measure—the length of a footrace; the buildings that housed these footraces were called "stadia". Yankee Stadium was one of the first to be deliberately designed as a multi-purpose facility. The field was initially surrounded by a (misshapen) running track, which effectively also served as a warning track for outfielders, a feature now standard on all major league fields. The left and right field bleacher sections were laid out roughly at a right angle and to the third base stands, to be properly positioned for both track-and-field events and football. The large electronic scoreboard in right-center field, featuring both teams' lineups and scores of other baseball games, was the first of its kind.
As Yankee Stadium owed its creation largely to Ruth, its design partially accommodated the game's left-handed-hitting slugger. Initially the fence was from home plate down the right-field line, referred to as the "short porch" and to near right field, compared with to the deepest part of center field, nicknamed "Death Valley". The right-field bleachers were appropriately nicknamed "Ruthville". Although the right field fences were eventually pushed back after the 1974–1975 renovations, they were still relatively close to home plate and retained the "short porch" moniker. There is an urban legend that the stadium's field level was several feet below sea level, but that is easily disproven by observing how much higher the stadium site was (and is) than the level of the nearby Harlem River. In fact, the altitude of the old ballpark's site is 39 feet above sea level.
Monument Park.
Monument Park was an open-air museum that contained the Yankees' retired numbers, as well as a collection of monuments and plaques honoring distinguished members of the New York Yankees. It was located beyond the left-center field fences, near the bullpens.
The origins of Monument Park can be traced to the original three monuments of Lou Gehrig, Miller Huggins and Babe Ruth that once used to stand in-play in center field. Over the years, the Yankees continued to honor players and personnel with additional monuments and plaques. After the 1974–1975 renovations of Yankee Stadium, the monuments and plaques were moved behind the outfield fences to "Monument Park". A visual collection of retired numbers was soon added to this location. Monument Park remained there until the stadium's closing in 2008; after the new Yankee Stadium opened, the retired numbers, plaques, and monuments were moved into a new Monument Park in the new ballpark.
Facade.
One of the most distinguishing characteristics of Yankee Stadium was the facade, which consisted of a white frieze that ran along the bleacher billboards and scoreboard.
The facade was an addition made by Osborn Engineering, when the owners of the Yankees asked that the stadium be given "an air of dignity". Yankee Stadium tour guide Tony Morante stated, "The owners of the New York Yankees at the time decided that they wanted to give it an air of dignity, so the Osborn Engineering Company had erected what was known originally as a frieze. Somewhere along the way it took on the term of facade, and most people know it today as the facade."
It originally ran around the roof of the grandstand's upper deck. This original facade was made of copper and over the course of time, developed a patina (just like the Statue of Liberty). It was painted white in the mid-1960s.
When the stadium was renovated in the 1970s, 10 rows were added to the top of upper deck, and the support columns were removed. The original roof had to be removed; the facade was removed and sold as scrap. A smaller, concrete version was erected above the scoreboards and billboards behind the bleachers. In the new stadium, the facade was replicated in its original position along the roof of the upper deck, although now constructed of steel painted white. It does not cantilever out over the upper deck as much as the original did.
The iconic facade is employed in graphics for the YES Network and was incorporated into the logo for the 2008 All-Star Game held at the Stadium.
The term "facade" is actually a misnomer. The scalloped arches are actually a frieze, and it was originally known as such. It is unknown when or where the term "facade" came into use, but it has become the more common name, used by fans, broadcasters and personnel. With the move to the new stadium, the organization has made a move to return to the term "frieze", exclusively using it in public statements and literature.
Outfield dimensions.
In its existence, Yankee Stadium changed its dimensions several times. Many photographs taken throughout the stadium's history are used as references, as the Yankees were among the first to post distance markers on the outfield walls.
The 415 sign, and its 367 counterpart in right field, were both covered by auxiliary scoreboards during the 1949 season. Those boards displayed the current game inning-by-inning along with runs-hits-errors. When the stadium reopened in 1976, the distance in straight-away center field was . The deepest part of the outfield was in left center at . The most recent field dimensions were reached primarily by moving the Yankee bullpen to left-center from right and making a few other changes so as to bring the left-center field wall in. The 1973-era left-center field wall locations could still be seen in 1976, as this is where the outfield bleacher seats began.
The following is a partial list of the stadium's dimensions throughout the years:
After a mid-1960s remodeling, the 461 marker was replaced by a 463 marker slightly farther to the left of the pair of double doors and a 433 marker was added between the 463 and 407 markers ostensibly to represent true straightaway center field (being roughly at the midpoint of the batter's-eye screen).
Traditions and mainstays.
Bob Sheppard.
From 1951 through 2007, Bob Sheppard was the public address announcer at Yankee Stadium. His distinctive voice (Yankee legend Reggie Jackson has called him "the Voice of God") and the way he announced players for over half a century made him a part of the lore of the stadium and the team. Before a player's first at-bat of the game, Sheppard announced his position, his uniform number, his name, and his uniform number again. Example: "Now batting for the Yankees, the shortstop, number 2, Derek Jeter, Number 2." For each following at-bat, Sheppard announced just the position and name: "The shortstop, Derek Jeter." Due to health reasons, 97-year-old Sheppard announced his last game on September 5, 2007. He did sign a new two-year contract with the Yankees in March 2008 but lacked the strength necessary to do the job and missed the entire 2008 season, including the 2008 All-Star Game, which was played at Yankee Stadium. He could not announce the final game at the old stadium in September 2008, but recorded a video address that was played during the pregame ceremonies and also recorded the lineups for the game. He officially announced his retirement after the 2009 season. Sheppard died in July 2010.
Hammond Organ.
The Hammond Organ was installed at Yankee Stadium in 1967 and was primarily played by Eddie Layton from its introduction until his retirement after the 2003 season. The playing of the organ has added to the character of the stadium for many years, playing before games, introducing players, during the national anthem and the rendition of "Take me out to the ball game" during the seventh-inning stretch. After Layton's retirement, he got to pick his replacement, Paul Cartier. In recent years, the use of the organ has been decreased in favor of recorded music between innings and introducing players. Since the 2004 season, the national anthem has rarely been performed by the organists, opting for military recordings of the Star Spangled Banner. In 2005, a new Hammond Elegante was installed replacing the original Hammond Colonnade.
Music.
One of the most famous traditions for Yankee Stadium was playing Frank Sinatra's version of the "Theme from New York, New York" over the loudspeakers after every home game, since 1980.
After the September 11 attacks, all American Major League Baseball stadiums started playing God Bless America during the seventh-inning stretch for the remainder of the 2001 season. Many teams ceased this practice the following season, although it has continued in post-season events at many cities and become a tradition at Yankee Stadium alongside "Take Me Out to the Ballgame." Usually, a recording of the song by Kate Smith is played, although sometimes there is a live performance by Irish tenor Ronan Tynan. For part of the 2005 season, the Yankees used a recording of Tynan, but the Kate Smith version was reinstated due to fan complaints about the long duration of the Tynan version. For the final game at Yankee Stadium, Tynan performed "God Bless America" live, including the rarely heard introduction to the song (which Tynan includes every time he performs the song at a Yankees game).
When the Yankees scored a run, a version of the Westminster chime played as the last player to score in the at-bat gets to home plate. The version of the chime is the beginning of "Workaholic" by the music group 2 Unlimited.
Since , the Yankees' World Series championship has been celebrated with the playing of Queen's "We Are The Champions" followed by Frank Sinatra's "New York, New York".
Meeting at "the bat".
Outside the stadium's main entrance gate, stands a tall exhaust pipe in the shape of a baseball bat, complete with tape at the handle that frays off at the end. It is sponsored by Hillerich & Bradsby, makers of the famous Louisville Slugger line of baseball bats, which is specifically designed to look like a Babe Ruth model. As the most prominent feature on the stadium's exterior, recognizable even to first-time visitors, the bat was often used as a designated meeting spot for fans to meet their ticket holding friends before entering the stadium.
The "Bat" continues to stand outside the Metro North Station, built in 2009. A 450-foot long pedestrian walkway and its staircase meet at the "bat".
Roll call.
Beginning in the 1990s and after the first pitch was thrown at the top of the first inning, the "Bleacher Creatures" in Section 39, usually led by a man nicknamed Bald Vinny, began chanting the names of every player in the defensive lineup (except the pitcher and catcher, with some rare exceptions), starting with the center fielder. They did not stop chanting the player's name until he acknowledged the Creatures (usually with a wave or a point), who then moved on to the next player. Other names called out during roll call from time to time have included Yankee broadcasters John Sterling and Michael Kay or Aaron Boone, Bucky Dent and Babe Ruth when the Yankees hosted the rival Boston Red Sox. Sometimes, after a long rain delay, the Creatures started another Roll Call for comedic effect. Often when a player was replaced in the field, their replacement was also welcomed with a chant. In 2008, center fielder Melky Cabrera booted a routine grounder while attempting to wave to the fans.
Stadium usage.
Baseball.
In its 86 years of existence, Yankee Stadium hosted 6,581 regular season home games for the Yankees. Only Fenway Park (Boston), Wrigley Field (Chicago), Sportsman's Park (St. Louis) and Tiger Stadium (Detroit) have hosted more games. Due to the Yankees' frequent appearances in the World Series, Yankee Stadium played host to 161 postseason games, more than any other stadium in baseball history. The Stadium hosted 37 of the 83 possible World Series during its existence (not counting 1974–75, and the 1994 strike), with the Yankees winning 26 of them. In total, the venue hosted 100 World Series games.
16 of the 17 World Series won in the Bronx were clinched at the 1923 Yankee Stadium, nine by the Yankees and seven by their opponents:
Perhaps the most memorable moment in the venue's history came on July 4, 1939, designated as "Lou Gehrig Appreciation Day". Gehrig, forced out of action permanently by amyotrophic lateral sclerosis (ALS) and facing his impending death, gave a legendary farewell speech thanking his fans and colleagues for making him "the luckiest man on the face of the earth".
Many memorable and historic games have been played at Yankee Stadium. All three perfect games thrown by Yankee pitchers have occurred at the Stadium. Don Larsen threw a perfect game on October 8, 1956, in the fifth game of the World Series, while David Wells and David Cone threw theirs on May 17, 1998 and July 18, 1999, respectively. No-hitters were thrown by Monte Pearson, Bob Feller, Allie Reynolds, Virgil Trucks, Dave Righetti, Jim Abbott, Dwight Gooden and a combination of six Houston Astros pitchers in one game.
The Stadium was the site of a nationally televised game on August 6, 1979, the same day as the funeral for departed Yankees captain Thurman Munson. The team attended the funeral in Canton, Ohio earlier in the day and flew to New York for an emotional game. Bobby Murcer drove in all five runs for the Yankees, including a game winning two-run single that defeated the Baltimore Orioles 5–4.
Many historic home runs have been hit at Yankee Stadium. Babe Ruth hit the ballpark's first home run on its Opening Day in 1923. Ruth also set the then-league record for most home runs in a single season by hitting his 60th home run in 1927. Roger Maris would later break this record in 1961 at Yankee Stadium on the final day of the season by hitting his 61st home run. In 1967, Mickey Mantle slugged his 500th career home run. Chris Chambliss won the 1976 ALCS by hitting a "walk-off" home run in which thousands of fans ran onto the field as Chambliss circled the bases. A year later, in the 1977 World Series, Reggie Jackson hit three home runs on three consecutive pitches in the championship-clinching Game 6. In 1983, the Pine Tar Incident involving George Brett occurred; Brett's go-ahead home run in the ninth inning of the game was overturned for his bat having too much pine tar, resulting in him furiously charging out of the dugout. In Game 1 of the 1996 ALCS, Derek Jeter hit a fly ball to right-field that was interfered with by fan Jeffrey Maier but ruled a home run. In Game 7 of the 2003 ALCS, Aaron Boone hit an extra-inning "walk-off" home run to send the Yankees to the World Series. On August 6, 2007, Alex Rodriguez hit his 500th home run against the Kansas City Royals at the Stadium.
In 2001, six weeks after the September 11 attacks, Yankee Stadium hosted an emotional three games in the World Series. For Game 3, President George W. Bush hurled the ceremonial first pitch, throwing a strike. In Game 4, Tino Martinez hit a game-tying home run off Arizona Diamondbacks closer Byung-Hyun Kim with two out in the ninth inning. Derek Jeter hit the winning "walk-off" home run in extra innings off Kim, earning himself the nickname "Mr. November". The following night in Game 5, the Yankees replicated their heroics from the previous night; Scott Brosius hit a game-tying home run off Kim with two outs in the bottom of the ninth inning en route to a win.
All-Star Games.
On July 11, 1939, Major League Baseball held the league's seventh All-Star Game at Yankee Stadium, in concert with the World's Fair being held at Flushing-Meadows in Queens. Yankees manager Joe McCarthy loaded his American League team with pinstripes: Bill Dickey (catcher), Joe DiMaggio (outfield), Joe Gordon (second base), Red Rolfe (third base), George Selkirk (outfield) and Red Ruffing (pitcher) were all in the starting lineup. Reserve players included Frank Crosetti (shortstop), Lou Gehrig (first base), Lefty Gomez (pitcher) and Johnny Murphy (pitcher). The American League won, 3–1, behind a home run by DiMaggio, in front of more than 62,000. This was the second All-Star Game held in New York; the Polo Grounds had hosted the event in 1934.
From 1959 to 1962, Major League Baseball held two All-Star Games each year. On July 13, 1960, Yankee Stadium hosted baseball's second All-Star Game in three days. The National League won both games. In the latter game, Whitey Ford was the starting pitcher. Yogi Berra (catcher), Mickey Mantle (outfield), Roger Maris (outfield) and Bill Skowron (first base) were in the starting lineup; Jim Coates (pitcher) and Elston Howard (catcher) were reserves. The National League won the Yankee Stadium game, 6–0, tying a record with four home runs, including one by hometown favorite Willie Mays. The 38,000 fans who attended the game also saw the Red Sox' Ted Williams in his final All-Star appearance.
Showcasing its new renovation, Yankee Stadium hosted the All-Star Game on July 19, 1977. With the Yankees defending their 1976 pennant, Billy Martin managed the American League team on his home field. The National League won its sixth consecutive All-Star Game, 7–5, in front of more than 56,000 fans; the senior circuit's streak would reach 11. Reggie Jackson (outfield) and Willie Randolph (second base) started for the American League; Sparky Lyle (pitcher), Thurman Munson (catcher) and Graig Nettles (third base) also made the team. Jim Palmer was the game's starting pitcher because Nolan Ryan refused to play when Martin asked him.
In honor of its final year of existence, in July 2008, Yankee Stadium hosted 2008 All-Star Game festivities. The Yankees were represented by Derek Jeter, Alex Rodriguez and Mariano Rivera. In the Home Run Derby, Josh Hamilton set a single-round record with 28 home runs in the first round. At one point, he hit 13 straight home runs, many of which landed in the stadium's upper deck and deep into the right field bleachers, spurring the crowd to chant his name. Minnesota Twins first baseman Justin Morneau won the competition defeating Hamilton in the final round. The following evening, the American League won the 2008 All-Star Game 4–3 in 15 innings. Michael Young hit the game winning sacrifice fly in the 15th inning off Brad Lidge. The game was the longest in All-Star Game history by time, lasting 4 hours and 50 minutes and tied for the longest in history by innings, tied with the 1967 All-Star Game and was played in front of 55,632 people. J. D. Drew was named game MVP going 2 for 4 with a home run and two RBIs.
Final game, 2008.
Yankee Stadium hosted its final baseball game on September 21, 2008. The ceremonies for the final game at Yankee Stadium began with the opening of Monument Park, as well as allowing Yankee fans to walk on the warning track around the field. Many former Yankee greats, including Yogi Berra, Whitey Ford, Reggie Jackson, Bernie Williams, Paul O'Neill, Willie Randolph, Roy White and Chris Chambliss took their positions in the playing field as their names were announced by the legendary Bob Sheppard. Julia Ruth Stevens, daughter of Babe Ruth, threw out the ceremonial first pitch in the final game in "The House That Ruth Built".
With Andy Pettitte as the starting pitcher, the Yankees played their final game at Yankee Stadium against the Baltimore Orioles, recording the final out at 11:43 pm EDT in a 7–3 Yankee victory. Among many lasts to be recorded, a long-time standing question was answered. It was first wondered by Babe Ruth after he hit the first home run in Yankee Stadium on its opening day of April 18, 1923:
That person turned out to be Jose Molina, as he hit a two-run home run in the fourth inning.
Other lasts were Jason Giambi recording the last hit in Yankee Stadium, driving in Brett Gardner, who scored the last run in Yankee Stadium. Mariano Rivera made the final pitch in the stadium with Cody Ransom recording the final out at first base. In the eighth inning, Derek Jeter became the final Yankee to bat in Yankee Stadium.
After the game was over, captain Derek Jeter delivered a speech on the field surrounded by his teammates. In the unplanned speech, Jeter thanked and saluted the fans:
Afterwards, the team circled the stadium on the warning track waving to fans and wishing the stadium goodbye.
Boxing.
When Yankee Stadium opened in 1923, the Polo Grounds continued to host boxing matches; however, Yankee Stadium was home to prizefighting beginning in its first few months. Benny Leonard retained the lightweight championship in a 15-round decision over Lew Tendler on July 24, 1923, in front of more than 58,000 fans. It was the first of 30 championship bouts to be held at the Stadium. (This excludes dozens of non-title fights.) The boxing ring was placed over second base; a vault contained electrical, telegraph and telephone connections. In July 1927, the aging former heavyweight champion Jack Dempsey came from behind to defeat heavily favored Jack Sharkey by delivering several questionable punches that were deemed illegal. Sharkey had similarly bad luck in a July 1930 heavyweight championship bout at Yankee Stadium, when his knockout punch to Max Schmeling was ruled illegal; Schmeling won by default. In July 1928, Gene Tunney upheld the heavyweight title against Tom Heeney at Yankee Stadium, and then retired as champion.
Perhaps the most famous boxing match ever held at Yankee Stadium was on June 22, 1938, when Joe Louis, an African-American, squared off against Schmeling, a German. Adolf Hitler followed the rematch carefully, imploring Schmeling to defeat Louis, whom Hitler publicly berated. This left some with what they perceived as a moral predicament: root for the black fighter, or for the Nazi. Schmeling had defeated Louis in 1936, but in defense of his title, Louis knocked out Schmeling in the first round. This was one of eight championship fights the "Brown Bomber" fought at Yankee Stadium.
On July 1, 1939, Max Baer defeated Lou Nova at Yankee Stadium, in the first televised boxing match in the United States. The event was broadcast by television station W2XBS, forerunner of WNBC-TV. (The World Series was not televised until 1947.) On September 27, 1946, Tony Zale knocked out New York native Rocky Graziano for the middleweight crown; it was the first of three bouts between Zale and Graziano.
On June 25, 1952, middleweight champion Sugar Ray Robinson sought his third title against light-heavyweight champ Joey Maxim at Yankee Stadium. More than 47,000 saw Robinson outfight Maxim but lose due to heat exhaustion in round 14 (due to the weather that topped 104-degrees Fahrenheit). The referee who declared Maxim the winner was the second that night; the first had left the fight due to heat exhaustion.
After its 1970s renovation, Yankee Stadium hosted only one championship fight. On September 28, 1976, a declining Muhammad Ali defended his heavyweight crown against Ken Norton. To that point, Norton was one of only two boxers who had beaten Ali (in 1973); this was their third and final, meeting. Norton led for most of the fight, but Ali improved in the later rounds to win by unanimous decision.
College football.
The first college football game played in Yankee Stadium was a 3-0 Syracuse victory over Pittsburgh on October 20, 1923. When an ill Ruth could not lead the Yankees to the World Series in 1925, college football took center stage at Yankee Stadium that fall. The fiercely competitive Notre Dame–Army game moved to Yankee Stadium, where it remained until 1947. In the 1928 game, with the score 0–0 at halftime, legendary Notre Dame coach Knute Rockne gave his "win one for the Gipper" speech (with reference to All-American halfback George Gipp, who died in 1920); Notre Dame went on to defeat Army, 12–6. The 1929 game between the two teams had the highest attendance in the series at 79,408. The 1946 Army vs. Notre Dame football game at Yankee stadium is regarded as one of the 20th century college football Games of the Century.
Notre Dame played 24 games at Yankee Stadium, going 15–6–3. Army played 38, compiling a 17–17–4 record (including the best-attended game, on December 1, 1928 when Army lost to Stanford 26–0 before 86,000 fans). New York University played more games there than any other school, 96, using it as a secondary home field from 1923 to 1948, with a record of 52–40–4. Nearby Fordham University played 19 games there, going 13–5–1.
Eight college football games were played at Yankee Stadium on Thanksgiving Day, the first seven by New York University. Perhaps, the most famous Thanksgiving Day game was the first. Oregon State Agricultural College (now Oregon State) was the first West Coast team to travel across the country and play an East Coast team. 8–1 NYU was a 3–1 favorite to beat 5–3 OSAC, but Oregon State upset the hometown favorites 25–13. Will Rogers lamented what the "Oregon apple knockers" had done to his "city slickers" in a column after the game. After the 1928 game, NYU beat Carnegie Tech (now Carnegie Mellon University) in 1931 and 1932, defeated Fordham in 1936, lost to Carnegie Tech in 1929 and lost to Fordham in 1934 and 1935. In the eighth game, in 1963, Syracuse beat Notre Dame, 14–7. This was a rematch following the teams' controversial 1961 game won by Notre Dame, 17–15.
The Gotham Bowl was scheduled to premiere at Yankee Stadium in 1960, but was canceled when no opponent could be found for Oregon State University. The 1961 game was moved to the Polo Grounds, and when just 6,166 people came to Yankee Stadium for the 1962 game, in which the University of Nebraska defeated the University of Miami, 36–34, the Gotham Bowl was never played again. The Miami-Nebraska game remains the only college bowl ever played at the stadium.
In 1969, Notre Dame and Army reprised their long series at the Stadium (1925–1946 except 1930) with one final game.
Starting in 1971, the Stadium hosted the Whitney M. Young Urban League Classic, a game between historically black colleges, often featuring Grambling State University of Louisiana, coached by Eddie Robinson, the first college coach to win 400 games. The Classic helped to spread the fame of Grambling and other similar schools. Yankee Stadium hosted its final Classic during the 1987 season, also the last time a football game was played there. Grambling lost to Central State University of Ohio, 37–21.
The Classic has been held at Giants Stadium and MetLife Stadium in New Jersey's Meadowlands Sports Complex ever since, though the Yankees remain a supporter of the event.
Professional football.
In 1926, after negotiations failed with the fledgling NFL and the Chicago Bears, Red Grange and his agent C.C. Pyle formed the first American Football League and fielded a team called the New York Yankees based in Yankee Stadium. The league failed after only one year, but the team continued as a member of the NFL for two seasons before ceasing operations. A second New York Yankees football team, not related to the first, split its home games between Yankee Stadium and Downing Stadium as it competed in the second AFL in 1936 and 1937. A third AFL New York Yankees took the field in 1940 and became the New York Americans in 1941.
The New York Yankees of the All-America Football Conference (AAFC) played their home games at Yankee Stadium from 1946 to 1949. The 1947 AAFC championship game was held at Yankee Stadium. Following the 1949 season, the NFL New York Bulldogs acquired many of the players from the 1949 Yankees. Using the name the New York Yanks they played two seasons at Yankee Stadium, 1950 and 1951.
The New York Giants of the NFL played their home games at Yankee Stadium from 1956 to 1973. On December 28, 1958, Yankee Stadium hosted the NFL championship game, frequently called "The Greatest Game Ever Played". The Baltimore Colts tied the Giants, 17–17, on a field goal with seven seconds left. Led by quarterback Johnny Unitas, the Colts won in overtime, 23–17. The game's dramatic ending is often cited as elevating professional football to one of the United States' major sports. Additionally, one of the most notable plays in NFL history occurred at Yankee Stadium on November 20, 1960 when the Philadelphia Eagles' Chuck Bednarik forcefully tackled the Giants' Frank Gifford in the last minute of a close game, forcing a fumble recovered by the Eagles that clinched the victory for Philadelphia and ultimately helped the Eagles dethrone the two-time defending champion Giants as NFL Eastern Conference champions. The hit left Gifford with a concussion and forced his temporary retirement from football for the remainder of the 1960 season and all of the 1961 season. Three NFL championships games were played at Yankee Stadium; 1956, 1958 and 1962.
The Giants played their first two home games at Yankee Stadium in 1973, concluding their tenancy on September 23 with a 23–23 tie against the Philadelphia Eagles. In October, they moved to the Yale Bowl in New Haven, Connecticut, for the rest of the season.
Soccer.
Celtic F.C. defeated New York Yankees in the first major soccer game to be played at the Stadium on June 28, 1931. In the coming three decades, a number of games between Jewish Palestinian teams and American all-stars were played. European club exhibitions first came in 1952, when on June 14, Liverpool drew 1–1 with Grasshopper Club Zürich. The next day, Tottenham Hotspur thrashed Manchester United 7–1, just a year after United had taken over for Spurs as champions of England. The following year, on June 8, the English national team defeated the U.S. national team 6–3, in a rematch of the Miracle on Grass match at the 1950 World Cup.
Major international clubs returned to the Stadium in 1966, with Pele's Santos of Brazil beating Inter Milan 4–1 on June 5. In 1967, C.A. Cerro of Uruguay played in the United Soccer Association during the summer months under the title "New York Skyliners". They played major games against Hibernian F.C. of Scotland, renamed "Toronto City", Cagliari F.C. of Italy, renamed "Chicago Mustangs" and Bangu Atlético Clube of Brazil, renamed "Houston Stars". During the same year, the stadium also became home to the New York Generals of the National Professional Soccer League. Upon the 1968 merger of the United Soccer Association and the National Professional Soccer League, a new league was created known as the North American Soccer League, where the Generals remained as the New York team. In 1968, in addition to league competition, the Generals took on Santos, winning 5–3 and Real Madrid, losing 4–1. That year, Santos also played and beat S.S.C. Napoli of Italy 4–2 at the Stadium, along with S.L. Benfica of Portugal, with whom they drew 3–3. The next year, four major international club games were played at the Stadium: Barcelona beat Juventus 3–2 on May 30, Inter Milan beat Sparta Prague 4–0 on June 27 and A.C. Milan defeated Panathinaikos 4–0 also on June 27. Finally, on June 29, Yankee Stadium hosted its own version of the Derby della Madonnina, with A.C. Milan defeating Inter 6–4. The latter three games that year were all part of a three-day "United States Cup of Champions".
On September 15, 1968, the U.S. national soccer team played an international friendly against the Israel national team at the Stadium. It was the first game for the U.S. in 15 months and 10,118 saw Israel and the U.S. draw 3-3.
In 1971 and 1976, the New York Cosmos of the NASL played their home games at Yankee Stadium. During the 1971 season, they also hosted Hearts from Scotland, and Apollon Kalamarias of Greece. In 1976 the team's star attraction was Pelé. The Brazil native, known as "The King of Football", was considered the best player in the world. Also that year, in Yankee Stadium's final international match on May 28, England defeated Italy 3–2 as part of the Bicentennial Cup Tournament. Finally, on August 10, 1976, the last ever soccer game was played at Yankee Stadium, with the Cosmos thrashing the Miami Toros 8–2. The Cosmos moved to Giants Stadium for the 1977 season.
Other events.
Beginning in 1950, the stadium began holding religious conventions of Jehovah's Witnesses. The 1958 New York International Convention of Jehovah's Witnesses attracted 253,922 people from all over the world, although many were at the nearby Polo Grounds, the Yankee Stadium total of 123,707 in a single day remains the biggest attendance ever for any event at Yankee Stadium and is commemorated by a historical marker in the sidewalk nearby. These conventions would continue on until the late 1980s. When room ran out in the stands, the ladies were asked to remove their heels, and people were brought in to sit in the outfield. There was also a makeshift camp nearby where the program was broadcast for hundreds others to listen to.
On July 20, 1957, evangelist Billy Graham attracted a crowd of 100,000 to a televised "crusade" at Yankee Stadium. A "New York Times" article of the following day described the turnout as "the largest crowd in stadium history" to that time.
Cardinal Francis Spellman (1957), Pope Paul VI (1965), Pope John Paul II (1969 as a cardinal, 1979 as pope) and Pope Benedict XVI (2008) all celebrated Mass at the ballpark, along with numerous clergy and lay Catholics. On June 21, 1990, a rally was held at Yankee Stadium for Nelson Mandela upon his release from prison. On September 23, 2001, Yankee Stadium hosted a memorial service for victims of the September 11 terrorist attacks in New York City.
The first concert ever held there was an ensemble R&B show on June 21, 1969, put together by the Isley Brothers; the first rock concert held at the stadium was on June 22, 1990, by Billy Joel. It was also the site of two dates of U2's Zoo TV Tour in 1992. During one song, Bono paid tribute to the show's setting with the line "I dreamed I saw Joe DiMaggio/Dancing with Marilyn Monroe". Pink Floyd also performed two sold-out shows at this venue on their final North American tour in 1994 in support of their album "The Division Bell".
On March 10, 2006, Yankee Stadium saw its only wedding at home plate. Blind sportswriter Ed Lucas, who has been a member of the Yankee family for over 40 years, got special permission from the Yankees, the City of New York and Major League Baseball to exchange vows with his fiancée, Allison Pfieffle, on the same spot where Lou Gehrig made his famous farewell speech, among the many notable events. Over 400 people, including present and former members of the Yankee family were in attendance to see the happy couple united, and the ceremony was broadcast on ESPN, the YES Network, NBC's "Today Show" and other national media outlets.
National Hockey League (NHL) executives inquired about the possibility of using Yankee Stadium for an outdoor ice hockey match featuring the New York Rangers in the 2008–2009 season after the successful reception of both the 2003 Heritage Classic and the 2008 NHL Winter Classic outdoor games. If approved, it would have been the final sporting event at the current stadium. The NHL, however, decided to hold the second Winter Classic in Chicago, at Wrigley Field.
References.
Notes
Bibliography

</doc>
<doc id="40020" url="https://en.wikipedia.org/wiki?curid=40020" title="Cathedral of Saint John the Divine">
Cathedral of Saint John the Divine

The Cathedral of St. John the Divine, officially the Cathedral Church of Saint John: The Great Divine in the City and Diocese of New York, is the cathedral of the Episcopal Diocese of New York. It is located in New York City on Amsterdam Avenue between West 110th Street and 113th Street in Manhattan's Morningside Heights neighborhood.
Designed in 1888 and begun in 1892, the cathedral has undergone radical stylistic changes and the interruption of the two World Wars. Originally designed in the Byzantine Revival-Romanesque Revival styles, the plan was changed after 1909 to a Gothic Revival design. After a large fire on December 18, 2001, it was closed for repairs and reopened in November 2008. It remains unfinished, with construction and restoration a continuing process. As a result, it is often nicknamed "St. John the Unfinished".
There is a dispute about whether this cathedral or Liverpool Cathedral is the world's largest Anglican cathedral and church. It is also the fourth largest Christian church in the world. The interior covers , spanning a length of 601 ft (183.2 meters) and height 232 ft (70.7 meters). The interior height of the nave is 124 feet (37.8 meters).
The cathedral houses one of the nation's premiere textile conservation laboratories to conserve the cathedral's textiles, including the Barberini tapestries to cartoons by Raphael. The laboratory also conserves tapestries, needlepoint, upholstery, costumes, and other textiles for its clients.
History.
Planning and construction.
In 1887 Bishop Henry Codman Potter of the Episcopal Diocese of New York called for a cathedral to rival the Catholic St. Patrick's Cathedral in Manhattan. An 11.5-acre (4.7 ha) property, on which the Leake and Watts Orphan Asylum had stood, was purchased by deed for the cathedral in 1891. After an open competition, a design by the New York firm of George Lewis Heins and Christopher Grant LaFarge in a Byzantine-Romanesque style was accepted the next year.
Construction on the cathedral was begun with the laying of the cornerstone on December 27, 1892, St. John's Day, when Bishop Henry Potter hit the stone three times with a mallet and said "Other foundation can no man lay, than that is laid which is Jesus Christ." The foundations were completed at enormous expense, largely because bedrock was not struck until the excavation had reached . The walls were built around eight massive 130-ton, 50-foot (15 m) granite columns, each turned as one piece, sourced from Vinalhaven, Maine and said to be the largest in the world. The columns, which were transported to New York on a specially constructed barge towed by the large steam tug "Clara Clarita", took more than a year to install.
The first services were held in the crypt, under the crossing in 1899. The Ardolino brothers from Torre di Nocelli, Italy, did much of the stone carving work on the statues designed by the English sculptor John Angel.
After the large central dome made of Guastavino tile was completed in 1909, the original Byzantine-Romanesque design was changed to a Gothic design. Increasing friction after the premature death of Heins in 1907, fueled by a preference among some trustees for a less Romanesque and more Gothic style for the cathedral, ultimately led the trustees to dismiss the surviving architect, C. Grant LaFarge, and hire the noted Gothic Revival architect Ralph Adams Cram to design the nave and "Gothicize" what LaFarge had already built. In 1911, the choir and the crossing were opened, and the foundation for Cram's nave began to be excavated in 1916.
The first stone of the nave was laid and the west front was undertaken in 1925. Bishop William T. Manning had announced a $10 million capital campaign to raise money for this project at a major press conference; the New York campaign committee was headed by Franklin D. Roosevelt. Work at the church went on during the Great Depression as a result of monies raised in this campaign.
First opening.
The Cathedral was opened end-to-end for the first time on November 30, 1941, a week before the bombing of Pearl Harbor. Subsequently construction on the cathedral was halted, because the then-bishop felt that the church's funds would better be spent on works of charity, and because the United States' subsequent involvement with the Second World War greatly limited available manpower. Although Cram intended to dismantle the dome and construct a massive Gothic tower in its place, this plan was never realized. The result is that the Cathedral reflects a mixture of architectural styles, with a Gothic nave, a Romanesque crossing under the dome; chapels in French, English and Spanish Gothic styles, as well as Norman and Byzantine; Gothic choir stalls, and Roman arches and columns separating the high altar and ambulatory.
The Very Reverend James Parks Morton, who became dean of the cathedral in 1972, fostered projects to enable it to become "a holy place for the whole city" and encouraged a revival in the construction of the Cathedral. In 1979 the then bishop, the Right Reverend Paul Moore, Jr., decided that construction should be continued, in part to preserve the crafts of stonemasonry by training neighborhood youths, thus providing them with a valuable skill. In 1979, Mayor Ed Koch quipped during the dedication ceremony, "I am told that some of the great cathedrals took over five hundred years to build. But I would like to remind you that we are only in our first hundred years."
One architect who worked for Cram and Ferguson as a young man, John Thomas Doran, eventually became a full partner. (Cram and Ferguson became known as Hoyle, Doran and Berry. The firm exists today as HDB/ Cram and Ferguson). The November 1979 edition of "LIFE" magazine featured St. John the Divine Cathedral. To quote the magazine: (p. 102)"One architect from Cram's firm survives. At 80, John Doran is among the last architects able to draw Gothic plans - the difficult style is not taught in schools. He is helping St. John's new generation of builders. "Nothing I've done," Doran says, "has held my interest like the cathedral. Everything since then has just been making a living."
Construction on the south tower resumed for some years in the 1980s, during which campaign another of height was added, in limestone rather than the granite of the original construction. Following the abandonment of this initiative, the scaffolding that had been erected around the south tower remained, rusting away (until it was removed in the summer of 2007).
Under master stone carvers Simon Verity and Jean Claude Marchionni, work on the statuary of the central portal of the Cathedral's western façade was completed in 1997. The Cathedral has since seen no further construction, and the new generation of trained stonecarvers has gone on to other projects.
21st century.
In 2001 the choir parapet was completed with the addition of a sculpture by Chris Pelletierri of a group of four figures: Martin Luther King, Albert Einstein, Susan B. Anthony and Mohandas Gandhi.
The parapet was originally installed in 1922 with twenty niches for statues of the spiritual heroes of the twenty centuries since the birth of Christianity.
Representing the 17th, 18th and 19th centuries are statues of William Shakespeare, George Washington and Abraham Lincoln. The niche for the 20th century was left blank until that century was completed.
On the morning of December 18, 2001, a fire swept through the unfinished north transept, destroying the gift shop and for a time threatening the sanctuary of the cathedral itself. It temporarily silenced the Aeolian-Skinner pipe organ. Although the organ was not damaged, all its pipes and other component parts had to be removed and laboriously cleaned and restored, to prevent damage from the fire's accumulated soot. Valuable tapestries and other items in the cathedral were damaged by the smoke.
In 2003, the cathedral was designated a landmark by the New York City Landmarks Preservation Commission; however, shortly thereafter, the designation was unanimously overturned by the New York City Council, some of whose members favored landmark status for the cathedral's entire footprint, rather than just the building. Councilman Bill Perkins proposed that the protective status should also be extended to the cathedral's grounds in order to control development there. During the last several years, no move to designate a special status for the entire grounds has been made. Consequently, the cathedral is not officially a New York City landmark at this time.
In January 2005, the cathedral began a major restoration, which was completed and the cathedral rededicated on Sunday, November 30, 2008. A state-of-the-art chemical-based cleaning system was utilized, not only to remove smoke damage resulting from the 2001 fire but also the dark patina of 80 years of city air, filling the interior with unfamiliar light.
In 2008, the cathedral leased the southeast corner of its property, which contained the Cathedral's playground and Rose Garden, to the AvalonBay Communities. A modern, glass apartment tower, the Avalon Morningside Park now occupies the space.
In 2014, it housed one of the biggest pieces of sculpture ever displayed in the United States, "Phoenix", by Chinese artist Xu Bing.
Description.
The Cathedral is located at 1047 Amsterdam Avenue (between West 110th Street, also known as Cathedral Parkway, and 113th Street) in Manhattan's Morningside Heights. The New York St. Luke's-Roosevelt Hospital Center and the campus of Columbia University are nearby.
The building as it appears today conforms primarily to a second design campaign from the prolific Gothic Revival architect Ralph Adams Cram of the Boston firm Cram, Goodhue, and Ferguson. Without copying any one historical model, and without compromising its authentic stone-on-stone construction by using modern steel girders, Saint John the Divine is an example of the 13th century High Gothic style of northern France. The cathedral is 601 feet (186 meters) in length, and the nave ceiling reaches 124 feet (37.7 m) high. It is the longest Gothic nave in the United States, at . At the west end of the nave, installed by stained glass artist Charles Connick and constructed out of 10,000 pieces of glass, is the largest rose window in the U.S. Seven chapels radiating from the ambulatory behind the choir are each in a distinctive nationalistic style, some of them borrowing from outside the Gothic vocabulary. These chapels are known as the "Chapels of the Tongues", and they are devoted to St. Ansgar, patron of Denmark, who is venerated as an apostle to the Scandinavian countries; St. Boniface, apostle of the Germans; St. Columba, patron of Ireland and Scotland; St. Savior (Holy Savior), devoted to immigrants from the east, especially Africa and Asia; St. Martin of Tours, patron of the French; St. Ambrose, patron of Milan; and St. James, patron of Spain. The designs of the chapels are meant to represent each of the seven most prominent ethnic groups to first immigrate to New York City upon the opening of Ellis Island in 1892, the same year the cathedral was begun.
In the center, just beyond the crossing, is the large, raised high altar, behind which is a wrought iron enclosure containing the Gothic style tomb of the man who originally conceived and founded the cathedral, the Right Reverend Horatio Potter, Bishop of New York. Later Episcopal bishops of New York, and other notables of the church, are entombed in side chapels.
Directly below this is a large hall in the basement, used regularly to feed the poor and homeless, and for meetings, and multiple crypts.
On the grounds of the cathedral, toward the south, are several buildings (including a synod hall and the Cathedral School of St. John the Divine), and a Biblical garden, as well as a large bronze work of public art by the cathedral's sculptor-in-residence, Greg Wyatt, known as the Peace Fountain, which has been both strongly praised and strongly criticized.
Great west doors.
The great west doors on Amsterdam Avenue were designed between 1927 and 1931 by the designer Henry Wilson. The bronze doors (unveiled as the "Golden Doors") were installed in 1936. The sequence of 48 relief panels presents scenes from the Old and New Testaments and the Apocalypse.
In his lifetime, Henry Wilson only produced four sets of bronze doors, St Mary's Church, Nottingham, the chapel at Welbeck Abbey, the Salada Tea Company in Boston, and these. The Cathedral's great west doors were the last of the four commissions, and are on a monumental scale, measuring some . Henry Wilson died in Menton, France, in 1934, shortly after finishing the design but before the doors were installed.
Concerts and activities.
The size of the Cathedral's interior, the fourth largest in the world, presents a superlative level of natural acoustics that confer a reverb time greater than eight seconds and an organic brilliance of tone. Music of many genres, including chant, choral music, organ music, and hymnody adapted for large cathedrals is therefore important for the worship regularly celebrated in its nave.
The cathedral is additionally a major center for concert musical performances in New York. Organ recitals are held regularly weekdays at noon and most Sundays at 5:15pm, as well as on special occasions. In addition, several times a year on selected Sundays at 5:15pm, the St. James's Recital Series features performances by local musicians, pianists in particular; recitals follow the 4pm Choral Evensong in St. James Chapel and are free and open to the public.
The cathedral has an annual New Year's Eve Concert for Peace. The Postlude to Act I of Leonard Bernstein's opera "Quiet Place" received its New York premiere at the 1985 concert. The 1990 concert was a tribute to Bernstein himself, who helped found the event and had died two months earlier on October 14.
Duke Ellington's "Second Sacred Concert," of his original sacred music compositions, premiered at the cathedral on January 19, 1968. No recording of the performance has surfaced to date. After its debut performance, the "Second Sacred Concert" was recorded on January 22 and February 19, 1968 at Fine Studio, New York City. The concert was originally issued as a double LP on Prestige Records. It was later reissued on a single CD without the original tracks "Don't Get Down On Your Knees To Pray Until You Have Forgiven Everyone" and "Father Forgive". Performing at the recording session were Ellington on the piano and doing the narration, 16 of his orchestra members, four vocalists including the Swedish singer Alice Babs, and five choirs: the AME Mother Zion Church Choir, the choirs Of St Hilda's and St. Hugh's School, the Central Connecticut State College Singers, and the Frank Parker Singers.
In 1990, the avant-garde musician Diamanda Galas performed "Plague Mass," a culmination of her work dedicated to the victims of the AIDS epidemic. Galas' performance consisted of covering her body in cattle blood and reinterpreting biblical texts and classic literature; she said it was a protest against what she saw as the ignorance and condemnation towards people with AIDS from religious and political groups.
Paul Winter has given many concerts at the cathedral, and the Paul Winter Consort are the artists in residence. Among the major musical event that takes place every year is a celebration of the feast day of Saint Francis of Assisi, when the Paul Winter Consort participates in a liturgical performance of Winter's "Missa Gaia" (Earth Mass). The musical group also performs at the annual Winter Solstice program. Musical performances and special events are customarily listed on the cathedral's website under Events & Programs.
The Congregation of Saint Saviour, a separately incorporated congregation, makes its home at the cathedral. It offers events, classes and programs.
Organ.
The Great Organ was built by the renowned organbuilder Ernest M. Skinner in 1906 as the firm's Opus 150. It is the largest of five organs in the cathedral complex. It is located above the Choir on the North and South sides. In 1954, it was enlarged by the Aeolian-Skinner Organ Company, Opus 150-A, under the tonal direction of G. Donald Harrison. During this rebuild, the world-famous State Trumpet was added and placed below the rose window. Speaking on of wind pressure, it is among the most powerful organ stops in the world. In late 2001, a fire in the North Transept resulted in heavy smoke damage to the organ, which was finally returned to service in 2008. While The Great Organ is currently valued at over eight million U.S. dollars, it is considered to be a priceless treasure not only to organists, but to the worlds of both music and Christianity. This instrument, perhaps the pinnacle of the American Classic organ, speaks into an enviable eight-plus-second acoustic.

</doc>
<doc id="40021" url="https://en.wikipedia.org/wiki?curid=40021" title="990">
990

__NOTOC__
Year 990 (CMXC) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40022" url="https://en.wikipedia.org/wiki?curid=40022" title="993">
993

__NOTOC__
Year 993 (CMXCIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Astronomy.
</onlyinclude>

</doc>
<doc id="40023" url="https://en.wikipedia.org/wiki?curid=40023" title="994">
994

__NOTOC__
Year 994 (CMXCIV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Astronomy.
</onlyinclude>

</doc>
<doc id="40025" url="https://en.wikipedia.org/wiki?curid=40025" title="996">
996

__NOTOC__
Year 996 (CMXCVI) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40026" url="https://en.wikipedia.org/wiki?curid=40026" title="997">
997

__NOTOC__
Year 997 (CMXCVII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="40027" url="https://en.wikipedia.org/wiki?curid=40027" title="998">
998

__NOTOC__
Year 998 (CMXCVIII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40028" url="https://en.wikipedia.org/wiki?curid=40028" title="List of Governors of Montana">
List of Governors of Montana

The Governor of Montana is the head of the executive branch of Montana's state government and the commander-in-chief of the state's military forces. The governor has a duty to enforce state laws, the power to either approve or veto bills passed by the Montana State Legislature, to convene the legislature at any time, and to grant pardons and reprieves.
The current Montana Constitution, ratified in 1972, calls for a four-year term for the governor, commencing on the first Monday in January following an election. The governor is term-limited to 8 years in any 16-year period. The constitution provides for the election of a lieutenant governor for the same term as the governor. The two offices are elected on the same ticket; a provision which did not appear in the state's first constitution, ratified in 1889. In the event of a vacancy in the office of governor due to resignation, disqualification, or death, the lieutenant governor becomes governor for the remainder of the term. If the governor is unable to perform his duties for any other reason, the lieutenant governor may become acting governor at the discretion of the state legislature. The 1889 constitution made the lieutenant governor president of the state senate, but this provision was removed in the 1972 constitution.
Montana has had 24 governors (ten of whom were actually born within state boundaries), consisting of 9 Republicans and 15 Democrats. The longest-serving governor was John Edward Erickson, who was elected three times and served from 1925 to 1933 before resigning to become a U.S. senator, only two months into his third term. The shortest-serving governor was Elmer Holt, who served less than 13 months when the previous governor died. The current governor is Democrat Steve Bullock, who took office on January 7, 2013 and is serving his first term.
Governors.
Prior to the creation of Montana Territory (1864–1889), numerous areas of what is now Montana were areas of Oregon Territory (1848–1859), Washington Territory (1853–1863), Idaho Territory (1863–1864), and Dakota Territory (1861–1864).
Governors of Montana Territory.
"NOTE:" Term dates are for the full, official term of office, see notes column for clarification of dates when men served as governor.
Dem Democratic
Rep Republican
Governors of Montana.
Dem Democratic
Rep Republican
Other high offices held.
This is a table of the equivalent or higher state and federal offices and other governorships held by governors. All representatives and senators represented Montana. * denotes cases where the governor resigned the governship to accept the other office.
Living former governors of Montana.
, there are five former governors of Montana who are currently living at this time, the oldest former governor of Montana being Ted Schwinden (served 1981–1989, born 1925). The most recent death of a former governor of Montana, was Tim M. Babcock (served 1962–1969, born 1919), on April 7, 2015. The most recently serving former governor of Montana to die was Thomas Lee Judge (served 1973–1981, born 1934), on September 8, 2006.

</doc>
<doc id="40029" url="https://en.wikipedia.org/wiki?curid=40029" title="Postmark">
Postmark

A postmark is a postal marking made on a letter, package, postcard or the like indicating the date and time that the item was delivered into the care of the postal service. Modern postmarks are often applied simultaneously with the cancellation or killer that marks the postage stamp(s) as having been used (though in some circumstances there may be a postmark without a killer, and sometimes the postmark and killer form a continuous design), and the two terms are often used interchangeably, if incorrectly. Postmarks may be applied by hand or by machines, using methods such as rollers or inkjets, while digital postmarks are a recent innovation. The local post Hawai'i Post had a rubber-stamp postmark, parts of which were hand-painted. At Hideaway Island, Vanuatu, the Underwater Post Office has an embossed postmark.
History.
The first postmark (called the "Bishop Mark") was introduced by English Postmaster General Henry Bishop in 1661 and showed only the day and month of mailing in order to prevent the delay of the mail by carriers.
In England during the latter part of the 17th century several postmarks were devised for use with the London Penny Post, a postal system that delivered mailed items within the city of London. The postmarks bore the initial of the particular post office or handling house it was sent from along with a separate time stamp. Postage was prepaid and the postmark was applied to the mailed item by means of an inked hand-stamp. Some historians also consider these postmarks to be the world's first postage 'stamps'.
In the 19th century and early 1900s it was common for letters to receive multiple postmarks indicating the time, date, and location of each post office delivering or transporting the letter, and this is still occasionally true, though to a lesser extent (see "backstamp"). While almost every contemporary postmark includes a location as well as a date, in 2004 New Zealand Post announced plans to eliminate the location on their postmarks and include only the date; however, information about this can be determined by a three-number code on the postmarks.
In Great Britain the first postmark employed for the cancellation of the then new adhesive postage stamps was the Maltese Cross, so named because of its shape and appearance. This was used in conjunction with a date stamp which was applied, usually to the rear of the letter, which denoted the date of posting.
Different types of postmarks include railway post offices ("RPOs") and maritime (on-board ship) postmarks. Postmarks on naval vessels during sensitive operations in wartime are sometimes "clean", showing less information than normally to prevent route of travel or other details from falling into enemy hands. Similar to this is the "censored postmark," overprinted with a black obliteration of the time and place of mailing for similar reasons.
The Pony Express used a variety of different postmarks on the mail it carried across the Western United States. There are only 250 known examples of surviving Pony Express mail/postmarks in various collections today bearing one of more than a dozen different types of postmarks.
Hawai'i post once had a surfboard mail postmark, for covers that traveled by surfboard.
A colour postmark is on the United States Postal Service-issued collectible envelope commemorating the 2004 inauguration of George W. Bush.
While postmarks are applied almost universally by or under the authority of the official postal department, service, or authority in the United States it is possible to receive a permit to apply your own postmark, called a Mailer's Permit Postmark, and under certain conditions specified by the private express statutes in the United States, a privately carried letter may be cancelled with a private postmark. Unofficial entities that issue artistamps may use postmark-like markings as well.
Marcophily is the study of postmarks and there are many published work on postmarks covering the topic from before 1900, such as the fancy cancels, until the present day. These include the so-called fancy cancels of United States to modern machine postmarks.
Fewer postmarks are used now than previously, with the advent of meter labels, some types of computer vended postage, and computerized postage that people can print from their own PCs (called PC Postage in the United States, these services were offered by such companies as Stamps.com and Neopost, Inc.). These indicia are not always postmarked by the Post Office but if put into the mailstream later than the date listed on them, they are postmarked about 50% of the time. Because of this, it is a bad idea to try and use the date on your postage as a postmark.
An official example relating a numismatic item to postmarks occurred on April 13, 1976 when the U.S. issued a new two-dollar bill. People could buy the bills at face value, add a first class stamp (at the time 13 cents), and have the combination postmarked to show they were the first day of issue. Large numbers of these were produced and they remain common.
Ink colour.
When the first universal postal system was started in the United Kingdom with its Penny Black, the postmark used red ink for contrast. This was not successful, and the stamp was changed to non-black colours so that the postmark could use black ink.
The majority of postmarks today are in black, with red (particularly in the United States with local post offices' handstamps) following, though sometimes they are in other colours. This is particularly true in the case of pictorial postmarks if the colour in question has some connection to the commemoration.
Digital postmarks.
In 2004 the United States Postal Service announced plans to introduce first day digital colour postmarks to be used to cancel some first day covers for commemorative stamps in 2005 and this practice has continued into 2006 and was ongoing as of 2015.
Postmark advertisement.
Singapore Post offers a "postmark advertising" service which, strictly speaking, applies to the "killer" rather than the postmark. Hungarian Post Co., Ltd. offers a similar service.
Stereoscopic.
There have apparently been some postmarks with a producing a stereoscopic or "3D" effect where a special viewer is required and is considered more as a novelty than a practical postmark.
Valuation of cancellations.
The study of postmarks is a specialized branch of philately called marcophily. It may bring added value to the stamps by their historical significance. Other parameters are the rarity and the attractiveness. In particular, the stamps issued by the Empire of Austria during the 1850-1867 period (the 5 issues before the Austro-Hungarian compromise of 1867), are collected for their variety and beauty. More details can be found in Valuation of cancellations of the Austrian Empire.
A special or rare postmark can substantially add to the value of a stamp. Also, in addition to everyday postmarks there are postmarks indicating the first day of issue of a particular stamp and pictorial cancellations commemorating local events, anniversaries, and the like and slogan postmarks which advertise an event or pass information to the public. (There has been a recent change to the term "pictorial postmarks" rather than "pictorial cancellations" by the USPS.) 
There are some examples of "faked covers" produced by philatelic forgers, most usually in order to increase their value, in which the postmark has been altered in some way; for example, by changing the date.
Practical uses.
The postmark is often considered as an official confirmation that a cover (letter, packet, etc.) mailed item was mailed at a given location at a specific date. For example, the date of the postmark can be quite important. In the United States, the Internal Revenue Service will still consider income tax returns as filed on time though it receives them late if they are postmarked on time, and this date (with, perhaps, other proofs of mailing), may have significance as regards legal filings and proofs of service (though in this case the date may viewed as "on time" if the date of the postmark is no more than one day after the date service is supposed to have been made). Entries into sweepstakes and contests, and juried art exhibitions, may likewise have a "postmark deadline," and in at least one case it might have significance regarding the date of class withdrawal.
Similar marks.
A postmark should not be confused with the killer which are lines, bars, etc. used to cancel a postage stamp. Neither should a postmark be confused with overprints generally, or pre-cancels (stamps that have been cancelled before the envelope or package to which they are affixed is submitted or deposited for acceptance into the mailstream, they most commonly have taken the form of a pre-printed city name on the stamp) specifically, which generally do not indicate a date.
Flight cachets, more or less elaborate rubber-stamps on an envelope indicating on which flight (typically a first flight) a cover has traveled via air mail, are in addition to the postmark and are not postmarks either.
Clubs.
There are many clubs devoted to the hobby of collecting postmarks. One of those clubs is the Post Mark Collector's Club, founded in 1946 and based in the USA. Another is the British Postmark Society, founded in 1958.

</doc>
<doc id="40030" url="https://en.wikipedia.org/wiki?curid=40030" title="Killer">
Killer

A killer is someone or something that kills, such as a murderer.
Killer may also refer to:

</doc>
<doc id="40031" url="https://en.wikipedia.org/wiki?curid=40031" title="1031">
1031

__NOTOC__
Year 1031 (MXXXI) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Middle East.
</onlyinclude>

</doc>
<doc id="40032" url="https://en.wikipedia.org/wiki?curid=40032" title="1032">
1032

__NOTOC__
Year 1032 (MXXXII) was a leap year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="40033" url="https://en.wikipedia.org/wiki?curid=40033" title="1033">
1033

__NOTOC__
Year 1033 (MXXXIII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="40034" url="https://en.wikipedia.org/wiki?curid=40034" title="1035">
1035

__NOTOC__
Year 1035 (MXXXV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="40036" url="https://en.wikipedia.org/wiki?curid=40036" title="1037">
1037

__NOTOC__
Year 1037 (MXXXVII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="40037" url="https://en.wikipedia.org/wiki?curid=40037" title="1038">
1038

__NOTOC__
Year 1038 (MXXXVIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="40038" url="https://en.wikipedia.org/wiki?curid=40038" title="MBE (disambiguation)">
MBE (disambiguation)

MBE commonly refers to Member of the Most Excellent Order of the British Empire, a grade within the British order of chivalry.
MBE may also refer to: 

</doc>
<doc id="40039" url="https://en.wikipedia.org/wiki?curid=40039" title="1039">
1039

__NOTOC__
Year 1039 (MXXXIX) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="40040" url="https://en.wikipedia.org/wiki?curid=40040" title="1041">
1041

__NOTOC__
Year 1041 (MXLI) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="40041" url="https://en.wikipedia.org/wiki?curid=40041" title="1042">
1042

__NOTOC__
Year 1042 (MXLII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40042" url="https://en.wikipedia.org/wiki?curid=40042" title="1043">
1043

__NOTOC__
Year 1043 (MXLIII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40043" url="https://en.wikipedia.org/wiki?curid=40043" title="1044">
1044

__NOTOC__
Year 1044 (MXLIV) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40044" url="https://en.wikipedia.org/wiki?curid=40044" title="1046">
1046

__NOTOC__
Year 1046 (MXLVI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40045" url="https://en.wikipedia.org/wiki?curid=40045" title="1047">
1047

__NOTOC__
Year 1047 (MXLVII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40046" url="https://en.wikipedia.org/wiki?curid=40046" title="1048">
1048

__NOTOC__
Year 1048 (MXLVIII) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40047" url="https://en.wikipedia.org/wiki?curid=40047" title="1049">
1049

__NOTOC__
Year 1049 (MXLIX) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40048" url="https://en.wikipedia.org/wiki?curid=40048" title="Ross Powers">
Ross Powers

Ross Powers (born February 10, 1979), is an American world champion halfpipe snowboarder from South Londonderry, Vermont. Though he originally rode at Stratton Mountain, Vermont, his home mountain is now Okemo, VT. Ross helps with the design of the Superpipe and also helped design the RossCross Family Terrain Park. Ross also runs a snowboard camp through Okemo. He led the U.S. sweep in the 2002 Winter Olympics men's halfpipe competition, one day after his 23rd birthday. This is the first time the Americans have swept a Winter Olympic event since the men's figure skaters did in 1956. Powers, with a score of 46.1, dominated the competition.
During his final run, Powers dropped in and aired out with an 18 foot method grab (a world record at that time), and followed up with two McTwists, a cab 720 indy grab, a frontside 720 indy grab and a switch frontside air.
Powers is one of the most high profile figures on the halfpipe snowboard circuit. He regularly competes in such events as the US and European Opens of Snowboarding, the Vans Triple Crown (now known simply as the Vans Cup), and the X-Games. During the 2004/2005 season, Ross won the Mt. Bachelor Grand Prix event and went on to be the overall champion for the series.
In 2007 Powers, shifted gears and began (or returned to) racing in snowboard cross. He had his 1st world cup podium in that discipline in Feb. 2009 at Sunday River Maine, and again in Dec. 2009 in Telluride, CO.
In 2010 Powers narrowly missed earning a spot on the US Olympic Team, this time for snowboard cross. He finished the season with his SBX World Cup rank at 11th.
In April 2010 Powers was named Director of the snowboarding program at The Stratton Mountain School (SMS), in Vermont. Powers is a 1997 graduate of SMS. His current snowboard sponsor is RAMP Sports.
Philanthropy.
Powers is the Director of the Snowboarding program at the Stratton Mountain School and currently (2010–present) resides in Stratton, Vermont, with his wife Marisa and daughters, Victoria and Meredith.
In 2001 Powers founded the non-profit "Ross Powers Foundation" a philanthropic organization dedicated to providing financial aide to promising athletes from all economic backgrounds. In 2010 the Foundation provided unprecedented assistance to a number of up and coming snowboarders.
In 2010 The Ross Powers Foundation teamed up with Olympic Gold Medalist Michael Phelps and formed the "Level Field Fund", a non profit organization with the mission statement:"The Level Field Fund strives to bridge gaps in funding for uniquely talented athletes, following the belief that opportunities to pursue excellence in sport should not be limited by an athlete's financial situation."

</doc>
<doc id="40049" url="https://en.wikipedia.org/wiki?curid=40049" title="1051">
1051

__NOTOC__
Year 1051 (MLI) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40050" url="https://en.wikipedia.org/wiki?curid=40050" title="1052">
1052

__NOTOC__
Year 1052 (MLII) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="40052" url="https://en.wikipedia.org/wiki?curid=40052" title="1056">
1056

__NOTOC__
Year 1056 (MLVI) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40054" url="https://en.wikipedia.org/wiki?curid=40054" title="1059">
1059

__NOTOC__
Year 1059 (MLIX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40055" url="https://en.wikipedia.org/wiki?curid=40055" title="Nordic combined">
Nordic combined

The Nordic combined is a winter sport in which athletes compete in cross-country skiing and ski jumping. Nordic combined at the Winter Olympics and the FIS Nordic Combined World Cup are ongoing. There is no women's competition sanctioned by the International Ski Federation.
History.
The first major competition was held in 1892 in Oslo at the first Holmenkollen ski jump. King Olav V of Norway was an able jumper and competed in the Holmenkollen Ski Festival in the 1920s. It was in the 1924 Winter Olympics, and has been on the programme ever since. Until the 1950s, the cross-country race was held first, followed by the ski jumping. This was reversed as the difference in the cross-country race tended to be too big to overcome in ski jumping. The sport has been dominated by the Norwegians, supported by the Finns. It was not until 1960 that the Nordic grip on this discipline was broken when West German Georg Thoma won the gold medal at the 1960 Winter Olympics.
Competition.
Formats and variations currently used in the World Cup are:
Included in the rules but currently not used in World Cup:
Events in the Olympics are: the sprint K120 individual, ski jumping K90 (70m), and Team/4x5km.
Nordic Skiing Triple Crown Winners.
Below is a list of Nordic skiers that have won at the Winter Olympics, FIS Nordic World Ski Championships, and Holmenkollen events. Bold years indicate when a skier achieved all the three wins in the same year.
Men's 18 km.
Length shortened to 15 km in 1950
Men's 15 km.
Holmenkollen ran 1954-85 and 1994
Women's 10 km.
Holmenkollen ran 1954-86
Women's 5 km.
Olympic: 1964-98, FIS: 1963-99, Holmenkollen: 1966-91

</doc>
<doc id="40056" url="https://en.wikipedia.org/wiki?curid=40056" title="Ski jumping">
Ski jumping

Ski jumping is a form of Nordic skiing in which athletes descend a specially constructed takeoff ramp (known as the "inrun"), jump from the end of it (the "table") with as much power as they can generate, and "fly" as far as possible down a steeply sloped hill. Points are awarded for distance and style by five judges, with competition sanctioned by the International Ski Federation (FIS). To enable the athletes (who are known as "ski jumpers") to effectively glide such long distances and land safely, the skis they use are considerably wider and longer than their cross-country and alpine skiing counterparts. Ski jumping is predominantly a winter sport and has been part of the Winter Olympic Games since its inception in 1924, but it can also be performed in the summer on artificial surfaces made from plastic. Along with cross-country skiing, ski jumping is one of two sports which form the Nordic combined discipline.
History.
The recorded origins of ski jumping can be traced directly to November 1809, in which Danish-Norwegian lieutenant Olaf Rye launched himself 9.5 metres in the air as a show of courage to his fellow soldiers at Eidsberg church in Eidsberg, Norway. By 1862, ski jumpers were facing much larger jumps and traveling longer. The very first recorded public competition was held at Trysil, Norway, on 22 January 1862. At this first competition, judges already awarded points for style ("elegance and smoothness"), participants had to complete three jumps without falling and rules were agreed upon in advance. It is clear from the news report published in "Morgenbladet" that the ski jumping in Trysild was entertainment, but also a national, competitive sports event. The first known female ski jumper participated at the Trysil competition in 1863. Norway's Sondre Norheim jumped 30 meters without the benefit of poles. In 1866, the first skiing event held in Christiania near Old Aker Church was a combined cross-country, slalom and jumping competition, and attracted an audience of some 2,000 people. Sondre Norheim won his first competition in Christiania in 1868. The first widely known ski jumping competition was the Husebyrennene, held in Oslo in 1879, with Olaf Haugann of Norway setting the first world record for the longest ski jump at 20 meters. Explorer Fridtjof Nansen was a skilled skier and was number 7 in the 1881 competition at Huseby. Until 1884–1886 jumping and cross-country was a single integrated competition: In 1886 at Huseby cross-country and jumping were held on separate days, and final results were calculated from the combined achievements (similar to present nordic combined). The annual event was moved to Holmenkollen from 1892, and Holmenkollen has remained the pinnacle of ski jumping venues. To distinguish ski jumping competition only from Nordic combined, it is still referred to as "spesielt hopprenn" in Norwegian (ski jumping only). Until 1933 there were no "jumping only" national championships in Norway, only Nordic combined. International championships in ski jumping only were introduced in the 1920s.
In 1929, Norwegian instructors arrived in Sapporo to train the Japanese in ski jumping.
The Large Hill competition was included on the Olympic programme for the 1964 Olympic Games in Innsbruck.
Competition.
The FIS Ski Jumping World Cup is the highest level of the sport, and is contested on three types of hills:
Amateur and junior level competitions are held on hills which are smaller than 80 m. The second level of senior competition, below the World Cup, is the FIS Ski Jumping Continental Cup. In addition to individual competitions on all three hill types, a lesser number of team competitions take place as part of the World Cup. In team events, four ski jumpers are chosen to represent their country. One member of each team participates in an opening round, until all teams have completed their jumps. The lowest-scoring teams (usually two or three) are then eliminated, after which a second round decides the winning team and subsequent order based on accumulated points.
Individual ski jumping at the Winter Olympics consists of a "training" jump and two scored jumps.
Summer ski jumping.
Ski jumping can also be performed in the summer on an inrun where the tracks are made from porcelain and the grass on the slope is coated with plastic, combined with water. However, not all hills are equipped with these facilities. There are also many competitions during the summer, including the FIS Ski Jumping Grand Prix.
Women's ski jumping.
Women competed at the 2009 Nordic World Ski Championships followed by a women's team event at the 2011 world championships.
In 2006 the FIS proposed that women could compete at the 2010 Winter Olympics, but this was rejected by the IOC because of the low number of athletes and participating countries at the time.
A group of fifteen competitive female ski jumpers later filed a suit against the Vancouver Organizing Committee for the 2010 Olympic and Paralympic Winter Games on the grounds that it violated the Canadian Charter of Rights and Freedoms since men were competing. The suit failed, with the judge ruling that the situation was not governed by the charter. Virginia Madsen told the story in the film called "Fighting Gravity" (2009).
The 2011–12 World Cup season was the very first in which women competed at World Cup level; previously, women had only competed in Continental Cup seasons. The inaugural women's World Cup champion was Sarah Hendrickson. A further milestone was reached when women's ski jumping was included as part of the 2014 Winter Olympics.
Because they are lighter than men, female ski jumpers need a longer inrun and reach a higher landing speed. Injuries have affected a number of the sport's female athletes including Lisa Demetz, Daniela Iraschko, Anja Tepeš, 
Caroline Espiau, Alexandra Pretorius, Sarah Hendrickson, Jacqueline Seifriedsberger, Svenja Würth, Ema Klinec, Ramona Straub, Anja Tepeš, Daniela Iraschko-Stolz, Bigna Windmüller, Lindsey Van, Carina Vogt, Manuela Malsiner, and Elena Runggaldier.
Mixed team ski jumping.
A number of events took place in 2012:
Tandem.
On 18 February 2016 Slovenian ski jumpers Rok Urbanc and Jaka Rus made a historic first ever 35 metres (115 ft) world record tandem ski jump both on one pair of longer skis at HS45 hill in Planica, Slovenia.
Scoring and rules.
Ski jumpers below the minimum safe body mass index are penalized with a shorter maximum ski length, reducing the aerodynamic lift they can achieve. These rules have been credited with stopping the most severe cases of underweight athletes, but some competitors still lose weight to maximize the distance they can jump.
The winner is decided on a scoring system based on distance, style, inrun length and wind conditions.
Aerodynamics has become a factor of increasing importance in modern ski jumping, with recent rules addressing the regulation of ski jumping suits. This follows a period when loopholes in the rules seemed to favour skinny jumpers in stiff, air foil-like suits.
Each hill has a target called the "calculation point" (or "K point" or "critical point") which is a par distance to aim for. It is also the place where many jumpers land, in the middle of the landing area. This point is marked by the "K line" on the landing strip. For K-90 and K-120 competitions, the K line is at and respectively. Skiers are awarded 60 points if they land on the K Line. Skiers earn extra points for flying beyond the K Line, or lose points for every meter(~3 ft) they land short of the mark. The typical meter value is 2 points in small hills, 1.8 points in large hills and 1.2 points in ski-flying hills. Thus, it is possible for a jumper to get a negative score if the jump is way short of the K line with poor style marks (typically a fall hill where the slope begins to flatten as measured from the take off.
In addition, five judges are based in a tower to the side of the expected landing point. They can award up to 20 points each for style based on keeping the skis steady during flight, balance, good body position, and landing. The highest and lowest style scores are disregarded, with the remaining three scores added to the distance score. Thus, a perfectly scored K-120 jump – with at least four of the judges awarding 20 points each – and the jumper landing on the K-point, is awarded a total of 120 points.
In January 2010, a new scoring factor was introduced to compensate for variable outdoor conditions. Aerodynamics and take-off speed are important variables that determine the value of a jump, and if weather conditions change during a competition, the conditions will not be equal for everyone, which is unfair. The jumper will now receive or lose points if the inrun (or "start gate") length is adjusted to provide optimal takeoff speed. An advanced calculation also determines plus/minus points for the actual wind conditions at the time of the jump. These points are added or withdrawn from the original scores from the jump itself.
In the individual event, the scores from each skier's two competition jumps are combined to determine the winner.
Technique.
The ski jump is divided into four parts: in-run, take-off (jump), flight and landing. In each part the athlete is required to pay attention to and practice a particular technique in order to maximize the outcome of ultimate length and style marks.
Using the V-style, popularised in late 1980s by Jan Boklöv from Sweden and Jiří Malec from Czechoslovakia, skiers are able to exceed the distance of the take-off hill by about 10% compared to the previous technique with parallel skis. Previous techniques first included the Kongsberger technique, the Däescher technique and the Windisch technique. Until the mid-1960s, the ski jumper came down the in-run of the hill with both arms pointing forwards. This changed when the former East German Ski jumper Jochen Danneberg introduced the new in-run technique of directing the arms backwards in a more aerodynamic position.
The landing requires the skiers to touch the ground in the Telemark landing style (). This involves the jumper landing with one foot in front of the other, mimicking the style of Telemark skiing. Failure to comply with this regulation leads to the deduction of style marks (points).
All-time records.
As of 9 January 2015
Highest attendance.
Single daily events with more than 50,000 people. List is not complete:
Perfect score jumps: 5 x 20.
Those who have managed to show a perfect jump, which means that all five judges attributed the maximum style score of 20 points for their jumps. So far only 7 jumpers are recorded to have achieved this:
Sven Hannawald and Wolfgang Loitzl were attributed four times "20" (plus another "19,5") style score points for their second jump, thus receiving nine times the maximum score of "20" points within one competition.
Notable ski jumpers.
Notable ski jumpers can be found in the following lists:

</doc>
<doc id="40057" url="https://en.wikipedia.org/wiki?curid=40057" title="Freestyle skiing">
Freestyle skiing

Freestyle skiing is a skiing discipline comprising aerials, moguls, cross, half-pipe and slopestyle as part of the winter olympics. It can consist of a skier performing aerial flips and spins, and can include skiers sliding rails and boxes on their skis. It is also commonly referred to as freeskiing, jibbing, as well as many other names around the world. 
History.
Aerial skiing was developed in about 1950 by Olympic gold medalist Stein Eriksen. The International Ski Federation (FIS) recognized freestyle as a sport in 1979 and brought in new regulations regarding certification of athletes and jump techniques in an effort to curb the dangerous elements of the competitions. The first FIS Freestyle Skiing World Cup was staged in 1980 and the first FIS Freestyle World Ski Championships took place in 1986 in Tignes, France. Freestyle skiing was a demonstration event at the 1988 Winter Olympics in Calgary. Mogul skiing was added as an official medal event at the 1992 Winter Olympics in Albertville, and the aerials event was added for the 1994 Winter Olympics in Lillehammer. Stein Eriksen was a silver medalist in slalom.
Forms of freestyle skiing.
Aerial skiing.
Aerialists ski off 2-4 meter jumps, that propel them up to 6 meters in the air (which can be up to 20 meters above the landing height, given the landing slope). Once in the air, aerialists perform multiple flips and twists before landing on a 34 to 39-degree inclined landing hill about 30 meters in length. The top male aerialists can currently perform triple back flips with up to four or five twists.
Aerial skiing is a judged sport, and competitors receive a score based on jump takeoff (20%), jump form (50%) and landing (30%). A degree of difficulty (DD) is then factored in for a total score. Skiers are judged on a cumulative score of two jumps. These scores do not generally carry over to the next round.
Aerialists train for their jumping maneuvers during the summer months by skiing on specially constructed water ramps and landing in a large swimming pool. An example of this is the Utah Olympic Park training facility. A water ramp consists of a wooden ramp covered with a special plastic mat that when lubricated with sprinklers allows an athlete to ski down the ramp towards a jump. The skier then skis off the wooden jump and lands safely in a large swimming pool. A burst of air is sent up from the bottom of the pool just before landing to break up the surface tension of the water, thus softening the impact of the landing. Skiers sometimes reinforce the skis that they use for water-ramping with 6mm of fiberglass or cut holes in the front and back in order to soften the impact when landing properly on their skis.
Summer training also includes training on trampolines, diving boards, and other acrobatic or gymnastic training apparatus.
Mogul skiing.
Moguls are a series of bumps on a trail formed when skiers push the snow into mounds or piles as they execute short-radius turns.
Ski ballet.
Ski ballet (later renamed acroski) was a competitive discipline until the International Ski Federation ceased all formal competition of this event after 2000.
Ski cross.
Ski cross is based on the snowboarding boardercross. Despite it being a timed racing event, it is often considered part of freestyle skiing because it incorporates terrain features traditionally found in freestyle.
Half-pipe skiing.
Half-pipe skiing takes the well-known halfpipe to the next level. Competitors gradually ski to the end of the pipe by doing flips and tricks.
Equipment.
Twin-tip skis are used in events such as slopestyle and halfpipe. Mogul skis are used in moguls and sometimes in aerials. Specially designed racing skis are used in ski cross. Ski bindings took a major design change to include plate bindings mounted to the bottom of the skiers boot to allow for multi-directional release.

</doc>
<doc id="40058" url="https://en.wikipedia.org/wiki?curid=40058" title="Short track speed skating">
Short track speed skating

Short track speed skating is a form of competitive ice speed skating. In competitions, multiple skaters (typically between four and six) skate on an oval ice track with a circumference of 111.12 m. The rink itself is 60 m by 30 m, which is the same size as an international-sized ice hockey rink. Short track speed skating is the sister sport to long track speed skating.
History.
Short track speed skating originated in the speed skating events held with mass starts. This form of speed skating was mainly practiced in the United States and Canada, as opposed to the international form, where skaters skated in pairs. At the 1932 Winter Olympics, speed skating events were conducted in the mass start form. Competitions in North America were also held indoors, for example in Madison Square Garden, New York, and therefore on shorter tracks than usual for outdoor skating.
In 1967, the International Skating Union adopted short track speed skating, although it did not organize international competitions until 1976. World Championships have been held since 1981 (though events held in 1976-1980 under different names later received the status of World Championships). After several changes in the name of the competition (last time in 1989), the event is now held annually as the World Short Track Speed Skating Championships.
At the 1988 Winter Olympics, held in Calgary, Alberta, Canada, short track was a demonstration sport. It was upgraded to a full Olympic sport in 1992 and has been part of the Winter Olympics since. The programme was expanded from four events in 1992 to eight in 2002. The events are the same for both men and women: 500 m, 1000 m, 1500 m, 3000m, and the relay (5000 m (men)/3000 m (women)).
Rules.
There are several actions that will result in skaters being disqualified from a race, and having their time rendered invalid.
Classes.
In Canada, short track competitions are held either as all-points meets, where skaters are seeded based only on their times for a standard distance (usually the 500m), or an age class, where people are seeded by age and gender. All-points meets allow racing against skaters of all ages and genders, with the exception of the Masters age class (30+). All-points meets are usually held at the local level in only certain provinces. Age class meets are utilized at the provincial and national levels. Age classes are:
Ages are determined as of July 1 or June 30 prior to competition. At International and Olympic competitions, skaters are placed by gender only.
Notable skaters.
The following is the list of athletes who are Individual gold medalist at the Olympic Winter Games or Overall World Champion and who have won Olympic Winter Games or Overall World Championships at least three times.

</doc>
<doc id="40060" url="https://en.wikipedia.org/wiki?curid=40060" title="1197">
1197

__NOTOC__
Year 1197 (MCXCVII) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40061" url="https://en.wikipedia.org/wiki?curid=40061" title="1198">
1198

__NOTOC__
Year 1198 (MCXCVIII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40062" url="https://en.wikipedia.org/wiki?curid=40062" title="1199">
1199

__NOTOC__
Year 1199 (MCXCIX) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40063" url="https://en.wikipedia.org/wiki?curid=40063" title="1231">
1231

__NOTOC__
Year 1231 (MCCXXXI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40064" url="https://en.wikipedia.org/wiki?curid=40064" title="1230">
1230

__NOTOC__
Year 1230 (MCCXXX) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Arts.
</onlyinclude>

</doc>
<doc id="40065" url="https://en.wikipedia.org/wiki?curid=40065" title="1233">
1233

__NOTOC__
Year 1233 (MCCXXXIII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40066" url="https://en.wikipedia.org/wiki?curid=40066" title="1235">
1235

__NOTOC__
Year 1235 (MCCXXXV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40067" url="https://en.wikipedia.org/wiki?curid=40067" title="1236">
1236

__NOTOC__
Year 1236 (MCCXXXVI) was a leap year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Religion.
</onlyinclude>

</doc>
<doc id="40068" url="https://en.wikipedia.org/wiki?curid=40068" title="1237">
1237

__NOTOC__
Year 1237 (MCCXXXVII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40069" url="https://en.wikipedia.org/wiki?curid=40069" title="1239">
1239

__NOTOC__
Year 1239 (MCCXXXIX) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40071" url="https://en.wikipedia.org/wiki?curid=40071" title="1131">
1131

__NOTOC__
Year 1131 (MCXXXI) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40072" url="https://en.wikipedia.org/wiki?curid=40072" title="1132">
1132

__NOTOC__
Year 1132 (MCXXXII) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40073" url="https://en.wikipedia.org/wiki?curid=40073" title="1133">
1133

__NOTOC__
Year 1133 (MCXXXIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40074" url="https://en.wikipedia.org/wiki?curid=40074" title="1134">
1134

__NOTOC__
Year 1134 (MCXXXIV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40075" url="https://en.wikipedia.org/wiki?curid=40075" title="1136">
1136

__NOTOC__
Year 1136 (MCXXXVI) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40076" url="https://en.wikipedia.org/wiki?curid=40076" title="1137">
1137

__NOTOC__
Year 1137 (MCXXXVII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40077" url="https://en.wikipedia.org/wiki?curid=40077" title="1138">
1138

__NOTOC__
Year 1138 (MCXXXVIII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40078" url="https://en.wikipedia.org/wiki?curid=40078" title="1140">
1140

__NOTOC__
Year 1140 (MCXL) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40079" url="https://en.wikipedia.org/wiki?curid=40079" title="1145">
1145

__NOTOC__
Year 1145 (MCXLV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40080" url="https://en.wikipedia.org/wiki?curid=40080" title="1148">
1148

__NOTOC__
Year 1148 (MCXLVIII) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
Europe.
</onlyinclude>

</doc>
<doc id="40081" url="https://en.wikipedia.org/wiki?curid=40081" title="1149">
1149

__NOTOC__
Year 1149 (MCXLIX) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40082" url="https://en.wikipedia.org/wiki?curid=40082" title="1151">
1151

__NOTOC__
Year 1151 (MCLI) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40083" url="https://en.wikipedia.org/wiki?curid=40083" title="1150">
1150

__NOTOC__
Year 1150 (MCL) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="40084" url="https://en.wikipedia.org/wiki?curid=40084" title="1159">
1159

__NOTOC__
Year 1159 (MCLIX) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40085" url="https://en.wikipedia.org/wiki?curid=40085" title="1171">
1171

__NOTOC__
Year 1171 (MCLXXI) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40086" url="https://en.wikipedia.org/wiki?curid=40086" title="1174">
1174

__NOTOC__
Year 1174 (MCLXXIV) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Central America.
</onlyinclude>

</doc>
<doc id="40087" url="https://en.wikipedia.org/wiki?curid=40087" title="1175">
1175

__NOTOC__
Year 1175 (MCLXXV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40088" url="https://en.wikipedia.org/wiki?curid=40088" title="1177">
1177

__NOTOC__
Year 1177 (MCLXXVII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40089" url="https://en.wikipedia.org/wiki?curid=40089" title="1178">
1178

__NOTOC__
Year 1178 (MCLXXVIII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>

</doc>
<doc id="40091" url="https://en.wikipedia.org/wiki?curid=40091" title="1182">
1182

__NOTOC__
Year 1182 (MCLXXXII) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40092" url="https://en.wikipedia.org/wiki?curid=40092" title="1183">
1183

__NOTOC__1183
Year 1183 (MCLXXXIII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40093" url="https://en.wikipedia.org/wiki?curid=40093" title="1184">
1184

__NOTOC__
Year 1184 (MCLXXXIV) was a leap year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40094" url="https://en.wikipedia.org/wiki?curid=40094" title="1185">
1185

__NOTOC__
Year 1185 (MCLXXXV) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="40095" url="https://en.wikipedia.org/wiki?curid=40095" title="1186">
1186

__NOTOC__
Year 1186 (MCLXXXVI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
</onlyinclude>

</doc>
<doc id="40096" url="https://en.wikipedia.org/wiki?curid=40096" title="History of Bangladesh">
History of Bangladesh

Modern Bangladesh emerged as an independent nation in 1971 after breaking away and achieving independence from Pakistan in the Bangladesh liberation war. The country's borders coincide with the major portion of the ancient and historic region of Bengal in the eastern part of the Indian subcontinent, where civilization dates back over four millennia, to the Chalcolithic. The history of the region is closely intertwined with the history of Bengal and the history of India.
The area's early history featured a succession of Indian empires, internal squabbling, and a tussle between Hinduism and Buddhism for dominance. Islam became dominant gradually since the 13th century when Sunni missionaries arrived. Later, Muslim rulers reinforced the process of conversion by building masaajid (mosques), and madrassas.
The borders of modern Bangladesh were established with the partition of Bengal and India in August 1947, when the region became East Pakistan as a part of the newly formed State of Pakistan following the Radcliffe Line.
However, it was separated from West Pakistan by 1,600 km (994 mi) of Indian territory. Due to political exclusion, ethnic and linguistic discrimination, as well as economic neglect by the politically dominant western-wing, popular agitation and civil disobedience led to the war of independence in 1971. After independence, the new state endured famine, natural disasters and widespread poverty, as well as political turmoil and military coups. The restoration of democracy in 1991 has been followed by relative calm and economic progress.
Etymology of "Bengal".
The exact origin of the word "Bangla" or Bengal is unknown. According to Mahabharata, Purana, Harivamsha Vanga was one of the adopted sons of King Vali who founded the Vanga Kingdom. The earliest reference to "Vangala" ("Bôngal") has been traced in the Nesari plates (805 AD) of the south Indian ruler Rashtrakuta Govinda III, who invaded northern India in the 9th century, which speak of Dharmapala as the king of Vangala. The records of Rajendra Chola I of the Chola dynasty, who invaded Bengal in the 11th century, speak of Govindachandra as the ruler of Vangaladesa. Shams-ud-din Ilyas Shah took the title "Shah-e-Bangalah" and united the whole region under one government for the first time.
The Vanga Kingdom (also known as Banga) was located in the eastern part of the Indian Subcontinent, comprising part of West Bengal, India and present-day modern Bangladesh. Vanga and Pundra were two dominant tribes in Bangladesh in ancient time.
Ancient period.
Pre-historic Bengal.
Many of archeological excavations in Bangladesh revealed evidences of the Northern Black Polished Ware culture (abbreviated NBPW or NBP) of the Indian Subcontinent (c. 700–200 BC) which was an Iron Age culture developed beginning around 700 BC and peaked from c. 500–300 BC, coinciding with the emerging of 16 great states or mahajanapadas in Northern India, and the subsequent rise of the Mauryan Empire. The eastern part of ancient India, covering much of current days Bangladesh was part of one of such mahajanapadas, the ancient kingdom of Anga, which flourished in the 6th century BCE.
Linguistically, the oldest population of this land may have been speakers of Dravidian languages, such as the Kurux, or perhaps of Austroasiatic languages such as the Santals. Subsequently, people speaking languages from other language families, such as Tibeto-Burman, settled in Bengal. Indic Bengali represents the latest settlement.
While western Bangladesh, as part of Magadha, became part of the Indo-Aryan civilization by the 7th century BCE, the Nanda Dynasty was the first historical state to unify all of Bangladesh under Indo-Aryan rule. Later after the rise of Buddhism many missionaries settled in the land to spread the religion and established many monuments such as Mahasthangarh.
Overseas Colonization.
The Vanga Kingdom was a powerful seafaring nation of Ancient India. They had overseas trade relations with Java, Sumatra and Siam (modern day Thailand). According to Mahavamsa, the Vanga prince Vijaya Singha conquered Lanka (modern day Sri Lanka) in 544 BC and gave the name "Sinhala" to the country. Bengali people migrated to the Maritime Southeast Asia and Siam (in modern Thailand), establishing their own colonies there.
Gangaridai Empire.
Though north and west Bengal were part of the empire southern Bengal thrived and became powerful with her overseas trades. In 326 BCE, with the invasion of Alexander the Great the region again came to prominence. The Greek and Latin historians suggested that Alexander the Great withdrew from India anticipating the valiant counterattack of the mighty Gangaridai empire that was located in the Bengal region. Alexander, after the meeting with his officer, Coenus, was convinced that it was better to return. Diodorus Siculus mentions Gangaridai to be the most powerful empire in India whose king possessed an army of 20,000 horses, 200,000 infantry, 2,000 chariots and 4,000 elephants trained and equipped for war. The allied forces of Gangaridai Empire and Nanda Empire (Prasii) were preparing a massive counterattack against the forces of Alexander on the banks of Ganges. Gangaridai, according to the Greek accounts, kept on flourishing at least up to the 1st century AD.
Early Middle Ages.
The pre-Gupta period of Bengal is shrouded with obscurity. Before the conquest of Samudragupta Bengal was divided into two kingdoms: Pushkarana and Samatata. Chandragupta II had defeated a confederacy of Vanga kings resulting in Bengal becoming part of the Gupta Empire.
The Pala dynasty.
Pala dynasty were the first independent Buddhist dynasty of Bengal. The name "Pala" ( "pal") means "protector" and was used as an ending to the names of all Pala monarchs. The Palas were followers of the Mahayana and Tantric schools of Buddhism. Gopala was the first ruler from the dynasty. He came to power in 750 in Gaur, after being elected by a group of feudal chiefs. He reigned from 750 to 770 and consolidated his position by extending his control over all of Bengal. The Buddhist dynasty lasted for four centuries (750-1120 AD) and ushered in a period of stability and prosperity in Bengal. They created many temples and works of art as well as supported the Universities of Nalanda and Vikramashila. Somapura Mahavihara built by Dharmapala is the greatest Buddhist Vihara in the Indian Subcontinent.
The empire reached its peak under Dharmapala and Devapala. Dharmapala extended the empire into the northern parts of the Indian Subcontinent. This triggered once more for the control of the subcontinent. Devapala, successor of Dharmapala, expanded the empire considerably. The Pala inscriptions credit him with extensive conquests in hyperbolic language. The Badal pillar inscription of his successor Narayana Pala states that he became the suzerain monarch or Chakravarti of the whole tract of Northern India bounded by the Vindhyas and the Himalayas. It also states that his empire extended up to the two oceans (presumably the Arabian Sea and the Bay of Bengal). It also claims that Devpala defeated Utkala (present-day Orissa), the Hunas, the Dravidas, the Kamarupa (present-day Assam), the Kambojas and the Gurjaras. These claims about Devapala's victories are exaggerated, but cannot be dismissed entirely: there is no reason to doubt his conquest of Utkala and Kamarupa. Besides, the neighbouring kingdoms of Rashtrakutas and the Gurjara-Pratiharas were weak at the time, which might have helped him extend his empire. Devapala is also believed to have led an army up to the Indus river in Punjab.
The death of Devapala ended the period of ascendancy of the Pala Empire and several independent dynasties and kingdoms emerged during this time. However, Mahipala − I rejuvenated the reign of the Palas. He recovered control over all of Bengal and expanded the empire. He survived the invasions of Rajendra Chola of the Chola dynasty and the Western Chalukya Empire from southern India. After Mahipala − I the Pala dynasty again saw its decline until Ramapala, the last great ruler of the dynasty, managed to retrieve the position of the dynasty to some extent. He crushed the Varendra Rebellion and extended his empire farther to Kamarupa, Odisha and northern India.
The Pala Empire can be considered as the golden era of Bengal. Never had the Bengali people reached such height of power and glory to that extent. Palas were responsible for the introduction of Mahayana Buddhism in Tibet, Bhutan and Myanmar. The Pala had extensive trade as well as influence in south-east Asia. This can be seen in the sculptures and architectural style of the Sailendra Empire (present-day Malaya, Java, Sumatra).
During the later part of Pala rule, Rajendra Chola I of the Chola Empire frequently invaded Bengal from 1021 to 1023 CE in order to get Ganges water and in the process, succeeded to humble the rulers, acquiring considerable booty. The rulers of Bengal who were defeated by Rajendra Chola were Dharmapal, Ranasur and Govindachandra of the Candra Dynasty who might have been feudatories under Mahipala of the Pala Dynasty. The invasion of the south Indian ruler Vikramaditya VI of the Western Chalukya Empire brought bodies of his countrymen from Karnataka into Bengal which explains the southern origin of the Sena Dynasty. The invasions of the Chola dynasty and Western Chalukya Empire led to the decline of the Pala Dynasty in Bengal and to the establishment of the Sena dynasty
Candra Dynasty.
The Candra dynasty were a family who ruled over the kingdom of Harikela in eastern Bengal (comprising the ancient lands of Harikela, Vanga and Samatata) for roughly a century and a half from the beginning of the 10th century CE. Their empire also encompassed Vanga and Samatata, with Srichandra expanding his domain to include parts of Kamarupa. Their empire was ruled from their capital, Vikrampur (modern Munshiganj) and was powerful enough to militarily withstand the Pala Empire to the north-west. The last ruler of the Candra Dynasty Govindachandra was defeated by the south Indian Emperor Rajendra Chola I of the Chola dynasty in the 11th century.
Sena dynasty.
The Palas were followed by the Sena dynasty who brought Bengal under one ruler during the 12th century. Vijay Sen the second ruler of this dynasty defeated the last Pala emperor Madanapala and established his reign. Ballal Sena introduced caste system in Bengal and made Nabadwip the capital. The fourth king of this dynasty Lakshman Sen expanded the empire beyond Bengal to Bihar. Lakshman fled to eastern Bengal fearing of the invading Muslims without facing them in battle. The Sena dynasty brought a period of revival in Hinduism in Bengal. A popular myth comprehended by some Bengali authors about Jayadeva, the famous Sanskrit poet of Odisha (then known as the Kalinga) and author of Gita Govinda, was one of the "Pancharatnas" (meaning 5 gems) in the court of Lakshman Sen (although this may be disputed by some).
Deva Kingdom.
The Deva Kingdom was a Hindu dynasty of medieval Bengal that ruled over eastern Bengal after the collapse Sena Empire. The capital of this dynasty was Bikrampur in present-day Munshiganj District of Bangladesh. The inscriptional evidences show that his kingdom was extended up to the present-day Comilla-Noakhali-Chittagong region. A later ruler of the dynasty "Ariraja-Danuja-Madhava" Dasharathadeva extended his kingdom to cover much of East Bengal.
Late Middle Ages - Advent of Islam.
Islam made its first appearance in the Bengal region during the 7th century AD by Arab Muslim traders and Sufi missionaries, and the subsequent Muslim conquest of Bengal in the 12th century led to the rooting of Islam across the region. Beginning in 1202, a military commander from the Delhi Sultanate, Bakhtiar Khilji, overran Bihar and Bengal. He conquered Nabadwip from the old emperor Lakshman Sen in 1203. and intruded into much of Bengal as far east as Rangpur and Bogra ushering Muslim rule in this part of the world.
Under the Muslim rulers, Bengal entered a new era as cities were developed; palaces, forts, mosques, mausoleums and gardens sprang up; roads and bridges were constructed; and new trade routes brought prosperity and a new cultural life.
However, smaller Hindu states continued to exist in the Southern and the Eastern parts of Bengal till the 1450s such as the Deva dynasty. Some independent small Hindu states were also established in Bengal during the Mughal period like those of Maharaja Pratapaditya of Jessore and Raja Sitaram Ray of Burdwan. These kingdoms contributed a lot to the economic and cultural landscape of Bengal. Militarily, these served as bulwarks against Portuguese and Burmese attacks. Many of these kingdoms are recorded to have fallen during the late 1700s. While Koch Bihar Kingdom in the North, flourished during the period of 16th and the 17th centuries as well till the advent of the British.
Turkic rule.
In 1203 AD, the first Muslim ruler, Muhammad Bakhtiyar Khalji, a Turk, captured Nadia and established Muslim rule. The political influence of Islam began to spread in Bengal with the conquest of Nadia, the capital city of the Sen ruler Lakshmana, by him. Bakhtiyar captured Nadia in a unique way. Sensing the presence of a strong army of Lakshmana Sen on the main route to Nadia, Bakhtyar proceeded instead through the jungle of Jharkhand. He divided his army into several groups, and he himself led a group of 17 horsemen and advanced towards Nadia in the guise of horse-traders. In this manner, Bakhtiyar had no problem in entering through the gates of the royal palace. Shortly afterwards, Bakhityar's main army also joined him and within a short while Nadia was captured. After capturing Nadia, Bakhtiyar advanced towards Gauda (Lakhnuti), another capital of the Sena kingdom, conquered it and made it his capital in 1205. Next year, Bakhtiyar set out for an expedition to capture Tibet, but this attempt failed and he had to return to Bengal with poor health and a reduced army. Shortly afterwards, he was killed by one of his commanders, Ali Mardan Khalji.
Defeated Lakshman Sen and his two sons moved to a place then called Vikramapur (present-day Munshiganj District in Bangladesh), where their diminished dominion lasted until the late 13th century.
Khiljis.
The period after Bakhtiar Khilji's death in 1207 devolved into infighting among the Khiljis - representative of a pattern of succession struggles and intra-empire intrigues during later Turkic regimes. Ghiyasuddin Iwaz Khalji prevailed and extended the Sultan's domain south to Jessore and made the eastern Bang province a tributary. The capital was made at Lakhnauti on the Ganges near the older Bengal capital of Gaur. He managed to make Kamarupa and Trihut pay tribute to him. But he was later defeated by Shams-ud-Din Iltutmish.
Mamluk rule.
The weak successors of Iltutmish encouraged the local governors to declare independence. Bengal was sufficiently remote from Delhi that its governors would declare independence on occasion, styling themselves as Sultans of Bengal. It was during this time that Bengal earned the name "Bulgakpur" (land of the rebels). Tughral Togun Khan added Oudh and Bihar to Bengal. Mughisuddin Yuzbak also conquered Bihar and Oudh from Delhi but was killed during an unsuccessful expedition in Assam. Two Turkic attempts to push east of the broad Jamuna and Brahmaputra rivers were repulsed, but a third led by Mughisuddin Tughral conquered the Sonargaon area south of Dhaka to Faridpur, bringing the Sen Kingdom officially to an end by 1277. Mughisuddin Tughral repulsed two massive attacks of the sultanate of Delhi before finally being defeated and killed by Ghiyas ud din Balban.
Mahmud Shahi dynasty.
Mahmud Shahi dynasty started when Nasiruddin Bughra Khan declared independence in Bengal. Thus, Bengal regained her independence back. Nasiruddin Bughra Khan and his successors ruled Bengal for 23 years finally being incorporated into Delhi Sultanate by Ghyiasuddin Tughlaq.
Ilyas Shahi dynasty.
Shamsuddin Iliyas Shah founded an independent dynasty that lasted from 1342 to 1487. The dynasty successfully repulsed attempts by Delhi to conquer them. They continued to reel in the territory of modern-day Bengal, reaching to Khulna in the south and Sylhet in the east. The sultans advanced civic institutions and became more responsive and "native" in their outlook and cut loose from Delhi. Considerable architectural projects were completed including the massive Adina Mosque and the Darasbari Mosque which still stands in Bangladesh near the border. The Sultans of Bengal were patrons of Bengali literature and began a process in which Bengali culture and identity would flourish. During the rule of this dynasty, Bengal, for the first time, achieved its identity. Indeed, Ilyas Shah named this province as 'Bangalah' and united different parts into a single, unified territory. The Ilyas Shahi Dynasty was interrupted by an uprising by the Hindus under Raja Ganesha. However, the Ilyas Shahi dynasty was restored by Nasiruddin Mahmud Shah. Famous globe-trotter, Ibn Battuta arrived Bengal this reign. In his account of Bengal in his Rihla, he depicts a land full of abundance. Bengal was a progressive state with commercial links to China, Java, Ceylon. Merchant ships were available from various destinations.
Ganesha dynasty.
The Ganesha dynasty began with Raja Ganesha in 1414. After Raja Ganesha seized control over Bengal, he faced an imminent threat of invasion. Ganesha appealed to a powerful Muslim holy man named Qutb al Alam, to stop the threat. The saint agreed on the condition that Raja Ganesha's son Jadu would convert to Islam and rule in his place. Raja Ganesha agreed and Jadu started ruling Bengal as "Jalaluddin Muhammad Shah" in 1415 AD. Qutb al Alam died in 1416 AD and Raja Ganesha was emboldened to depose his son and accede to the throne himself as "Danujamarddana Deva". Jalaluddin was reconverted to Hinduism by the "Golden Cow" ritual. After the death of his father he once again converted to Islam and started ruling his second phase. Jalaluddin's son, Shamsuddin Ahmad Shah ruled for only 3 years due to chaos and anarchy. The dynasty is known for their liberal policy as well as justice and charity.
Hussain Shahi dynasty.
The Habshi rule gave way to the Hussain Shahi dynasty that ruled from 1494 to 1538. Alauddin Hussain Shah, considered as the greatest of all the sultans of Bengal for bringing cultural renaissance during his reign. He extended the sultanate all the way to the port of Chittagong, which witnessed the arrival of the first Portuguese merchants. Nasiruddin Nasrat Shah gave refuge to the Afghan lords during the invasion of Babur though he remained neutral. However, Nusrat Shah made a treaty with Babur and saved Bengal from a Mughal invasion. The last Sultan of the dynasty, who continued to rule from Gaur, had to contend with rising Afghan activity on his northwestern border. Eventually, the Afghans broke through and sacked the capital in 1538 where they remained for several decades until the arrival of the Mughals.
Pashtun rule.
Suri dynasty.
Sher Shah Suri established the Sur dynasty in Bengal. After the battle of Chausa he declared himself independent Sultan of Bengal and Bihar. Sher Shah was the only Muslim Sultan of Bengal to establish an empire in northern India. The Delhi Sultanate Islam Shah appointed Muhammad Khan Sur as the governor of Bengal. After the death of Islam Shah, Muhammad Khan Sur became independent. Muhammad Khan Sur was followed by Ghyiasuddin Bahadur Shah and Ghyiasuddin Jalal Shah. The Pashtun rule in Bengal remained for 44 years. Their most impressive achievement was Sher Shah's construction of the Grand Trunk Road connecting Sonargaon, Delhi and Kabul.
Karrani dynasty.
The Sur dynasty was followed by the Karrani dynasty. Sulaiman Khan Karrani annexed Odisha to the Muslim sultanate permanently. Daoud Shah Karrani declared independence from Akbar which led to four years of bloody war between the Mughals and the Pashtuns. The Mughal onslaught against the Pashtun Sultan ended with the battle of Rajmahal in 1576, led by Khan Jahan. However, the Pashtun and the local landlords (Baro Bhuyans) led by Isa Khan resisted the Mughal invasion.
Sonargaon Sultanate.
Fakhruddin Mubarak Shah ruled an independent kingdom in areas that lie within modern-day eastern and southeastern Bangladesh from 1338 to 1349 AD. He was the first Muslim ruler to conquest Chittagong, the principal port of Bengal region in 1340 AD. Fakhruddin's capital was Sonargaon which emerged as the principal city of the region as the capital of an independent sultanate during his reign. Ibn Batuta, the famous Moroccan explorer, after visiting his capital in 1346, described Shah as "a distinguished sovereign who loved strangers, particularly the fakirs and Sufis."
Mughal period.
Bengal came into the domain of Mughal Empire during the reign of Akbar after the Battle of Tukaroi which was fought in 1575 near the village of Tukaroi now in Balasore District, West Bengal between the Mughals and the Karrani Sultanate of Bengal and Bihar.
At that time Dhaka became the capital of the Mughal province of Bengal. But due to its geographical remoteness it was a bit difficult to govern the region. Especially the section east of the Brahmaputra river remained outside the mainstream Mughal influence. The Bengali ethnic and linguistic identity further crystallized during this period, since the whole of Bengal was united under an able and long-lasting administration. Furthermore, its inhabitants were given sufficient autonomy to cultivate their own customs and literature.
In 1612, during Emperor Jahangir's reign, the defeat of Sylhet completed the Mughal conquest of Bengal except for Chittagong. At this time Dhaka rose in prominence by becoming the provincial capital of Bengal. Chittagong was later annexed in order to stifle Arakanese raids from the east. A well-known Dhaka landmark, Lalbagh Fort, was built during Aurangzeb's sovereignty.
Islam Khan.
Islam Khan was appointed the Subahdar of Bengal in 1608 by Mughal emperor Jahangir. He ruled Bengal from his capital Dhaka which he renamed as Jahangir Nagar.
His major task was to subdue the rebellious Rajas, Bara-Bhuiyans, Zamindars and Afghan chiefs. He fought with Musa Khan, the leader of Bara-Bhuiyans and by the end of 1611 he was subdued. Islam Khan also defeated Pratapaditya of Jessore, Ram Chandra of Bakla and Ananta Manikya of Bhulua. Then he annexed the kingdoms of Koch Bihar, Koch Hajo and Kachhar thus taking total control over entire Bengal excepting Chittagong.
Shaista Khan.
Shaista Khan was appointed the Subahdar (Governor) of Bengal upon the death of Mir Jumla II in 1663. He was the longest-serving governor of Bengal as he ably ruled the province from his administrative headquarters in Dhaka for almost 24 years from 1664 to 1688 AD. As governor, he encouraged trade with Europe, Southeast Asia and other parts of India. He consolidated his power by signing trade agreements with European powers. Despite his powerful position he remained loyal to emperor Aurangzeb.
Shaista Khan’s great fame in Bengal chiefly rests on his re-conquest of Chittagong. Though Chittagong came under the suzerainty of Bengal during Sultan Fakhruddin Mubarak Shah's reign in 1342 and the Bengal Sultanate until the 16th century, it subsequently went to the hands of Arakanese rulers in 1530. Considering the strategic importance of the Chittagong port, Shaista Khan gave the highest priority to recapture it and conquested Chittagong in January 1666 AD. The conquest brought a relief and peace much to the popular mass as pirates have caused a great distress to public life.
The Nawabs of Bengal.
Murshid Quli Khan ended the nominal Mughal rule in 1717 when he declared Bengal's independence from the Mughal empire. He shifted the capital to Murshidabad ushering in a series of independent Bengal Nawabs.
The founder of the Nasiri, Murshid Quli Jafar Khan, was born a poor Deccani Oriya Brahmin before being sold into slavery and bought by one Haji Shafi Isfahani, a Persian merchant from Isfahan who converted him to Islam. He entered the service of the Emperor Aurangzeb and rose through the ranks before becoming Nazim of Bengal in 1717, a post he held until his death in 1727. He in turn was succeeded by his grandson and son-in-law until his grandson was killed in battle and succeeded by Alivardi Khan of the Afshar Dynasty in 1740.
The Afshar, ruled from 1740 to 1757. They were succeeded by the third and final dynasty to rule Bengal, the Najafi, when Siraj Ud Daula, the last of the Afshar rulers was killed at the Battle of Plassey in 1757.
Nawab Alivardi Khan showed military skill during his wars with the Marathas when they first invaded Bengal. He repulsed the first Maratha invasion from Bengal. He crushed an uprising of the Afghans in Bihar and made the British pay 150,000 Tk for blocking Mughal and Armenian trade ships. But the Marathas of the Maratha Empire invaded Bengal again and during the fourth Maratha invasion the Nawab Alivardi Khan was defeated and compelled to come to terms with the Marathas of the Maratha Empire. He agreed to pay twelve lakhs of rupees annually as the chauth of Bengal, and ceded the province of Orissa to the Marathas.
Colonial era.
Europeans in Bengal.
Portuguese traders and missionaries were the first Europeans to reach Bengal in the latter part of the 15th century. They established themselves in Chittagong and Hoogly. In 1632, the Mughal Subahdar of Bengal Kasim Khan Mashadi expelled the Portuguese in the Battle of Hoogly.
Dutch, French, and British East India Companies and representatives from Denmark soon followed contact with Bengal.
During Aurangzeb's reign, the local Nawab sold three villages, including one then known as Calcutta, to the British. Calcutta was Britain's first foothold in Bengal and remained a focal point of their economic activity. The British gradually extended their commercial contacts and administrative control beyond Calcutta to the rest of Bengal. Job Charnock was one of the first dreamers of a British empire in Bengal. He waged war against the Mughal authority of Bengal which led to the Anglo-Mughal war for Bengal (1686–1690). Shaista Khan, the Nawab of Bengal, defeated the British in the battles of Hoogly as well as Baleshwar and expelled the British from Bengal. Captain William Heath with a naval fleet moved towards Chittagong but it was a failure and he had to retreat to Madras.
British rule.
The British East India Company gained official control of Bengal following the Battle of Plassey in 1757. This was the first conquest, in a series of engagements that ultimately lead to the expulsion of other European competitors. The defeat of the Mughals and the consolidation of the subcontinent under the rule of a corporation was a unique event in imperialistic history. Kolkata (Anglicized as "Calcutta") on the Hooghly became a major trading port for bamboo, tea, sugar cane, spices, cotton, muslin and jute produced in Dhaka, Rajshahi, Khulna, and Kushtia.
Scandals and the bloody rebellion known as the Sepoy Mutiny prompted the British government to intervene in the affairs of the East India Company. In 1858, authority in India was transferred from the Company to the crown, and the rebellion was brutally suppressed. Rule of India was organized under a Viceroy and continued a pattern of economic exploitation. Famine racked the subcontinent many times, including at least two major famines in Bengal. The British Raj was politically organized into seventeen provinces of which Bengal was one of the most significant.
Bengal Renaissance.
The Bengal Renaissance refers to a social reform movement during the 19th and early 20th centuries in Bengal during the period of British rule. The Bengal renaissance can be said to have started with Raja Ram Mohan Roy (1775–1833) and ended with Rabindranath Tagore (1861–1941). Bengal in the 19th century was a unique blend of religious and social reformers, scholars, literary giants, journalists, patriotic orators and scientists, all merging to form the image of a renaissance, and marked the transition from the 'medieval' to the 'modern'. Bangladeshi people are also very proud of their national poet Kazi Nazrul Islam. He is greatly remembered for his active voice against the oppression of the British rulers in the 20th century. He was imprisoned for writing his most famous poem of "Bidrohee".
Partition of Bengal, 1905.
The decision to effect the Partition of Bengal (Bengali: বঙ্গভঙ্গ) was announced in July 1905 by the Viceroy of India, Lord Curzon. The partition took place on 16 October 1905 and separated the largely Muslim eastern areas from the largely Hindu western areas. The former province of Bengal was divided into two new provinces "Bengal" (comprising western Bengal as well as the province of Bihar and Orissa) and Eastern Bengal and Assam with Dacca as the capital of the latter. Partition was promoted for administrative reasons: Bengal was geographically as large as France and had a significantly larger population. Curzon stated the eastern region was neglected and under-governed. By splitting the province, an improved administration could be established in the east, where subsequently, the population would benefit from new schools and employment opportunities. The Hindus of West Bengal who dominated Bengal's business and rural life complained that the division would make them a minority in a province that would incorporate the province of Bihar and Orissa. Indians were outraged at what they recognised as a "divide and rule" policy, where the colonisers turned the native population against itself in order to rule, even though Curzon stressed it would produce administrative efficiency. John barrier, had created the famously known invention, the barrier, In 1937. in an effort to both appease the Bengali sentiment and have easier administration. The partition was generally supported by the Muslims of East Bengal. Their support was motivated by both their poor economic conditions in East Bengal, and the perceived dominance of the Hindu businessmen and landlords in West Bengal over the governance of Bengal.
Due to political protests, the two parts of Bengal were reunited in 1911. A new partition which divided the province on linguistic, rather than religious grounds followed, with the Hindi, Oriya and Assamese areas separated to form separate administrative units: Bihar and Orissa Province was created to the west, and Assam Province to the east. The administrative capital of British India was moved from Calcutta to New Delhi as well.
Movement for self-rule and establishment of Pakistan.
As the independence movement throughout British-controlled India began in the late 19th century gained momentum during the 20th century, Bengali politicians played an active role in Mohandas Gandhi's Congress Party and Mohammad Ali Jinnah's Muslim League, exposing the opposing forces of ethnic and religious nationalism. By exploiting the latter, the British probably intended to distract the independence movement, for example by partitioning Bengal in 1905 along religious lines. Partition of Bengal (1905) divided Bengal Presidency into an overwhelmingly Hindu west (including present-day Bihar and Odisha) and a predominantly Muslim east (including Assam). Dhaka was made the capital of the new province of Eastern Bengal and Assam. But the split only lasted for seven years. The partition was abolished in 1911 due to severe opposition from Indian National Congress and a major section of the Bengali Hindus.
Creation of Pakistan.
The All-India Muslim League was founded on 30 December 1906, in the aftermath of partition of Bengal, on the sidelines of the annual All India Muhammadan Educational Conference in Shahbagh, Dhaka. At first the Muslim League sought only to ensure minority Muslim rights in the future nation of independent India. However, in 1940 the Muslim League passed the Lahore Resolution which envisaged one or more Muslim majority states in South Asia. The resolution unambiguously rejected the concept of a United India because of increasing inter-religious violence The resolution was moved in the general session by "Sher-e-Bangla" A. K. Fazlul Huq, the then Chief Minister of Bengal, and was adopted on 23 March 1940. Non-negotiable was the inclusion of the Muslim parts of Punjab and Bengal in these proposed states. The stakes grew as a new Viceroy Lord Mountbatten of Burma was appointed expressly for the purpose of effecting a graceful British exit. Sectarian violence in Noakhali and Calcutta sparked a surge in support for the Muslim League, which won the majority seats in Bengal legislature in the 1946 election. This surge of support also emerged as a reaction against the British decision to reverse the 1905 Partition of Bengal, which the League regarded as a betrayal of the Bengali Muslims. At the last moment Huseyn Shaheed Suhrawardy and Sarat Chandra Bose came up with the idea of an independent and unified Bengal state, which was endorsed by Jinnah. This idea was vetoed by the Indian National Congress.
British India was partitioned and the independent states of India and Pakistan were created in 1947; the region of Bengal was divided along religious lines. The predominantly Muslim eastern part of Bengal became the East Bengal (later renamed East Pakistan) province of Pakistan and the predominantly Hindu western part became the Indian state of West Bengal. Most of the Sylhet
District of Assam also joined East Pakistan following a referendum .
Pakistan's history from 1947 to 1971 was marked by political instability and economic difficulties. In 1956 a constitution was at last adopted, making the country an "Islamic republic within the Commonwealth". The nascent democratic institutions foundered in the face of military intervention in 1958, and the government imposed martial law between 1958 and 1962, and again between 1969 and 1971.
Almost from the advent of independent Pakistan in 1947, frictions developed between East and West Pakistan, which were separated by more than 1,000 miles of Indian territory. East Pakistanis felt exploited by the West Pakistan-dominated central government. Linguistic, cultural, and ethnic differences also contributed to the estrangement of East from West Pakistan.
The Bengali Language Movement.
The Bengali Language Movement, also known as the Language Movement "Bhasha Andolon", was a political effort in Bangladesh (then known as East Pakistan), advocating the recognition of the Bengali language as an official language of Pakistan. Such recognition would allow Bengali to be used in government affairs.
Movement was led by Mufti Nadimul Quamar Ahmed.
When the state of Pakistan was formed in 1947, its two regions, East Pakistan (also called East Bengal) and West Pakistan, were split along cultural, geographical, and linguistic lines. on 23 february in 1948, the Government of Pakistan ordained Urdu as the sole national language, sparking extensive protests among the Bengali-speaking majority of East Pakistan. Facing rising sectarian tensions and mass discontent with the new law, the government outlawed public meetings and rallies. The students of the University of Dhaka and other political activists defied the law and organised a protest on 21 February 1952. The movement reached its climax when police killed student demonstrators on that day. The deaths provoked widespread civil unrest led by the Awami Muslim League, later renamed the Awami League. After years of conflict, the central government relented and granted official status to the Bengali language in 1956. On 17 November 1999, UNESCO declared 21 February International Mother Language Day for the whole world to celebrate, in tribute to the Language Movement and the ethno-linguistic rights of people around the world.
Politics: 1954–1970.
Great differences began developing between the two wings of Pakistan. While the west had a minority share of Pakistan's total population, it had the largest share of revenue allocation, industrial development, agricultural reforms and civil development projects. Pakistan's military and civil services were dominated by the Punjabis. Only one regiment in the Pakistani Army was Bengali. And many Bengali Pakistanis could not share the natural enthusiasm for the Kashmir issue, which they felt was leaving East Pakistan more vulnerable and threatened as a result.
In 1966, Sheikh Mujibur Rahman, the frontier leader of Awami League proclaimed a 6-point plan titled Our Charter of Survival at a national conference of opposition political parties at Lahore, in which he demanded self-government and considerable political, economic and defence autonomy for East Pakistan in a Pakistani federation with a weak central government. This led to the historic Six point movement.
Early 1968, Agartala Conspiracy Case was filed against Sheikh Mujib and 34 others, with the allegation that the accused were planning to liberate the East Pakistan; however, as the trial moved on, a mass uprising formed in protest against this accusation and in demand to free all the prisoners. Meanwhile, on February 15, 1969, one of the prisoners, Sergeant Zahurul Haq was shot dead at point blank range, which further enraged the public movement and eventually, the government had to withdraw the case on February 22. The mass uprising subsequently culminated into the historic Uprising of '69.
On March 25, 1969, General Ayub Khan handed the state power to General Yahya Khan; subsequently all sorts of political activities in the country were postponed by the new military President.
However, few of the students kept on their movement in a clandestine way; a new group called 'February 15 Bahini' was formed under the leadership of and Kazi Aref Ahmed, members of Swadhin Bangla Nucleus.
Later in 1969, Yahya Khan announced a fresh election date for October 5, 1970.
Independence movement.
After the Awami League won all the East Pakistan seats as well as majority of the Pakistan's National Assembly in the 1970-71 elections, West Pakistan opened talks with the East on constitutional questions about the division of power between the central government and the provinces, as well as the formation of a national government headed by the Awami League.
The talks proved unsuccessful, however, and on March 1, 1971, Pakistani President Yahya Khan indefinitely postponed the pending National Assembly session, precipitating massive civil disobedience in East Pakistan.
On March 2, 1971, a group of students, led by A S M Abdur Rob, student leader & VP of DUCSU (Dhaka University Central Students Union) raised the new (proposed) flag of Bangladesh under the direction of Swadhin Bangla Nucleus. They demanded Sheikh Mujibur Rahman to declare the independence of Bangladesh immediately but Mujib refused to the strong demand. Rather, he decided that he will declare his next steps on March 7 public meeting.
On March 3, 1971, student leader Shahjahan Siraj read the 'Sadhinotar Ishtehar' (Declaration of independence) at Paltan Maidan in front of Bangabandhu Sheikh Mujib along with student and public gathering under the direction of Swadhin Bangla Nucleus.
On March 7, there was a historical public gathering in Suhrawardy Udyan to hear updates on the ongoing movement from Bangabandhu Sheikh Mujib, the frontier leader of movement that time. Although he avoided the direct speech of independence as the talks were still underway, he influenced the mob to prepare for any imminent war. The speech is considered a key moment in the war of liberation, and is remembered for the phrase,
Formal Declaration of Independence.
After the military crackdown by the Pakistan army began during the early hours of March 26, 1971 Bangabandhu Sheikh Mujibur Rahman was arrested and the political leaders dispersed, mostly fleeing to neighbouring India where they organized a provisional government afterwards. Before being held up by the Pakistani Army Sheikh Mujibur Rahman gave a hand note of the Bangladeshi Declaration of Independence and it was circulated amongst people and transmitted by the then East Pakistan Rifles' wireless transmitter. The world press reports from late March 1971 also make clear that Bangladesh’s declaration of independence by Bangabandhu was widely reported throughout the world. Bengali Army officer Major Ziaur Rahman captured Kalurghat Radio Station in Chittagong and read the declaration of independence of Bangladesh on the evening hours of March 27, 1971.
"This is Swadhin Bangla Betar Kendra. I, Major Ziaur Rahman, at the direction of Bangobondhu Mujibur Rahman, hereby declare that Independent People's Republic of Bangladesh has been established. At his direction, I have taken the command as the temporary Head of the Republic. In the name of Sheikh Mujibur Rahman, I call upon all Bengalees to rise against the attack by the West Pakistani Army. We shall fight to the last to free our motherland. Victory is, by the Grace of Allah, ours. Joy Bangla."
The Provisional Government of the People's Republic of Bangladesh was formed on April 10 in Meherpur, (later renamed as Mujibnagar a place adjacent to the Indian border). Sheikh Mujibur Rahman was announced to be the head of the state. Tajuddin Ahmed became the prime minister of the government, Syed Nazrul Islam became the acting president and Khondaker Mostaq Ahmed the Foreign Minister. There the war plan was sketched with armed forces established named "Muktifoujo". Later it was named "Muktibahini" (freedom fighters). M. A. G. Osmani was assigned as the Chief of the force. The land sketched into 11 sectors under 11 sector commanders. Along with these sectors on the later part of the war Three special forces were formed namely Z Force, S Force and K Force. These three forces name were derived from the initial letter of the commandar's name. The training and most of the arms and ammunitions were arranged by the Meherpur government which were supported by India. As fighting grew between the Pakistan Army and the Bengali Mukti Bahini, an estimated ten million Bengalis, mainly Hindus, sought refuge in the Indian states of Assam, Tripura and West Bengal.
The crisis in East Pakistan produced new strains in Pakistan's troubled relations with India. The two nations had fought a war in 1965, mainly in the west, but the pressure of millions of refugees escaping into India in autumn of 1971 as well as Pakistani aggression reignited hostilities with Pakistan. Indian sympathies lay with East Pakistan, and on December 3, 1971, India intervened on the side of the Bangladeshis which led to a short, but violent, two-week war known as the Indo-Pakistani War of 1971.
Pakistani capitulation and aftermath.
On 16 December 1971, Lt. Gen A. A. K. Niazi, CO of Pakistan Army forces located in East Pakistan signed the Instrument of Surrender and the nation of "Bangla Desh" ("Country of Bengal") was finally established the following day. At the time of surrender only a few countries had provided diplomatic recognition to the new nation. Over 90,000 Pakistani troops surrendered to the Indian forces making it the largest surrender since World War II.
The new country changed its name to Bangladesh on January 11, 1972 and became a parliamentary democracy under a constitution. Shortly thereafter on March 19 Bangladesh signed a friendship treaty with India. Bangladesh sought admission in the UN with most voting in its favour, but China vetoed this as Pakistan was its key ally. The United States, also a key ally of Pakistan, was one of the last nations to accord Bangladesh recognition. To ensure a smooth transition, in 1972 the Simla Agreement was signed between India and Pakistan. The treaty ensured that Pakistan recognised the independence of Bangladesh in exchange for the return of the Pakistani PoWs. India treated all the PoWs in strict accordance with the Geneva Convention, rule 1925. It released more than 93,000 Pakistani PoWs in five months.
Furthermore, as a gesture of goodwill, nearly 200 soldiers who were sought for war crimes by Bengalis were also pardoned by India. The accord also gave back more than of land that Indian troops had seized in West Pakistan during the war, though India retained a few strategic areas; most notably Kargil (which would in turn again be the focal point for a war between the two nations in 1999).
People's Republic of Bangladesh.
Constitution.
After Bangladesh achieved recognition from major countries, Sheikh Mujibur Rahman briefly assumed the provisional presidency. He charged the provisional parliament to write a new constitution. The constitution proclaims Bangladesh as a secular democratic republic, declares the fundamental rights and freedoms of Bangladeshi citizens, spells out the fundamental principles of state policy, and establishes the structure and functions of the executive, legislative and judicial branches of the republic. Passed by the Constituent Assembly of Bangladesh on November 4, 1972, it came into effect from December 16, 1972, on the first anniversary of Bangladesh's victory over Pakistan in the Liberation War. The constitution proclaims nationalism, democracy, socialism and secularity as the national ideals of the Bangladeshi republic. When adopted in 1972, it was one of the most liberal constitutions of the time.
Sheikh Mujib Administration (1971–1975).
Sheikh Mujibur Rahman came to office with immense personal popularity but had difficulty transforming this popular support into the political strength needed to function as head of government. The new constitution, which came into force on 16 December 1972, created a strong executive prime minister, a largely ceremonial presidency, an independent judiciary, and a unicameral legislature on a modified Westminster model.
The 1972 constitution adopted as state policy the Awami League's (AL) four basic principles of nationalism, secularism, socialism, and democracy.
The first parliamentary elections held under the 1972 constitution were on 7 March 1973, with the Awami League winning a massive majority. No other political party in Bangladesh's early years was able to duplicate or challenge the League's broad-based appeal, membership, or organizational strength. Relying heavily on experienced civil servants and members of the Awami League, the new Bangladesh government focused on relief, rehabilitation, and reconstruction of the economy and society. Economic conditions remained precarious, however.
In 1972, Sheikh Mujibur Rahman introduced the Collaborators Act 1972 with a view to trying war criminals which was followed by a general amnesty in 1973 amid some conditions like no criminals with specific charges of arson, murder and rape will remain under the purview of the act.
In December 1974, Mujib decided that continuing economic deterioration and mounting civil disorder required strong measures. After proclaiming a state of emergency, Mujib used his parliamentary majority to win a constitutional amendment limiting the powers of the legislative and judicial branches, establishing an executive presidency, and instituting a one-party system, the Bangladesh Krishak Sramik Awami League (BAKSAL), which all members of Parliament (and senior civil and military officials) were obliged to join. To eshtablish one-party system all the political parties, including Awami League, were banned.
Despite some improvement in the economic situation during the first half of 1975, implementation of promised political reforms was slow, and criticism of government policies became increasingly centered on Mujib. On 15 August 1975, Mujib, and most of his family, were assassinated by mid-level army officers. His daughters, Sheikh Hasina and Sheikh Rehana, were out of the country. A new government, headed by former Mujib associate Khondaker Mostaq Ahmad, was formed.
Ziaur Rahman Zia (1977-1981).
Two Army uprisings on 3 November and 7 November 1975 led to a reorganised structure of power in Bangladesh. A state of emergency was declared to restore order and calm. Mushtaq resigned, and the country was placed under temporary martial law, with three service chiefs serving as deputies to the new president, Justice Abu Sayem, who also became the Chief Martial Law Administrator. Lieutenant General Ziaur Rahman took over the presidency in 1977 when Justice Sayem resigned. President Zia reinstated multi-party politics, introduced free markets, and founded the Bangladesh Nationalist Party (BNP). At that situation of multi-party politics, former Awami League was reorganized. Zia's rule ended when he was assassinated by elements of the military in 1981.
Ershad Era (1982-1990).
Bangladesh's next major ruler was Lieutenant General Hossain Mohammad Ershad, who gained power in a coup on 24 March 1982, and ruled until 6 December 1990, when he was forced to resign after a revolt of all major political parties and the public, along with pressure from Western donors (which was a major shift in international policy after the fall of the Soviet Union).
Democratic era (1991–2014).
A constitutional referendum was held in Bangladesh on 15 September 1991. Voters were asked "Should or not the President assent to the Constitution (Twelfth Amendment) Bill, 1991 of the People's Republic of Bangladesh?" The amendments would lead to the reintroduction of parliamentary government, with the President becoming the constitutional head of state, but the Prime Minister the executive head. It also abolished the position of Vice-President and would see the President elected by Parliament. Since then, Bangladesh has reverted to a parliamentary democracy. Zia's widow, Khaleda Zia, led the Bangladesh Nationalist Party to parliamentary victory at the general election in 1991 and became the first female Prime Minister in Bangladeshi history. However, the Awami League, headed by Sheikh Hasina, one of Mujib's surviving daughters, won the next election in 1996. The Awami League lost again to the Bangladesh Nationalist Party in 2001.
Widespread political unrest followed the resignation of the BNP in late October 2006, but the caretaker government worked to bring the parties to election within the required ninety days. At the last minute in early January, the Awami League withdrew from the election scheduled for later that month. On 11 January 2007, the military intervened to support both a state of emergency and a continuing but neutral caretaker government under a newly appointed Chief Advisor, who was not a politician. The country had suffered for decades from extensive corruption, disorder, and political violence. The caretaker government worked to root out corruption from all levels of government. It arrested on corruption charges more than 160 people, including politicians, civil servants, and businessmen, among whom were both major party leaders, some of their senior staff, and two sons of Khaleda Zia.
After working to clean up the system, the caretaker government held what was described by observers as a largely free and fair election on 29 December 2008. The Awami League's Sheikh Hasina won with a two-thirds landslide in the elections; she took the oath of Prime Minister on 6 January 2009.

</doc>
<doc id="40097" url="https://en.wikipedia.org/wiki?curid=40097" title="Collecting">
Collecting

The hobby of collecting includes seeking, locating, acquiring, organizing, cataloging, displaying, storing, and maintaining whatever items are of interest to the individual collector. The scope of collecting is unlimited: "If something exists, somebody somewhere collects them."
The most obvious way to categorise collections is by the type of objects collected. Most collections are of manufactured commercial items, but natural objects such as birds' eggs, butterflies, rocks, and seashells can also be the subject of a collection. Among collections of manufactured items, the objects may be antique, or simply collectible. Antiques are collectible items at least 100 years old, while collectibles can be arbitrarily recent. Collectors and dealers may use the word "vintage" to describe older collectibles. Items which were once everyday objects but may now be collectible since almost all those once produced have been destroyed or discarded are called Ephemera. Philately, phillumeny, and deltiology (collecting postage stamps, matchboxes and postcards) are forms of collecting which can be undertaken at minimal expense.
Some collectors are generalists with very broad criteria for inclusion, while others focus on a subtopic within their area of interest. Some collectors accumulate arbitrarily many objects that meet the thematic and quality requirements of their collection, others—called "completists"—aim to acquire all items in a well-defined set that can in principle be completed, and others seek a limited number of items per category (e.g. one representative item per year of manufacture or place of purchase). The monetary value of objects is important to some collectors but irrelevant to others. Some collectors maintain objects in pristine condition, while others use the items they collect, and still others collect items that once belonged to famous people.
Collecting is for some people a childhood hobby, but for others a lifelong pursuit or one that begins in adulthood. Collectors who begin early in life often modify their aims when they get older. Some novice collectors start purchasing items that appeal to them then slowly work at learning how to build a collection, while others prefer to develop some background in the field before starting to buy items.
The emergence of the internet as a global forum for different collectors has resulted in many isolated enthusiasts finding each other.
History.
Collecting is a practice with a very old cultural history. The Egyptian Ptolemaic dynasty collected books from all over the known world at the Library of Alexandria. The Medici family, in Renaissance Florence, made the first effort to collect art by private patronage, this way artists could be free for the first time from the money given by the Church and Kings; this citizenship tradition continues today with the work of private art collectors. Many of the world's popular museums—from the Metropolitan in New York City to the Thyssen in Madrid or the Franz Mayer in Mexico City—have collections formed by the generous collectors that donated them to be seen by the general public.
The collecting hobby is a modern descendant of the "cabinet of curiosities" which was common among scholars with the means and opportunities to acquire unusual items from the 16th century onwards. Planned collecting of ephemeral publications goes back at least to George Thomason in the reign of Charles I and Samuel Pepys in that of Charles II. Collecting engravings and other prints by those whose means did not allow them to buy original works of art also goes back many centuries. The progress in 18th-century Paris of collecting both works of art and of "curiosité", dimly echoed in the English "curios", and the origins in Paris, Amsterdam and London of the modern art market have been increasingly well documented and studied since the mid-19th century.
The involvement of larger numbers of people in collecting activities comes with the prosperity and increased leisure for some in the later 19th century in industrial countries. That is when collecting such items as antique china, furniture and decorative items from oriental countries becomes established.
On the Internet.
The Internet offers many resources to any collector: personal sites presenting one's collection, online collectible catalogs, dealer/shops websites displaying their merchandise, Internet trading platforms, collector clubs, autograph club, collector forums and collector mailing lists.
Factors affecting collectability.
Secondary market.
The retail price of a collectible is valid only at the moment it was purchased. Once the collectible comes into the buyer’s possession, its value is linked to what is called the secondary market. There is no secondary market for an item unless someone is willing to buy it, and an object's value is whatever the buyer is willing to pay for it. Depending on various factors, individuals, auctioneers, and secondary retailers may sell a collectible for more, the same, or less than what they originally paid for it. These factors include, but are not limited to, condition, age, supply, and demand. A price guide is a resource such as a book or website that lists typical selling prices. The first price guide was the Stanley Gibbons catalogue issued in November 1865.
Items sold in limited editions may be limited by an announced quantity, or by a particular period of production for items that are not mass-produced, often one year. In either case, items may or may not be numbered.
Age of collected items.
The term antique generally refers to items made over 100 years ago. In some fields, such as antique cars, the time frame is less stringent-—25 years or so being considered enough time to make a car a "classic" if not an antique. Traditionally in the area of furniture, the 1830s was regarded as the limit for antique furniture. However Victorian, Arts and Crafts, and some types of 20th century furniture can all be regarded as collectible.
In general, then, items of significance, beauty, values or interest that are "too young" to be considered antiques, fall into the realm of collectibles. But not all collectibles are limited editions, and many of them have been around for decades: for example, the popular turn-of-the-century posters, Art Deco and Art Nouveau items, Carnival and Depression era glass, etc. In addition, there exists the "contemporary collectibles" category, featuring items like plates, figurines, bells, graphics, steins, and dolls.
The 1960s through the early 1990s were major years for the manufacturing of contemporary collectibles. While some individuals purchased contemporary collectibles to enjoy and use, many purchased them as investments. Speculative secondary markets developed for many of these pieces. Because so many people bought for investment purposes, duplicates are common. And although many collectibles were labeled as "limited editions," the actual number of items produced was very large. The result of this is that there is very little demand for many (but not all) items produced during this time period, which means their secondary market values are often low.
Psychological aspects.
Psychological factors can play a role in both the motivation for keeping a collection and the impact it has on the collector's life. These factors can be positive or negative.
The hobby of collecting often goes hand-in-hand with an interest in the objects collected and what they represent, for example collecting postcards may reflect an interest in different places and cultures. For this reason, collecting can have educational benefits, and some collectors even become experts in their field.
Collecting for most people is a choice, but for some it can be a compulsion, sharing characteristics with obsessive hoarding. When collecting is passed between generations, it might sometimes be that children have inherited symptoms of obsessive–compulsive disorder. Collecting can sometimes reflect a fear of scarcity, or of discarding something then later regretting it. Certain patterns of collection are common among people who have lived through poverty or war.
Maintaining a collection can be a relaxing activity that counteracts the stress of life, while providing a purposeful pursuit which prevents boredom. The hobby can lead to social connections between people with similar interests. On the other hand, collecting can also be a means of withdrawing from the world and avoiding human contact.
It has been speculated that the widespread appeal of collecting is connected to the hunting and gathering that was once necessary for human survival. For some people, collecting things may be a symbolic way of asserting power over them.

</doc>
<doc id="40112" url="https://en.wikipedia.org/wiki?curid=40112" title="Salvador Dalí">
Salvador Dalí

Salvador Domingo Felipe Jacinto Dalí i Domènech, Marqués de Dalí de Pubol (11 May 190423 January 1989), known as Salvador Dalí (; ), was a prominent Spanish surrealist painter born in Figueres, Catalonia, Spain.
Dalí was a skilled draftsman, best known for the striking and bizarre images in his surrealist work. His painterly skills are often attributed to the influence of Renaissance masters. His best-known work, "The Persistence of Memory", was completed in August 1931. Dalí's expansive artistic repertoire included film, sculpture, and photography, in collaboration with a range of artists in a variety of media.
Dalí attributed his "love of everything that is gilded and excessive, my passion for luxury and my love of oriental clothes" to an "Arab lineage", claiming that his ancestors were descended from the Moors.
Dalí was highly imaginative, and also enjoyed indulging in unusual and grandiose behavior. His eccentric manner and attention-grabbing public actions sometimes drew more attention than his artwork, to the dismay of those who held his work in high esteem, and to the irritation of his critics.
Biography.
Early life.
Salvador Domingo Felipe Jacinto Dalí i Domènech was born on 11 May 1904, at 8:45 am GMT, at the 1st floor of Carrer Monturiol, 20 (presently 6), in the town of Figueres, in the Empordà region, close to the French border in Catalonia, Spain. In the Summer of 1912, the family moved to the top floor of Carrer Monturiol 24 (presently 10). Dalí's older brother, who had also been named Salvador (born 12 October 1901), had died of gastroenteritis nine months earlier, on 1 August 1903. His father, Salvador Dalí i Cusí, was a middle-class lawyer and notary whose strict disciplinary approach was tempered by his wife, Felipa Domenech Ferrés, who encouraged her son's artistic endeavors.
When he was five, Dalí was taken to his brother's grave and told by his parents that he was his brother's reincarnation, a concept which he came to believe. Of his brother, Dalí said, "... resembled each other like two drops of water, but we had different reflections." He "was probably a first version of myself but conceived too much in the absolute." Images of his long-dead brother would reappear embedded in his later works, including "Portrait of My Dead Brother" (1963).
Dalí also had a sister, Anna Maria, who was three years younger. In 1949, she published a book about her brother, "Dalí As Seen By His Sister". His childhood friends included future FC Barcelona footballers Sagibarba and Josep Samitier. During holidays at the Catalan resort of Cadaqués, the trio played football (soccer) together.
Dalí attended drawing school. In 1916, he also discovered modern painting on a summer vacation trip to Cadaqués with the family of Ramon Pichot, a local artist who made regular trips to Paris. The next year, Dalí's father organized an exhibition of his charcoal drawings in their family home. He had his first public exhibition at the Municipal Theatre in Figueres in 1919, a site he would return to decades later.
In February 1921, Dalí's mother died of breast cancer. Dalí was 16 years old; he later said his mother's death "was the greatest blow I had experienced in my life. I worshipped her... I could not resign myself to the loss of a being on whom I counted to make invisible the unavoidable blemishes of my soul." After her death, Dalí's father married his deceased wife's sister. Dalí did not resent this marriage, because he had a great love and respect for his aunt.
Madrid and Paris.
In 1922, Dalí moved into the Residencia de Estudiantes (Students' Residence) in Madrid and studied at the Real Academia de Bellas Artes de San Fernando. A lean tall, Dalí already drew attention as an eccentric and dandy. He had long hair and sideburns, coat, stockings, and knee-breeches in the style of English aesthetes of the late 19th century.
At the Residencia, he became close friends with (among others) Pepín Bello, Luis Buñuel, and Federico García Lorca. The friendship with Lorca had a strong element of mutual passion, but Dalí rejected the poet's sexual advances.
However it was his paintings, in which he experimented with Cubism, that earned him the most attention from his fellow students. His only information on Cubist art had come from magazine articles and a catalog given to him by Pichot, since there were no Cubist artists in Madrid at the time. In 1924, the still-unknown Salvador Dalí illustrated a book for the first time. It was a publication of the Catalan poem "Les bruixes de Llers" ("The Witches of Llers") by his friend and schoolmate, poet Carles Fages de Climent. Dalí also experimented with Dada, which influenced his work throughout his life.
Dalí was expelled from the Academy in 1926, shortly before his final exams when he was accused of starting an unrest. His mastery of painting skills at that time was evidenced by his realistic "The Basket of Bread", painted in 1926. That same year, he made his first visit to Paris, where he met Pablo Picasso, whom the young Dalí revered. Picasso had already heard favorable reports about Dalí from Joan Miró, a fellow Catalan who introduced him to many Surrealist friends. As he developed his own style over the next few years, Dalí made a number of works heavily influenced by Picasso and Miró.
Some trends in Dalí's work that would continue throughout his life were already evident in the 1920s. Dalí devoured influences from many styles of art, ranging from the most academically classic, to the most cutting-edge avant-garde. His classical influences included Raphael, Bronzino, Francisco de Zurbarán, Vermeer and Velázquez. He used both classical and modernist techniques, sometimes in separate works, and sometimes combined. Exhibitions of his works in Barcelona attracted much attention along with mixtures of praise and puzzled debate from critics.
Dalí grew a flamboyant moustache, influenced by 17th-century Spanish master painter Diego Velázquez. The moustache became an iconic trademark of his appearance for the rest of his life.
1929 to World War II.
In 1929, Dalí collaborated with surrealist film director Luis Buñuel on the short film ("An Andalusian Dog"). His main contribution was to help Buñuel write the script for the film. Dalí later claimed to have also played a significant role in the filming of the project, but this is not substantiated by contemporary accounts. Also, in August 1929, Dalí met his lifelong and primary muse, inspiration, and future wife Gala, born Elena Ivanovna Diakonova. She was a Russian immigrant ten years his senior, who at that time was married to surrealist poet Paul Éluard. In the same year, Dalí had important professional exhibitions and officially joined the Surrealist group in the Montparnasse quarter of Paris. His work had already been heavily influenced by surrealism for two years. The Surrealists hailed what Dalí called his paranoiac-critical method of accessing the subconscious for greater artistic creativity.
Meanwhile, Dalí's relationship with his father was close to rupture. Don Salvador Dalí y Cusi strongly disapproved of his son's romance with Gala, and saw his connection to the Surrealists as a bad influence on his morals. The final straw was when Don Salvador read in a Barcelona newspaper that his son had recently exhibited in Paris a drawing of the "Sacred Heart of Jesus Christ", with a provocative inscription: "Sometimes, I spit for fun on my mother's portrait".
Outraged, Don Salvador demanded that his son recant publicly. Dalí refused, perhaps out of fear of expulsion from the Surrealist group, and was violently thrown out of his paternal home on December 28, 1929. His father told him that he would be disinherited, and that he should never set foot in Cadaqués again. The following summer, Dalí and Gala rented a small fisherman's cabin in a nearby bay at Port Lligat. He bought the place, and over the years enlarged it by buying the neighbouring fishermen cabins, gradually building his much beloved villa by the sea. Dalí's father would eventually relent and come to accept his son's companion.
In 1931, Dalí painted one of his most famous works, "The Persistence of Memory", which introduced a surrealistic image of soft, melting pocket watches. The general interpretation of the work is that the soft watches are a rejection of the assumption that time is rigid or deterministic. This idea is supported by other images in the work, such as the wide expanding landscape, and other limp watches shown being devoured by ants.
Dalí and Gala, having lived together since 1929, were married in 1934 in a semi-secret civil ceremony. They later remarried in a Catholic ceremony in 1958. In addition to inspiring many artworks throughout her life, Gala would act as Dalí's business manager, supporting their extravagant lifestyle while adeptly steering clear of insolvency. Gala seemed to tolerate Dalí's dalliances with younger muses, secure in her own position as his primary relationship. Dalí continued to paint her as they both aged, producing sympathetic and adoring images of his muse. The "tense, complex and ambiguous relationship" lasting over 50 years would later become the subject of an opera, "Jo, Dalí" ("I, Dalí") by Catalan composer Xavier Benguerel.
Dalí was introduced to the United States by art dealer Julien Levy in 1934. The exhibition in New York of Dalí's works, including "Persistence of Memory", created an immediate sensation. Social Register listees feted him at a specially organized "Dalí Ball". He showed up wearing a glass case on his chest, which contained a brassiere. In that year, Dalí and Gala also attended a masquerade party in New York, hosted for them by heiress Caresse Crosby. For their costumes, they dressed as the Lindbergh baby and his kidnapper. The resulting uproar in the press was so great that Dalí apologized. When he returned to Paris, the Surrealists confronted him about his apology for a surrealist act.
While the majority of the Surrealist artists had become increasingly associated with leftist politics, Dalí maintained an ambiguous position on the subject of the proper relationship between politics and art. Leading surrealist André Breton accused Dalí of defending the "new" and "irrational" in "the Hitler phenomenon", but Dalí quickly rejected this claim, saying, "I am Hitlerian neither in fact nor intention". Dalí insisted that surrealism could exist in an apolitical context and refused to explicitly denounce fascism. Among other factors, this had landed him in trouble with his colleagues. Later in 1934, Dalí was subjected to a "trial", in which he was formally expelled from the Surrealist group. To this, Dalí retorted, "I myself am surrealism".
In 1936, Dalí took part in the London International Surrealist Exhibition. His lecture, titled , was delivered while wearing a deep-sea diving suit and helmet. He had arrived carrying a billiard cue and leading a pair of Russian wolfhounds, and had to have the helmet unscrewed as he gasped for breath. He commented that "I just wanted to show that I was 'plunging deeply' into the human mind." In 1936, Dalí, aged 32, was featured on the cover of "Time" magazine.
Also in 1936, at the premiere screening of Joseph Cornell's film "Rose Hobart" at Julien Levy's gallery in New York City, Dalí became famous for another incident. Levy's program of short surrealist films was timed to take place at the same time as the first surrealism exhibition at the Museum of Modern Art, featuring Dalí's work. Dalí was in the audience at the screening, but halfway through the film, he knocked over the projector in a rage. "My idea for a film is exactly that, and I was going to propose it to someone who would pay to have it made", he said. "I never wrote it down or told anyone, but it is as if he had stolen it". Other versions of Dalí's accusation tend to the more poetic: "He stole it from my subconscious!" or even "He stole my dreams!"
In this period, Dalí's main patron in London was the very wealthy Edward James. He had helped Dalí emerge into the art world by purchasing many works and by supporting him financially for two years. They also collaborated on two of the most enduring icons of the Surrealist movement: the "Lobster Telephone" and the "Mae West Lips Sofa".
Meanwhile, Spain was going through a civil war (1936-1939), with many artists taking a side or going into exile.
In 1938, Dalí met Sigmund Freud thanks to Stefan Zweig. Dalí started to sketch Freud's portrait, while the 82-year-old celebrity confided to others that "This boy looks like a fanatic." Dalí was delighted upon hearing later about this comment from his hero.
Later, in September 1938, Salvador Dalí was invited by Gabrielle Coco Chanel to her house "La Pausa" in Roquebrune on the French Riviera. There he painted numerous paintings he later exhibited at Julien Levy Gallery in New York. At the end of the 20th century, "La Pausa" was partially replicated at the Dallas Museum of Art to welcome the Reeves collection and part of Chanel's original furniture for the house.
Also in 1938, Dalí unveiled "Rainy Taxi", a three-dimensional artwork, consisting of an actual automobile with two mannequin occupants. The piece was first displayed at the Galerie Beaux-Arts in Paris at the Exposition Internationale du Surréalisme, organised by André Breton and Paul Éluard. The Exposition was designed by artist Marcel Duchamp, who also served as host.
At the 1939 New York World's Fair, Dalí debuted his "Dream of Venus" surrealist pavilion, located in the Amusements Area of the exposition. It featured bizarre sculptures, statues, and live nude models in "costumes" made of fresh seafood, an event photographed by Horst P. Horst, George Platt Lynes and Murray Korman. Like most attractions in the Amusements Area, an admission fee was charged.
In 1939, André Breton coined the derogatory nickname "Avida Dollars", an anagram for "Salvador Dalí", which may be more or less translated as "eager for dollars". This was a derisive reference to the increasing commercialization of Dalí's work, and the perception that Dalí sought self-aggrandizement through fame and fortune. The Surrealists, many of whom were closely connected to the French Communist Party at the time, expelled him from their movement. Some surrealists henceforth spoke of Dalí in the past tense, as if he were dead. The Surrealist movement and various members thereof (such as Ted Joans) would continue to issue extremely harsh polemics against Dalí until the time of his death, and beyond.
World War II.
In 1940, as World War II tore through Europe, Dalí and Gala retreated to the United States, where they lived for eight years. They were able to escape because on June 20, 1940, they were issued visas by Aristides de Sousa Mendes, Portuguese consul in Bordeaux, France. Dalí’s arrival in New York was one of the catalysts in the development of that city as a world art center in the post-War years. Salvador and Gala Dalí crossed into Portugal and subsequently sailed on the Excambion from Lisbon to New York in August 1940. After the move, Dalí returned to the practice of Catholicism. "During this period, Dalí never stopped writing", wrote Robert and Nicolas Descharnes.
Dalí worked prolifically in a variety of media during this period, designing jewelry, clothes, furniture, stage sets for plays and ballet, and retail store display windows. In 1939, while working on a window display for Bonwit Teller, he became so enraged by unauthorized changes to his work that he shoved a decorative bathtub through a plate glass window.
In 1941, Dalí drafted a film scenario for Jean Gabin called "Moontide". In 1942, he published his autobiography, "The Secret Life of Salvador Dalí". He wrote catalogs for his exhibitions, such as that at the Knoedler Gallery in New York in 1943. Therein he attacked some often-used surrealist techniques by proclaiming, "Surrealism will at least have served to give experimental proof that total sterility and attempts at automatizations have gone too far and have led to a totalitarian system. ... Today's laziness and the total lack of technique have reached their paroxysm in the psychological signification of the current use of the college" (collage). He also wrote a novel, published in 1944, about a fashion salon for automobiles. This resulted in a drawing by Edwin Cox in "The Miami Herald", depicting Dalí dressing an automobile in an evening gown.
In "The Secret Life", Dalí suggested that he had split with Luis Buñuel because the latter was a Communist and an atheist. Buñuel was fired (or resigned) from his position at the Museum of Modern Art (MOMA), supposedly after Cardinal Spellman of New York went to see Iris Barry, head of the film department at MOMA. Buñuel then went back to Hollywood where he worked in the dubbing department of Warner Brothers from 1942 to 1946. In his 1982 autobiography "Mon Dernier soupir" ("My Last Sigh", 1983), Buñuel wrote that, over the years, he had rejected Dalí's attempts at reconciliation.
An Italian friar, Gabriele Maria Berardi, claimed to have performed an exorcism on Dalí while he was in France in 1947. In 2005, a sculpture of Christ on the Cross was discovered in the friar's estate. It had been claimed that Dalí gave this work to his exorcist out of gratitude, and two Spanish art experts confirmed that there were adequate stylistic reasons to believe the sculpture was made by Dalí.
Later years in Spain.
In 1948 Dalí and Gala moved back into their house in Port Lligat, on the coast near Cadaqués. For the next three decades, he would spend most of his time there painting, taking time off and spending winters with his wife in Paris and New York. His acceptance and implicit embrace of Franco's dictatorship were strongly disapproved of by other Spanish artists and intellectuals who remained in exile.
In 1959, André Breton organized an exhibit called "Homage to Surrealism", celebrating the fortieth anniversary of Surrealism, which contained works by Dalí, Joan Miró, Enrique Tábara, and Eugenio Granell. Breton vehemently fought against the inclusion of Dalí's "Sistine Madonna" in the International Surrealism Exhibition in New York the following year.
Late in his career Dalí did not confine himself to painting, but explored many unusual or novel media and processes: for example, he experimented with bulletist artworks. Many of his late works incorporated optical illusions, negative space, visual puns and trompe l'œil visual effects. He also experimented with pointillism, enlarged half-tone dot grids (a technique which Roy Lichtenstein would later use), and stereoscopic images. He was among the first artists to employ holography in an artistic manner. In Dalí's later years, young artists such as Andy Warhol proclaimed him an important influence on pop art.
Dalí also developed a keen interest in natural science and mathematics. This is manifested in several of his paintings, notably from the 1950s, in which he painted his subjects as composed of rhinoceros horn shapes. According to Dalí, the rhinoceros horn signifies divine geometry because it grows in a logarithmic spiral. He linked the rhinoceros to themes of chastity and to the Virgin Mary. Dalí was also fascinated by DNA and the tesseract (a 4-dimensional cube); an unfolding of a hypercube is featured in the painting "Crucifixion (Corpus Hypercubus)".
At some point, Dalí had a glass floor installed in a room near his studio. He made extensive use of it to study foreshortening, both from above and from below, incorporating dramatic perspectives of figures and objects into his paintings. He also delighted in using the room for entertaining guests and visitors to his house and studio.
Dalí's post–World War II period bore the hallmarks of technical virtuosity and an intensifying interest in optical effects, science, and religion. He became an increasingly devout Catholic, while at the same time he had been inspired by the shock of Hiroshima and the dawning of the "atomic age". Therefore, Dalí labeled this period "Nuclear Mysticism". In paintings such as "The Madonna of Port Lligat" (first version, 1949) and "Corpus Hypercubus" (1954), Dalí sought to synthesize Christian iconography with images of material disintegration inspired by nuclear physics. His Nuclear Mysticism works included such notable pieces as "La Gare de Perpignan" (1965) and "The Hallucinogenic Toreador" (1968–70).
In 1960, Dalí began work on his Theatre and Museum in his home town of Figueres; it was his largest single project and a main focus of his energy through 1974, when it opened. He continued to make additions through the mid-1980s.
Dalí continued to indulge in publicity stunts and self-consciously outrageous behavior. To promote his 1962 book "The World of Salvador Dalí", he appeared in a Manhattan bookstore on a bed, wired up to a machine that traced his brain waves and blood pressure. He would autograph books while thus monitored, and the book buyer would also be given the paper chart recording.
In 1968, Dalí filmed a humorous television advertisement for Lanvin chocolates. In this, he proclaims in French "Je suis fou du chocolat Lanvin!" ("I'm crazy about Lanvin chocolate!") while biting a morsel, causing him to become cross-eyed and his moustache to swivel upwards. In 1969, he designed the Chupa Chups logo, in addition to facilitating the design of the advertising campaign for the 1969 Eurovision Song Contest and creating a large on-stage metal sculpture that stood at the Teatro Real in Madrid.
In the television programme "Dirty Dalí: A Private View" broadcast on Channel 4 on June 3, 2007, art critic Brian Sewell described his acquaintance with Dalí in the late 1960s, which included lying down in the fetal position without trousers in the armpit of a figure of Christ and masturbating for Dalí, who pretended to take photos while fumbling in his own trousers.
Final years and death.
In 1968, Dalí had bought a castle in Púbol for Gala; and starting in 1971 she would retreat there alone for weeks at a time. By Dalí's own admission, he had agreed not to go there without written permission from his wife. His fears of abandonment and estrangement from his longtime artistic muse contributed to depression and failing health.
In 1980 at age 76, Dalí's health took a catastrophic turn. His right hand trembled terribly, with Parkinson-like symptoms. His near-senile wife allegedly had been dosing him with a dangerous cocktail of unprescribed medicine that damaged his nervous system, thus causing an untimely end to his artistic capacity.
In 1982, King Juan Carlos bestowed on Dalí the title of "Marqués de Dalí de Púbol" ("Marquis of Dalí de Púbol") in the nobility of Spain, hereby referring to Púbol, the place where he lived. The title was in first instance hereditary, but on request of Dalí changed to life only in 1983.
Gala died on 10 June 1982, at the age of 87. After Gala's death, Dalí lost much of his will to live. He deliberately dehydrated himself, possibly as a suicide attempt, with claims stating he had tried to put himself into a state of suspended animation as he had read that some microorganisms could do. He moved from Figueres to the castle in Púbol, which was the site of her death and her grave.
In May 1983, Dalí revealed what would be his last painting, "The Swallow's Tail", a work heavily influenced by the mathematical catastrophe theory of René Thom.
In 1984, a fire broke out in his bedroom under unclear circumstances. It was possibly a suicide attempt by Dalí, or possibly simple negligence by his staff. Dalí was rescued by friend and collaborator Robert Descharnes and returned to Figueres, where a group of his friends, patrons, and fellow artists saw to it that he was comfortable living in his Theater-Museum in his final years.
There have been allegations that Dalí was forced by his guardians to sign blank canvases that would later, even after his death, be used in forgeries and sold as originals. It is also alleged that he knowingly sold otherwise-blank signed lithograph paper, possibly producing over 50,000 such sheets from 1965 until his death. As a result, art dealers tend to be wary of late works attributed to Dalí.
In November 1988, Dalí entered the hospital with heart failure; a pacemaker had been implanted previously. On December 5, 1988, he was visited by King Juan Carlos, who confessed that he had always been a serious devotee of Dalí. Dalí gave the king a drawing ("Head of Europa", which would turn out to be Dalí's final drawing) after the king visited him on his deathbed.
On the morning of 23 January 1989, while his favorite record of "Tristan and Isolde" played, Dalí died of heart failure at Figueres at the age of 84. He is buried in the crypt below the stage of his Theatre and Museum in Figueres. The location is across the street from the church of "Sant Pere", where he had his baptism, first communion, and funeral, and is only three blocks from the house where he was born.
The Gala-Salvador Dalí Foundation currently serves as his official estate. The US copyright representative for the Gala-Salvador Dalí Foundation is the Artists Rights Society. In 2002, the Society made news when it asked Google to remove a customized version of its logo put up to commemorate Dalí, alleging that portions of specific artworks under its protection had been used without permission. Google complied with the request, but denied that there was any copyright violation.
Symbolism.
Dalí employed extensive symbolism in his work. For instance, the hallmark "melting watches" that first appear in "The Persistence of Memory" suggest Einstein's theory that time is relative and not fixed. The idea for clocks functioning symbolically in this way came to Dalí when he was staring at a runny piece of Camembert cheese on a hot August day.
The elephant is also a recurring image in Dalí's works. It appeared in his 1944 work "Dream Caused by the Flight of a Bee Around a Pomegranate a Second Before Awakening". The elephants, inspired by Gian Lorenzo Bernini's sculpture base in Rome of an elephant carrying an ancient obelisk, are portrayed "with long, multijointed, almost invisible legs of desire" along with obelisks on their backs. Coupled with the image of their brittle legs, these encumbrances, noted for their phallic overtones, create a sense of phantom reality. "The elephant is a distortion in space", one analysis explains, "its spindly legs contrasting the idea of weightlessness with structure." "I am painting pictures which make me die for joy, I am creating with an absolute naturalness, without the slightest aesthetic concern, I am making things that inspire me with a profound emotion and I am trying to paint them honestly." —Salvador Dalí, in Dawn Ades, "Dalí and Surrealism".
The egg is another common Dalíesque image. He connects the egg to the prenatal and intrauterine, thus using it to symbolize hope and love; it appears in "The Great Masturbator" and "The Metamorphosis of Narcissus". "The Metamorphosis of Narcissus" also symbolized death and petrification.
Various other animals appear throughout his work as well: ants point to death, decay, and immense sexual desire; the snail is connected to the human head (he saw a snail on a bicycle outside Freud's house when he first met Sigmund Freud); and locusts are a symbol of waste and fear.
Both Dalí and his father enjoyed eating sea urchins, freshly caught in the sea near Cadaqués. The symmetry of the sea urchin fascinated Dalí and adapted its form to many art works and other foods also appear throughout his work.
Science.
References to Dalí in the context of science are made in terms of his fascination with the paradigm shift that accompanied the birth of quantum mechanics in the twentieth century. Inspired by Werner Heisenberg's uncertainty principle, in 1958 he wrote in his "Anti-Matter Manifesto": "In the Surrealist period, I wanted to create the iconography of the interior world and the world of the marvelous, of my father Freud. Today, the exterior world and that of physics has transcended the one of psychology. My father today is Dr. Heisenberg."
In this respect, "The Disintegration of the Persistence of Memory", which appeared in 1954, in harking back to "The Persistence of Memory" and in portraying that painting in fragmentation and disintegration, summarizes Dalí's acknowledgment of the new science.
Endeavors outside painting.
Dalí was a versatile artist. Some of his more popular works are sculptures and other objects, and he is also noted for his contributions to theatre, fashion, and photography, among other areas.
Sculptures and other objects.
Two of the most popular objects of the surrealist movement were "Lobster Telephone" and "Mae West Lips Sofa", completed by Dalí in 1936 and 1937, respectively. Surrealist artist and patron Edward James commissioned both of these pieces from Dalí; James inherited a large English estate in West Dean, West Sussex when he was five and was one of the foremost supporters of the surrealists in the 1930s. "Lobsters and telephones had strong sexual connotations for according to the display caption for the "Lobster Telephone" at the Tate Gallery, "and he drew a close analogy between food and sex." The telephone was functional, and James purchased four of them from Dalí to replace the phones in his retreat home. One now appears at the Tate Gallery; the second can be found at the German Telephone Museum in Frankfurt; the third belongs to the Edward James Foundation; and the fourth is at the National Gallery of Australia.
The wood and satin "Mae West Lips Sofa" was shaped after the lips of actress Mae West, whom Dalí apparently found fascinating. West was previously the subject of Dalí's 1935 painting "The Face of Mae West". The "Mae West Lips Sofa" currently resides at the Brighton and Hove Museum in England.
Between 1941 and 1970, Dalí created an ensemble of 39 pieces of jewelry; many pieces are intricate, and some contain moving parts. The most famous assemblage, "The Royal Heart", is made of gold and is encrusted with 46 rubies, 42 diamonds, and four emeralds, created in such a way that the center "beats" much like a real heart. Dalí himself commented that "Without an audience, without the presence of spectators, these jewels would not fulfill the function for which they came into being. The viewer, then, is the ultimate artist." The "Dalí – Joies" ("The Jewels of Dalí") collection can be seen at the Dalí Theater Museum in Figueres, Catalonia, Spain, where it is on permanent exhibition.
Dalí took a stab at industrial design in the 1970s with a 500-piece run of the upscale "Suomi" tableware by Timo Sarpaneva that Dalí decorated for the German Rosenthal porcelain maker's "Studio Linie".
Theatre and film.
In theatre, Dalí constructed the scenery for Federico García Lorca's 1927 romantic play "Mariana Pineda". For "Bacchanale" (1939), a ballet based on and set to the music of Richard Wagner's 1845 opera "Tannhäuser", Dalí provided both the set design and the libretto. "Bacchanale" was followed by set designs for "Labyrinth" in 1941 and "The Three-Cornered Hat" in 1949.
Dalí became intensely interested in film when he was young, going to the theatre most Sundays. He was part of the era where silent films were being viewed and drawing on the medium of film became popular. He believed there were two dimensions to the theories of film and cinema: "things themselves", the facts that are presented in the world of the camera; and "photographic imagination", the way the camera shows the picture and how creative or imaginative it looks. Dalí was active in front of and behind the scenes in the film world.
He is credited as co-creator of Luis Buñuel's surrealist film "Un Chien Andalou", a 17-minute French art film co-written with Luis Buñuel that is widely remembered for its graphic opening scene simulating the slashing of a human eyeball with a razor. This film is what Dalí is known for in the independent film world. "Un Chien Andalou" was Dalí's way of creating his dreamlike qualities in the real world. Images would change and scenes would switch, leading the viewer in a completely different direction from the one they were previously viewing. The second film he produced with Buñuel was entitled "L'Age d'Or", and it was performed at Studio 28 in Paris in 1930. "L'Age d'Or" was "banned for years after fascist and anti-Semitic groups staged a stink bomb and ink-throwing riot in the Paris theater where it was shown".
Although negative aspects of society were being thrown into the life of Dalí which affected the commercial success of his artwork, it did not hold him back from expressing his own ideas and beliefs in his art. Both of these films, "Un Chien Andalou" and "L'Age d'Or", have had a tremendous impact on the independent surrealist film movement. "If "Un Chien Andalou" stands as the supreme record of Surrealism's adventures into the realm of the unconscious, then "L'Âge d'Or" is perhaps the most trenchant and implacable expression of its revolutionary intent".
Dalí worked with other famous filmmakers, such as Alfred Hitchcock. The most well-known of his film projects is probably the dream sequence in Hitchcock's "Spellbound", which heavily delves into themes of psychoanalysis. Hitchcock needed a dreamlike quality to his film, which dealt with the idea that a repressed experience can directly trigger a neurosis, and he knew that Dalí's work would help create the atmosphere he wanted in his film. He also worked on a documentary called "Chaos and Creation", which has a lot of artistic references thrown into it to help one see what Dalí's vision of art really is.
Dalí also worked with Walt Disney on the short film production "Destino". Completed in 2003 by Baker Bloodworth and Walt's nephew Roy E. Disney, it contains dreamlike images of strange figures flying and walking about. It is based on Mexican songwriter Armando Dominguez' song "Destino". When Disney hired Dalí to help produce the film in 1946, they were not prepared for the quantity of work that lay ahead. For eight months, they worked on it continuously, until their efforts had to stop when they realized they were in financial trouble. However, it was eventually finished 48 years later, and shown in various film festivals. The film consists of Dalí's artwork interacting with Disney's character animation.
Dalí completed only one other film in his lifetime, "Impressions of Upper Mongolia" (1975), in which he narrated a story about an expedition in search of giant hallucinogenic mushrooms. The imagery was based on microscopic uric acid stains on the brass band of a ballpoint pen on which Dalí had been urinating for several weeks.
In the mid-1970s, film director Alejandro Jodorowsky cast Dali in the role of the Padishah Emperor in a production of "Dune", based on the novel by Frank Herbert. According to the 2013 documentary on the film, "Jodorowsky's Dune", Jodorowsky met Dali in the King Cole Bar in the St. Regis hotel in Manhattan to discuss the role. Dali expressed interest in the film but required as a condition of appearing that he be made the highest paid actor in Hollywood. Jodorowsky accordingly cast Dali as the emperor, but he planned to cut Dali's screen time to mere minutes, promising he be the highest-paid actor on a per minute basis. The film was ultimately never made.
In the year 1927, Dali began to write the libretto for an opera, which he called "Être Dieu" ("To Be God"). He wrote this together with Federico Garcia Lorca one afternoon in the Café Regina Victoria in Madrid. In 1974, for a recording in Paris, the opera was adapted by the Spanish writer Manuel Vazquez Montalban, who wrote the libretto, while the music was created by Igor Wakhevitch. During the recording, however, Dali refused to follow the text written by Montalban, and instead, began to improvise in the belief that “Salvador Dali never repeats himself.”
Fashion and photography.
Dalí built a repertoire in the fashion and photography businesses as well. His cooperation with Italian fashion designer Elsa Schiaparelli was well-known, when Dalí was commissioned to produce a white dress with a lobster print. Other designs Dalí made for her include a shoe-shaped hat, and a pink belt with lips for a buckle. He was also involved in creating textile designs and perfume bottles. In 1950, Dalí created a special "costume for the year 2045" with Christian Dior.
Photographers with whom he collaborated include Man Ray, Brassaï, Cecil Beaton, and Philippe Halsman. With Man Ray and Brassaï, Dalí photographed nature; with the others, he explored a range of obscure topics, including (with Halsman) the "Dalí Atomica" series (1948) — inspired by his painting "Leda Atomica" — which in one photograph depicts "a painter's easel, three cats, a bucket of water, and Dalí himself floating in the air."
One of Dalí's most unorthodox artistic creations may have been an entire persona, in addition to his own. At a French nightclub in 1965, Dalí met Amanda Lear, a fashion model then known as Peki D'Oslo. Lear became his protégée and muse, later writing about their affair in her authorized biography "My Life With Dalí" (1986). Transfixed by the mannish, larger-than-life Lear, Dalí masterminded her successful transition from modeling to the music world, advising her on self-presentation and helping spin mysterious stories about her origin as she took the disco-art scene by storm. According to Lear, she and Dalí were united in a "spiritual marriage" on a deserted mountaintop. She was referred to as Dalí's "Frankenstein," and some observers believed Lear's assumed name was a pun on the French phrase "L'Amant Dalí", or "Lover of Dalí". Lear took the place of an earlier muse, Ultra Violet (Isabelle Collin Dufresne), who had left Dalí's side to join The Factory of Andy Warhol.
Both former apprentices would go on to successfully promote their own careers in the arts. On April 10, 2005, they joined a panel discussion "Reminiscences of Dalí: A Conversation with Friends of the Artist" as part of a symposium "The Dalí Renaissance" for a major retrospective Dalí show at the Philadelphia Museum of Art. Their conversation is recorded in the 236-page exhibition catalog "The Dalí Renaissance: New Perspectives on His Life and Art after 1940".
Architecture.
Architectural achievements include his Port Lligat house near Cadaqués, as well as his Theatre and Museum in Figueres. A major work outside of Spain was the temporary "Dream of Venus" surrealist pavilion at the 1939 New York World's Fair, which contained within it a number of unusual sculptures and statues, including live performers posing as statues.
Literary works.
Under the encouragement of poet Federico García Lorca, Dalí attempted an approach to a literary career through the means of the "pure novel". In his literary production "Hidden Faces" (1944), Dalí describes, in vividly visual terms, the intrigues and love affairs of a group of dazzling, eccentric aristocrats who, with their luxurious and extravagant lifestyle, symbolize the decadence of the 1930s. The Comte de Grainsalles and Solange de Cléda pursue an awkward love affair, but property transactions, interwar political turmoil, the French Resistance, his marriage to another woman and her responsibilities as a landowner and businesswoman drive them apart. It is variously set in Paris, rural France, Casablanca in North Africa and Palm Springs in the United States. Secondary characters include ageing widow Barbara Rogers, her bisexual daughter Veronica, Veronica's sometime female lover Betka, and Baba, a disfigured US fighter pilot. The novel concludes at the end of the Second World War, with Solange dying before Grainsalles can return to his former property and reunite with her 
His other, nonfictional literary works include "The Secret Life of Salvador Dalí" (1942), "Diary of a Genius" (1952–63), and "Oui: The Paranoid-Critical Revolution " (1927–33).
Graphic arts.
The artist worked extensively in the graphic arts, producing many etchings and lithographs. While his early work in printmaking is equal in quality to his important paintings, as he grew older he would sell the rights to images but not be involved in the print production itself. In addition, a large number of fakes were produced in the 1980s and 1990s, thus further confusing the Dalí print market.
Publicity.
After his arrival in the United States, Dalí engaged in heavy self-promotion.
While many of his stunts were seen as antics by art critics, they were later interpreted as performances.
His status as an extravagant artist was put to use in several publicity campaigns for Lanvin chocolates, "If you got it, flaunt it!" for Braniff International Airlines (1968), and Iberia Airlines.
Politics and personality.
Salvador Dalí's politics played a significant role in his emergence as an artist. In his youth, he embraced both anarchism and Communism, though his writings tell anecdotes of making radical political statements more to shock listeners than from any deep conviction. This was in keeping with Dalí's allegiance to the Dada movement.
As he grew older his political allegiances changed, especially as the Surrealist movement went through transformations under the leadership of the Trotskyist writer André Breton, who is said to have called Dalí in for questioning on his politics. In his 1970 book "Dalí by Dalí", Dalí declared himself to be both an anarchist and monarchist.
With the outbreak of the Spanish Civil War (1936–1939), Dalí fled from the fighting and refused to align himself with any group. He did the same during World War II (1939–1945), for which he was heavily criticized; George Orwell accused him of "scuttling off like a rat as soon as France is in danger" after Dalí had prospered in France during the pre-war years. "When the European War approaches he has one preoccupation only: how to find a place which has good cookery and from which he can make a quick bolt if danger comes too near", Orwell observed. In a notable 1944 review of Dalí's autobiography, Orwell wrote, "One ought to be able to hold in one's head simultaneously the two facts that Dalí is a good draughtsman and a disgusting human being".
After his return to Catalonia post World War II, Dalí moved closer to the authoritarian regime of Francisco Franco. Some of Dalí's statements were supportive, congratulating Franco for his actions aimed "at clearing Spain of destructive forces". Dalí, having returned to the Catholic faith and becoming increasingly religious as time went on, may have been referring to the Republican atrocities during the Spanish Civil War. Dalí sent telegrams to Franco, praising him for signing death warrants for prisoners. He even met Franco personally, and painted a portrait of Franco's granddaughter. 
He also once sent a telegram praising the "Conducător", Romanian Communist leader Nicolae Ceauşescu, for his adoption of a scepter as part of his regalia. The Romanian daily newspaper "Scînteia" published it, without suspecting its mocking aspect. One of Dalí's few possible bits of open disobedience was his continued praise of Federico García Lorca even in the years when Lorca's works were banned.
Dalí, a colorful and imposing presence with his ever–present long cape, walking stick, haughty expression, and upturned waxed moustache, was famous for having said that "every morning upon awakening, I experience a supreme pleasure: that of being Salvador Dalí". The entertainer Cher and her husband Sonny Bono, when young, came to a party at Dalí's expensive residence in New York's Plaza Hotel and were startled when Cher sat down on an oddly shaped sexual vibrator left in an easy chair. In the 1960s, he gave the actress Mia Farrow a dead mouse in a bottle, hand-painted, which her mother, actress Maureen O'Sullivan, demanded be removed from her house.
Dali's religious views were a matter of interest. In interviews Dali revealed his mysticism. In his later years, while still remaining a Roman Catholic, Dalí also claimed to be an agnostic.
When signing autographs for fans, Dalí would always keep their pens. Salvador Dalí frequently traveled with his pet ocelot Babou, even bringing it aboard the luxury ocean liner "SS France". He was also known to avoid paying tabs at restaurants by drawing on the checks he wrote. His theory was the restaurant would never want to cash such a valuable piece of art, and he was usually correct.
Besides visual puns, Dalí shared in the surrealist delight in verbal puns, obscure allusions, and word games. He often spoke in a bizarre combination of French, Spanish, Catalan, and English which was sometimes amusing as well as arcane. His copious writings freely mixed words from different languages with terms entirely of his own devising.
When interviewed by Mike Wallace on his "60 Minutes" television show, Dalí kept referring to himself in the third person, as the "Divino Dalí" (Divine Dalí), and told the startled Wallace matter-of-factly that he did not believe in his death. On January 27, 1957, he was the mystery guest on the US panel show "What's My Line?" and signed the chalkboard with thick white paint. His answers were misleading and prompted guidance from host Daly.
Dali appeared in public a number of occasions with an anteater, notably on a lead in Paris in 1969 and on the "The Dick Cavett Show" on March 6, 1970 when he carried a small anteater on-stage. It has been claimed that he surprised fellow guest Lillian Gish by flinging the anteater onto her lap.
Legacy.
Salvador Dalí has been cited as major inspiration by many modern artists, such as Damien Hirst, Noel Fielding, Jeff Koons and most other modern surrealists. Salvador Dalí's manic expression and famous moustache have made him something of a cultural icon for the bizarre and surreal. He has been portrayed on film by Robert Pattinson in "Little Ashes" (2008), and by Adrien Brody in "Midnight in Paris" (2011). He was also parodied in a series of painting skits on "Captain Kangaroo" as "Salvador Silly" (played by Cosmo Allegretti) and in a "Sesame Street" muppet skit as "Salvador Dada" (an orange gold Anything Muppet performed by Jim Henson).
The Dali crater on the planet Mercury is named for him.
Listing of selected works.
Dalí produced over 1,500 paintings in his career in addition to producing illustrations for books, lithographs, designs for theatre sets and costumes, a great number of drawings, dozens of sculptures, and various other projects, including an animated short film for Disney. He also collaborated with director Jack Bond in 1965, creating a movie titled "Dalí in New York". Below is a chronological sample of important and representative work, as well as some notes on what Dalí did in particular years.
In Carlos Lozano's biography, "Sex, Surrealism, Dalí, and Me", produced with the collaboration of Clifford Thurlow, Lozano makes it clear that Dalí never stopped being a surrealist. As Dalí said of himself: "the only difference between me and the surrealists is that I am a surrealist."
The largest collections of Dalí's work are at the Dalí Theatre and Museum in Figueres, Catalonia, Spain, followed by the Salvador Dalí Museum in St. Petersburg, Florida, which contains the collection of A. Reynolds Morse & Eleanor R. Morse. It holds over 1,500 works from Dalí. Other particularly significant collections include the Reina Sofia Museum in Madrid and the Salvador Dalí Gallery in San Juan Capistrano, California. Espace Dalí in Montmartre, Paris, France, as well as the Dalí Universe in London, England, contain a large collection of his drawings and sculptures.
The unlikeliest venue for Dalí's work was the Rikers Island jail in New York City; a sketch of the Crucifixion he donated to the jail hung in the inmate dining room for 16 years before it was moved to the prison lobby for safekeeping. Ironically, the drawing was stolen from that location in March 2003 and has not been recovered.

</doc>
<doc id="40113" url="https://en.wikipedia.org/wiki?curid=40113" title="Ides of March">
Ides of March

The Ides of March (, Late Latin: ) is a day on the Roman calendar that corresponds to 15 March. It was marked by several religious observances and became notorious as the date of the assassination of Julius Caesar in 44 BC. The death of Caesar made the Ides of March a turning point in Roman history, as one of the events that marked the transition from the historical period known as the Roman Republic to the Roman Empire.
Although March "(Martius)" was the third month of the Julian calendar, in the oldest Roman calendar it was the first month of the year. The holidays observed by the Romans from the first through the Ides often reflect their origin as new year celebrations.
Ides.
The Romans did not number days of a month sequentially from the first through the last day. Instead, they counted back from three fixed points of the month: the Nones (5th or 7th, depending on the length of the month), the Ides (13th or 15th), and the Kalends (1st of the following month). The Ides occurred near the midpoint, on the 13th for most months, but on the 15th for March, May, July, and October. The Ides were supposed to be determined by the full moon, reflecting the lunar origin of the Roman calendar. On the earliest calendar, the Ides of March would have been the first full moon of the new year.
Religious observances.
The Ides of each month was sacred to Jupiter, the Romans' supreme deity. The Flamen Dialis, Jupiter's high priest, led the "Ides sheep" ("ovis Idulius") in procession along the Via Sacra to the "arx", where it was sacrificed.
In addition to the monthly sacrifice, the Ides of March was also the occasion of the Feast of Anna Perenna, a goddess of the year (Latin "annus") whose festival originally concluded the ceremonies of the new year. The day was enthusiastically celebrated among the common people with picnics, drinking, and revelry. One source from late antiquity also places the Mamuralia on the Ides of March. This observance, which has aspects of scapegoat or ancient Greek "pharmakos" ritual, involved beating an old man dressed in animal skins and perhaps driving him from the city. The ritual may have been a new year festival representing the expulsion of the old year.
In the later Imperial period, the Ides began a "holy week" of festivals for Cybele and Attis. The Ides was the day of "Canna intrat" ("The Reed enters"), when Attis was born and exposed as an infant among the reeds of a Phrygian river. He was discovered—depending on the version of the myth—by either shepherds or the goddess Cybele, who was also known as the "Magna Mater", "Great Mother". A week later, on 22 March, the day of "Arbor intrat" ("The Tree enters") commemorated the death of Attis under a pine tree. A college of priests called "tree bearers" "(dendrophoroi)" cut down a tree, suspended from it an image of Attis, and carried it to the temple of the Magna Mater with lamentations. The day was formalized as part of the official Roman calendar under Claudius. A three-day period of mourning followed, culminating with the rebirth of Attis on 25 March, the date of the vernal equinox on the Julian calendar.
Assassination of Caesar.
In modern times, the Ides of March is best known as the date on which Julius Caesar was assassinated in 44 BC. Caesar was stabbed to death at a meeting of the senate. As many as 60 conspirators, led by Brutus and Cassius, were involved. According to Plutarch, a seer had warned that harm would come to Caesar no later than the Ides of March. On his way to the Theatre of Pompey, where he would be assassinated, Caesar passed the seer and joked, "The Ides of March are come", implying that the prophecy had not been fulfilled, to which the seer replied "Aye, Caesar; but not gone." This meeting is famously dramatised in William Shakespeare's play "Julius Caesar", when Caesar is warned by the soothsayer to "beware the Ides of March." The Roman biographer Suetonius identifies the "seer" as a haruspex named Spurinna.
Caesar's death was a closing event in the crisis of the Roman Republic, and triggered the civil war that would result in the rise to sole power of his adopted heir Octavian (later known as Augustus). Writing under Augustus, Ovid portrays the murder as a sacrilege, since Caesar was also the Pontifex Maximus of Rome and a priest of Vesta. On the fourth anniversary of Caesar's death in 40 BC, after achieving a victory at the siege of Perugia, Octavian executed 300 senators and knights who had fought against him under Lucius Antonius, the brother of Mark Antony. The executions were one of a series of actions taken by Octavian to avenge Caesar's death. Suetonius and the historian Cassius Dio characterised the slaughter as a religious sacrifice, noting that it occurred on the Ides of March at the new altar to the deified Julius.

</doc>
<doc id="40114" url="https://en.wikipedia.org/wiki?curid=40114" title="Escherichia coli">
Escherichia coli

Escherichia coli (; also known as E. coli) is a Gram-negative, facultatively anaerobic, rod-shaped bacterium of the genus "Escherichia" that is commonly found in the lower intestine of warm-blooded organisms (endotherms). Most "E. coli" strains are harmless, but some serotypes can cause serious food poisoning in their hosts, and are occasionally responsible for product recalls due to food contamination. The harmless strains are part of the normal flora of the gut, and can benefit their hosts by producing vitamin K2, and preventing colonization of the intestine with pathogenic bacteria. "E. coli" is expelled into the environment within fecal matter. The bacterium grows massively in fresh fecal matter under aerobic conditions for 3 days, but its numbers decline slowly afterwards.
"E. coli" and other facultative anaerobes constitute about 0.1% of gut flora, and fecal–oral transmission is the major route through which pathogenic strains of the bacterium cause disease. Cells are able to survive outside the body for a limited amount of time, which makes them potential indicator organisms to test environmental samples for fecal contamination. A growing body of research, though, has examined environmentally persistent "E. coli" which can survive for extended periods outside of a host.
The bacterium can be grown and cultured easily and inexpensively in a laboratory setting, and has been intensively investigated for over 60 years. "E. coli" is a chemoheterotroph whose chemically defined medium must include a source of carbon and energy. Organic growth factors included in chemically defined medium used to grow "E. coli" includes glucose, ammonium phosphate, mono basic, sodium chloride, magnesium sulfate, potassium phosphate, dibasic, and water. The exact chemical composition is known for media that is considered chemically defined medium. "E. coli" is the most widely studied prokaryotic model organism, and an important species in the fields of biotechnology and microbiology, where it has served as the host organism for the majority of work with recombinant DNA. Under favorable conditions, it takes only 20 minutes to reproduce.
Biology and biochemistry.
Type and morphology.
"E. coli" is a Gram-negative, facultative anaerobic (that makes ATP by aerobic respiration if oxygen is present, but is capable of switching to fermentation or anaerobic respiration if oxygen is absent) and nonsporulating bacterium. Cells are typically rod-shaped, and are about 2.0 micrometers (μm) long and 0.25–1.0 μm in diameter, with a cell volume of 0.6–0.7 μm3.
"E. coli" stains Gram-negative because its cell wall is composed of a thin peptidoglycan layer and an outer membrane. During the staining process, "E. coli" picks up the color of the counterstain safranin and stains pink. The outer membrane surrounding the cell wall provides a barrier to certain antibiotics such that "E. coli" is not damaged by penicillin.
Strains that possess flagella are motile. The flagella have a peritrichous arrangement.
Metabolism.
"E. coli" can live on a wide variety of substrates and uses mixed-acid fermentation in anaerobic conditions, producing lactate, succinate, ethanol, acetate, and carbon dioxide. Since many pathways in mixed-acid fermentation produce hydrogen gas, these pathways require the levels of hydrogen to be low, as is the case when "E. coli" lives together with hydrogen-consuming organisms, such as methanogens or sulphate-reducing bacteria.
Culture growth.
Optimum growth of "E. coli" occurs at 37 °C (98.6 °F), but some laboratory strains can multiply at temperatures of up to 49 °C (120.2 °F). Growth can be driven by aerobic or anaerobic respiration, using a large variety of redox pairs, including the oxidation of pyruvic acid, formic acid, hydrogen, and amino acids, and the reduction of substrates such as oxygen, nitrate, fumarate, dimethyl sulfoxide, and trimethylamine N-oxide. "E. coli" is classified as a facultative anaerobe. It uses oxygen when it is present and available. It can however, continue to grow in the absence of oxygen using fermentation or anaerobic respiration. The ability to be able to continue growing in the absence of oxygen is an advantage to bacteria because their survival is increased in environments where water predominates.
Cell cycle.
The bacterial cell cycle is divided into three stages. The B period occurs between the completion of cell division and the beginning of DNA replication. The C period encompasses the time it takes to replicate the chromosomal DNA. The D period refers to the stage between the conclusion of DNA replication and the end of cell division. The doubling rate of "E. coli" is higher when more nutrients are available. However, the length of the C and D periods do not change, even when the doubling time becomes less than the sum of the C and D periods. At the fastest growth rates, replication begins before the previous round of replication has completed, resulting in multiple replication forks along the DNA and overlapping cell cycles.
Unlike eukaryotes, prokaryotes do not rely upon either changes in gene expression or changes in protein synthesis to control the cell cycle. This probably explains why they do not have similar proteins to those used by eukaryotes to control their cell cycle, such as cdk1. This has led to research on what the control mechanism is in prokaryotes. Recent evidence suggests that it may be membrane- or lipid-based.
Genetic adaptation.
"E. coli" and related bacteria possess the ability to transfer DNA via bacterial conjugation or transduction, which allows genetic material to spread horizontally through an existing population. The process of transduction, which uses the bacterial virus called a bacteriophage, is where the spread of the gene encoding for the Shiga toxin from the "Shigella" bacteria to "E. coli" helped produce , the Shiga toxin producing strain of "E. coli."
Diversity.
"Escherichia coli" encompasses an enormous population of bacteria that exhibit a very high degree of both genetic and phenotypic diversity. Genome sequencing of a large number of isolates of "E. coli" and related bacteria shows that a taxonomic reclassification would be desirable. However, this has not been done, largely due to its medical importance, and "E. coli" remains one of the most diverse bacterial species: only 20% of the genes in a typical "E. coli" genome is shared among all strains.
In fact, from the evolutionary point of view, the members of genus "Shigella" ("S. dysenteriae", "S. flexneri", "S. boydii", and "S. sonnei") should be classified as "E. coli" strains, a phenomenon termed taxa in disguise. Similarly, other strains of "E. coli" (e.g. the K-12 strain commonly used in recombinant DNA work) are sufficiently different that they would merit reclassification.
A strain is a subgroup within the species that has unique characteristics that distinguish it from other strains. These differences are often detectable only at the molecular level; however, they may result in changes to the physiology or lifecycle of the bacterium. For example, a strain may gain pathogenic capacity, the ability to use a unique carbon source, the ability to take upon a particular ecological niche, or the ability to resist antimicrobial agents. Different strains of "E. coli" are often host-specific, making it possible to determine the source of fecal contamination in environmental samples. For example, knowing which "E. coli" strains are present in a water sample allows researchers to make assumptions about whether the contamination originated from a human, another mammal, or a bird.
Serotypes.
A common subdivision system of "E. coli", but not based on evolutionary relatedness, is by serotype, which is based on major surface antigens (O antigen: part of lipopolysaccharide layer; H: flagellin; K antigen: capsule), e.g. O157:H7). It is, however, common to cite only the serogroup, i.e. the O-antigen. At present, about 190 serogroups are known. The common laboratory strain has a mutation that prevents the formation of an O-antigen and is thus not typeable.
Genome plasticity and evolution.
Like all lifeforms, new strains of "E. coli" evolve through the natural biological processes of mutation, gene duplication, and horizontal gene transfer; in particular, 18% of the genome of the laboratory strain MG1655 was horizontally acquired since the divergence from "Salmonella". "E. coli" K-12 and "E. coli" B strains are the most frequently used varieties for laboratory purposes. Some strains develop traits that can be harmful to a host animal. These virulent strains typically cause a bout of diarrhea that is unpleasant in healthy adults and is often lethal to children in the developing world. More virulent strains, such as , cause serious illness or death in the elderly, the very young, or the immunocompromised.
The genera "Escherichia" and "Salmonella" diverged around 102 million years ago (credibility interval: 57–176 mya) which coincides with the divergence of their hosts: the former being found in mammals and the latter in birds and reptiles. This was followed by a split of the escherichian ancestor into five species ("E. albertii", "E. coli", "E. fergusonii", "E. hermannii", and "E. vulneris"). The last "E. coli" ancestor split between 20 and 30 million years ago.
The long-term evolution experiments using "E. coli", begun by Richard Lenski in 1988, have allowed direct observation of major evolutionary shifts in the laboratory. In this experiment, one population of "E. coli" unexpectedly evolved the ability to aerobically metabolize citrate, which is extremely rare in "E. coli". As the inability to grow aerobically is normally used as a diagnostic criterion with which to differentiate "E. coli" from other, closely related bacteria, such as "Salmonella", this innovation may mark a speciation event observed in the laboratory.
Neotype strain.
"E. coli" is the type species of the genus ("Escherichia") and in turn "Escherichia" is the type genus of the family Enterobacteriaceae, where the family name does not stem from the genus "Enterobacter" + "i" (sic.) + "aceae", but from "enterobacterium" + "aceae" (enterobacterium being not a genus, but an alternative trivial name to enteric bacterium).
The original strain described by Escherich is believed to be lost, consequently a new type strain (neotype) was chosen as a representative: the neotype strain is U5/41T, also known under the deposit names DSM 30083, ATCC 11775, and NCTC 9001, which is pathogenic to chickens and has an O1:K1:H7 serotype. However, in most studies, either O157:H7, K-12 MG1655, or K-12 W3110 were used as a representative "E. coli". The genome of the type strain has only lately been sequenced. Particularly the use of whole genome sequences yields highly supported phylogenies. Based on such data, five subspecies of "E. coli" were distinguished.
Today, several hundred complete genomic sequences of "Escherichia" and "Shigella" species are available. The genome sequence of the type strain of "E. coli" has been added to this collection not before 2014.
Gene nomenclature.
Genes in "E. coli" are usually named by 4-letter acronyms that derive from their function (when known). For instance, recA is named after its role in homologous recombination plus the letter A. Functionally related genes are named recB, recC, recD etc. The proteins are named by uppercase acronyms, e.g. RecA, RecB, etc. When the genome of "E. coli" was sequenced, all genes were numbered (more or less) in their order on the genome and abbreviated by b numbers, such as b2819 (=recD) etc. The "b" names were created after Fred Blattner who led the genome sequence effort. Another numbering system was introduced with the sequence of another "E. coli" strain, W3110, which was sequenced in Japan and hence uses numbers starting by JW... (Japanese W3110), e.g. JW2787 (= recD). Hence, recD = b2819 = JW2787. Note, however, that most databases have their own numbering system, e.g. the EcoGene database uses EG10826 for recD. Finally, ECK numbers are specifically used for alleles in the MG1655 strain of "E. coli" K-12. Complete lists of genes and their synonyms can be obtained from databases such as EcoGene or Uniprot.
Proteomics.
Proteome.
Several studies have investigated the proteome of "E. coli". By 2006, 1,627 (38%) of the 4,237 open reading frames (ORFs) had been identified experimentally.
Interactome.
The interactome of "E. coli" has been studied by affinity purification and mass spectrometry (AP/MS) and by analyzing the binary interactions among its proteins.
Protein complexes. A 2006 study purified 4,339 proteins from cultures of strain K-12 and found interacting partners for 2,667 proteins, many of which had unknown functions at the time. A 2009 study found 5,993 interactions between proteins of the same "E. coli" strain, though these data showed little overlap with those of the 2006 publication.
Binary interactions. Rajagopala "et al." (2014) have carried out systematic yeast two-hybrid screens with most "E. coli" proteins, and found a total of 2,234 protein-protein interactions. This study also integrated genetic interactions and protein structures and mapped 458 interactions within 227 protein complexes.
Normal microbiota.
"E. coli" belongs to a group of bacteria informally known as coliforms that are found in the gastrointestinal tract of warm-blooded animals. "E. coli" normally colonizes an infant's gastrointestinal tract within 40 hours of birth, arriving with food or water or from the individuals handling the child. In the bowel, "E. coli" adheres to the mucus of the large intestine. It is the primary facultative anaerobe of the human gastrointestinal tract. (Facultative anaerobes are organisms that can grow in either the presence or absence of oxygen.) As long as these bacteria do not acquire genetic elements encoding for virulence factors, they remain benign commensals.
Therapeutic use.
Nonpathogenic "E. coli" strain Nissle 1917, also known as Mutaflor, and "E. coli" O83:K24:H31 (known as Colinfant) are used as probiotic agents in medicine, mainly for the treatment of various gastroenterological diseases, including inflammatory bowel disease.
Role in disease.
Most "E. coli" strains do not cause disease, but virulent strains can cause gastroenteritis, urinary tract infections, and neonatal meningitis. It can also be characterized by severe abdominal cramps, diarrhea that typically turns bloody within 24 hours, and sometimes fever. In rarer cases, virulent strains are also responsible for bowel necrosis (tissue death) and perforation without progressing to hemolytic-uremic syndrome, peritonitis, mastitis, septicemia, and Gram-negative pneumonia.
There is one strain, "E.coli" #0157:H7, that produces a toxin called the Shiga toxin (classified as a bioterrorist agent). This toxin causes premature destruction of the red blood cells which then clog the body’s filtering system, the kidneys, causing hemolytic-uremic syndrome (HUS). This in turn causes strokes due to small clots of blood which lodge in capillaries in the brain. This causes the body parts controlled by this region of the brain not to work properly. In addition, this strain causes the buildup of fluid (since the kidneys do not work) leading to edema around the lungs and legs and arms. This increase in fluid buildup especially around the lungs impedes the functioning of the heart, causing an increase in blood pressure.
Uropathogenic "E. coli" (UPEC) is one of the main causes of urinary tract infections. It is part of the normal flora in the gut and can be introduced in many ways. In particular for females, the direction of wiping after defecation (wiping back to front) can lead to fecal contamination of the urogenital orifices. Anal intercourse can also introduce this bacterium into the male urethra, and in switching from anal to vaginal intercourse, the male can also introduce UPEC to the female urogenital system. For more information, see the databases at the end of the article or UPEC pathogenicity.
In May 2011, one "E. coli" strain, , was the subject of a that began in Germany. Certain strains of "E. coli" are a major cause of foodborne illness. The outbreak started when several people in Germany were infected with enterohemorrhagic "E. coli" (EHEC) bacteria, leading to hemolytic-uremic syndrome (HUS), a medical emergency that requires urgent treatment. The outbreak did not only concern Germany, but also 11 other countries, including regions in North America. On 30 June 2011, the German "Bundesinstitut für Risikobewertung (BfR)" (Federal Institute for Risk Assessment, a federal institute within the German Federal Ministry of Food, Agriculture and Consumer Protection) announced that seeds of fenugreek from Egypt were likely the cause of the EHEC outbreak.
Treatment.
The mainstay of treatment is the assessment of dehydration and replacement of fluid and electrolytes. Administration of antibiotics has been shown to shorten the course of illness and duration of excretion of ETEC in adults in endemic areas and in traveller’s diarrhoea. The antibiotic used depends upon susceptibility patterns in the particular geographical region. Currently, the antibiotics of choice are fluoroquinolones or azithromycin, with an emerging role for rifaximin. Oral rifaximin, a semisynthetic rifamycin derivative, is an effective and well-tolerated antibacterial for the management of adults with non-invasive traveller’s diarrhoea. Rifaximin was significantly more effective than placebo and no less effective than ciprofloxacin in reducing the duration of diarrhoea. While rifaximin is effective in patients with E. coli-predominant traveller’s diarrhoea, it appears ineffective in patients infected with inflammatory or invasive enteropathogens.
Prevention.
Antibodies against the LT and major CFs of ETEC provide protection against LT-producing ETEC expressing homologous CFs. Oral inactivated vaccines consisting of toxin antigen and whole cells, i.e. the licensed recombinant cholera B subunit (rCTB)-WC cholera vaccine Dukoral and candidate ETEC vaccines have been developed. In different trials, the rCTB-WC cholera vaccine provided high (85–100%) short-term protection. An oral ETEC vaccine consisting of rCTB and formalininactivated E. coli bacteria expressing major CFs has been shown to be safe, immunogenic and effective against severe diarrhoea in American travellers but not against ETEC diarrhoea in young children in Egypt. A modified ETEC vaccine consisting of recombinant E. coli strains overexpressing the major CFs and a more LT-like hybrid toxoid called LCTBA, have been developed and are being tested.
Model organism in life science research.
Role in biotechnology.
Because of its long history of laboratory culture and ease of manipulation, "E. coli" plays an important role in modern biological engineering and industrial microbiology. The work of Stanley Norman Cohen and Herbert Boyer in "E. coli", using plasmids and restriction enzymes to create recombinant DNA, became a foundation of biotechnology.
"E. coli" is a very versatile host for the production of heterologous proteins, and various protein expression systems have been developed which allow the production of recombinant proteins in "E. coli". Researchers can introduce genes into the microbes using plasmids which permit high level expression of protein, and such protein may be mass-produced in industrial fermentation processes. One of the first useful applications of recombinant DNA technology was the manipulation of "E. coli" to produce human insulin.
Many proteins previously thought difficult or impossible to be expressed in "E. coli" in folded form have been successfully expressed in "E. coli". For example, proteins with multiple disulphide bonds may be produced in the periplasmic space or in the cytoplasm of mutants rendered sufficiently oxidizing to allow disulphide-bonds to form, while proteins requiring post-translational modification such as glycosylation for stability or function have been expressed using the N-linked glycosylation system of "Campylobacter jejuni" engineered into "E. coli".
Modified "E. coli" cells have been used in vaccine development, bioremediation, production of biofuels, lighting, and production of immobilised enzymes.
Model organism.
"E. coli" is frequently used as a model organism in microbiology studies. Cultivated strains (e.g. "E. coli" K12) are well-adapted to the laboratory environment, and, unlike wild-type strains, have lost their ability to thrive in the intestine. Many laboratory strains lose their ability to form biofilms. These features protect wild-type strains from antibodies and other chemical attacks, but require a large expenditure of energy and material resources.
In 1946, Joshua Lederberg and Edward Tatum first described the phenomenon known as bacterial conjugation using "E. coli" as a model bacterium, and it remains the primary model to study conjugation. "E. coli" was an integral part of the first experiments to understand phage genetics, and early researchers, such as Seymour Benzer, used "E. coli" and phage T4 to understand the topography of gene structure. Prior to Benzer's research, it was not known whether the gene was a linear structure, or if it had a branching pattern.
"E. coli" was one of the first organisms to have its genome sequenced; the complete genome of "E. coli" K12 was published by "Science" in 1997.
By evaluating the possible combination of nanotechnologies with landscape ecology, complex habitat landscapes can be generated with details at the nanoscale. On such synthetic ecosystems, evolutionary experiments with "E. coli" have been performed to study the spatial biophysics of adaptation in an island biogeography on-chip.
Studies are also being performed attempting to program "E. coli" to solve complicated mathematics problems, such as the Hamiltonian path problem.
History.
In 1885, the German-Austrian pediatrician Theodor Escherich discovered this organism in the feces of healthy individuals. He called it "Bacterium coli commune" because it is found in the colon. Early classifications of prokaryotes placed these in a handful of genera based on their shape and motility (at that time Ernst Haeckel's classification of bacteria in the kingdom Monera was in place).
"Bacterium coli" was the type species of the now invalid genus "Bacterium" when it was revealed that the former type species (""Bacterium triloculare"") was missing. Following a revision of "Bacterium", it was reclassified as "Bacillus coli" by Migula in 1895 and later reclassified in the newly created genus "Escherichia", named after its original discoverer.

</doc>
<doc id="40119" url="https://en.wikipedia.org/wiki?curid=40119" title="William Makepeace Thackeray">
William Makepeace Thackeray

William Makepeace Thackeray (; 18 July 1811 – 24 December 1863) was an English novelist of the 19th century. He is famous for his satirical works, particularly "Vanity Fair", a panoramic portrait of English society.
Biography.
Thackeray, an only child, was born in Calcutta, India, where his father, Richmond Thackeray (1 September 1781 – 13 September 1815), was secretary to the Board of Revenue in the British East India Company. His mother, Anne Becher (1792–1864), was the second daughter of Harriet Becher and John Harman Becher, who was also a secretary (writer) for the East India Company.
Richmond died in 1815, which caused Anne to send her son to England in 1816, while she remained in India. The ship on which he travelled made a short stopover at St. Helena, where the imprisoned Napoleon was pointed out to him. Once in England he was educated at schools in Southampton and Chiswick, and then at Charterhouse School, where he became a close friend of John Leech. Thackeray disliked Charterhouse, and parodied it in his fiction as "Slaughterhouse". Nevertheless, Thackeray was honoured in the Charterhouse Chapel with a monument after his death. Illness in his last year there, during which he reportedly grew to his full height of six foot three, postponed his matriculation at Trinity College, Cambridge, until February 1829. Never too keen on academic studies, Thackeray left Cambridge in 1830, but some of his earliest published writing appeared in two university periodicals, "The Snob" and "The Gownsman".
Thackeray then travelled for some time on the continent, visiting Paris and Weimar, where he met Goethe. He returned to England and began to study law at the Middle Temple, but soon gave that up. On reaching the age of 21 he came into his inheritance from his father, but he squandered much of it on gambling and on funding two unsuccessful newspapers, "The National Standard" and "The Constitutional", for which he had hoped to write. He also lost a good part of his fortune in the collapse of two Indian banks. Forced to consider a profession to support himself, he turned first to art, which he studied in Paris, but did not pursue it, except in later years as the illustrator of some of his own novels and other writings.
Thackeray's years of semi-idleness ended after he married, on 20 August 1836, Isabella Gethin Shawe (1816–1893), second daughter of Isabella Creagh Shawe and Matthew Shawe, a colonel who had died after distinguished service, primarily in India. The Thackerays had three children, all girls: Anne Isabella (1837–1919), Jane (who died at eight months old) and Harriet Marian (1840–1875). 
Thackeray now began "writing for his life", as he put it, turning to journalism in an effort to support his young family. He primarily worked for "Fraser's Magazine", a sharp-witted and sharp-tongued conservative publication for which he produced art criticism, short fictional sketches, and two longer fictional works, "Catherine" and "The Luck of Barry Lyndon". Between 1837 and 1840 he also reviewed books for "The Times". He was also a regular contributor to "The Morning Chronicle" and "The Foreign Quarterly Review". Later, through his connection to the illustrator John Leech, he began writing for the newly created magazine "Punch", in which he published "The Snob Papers", later collected as "The Book of Snobs". This work popularised the modern meaning of the word "snob". Thackeray was a regular contributor to "Punch" between 1843 and 1854.
Tragedy struck in Thackeray's personal life as his wife, Isabella, succumbed to depression after the birth of their third child, in 1840. Finding that he could get no work done at home, he spent more and more time away until September 1840, when he realised how grave his wife's condition was. Struck by guilt, he set out with his wife to Ireland. During the crossing she threw herself from a water-closet into the sea, but she was pulled from the waters. They fled back home after a four-week battle with her mother. From November 1840 to February 1842 Isabella was in and out of professional care, as her condition waxed and waned.
She eventually deteriorated into a permanent state of detachment from reality. Thackeray desperately sought cures for her, but nothing worked, and she ended up in two different asylums in or near Paris until 1845, after which Thackeray took her back to England, where he installed her with a Mrs Bakewell at Camberwell. Isabella outlived her husband by 30 years, in the end being cared for by a family named Thompson in Leigh-on-Sea at Southend until her death in 1894. After his wife's illness Thackeray became a "de facto" widower, never establishing another permanent relationship. He did pursue other women, however, in particular Mrs Jane Brookfield and Sally Baxter. In 1851 Mr Brookfield barred Thackeray from further visits to or correspondence with Jane. Baxter, an American twenty years Thackeray's junior whom he met during a lecture tour in New York City in 1852, married another man in 1855.
In the early 1840s Thackeray had some success with two travel books, "The Paris Sketch Book" and "The Irish Sketch Book", the latter marked by hostility to Irish Catholics. However, as the book appealed to British prejudices, Thackeray was given the job of being "Punch"’s Irish expert, often under the pseudonym Hibernis Hibernior. It was Thackeray, in other words, who was chiefly responsible for "Punch"'s notoriously hostile and condescending depictions of the Irish during An Gorta Mór (1845–51).
Thackeray achieved more recognition with his "Snob Papers" (serialised 1846/7, published in book form in 1848), but the work that really established his fame was the novel "Vanity Fair", which first appeared in serialised instalments beginning in January 1847. Even before "Vanity Fair" completed its serial run Thackeray had become a celebrity, sought after by the very lords and ladies whom he satirised. They hailed him as the equal of Dickens.
He remained "at the top of the tree," as he put it, for the rest of his life, during which he produced several large novels, notably "Pendennis", "The Newcomes" and "The History of Henry Esmond", despite various illnesses, including a near-fatal one that struck him in 1849 in the middle of writing "Pendennis". He twice visited the United States on lecture tours during this period. Thackeray also gave lectures in London on the English humorists of the eighteenth century, and on the first four Hanoverian monarchs. The latter series was published in book form as "The Four Georges". 
In Oxford he stood unsuccessfully as an independent for Parliament. He was narrowly beaten by Cardwell, who received 1,070 votes, as against 1,005 for Thackeray.
In 1860 Thackeray became editor of the newly established "Cornhill Magazine", but he was never comfortable in the role, preferring to contribute to the magazine as the writer of a column called "Roundabout Papers".
Thackeray's health worsened during the 1850s and he was plagued by a recurring stricture of the urethra that laid him up for days at a time. He also felt that he had lost much of his creative impetus. He worsened matters by excessive eating and drinking, and avoiding exercise, though he enjoyed horseback-riding (he kept a horse). He has been described as "the greatest literary glutton who ever lived". His main activity apart from writing was "guttling and gorging". He could not break his addiction to spicy peppers, further ruining his digestion. On 23 December 1863, after returning from dining out and before dressing for bed, he suffered a stroke. He was found dead in his bed the following morning. His death at the age of fifty-two was entirely unexpected, and shocked his family, his friends and the reading public. An estimated 7,000 people attended his funeral at Kensington Gardens. He was buried on 29 December at Kensal Green Cemetery, and a memorial bust sculpted by Marochetti can be found in Westminster Abbey.
Works.
Thackeray began as a satirist and parodist, writing works that displayed a sneaking fondness for roguish upstarts such as Becky Sharp in "Vanity Fair", and the title characters of "The Luck of Barry Lyndon" and "Catherine". In his earliest works, written under such pseudonyms as Charles James Yellowplush, Michael Angelo Titmarsh and George Savage Fitz-Boodle, he tended towards savagery in his attacks on high society, military prowess, the institution of marriage and hypocrisy.
One of his earliest works, "Timbuctoo" (1829), contains a burlesque upon the subject set for the Cambridge Chancellor's Medal for English Verse (the contest was won by Tennyson with "Timbuctoo"). Thackeray's writing career really began with a series of satirical sketches now usually known as "The Yellowplush Papers", which appeared in "Fraser's Magazine" beginning in 1837. These were adapted for BBC Radio 4 in 2009, with Adam Buxton playing Charles Yellowplush.
Between May 1839 and February 1840 "Fraser's" published the work sometimes considered Thackeray's first novel, "Catherine". Originally intended as a satire of the Newgate school of crime fiction, it ended up being more of a picaresque tale. He also began work, never finished, on the novel later published as "A Shabby Genteel Story".
In "The Luck of Barry Lyndon", a novel serialised in "Fraser's" in 1844, Thackeray explored the situation of an outsider trying to achieve status in high society, a theme he developed more successfully in "Vanity Fair" with the character of Becky Sharp, the artist's daughter who rises nearly to the heights by manipulating the other characters.
Thackeray is probably best known now for "Vanity Fair". In contrast, his large novels from the period after "Vanity Fair", which were once described by Henry James as examples of "loose baggy monsters", have largely faded from view, perhaps because they reflect a mellowing in Thackeray, who had become so successful with his satires on society that he seemed to lose his zest for attacking it. These later works include "Pendennis", a "Bildungsroman" depicting the coming of age of Arthur Pendennis, an alter ego of Thackeray, who also features as the narrator of two later novels, "The Newcomes" and "The Adventures of Philip". "The Newcomes" is noteworthy for its critical portrayal of the "marriage market," while "Philip" is known for its semi-autobiographical depiction of Thackeray's early life, in which he partially regains some of his early satirical power.
Also notable among the later novels is "The History of Henry Esmond", in which Thackeray tried to write a novel in the style of the eighteenth century, a period that held great appeal for him. Not only "Esmond" but also "Barry Lyndon" and "Catherine" are set in that period, as is the sequel to "Esmond", "The Virginians", which takes place in North America and includes George Washington as a character who nearly kills one of the protagonists in a duel.
Family.
Parents.
Thackeray's father, Richmond Thackeray, was born at South Mimms and went to India in 1798 at age sixteen as a writer (civil servant) with the East India Company. Richmond fathered a daughter, Sarah Redfield, in 1804 with Charlotte Sophia Rudd, his possibly Eurasian mistress, and both mother and daughter were named in his will. Such liaisons were common among gentlemen of the East India Company, and it formed no bar to his later courting and marrying William's mother.
Thackeray's mother, Anne Becher (born 1792), was "one of the reigning beauties of the day" and a daughter of John Harmon Becher, Collector of the South 24 Parganas district (d. Calcutta, 1800), of an old Bengal civilian family "noted for the tenderness of its women". Anne Becher, her sister Harriet and their widowed mother, also Harriet, had been sent back to India by her authoritarian guardian grandmother, Ann Becher, in 1809 on the "Earl Howe". Anne's grandmother had told her that the man she loved, Henry Carmichael-Smyth, an ensign in the Bengal Engineers whom she met at an Assembly Ball in 1807 in Bath, had died, while he was told that Anne was no longer interested in him. Neither of these assertions was true. Though Carmichael-Smyth was from a distinguished Scottish military family, Anne's grandmother went to extreme lengths to prevent their marriage. Surviving family letters state that she wanted a better match for her granddaughter.
Anne Becher and Richmond Thackeray were married in Calcutta on 13 October 1810. Their only child, William, was born on 18 July 1811. There is a fine miniature portrait of Anne Becher Thackeray and William Makepeace Thackeray, aged about two, done in Madras by George Chinnery c. 1813.
Anne's family's deception was unexpectedly revealed in 1812, when Richmond Thackeray unwittingly invited the supposedly dead Carmichael-Smyth to dinner. Five years later, after Richmond had died of a fever on 13 September 1815, Anne married Henry Carmichael-Smyth, on 13 March 1817. The couple moved to England in 1820, after having sent William off to school there more than three years earlier. The separation from his mother had a traumatic effect on the young Thackeray, which he discussed in his essay "On Letts's Diary" in "The Roundabout Papers".
Descendants.
Thackeray is an ancestor of the British financier Ryan Williams, and is the great-great-great-grandfather of the British comedian Al Murray.
Reputation and legacy.
During the Victorian era Thackeray was ranked second only to Charles Dickens, but he is now much less widely read and is known almost exclusively for "Vanity Fair", which has become a fixture in university courses, and has been repeatedly adapted for the cinema and television.
In Thackeray's own day some commentators, such as Anthony Trollope, ranked his "History of Henry Esmond" as his greatest work, perhaps because it expressed Victorian values of duty and earnestness, as did some of his other later novels. It is perhaps for this reason that they have not survived as well as "Vanity Fair", which satirises those values.
Thackeray saw himself as writing in the realistic tradition, and distinguished his work from the exaggerations and sentimentality of Dickens. Some later commentators have accepted this self-evaluation and seen him as a realist, but others note his inclination to use eighteenth-century narrative techniques, such as digressions and direct addresses to the reader, and argue that through them he frequently disrupts the illusion of reality. The school of Henry James, with its emphasis on maintaining that illusion, marked a break with Thackeray's techniques.
In 1887 the Royal Society of Arts unveiled a blue plaque to commemorate Thackeray at the house at 2 Palace Green, London, that had been built for him in the 1860s. It is now the location of the Israeli Embassy.
Thackeray's former home in Tunbridge Wells, Kent, is now a restaurant named after the author.

</doc>
<doc id="40121" url="https://en.wikipedia.org/wiki?curid=40121" title="Vanity Fair (novel)">
Vanity Fair (novel)

Vanity Fair: A Novel without a Hero is a novel by English author William Makepeace Thackeray, first published in 1847–48, satirising society in early 19th-century Britain. It follows the lives of two women, Becky Sharp and Amelia Sedley, amid their friends and family. The novel is now considered a classic, and has inspired several film adaptations. In 2003, "Vanity Fair" was listed at #122 on the BBC's The Big Read poll of the UK's best-loved books.
Title.
The book's title comes from John Bunyan's allegorical story "The Pilgrim's Progress", first published in 1678 and still widely read at the time of Thackeray's novel. In that work, "Vanity Fair" refers to a stop along the pilgrim's route: a never-ending fair held in a town called Vanity, which is meant to represent man's sinful attachment to worldly things.
Plot summary.
Rebecca Sharp ("Becky") is a strong-willed, cunning, moneyless, young woman determined to make her way in society. After leaving school, Becky stays with Amelia Sedley ("Emmy"), who is a good-natured, simple-minded young girl, of a wealthy City family. There, Becky meets the dashing and self-obsessed Captain George Osborne (Amelia's betrothed) and Amelia's brother Joseph ("Jos") Sedley, a clumsy and vainglorious but rich civil servant home from the East India Company. Hoping to marry Sedley, the richest young man she has met, Becky entices him, but she fails. George Osborne's friend Captain William Dobbin loves Amelia, but only wishes her happiness, which is centred on George.
Becky Sharp says farewell to the Sedley family and enters the service of the crude and profligate baronet Sir Pitt Crawley, who has engaged her as a governess to his daughters. Her behaviour at Sir Pitt's house gains his favour, and after the premature death of his second wife, he proposes marriage to her. However he finds that she has secretly married his second son, Captain Rawdon Crawley. Sir Pitt's elder half sister, the spinster Miss Crawley, is very rich, having inherited her mother's fortune, and the whole Crawley family compete for her favour so she will bequeath them her wealth. Initially her favourite is Rawdon Crawley. But his marriage with Becky enrages her. First she favours the family of Sir Pitt's brother, but when she dies, she has left her money to Sir Pitt's oldest son, also called Pitt.
Amelia's father, John Sedley, becomes bankrupt. George's rich father forbids George to marry Amelia, who is now poor. Dobbin persuades George to marry Amelia, and George is consequently disinherited. News arrives that Napoleon has escaped from Elba, so George Osborne, William Dobbin and Rawdon Crawley are deployed to Brussels, accompanied by Amelia and Becky, and Amelia's brother, Jos. George is embarrassed by the vulgarity of Mrs. Major O'Dowd, the wife of the head of the regiment. Already, the newly wedded Osborne is growing tired of Amelia, and he becomes increasingly attracted to Becky, which makes Amelia jealous and unhappy. He is also losing money to Rawdon at cards and billiards. At a ball in Brussels, George gives Becky a note inviting her to run away with him. But then the army have marching orders to the Battle of Waterloo, and George spends a tender night with Amelia and leaves. The noise of battle horrifies Amelia, and she is comforted by the brisk but kind Mrs. O'Dowd. Becky is indifferent and makes plans for the outcome. She also makes a profit selling her carriage and horses at inflated prices to Jos, seeking to flee Brussels.
George Osborne dies at Waterloo, while Dobbin and Rawdon survive. Amelia bears George a posthumous son, also named George. She returns to live in genteel poverty with her parents, spending her life in memory of her husband and care of her son. Dobbin pays for a small annuity for Amelia and expresses his love for her by small kindnesses toward her and her son. She is too much in love with her husband's memory to return Dobbin's love. Saddened, he goes with his regiment to India for many years.
Becky also has a son, named Rawdon after his father. Becky is a cold, distant mother, although Rawdon loves his son. Becky continues her ascent first in post-war Paris and then in London where she is patronised by the rich and powerful Marquis of Steyne. She is eventually presented at court to the Prince Regent. During this time, the elderly Sir Pitt Crawley dies, and is succeeded by his son Pitt, who had married Lady Jane Sheepshanks, Lord Southdown's third daughter. Becky is on good terms with Pitt and Jane originally, but Jane is disgusted by Becky's attitude to her son, and jealous of Becky's relationship with Pitt.
Becky and Rawdon appear to be financially successful, but they have no money and live on credit, even if this ruins those who trust them such as their landlord, an old servant of the Crawley family. The Marquis of Steyne gives Becky money, as well as other gifts.
At the summit of their social success, Rawdon is arrested for debt. Becky does not bail him out, so he applies to his brother's wife, Lady Jane. When he returns home, he finds Becky and Steyne there, and assumes (perhaps rightly) that they are having an affair. He also finds the money that Steyne has given her. He leaves Becky, and expects Steyne to challenge him to a duel. Instead Steyne arranges for Rawdon to be made Governor of Coventry Island, a pest-ridden location. Becky, having lost both husband and credibility, leaves England and wanders the continent, leaving her son in the care of Pitt Crawley and Lady Jane.
As Amelia's adored son George grows up, his grandfather Mr Osborne relents towards him (though not towards Amelia) and takes him from his impoverished mother, who knows the rich old man will give him a better start in life than she could manage. After twelve years abroad, both Joseph Sedley and Dobbin return. Dobbin professes his unchanged love to Amelia. Amelia is affectionate, but she cannot forget the memory of her dead husband. Dobbin mediates a reconciliation between Amelia and her father-in-law, who dies soon after. He had amended his will, bequeathing young George half his large fortune and Amelia a generous annuity.
After the death of Mr Osborne, Amelia, Jos, George and Dobbin go to Germany, where they encounter the destitute Becky. Becky has fallen in life. She is drinking heavily, gambles, and spends time with card sharps and con artists. Becky enchants Jos Sedley all over again, and Amelia is persuaded to let Becky join them. Dobbin forbids this, and reminds Amelia of her jealousy of Becky with her husband. Amelia feels that this dishonours the memory of her dead and revered husband, and this leads to a complete breach between her and Dobbin. Dobbin leaves the group and rejoins his regiment, while Becky remains with the group.
However, Becky has decided that Amelia should marry Dobbin, even though she knows Dobbin is her enemy. Becky shows Amelia George's note, kept all this time from the eve of the Battle of Waterloo, and Amelia finally realises that George was not the perfect man she always thought, and that she has rejected a better man, Dobbin. Amelia and Dobbin are reconciled and return to England. Becky and Jos stay in Europe. Jos dies, possibly suspiciously, after signing a portion of his money to Becky as life insurance, setting her up with an income. She returns to England, and manages a respectable life, although all her previous friends refuse to acknowledge her.
Characters.
Amelia Sedley.
Amelia is good-natured but passive and naïve. Not very beautiful, she is frequently ignored by men and women, but is well-liked by most men who get to know her because of her personality. Her popularity is often resented by other women. She marries George Osborne against his father's wishes, and is devoted to him despite his neglect of her and his flirtation with Becky. After George dies in the Battle of Waterloo she brings up little George alone while living with her parents. She is completely dominated by her spendthrift father, who, it is revealed, sells the annuity Jos had provided in order to finance one of failing investment schemes and by her increasingly peevish mother.
After George Osborne's death Amelia becomes obsessed with her son and the memory of her husband. She ignores William Dobbin, who courts her for years, and treats him shabbily until he leaves. Only when Becky shows her George's letter to her is Amelia able to move on, though she informs Becky that she has already written to Dobbin to ask him to come back. She eventually marries Dobbin.
Becky Sharp (Rebecca).
The anti-heroine, and Amelia's opposite, is an intelligent young woman with a gift for satire. She is described as a short sandy haired girl who has green eyes and a great deal of wit. Fluent in both French and English, Becky has a beautiful singing voice, plays the piano, and shows great talent as an actress. She is also completely amoral and without conscience. She does not seem to have the ability to get attached to other people, and lies easily and intelligently to get her way. She is extremely manipulative and, after the first few chapters and her failure to attract Jos Sedley, is not shown as being particularly sincere.
Never having known financial or social security even as a child, Becky desires it above all things. Nearly everything she does is with the intention of securing a stable position for herself, or herself and her husband after she and Rawdon are married. She advances Rawdon's interests tirelessly, flirting with men such as General Tufto and the Marquis of Steyne in order to get him promoted. She also uses her feminine wiles to distract men at card parties while Rawdon cheats them blind.
Marrying Rawdon Crawley in secret was a mistake, as was running off instead of begging Miss Crawley's forgiveness. She also fails to manipulate Miss Crawley through Rawdon so as to obtain an inheritance. Although Becky manipulates men very easily, she does not even try to cultivate the friendship of most women. Lady Jane, the Dobbin sisters, and Lady Steyne see right through her. Amelia and (initially) Miss Crawley are exceptions to the rule.
Rawdon Crawley.
Rawdon, the younger of the two Crawley sons, is an empty-headed cavalry officer who is his wealthy aunt's favourite until he marries Becky Sharp, who is of a far lower class. He permanently alienates his aunt, who leaves her estate to Rawdon's elder brother Sir Pitt instead. Sir Pitt has by this time inherited their father's estate, leaving Rawdon destitute.
The well-meaning Rawdon does have a few talents in life, most of them having to do with gambling and duelling. He is very good at cards and billiards, and although he does not always win he is able to earn cash by betting against less talented gamblers. He is heavily indebted throughout most of the book, not so much for his own expenses as for Becky's. Not particularly talented as a military officer, he is content to let Becky manage his career.
Although Rawdon knows Becky is attractive to men, he believes her reputation is spotless even though she is widely suspected of romantic intrigue with General Tufto and other powerful men. Nobody dares to suggest otherwise to Rawdon because of his temper and his reputation for duelling. Yet other people, particularly the Marquis of Steyne, find it impossible to believe that Crawley is unaware of Becky's tricks. Steyne in particular believes Rawdon is fully aware Becky is prostituting herself, and believes Rawdon is going along with the charade in the hope of financial gain.
After Rawdon finds out the truth and leaves Becky for an assignment overseas, he leaves his son to be brought up by his brother Sir Pitt and his wife Lady Jane. While overseas, Rawdon dies of Malaria.
Sir Pitt Crawley, Baronet.
Rawdon Crawley's elder brother inherits the Crawley estate from his elderly father, and he also inherits from his wealthy aunt, Miss Crawley. Sir Pitt is very religious and has political aspirations, although not many people appreciate his intelligence or wisdom because there's not much there to appreciate. Somewhat pedantic and conservative, Sir Pitt does nothing to help Rawdon or Becky even when they fall on hard times. This is chiefly due to the influence of his wife Lady Jane who dislikes Becky because of her callous treatment of her son, and also because Becky repaid Lady Jane's earlier kindness by patronizing her and flirting with Sir Pitt.
Miss Matilda Crawley.
The elderly Miss Crawley is everyone's favourite wealthy aunt. Sir Pitt and Rawdon both dote on her, although Rawdon is her favourite nephew and sole heir until he marries Becky. While Miss Crawley likes Becky and keeps her around to entertain her with sarcasm and wit, and while she loves scandal and particularly stories of unwise marriage, she does not want scandal or unwise marriage in her family.
A substantial part of the early section of the book deals with the efforts the Crawleys make to kowtow to Miss Crawley in the hope of receiving a big inheritance.
George Osborne.
George Osborne, his father, and his two sisters are close to the Sedley family until Mr. Sedley (the father of Jos and Amelia) goes bankrupt following some ill-advised speculation. Since George and Amelia were raised in close company and were childhood sweethearts, George defies his father in order to marry Amelia. Before father and son can be reconciled, George is killed at the battle of Waterloo, leaving the pregnant Amelia to carry on as well as she can.
Raised to be a selfish, vain, profligate spender, handsome and self-obsessed, George squanders the last of the money he receives from his father and sets nothing aside to help support Amelia. After marrying Amelia, he finds after a couple of weeks that he is bored. He flirts with Becky quite seriously and is reconciled to Amelia only a short time before he is killed in battle.
William Dobbin.
The best friend of George Osborne, William Dobbin is tall, ungainly, and not particularly handsome. He is a few years older than George but has been friends with him since his school days even though Dobbin's father is a fig-merchant and the Osbornes belong to the genteel class and have become independently wealthy. He defends George and is blind to his faults in many ways although he tries to force George to do the right thing. He pushes George to keep his promise to marry Amelia even though Dobbin is in love with Amelia himself. After George is killed, Dobbin puts together an annuity to help support Amelia, ostensibly with the help of George's fellow officers.
Later, Dobbin discreetly does what he can to help support Amelia and also her son George. He allows Amelia to continue with her obsession over George and does not correct her erroneous beliefs about him. He hangs about for years, either pining away over her while serving in India or waiting on her in person, allowing her to take advantage of his good nature. After Amelia finally chooses Becky's friendship over his during their stay in Germany, Dobbin leaves in disgust. He returns when Amelia writes to him and admits her feelings for him, marries her (despite having lost much of his passion for her), and has a daughter whom he loves deeply.
Joseph Sedley.
Amelia's older brother, Joseph "Jos" Sedley, is a "nabob", who made a respectable fortune as a collector in India. Obese and self-important but very shy and insecure, he is attracted to Becky Sharp but circumstances prevent him from proposing. He never marries, but when he meets Becky again he is easily manipulated into falling in love with her. Jos is not a courageous or intelligent man, displaying his cowardice at the Battle of Waterloo by trying to flee and purchasing both of Becky's overpriced horses. Becky ensnares him again near the end of the book and, it is hinted, murders him for his life insurance.
Publication history.
Like many novels of the time, "Vanity Fair" was published as a serial before being sold in book form; it was printed in 20 monthly parts between January 1847 and July 1848. As was standard practice, the last part was a "double number" containing parts 19 and 20.
The parts resembled pamphlets, and contained the text of several chapters between outer pages of steel-plate engravings and advertising. Woodcut engravings, which could be set along with normal moveable type, appeared within the text. The same engraved illustration appeared on the canary-yellow cover of each monthly part; this colour became Thackeray's signature, as a light blue-green was Dickens', allowing passers-by to notice a new Thackeray number in a bookstall from a distance. "Vanity Fair" was the first work that Thackeray published under his own name, and was extremely well received at the time. The original monthly numbers and later bound version featured Thackeray's own illustrations, which at times provided plot hints or symbolically freighted images (a major character shown as a man-eating mermaid, for instance) to which the text does not explicitly refer. Most modern editions either do not reproduce all the illustrations, or reproduce them so badly that much detail is lost.
Thackeray meant the book to be not only entertaining but also instructive, an intention demonstrated through the book's narration and through Thackeray's private correspondence. The novel is considered a classic of English literature, though some critics claim that it has structural problems; Thackeray sometimes lost track of the huge scope of his work, mixing up characters' names and minor plot details. The number of allusions and references it contains can make it difficult for modern readers to follow.
Literary significance and criticism.
Contemporary critics.
Even before the last part of the serial was published, critics hailed the work as a literary treasure. Although the critics were superlative in their praise, some expressed disappointment at the unremittingly dark portrayal of human nature, fearing Thackeray had taken his dismal metaphor too far. In response to these critics, Thackeray explained that he saw people for the most part as "abominably foolish and selfish". The unhappy ending was intended to inspire readers to look inward at their own shortcomings.
Theorists.
The subtitle, "A Novel without a Hero", is apt because the characters are all flawed to a greater or lesser degree; even the most sympathetic have weaknesses, for example Captain Dobbin, who is prone to vanity and melancholy. The human weaknesses Thackeray illustrates are mostly to do with greed, idleness, and snobbery, and the scheming, deceit and hypocrisy which mask them. None of the characters are wholly evil, although Becky's psychopathic tendencies make her come pretty close. However, even Becky, who is amoral and cunning, is thrown on her own resources by poverty and its stigma. (She is the orphaned daughter of a poor artist and an opera dancer.) Thackeray's tendency to highlight faults in all of his characters displays his desire for a greater level of realism in his fiction compared to the rather unlikely or idealised people in many contemporary novels.
The novel is a satire of society as a whole, characterised by hypocrisy and opportunism, but it is not a reforming novel; there is no suggestion that social or political changes, or greater piety and moral reformism could improve the nature of society. It thus paints a fairly bleak view of the human condition. This bleak portrait is continued with Thackeray's own role as an omniscient narrator, one of the writers best known for using the technique. He continually offers asides about his characters and compares them to actors and puppets, but his scorn goes even as far as his readers; accusing all who may be interested in such "Vanity Fairs" as being either "of a lazy, or a benevolent, or a sarcastic mood". As Lord David Cecil remarked, "Thackeray liked people, and for the most part he thought them well-intentioned. But he also saw very clearly that they were all in some degree weak and vain, self-absorbed and self-deceived."
The work is often compared — for instance by John Carey — to the other great historical novel of the Napoleonic wars, Tolstoy's "War and Peace". While Tolstoy's work has a greater emphasis on the historical detail and the effect the war has upon his protagonists, Thackeray instead uses the conflict as a backdrop to the lives of his characters. The momentous events on the continent do not always have an equally important influence on the behaviors of Thackeray's characters. Rather their faults tend to compound over time. This is in contrast to the redemptive power conflict has on the characters in "War and Peace". For Thackeray, the Napoleonic wars as a whole can be thought of as one more of the vanities expressed in the title.
In the original illustrations, which were done by Thackeray, Becky is shown behind a curtain when Jos dies, with a vial in her hand; the picture is labelled "Becky's second appearance in the character of Clytemnestra" (she had played Clytemnestra during charades at a party earlier in the book). Joseph's death appears to have made her fortune. The suggestion near the end of the work that Becky may have killed Jos is argued against by John Sutherland. Although Becky is portrayed as having a highly dubious moral sense, the idea that she would commit premeditated murder is quite a step forward for the character. Thackeray was a fierce critic of the crime fiction popular at the time, particularly that of Edward Bulwer-Lytton. These lurid and sensationalist accounts—known as "Newgate novels"—took their inspiration, and sometimes entire stories, from the pages of "The Newgate Calendar". What Thackeray principally objected to was the glorification of a criminal's deeds; it therefore seems strange that he would have depicted Becky as such a villainess. His intent may have been to entrap the Victorian reader with their own prejudices and make them think the worst of Becky Sharp even when they have no proof of her actions. The trio of lawyers she gets to defend her from the claims, Burke, Thurtell, and Hayes, are named after prominent murderers of the time, although this may have been a tease or further commentary aimed at the legal profession.
Though Thackeray does not settle definitively whether Becky murders Jos, such a development could be seen as in keeping with the overall trend of character development in the novel. The tone of "Vanity Fair" seems to darken as the book goes on. At the novel's beginning, Becky Sharp is a bright girl with an eye to improving her lot through marrying up the social scale; though she is thoroughly unsentimental, she is nonetheless portrayed as being a good friend to Amelia. By the novel's end she has become an adulteress and is suspected of being a murderess. Amelia begins as a warm-hearted and friendly girl, though sentimental and naive, but by the story's end she is portrayed as vacuous and shallow. Dobbin's infatuation with Amelia is a theme which unifies the novel and one which many have compared to Thackeray's unrequited love for a friend's wife (Jane Brookfield). Dobbin appears first as loyal and magnanimous, if unaware of his own worth; by the end of the story he is presented as a tragic fool, a prisoner of his own sense of duty who knows he is wasting his gifts on Amelia but is unable to live without her. Whether Thackeray intended this shift in tone when he began writing, or whether it developed over the course of the work's composition, is a question that cannot be settled. Regardless of its provenance, the novel's increasingly grim outlook can take readers aback, as characters whom Thackeray—and the reader—at first hold in sympathy are shown to be unworthy of such regard.
It has been claimed that the character of Becky Sharp is based in part on Thackeray's maternal grandmother Harriet Becher, but according to Peter Shillingsburg she is said to have been the model for Miss Crawley. She abandoned her husband and children when she eloped with Captain Charles Christie. In 1806, shortly after the death of Christie and her husband, she married Edward Butler, another army officer. Thackeray lived with his grandmother in Paris in the 1830s and again in the 1840s.
Film, television and radio adaptations.
The book has inspired a number of adaptations:

</doc>
<doc id="40124" url="https://en.wikipedia.org/wiki?curid=40124" title="Acetic acid bacteria">
Acetic acid bacteria

Acetic acid bacteria (AAB) are a group of gram-negative bacteria which oxidize sugars or ethanol and produce acetic acid during fermentation. The acetic acid bacteria consist of 10 genera in the family "Acetobacteraceae". Several species of acetic acid bacteria are used in industry for production of certain foods and chemicals.
Characteristics.
All acetic acid bacteria are rod-shaped and obligate aerobes.
Occurrence.
Acetic acid bacteria are airborne and are ubiquitous in nature. They are actively present in environments where ethanol is being formed as a result of fermentation of sugars. They can be isolated from the nectar of flowers and from damaged fruit. Other good sources are fresh apple cider and unpasteurized beer that has not been filter sterilized. In these liquids, they grow as a surface film due to their aerobic nature and active motility. Fruit flies or vinegar eels are considered as a common vector in propagating acetic acid bacteria in nature.
Suppression.
The growth of "Acetobacter" in wine can be suppressed through effective sanitation, by complete exclusion of air from wine in storage, and by the use of moderate amounts of sulfur dioxide in the wine as a preservative.
Metabolism.
Vinegar is produced when acetic acid bacteria act on alcoholic beverages such as wine.
Some genera, such as "Acetobacter", can oxidize ethanol to carbon dioxide and water using Krebs cycle enzymes. Other genera, such as "Gluconobacter", do not oxidize ethanol, as they do not have a full set of Krebs cycle enzymes.
As these bacteria produce acid, they are usually acid-tolerant, growing well below pH 5.0, although the pH optimum for growth is 5.4-6.3.
One species of "Acetobacter", "Acetobacter xylinum", is able to synthesize cellulose, something normally done only by plants.
Genus "Acetobacter".
"Acetobacter" is a genus of acetic acid bacteria characterized by the ability to convert ethanol to acetic acid in the presence of oxygen. Several species are in this genus, and other bacteria are capable of forming acetic acid under various conditions, but all of the "Acetobacter" species are known by this characteristic ability.
"Acetobacter" is of particular importance commercially, because some species are used in the production of vinegar (intentionally converting the ethanol in wine to acetic acid), and they can destroy wine which they infect by producing excessive amounts of acetic acid or ethyl acetate, both of which can render the wine unpalatable. "Acetobacter" species are also used to intentionally acidify beer during long maturation periods in the production of traditional Flemish sour ales.
"Acetobacter" species can be easily distinguished in the laboratory by the growth of colonies on a medium containing about 7% ethanol and enough calcium carbonate to render it partially opaque. When "Acetobacter" colonies form enough acetic acid from the ethanol, the calcium carbonate around the colonies dissolves, forming a very distinct clear zone.

</doc>
<doc id="40127" url="https://en.wikipedia.org/wiki?curid=40127" title="Arthrobacter">
Arthrobacter

Arthrobacter (from the Greek, "jointed small stick”) is a genus of bacteria that is commonly found in soil. All species in this genus are Gram-positive obligate aerobes that are rods during exponential growth and cocci in their stationary phase.
Colonies of "Arthrobacter" have a greenish metallic center on mineral salts pyridone broth incubated at . This genus is distinctive because of its unusual habit of "snapping division" in which the outer bacterial cell wall ruptures at a joint (hence its name). Microbiologists refer to the type of cell division in which rods break into cocci as reversion. Under the microscope, these dividing cells appear as chevrons ("V" shapes). Other notable characteristics are that it can use pyridone as its sole carbon source, and that its cocci are resistant to desiccation and starvation.
In a bioprocess, one requires two important things: cells and media.
The production of L-glutamate can utilise a large variety of bacterial strains, from many different genera and type. In the past, bacteria from the Brevibacterium, Arthrobacter, Microbacterium and Corynebacterium genera have been exploited for this purpose. The most commonly-used bacterial strain today, however, is Corynebacterium glutamicum, previously known as Micrococcus glutamicum. As a non-pathogenic coryneform bacterium, C. glutamicum is a popular choice of bacteria for several other amino acids as well.
As for growth media, the choices are many. A major concern of large-scale manufacturers is the cost of the media, and so they prefer to use sugar sources such as cane or beet molasses, starch hydrolysates from corn or cassava tubers, or even tapioca. The choice of sugar source essentially depends on whatever is most readily available. Generally, a manufacturer will use a sugar source from a regional plant source. Along with sugar, ammonia and ammonium salts are added as a nitrogen source. The vitamins, minerals, and some other types of nutrients can be easily and cheaply provided by adding corn steep liquour.
One species, "A. crystallopoietes", has been shown to reduce hexavalent chromium levels in contaminated soil, suggesting that it may be useful in bioremediation.
"Arthrobacter chlorophenolicus" sp. nov., a species capable of degrading high concentrations of 4-chlorophenol, may also be useful in bioremediation. "Arthrobacter" sp. strain R1 (American Type Culture Collection strain number 49987) has been shown to grow on a variety of aromatic compounds, including homocyclic compounds, such as hydroxybenzoates, as well as N-heterocycles, including pyridine and picoline.
"Arthrobacter" sp H65-7 produces the enzyme inulase II that converts inulin into difructose anhydride (DFA). DFA is a promising nutrient for fighting osteoporis, because it helps absorption of calcium in the intestines.
The enzyme Alu obtained from "Arthrobacter luteus" is able to cleave Alu sequences in human DNA, causing the kind of gene sequence to be named after the enzyme. Alu are a group of moderately repetitive gene sequences (300bp in length). Alu sequences make up 6-8% of the human genome.

</doc>
<doc id="40130" url="https://en.wikipedia.org/wiki?curid=40130" title="Mineral salts pyridone broth">
Mineral salts pyridone broth

Mineral salts pyridone broth is a selective medium for bacteria that can metabolize pyridone (which is an unusual carbon source that a select few types of bacteria can use). This medium is used to isolate bacteria belonging to the "Arthrobacter" genus among other bacteria genera. 

</doc>
