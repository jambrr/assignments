<doc id="70179" url="https://en.wikipedia.org/wiki?curid=70179" title="Lucy Webb Hayes">
Lucy Webb Hayes

Lucy Ware Webb Hayes (August 28, 1831 – June 25, 1889) was a First Lady of the United States and the wife of President Rutherford B. Hayes.
Historians have christened her "Lemonade Lucy" due to her staunch support of the temperance movement; however, contrary to popular belief, she was never referred to by that nickname while living, and it was her husband who banned alcohol from the White House.
Early life.
Born in Chillicothe, Ohio, the daughter of James Webb, a doctor, and Maria Cook-Webb, Lucy was descended from seven veterans of the American Revolution. Her father died when she was a child. After his death, she, her mother and the other children freed the family slaves and continued to give them assistance and show an interest in their welfare. With her mother, she moved to Delaware, Ohio where in 1847 she met Rutherford B. Hayes. Later that year, she enrolled at Wesleyan Women’s College, class of 1850 (which later merged with Ohio Wesleyan University), from which she graduated with first honors; she was the first first lady to have graduated from college and was a member of Kappa Kappa Gamma sorority. Hayes was by this time practicing law in Cincinnati, and the two began dating seriously. He proposed in June 1851.
Rutherford Hayes, aged 30, married Lucy Webb, aged 21, on December 30, 1852, at the home of the bride’s mother in Cincinnati, Ohio. After the wedding, performed by Dr. L.D. McCabe of Delaware, the couple honeymooned at the home of the groom’s sister and brother-in-law in Columbus, Ohio.
She and her husband were both strong supporters of the Methodist Church in their home town, Fremont, Ohio. When the church constructed a new building there, they paid a quarter of the cost, and did so again when it burned and had to be rebuilt some years later. They assisted other churches as well.
During the Civil War, Lucy spent two winters with him at a camp in Virginia, nursing him back to health while he served with the Union forces. She also worked with other hospitals and camps during the war.
A vigorous opponent of slavery, Hayes contributed to her husband’s decision to abandon the Whigs for the antislavery Republican Party. During the American Civil War, she visited Hayes often in the field. Before becoming First Lady of the United States, she was twice First Lady of Ohio, first from 1868 to 1872 and again from 1876 until 1877 when her husband became President. While her husband was governor of Ohio, she helped establish the state Home for Soldiers’ Orphans at Xenia.
First Lady.
As First Lady, Hayes brought her zeal to the White House and supported her husband's ban of alcoholic beverages at state functions, excepting only the reception for Grand Duke Alexei Alexandrovich of Russia in 1877, at which wine was served. The Hayes had a lifelong habit of avoiding alcoholic beverages. Of their decision to continue that habit in the White House, Lucy said "It is true I shall violate a precedent, but I shall not violate the Constitution, which is all that, through my husband, I have taken the oath to obey. As for my countrymen, they are accustomed to independent action." Because of this stand, she was dubbed "Lemonade Lucy" and the Hayes administration became known as "the cold water regime." The Women's Christian Temperance Union hailed her policy and in gratitude commissioned a full-length portrait of her, which now hangs in the White House. She also instituted the custom of conducting an Easter egg roll on the White House lawn. A devout Methodist, she joined the president in saying prayers after breakfast and she presided over group hymn sings with the cabinet and congressmen on Sunday evenings, singing with great joy in her warm contralto voice.
During her years as First Lady, the Hayes family attended the Foundry Methodist Episcopal Church, and when the Woman's Home Missionary Society of that denomination was organized in 1880, Lucy became its first president and held that position for nine years. The Lucy Webb Hayes Training School for Deaconesses in Washington, D.C. was named in her honor. In that position, she spoke out often about the importance of the family, saying that with "American homes what they should be, we need not greatly fear the evils that threaten us from other lands." "America is the cradle of the future for all the world. Elevate woman, and you lift up the home; exalt the home and you lift up the nation." She made these statements in a public address at Syracuse, New York.
The social highlight of the Hayes's years was their twenty-fifth wedding anniversary celebration, at which the President and the First Lady repeated their vows at a White House ceremony before many of the same guests who had attended the original nuptials in Cincinnati. On that occasion, Major William McKinley, who later became President, and others of the regiment she had served during the Civil War gave her a large silver platter with an affectionate inscription on it.
Later life.
In 1881 she retired with the President to Spiegel Grove in Fremont, Ohio. She died of a stroke on June 25, 1889, and was buried at Spiegel Grove. Upon her death, flags across the United States were lowered to half staff.
Children.
The Hayes had four sons and a daughter to live to maturity:

</doc>
<doc id="70180" url="https://en.wikipedia.org/wiki?curid=70180" title="Oology">
Oology

Oology (or oölogy) is a branch of ornithology studying bird eggs, nests and breeding behaviour. The word is derived from the Greek "oion", meaning egg. Oology can also refer to the hobby of collecting wild birds' eggs, sometimes called egg collecting, birdnesting or egging, which is now illegal in many jurisdictions.
History.
As a science.
Oology became increasingly popular in Britain and the United States during the 1800s. Observing birds from afar was difficult because high quality binoculars were not readily available. Thus it was often more practical to shoot the birds, or collect their eggs. While the collection of the eggs of wild birds by amateurs was considered a respectable scientific pursuit in the 19th Century and early 20th Century, from the mid 20th Century onwards it was increasingly regarded as being a hobby rather than a scientific discipline.
In the 1960s, the naturalist Derek Ratcliffe compared peregrine falcon eggs from historical collections with more recent egg-shell samples, and was able to demonstrate a decline in shell thickness. This was found to cause the link between the use by farmers of pesticides such as DDT and dieldrin, and the decline of British populations of birds of prey.
As a hobby.
Egg collecting was still popular in the early 20th century, even as its scientific value became less prominent. Egg collectors built large collections and traded with one another. Frequently, collectors would go to extreme lengths to obtain eggs of rare birds. For example, Charles Bendire was willing to have his teeth broken to remove a rare egg that became stuck in his mouth. He had placed the egg in his mouth while climbing down a tree.
In 1922, the British Oological Association was founded by Baron Rothschild, a prominent amateur naturalist, and the Reverend Francis Jourdain; the group was renamed the Jourdain Society after Jourdain's death in 1940. Rothschild and Jourdain founded it as a breakaway group after egg collecting by members of the British Ornithologists’ Union, was denounced by Earl Buxton at a meeting of the Royal Society for the Protection of Birds.
As a crime.
Legislation, such as the "Protection of Birds Act 1954" and "Wildlife and Countryside Act 1981" in the United Kingdom, has made it impossible to collect wild birds' eggs legally. In the United Kingdom, it is only legal to possess a wild-bird's egg if it was taken before 1954; selling wild birds' eggs, regardless of their age, is illegal.
However, the practice of egg collecting, or 'egging', continues as an 'underground' or illegal activity in the UK and elsewhere. In the 1980s and 1990s, the fines allowed by the law were only a moderate deterrent to some egg collectors. However, the "Countryside and Rights of Way Act 2000" allowed for six months' imprisonment for the possession of the eggs of wild birds and, since it came into force, a number of individuals have been imprisoned, both for possessing and for attempting to buy egg collections. The Jourdain Society continued to meet although membership dwindled after 1994, when a dinner of the society was raided by police, assisted by the Royal Society for the Protection of Birds (RSPB). This resulted in six members being convicted and fined.
Despite this, some of those who engage in egg collecting show considerable recidivism in their activity. One, Colin Watson, was convicted six times before he fell to his death in 2006, while attempting to climb to a nest high up in a tree. Another individual has been convicted nine times and imprisoned twice and a third has been convicted 51 times, imprisoned four times and barred from entering Scotland during the bird breeding season.
The Royal Society for the Protection of Birds has been particularly active in fighting illegal egg collection and maintains an investigative unit that collects intelligence on egg collectors and assists police in mounting prosecutions on them, in addition to investigating other wildlife crimes. At one point, RSPB staff were being trained by soldiers from the Brigade of Gurkhas in camouflage skills and in surveillance, map and radio techniques, to better enable them to guard nests of rare birds.
In the United Kingdom, to avoid the possibility of prosecution, owners of old egg collections must retain sufficient proof to show, on the balance of probabilities, that the eggs pre-date 1954. However owners of genuinely old collections are unlikely to face prosecution as experienced investigators and prosecutors are able to distinguish them from recently collected eggs. It is illegal to sell a collection, regardless of the eggs' age, so old collections may only be disposed of by giving the eggs away or by destroying them. Museums are reluctant to accept donations of collections without reliable collection data (i.e. date and place that they were collected) that gives them scientific value.
In the United States, the collection and possession of wild bird eggs is also restricted, and in some cases is a criminal act. Depending on the species, the Migratory Bird Treaty Act, the Lacey Act, the Endangered Species Act, or other laws may apply.
Collecting.
Methods.
When collecting eggs, normally the whole clutch of eggs is taken. Because eggs will rot if the contents are left inside, they must be 'blown' to remove the contents. Although collectors will take eggs at all stages of incubation, freshly laid eggs are much easier to 'blow', usually through a small, inconspicuous hole drilled with a specialized drill through the side of the eggshell. Egg blowing is also done with domestic bird's eggs for the hobby of Egg decorating.
Oology related publications.
Numerous books, and at one point a journal, have been published on egg collecting and identification:

</doc>
<doc id="70181" url="https://en.wikipedia.org/wiki?curid=70181" title="Battle of Worcester">
Battle of Worcester

The Battle of Worcester took place on 3 September 1651 at Worcester, England, and was the final battle of the English Civil War. Oliver Cromwell and the Parliamentarians defeated the Royalist, predominantly Scottish, forces of King Charles II. The 16,000 Royalist forces, of whom the vast majority were from Scottish regiments, were overwhelmed by the 28,000 strong "New Model Army" of Cromwell.
Invasion of England.
The King was aided by Scottish allies and was attempting to regain the throne that had been lost when his father Charles I was executed. The commander of the Scots, David Leslie, supported the plan of fighting in Scotland, where royal support was strongest. Charles, however, insisted on making war in England. He calculated that Cromwell's campaign north of the River Forth would allow the main Scottish Royalist army which was south of the Forth to steal the march on the Roundhead New Model Army in a race to London. He hoped to rally not merely the old faithful Royalists, but also the overwhelming numerical strength of the English Presbyterians to his standard. He calculated that his alliance with the Scottish Presbyterian Covenanters and his signing of the Solemn League and Covenant would encourage English Presbyterians to support him against the English Independent faction which had grown in power over the last few years. The Royalist army was kept well in hand, no excesses were allowed, and in a week the Royalists covered 150 miles in marked contrast to the Duke of Hamilton's ill-fated expedition of 1648. On 8 August the troops were given a well-earned rest between Penrith and Kendal.
But the Royalists were mistaken in supposing that the enemy was taken aback by their new move. Everything had been foreseen both by Cromwell and by the Council of State in Westminster. The latter had called out the greater part of the militia on 7 August. Lieutenant-General Charles Fleetwood began to draw together the midland contingents at Banbury. The London trained-bands turned out for field service no fewer than 14,000 strong. Every suspected Royalist was closely watched, and the magazines of arms in the country-houses of the gentry were for the most part removed into the strong places. On his part Cromwell had quietly made his preparations. Perth passed into his hands on 2 August and he brought back his army to Leith by 5 August. Thence he dispatched Lieutenant-General John Lambert with a cavalry corps to harass the invaders. Major-General Thomas Harrison was already at Newcastle picking the best of the county mounted-troops to add to his own regulars. On 9 August, Charles was at Kendal, Lambert hovering in his rear, and Harrison marching swiftly to bar his way at the Mersey. Thomas Fairfax emerged for a moment from his retirement to organize the Yorkshire levies, and the best of these as well as of the Lancashire, Cheshire and Staffordshire militias were directed upon Warrington, which Harrison reached on 15 August, a few hours in front of Charles's advanced guard. Lambert too, slipping round the left flank of the enemy, joined Harrison, and the English fell back (16 August), slowly and without letting themselves be drawn into a fight, along the London road.
Worcester campaign.
Cromwell meanwhile, leaving George Monck with the least efficient regiments to carry on the war in Scotland, had reached the river Tyne in seven days, and thence, marching 20 miles a day in extreme heat with the country people carrying their arms and equipment, the regulars entered Ferrybridge on 19 August, at which date Lambert, Harrison and the north-western militia were about Congleton. It seemed probable that a great battle would take place between Lichfield and Coventry on or just after 25 August and that Cromwell, Harrison, Lambert and Fleetwood would all take part in it. But the scene and the date of the denouement were changed by the enemy's movements. Shortly after leaving Warrington the young king had resolved to abandon the direct march on London and to make for the Severn valley, where his father had found the most constant and the most numerous adherents in the first war, and which had been the centre of gravity of the English Royalist movement of 1648. Sir Edward Massey, formerly the Parliamentary governor of Gloucester, was now with Charles, and it was hoped that he would induce his fellow Presbyterians to take arms. The military quality of the Welsh border Royalists was well proved, that of the Gloucestershire Presbyterians not less so, and, in basing himself on Gloucester and Worcester as his father had done on Oxford, Charles II hoped, naturally, to deal with the Independent faction minority of the English people more effectually than Charles I had earlier dealt with the majority of the people of England who had supported the Parliamentary cause. But even the pure Royalism which now ruled in the invading army could not alter the fact that it was a foreign, Scottish, army, and it was not merely an Independent faction but all England that united against it.
Charles arrived at Worcester on 22 August and spent five days in resting the troops, preparing for further operations, and gathering and arming the few recruits who came in. The delay was to prove fatal; it was a necessity of the case foreseen and accepted when the march to Worcester had been decided upon, and had the other course, that of marching on London via Lichfield, been taken the battle would have been fought three days earlier with the same result. Worcester itself had no particular claim to being loyal to the King. Throughout the First Civil War it had taken the pragmatic position of declaring loyalty to whichever side had been in occupation! The epithet 'Faithful City' arose out of a cynical (and unsuccessful) claim at the Restoration for compensation from the new king.
Cromwell, the lord general, had during his march south thrown out successively two flying columns under Colonel Robert Lilburne to deal with the Lancashire Royalists under the Earl of Derby. Lilburne entirely routed a Lancashire detachment of the enemy on their way to join the main Royalist army at the Battle of Wigan Lane on 25 August and as affairs turned out Cromwell merely shifted the area of his concentration two marches to the south-west, to Evesham. Early on 28 August, Lambert's brigade made a surprise crossing of the Severn at Upton, 6 miles below Worcester. In the action which followed Massey was severely wounded and he and his men were forced to retreat northwards along the west bank of the Severn towards the river Teme and Worcester. Fleetwood followed Lambert with reinforcements and orders to advance north towards the Teme. This western envelopment severed the Royalists lines of communications to Wales and the western counties of England. The Royalists were now only 16,000 strong with no hope of significant reinforcements and disheartened by the apathy with which they had been received in districts formerly all their own. Cromwell, for the only time in his military career, had a two-to-one numerical superiority.
On 30 August Cromwell delayed the start of the battle to give time for two pontoon bridges to be constructed, one over the Severn and the other over the Teme close to their confluence. The delay allowed Cromwell to launch his attack on 3 September, one year to the day since his victory at the Battle of Dunbar.
Battle.
Cromwell took his measures deliberately. Lilburne from Lancashire and Major Mercer with the Worcestershire horse were to secure Bewdley Bridge, 20 miles (32 km) north of Worcester and on the enemy's line of retreat. Fleetwood was to force his way across the Teme and attack St John's, the western suburb of Worcester. While Lambert commanded the Eastern Flank of the Army which would advance and encircle the Eastern walls of Worcester, Cromwell would lead the attack on the southern ramparts of the city.
The assault started on the morning of 3 September and initially the initiative lay with the Parliamentarians. Fleetwood forced the passage of the Teme over the pontoon bridges against Royalists under the command of Major General Montgomery. Colonel Richard Deane's initial attempts to cross the Powick Bridge (where Prince Rupert of the Rhine had won the Battle of Powick Bridge, his first victory in 1642) failed against stubborn resistance by the Royalists (many of whom were Scottish Highlanders) commanded by Colonel Keith. By force of arms and numbers the Royalist army was pushed backward by the New Model Army with Cromwell on the eastern bank of the Severn and Fleetwood on the western sweeping in a semicircle four miles long up toward Worcester.
The Royalists contested every hedgerow around Powick meadows. This stubborn resistance on the west bank of the Severn north of the Teme was becoming a serious problem for the Parliamentarians, so Cromwell led Parliamentary reinforcements from the eastern side of the town over the Severn pontoon bridge to aid Fleetwood. Charles II from his vantage point on top of Worcester cathedral's tower realised that an opportunity existed to attack the now-exposed eastern flank of the Parliamentary army. As the defenders on the Western side of the city retreated in good order into the city (although during this manoeuvre Keith was captured and Montgomery was badly wounded), Charles ordered two sorties to attack the Parliamentary forces east of the city. The north-eastern sortie through St. Martin's Gate was commanded by the Duke of Hamilton and attacked the Parliamentary lines at Perry Wood. The south-eastern one through Sidbury Gate was led by Charles II and attacked Red Hill. The Royalist cavalry under the command of David Leslie that was gathered on Pitchcroft meadow on the northern side of the city did not receive orders to aid the sorties and Leslie chose not to do so under his own initiative. Cromwell seeing the difficulty that his east flank was under rushed back over the Severn pontoon bridge with three brigades of troops to reinforce the flank.
Although they were pushed back, the Parliamentarians under Lambert were too numerous and experienced to be defeated by such a move. After an hour in which the Parliamentarians initially retreated under the unexpected attack, when reinforced by Cromwell's three brigades, they in turn forced the Royalists to retreat back toward the city.
The Royalist retreat turned into a rout in which Parliamentarian and Royalist forces intermingled and skirmished up to and into the city. The Royalist position became untenable when the Essex militia stormed and captured Fort Royal, (a redoubt on a small hill to the south-east of Worcester overlooking the Sidbury gate), turning the Royalist guns to fire on Worcester.
Once in the city, Charles II removed his armour and found a fresh mount; he attempted to rally his troops but it was to no avail. A desperate Royalist cavalry charge down Sidbury Street and High Street, led by the Earl of Cleveland and Major Careless amongst others, allowed King Charles to escape the city by St. Martin's Gate. This cavalry force was composed of the few Midland English Royalists who had rallied to Charles II, and largely consisted of Lord Talbot's troop of horse.
The defences of the city were stormed from three different directions as darkness came on, regulars and militia fighting with equal gallantry. Most of the few thousands of the Royalists who escaped during the night were easily captured by Lilburne and Mercer, or by the militia which watched every road in Yorkshire and Lancashire. Even the country people brought in scores of prisoners, for officers and men alike, stunned by the suddenness of the disaster, offered no resistance.
Aftermath.
About 3,000 men were killed during the battle and a further 10,000 were taken prisoner at Worcester or soon afterwards. The Earl of Derby was executed, while the other English prisoners were conscripted into the New Model Army and sent to Ireland. Around 8,000 Scottish prisoners were deported to New England, Bermuda, and the West Indies to work for landowners as indentured labourers. Parliamentary casualties numbered in the low hundreds.
Charles II's escape included various incidents, including one of his hiding from a Parliamentarian patrol in an oak tree in the grounds of Boscobel House. The result of the battle was, in brief, one of those rare victories in which a pursuit is superfluous. In announcing the Worcester victory of the day earlier, Cromwell's 4 September 1651 despatch to William Lenthall, the Speaker of the House of Commons, has become famous: "The dimensions of this mercy are above my thoughts. It is, for aught I know, a crowning mercy." Hence, Cromwell thought the victory was the greatest of all the favours, or mercies, given to him by God, and the expression "crowning mercy" is frequently linked to the battle, thought to be descriptive of the impact of the end of the English Civil War through complete destruction of the last Royalist army.
The Parliamentary militia were sent home within a week. Cromwell, who had ridiculed "such stuff" six months ago, knew them better now. "Your new raised forces," he wrote to the Rump Parliament, "did perform singular good service, for which they deserve a very high estimation and acknowledgement". The New England preacher Hugh Peters gave the militia a rousing farewell sermon "when their wives and children should ask them where they had been and what news, they should say they had been at Worcester, where England's sorrows began, and where they were happily ended", referring to the first clash of the Royalist and Parliamentarian Armies at the Battle of Powick Bridge on 23 September 1642, almost exactly nine years before.
Before the battle King Charles II contracted the Worcester Clothiers Company to outfit his army with uniforms but was unable to pay the £453.3s bill. In June 2008 Charles, Prince of Wales paid off the 357-year-old debt (less the interest, which would have amounted to around £47,500.)
Legacy.
In early April 1786, John Adams and Thomas Jefferson visited Fort Royal Hill at the battlefield at Worcester. John Adams wrote that he was "deeply moved" but disappointed at the locals' lack of knowledge of the battle, and gave the townspeople an "impromptu lecture":

</doc>
<doc id="70184" url="https://en.wikipedia.org/wiki?curid=70184" title="Duodenum">
Duodenum

The duodenum or also known as dodecadactylum, is the first section of the small intestine in most higher vertebrates, including mammals, reptiles, and birds. In fish, the divisions of the small intestine are not as clear, and the terms anterior intestine or proximal intestine may be used instead of duodenum. In mammals the duodenum may be the principal site for iron absorption.
The duodenum precedes the jejunum and ileum and is the shortest part of the small intestine, where most chemical digestion takes place.
In humans, the duodenum is a hollow jointed tube about 25–38 cm (10–15 inches) long connecting the stomach to the jejunum. It begins with the duodenal bulb and ends at the suspensory muscle of duodenum. It can be divided into four parts.
Structure.
The duodenum is a 25–38 cm C-shaped structure lying adjacent to the stomach. It is divided anatomically into four sections. The first part of the duodenum lies within the peritoneum but its other parts are retroperitoneal. 
First part.
The "first part", or "superior part", of the duodenum is a continuation from the pylorus. It is superior to the rest of the segments, at the vertebral level of L1. The duodenal bulb about 2 cm long, is the very first part of the duodenum and is slightly dilated. The duodenal bulb is a remnant of the mesoduodenum, a mesentery which suspends the organ from the posterior abdominal wall in fetal life. The first part of the duodenum is mobile, and connected to the liver by the hepatoduodenal ligament of the lesser omentum. The first part of the duodenum ends at the corner, the "superior duodenal flexure".
Relations:
Second part.
The "second part", or "descending part", of the duodenum begins at the superior duodenal flexure. It goes inferior to the lower border of vertebral body L3, before making a sharp turn medially into the "inferior duodenal flexure", the end of the descending part.
The pancreatic duct and common bile duct enter the descending duodenum, through the major duodenal papilla. The second part of the duodenum also contains the minor duodenal papilla, the entrance for the accessory pancreatic duct. The junction between the embryological foregut and midgut lies just below the major duodenal papilla.
Third part.
The "third part", or "horizontal part" or "inferior part" of the duodenum begins at the "inferior duodenal flexure" and passes transversely to the left, passing in front of the inferior vena cava, abdominal aorta and the vertebral column. The superior mesenteric artery and vein are anterior to the third part of duodenum. This part may be compressed between Aorta and SMA causing Superior Mesenteric Artery Syndrome
Fourth part.
The "fourth part", or "ascending part", of the duodenum passes upward, joining with the jejunum at the duodenojejunal flexure. The fourth part of the duodenum is at the vertebral level L2, and may pass directly on top of, or slightly left to, the aorta.
Blood supply.
The duodenum receives arterial blood from two different sources. The transition between these sources is important as it demarcates the foregut from the midgut. Proximal to the 2nd part of the duodenum (approximately at the major duodenal papilla – where the bile duct enters) the arterial supply is from the gastroduodenal artery and its branch the superior pancreaticoduodenal artery. Distal to this point (the midgut) the arterial supply is from the superior mesenteric artery (SMA), and its branch the inferior pancreaticoduodenal artery supplies the 3rd and 4th sections.
The superior and inferior pancreaticoduodenal arteries (from the gastroduodenal artery and SMA respectively) form an anastomotic loop between the celiac trunk and the SMA; so there is potential for collateral circulation here.
The venous drainage of the duodenum follows the arteries. Ultimately these veins drain into the portal system, either directly or indirectly through the splenic or superior mesenteric vein.
Lymphatic drainage.
The lymphatic vessels follow the arteries in a retrograde fashion. The anterior lymphatic vessels drain into the pancreatoduodenal lymph nodes located along the superior and inferior pancreatoduodenal arteries and then into the pyloric lymph nodes (along the gastroduodenal artery).
The posterior lymphatic vessels pass posterior to the head of the pancreas and drain into the superior mesenteric lymph nodes. Efferent lymphatic vessels from the duodenal lymph nodes ultimately pass into the celiac lymph nodes.
Histology.
Under microscopy, the duodenum has a villous mucosa. This is distinct from the mucosa of the pylorus, which directly joins to the duodenum. Like other structures of the gastrointestinal tract, the duodenum has a mucosa, submucosa, muscularis externa, and adventitia. Glands line the duodenum, known as Brunner's glands, which secrete mucus and bicarbonate in order to neutralise stomach acids. These are distinct glands not found in the ileum or jejunum, the other parts of the small intestine. 
Function.
The duodenum is largely responsible for the breakdown of food in the small intestine, using enzymes. The villi of the duodenum have a leafy-looking appearance, which is a histologically identifiable structure. Brunner's glands, which secrete mucus, are found in the duodenum "only". The duodenum wall is composed of a very thin layer of cells that form the muscularis mucosae. The duodenum is almost entirely retroperitoneal. It has three parts and each part has its own significance.
The duodenum also regulates the rate of emptying of the stomach via hormonal pathways. Secretin and cholecystokinin are released from cells in the duodenal epithelium in response to acidic and fatty stimuli present there when the pylorus opens and releases gastric chyme into the duodenum for further digestion. These cause the liver and gall bladder to release bile, and the pancreas to release bicarbonate and digestive enzymes such as trypsin, lipase and amylase into the duodenum as they are needed.
Clinical significance.
Ulceration.
Ulcers of the duodenum commonly occur because of infection by the bacteria "Helicobacter pylori". This bacteria, through a number of mechanisms, erodes the protective mucosa of the duodenum, predisposing it to damage from gastric acids. The first part of the duodenum is the most common location of ulcers as it is where the acidic chyme meets the duodenal mucosa before mixing with the alkaline secretions of the duodenum. Duodenal ulcers may cause recurrent abdominal pain and dyspepsia, and are often investigated using a urea breath test to test for the bacteria, and endoscopy to confirm ulceration and take a biopsy. If managed, these are often managed through antibiotics that aim to eradicate the bacteria, and PPIs and antacids to reduce the gastric acidity.
Coeliac disease.
The British Society of Gastroenterology (BSG) guidelines specify that a duodenal biopsy is required for the diagnosis of adult coeliac disease. The biopsy is ideally performed at a moment when the patient is on a gluten-containing diet.
Other.
Other causes of disease include:
Etymology.
The name "duodenum" is from Medieval Latin, short for "intestīnum duodēnum digitōrum", which may be translated: intestine of twelve finger-widths (in length), from Latin duodēnum, genitive pl. of duodēnī, twelve each, from duodecim, twelve. The Latin phrase "intestīnum duodēnum digitōrum" is thought to be a loan-translation from the Greek word "dodekadaktylon" (δώδεκαδάκτυλοv), literally "twelve fingers long." The intestinal section was so called by Greek physician Herophilus (c.335–280 B.C.E.) for its length, about equal to the breadth of twelve fingers.

</doc>
<doc id="70188" url="https://en.wikipedia.org/wiki?curid=70188" title="Highgate Cemetery">
Highgate Cemetery

Highgate Cemetery is a place of burial in north London, England. It is designated Grade I on the Historic England Register of Parks and Gardens of Special Historic Interest in England. It is divided into two parts, named the East and West cemetery. There are approximately 170,000 people buried in around 53,000 graves at Highgate Cemetery. Highgate Cemetery is notable both for some of the people buried there as well as for its "de facto" status as a nature reserve.
Location.
The cemetery is located on both sides of Swain's Lane in Highgate, N6, next to Waterlow Park. The main gate is located just north of Oakshott Avenue. There is another disused gate on Chester Road. The cemetery is in the London Boroughs of Camden, Haringey and Islington. The nearest transport link is Archway tube station.
History and setting.
The cemetery in its original form – the northwestern wooded area – opened in 1839, as part of a plan to provide seven large, modern cemeteries, now known as the "Magnificent Seven", around the outside of central London. The inner-city cemeteries, mostly the graveyards attached to individual churches, had long been unable to cope with the number of burials and were seen as a hazard to health and an undignified way to treat the dead. The initial design was by architect and entrepreneur Stephen Geary.
On Monday 20 May 1839, Highgate Cemetery was dedicated to St. James by the Right Reverend Charles Blomfield, Lord Bishop of London. Fifteen acres were consecrated for the use of the Church of England, and two acres set aside for Dissenters. Rights of burial were sold for either limited period or in perpetuity. The first burial was Elizabeth Jackson of Little Windmill Street, Soho, on 26 May.
Highgate, like the others of the Magnificent Seven, soon became a fashionable place for burials and was much admired and visited. The Victorian attitude to death and its presentation led to the creation of a wealth of Gothic tombs and buildings. It occupies a spectacular south-facing hillside site slightly downhill from the top of the hill of Highgate itself, next to Waterlow Park. In 1854 the area to the east of the original area across Swains Lane was bought to form the eastern part of the cemetery. This part is still used today for burials, as is the western part. Most of the open unforested area in the new addition still has fairly few graves on it.
The cemetery's grounds are full of trees, shrubbery and wildflowers, most of which have been planted and grown without human influence. The grounds are a haven for birds and small animals such as foxes. The Egyptian Avenue and the Circle of Lebanon (topped by a huge Cedar of Lebanon) feature tombs, vaults and winding paths dug into hillsides. For its protection, the oldest section, which holds an impressive collection of Victorian mausoleums and gravestones, plus elaborately carved tombs, allows admission only in tour groups. The eastern section, which contains a mix of Victorian and modern statuary, can be toured unescorted.
The tomb of Karl Marx, the Egyptian Avenue and the Columbarium are Grade I listed buildings.
Because of the Karl Marx association a variety of Socialist leaders and thinkers are buried within the cemetery grounds.
Highgate Cemetery was featured in the popular media from the 1960s to the late 1980s for its so-called occult past, particularly as being the alleged site of the "Highgate Vampire".
Friends of Highgate Cemetery.
The Friends of Highgate Cemetery Trust was set up in 1975 and acquired the freehold of both East and West Cemeteries by 1981, since when they have had responsibility for the maintenance of the location. In 1984 they published "Highgate Cemetery: Victorian Valhalla" by John Gay.
Interments.
The most famous burial in the East cemetery is arguably that of Karl Marx, whose tomb was the site of attempted bombings on 2 September 1965 and in 1970
There are many other prominent figures, Victorian and otherwise, buried at Highgate Cemetery. Most of the historically notable figures lie in the eastern part. Tours of the most famous graves are available but, due to vandalism and souvenir hunters, visitors are no longer allowed to explore unaccompanied, unless they have a personal connection with the cemetery and hold a pass to their deceased relative's grave.
War graves.
The cemetery contains the graves of 316 Commonwealth service personnel maintained and registered by the Commonwealth War Graves Commission, in both the East and West Cemeteries, 257 from the First World War and 59 from the Second. Those whose graves could not be marked by headstones are listed on a Screen Wall memorial erected near the Cross of Sacrifice in the older (western) cemetery.
Visiting.
As of 1 March 2013, a new pricing structure was implemented at Highgate Cemetery. The West Cemetery is accessible by guided tour only, the cost of which has increased to £12 per adult and £6 per child. However, this now includes access to the East Cemetery and a map. The tour lasts for approximately one hour.
The cost per adult to access the East Cemetery (self-guiding) is now £4.00 and also includes a map. The cost of a guided tour of the East Cemetery is now £8 per adult and £4 per child.
Booking for a weekday tour (13h45) is essential and can be done via the Cemetery's website. However, weekend tours do not need to be booked online in advance and tickets can be purchased in person on the day for tours later that same day. These start at 11h00 and the last tour during summer hours departs at 16h00.
There are now no longer concessions for students, a decision taken in line with the policy of the National Trust.

</doc>
<doc id="70193" url="https://en.wikipedia.org/wiki?curid=70193" title="List of cities and towns in Poland">
List of cities and towns in Poland

This page contains a list of cities and towns in Poland, preceded by a table of major Polish cities. The table ranks cities by population based on data from the Central Statistical Office of Poland. Note that in the Polish system of administration there is no difference between a city and a town. A gazetteer is available to locate any town or settlement on a detailed map.
As of 1 January 2016 there are 919 towns in Poland. For lists of places which obtained or regained town status in the years since 1900, see "Nadania praw miejskich w Polsce po 1900" in Polish Wikipedia.
Largest cities by size.
Below is the list of the most populated cities in Poland. The seats of either a voivode, or a voivodeship legislature, are marked in bold.

</doc>
<doc id="70194" url="https://en.wikipedia.org/wiki?curid=70194" title="Margaret Beaufort, Countess of Richmond and Derby">
Margaret Beaufort, Countess of Richmond and Derby

Lady Margaret Beaufort (usually pronounced: , ; or , ), Countess of Richmond and Derby (31 May 1443 – 29 June 1509), was the mother of King Henry VII and paternal grandmother of King Henry VIII of England. 
She was a key figure in the Wars of the Roses and an influential matriarch of the House of Tudor. She is credited with the establishment of two prominent Cambridge colleges, founding Christ's College in 1505 and beginning the development of St John's College, which was completed posthumously by her executors in 1511.
Early life.
Margaret was born at Bletsoe Castle, Bedfordshire, on 31 May 1443 or 1441. The day and month are not disputed, as she required Westminster Abbey to celebrate her birthday on 31 May. The year of her birth is more uncertain. William Dugdale, the 17th century antiquary, has suggested that she may have been born in 1441; this suggestion is based on evidence of inquisitions taken at the death of Margaret's father. Dugdale has been followed by a number of Margaret's biographers; however, it is more likely that she was born in 1443, as in May 1443, her father had negotiated with the king about the wardship of his unborn child in case he died on a campaign.
She was the daughter of Margaret Beauchamp of Bletsoe and John Beaufort, 1st Duke of Somerset. Margaret's father was a great-grandson of King Edward III through his third surviving son, John of Gaunt, Duke of Lancaster. At the moment of her birth, Margaret's father was preparing to go to France and lead an important military expedition for King Henry VI. Somerset negotiated with the king to ensure that, in case of his death, the rights to Margaret's wardship and marriage would belong only to his wife.
Somerset fell out with the king after coming back from France, however, and he was banished from the court and about to be charged with treason. He died shortly afterwards. According to Thomas Basin, Somerset died of illness, but the Crowland Chronicle reported that his death was suicide. Margaret, as his only child, was the heiress to his fortunes.
On Margaret's first birthday, the king broke the arrangement with Margaret's father and gave her wardship to William de la Pole, 1st Duke of Suffolk, although Margaret remained with her mother. Margaret's mother was pregnant at the time of Somerset's death, but the child did not survive and Margaret remained sole heir. Although she was her father's only legitimate child, Margaret had two half-brothers and three half-sisters from her mother's first marriage whom she supported after her son's accession.
Marriages.
First marriage.
Margaret was married to Suffolk's son, John de la Pole. The wedding may have been held between 28 January and 7 February 1444, when she was perhaps a year old but certainly no more than three. However, there is more evidence to suggest they were married in January 1450, after Suffolk had been arrested and was looking to secure his son's future. Papal dispensation was granted on 18 August 1450, necessary because the spouses were too closely related, and this concurs with the later date of marriage.
Margaret never recognised this marriage. Three years later, the marriage was dissolved and King Henry VI granted Margaret's wardship to his own half-brothers, Jasper and Edmund Tudor. In her will, made in 1472, Margaret refers to Edmund Tudor as her first husband. Under canon law, Margaret was not bound by the marriage contract as she was entered into the marriage before reaching the age of twelve.
Second marriage.
Even before the annulment of her first marriage, Henry VI chose Margaret as a bride for his half-brother, Edmund Tudor, 1st Earl of Richmond. Edmund was the eldest son of the king's mother, Catherine of Valois, by Owen Tudor.
Margaret was 12 when she married the 24-year-old Edmund Tudor on 1 November 1455. The Wars of the Roses had just broken out; Edmund, a Lancastrian, was taken prisoner by Yorkist forces less than a year later. He died of the plague in captivity at Carmarthen the following November, leaving a 13-year-old widow who was seven months pregnant with their child.
Taken into the care of her brother-in-law Jasper, at Pembroke Castle, the Countess gave birth on 28 January 1457 to her only child, Henry Tudor, the future Henry VII of England. The birth was particularly difficult; at one point, both the Countess and her child were close to death, due to her young age and small size. She would never give birth again.
Margaret and her son remained in Pembroke until the York triumphs of 1461 saw the castle pass to Lord Herbert of Raglan. From the age of two, Henry lived with his father's family in Wales, and from the age of fourteen, he lived in exile in France. During this period, the relationship between mother and son was sustained by letters and a few visits.
The Countess always respected the name and memory of Edmund as the father of her only child. In 1472, sixteen years after his death, Margaret specified in her will that she wanted to be buried alongside Edmund, even though she had enjoyed a long, stable and close relationship with her third husband, who had died in 1471.
Third marriage.
On 3 January 1458, the 14-year-old Margaret married Sir Henry Stafford (c.1425–1471), son of Humphrey Stafford, 1st Duke of Buckingham. A dispensation for the marriage, necessary because Margaret and Stafford were second cousins, was granted on 6 April 1457. The Countess enjoyed a fairly long and harmonious marital relationship during her marriage to Stafford. Margaret and her husband were given 400 marks' worth of land by Buckingham, but Margaret's own estates were still the main source of income. They had no children.
In 1471, Stafford died of wounds suffered at the Battle of Barnet, fighting for the Yorkists. At 28 years old, Margaret became a widow again.
Fourth marriage.
In June 1472, Margaret married Thomas Stanley, the Lord High Constable and King of Mann. Their marriage was at first a marriage of convenience. Recent historians have suggested that Margaret never considered herself a member of the Stanley family. Margaret's marriage to Stanley enabled her to return to the court of Edward IV and Elizabeth Woodville. She was chosen by Queen Elizabeth to be godmother to one of her daughters.
Following Edward's death and the seizure of the throne by Richard, Margaret was soon back at court serving the new queen, Anne Neville. Margaret carried Anne's train at the coronation. Nevertheless, Richard III passed an act of Parliament stripping Margaret of all her titles and estates, although he stopped short of a full attainder by transferring her property to her husband.
While serving the new king and queen, Margaret was secretly plotting with the dowager queen, Elizabeth Woodville, and was almost certainly involved in Buckingham's rebellion. As Queen Elizabeth's sons, the Princes in the Tower, were presumed murdered, it was agreed that Margaret's son, Henry, would be betrothed to Elizabeth of York, the eldest daughter of Elizabeth and Edward IV, thus creating a marriage alliance with potential to attract both Yorkist and Lancastrian support.
Margaret's husband Stanley, despite having fought for Richard III during the Buckingham rebellion, did not respond when summoned to fight at the Battle of Bosworth Field in 1485, remaining aloof from the battle, even though his eldest son, George Stanley (styled Lord Strange), was held hostage by Richard. After the battle, it was Stanley who placed the crown on the head of his stepson (Henry VII), who later made him Earl of Derby. Margaret was then styled "Countess of Richmond and Derby". She was invested as a Lady Companion, Order of the Garter (L.G.) in 1488.
Later in her marriage, the Countess preferred living alone. In 1499, with her husband's permission, she took a vow of chastity in the presence of Richard FitzJames, Bishop of London. Taking a vow of chastity while being married was unusual but not unprecedented; around 1413, Margery Kempe also negotiated a vow of chastity with her husband. The Countess moved away from her husband and lived alone at Collyweston in Northamptonshire, near Stamford. She was regularly visited by her husband, who had rooms reserved for him. Margaret renewed her vows in 1504.
The King's Mother.
After her son won the crown at the Battle of Bosworth Field, the Countess was referred to in court as "My Lady the King's Mother". As such, she enjoyed legal and social independence which other married women could not (see Coverture). Her son's first parliament recognised her right to hold property independently from her husband, as if she were unmarried. Towards the end of her son's reign she was given a special commission to administer justice in the north of England.
As arranged by their mothers, Henry married Elizabeth of York. The Countess was reluctant to accept a lower status than the dowager queen Elizabeth or even her daughter-in-law, the queen consort. She wore robes of the same quality as the queen consort and walked only half a pace behind her. Elizabeth's biographer, Amy Licence, states that this "would have been the correct courtly protocol", adding that "Only one person knew how Elizabeth really felt about Margaret and she did not commit it to paper."
Margaret had written her signature as "M. Richmond" for years, since the 1460s. In 1499, she changed her signature to "Margaret R.", perhaps to signify her royal authority ("R" standing either for "regina" – queen in Latin as customarily employed by female monarchs – or for Richmond). Furthermore, she included the Tudor crown and the caption "et mater Henrici septimi regis Angliæ et Hiberniæ" ("and mother of Henry VII, king of England and Ireland").
Many historians believe the departure from court of dowager queen Elizabeth Woodville in 1487 was partly at the behest of Henry's influential mother, though this is uncertain. The Countess was known for her education and her piety, and her son is said to have been devoted to her. He died on 21 April 1509, having designated his mother chief executor of his will. She arranged her son's funeral and her grandson's coronation. At her son's funeral she was given precedence over all the other women of the royal family.
Death.
The Countess died in the Deanery of Westminster Abbey on 29 June 1509. This was the day after her grandson's 18th birthday, and just over two months after the death of her son. She is buried in the Henry VII Chapel of the Abbey, in a black marble tomb topped with a bronze gilded effigy and canopy. She is now situated between the later graves of William and Mary and the tomb of Mary, Queen of Scots.
Legacy.
In 1497 she announced her intention to build a free school for the general public of Wimborne, Dorset. With her death in 1509, Wimborne Grammar School, now Queen Elizabeth's School, came into existence.
In 1502 she established the Lady Margaret's Professorship of Divinity at the University of Cambridge. In 1505 she refounded and enlarged God's House, Cambridge as Christ's College, Cambridge with a royal charter from the king. She has been honoured ever since as the Foundress of the College. A copy of her signature can be found carved on one of the buildings (4 staircase, 1994) within the College. In 1511, St. John's College, Cambridge was founded by her estate, either at her direct behest or at the suggestion of her chaplain, John Fisher. Land that she owned around Great Bradley in Suffolk was bequeathed to St. John's upon its foundation. Her portrait hangs in the Great Halls of both Christ's and St. John's, accompanied by portraits of John Fisher. Both Colleges also have her crest and motto as the College arms. Furthermore, various societies, including the Lady Margaret Society as well as the Beaufort Club at Christ's, and the Lady Margaret Boat Club at John's, were named after her.
Lady Margaret Hall, the first women's college at the University of Oxford, was named in her honour.
A parctical woman, when faced with problems of flooding in parts of the Fens that threatened some of her properties, she was able to initiate an ambitious drainage scheme, involving foreign engineers, that saw the construction of a large sluice at Boston. She also funded the restoration of Church of All Saints, Martock in Somerset, and the construction of the church tower.
Margaret Beaufort Middle School (formerly Margaret Beaufort County Secondary Modern School) in Riseley, Bedfordshire, is named after her.
Portraits.
There is no surviving portrait of Margaret Beaufort dating from her lifetime. All known portraits, however, are in essentially the same format, depicting her in her later years, wearing a long, peaked, white headdress and in a pose of religious contemplation. Most of these were made in the reign of Henry VIII and Elizabeth I as symbols of loyalty to the Tudor regime. They may be based on a lost original, or be derived from Pietro Torrigiano's sculpture of Margaret on her tomb in Westminster Abbey, in which she wears the same headdress. Torrigiano, who probably arrived in England in 1509, was commissioned to make the sculpture in the following year.
One variant by Rowland Lockey shows her at prayer in her richly furnished private closet behind her chamber. The plain desk at which she kneels is draped with a richly-patterned textile that is so densely encrusted with embroidery that its corners stand away stiffly. Her lavishly illuminated Book of Hours is open before her, with its protective cloth wrapper (called a "chemise" binding), spread out around it. The walls are patterned with oak leaf designs, perhaps in lozenges, perhaps of stamped and part-gilded leather. Against the wall hangs the dosser of her canopy of estate, with the tester above her head (the Tudor rose at its centre) supported on cords from the ceiling. The coats-of-arms woven into the tapestry are of England (parted as usual with France) and the portcullis badge of the Beauforts, which the early Tudor kings later used in their arms. Small stained glass roundels in the leaded glass of her lancet windows also display elements of the arms of both England (cropped away here) and Beaufort.
Titles, styles, honours and arms.
[[File:Arms of Lady Margaret Beaufort, Countess of Richmond.svg|thumb|right|upright|Margaret Beaufort's arms as wife of Edmund Tudor
Ancestors.
Through her father, Lady Margaret Beaufort was a granddaughter of John Beaufort, 1st Earl of Somerset, a great-granddaughter of John of Gaunt, 1st Duke of Lancaster and his mistress and third wife Katherine Swynford, and a great-great-granddaughter of King Edward III of England.
Following Gaunt's marriage to Katherine, their children (the Beauforts) were legitimised by King Richard II but the legitimation carried a condition: their descendants were barred from inheriting the throne. Lady Margaret's own son Henry VII (and all English, British, and UK sovereigns who followed) are descended from Gaunt and Swynford, Henry VII having come to the throne not through inheritance but by force of arms.
Depictions in the media.
On screen.
The character of Lady Margaret, portrayed by Marigold Sharman, appears in eight episodes of the BBC miniseries "Shadow of the Tower", opposite James Maxwell as her son Henry VII. She is portrayed as a woman of extreme ambition and piety, with a hint of ruthlessness for those who stand in the way of the Tudor Dynasty.
Channel 4 and RDF Media produced a drama about Perkin Warbeck for British television in 2005, "Princes in the Tower". It was directed by Justin Hardy and starred Sally Edwards as Lady Margaret, opposite Paul Hilton as Henry VII, Mark Umbers as Warbeck, and Nadia Cameron Blakey as Elizabeth of York. In this drama, Margaret is depicted as the power behind the throne, a hardened woman of fanatical devotion to both God and herself. She is referenced as a victim of abuse and power who, used by men all her life, became as ruthless and callous as those around her.
In 2013, Amanda Hale portrayed Lady Margaret Beaufort in the television drama series, "The White Queen", an adaptation of Gregory's novels, which was shown on BBC One, Starz, and VRT.

</doc>
<doc id="70197" url="https://en.wikipedia.org/wiki?curid=70197" title="Demography of the United States">
Demography of the United States

As of April 30, 2016, the United States has a total resident population of 323,730,000, making it the third most populous country in the world. It is very urbanized, with 81% residing in cities and suburbs as of 2014 (the worldwide urban rate is 54%). California and Texas are the most populous states, as the mean center of U.S. population has consistently shifted westward and southward. New York City is the most populous city in the United States.
The total fertility rate in the United States estimated for 2014 is 1.86 children per woman, which is below the replacement fertility rate of approximately 2.1. Compared to other Western countries, in 2012, U.S. fertility rate was lower than that of France (2.01), Australia (1.93) and the United Kingdom (1.92). However, U.S. population growth is among the highest in industrialized countries, because the differences in fertility rates are less than the differences in immigration levels, which are higher in the U.S. The United States Census Bureau shows a population increase of 0.75% for the twelve-month period ending in July 2012. Though high by industrialized country standards, this is below the world average annual rate of 1.1%.
There were about 125.9 million adult women in the United States in 2014. The number of men was 119.4 million. At age 85 and older, there were almost twice as many women as men (4 million vs. 2.1 million). People under 21 years of age made up over a quarter of the U.S. population (27.1%), and people age 65 and over made up one-seventh (14.5%). The national median age was 36.8 years in 2009.
The United States Census Bureau defines White people as those "having origins in any of the original peoples of Europe, the Middle East, or North Africa. It includes people who reported "White" or wrote in entries such as Irish, German, Italian, Lebanese, Near Easterner, Arab, or Polish." Whites constitute the majority of the U.S. population, with a total of about 245,532,000 or 77.7% of the population as of 2013. There are 62.6% Whites when Hispanics who describe themselves as "white" are taken out of the calculation. Despite major changes due to illegal and legal immigration since the 1960s and the higher birth-rates of nonwhites, the overall current majority of American citizens are still white, and English-speaking, though regional differences exist.
The American population almost quadrupled during the 20th century—at a growth rate of about 1.3% a year—from about 76 million in 1900 to 281 million in 2000. It reached the 200 million mark in 1968, and the 300 million mark on October 17, 2006. Population growth is fastest among minorities as a whole, and according to the Census Bureau's estimation for 2012, 50.4% of American children under the age of 1 belonged to minority groups.
Hispanic and Latino Americans accounted for 48% of the national population growth of 2.9 million between July 1, 2005, and July 1, 2006. Immigrants and their U.S.-born descendants are expected to provide most of the U.S. population gains in the decades ahead.
The Census Bureau projects a U.S. population of 417 million in 2060, which is a 38% increase from 2007 (301.3 million). However, the United Nations projects a U.S. population of 402 million in 2050, an increase of 32% from 2007. In an official census report, it was reported that 54.4% (2,150,926 out of 3,953,593) of births in 2010, were non-Hispanic white. This represents an increase of 0.34% compared to the previous year, which was 54.06%. 
History.
In 1900, when the U.S. population was 76 million, there were 66.8 million Whites in the United States, representing 88% of the total population, 8.8 million African Americans, with about 90% of them still living in Southern states, and slightly more than 500,000 Hispanics.
Under the law, the Immigration and Nationality Act of 1965, the number of first-generation immigrants living in the United States has increased, from 9.6 million in 1970 to about 38 million in 2007. Around a million people legally immigrated to the United States per year in the 1990s, up from 250,000 per year in the 1950s. In 2009, 37% of immigrants originated in Asia, 42% in North America, and 11% in Africa.
In 1900, non-Hispanic whites comprised almost 97% of the population of the 10 largest American cities. By 2006, non-Hispanic whites had dwindled to a minority in 35 of the nation's 50 largest cities. The Census Bureau reported that minorities (including Hispanic whites) made up 50.4% of the children born in the U.S. between July 2010 and July 2011, compared to 37% in 1990.
In 2010 the state with the lowest fertility rate was Rhode Island, with a rate of 1.63, while Utah had the greatest rate with a rate of 2.45. This correlates with the ages of the states' populations: Rhode Island has the ninth-oldest median age in the US—39.2—while Utah has the youngest—29.0.
Vital statistics.
The U.S. total fertility rate as of 2010 census is 1.931:
Other:
Source: National Vital statistics report based on 2010 US Census data
2013-2014 birth data by race.
"Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."
Population density.
The most densely populated state is New Jersey (1,121/mi2 or 433/km2). See List of U.S. states by population density for maps and complete statistics.
The United States Census Bureau publishes a popular "dot" or "nighttime" map showing population distribution at resolutions of 1,000 and 7,500 people, as well as complete listings of population density by place name.
Cities.
The United States has dozens of major cities, including 31 "global cities" of all types, with 8 in the "alpha" group of global cities: New York City, Los Angeles, Chicago, Washington, DC, Boston, San Francisco, Miami and Atlanta. , the United States had 51 metropolitan areas with a population of over 1,000,000 people each. (See Table of United States Metropolitan Statistical Areas.)
, about 250 million Americans live in or around urban areas. That means more than three-quarters of the U.S. population shares just about three percent of the U.S. land area.
The following table shows the populations of the top twenty metropolitan areas, at the time of the 2010 Census.
Race and ethnicity.
The U.S. population's distribution by race and ethnicity in 2010 was as follows; due to rounding, percentage figures may not add up to the totals shown.
Hispanic or Latino origin.
The total population of Hispanic and Latino Americans comprised 50.5 million or 16.3% of the national total in 2010. The category of "Hispanic or Latino" is considered by the U.S. Census Bureau to be separate from racial categories, including all people who identify their ethnicity as "Hispanic or Latino". The U.S. Census Bureau defines Hispanic or Latino as "those who classify themselves in one of the specific Hispanic or Latino categories listed on the Census 2000 or ACS questionnaire"—Mexican", "Puerto Rican", or "Cuban"—as well as those who indicate that they are "other Spanish, Hispanic, or Latino."" Persons whose ethnicity is identified as Hispanic or Latino may be of any race.
Breakdown by state/territory.
This is a racial breakdown by the 50 states, the District of Columbia, and 5 inhabited territories.
Other groups.
There were 22.1 million veterans in 2009, meaning that less than 10% of Americans serve in the Armed Forces.
In 2010, the "Washington Post" estimated that there were 11 million illegal immigrants in the country.
There were about 2 million people in prison in 2010.
The 2000 U.S. Census counted same-sex couples in an oblique way; asking the sex and the relationship to the "main householder", whose sex was also asked. One organization specializing in analyzing gay demographic data reported, based on this count in the 2000 census and in the 2000 supplementary survey, that same-sex couples comprised between 0.99% and 1.13% of U.S. couples in 2000. A 2006 report issued by The Williams Institute on Sexual Orientation concluded that the number of same-sex couples in the U.S. grew from 2000 to 2005, from nearly 600,000 couples in 2000 to almost 777,000 in 2005. A 2006 UCLA study reported that 4.1% of Americans aged 18–45 identify as gay, lesbian, or bisexual.
A 2011 report by the Institute estimated that 4 million adults identify as gay or lesbian, representing 1.7% of the population over 18. A spokesperson said that, until recently, few studies have tried to eliminate people who had occasionally undertaken homosexual behavior or entertained homosexual thoughts, from people who identified as lesbian or gay. (Older estimates have varied depending on methodology and timing; see Demographics of sexual orientation for a list of studies.) The American Community Survey from the 2000 U.S. Census estimated 776,943 same-sex couple households in the country as a whole, representing about 0.5% of the population.
Projections.
A report by the U.S. Census Bureau projects a decrease in the ratio of Whites between 2010 and 2050, from 79.5% to 74.0%. At the same time, Non-Hispanic Whites are projected to no longer make up a majority of the population by 2042, but will remain the largest single ethnic group. In 2050 they will compose 46.3% of the population. Non-Hispanic whites made up 85% of the population in 1960.
The report foresees the Hispanic or Latino population rising from 16% today to 30% by 2050, the Black percentage barely rising from 12.9% to 13.1%, and Asian Americans upping their 4.6% share to 7.8%. The United States had a population of 310 million people in October 2010, and is projected to reach 400 million by 2039 and 439 million in 2050. It is further projected that 82% of the increase in population from 2005 to 2050 will be due to immigrants and their children.
Of the nation's children in 2050, 62% are expected to be of a minority ethnicity, up from 44% today. Approximately 39% are projected to be Hispanic or Latino (up from 22% in 2008), and 38% are projected to be single-race, non-Hispanic Whites (down from 56% in 2008).
In 2008, the U.S. Census Bureau projected future censuses as follows:
Religion.
Religious affiliations in 2004.
The table below is based mainly on selected data as reported to the United States Census Bureau. It only includes the voluntary self-reported membership of religious bodies with 750,000 or more. The definition of a member is determined by each religious body. , the US census bureau reported that about 13% of the population did not identify themselves as a member of any religion.
In a Pew Research Survey performed in 2012, Americans without a religion (atheists, agnostics, nothing in particular, etc.) surpassed Evangelical Protestant Americans with almost 20% of Americans being nonreligious. If this current growth rate continues, by 2050, around 51% of Americans will not have a religion.
A survey conducted in 2014 by the same organization indicated that the percentage of Americans unaffiliated with a religion rose to nearly 23% of the population, up from 16% in 2007.
Religions of American adults.
The United States government does not collect religious data in its census. The survey below, the American Religious Identification Survey (ARIS) 2008, was a random digit-dialed telephone survey of 54,461 American residential households in the contiguous United States. The 1990 sample size was 113,723; 2001 sample size was 50,281.
Adult respondents were asked the open-ended question, "What is your religion, if any?". Interviewers did not prompt or offer a suggested list of potential answers. The religion of the spouse or partner was also asked. If the initial answer was "Protestant" or "Christian" further questions were asked to probe which particular denomination. About one-third of the sample was asked more detailed demographic questions.
Religious Self-Identification of the U.S. Adult Population: 1990, 2001, 2008<br>Figures are not adjusted for refusals to reply; investigators suspect refusals are possibly more representative of "no religion" than any other group.
Marriage.
In 2010, the median age for marriage for men was 27; for women, 26.
Income.
In 2006, the median household income in the United States was around $46,326. Household and personal income depends on variables such as race, number of income earners, educational attainment and marital status.
Economic class.
Social classes in the United States lack distinct boundaries and may overlap. Even their existence (when distinguished from economic strata) is controversial. The following table provides a summary of some prominent academic theories on the stratification of American society:
Health.
In 2010, the average man weighed ; the average woman . The height of an American man was and woman The average BMI is 27.3 for males (overweight) and 28.5 for females (overweight).
According to a Gallup poll in 2012, an estimated 26% of the population were obese, 21% smoked, and 11% had diabetes.
A nationwide study reported by the "New York Times" in 2010 indicated that 19.5% of teens, aged 12–19, had developed "slight" hearing loss. "Slight" was defined as an inability to hear at 16 to 24 decibels.
According to the Centers for Disease Control in 2011, an estimated 1.2 million people were living with HIV/AIDS in the United States.
Generational cohorts.
A study by William Strauss and Neil Howe, in their books "Generations" and "Fourth Turning", looked at generational similarities and differences going back to the 15th century and concluded that over 80-year spans, generations proceed through four stages of about 20 years each.
A definitive recent study of US generational cohorts was done by Schuman and Scott (2012) in which a broad sample of adults of all ages was asked, "What world events are especially important to you?" They found that 33 events were mentioned with great frequency. When the ages of the respondents were correlated with the expressed importance rankings, seven (some put 8 or 9) distinct cohorts became evident.
Today the following descriptors are frequently used for these cohorts (alive in 2000–10):
U.S. demographic birth cohorts.
Subdivided groups are present when peak boom years or inverted peak bust years are present, and may be represented by a normal or inverted bell-shaped curve (rather than a straight curve). The boom subdivided cohorts may be considered as "pre-peak" (including peak year) and "post-peak". The year 1957 was the baby boom peak with 4.3 million births and 122.7 fertility rate. Although post-peak births (such as trailing edge boomers) are in decline, and sometimes referred to as a "bust", there are still a "relatively" large number of births. The dearth-in-birth bust cohorts include those up to the valley birth year, and those including and beyond, leading up to the subsequent normal birth rate. The Baby boom began around 1943 to 1946.
From the decline in U.S. birth rates starting in 1958 and the introduction of the birth-control pill in 1960, the Baby Boomer normal distribution curve is negatively skewed. The trend in birth rates from 1958 to 1961 show a tendency to end late in the decade at approximately 1969, thus returning to pre-WWII levels, with 12 years of rising and 12 years of declining birth rates. Pre-war birth rates were defined as anywhere between 1939 and 1941 by demographers such as the Taeuber's, Philip M. Hauser and William Fielding Ogburn.
Demographic statistics.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Ages.
Median ages are 37.3 years; males are 36.1 years; females are 38.5 years estimated as of 2012.
As of 2012, people are distributed by age as follows:
Birth, growth, and death rates.
The growth rate is 0.760% as estimated from 2014-2010 by the US Census
The birth rate is 12.5 births/1,000 population, estimated as of 2013. This was the lowest since records began. There were 3,957,577 births in 2013.
In 2009, "Time magazine" reported that 40% of births were to unmarried women. The following is a breakdown by race for unwed births: 17% Asian, 29% White, 53% Hispanics, 66% Native Americans, and 72% African American.
The drop in the birth rate from 2007 to 2009 is believed to be associated with the Late-2000s recession.
A study by the Agency for Healthcare Research and Quality (AHRQ) found that more than half (51 percent) of live hospital births in 2008 and 2011 were male.
Death rate.
As of July 2010, it was estimated that there were 8.18 deaths/1,000 population.
Immigration and emigration.
Thirteen percent of the population was foreign-born in 2009 a rise of 350% since 1970 when foreign-born people accounted for 3.7% of the population,including 11.2 million undocumented aliens, 80% of whom come from Latin America. Latin America is the largest region-of-birth group, accounting for over half (53%) of all foreign born population in US, and thus is also the largest source of both legal and illegal immigration to US. In 2011, there are 18.1 million naturalized citizens in USA, accounting for 45% of the foreign-born population (40.4 million) and 6 percent of the total US population at the time, and around 680,000 legal immigrants are naturalized annually.
4.32 people migrate per 1,000 population, estimated in 2010.
Unemployment rate.
, the U.S. unemployment rate was 5.3 percent (U3 Rate).
, the U.S. unemployment rate was 6.2 percent (U3 Rate).
, the U6 unemployment rate is 14.9 percent. The U6 unemployment rate counts not only people without work seeking full-time employment (the more familiar U-3 rate), but also counts "marginally attached workers and those working part-time for economic reasons." Note that some of these part-time workers counted as employed by U-3 could be working as little as an hour a week. And the "marginally attached workers" include those who have gotten discouraged and stopped looking, but still want to work. The age considered for this calculation is 16 years and over.
Mobility.
In 2013, about 15% of Americans moved. Most of these, 67%, moved within the same county. Of the 33% who moved beyond local county boundaries, 13% of those moved more than .
See also.
Lists:
Income:
Population:

</doc>
<doc id="70198" url="https://en.wikipedia.org/wiki?curid=70198" title="Genipa">
Genipa

Genipa, the genip-trees, are a genus of flowering plants in the family Rubiaceae. This genus is closely allied to "Gardenia"; several "Gardenia" species were originally placed in "Genipa". It is not to be confused with genip ("Melicoccus bijugatus"), a completely unrelated eudicot. The name is derived from "genipapo", the Guianan name for "G. americana" (commonly known as huito). The genus is also commonly called jagua, xagua or xaqua.
Most authors today restrict "Genipa" to the New World species, transferring the Old World species to other genera. The ten species from Madagascar, originally described by Drake, are referred to as "Genipa sensu" Drake. They do not belong to the Rubiaceae tribe Gardenieae like the New World "Genipa" species and their Australasian relatives, but in the tribe Octotropideae. The "Genipa" species "sensu" Drake are better placed in the otherwise South African genus "Hyperacanthus". Other species are now in "Randia", and a number of additional genera. Altogether, a mere 3 species are nowadays included in "Genipa"; even of the Neotropical taxa, many are now included in the widespread and variable "G. americana".
Description.
Genip trees are shrubs and medium-sized (up to 18 m tall) trees, native to tropical regions of the Americas.
The bark is mostly smooth and gray. The dense foliage consists of opposite leaves that are sessile or with short peduncles. They are mostly clustered at the tips of the branches. The leathery leaves have an oblanceolate, elliptic or obovate shape. The ovate and acuminate stipules are interpetiolar, fused at base. 
The inflorescence is axillary or terminal. The flowers are solitary or few in a cyme. They are at first white or creamy-white, but turn yellow later on. The flowers are sexually dimorphic; they can be bisexual or functionally unisexual. The male flowers ripen before the female flowers. The short, tubular calyx has five or six small lobes. The bell-shaped corolla consists of five symmetrical left-contorted oblong petals, rounded at their apex. The stamens lie between the corolla lobes, exserting for half their length. The style projects beyond the corolla. The inferior ovary is 2-locular, with many ovules per locule. The fruit is a succulent berry with a thick rind, the size of a small lime.
The fruits of these culturally significant plants are edible. The wood is used in handicraft.
List of species.
The three remaining good species placed in "Genipa" are:
Formerly placed here.
In addition to those species now in "Gardenia", "Hyperacanthus" and "Randia", former members of "Genipa" are:
"Genipa vaginata" Baill. from New Caledonia is of unclear affiliation, but almost certainly does not actually belong in the present genus.

</doc>
<doc id="70201" url="https://en.wikipedia.org/wiki?curid=70201" title="Federal republic">
Federal republic

A federal republic is a federation of states with a democratic form of government. Usage of the term "republic" is inconsistent. At its core, the literal meaning of the word republic when used to reference a form of government means: "a state where sovereignty rests with the people or their representatives, rather than with a monarch or emperor; a country with no monarchy".
In a federal republic, there is a division of powers between the federal government and the government of the individual subdivisions. While each federal republic manages this division of powers differently, common matters relating to security and defense, and monetary policy are usually handled at the federal level, while matters such as infrastructure maintenance and education policy are usually handled at the regional or local level. However, views differ on what issues should be a federal competence, and subdivisions usually have sovereignty in some matters where the federal government does not have jurisdiction. A federal republic is thus best defined in contrast to a unitary republic, whereby the central government has complete sovereignty over all aspects of political life. As in the United States, most federal republics codify the division of powers between orders of government in a written constitutional document.
The political differences between a federal republic and other federal states, especially federal monarchies under a parliamentary system of government, are largely a matter of legal form rather than political substance, as most federal states are democratic in structure if not practice. However, some federal monarchies, such as the United Arab Emirates are based upon principles other than democracy.

</doc>
<doc id="70206" url="https://en.wikipedia.org/wiki?curid=70206" title="Picnic at Hanging Rock (novel)">
Picnic at Hanging Rock (novel)

Picnic at Hanging Rock is a 1967 Australian historical novel by Joan Lindsay. The plot focuses on a group of female students at an Australian women's college in 1900 who inexplicably vanish at the site of an enormous rock formation while on a Valentine's Day picnic, and also explores the outlying effects the girls' disappearance has on the community. The novel has been often discussed and debated due to its inexorably ambiguous ending.
Lindsay wrote the novel over a four-week period at her home Mulberry Hill in Baxter, on Victoria's Mornington Peninsula. It was first published in 1967 in Australia by Cheshire Publishing and was released in paperback by Penguin in 1970.
The rock formation featured in the story, Hanging Rock, is an actual geological formation located in Victoria, Australia. The novel was adapted into a critically acclaimed film of the same name in 1975 by director Peter Weir.
Synopsis.
At Appleyard College, an upper-class women's private boarding school, a picnic is being planned for the students under the supervision of Mrs. Appleyard, the school's headmistress. The picnic entails a day trip to Hanging Rock in the Mount Macedon area, Victoria, on St. Valentine's Day in 1900. One of the students, Sara, who is in trouble with Mrs. Appleyard, is not allowed to go. Sara's close friend Miranda, who is described as an ethereal girl, goes without her. When they arrive, the students lounge about and eat a lunch. Afterward, Miranda goes to climb the rock with classmates Edith, Irma, and Marion. The girls' mathematics teacher, Greta McCraw, follows behind them. As they ascend the rock, in a dreamlike episode, Miranda, Marion, and Irma vanish into the rock while Edith watches; she returns to the picnic in hysterics, disoriented and with no memory of what occurred. Miss McCraw is also nowhere to be accounted for. The school scours the rock in search of the girls and their teacher, but they are not found.
The disappearances provoke much local concern and international sensation with sexual molestation, abduction and murder being high on the list of possible outcomes. Several organized searches of the picnic grounds and the area surrounding the rock itself turn up nothing. Meanwhile, the students, teachers and staff of the college, as well as members of the community, grapple with the riddle-like events. A young man on a private search finds one of the missing girls, but is himself found in an unexplained daze – yet another victim of the rock. Concerned parents begin withdrawing their daughters from the formerly prestigious college and several of the staff, including the headmistress, either resign or meet with tragic ends. We are told that both the college, and the Woodend Police Station where records of the investigation were kept, are destroyed by fire shortly afterwards.
Interpretations.
The unsolvable mystery of the disappearances was arguably the key to the success of both the book and the subsequent film. This aroused enough lasting public interest that in 1980 a book of hypothetical solutions (by Yvonne Rousseau) was published, called "The Murders at Hanging Rock".
The novel is written in the form of a true story, and even begins and ends with a pseudo-historical prologue and epilogue, adding to the overall feeling of mystery. However, while the geological feature, Hanging Rock, and the several towns mentioned are actual places near Mount Macedon, the story is fiction. Lindsay had done little to dispel the myth that the story is based on truth, in many interviews either refusing to confirm it was entirely fiction, or hinting that parts of the book were fictitious, and others were not. Valentine's Day, 14 February 1900 was a Wednesday, not a Saturday as depicted in the story. All attempts by enthusiastic readers to find historical evidence of the event, characters, or even Appleyard College, have proved fruitless.
Appleyard College was to some extent based on Clyde Girls' Grammar School at East St Kilda, Melbourne, which Joan Lindsay attended as a day-girl while in her teens. Incidentally, in 1919 this school was transferred to the town of Woodend, Victoria, about 8 km southwest of Hanging Rock. The book suggests that the fictional site of Appleyard College, given its eastward view of Mount Macedon on the Bendigo-Melbourne Road, might have been on the western side of Calder Highway/Black Forest Drive (C792), about 2–4 km south of Woodend.
Excised final chapter.
According to her editor, Lindsay's original draft of the novel included a final chapter in which the mystery was resolved. At her editor's suggestion, Lindsay removed it prior to publication. Chapter Eighteen, as it is known, was published posthumously in 1987 as "The Secret of Hanging Rock" by Angus & Robertson Publishing.
In this chapter, each girl begins to experience dizziness and feel as if she is "being pulled from the inside out"; they then throw their corsets from the top of the cliff but, instead of falling, the corsets stand still in mid-air. The girls then encounter what is described as "a hole in space", by which they physically enter a crack in the rock. The suspension of the corsets and description of the hole in space suggest that the girls have encountered some sort of time warp, which is compatible with Lindsay's fascination with and emphasis on clocks and time in the novel.
Adaptations.
Film.
The first film adaptation of the book was a short by Tony Ingram, a fourteen-year-old filmmaker, who got permission from Joan Lindsay to adapt her book as "The Day of Saint Valentine." However, only about ten minutes of footage was filmed before the rights were optioned to Peter Weir for his more famous feature-length version, and the production was permanently shelved. The completed footage is included on some DVD releases of Weir's film.
The feature film version of "Picnic at Hanging Rock" premiered at the Hindley Cinema Complex in Adelaide on 8 August 1975. It became an early film of the Australian New Wave and is arguably Australia's first international hit film.
Theatre.
"Picnic at Hanging Rock" was adapted by playwright Laura Annawyn Shamas in 1987 and published by Dramatic Publishing Company. Subsequently, it has had many productions in the US, Canada, and Australia. There have also been musical adaptations of the novel.
A stage-musical adaptation, with book, music, and lyrics by Daniel Zaitchik, was scheduled to open in New York City in the fall of 2012. The musical received a 2007 staged reading at New York's Lincoln Center, and further workshop development at the 2009 O'Neill Theater Center National Music Theater Conference. The musical had its world premiere on 28 February 2014 at Weber State University in Ogden, Utah under the direction of Jim Christian. The cast included Amelia Moore, Jenessa Bowen, Casey Greenwood, Kacee Neff, Shae Wilson, Erin Crouch, Bailee DeYoung, Katie Jones, MeiLee Ballard, Emily Wells, Mandie Harris, Alice Gittins, Amanda Shaffer, Jason Baldwin, Nate Waite, Aaron Ross, Brittany Wood and Clayton Porter.
Radio.
In 2010, BBC Radio 4 broadcast a radio adaptation. The cast included Simon Burke, Penny Downie, Anna Skellern and Andi Snelling.

</doc>
<doc id="70208" url="https://en.wikipedia.org/wiki?curid=70208" title="Henry Stuart, Lord Darnley">
Henry Stuart, Lord Darnley

Henry Stuart (or Stewart), Duke of Albany (7 December 1545 – 10 February 1567), styled Lord Darnley until 1565, was king consort of Scotland from 1565 until his murder at Kirk o' Field in 1567. Many contemporary narratives describing his life and death refer to him as Lord Darnley, his title as heir apparent to the Earldom of Lennox, and it is by this appellation that he is now generally known.
He was the second but eldest surviving son of Matthew Stewart, 4th Earl of Lennox, and his wife, Lady Margaret Douglas. Darnley's maternal grandparents were Archibald Douglas, sixth Earl of Angus, and Margaret Tudor, daughter of Henry VII of England, and widow of James IV of Scotland. It is the common belief that Henry Stewart was born on 7 December, but this is disputed. He was a first cousin and the second husband of Mary, Queen of Scots, and was the father of her son James VI of Scotland, who succeeded Elizabeth I of England as James I.
Early life.
Darnley was born in 1545, at Temple Newsam, Leeds, in the West Riding of Yorkshire, England. Through his parents he had claims to both the Scottish and English thrones, as he was descended from both James II of Scotland and Henry VII.
Darnley's father, Matthew Earl of Lennox, had been declared guilty of treason in Scotland for his part in the war of the Rough Wooing, siding with the English as an opponent of Mary of Guise and Regent Arran, and his Scottish estates were forfeited in 1545. Lennox lived in exile in England for 22 years, returning to Scotland in 1564. Darnley's mother, Margaret Douglas had left Scotland in 1528.
Lord Darnley was well educated and brought up conscious of his status and inheritance. He became well-versed in Latin and grew up familiar with Gaelic, English and French. He excelled in singing, lute playing, and dancing. His tutors included the Scottish scholar, John Elder, who had been an advocate of Anglo-Scottish union by a marriage of Mary, Queen of Scots, to Prince Edward, and gave his opinions to Henry VIII as the "Advice of a Redshank" in 1543. Another of his schoolmasters, Arthur Lallart, was interrogated in London after going to Scotland in 1562.
Darnley was strong and athletic, a good horseman with knowledge of weapons and a passion for hunting and hawking. Darnley wrote a letter to Mary I of England from Temple Newsam in March 1554 mentioning a drama or map he had made, the "Utopia Nova". He wished, "every haire in my heade for to be a wourthy souldiour".
Lennox Crisis.
The "Lennox crisis" was a political dilemma in England that arose from the dynastic ambition of the Lennoxes: Matthew Stewart, 4th Earl of Lennox, was third in line to the Scottish throne, and his wife Margaret Douglas was niece to Henry VIII and granddaughter of Henry VII. The Lennox family were Roman Catholic and might therefore have represented an alternative succession in England.
When Henry II of France died in July 1559, Lennox's brother, the Sieur d'Aubigny, was elevated in the French court as kinsman of the new queen, Mary, Queen of Scots. Aubigny arranged for Darnley to be dispatched to the French court to congratulate Mary and Francis II of France on their accession and seek restoration for Lennox. Mary did not restore Lennox to his Scottish earldom, but she did give 1,000 crowns to Darnley and invited him to her coronation. Lennox's plan was to appeal directly to the Queen of Scots via her ambassador, above the heads of Elizabeth and the Guise. The mission of Lennox's agent, one Nesbit, appears to have been a desperate one; not only was Lennox willing to hand over Darnley and his brother Charles as hostages for his restoration, but he supplied pedigrees of Darnley, indicating his right to the inheritance of England and Scotland and the houses of Hamilton and Douglas. Aubigny was also later accused of supporting Mary's title to the throne of England and hinting that even his nephew had a stronger claim than Elizabeth.
Lennox set Nesbit to watch Mary, Darnley and Darnley's tutor, John Elder. In 1559 Nicholas Throckmorton, the English ambassador in Paris, warned Elizabeth that Elder was "as dangerous for the matters of England as any he knew." 
The historian Sarah Macauley notes, "After the Queen of Scots, Lord Darnley was the strongest dynastic claimant to Elizabeth's throne. He was also the natural choice for many of Elizabeth's enemies as male, English-born and Catholic. Paget supposed in March 1560 that talk of the Catholics raising Darnley to the throne in the event of the Queen's death was 'well founded'." 
By the summer of that year, Elizabeth's position was considerably strengthened. Francis Yaxley was one notable spy. A Catholic, Yaxley had been a clerk of the Signet and had been employed by William Cecil since 1549, travelling in France for him. Yaxley had placed Mabel Fortescue and other ladies as servants in the Lennox household at Settrington in November 1560. Yaxley had been employed by Margaret Douglas; his interrogation at the Tower of London in February 1562 revealed that he had obtained intelligence about the English Court from the Spanish ambassador, and the ambassador had entrusted him and Hugh Allen with messages and tokens for the Lennoxes and Darnley. Yaxley admitted that his missions were intended to arrange the marriage of the Queen of Scots with Darnley, that Darnley's religion guaranteed him greater success in his suit than the Earl of Arran, and that Margaret Douglas had many friends "in the nurtht." Although the Lennox threat never died out, Elizabeth did not convict the family of treason in 1562 after their arrest nor did she encourage steps made to annul Margaret's claim to her throne by inquiring into her legitimacy. Perhaps, as has been suggested, Elizabeth feared that these investigations could also be directed at herself, or her inaction was intended merely to ensure the survival of the monarchy by not reducing the number of potential heirs. The Lennox family were released in February 1563, and within a few months, Darnley and his mother were conspicuous by their presence at Court and the favour they received there, although Elizabeth would not accommodate the Earl at Court.
Sarah Macauley notes three outcomes of the courts' final decision of the Lennox trial:"Their elevation at Court was, as it turned out in 1563, a useful complication in the succession issue. First, it presented a public statement that the preferences of Parliament (the claim of Catherine Grey in the succession crisis) could not dictate her own policy. Secondly, favouring the Lennoxes could serve as some kind of appeasement of the English Roman Catholics, who, like the Spanish ambassador, might foresee Elizabeth naming Darnley as her successor... Such speculation would also distract them from favouring the more alarming claim of the Queen of Scots ... Thirdly, and most significantly, the elevation of the Lennoxes presented an obstacle between the Queen of Scots and the English throne. Thus was Darnley's uniquely 'British' inheritance put to use at last ...The subsequent release of Darnley into Scotland and the restoration of his father at the Scottish Court were part of this policy: the political disaster of the Darnley marriage as yet unforeseen."
In September 1564, the Scottish Parliament restored Matthew Stewart's rights and titles as Earl of Lennox, and listened to a lengthy speech from the Queen's secretary William Maitland, who offered;"it may be affirmid Scotland in na manis age that presentlie levis wes in gritter tranquillitie."
Marriage to the Queen of Scots.
On 3 February 1565 Darnley left London and by 12 February he was in Edinburgh. On 17 February he presented himself to Mary at Wemyss Castle in Fife. James Melville of Halhill reported that "Her Majesty took well with him, and said that he was the lustiest and best proportioned long man that she had seen." After a brief visit to his father at Dunkeld, Darnley returned with Mary and the court to Holyrood on 24 February. The next day he heard John Knox preach, and he danced a galliard with Mary at night. From then on, he was constantly in Mary's company.
Darnley was his wife's first cousin through Margaret Tudor, putting both Mary and Darnley high in the line of succession for the English throne. Darnley was also a descendant of a daughter of James II of Scotland and so also in line for the throne of Scotland.
As a preliminary to the marriage, Darnley was made Lord of Ardmanoch and Earl of Ross at Stirling Castle on 15 May 1565. An entourage of 15 men were made knights, including one of Mary's half brothers, Sir Robert Stewart of Strathdon, Robert Drummond of Carnock, and James Stewart of Doune Castle. In England, a concerned Privy council debated the perils of the intended marriage on 4 June 1565. One of their resolutions was to relax the displeasure shown to Lady Catherine Grey, another rival to Mary Stuart for the English throne. Mary sent John Hay, Commendator of Balmerino, to speak to Elizabeth; Elizabeth demanded Darnley's return, and gave John Hay plainly to understand her small satisfaction.
On 22 July, Darnley was made Duke of Albany in Holyrood Abbey, and the banns of marriage were called in the parish of Canongate. A proclamation was made at the Cross of Edinburgh on 28 July that government would be in the joint names of the king and queen of Scots, thus giving Darnley equality with, and precedence over, Mary. This was confirmed in the circulation of a silver ryal in the names of Henry and Mary. 
On 29 July 1565, the marriage took place by Roman Catholic rites in Mary's private chapel at Holyrood, but Darnley (whose religious beliefs were unfixed – he was raised as a Catholic, but was later influenced by Protestantism) – refused to accompany Mary to the nuptial mass after the wedding itself.
Estrangement.
Soon after Mary married Darnley, she became aware of his vain, arrogant and unreliable qualities, which threatened the well-being of the state. Henry was unpopular with the other nobles and had a violent streak, aggravated by his drinking. Mary refused to grant Darnley the Crown Matrimonial, which would have made him the successor to the throne if she died childless. By August 1565, less than a month after the marriage, William Cecil heard that Darnley's insolence had driven Lennox from the Scottish court. Mary soon became pregnant. 
Mary's private secretary, David Rizzio was stabbed 56 times on 9 March 1566 by Lord Darnley and his friends in the presence of the seven-months-pregnant queen in her dining room. According to English diplomats Thomas Randolph and the Earl of Bedford, the murder of Rizzio (who was rumoured to be the father of Mary's unborn child) was part of Darnley's bid to force Mary to cede the Crown Matrimonial. Darnley also made a bargain with his allies to advance his claim to the Crown Matrimonial in the Parliament of Scotland in return for restoring their lands and titles.
When the Spanish Ambassador in Paris heard this news, the headlines were that Darnley "had murdered his wife, admitted the exiled heretics, and seized the kingdom." However, on 20 March, Darnley posted a declaration denying all knowledge of or complicity in the Rizzio murder. 
Mary no longer trusted her husband, and he was disgraced by the kingdom. On 27 March, the Earl of Morton and Lord Ruthven, who were both present at Rizzio's murder and had fled to England, wrote to Cecil claiming that Darnley had initiated the murder plot and recruited them, because of his "heich quarrel" and "deadly hatred" of Rizzio.
Birth of James I of England and VI of Scotland.
Mary and Darnley's son James was born on 19 June 1566 at Edinburgh Castle. He was baptised Charles James on 17 December 1566 in a Catholic ceremony held at Stirling Castle. His godparents were Charles IX of France, Elizabeth I of England and Emmanuel Philibert, Duke of Savoy. Mary refused to let the Archbishop of St Andrews, whom she referred to as "a pocky priest", spit in the child's mouth, as was then the custom. In the entertainment, devised by Frenchman Bastian Pagez, men danced dressed as satyrs and sporting tails; the English guests took offence, thinking the satyrs "done against them".
Following the birth of James the succession was more secure; in late 1566 and early 1567, Darnley and Mary appeared to be close to reconciliation as she was often seen visiting his chambers. Darnley, however, alienated many who would otherwise have been his supporters through his erratic behaviour. His insistence that he be awarded the Crown Matrimonial was still a source of marital frustration.
Death.
Darnley was murdered eight months after James's birth. On 9 February 1567, his body and that of his valet were discovered in the orchard of Kirk o' Field, in Edinburgh, where they had been staying.
During the weeks leading up to his death, Darnley was recovering from a bout of smallpox (or, it has been speculated, syphilis). He was described as having deformed pocks upon his face and body. He stayed with his family in Glasgow, until Mary brought him to recuperate at Old Provost's lodging at Kirk o' Field, a two-storey house within the church quadrangle, a short walk from Holyrood – with the intention of incorporating him into the court again. Darnley stayed at Kirk o' Field while Mary attended the wedding of Bastian Pagez, one of her closest servants, at Holyrood. Around 2 am on the night of 10 February 1567, while Mary was away, two explosions rocked the foundation of Kirk o' Field. These explosions were later attributed to two barrels of gunpowder that had been placed in the small room under Darnley's sleeping quarters. Darnley's body and the body of his valet William Taylor, were found outside, surrounded by a cloak, a dagger, a chair and a coat. Darnley was dressed only in his nightshirt, suggesting he had fled in some haste from his bedchamber. Upon further examination, the bodies had no signs of injuries that could be associated with the explosion, so the blast was not considered to have killed Darnley. It was determined that the two men were killed by strangulation, believed to have taken place after the explosion. (However, modern medicine recognises that internal injuries can kill explosion victims with no sign of injury.)
Aftermath.
Suspicion quickly fell on the Earl of Bothwell and his supporters, notably Archibald Douglas, Parson of Douglas, whose shoes were found at the scene, and on Mary herself. Bothwell had long been suspected of having designs on the throne, and his close relationship with the queen gave rise to rumours they were sexually intimate. This was viewed as a motive for Bothwell to have Darnley murdered, with help from some of the nobility and seemingly with royal approval. Mary had been looking at options for removing Darnley, though her ideas were for divorce, and none were suitable.
Soon after Darnley's death, Bothwell and Mary left Edinburgh together. There are two points of view about the circumstances: in the first, Bothwell kidnapped the queen, took her to Dunbar Castle, and raped her. In the second, Mary was a willing participant in the kidnapping, and the story of rape was a fabrication so her honour and reputation were not ruined by her marriage to a man widely suspected of murder. Mary later miscarried twins by Bothwell.
Suspicions that Mary colluded with conspirators in her husband's death or that she took no action to prevent his death were key factors in the downward spiral that led to Mary's loss of the Scottish crown. The Casket letters, alleged to have been written by Mary, seemed to indicate her support for the killing. The letters were purportedly found by James Douglas, 4th Earl of Morton in Edinburgh in a silver box engraved with an F (supposedly for Francis II), along with a number of other documents, including the Mary-Bothwell marriage certificate. Before Morton's execution in 1581, he admitted having knowledge of the murder plot, and that Bothwell and Archibald Douglas were "chief actors" in Darnley's murder.
A soldier under the pay of Bothwell, William Blackadder of the Clan Blackadder, was allegedly the first non-participant to happen upon the scene, and for that reason was initially treated as a suspect. Although initially cleared of any involvement in the murder, he was offered up by the conspirators and convicted at a show trial, after which he was executed by being hanged, drawn and quartered before each of his limbs was nailed to the gates of a different Scottish town.
Not long after that, both Mary and Bothwell were charged with Henry's murder. They were given separate trials in England. Bothwell was found not guilty. Mary's trial took longer, ending with no definitive finding. Mary was kept in captivity until she was implicated in the Babington plot against Elizabeth, after which she was convicted of treason and executed.

</doc>
<doc id="70209" url="https://en.wikipedia.org/wiki?curid=70209" title="Cinema of Australia">
Cinema of Australia

The Australian film industry has its beginnings with the 1906 production of "The Story of the Kelly Gang", the earliest feature film ever made. Since then, many films have been produced in Australia, a number of which have received international recognition. Many actors and filmmakers started their careers in Australian films, a large number of whom have acquired international reputations, and a number of whom have found greater financial benefits in careers in larger film producing centers, such as in the United States.
Cinema in Australia began with the first public screenings of films in Australia in October 1896, within a year of the world's first screening in Paris by Lumière brothers. The first Australian exhibition took place at the Athenaeum Hall in Collins Street, Melbourne, to provide alternative entertainment for the dance hall patrons. The venue would continue screenings, but these were all short films.
Commercially successful Australian films have included Paul Hogan's ""Crocodile" Dundee", Baz Luhrmann's "Moulin Rouge!" , and Chris Noonan's "Babe". Other award winning productions include "Picnic at Hanging Rock", "Gallipoli", "The Tracker", "Shine" and "Ten Canoes".
Australian actors of renown include Errol Flynn, Peter Finch, Rod Taylor, Mel Gibson, Guy Pearce, Nicole Kidman, Geoffrey Rush, Toni Collette, Hugh Jackman, Russell Crowe, Eric Bana, Cate Blanchett, Heath Ledger, Chris Hemsworth, Liam Hemsworth and Sam Worthington.
History.
The Australian film history has been characterized as one of 'boom and bust' due to the unstable and cyclical nature of its industry; there have been deep troughs when few films were made for decades and high peaks when a glut of films reached the market.
Pioneer days – 1890s–1910.
The Athanaeum Hall in Collins Street, Melbourne, was a dance hall from the 1880s, which from time to time would provide alternative entertainment to patrons. In October 1896, it exhibited the first movie shown in Australia, within a year of the first public screening of a film in Paris on 28 December 1895 by the French Lumière brothers. The Athanaeum would continue screenings, but these early screenings were all short films. The earliest feature length narrative film in the world was the Australian produced "The Story of the Kelly Gang" (1906), also shown at the Athenaeum. The film was written and directed by Charles Tait and included several of his family. The film was also exhibited in the United Kingdom, and was commercially very successful.
Melbourne was also home of one of the world's first film studios, the Limelight Department, operated by The Salvation Army between 1897 and 1910. The Limelight Department produced evangelical material for use by the Salvation Army, as well as private and government contracts. In its 19 years of operation, the Limelight Department produced about 300 films of various lengths, making it the largest film producer of its time. The major innovation of the Limelight Department came in 1899 when Herbert Booth and Joseph Perry began work on "Soldiers of the Cross", described by some as the first feature-length film ever produced. "Soldiers of the Cross" fortified the Limelight Department as a major player in the early film industry. The Limelight Department was commissioned to film the Federation of Australia.
Boom and bust – 1910s–1920s.
The 1910s was a "boom" period in Australian cinema. It began slowly in the 1900s, and 1910 saw 4 narrative films released, then 51 in 1911, 30 in 1912, and 17 in 1913, and back to 4 in 1914, when the beginning of World War I brought an end to film making. While these numbers may seem small, Australia was one of the most prolific film-producing countries at the time. In all, between 1906 and 1928, 150 narrative feature films were made, of which almost 90 were made between 1910 and 1912.
There was a general consolidation in the early 1910s in the production, distribution and exhibition of films in Australia which saw by 1912 the merger of numerous independent producers into Australasian Films and Union Theaters which established control over film distributors and cinemas and required smaller producers to deal with the cartel. Some view the arrangement as opening the way for American distributors in the 1920s to sign exclusive deals with Australian cinemas to exhibit only their products, thereby shutting out the local product and crippling the local film industry.
There are various other explanations for the decline of the industry in the 1920s. Some historians point to falling audience numbers, a lack of interest in Australian product and narratives, and Australia's participation in the war. Also, there was an official ban on bushranger films in 1912. With the suspension of local film production, Australian cinema chains sought alternative products in the United States and realised that Australian-produced films were much more expensive than the imported product, which were priced cheaply as production expenses had already been recouped in the home market. To redress this imbalance, the federal government imposed a tax on imported film in 1914, but this was removed by 1918.
Whatever the explanation, by 1923, American films dominated the Australian market with 94% of all exhibited films coming from that country.
1930s–1960s.
In 1930, F.W. Thring (1883–1936) established the Efftee Studios based in Melbourne to make talking films using optical sound equipment imported from the USA. The first sound films produced were in 1931, when the company produced "Diggers" (1931), "A Co-respondent's Course" (1931), "The Haunted Barn" (1931) and "The Sentimental Bloke" (1932). During the five years of its existence, Efftee produced nine features, over 80 shorts and several stage productions. Notable collaborators included C. J. Dennis, George Wallace and Frank Harvey. Film production continued only until 1934, when it ceased as a protest over the refusal of the Australian government to set Australian film quotas, followed soon by Thring's death. It was estimated Thring lost over ₤75,000 of his own money on his filmmaking and theatrical ventures.
Cinesound Productions was established in 1931 with Ken G. Hall as its main driving force. The company was one of Australia's first feature film production companies which operated into the early 1940s and became Australia's leading domestic studio, based on the Hollywood model. The company also used the Hollywood model for the promotion of its films and attempted to promote a star system. It was particularly successful with the "On Our Selection" (1932) series of comedies, based on the popular writings of author Steele Rudd, which featured the adventures of a fictional Australian farming family, the Rudds, and the perennial father-and-son duo, 'Dad and Dave'. Despite its ambitions, Cinesound produced only 17 feature films, all but one being directed by Ken Hall. The company was financially successful. The company ceased making feature films with the outbreak of World War II.
In 1933, "In the Wake of the Bounty", directed by Charles Chauvel, cast Tasmanian born Errol Flynn in a leading role, before he went on to a celebrated Hollywood career. Chauvel directed a number of successful Australian films, including 1944's World War II classic "The Rats of Tobruk" which starred Peter Finch and Chips Rafferty and 1955's "Jedda", which was notable for being the first Australian film to be shot in colour, and the first to feature Aboriginal actors in lead roles and to be entered at the Cannes Film Festival.
The Cinematograph Films Act 1927 established a quota of films that had to be shown in British cinemas that would be shot in Great Britain as well as nations in the British Empire that stimulated Australian film production. However the Cinematograph Films Act 1938 mollified the British film industry by specifying only films made by and shot in Great Britain would be included in the quota that removed Australian films from the British local film quota, which saw the loss of a guaranteed market for Australian films.
The first Australian Oscar was won by 1942's "Kokoda Front Line!", directed by Ken G. Hall. Chips Rafferty and Peter Finch were prominent international stars of the period. Rafferty's onscreen image as a lanky, laconic bushman struck a chord with filmgoers and he appeared in iconic early Australian films such as "Forty Thousand Horsemen", "The Rats of Tobruk", "The Overlanders" and "Eureka Stockade" ("Overlanders" and "Eureka" were part of a series of Australian themed films produced by Britain's iconic Ealing Studios). In Hollywood, Rafferty also appeared in Australian themed films, including "The Desert Rats", "The Sundowners" and "Mutiny on the Bounty". Similarly, Peter Finch starred in quintessentially Australian roles (such as "Digger" or stockman) through a series of popular films and had a successful and diverse screen career in Britain and the United States.
Both Ron Randell and Rod Taylor began their acting careers in Australia initially in radio and on stage before appearing in such Australian films as "Smithy" (1946) for the former and "Long John Silver" (1954) for the latter before transferring to the United States to become a Hollywood leading men in a number of films of the late 1940s (Randell) and both from the 1950s onwards' Taylor had with starring roles in "The Time Machine" (1960) and "The Birds" (1963) as well as several American TV series such as "Hong Kong".
Several notable films based on stories from Australian literature (generally with strong rural themes) were made in Australia in the 1950s – but by British and American production companies, including "A Town Like Alice" (1956) which starred Virginia McKenna and Peter Finch; "The Shiralee" (1957) also starring Peter Finch with Australian actors Charles Tingwell, Bill Kerr and Ed Devereaux in supporting roles; "Robbery Under Arms", again starring Finch in 1957; and "Summer of the Seventeenth Doll" (1959), starring Ernest Borgnine, John Mills and Angela Lansbury; and in 1960, "The Sundowners" was shot partly in the Snowy Mountains of New South Wales with foreign leads Deborah Kerr, Robert Mitchum, and Peter Ustinov but a supporting cast including Australians Chips Rafferty, John Meillon and Leonard Teale.
In 1958, the Australian Film Institute was formed and in the same year began awarding the Australian Film Institute Awards.
Australian film production was reaching a low ebb with few notable productions during the 1960s. The 1966 comedy "They're a Weird Mob", starring Walter Chiari, Chips Rafferty and Clare Dunne was a rare hit of the period which also documented something of the changing face of Australian society: telling the story of a newly arrived Italian immigrant who, working as a labourer in Sydney, becomes mates with his co-workers, despite some difficulties with Australian slang and culture. The film foreshadowed the successful approaching "New Wave" of Australian cinema of the 1970s that would often showcase colloquial Australian culture.
There continued to be an appeal for Australian actors in Hollywood as "action-men", with the casting of Australian George Lazenby to replace Sean Connery portraying the superspy James Bond in the 1969 film "On Her Majesty's Secret Service".
Film renaissance – 1970s and 1980s.
John Gorton, Prime Minister of Australia from 1968–1971, initiated several forms of government support for film and the arts. The Gough Whitlam government (1972–75) continued to support Australian film and state governments also established assistance programs.
These measures led to the resurgence of Australian film called the Australian New Wave, which lasted until the mid-late 1980s. The era also marked the emergence of the "Ozploitation" style – characterised by the exploitation of colloquial Australian culture.
Films such as "Picnic at Hanging Rock" (Peter Weir, 1975) and "Sunday Too Far Away" (Ken Hannam, 1975) made an impact on the international arena. The 1970s and '80s are regarded by many as a 'golden age' of Australian cinema, with many successful films, from the dark science fiction of "Mad Max" (George Miller, 1979) to the romantic comedy of ""Crocodile" Dundee" (Peter Faiman, 1986) and the emergence of such film directing auteurs as Gillian Armstrong, Phillip Noyce and Bruce Beresford.
A major theme of Australian cinema which matured in the 1970s was one of survival in the harsh Australian landscape. A number of thrillers and horror films dubbed "outback gothic" have been created, including "Wake in Fright", "Walkabout", "The Cars That Ate Paris" and "Picnic at Hanging Rock" in the 1970s, "Razorback" and "Shame" in the 1980s and "Japanese Story", "The Proposition" and "Wolf Creek" in the 2000s. These films depict the Australian bush and its creatures as deadly, and its people as outcasts and psychopaths. These are combined with futuristic post-apocalyptic themes in the Mad Max series. 1971's Walkabout was a British film set in Australia which was a forerunner to many Australian films related to indigenous themes and introduced David Gulpilil to cinematic audiences. 1976's The Chant of Jimmie Blacksmith directed by Fred Schepisi was an award winning historical drama from a book by Thomas Keneally about the tragic story of an Aboriginal Bushranger.
Classic stories from Australian literature and Australian history continued to be popular subjects for cinematic adaptation during the 1970s and 1980s. Gillian Armstrong's "My Brilliant Career" (1979) featured Judy Davis and Sam Neill in early lead roles. 1982's "We of the Never Never" followed up on the theme of the female experience of life in the Australian bush. 1982's "The Man from Snowy River" starring Tom Burlinson and Sigrid Thornton dramatised the classic Banjo Paterson poem of that name and became one of the all time box-office successes of Australian cinema. In addition to the serious historical dramas popular in the 1970s, a number of films celebrating and satirizing Australian colloquial culture were produced over the decade, including: "The Adventures of Barry McKenzie" (1972), "Alvin Purple" (1973), and "Barry McKenzie Holds His Own" (1974). The Barry McKenzie films saw performing-artist and writer Barry Humphries collaborating with director Bruce Beresford. In 1976, Peter Finch was awarded a posthumous Academy Award for Best Actor for his role in the American satire "Network", becoming the first Australian to win an Oscar for best actor.
1980's "Breaker Morant" starring Jack Thompson and Bryan Brown dramatised the controversial trial of an Australian soldier during the Boer War and was followed by 1981's World War I drama "Gallipoli" directed by Peter Weir and starring Mel Gibson. These films, now considered classics of Australian cinema explored contemporary Australian identity through dramatic episodes in Australian history. Gibson went on to further success in 1982's "The Year of Living Dangerously" before transferring to pursue his Hollywood career as an actor and director. Many other Australian stars would follow his path to international stardom in the coming decades. "The Year of Living Dangerously" was directed by Peter Weir, who also made a successful transition to Hollywood. Weir contributed to the screenplay along with its original author Christopher Koch, and playwright David Williamson. Williamson rose to prominence in the early 1970s, and has gone on to write several other original scripts and screenplays made into successful Australian films including: "Don's Party" (1976); "Gallipoli" (1981), "Emerald City" (1988), and "Balibo" (2009).
Actor/comedian Paul Hogan wrote the screenplay and starred in the title role in his first film, ""Crocodile" Dundee" (1986), about a down-to-earth hunter who travelled from the Australian Outback to New York City. The movie became the most successful Australian film ever, and launched Hogan's international film career. Following the success of "Crocodile" Dundee Hogan starred in the sequel, ""Crocodile" Dundee II" in 1988. 1988 also saw the release of the drama "Evil Angels" (released outside of Australia and New Zealand as "A Cry in the Dark") about the Lindy Chamberlain saga, in which a baby was taken by a dingo at Ayers Rock and her mother was accused of having murdered the child.
Nicole Kidman began appearing in Australian children's TV and Film in the early 1980s – including starring roles in "BMX Bandits" and "Bush Christmas". During the 1980s, she appeared in several Australian productions, including "Emerald City" (1988), and "Bangkok Hilton" (1989), and in 1989, Kidman starred in "Dead Calm" alongside Sam Neill and Billy Zane. The thriller garnered strong reviews and Hollywood roles followed.
1990–present.
The 1990s proved a successful decade for Australian film and introduced several new stars to a global audience. Low budget films such as the comedy/drama "Muriel's Wedding", starring Toni Collette, the gently satirical suburban comedy "The Castle" directed by Rob Sitch (which cast Eric Bana in his first prominent film role), and Baz Luhrmann's flamboyant "Strictly Ballroom" each attained commercial and critical success, and explored quirky characters inhabiting contemporary Australian suburbia – marking something of a departure from the Outback and historical sagas which obtained success in the 1970s and 1980s. Stephan Elliott's 1994 film "Priscilla Queen of the Desert" mixed traditional outback cinematography and landscape with contemporary urban sub-culture: following three drag queens on a road trip to Central Australia.
While a number of major international stars gained early prominence in Australia over the period, an important stable of established and emerging local stars with prodigious film credits remained prominent, including screen veterans Charles Tingwell, Bill Hunter, Jack Thompson, Bryan Brown and Chris Haywood.
The World War II drama "Blood Oath" (1990) debuted both Russell Crowe and Jason Donovan, in minor cinematic roles. Crowe demonstrated his versatility as an actor in this early period of his career by starring soon after as a street gang Melbourne skinhead in 1992's "Romper Stomper" and then as an inner-Sydney working class gay man in 1994's "The Sum of Us" before transferring to the USA to commence his Hollywood career.
George Miller's "Babe" (1995) employed new digital effects to make a barnyard come alive and went on to become one of Australia's highest grossing films. The 1996 drama "Shine" achieved an Academy Award for Best Actor award for Geoffrey Rush and Gregor Jordan's 1999 film "Two Hands" gave Heath Ledger his first leading role. After Ledger's successful transition to Hollywood, Jordan and Ledger collaborated again in 2003 with Ledger playing the iconic bushranger title role in the film "Ned Kelly", which co-starred British actress Naomi Watts.
The canon of films related to Indigenous Australians also increased over the period of the 1990s and early 21st Century, with Nick Parson's 1996 film "Dead Heart" featuring Ernie Dingo and Bryan Brown; Rolf de Heer's "The Tracker", starring Gary Sweet and David Gulpilil; and Phillip Noyce's "Rabbit-Proof Fence" in 2002. In 2006, Rolf de Heer's "Ten Canoes" became the first major feature film to be shot in an indigenous language and the film was recognised at Cannes and elsewhere.
The shifting demographics of Australia following post-war multicultural immigration was reflected in Australian cinema through the period and in successful films like 1993's The Heartbreak Kid; 1999's Looking for Alibrandi; 2003's Fat Pizza; the Wog Boy comedies and 2007's Romulus, My Father which all dealt with aspects of the migrant experience or Australian subcultures.
Rob Sitch and Working Dog Productions followed the success of "The Castle" with period comedy "The Dish", which was the highest grossing Australian film of the Year 2000 and entered the top ten list of highest grossing Australian films. Big budget Australian-international co-productions "Moulin Rouge!" (Baz Luhrmann, 2001) and Happy Feet (which won the Academy Award for Best Animated Feature for filmmaker George Miller in 2006) also entered the top ten list during the first decade of the new century. Baz Luhrmann directed a series of international hits and returned to Australia for the production of 2008's "Australia", which showcased a host of Australian stars including Nicole Kidman, Hugh Jackman and David Wenham and went on to become the second highest grossing film in Australian cinematic history.
"Lantana", directed by Ray Lawrence attained critical and commercial success in 2001 for its examination of a complex series of relationships in suburban Sydney, and events surrounding a mysterious crime. It won seven AFI Awards including Best Picture, Best Director, Best Actor for Anthony LaPaglia and Best Actress for Kerry Armstrong.
Emerging star Sam Worthington had early lead roles in the 2002 mobster black comedy "Dirty Deeds" and 2003's crime caper "Gettin' Square". "Gettin Square" also featured rising star David Wenham who demonstrated versatility with a string of critically acclaimed roles including the title role in Paul Cox's 1999 biopic "" and the 2001 thriller "The Bank", directed by the politically conscious film director Robert Connolly.
In 2005, "Little Fish" marked a return to Australian film for actress Cate Blanchett and won five Australian Film Institute Awards including Best Actor for Hugo Weaving, Best Actress for Blanchett and Best Supporting Actress for screen veteran Noni Hazlehurst.
In 2008, the documentary film celebrating the romps of the Australian New Wave of 1970s and 1980s low-budget cinema: "" The film was directed by Mark Hartley and interviews filmmakers including Quentin Tarantino, Dennis Hopper, George Miller and Barry Humphries.
The early 2000s were generally not successful years for Australian cinema, with several confronting dramas proving unpopular at the box office. In 2008, no Australian movies made $3 million at the box office, but a conscious decision by film-makers to broaden the types of films being made as well as the range of budgets produced a series of box-office hits at the close of the decade. Strong box office performances were recorded in 2009–10 by Bruce Beresford's "Mao's Last Dancer"; the Aboriginal musical "Bran Nue Dae" the dramatization of John Marsden's novel "Tomorrow, When the War Began"; and the crime drama "Animal Kingdom" which featured major Australian screen stars Ben Mendelsohn, Joel Edgerton, Guy Pearce and Jackie Weaver. "Animal Kingdom" achieved success at the 2010 Australian Film Institute Awards and was acclaimed at film festivals around the world. "Tomorrow, When the War Began" became the highest-grossing domestic film of 2010 and it was nominated for nine Australian Film Institute Awards.
Other notable films of the period included "Balibo" (2009) starring Anthony LaPaglia; MIddle Eastern crime flick Cedar Boys (2009) Directed by Serhat Caradee, the animated feature Mary and Max; and the 2010 World War I drama "Beneath Hill 60", directed by Jeremy Sims and starring Brendan Cowell.
Present.
The Australian film industry continues to produce a reasonable number of films each year, but in common with other English-speaking countries, Australia has often found it difficult to compete with the American film industry, the latter helped by having a much larger home market. The most successful Australian actors and film-makers are easily lured by Hollywood and rarely return to the domestic film industry.
Since Rupert Murdoch, the head of Fox Studios and an Australian, moved the new Fox studios to Sydney, some US producers have chosen to film at Fox's state of the art facilities, as production costs in Sydney are well below US costs. Studios established in Australia, like Fox Studios Australia and Warner Roadshow Studios, host large international productions like "The Matrix" and ' and '.
Government support.
John Gorton, Prime Minister of Australia from 1968–1971, initiated several forms of Government support for Australian film and the arts, establishing the Australian Council for the Arts, the Australian Film Development Corporation and the National Film and Television Training School. Prime Minister Gough Whitlam continued to support Australian film. The South Australian Film Corporation was established in 1972 to promote and produce films, while the Australian Film Commission was created in 1975 to fund and produce internationally competitive films.
The Federal Australian government had supported the Australian film industry through the funding and development agencies of Film Finance Corporation Australia, the Australian Film Commission and Film Australia. In 2008 the three agencies were consolidated into Screen Australia.
There is an ongoing debate of the need and role of government support for the Australian film industry. Some argue in favour of government support as being the only way that the local film industry can compete against the hegemony of Hollywood. The argument against government support is that the industry is viable without support and will become stronger if increasingly globalised market forces are allowed full and untrammeled play. Others argue that a film industry in itself has little value. The history of the industry in Australia is to some extent a result of the ascendancy of one position over the other.
Highest-grossing Australian films.
Other popular Australian films.
High grossing Australian films from earlier decades include:
Personalities.
Actors.
The Australian film industry has produced a number of successful actors, actresses, writers, directors and filmmakers many of whom have been known internationally.
Actors
Actresses

</doc>
<doc id="70210" url="https://en.wikipedia.org/wiki?curid=70210" title="Motto">
Motto

A motto (derived from the Latin "muttum", 'mutter', by way of Italian "motto", 'word', 'sentence') is a maxim, a phrase meant to formally summarize the general motivation or intention of an individual, family, social group or organization. Mottos are usually not expressed verbally, unlike slogans, but are expressed in writing and usually stem from long traditions of social foundations, or also from significant events, such as a civil war or a revolution. A motto may be in any language, but Latin has been widely used, especially in the Western world.
Heraldry.
In heraldry, a motto is often depicted below the shield in a banderole; this placement stems from the Middle Ages, in which the vast majority of nobles possessed a coat of arms and a motto. In the case of Scottish heraldry it is mandated to appear above the crest. Spanish coats of arms may display a motto in the bordure of the shield. In heraldic literature, the terms "rallying cry" respectively "battle banner" are also common, which date back to the battle cry, and is usually located above the coat of arms.
In English heraldry mottos are not granted with armorial bearings, and may be adopted and changed at will. In Scottish heraldry, mottos can only be changed by re-matriculation, with the Lord Lyon King of Arms. Although very unusual and perhaps outside standard heraldic practice, there are some examples of the particular appearance of the motto scroll and letters thereon being blazoned.
Ships and submarines in the Royal Navy each have a badge and motto, as do units of the Royal Air Force.
Latin has been very common for mottos, but for nation states their official language is generally chosen. Examples of unusual choices in motto language include:
A canting motto is one that contains word play. For example, the motto of the Earl of Onslow is "Festina lente", punningly interpreting "on-slow" (literally "make haste slowly").
Literature.
In literature, a motto is a sentence, phrase, poem, or word prefixed to an essay, chapter, novel, or the like suggestive of its subject matter. It is a short, suggestive expression of a guiding principle for the written material that follows.
For example, Robert Louis Stevenson's "Travels with a Donkey in the Cévennes" uses mottos at the start of each section.

</doc>
<doc id="70219" url="https://en.wikipedia.org/wiki?curid=70219" title="Charles I of Hungary">
Charles I of Hungary

Charles I, also known as Charles Robert (; ; ; 128816 July 1342) was King of Hungary and Croatia from 1308 to his death. He was a member of the Capetian House of Anjou and the only son of Charles Martel, Prince of Salerno. His father was the eldest son of Charles II of Naples and Mary of Hungary. She laid claim to Hungary after her brother, Ladislaus IV of Hungary, died in 1290, but the Hungarian prelates and lords elected her cousin, Andrew III, king. Instead of abandoning her claim to Hungary, she transferred it to her son, Charles Martel, and after his death in 1295, to her grandson, Charles. On the other hand, her husband, Charles II of Naples, made their third son, Robert, heir to the Kingdom of Naples, thus disinheriting Charles.
Charles came to the Kingdom of Hungary upon the invitation of an influential Croatian lord, Paul Šubić, in August 1300. Andrew III died on 14 January 1301, and within four months Charles was crowned king, but with a provisional crown instead of the Holy Crown of Hungary. Most Hungarian noblemen refused to yield to him and elected Wenceslaus of Bohemia king. Charles withdrew to the southern regions of the kingdom. Pope Boniface VIII acknowledged Charles as the lawful king in 1303, but Charles was unable to strengthen his position against his opponent. Wenceslaus abdicated in favor of Otto of Bavaria in 1305. Because it had no central government, the Kingdom of Hungary had disintegrated into a dozen provinces, each headed by a powerful nobleman, or oligarch. One of those oligarchs, Ladislaus Kán, captured and imprisoned Otto of Bavaria in 1307. Charles was elected king in Pest on 27 November 1308, but his rule remained nominal in most parts of his kingdom even after he was crowned with the Holy Crown on 27 August 1310.
Charles won his first decisive victory in the Battle of Rozgony (at present-day Rozhanovce in Slovakia) on 15 June 1312. After that his troops seized most fortresses of the powerful Aba family. During the next decade, Charles restored royal power primarily with the assistance of the prelates and lesser noblemen in most regions of the kingdom. After the death of the most powerful oligarch, Matthew Csák, in 1321, Charles became the undisputed ruler of the whole kingdom, with the exception of Croatia where local noblemen were able to preserve their autonomous status. He was not able to hinder the development of Wallachia into an independent principality after his defeat in the Battle of Posada in 1330. Charles's contemporaries described his defeat in that battle as a punishment from God for his cruel revenge against the family of Felician Záh who had attempted to slaughter the royal family.
Charles rarely made perpetual land grants, instead introducing a system of "office fiefs", whereby his officials enjoyed significant revenues, but only for the time they held a royal office, which ensured their loyalty. In the second half of his reign, Charles did not hold Diets and administered his kingdom with absolute power. He established the Order of Saint George, which was the first secular order of knights. He promoted the opening of new gold mines, which made Hungary the largest producer of gold in Europe. The first Hungarian gold coins were minted during his reign. At the congress of Visegrád in 1335, he mediated a reconciliation between two neighboring monarchs, John of Bohemia and Casimir III of Poland. Treaties signed at the same congress also contributed to the development of new commercial routes linking Hungary with Western Europe. Charles's efforts to reunite Hungary, together with his administrative and economic reforms, established the basis for the achievements of his successor, Louis the Great.
Early years.
Childhood (1288–1300).
Charles was the only son of Charles Martel, Prince of Salerno, and his wife, Klementia of Habsburg. He was born in 1288; the place of his birth is unknown. Charles Martel was the firstborn son of Charles II of Naples and Charles II's wife, Mary, who was a daughter of Stephen V of Hungary. After the death of her brother, Ladislaus IV of Hungary, in 1290, Queen Mary announced her claim to Hungary, stating that the House of Árpád (the royal family of Hungary) had become extinct with Ladislaus's death. However, her father's cousin, Andrew also laid claim to the throne, although his father, Stephen the Posthumous, had been regarded a bastard by all other members of the royal family. For all that, the Hungarian lords and prelates preferred Andrew against Mary and he was crowned king of Hungary on 23 July 1290. She transferred her claim to Hungary to Charles Martel in January 1292. The Babonići, Frankopans, Šubići and other Croatian and Slavonian noble families seemingly acknowledged Charles Martel's claim, but in fact their loyalty vacillated between Charles Martel and Andrew III.
Charles Martel died in autumn 1295, and his seven-year-old son, Charles, inherited his claim to Hungary. Charles would have also been the lawful heir to his grandfather, Charles II of Naples, in accordance with the principles of primogeniture. However, Charles II, who preferred his third son, Robert, to his grandson, bestowed the rights of a firstborn son upon Robert on 13 February 1296. Pope Boniface VIII confirmed Charles II's decision on 27 February 1296, excluding the child Charles from succeeding his grandfather in the Kingdom of Naples. Dante Alighieri wrote of "the schemes and frauds that would attack" Charles Martel's family in reference to Robert's alleged manoeuvres to acquire the right to inherit Naples. The 14th-century historian Giovanni Villani also noted that his contemporaries were of the opinion that Robert's claim to Naples was weaker than his nephew's. The jurist Baldus de Ubaldis refrained from setting out his position on the legitimacy of Robert's rule.
Struggle for Hungary (1300–1308).
Andrew III of Hungary made his maternal uncle, Alberto Morosini, Duke of Slavonia, in July 1299, stirring up the Slavonian and Croatian noblemen to revolt. A powerful Croatian baron, Paul Šubić, sent his brother, George, to Italy in early 1300 to convince Charles II of Naples to send his grandson to Hungary to claim the throne in person. The king of Naples accepted the proposal and borrowed 1,300 ounces of gold from Florentine bankers to finance Charles's journey. A Neapolitan knight of French origin, Philip Drugeth, accompanied the twelve-year-old Charles to Hungary. They landed at Split in Dalmatia in August 1300. From Split, Paul Šubić escorted him to Zagreb where Ugrin Csák swore loyalty to Charles. Charles's opponent, Andrew III of Hungary, died on 14 January 1301. Charles hurried to Esztergom where the Archbishop-elect, Gregory Bicskei, crowned him with a provisional crown before 13 May. However, most Hungarians considered Charles's coronation unlawful because customary law required that it should have been performed with the Holy Crown of Hungary in Székesfehérvár.
Charles counted his regnal years from this coronation, but Hungary had actually disintegrated into about a dozen independent provinces, each ruled by a powerful lord, or oligarch. Among them, Matthew Csák dominated the northwestern parts of Hungary (which now form the eastern territories of present-day Slovakia), Amadeus Aba controlled the northeastern lands, Ivan Kőszegi ruled Transdanubia, and Ladislaus Kán governed Transylvania. Most of those lords refused to accept Charles's rule and proposed the crown to Wenceslaus II of Bohemia's son and namesake, Wenceslaus, whose bride, Elisabeth, was Andrew III's only daughter. Although Wenceslaus was crowned with the Holy Crown in Székesfehérvár, the legitimacy of his coronation was also questionable because John Hont-Pázmány, Archbishop of Kalocsa, put the crown on Wenceslaus's head, although customary law authorized the Archbishop of Esztergom to perform the ceremony.
After Wenceslaus's coronation, Charles withdrew to Ugrin Csák's domains in the southern regions of the kingdom. Pope Boniface sent his legate, Niccolo Boccasini, to Hungary. Boccasini convinced the majority of the Hungarian prelates to accept Charles's reign. However, most Hungarian lords continued to oppose Charles because, according to the "Illuminated Chronicle", they feared that "the free men of the kingdom should lose their freedom by accepting a king appointed by the Church". Charles laid siege to Buda, the capital of the kingdom, in September 1302, but Ivan Kőszegi relieved the siege. Charles's charters show that he primarily stayed in the southern parts of the kingdom during the next years although he also visited Amadeus Aba in the fortress of Gönc.
Pope Boniface who regarded Hungary as a fief of the Holy See declared Charles the lawful king of Hungary on 31 May 1303. He also threatened Wenceslaus with excommunication if he continued to style himself king of Hungary. Wenceslaus, left Hungary in summer 1304, taking the Holy Crown with him. Charles met his cousin, Rudolph III of Austria, in Pressburg (now Bratislava in Slovakia) on 24 August. After signing an alliance, they jointly invaded Bohemia in the autumn. Wenceslaus who had succeeded his father in Bohemia renounced his claim to Hungary in favor of Otto III, Duke of Bavaria on 9 October 1305.
Otto was crowned with the Holy Crown in Székesfehérvár on 6 December 1304 by Benedict Rád, Bishop of Veszprém, and Anton, Bishop of Csanád. He was never able to strengthen his position in Hungary, because only the Kőszegis and the Transylvanian Saxons supported him. Charles seized Esztergom and many fortresses in the northern parts of Hungary (now in Slovakia) in 1306. His partisans also occupied Buda in June 1307. Ladislaus Kán, Voivode of Transylvania, seized and imprisoned Otto in Transylvania. An assembly of Charles's partisans confirmed Charles's claim to the throne on 10 October, but three powerful lords—Matthew Csák, Ladislaus Kán, and Ivan Kőszegi—were absent from the meeting. In 1308, Ladislaus Kán released Otto, who then left Hungary. Otto never ceased styling himself King of Hungary, but he never returned to the country.
Pope Clement V sent a new papal legate, Gentile Partino da Montefiore, to Hungary. Montefiore arrived in the summer of 1308. In the next few months, he persuaded the most powerful lords one by one to accept Charles's rule. At the Diet, which was held in the Dominican monastery in Pest, Charles was unanimously proclaimed king on 27 November 1308. The delegates sent by Matthew Csák and Ladislaus Kán were also present at the assembly.
Reign.
Wars against the oligarchs (1308–1323).
The papal legate convoked the synod of the Hungarian prelates, who declared the monarch inviolable in December 1308. They also urged Ladislaus Kán to hand over the Holy Crown to Charles. After Kán refused to do so, the legate consecrated a new crown for Charles. Thomas II, Archbishop of Esztergom crowned Charles king with the new crown in the Church of Our Lady in Buda on 15 or 16 June 1309. However, most Hungarians regarded his second coronation invalid. The papal legate excommunicated Ladislaus Kán, who finally agreed to give the Holy Crown to Charles. On 27 August 1310, Archbishop Thomas of Esztergom put the Holy Crown on Charles's head in Székesfehérvár; thus, Charles's third coronation was performed in full accordance with customary law. However, his rule remained nominal in most parts of his kingdom.
Matthew Csák laid siege Buda in June 1311, and Ladislaus Kán declined to assist the king. Charles sent an army to invade Matthew Csák's domains in September, but it achieved nothing. In the same year, Ugrin Csák died, enabling Charles to take possession of the deceased lord's domains, which were situated between Požega in Slavonia and Temesvár (present-day Timișoara in Romania). The burghers of Kassa (now Košice in Slovakia) assassinated Amadeus Aba in September 1311. Charles's envoys arbitrated an agreement between Aba's sons and the town, which also prescribed that the Abas withdraw from two counties and allow the noblemen inhabiting their domains to freely join Charles. However, the Abas soon entered into an alliance with Matthew Csák against the king. The united forces of the Abas and Matthew Csák besieged Kassa, but Charles routed them in the Battle of Rozgony (now Rozhanovce in Slovakia) on 15 June 1312. Almost half of the noblemen who had served Amadeus Aba fought on Charles's side in the battle. In July, Charles captured the Abas' many fortresses in Abaúj, Torna and Sáros counties, including Füzér, Regéc, and Munkács (now Mukacheve in Ukraine). Thereafter he waged war against Matthew Csák, capturing Nagyszombat (now Trnava in Slovakia) in 1313 and Visegrád in 1315, but was unable to win a decisive victory.
Charles transferred his residence from Buda to Temesvár in early 1315. Ladislaus Kán died in 1315, but his sons did not yield to Charles. Charles launched a campaign against the Kőszegis in Transdanubia and Slavonia in the first half of 1316. Local noblemen joined the royal troops, which contributed to the quick collapse of the Kőszegis' rule in southern parts of their domains. Meanwhile, James Borsa made an alliance against Charles with Ladislaus Kán's sons and other lords. They offered the crown to Andrew of Galicia. Charles's troops, which were under the command of a former supporter of the Borsas, Dózsa Debreceni, defeated the rebels' united troops at Debrecen at the end of June. In the next two months, many fortresses of Borsa and his allies fell to the royal troops in Bihar, Szolnok, Borsod and Kolozs counties. No primary source has made reference to Charles's bravery or heroic acts, suggesting that he rarely fought in person in the battles and sieges. However, he had excellent strategic skills: it was always Charles who appointed the fortresses to be besieged.
Stefan Dragutin, who controlled the Szerémség, Macsó and other regions along the southern borders of Hungary, died in 1316. Charles confirmed the right of Stefan Dragutin's son, Vladislav, to succeed his father and declared Vladislav the lawful ruler of Serbia against Stefan Uroš II Milutin. However, Stefan Uroš II captured Vladislav and invaded the Szerémség. Charles launched a counter-campaign across the river Száva and seized the fortress of Macsó. In May 1317, Charles's army suppressed the Abas' revolt, seizing Ungvár and Nevicke Castle (present-day Uzhhorod and Nevytsky Castle in Ukraine) from them. After that, Charles invaded Matthew Csák's domains and captured Komárom (now Komárno in Slovakia) on 3 November 1317. After his uncle, King Robert of Naples, granted the Principality of Salerno and the domain of Monte Sant'Angelo to his brother (Charles's younger uncle), John, Charles protested and laid claim to those domains, previously held by his father.
After Charles neglected to reclaim Church property that Matthew Csák had seized by force, the prelates of the realm made an alliance in early 1318 against all who would jeopardize their interests. Upon their demand, Charles held a Diet in summer, but refused to confirm the Golden Bull of 1222. Before the end of the year, the prelates made a complaint against Charles because he had taken possession of Church property. In 1319, Charles fell so seriously ill that the pope authorized Charles's confessor to absolve him from his all sins before he died, but Charles recovered. In the same year, Dózsa Debreceni, whom Charles had made voivode of Transylvania, launched successful expeditions against Ladislaus Kán's sons and their allies, and Charles's Judge royal, Alexander Köcski, seized the Kőszegis' six fortresses. In summer, Charles launched an expedition against Stefan Uroš II Milutin, during which he retook Belgrade and restored tha Banate of Macsó. The last Diet during Charles's reign was held in 1320; following that, he failed to convoke the yearly public judicial sessions, contravening the provisions of the Golden Bull.
Matthew Csák died on 21 March 1321. The royal army invaded the deceased lord's province, which soon disintegrated because most of his former castellans yielded without resistance. Charles personally led the siege of Csák's former seat, Trencsén (now Trenčín in Slovakia), which fell on 8 August. About three months later, Charles's new voivode of Transylvania, Thomas Szécsényi, seized Csicsó (present-day Ciceu-Corabia in Romania), the last fortress of Ladislaus Kán's sons.
In January 1322, two Dalmatian towns, Šibenik and Trogir, rebelled against Mladen II Šubić, who was a son of Charles's one-time leading partisan, Paul Šubić. The two towns also accepted the suzerainty of the Republic of Venice although Charles had urged Venice not to intervene in the conflict between his subjects. Many Croatian lords (including his own brother, Paul II Šubić) also turned against Mladen, and their coalition defeated him at Klis. In September, Charles marched to Croatia where all the Croatian lords who were opposed to Mladen Šubić yielded to him in Knin. Mladen Šubić also visited Charles, but the king had the powerful lord imprisoned.
Consolidation and reforms (1323–1330).
As one of his charters concluded, Charles had taken "full possession" of his kingdom by 1323. In the first half of the year, he moved his capital from Temesvár to Visegrád in the centre of his kingdom. In the same year, the Dukes of Austria renounced Pressburg (now Bratislava in Slovakia), which they had controlled for decades, in exchange for the support they had received from Charles against Louis IV, Holy Roman Emperor, in 1322.
Royal power was only nominally restored in the lands between the Carpathian Mountains and the Lower Danube, which had been united under a voivode, known as Basarab, by the early 1320s. Although Basarab was willing to accept Charles's suzerainty in a peace treaty signed in 1324, he refrained from renouncing control of the lands he had occupied in the Banate of Severin. Charles also attempted to reinstate royal authority in Croatia and Slavonia. He dismissed the Ban of Slavonia, John Babonić, replacing him with Mikcs Ákos in 1325. Ban Mikcs invaded Croatia to subjugate the local lords who had seized the former castles of Mladen Subić without the king's approval, but one of the Croatian lords, Ivan I Nelipac, routed the ban's troops in 1326. Consequently, royal power remained only nominal in Croatia during Charles's reign. The Babonići and the Kőszegis rose up in open rebellion in 1327, but Ban Mikcs and Alexander Köcski defeated them. In retaliation, at least eight fortresses of the rebellious lords were confiscated in Slavonia and Transdanubia.
Through his victory over the oligarchs, Charles acquired about 60% of the Hungarian castles, along with the estates belonging to them. In 1323, he set about revising his previous land grants, which enabled him to reclaim former royal estates. During his reign, special commissions were set up to detect royal estates that had been unlawfully acquired by their owners. Charles refrained from making perpetual grants to his partisans. Instead, he applied a system of "office fiefs" (or "honors"), whereby his officials were entitled to enjoy all revenues accrued from their offices, but only for the time they held those offices. That system assured the preponderance of royal power, enabling Charles to rule "with the plenitude of power", as he emphasized in one of his charters of 1335. He even ignored customary law: for instance, "promoting a daughter to a son", which entitled her to inherit her father's estates instead of her male cousins. Charles also took control of the administration of the Church in Hungary. He appointed the Hungarian prelates at will, without allowing the cathedral chapters to elect them.
He promoted the spread of chivalrous culture in his realms. He regularly held tournaments and introduced the new ranks of "page of the royal court" and "knight of the royal court". Charles was the first monarch to create a secular order of knighthood by establishing the Order of Saint George in 1326. He was the first Hungarian king to grant helmet crests to his faithful followers to distinguish them from others "by means of an "insignium" of their own", as he emphasized in one of his charters.
Charles reorganized and improved the administration of royal revenues. During his reign, five new "chambers" (administrative bodies headed by German, Italian or Hungarian merchants) were established for the control and collection of royal revenues from coinage, monopolies and custom duties. In 1327, he partially abolished the royal monopoly of gold mining, giving one third of the royal revenues from the gold extracted from a newly opened mine to the owner of the land where that mine was discovered. In the next few years, new gold mines were opened at Körmöcbánya (now Kremnica in Slovakia), Nagybánya (present-day Baia Mare in Romania) and Aranyosbánya (now Baia de Arieș in Romania). Hungarian mines yielded about of gold around 1330, which made up more than 30% of the world's total production. The minting of gold coins began under Charles's auspices in the lands north of the Alps in Europe. His florins, which were modelled on the gold coins of Florence, were first issued in 1326.
Internal peace and increasing royal revenues strengthened the international position of Hungary in the 1320s. On 13 February 1327, Charles and John of Bohemia signed an alliance in Nagyszombat (present-day Trnava in Slovakia) against the Habsburgs, who had occupied Pressburg. In the summer of 1328 Hungarian and Bohemian troops invaded Austria and routed the Austrian army on the banks of the Leitha River. On 21 September 1328, Charles signed a peace treaty with the three dukes of Austria (Frederick the Fair, Albert the Lame, and Otto the Merry), who renounced Pressburg and the Muraköz (now Međimurje in Croatia). The following year, Serbian troops laid siege to Belgrade, but Charles relieved the fortress.
Alliance with his father-in-law, Władysław I the Elbow-high, King of Poland, became a permanent element of Charles's foreign policy in the 1320s. After being defeated by the united forces of the Teutonic Knights and John of Bohemia, Władysław I sent his son and heir, Casimir, to Visegrád in late 1329 to seek assistance from Charles. During his stay in Charles's court, the nineteen-year-old Casimir seduced Claire Záh, who was a lady-in-waiting of Charles's wife, Elisabeth of Poland, according to an Italian writer. On 17 April 1330, the young lady's father, Felician Záh, stormed into the dining room of the royal palace at Visegrád with a sword in his hand and attacked the royal family. Záh wounded both Charles and the queen on their right hand and attempted to kill their two sons, Louis and Andrew, before the royal guards killed him. Charles's revenge was brutal: with the exception of Claire, Felician Záh's children were tortured to death; Claire's lips and all eight fingers were cut before she was dragged by a horse through the streets of many towns; all of Felician's other relatives within the third degree of kinship (including his sons-in-law and sisters) were executed, and those within the seventh degree were condemned to perpetual serfdom.
Active foreign policy (1330–1339).
In September 1330, Charles launched a military expedition against Basarab of Wallachia who had attempted to get rid of his suzerainty. After seizing the fortress of Severin (present-day Drobeta-Turnu Severin in Romania), he refused to make peace with Basarab and marched towards Curtea de Argeș, which was Basarab's seat. The Wallachians applied scorched earth tactics, compelling Charles to make a truce with Basarab and withdraw his troops from Wallachia. While the royal troops were marching through a narrow pass across the Southern Carpathians on 9 November, the Wallachians ambushed them. During the next four days, the royal army was decimated; Charles could only escape from the battlefield after changing his clothes with one of his knights, Desiderius Héder, who sacrificed his life to enable the king's escape. Charles did not attempt a new invasion of Wallachia, which subsequently developed into an independent principality.
In September 1331, Charles made an alliance with Otto the Merry, Duke of Austria, against Bohemia. He also sent reinforcements to Poland to fight against the Teutonic Knights and the Bohemians. In 1332 he signed a peace treaty with John of Bohemia and mediated a truce between Bohemia and Poland. In 1332 Charles allowed the collection of the papal tithe (the tenth part of the Church revenues) in his realms only after the Holy See agreed to give one third of the money collected to him. After years of negotiations, Charles visited his uncle, Robert, in Naples in July 1333. Two months later, Charles's son, Andrew, was betrothed to Robert's granddaughter, Joanna, who had been made her grandfather's heir. Charles returned to Hungary in early 1334. In retaliation for a previous Serbian raid, he invaded Serbia and captured the fortress of Galambóc (now Golubac in Serbia).
In summer 1335, the delegates of John of Bohemia and the new King of Poland, Casimir III, entered into negotiations in Trencsén to put an end to the conflicts between the two countries. With Charles's mediation, a compromise was reached on 24 August: John of Bohemia renounced his claim to Poland and Casimir of Poland acknowledged John of Bohemia's suzerainty in Silesia. On 3 September, Charles signed an alliance with John of Bohemia in Visegrád, which was primarily formed against the Dukes of Austria. Upon Charles's invitation, John of Bohemia and Casimir of Poland met in Visegrád in November. During the Congress of Visegrád, the two rulers confirmed the compromise that their delegates had worked out in Trencsén. Casimir III also promised to pay 400,000 groschen to John of Bohemia, but a part of this indemnification (120,000 groschen) was finally paid off by Charles instead of his brother-in-law. The three rulers agreed upon a mutual defence union against the Habsburgs, and a new commercial route was set up to enable merchants travelling between Hungary and the Holy Roman Empire to bypass Vienna.
The Babonići and the Kőszegis made an alliance with the Dukes of Austria in January 1336. John of Bohemia, who claimed Carinthia from the Habsburgs, invaded Austria in February. Casimir III of Poland came to Austria to assist him in late June. Charles soon joined them at Marchegg. The dukes sought reconciliation and signed a peace treaty with John of Bohemia in July. Charles signed a truce with them on 13 December, and launched a new expedition against Austria early the next year. He forced the Babonići and the Kőszegis to yield, and the latter were also compelled to hand over to him their fortresses along the frontier in exchange for faraway castles. Charles's peace treaty with Albert and Otto of Austria, which was signed on 11 September 1337, forbade both the dukes and Charles to give shelter to the other party's rebellious subjects.
Charles continued the reform of coinage in the late 1330s. In 1336, he abolished the compulsory exchange of old coins for newly issued coins for villagers, but introduced a new tax, the chamber's profit, to compensate the loss of royal revenues. Two years later, Charles ordered the minting of a new silver penny and prohibited payments made in foreign coins or silver bars.
John of Bohemia's heir, Charles, Margrave of Moravia, visited Charles in Visegrád in early 1338. The margrave acknowledged the right of Charles's son, Louis, to inherit Poland if Casimir III died without a son in exchange for Charles's promise to persuade Casimir III not to invade Silesia. Two leading Polish lords, Zbigniew, chancellor of Cracow, and Spycimir Leliwita, also supported this plan and persuaded Casimir III, who lost his first wife on 26 May 1339, to start negotiations with Charles. In July, Casimir came to Hungary and designated his sister (Charles's wife), Elizabeth, and her sons as his heirs. On his sons' behalf, Charles promised that they would make every effort to reconquer all lands that Poland had lost and that they would refrain from employing foreigners in Poland.
Last years (1339–1342).
Charles obliged the Kőszegis to renounce their last fortresses along the western borders of the kingdom in 1339 or 1340. He divided the large Zólyom County (now in Slovakia), which had been dominated by a powerful local lord, Donch, into three smaller counties in 1340. The following year, Charles also forced Donch to renounce his two fortresses in Zólyom in exchange for one castle in the distant Kraszna County (in present-day Romania). Around the same time, Stephen Uroš IV Dušan of Serbia, invaded Sirmium and captured Belgrade.
Charles was ailing during the last years of his life. He died in Visegrád on 16 July 1342. His corpse was first delivered to Buda where a Mass was said for his soul. From Buda, his corpse was taken to Székesfehérvár. He was buried in the Székesfehérvár Basilica a month after his death. His brother-in-law, Casimir III of Poland, and Charles, Margrave of Moravia, were present at his funeral, an indication of Charles's international prestige.
Family.
The "Anonymi descriptio Europae orientalis" ("An Anonymous' Description of Eastern Europe") wrote, in the first half of 1308, that "the daughter of the strapping Duke of Ruthenia, Leo, has recently married Charles, King of Hungary". Charles also stated in a charter of 1326 that he once travelled to "Ruthenia" (or Halych-Lodomeria) in order to bring his first wife back to Hungary. A charter issued on 23 June 1326 referred to Charles's wife, Queen Mary. Historian Gyula Kristó says, the three documents show that Charles married a daughter of Leo II of Galicia in late 1305 or early 1306. Historian Enikő Csukovits accepts Kristó's interpretation, but she writes that Mary of Galicia most probably died before the marriage. The Polish scholar, Stanisław Sroka, rejects Kristó's interpretation, stating that Leo I—who was born in 1292, according to him—could hardly have fathered Charles's first wife. In accordance with previous academic consensus, Sroka says that Charles's first wife was Mary of Bytom from the Silesian branch of the Piast dynasty.
The "Illuminated Chronicle" stated that Charles's "first consort, Maria ... was of the Polish nation" and she was "the daughter of Duke Casimir". Sroka proposes that Mary of Bytom married Charles in 1306, but Kristó writes that their marriage probably took place in the first half of 1311. The "Illuminated Chronicle" recorded that she died on 15 December 1317, but a royal charter issued on 12 July 1318 stated that her husband made a land grant with her consent. Charles's next—second or third—wife was Beatrice of Luxembourg, who was a daughter of Henry VII, Holy Roman Emperor, and the sister of John, King of Bohemia. Their marriage took place before the end of February 1319. She died in childbirth in early November in the same year. Charles's last wife, Elisabeth, daughter of Władysław I, King of Poland, was born around 1306. Their marriage took place on 6 July 1320.
Most 14th-century Hungarian chroniclers write that Charles and Elisabeth of Poland had five sons. Their first son, Charles, was born in 1321 and died in the same year according to the "Illuminated Chronicle". However, a charter of June 1323 states that the child had died in this month. The second son of Charles and Elisabeth, Ladislaus, was born in 1324. The marriage of Ladislaus and Anne, a daughter of King John of Bohemia, was planned by their parents, but Ladislaus died in 1329. Charles's and Elisabeth's third son, Louis, who was born in 1326, survived his father and succeeded him as King of Hungary. His younger brothers, Andrew and Stephen, who were born in 1327 and 1332, respectively, also survived Charles.
Although no contemporaneous or nearly contemporaneous sources made mention of any further children, Charles may have fathered two daughters, according to historians Zsuzsa Teke and Gyula Kristó. Zsuzsa Teke writes that they were born to Mary of Bytom, but the nearly contemporaneous Peter of Zittau wrote that she had died childless. Gyula Kristó proposes that a miniature in the "Illuminated Chronicle", which depicts Elisabeth of Poland and five children, implies that she gave birth to Charles's two daughters, because Kristó identifies two of the three children standing on her right as daughters. The elder of Charles's two possible daughters, Catherine, who was born in the early 1320s, was the wife of Henry II, Duke of Świdnica. Their only daughter, Anne, grew up in the Hungarian royal court after her parents' death, implying that Charles and Elisabeth of Poland were her grandparents. Historian Kazimierz Jasiński says that Elisabeth, the wife of Boleslaus II of Troppau, was also Charles's daughter. If she was actually Charles's daughter, she must have been born in about 1330, according to Kristó.
Charles also fathered an illegitimate son, Coloman, who was born in early 1317. His mother was a daughter of Gurke Csák. Coloman was elected Bishop of Győr in 1336.
Legacy.
Charles often declared that his principal aim was the "restoration of the ancient good conditions" of the kingdom. 
On his coat-of-arms, he united the "Árpád stripes" with the motives of the coat-of-arms of his paternal family, which emphasized his kinship with the first royal house of Hungary. During his reign, Charles reunited Hungary and introduced administrative and fiscal reforms. He bequeathed to his son, Louis the Great, a "bulging exchequer and an effective system of taxation", according to scholar Bryan Cartledge. Nevertheless, Louis the Great's achievements overshadowed Charles's reputation.
The only contemporaneous record of Charles's deeds were made by a Franciscan friar who was hostile towards the monarch. Instead of emphasizing Charles's achievements in the reunification of the country, the friar described in detail the negative episodes of Charles's reign. In particular, the unusual cruelty that the king showed after Felician Záh's assassination attempt on the royal family contributed to the negative picture of Charles's personality. The Franciscan friar attributed Charles's defeat by Basarab of Wallachia as a punishment from God for the king's revenge.

</doc>
<doc id="70228" url="https://en.wikipedia.org/wiki?curid=70228" title="United States courts of appeals">
United States courts of appeals

The United States courts of appeals (or circuit courts) are the intermediate appellate courts of the United States federal court system. A court of appeals decides appeals from the district courts within its federal judicial circuit, and in some instances from other designated federal courts and administrative agencies.
The United States courts of appeals are considered among the most powerful and influential courts in the United States. Because of their ability to set legal precedent in regions that cover millions of Americans, the United States courts of appeals have strong policy influence on U.S. law. Moreover, because the U.S. Supreme Court chooses to review less than 1% of the more than 10,000 cases filed with it annually, the United States courts of appeals serve as the final arbiter on most federal cases. The Ninth Circuit in particular is very influential, covering 20% of the American population.
There are currently 179 judges on the United States courts of appeals authorized by Congress and Article III of the U.S. Constitution. These judges are nominated by the President of the United States and confirmed by the United States Senate. They have lifetime tenure, earning an annual salary of $213,300.
There are thirteen United States courts of appeals, although there are other tribunals that have "Court of Appeals" in their titles, such as the Court of Appeals for the Armed Forces, which hears appeals in court-martial cases, and the United States Court of Appeals for Veterans Claims, which reviews final decisions by the Board of Veterans' Appeals in the Department of Veterans Affairs. The eleven numbered circuits and the D.C. Circuit are geographically defined. The thirteenth court of appeals is the United States Court of Appeals for the Federal Circuit, which has nationwide jurisdiction over certain appeals based on their subject matter. All of the courts of appeals also hear appeals from some administrative agency decisions and rulemaking, with by far the largest share of these cases heard by the D.C. Circuit. The Federal Circuit hears appeals from specialized trial courts, primarily the United States Court of International Trade and the United States Court of Federal Claims, as well as appeals from the district courts in patent cases and certain other specialized matters.
Decisions of the United States courts of appeals have been published by the private company West Publishing in the "Federal Reporter" series since the courts were established. Only decisions that the courts designate for publication are included. The "unpublished" opinions (of all but the Fifth and Eleventh Circuits) are published separately in West's "Federal Appendix", and they are also available in on-line databases like LexisNexis or Westlaw. More recently, court decisions are also available electronically on the official court websites. However, there are also a few federal court decisions that are classified for national security reasons.
The circuit with the smallest number of appellate judges is the First Circuit, and the one with the largest number of appellate judges is the geographically-large and populous Ninth Circuit in the Far West. The number of judges that the U.S. Congress has authorized for each circuit is set forth by law in , while the places where those judges must regularly sit to hear appeals are prescribed in .
Although the courts of appeals are frequently referred to as "circuit courts", they should not be confused with the former United States circuit courts, which were active from 1789 to 1911, during the time when long-distance transportation was much less available, and which were primarily first-level federal trial courts that moved periodically from place to place in "circuits" in order to serve the dispersed population in towns and the smaller cities that existed then. The current "courts of appeal" system was established in the Judiciary Act of 1891, also known as the Evarts Act.
Procedure.
Trials, at which witnesses and other evidence are presented to a jury or judge in order to determine the truth or facts regarding a particular case, are held only in courts with original jurisdiction, i.e., courts in which a lawsuit is originally (and properly) filed and which have the power to accept evidence from witnesses and make factual and legal determinations regarding the evidence presented. Such trial courts also determine punishments (in criminal cases) and remedies (in civil cases). Because the courts of appeals possess only appellate jurisdiction, they do not hold trials. Instead, appeals courts review decisions of trial courts for errors of law. Accordingly, an appeals court considers only the record (that is, the papers the parties filed and the transcripts and any exhibits from any trial) from the trial court, and the legal arguments of the parties. These arguments, which are presented in written form, and can range in length from dozens to hundreds of pages and are known as briefs. Sometimes lawyers are permitted to add to their written briefs with oral arguments before the appeals judges. At such hearings, only the parties' lawyers speak to the court.
The rules that govern the procedure in the courts of appeals are the Federal Rules of Appellate Procedure. In a court of appeals, an appeal is almost always heard by a "panel" of three judges who are randomly selected from the available judges (including senior judges and judges temporarily assigned to the circuit). Some cases, however, receive an "en banc" hearing. Except in the Ninth Circuit Courts, the "en banc" court consists of all of the circuit judges who are on active status, but it does not include the senior or assigned judges (except that under some circumstances, a senior judge may participate in an en banc hearing when he or she participated at an earlier stage of the same case).
Many decades ago, certain classes of federal court cases held the right of an automatic appeal to the Supreme Court of the United States. That is, one of the parties in the case could appeal a decision of a court of appeals to the Supreme Court, and it had to accept the case. The right of automatic appeal for most types of decisions of a court of appeals was ended by an Act of Congress, the Judiciary Act of 1925. This law was urged by Chief Justice William Howard Taft, and it also reorganized many other things in the federal court system.
The current procedure is that a party in a case may apply to the Supreme Court to review a ruling of the circuit court. This is called petitioning for a writ of certiorari, and the Supreme Court may choose, in its sole discretion, to review any lower court ruling. In extremely rare cases, the Supreme Court may grant the writ of certiorari before the judgment is rendered by the court of appeals, thereby reviewing the lower court's ruling directly. Certiorari before judgment was granted in the Watergate scandal-related case, "United States v. Nixon", and in the 2005 decision involving the Federal Sentencing Guidelines, "United States v. Booker".
A court of appeals may also pose questions to the Supreme Court for a ruling in the midst of reviewing a case. This procedure was formerly used somewhat commonly, but now it is quite rare. The Second Circuit, sitting "en banc", attempted to use this procedure in the case "United States v. Penaranda", as a result of the Supreme Court's decision in "Blakely v. Washington", but the Supreme Court dismissed the question after resolving the same issue in another case, which had come before the Court through the standard procedure. The last instance of the Supreme Court accepting a set of questions and answering them was in a case in 1982.
A court of appeals may convene a Bankruptcy Appellate Panel to hear appeals in bankruptcy cases directly from the bankruptcy court of its circuit. , only the First, Sixth, Eighth, Ninth, and Tenth Circuits have established a Bankruptcy Appellate Panel. Those circuits that do not have a Bankruptcy Appellate Panel have their bankruptcy appeals heard by the District Court.
Courts of appeals decisions, unlike those of the lower federal courts, establish binding precedents. Other federal courts in that circuit must, from that point forward, follow the appeals court's guidance in similar cases, regardless of whether the trial judge thinks that the case should be decided differently.
Federal and state laws can and do change from time to time, depending on the actions of Congress and the state legislatures. Therefore, the law that exists at the time of the appeal might be different from the law that existed at the time of the events that are in controversy under civil or criminal law in the case at hand. A court of appeals applies the law as it exists at the time of the appeal; otherwise, it would be handing down decisions that would be instantly obsolete, and this would be a waste of time and resources, since such decisions could not be cited as precedent. " court is to apply the law in effect at the time it renders its decision, unless doing so would result in manifest injustice, or there is statutory direction or some legislative history to the contrary."
However, the above rule cannot apply in criminal cases if the effect of applying the newer law would be to create an "ex post facto" law to the detriment of the defendant.
Attorneys.
In order to serve as counsel in a case appealed to a circuit court the attorney must be admitted to the bar of that circuit. Admission to the bar of a circuit court is granted as a matter of course to any attorney who is admitted to practice law in any state of the United States. The attorney submits an application, pays a fee, and takes the oath of admission. Local practice varies as to whether the oath is given in writing or in open court before a judge of the circuit, and most courts of appeals allow the applicant attorney to choose which method he or she prefers.
Nomenclature.
When the courts of appeals were created in 1891, one was created for each of the nine circuits then existing, and each court was named the "United States Circuit Court of Appeals for the _____ Circuit". When a court of appeals was created for the District of Columbia in 1893, it was named the "Court of Appeals for the District of Columbia", and it was renamed to the "United States Court of Appeals for the District of Columbia" in 1934. In 1948, Congress renamed all of the courts of appeals then existing to their current formal names: the court of appeals for each numbered circuit was named the "United States Court of Appeals for the _____ Circuit", and the "United States Court of Appeals for the District of Columbia" became the "United States Court of Appeals for the District of Columbia Circuit". The Tenth Circuit was created in 1929 by subdividing the existing Eighth Circuit, and the Eleventh Circuit was created in 1981 by subdividing the existing Fifth Circuit. The Federal Circuit was created in 1982 by the merger of the United States Court of Customs and Patent Appeals and the appellate division of the United States Court of Claims.
Judicial councils.
Judicial councils are panels in each circuit that are charged with making "necessary and appropriate orders for the effective and expeditious administration of justice" within their circuits. Among their responsibilities is judicial discipline, the formulation of circuit policy, the implementation of policy directives received from the Judicial Conference of the United States, and the annual submission of a report to the Administrative Office of the United States Courts on the number and nature of orders entered during the year that relate to judicial misconduct. Judicial councils consist of the chief judge of the circuit and an equal number of circuit judges and district judges of the circuit.
Circuit population.
Based on 2010 United States Census figures, the population residing in each circuit is as follows.
History.
The Judiciary Act of 1789 established three circuits, which were groups of judicial districts in which United States circuit courts were established. Each circuit court consisted of two Supreme Court justices and the local district judge; the three circuits existed solely for the purpose of assigning the justices to a group of circuit courts. Some districts (generally the ones most difficult for an itinerant justice to reach) did not have a circuit court; in these districts the district court exercised the original jurisdiction of a circuit court. As new states were admitted to the Union, Congress often did not create circuit courts for them for a number of years.
The Midnight Judges Act reorganized the districts into six circuits, and created circuit judgeships so that Supreme Court justices would no longer have to ride circuit. This Act, however, was repealed in March 1802, and Congress provided that the former circuit courts would be revived as of July 1 of that year. But it then passed the new Judiciary Act of 1802 in April, so that the revival of the old courts never took effect. The 1802 Act restored circuit riding, but with only one justice to a circuit; it therefore created six new circuits, but with slightly different compositions than the 1801 Act. These six circuits later were augmented by others. Until 1866, each new circuit (except the short-lived California Circuit) was accompanied by a newly created Supreme Court seat.

</doc>
<doc id="70229" url="https://en.wikipedia.org/wiki?curid=70229" title="Joan Lindsay">
Joan Lindsay

Lady Joan à Beckett Lindsay (née Weigall; 16 November 189623 December 1984) was an Australian novelist, playwright, essayist, and artist. Trained in her youth as a painter, Lindsay published her first literary work in 1936 under a pseudonym, a satirical novel titled "Through Darkest Pondelayo". Her second novel, "Time Without Clocks", was published nearly thirty years later, and was a semi-autobiographical account of her early married years to artist Daryl Lindsay.
In 1967, Lindsay published her most celebrated work, "Picnic at Hanging Rock", a historical Gothic novel detailing the vanishing of three schoolgirls and their teacher at the site of a monolith. The novel sparked critical and public interest for its ambivalent presentation as a true story as well as its vague conclusion, and is widely considered to be one of the most important Australian novels of all time. It was adapted into a 1975 film of the same name.
She was also the author of several unpublished plays, and contributed essays, short stories, and poetry to numerous journals and publications throughout her career.
Biography.
Early life.
Joan à Beckett Weigall was born in St Kilda East, Victoria, Australia, the third daughter of Theyre à Beckett Weigall, a prominent judge who was related to the Boyd family, perhaps Australia's most famous and prolific artistic dynasty. Her mother, Ann Sophie Weigall (née Hamilton), was a musician of Irish descent, and grew up in Dublin. Lindsay had two sisters, Mim and Nancy, and a brother, Theyre Jr. Lindsay spent her early years in a villa in St. Margarets, Victoria. She described her childhood as "outwardly happy and uneventful."
In 1909 at the age of thirteen, Lindsay was sent to a local boarding school, then called Carhue, to complete her education. The school went through a change in ownership, and was renamed the Clyde Girls' Grammar School during Lindsay's time there, where she was a model student. After graduating from Clyde, Lindsay considered becoming an architect, but decided to study art instead, enrolling at the National Gallery of Victoria Art School in Melbourne in 1916. There, while studying painting, she was educated by Bernard Hall and Frederick McCubbin.
In 1920 she began sharing a Melbourne studio with Maie Ryan (later Lady Casey). Joan exhibited her watercolours and oils at two Melbourne exhibitions in 1920, one of which was titled "The Neo-Pantechnicists" and exhibited with the Victorian Artists Society. She and Casey also collaborated on an unfinished book together, titled "Portrait of Anna".
Marriage to Daryl Lindsay; early works.
While studying at the National Gallery of Victoria Art School, she met fellow art student Daryl Lindsay. The two married in Marylebone, London, England on St. Valentine's Day 1922. The day was always a special occasion for her, and she set her most famous work, "Picnic at Hanging Rock", on St. Valentine's Day.
When the couple returned to live in Australia, they renovated a farmhouse in Baxter, Mulberry Hill, and lived there until the Great Depression forced them to take up humble lodgings in Bacchus Marsh, renting out their home until the economic situation improved. During this time, Lindsay shifted her focus from painting to writing, and wrote two plays, both of which explored the uncanny and the macabre— "Cataract", and "Wolf!", the latter of which was a collaboration with Margot Goyder and Ann Joske, both of whom were Australia's best-known detective story writers at the time. Though neither of the plays were published, "Wolf!" was performed onstage in Swanage, England in May 1930.
After having returned from travel in England and Europe, Lindsay published her first novel, "Through Darkest Pondelayo: An account of the adventures of two English ladies on a cannibal island", in 1936, under the pseudonym Serena Livingstone-Stanley. Published by Chatto & Windus in the United Kingdom, the novel is structured as a parody of popular travel books of the time but filled with intentional grammatical errors, also functioning as a satire on English tourists abroad. According to Lindsay's cousin Martin Boyd, the novel was "one of the best collections of malapropisms in the English language." Lindsay helped Boyd write the outline for his novel, "Nuns in Jeopardy" (1940).
Lindsay also contributed articles, reviews and stories to various magazines and newspapers on art, literature and prominent people. In 1928, she interviewed actress Margaret Bannerman for Victoria's "The Weekly Courier", and, in 1941, co-authored the "History of the Australian Red Cross" with husband Daryl. In 1942, Lindsay published an essay of literary criticism on novelist George Moore in "The Age", titled "A Modern of the Nineties. George Moore: literary craftsman."
During this period, Daryl Lindsay abandoned painting to become Director of the National Gallery of Victoria, a position he held between 1942 and 1955. The position necessitated their relocation to Melbourne until his retirement. They retained their country home during their Victoria sojourn. Daryl was knighted in 1956, thus becoming Lady Lindsay. 
Her semi-autobiographical novel "Time Without Clocks" describes her wedding and idyllic early married life. The work takes its title from a strange ability which Joan described herself as having, of stopping clocks and machinery when she came close. The title also plays on the idea that this period in her life was unstructured and free. This was followed with "Facts Soft and Hard", a humorous, semi-autobiographical account of the Lindsays' travels in the United States while Daryl was on a Fulbright Award, which took the couple to New York City on a study tour of American art collections held by the Carnegie Corporation.
"Picnic at Hanging Rock".
"Picnic at Hanging Rock", published in 1967, is Lindsay's best known work. Lindsay wrote the novel over a four-week period at her home Mulberry Hill in Baxter, on Victoria's Mornington Peninsula, and structured it around the real-life Hanging Rock, a monolith that had fascinated her since her childhood. She compared the story to the work of Henry James, citing the "book about the children in a haunted house with a governess" (ostensibly "The Turn of the Screw".
The novel is historical fiction, though Lindsay dropped hints that it was based on an actual event, and is framed as such in the novel's introduction. An ending that explained the girls' fates, in draft form, was excised by her publisher prior to publication. The final chapter was published only in the 1980s, in accordance with her wishes. Lindsay had based Appleyard College, the setting for the novel, on the school that she had attended, Clyde Girls Grammar School (Clyde School), at East St Kilda, Melbourne—which, incidentally, in 1919 was transferred to Woodend, Victoria, in the immediate vicinity of Hanging Rock itself. 
In a 1974 interview, Lindsay addressed readers' and critics' questioning about the novel's ambiguous conclusion, saying:Well, it was written as a mystery and it remains a mystery. If you can draw your own conclusions, that's fine, but I don't think that it matters. I wrote that book as a sort of atmosphere of a place, and it was like dropping a stone into the water. I felt that story, if you call it a story—that the thing that happened on St. Valentine's Day went on spreading, out and out and out, in circles.
The novel's inexorably ambiguous conclusion led to significant interest from both public and critical readership, and the novel has drawn comparisons from literary critics to the work of E.M. Forster and Nathaniel Hawthorne. It was made into a 1975 feature film by producers Patricia Lovell, Hal and Jim McElroy, and director Peter Weir, which was hailed as initiating a Renaissance in Australian film. The novel's re-printing by Penguin Books in Australia in 1975 sold over 350,000 copies, making it Penguin Australia's best-selling novel of all time second to AB Facey's "A Fortunate Life".
Later life and death.
In 1969, Lindsay suffered severe injuries in a car accident that required months of convalescence. Daryl Lindsay died in 1976. Lady Lindsay's later years were spent invested in visual arts, with frequent visits to the Lyceum Club in Melbourne, and to the McClelland Gallery in Langwarrin. She produced multiple paintings in her later years, and was lauded by art critic Alan McCulloch. In 1972, she reunited with Lady Maie Casey and held an art exhibition at the McLelland in Langwarrin. Artist Rick Amor and his children, who had lived in a cottage of Lindsay's property, led her to resurrect an unpublished children's book she had written, titled "Syd Sixpence", which she had published in 1982.
Lady Lindsay died in Frankston, Melbourne in 1984 of natural causes, and was cremated. Because the Lindsays had no children, their Mulberry Hill house was donated to the National Trust upon her death, at her wishes. Her ashes are interred at Creswick Cemetery in Creswick, Shire of Hepburn in Victoria, Australia.
Lindsay's visual artwork has been exhibited posthumously as part of the National Women's Art Exhibition in Australia.

</doc>
<doc id="70235" url="https://en.wikipedia.org/wiki?curid=70235" title="United States district court">
United States district court

The United States district courts are the general trial courts of the United States federal court system. They are known as the work horses because they deal with most of the court cases. Both civil and criminal cases are filed in the district court, which is a court of law, equity, and admiralty. There is a United States bankruptcy court associated with each United States district court. Each federal judicial district has at least one courthouse, and many districts have more than one. The formal name of a district court is "the United States District Court for" the name of the district—for example, the "United States District Court for the Eastern District of Missouri".
In contrast to the Supreme Court, which was established by Article III of the Constitution, the district courts were established by Congress. There is no constitutional requirement that district courts exist at all. Indeed, after the ratification of the Constitution, some opponents of a strong federal judiciary urged that the federal court system be limited to the Supreme Court, which would hear appeals from state courts. This view did not prevail, however, and the first Congress created the district court system that is still in place today.
There is at least one judicial district for each state, the District of Columbia, and Puerto Rico. District courts in three insular areas—the United States Virgin Islands, Guam, and the Northern Mariana Islands—exercise the same jurisdiction as Article III U.S. district courts. Despite their name, these courts are technically not "District Courts of the United States". Judges on these Article IV territorial courts do not enjoy the protections of Article Three of the Constitution, and serve terms of ten years rather than for life.
There are 89 districts in the 50 states, with a total of 94 districts including territories.
Other federal trial courts.
There are other federal trial courts that have nationwide jurisdiction over certain types of cases, but the district court also has concurrent jurisdiction over many of those cases, and the district court is the only one with jurisdiction over civilian criminal cases. The United States Court of International Trade addresses cases involving international trade and customs issues. The United States Court of Federal Claims has exclusive jurisdiction over most claims for money damages against the United States, including disputes over federal contracts, unlawful takings of private property by the federal government, and suits for injury on federal property or by a federal employee. The United States Tax Court has jurisdiction over contested pre-assessment determinations of taxes.
United States district judges.
A judge of a United States district court is officially titled a "United States District Judge". Other federal judges, including circuit judges and Supreme Court Justices, can also sit in a district court upon assignment by the chief judge of the circuit or by the Chief Justice of the United States. The number of judges in each district court (and the structure of the judicial system generally) is set by Congress in the United States Code. The President appoints the federal judges for terms of good behavior (subject to the advice and consent of the Senate), so the nominees often share at least some of his convictions. In states represented by a senator of the president's party, the senator (or the more senior of them if both senators are of the president's party) has substantial input into the nominating process, and through a tradition known as senatorial courtesy can exercise an unofficial veto over a nominee unacceptable to the senator.
With the exception of the territorial courts (Guam, the Northern Mariana Islands, and the Virgin Islands), federal district judges are Article III judges appointed for life, and can be removed involuntarily only when they violate the standard of "good behavior". The sole method of involuntary removal of a judge is through impeachment by the United States House of Representatives followed by a trial in the United States Senate and a conviction by a two-thirds vote. Otherwise, a judge, even if convicted of a felony criminal offense by a jury, is entitled to hold office until retirement or death. In the history of the United States, only twelve judges have been impeached by the House, and only seven have been removed following conviction in the Senate. (For a table that includes the twelve impeached judges, see Impeachment in the United States.)
A judge who has reached the age of 65 (or has become disabled) may retire or elect to go on senior status and keep working. Such senior judges are not counted in the quota of active judges for the district and do only whatever work they are assigned by the chief judge of the district, but they keep their offices (called "chambers") and staff, and many of them work full-time. A federal judge is addressed in writing as "The Honorable John/Jane Doe" or "Hon. John/Jane Doe" and in speech as "Judge" or "Judge Doe" or, when presiding in court, "Your Honor".
District judges usually concentrate on managing their court's overall caseload, supervising trials, and writing opinions in response to important motions like the motion for summary judgment. Since the 1960s, routine tasks like resolving discovery disputes can, in the district judge's discretion, be referred to magistrate judges. Magistrate judges can also be requested to prepare reports and recommendations on contested matters for the district judge's consideration or, with the consent of all parties, to assume complete jurisdiction over a case including conducting the trial.
Federal magistrate judges are appointed by each district court pursuant to statute. They are appointed for an eight-year term and may be reappointed for additional eight-year terms. A magistrate judge may be removed "for incompetency, misconduct, neglect of duty, or physical or mental disability". A magistrate judgeship may be a stepping stone to a district judgeship nomination.
As of 2010, there were 678 authorized district court judgeships. A study put forth by Brennan Center for Justice at New York University of Law found that under the Obama administration and especially in the year 2009 there have been a "uniquely high" number of vacancies in Federal Court, averaging 60 or more from the years 2009 to 2013. The Obama administration has blamed Senate Republicans for opposing (and therefore, not confirming) presidential nominations, while the Republicans say Obama has been slow to nominate.
Jurisdiction.
Unlike some state courts, the power of federal courts to hear cases and controversies is strictly limited. Federal courts may not decide every case that happens to come before them. In order for a district court to entertain a lawsuit, Congress must first grant the court subject matter jurisdiction over the type of dispute in question. 
The district courts exercise original jurisdiction over—that is, they are empowered to conduct trials in—the following types of cases:
For most of these cases, the jurisdiction of the federal district courts is concurrent with that of the state courts. In other words, a plaintiff can choose to bring these cases in either a federal district court or a state court. Congress has established a procedure whereby a party, typically the defendant, can "remove" a case from state court to federal court, provided that the federal court also has original jurisdiction over the matter. For certain matters, such as patent and copyright infringement disputes and prosecutions for federal crimes, the jurisdiction of the district courts is exclusive of that of the state courts.
In addition to their original jurisdiction, the district courts have appellate jurisdiction over a very limited class of judgments, orders, and decrees.
Attorneys.
In order to represent a party in a case in a district court, a person must be an attorney at law and generally must be admitted to the bar of that particular court. The United States usually does not have a separate bar examination for federal practice (except with respect to patent practice before the United States Patent and Trademark Office). Admission to the bar of a district court is generally granted as a matter of course to any attorney who is admitted to practice law in the state where the district court sits. Many district courts also allow an attorney who has been admitted and remains an active member in good standing of any state, territory or the District of Columbia bar to become a member. The attorney submits his application with a fee and takes the oath of admission. Local practice varies as to whether the oath is given in writing or in open court before a judge of the district.
Several district courts require attorneys seeking admission to their bars to take an additional bar examination on federal law, including the following: the Southern District of Ohio, the Northern District of Florida, and the District of Puerto Rico.
Appeals.
Generally, a final ruling by a district court in either a civil or a criminal case can be appealed to the United States court of appeals in the federal judicial circuit in which the district court is located, except that some district court rulings involving patents and certain other specialized matters must be appealed instead to the United States Court of Appeals for the Federal Circuit, and in a very few cases the appeal may be taken directly to the United States Supreme Court.
Busiest district courts.
The Central District of California is the largest federal district by population; it includes all five counties that make up the Greater Los Angeles Area. By contrast, New York City and the surrounding metropolitan area are divided between the Southern District of New York (which includes Manhattan and The Bronx) and the Eastern District of New York (which includes Brooklyn, Queens, Staten Island, Nassau County and Suffolk County). New York suburbs in Connecticut and New Jersey are covered by the District of Connecticut and District of New Jersey, respectively.
The Southern District of New York and the Central District of California are the largest federal districts by number of judges, with 28 and 27, respectively.
In 2007, the busiest district courts in terms of criminal federal felony filings were the District of New Mexico, Western District of Texas, Southern District of Texas, and the District of Arizona. These four districts all share the border with Mexico. A crackdown on illegal immigration resulted in 75 percent of the criminal cases filed in the 94 district courts in 2007 being filed in these four districts and the other district that borders Mexico, the Southern District of California.
Extinct district courts.
Subdivided district courts.
Most extinct district courts have disappeared by being divided into smaller districts. The following courts were subdivided out of existence: Alabama, Arkansas, California, Florida, Georgia, Illinois, Indiana, Iowa, Kentucky, Louisiana, Michigan, Mississippi, Missouri, New York, North Carolina, Ohio, Pennsylvania, Tennessee, Texas, Virginia, Washington, West Virginia, Wisconsin.
Other abolished district courts.
On rare occasions, an extinct district court was extinguished by merging it with other district courts. In every case except one, this has restored a district court that had been subdivided:
There are a few additional extinct district courts that fall into neither of the above two patterns.

</doc>
<doc id="70237" url="https://en.wikipedia.org/wiki?curid=70237" title="United States bankruptcy court">
United States bankruptcy court

United States bankruptcy courts are courts created under Article I of the United States Constitution. They function as units of the district courts and have subject-matter jurisdiction over bankruptcy cases. The federal district courts have original and exclusive jurisdiction over all cases arising under the bankruptcy code, (see ), and bankruptcy cases cannot be filed in state court. Each of the 94 federal judicial districts handles bankruptcy matters. The current system of bankruptcy courts was created by United States Congress in 1978, effective April 1, 1984.
The bankruptcy judges in each judicial district in regular active service constitute a "unit" of the applicable United States district court (see ). The bankruptcy judge is appointed for a term of 14 years by the United States court of appeals for the circuit in which the applicable district is located (see ).
Technically, the United States district courts have subject matter jurisdiction over bankruptcy matters (see ). However, each such district court may, by order, "refer" bankruptcy matters to the bankruptcy court (see ). As a practical matter, most district courts have a standing "reference" order to that effect, so that all bankruptcy cases in that district are handled, at least initially, by the bankruptcy court. In unusual circumstances, a district court may in a particular case “withdraw the reference” (i.e., take the case or a particular proceeding within the case away from the bankruptcy court and decide the matter itself) under .
The overwhelming majority of all proceedings in bankruptcy are held before a United States bankruptcy judge, whose decisions are subject to appeals to the district court. In some judicial circuits, appeals may be taken to a Bankruptcy Appellate Panel (BAP).
The Federal Rules of Bankruptcy Procedure (FRBP) govern procedure in the U.S. bankruptcy courts.
Decisions of the Bankruptcy Courts are not collected and published in an official reporter produced by the government. Instead, the "de facto" official source for opinions of the Bankruptcy Courts is "West's Bankruptcy Reporter", published privately by Thomson West.
Bankruptcy courts appoint a trustee to represent the interests of the creditors and administer the cases. The U.S. Trustee appoints Chapter 7 trustees for a renewable period of 1 year, Chapter 13 trustees are “standing trustees” who administrator cases in a specific geographic region.

</doc>
<doc id="70239" url="https://en.wikipedia.org/wiki?curid=70239" title="Victorian Artists Society">
Victorian Artists Society

The Victorian Artists Society, which can trace its establishment to 1856 in Melbourne, promotes artistic education, art classes and gallery hire exhibition in Australia.
The Victorian Artists Society was formed in March 1888 following the decision of the Victorian Academy of Arts and the Australian Artists' Association to amalgamate. The Victorian Academy of Arts had been formed in 1870 with 'about twenty artists and amateurs' amongst its first members. The Academy's forerunner, the Victorian Society of Fine Arts, was established in 1856. The Australian Artists' Association held its first exhibition in 1886 with works by Tom Roberts, Louis Buvelot, Frederick McCubbin, and Arthur Streeton.
The founding president of the new amalgamated Society was Joseph Anderson Panton and later presidents included Frederick McCubbin and Paul Raphael Montford.
The premises at 430 Albert Street in East Melbourne were erected for the society in 1888, enlarged in 1892 and modernised in 1953. Facilities include four galleries, teaching studio, members room, offices and other ancillary facilities.
Membership is restricted to 1000, a figure last reached in 1979, and is open for new members to join. Membership is open to all persons interested in the fine arts, with the emphasis on practising artists.
Regular classes are held in various media which are open to members and non-members including watercolour, oil painting, drawing, mixed media, life model.
Exhibitions are held annually, including the seasonal spring, summer, autumn and winter exhibitions, with awards given at each.
The 2011 Artist of the Year Award was given to Clive Sinclair.

</doc>
<doc id="70243" url="https://en.wikipedia.org/wiki?curid=70243" title="United States Department of Commerce">
United States Department of Commerce

The United States Department of Commerce (DOC) is the Cabinet department of the United States government concerned with promoting economic growth. The mission of the department is to "promote job creation and improved living standards for all Americans by creating an infrastructure that promotes economic growth, technological competitiveness, and sustainable development". Among its tasks are gathering economic and demographic data for business and government decision-making, and helping to set industrial standards. The Department of Commerce headquarters is the Herbert C. Hoover Building in Washington, D.C.
History.
The department was originally created as the United States Department of Commerce and Labor on February 14, 1903. This organization's main purpose is to create jobs, promote economic growth, encourage sustainable development and improve standards of living for all Americans. It was subsequently renamed the Department of Commerce on March 4, 1913, as the bureaus and agencies specializing in labor were transferred to the new Department of Labor. The United States Patent and Trademark Office was transferred from the Interior Department into Commerce, and the Federal Employment Stabilization Office existed within the department from 1931 to 1939. In 1940, the Weather Bureau (now the National Weather Service) was transferred from the Agriculture Department, and the Civil Aeronautics Authority was merged into the department. In 1949, the Public Roads Administration was added to the department due to the dissolution of the Federal Works Agency. In 1958, the independent Federal Aviation Agency was created and the Civil Aeronautics Authority was abolished. The United States Travel Service was established by the United States Secretary of Commerce on July 1, 1961 pursuant to the International Travel Act of 1961 (75 Stat. 129; 22 U.S.C. 2121 note) The Economic Development Administration was created in 1965. In 1966, the Bureau of Public Roads was transferred to the newly created Department of Transportation. The National Oceanic and Atmospheric Administration (NOAA) was created on October 3, 1970. The DOC is currently headed by Secretary Penny Pritzker.
Reorganization proposals.
Proposals to reorganize the Department go back many decades. The Department of Commerce was one of three departments that Texas governor Rick Perry advocated eliminating during his 2012 presidential campaign, along with the Department of Education and Department of Energy. Perry's campaign cited the frequency with which agencies had historically been moved into and out of the department and its lack of a coherent focus, and advocated moving its vital programs into other departments such as the Department of the Interior, Department of Labor, and Department of the Treasury. The Economic Development Administration would be completely eliminated. The Department of Commerce was one of five departments that Texas Congressman Ron Paul supported eliminating during his 2012 presidential campaign, along with Department of Education, Department of Energy, Department of Interior, and Department of Housing and Urban Development.
On January 13, 2012, President Obama announced his intentions to ask the United States Congress for the power to close the department and replace it with a new cabinet-level agency focused on trade and exports. The new agency would include the Office of the United States Trade Representative, currently part of the Executive Office of the President, as well as the Export-Import Bank of the United States, the Overseas Private Investment Corporation, the United States Trade and Development Agency, and the Small Business Administration, which are all currently independent agencies. The Obama administration projects that the reorganization would save $3 billion and will help the administration's goal of doubling U.S. exports in five years. The new agency would be organized around four "pillars": a technology and innovation office including the United States Patent and Trademark Office and the National Institute of Standards and Technology; a statistical division including the United States Census Bureau and other data-collection agencies currently in the Commerce Department, and also the Bureau of Labor Statistics which would be transferred from the Department of Labor; a trade and investment policy office; and a small business development office. The National Oceanic and Atmospheric Administration (NOAA) would be transferred from the Department of Commerce into the Department of the Interior. Later that year, shortly before the 2012 presidential election, Obama invoked the idea of a "secretary of business" in reference to the plan. The reorganization was part of a larger proposal which would grant the President the authority to propose mergers of federal agencies, which would then be subject to an up-or-down Congressional vote. This ability had existed from the Great Depression until the Reagan presidency, when Congress rescinded the authority.
The Obama administration plan faced criticism for some of its elements. Some Congress members expressed concern that the Office of the United States Trade Representative would lose focus if it were included in a larger bureaucracy, especially given its status as an "honest broker" between other agencies, which tend to advocate for specific points of view. The overall plan has also been criticized as an attempt to create an agency similar to Japan's powerful Ministry of International Trade and Industry, which was abolished in 2001 after some of its initiatives failed and it became seen as a hindrance to growth. NOAA's climate and terrestrial operations and fisheries and endangered species programs would be expected to integrate well with agencies already in the Interior Department, such as the United States Geological Survey and the United States Fish and Wildlife Service. However, environmental groups such as the Natural Resources Defense Council feared that the reorganization could distract the agency from its mission of protecting the nation's oceans and ecosystems.
The plan was reiterated in the Obama administration's FY2016 budget proposal that was released in February 2015.
Organization.
Budget and finances.
The Department of Commerce was authorized a budget for Fiscal Year 2015 of $60.9 billion. The budget authorization is broken down as follows:

</doc>
<doc id="70247" url="https://en.wikipedia.org/wiki?curid=70247" title="Bureau of Industry and Security">
Bureau of Industry and Security

The Bureau of Industry and Security (BIS) is an agency of the United States Department of Commerce that deals with issues involving national security and high technology. A principal goal for the bureau is helping stop proliferation of weapons of mass destruction, while furthering the growth of United States exports. The Bureau is led by the Under Secretary of Commerce for Industry and Security.
The mission of the BIS is to advance U.S. national security, foreign policy, and economic interests. BIS's activities include regulating the export of sensitive goods and dual-use technologies in an effective and efficient manner; enforcing export control, anti-boycott, and public safety laws; cooperating with and assisting other countries on export control and strategic trade issues; assisting U.S. industry to comply with international arms control agreements; monitoring the viability of the U.S. defense-industrial base; and promoting federal initiatives and public-private partnerships to protect the nation's critical infrastructures.
Items on the Commerce Control List (CCL) - which includes many sensitive goods and technologies like encryption software - require a permit from the Department of Commerce before they can be exported. To determine whether an export permit is required, an Export Control Classification Number (ECCN) is used.
Organization.
The Bureau of Industry and Security, a component of the United States Department of Commerce, is organized by the United States Secretary of Commerce as follows:
Guiding Principles of the Bureau of Industry and Security.
The main focus of BIS is the security of the United States, which includes its national security, economic security, cyber security, and homeland security. For example, in the area of dual-use export controls, BIS administers and enforces such controls to stem the proliferation of weapons of mass destruction and the means of delivering them, to halt the spread of weapons to terrorists or countries of concern, and to further U.S. foreign policy objectives. Where there is credible evidence suggesting that the export of a dual-use item threatens U.S. security, the Bureau is empowered to prevent export of the item.
In addition to national security, BIS's function is to ensuring the health of the U.S. economy and the competitiveness of U.S. industry. BIS promotes a strong defense-industrial base that can develop and provide technologies that will enable the United States to maintain its military superiority. BIS takes care to ensure that its regulations do not impose unreasonable restrictions on legitimate international commercial activity that are necessary for the health of U.S. industry.
Private Sector Collaboration.
BIS works with the private sectors of the aerospace manufacturers, microprocessor, defense and other high-tech industries, which today controls a greater share of critical U.S. resources than in the past. Because the health of U.S. industry is dependent on U.S. security, BIS has formed a symbiotic relationship between industry and security, which is reflected in the formulation, application, and enforcement of BIS rules and policies.
Shifting Global Priorities.
BIS activities and regulations also seek to adapt to changing global conditions and challenges. The political, economic, technological, and security environment that exists today is substantially different than that of only a decade ago. Laws, regulations, or practices that do not take into account these new global realities - and that do not have sufficient flexibility to allow for adaptation in response to future changes - ultimately harm national security by imposing costs and burdens on U.S. industry without any corresponding benefit to U.S. security. In the area of exports, these significant geopolitical changes suggest that the U.S. control regime that in the past was primarily list-based must shift to a mix of list-based controls and controls that target specific end-uses and end-users of concern. BIS also should be creative in thinking about how new technologies can be utilized in designing better export controls and enforcing controls more effectively.
BIS strives to work cooperatively with state and local government officials, first responders, and federal executive departments and agencies, including the National Security Council, Department of Homeland Security, Department of State, Department of Defense, Department of Energy, Department of Justice, and the Intelligence Community. BIS consults with its oversight committees, (the House Foreign Affairs Committee and Senate Foreign Relations Committee) and other appropriate Members of Congress and congressional staff on matters of mutual interest.
International Cooperation.
International cooperation is critical to BIS's activities. The mission of promoting security depends heavily upon international cooperation with the United States's principal trading partners and other countries of strategic importance, such as major transshipment hubs. BIS takes the viewpoint that when seeking to control the spread of dangerous goods and technologies, protecting critical infrastructures, and ensuring the existence of a strong defense industrial base, international cooperation is critical. With regard to export control laws in particular, effective enforcement is greatly enhanced by both international cooperation and an effort to harmonize the substance of U.S. laws with those of our principal trading partners. International cooperation, however, does not mean "settling on the lowest common denominator." Where consensus cannot be broadly obtained, the BIS will maintain its principles, but should seek to achieve its goals through other means, including cooperation among smaller groups of like-minded partners.

</doc>
<doc id="70248" url="https://en.wikipedia.org/wiki?curid=70248" title="DOD">
DOD

DOD, Dod and/or DoD may refer to:

</doc>
<doc id="70249" url="https://en.wikipedia.org/wiki?curid=70249" title="Walkabout (disambiguation)">
Walkabout (disambiguation)

A walkabout is an Australian aboriginal ritual of manhood.
Walkabout may also refer to:

</doc>
<doc id="70250" url="https://en.wikipedia.org/wiki?curid=70250" title="Nicolas Roeg">
Nicolas Roeg

Nicolas Jack Roeg (; born 15 August 1928) is an English film director and cinematographer.
After National Service he entered the film business as a tea boy moving up to clapper-loader, the bottom rung of the camera department, at Marylebone Studios in London. Early in his career Roeg was a second-unit cinematographer on "Lawrence of Arabia", then cinematographer on Roger Corman's "The Masque of the Red Death" and François Truffaut's "Fahrenheit 451". He co-directed and photographed "Performance" in 1970. He later directed such films as "Walkabout", "Don't Look Now" and "The Man Who Fell to Earth".
Film career.
Roeg's films are known for having scenes and images from the plot presented in a disarranged fashion, out of chronological and causal order, requiring the viewer to do the work of mentally rearranging them to comprehend the storyline. They seem, "to shatter reality into a thousand pieces" and are "unpredictable, fascinating, cryptic and liable to leave you wondering what the hell just happened. ..."
A characteristic of Roeg's films is that they are edited in disjunctive and semi-coherent ways that make full sense only in the film's final moments, when a crucial piece of information surfaces; they are "mosaic-like montages with elliptical details which become very important later."
These techniques, and Roeg's foreboding sense of atmosphere, influenced later filmmakers such as Steven Soderbergh, Tony Scott, Ridley Scott, François Ozon and Danny Boyle.
Roeg's influence on cinema is not limited to deconstructing narrative. The "Memo From Turner" sequence in "Performance" predates many techniques later used in music videos. The "quadrant" sequence in "Bad Timing", in which the thoughts of Theresa Russell and Art Garfunkel are heard before words are spoken, set to Keith Jarrett's piano music from the "Köln Concert", stretched the boundaries of what could be done with film. His work was documented at the Riverside Studios, London from 12–14 September 2008, showcasing nine of his films. He introduced the retrospective along with Miranda Richardson, who starred in "Puffball". The retrospective included "Bad Timing", "Puffball", "Far from the Madding Crowd", "The Man Who Fell to Earth", "The Witches", "Eureka", "Don't Look Now" and "Insignificance". The London Film Academy organised this event for Roeg in honour of his patronage of the school.
Personal life.
Roeg was born in London, to Mabel Gertrude (née Silk) and Jack Nicolas Roeg.
Roeg was married to Susan Stephen from 1957–77. They had four children, Waldo, Nico, Sholto and the producer Luc Roeg, who also stars in Roeg's first film, "Walkabout", as Lucien John. Roeg married Theresa Russell in 1982 and they had two children, Max (an actor) and Statten Roeg. Following their divorce, Roeg married Harriet Harper in 2004. 

</doc>
<doc id="70257" url="https://en.wikipedia.org/wiki?curid=70257" title="Growth accounting">
Growth accounting

Growth accounting is a procedure used in economics to measure the contribution of different factors to economic growth and to indirectly compute the rate of technological progress, measured as a residual, in an economy. This methodology was introduced by Robert Solow in 1957.
Growth accounting decomposes the growth rate of economy's total output into that which is due to increases in the amount of factors used—usually the increase in the amount of capital and labor—and that which cannot be accounted for by observable changes in factor utilization. The unexplained part of growth in GDP is then taken to represent increases in productivity (getting more output with the same amounts of inputs) or a measure of broadly defined technological progress.
The technique has been applied to virtually every economy in the world and a common finding is that observed levels of economic growth cannot be explained simply by changes in the stock of capital in the economy or population and labor force growth rates. Hence, technological progress plays a key role in the economic growth of nations, or the lack of it.
Example.
As an abstract example consider an economy whose total output (GDP) grows at 3% per year. Over the same period its capital stock grows at 6% per year and its labor force by 1%. The contribution of the growth rate of capital to output is equal to that growth rate weighted by the share of capital in total output and the contribution of labor is given by the growth rate of labor weighted by labor's share in income. If capital's share in output is , then labor's share is (assuming these are the only two factors of production). This means that the portion of growth in output which is due to changes in factors is .06×()+.01×()=.027 or 2.7%. This means that there is still 0.3% of the growth in output that cannot be accounted for. This remainder is the increase in the productivity of factors that happened over the period, or the measure of technological progress during this time.
Technical derivation.
The total output of an economy is modeled as being produced by various factors of production, with capital and labor being the primary ones in modern economies (although land and natural resources can also be included). This is usually captured by an aggregate production function:
formula_1
where Y is total output, K is the stock of capital in the economy, L is the labor force (or population) and A is a "catch all" factor for technology, role of institutions and other relevant forces which measures how productively capital and labor are used in production.
Standard assumptions on the form of the function F(.) is that it is increasing in K, L, A (if you increase productivity or you increase the amount of factors used you get more output) and that it is homogeneous of degree one, or in other words that there are constant returns to scale (which means that if you double both K and L you get double the output). The assumption of constant returns to scale facilitates the assumption of perfect competition which in turn implies that factors get their marginal products:
formula_2
formula_3
where MPK denotes the extra units of output produced with an additional unit of capital and similarly, for MPL. Wages paid to labor are denoted by w and the rate of profit or the real interest rate is denoted by r. Note that the assumption of perfect competition enables us to take prices as given. For simplicity we assume unit price (i.e. P =1), and thus quantities also represent values in all equations.
If we totally differentiate the above production function we get;
formula_4
where formula_5 denotes the partial derivative with respect to factor i, or for the case of capital and labor, the marginal products. With perfect competition this equation becomes:
formula_6
If we divide through by Y and convert each change into growth rates we get:
formula_7
or denoting a growth rate (percentage change over time) of a factor as formula_8 we get:
formula_9
Then formula_10 is the share of total income that goes to capital, which can be denoted as formula_11 and formula_12 is the share of total income that goes to labor, denoted by formula_13. This allows us to express the above equation as:
formula_14
In principle the terms formula_11, formula_16, formula_17 and formula_18 are all observable and can be measured using standard national income accounting methods (with capital stock being measured using investment rates via the perpetual inventory method). The term formula_19 however is not directly observable as it captures technological growth and improvement in productivity that are unrelated to changes in use of factors. This term is usually referred to as Solow residual or Total factor productivity growth. Slightly rearranging the previous equation we can measure this as that portion of increase in total output which is not due to the (weighted) growth of factor inputs:
formula_20
Another way to express the same idea is in per capita (or per worker) terms in which we subtract off the growth rate of labor force from both sides:
formula_21
which states that the rate of technological growth is that part of the growth rate of per capita income which is not due to the (weighted) growth rate of capital per person.

</doc>
<doc id="70258" url="https://en.wikipedia.org/wiki?curid=70258" title="I, the Jury">
I, the Jury

I, the Jury is the 1947 debut novel of American crime-fiction writer Mickey Spillane, the first work to feature private investigator Mike Hammer.
Plot summary.
Dr. Charlotte Manning is young, beautiful, blonde, and well-to-do psychiatrist motivated by greed. To increase her profit, she becomes involved with a crime syndicate with ties to both prostitution and drug-trafficking. The leader of the organization is Hal Kines, who has had plastic surgery to make him look younger, and who recruits young women for the sex trade. Manning herself has upscale clientele, though her trade is not prostitution but coercing her patients into becoming dependent upon medications, primarily heroin, in order to extort money from them. On the surface, Charlotte Manning maintains her facade as a renowned psychiatrist.
As the sinister plots of Manning and the crime syndicate evolve, Jack Williams falls in love with Myrna Devlin when he stops her from committing suicide by jumping from a bridge. Williams himself is a former New York police officer who has lost his arm in World War II saving the life of his friend Mike Hammer. Williams asks Dr. Manning to admit Devlin to her clinic for psychotherapy. After Myrna has become clean, she and Williams become engaged, though the couple maintains a casual friendship with Manning. Over time, Williams becomes suspicious of Manning's business, and secretly investigates further. He realizes that Hal Kines, one of Manning's college students who has spent some time at her clinic and who has become one of her casual acquaintances, is in fact a criminal. When, at a party given by Williams in his apartment, Charlotte Manning finds old college yearbooks whose contents would expose Kines' criminal actions, she has to act fast. After the party, she goes home but on the same night, undetected, returns to Williams' apartment and shoots him in the stomach with a silencer as she watches him die slowly. Then she takes the college yearbooks and leaves.
On a Saturday morning, Hammer picks up Myrna Devlin and gives her a lift. They drive to the Bellemy twins' estate in the country for a gigantic all-day party there. Charlotte Manning says she has some business to attend to and will be there in time for a tennis game due to take place that evening. After an unsuccessful attempt at playing tennis himself, Hammer gets rid of his sleep deficit by spending all day in his room, fast asleep, with "old junior" — his gun — close to him. He is woken up just in time for dinner, during which Harmon Wilder, the Bellemys' lawyer, and Charles Sherman, Wilder's assistant, are pointed out to him. This is a fine — and the final — distractor in the novel: Wilder and Sherman are suddenly missing from the party after Myrna Devlin has been found shot. In fact they had illicit drugs on them and did not want to be found out. During the tennis game, Mary Bellemy asks Charlotte if she can "borrow" Hammer. Then she leads him into the woods where they have sex. They return to the party just as a maid discovers Myrna's body in an upstairs room, in front of a large mirror. Both Pat Chambers and the police are called in, and the alibis of each guest is checked. Again Charlotte can convince everyone that she could not have done anything.
Back home, Hammer retreats into his apartment to think. Finally, he knows the identity of the killer. This is when he goes to Charlotte's place, recapitulates the whole crime and finally shoots her dead, despite her efforts to pull the trigger on him.
Reception.
By the time the book was adapted into a film in 1953, it had sold 3 500 000 copies.
Films.
The first film version of "I, the Jury" was shot in 1953 and was released through United Artists. After a four-picture contract was signed with Spillane, the movie was filmed, in 3-D, featuring Biff Elliot as Mike Hammer, Preston Foster and Peggie Castle. The plot from the novel was toned down for the film version. It grossed $1,299,000. The cinematographer was John Alton.
In 1982, the story was made into a movie again by director Richard T. Heffron with Armand Assante as Mike Hammer.
In popular culture.
The novel's reputation for raciness and violence has outlasted the popularity of the book itself.

</doc>
<doc id="70260" url="https://en.wikipedia.org/wiki?curid=70260" title="Castile and León">
Castile and León

Castile and León (; ; Leonese: "Castiella y Llión" ; ; ) is an autonomous community in north-western Spain. It was constituted in 1983, although it existed for the first time during the First Spanish Republic in the 19th century. León first appeared as a Kingdom in 910, whilst the Kingdom of Castile gained an independent identity in 1065 and was intermittently held in personal union with León before merging with it permanently in 1230. It is the largest autonomous community in Spain and the third largest region of the European Union, covering an area of with an official population of around 2.5 million (2011).
The organic law of Castile and León, under the Spanish Constitution of 1978, is the bi-region's Statute of Autonomy. The statute lays out the basic laws of the region and defines a series of essential values and symbols of the inhabitants of Castile and León, such as their linguistic patrimony (the Castilian language, which English speakers commonly refer to simply as Spanish, as well as Leonese and Galician), as well as their historic, artistic, and natural patrimony (see Castilian people). Other symbols alluded to are the coat of arms, flag, and banner; there is also allusion to a regional anthem, though as of 2013 none has been adopted. 
It is the region of the world with the most World Heritage Sites, 8 in total. April 23 is designated Castile and León Day, commemorating the defeat of the "comuneros" at the Battle of Villalar during the Revolt of the Comuneros, in 1521. 
Geography.
Castile and León is bordered by Portugal and Galicia to the west and by Asturias and Cantabria to the north. Aragon, the Basque Country and La Rioja is to the east and the border to the south is with Madrid, and with Castile-La Mancha and Extremadura to the southwest.
Castile and León is in the Meseta Central, a plateau in the middle of the northern half of the Iberian Peninsula; the Spanish part of the Douro River basin is nearly coterminous. There is also El Bierzo (León) and Laciana (León), Valle de Mena (Burgos), and the Valle del Tietar (Ávila), very secluded mountain valleys including some from neighbouring valleys and stretches. 
Terrain.
Much of its territory consists of a large, central plateau - the Meseta. Its height lies between 700-1000m.
Rivers.
The most prominent hydrographic feature of Castile and León is the River Douro () and its tributaries. The Douro runs from its headwaters in the Picos de Urbión in Soria to its mouth at the Portuguese city of Porto. Flowing into the Douro from the north, on its right bank, are the Pisuerga, the Valderaduey and the Esla, its most capacious tributaries, and from the east, on its left bank, the lesser flows of the Adaja and Duratón. After passing the city of Zamora, the Douro flows through a canyon in the Arribes del Duero Natural Park where it constitutes the border with Portugal, flowing north. From its left bank, it receives the waters of such important tributaries as the Tormes, Huebra, Águeda, the Côa and the Paiva, all originating in the Sistema Central. From the right bank, it receives the waters of the Sabor, the Tua and the Támega, originating in the Galician Massif. Beyond the Arribes, the Douro turns west, flowing through Portugal to the Atlantic. 
Climate.
The highest rainfall is found in Leon, with a yearly average of 556mm, whilst Palencia has the lowest amount. The region has a continental climate, characterized by relatively cold winters and dry warm summers. This is the result of distance from the sea and high altitude. Only two small areas have a milder climate, the section of the province of Avila which extends south of Gredos mountains into the Tiétar valley, and the area where the Duero river forms a natural border between Zamora province and Portugal known as the Arribes del Duero. 
Regional administration and government.
Castile and León is divided into nine provinces: 
Each of these provinces is named after its respective provincial capital.
Autonomous Executive.
The executive of Castile and León is known as the "Junta de Castilla y León" in Spanish. 
It has one head of the Regional Executive, the President of the Junta of Castile and León, and twelve departments: Two "Vicepresidencias" and ten ministries (Spanish: "Consejerías"). 
Another party, the left-of-centre Castilian Nationalist Tierra Comunera - ACAL, has contested previous elections and has held seats in the Regional Courts in the past, but as of 2011 it is not represented in that body. 
Culture.
Languages.
Besides the dominant Castilian Spanish, three other regional languages figure in the linguistic patrimony of Castile and León. Two of these are recognized explicitly in the Statute of Autonomy. The Leonese language, according to the Statute, "will be the object of specific protection [...] for its particular value in the linguistic heritage of the Community". The Galician language, according to the statute, "merits respect and protection in the places where it is habitually used, which is effectively to say the portions of the comarcas of El Bierzo and Sanabria bordering Galicia. In addition, although unmentioned in the Statute, in the comarca of El Rebollar in the province of Salamanca, people speak a variety of Extremaduran known as "Habla del Rebollar" ("the speech of Rebollar").
History.
Castile and León traces its history to the medieval kingdoms of Castile and León, which were permanently united under the Crown of Castile in 1301. Together with other Christian-ruled Iberian kingdoms, the separate monarchies of Castile and León participated in the "Reconquista", the re-conquest of Iberia from the Moors, its medieval Muslim rulers. 
The first dynastic union of León and Castile came about in 1037, when Ferdinand, the 20-year-old Count of Castile, defeated his brother-in-law Bermudo III of León in battle and claimed the Crown of León through the rights of his own wife, Sancha, Bermudo's sister. Although he declared himself Emperor of All Spain in 1056, the union ended with Ferdinand's death in 1065, when Castile, León, and Galicia each passed to a different one of Ferdinand's sons and certain cities to his daughters, with a further division of spheres of influence in the Muslim "taifas". The arrangement did not hold. The sons soon fought; eventually one son, Alfonso VI of León again created an effective union and in 1077 again claimed the title of Emperor of All Spain. However, his death in 1109 left the kingdoms again disunited. 
The medieval Cortes of León is one of the earliest ancestors of Europe's parliaments. The remote origins of the Cortes dates back to the early 12th century. The Cortes of León of 1188 called by Alfonso IX is one of the earliest documented gatherings of the estates in which commoners of the cities and towns are represented beside the clergy and nobility as counselors to the monarch. Alfonso gathered similar assemblies in 1202 in Benavente and 1208 in León. 
In the kingdom of Castile, the first "curia"—a large assembly to address the affairs of the kingdom—appears to have been convoked by Alfonso VIII in 1187 at San Esteban de Gormaz, with the leading men of fifty cities in attendance. In his capacity as king of Castile, Ferdinand III received the homage of large delegations at Valladolid in 1217 and convoked a curia in 1219 at Burgos. 
Valladolid was home to a number of Castilian kings between the 12th and 17th centuries.
Antecedents to the autonomous community.
Spain has alternated between regionalism and centralization several times in the last century and a half. In 1869, the republicans of the present Castile and León plus the provinces of Santander (now Cantabria) and Logroño (now La Rioja) had drafted the Castilian Federal Pact ("Pacto Federal Castellano"), which projected the creation of a federated state under the name "Castilla la Vieja" (Old Castile) in these eleven provinces. During the First Republic (1873–1874), the Republican Democratic Federal Party ("Partido Republicano Democrático Federal") intended to make this a reality. However, the fall of the Republic at the beginning of 1874 put an end to this initiative.
In 1921, on the fourth centenary of the Battle of Villalar, the municipal government of Santander, Cantabria advocated for the establishment of a Castilian commonwealth of these same eleven provinces. In late 1931 and early 1932, the priest Eugenio Merino, in León, wrote a piece for the "Diario de León" stating a basis for Castilian-Leonese regionalism.
During the Second Republic, especially in 1936, there was a great deal of regionalist activity favorable to a region of eleven provinces, including the elaboration of the basis of a statute of autonomy. The "Diario de León" advocated for the formalization of this initiative and the constitution of an autonomous region as follows: "to unite in one personality León and Old Castile around the great basin of the Douro, without falling now into simple village rivalries." The establishment of a centralising regime after the Spanish Civil War brought an end to these aspirations for regional autonomy. 
After the death of the dictator Francisco Franco unleashed the Spanish transition to democracy, there was an upwelling of Castilian-Leonese regionalist, autonomist and nationalist organizations, such as Alianza Regional de Castilla y León (1975), Instituto Regional de Castilla y León (1976) and the Autonomic Nationalist Party of Castile and León (Partido Autonómico Nacionalista de Castilla y León, PANCAL, 1977). None of these survive today, but similar sentiments are now represented by Unidad Regionalista de Castilla y León (1993).
Forming the autonomous community.
Castile and León obtained a "pre-autonomic" regime by the Royal Decree Ley 20/1978, June 13, 1978. This set the region on the course toward establishing an autonomous community, a path that had been offered first to Catalonia toward the end of 1977 and would eventually be granted to every part of Spain. Five years later, in 1983, the autonomous community of Castile and León was made concrete by the Statute of Autonomy accepted by both the community and the Spanish state. 
The Provincial Deputation of León agreed on April 16, 1980 to endorse the Castilian-Leonese process, but then revoked that support January 13, 1983, just as the proposed Organic Law was before the Spanish parliament. The Constitutional Court of Spain upheld the first of these two contradictory Leonese resolutions. The court's decision was met by demonstrations in León and elsewhere in the Leonese territories in favor of a policy of "León solo" ("León alone"). The roughly 90,000 people who gathered in León at that time constituted the largest demonstration in that city between the revival of democracy and the demonstrations after the 2004 Madrid train bombings.
Demography.
The most recent official census by the Instituto Nacional de Estadística, as January 1, 2011, gave a population of 2,558,463 (1,267,671 males and 1,290,792 females) representing 5.42 percent of the population of Spain. As of January 2011 the population of Castile and León, by province, stood as follows: Ávila, 172,704 inhabitants; Burgos, 375,657; León, 497,799; Palencia,171,668; Salamanca, 352,986; Segovia, 164,169; Soria, 95,223; Valladolid, 534,874; and Zamora, 193,383.
Depopulation in the mid-20th century.
Even before the Spanish Civil War (1936–1939), the rural areas (and smaller cities) of present-day Castile and León were losing population due to emigration to Spain's large cities and abroad. This trend accelerated in the decade immediately after the Civil War. The growth of a strong industrial centre in Valladolid, including Spain's first automobile factory—the Renault plant led by the soldier and engineer Manuel Jiménez Alfaro—mitigated, but did not stop, the emigration. In both the 1960s and 1980s, the urban nuclei and provincial capitals gained population, but the region as a whole still suffered a net loss. To this day, the region has an aging population and a low birth rate contrasted against a merely average death rate by national standards. 
Present-day population distribution.
In 1960 only 20.6 percent of the population of present-day Castile and León was urban; by 1991 that percentage had risen to 42.3 percent. The decline in rural population has apparently been somewhat stemmed, with a 1998 statistic showing 43 percent.
Many rural areas became very sparsely populated in the mid-to-late 20th century. In 1986 there were seven times as many municipalities with less than 100 inhabitants as in 1960.
A recent study from University of Porto (Portugal) highlighted Castile and León - particularly the province of Salamanca - as one of the European regions where old people could expect to live longer.
Notable cities include the nine provincial capitals plus Miranda de Ebro and Aranda de Duero in the province of Burgos, Ponferrada and San Andrés del Rabanedo in León, Béjar in Salamanca, and Medina del Campo and Laguna de Duero in Valladolid.
Of the 2,247 municipalities in the autonomous community, the 2000 census shows 1,970 with 1,000 or fewer inhabitants; 234 between 1,001 and 5,000; 20 between 5,001 and 10,000; 10 between 10,001 and 20,000; 6 between 20,001 and 50,000; 3 between 50,001 and 100,000; and 4 with over 100,000 inhabitants. Those last are Valladolid (319,943 in 2007), Burgos (174,075), Salamanca (159,754) and León (135,059). At the other extreme Blasconuño de Matacabras (Ávila) has a population of 18, Reinoso (Burgos) has 24, Villarmentero de Campos (Palencia), has 14, and Gormaz (Soria), 17.
Economy.
Castilla y Leon accounts for 5.2% of Spain's GDP.
Work force.
In 2001 the work force was 1,005,200 with 884,200 employed, meaning 12.1 percent of the work force were out of work. 10.9 percent of the employed population work in agriculture, 20.6 percent in industry, 12.7 percent in construction, and 63.1 percent in the service sector.
In 2007, the unemployment rate was down to 6.99 percent, but the late-2000s recession drove that number up to 14.14 percent by July 2009.
Primary sector (agriculture and livestock).
Castile and León has roughly of arable land, more than half of the region's area. The land is generally dry, but fertile; dryland farming, predominates. Nonetheless, there is increasing irrigation in the basins of the Douro, Pisuerga, and Tormes. About 10 percent of the region's farmland is irrigated, allowing intensive farming in those regions. Flat topography and improved communications have facilitated the entry of technical innovations throughout the agricultural production process, above all in areas such as the provinces of Valladolid and Burgos where production per hectare is among Spain's highest. Castile and León's most fertile lands are in the Esla valley of León, in the countryside of Valladolid and in the Tierra de Campos, which intersects the provinces of Zamora, Valladolid, Palencia, and León. 
The region has nine DO wine zones, which are mostly located around the Duero valley.
Agricultural work force.
Some 92,600 people work in the primary sector in Castile and León, about 10 percent of employment in the region. 2001 data showed 5 percent unemployment in this sector.
Broken down by provinces, approximately 9,400 are employed in this sector in Ávila, 8,100 each in Burgos and Palencia, 18,300 in León, 9,200 in Salamanca, 6,400 in Segovia, 5,600 in Soria, 8,300 in Valladolid, and 14,600 in Zamora. The region's agricultural and farming sector represent 7.6% of the total in Spain.
Secondary sector (industry, mining, energy).
Industry.
As of 2000, industry 18 percent of the work force of Castile and León were engaged in industry, generating 25 percent of regional GDP. The principal industrial centres are the cities of Valladolid (21,054 workers in industry), Burgos (20,217), Aranda de Duero (4,872), León (4,521) and Ponferrada (4,270).
Mining.
Mining has been important in Castile y León since the time of the Roman Empire, when the Roman Via de la Plata (English: "Silver Way", Spanish: "Vía de la Plata") from Asturica Augusta (Astorga) to Emerita Augusta (Mérida) and Hispalis (Seville) was built to transport silver and gold mined from the deposits of las Médulas in El Bierzo. 
Centuries later, after the Spanish Civil War, mining was again a factor in the economic development of the region. However, production of iron, tin, and tungsten declined notably from the 1970s onward. Coal mining (including anthracite coal) continued due to local demand for thermal power generation. Numerous Leonese mines closed in the 1980s and 1990s. Despite investments under the Mining Action Plan of the Junta of Castile and León, coal mining continues to be a troubled industry regionally. 
Energy.
The Douro and Ebro Rivers have numerous hydroelectric plants that make Castile and León one of Spain's leading regions in terms of power generation. 
Installed hydroelectric power total 3,992 megawatts, with an annual product of 5,417 gigawatt hours. Nuclear power generates another 3,483 gigawatts per year. Thermal power from carboniferous fuels remains the region's leading source of energy, contributing 16,956 gigawatt hours for a regional total of 25,856 gigawatt hours from these major facilities. All of the nuclear power comes from the Santa María de Garoña Nuclear Power Plant in the province of Burgos, which is currently (as of 2009) expected to shut down in July 2013. 
Tertiary sector (services).
63.1 percent of the work force of Castile and León is deployed in the service sector. 
Tourism.
Tourism highlights of the region include:
Transportation.
Most major surface routes from northern Spain to the capital, Madrid, and to southern Spain and Portugal, pass through Castile and León. Portugal's most important route to the east also traverses the region. As a result, Castile and León is important in the transportation network.
The major roads are Autovía A-1 (the "Autovía del Norte") which runs from Madrid to the Basque port of Irun on the French border and Autovía A-6, the "Autovía del Noroeste", which runs from Madrid to Arteixo, A Coruña). Also important is Autovía A-62 (the "Autovía de Castilla"), which comes out of Portugal through the cities of Salamanca, Valladolid, Palencia, and Burgos and continues east as part of European route E-80. Along those three routes are such important cities as Medina del Campo, Aranda de Duero, and Miranda de Ebro. 
Air travel.
León Airport, also known as Virgen del Camino, currently handles only domestic traffic, but hopes to handle international traffic in the future. Salamanca Airport, also known as Matacán, handles domestic flights and international charter flights. Burgos Airport, also known as Villafría, opened in July 2008. Madrid's main airport Barajas is nearby as well, although as of 2009 there is no direct connection through public transportation. 
Rail.
Castile and León has an extensive rail network, including the principal lines from Madrid to Cantabria and Galicia. The line from Paris to Lisbon crosses the region, reaching the Portuguese frontier at Fuentes de Oñoro in Salamanca. Astorga, Burgos, León, Miranda de Ebro, Palencia, Ponferrada,Medina del Campo and Valladolid are all important railway junctions.
Railways operate in several different gauges: Iberian gauge (), UIC gauge () and Narrow gauge (). Except for some narrow-gauge lines, trains are operated by RENFE on lines maintained by the Administrador de Infraestructuras Ferroviarias (ADIF); both of these are national, state-owned companies. 
Roads.
Castile and León is the land transport hub of northern Spain. It is crossed by International E-roads E80 and E05. These are the main road connections from Portugal and the south of Spain to the rest of Europe. 
The region is also crossed by two major ancient routes:
The road network is regulated by the Ley de carreteras 10/2008 de Castilla y León (Highway Law 10/2008 of Castile and León). This law allows for the possibility of
roads financed by the private sector through concessions, as well as the public construction of roads that has long prevailed. 
Nature.
Flora and vegetation.
The solitary oaks and junipers now found on the Castilian-Leonese plains are remnants of forests that once covered these lands. Agricultural exploitation—cultivation of cereals and creation of pastures for the vast flocks of the Castilian Meseta—meant the deforestation of these lands during the Middle Ages. The last juniper forests of Castile and León can be found in the provinces of Soria and Burgos. In some of these forest, junipers are mixed with pine—or even with oak or gall oak—but the conifers predominate.
The Castilian-Leonese slope of the Cantabrian Mountains and the northern foothills of the Sistema Ibérico both boast rich vegetation. The cool, moist slopes are populated by large beech forests, which can extend as high as altitudes of . The beeches may form mixed forests with yew, rowan (mountain ash), common hawthorne, holly, and birch. The sunny slopes bring forth sessile oak, English oak, ash, common hawthorne, chestnut, birch, and "pinar de Lillo" ("Pinus silvestris"), a native pine species of northern León.
Wide extensions of oak survive on the lower slopes of the Sistema Central. Higher up, between and altitude, chestnuts are abundant. Nonetheless, many oak forests have disappeared, cut down and replaced by pines. The principal native pine forests are in the Sierra de Guadarrama. The subalpine zones between and are home to shrubs and juniper. 
Much of the province of Salamanca, above all in the comarcas of Salices and Ciudad Rodrigo, is occupied by "dehesas", a type of sparsely wooded land resembling the African savannas, with oak, cork oak, gall oak and Turkish oak. The provinces of Salamanca and Valladolid in the area of Rueda also have olive trees, which do not grow elsewhere in Castile and León.
Fauna.
Castile and León has a great diversity of fauna. Some of these are notable either for being endemic to the region or for their rarity. 418 species of vertebrates have been identified, constituting 63 percent of the vertebrates that can be found in Spain. Animals adapted to the high mountains, inhabitant of rocky landscapes, river dwellers, lowland species, and forest animals all can be found in Castile and León. 
The mountain rivers provide a habitat for nutrias and Pyrenean desmans, not to mention trout, freshwater eels, bighead carp and some increasingly rare native freshwater crabs. Mammals include the otter ("Lutra lutra") and desman ("Galemys pyrenaicus"). In the lower depths of the river are the barbels ("Barbus barbus") and carp. Local amphibians include newts, the Almanzor salamander ("Salamandra salamandra almanzoris", a subspecies of fire salamander) and the Gredos toad ("Bufo bufo gredosicola", a supspecies of common toad); the latter two are endemic to the Sistema Central. 
Among the birds that populate the open Mediterranean forests are two endangered species: the black stork ("Ciconia nigra") and the Spanish imperial eagle (also known as Iberian imperial eagle or Adalbert's eagle, "Aquila adalberti"). 
In the coniferous forests live, among other treecreepers (of the family "Certhiidae"), the coal tit ("Periparus ater"), and the Eurasian nuthatch ("Sitta europaea"). The western capercaillie ("Tetrao urogallus") can also be found. Among the raptors in the forests are the northern goshawk, the Eurasian sparrowhawk and members of the true owl family, which frequently prey upon such smaller birds as Eurasian jays, woodpeckers (notably the great spotted woodpecker, "Dendrocopos major"), finches of the genus "Fringilla", and warblers of the genus "Sylvia". 
The great bustard ("Otis tarda") frequents the plains cleared for dryland farming. In the winter, the Castilian-Leonese wetlands teem with greylag geese ("Anser anser"), that have flown south from their breeding grounds in Northern Europe. 
After many centuries disappeared from the Iberian Peninsula, the European bison is being reintroduced in Castile and Leon.

</doc>
<doc id="70261" url="https://en.wikipedia.org/wiki?curid=70261" title="Safeword">
Safeword

A safeword is a code word or series of code words that are sometimes used in BDSM for a submissive or bottom to unambiguously communicate their physical or emotional state to a dominant or top, typically when approaching, or crossing, a physical, emotional, or moral boundary. Some safewords are used to "stop" the scene outright, while others can communicate a willingness to continue, but at a reduced level of intensity. Safewords are usually agreed upon before playing a scene by all participants, and many organized BDSM groups have standard safewords that all members agree to use to avoid confusion at organized play events.
Safewords of BDSM falls under the guiding philosophy of safe, sane and consensual. Those who practice the more permissive philosophy of risk-aware consensual kink may abandon the use of safewords, especially those that practice forms of edgeplay or extreme forms of dominance and submission. In such cases, the choice to give up the use of safewords is a consensual act on the part of the bottom or submissive.
Usage.
A safeword is usually used by the submissive, but can be used by all participants in a scene, including tops, dungeon masters at play parties, and sometimes even observers. For example, a submissive may misbehave intentionally to indicate the desire for harsher treatment, and sometimes a top will need to safeword the scene to let them know it has gone too far for the top to continue the scene. Or, a third party observing a scene may have the ability to spot something dangerous going on that both the top and submissive have missed, and need to stop the scene to point it out.
Forms of safewords.
A safeword makes it possible for a submissive to say "No" or "Stop" and pretend as much as he or she wants without really meaning it while still having a safe way of indicating they seriously need the scene to stop. In theory a safeword is usually a word that the person would not ordinarily say during sex, such as "pineapple", "velociraptor", or "teacup". With the range of safewords in common use it is important that the safeword be negotiated beforehand.
Since a scene may become too intense for a submissive partner to remember what the safeword is, in practice commonly the words "safeword" or "red" are also used as safewords. They are often the default at many play parties, or respected as a safeword in addition to any negotiated safeword. A dungeon monitor would likely expect either of those words to be respected.
Some partners may also have different gradations of safewords, such as "green" to mean "Okay" or even "harder" or "more", "yellow" to mean "slow down" or "stop doing that" without stopping the scene, and "red" to mean "stop the scene". In this fashion, a dominant partner may ask the submissive partner "What is your color?" to check with a submissive partner without having to stop the scene.
In other circumstances the safeword may not be a "word" at all, which is very useful when the submissive is bound and gagged. In these instances a signal such as dropping a bell or a ball, the snapping of fingers, or opening and closing both hands repeatedly or making three clear and rhythmic grunts as a pre-defined signal to stop or otherwise slow down the scene. There is also a convention of tops to put a finger in the "submissive's" hand as a sort of "check in" when the "submissive" has become non-verbal, such as may happen as they reach subspace. In this scenario the "submissive" squeezes the "top's" finger to indicate OK.
Effects of use.
A "red" safeword is only used when one of the partners needs it to end a scene. Many submissive partners may see the use of a safeword as being weak, and will push themselves past their "comfort" zone to please their partner. This may allow a submissive partner to expand their boundaries and learn what they are capable of but may also expose them to risk if they are pushed too far. Additionally, many dominant partners may interpret the use of a safeword as a failure on their part, i.e., failing to understand body language, to know their partner, or loss of control. This is also why gradations of safewords and/or actions that signify a scene may be becoming too much are commonly used (i.e.,"Yellow") so that the partners can safely adjust the scene before crossing boundaries.
It is considered important in many parts of the BDSM community that the use of safewords should remain "no-fault" so that participants feel encouraged to use it if necessary. Discouraging the use of safewords runs the risk of scenes becoming non-consensual, harming trust between partners and potentially damaging to their mental and emotional state.
A top will often sensibly make clear beforehand that they will not agree to a scene if they do not believe the submissive will use the safeword as soon as they need to, and the submissive will not delay using the safeword and endure more than they really want to, simply to avoid disappointing the top, since the top will be far more upset if they unwittingly inflict psychological trauma. In addition, intentionally "disregarding" the activation of a safeword is considered a serious ethical violation.
While many in the BDSM community consider safewords to be an essential part of safe play, there is a contingent that chooses to occasionally play without using safewords. They rely on the dominant partner to monitor the condition of the submissive partner and stop if necessary, at their discretion. In such circumstances the "submissive" or submissive must have consented "not" to have control over the duration of the scene in advance; this is often referred to as "consensual nonconsent". Also, some people who routinely play with each other may agree to stop using safe words because they know each other's boundaries and are able to read each other's body language well. In any case "consensual nonconsent" is risky and advanced activity.
"Consensual nonconsent" may also occur if the top and the submissive are reenacting a punishment scene (e.g. a shipboard flogging) in which the offender, played by the submissive, is sentenced to receive a certain number of lashes as punishment. Since the offender would not be able to use a safeword in such circumstances, the parties reenacting the scene agree that it would be "out of character" for them to do so.

</doc>
<doc id="70277" url="https://en.wikipedia.org/wiki?curid=70277" title="Pillow lava">
Pillow lava

Pillow lavas are lavas that contain characteristic pillow-shaped structures that are attributed to the extrusion of the lava under water, or "subaqueous extrusion". Pillow lavas in volcanic rock are characterized by thick sequences of discontinuous pillow-shaped masses, commonly up to one metre in diameter. They form the upper part of 'Layer 2' of normal oceanic crust.
Composition.
Pillow lavas are commonly of basaltic composition, although pillows formed of komatiite, picrite, boninite, basaltic andesite, andesite or even dacite are known. In general the more intermediate the composition, the larger the pillows, due to the increase in viscosity of the erupting lava.
Occurrence.
They occur wherever mafic to intermediate lavas are extruded under water, such as along marine hotspot volcano chains and the constructive plate boundaries of mid-ocean ridges. As new oceanic crust is formed, thick sequences of pillow lavas are erupted at the spreading center fed by dykes from the underlying magma chamber. Pillow lavas and the related sheeted dyke complexes form part of a classic ophiolite sequence when a segment of oceanic crust is obducted onto continental crust.
The presence of pillow lavas in the oldest preserved volcanic sequences on the planet, the Isua and Barberton greenstone belts, confirms the presence of large bodies of water on the Earth's surface early in the Archean. Pillow lavas are used generally to confirm subaqueous volcanism in metamorphic belts.
Pillow lavas are also found associated with some subglacial volcanoes at an early stage of an eruption.
Formation.
They are created when magma reaches the surface but, as there is a large difference in temperature between the lava and the water, the surface of the emergent tongue cools very quickly, forming a skin. The tongue continues to lengthen and inflate with more lava, forming a lobe, until the pressure of the magma becomes sufficient to rupture the skin and start the formation of a new eruption point nearer the vent. This process produces a series of interconnecting lobate shapes that are pillow-like in cross-section. The skin cools a lot faster than the inside of the pillow, so it is very fine grained, with a glassy texture. The magma inside the pillow cools more slowly, so is slightly coarser grained than the skin, but still classified as fine grained.
Use as a 'Way-up' criterion.
Pillow lavas are used as way-up criterion in geology. There are three key ideas that can be used as part of this, and that a pillow lava will show if it is the correct way-up:

</doc>
<doc id="70284" url="https://en.wikipedia.org/wiki?curid=70284" title="HHG">
HHG

HHG may refer to: 

</doc>
<doc id="70289" url="https://en.wikipedia.org/wiki?curid=70289" title="Trachea">
Trachea

The trachea, colloquially called the windpipe, is a tube that connects the pharynx and larynx to the lungs, allowing the passage of air, and so is present in almost all air-breathing animals with lungs. Only in the lungfish, where the lung is connected to the pharynx and the larynx, is it absent. The trachea extends from the larynx and branches into the two primary bronchi. At the top of the trachea the cricoid cartilage attaches it to the larynx. This is the only complete ring, the others being incomplete rings of reinforcing cartilage. The trachealis muscle joins the ends of the rings and these are joined vertically by bands of fibrous connective tissue, the "annular ligaments of trachea". The epiglottis closes the opening to the larynx during swallowing.
The trachea develops in the second month of development. It is lined with an epithelium that has goblet cells which produce protective mucins. An inflammatory condition, also involving the larynx and bronchi, called croup can result in a barking cough. A tracheotomy is often performed for ventilation in surgical operations where needed. Intubation is also carried out for the same reason by the inserting of a tube into the trachea. From 2008, operations have transplanted a windpipe grown by stem cells, and synthetic windpipes; their success is however doubtful.
Structure.
[[File:Relations of the aorta, trachea, esophagus and other heart structures.png|thumb|240px|In humans, the trachea passes ventrally to the esophagus, dorsally to the ascending aortic arch, but the 
left main bronchus from the trachea, passes ventrally to the descending aortic arch.]]
The human trachea has an inner diameter of about and a length of about . It commences at the lower border of the larynx, level with the sixth cervical vertebra. Inside the trachea at the level of the fifth thoracic vertebra (T5) there is a cartilaginous ridge known as the carina of trachea which runs across from the front to the back of the trachea and marks the point of bifurcation into the right and left primary bronchi. The carina is opposite the sternal angle and can be positioned up to two vertebrae lower or higher, depending on breathing.
A ring of hyaline cartilage called the cricoid cartilage forms the inferior wall of the larynx and is attached to the top of the trachea. The cricoid cartilage is the only complete ring of cartilage in the trachea. Below this there are from fifteen to twenty incomplete C-shaped tracheal rings or tracheal cartilages, also of hyaline, that reinforce the front and sides of the trachea to protect and maintain the airway. This leaves a membranous wall at the back, (about a third of the ring's diameter) without cartilage. The cartilages (around 4 mm deep and 1 mm thick) are placed horizontally above each other, separated by narrow intervals. The outer surfaces are directed vertically and the inner surfaces are convex due to the cartilages being thicker in the middle than at the margins.The first tracheal ring is broader than the rest, and often divided at one end; it is connected by the cricotracheal ligament with the lower border of the cricoid cartilage, and is sometimes blended with the next cartilage down. The last cartilage is thick and broad in the middle, due to its lower border being prolonged into a triangular hook-shaped (uncinate) process, which curves downward and backward between the two bronchi. It ends on each side in an imperfect ring, which encloses the commencement of the bronchus. The cartilage above the last is somewhat broader than the others at its center.
Two or more of the cartilages often unite, partially or completely, and they are sometimes bifurcated at their extremities. The rings are generally highly elastic but they may calcify with age. 
The trachealis muscle connects the ends of the incomplete rings and contracts during coughing, reducing the size of the lumen of the trachea to increase the rate of air flow. The esophagus lies posteriorly to the trachea, adjoining along the tracheoesophageal stripe. Circular horizontal bands of fibrous tissue called the annular ligaments of trachea join the tracheal rings together. The cartilaginous rings are incomplete to allow the trachea to collapse slightly so that food can pass down the esophagus. A flap-like epiglottis closes the opening to the larynx during swallowing to prevent swallowed matter from entering the trachea.
Development.
In the fourth week of embryogenesis as the respiratory bud grows, the trachea separates from the foregut through the formation of tracheoesophageal ridges which fuse to form the tracheoesophageal septum and this separates the future trachea from the oesophagus and divides the foregut tube into the laryngotracheal tube. Before the end of the fifth week, the trachea begins to develop from the laryngotracheal tube which develops from the laryngotracheal groove. The first part of the cephalic region of the tube forms the larynx, and the next part forms the trachea.
Histology.
The trachea is lined with a layer of pseudostratified columnar epithelium, a type of epithelium. The epithelium contains goblet cells, which are glandular, modified simple columnar epithelial cells that produce mucins, the main component of mucus. Mucus helps to moisten and protect the airways. Mucus lines the ciliated cells of the trachea to trap inhaled foreign particles that the cilia then waft upward toward the larynx and then the pharynx where it can be either swallowed into the stomach or expelled as phlegm. This self-clearing mechanism is termed mucociliary clearance.
Clinical significance.
Inflammation.
Inflammation of the trachea is known as tracheitis. When the trachea is inflamed as well as the larynx and bronchi, this is known as croup, which often causes a distinct, barking cough.
Intubation.
Tracheal intubation refers to the insertion of a tracheal tube down the trachea. This procedure is commonly performed during surgery, in order to ensure a person receives enough oxygen when sedated. The tube inserted down the trachea is connected to a machine that monitors the airflow, oxygenation and several other metrics. This is often one of the responsibilities of an anesthetist during surgery.
In an emergency, or when tracheal intubation is deemed impossible, a tracheotomy is often performed to insert a tube for ventilation, usually when needed for particular types of surgery to be carried out so that the airway is kept open for sufficient time. Another less invasive method is used when a procedure can be carried out more quickly, or in an emergency situation, and this is a cricothyrotomy.
Congenital disorders.
Tracheal agenesis, is a rare birth defect in which the trachea fails to develop. The defect is usually fatal though sometimes surgical intervention has been successful.
A tracheoesophageal fistula is a congenital defect in which the trachea and esophagus are abnormally connected.
Sometimes as an anatomical variation one or more of the tracheal rings are completely formed. These "O" rings are smaller than the normal C-shaped and can cause narrowing of the trachea resulting in breathing difficulties. An operation called a "slide tracheoplasty" can be performed which opens up the rings and rejoins them as wider rings shortening the length of the trachea. Slide tracheoplasty is said to be the best option in treating tracheal stenosis.
Mounier-Kuhn syndrome is a very rare congenital disorder of an abnormally enlarged trachea.
Other animals.
Allowing for variations in the length of the neck, the trachea in other mammals is, in general, similar to that in humans. Generally, it is also similar to the reptilian trachea.
Vertebrates.
In birds, the trachea runs from the pharynx to the syrinx, from which the primary bronchi diverge. Swans have an unusually elongated trachea, part of which is coiled beneath the sternum; this may act as a resonator to amplify sound. In some birds, the tracheal rings are complete, and may even be ossified.
In amphibians, the trachea is normally extremely short, and leads directly into the lungs, without clear primary bronchi. A longer trachea is, however, found in some long-necked salamanders, and in caecilians. While there are irregular cartilagenous nodules on the amphibian trachea, these do not form the rings found in amniotes.
The only vertebrate to have lungs, but no trachea, is "Polypterus", in which the lungs arise directly from the pharynx.
Invertebrates.
The invertebrate trachea refers to the open respiratory system composed of spiracles, tracheae, and tracheoles that terrestrial arthropods have to transport metabolic gases to and from tissues. The distribution of spiracles can vary greatly among the many orders of insects, but in general each segment of the body can have only one pair of spiracles, each of which connects to an atrium and has a relatively large tracheal tube behind it. The tracheae are invaginations of the cuticular exoskeleton that branch (anastomose) throughout the body with diameters from only a few micrometres up to 0.8 mm. The smallest tubes, tracheoles, penetrate cells and serve as sites of diffusion for water, oxygen, and carbon dioxide. Gas may be conducted through the respiratory system by means of active ventilation or passive diffusion. Unlike vertebrates, insects do not generally carry oxygen in their haemolymph.
This is one of the factors that may limit their size.
A tracheal tube may contain ridge-like circumferential rings of taenidia in various geometries such as loops or helices. In the head, thorax, or abdomen, tracheae may also be connected to air sacs. Many insects, such as grasshoppers and bees, which actively pump the air sacs in their abdomen, are able to control the flow of air through their body. In some aquatic insects, the tracheae exchange gas through the body wall directly, in the form of a gill, or function essentially as normal, via a plastron. Note that despite being internal, the tracheae of arthropods are shed during moulting (ecdysis).
Artificial trachea.
In 2008, a Colombian woman, Claudia Castillo (30), received a trachea transplant using her own stem cells so her body would not reject the transplant. In June 2011, a team of surgeons led by Professor Paolo Macchiarini at the Karolinska University Hospital performed the first synthetic windpipe transplant on a 36-year-old Eritrean man, Andemariam Teklesenbet Beyene. The second and the subsequent transplanted patients passed away from complications within several months to two years after the surgery. 
References.
Ligaments

</doc>
<doc id="70290" url="https://en.wikipedia.org/wiki?curid=70290" title="Jewish Autonomous Oblast">
Jewish Autonomous Oblast

The Jewish Autonomous Oblast (, "Yevreyskaya avtonomnaya oblast"; , "yidishe avtonome gegnt") is a federal subject of Russia (an autonomous oblast) in the Russian Far East, bordering Khabarovsk Krai and Amur Oblast in Russia and Heilongjiang province in China. It is also referred to as "Yevrey" (Yiddish: יעװרײ) and "Birobidzhan" (Yiddish: ביראָבידזשאַן). Its administrative center is the town of Birobidzhan. As of the 2010 Census, its population was 176,558, although Jews nowadays make barely 0.2% of the JAO's population. The JAO is Russia's only autonomous oblast and, aside from Israel, the world's only Jewish territory with an official status.
Soviet authorities established the autonomous oblast in 1934. It was the result of Soviet nationality policy under Stalin, which provided the Jewish population of the Soviet Union with a territory in which to pursue Yiddish cultural heritage. According to the 1939 population census, 17,695 Jews lived in the region (16% of the total population). The Jewish population peaked in 1948 at around 30,000, about one-quarter of the region's population.
In 1953, Joseph Stalin died and thereafter the Jewish population in the JAO began a long decline. The census of 1959 found that the Jewish population of the JAO had declined by approximately 50%, down to 14,269 persons. In 2002, there were 2,327 people of Jewish descent living in the JAO (1.2% of the total population), while ethnic Russians made up 90% of the JAO population. By 2010, according to data provided by the Russian Census Bureau, there were only 1,628 people of Jewish descent remaining in the JAO (1% of the total population), while ethnic Russians made up 92.7% of the JAO population. By 2010, according to data provided by the Russian Census Bureau, 97 persons spoke Yiddish, 312 persons spoke Hebrew, and a further 54 persons spoke unspecified Jewish languages.
A 2007 article in the Jerusalem Post claimed that, at the time, approximately 4,000 Jews remain in the JAO. According to Mordechai Scheiner, the Chief Rabbi of the JAO from 2002 to 2011, Judaism and the Jewish culture in the oblast have recently begun enjoying a religious and cultural resurgence. However, according to the magazine of the Federation of Jewish Communities of the CIS "Lechaim", currently the Jewish presence in the Jewish Autonomous Oblast is extremely small, and is limited to the city of Birobidzhan and the nearby village of Valdgeym.
Geography.
Climate.
The territory has a monsoonal/anti-cyclonic climate, with warm, wet, humid summers due to the influence of the East Asian monsoon; and cold, dry, windy conditions prevailing in the winter months courtesy of the Siberian high-pressure system.
History.
Military colonization and the advent of the Trans-Siberian Railway.
The northern bank of the Amur, including the territory of today's Jewish Autonomous Oblast, became incorporated into the Russian Empire pursuant to the treaties of Aigun and Peking of 1858-1860 (see Amur Annexation).
In December 1858 the Russian government authorized formation of the Amur Cossacks to protect the southeast boundary of Siberia and communications on the Amur and Ussuri rivers. This military colonization included settlers from Transbaikalia. During the years 1858–82, sixty three settlements were founded, including, in 1857, Radde settlement; in 1858, Pashkovo, Pompeyevka, Puzino, Yekaterino-Nikolskoye, Mikhailo-Semyonovskoye, Voskresenovka, Petrovskoye, and Ventzelevo; in 1860, Storozhevoye, Soyuznoye, and Golovino; later in the decade, Babstovo, Bidzhan, and Bashurovo settlements. Expeditions of scientists — including such geographers, ethnographers, naturalists, and botanists as Venyukov, Schrenck, Maximovich, Radde, and Komarov - promoted the development of the new territories. Their achievements produced the first detailed "map of the Amur land".
Construction began in 1898 on the Trans-Siberian Railway connecting Chita and Vladivostok, starting at each end and meeting halfway. The project produced a large influx of new settlers and the foundation of new settlements. In 1908 Volochayevka, Obluchye, and Bira, Russia stations appeared; in 1910, Birakan, Londoko, and In stations; in 1912, Tikhonkaya station. The railway construction finished in October 1916 with the opening of the Khabarovsk Bridge across the Amur at Khabarovsk. In the pre-revolutionary period most local inhabitants were farmers. The only industrial enterprise was the Tungussky timber mill, although gold was mined in the Sutara River, and there were some small railway workshops. During the civil war, the territory of the future Jewish Autonomous Oblast was the scene of terrible battles. The economy declined, though it was recovering in 1926 and 1927.
Jewish settlement and development in the region.
Originally the plan was to settle the Jews in the Ukraine and the Crimea, but local opposition made the governmental committees look elsewhere. Finally Birobidzhan was chosen. Two Jewish districts ("raiony") were formed in the Crimea and three in south Ukraine.
On March 28, 1928, the Presidium of the General Executive Committee of the USSR passed the decree "On the attaching for Komzet of free territory near the Amur River in the Far East for settlement of the working Jews." The decree meant "a possibility of establishment of a Jewish administrative territorial unit on the territory of the called region". In the future, based on JAO was supposed to create a Jewish republic (as a place of compact residence of the Jews of the USSR), but this plan was never implemented.
On August 20, 1930 the General Executive Committee of RSFSR accepted the decree "On formation of the Birobidzhan national region in the structure of the Far Eastern Territory". The State Planning Committee considered the Birobidzhan national region as a separate economic unit. In 1932 the first scheduled figures of the region development were considered and authorized. The Organization for Jewish Colonisation in the Soviet Union, a Jewish Communist organization in North America, successfully encouraged the immigration of some US residents, such as the family of George Koval, which arrived in 1932. Some 1,200 non-Soviet Jews chose to settle in Birobidzhan.
On May 7, 1934, the Presidium of the General Executive Committee accepted the decree on its transformation into the Jewish Autonomous Region within the Russian Federation. In 1938, with formation of the Khabarovsk Territory, the Jewish Autonomous Region (JAR) was included in its structure.
According to Joseph Stalin's national policy, each of the national groups that formed the Soviet Union would receive a territory in which to pursue cultural autonomy in a socialist framework. In that sense, it also responded to two supposed threats to the Soviet state:
The Soviets envisaged setting up a new "Soviet Zion", where a proletarian Jewish culture could be developed. Yiddish, rather than Hebrew, would be the national language, and literature and the arts would replace religion as the primary expression of culture.
Stalin's theory on the National Question regarded a group as a nation only if it had a territory, and since there was no Jewish territory, per se, the Jews were not a nation and did not have national rights. Jewish Communists argued that the way to solve this ideological dilemma was by creating a Jewish territory, hence the ideological motivation for the Jewish Autonomous Oblast. Politically, it was also considered desirable to create a Soviet Jewish homeland as an ideological alternative to Zionism and the theory put forward by Socialist Zionists such as Ber Borochov that the Jewish Question could be resolved by creating a Jewish territory in Palestine. Thus Birobidzhan was important for propaganda purposes as an argument against Zionism which was a rival ideology to Marxism among left-wing Jews.
Another important goal of the Birobidzhan project was to increase settlement in the remote Soviet Far East, especially along the vulnerable border with China. The region was often infiltrated by the Chinese; in 1927, Shiang-Kai-Shek had ended cooperation with the Chinese Communist Party, which further increased the threat. Japan also seemed willing and ready to detach the Far Eastern provinces from the USSR. In the mid-1920s, there were only about 30,000 inhabitants, mostly descendants of Trans-Baikal Cossacks planted there by tsarist authorities, Koreans, Kazakhs, and a primitive tribe called the Tungus. Birobidzhan had a harsh geography and climate: it was mountainous, covered with virgin forests of oak, pine and cedar, and also swamplands, and any new settlers would have to build their lives from scratch. To make colonization more enticing, the Soviet government allowed private land-ownership. This led to many non-Jews settling in the oblast to get a free farm.
By the 1930s, a massive propaganda campaign developed to induce more Jewish settlers to move there. The campaign partly incorporated the standard Soviet propaganda tools of the era and included posters and Yiddish-language novels describing a socialist utopia there. In one instance, leaflets promoting Birobidzhan were dropped from an airplane over a Jewish neighborhood in Belarus. In another instance, a government-produced Yiddish film called "Seekers of Happiness" told the story of a Jewish family that fled the Great Depression in the United States to make a new life for itself in Birobidzhan.
As the Jewish population grew, so did the impact of Yiddish culture on the region. Settlers established a Yiddish newspaper, the "Birobidzhaner Shtern"; a theater troupe was created; and streets being built in the new city were named after prominent Yiddish authors such as Sholom Aleichem and Y. L. Peretz. The Yiddish language was deliberately bolstered as a basis for efforts to secularize the Jewish population and, despite the general curtailment of this action as described immediately below, the "Birobidzhaner Shtern" continues to publish a section in Yiddish.
Valdgeym, a Jewish settlement within the Jewish Autonomous Oblast, dates from 1928 and formed the first collective farm established in the oblast. In 1980 a Yiddish school was opened in the settlement. Amurzet also has a history of Jewish settlement in the JAO. For the period 1929 through 1939, this village was the center of Jewish settlement south of Birobidzhan. The present day Jewish community members hold Kabalat Shabbat ceremonies and gatherings that feature songs in Yiddish, Jewish cuisine, and broad information presenting historical facts on Jewish culture. Many descendants of the founders of this settlement, which was established just after the turn of the 20th century, have left their native village. Those who remained in Amurzet, especially those having relatives in Israel, are learning about the traditions and roots of the Jewish people. The population of Amurzet, as estimated in late 2006, is 5,213.
Smidovich is another early Jewish settlement in the JAO.
World War II era (1930s and 1940s).
The Jewish population of JAO reached a pre-war peak of 20,000 in 1937. The Birobidzhan experiment ground to a halt in the mid-1930s, during Stalin's first campaign of purges. Soviet authorities arrested and executed Jewish leaders, and Yiddish schools were shut down. Shortly after this, World War II brought an abrupt end to concerted efforts to bring Jews east.
After the war ended in 1945, there was renewed interest in the idea of Birobidzhan as a potential home for Jewish refugees. The Jewish population peaked in 1948 at around 30,000, about one-quarter of the region's population. Stalin's anti-Jewish purges that same year essentially criminalized Jewish activities.
Events since 1991.
In 1991, the Jewish Autonomous Oblast moved from the jurisdiction of Khabarovsk Krai to the jurisdiction of the Federation; however, by that time, most of the Jews had emigrated from the Soviet Union and the remaining Jews now constituted fewer than two percent of the local population. Nevertheless, Yiddish is once again taught in the schools, a Yiddish radio station is in operation, and the "Birobidzhaner Shtern" includes a section in Yiddish.
"L'Chayim, Comrade Stalin!", a documentary on Stalin's creation of the Jewish Autonomous Region and its settlement, was released by The Cinema Guild in 2002. In addition to being a history of the creation of the Jewish Autonomous Oblast, the film features scenes of contemporary Birobidzhan and interviews with Jewish residents.
There is a proposal to merge JAO with Khabarovsk Krai. Another suggestion was to merge it with Amur Oblast to form the Amur region. The proposals caused many objections from amongst local JAO groups and residents, and also protests in the Jewish community of Russia. The presidential envoy to the Far Eastern Federal District Viktor Ishayev advocated merging JAO into Khabarovsk Krai, but believed the merger is currently premature. Some have projected that the JAO may soon become the wealthiest oblast in the region. Amongst the citizens of the JAO, there is nearly uniform opposition to such a merger, yet neighboring oblasts more generally support the prospect of such a merger.
Economy.
The Jewish Autonomous Oblast is part of the Far Eastern Economic Region; it has well-developed industry and agriculture and a dense transportation network. Its status as a free economic zone increases the opportunities for economic development. The oblast's rich mineral and building and finishing material resources are in great demand on the Russian market. Nonferrous metallurgy, engineering, metalworking, and the building material, forest, woodworking, light, and food industries are the most highly developed industrial sectors.
Agriculture is the Jewish Autonomous Oblast's main economic sector owing to fertile soils and a moist climate.
Transportation.
The region's well-developed transportation network consists of 530 km of railways, including the Trans-Siberian Railway; 600 km of waterways along the Amur and Tunguska rivers; and 1900 km of roads, including 1600 km of paved roads. The most important road is the Khabarovsk-Birobidzhan-Obluchye-Amur Region highway with ferry service across the Amur. The Zhelty Yar airport located in the center of the region connects Birobidzhan with Khabarovsk and outlying district centers. There are also plans to establish international air service between Birobidzhan and Jiamusi in China.
Amur Bridge Project.
In 2007, Russian mining interests, in consortium with the Chinese government, announced the possibility of the construction of a rail-bridge link between the two countries across the Amur River at Nizhneleninskoye. In the years since the initial proposal for the bridge, various proposed construction start dates have been first announced, and then postponed/ discarded. The bridge would link Nizhneleninskoye in the Jewish Autonomous Oblast with Tongjiang in Heilongjiang Province. The 2,197-meter-long bridge would require an estimated investment of nearly US$230 million, Gurevich said. As of 2013, construction on the project had not yet begun.
Demographics.
Population: 
The 2010 Census reported the largest group to be the 160,185 ethnic Russians (92.7%), followed by 4,871 ethnic Ukrainians (2.8%), and 1,628 ethnic Jews (1%). Additionally, 3,832 people were registered from administrative databases, and could not declare an ethnicity. It is estimated that the proportion of ethnicities in this group is the same as that of the declared group.
Total fertility rate: 
2009 - 1.67 | 2010 - 1.67 | 2011 - 1.79 | 2012 - 1.84 | 2013 - 1.86 | 2014 - 1.95 | 2015 - 1.98(e)
Religion.
According to a 2012 official survey 22.6% of the population of the Jewish Autonomous Oblast adhere to Russian Orthodoxy, 6% are Orthodox Christians of other church jurisdictions or Orthodox believers who aren't members of any church, and 9% are unaffiliated or generic Christians. Judaism is practiced by 0.2% of the population. In addition, 35% of the population identify as "spiritual but not religious", 22% profess atheism, and 5.2% follow other religions or declined to answer the question.
Education.
The Birobidzhan Jewish National University works in cooperation with the local Jewish community of Birobidzhan. The university, uniquely in the Russian Far East and the Far East as a whole, uses as the basis of its teaching the study of the Hebrew language, history and classic Jewish texts.
In recent years, the Jewish Autonomous Oblast has grown interested in its Jewish roots. Students study Hebrew and Yiddish at a Jewish school and at the Birobidzhan Jewish National University. In 1989, the Jewish center founded its Sunday school, where children study Yiddish, learn Jewish folk dances, and memorize dates from the history of Israel. The Israeli government helps fund the program.
Birobidzhan has several state-run schools that teach Yiddish, a Yiddish school for religious instruction and a kindergarten. The five- to seven-year-olds spend two lessons a week learning to speak Yiddish, as well as being taught Jewish songs, dance, and traditions. Today, the city’s fourteen public schools must teach Yiddish and Jewish tradition. The school Menora was created in 1991. It is a public school that offers a half-day Yiddish and Jewish curriculum for those parents who choose it. About half the school’s 120 pupils are enrolled in the Yiddish course. Many of them continue on to Public School No. 2, which offers the same half-day Yiddish/Jewish curriculum from first through twelfth grades. Yiddish also is offered at Birobidzhan’s Pedagogical Institute, one of the few university-level Yiddish courses in the country.
In 2007 Yiddish studies professor Boris Kotlerman of Bar-Ilan University launched "the First Birobidzhan International Summer Program for Yiddish Language and Culture".

</doc>
<doc id="70291" url="https://en.wikipedia.org/wiki?curid=70291" title="Birobidzhan">
Birobidzhan

Birobidzhan (; ) is a town and the administrative center of the Jewish Autonomous Oblast, Russia, located on the Trans-Siberian Railway, close to the border with China. Population: 
Name and geography.
The town is named after the two largest rivers in the autonomous oblast: the Bira and the Bidzhan, although only the Bira flows through the town, which lies to the east of the Bidzhan Valley. Both rivers are tributaries of the Amur.
History.
Planned by the Swiss architect Hannes Meyer, it was established in 1931 and became the administrative center of the Jewish Autonomous Oblast in 1934; town status was granted to it in 1937.
Administrative and municipal status.
Birobidzhan is the administrative center of the autonomous oblast and, within the framework of administrative divisions, it also serves as the administrative center of Birobidzhansky District, even though it is not a part of it. As an administrative division, it is incorporated separately as the town of oblast significance of Birobidzhan—an administrative unit with the status equal to that of the districts. As a municipal division, the town of oblast significance of Birobidzhan is incorporated as Birobidzhan Urban Okrug.
Economy.
The chief economic activity is light industry.
Jewish and Yiddish culture.
According to Rabbi Mordechai Scheiner, the former Chief Rabbi of Birobidzhan and Chabad Lubavitch representative to the region, "Today one can enjoy the benefits of the Yiddish culture and not be afraid to return to their Jewish traditions. It's safe without any anti-Semitism, and we plan to open the first Jewish day school here." Mordechai Scheiner, an Israeli father of six, was the rabbi in Birobidzhan. He also hosted the Russian television show, "Yiddishkeit". His student, actually born in Birobidzhan, Rabbi Eliyahu Reiss, has taken over the reins since 2010.
The town's synagogue opened in 2004. Rabbi Scheiner says there are 4,000 Jews in Birobidzhan, just over 5 percent of the town's population of 75,000. The Birobidzhan Jewish community was led by Lev Toitman, until his death in September, 2007.
Jewish culture was revived in Birobidzhan much earlier than elsewhere in the Soviet Union. Yiddish theaters opened in the 1970s. Yiddish and Jewish traditions have been required components in all public schools for almost fifteen years, taught not as Jewish exotica but as part of the region's national heritage. Concerning the Jewish community of the oblast, Governor Nikolay Mikhaylovich Volkov has stated that he intends to "support every valuable initiative maintained by our local Jewish organizations.". In 2007, The First Birobidzhan International Summer Program for Yiddish Language and Culture was launched by Yiddish studies professor Boris Kotlerman of Bar-Ilan University. The town's main street is named after the Yiddish language author and humorist Sholom Aleichem.
For the Chanukah celebration of 2007, officials of Birobidzhan in the Jewish Autonomous Oblast claimed to have built the world's largest Menorah.
Education.
The Birobidzhan Jewish National University works in cooperation with the local religious community. The university is unique in the Russian Far East. The basis of the training course is study of the Hebrew language, history and classic Jewish texts. The town now boasts several state-run schools that teach Yiddish, as well as an Anglo-Yiddish faculty at its higher education college, a Yiddish school for religious instruction and a kindergarten. The five- to seven-year-olds spend two lessons a week learning to speak Yiddish, as well as being taught Jewish songs, dance and traditions. The school menorah was created in 1991. It is a public school that offers a half-day Yiddish and Jewish curriculum for those parents who choose it. About half the school’s 120 pupils are enrolled in the Yiddish course. Many of them continue on to Public School No. 2, which offers the same half-day Yiddish/Jewish curriculum from first through 12th grade. Yiddish is also offered at Birobidzhan’s Pedagogical Institute, one of the only university-level Yiddish courses in the country.
Today, the town's fourteen public schools must teach Yiddish and Jewish tradition.
Climate.
Birobidzhan experiences a monsoonal humid continental climate (Köppen climate classification "Dwb") with very cold, dry winters and warm, very wet summers.
Sports.
The bandy club Nadezhda plays in the 2nd highest division, the Russian Bandy Supreme League. There are talks about building an indoor arena.
"L'Chayim, Comrade Stalin!".
A documentary film, "L'Chayim, Comrade Stalin!" on Stalin's creation of the Jewish Autonomous Oblast and its partial settlement by thousands of Russian and Yiddish-speaking Jews was released in 2003. As well as relating the history of the creation of the proposed Jewish homeland, the film features scenes of life in contemporary Birobidzhan and interviews with Jewish residents.
According to "The New York Times", Stalin promoted the town as a home for secular Jews.
Twin towns and sister cities.
Birobidzhan is twinned with:

</doc>
<doc id="70292" url="https://en.wikipedia.org/wiki?curid=70292" title="Texas League">
Texas League

The Texas League is a minor league baseball league which operates in the South Central United States. It is classified as a Double-A league. The league was founded in 1888 and ran through 1892. It was called the Texas Association in 1895, the Texas-Southern League in 1896 and again as the Texas League from 1897–1899. It was revived as a class D league in 1902, moved to class C in 1904 where it played through 1910 (except for 1906 as class D again), played at class B until 1920, and finally moved up to class A in 1921. The Texas League, like many others, shut down during World War II. From 1959 to 1961, the Texas League and the Mexican League formed the Pan American Association. The two leagues played a limited interlocking schedule and post-season championship. By 1971, the Texas League and the Southern League had both decreased to seven teams. They played an interlocking schedule with the SL known as the Dixie Association. The two leagues played separate playoffs.
Despite the league's name, only its four South Division teams are actually based in Texas; the four North Division teams are located in surrounding states of Oklahoma, Arkansas, and Missouri. The league maintains its headquarters in San Antonio.
The League's name is well known due to its association with a particular aspect of the game. A bloop single that drops between the infielders and outfielders has been called a Texas Leaguer since the 1890s, despite no evidence that it originated in the Texas League, or was any more common there than elsewhere.
There is a common thread throughout Civil War anecdotes that refer to a game played 30 years earlier in the Sabine Pass area. As the story goes, a Union soldier hit a ball over the outfielder's head, leading him into a long chase for the ball which resulted in a bullet wound from a nearby sniper. After the incident, hits were only awarded for balls that landed between the infielders and outfielders.
Team moves.
In recent years, the Texas League has witnessed a great deal of change. Teams once known as the Jackson Mets, El Paso Diablos, Shreveport Captains, and Wichita Wranglers have all relocated to new cities and bigger stadiums.

</doc>
<doc id="70294" url="https://en.wikipedia.org/wiki?curid=70294" title="California League">
California League

The California League is a "Class A Advanced" minor league baseball league which operates throughout the Pacific Ocean coast state of California. A few draftees, generally early-round draftees from colleges with college experience, will be assigned to a High-A team upon signing a professional contract, but generally players will not arrive at this level until their third or fourth year of professional play.
All of the current teams are playing in stadiums that have been built or extensively renovated since 1990. League attendance continues to increase each season, with over one million fans attending games per year, part of a general nationwide growth and expansion to smaller towns, cities and regions below those in the National League or American League with minor league baseball at various levels of play in growing popularity in the last few decades. The League is divided into a Northern Division and a Southern Division.
History.
There were various attempts in the late 1800s and early 1900s to form a "California League" on the West Coast, considering the distance of the two current major leagues which generally had teams only in the Northeast and were restricted at first until World War I by long distance train travel. The first organized California League lasted from 1887–1889, then another followed in 1891, and 1893, and finally in 1899–1902. After the National Association of Professional Baseball Leagues, an organization of minor leagues was formed in 1902, (following the "truce" and agreements between the older National League of 1876 and the newly "upstart" American League of 1901), the California League operated outside the NAPBL system as an independent league in 1902 and again from 1907–1909. This led to huge differences in the quality of teams competing with each other. In 1907, the San Francisco team was 3-34, while later in 1908 San Francisco was 9-67 and Oakland was 4-71. Oakland and San Francisco competed in every year of these various state leagues, with San Francisco having two teams during 1887-88.
The current California League was founded in 1941, and included teams in Anaheim, Bakersfield, Fresno, Merced, Riverside, San Bernardino, Santa Barbara, and Stockton. The following year, as a result of World War II, the league dropped to four teams, then ceased and suspended operations altogether, although major league baseball and some minor leagues continued as much as possible with limited availability of players during the war years. It reorganized and came back in 1946, adding teams in Visalia, San Jose, and Ventura by 1947. Further east, Reno, Nevada joined the league in 1955 with the movement of the old Channel Cities Oilers in Santa Barbara and continued as a member for 37 years.
California League Champions.
Year by Year list of league champions: 
Complete team list (1941-42, 1946–present).
The Los Angeles area, Riverside, San Bernardino, Palm Springs, Yuma (AZ) and Las Vegas (NV) were also major league spring training site cities, as well possessed California League teams on different occasions.
Cities that have had California League Teams (current in bold).
Modesto has hosted a California League team longer than any other city, hosting a team in all but two of the CL's 65 seasons.
California League Hall of Fame.
In 2016, the California League announced the establishment of a league Hall of Fame. There were 15 inductees in 2016. 

</doc>
<doc id="70295" url="https://en.wikipedia.org/wiki?curid=70295" title="Carolina League">
Carolina League

The Carolina League is a minor league baseball affiliation which operates along the Atlantic Coast of the United States. It is classified as a "Class A-Advanced" league.
The organization that later became the Carolina League formed in 1945, just as World War II was ending, and consisted of only two teams based in southern Virginia. Historically, however, as many as 12 teams in a given year have competed in the Carolina League. Today, the league consists of eight teams in a region stretching from Delaware to South Carolina, and is divided into a Northern Division and a Southern Division.
History.
The league originated in the vicinity of Raleigh, North Carolina, and has since branched out.
A few of the many Carolina League players who have gone on to star in the Major Leagues are: Johnny Bench (Peninsula, 1966), Wade Boggs (Winston-Salem, 1977), Barry Bonds (Prince William, 1985), Rod Carew (Wilson, 1966), Dock Ellis (Kinston, 1965), Dwight Evans (Winston-Salem, 1971), Dwight Gooden (Lynchburg, 1983), Zack Greinke (Wilmington, 2003), Andruw Jones (Durham, 1996), Chipper Jones (Durham, 1992), Willie McCovey (Danville, 1956), Joe Morgan (Durham, 1963), Dave Parker (Salem, 1972), Tony Pérez (Rocky Mount, 1962), Andy Pettitte (Prince William, 1993), Jorge Posada (Prince William, 1993), Darryl Strawberry (Lynchburg, 1981), Bernie Williams (Prince William, 1988), and Carl Yastrzemski (Raleigh, 1959).
Director and screenwriter Ron Shelton's 1988 film "Bull Durham", starring Kevin Costner, Tim Robbins, and Susan Sarandon, depicted a fictionalized account of the Durham Bulls, at that time a Carolina League team (they have since become a Class AAA team in the International League). Before he began making films, Shelton had a five-year minor league career in the Baltimore Orioles' organization, which included a stint in the Carolina League.
The most recent change to the league's composition came in 2012, when the Kinston Indians relocated to Zebulon, North Carolina and became the Carolina Mudcats.
L
Carolina League champions.
</TR></TD>
All-time teams (1945–present).
All teams that have competed in the Carolina League from its founding in 1945. Teams in bold are currently active.

</doc>
<doc id="70296" url="https://en.wikipedia.org/wiki?curid=70296" title="Tucson Padres">
Tucson Padres

The Tucson Padres were a minor league baseball team representing Tucson, Arizona in the Pacific Coast League (PCL). They were the Triple-A affiliate for the San Diego Padres. The team moved to Tucson from Portland, Oregon for the 2011 season. In April 2014, the team moved to El Paso, Texas and changed their name to the El Paso Chihuahuas.
Franchise history.
Following the 2010 season, the Portland Beavers were put up for sale after PGE Park (now JELD-Wen Field) was remodeled into a soccer-only configuration for the MLS's 2011 expansion Portland Timbers. In 2010, the Beavers were sold to Jeff Moorad, principal owner of the San Diego Padres.
The Move to Tucson.
On October 19, 2010, it was announced that a site in Escondido, California had been selected for the new home of the Portland Beavers. The new ballpark was scheduled to open in April 2013. Until the move to Escondido could be completed the Padres would play their home games at Kino Veterans Memorial Stadium in Tucson, Arizona. In May 2011, citing reasons of proposed redevelopment revenue confiscation by the State, the ballpark plans in Escondido were placed on indefinite hold.
Franchise sale.
Following the California Supreme Court's decision to uphold the 2011 decision by the State to abolish redevelopment agencies it was decided by the Mayor of Escondido, Sam Abed, that the city would not be able to build the proposed stadium. In reaction Jeff Moorad announced he would sell the team if a location within the San Diego area could not be found. No sites materialized and in December 2011, Moorad decided to place the Tucson Padres up for sale. , Moorad received offers from buyers in three cities outside California. No offers to keep the team in Tucson were made. As a result, the Padres played in Tucson for the 2012 season and, in July 2012, announced that they would remain in Tucson for the 2013 season as well.
Relocation to El Paso.
On July 30, 2012, the Pacific Coast League gave preliminary approval to MountainStar Sports Group, an ownership group based out of El Paso, Texas, for the purchase of the Tucson Padres. The final sale of the Padres to MountainStar Sports was approved on September 26, 2012. On October 22, 2013 in front of a capacity crowd inside the historic Plaza Theater in Downtown El Paso, the MountainStar Sports Group announced that the team would officially be renamed as The El Paso Chihuahuas.

</doc>
<doc id="70297" url="https://en.wikipedia.org/wiki?curid=70297" title="Florida State League">
Florida State League

The Florida State League is a Class A-Advanced minor league baseball league operating in the state of Florida. They are one of three leagues currently operating in Class A-Advanced, the third highest of six classifications of minor leagues. Each team in the league is affiliated with a Major League Baseball team, and most play in their affiliate's spring training facility.
The league was founded in 1919, and has continued almost entirely uninterrupted to the present day. Most players in the Florida State League do not reach this level until their third or fourth year of professional play.
Attendance averages around 500–1,000 per game.
History.
The league originated in with teams in Bartow, Bradenton, Lakeland, Orlando, Sanford, and Tampa, Florida. The league closed down in and resumed play in . It has continued uninterrupted, except for a four-year (–) suspension during World War II.
In , the Florida State League established a Hall of Fame commemorating the league's great players, managers, owners, and umpires. The awards and ceremonies for the inaugural class will take place at the FSL's winter meetings in Daytona Beach in November.
The Tampa Yankees defeated the Charlotte Stone Crabs, 3–2, in the Florida State League Championship Series. In the 2011 championship, the Daytona Cubs swept the St. Lucie Mets, 3–0, and claimed their fourth title in 11 years.
League champions.
Since 1979, the winner of the League Championship Series has become the holder—until the following season's championship—of the Watson Spoelstra Florida State League Championship Trophy.
Florida State League Hall of Fame.
The Florida State League Hall of Fame began in 2009.

</doc>
<doc id="70298" url="https://en.wikipedia.org/wiki?curid=70298" title="Midwest League">
Midwest League

The Midwest League is a Class-A minor league baseball league, established in 1954 and operating in the Midwestern United States. The Midwest League began as the Illinois State League (1947-1948) and Mississippi–Ohio Valley League (1949-1955), which were renamed. In 1956, the Mississippi-Ohio Valley League was renamed the Midwest League.Today, the league has 16 teams in 2 divisions.
History.
The Midwest League directly evolved from two earlier leagues in the region. In 1947, the Class D Illinois State League (ISL) began operation with six Illinois teams – the Belleville Stags, Centralia Cubs, Marion Indians, Mattoon Indians, Mount Vernon Braves and the West Frankfort Cardinals. In 1949, the ISL changed its name to the Mississippi–Ohio Valley League after Marion moved their franchise to Kentucky and became the Paducah Chiefs. In 1954, the Mississippi-Ohio Valley League expanded, adding teams in Clinton and Dubuque, Iowa. The Mississippi-Ohio Valley League was then renamed Midwest League in 1956.
The original teams in 1956, the first year of Midwest League play, were: Clinton Pirates, Decatur Commodores, Dubuque Packers, Kokomo Dodgers, Lafayette Red Sox, Mattoon Phillies, Michigan City White Caps and the Paris Lakers. Mattoon is the oldest franchise in the MWL, evolving into today's Fort Wayne TinCaps, while Clinton is the oldest MWL locale. 
In 1960, the Davenport, Iowa based Quad City Braves joined the league as an expansion team. In 1962, Appleton, Burlington, and Cedar Rapids joined the Midwest League from the Illinois-Indiana-Iowa League which folded operations when those franchises switched leagues. All those franchised remain in the league today. In 1963, the Midwest League was designated as a Class A league, after the minor league classification structure was reorganized.
The 1975 Waterloo Royals, led by future MLB All-Stars Willie Wilson and Dan Quisenberry, are ranked #60 on MiLB.com's Top 100 Teams. The Royals finished the season 93–35.
In 1976, the Midwest League contracted from ten teams to eight, as franchises in Danville and Dubuque were eliminated. In 1982, the league expanded from 8 to 12 teams, adding the Beloit Brewers, the Danville Suns, the Madison Muskies, and the Springfield Cardinals. The Peoria Suns relocated from Danville in 1983, and acquired their current name, Peoria Chiefs, the following year. In 1988, the league began splitting its season into two halves and expanded from 12 to 14 teams, with the addition of franchises in South Bend, Indiana, and Rockford, Illinois. During the 1990s several teams changed cities as Major League Baseball placed higher standards on minor league baseball facilities; franchises in smaller cities were sold to new owners who moved those teams to new ballparks in larger cities. Kenosha, Madison, Rockford, Springfield, Waterloo, and Wausau lost teams during this decade while Battle Creek, Dayton, Fort Wayne, Grand Rapids (West Michigan), Kane County, and Lansing gained teams.
The 1978 Appleton Foxes are ranked #93 on the Top-100 All Time teams by MiLB.com. Led by future Cy Young Award winner LaMarr Hoyt, the team finished 97-40. Harry Chappas, Ross Baumgarten and Britt Burns were all called up to the parent Chicago White Sox at the conclusin of the MWL season. The 97 wins by the Foxes remains a Midwest League record. 
The Fort Wayne TinCaps are the oldest franchise in the league, having begun as the Mattoon Indians in 1947 and playing in Keokuk, Iowa; Wisconsin Rapids, Wisconsin; and Kenosha, Wisconsin, before moving to Fort Wayne, Indiana, in 1993. The Clinton LumberKings have been in one city longer than any Midwest League team, having called Clinton, Iowa, home since 1954.
The Southwest Michigan Devil Rays moved to Midland, Michigan, and became the Great Lakes Loons prior to the 2007 season.
On September 2, 2008, Minor League Baseball announced that two teams would transfer from the fellow Class A South Atlantic League to the Midwest League: the Lake County Captains (an affiliate of the Cleveland Indians playing in Eastlake, Ohio) and the Bowling Green Hot Rods (an affiliate of the Tampa Bay Rays playing in Bowling Green, Kentucky).
Midwest League Champions.
Year by Year championship teams: List of Midwest League champions

</doc>
<doc id="70299" url="https://en.wikipedia.org/wiki?curid=70299" title="South Atlantic League">
South Atlantic League

The South Atlantic League is a minor league baseball league based chiefly in the Southeastern United States, with the exception of three teams in the Mid-Atlantic States. It is a Class A league that plays a full season; its players are typically a mixture of newly signed draftees (especially late in the season) and players promoted from rookie leagues.
A number of different leagues known as the South Atlantic League have existed since 1904. The current league of that name adopted the moniker in 1980, having previously been the Western Carolinas League, founded in 1963.
History.
There have been different South Atlantic Leagues in the history of minor league baseball, spanning from 1904 to the present with a few breaks. The league ran from 1904 to 1917 as a class C league, then started up again in 1919, also class C. This time it ran from 1919 to 1930, moving up to class B beginning in 1921. William G. Bramham became league president in mid-1924, and served until 1930. The league was restarted again as a class B from 1936 to 1942, shut down for the war and returned in 1946 as a class A league. The AA Southern Association (which never integrated) died after the 1961 season and so the SAL was promoted to AA in 1963 to take its place; a year later the name was changed to the Southern League. Out of the 51 seasons of operation, Augusta, Georgia competed in 46, Macon, Georgia was around for 46, and Columbia, South Carolina was in 45. Charleston, South Carolina; Jacksonville, Florida; Savannah, Georgia; and Columbus, Georgia; each competed for at least 29 years also, making for a relatively stable lineup.
The South Atlantic League name went unused for 16 years, but in 1980 the Western Carolinas League brought back the name when it sought to change its identity. For nearly 60 years, 1948 through 2007, the dominant figure in the WCL/SAL was league founder and president John Henry Moss, who started the WCL as a young man in 1948, refounded it in 1960 and then led it into the new century. Moss retired at the close of the 2007 South Atlantic League season. He died at age 90 on July 1, 2009, at Kings Mountain, North Carolina—a town where he had also been mayor for 23 years.
In 2005, the SAL had the highest attendance in 101 years with over 3,541,992 fans (while minor league baseball set a second straight record with 41,333,279 attendees). Currently, the league has 14 teams, divided into two divisions of seven clubs.
In 2015, the Savannah Sand Gnats relocated to Columbia, South Carolina, becoming the Columbia Fireflies.
Current teams.
The league is divided into a Northern Division and a Southern Division.
1 Hosting 2010 South Atlantic League All-Star Game -->
South Atlantic League teams (1980–present).
Notes: Bold font indicates that team is an active South Atlantic League team • An "^" indicates that team's article redirects to an article of an active team in the South Atlantic League or in a different league
South Atlantic League Hall of Fame.
The South Atlantic League Hall of Fame was opened in 1994: 

</doc>
<doc id="70300" url="https://en.wikipedia.org/wiki?curid=70300" title="New York–Penn League">
New York–Penn League

The New York–Penn League is a minor league baseball league which operates in the northeastern United States. It is classified as a "Short-Season A" league; its season starts in June, after major-league teams have signed their amateur draft picks to professional contracts, and ends in early September. The league is divided into the McNamara Division, the Pinckney Division, and the Stedler Division.
As of the 2015 season, the league includes teams in eight different states. In addition to New York and Pennsylvania, from which the league draws its name, the NYPL also has clubs in Maryland, Massachusetts, Ohio, Vermont, West Virginia, and Connecticut.
The West Virginia Black Bears are the most recent league champions, defeating the Staten Island Yankees on September 15, 2015, by a score of 3-1 to win the series 2-0. It is their first title in their first season in Morgantown and as the Black Bears.
History.
The league was founded in 1939 with the name Pennsylvania – Ontario – New York League in a hotel in Batavia, New York. This was generally shortened to PONY League. The original teams included the Batavia Clippers, Bradford Bees, Hamilton Red Wings, Jamestown Jaguars, Niagara Falls Rainbows, and Olean Oilers. The Oilers, a Brooklyn Dodgers affiliate, won both the regular-season and playoff championships.
The Hamilton Red Wings folded early in the 1956 season, and with no more teams in Ontario, the league adopted its current name in 1957. The league crossed back into Canada with the formation of the St. Catharines Blue Jays in 1986. They were joined by the Hamilton Redbirds in 1987 and the Welland Pirates in 1989, but all three clubs had moved back to the United States by 2000.
Player limits and requirements.
New York–Penn League teams may have no more than 3 players on their active lists that have 4 or more years of prior combined Major League / Minor League service, with the exception of position players changing roles to become a pitcher or a pitcher changing into a position player. Teams may get to eliminate up to one year of time of Minor League service for players who have spent time on the disabled list.
By July 1 of each year, all clubs must have at least 10 pitchers.
Maximum number of players under team control is 35, 30 of those may be active, but only 25 may be in uniform and eligible to play in any given game.
PONY/NY–Penn League teams (1939–present).
Cities represented.
Connecticut
Maryland
Massachusetts
New Jersey
New York
Ohio
Pennsylvania
Vermont
West Virginia
Ontario

</doc>
<doc id="70301" url="https://en.wikipedia.org/wiki?curid=70301" title="Northwest League">
Northwest League

Northwest League of Professional Baseball (or simply the Northwest League or NWL) is a Class A-Short Season minor league. The league is the descendant of the Western International League (WIL), a class B league from 1937–1951 (with time out for World War II), and class A from 1952–1954. The league reformed, dropped to class B, and changed its name for the 1955 season.
The Northwest League (or the "Northwestern League") has existed in various forms since 1890, and has been in its current incarnation since 1955. It switched to the short season schedule in 1966, with only four teams.
The WIL had ten teams in its final year in 1954, with four in Canada. The six U.S. cities plus Eugene were the seven charter teams of the Northwest League in 1955: Salem Senators, Eugene Emeralds, Yakima Bears, Spokane Indians, Tri-City Braves, Wenatchee Chiefs, and Lewiston Broncs. During its fiftieth season in 2004, five of the seven original cities were in the league.
The NWL's short season starts in mid-June, after major league teams have signed their amateur draft picks to professional contracts, and ends in early September. All eight teams are affiliated with a major league team.
Current teams.
Source:
Former Northwest League Teams (1955–).
Cities that have hosted NWL teams.
Washington.
Eugene is the most-tenured city in the NWL, having fielded a team in all but five of the NWL's seasons (from 1969–73, they had a PCL franchise)

</doc>
<doc id="70302" url="https://en.wikipedia.org/wiki?curid=70302" title="Appalachian League">
Appalachian League

The Appalachian League of Professional Baseball is a Rookie-class minor league baseball league that began play in 1911. It operated as a Class D league (1911-1914), (1921-1925), (1937-1955) and (1957-1962) before becoming a Rookie League in 1963. Teams are located in the Appalachian regions of Virginia, North Carolina, West Virginia and Tennessee. The league's season starts in June, after major league teams have signed players that they selected in the annual amateur draft, and ends in September.
Along with the Pioneer League, it forms the second-lowest rung on the minor league ladder. Although classified as a Rookie league, the level of play is slightly higher than that of the two "complex" Rookie leagues, the Gulf Coast League and Arizona League. Unlike these two leagues, Appalachian League games charge admission and sell concessions.
History.
The original Appalachian League only existed for four seasons from 1911-1914 and all teams were independent with no MLB affiliation. The teams that were a part of this were: Asheville Moonshiners, Bristol Boosters, Cleveland Counts, Johnson City Soldiers, Knoxville Appalachians, and Morristown Jobbers.
The second Appalachian League existed for five seasons from 1921-1925, and again only had independent teams. These teams were the Bristol State-Liners, the Cleveland Manufacturers, the Greeneville Burley Cats, the second iteration of the Johnson City Soldiers, the Kingsport Indians, and the Knoxville Pioneers. 1921 was the first appearance of 2 locations which have present-day teams in the Appalachian League – Kingsport, Tennessee, with the present-day Kingsport Mets; and Greeneville, Tennessee, with the present-day Greeneville Astros.
The third Appalachian league was shifted to D-level minor league, the lowest level in the pre - 1963 MLB. It started in 1937 and had four teams - the Elizabethton Betsy Red Sox, the third iteration of the Johnson City Soldiers, the Newport Canners, and the Pennington Gap Lee Bears.

</doc>
<doc id="70305" url="https://en.wikipedia.org/wiki?curid=70305" title="Pioneer League (baseball)">
Pioneer League (baseball)

The Pioneer League is a minor league baseball league which currently operates in the Rocky Mountain region of the United States. In the past, it also operated in adjoining portions of Canada. It is classified as a Rookie League, and is almost exclusively the first professional league in which many players compete; most of the players have just been signed out of high school. The Pioneer League is a short-season league operating from June to early September.
Along with the Appalachian League, it forms the second-lowest rung on the minor league ladder. Although classified as a Rookie league, the level of play is slightly higher than that of the two "complex" Rookie leagues, the Gulf Coast League and Arizona League. Unlike these two leagues, Pioneer League games charge admission and sell concessions.
The Pioneer League began in 1939 with six teams in Idaho and Utah. With players in short supply due to World War II, the league suspended operations for the 1943 through 1945 seasons. In 1948, the league expanded into Montana. At that time, several of the teams were operating as minor league affiliates of Pacific Coast League teams, which were unsuccessfully trying to grow into a major league. When the Los Angeles Dodgers displaced the Hollywood Stars PCL team, they moved to Salt Lake City, Utah, taking away the Pioneer League's largest market. By 1959, the league was down to six teams, and by 1964, there were only four. By the end of the 1970s there were eight teams, a number that remains to this day and is not likely to change without further expansion or contraction within Major League Baseball.
In 2015, total league attendance was 633,622.

</doc>
<doc id="70310" url="https://en.wikipedia.org/wiki?curid=70310" title="USS Ronald Reagan">
USS Ronald Reagan

USS "Ronald Reagan" (CVN-76) is a nuclear-powered supercarrier in the service of the United States Navy. The ninth ship of her class, she is named in honor of former President Ronald Reagan, President of the United States from 1981 to 1989. Upon her christening in 2001, she was the first ship to be named for a then-still living former president.
As of May 2012 the ship was operationally part of Carrier Strike Group Nine and administratively under the command of Commander, Naval Air Forces Pacific/Commander, Naval Air Forces. The two administrative titles actually refer to one command carrying out two functions. In January 2014, the U.S. Navy announced that the "Ronald Reagan" would replace the as the flagship of Carrier Strike Group Five, the only forward-based carrier strike group home-ported at Yokosuka, Japan, as part of the United States Seventh Fleet.
Design and construction.
The contract to build "Reagan" was awarded to Northrop Grumman Newport News and Dry Dock Company in Newport News, Virginia on 8 December 1994, and her keel was laid down on 12 February 1998. The budget for the ship had to be increased several times and ultimately $4.5 billion was spent on her construction. This included a redesigned ship island. "Reagan" was christened by Reagan's wife Nancy on 4 March 2001 at Newport News Shipbuilding, the crew moved aboard on 30 October 2002, and the ship was commissioned on 12 July 2003 at Naval Station Norfolk, with Captain J. W. Goodwin in command. Vice President Dick Cheney and Lynne Cheney were both present at the ceremony, as well as Nancy Reagan, who gave the ship's crew the traditional first order as an active unit of the Navy: "Man the ship and bring her to life." "Ronald Reagan" made her maiden voyage on 21 July 2003. President Reagan, who did not attend either the launch or the commissioning due to Alzheimer's disease, died eleven months later. At the end of the graveside services, the ship's commanding officer at that time, Captain James Symonds, presented the flag that draped the former president's casket to Mrs. Reagan at her request. This was also the flag that had flown over Capitol Hill on 20 January 1981, when the president was inaugurated. At a later date, Captain Symonds also presented Mrs. Reagan the flag that had been flying over "Ronald Reagan" when the former president died.
Naming.
"Ronald Reagan" was the first nuclear-powered warship of any kind to be named in honor of a living former president. Unlike most of the other men honored by inclusion in this group, Reagan was not associated with the United States Navy, apart from his term as Commander-in-Chief, though one of his key initiatives in office was the 600-ship Navy program.
Ship's seal.
The design of "Ronald Reagan" seal was created entirely by her plankowner crew with historical assistance provided by staff members at the Ronald Reagan Presidential Library foundation. The red border that rings the ship's seal is similar to the distinctive red rim that defines the White House china designed for the Reagans during their White House years. Four gold stars represent President Reagan's 40th presidency and his four pillars of freedom: individual liberty; economic opportunity; global democracy; and national pride. "Peace through Strength" was a recurring theme of the President's life in public service. The aircraft carrier is positioned by the West Coast, representing President Reagan's two terms as Governor of California and the ship's homeport in the Pacific Fleet. The three aircraft with their patriotic contrails symbolize the three major military operations the President directed during his tenure: Operation Urgent Fury (Grenada/1983); Operation El Dorado Canyon (Libya/1986); and Operation Praying Mantis (Iran/1988). The view of the globe signifies the President's vision of global democracy, and the center is the United States representing the country's national pride. Colors of red, white and blue dominate the seal reflecting the American flag.
Service history.
On 8 May 2004, following her five-month post-shakedown availability (PSA), the aircraft carrier "Ronald Reagan" received her second flight deck certification which encompassed all flight operations, including aircraft launch and recovery, safety, crash and salvage, fuel certifications, and training. "Reagan" then began her transit from Naval Station Norfolk, Virginia, around Cape Horn, South America, to her new homeport of Naval Air Station North Island, San Diego.
Carrier Air Wing Eleven, normally assigned to , embarked only 25 percent of its total strength for the transit. The squadrons making the transit were VFA-14 and VFA-41 flying the F/A-18E/F Super Hornet, VAW-117 flying the E-2C Hawkeye 2000, HS-6 flying the SH-60F Seahawk and VRC-30 flying the C-2A Greyhound. The ship visited Rio de Janeiro, Brazil on 5 June 2004 and during the first evening after arrival the ship's namesake Ronald Reagan died. A ceremony in his honor was held onboard later that evening, soon after the US national anthem was publicly played. After leaving Rio, "Reagan" transited the Strait of Magellan on 20–21 June and subsequently made port visits to Valparaíso, Chile, and Callao, Peru before arriving in San Diego on 23 July 2004. From 1 October 2004, "Reagan" was assigned to Carrier Strike Group Fifteen.
2006 maiden deployment.
USS "Ronald Reagan" departed San Diego on 4 January 2006, on her maiden deployment to conduct naval operations in support of Operation Iraqi Freedom and Operation Enduring Freedom, as well as to conduct maritime security operations (MSO) in the Persian Gulf. On 28 January 2006, an F/A-18 Hornet strike fighter attempting a night landing aboard "Reagan" crashed into the ship's flight deck about southeast of Brisbane, Queensland. The aircraft struck the ramp at a low angle, caught fire and skidded overboard. The pilot ejected safely, but the aircraft was lost. The ship entered the Persian Gulf on 22 February 2006, and returned from deployment on 6 July 2006.
2007 surge deployment.
USS "Ronald Reagan" and the "Reagan" Carrier Strike Group (CSG) departed North Island, Coronado in San Diego on 27 January 2007 on an unscheduled surge deployment to the Western Pacific, fulfilling the role of the forward deployed carrier while it underwent maintenance in Japan. On 20 April 2007, "Ronald Reagan" and her CSG returned to Coronado. The "surge deployment" was part of the Navy's Fleet Response Plan (FRP), which provides the U.S. with the ability to respond to any global commitment with flexible and sustainable forces and the ability to rapidly respond to a range of situations on short notice.
In January 2007, it was announced that "Ronald Reagan" had earned the 2006 Commander, Naval Air Forces Pacific Carrier Battle Efficiency "E" award for the West Coast, the first Battle "E" ever for the carrier.
"Reagan" returned to Naval Air Station North Island on 20 April 2007, following the three-month deployment in support of operations in the Western Pacific.
On 15 December 2007, the carrier answered a distress call from a cruise ship off the coast of Baja California. An Illinois teenager whose appendix had ruptured while on a Mexican cruise was airlifted by an SH-60 helicopter to "Ronald Reagan", where an emergency appendectomy was performed by the ship's surgeon.
2008 deployment.
USS "Ronald Reagan", with CVW-14 embarked, departed San Diego on 19 May 2008, for a scheduled 7th Fleet and 5th Fleet deployment.
The "Reagan" Carrier Strike Group performed humanitarian assistance and disaster relief operations in the Philippines on 24 June 2008 after that country was devastated by Typhoon Fengshen, killing hundreds from the central island regions and the main island of Luzon. The typhoon also capsized the passenger ferry . Working in support of the Armed Forces of the Philippines, "Reagan" and her escorts of Carrier Strike Group 7 focused their efforts on the island of Panay in the Central Visayas. For eight days, SH-60 Seahawk helicopters and C-2A Greyhound aircraft of the "Ronald Reagan" Strike Group helped deliver more than of rice, fresh water and other supplies to areas of Panay, which were not reachable via truck due to flooded roads. The mission in Panay would earn the entire strike group the Navy's Humanitarian Service Medal.
The Strike Group arrived in the U.S. Fifth Fleet area on 28 August 2008, where she launched more than 1,150 sorties into Afghanistan in support of Operation Enduring Freedom. "Reagan" returned to San Diego on 25 November 2008.
USS "Ronald Reagan" received word in February 2009 that the ship had won its second Battle Effectiveness Award.
2009 deployment.
On 28 May 2009, "Reagan" deployed with Carrier Air Wing 14 to the 7th and 5th Fleet Areas of Responsibility. "Reagan" relieved the CSG and launched its first sorties in support of OEF on 6 July. "Reagan" returned to homeport on 21 October after a five-month deployment.
2010.
In early 2010, "Reagan" was awarded the 2009 Chief of Naval Operations Afloat Safety "S" Award, and the 2009 Pacific Fleet Battle "E" for combat efficiency. The Battle "E" award was "Reagan"s second consecutive and third in four years.
On 19 May 2010, Norfolk Naval Shipyard (NNSY) completed the six-month Planned Incremental Availability (PIA) maintenance cycle on "Reagan". This PIA project came in under budget, and it marked both Norfolk Naval Shipyard's largest off-site availability as well as the largest public sector work package ever performed on an aircraft carrier berthed at Naval Air Station North Island (NASNI) located near Coronado, California ("pictured"). During the maintenance period, "Ronald Reagan" received technological upgrades that prepared it for its next deployment and subsequent operations. Refurbishments included hi-tech combat systems and firefighting equipment to improved ship's laundry services and living spaces. This PIA maintenance project was an example of the 'One Shipyard' concept wherein the U.S. Navy mobilizes its work force across its various shipyards to better meet fleet readiness requirements as well as to stabilize a vital workforce base for the U.S. defense industry. While Norfolk Naval Shipyard was the project lead, significant work was done by its partners: Puget Sound Naval Shipyard & Intermediate Maintenance Facility (PSNS & IMF), Southwest Regional Maintenance Center (SWRMC), Northrop Grumman Shipbuilding (NGSB).
During peak manning, approximately 1,400 worked the project on a daily basis. This included approximately 625 NNSY personnel, 165 PSNS & IMF employees, and 600 from SWRMC/NGSB.
On 18 May 2010, "Reagan" departed Naval Air Station North Island for sea trials. The sea trial was the final phase of the PIA, and it was conducted to assess the carriers material readiness to return to the operational fleet. "Reagan" pulled into Naval Air Station North Island on 19 May 2010 after completing its two-day sea trial, marking the official end to its six-month planned incremental availability (PIA) maintenance period.
On 2 June 2010, "Ronald Reagan", with Carrier Air Wing Fourteen (CVW-14) embarked, departed Naval Air Station North Island to conduct flight deck certifications. The first CVW-14 aircraft to land on aircraft carriers flight deck was from Helicopter Anti-Submarine Squadron 4 (HS-4). Other embarked squadrons included:
Marine Fighter Attack Squadron 323 (VMFA-323), Strike Fighter Squadron 154 (VFA-154), Strike Fighter Squadron 147 (VFA-147)* Strike Fighter Squadron 146 (VFA-146), Airborne Early Warning Squadron 113 (VAW-113), Fleet Logistics Squadron 30 (VRC-30)
The certification included a full evaluation of the arresting gear, steam catapults, and flight deck personnel. "Reagan"s air department was assessed on its ability to maintain a fully operational flight deck and respond to simulated mishaps.
During the summer of 2010 "Ronald Reagan" participated in Exercise RIMPAC, departed from Naval Air Station North Island, California, for a Board of Inspection and Survey (INSURV) assessment on 25 August 2010, and departed her homeport to conduct routine operations off the coast of southern California in preparation for its 2011 Western Pacific (WESTPAC) deployment. In November 2010, the ship provided emergency supplies and assistance to passengers stranded in the Pacific Ocean aboard the "Carnival Splendor", which had lost power by an engine fire.
2011.
The ship departed for an Asian deployment on 2 February 2011. On 11 March 2011, "Reagan" was in the Korean peninsula region for a long-planned exercise off Korea, but was redirected towards Japan to provide support after the massive 2011 Tōhoku earthquake and tsunami. The ship, stationed off Sendai, served as a refueling station for Japanese coast guard and military helicopters on relief missions in the area. US Navy helicopters also flew relief missions from the carrier. 
On 13 March 2011, the ship measured 0.6 mR/hr direct gamma shine from clouds 130 miles (≈210 km) from the Fukushima Daiichi Nuclear Power Plant. Members of the crew blamed their cancers on the event.
On 14 March 2011, the ship was forced to relocate to avoid a radioactive plume from the Fukushima I nuclear accidents which had contaminated 17 crew members of three helicopter crews. On 23 March, "Reagan"s crew performed radiation decontamination by scrubbing down any surface that could have been contaminated, including the island superstructure and flight deck, to remove any potential radiation hazards. On 4 April 2011, Japan's minister of defense, Toshimi Kitazawa, accompanied by US ambassador to Japan John Roos, visited the ship to thank its crew for its assistance as part of Operation Tomodachi. Said Kitazawa, "I have never been more encouraged by and proud of the fact that the United States is our ally." The ship returned to San Diego on 8 September 2011. In January 2011, the Navy announced that the aircraft carrier would be transferred to the Puget Sound Naval Ship Yard in Bremerton, Washington for scheduled repair and maintenance beginning January 2012.
2012 and 2013.
On 10 January 2012 "Reagan"s official home port was changed to Bremerton, Washington, where she stayed for a little over a year until returning to her home port of San Diego on 21 March 2013. For the sailors being relocated, the Navy had many of their vehicles transported on the deck of the ship as a cost-saving measure.
2014.
On 14 January 2014, the Navy announced that "Ronald Reagan" would replace her sister ship as the Seventh Fleet forward deployed carrier at Yokosuka, Japan in 2015.
2015.
On 1 October 2015, the Reagan arrived in Yokosuka, Japan replacing the USS George Washington and taking its new place as the flagship of Carrier Strike Group Five. With the new home port, the carrier's air wing is now CVW-5.
Gallery.
"Click on the thumbnail to enlarge."

</doc>
<doc id="70311" url="https://en.wikipedia.org/wiki?curid=70311" title="Maraschino cherry">
Maraschino cherry

In the United States, a maraschino cherry ( or ) is a preserved, sweetened cherry, typically made from light-colored sweet cherries such as the Royal Ann, Rainier, or Gold varieties. In their modern form, the cherries are first preserved in a brine solution usually containing sulfur dioxide and calcium chloride to bleach the fruit, then soaked in a suspension of food coloring (common red food dye, FD&C Red 40), sugar syrup, and other components.
Maraschino cherries are an ingredient in many cocktails, giving them the nickname "cocktail cherries." As a garnish, they often are used to decorate frozen yogurt, baked ham, cakes, pastry, parfaits, milkshakes, ice cream sundaes, and ice cream sodas. They are an integral part of an American pineapple upside-down cake. They are frequently included in canned fruit cocktail. They are also used as an accompaniment to sweet paan, and sometimes, along with some of the maraschino "juice," put into a glass of Coca-Cola to make an old-fashioned or homemade "Cherry Coke."
Europe.
The name "maraschino" originates from the Marasca cherry of Croatian origin and the maraschino liqueur made from it, in which Marasca cherries were crushed and preserved after being pickled. Whole cherries preserved in this liqueur were known as "maraschino cherries." These had been a local means of preserving the fruit in Dalmatia.
In the 19th century, these became popular in the rest of Europe, but the supply in Dalmatia was too small for the whole continent, so they came to be seen as a delicacy for royalty and the wealthy.
Because of the relative scarcity of the Marasca, other cherries came to be preserved in various ways and sold as "maraschino."
United States.
The cherries were first introduced in the United States in the late 19th century, where they were served in fine bars and restaurants. Because they were scarce and expensive, by the turn of the century American producers were experimenting with other processes for preserving cherries, with flavors such as almond extract and substitute fruit like Queen Anne cherries. Among these, alcohol was already becoming less common.
In response, the USDA in 1912 defined "maraschino cherries" as "Marasca cherries preserved in maraschino" under the authority of the Food and Drugs Act of 1906. The artificially-colored and sweetened Royal Anne variety were required to be called "Imitation Maraschino Cherries" instead. Food Inspection Decision 141, defined Marasca cherries and maraschino themselves. It was signed on Feb. 17, 1912.
During Prohibition in the United States as of 1920, the decreasingly popular alcoholic variety was illegal as well. Ernest H. Wiegand, a professor of horticulture at Oregon State University, developed the modern method of manufacturing maraschino cherries using a brine solution rather than alcohol. Accordingly, most modern maraschino cherries have only a historical connection with maraschino liqueur.
According to Bob Cain, Cliff Samuels, and Hoya Yang, who worked with Wiegand at OSU, Prohibition had nothing to do with Wiegand's research: his intention was to develop a better brining process for cherries that would not soften them. When Wiegand began his research, there were several ways to preserve maraschino cherries without alcohol, long before Prohibition went into effect. Wiegand took a process that people had their own recipes for—"and who knows what they were putting in there" (frequently not alcohol)—and turned it into a science, something replicable.
When Wiegand began his research, sodium metabisulfite was being used to preserve maraschino cherries. Some accounts indicate that this preservation method was being used long before Prohibition. Some manufacturers used maraschino or imitation liqueurs to flavor the cherries, but newspaper stories from the early part of the century suggest that many manufacturers stopped using alcohol and artificial dyes before Prohibition.
After Prohibition was repealed lobbying by the non-alcoholic preserved cherry industry encouraged the Food and Drug Administration to revise federal policy toward canned cherries. It held a hearing in April 1939 to establish a new standard of identity. Since 1940, "maraschino cherries" have been defined as "cherries which have been dyed red, impregnated with sugar, and packed in a sugar syrup flavored with oil of bitter almonds or a similar flavor."
FD&C Red Number 1 and 4, and FD&C Yellow Number 1 through 4 were removed from the approved list in 1960. The ban on Red Number 4 was lifted in 1965 to allow the coloring of maraschino cherries, which by then were considered mainly decorative and not a foodstuff.
In 1975, William F. Randolph of the FDA ruled that if an "artificial bitter almond flavor or any synthetic flavor is used, the product must be labeled artificial or artificially flavored."
Maraschino cherries currently use FD&C Red 40 as a colorant.

</doc>
<doc id="70315" url="https://en.wikipedia.org/wiki?curid=70315" title="Debbie Reynolds">
Debbie Reynolds

Mary Frances "Debbie" Reynolds (born April 1, 1932) is an American actress, entertainer, businesswoman, film historian and a noted former collector of film memorabilia.
Her breakout role was the portrayal of Helen Kane in the 1950 film "Three Little Words", for which she was nominated for the Golden Globe Award for Most Promising Newcomer. However, it was her first leading role in 1952 at age 19, as Kathy Selden in "Singin' in the Rain", that set her on the path to fame. By the mid-1950s, she was a major star.
Other notable successes include "The Affairs of Dobie Gillis" (1953), "Susan Slept Here" (1954), "Bundle of Joy" (1956 Golden Globe nomination), "The Catered Affair" (1956 National Board of Review Best Supporting Actress Winner), and "Tammy and the Bachelor" (1957), in which her rendering of the song "Tammy" reached number one on the music charts. In 1959, she released her first pop music album, entitled "Debbie".
She starred in "How the West Was Won" (1963), and "The Unsinkable Molly Brown" (1964), a biographical film about the famously boisterous Molly Brown. Her performance as Molly Brown earned her a nomination for the Academy Award for Best Actress. Her other notable films include "The Singing Nun" (1966), "Divorce American Style" (1967), "What's the Matter with Helen?" (1971), "Mother" (1996 Golden Globe nomination), and "In & Out" (1997). Reynolds is also a noted cabaret performer. In 1979, she founded the "Debbie Reynolds Dance Studio" in North Hollywood, which still operates today.
In 1973, Reynolds starred in a Broadway revival of the musical "Irene" and was nominated for the Tony Award for Best Lead Actress in a Musical. In 1969 she starred in her own television show "The Debbie Reynolds Show", for which she received a Golden Globe nomination. She was also nominated for a Daytime Emmy Award for her performance in "A Gift of Love" (1999) and an Emmy Award for playing Grace's mother Bobbi on "Will & Grace". Reynolds is known for her role as Aggie Cromwell in Disney's Halloweentown series. In 1988, she released her autobiography titled, "Debbie: My Life". In 2013, she released an updated version titled "Unsinkable: A Memoir".
She is a noted businesswoman, having operated her own hotel in Las Vegas. Reynolds is also a collector of film memorabilia, beginning with the landmark 1970 MGM auction. She is the former president of The Thalians, an organization dedicated to mental health causes. She continues to perform successfully on stage, television and film. In January 2015, Reynolds received the Screen Actors Guild Life Achievement Award. In August 2015, it was announced Reynolds would be the recipient of the 2016 Academy Awards Jean Hersholt Humanitarian Award.
Early life.
She was born Mary Frances Reynolds on April 1, 1932, in El Paso, Texas, the daughter of Maxine (née Harmon; 1913–99) and Raymond Francis Reynolds (1903–86), who was a carpenter for the Southern Pacific Railroad. She has Scottish-Irish and English ancestry, and was raised in a strict Nazarene church. Reynolds was a Girl Scout and a troop leader (a scholarship in her name is offered to high-school age Girl Scouts). 
Her family moved to Burbank, California, in 1939. At age sixteen, in 1948, while a student at Burbank High School (not Burroughs High as has been misreported), she won the Miss Burbank beauty contest. Soon after, she had a contract with Warner Bros, and acquired a new first name. Her older brother Bill Reynolds graduated from Burbank High School in 1947.
Music career.
Reynolds regularly appeared in movie musicals during the 1950s and had several hit records during the period. Her song "Aba Daba Honeymoon" (featured in the film "Two Weeks with Love" (1950) as a duet with Carleton Carpenter) was a top-three hit in 1951. Her most high-profile film role was in "Singin' in the Rain" (1952) as Kathy Selden. In "Bundle of Joy" (1956), she appeared with her then-husband, Eddie Fisher.
Her recording of the song "Tammy" (1957; from "Tammy and the Bachelor"), earned her a gold record, and was the best-selling single by a female vocalist in 1957. It was number one for five weeks on the "Billboard" pop charts. In the movie (the first of the "Tammy" film series), she co-starred with Leslie Nielsen.
In 1959, Reynolds recorded her first album for Dot Records, simply called "Debbie", which included her own selection of twelve standards including "S'posin'", "Moonglow", "Mean To Me", and "Time After Time". Bing Crosby paid tribute to Reynolds in the sleeve notes accompanying the album thus:Someone recently said, and with reasonable accuracy I would think, that good singers make good actors. Evidence in support of this belief is available in the recent performances of Sinatra and Martin, for instance, but I would like to put forth also the proposition that the reverse is quite true: good actors make good singers. Assuming they can carry a tune. We all know that Debbie is better than a good actress—she's VERY good, and we all know she can sing with a lilt and a listenable quality that's genuinely pleasant and agreeable. Witness "Tammy". It was small surprise to me then that when I listened to this beautiful album she has etched for Dot, I found myself captivated and enchanted. Quite obviously Debbie had spent a great deal of time selecting the songs to be included, because she's made them her own, and invested them with a sincerity that's inescapable—of contrasting moods to be sure, but the moods are there, and to me, mighty effective. And that, mes amis, is artistry.
Reynolds also scored two other top-25 "Billboard" hits with "A Very Special Love" (#20 in January of 1958) and "Am I That Easy to Forget" (#25 in March 1960)—a pop-music version of a country-music hit made famous by both songwriters Carl Belew (in 1959), Skeeter Davis (in 1960), and several years later by singer Engelbert Humperdinck. She has released several albums of both her vintage performances and her later recordings. 
During these years, she also headlined in major Las Vegas showrooms. Reynolds last CD was a Christmas Record with the late Donald O'Connor entitled "Chrissy the Christmas Mouse". It received rave reviews and was arranged by Angelo DiPippo and produced by Dr. Fillardi.
Film and television.
Her starring role in "The Unsinkable Molly Brown" (1964) led to a nomination for the Academy Award for Best Actress. She then portrayed Jeanine Deckers in "The Singing Nun" (1966). In what Reynolds has called the "stupidest mistake of my entire career", she made headlines in 1970 after instigating a fight with the NBC television network over cigarette advertising on her eponymous television series; NBC canceled the show.
Reynolds continued to make appearances in film and television. She played Helen Chappel Hackett's mother, Deedee Chappel, on an episode of "Wings" titled, "If It's Not One Thing, It's Your Mother", which originally aired on November 22, 1994. From 1999 to its 2006 series finale, she played Grace Adler's theatrical mother, Bobbi Adler, on the NBC sitcom "Will & Grace", which earned her an Emmy Award nomination for Outstanding Guest Actress in a Comedy Series in 2000. She plays a recurring role in the Disney Channel Original Movie "Halloweentown" film series as Aggie Cromwell. Reynolds made a guest appearance as a presenter at the 69th Academy Awards in 1997. She made a cameo role as herself in the 2004 film "Connie and Carla". In 2013, she appeared in "Behind the Candelabra", as the mother of Liberace.
Film history preservation.
Reynolds has amassed a large collection of movie memorabilia, beginning with the landmark 1970 Metro-Goldwyn-Mayer auction, and displayed them, first in a museum at her Las Vegas hotel and casino during the 1990s and later in a museum close to the Kodak Theater in Los Angeles. On several occasions, she has auctioned off items from the collection.
The museum was to relocate to be the centerpiece of the Belle Island Village tourist attraction in the resort city of Pigeon Forge, Tennessee, but the developer went bankrupt. The museum itself filed for Chapter 11 bankruptcy in June 2009.
Todd Fisher, Reynolds' son, announced that his mother was "heartbroken" to have to auction off her collection. It was valued at $10.79 million in the bankruptcy filing. "The Vancouver Sun" reported that Profiles in History has been given the responsibility of conducting a series of auctions beginning in June and continuing into December 2011. Among the "more than 3500 costumes, 20,000 photographs, and thousands of movie posters, costume sketches, and props" to be sold are Charlie Chaplin's bowler hat and Marilyn Monroe's white "subway dress", whose skirt is lifted up by the breeze from a passing subway train in the film "The Seven Year Itch" (1955).
Business ventures.
In 1979, she opened her own dance studio in North Hollywood. In 1983 Reynolds released an exercise video titled "Do It Debbie's Way!".
She purchased the Clarion Hotel and Casino, a hotel and casino in Las Vegas, in 1992 and renamed it the "Debbie Reynolds Hollywood Hotel", but it was not a success. In 1997, Reynolds was forced to declare bankruptcy. In June 2010 she replaced Ivana Trump answering reader queries for the weekly paper "Globe".
Marriages and later life.
Reynolds has been married three times. Her first marriage was to singer Eddie Fisher in 1955. They are the parents of Carrie and Todd Fisher. The couple divorced in 1959 when Fisher had an affair with Elizabeth Taylor shortly after the death of Taylor's then-husband Mike Todd, which caused a serious public scandal. In 2011, first on "The Oprah Winfrey Show" only weeks before Elizabeth Taylor's death from congestive heart failure, Reynolds explained that she and Taylor happened to be traveling on the ocean liner "Queen Elizabeth" at the same time when they made up. Reynolds sent a note to Taylor's room, and Taylor sent a note in reply asking to have dinner with Reynolds and end their feud. The two reconciled, and, as Reynolds put it, "...we had a wonderful evening with a lot of laughs". The 1990 film "Postcards from the Edge" was written by her daughter Carrie Fisher and was semi-autobiographical, with the character of "Doris Mann" based on Reynolds.
Her second marriage, to millionaire businessman Harry Karl, lasted from 1960 to 1973. He was previously married to Marie McDonald. Reynolds later found herself in financial difficulty because of Karl's gambling and bad investments.
Reynolds was married to real estate developer Richard Hamlett from 1984 to 1996. In 2010, she appeared in her own West End show "Debbie Reynolds: Alive and Fabulous". Since 1955, Reynolds has been active in The Thalians, a charitable organization, devoted to children and adults with mental health issues. In 2011 she stepped down after 56 years of involvement, and is now an emerita member.
Reynolds was hospitalized in October 2012 at Cedars-Sinai Medical Center in Los Angeles, due to an adverse reaction to medication. She canceled appearances and concert engagements for the next three months.
Filmography.
Short subjects:
Stage work.
Reynolds made her Broadway debut in 1973 in a revival of "Irene", a musical first produced 60 years before. For that production, she received a Tony nomination. She toured with Harve Presnell in "Annie Get Your Gun", then wrapped up the Broadway run of "Woman of the Year" in 1983. In the late 1980s, Reynolds repeated her role as Molly Brown in the stage version of "The Unsinkable Molly Brown", first opposite Presnell (repeating his original Broadway and movie role) and later with Ron Raines.
Awards and honors.
Reynolds was the 1955 Hasty Pudding Woman of the Year. Her foot and hand prints are preserved at the Grauman's Chinese Theatre in Hollywood, California. She also has a star on the Hollywood Walk of Fame at 6654 Hollywood Boulevard for live performance and a Golden Palm Star on the Palm Springs, California, Walk of Stars dedicated to her. In keeping with the celebrity tradition of the Shenandoah Apple Blossom Festival of Winchester, Virginia, Reynolds was honored as the Grand Marshal of the 2011 ABF that took place from April 26 to May 1, 2011.
In November 2006, Reynolds received the "Lifetime Achievement Award" from Chapman University (Orange, California). On May 17, 2007, she was awarded an honorary degree of Doctor of Humane Letters from the University of Nevada, Reno, (Reno, Nevada) where she had contributed for many years to the film-studies program.
See Also

</doc>
<doc id="70317" url="https://en.wikipedia.org/wiki?curid=70317" title="Kiss Me, Kate">
Kiss Me, Kate

Kiss Me, Kate is a musical written by Samuel and Bella Spewack with music and lyrics by Cole Porter.
The story involves the production of a musical version of William Shakespeare's "The Taming of the Shrew" and the conflict on and off-stage between Fred Graham, the show's director, producer, and star, and his leading lady, his ex-wife Lilli Vanessi. A secondary romance concerns Lois Lane, the actress playing Bianca, and her gambler boyfriend, Bill, who runs afoul of some gangsters. The original production starred Alfred Drake, Patricia Morison, Lisa Kirk and Harold Lang and won the Tony-Award.
"Kiss Me, Kate" was Porter's response to Rodgers and Hammerstein's "Oklahoma!" and other integrated musicals; it was the first show he wrote in which the music and lyrics were firmly connected to the script, and it proved to be his biggest hit and the only one of his shows to run for more than 1,000 performances on Broadway. In 1949, it won the first Tony Award presented for Best Musical.
On March 25, 2015 it was announced that the 1949 original cast recording will be inducted into the Library of Congress's National Recording Registry for the album's "cultural, artistic and/or historical significance to American society and the nation’s audio legacy".
Inspiration.
The musical was inspired by the on-stage/off-stage battling of husband-and-wife actors Alfred Lunt and Lynn Fontanne during their 1935 production of "Shrew", witnessed by future Broadway producer Arnold Saint-Subber. In 1947 he asked the Spewacks (undergoing their own marital woes at the time) to write the script; Bella Spewack in turn enlisted Cole Porter to write the music and lyrics.
Productions.
Original Broadway production.
After a 3½-week pre-Broadway tryout at the Shubert Theatre in Philadelphia starting December 2, 1948, the original Broadway production opened on December 30, 1948, at the New Century Theatre, where it ran for nineteen months before transferring to the Shubert, for a total run of 1,077 performances. Directed by John C. Wilson with choreography by Hanya Holm, the original cast included Alfred Drake, Patricia Morison, Lisa Kirk, Harold Lang, Charles Wood and Harry Clark.
Original London production.
The original West End production opened on March 8, 1951 at the Coliseum Theatre, and ran for 400 performances. Directed by Sam Spewack with choreography again by Holm, this production starred Patricia Morison, Bill Johnson, Adelaide Hall and Julie Wilson.
1970 London revival.
A London revival opened in December 1970 at the London Coliseum, in a production by the Sadler's Wells Opera. The cast featured Emile Belcourt (Petruchio), Judith Bruce, Eric Shilling, Ann Howard (Kate), Francis Egerton, Robert Lloyd, with direction by Peter Coe and choreography by Sheila O'Neill. Coe did a translation for British audiences, including having "a tea wagon", and included "traditional English music hall jokes". This revival had a "brief run", according to the "Encyclopedia of the Musical Theatre".
1987 London revival.
The Royal Shakespeare Company staged a production at London's Old Vic Theatre, which opened 19 May 1987. Directed by Adrian Noble and staged by Ron Field, the production starred Nichola McAuliffe and Paul Jones as Lilli/Kate and Fred/Petruchio, with Tim Flavin and Fiona Hendley as Bill/Lucentio and Lois/Bianca. The gangsters were played by Emil Wolk and John Bardon. The cast recorded a CD album which is available on First Night Records in their Cast Masters range.
1999 Broadway revival.
A Broadway revival opened at the Martin Beck Theatre on November 18, 1999 and closed on December 30, 2001 after 881 performances and 28 previews. Directed by Michael Blakemore and choreographed by Kathleen Marshall and Rob Ashford, the opening night cast included Marin Mazzie, Brian Stokes Mitchell, Amy Spanger, Michael Berresse, Ron Holgate, Lee Wilkof, and Michael Mulheren. This production won the Tony Awards for Best Revival of a Musical and Best Actor in a Musical for Mitchell; Marin Mazzie received a Tony nomination for Best Actress in a Musical, and Michael Berresse, Lee Wilkof and Michael Mulheren received Tony nominations for Best Featured Actor in a Musical.
2001 London revival.
A West End revival opened at the Victoria Palace Theatre on October 30, 2001, and closed on August 24, 2002. As with the 1999 Broadway revival, Michael Blakemore was the director with choreography by Kathleen Marshall. Brent Barrett and Marin Mazzie co-starred.
2012 London revival.
Chichester Festival Theatre's 2012 revival of the show transferred to the Old Vic Theatre on London's South Bank in November 2012, with an official opening in December. It starred Hannah Waddingham as Lili/Kate and Alex Bourne as Fred Graham. The production was directed by Trevor Nunn. The show received positive reviews from critics and audiences. Hannah Waddingham and Alex Bourne were both nominated for the 2013 Olivier Awards as Best Actress/Actor in a Musical for their performances.
Plot.
Act I
The cast of a musical version of William Shakespeare's "The Taming of the Shrew" is rehearsing for the opening of the show that evening ("Another Op'nin', Another Show"). Egotistical Fred Graham is the director and producer and is starring as Petruchio, and his movie-star ex-wife, Lilli Vanessi, is playing Katherine. The two seem to be constantly arguing, and Lilli is particularly angry that Fred is pursuing the sexy young actress Lois Lane, who is playing Bianca. After the rehearsal, Lois's boyfriend Bill appears; he is playing Lucentio, but he missed the rehearsal because he was gambling. He tells her that he signed a $10,000 IOU in Fred's name, and Lois reprimands him ("Why Can't You Behave?").
Before the opening, Fred and Lilli meet backstage, and Lilli shows off her engagement ring from Washington insider Harrison Howell, reminding Fred that it's the anniversary of their divorce. They recall the operetta in which they met, which included "Wunderbar", a Viennese waltz; they end up fondly reminiscing and singing and dancing. Two gangsters show up to collect the $10,000 IOU, and Fred replies that he never signed it. The gangsters obligingly say they will give him time to remember it and will return later. In her dressing room, Lilli receives flowers from Fred, and she declares that she is still "So In Love" with him. Fred tries to keep Lilli from reading the card that came with the flowers, which reveals that he really intended them for Lois. However, Lilli takes the card with her onstage, saying she will read it later.
The show begins ("We Open in Venice"). Baptista, Katherine and Bianca's father, will not allow his younger daughter Bianca to marry until his older daughter Katherine is married. However, she is shrewish and ill-tempered, and no man desires to marry her. Three suitors - Lucentio, Hortensio, and Gremio - try to woo Bianca, and she says that she would marry any of them ("Tom, Dick, or Harry"). Petruchio, a friend of Lucentio, expresses a desire to marry into wealth ("I've Come to Wive it Wealthily in Padua"). The suitors hatch a plan for him to marry Kate, as Baptista is rich. Kate, however, has no intentions of getting married ("I Hate Men"). Petruchio attempts to woo her ("Were Thine That Special Face"). Offstage, Lilli has an opportunity to read the card. She walks on stage off-cue and begins hitting Fred, who, along with the other actors, tries to remain in character as Baptista gives Petruchio permission to marry Kate. Lilli continues to strike Fred, and he ends up spanking her. Offstage, Lilli furiously declares she is leaving the show. However, the gangsters have reappeared, and Fred tells them that if Lilli quits, he'll have to close the show and won't be able to pay them the $10,000. The gangsters force her to stay at gunpoint. Back onstage, Bianca and Lucentio dance while the chorus performs "We Sing of Love", covering a scene change. The curtain opens, revealing the exterior of a church; Petruchio and Kate have just been married, and they exit the church; the gangsters, dressed in Shakespearean costume, are onstage to make sure that Lilli stays. Petruchio implores for Kate to kiss him, and she refuses. He lifts her over his shoulder and carries her offstage while she pummels his shoulder with her fists ("Kiss Me Kate").
Act II
During the show's intermission, the cast and crew relax in the alley behind the theater. Paul (Fred's assistant), along with a couple other crew members, lament that it's "Too Darn Hot" to meet their lovers that night. The play continues, and Petruchio tries to 'tame' Katherine and mourns for his now-lost bachelor life ("Where Is the Life That Late I Led?"). Off-stage, Lilli's fiancé Harrison Howell is looking for Lilli. He runs into Lois, and she recognizes him as a former lover but promises not to tell Lilli. Bill is shocked to overhear this, but Lois tells him that even if she is involved with other men, she is faithful to him in her own way ("Always True to You in My Fashion"). Lilli tries to explain to Howell that she is being forced to stay at the theatre by the gangsters, but Howell doesn't believe her and wants to discuss wedding plans. Fred insidiously points out how boring Lilli's life with Howell will be compared to the theatre. Bill sings a love song he has written for Lois ("Bianca").
The gangsters discover that their boss has been killed, so the IOU is no longer valid. Lilli leaves—without Howell—as Fred unsuccessfully tries to convince her to stay ("So in Love" (Reprise)). The gangsters get caught on stage and improvise a tribute to Shakespeare in which they explain that knowing Shakespeare is the key to romance ("Brush Up Your Shakespeare"). The company prepares for the conclusion of the play, the wedding of Bianca and Lucentio, even though they are now missing one of the main characters. However, just in time for Katherine's final speech, Lilli arrives onstage ("I Am Ashamed That Women Are So Simple"). Fred and Lilli wordlessly reconcile on stage, and the play ends ("Kiss Me Kate" (Finale)) with them, as well as Bill and Lois, kissing passionately.
Song list.
Act I
Act II
Notes
Film and television.
A film version of the same name was released in 1953. There have been at least four television productions, the first on "Hallmark Hall of Fame" in 1958, with Drake and Morison reprising their Broadway roles, the second recorded for the launch of BBC Two in the UK in 1964, starring Howard Keel, Patricia Morison and Millicent Martin, the third in 1968 with then husband-and-wife team Robert Goulet and Carol Lawrence, and the fourth in 2003 on "Great Performances", a high-definition shot performance of the London revival with Brent Barrett and Rachel York.

</doc>
<doc id="70318" url="https://en.wikipedia.org/wiki?curid=70318" title="Sound film">
Sound film

A sound film is a motion picture with synchronized sound, or sound technologically coupled to image, as opposed to a silent film. The first known public exhibition of projected sound films took place in Paris in 1900, but decades passed before sound motion pictures were made commercially practical. Reliable synchronization was difficult to achieve with the early sound-on-disc systems, and amplification and recording quality were also inadequate. Innovations in sound-on-film led to the first commercial screening of short motion pictures using the technology, which took place in 1923.
The primary steps in the commercialization of sound cinema were taken in the mid- to late 1920s. At first, the sound films incorporating synchronized dialogue—known as "talking pictures", or "talkies"—were exclusively shorts; the earliest feature-length movies with recorded sound included only music and effects. The first feature film originally presented as a talkie was "The Jazz Singer", released in October 1927. A major hit, it was made with Vitaphone, which was at the time the leading brand of sound-on-disc technology. Sound-on-film, however, would soon become the standard for talking pictures.
By the early 1930s, the talkies were a global phenomenon. In the United States, they helped secure Hollywood's position as one of the world's most powerful cultural/commercial systems (see Cinema of the United States). In Europe (and, to a lesser degree, elsewhere), the new development was treated with suspicion by many filmmakers and critics, who worried that a focus on dialogue would subvert the unique aesthetic virtues of soundless cinema. In Japan, where the popular film tradition integrated silent movie and live vocal performance, talking pictures were slow to take root. In India, sound was the transformative element that led to the rapid expansion of the nation's film industry.
History.
Early steps.
The idea of combining motion pictures with recorded sound is nearly as old as the concept of cinema itself. On February 27, 1888, a couple of days after photographic pioneer Eadweard Muybridge gave a lecture not far from the laboratory of Thomas Edison, the two inventors privately met. Muybridge later claimed that on this occasion, six years before the first commercial motion picture exhibition, he proposed a scheme for sound cinema that would combine his image-casting zoopraxiscope with Edison's recorded-sound technology. No agreement was reached, but within a year Edison commissioned the development of the Kinetoscope, essentially a "peep-show" system, as a visual complement to his cylinder phonograph. The two devices were brought together as the Kinetophone in 1895, but individual, cabinet viewing of motion pictures was soon to be outmoded by successes in film projection. In 1899, a projected sound-film system known as Cinemacrophonograph or Phonorama, based primarily on the work of Swiss-born inventor François Dussaud, was exhibited in Paris; similar to the Kinetophone, the system required individual use of earphones. An improved cylinder-based system, Phono-Cinéma-Théâtre, was developed by Clément-Maurice Gratioulet and Henri Lioret of France, allowing short films of theater, opera, and ballet excerpts to be presented at the Paris Exposition in 1900. These appear to be the first publicly exhibited films with projection of both image and recorded sound. Phonorama and yet another sound-film system—Théâtroscope—were also presented at the Exposition.
Three major problems persisted, leading to motion pictures and sound recording largely taking separate paths for a generation. The primary issue was synchronization: pictures and sound were recorded and played back by separate devices, which were difficult to start and maintain in tandem. Sufficient playback volume was also hard to achieve. While motion picture projectors soon allowed film to be shown to large theater audiences, audio technology before the development of electric amplification could not project satisfactorily to fill large spaces. Finally, there was the challenge of recording fidelity. The primitive systems of the era produced sound of very low quality unless the performers were stationed directly in front of the cumbersome recording devices (acoustical horns, for the most part), imposing severe limits on the sort of films that could be created with live-recorded sound.
Cinematic innovators attempted to cope with the fundamental synchronization problem in a variety of ways. An increasing number of motion picture systems relied on gramophone records—known as sound-on-disc technology; the records themselves were often referred to as "Berliner discs", after one of the primary inventors in the field, German-American Emile Berliner. In 1902, Léon Gaumont demonstrated his sound-on-disc Chronophone, involving an electrical connection he had recently patented, to the French Photographic Society. Four years later, Gaumont introduced the Elgéphone, a compressed-air amplification system based on the Auxetophone, developed by British inventors Horace Short and Charles Parsons. Despite
high expectations, Gaumont's sound innovations had only limited commercial success—though improvements, they still did not satisfactorily address the three basic issues with sound film and were expensive as well. For some years, American inventor E. E. Norton's Cameraphone was the primary competitor to the Gaumont system (sources differ on whether the Cameraphone was disc- or cylinder-based); it ultimately failed for many of the same reasons that held back the Chronophone.
In 1913, Edison introduced a new cylinder-based synch-sound apparatus known, just like his 1895 system, as the Kinetophone; instead of films being shown to individual viewers in the Kinetoscope cabinet, they were now projected onto a screen. The phonograph was connected by an intricate arrangement of pulleys to the film projector, allowing—under ideal conditions—for synchronization. However, conditions were rarely ideal, and the new, improved Kinetophone was retired after little more than a year. By the mid-1910s, the groundswell in commercial sound motion picture exhibition had subsided. Beginning in 1914, "The Photo-Drama of Creation", promoting Jehovah's Witnesses' conception of mankind's genesis, was screened around the United States: eight hours worth of projected visuals involving both slides and live action were synchronized with separately recorded lectures and musical performances played back on phonograph.
Meanwhile, innovations continued on another significant front. In 1907, French-born, London-based Eugene Lauste—who had worked at Edison's lab between 1886 and 1892—was awarded the first patent for sound-on-film technology, involving the transformation of sound into light waves that are photographically recorded direct onto celluloid. As described by historian Scott Eyman,
It was a double system, that is, the sound was on a different piece of film from the picture... In essence, the sound was captured by a microphone and translated into light waves via a light valve, a thin ribbon of sensitive metal over a tiny slit. The sound reaching this ribbon would be converted into light by the shivering of the diaphragm, focusing the resulting light waves through the slit, where it would be photographed on the side of the film, on a strip about a tenth of an inch wide.
Though sound-on-film would eventually become the universal standard for synchronized sound cinema, Lauste never successfully exploited his innovations, which came to an effective dead end. In 1914, Finnish inventor Eric Tigerstedt was granted German patent 309,536 for his sound-on-film work; that same year, he apparently demonstrated a film made with the process to an audience of scientists in Berlin. Hungarian engineer Denes Mihaly submitted his sound-on-film Projectofon concept to the Royal Hungarian Patent Court in 1918; the patent award was published four years later. Whether sound was captured on cylinder, disc, or film, none of the available technology was adequate for big-league commercial purposes, and for many years the heads of the major Hollywood film studios saw little benefit in producing sound motion pictures.
Crucial innovations.
A number of technological developments contributed to making sound cinema commercially viable by the late 1920s. Two involved contrasting approaches to synchronized sound reproduction, or playback:
Advanced sound-on-film.
In 1919, American inventor Lee De Forest was awarded several patents that would lead to the first optical sound-on-film technology with commercial application. In De Forest's system, the sound track was photographically recorded onto the side of the strip of motion picture film to create a composite, or "married", print. If proper synchronization of sound and picture was achieved in recording, it could be absolutely counted on in playback. Over the next four years, he improved his system with the help of equipment and patents licensed from another American inventor in the field, Theodore Case.
At the University of Illinois, Polish-born research engineer Joseph Tykociński-Tykociner was working independently on a similar process. On June 9, 1922, he gave the first reported U.S. demonstration of a sound-on-film motion picture to members of the American Institute of Electrical Engineers. As with Lauste and Tigerstedt, Tykociner's system would never be taken advantage of commercially; however, De Forest's soon would.
On April 15, 1923, at New York City's Rivoli Theater, came the first commercial screening of motion pictures with sound-on-film, the future standard: a set of shorts under the banner of De Forest Phonofilms, accompanying a silent feature. That June, De Forest entered into an extended legal battle with an employee, Freeman Harrison Owens, for title to one of the crucial Phonofilm patents. Although De Forest ultimately won the case in the courts, Owens is today recognized as a central innovator in the field. The following year, De Forest's studio released the first commercial dramatic film shot as a talking picture—the two-reeler "Love's Old Sweet Song", directed by J. Searle Dawley and featuring Una Merkel. However, phonofilm's stock in trade was not original dramas but celebrity documentaries, popular music acts, and comedy performances. President Calvin Coolidge, opera singer Abbie Mitchell, and vaudeville stars such as Phil Baker, Ben Bernie, Eddie Cantor and Oscar Levant appeared in the firm's pictures. Hollywood remained suspicious, even fearful, of the new technology. As "Photoplay" editor James Quirk put it in March 1924, "Talking pictures are perfected, says Dr. Lee De Forest. "So" is castor oil." De Forest's process continued to be used through 1927 in the United States for dozens of short Phonofilms; in the UK it was employed a few years longer for both shorts and features by British Sound Film Productions, a subsidiary of British Talking Pictures, which purchased the primary Phonofilm assets. By the end of 1930, the Phonofilm business would be liquidated.
In Europe, others were also working on the development of sound-on-film. In 1919, the same year that DeForest received his first patents in the field, three German inventors patented the Tri-Ergon sound system. On September 17, 1922, the Tri-Ergon group gave a public screening of sound-on-film productions—including a dramatic talkie, "Der Brandstifter" ("The Arsonist") —before an invited audience at the Alhambra Kino in Berlin. By the end of the decade, Tri-Ergon would be the dominant European sound system. In 1923, two Danish engineers, Axel Petersen and Arnold Poulsen, patented a system that recorded sound on a separate filmstrip running parallel with the image reel. Gaumont licensed the technology and briefly put it to commercial use under the name Cinéphone.
Domestic competition, however, eclipsed Phonofilm. By September 1925, De Forest and Case's working arrangement had fallen through. The following July, Case joined Fox Film, Hollywood's third largest studio, to found the Fox-Case Corporation. The system developed by Case and his assistant, Earl Sponable, given the name Movietone, thus became the first viable sound-on-film technology controlled by a Hollywood movie studio. The following year, Fox purchased the North American rights to the Tri-Ergon system, though the company found it inferior to Movietone and virtually impossible to integrate the two different systems to advantage. In 1927, as well, Fox retained the services of Freeman Owens, who had particular expertise in constructing cameras for synch-sound film.
Advanced sound-on-disc.
Parallel with improvements in sound-on-film technology, a number of companies were making progress with systems that recorded movie sound on phonograph discs. In sound-on-disc technology from the era, a phonograph turntable is connected by a mechanical interlock to a specially modified film projector, allowing for synchronization. In 1921, the Photokinema sound-on-disc system developed by Orlando Kellum was employed to add synchronized sound sequences to D. W. Griffith's failed silent film "Dream Street". A love song, performed by star Ralph Graves, was recorded, as was a sequence of live vocal effects. Apparently, dialogue scenes were also recorded, but the results were unsatisfactory and the film was never publicly screened incorporating them. On May 1, 1921, "Dream Street" was re-released, with love song added, at New York City's Town Hall theater, qualifying it—however haphazardly—as the first feature-length film with a live-recorded vocal sequence. There would be no others for more than six years.
In 1925, Sam Warner of Warner Bros., then a small Hollywood studio with big ambitions, saw a demonstration of the Western Electric sound-on-disc system and was sufficiently impressed to persuade his brothers to agree to experiment with using this system at New York's Vitagraph Studios, which they had recently purchased. The tests were convincing to the Warner Brothers, if not to the executives of some other picture companies who witnessed them. Consequently, in April 1926 the Western Electric Company entered into a contract with Warner Brothers and W. J. Rich, a financier, giving them an exclusive license for recording and reproducing sound pictures under the Western Electric system. To exploit this license the Vitaphone Corporation was organized with Samuel L. Warner as its president.
Vitaphone, as this system was now called, was publicly introduced on August 6, 1926, with the premiere of the nearly three-hour-long "Don Juan"; the first feature-length movie to employ a synchronized sound system of any type throughout, its soundtrack contained a musical score and added sound effects, but no recorded dialogue—in other words, it had been staged and shot as a silent film. Accompanying "Don Juan", however, were eight shorts of musical performances, mostly classical, as well as a four-minute filmed introduction by Will H. Hays, president of the Motion Picture Association of America, all with live-recorded sound. These were the first true sound films exhibited by a Hollywood studio. Warner Bros.' "The Better 'Ole", technically similar to "Don Juan", followed in October.
Sound-on-film would ultimately win out over sound-on-disc because of a number of fundamental technical advantages:
Nonetheless, in the early years, sound-on-disc had the edge over sound-on-film in two substantial ways:
As sound-on-film technology improved, both of these disadvantages were overcome.
The third crucial set of innovations marked a major step forward in both the live recording of sound and its effective playback:
Fidelity electronic recording and amplification.
In 1913, Western Electric, the manufacturing division of AT&T, acquired the rights to the de Forest audion, the forerunner of the triode vacuum tube. Over the next few years they developed it into a predictable and reliable device that made electronic amplification possible for the first time. Western Electric then branched-out into developing uses for the vacuum tube including public address systems and an electrical recording system for the recording industry. Beginning in 1922, the research branch of Western Electric began working intensively on recording technology for both sound-on-disc and sound-on film synchronised sound systems for motion-pictures.
The engineers working on the sound-on-disc system were able to draw on expertise that Western Electric already had in electrical disc recording and were thus able to make faster initial progress. The main change required was to increase the playing time of the disc so that it could match that of a standard reel of 35 mm film. The chosen design used a disc measuring rotating at 33 1/3 rpm. This could play for 11 minutes, the running time of 1000 ft of film at 90 ft/min (24 frames/s). Because of the larger diameter the minimum groove velocity of 70 ft/min (14 inches or 356 mm/s) was only slightly less than that of a standard 10-inch 78 rpm commercial disc.
In 1925, the company publicly introduced a greatly improved system of electronic audio, including sensitive condenser microphones and rubber-line recorders (named after the use of a rubber damping band for recording with better frequency response onto a wax master disk). That May, the company licensed entrepreneur Walter J. Rich to exploit the system for commercial motion pictures; he founded Vitagraph, in which Warner Bros. acquired a half interest, just one month later. In April 1926, Warners signed a contract with AT&T for exclusive use of its film sound technology for the redubbed Vitaphone operation, leading to the production of "Don Juan" and its accompanying shorts over the following months. During the period when Vitaphone had exclusive access to the patents, the fidelity of recordings made for Warners films was markedly superior to those made for the company's sound-on-film competitors. Meanwhile, Bell Labs—the new name for the AT&T research operation—was working at a furious pace on sophisticated sound amplification technology that would allow recordings to be played back over loudspeakers at theater-filling volume. The new moving-coil speaker system was installed in New York's Warners Theatre at the end of July and its patent submission, for what Western Electric called the No. 555 Receiver, was filed on August 4, just two days before the premiere of "Don Juan".
Late in the year, AT&T/Western Electric created a licensing division, Electrical Research Products Inc. (ERPI), to handle rights to the company's film-related audio technology. Vitaphone still had legal exclusivity, but having lapsed in its royalty payments, effective control of the rights was in ERPI's hands. On December 31, 1926, Warners granted Fox-Case a sublicense for the use of the Western Electric system; in exchange for the sublicense, both Warners and ERPI received a share of Fox's related revenues. The patents of all three concerns were cross-licensed. Superior recording and amplification technology was now available to two Hollywood studios, pursuing two very different methods of sound reproduction. The new year would finally see the emergence of sound cinema as a significant commercial medium.
Triumph of the "talkies".
In February 1927, an agreement was signed by five leading Hollywood movie companies: Famous Players Lasky (soon to be part of Paramount), Metro-Goldwyn-Mayer, Universal, First National, and Cecil B. DeMille's small but prestigious Producers Distributing Corporation (PDC). The five studios agreed to collectively select just one provider for sound conversion. The alliance then sat back and waited to see what sort of results the forerunners came up with. In May, Warner Bros. sold back its exclusivity rights to ERPI (along with the Fox-Case sublicense) and signed a new royalty contract similar to Fox's for use of Western Electric technology. As Fox and Warners pressed forward with sound cinema in different directions, both technologically and commercially—Fox with newsreels and then scored dramas, Warners with talking features—so did ERPI, which sought to corner the market by signing up the five allied studios.
The big sound film sensations of the year all took advantage of preexisting celebrity. On May 20, 1927, at New York's Roxy Theater, Fox Movietone presented a sound film of the takeoff of Charles Lindbergh's celebrated flight to Paris, recorded earlier that day. In June, a Fox sound newsreel depicting his return welcomes in New York and Washington, D.C., was shown. These were the two most acclaimed sound motion pictures to date. In May, as well, Fox had released the first Hollywood fiction film with synchronized dialogue: the short "They're Coming to Get Me", starring comedian Chic Sale. After rereleasing a few silent feature hits, such as "Seventh Heaven", with recorded music, Fox came out with its first original Movietone feature on September 23: "Sunrise", by acclaimed German director F. W. Murnau. As with "Don Juan", the film's soundtrack consisted of a musical score and sound effects (including, in a couple of crowd scenes, "wild", nonspecific vocals).
Then, on October 6, 1927, Warner Bros.' "The Jazz Singer" premiered. It was a smash box office success for the mid-level studio, earning a total of $2.625 million in the United States and abroad, almost a million dollars more than the previous record for a Warners film. Produced with the Vitaphone system, most of the film does not contain live-recorded audio, relying, like "Sunrise" and "Don Juan", on a score and effects. When the movie's star, Al Jolson, sings, however, the film shifts to sound recorded on the set, including both his musical performances and two scenes with ad-libbed speech—one of Jolson's character, Jakie Rabinowitz (Jack Robin), addressing a cabaret audience; the other an exchange between him and his mother. The "natural" sounds of the settings were also audible. Though the success of "The Jazz Singer" was due largely to Jolson, already established as one of America's biggest music stars, and its limited use of synchronized sound hardly qualified it as an innovative sound film (let alone the "first"), the movie's profits were proof enough to the industry that the technology was worth investing in.
The development of commercial sound cinema had proceeded in fits and starts before "The Jazz Singer", and the film's success did not change things overnight. Not until May 1928 did the group of four big studios (PDC had dropped out of the alliance), along with United Artists and others, sign with ERPI for conversion of production facilities and theaters for sound film. Initially, all ERPI-wired theaters were made Vitaphone-compatible; most were equipped to project Movietone reels as well. However, even with access to both technologies, most of the Hollywood companies remained slow to produce talking features of their own. No studio besides Warner Bros. released even a part-talking feature until the low-budget-oriented Film Booking Offices of America (FBO) premiered "The Perfect Crime" on June 17, 1928, eight months after "The Jazz Singer". FBO had come under the effective control of a Western Electric competitor, General Electric's RCA division, which was looking to market its new sound-on-film system, Photophone. Unlike Fox-Case's Movietone and De Forest's Phonofilm, which were variable-density systems, Photophone was a variable-area system—a refinement in the way the audio signal was inscribed on film that would ultimately become the standard. (In both sorts of systems, a specially-designed lamp, whose exposure to the film is determined by the audio input, is used to record sound photographically as a series of minuscule lines. In a variable-density process, the lines are of varying darkness; in a variable-area process, the lines are of varying width.) By October, the FBO-RCA alliance would lead to the creation of Hollywood's newest major studio, RKO Pictures.
Meanwhile, Warner Bros. had released three more talkies, all profitable, if not at the level of "The Jazz Singer": In March, "Tenderloin" appeared; it was billed by Warners as the first feature in which characters spoke their parts, though only 15 of its 88 minutes had dialogue. "Glorious Betsy" followed in April, and "The Lion and the Mouse" (31 minutes of dialogue) in May. On July 6, 1928, the first all-talking feature, "Lights of New York", premiered. The film cost Warner Bros. only $23,000 to produce, but grossed $1.252 million, a record rate of return surpassing 5,000%. In September, the studio released another Al Jolson part-talking picture, "The Singing Fool", which more than doubled "The Jazz Singer"'s earnings record for a Warners movie. This second Jolson screen smash demonstrated the movie musical's ability to turn a song into a national hit: inside of nine months, the Jolson number "Sonny Boy" had racked up 2 million record and 1.25 million sheet music sales. September 1928 also saw the release of Paul Terry's "Dinner Time", among the first animated cartoons produced with synchronized sound. Soon after he saw it, Walt Disney released his first sound picture, the Mickey Mouse short "Steamboat Willie".
Over the course of 1928, as Warner Bros. began to rake in huge profits due to the popularity of its sound films, the other studios quickened the pace of their conversion to the new technology. Paramount, the industry leader, put out its first talkie in late September, "Beggars of Life"; though it had just a few lines of dialogue, it demonstrated the studio's recognition of the new medium's power. "Interference", Paramount's first all-talker, debuted in November. The process known as "goat glanding" briefly became widespread: soundtracks, sometimes including a smatter of post-dubbed dialogue or song, were added to movies that had been shot, and in some cases released, as silents. A few minutes of singing could qualify such a newly endowed film as a "musical." (Griffith's "Dream Street" had essentially been a "goat gland.") Expectations swiftly changed, and the sound "fad" of 1927 became standard procedure by 1929. In February 1929, sixteen months after "The Jazz Singer"'s debut, Columbia Pictures became the last of the eight studios that would be known as "majors" during Hollywood's Golden Age to release its first part-talking feature, "Lone Wolf's Daughter". In late May, the first all-color, all-talking feature, Warner Bros.' "On with the Show!", premiered.
Yet most American movie theaters, especially outside of urban areas, were still not equipped for sound: while the number of sound cinemas grew from 100 to 800 between 1928 and 1929, they were still vastly outnumbered by silent theaters, which had actually grown in number as well, from 22,204 to 22,544. The studios, in parallel, were still not entirely convinced of the talkies' universal appeal—through mid-1930, the majority of Hollywood movies were produced in dual versions, silent as well as talking. Though few in the industry predicted it, silent film as a viable commercial medium in the United States would soon be little more than a memory. "Points West", a Hoot Gibson Western released by Universal Pictures in August 1929, was the last purely silent mainstream feature put out by a major Hollywood studio.
Transition: Europe.
"The Jazz Singer" had its European sound premiere at the Piccadilly Theatre in London on September 27, 1928. According to film historian Rachael Low, "Many in the industry realized at once that a change to sound production was inevitable." On January 16, 1929, the first European feature film with a synchronized vocal performance and recorded score premiered: the German production "Ich küsse Ihre Hand, Madame" ("I Kiss Your Hand, Madame"). Dialogueless, it contains only a few songs performed by Richard Tauber. The movie was made with the sound-on-film system controlled by the German-Dutch firm Tobis, corporate heirs to the Tri-Ergon concern. With an eye toward commanding the emerging European market for sound film, Tobis entered into a compact with its chief competitor, Klangfilm, a joint subsidiary of Germany's two leading electrical manufacturers. Early in 1929, Tobis and Klangfilm began comarketing their recording and playback technologies. As ERPI began to wire theaters around Europe, Tobis-Klangfilm claimed that the Western Electric system infringed on the Tri-Ergon patents, stalling the introduction of American technology in many places. Just as RCA had entered the movie business to maximize its recording system's value, Tobis also established its own production operations.
During 1929, most of the major European filmmaking countries began joining Hollywood in the changeover to sound. Many of the trend-setting European talkies were shot abroad as production companies leased studios while their own were being converted or as they deliberately targeted markets speaking different languages. One of Europe's first two feature-length dramatic talkies was created in still a different sort of twist on multinational moviemaking: "The Crimson Circle" was a coproduction between director Friedrich Zelnik's Efzet-Film company and British Sound Film Productions (BSFP). In 1928, the film had been released as the silent "Der Rote Kreis" in Germany, where it was shot; English dialogue was apparently dubbed in much later using the De Forest Phonofilm process controlled by BSFP's corporate parent. It was given a British trade screening in March 1929, as was a part-talking film made entirely in the UK: "The Clue of the New Pin", a British Lion production using the sound-on-disc British Photophone system. In May, "Black Waters", a British and Dominions Film Corporation promoted as the first UK all-talker, received its initial trade screening; it had been shot completely in Hollywood with a Western Electric sound-on-film system. None of these pictures made much impact.
The first successful European dramatic talkie was the all-British "Blackmail". Directed by twenty-nine-year-old Alfred Hitchcock, the movie had its London debut June 21, 1929. Originally shot as a silent, "Blackmail" was restaged to include dialogue sequences, along with a score and sound effects, before its premiere. A British International Pictures (BIP) production, it was recorded on RCA Photophone, General Electric having bought a share of AEG so they could access the Tobis-Klangfilm markets. "Blackmail" was a substantial hit; critical response was also positive—notorious curmudgeon Hugh Castle, for example, called it "perhaps the most intelligent mixture of sound and silence we have yet seen."
On August 23, the modest-sized Austrian film industry came out with a talkie: "G’schichten aus der Steiermark" ("Stories from Styria"), an Eagle Film–Ottoton Film production. On September 30, the first entirely German-made feature-length dramatic talkie, "Das Land ohne Frauen" ("Land Without Women"), premiered. A Tobis Filmkunst production, about one-quarter of the movie contained dialogue, which was strictly segregated from the special effects and music. The response was underwhelming. Sweden's first talkie, "Konstgjorda Svensson" ("Artificial Svensson"), premiered on October 14. Eight days later, Aubert Franco-Film came out with "Le Collier de la reine" ("The Queen's Necklace"), shot at the Épinay studio near Paris. Conceived as a silent film, it was given a Tobis-recorded score and a single talking sequence—the first dialogue scene in a French feature. On October 31, "Les Trois masques" debuted; a Pathé-Natan film, it is generally regarded as the initial French feature talkie, though it was shot, like "Blackmail", at the Elstree studio, just outside London. The production company had contracted with RCA Photophone and Britain then had the nearest facility with the system. The Braunberger-Richebé talkie "La Route est belle", also shot at Elstree, followed a few weeks later.
Before the Paris studios were fully sound-equipped—a process that stretched well into 1930—a number of other early French talkies were shot in Germany. The first all-talking German feature, "Atlantik", had premiered in Berlin on October 28. Yet another Elstree-made movie, it was rather less German at heart than "Les Trois masques" and "La Route est belle" were French; a BIP production with a British scenarist and German director, it was also shot in English as "Atlantic". The entirely German Aafa-Film production "It's You I Have Loved" ("Dich hab ich geliebt") opened three-and-a-half weeks later. It was not "Germany's First Talking Film", as the marketing had it, but it was the first to be released in the United States.
In 1930, the first Polish talkies premiered, using sound-on-disc systems: "Moralność pani Dulskiej" ("The Morality of Mrs. Dulska") in March and the all-talking "Niebezpieczny romans" ("Dangerous Love Affair") in October. In Italy, whose once vibrant film industry had become moribund by the late 1920s, the first talkie, "La Canzone dell'amore" ("The Song of Love"), also came out in October; within two years, Italian cinema would be enjoying a revival. The first movie spoken in Czech debuted in 1930 as well, "Tonka Šibenice" ("Tonka of the Gallows"). Several European nations with minor positions in the field also produced their first talking pictures—Belgium (in French), Denmark, Greece, and Romania. The Soviet Union's robust film industry came out with its first sound features in December 1930: Dziga Vertov's nonfiction "Entuziazm" had an experimental, dialogueless soundtrack; Abram Room's documentary "Plan velikikh rabot" ("The Plan of the Great Works") had music and spoken voiceovers. Both were made with locally developed sound-on-film systems, two of the two hundred or so movie sound systems then available somewhere in the world. In June 1931, the Nikolai Ekk drama "Putevka v zhizn" ("The Road to Life" or "A Start in Life"), premiered as the Soviet Union's first true talking picture.
Throughout much of Europe, conversion of exhibition venues lagged well behind production capacity, requiring talkies to be produced in parallel silent versions or simply shown without sound in many places. While the pace of conversion was relatively swift in Britain—with over 60 percent of theaters equipped for sound by the end of 1930, similar to the U.S. figure—in France, by contrast, more than half of theaters nationwide were still projecting in silence by late 1932. According to scholar Colin G. Crisp, "Anxiety about resuscitating the flow of silent films was frequently expressed in the industrial press, and a large section of the industry still saw the silent as a viable artistic and commercial prospect till about 1935." The situation was particularly acute in the Soviet Union; as of May 1933, fewer than one out of every hundred film projectors in the country was as yet equipped for sound.
Transition: Asia.
During the 1920s and 1930s, Japan was one of the world's two largest producers of motion pictures, along with the United States. Though the country's film industry was among the first to produce both sound and talking features, the full changeover to sound proceeded much more slowly than in the West. It appears that the first Japanese sound film, "Reimai" ("Dawn"), was made in 1926 with the De Forest Phonofilm system. Using the sound-on-disc Minatoki system, the leading Nikkatsu studio produced a pair of talkies in 1929: "Taii no musume" ("The Captain's Daughter") and "Furusato" ("Hometown"), the latter directed by Kenji Mizoguchi. The rival Shochiku studio began the successful production of sound-on-film talkies in 1931 using a variable-density process called Tsuchibashi. Two years later, however, more than 80 percent of movies made in the country were still silents. Two of the country's leading directors, Mikio Naruse and Yasujiro Ozu, did not make their first sound films until 1935 and 1936, respectively. As late as 1938, over a third of all movies produced in Japan were shot without dialogue.
The enduring popularity of the silent medium in Japanese cinema owed in great part to the tradition of the "benshi", a live narrator who performed as accompaniment to a film screening. As director Akira Kurosawa later described, the benshi "not only recounted the plot of the films, they enhanced the emotional content by performing the voices and sound effects and providing evocative descriptions of events and images on the screen... The most popular narrators were stars in their own right, solely responsible for the patronage of a particular theatre." Film historian Mariann Lewinsky argues,
The end of silent film in the West and in Japan was imposed by the industry and the market, not by any inner need or natural evolution... Silent cinema was a highly pleasurable and fully mature form. It didn't lack anything, least in Japan, where there was always the human voice doing the dialogues and the commentary. Sound films were not better, just more economical. As a cinema owner you didn't have to pay the wages of musicians and benshi any more. And a good benshi was a star demanding star payment.
By the same token, the viability of the benshi system facilitated a gradual transition to sound—allowing the studios to spread out the capital costs of conversion and their directors and technical crews time to become familiar with the new technology.
The Mandarin-language "Gēnǚ hóng mǔdān" (, "Singsong Girl Red Peony"), starring Butterfly Wu, premiered as China's first feature talkie in 1930. By February of that year, production was apparently completed on a sound version of "The Devil's Playground", arguably qualifying it as the first Australian talking motion picture; however, the May press screening of Commonwealth Film Contest prizewinner "Fellers" is the first verifiable public exhibition of an Australian talkie. In September 1930, a song performed by Indian star Sulochana, excerpted from the silent feature "Madhuri" (1928), was released as a synchronized-sound short, the country's first. The following year, Ardeshir Irani directed the first Indian talking feature, the Hindi-Urdu "Alam Ara", and produced "Kalidas", primarily in Tamil with some Telugu. Nineteen-thirty-one also saw the first Bengali-language film, "Jamai Sasthi", and the first movie fully spoken in Telugu, "Bhakta Prahlada". In 1932, "Ayodhyecha Raja" became the first movie in which Marathi was spoken to be released (though "Sant Tukaram" was the first to go through the official censorship process); the first Gujarati-language film, "Narsimha Mehta", and all-Tamil talkie, "Kalava", debuted as well. The next year, Ardeshir Irani produced the first Persian-language talkie, "Dukhtar-e-loor". Also in 1933, the first Cantonese-language films were produced in Hong Kong—"Sha zai dongfang" ("The Idiot's Wedding Night") and "Liang xing" ("Conscience"); within two years, the local film industry had fully converted to sound. Korea, where "pyonsa" (or "byun-sa") held a role and status similar to that of the Japanese benshi, in 1935 became the last country with a significant film industry to produce its first talking picture: "Chunhyangjeon" (/) is based on the seventeenth-century pansori folktale "Chunhyangga", of which as many as fifteen film versions have been made through 2009.
Consequences.
Technology.
In the short term, the introduction of live sound recording caused major difficulties in production. Cameras were noisy, so a soundproofed cabinet was used in many of the earliest talkies to isolate the loud equipment from the actors, at the expense of a drastic reduction in the ability to move the camera. For a time, multiple-camera shooting was used to compensate for the loss of mobility and innovative studio technicians could often find ways to liberate the camera for particular shots. The necessity of staying within range of still microphones meant that actors also often had to limit their movements unnaturally. "Show Girl in Hollywood" (1930), from First National Pictures (which Warner Bros. had taken control of thanks to its profitable adventure into sound), gives a behind-the-scenes look at some of the techniques involved in shooting early talkies. Several of the fundamental problems caused by the transition to sound were soon solved with new camera casings, known as "blimps", designed to suppress noise and boom microphones that could be held just out of frame and moved with the actors. In 1931, a major improvement in playback fidelity was introduced: three-way speaker systems in which sound was separated into low, medium, and high frequencies and sent respectively to a large bass "woofer", a midrange driver, and a treble "tweeter."
There were consequences, as well, for other technological aspects of the cinema. Proper recording and playback of sound required exact standardization of camera and projector speed. Before sound, 16 frames per second (fps) was the supposed norm, but practice varied widely. Cameras were often undercranked or overcranked to improve exposures or for dramatic effect. Projectors were commonly run too fast to shorten running time and squeeze in extra shows. Variable frame rate, however, made sound unlistenable, and a new, strict standard of 24 fps was soon established. Sound also forced the abandonment of the noisy arc lights used for filming in studio interiors. The switch to quiet incandescent illumination in turn required a switch to more expensive film stock. The sensitivity of the new panchromatic film delivered superior image tonal quality and gave directors the freedom to shoot scenes at lower light levels than was previously practical.
As David Bordwell describes, technological improvements continued at a swift pace: "Between 1932 and 1935, Electric and RCA created directional microphones, increased the frequency range of film recording, reduced ground noise ... and extended the volume range." These technical advances often meant new aesthetic opportunities: "Increasing the fidelity of recording ... heightened the dramatic possibilities of vocal timbre, pitch, and loudness." Another basic problem—famously spoofed in the 1952 film "Singin' in the Rain"—was that some silent-era actors simply did not have attractive voices; though this issue was frequently overstated, there were related concerns about general vocal quality and the casting of performers for their dramatic skills in roles also requiring singing talent beyond their own. By 1935, rerecording of vocals by the original or different actors in postproduction, a process known as "looping", had become practical. The ultraviolet recording system introduced by RCA in 1936 improved the reproduction of sibilants and high notes.
With Hollywood's wholesale adoption of the talkies, the competition between the two fundamental approaches to sound-film production was soon resolved. Over the course of 1930–31, the only major players using sound-on-disc, Warner Bros. and First National, changed over to sound-on-film recording. Vitaphone's dominating presence in sound-equipped theaters, however, meant that for years to come all of the Hollywood studios pressed and distributed sound-on-disc versions of their films alongside the sound-on-film prints. Fox Movietone soon followed Vitaphone into disuse as a recording and reproduction method, leaving two major American systems: the variable-area RCA Photophone and Western Electric's own variable-density process, a substantial improvement on the cross-licensed Movietone. Under RCA's instigation, the two parent companies made their projection equipment compatible, meaning films shot with one system could be screened in theaters equipped for the other. This left one big issue—the Tobis-Klangfilm challenge. In May 1930, Western Electric won an Austrian lawsuit that voided protection for certain Tri-Ergon patents, helping bring Tobis-Klangfilm to the negotiating table. The following month an accord was reached on patent cross-licensing, full playback compatibility, and the division of the world into three parts for the provision of equipment. As a contemporary report describes:
Tobis-Klangfilm has the exclusive rights to provide equipment for: Germany, Danzig, Austria, Hungary, Switzerland, Czechoslovakia, Holland, the Dutch Indies, Denmark, Sweden, Norway, Bulgaria, Romania, Yugoslavia, and Finland. The Americans have the exclusive rights for the United States, Canada, Australia, New Zealand, India, and Russia. All other countries, among them Italy, France, and England, are open to both parties.
The agreement did not resolve all the patent disputes, and further negotiations were undertaken and concords signed over the course of the 1930s. During these years, as well, the American studios began abandoning the Western Electric system for RCA Photophone's variable-area approach—by the end of 1936, only Paramount, MGM, and United Artists still had contracts with ERPI.
Labor.
While the introduction of sound led to a boom in the motion picture industry, it had an adverse effect on the employability of a host of Hollywood actors of the time. Suddenly those without stage experience were regarded as suspect by the studios; as suggested above, those whose heavy accents or otherwise discordant voices had previously been concealed were particularly at risk. The career of major silent star Norma Talmadge effectively came to an end in this way. The celebrated German actor Emil Jannings returned to Europe. Moviegoers found John Gilbert's voice an awkward match with his swashbuckling persona, and his star also faded. Audiences now seemed to perceive certain silent-era stars as old-fashioned, even those who had the talent to succeed in the sound era. The career of Harold Lloyd, one of the top screen comedians of the 1920s, declined precipitously. Lillian Gish departed, back to the stage, and other leading figures soon left acting entirely: Colleen Moore, Gloria Swanson, and Hollywood's most famous performing couple, Douglas Fairbanks and Mary Pickford. As actress Louise Brooks suggested, there were other issues as well:
Studio heads, now forced into unprecedented decisions, decided to begin with the actors, the least palatable, the most vulnerable part of movie production. It was such a splendid opportunity, anyhow, for breaking contracts, cutting salaries, and taming the stars... Me, they gave the salary treatment. I could stay on without the raise my contract called for, or quit, studio chief B. P. Schulberg said, using the questionable dodge of whether I'd be good for the talkies. Questionable, I say, because I spoke decent English in a decent voice and came from the theater. So without hesitation I quit.
Similarly, Clara Bow's speaking voice was sometimes blamed for the demise of her Hollywood career, though the real issues involved her clashes with studio executives and what film historian David Thomson describes as the "backlash of bourgeois hypocrisy" against a lifestyle that would have been unremarkable for a male star. Buster Keaton was eager to explore the new medium, but when his studio, MGM, made the changeover to sound, he was quickly stripped of creative control. Though a number of Keaton's early talkies made impressive profits, they were artistically dismal.
Several of the new medium's biggest attractions came from vaudeville and the musical theater, where performers such as Jolson, Eddie Cantor, Jeanette MacDonald, and the Marx Brothers were accustomed to the demands of both dialogue and song. James Cagney and Joan Blondell, who had teamed on Broadway, were brought west together by Warner Bros. in 1930. A few actors were major stars during both the silent and the sound eras: Richard Barthelmess, Clive Brook, Bebe Daniels, Norma Shearer, the comedy team of Stan Laurel and Oliver Hardy, and the incomparable Charlie Chaplin, whose "City Lights" (1931) and "Modern Times" (1936) employed sound almost exclusively for music and effects. Janet Gaynor became a top star with the synch-sound but dialogueless "Seventh Heaven" and "Sunrise", as did Joan Crawford with the technologically similar "Our Dancing Daughters" (1928). Greta Garbo was the one non–native English speaker to retain Hollywood stardom on both sides of the great sound divide. The new emphasis on speech also caused producers to hire many novelists, journalists, and playwrights with experience writing good dialogue. Among those who became Hollywood scriptwriters during the 1930s were Nathanael West, William Faulkner, Robert Sherwood, Aldous Huxley, and Dorothy Parker.
As talking pictures emerged, with their prerecorded musical tracks, an increasing number of moviehouse orchestra musicians found themselves out of work. More than just their position as film accompanists was usurped; according to historian Preston J. Hubbard, "During the 1920s live musical performances at first-run theaters became an exceedingly important aspect of the American cinema." With the coming of the talkies, those featured performances—usually staged as preludes—were largely eliminated as well. The American Federation of Musicians took out newspaper advertisements protesting the replacement of live musicians with mechanical playing devices. One 1929 ad that appeared in the "Pittsburgh Press" features an image of a can labeled "Canned Music / Big Noise Brand / Guaranteed to Produce No Intellectual or Emotional Reaction Whatever" and reads in part:
Canned Music on Trial
This is the case of Art vs. Mechanical Music in theatres. The defendant stands accused in front of the American people of attempted corruption of musical appreciation and discouragement of musical education. Theatres in many cities are offering synchronised mechanical music as a substitute for Real Music. If the theatre-going public accepts this vitiation of its entertainment program a deplorable decline in the Art of Music is inevitable. Musical authorities know that the soul of the Art is lost in mechanisation. It cannot be otherwise because the quality of music is dependent on the mood of the artist, upon the human contact, without which the essence of intellectual stimulation and emotional rapture is lost.
Is Music Worth Saving? No great volume of evidence is required to answer this question. Music is a well-nigh universally beloved art. From the beginning of history, men have turned to musical expression to lighten the burdens of life, to make them happier. Aborigines, lowest in the scale of savagery, chant their song to tribal gods and play upon pipes and shark-skin drums. Musical development has kept pace with good taste and ethics throughout the ages, and has influenced the gentler nature of man more powerfully perhaps than any other factor. Has it remained for the Great Age of Science to snub the Art by setting up in its place a pale and feeble shadow of itself?
</ref>
By the following year, a reported 22,000 U.S. moviehouse musicians had lost their jobs.
Commerce.
In September 1926, Jack L. Warner, head of Warner Bros., was quoted to the effect that talking pictures would never be viable: "They fail to take into account the international language of the silent pictures, and the unconscious share of each onlooker in creating the play, the action, the plot, and the imagined dialogue for himself." Much to his company's benefit, he would be proven very wrong—between the 1927–28 and 1928–29 fiscal years, Warners' profits surged from $2 million to $14 million. Sound film, in fact, was a clear boon to all the major players in the industry. During that same twelve-month span, Paramount's profits rose by $7 million, Fox's by $3.5 million, and Loew's/MGM's by $3 million. RKO, which hadn't even existed in September 1928 and whose parent production company, FBO, was in the Hollywood minor leagues, by the end of 1929 was established as one of America's leading entertainment businesses. Fueling the boom was the emergence of an important new cinematic genre made possible by sound: the musical. Over sixty Hollywood musicals were released in 1929, and more than eighty the following year.
Even as the Wall Street crash of October 1929 helped plunge the United States and ultimately the global economy into depression, the popularity of the talkies at first seemed to keep Hollywood immune. The 1929–30 exhibition season was even better for the motion picture industry than the previous, with ticket sales and overall profits hitting new highs. Reality finally struck later in 1930, but sound had clearly secured Hollywood's position as one of the most important industrial fields, both commercially and culturally, in the United States. In 1929, film box-office receipts comprised 16.6 percent of total spending by Americans on recreation; by 1931, the figure had reached 21.8 percent. The motion picture business would command similar figures for the next decade and a half. Hollywood ruled on the larger stage, as well. The American movie industry—already the world's most powerful—set an export record in 1929 that, by the applied measure of total feet of exposed film, was 27 percent higher than the year before. Concerns that language differences would hamper U.S. film exports turned out to be largely unfounded. In fact, the expense of sound conversion was a major obstacle to many overseas producers, relatively undercapitalized by Hollywood standards. The production of multiple versions of export-bound talkies in different languages (known as "Foreign Language Version"), as well as the production of the cheaper "International Sound Version", a common approach at first, largely ceased by mid-1931, replaced by post-dubbing and subtitling. Despite trade restrictions imposed in most foreign markets, by 1937, American films commanded about 70 percent of screen time around the globe.
Just as the leading Hollywood studios gained from sound in relation to their foreign competitors, they did the same at home. As historian Richard B. Jewell describes, "The sound revolution crushed many small film companies and producers who were unable to meet the financial demands of sound conversion." The combination of sound and the Great Depression led to a wholesale shakeout in the business, resulting in the hierarchy of the Big Five integrated companies (MGM, Paramount, Fox, Warners, RKO) and the three smaller studios also called "majors" (Columbia, Universal, United Artists) that would predominate through the 1950s. Historian Thomas Schatz describes the ancillary effects:
Because the studios were forced to streamline operations and rely on their own resources, their individual house styles and corporate personalities came into much sharper focus. Thus the watershed period from the coming of sound into the early Depression saw the studio system finally coalesce, with the individual studios coming to terms with their own identities and their respective positions within the industry.
The other country in which sound cinema had an immediate major commercial impact was India. As one distributor of the period said, "With the coming of the talkies, the Indian motion picture came into its own as a definite and distinctive piece of creation. This was achieved by music." From its earliest days, Indian sound cinema has been defined by the musical—"Alam Ara" featured seven songs; a year later, "Indrasabha" would feature seventy. While the European film industries fought an endless battle against the popularity and economic muscle of Hollywood, ten years after the debut of "Alam Ara", over 90 percent of the films showing on Indian screens were made within the country.
Most of India's early talkies were shot in Bombay, which remains the leading production center, but sound filmmaking soon spread across the multilingual nation. Within just a few weeks of "Alam Ara"'s March 1931 premiere, the Calcutta-based Madan Pictures had released both the Hindi "Shirin Farhad" and the Bengali "Jamai Sasthi". The Hindustani "Heer Ranjha" was produced in Lahore, Punjab, the following year. In 1934, "Sati Sulochana", the first Kannada talking picture to be released, was shot in Kolhapur, Maharashtra; "Srinivasa Kalyanam" became the first Tamil talkie actually shot in Tamil Nadu. Once the first talkie features appeared, the conversion to full sound production happened as rapidly in India as it did in the United States. Already by 1932, the majority of feature productions were in sound; two years later, 164 of the 172 Indian feature films were talking pictures. Since 1934, with the sole exception of 1952, India has been among the top three movie-producing countries in the world every single year.
Aesthetic quality.
In the first, 1930 edition of his global survey "The Film Till Now", British cinema pundit Paul Rotha declared, "A film in which the speech and sound effects are perfectly synchronised and coincide with their visual image on the screen is absolutely contrary to the aims of cinema. It is a degenerate and misguided attempt to destroy the real use of the film and cannot be accepted as coming within the true boundaries of the cinema." Such opinions were not rare among those who cared about cinema as an art form; Alfred Hitchcock, though he directed the first commercially successful talkie produced in Europe, held that "the silent pictures were the purest form of cinema" and scoffed at many early sound films as delivering little beside "photographs of people talking". In Germany, Max Reinhardt, stage producer and movie director, expressed the belief that the talkies, "bringing to the screen stage plays ... tend to make this independent art a subsidiary of the theater and really make it only a substitute for the theater instead of an art in itself ... like reproductions of paintings."
In the opinion of many film historians and aficionados, both at the time and subsequently, silent film had reached an aesthetic peak by the late 1920s and the early years of sound cinema delivered little that was comparable to the best of the silents. For instance, despite fading into relative obscurity once its era had passed, silent cinema is represented by eleven films in "Time Out"'s Centenary of Cinema Top One Hundred poll, held in 1995. The first year in which sound film production predominated over silent film—not only in the United States, but also in the West as a whole—was 1929; yet the years 1929 through 1933 are represented by three dialogueless pictures ("Pandora's Box" "Zemlya" [1930, "City Lights" ) and zero talkies in the "Time Out" poll. ("City Lights", like "Sunrise", was released with a recorded score and sound effects, but is now customarily referred to by historians and industry professionals as a "silent"—spoken dialogue regarded as the crucial distinguishing factor between silent and sound dramatic cinema.) The earliest sound film to place is the French "L'Atalante" (1934), directed by Jean Vigo; the earliest Hollywood sound film to qualify is "Bringing Up Baby" (1938), directed by Howard Hawks.
The first sound feature film to receive near-universal critical approbation was "Der Blaue Engel" ("The Blue Angel"); premiering on April 1, 1930, it was directed by Josef von Sternberg in both German and English versions for Berlin's UFA studio. The first American talkie to be widely honored was "All Quiet on the Western Front", directed by Lewis Milestone, which premiered April 21. The other internationally acclaimed sound drama of the year was "Westfront 1918", directed by G. W. Pabst for Nero-Film of Berlin. Historian Anton Kaes points to it as an example of "the new verisimilitude rendered silent cinema's former emphasis on the hypnotic gaze and the symbolism of light and shadow, as well as its preference for allegorical characters, anachronistic." Cultural historians consider the French "L'Âge d'Or", directed by Luis Buñuel, which appeared late in 1930, to be of great aesthetic import; at the time, its erotic, blasphemous, anti-bourgeois content caused a scandal. Swiftly banned by Paris police chief Jean Chiappe, it was unavailable for fifty years. The earliest sound movie now acknowledged by most film historians as a masterpiece is Nero-Film's "M", directed by Fritz Lang, which premiered May 11, 1931. As described by Roger Ebert, "Many early talkies felt they had to talk all the time, but Lang allows his camera to prowl through the streets and dives, providing a rat's-eye view."
Cinematic form.
"Talking film is as little needed as a singing book." Such was the blunt proclamation of critic Viktor Shklovsky, one of the leaders of the Russian formalist movement, in 1927. While some regarded sound as irreconcilable with film art, others saw it as opening a new field of creative opportunity. The following year, a group of Soviet filmmakers, including Sergei Eisenstein, proclaimed that the use of image and sound in juxtaposition, the so-called contrapuntal method, would raise the cinema to "...unprecedented power and cultural height. Such a method for constructing the sound-film will not confine it to a national market, as must happen with the photographing of plays, but will give a greater possibility than ever before for the circulation throughout the world of a filmically expressed idea." So far as one segment of the audience was concerned, however, the introduction of sound brought a virtual end to such circulation: Elizabeth C. Hamilton writes, "Silent films offered people who were deaf a rare opportunity to participate in a public discourse, cinema, on equal terms with hearing people. The emergence of sound film effectively separated deaf from hearing audience members once again."
On March 12, 1929, the first feature-length talking picture made in Germany had its premiere. The inaugural Tobis Filmkunst production, it was not a drama, but a documentary sponsored by a shipping line: "Melodie der Welt" ("Melody of the World"), directed by Walter Ruttmann. This was also perhaps the first feature film anywhere to significantly explore the artistic possibilities of joining the motion picture with recorded sound. As described by scholar William Moritz, the movie is "intricate, dynamic, fast-paced ... juxtapos similar cultural habits from countries around the world, with a superb orchestral score ... and many synchronized sound effects." Composer Lou Lichtveld was among a number of contemporary artists struck by the film: ""Melodie der Welt" became the first important sound documentary, the first in which musical and unmusical sounds were composed into a single unit and in which image and sound are controlled by one and the same impulse." "Melodie der Welt" was a direct influence on the industrial film "Philips Radio" (1931), directed by Dutch avant-garde filmmaker Joris Ivens and scored by Lichtveld, who described its audiovisual aims:
To render the half-musical impressions of factory sounds in a complex audio world that moved from absolute music to the purely documentary noises of nature. In this film every intermediate stage can be found: such as the movement of the machine interpreted by the music, the noises of the machine dominating the musical background, the music itself is the documentary, and those scenes where the pure sound of the machine goes solo.
Many similar experiments were pursued by Dziga Vertov in his 1931 "Entuziazm" and by Chaplin in "Modern Times", a half-decade later.
A few innovative commercial directors immediately saw the ways in which sound could be employed as an integral part of cinematic storytelling, beyond the obvious function of recording speech. In "Blackmail", Hitchcock manipulated the reproduction of a character's monologue so the word "knife" would leap out from a blurry stream of sound, reflecting the subjective impression of the protagonist, who is desperate to conceal her involvement in a fatal stabbing. In his first film, the Paramount "Applause" (1929), Rouben Mamoulian created the illusion of acoustic depth by varying the volume of ambient sound in proportion to the distance of shots. At a certain point, Mamoulian wanted the audience to hear one character singing at the same time as another prays; according to the director, "They said we couldn't record the two things—the song and the prayer—on one mike and one channel. So I said to the sound man, 'Why not use two mikes and two channels and combine the two tracks in printing?'" Such methods would eventually become standard procedure in popular filmmaking.
One of the first commercial films to take full advantage of the new opportunities provided by recorded sound was "Le Million", directed by René Clair and produced by Tobis's French division. Premiering in Paris in April 1931 and New York a month later, the picture was both a critical and popular success. A musical comedy with a barebones plot, it is memorable for its formal accomplishments, in particular, its emphatically artificial treatment of sound. As described by scholar Donald Crafton,
"Le Million" never lets us forget that the acoustic component is as much a construction as the whitewashed sets. replaced dialogue with actors singing and talking in rhyming couplets. Clair created teasing confusions between on- and off-screen sound. He also experimented with asynchronous audio tricks, as in the famous scene in which a chase after a coat is synched to the cheers of an invisible football (or rugby) crowd.
These and similar techniques became part of the vocabulary of the sound comedy film, though as special effects and "color", not as the basis for the kind of comprehensive, non-naturalistic design achieved by Clair. Outside of the comedic field, the sort of bold play with sound exemplified by "Melodie der Welt" and "Le Million" would be pursued very rarely in commercial production. Hollywood, in particular, incorporated sound into a reliable system of genre-based moviemaking, in which the formal possibilities of the new medium were subordinated to the traditional goals of star affirmation and straightforward storytelling. As accurately predicted in 1928 by Frank Woods, secretary of the Academy of Motion Picture Arts and Sciences, "The talking pictures of the future will follow the general line of treatment heretofore developed by the silent drama... The talking scenes will require different handling, but the general construction of the story will be much the same."

</doc>
<doc id="70322" url="https://en.wikipedia.org/wiki?curid=70322" title="Suffrage">
Suffrage

Suffrage, political franchise, or simply franchise is the right to vote in public, political elections (although the term is sometimes used for any right to vote). The right to run for office is sometimes called "candidate eligibility", and the combination of both rights is sometimes called "full suffrage". In many languages, the right to vote is called the "active right to vote" and the right to run for office is called the "passive right to vote". In English, these are sometimes called "active suffrage" and "passive suffrage".
Suffrage is often conceived in terms of elections for representatives. However, suffrage applies equally to referenda and initiatives. Suffrage describes not only the legal right to vote, but also the practical question of whether a question will be put to a vote. The utility of suffrage is reduced when important questions are decided unilaterally by elected or non-elected representatives.
In most democracies, eligible voters can vote in elections of representatives. Voting on issues by referendum may also be available. For example, in Switzerland this is permitted at all levels of government. In the United States, some states such as California and Washington have exercised their shared sovereignty to offer citizens the opportunity to write, propose, and vote on referendums and initiatives; other states have not. The United States federal government does not offer any initiatives at all.
Suffrage is granted to qualifying citizens once they have reached the voting age. What constitutes a qualifying citizen depends on the government's decision, but most democracies no longer extend differing rights to vote on the basis of sex or race. Resident non-citizens can vote in some countries, which may be restricted to citizens of closely-linked countries (e.g., Commonwealth citizens and European Union citizens).
Etymology.
The word "suffrage" comes from Latin "suffragium", meaning "vote", "political support", and "the right to vote". The etymology of the Latin word is uncertain, with some sources citing Latin "suffragari" "lend support, vote for someone", from "sub" "under" + "fragor" "crash, din, shouts (as of approval)", related to "frangere" "to break" (related to "fraction"). Other sources say that attempts to connect "suffragium" with "fragor" cannot be taken seriously. Some etymologists think the word may be related to "suffrago" and may have originally meant an ankle bone or knuckle bone.
Types.
Universal suffrage.
Where universal suffrage exists, the right to vote is not restricted by sex, race, social status, education level, or wealth. It typically does not extend a right to vote to all residents of a region; distinctions are frequently made in regard to citizenship, age, and occasionally mental capacity or criminal convictions.
The short-lived Corsican Republic (1755–1769) was the first country to grant limited universal suffrage for all inhabitants over the age of 25. This was followed by other experiments in the Paris Commune of 1871 and the island republic of Franceville (1889). In 1893, New Zealand became the first major nation to practice universal suffrage, and the Freedom in the World index lists New Zealand as the only free country in the world in 1893. In 1906, Finland became the second country in the world, and the first in Europe, to grant universal suffrage to its citizens. At this time, however, women in New Zealand did not have the right to run for office. In 1906, Finland became the first country in the world to grant women full political rights.
Women's suffrage.
Women's suffrage is the right of women to vote on the same terms as men. This was the goal of the suffragists in the United States and the suffragettes in Great Britain. Short-lived suffrage equity was drafted into provisions of the State of New Jersey's first, 1776 Constitution, which extended the Right to Vote to unwed female landholders & Black land owners.
However, the document did not specify an Amendment procedure, and the provision was subsequently replaced in 1844 by the adoption of the succeeding constitution, which reverted to "all white male" suffrage restrictions.
Limited voting rights were gained by some women in Sweden, Britain, and some western U.S. states in the 1860s. In 1893, the British colony of New Zealand became the first self-governing nation to extend the right to vote to all adult women. In 1894 the women of South Australia achieved the right to both vote "and" stand for Parliament. The autonomous Grand Duchy of Finland in the Russian Empire was the first nation to allow all women to both vote and run for parliament.
Equal suffrage.
Equal suffrage is sometimes confused with "Universal suffrage", although the meaning of the former is the removal of graded votes, wherein a voter could possess a number of votes in accordance with income, wealth or social status.
Census suffrage.
Also known as "censitary suffrage", the opposite of "equal suffrage," meaning that the votes cast by those eligible to vote are not equal, but are weighed differently according to the person's rank in the census (e.g., people with high incomes have more votes than those with a small income, or a stockholder in a company with more shares has more votes than someone with fewer shares). Suffrage may therefore be limited, usually to the propertied classes.
Compulsory suffrage.
Where compulsory suffrage exists, those who are eligible to vote are required by law to do so. Thirty-two countries currently practice this form of suffrage.
Business vote.
In local government in England and some of its ex-colonies, businesses formerly had, and in some places still have, a vote in the urban area in which they paid rates. This is an extension of the historical property-based franchise from natural persons to other legal persons. In the United Kingdom, the Corporation of the City of London retains business votes, as the City of London is a major financial centre with few residents. The first issue taken up by the Northern Ireland civil rights movement was the business vote, abolished in 1968. In cities in most Australian states, voting is optional for businesses but compulsory for individuals.
Forms of exclusion from suffrage.
Religion.
In the aftermath of the Reformation it was common in European countries for people of disfavored religious denominations to be denied civil and political rights, often including the right to vote, to stand for election or to sit in parliament. In Great Britain and Ireland, Roman Catholics were denied the right to vote from 1728 to 1793, and the right to sit in parliament until 1829. The anti-Catholic policy was justified on the grounds that the loyalty of Catholics supposedly lay with the Pope rather than the national monarch.
In England and Ireland, several Acts practically disenfranchised non-Anglicans or non-Protestants by imposing an oath before admission to vote or to stand for office. The 1672 and 1678 Test Acts forbade non-Anglicans to hold public offices, and the 1727 Disenfranchising Act took away Catholics' voting rights in Ireland, which were restored only in 1788. Jews could not even be naturalized. An attempt was made to change this situation, but the Jewish Naturalization Act 1753 provoked such reactions that it was repealed the following year. Nonconformists (Methodists and Presbyterians) were only allowed to run for election to the British House of Commons starting in 1828, Catholics in 1829 (following the Catholic Relief Act 1829, which extended the Roman Catholic Relief Act 1791), and Jews in 1858 (with the Emancipation of the Jews in England). Benjamin Disraeli could only begin his political career in 1837 because he had been converted to Anglicanism at the age of 12.
In several states in the U.S. after the Declaration of Independence, Jews, Quakers or Catholics were denied voting rights and/or forbidden to run for office. The Delaware Constitution of 1776 stated that "Every person who shall be chosen a member of either house, or appointed to any office or place of trust, before taking his seat, or entering upon the execution of his office, shall (…) also make and subscribe the following declaration, to wit: "I, A B. do profess faith in God the Father, and in Jesus Christ His only Son, and in the Holy Ghost, one God, blessed for evermore; and I do acknowledge the holy scriptures of the Old and New Testament to be given by divine inspiration."" This was repealed by article I, section 2 of the 1792 Constitution: "No religious test shall be required as a qualification to any office, or public trust, under this State". The 1778 Constitution of the State of South Carolina stated that "No person shall be eligible to sit in the house of representatives unless he be of the Protestant religion", the 1777 Constitution of the State of Georgia (art. VI) that "The representatives shall be chosen out of the residents in each county (…) and they shall be of the Protestent "(sic)" religion". In Maryland, voting rights and eligibility were extended to Jews in 1828.
In Canada, several religious groups (Mennonites, Hutterites, Doukhobors) were disenfranchised by the wartime Elections Act of 1917, mainly because they opposed military service. This disenfranchisement ended with the closure of the First World War, but was renewed for Doukhobors from 1934 (via the "Dominion Elections Act") to 1955.
The first Constitution of modern Romania in 1866 provided in article 7 that only Christians could become Romanian citizens. Jews native to Romania were declared stateless persons. In 1879, under pressure from the Berlin Peace Conference, this article was amended, granting non-Christians the right to become Romanian citizens, but naturalization was granted on a case-by-case basis and was subject to Parliamentary approval. An application took over ten years to process. Only in 1923 was a new constitution adopted, whose article 133 extended Romanian citizenship to all Jewish residents and equality of rights to all Romanian citizens.
In the Republic of Maldives, only Muslim citizens have voting rights and are eligible for parliamentary elections. On 25 November 2011, the UN human rights chief called on Maldivian authorities to remove the discriminatory constitutional provision that requires that every citizen be a Muslim.
Wealth, tax class, social class.
Until the nineteenth century, many Western proto-democracies had property qualifications in their electoral laws; e.g. only landowners could vote (because the only tax for such countries was the property tax), or the voting rights were weighted according to the amount of taxes paid (as in the Prussian three-class franchise). Most countries abolished the property qualification for national elections in the late nineteenth century, but retained it for local government elections for several decades. Today these laws have largely been abolished, although the homeless may not be able to register because they lack regular addresses.
In the United Kingdom, until the House of Lords Act 1999, peers who were members of the House of Lords were excluded from voting for the House of Commons because they were not commoners. In Britain and some other monarchies, the sovereign is ineligible to vote in parliamentary elections.
Knowledge.
Sometimes the right to vote has been limited to people who had achieved a certain level of education or passed a certain test, e.g. "literacy tests" in some states of the U.S.
Race.
Various countries, usually countries with a dominant race within a wider population, have historically denied the vote to people of particular races, or to all but the dominant race. This has been achieved in a number of ways:
In New Zealand the Maori have been enfranchised effectively since 1865 at the conclusion of the Maori War. Maori still have the choice of voting in a general (all race) electorate or a solely Maori electorate. 
Age.
All modern democracies require voters to meet age qualifications to vote. Worldwide voting ages are not consistent, differing between countries and even within countries, though the range usually varies between 16 and 21 years. Demeny voting would extend voting rights to everyone including children regardless of age. The movement to lower the voting age is known as the Youth rights movement.
Criminality.
Many countries restrict the voting rights of convicted criminals. Some countries, and some U.S. states, also deny the right to vote to those convicted of serious crimes even once they are released from prison. In some cases (e.g. the felony disenfranchisement laws found in many U.S. states) the denial of the right to vote is automatic upon a felony conviction; in other cases (e.g. France and Germany) deprivation of the vote is meted out separately, and often limited to perpetrators of specific crimes such as those against the electoral system or corruption of public officials. In the Republic of Ireland, prisoners are allowed the right to vote, following the "Hirst v UK (No2)" ruling, which was granted in 2006. Canada allowed only prisoners serving a term of less than 2 years the right to vote, but this was found to be unconstitutional in 2002 by the Supreme Court of Canada in "Sauvé v. Canada (Chief Electoral Officer)", and all prisoners have been allowed to vote as of the 2004 Canadian federal election.
Residency.
Under certain electoral systems elections are held within subnational jurisdictions, thus preventing persons from voting who would otherwise be eligible on the basis that they do not reside within such a jurisdiction, or because they live in an area that cannot participate. In the United States, residents of Washington, D.C. receive no voting representation in Congress, although they do have full representation in presidential elections, based on the Twenty-third Amendment to the United States Constitution adopted in 1961. Residents of Puerto Rico enjoy neither.
Sometimes citizens become ineligible to vote because they are no longer resident in their country of citizenship. For example, Australian citizens who have been outside Australia for more than one and fewer than six years may excuse themselves from the requirement to vote in Australian elections while they remain outside Australia (voting in Australia is compulsory for resident citizens).
Danish citizens that reside permanently outside Denmark lose their right to vote.
In some cases, a certain period of residence in a locality may required for the right to vote in that location. For example, in the United Kingdom up to 2001, each 15 February a new electoral register came into effect, based on registration as of the previous 10 October, with the effect of limiting voting to those resident five to seventeen months earlier depending on the timing of the election.
Nationality.
In most countries, suffrage is limited to citizens and, in many cases, permanent residents of that country. However, some members of supra-national organisations such as the Commonwealth of Nations and the European Union have granted voting rights to citizens of all countries within that organisation. Until the mid-twentieth century, many Commonwealth countries gave the vote to all British citizens within the country, regardless of whether they were normally resident there. In most cases this was because there was no distinction between British and local citizenship. Several countries qualified this with restrictions preventing non-white British citizens such as Indians and British Africans from voting. Under European Union law, citizens of European Union countries can vote in each other's local and European Parliament elections on the same basis as citizens of the country in question, but usually not in national elections.
Naturalization.
In some countries, naturalized citizens do not have the right to vote or to be a candidate, either permanently or for a determined period.
Article 5 of the 1831 Belgian Constitution made a difference between ordinary naturalization, and "grande naturalisation". Only (former) foreigners who had been granted "grande naturalisation" were entitled to vote, be a candidate for parliamentary elections, or be appointed minister. However, ordinary naturalized citizens could vote for municipal elections. Ordinary naturalized citizens and citizens who had acquired Belgian nationality through marriage could vote, but not run as candidates for parliamentary elections in 1976. The concepts of ordinary and grande naturalization were suppressed from the Constitution in 1991.
In France, the 1889 Nationality Law barred those who had acquired the French nationality by naturalization or marriage from voting, and from eligibility and access to several public jobs. In 1938 the delay was reduced to five years. needed These instances of discrimination, as well as others against naturalized citizens, were gradually abolished in 1973 (9 January 1973 law) and 1983.
In Morocco, a former French protectorate, and in Guinea, a former French colony, naturalized citizens are prohibited from voting for five years following their naturalization.
In the Federated States of Micronesia, one must be a Micronesian citizen for at least 15 years to run for parliament.
In Nicaragua, Peru and the Philippines, only citizens by birth are eligible for being elected to the national legislature; naturalized citizens enjoy only voting rights.
In Uruguay, naturalized citizens have the right of eligibility to the parliament after five years.
In the United States, the President and Vice President must be natural-born citizens. All other governmental offices may be held by any citizen, although citizens may only run for Congress after an extended period of citizenship (seven years for the House of Representatives and nine for the Senate).
Function.
In France, an 1872 law, rescinded only by a 1945 decree, prohibited all army personnel from voting.
In Ireland, police (the Garda Síochána and, before 1925, the Dublin Metropolitan Police) were barred from voting in national elections, though not local elections, from 1923 to 1960.
The 1876 Constitution of Texas (article VI, section 1) stated that "The following classes of persons shall not be allowed to vote in this State, to wit: (…) Fifth—All soldiers, marines and seamen, employed in the service of the army or navy of the United States."
In many countries with a presidential system of government a person is forbidden to be a legislator and an official of the executive branch at the same time. Such provisions are found, for example, in Article I of the U.S. Constitution.
History around the world.
In 1906 Finland became the first nation in the world to give all adult citizens full suffrage, in other words the right to vote and to run for office. New Zealand was the first country in the world to grant all adult citizens the right to vote (in 1893), but women did not get the right to run for the New Zealand legislature until 1919.
Hong Kong.
Minimum age to vote was reduced from 21 to 18 years in 1995. The Basic Law, the constitution of the territory since 1997, stipulates that all permanent residents (a status conferred by birth or by seven years of residence) have the right to vote. The right of permanent residents who have right of abode in other countries to stand in election is, however, restricted to 12 functional constituencies by the Legislative Council Ordinance of 1997.
The right to vote and the right to stand in elections are not equal. Fewer than 250,000 of the electorate are eligible to run in the 30 functional constituencies, of which 23 are elected by fewer than 80,000 of the electorate, and in the 2008 Legislative Council election 14 members were elected unopposed from these functional constituencies. The size of the electorates of some constituencies is fewer than 200. Only persons who can demonstrate a connection to the sector are eligible to run in a functional constituency.
The Legislative Council (Amendment) Bill 2012, if passed, amends the Legislative Council Ordinance to restrict the right to stand in Legislative Council by-elections in geographical constituencies and the District Council (Second) functional constituency. In addition to those persons who are mentally disabled, bankrupt, or imprisoned, members who resign their seats will not have the right to stand for six months' time from their resignation. The bill is currently passing through the committee stage.
Italy.
The Supreme Court states that "the rules derogating from the passive electoral law must be strictly interpreted".
United Kingdom.
King Henry VI of England established in 1432 that only owners of property worth at least forty shillings, a significant sum, were entitled to vote in a county. The franchise was restricted to males by custom rather than statute. Changes were made to the details of the system, but there was no major reform until the Reform Act 1832. A series of Reform Acts and Representation of the People Acts followed. In 1918, all men over 21 and women over 30 won the right to vote, and in 1928 all women over 21 won the right to vote resulting in universal suffrage.
United States.
The Constitution did not originally define who was eligible to vote, allowing each state to determine who was eligible. In the early history of the U.S., most states allowed only white male adult property owners to vote (about 6% of the population). These property ownership and most tax-paying requirements were eliminated by 1856, by which time most adult white males had suffrage. Subsequently, the "right to vote" was expressly addressed in five Amendments to the U.S. Constitution. These five Amendments limit the basis on which the right to vote may be abridged or denied:
Full enfranchisement of citizens was not secured until the Voting Rights Act of 1965 gained passage through Congress following the African-American Civil Rights Movement (1954–68).

</doc>
<doc id="70328" url="https://en.wikipedia.org/wiki?curid=70328" title="Congressional power of enforcement">
Congressional power of enforcement

A Congressional power of enforcement is included in a number of amendments to the United States Constitution. The language ""The Congress shall have power to enforce this article by appropriate legislation"" is used, with slight variations, in Amendments XIII, XIV, XV, XVIII, XIX, XXIII, XXIV, and XXVI. The variations in the pertinent language are as follows: the Thirteenth Amendment leaves out the word "the", the Fourteenth Amendment states "The Congress shall have the power to enforce, by appropriate legislation, the provisions of this article." and the Eighteenth Amendment states "The Congress and the several States shall have concurrent power to enforce this article by appropriate legislation.
Initial creation and use.
These provisions made their first appearance in the Thirteenth, Fourteenth and Fifteenth Amendments, which were adopted during the Reconstruction period primarily to abolish slavery and protect the rights of the newly emancipated African-Americans. The enforcement provisions contained in these amendments extend the powers of Congress originally enumerated in Article One, Section 8 of the Constitution, and have the effect of increasing the power of Congress and diminishing that of the individual states. They led to the "Enforcement Acts" of 1870 and 1871. Congress had only that power delegated (granted, given) to it by the constitution.
Use in the courts.
Interpretation of the Fourteenth Amendment's enforcement provision has been the subject of several important Supreme Court cases, which reflect the tension between the Courts' role of interpreting the Constitution and Congress's power of adopting legislation to enforce specific Constitutional amendments.
Early on, in the so-called "Civil Rights Cases" decided in 1883, the Supreme Court concluded that the Congressional enforcement power in Section 5 of the Fourteenth Amendment did not authorize Congress to use the Privileges or Immunities Clause of that amendment to ban racial discrimination in public accommodations operated by private persons, such as inns and theaters. The Court stated that since the Fourteenth Amendment only restricted state action, Congress lacked power under this amendment to forbid discrimination that was not sponsored by the state. This ruling has not been overturned, although in modern times, similar civil rights legislation has been upheld under Congress's power to regulate interstate commerce under Article One, Section 8 of the Constitution. See Civil Rights Act of 1964.
In the "Katzenbach v. Morgan" case, decided in 1966, the Supreme Court concluded that Congress can forbid practices that are not themselves unconstitutional, if the law is aimed at preventing or remedying constitutional violations. On that basis, the Court upheld a provision of the Voting Rights Act that prevented states from using English language literacy tests as qualifications for voting. The Court decided that the law was a valid exercise of Congress's enforcement power under the Equal Protections Clause of Fourteenth Amendment, because it was aimed at remedying state-sponsored discrimination, despite an earlier court finding that a literacy test was not in and of itself a violation of the 14th Amendment.
In 1970, however, in "Oregon v. Mitchell", the Court held that Congress had exceeded its power by attempting to require the states to reduce the voting age to 18. This led to adoption of the Twenty-Sixth Amendment to the Constitution in 1971, which provided that the states could not set a minimum voting age higher than 18.
In the 1997 case of "City of Boerne v. Flores", the Court again took a narrow view of the Congressional power of enforcement, striking down a provision of the Religious Freedom Restoration Act (RFRA) that sought to forbid the states from placing burdens on religious practice in the absence of a compelling state interest in doing so. In enacting RFRA, Congress had sought to overturn the 1988 Supreme Court decision in "Employment Division v. Smith", which had held that the Constitution does not require states to recognize religious exemptions to laws of general applicability. In the "Boerne" case, the Supreme Court decided that RFRA overstepped Congress's authority, because the statute was not sufficiently connected to the goal of remedying a constitutional violation, but instead created new rights that are not guaranteed by the Constitution. Some observers have suggested that the Supreme Court saw RFRA as a threat to the Court's institutional power and an incursion on its role as final arbiter of the meaning of the Constitution, because that statute was aimed specifically at overturning the "Employment Division v. Smith" decision. However, the effect of "Boerne" lasted beyond "Boerne" itself. The standard announced in that case—that all legislation enacted under section 5 of the Fourteenth Amendment must be "congruent and proportional" to the unconstitutional harm it seeks to remedy—has been followed by every post-"Boerne" decision on legislation that sought to abrogate the states' sovereign immunity. 
"United States v. Morrison", decided in 2000, is one controversial successor case. In that case, the Supreme Court, applying the congruent-and-proportional "Boerne" test, overturned provisions of the Violence Against Women Act (VAWA), which criminalized gender-based violence. The Court held that Congress did not have power to forbid discrimination against women in the absence of a connection to state action or interstate commerce. But see "Tennessee v. Lane" and "Nevada Department of Human Resources v. Hibbs".

</doc>
<doc id="70342" url="https://en.wikipedia.org/wiki?curid=70342" title="Direct Connect (protocol)">
Direct Connect (protocol)

Direct Connect (DC) is a peer-to-peer file sharing protocol. Direct Connect clients connect to a central hub and can download files directly from one another. Advanced Direct Connect can be considered a successor protocol.
Hubs feature a list of clients or users connected to them. Users can search for files and download them from other clients, as well as chat with other users.
History.
NeoModus was started as a company funded by the adware "Direct Connect" by Jonathan Hess in November, 1999 while he was in high school.
The first third-party client was called "DClite", which never fully supported the file sharing aspects of the protocol. Hess released a new version of Direct Connect, requiring a simple encryption key to initiate a connection, locking out third-party clients. The encryption key was cracked, and the author of DClite released a new version of DClite compatible with the new software from NeoModus. Some time after, DClite was rewritten as Open Direct Connect with the purpose of having an MDI user interface and using plug-ins for file sharing protocols (similar to MLDonkey). Open Direct Connect also did not have complete support for the full file sharing aspects of the protocol, but a port to Java, however, did. Later on, other clients such as DCTC (Direct Connect Text Client) and DC++ became popular.
The DCDev archive contains discussions of protocol changes for development of DC in the years 2003-2005.
Protocol.
The Direct Connect protocol is a text-based computer protocol, in which commands and their information are sent in clear text, without encryption in original NeoModus software (encryption is available as a protocol extension). As clients connect to a central source of distribution (the hub) of information, the hub requires a substantial amount of upload bandwidth available.
There is no official specification of the protocol, meaning that every client and hub (besides the original NeoModus client and hub) has been forced to reverse engineer the information. As such, any protocol specification this article may reference is likely inaccurate and/or incomplete.
The client-server (as well as client-client, where one client acts as "server") aspect of the protocol stipulates that the server respond first when a connection is being made. For example, when a client connects to a hub's socket, the hub is first to respond to the client.
The protocol lacks a specified default character encoding for clients or hubs. The original client and hub use ASCII encoding instead of that of the Operating system. This allows migration to UTF-8 encoding in newer software.
Port 411 is the default port for hubs, and 412 for client-to-client connections. If either of these ports are already in use, the port number is incremented until the number of a free port is found for use. For example, if 411, 412 and 413 are in use, then port 414 will be used.
Hub addresses are in the following form: dchub://example.com[:411], where 411 is an optional port.
There is no global identification scheme; instead, users are identified with their nickname on a hub-to-hub basis.
An incoming request for a client-client connection cannot be linked with an actual connection.
A search result cannot be linked with a particular search.
The ability to kick or move (redirect) a user to another hub is supported by the protocol. If a user is kicked, the hub is not required to give that user a specific reason, and there is no restriction on where a user can be redirected to. However, if another client in power instructs the hub to kick, that client may send out a notification message before doing so. Redirecting a user must be accompanied by a reason. There is no HTTP referer equivalent.
Hubs may send out user commands to clients. These commands are only raw protocol commands and are used mostly for making a particular task simpler. For example, the hub cannot send a user command that will trigger the default browser to visit a website. It can, however, add the command "+rules" (where '+' indicates to the hub that it's a command - this may vary) to display the hub's rules.
The peer-to-peer part of the protocol is based on a concept of "slots" (similar to number of open positions for a job). These slots denote the number of people that are allowed to download from a user at any given time and are controlled by the client.
In client-to-client connections, the parties generate a random number to see who should be allowed to download first, and the client with the greater number wins.
Transporting downloads and connecting to the hub requires TCP, while active searches use UDP.
There are two kinds of modes a user can be in: either "active" or "passive" mode. Clients using active mode can download from anyone else on the network, while clients using passive mode users can only download from active users. In NeoModus Direct Connect, passive mode users receive other passive mode users' search results, but the user will not be able to download anything. In DC++, users will not receive those search results. In NeoModus Direct Connect, all users will be sent at most five search results per query. If a user has searched, DC++ will respond with ten search results when the user is in active mode and five when the user is in passive mode. Passive clients will be sent search results through the hub, while active clients will receive the results directly.
Protocol delimiters are '$', '|' and ' ' (&codice_1#32; (space)). Protocol have for them (and few others) escape sequence and most software use them correctly in login 
(Lock to Key) sequence. For some reason that escape sequence was ignored by DC++ developers and they use HTML equivalent if these characters are to be viewed by the user.
Continued interest exists in features such as ratings and language packs. However, the authors of DC++ have been actively working on a complete replacement of the Direct Connect protocol called Advanced Direct Connect.
One example of an added feature to the protocol, in comparison with the original protocol, is the broadcasting of Tiger-Tree Hashing of shared files (TTH). The advantages of this include verifying that a file is downloaded correctly, and the ability to find files independently of their names.
Direct Connect used for DDoS attacks.
As the protocol allows hubs to redirect users to other hubs, malicious hubs have redirected users to places other than real Direct Connect hubs, effectively causing a Distributed Denial of Service attack. The hubs may alter the IP in client to client connections, pointing to a potential victim.
The CTM Exploit surfaced in 2006–2007, during which period the whole Direct Connect network suffered from DDoS attacks. The situation prompted developers to take security issues more seriously.
As of February 2009,
Direct Connect Network Foundation.
The Direct Connect Network Foundation (DCNF) is a non-profit organization registered in Sweden that aims to improve the DC network by improving software, protocols and other services in the network.
Articles and papers.
The DCNF maintains a list of articles, papers and more documentation that relate to DC.
See also.
Advanced Direct Connect (Protocol)

</doc>
<doc id="70345" url="https://en.wikipedia.org/wiki?curid=70345" title="Shareaza">
Shareaza

Shareaza is a peer-to-peer file sharing client running under Microsoft Windows which supports the gnutella, Gnutella2 (G2), eDonkey, BitTorrent, FTP, HTTP and HTTPS network protocols and handles magnet links, ed2k links, and the now deprecated gnutella and Piolet links. It is available in 30 languages.
Shareaza was developed by Michael Stokes until June 1, 2004, and has since been maintained by a group of volunteers. On June 1, 2004, Shareaza 2.0 was released, along with the source code, under the GNU General Public License (GPL), making it free software.
Features.
Multi-network.
Shareaza can connect to gnutella, G2, eDonkey and BitTorrent. Shareaza hashes its files for all networks, and then distributes those hash values on G2. This allows Shareaza to download one file from several networks at once. When another client connected to G2 finds such a file, it is given the hash values for all networks and can search on the other networks with their respective hash values, which increases the number of sources and the download speed of the file. Shareaza also uses its G2 network to find more sources for torrents.
Security filter.
The Shareaza client has some basic content filters including a forced child and optional adult pornography filter, and some other optional filters such as a filter for files encumbered with Digital rights management (DRM). Shareaza's security filters can also be extended with user-defined keywords and/or IP addresses. Later versions of Shareaza allow for the use of regular expressions and filtering by hash.
These filters increase the chances of getting the files the user wants and decrease the chance of getting malicious or fake files. The file format used for the filters is an extendable XML schema. The filters are editable inside Shareaza, and can be exported from the application to be shared with others.
Plugins.
Shareaza implements a framework for additional plugins. The Shareaza installer ships several plugins. Most of them are used to read and strip off built in metadata from the files being hashed and convert it to an external XML based format, or to decode multimedia files for making a preview for other G2 clients. Some others serve the need of a media player inside Shareaza, and enhancements of that media player. Third party plugins can also be used, for example, "Sharemonkey", which will add a link inside Shareaza when downloading or searching copyrighted material from where it can be legally downloaded.
Skins.
The client can have almost all parts of the GUI skinned. This includes bars, icons, as well as backgrounds and buttons. In that way, Shareaza can be completely changed with colors, images, new buttons, etc. A basic list of skins is contained in the Shareaza installer package. Other skins can be downloaded in the community forums or found via a search for .sks (Shareaza skin files) in the G2 network. The skins are zip archives, renamed with the extension .sks, containing icons and images, as well as an XML file which binds the images and colors with the GUI.
This feature is also used for localization. The language files are XML files, like the normal skins, but not zipped. The XML file contains the translations for a certain part of the program. This enables languages to be easily changed, updated and tested without compiling an entire binary.
Modes.
Shareaza has three user modes. The first one is for normal users. This mode is the default mode and provides a clean, trimmed GUI. Users will not be able to make major changes to settings in this mode, but will be able to make use of the most essential functions, like searching and downloading. The second mode is for power users. It provides more access to network and advanced settings, but can also break your connection to the networks. The third mode is the windowed mode. In this mode, users can see different tabs (windows) simultaneously, providing a lot of control about the things happening. This mode also makes it possible to personalize the look of the client to perfectly fit the needs of the respective user.
IRC.
Shareaza contains a built-in IRC (chat) client which allows users to communicate with each other. There are channels in several languages for support and help. These channels are located on the P2PChat servers and can also by joined by any normal IRC client or via a Java addon on the Shareaza homepage.
History.
In mid-2002 Stokes released the first version of a gnutella client he had written and dubbed "Shareaza". It was from the beginning a client with the aim of having features other gnutella clients did not have. Over the next two years Stokes coded in support for the eDonkey 2000 network, BitTorrent and a rewritten gnutella-based protocol which he named Gnutella2.
On June 1, 2004 Stokes released the Shareaza source code under version 2 of the GNU General Public License (which coincided with the release of Shareaza version 2.0). Shareaza joined LimeWire, Gnucleus, and others as an open source client on the gnutella network.
Since the beginning Shareaza was advertised as "completely free. No ads, no spyware, no guilting you to upgrade to a commercial version", stating that the developers "[couldn't] stand that kind of crap." It has remained as such in each subsequent release.
From the first version Shareaza has supported swarming, metadata, library management, and automatic file hashing.
Domain takeover.
On 19 December 2007 the project's domain name, shareaza.com, was redirected to a site claiming to be "The Official Home of Shareaza", promoting the download of a client known as Shareaza V4 (which had become V6 in October 2009, V7 in August 2010, and V8 ) unrelated to releases by the Shareaza development team, an iMesh clone with only small graphical modifications, and using Shareaza v1 logo (see the picture above). The domain owner Jon Nilson was forced to sell it as a part of a settlement with "La Societe Des Producteurs De Phonogrammes En France". This client is a network interface for a centralised music shop by Discordia Ltd., and does not connect to any open P2P network such as gnutella, G2, eDonkey or BitTorrent. Content is limited to the DRM-protected music that can be bought in Discordia's online music store; Discordia is a company based in Cyprus, closely related to the RIAA and unrelated to the Shareaza development team. In response the Shareaza development team moved their website to SourceForge.net.
Versions prior to 2.3.1.0 of the original Shareaza connected to www.shareaza.com to check for software updates. From 1 January 2008 the new owner of the domain shareaza.com, Discordia Ltd. used this update check mechanism to suggest to users that ShareazaV4 (and later ShareazaV5, V6, and V7) was an update to the original Shareaza client. Since version 2.3.1.0, released on 3 January 2008, the original Shareaza has linked to the Shareaza pages at sourceforge.net.
Yahoo!, which uses SiteAdvisor to filter their search results, no longer lists domain shareaza.com due to it being listed by SiteAdvisor as a security risk. Other website reputation rating services, such as Web of trust, also rate Shareaza.com as dangerous.
Trademark registration by iMesh.
On January 10, 2008, the new owners of Shareaza.com, Discordia Ltd (iMesh Inc.), filed for trademark registration of the Shareaza name in an attempt to stop the original developers from using the name, claiming that the first-ever use was on December 17, 2007. The Shareaza Development Team obtained legal representation to challenge the registration and a legal defense fund was set up. The development team appointed William Erwin to handle the donations; it was stated that he had been paid by iMesh to sabotage the defense, and that he had stolen the money donated. The trademark was awarded to iMesh after the development team had given up defending the trademark.
Version history.
v2.3.1.0
Version 2.3.1.0 is the last stable version of Shareaza that supports Windows 9x. It followed 2 days after the new owners of the project domain (see the shareaza.com domain takeover) exploited the updating mechanism to emit a false update message to trick users into installing their fake Shareaza V4 client, and contained a fix for this issue.
v2.4.0.0
Version 2.4.0.0 of Shareaza was released on October 1, 2008, with many bug fixes and major changes to provide better stability of the client. It was the first stable release to include IRC support. Furthermore, major changes to the torrent handling mechanism were made and Windows 98/Me support was discontinued (the last version working on Windows 9x is 2.3.1.0).
When v2.4 was released the roadmap for the next version (2.4.1.0, a v2.5 release candidate) was set for release around October 1, 2009, to be followed by 2.5.0.0 a month later.
v2.5.x.0
Version 2.5.0.0 of Shareaza was released on October 31, 2009. It was significantly more stable and less resource-consuming than earlier versions, and further improved BitTorrent support, such as by selective downloading of files contained in batch torrents and download prioritization. There were also updates to the gnutella and eD2k implementation, such as extended support for GGEP, large files and chat. The IRC implementation of v2.4.0.0 was reworked to free it of the bugs that made it partially unusable in the previous version. Download manager capabilities were extended, Internet Explorer integration added, and "BugTrap" included to speed up and simplify reporting crashes.
Version 2.5.1.0 of Shareaza was released on December 1, 2009. It was significantly more stable and more functional than its predecessor due to fixed bugs. It improved usability and compatibility of BitTorrent according to most popular service suggestions. It made use of and required the SSE instruction set, and thus required at least an Pentium-III or an Athlon-XP processor.
Version 2.5.2.0 of Shareaza was released on February 6, 2010. It brought further improvements on stability. This and later versions were available optionally either as an SSE or non-SSE build to allow the use of older processors, unlike the SSE-only version 2.5.1.0. For this and later releases the SSE-optimized build uses SSE2, and requires at least a Pentium 4 or AMD Athlon 64.
Shareaza v2.5.3.0, released on June 13, 2010, focused on internal changes and optimizations; the only significant addition was a scheduler that allows full control over what the application does at a given time while running unattended.
Shareaza v2.5.4.0, released on February 12, 2011, improved UPnP support and added limited DC++ support. μTorrent-compatible peer exchange and tracker exchange for BitTorrent were also added. It fixed remaining IRC chat bugs and a lot of rather uncommon/rarely seen crashes.
Shareaza v2.5.5.0, released on May 29, 2011, further improved UPnP support and included DC++ and gnutella updates, enhanced anti-spam protection during searches, and multi-file download merging.
V2.6.0.0 was released on 3 June 2012, adding support for BitTorrent (Mainline) DHT and UDP trackers as well as containing interface optimizations for Windows 7.
Shareaza 2.7.0.0 was made available on 31 August 2013, described as a "huge bugfix release ... should we call it a Shareaza Service Pack?" It contained major improvements to the BitTorrent support, eDonkey uploading and the built-in media player. It was followed by further V2.7.x.x releases.
Shareaza and Linux.
Shareaza can be run under Linux using the Wine compatibility layer. Although the media player does not work, uploading and downloading work flawlessly.
There are two software projects that focus on porting Shareaza's functionality to operating systems other than Windows :

</doc>
