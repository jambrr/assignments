<doc id="12349" url="https://en.wikipedia.org/wiki?curid=12349" title="Telecommunications in Guadeloupe">
Telecommunications in Guadeloupe

Telephones - main lines in use:
159,000 (1995)
Telephones - mobile cellular:
814 (1990)
Telephone system:
domestic facilities inadequate
<br>"domestic:"
NA
<br>"international:"
satellite earth station - 1 Intelsat (Atlantic Ocean); microwave radio relay to Antigua and Barbuda, Dominica, and Martinique
Radio broadcast stations:
AM 1, FM 17, shortwave 0 (1998)
Radios:
113,000 (1997)
Television broadcast stations:
5 (plus several low-power repeaters) (1997)
Televisions:
118,000 (1997)
Internet Service Providers (ISPs): France Telecom (Orange)
Country code (Top-level domain): GP

</doc>
<doc id="12350" url="https://en.wikipedia.org/wiki?curid=12350" title="Transport in Guadeloupe">
Transport in Guadeloupe

Transport in Guadeloupe.
Railways.
<br>"total:"
NA km; privately owned, narrow-gauge plantation lines
Highways.
<br>"total:"
2,082 km
<br>"paved:"
1,742 km
<br>"unpaved:"
340 km (1985 est.)
<br>"note:"
in 1996 there were a total of 3,200 km of roads
Water transport.
Seaports and harbours.
Basse-Terre, Pointe-à-Pitre (on Grande-Terre).
Merchant marine:
<br>"total:"
1 ship (1,000 GRT or over) totaling 1,240 GRT/
<br>"ships by type:"
passenger 1 (1999 est.)
Air transport.
Airports.
9 (1999 est.)
Airports - with paved runways.
<br>"total:"
8
<br>"over 3,047 m:"
1
<br>"914 to 1,523 m:"
2
<br>"under 914 m:"
5 (1999 est.)
Airports - with unpaved runways.
<br>"total:"
1
<br>"under 914 m:"
1 (1999 est.)

</doc>
<doc id="12353" url="https://en.wikipedia.org/wiki?curid=12353" title="Glagolitic alphabet">
Glagolitic alphabet

The Glagolitic alphabet (, Ⰳⰾⰰⰳⱁⰾⰻⱌⰰ "Glagolitsa") is the oldest known Slavic alphabet. It was created in the 9th century by Saint Cyril, a Byzantine monk from Thessaloniki. He and his brother, Saint Methodius, were sent by the Byzantine Emperor Michael III in 863 to Great Moravia to spread Christianity among the Slavs in the area. The brothers decided to translate liturgical books into the Old Slavic language that was understandable to the general population, but as the words of that language could not be easily written by using either the Greek or Latin alphabets, Cyril decided to invent a new script, Glagolitic, which he based on the language of the Macedonian Slavs from the Thessaloniki region.
After the deaths of Cyril and Methodius, the Glagolitic alphabet ceased to be used in Moravia, but their students continued to propagate it in the west and south. The Glagolitic alphabet was preserved only by the Croats, using it from the 12th to the 20th century, mostly in liturgy.
Name.
The name was not coined until many centuries after its creation, and comes from the Old Church Slavonic глаголъ "glagolŭ" "utterance" (also the origin of the Slavic name for the letter "G"). The verb "glagoliti" means "to speak". It has been conjectured that the name "glagolitsa" developed in Croatia around the 14th century and was derived from the word "glagolity", applied to adherents of the liturgy in Slavonic.
In Old Church Slavonic the name is , ("Kyrillovitsa").
The words that denote "Glagolitic alphabet" in the main Slavic languages are as follows: Bulgarian, Russian, Macedonian , Belarusian , Croatian ', Serbian , Czech ', Polish "", Slovene , Slovak "hlaholika", and Ukrainian .
Origins of characters.
The creation of the characters is popularly attributed to Saints Cyril and Methodius, who may have created them to facilitate the introduction of Christianity. It is believed that the original letters were fitted to Bulgarian (Macedonian dialects specifically).
The number of letters in the original Glagolitic alphabet is not known, but it may have been close to its presumed Greek model. The 41 letters known today include letters for non-Greek sounds, which may have been added by Saint Cyril, as well as ligatures added in the 12th century under the influence of Cyrillic, as Glagolitic lost its dominance. In later centuries, the number of letters dropped dramatically, to fewer than 30 in modern Croatian and Czech recensions of the Church Slavic language. Twenty-four of the 41 original Glagolitic letters (see table below) probably derive from graphemes of the medieval cursive Greek small alphabet but have been given an ornamental design.
The source of the other consonantal letters is unknown. If they were added by Cyril, it is likely that they were taken from an alphabet used for Christian scripture. It is frequently proposed that the letters "sha" , "tsi" , and "cherv" were taken from the letters "shin" ש and "tsadi" צ of the Hebrew alphabet, and that Ⰶ "zhivete" derives from Coptic "janja" Ϫ. However, Cubberley (1996) suggests that if a single prototype were presumed, that the most likely source would be Armenian. Other proposals include the Samaritan alphabet, which Cyril learned during his journey to the Khazars in Cherson.
Glagolitic letters were also used as numbers, similarly to Cyrillic numerals. Unlike Cyrillic numerals, which inherited their numeric value from the corresponding Greek letter (see Greek numerals), Glagolitic letters were assigned values based on their native alphabetic order.
History.
The two monks later canonized as Saints Cyril and Methodius, brothers from Thessaloniki, were sent to Great Moravia in 862 by the Byzantine emperor at the request of Prince Rastislav, who wanted to weaken the dependence of his country on East Frankish priests. The Glagolitic alphabet, however it originated, was used between 863 and 885 for government and religious documents and books, and at the Great Moravian Academy ("Veľkomoravské učilište") founded by the missionaries, where their followers were educated. The Kiev Missal, found in the 19th century in Jerusalem, was dated to the 10th century.
In 886 an East Frankish bishop of Nitra named Wiching banned the script and jailed 200 followers of Methodius, mostly students of the original academy. They were then dispersed or, according to some sources, sold as slaves by the Franks. Many of them (including Naum, Clement, Angelarious, Sava and Gorazd), however, reached Bulgaria and were commissioned by Boris I of Bulgaria to teach and instruct the future clergy of the state in the Slavic languages. After the adoption of Christianity in Bulgaria in 865, religious ceremonies and Divine Liturgy were conducted in Greek by clergy sent from the Byzantine Empire, using the Byzantine rite. Fearing growing Byzantine influence and weakening of the state, Boris viewed the introduction of the Slavic alphabet and language into church use as a way to preserve the independence of the Bulgarian Empire from Byzantine Constantinople. As a result of Boris' measures, two academies, one in Ohrid and one in Preslav, were founded.
From there, the students traveled to other places and spread the use of their alphabet. Some went to Croatia (Dalmatia), where the squared variant arose and where the Glagolitic remained in use for a long time. In 1248, Pope Innocent IV granted the Croats of southern Dalmatia the unique privilege of using their own language and this script in the Roman Rite liturgy. Formally granted to bishop Philip of Senj, the permission to use the Glagolitic liturgy (the Roman Rite conducted in the Slavic language instead of Latin, not the Byzantine rite), actually extended to all Croatian lands, mostly along the Adriatic coast. The Holy See had several Glagolitic missals published in Rome. Authorization for the use of this language was extended to some other Slavic regions between 1886 and 1935. In missals, the Glagolitic script was eventually replaced with the Latin alphabet, but the use of the Slavic language in the Mass continued, until replaced by the modern vernacular languages.
Some students of the Ohrid academy went to Bohemia where the alphabet was used in the 10th and 11th centuries, along with other scripts. It is not clear whether Glagolitic alphabet was used in the Duchy of Kopnik before the Wendish Crusade, but it was certainly used in Kievan Rus'.
In Croatia, from the 12th century, Glagolitic inscriptions appeared mostly in littoral areas: Istria, Primorje, Kvarner and Kvarner islands, notably Krk, Cres and Lošinj; in Dalmatia, on the islands of Zadar, but there were also findings in inner Lika and Krbava, reaching to Kupa river, and even as far as Međimurje and Slovenia.
The Hrvoje's Missal () from 1404 was written in Split, and it is considered one of the most beautiful Croatian Glagolitic books. The 1483 Missale Romanum Glagolitice was the first printed Croatian Glagolitic book.
It was believed that Glagolitsa in Croatia was present only in those areas. But, in 1992, the discovery of Glagolitic inscriptions in churches along the Orljava river in Slavonia, totally changed the picture (churches in Brodski Drenovac, Lovčić and some others), showing that use of Glagolitic alphabet was spread from Slavonia also.
At the end of the 9th century, one of these students of Methodius – Naum, who had settled in Preslav (Bulgaria) – created the Cyrillic script, which almost entirely replaced the Glagolitic during the Middle Ages. The Cyrillic alphabet is derived from the Greek alphabet, with (at least 10) letters peculiar to Slavic languages being derived from the Glagolitic. The decision in favor of Cyrillic created an alphabetical difference between the two literary centres of the Bulgarian state in Pliska and Ohrid. In the western part the Glagolitic alphabet remained dominant at first. However, subsequently in the next two centuries, Glagolitic gradually ceased to be used there at all. Nevertheless, particular passages or words written with the Glagolitic alphabet appeared in Bulgarian Cyrillic manuscripts till the end of the 14th century.
Only in Croatia the Glagolitic alphabet was used until the 19th century. Nowadays, Glagolitic is used only for Church Slavic (Croatian and Czech recensions).
Versions of authorship and name.
The tradition that the alphabet was designed by Saint Cyril and Saint Methodius has not been universally accepted. A less common belief, contradicting allochthonic Slovene origin, was that the Glagolitic was created or used in the 4th century by St. Jerome (Latin: "Eusebius Sophronius Hieronymus"), hence the alphabet is sometimes named Hieronymian.
It is also acrophonically called azbuki from the names of its first two letters in Bulgaria, on the same model as "alpha" + "beta". The Slavs of Great Moravia (present-day Slovakia and Moravia), Hungary, Slovenia and Slavonia were called "Slověne" at that time, which gives rise to the name Slovenish for the alphabet. Some other, rarer, names for this alphabet are Bukvitsa (from common Slavic word "bukva" meaning "letter", and a suffix "-itsa") and Illyrian.
Hieronymian version.
In the Middle Ages, Glagolitsa was also known as "St. Jerome's script" due to popular mediaeval legend (created by Croatian scribes in the 13th century) ascribing its invention to St. Jerome (342–429). That claim, however, has been resolutely disproved.
The epoch of traditional attribution of the script to Jerome ended probably in 1812. In modern times, only certain marginal authors share this view, usually "re-discovering" one of the already-known mediaeval sources.
Pre-Glagolitic Slavic writing systems.
A hypothetical pre-Glagolitic writing system is typically referred to as "cherty i rezy" (strokes and incisions) – but no material evidence of the existence of any pre-Glagolitic Slavic writing system has been found, except for a few brief and vague references in old chronicles and "lives of the saints". All artifacts presented as evidence of pre-Glagolitic Slavic inscriptions have later been identified as texts in known scripts and in known non-Slavic languages, or as fakes. The well-known Chernorizets Hrabar's "strokes and incisions" are usually considered to be a reference to a kind of property mark or alternatively fortune-telling signs. Some "Ruthenian letters" found in one version of St. Cyril's life are explainable as misspelled "Syrian letters" (in Slavic, the roots are very similar: "rus-" vs. "sur-" or "syr-"), etc.
Characteristics.
The values of many of the letters are thought to have been displaced under Cyrillic influence or to have become confused through the early spread to different dialects so the original values are not always clear. For instance, the letter "yu" Ⱓ is thought to have perhaps originally had the sound /u/ but was displaced by the adoption of an "ow" ligature Ⱆ under the influence of later Cyrillic. Other letters were late creations after a Cyrillic model.
The following table lists each letter in its modern order, showing an image of the letter (round variant), the corresponding modern Cyrillic letter, the approximate sound transcribed with the , the name, and suggestions for its origin. Several letters have no modern counterpart.
Note that "yery" (ⰟⰉ) is a digraph of either "yer" (Ⱏ) or "yerь" (Ⱐ), followed by either "izhe" (Ⰹ, Ⰺ) or "i" (Ⰻ).
In older texts, "uk" (Ⱆ) and three out of four "yus"es (Ⱗ, Ⱘ, Ⱙ) also can be written as digraphs, in two separate parts.
The order of "izhe" (Ⰹ, Ⰺ) and "i" (Ⰻ) varies from source to source, as does the order of the various forms of "yus" (Ⱔ, Ⱗ, Ⱘ, Ⱙ). Correspondence between Glagolitic "izhe" (Ⰹ, Ⰺ) and "i" (Ⰻ) with Cyrillic "И" and "І" is unknown.
Unicode.
The Glagolitic alphabet was added to the Unicode Standard in March 2005 with the release of version 4.1.
The Unicode block for Glagolitic is U+2C00–U+2C5F.
In popular culture.
Glagolitic script is the writing system used in the world of The Witcher video game series. It was also featured as an inscription in one episode of Log Horizon, and as murder mystery clues in season 3 episode 7 of "The Bridge" (Danish/Swedish TV series). It is also featured, in various uses, in several of the point and click adventure games made by Cateia Games, a Croatian game studio.

</doc>
<doc id="12354" url="https://en.wikipedia.org/wiki?curid=12354" title="Greatest common divisor">
Greatest common divisor

In mathematics, the greatest common divisor (gcd) of two or more integers, when at least one of them is not zero, is the largest positive integer that divides the numbers without a remainder. For example, the GCD of 8 and 12 is 4.
The greatest common divisor is also known as the greatest common factor (gcf), highest common factor (hcf), greatest common measure (gcm), or highest common divisor.
This notion can be extended to polynomials (see Polynomial greatest common divisor) and other commutative rings (see below).
Overview.
Notation.
In this article we will denote the greatest common divisor of two integers "a" and "b" as gcd("a","b").
Some textbooks use ("a","b").
The J programming language uses a +. b
Example.
The number 54 can be expressed as a product of two integers in several different ways:
Thus the divisors of 54 are:
Similarly, the divisors of 24 are:
The numbers that these two lists share in common are the common divisors of 54 and 24:
The greatest of these is 6. That is, the greatest common divisor of 54 and 24. One writes:
Reducing fractions.
The greatest common divisor is useful for reducing fractions to be in lowest terms. For example, gcd(42, 56) = 14, therefore,
Coprime numbers.
Two numbers are called "relatively prime", or "coprime", if their greatest common divisor equals 1. For example, 9 and 28 are relatively prime.
A geometric view.
For example, a 24-by-60 rectangular area can be divided into a grid of: 1-by-1 squares, 2-by-2 squares, 3-by-3 squares, 4-by-4 squares, 6-by-6 squares or 12-by-12 squares. Therefore, 12 is the greatest common divisor of 24 and 60. A 24-by-60 rectangular area can be divided into a grid of 12-by-12 squares, with two squares along one edge (24/12 = 2) and five squares along the other (60/12 = 5).
Calculation.
Using prime factorizations.
Greatest common divisors can in principle be computed by determining the prime factorizations of the two numbers and comparing factors, as in the following example: to compute gcd(18, 84), we find the prime factorizations 18 = 2 · 32 and 84 = 22 · 3 · 7 and notice that the "overlap" of the two expressions is 2 · 3; so gcd(18, 84) = 6. In practice, this method is only feasible for small numbers; computing prime factorizations in general takes far too long.
Here is another concrete example, illustrated by a Venn diagram. Suppose it is desired to find the greatest common divisor of 48 and 180. First, find the prime factorizations of the two numbers:
What they share in common is two "2"s and a "3":
Using Euclid's algorithm.
A much more efficient method is the Euclidean algorithm, which uses a division algorithm such as long division in combination with the observation that the gcd of two numbers also divides their difference. To compute gcd(48,18), divide 48 by 18 to get a quotient of 2 and a remainder of 12. Then divide 18 by 12 to get a quotient of 1 and a remainder of 6. Then divide 12 by 6 to get a remainder of 0, which means that 6 is the gcd. Note that we ignored the quotient in each step except to notice when the remainder reached 0, signalling that we had arrived at the answer. Formally the algorithm can be described as:
where
If the arguments are both greater than zero then the algorithm can be written in more elementary terms as follows:
Complexity of Euclidean method.
The existence of the Euclidean algorithm places (the decision problem version of) the greatest common divisor problem in P, the class of problems solvable in polynomial time. The GCD problem is not known to be in NC, and so there is no known way to parallelize its computation across many processors; nor is it known to be P-complete, which would imply that it is unlikely to be possible to parallelize GCD computation. In this sense the GCD problem is analogous to e.g. the integer factorization problem, which has no known polynomial-time algorithm, but is not known to be NP-complete. Shallcross et al. showed that a related problem (EUGCD, determining the remainder sequence arising during the Euclidean algorithm) is NC-equivalent to the problem of integer linear programming with two variables; if either problem is in NC or is P-complete, the other is as well. Since NC contains NL, it is also unknown whether a space-efficient algorithm for computing the GCD exists, even for nondeterministic Turing machines.
Although the problem is not known to be in NC, parallel algorithms asymptotically faster than the Euclidean algorithm exist; the best known deterministic algorithm is by Chor and Goldreich, which (in the CRCW-PRAM model) can solve the problem in O("n"/log "n") time with "n"1+ε processors. Randomized algorithms can solve the problem in O((log "n")2) time on formula_13 processors (note this is superpolynomial).
Binary method.
An alternative method of computing the gcd is the binary gcd method which uses only subtraction and division by 2.
In outline the method is as follows: Let "a" and "b" be the two non negative integers. Also set the integer "d" to 0. There are five possibilities:
As gcd("a", "a") = "a", the desired gcd is "a"×2"d" (as "a" and "b" are changed in the other cases, and "d" records the number of times that "a" and "b" have been both divided by 2 in the next step, the gcd of the initial pair is the product of "a" by 2"d").
In this case 2 is a common divisor. Divide both "a" and "b" by 2, increment "d" by 1 to record the number of times 2 is a common divisor and continue.
In this case 2 is not a common divisor. Divide "a" by 2 and continue.
As in the previous case 2 is not a common divisor. Divide "b" by 2 and continue.
As gcd("a","b") = gcd("b","a") and we have already considered the case "a" = "b", we may assume that "a" > "b". The number "c" = "a" − "b" is smaller than "a" yet still positive. Any number that divides "a" and "b" must also divide "c" so every common divisor of "a" and "b" is also a common divisor of "b" and "c" Similarly, "a" = "b" + "c" and every common divisor of "b" and "c" is also a common divisor of "a" and "b". So the two pairs ("a", "b") and ("b", "c") have the same common divisors, and thus gcd("a","b") = gcd("b","c"). Moreover, as "a" and "b" are both odd, "c" is even, and one may replace "c" by "c"/2 without changing the gcd. Thus the process can be continued with the pair ("a", "b") replaced by the smaller numbers ("c"/2, "b").
Each of the above steps reduces at least one of "a" and "b" towards 0 and so can only be repeated a finite number of times. Thus one must eventually reach the case "a" = "b", which is the only stopping case. Then, as quoted above, the gcd is "a"×2"d".
This algorithm may easily programmed as follows:
Example: ("a", "b", "d") = (48, 18, 0) → (24, 9, 1) → (12, 9, 1) → (6, 9, 1) → (3, 9, 1) → (3, 6, 1) → (3, 3, 1) ; the original gcd is thus 2"d" = 21 times "a"= "b"= 3, that is 6.
The Binary GCD algorithm is particularly easy to implement on binary computers. The test for whether a number is divisible by two can be performed by testing the lowest bit in the number. Division by two can be achieved by shifting the input number by one bit. Each step of the algorithm makes at least one such shift. Subtracting two numbers smaller than "a" and "b" costs formula_14 bit operations. Each step makes at most one such subtraction. The total number of steps is at most the sum of the numbers of bits of "a" and "b", hence the computational complexity is
For further details see Binary GCD algorithm.
Other methods.
If "a" and "b" are both nonzero, the greatest common divisor of "a" and "b" can be computed by using least common multiple (lcm) of "a" and "b":
but more commonly the lcm is computed from the gcd.
Using Thomae's function "f",
which generalizes to "a" and "b" rational numbers or commensurable real numbers.
Keith Slavin has shown that for odd "a" ≥ 1:
which is a function that can be evaluated for complex "b". Wolfgang Schramm has shown that
is an entire function in the variable "b" for all positive integers "a" where "c""d"("k") is Ramanujan's sum. Donald Knuth proved the following reduction:
for non-negative integers "a" and "b", where "a" and "b" are not both zero. More generally
which can be proven by considering the Euclidean algorithm in base "n". Another useful identity relates formula_22 to the Euler's totient function:
Probabilities and expected value.
In 1972, James E. Nymann showed that "k" integers, chosen independently and uniformly from {"1"...,"n"}, are coprime with probability 1/"ζ"("k") as "n" goes to infinity, where "ζ" refers to the Riemann zeta function. (See coprime for a derivation.) This result was extended in 1987 to show that the probability that "k" random integers have greatest common divisor "d" is "d""−k"/ζ("k").
Using this information, the expected value of the greatest common divisor function can be seen (informally) to not exist when "k" = 2. In this case the probability that the gcd equals "d" is "d"−2/ζ(2), and since ζ(2) = π2/6 we have
This last summation is the harmonic series, which diverges. However, when "k" ≥ 3, the expected value is well-defined, and by the above argument, it is
For "k" = 3, this is approximately equal to 1.3684. For "k" = 4, it is approximately 1.1106.
The gcd in commutative rings.
The notion of greatest common divisor can more generally be defined for elements of an arbitrary commutative ring, although in general there need not exist one for every pair of elements.
If is a commutative ring, and and are in , then an element of is called a "common divisor" of and if it divides both and (that is, if there are elements and in such that "d"·"x" = "a" and "d"·"y" = "b").
If is a common divisor of and , and every common divisor of and divides , then is called a "greatest common divisor" of and "b".
Note that with this definition, two elements and may very well have several greatest common divisors, or none at all. If is an integral domain then any two gcd's of and must be associate elements, since by definition either one must divide the other; indeed if a gcd exists, any one of its associates is a gcd as well. Existence of a gcd is not assured in arbitrary integral domains. However if is a unique factorization domain, then any two elements have a gcd, and more generally this is true in gcd domains.
If is a Euclidean domain in which euclidean division is given algorithmically (as is the case for instance when "R" = "F"["X"] where is a field, or when is the ring of Gaussian integers), then greatest common divisors can be computed using a form of the Euclidean algorithm based on the division procedure.
The following is an example of an integral domain with two elements that do not have a gcd:
The elements 2 and 1 +  are two "maximal common divisors" (i.e. any common divisor which is a multiple of 2 is associated to 2, the same holds for 1 + , but they are not associated, so there is no greatest common divisor of and "b".
Corresponding to the Bézout property we may, in any commutative ring, consider the collection of elements of the form "pa" + "qb", where and range over the ring. This is the ideal generated by and , and is denoted simply ("a", "b"). In a ring all of whose ideals are principal (a principal ideal domain or PID), this ideal will be identical with the set of multiples of some ring element "d"; then this is a greatest common divisor of and "b". But the ideal ("a", "b") can be useful even when there is no greatest common divisor of and "b". (Indeed, Ernst Kummer used this ideal as a replacement for a gcd in his treatment of Fermat's Last Theorem, although he envisioned it as the set of multiples of some hypothetical, or "ideal", ring element , whence the ring-theoretic term.)

</doc>
<doc id="12357" url="https://en.wikipedia.org/wiki?curid=12357" title="Gazpacho">
Gazpacho

Gazpacho (; ) is a soup made of raw vegetables and served cold, usually with a tomato base, originating in the southern Spanish region of Andalusia. Gazpacho is widely eaten in Spain and neighbouring Portugal (, spelling "gaspacho"), particularly during the hot summers, as it is refreshing and cool.
History.
Gazpacho has ancient roots. There are a number of theories of its origin, including as a soup of bread, olive oil, water and garlic that arrived in Spain and Portugal with the Romans and also with the addition of vinegar. Once in Spain, it became a part of Andalusian cuisine, particularly Córdoba and Seville, using stale bread, garlic, olive oil, salt, and vinegar, similar to ajoblanco.
There are many modern variations of gazpacho, often in different colors and omitting the tomatoes and bread in favor of avocados, cucumbers, parsley, watermelon, grapes, meat stock, seafood, and other ingredients.
Ingredients and preparation.
In Andalusia, most gazpacho recipes typically include stale bread, tomato, cucumber, bell pepper, onion and garlic, olive oil, wine vinegar, water, and salt.
The following is a typical modern method of preparing gazpacho:
Traditionally, gazpacho was made by pounding the vegetables in a mortar with a pestle; this more laborious method is still sometimes used as it helps keep the gazpacho cool and avoids the foam and the completely smooth consistency created by blenders and food processors. A traditional way of preparation is to pound garlic cloves in a mortar, add a little soaked stale bread, then olive oil and salt, to make a paste. Then very ripe tomatoes and vinegar are added. In the days before refrigeration the gazpacho was left in an unglazed earthenware pot to cool by evaporation, and some water added.
Gazpacho may be served with garnishes, served separately, such as hard boiled eggs and chopped ham (in the salmorejo variety from Córdoba), chopped almonds, cumin crushed with mint, orange segments, finely chopped green pepper, onion, tomato or cucumber. In Extremadura, gazpacho with local ham, added to the gazpacho rather than as a garnish, is called "gazpacho extremeño". Andalusian sources say that gazpacho should be slightly chilled, but not iced.
Variations.
Ingredients, texture, and how thick the gazpacho is made vary regionally and between families.
Similar cold raw soups such as salmorejo, porra antequerana and ajoblanco, are also popular in Andalusia, although not as widespread as gazpacho.
"Gazpacho manchego", despite its name, is a meat stew, served hot, not a variation on the cold vegetable soup.
In Spain.
In the historical description of gazpacho it was remarked that the original recipe uses bread, water, vinegar, oil and salt. This recipe is very old in the Iberian Peninsula, going back to Roman times. Every Andalusian region or comarca has its own variety. The humble gazpacho became a very deeply rooted food for peasants and shepherds in the south of Spain. The basic gazpacho gave rise to many variants, some also called gazpacho, others not; some authors have tried to classify all these variations. Gazpachos may be classified by colour: the most usual red ones (which contain tomato), white ones (which contain no tomato, but include dried fruits), and green ones (which are white but contain some spices that make them green). These variants have their basic ingredients in common, garlic paste which works as an emulsifier, bread, olive oil, vinegar and salt. To the traditional ingredients red fruits such as strawberries, muskmelon, etc., may be added, making the gazpacho a bit sweeter. Gazpacho may be served as a starter, main dish, or tapa.
Arranque roteño.
A popular variation comes from the town of Rota in the province of Cadiz. During times of drought there was not enough water to make gazpacho; arranque has the same ingredients as gazpacho, but uses less water and bread, making it a sort of cream. Some people add more bread until it takes on the consistency of a dip.
Extremaduran variations.
In Extremadura, gazpachos are a kind of purée or thick gazpacho known as "cojondongo", or "cojondongo del gañán", made of breadcrumbs, garlics, oil, vinegar and on the top of that chopped onions, tomato and peppers.
La Mancha variations.
Gazpacho manchego, as its name implies, is made in the east region of La Mancha, in Albacete and nearby areas, and is also popular in other areas in the center and southwest of the country. It is not a cold vegetable soup but a meat stew, whose main ingredients are small game animals or birds such as rabbit, hare, quail, or pigeon and flat bread, and may also include garlic, tomatoes, and mushrooms. It is cooked in a cauldron and served hot. Garlic and tomatoes may be added. Another well-known variant in La Mancha is gazpachos de pastor or galianos. Some other hot meat or fish dishes from several regions are also called gazpachos (gazpacho jumillano, gazpacho de Yecla, gazpacho de Requena, etc.).
Castilian variations.
Gazpacho is often eaten during the very hot and dry summers in Castilla y León. The gazpacho made in La Moraña in the province of Ávila has large pieces of vegetables floating in a watery soup.

</doc>
<doc id="12359" url="https://en.wikipedia.org/wiki?curid=12359" title="Gopher (disambiguation)">
Gopher (disambiguation)

A gopher, also known as a "pocket gopher" (family Geomyidae), is a burrowing rodent native to North America and Central America.
Gopher may also refer to:

</doc>
<doc id="12361" url="https://en.wikipedia.org/wiki?curid=12361" title="Gnome">
Gnome

A gnome is a diminutive spirit in Renaissance magic and alchemy, first introduced by Paracelsus in the 16th century and later adopted by more recent authors including those of modern fantasy literature. Its characteristics have been reinterpreted to suit the needs of various story tellers, but it is typically said to be a small humanoid that lives underground.
History.
Origins.
The word comes from Renaissance Latin "gnomus", which first appears in the works of 16th century Swiss alchemist Paracelsus, possibly deriving the term from Latin "gēnomos" (itself representing a Greek , literally "earth-dweller"). In this case, the omission of the "ē" is, as the Oxford English Dictionary (OED) calls it, a blunder. Alternatively, the term may be an original invention of Paracelsus.
Paracelsus uses "Gnomi" as a synonym of "Pygmæi", and classifies them as earth elementals. He describes them as two spans high, very reluctant to interact with humans, and able to move through solid earth as easily as humans move through air.
The chthonic, or earth-dwelling, spirit has precedents in numerous ancient and medieval mythologies, often guarding mines and precious underground treasures, notably in the Germanic dwarves and the Greek Chalybes, Telchines or Dactyls.
In Romanticism and modern fairy tales.
The English word is attested from the early 18th century. Gnomes are used in Alexander Pope's "The Rape of the Lock". The creatures from this mock-epic are small, celestial creatures which were prudish women in their past-lives, and now spend all of eternity looking out for prudish women (in parallel to the guardian angels in Catholic belief). Other uses of the term gnome remain obscure until the early 19th century, when it is taken up by authors of Romanticist collections of fairy tales and becomes mostly synonymous with the older word "goblin".
Pope's stated source, the French satire "Comte de Gabalis" (1670), used the term "gnomide" to refer to female gnomes (often "gnomid" in English translations).
In 19th century fiction, the chthonic gnome became a sort of antithesis to the more airy or luminous fairy. Nathaniel Hawthorne in "Twice-Told Tales" (1837) contrasts the two in "Small enough to be king of the fairies, and ugly enough to be king of the gnomes" (cited after OED). Similarly, gnomes are contrasted to elves, as in William Cullen Bryant's "Little People of the Snow" (1877), which has "let us have a tale of elves that ride by night, with jingling reins, or gnomes of the mine" (cited after OED).
One of the first movements in Mussorgsky's 1874 work "Pictures at an Exhibition", named "Gnomus" (Latin for "The Gnome"), is written to sound as if a gnome is moving about, his movements constantly changing in speed.
Franz Hartmann in 1895 satirized materialism in an allegorical tale entitled "Unter den Gnomen im Untersberg". The English translation appeared in 1896 as "Among the Gnomes: An Occult Tale of Adventure in the Untersberg". In this story, the "Gnomes" are still clearly subterranean creatures, guarding treasures of gold within the Untersberg mountain.
As a figure of 19th century fairy tales, the term gnome became largely synonymous with other terms for "little people" by the 20th century, such as "goblin", "brownie", "kobold", "leprechaun", "Heinzelmännchen" and other instances of the "domestic spirit" type, losing its strict association with earth or the underground world.
Cultural references.
Modern fantasy literature.
The name "gnome" has been used in the Fantasy genre, typically in a cunning role, e.g. as an inventor.
In L. Frank Baum's Oz series, the Nomes (so spelled), especially their king, are the chief adversaries of the Oz people. Ruth Plumly Thompson, who continued the series after Baum's death, reverted to the traditional spelling.
In C. S. Lewis's "The Chronicles of Narnia", gnomes, or "Earthmen" as they are sometimes called, live in the Underland, a series of subterranean caverns. Unlike the traditional, more humanlike gnomes, they can have a wide variety of physical features and skin colours. They are used as slaves by the Lady of the Green Kirtle.
J. R. R. Tolkien, in the legendarium surrounding his Elves, uses "Gnomes" as a name of the Noldor, the most gifted and technologically minded of his elvish races, in conscious exploitation of the similarity with "gnomic". "Gnomes" is thus Tolkien's English loan-translation of Quenya "Noldor", "those with knowledge". In "The Father Christmas Letters", which Tolkien wrote for his children, Red Gnomes are helpful creatures who come from Norway to the North Pole to assist Father Christmas and his Elves in fighting the wicked Goblins.
The Dutch books "Gnomes" and "The Secret Book of Gnomes", written by Wil Huygen, deal with gnomes living together in harmony. These same books are the basis for a made-for-TV animated film and the Spanish-animated series "The World of David the Gnome" (as well as the spin-off "Wisdom of the Gnomes").
In J. K. Rowling's "Harry Potter series", gnomes are pests that inhabit the gardens of witches and wizards. They are small creatures with heads that look like potatoes on small stubby bodies. Gnomes are considered harmless but mischievous. They are quite durable. They are often thrown great distances by witches and wizards but return to the gardens, completely unharmed.
In Terry Brooks' Shannara Series gnomes are an offshoot race created after the Great Wars. There are several distinctive classes of gnomes. Gnomes are the smallest race. In "The Sword of Shannara" they are considered to be tribal and warlike, the one race that can be the most easily subverted to an evil cause. This is evidenced by their allegiance to the Warlock Lord in "The Sword of Shannara" and to the Mord Wraiths in "The Wishsong of Shannara".
BB's "The Little Grey Men" (1942) is a story of the last gnomes in England, little wild men who live by hunting and fishing.
Derivative uses.
Garden gnomes.
After World War II (with early references, in ironic use, from the late 1930s) the diminutive figurines introduced as lawn ornaments during the 19th century came to be known as garden gnomes. The image of the gnome changed further during the 1960s to 1970s, when the first plastic garden gnomes were manufactured. These gnomes followed the style of the 1937 depiction of the seven dwarves in "Snow White and the Seven Dwarfs" by Disney. This "Disneyfied" image of the gnome was built upon by the illustrated children's book classic "The Secret Book of Gnomes" (1976), in the original Dutch "Leven en werken van de Kabouter". Garden gnomes share a resemblance to the Scandinavian tomte and nisse, and the Swedish term "tomte" can be translated to "gnome" in English.
Garden Gnome Liberationists.
Garden gnome liberationists such as the Gnome Liberation Front were introduced in France in 1997. They claim that Garden Gnomes deserve the same freedom that any other living creature would have. They are noted to have stolen hundreds of gnomes.
Gnome parades.
Gnome parades are held annually at Atlanta's Inman Park Festival. Numerous one-off gnome parades have been held, including in Savannah, Georgia (April 2012) and Cleveland, Ohio (May 2011).

</doc>
<doc id="12365" url="https://en.wikipedia.org/wiki?curid=12365" title="Googolplex">
Googolplex

A googolplex is the number 10, or equivalently, 10. Written out in ordinary decimal notation, it is 1 followed by 10100 zeroes, that is, a 1 followed by a googol of zeroes.
History.
In 1920 Edward Kasner's nine-year-old nephew, Milton Sirotta, coined the term "googol", which is 10, then proposed the further term "googolplex" to be "one, followed by writing zeroes until you get tired". Kasner decided to adopt a more formal definition "because different people get tired at different times and it would never do to have Carnera be a better mathematician than Dr. Einstein, simply because he had more endurance and could write for longer". It thus became standardized to 10.
Size.
A typical book can be printed with 10 zeros (around 400 pages with 50 lines per page and 50 zeros per line). Therefore, it requires 10 such books to print all the zeros of a googolplex (that is, printing a googol of zeros). If such a book would weigh 100 grams, all of them would weigh 10 kilograms. In comparison, Earth's mass is 5.972 x 10 kilograms.
In pure mathematics.
In pure mathematics, there are several notational methods for representing large numbers by which the magnitude of a googolplex could be represented, such as tetration, hyperoperation, Knuth's up-arrow notation, Steinhaus-Moser notation, or Conway chained arrow notation.
In the physical universe.
In the PBS science program "", , astronomer and television personality Carl Sagan estimated that writing a googolplex in full decimal form (i.e., "10,000,000,000...") would be physically impossible, since doing so would require more space than is available in the known universe.
One googol is presumed to be greater than the number of atoms in the observable universe, which has been estimated to be approximately 1078. Thus, in the physical world, it is difficult to give examples of numbers that compare to the vastly greater googolplex. However, in analyzing quantum states and black holes, physicist Don Page writes that "determining experimentally whether or not information is lost down black holes of solar mass ... would require more than 10 measurements to give a rough determination of the final density matrix after a black hole evaporates". And the end of the Universe via Big Freeze without proton decay is expected to be around 10 years into the future.
In a separate article, Page shows that the number of states in a black hole with a mass roughly equivalent to the Andromeda Galaxy is in the range of a googolplex.
Writing the number would take an extreme amount of time: if a person can write two digits per second, then writing a googolplex would take around about 1.51 years, which is about 1.1 times the accepted age of the universe.
Mod "n".
The residues (mod "n") of a googolplex are:

</doc>
<doc id="12366" url="https://en.wikipedia.org/wiki?curid=12366" title="Graphite">
Graphite

Graphite (), archaically referred to as plumbago, is a crystalline form of carbon, a semimetal, a native element mineral, and one of the allotropes of carbon. Graphite is the most stable form of carbon under standard conditions. Therefore, it is used in thermochemistry as the standard state for defining the heat of formation of carbon compounds. Graphite may be considered the highest grade of coal, just above anthracite and alternatively called meta-anthracite, although it is not normally used as fuel because it is difficult to ignite.
Types and varieties.
There are three principal types of natural graphite, each occurring in different types of ore deposit:
Occurrence.
Graphite occurs in metamorphic rocks as a result of the reduction of sedimentary carbon compounds during metamorphism. It also occurs in igneous rocks and in meteorites. Minerals associated with graphite include quartz, calcite, micas and tourmaline. In meteorites it occurs with troilite and silicate minerals. Small graphitic crystals in meteoritic iron are called cliftonite.
According to the United States Geological Survey (USGS), world production of natural graphite in 2012 was 1,100,000 tonnes, of which the following major exporters are: China (750 kt), India (150 kt), Brazil (75 kt), North Korea (30 kt) and Canada (26 kt). Graphite is not mined in the United States, but U.S. production of synthetic graphite in 2010 was 134 kt valued at $1.07 billion.
Properties.
Structure.
Graphite has a layered, planar structure. In each layer, the carbon atoms are arranged in a honeycomb lattice with separation of 0.142 nm, and the distance between planes is 0.335 nm. Atoms in the plane are bonded covalently, with only three of the four potential bonding sites satisfied. The fourth electron is free to migrate in the plane, making graphite electrically conductive. However, it does not conduct in a direction at right angles to the plane. Bonding between layers is via weak van der Waals bonds, which allows layers of graphite to be easily separated, or to slide past each other.
The two known forms of graphite, "alpha" (hexagonal) and "beta" (rhombohedral), have very similar physical properties, except the graphene layers stack slightly differently. The hexagonal graphite may be either flat or buckled. The alpha form can be converted to the beta form through mechanical treatment and the beta form reverts to the alpha form when it is heated above 1300 °C.
Other properties.
The acoustic and thermal properties of graphite are highly anisotropic, since phonons propagate quickly along the tightly-bound planes, but are slower to travel from one plane to another. Graphite's high thermal stability and electrical conductivity facilitate its widespread use as electrodes and refractories in high temperature material processing applications. However, in oxygen containing atmospheres graphite readily oxidizes to form CO2 at temperatures of 700 °C and above.
Graphite is an electric conductor, consequently, useful in such applications as arc lamp electrodes. It can conduct electricity due to the vast electron delocalization within the carbon layers (a phenomenon called aromaticity). These valence electrons are free to move, so are able to conduct electricity. However, the electricity is primarily conducted within the plane of the layers. The conductive properties of powdered graphite allows its use as pressure sensor in carbon microphones.
Graphite and graphite powder are valued in industrial applications for their self-lubricating and dry lubricating properties. There is a common belief that graphite's lubricating properties are solely due to the loose interlamellar coupling between sheets in the structure. However, it has been shown that in a vacuum environment (such as in technologies for use in space), graphite is a very poor lubricant. This observation led to the hypothesis that the lubrication is due to the presence of fluids between the layers, such as air and water, which are naturally adsorbed from the environment. This hypothesis has been refuted by studies showing that air and water are not absorbed. Recent studies suggest that an effect called superlubricity can also account for graphite's lubricating properties. The use of graphite is limited by its tendency to facilitate pitting corrosion in some stainless steel, and to promote galvanic corrosion between dissimilar metals (due to its electrical conductivity). It is also corrosive to aluminium in the presence of moisture. For this reason, the US Air Force banned its use as a lubricant in aluminium aircraft, and discouraged its use in aluminium-containing automatic weapons. Even graphite pencil marks on aluminium parts may facilitate corrosion. Another high-temperature lubricant, hexagonal boron nitride, has the same molecular structure as graphite. It is sometimes called "white graphite", due to its similar properties.
When a large number of crystallographic defects bind these planes together, graphite loses its lubrication properties and becomes what is known as pyrolytic graphite. It is also highly anisotropic, and diamagnetic, thus it will float in mid-air above a strong magnet. If it is made in a fluidized bed at 1000–1300 °C then it is isotropic turbostratic, and is used in blood contacting devices like mechanical heart valves and is called pyrolytic carbon, and is not diamagnetic. Pyrolytic graphite, and pyrolytic carbon are often confused but are very different materials.
Natural and crystalline graphites are not often used in pure form as structural materials, due to their shear-planes, brittleness and inconsistent mechanical properties.
History of natural graphite use.
In the 4th millennium B.C., during the Neolithic Age in southeastern Europe, the Mariţa culture used graphite in a ceramic paint for decorating pottery.
Some time before 1565 (some sources say as early as 1500), an enormous deposit of graphite was discovered on the approach to Grey Knotts from the hamlet of Seathwaite in Borrowdale parish, Cumbria, England, which the locals found very useful for marking sheep. During the reign of Elizabeth I (1533–1603), Borrowdale graphite was used as a refractory material to line moulds for cannonballs, resulting in rounder, smoother balls that could be fired farther, contributing to the strength of the English navy. This particular deposit of graphite was extremely pure and soft, and could easily be broken into sticks. Because of its military importance, this unique mine and its production were strictly controlled by the Crown.
Other names.
Historically, graphite was called black lead or plumbago.
Plumbago was commonly used in its massive mineral form. Both of these names arise from confusion with the similar-appearing lead ores, particularly galena. The Latin word for lead, "plumbum", gave its name to the English term for this grey metallic-sheened mineral and even to the leadworts or plumbagos, plants with flowers that resemble this colour.
The term "black lead" usually refers to a powdered or processed graphite, matte black in color.
Abraham Gottlob Werner coined the name "graphite" ("writing stone") in 1789. He attempted to clear up the confusion between molybdena, plumbago and blacklead after Carl Wilhelm Scheele in 1778 proved that there are at least three different minerals. Scheele's analysis showed that the chemical compounds molybdenum sulfide (molybdenite), lead(II) sulfide (galena) and graphite were three different soft black minerals.
Uses of natural graphite.
Natural graphite is mostly consumed for refractories, batteries, steelmaking, expanded graphite, brake linings, foundry facings and lubricants. Graphene, which occurs naturally in graphite, has unique physical properties and is among the strongest substances known. However, the process of separating it from graphite will require more technological development.
Refractories.
This end-use began before 1900 with the graphite crucible used to hold molten metal; this is now a minor part of refractories. In the mid-1980s, the carbon-magnesite brick became important, and a bit later the alumina-graphite shape. Currently the order of importance is alumina-graphite shapes, carbon-magnesite brick, monolithics (gunning and ramming mixes), and then crucibles.
Crucibles began using very large flake graphite, and carbon-magnesite brick requiring not quite so large flake graphite; for these and others there is now much more flexibility in size of flake required, and amorphous graphite is no longer restricted to low-end refractories. Alumina-graphite shapes are used as continuous casting ware, such as nozzles and troughs, to convey the molten steel from ladle to mold, and carbon magnesite bricks line steel converters and electric arc furnaces to withstand extreme temperatures. Graphite Blocks are also used in parts of blast furnace linings where the high thermal conductivity of the graphite is critical. High-purity monolithics are often used as a continuous furnace lining instead of the carbon-magnesite bricks.
The US and European refractories industry had a crisis in 2000–2003, with an indifferent market for steel and a declining refractory consumption per tonne of steel underlying firm buyouts and many plant closures. Many of the plant closures resulted from the acquisition of Harbison-Walker Refractories by RHI AG and some plants had their equipment auctioned off. Since much of the lost capacity was for carbon-magnesite brick, graphite consumption within refractories area moved towards alumina-graphite shapes and monolithics, and away from the brick. The major source of carbon-magnesite brick is now imports from China. Almost all of the above refractories are used to make steel and account for 75% of refractory consumption; the rest is used by a variety of industries, such as cement.
According to the USGS, US natural graphite consumption in refractories was 12,500 tonnes in 2010.
Batteries.
The use of graphite in batteries has been increasing in the last 30 years. Natural and synthetic graphite are used to construct the anode of all major battery technologies. The lithium-ion battery utilizes roughly twice the amount of graphite than lithium carbonate.
The demand for batteries, primarily nickel-metal-hydride and lithium-ion batteries, has caused a growth in graphite demand in the late 1980s and early 1990s. This growth was driven by portable electronics, such as portable CD players and power tools. Laptops, mobile phones, tablet, and smartphone products have increased the demand for batteries. Electric vehicle batteries are anticipated to increase graphite demand. As an example, a lithium-ion battery in a fully electric Nissan Leaf contains nearly 40 kg of graphite.
Steelmaking.
Natural graphite in this end use mostly goes into carbon raising in molten steel, although it can be used to lubricate the dies used to extrude hot steel. Supplying carbon raisers is very competitive, therefore subject to cut-throat pricing from alternatives such as synthetic graphite powder, petroleum coke, and other forms of carbon. A carbon raiser is added to increase the carbon content of the steel to the specified level. An estimate based on USGS US graphite consumption statistics indicates that 10,500 tonnes were used in this fashion in 2005.
Brake linings.
Natural amorphous and fine flake graphite are used in brake linings or brake shoes for heavier (nonautomotive) vehicles, and became important with the need to substitute for asbestos. This use has been important for quite some time, but nonasbestos organic (NAO) compositions are beginning to reduce graphite's market share. A brake-lining industry shake-out with some plant closures has not been beneficial, nor has an indifferent automotive market. According to the USGS, US natural graphite consumption in brake linings was 6,510 tonnes in 2005.
Foundry facings and lubricants.
A foundry facing mold wash is a water-based paint of amorphous or fine flake graphite. Painting the inside of a mold with it and letting it dry leaves a fine graphite coat that will ease separation of the object cast after the hot metal has cooled. Graphite lubricants are specialty items for use at very high or very low temperatures, as forging die lubricant, an antiseize agent, a gear lubricant for mining machinery, and to lubricate locks. Having low-grit graphite, or even better no-grit graphite (ultra high purity), is highly desirable. It can be used as a dry powder, in water or oil, or as colloidal graphite (a permanent suspension in a liquid). An estimate based on USGS graphite consumption statistics indicates that 2,200 tonnes was used in this fashion in 2005.
Pencils.
The ability to leave marks on paper and other objects gave graphite its name, given in 1789 by German mineralogist Abraham Gottlob Werner. It stems from "graphein", meaning "to write/draw" in Ancient Greek.
From the 16th Century, pencils were made with leads of English natural graphite, but modern pencil lead is most commonly a mix of powdered graphite and clay; it was invented by Nicolas-Jacques Conté in 1795. It is chemically unrelated to the metal lead, whose ores had a similar appearance, hence the continuation of the name. Plumbago is another older term for natural graphite used for drawing, typically as a lump of the mineral without a wood casing. The term plumbago drawing is normally restricted to 17th and 18th century works, mostly portraits.
Today, pencils are still a small but significant market for natural graphite. Around 7% of the 1.1 million tonnes produced in 2011 was used to make pencils. Low-quality amorphous graphite is used and sourced mainly from China.
Other uses.
Natural graphite has found uses in zinc-carbon batteries, in electric motor brushes, and various specialized applications. Graphite of various hardness or softness results in different qualities and tones when used as an artistic medium. Railroads would often mix powdered graphite with waste oil or linseed oil to create a heat resistant protective coating for the exposed portions of a steam locomotive's boiler, such as the smokebox or lower part of the firebox.
Expanded graphite.
Expanded graphite is made by immersing natural flake graphite in a bath of chromic acid, then concentrated sulfuric acid, which forces the crystal lattice planes apart, thus expanding the graphite. The expanded graphite can be used to make graphite foil or used directly as "hot top" compound to insulate molten metal in a ladle or red-hot steel ingots and decrease heat loss, or as firestops fitted around a fire door or in sheet metal collars surrounding plastic pipe (during a fire, the graphite expands and chars to resist fire penetration and spread), or to make high-performance gasket material for high-temperature use. After being made into graphite foil, the foil is machined and assembled into the bipolar plates in fuel cells.
The foil is made into heat sinks for laptop computers which keeps them cool while saving weight, and is made into a foil laminate that can be used in valve packings or made into gaskets. Old-style packings are now a minor member of this grouping: fine flake graphite in oils or greases for uses requiring heat resistance. A GAN estimate of current US natural graphite consumption in this end use is 7,500 tonnes.
Intercalated graphite.
Graphite forms intercalation compounds with some metals and small molecules. In these compounds, the host molecule or atom gets "sandwiched" between the graphite layers, resulting in a type of compounds with variable stoichiometry. A prominent example of an intercalation compound is potassium graphite, denoted by the formula KC8. Graphite intercalation compounds are superconductors. The highest transition temperature (by June 2009) Tc = 11.5 K is achieved in CaC6, and it further increases under applied pressure (15.1 K at 8 GPa).
Uses of synthetic graphite.
Invention of a process to produce synthetic graphite.
A process to make synthetic graphite was invented accidentally by Edward Goodrich Acheson (1856–1931). In the mid-1890s, Acheson discovered that overheating carborundum, which he is also credited with discovering, produced almost pure graphite. While studying the effects of high temperature on carborundum, he had found that silicon vaporizes at about 4,150 °C (7,500 °F), leaving the carbon behind in graphitic carbon. This graphite was another major discovery for him, and it became extremely valuable and helpful as a lubricant.
In 1896 Acheson received a patent for his method of synthesizing graphite, and in 1897 started commercial production. The Acheson Graphite Co. was formed in 1899. In 1928 this company was merged with National Carbon Company (now GrafTech International). Acheson also developed a variety of colloidal graphite products including Oildag and Aquadag. These were later manufactured by the Acheson Colloids Co. (now Acheson Industries, a unit of Henkel AG).
Scientific research.
Highly oriented pyrolytic graphite (HOPG) is the highest-quality synthetic form of graphite. It is used in scientific research, in particular, as a length standard for scanner calibration of scanning probe microscope.
Electrodes.
Graphite electrodes carry the electricity that melts scrap iron and steel (and sometimes direct-reduced iron: DRI) in electric arc furnaces, which are the vast majority of steel furnaces. They are made from petroleum coke after it is mixed with coal tar pitch. They are then extruded and shaped, baked to carbonize the binder (pitch), and finally graphitized by heating it to temperatures approaching 3000 °C, at which the carbon atoms arrange into graphite. They can vary in size up to 11 feet long and 30 inches in diameter. An increasing proportion of global steel is made using electric arc furnaces, and the electric arc furnace itself is getting more efficient, making more steel per tonne of electrode. An estimate based on USGS data indicates that graphite electrode consumption was 197,000 tonnes in 2005.
On a much smaller scale, graphite is also used for making electrodes for electrical discharge machining (EDM), commonly used to make plastic injection molds. Graphite is also used as an electrode in electrolytically processing of Aluminium.
Powder and scrap.
The powder is made by heating powdered petroleum coke above the temperature of graphitization, sometimes with minor modifications. The graphite scrap comes from pieces of unusable electrode material (in the manufacturing stage or after use) and lathe turnings, usually after crushing and sizing. Most synthetic graphite powder goes to carbon raising in steel (competing with natural graphite), with some used in batteries and brake linings. According to the USGS, US synthetic graphite powder and scrap production was 95,000 tonnes in 2001 (latest data).
Neutron moderator.
Special grades of synthetic graphite also find use as a matrix and neutron moderator within nuclear reactors. Its low neutron cross-section also recommends it for use in proposed fusion reactors. Care must be taken that reactor-grade graphite is free of neutron absorbing materials such as boron, widely used as the seed electrode in commercial graphite deposition systems—this caused the failure of the Germans' World War II graphite-based nuclear reactors. Since they could not isolate the difficulty they were forced to use far more expensive heavy water moderators. Graphite used for nuclear reactors is often referred to as nuclear graphite.
Other uses.
Graphite (carbon) fiber and carbon nanotubes are also used in carbon fiber reinforced plastics, and in heat-resistant composites such as reinforced carbon-carbon (RCC). Commercial structures made from carbon fiber graphite composites include fishing rods, golf club shafts, bicycle frames, sports car body panels, the fuselage of the Boeing 787 Dreamliner and pool cue sticks and have been successfully employed in reinforced concrete, The mechanical properties of carbon fiber graphite-reinforced plastic composites and grey cast iron are strongly influenced by the role of graphite in these materials. In this context, the term "(100%) graphite" is often loosely used to refer to a pure mixture of carbon reinforcement and resin, while the term "composite" is used for composite materials with additional ingredients.
Modern smokeless powder is coated in graphite to prevent the buildup of static charge.
Graphite has been used in at least three radar absorbent materials. It was mixed with rubber in Sumpf and Schornsteinfeger, which were used on U-boat snorkels to reduce their radar cross section. It was also used in tiles on early F-117 Nighthawk (1983)s.
Graphite mining, beneficiation, and milling.
Graphite is mined by both open pit and underground methods. Graphite usually needs beneficiation. This may be carried out by hand-picking the pieces of gangue (rock) and hand-screening the product or by crushing the rock and floating out the graphite. Beneficiation by flotation encounters the difficulty that graphite is very soft and "marks" (coats) the particles of gangue. This makes the "marked" gangue particles float off with the graphite, yielding impure concentrate. There are two ways of obtaining a commercial concentrate or product: repeated regrinding and floating (up to seven times) to purify the concentrate, or by acid leaching (dissolving) the gangue with hydrofluoric acid (for a silicate gangue) or hydrochloric acid (for a carbonate gangue).
In milling, the incoming graphite products and concentrates can be ground before being classified (sized or screened), with the coarser flake size fractions (below 8 mesh, 8–20 mesh, 20–50 mesh) carefully preserved, and then the carbon contents are determined. Some standard blends can be prepared from the different fractions, each with a certain flake size distribution and carbon content. Custom blends can also be made for individual customers who want a certain flake size distribution and carbon content. If flake size is unimportant, the concentrate can be ground more freely. Typical end products include a fine powder for use as a slurry in oil drilling and coatings for foundry molds, carbon raiser in the steel industry (Synthetic graphite powder and powdered petroleum coke can also be used as carbon raiser). Environmental impacts from graphite mills consist of air pollution including fine particulate exposure of workers and also soil contamination from powder spillages leading to heavy metals contaminations of soil.
Occupational safety.
People can be exposed to graphite in the workplace by breathing it in, skin contact, and eye contact.
United States.
The Occupational Safety and Health Administration (OSHA) has set the legal limit (permissible exposure limit) for graphite exposure in the workplace as a time weighted average (TWA) of 15 millions of particles per cubic foot (1.5 mg/m3) over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of TWA 2.5 mg/m3 respirable dust over an 8-hour workday. At levels of 1250 mg/m3, graphite is immediately dangerous to life and health.
Graphite recycling.
The most common way of recycling graphite occurs when synthetic graphite electrodes are either manufactured and pieces are cut off or lathe turnings are discarded, or the electrode (or other) are used all the way down to the electrode holder. A new electrode replaces the old one, but a sizeable piece of the old electrode remains. This is crushed and sized, and the resulting graphite powder is mostly used to raise the carbon content of molten steel. Graphite-containing refractories are sometimes also recycled, but often not because of their graphite: the largest-volume items, such as carbon-magnesite bricks that contain only 15–25% graphite, usually contain too little graphite. However, some recycled carbon-magnesite brick is used as the basis for furnace-repair materials, and also crushed carbon-magnesite brick is used in slag conditioners. While crucibles have a high graphite content, the volume of crucibles used and then recycled is very small.
A high-quality flake graphite product that closely resembles natural flake graphite can be made from steelmaking kish. Kish is a large-volume near-molten waste skimmed from the molten iron feed to a basic oxygen furnace, and consists of a mix of graphite (precipitated out of the supersaturated iron), lime-rich slag, and some iron. The iron is recycled on site, leaving a mixture of graphite and slag. The best recovery process uses hydraulic classification (which utilizes a flow of water to separate minerals by specific gravity: graphite is light and settles nearly last) to get a 70% graphite rough concentrate. Leaching this concentrate with hydrochloric acid gives a 95% graphite product with a flake size ranging from 10 mesh down.

</doc>
<doc id="12367" url="https://en.wikipedia.org/wiki?curid=12367" title="Garry Trudeau">
Garry Trudeau

Garretson Beekman "Garry" Trudeau (born July 21, 1948) is an American cartoonist, best known for the Pulitzer Prize-winning "Doonesbury" comic strip. Trudeau is also the creator and executive producer of the Amazon Studios political comedy series "Alpha House".
Background and education.
Trudeau was born in New York City, the son of Jean Douglas (née Moore) and Francis Berger Trudeau, Jr. He is the great-grandson of Dr. Edward Livingston Trudeau, who created Adirondack Cottage Sanitarium for the treatment of pulmonary tuberculosis at Saranac Lake, New York. Edward was succeeded by his son Francis and grandson Francis Jr. The latter founded the Trudeau Institute at Saranac Lake, with which his son Garry retains a connection. Among his great-great-great-grandfathers were Bishop Richard Channing Moore (through his father) and the New York politician Francis E. Spinner (through his mother). Trudeau is also a descendant of Gerardus Beekman, one of the earliest colonial governors of the Province of New York. His ancestry includes French (Canadian), English, Dutch, German, and Swedish.
Raised in Saranac Lake, Garry Trudeau attended St. Paul's School in Concord, New Hampshire. He enrolled in Yale University in 1966. As an art major, Trudeau initially focused on painting, but soon discovered a greater interest in the graphic arts. He spent much of his time cartooning and writing for Yale's humor magazine "The Yale Record", eventually serving as the magazine's editor-in-chief. At the same time, Trudeau began contributing to the "Yale Daily News", which eventually led to the creation of "Bull Tales", a comic strip parodying the exploits of Yale quarterback Brian Dowling. This strip was the progenitor of "Doonesbury". While still an undergraduate at Yale, Trudeau published two collections of "Bull Tales": "Bull Tales" (1969, published by the "Yale Daily News") and "Michael J." (1970, published by "The Yale Record"). As a senior, Trudeau became a member of Scroll and Key. He did postgraduate work at the Yale School of Art, earning a master of fine arts degree in graphic design in 1973. It was there that Trudeau first met photographer David Levinthal, with whom he would later collaborate on "Hitler Moves East", an influential "graphic chronicle" of the German invasion of the Soviet Union.
Creative works.
Soon after "Bull Tales" began running in the Yale student newspaper, the strip caught the attention of the newly formed Universal Press Syndicate. The syndicate's editor, James F. Andrews, recruited Trudeau, changed the strip's name to "Doonesbury", and began distributing it following the cartoonist's graduation in 1970.
Today "Doonesbury" is syndicated to 1,000 daily and Sunday newspapers worldwide and is accessible online in association with "The Washington Post" at doonesbury.com. The strip has been collected in 72 hardcover, trade paperback, and mass-market editions, which have cumulatively sold over seven million copies worldwide.
In 1975, Trudeau became the first comic strip artist to win a Pulitzer, traditionally awarded to editorial-page cartoonists. He was also a Pulitzer finalist in 1990, 2004, and 2005. Other awards include the National Cartoonist Society Newspaper Comic Strip Award in 1994, and the Reuben Award in 1995. In 1993, Trudeau was made a fellow of the American Academy of Arts and Sciences. Wiley Miller, fellow comic-strip artist responsible for "Non Sequitur", called him "far and away the most influential editorial cartoonist in the last 25 years." A regular graduation speaker, Trudeau has received 34 honorary degrees, including doctorates from Yale, Brown, Colgate, Williams, University of Pennsylvania, Tufts, Johns Hopkins, Duke, and University College Dublin.
In addition to his creating his strip, Trudeau has worked in both theater and television. He was nominated for an Oscar in 1977 in the category of Animated Short Film for "A Doonesbury Special", created for NBC in collaboration with John Hubley and Faith Hubley. The film went on to win the Cannes Film Festival Jury Special Prize in 1978. Collaborating with composer Elizabeth Swados in 1984, he wrote the book and lyrics for the Broadway musical "Doonesbury", for which he was nominated for two Drama Desk Awards. A cast album of the show, recorded for MCA, received a Grammy nomination. Trudeau again collaborated with Swados in 1984, this time on "Rap Master Ronnie", a satirical review about the Reagan Administration that opened off-Broadway at the Village Gate. A filmed version, featuring Jon Cryer, the Smothers Brothers, and Carol Kane, was broadcast on Cinemax in 1988.
Also in 1988, Trudeau wrote and co-produced with director Robert Altman HBO's critically acclaimed Tanner '88, a satiric look at that year's presidential election campaign. The show won the gold medal for Best Television Series at the Cannes Television Festival, the British Academy Television Award for Best Foreign Program, and Best Imported Program from the British Broadcasting Press Guild. It also earned an Emmy Award, as well as four ACE Award nominations. In 2004, Trudeau reunited with Altman to write and co-produce a sequel mini-series, Tanner on Tanner, for the Sundance Channel.
In 1996, "Newsweek" and the "Washington Post" speculated that Trudeau wrote the novel "Primary Colors", which was later revealed to have been written by Joe Klein.
In February 2000, Trudeau, working with Dotcomix, launched "Duke2000", a web-based presidential campaign featuring a real-time, 3-D, streaming-animation version of Duke. Nearly 30 campaign videos were created for the site, and Ambassador Duke was interviewed live by satellite on the Today Show, Larry King Live, The Charlie Rose Show and dozens of local TV and radio news shows.
In 2013, Trudeau created, wrote and co-produced "Alpha House", a political sit-com starring John Goodman that revolves around four Republican U.S. Senators who live together in a townhouse on Capitol Hill. Trudeau was inspired to write the show's pilot after reading a 2007 "New York Times" article about a real D.C. townhouse shared by New York Senator Chuck Schumer, Illinois Senator Dick Durbin of Illinois, and California Representative George Miller, all Democrats. The pilot for "Alpha House" was produced by Amazon Studios and aired in early 2013. Due to positive response, Amazon picked up the show to develop into a full series, streaming eleven episodes for its first season. On March 31, 2014, Amazon announced that "Alpha House" had been renewed. Production began in July 2014, and the entire second season became available for streaming on October 24, 2014.
While writing "Alpha House", Trudeau put the daily Doonesbury into rerun mode. On March 3, 2014 the "Classic Doonesbury" series began, featuring approximately four weeks of daily strips from each year of the strip's run. He continues to produce new strips for Sundays.
Trudeau has contributed articles to publications such as "Harper's", "Rolling Stone", "The New Republic", "The New Yorker", "New York" and "The Washington Post". From 1990 to 1994, he wrote and drew an occasional column for "The New York Times" op-ed page, and was a contributing essayist for "Time" magazine from 1996 to 2001.
Beginning with the Gulf War in 1991, Trudeau has written about military issues extensively. In recognition for his work on wounded warriors, he has been presented with the Commander's Award for Public Service by the Department of the Army, the Commander's Award from Disabled American Veterans, the President's Award for Excellence in the Arts from Vietnam Veterans of America, the Distinguished Public Service Award from the American Academy of Physical Medicine and Rehabilitation, the Mental Health Research Advocacy Award from the Yale School of Medicine, and a special citation from the Vet Centers. He also received several unit commendations from the field during the Gulf War, and traveled with the USO to visit troops in Iraq and Afghanistan. From 2005 to 2014, his website hosted "The Sandbox", a milblog posting over 800 essays by deployed soldiers, returned vets, caregivers, and spouses.
For most the strip's run, Trudeau has eschewed merchandising, but starting in 1998 he teamed up with Starbucks to create "Doonesbury" products to raise funds for local literacy programs. The items were offered for sale in Starbucks stores for nearly two years and raised over $1 million. Also for charity, Trudeau licensed the strip to Ben & Jerry's, which created a best-selling sorbet flavor called "Doonesberry".
Private life and public appearances.
Trudeau married the journalist Jane Pauley in 1980. They have three children and live in New York City. He maintains a low personal profile. A rare and early appearance on television was as a guest on "To Tell the Truth" in 1971, where only one of the three panelists guessed his identity. On February 8, 1976, "Doonesbury" made the cover of "Time", under the headline "Doonesbury: Politics in the Funny Pages" but Trudeau declined to be interviewed for the story.
In 1990, Trudeau appeared on the cover of "Newsweek" for a story called "Inside Doonesbury's Brain," written by Jonathan Alter. This was the first interview Trudeau had given in seventeen years. Trudeau and Alter became friends after the interview and would collaborate years later as executive producers on the Amazon political series "Alpha House".
Trudeau cooperated extensively with "Wired" magazine for a 2000 profile, "The Revolution Will be Satirized." He later spoke with the writer of that article, Edward Cone, for a 2004 newspaper column in the Greensboro, NC "News & Record", about the war wounds suffered by the Doonesbury character B.D., and in 2006 did a Q&A at Cone's personal blog about his new site, The Sandbox.
On December 2, 2002, Trudeau did the first of two back-to-back half-hour interviews with Ted Koppel for ABC News's "Up Close". They were the first television interviews he had done in 31 years.
Trudeau granted an interview to "Rolling Stone" in 2004 in which he discussed his time at Yale University, which he attended two years behind George W. Bush. He granted another Rolling Stone interview in 2010.
In 2006, "The Washington Post" printed an extensive profile of Trudeau by writer Gene Weingarten. He has also appeared on the "Charlie Rose" television program, and at signings for "The Long Road Home: One Step at a Time", his "Doonesbury" book about B.D.'s struggle with injuries received during the second Gulf War.
On December 6, 2010, Trudeau appeared on "The Colbert Report" on Comedy Central to speak about "".
On December 17, 2013, Trudeau again appeared on Comedy Central's "The Colbert Report" to talk about the inspiration for his political comedy series "Alpha House".
Criticisms and controversies.
"Doonesbury" has been controversial since its inception. On countless occasions throughout its run, editors have removed the strip from their newspapers over content they judged inappropriate for their readerships. While Trudeau has not always agreed with the reasoning, he has consistently defended editorial prerogative, declining to characterize his strip's removal as censorship. In 2012, a series about a new abortion law in Texas was removed from at least 50 newspapers, generating far more comment and press attention than any other strip controversy in the past.
Media response through the years has been no less contentious. The "Saturday Review" once voted Trudeau one of the "Most Overrated People in American Arts and Letters", stating that after his hiatus, his comic strip was "predictable, mean-spirited, and not as funny as before." In "The Daily Caller", Jim Treacher wrote that Trudeau is a "dinosaur" who is "incapable of writing a character who doesn't sound like Trudeau." Eric Alterman writing in "The Nation", however, called "Doonesbury", "one of the great intellectual/artistic accomplishments of the past half-century, irrespective of category."
Trudeau's acceptance speech on the occasion of receiving a Polk Award for lifetime achievement stirred controversy. In his speech, Trudeau criticized the cartoonists of Charlie Hebdo for "punching downward..., attacking a powerless, disenfranchised minority with crude, vulgar drawings closer to graffiti than cartoons" and thereby wandering "into the realm of hate speech" with cartoons of Muhammad.
Writing in "The Atlantic", the journal in which Trudeau had published his speech, political commentator David Frum criticized what he called Trudeau's "moral theory" that calls for identifying "the bearer of privilege," then holding "the privilege-bearer responsible."
Trudeau was labelled a "terror apologist" by the editors of "The New York Post" for his comments and particularly the venue in which he expressed them, i.e. while accepting Long Island University's George Polk award for lifetime achievement in journalism.

</doc>
<doc id="12369" url="https://en.wikipedia.org/wiki?curid=12369" title="Guild">
Guild

Guilds were and are associations of artisans or merchants who control the practice of their craft in a particular town. The earliest types of guild were formed as confraternities of tradesmen. They were organized in a manner something between a professional association, trade union, a cartel, and a secret society. They often depended on grants of letters patent by a monarch or other authority to enforce the flow of trade to their self-employed members, and to retain ownership of tools and the supply of materials. A lasting legacy of traditional guilds are the guildhalls constructed and used as meeting places.
An important result of the guild framework was the emergence of universities at Bologna (established in 1088), Oxford (at least since 1096) and Paris (c. 1150).
Early guildlike associations.
In medieval cities, craftsmen tended to form associations based on their trades, confraternities of textile workers, masons, carpenters, carvers, glass workers, each of whom controlled secrets of traditionally imparted technology, the "arts" or "mysteries" of their crafts. Usually the founders were free independent master craftsmen who hired apprentices.
Medieval guild.
There were several types of guilds, including the two main categories of merchant guilds and craft guilds but also the frith guild and religious guild.
The continental system of guilds and merchants arrived in England after the Norman Conquest, with incorporated societies of merchants in each town or city holding exclusive rights of doing business there. In many cases they became the governing body of a town. For example, London's Guildhall became the seat of the Court of Common Council of the City of London Corporation, the world’s oldest continuously elected local government whose members to this day must be Freemen of the City. The Freedom of the City, effective from the Middle Ages until 1835, gave the right to trade, and was only bestowed upon members of a Guild or Livery.
Trade guilds arose in the 14th century as craftsmen united to protect their common interest.
Early egalitarian communities called "guilds" (for the gold deposited in their common funds) were denounced by Catholic clergy for their "conjurations"—the binding oaths sworn among the members to support one another in adversity, kill specific enemies, and back one another in feuds or in business ventures. The occasion for these oaths were drunken banquets held on December 26, the pagan feast of Jul: Bishop Hincmar, in 858, sought vainly to Christianize them.
In the Early Middle Ages, most of the Roman craft organizations, originally formed as religious confraternities, had disappeared, with the apparent exceptions of stonecutters and perhaps glassmakers, mostly the people that had local skills. Gregory of Tours tells a miraculous tale of a builder whose art and techniques suddenly left him, but were restored by an apparition of the Virgin Mary in a dream. Michel Rouche remarks that the story speaks for the importance of practically transmitted journeymanship.
In France, guilds were called "corps de métiers". According to Viktor Ivanovich Rutenburg, "Within the guild itself there was very little division of labour, which tended to operate rather between the guilds. Thus, according to Étienne Boileau's Book of Handicrafts, by the mid-13th century there were no less than 100 guilds in Paris, a figure which by the 14th century had risen to 350." There were different guilds of metal-workers: the farriers, knife-makers, locksmiths, chain-forgers, nail-makers, often formed separate and distinct corporations; the armourers were divided into helmet-makers, escutcheon-makers, harness-makers, harness-polishers, etc. In Catalan towns, specially at Barcelona, guilds or "gremis" were a basic agent in the society: a shoemakers' guild is recorded in 1202.
In England, specifically in the City of London Corporation, more than 110 guilds, referred to as livery companies, survive today, with the oldest more than a thousand years old. Other groups, such as the Worshipful Company of Tax Advisers, have been formed far more recently. Membership in a livery company is expected for individuals participating in the governance of "The City", as the Lord Mayor and the Remembrancer.
The guild system reached a mature state in Germany circa 1300 and held on in German cities into the 19th century, with some special privileges for certain occupations remaining today. In the 15th century, Hamburg had 100 guilds, Cologne 80, and Lübeck 70. The latest guilds to develop in Western Europe were the "" of Spain: e.g., Valencia (1332) or Toledo (1426).
Not all city economies were controlled by guilds; some cities were "free." Where guilds were in control, they shaped labor, production and trade; they had strong controls over instructional capital, and the modern concepts of a lifetime progression of apprentice to craftsman, journeyman, and eventually to widely recognized master and grandmaster began to emerge. In order to become a Master, a Journeyman would have to go on a three-year voyage called Journeyman years. The practice of the Journeyman years still exists in Germany and France.
As production became more specialized, trade guilds were divided and subdivided, eliciting the squabbles over jurisdiction that produced the paperwork by which economic historians trace their development: The metalworking guilds of Nuremberg were divided among dozens of independent trades in the boom economy of the 13th century, and there were 101 trades in Paris by 1260. In Ghent, as in Florence, the woolen textile industry developed as a congeries of specialized guilds. The appearance of the European guilds was tied to the emergent money economy, and to urbanization. Before this time it was not possible to run a money-driven organization, as commodity money was the normal way of doing business.
The guild was at the center of European handicraft organization into the 16th century. In France, a resurgence of the guilds in the second half of the 17th century is symptomatic of the monarchy's concerns to impose unity, control production and reap the benefits of transparent structure in the shape of more efficient taxation. 
The guilds were identified with organizations enjoying certain privileges (letters patent), usually issued by the king or state and overseen by local town business authorities (some kind of chamber of commerce). These were the predecessors of the modern patent and trademark system. The guilds also maintained funds in order to support infirm or elderly members, as well as widows and orphans of guild members, funeral benefits, and a 'tramping' allowance for those needing to travel to find work. As the guild system of the City of London declined during the 17th century, the Livery Companies transformed into mutual assistance fraternities along such lines.
European guilds imposed long standardized periods of apprenticeship, and made it difficult for those lacking the capital to set up for themselves or without the approval of their peers to gain access to materials or knowledge, or to sell into certain markets, an area that equally dominated the guilds' concerns. These are defining characteristics of mercantilism in economics, which dominated most European thinking about political economy until the rise of classical economics.
The guild system survived the emergence of early capitalists, which began to divide guild members into "haves" and dependent "have-nots". The civil struggles that characterize the 14th-century towns and cities were struggles in part between the greater guilds and the lesser artisanal guilds, which depended on piecework. "In Florence, they were openly distinguished: the "Arti maggiori" and the "Arti minori"—already there was a "popolo grasso" and a "popolo magro"". Fiercer struggles were those between essentially conservative guilds and the merchant class, which increasingly came to control the means of production and the capital that could be ventured in expansive schemes, often under the rules of guilds of their own. German social historians trace the "Zunftrevolution", the urban revolution of guildmembers against a controlling urban patriciate, sometimes reading into them, however, perceived foretastes of the class struggles of the 19th century.
In the countryside, where guild rules did not operate, there was freedom for the entrepreneur with capital to organize cottage industry, a network of cottagers who spun and wove in their own premises on his account, provided with their raw materials, perhaps even their looms, by the capitalist who took a share of the profits. Such a dispersed system could not so easily be controlled where there was a vigorous local market for the raw materials: wool was easily available in sheep-rearing regions, whereas silk was not.
Organization.
In Florence, Italy, there were seven to 12 "greater guilds" and 14 "lesser guilds" the most important of the greater guilds was that for judges and notaries, who handled the legal business of all the other guilds and often served as an arbitrator of disputes. Other greater guilds include the wool, silk, and the money changers' guilds. They prided themselves on a reputation for very high quality work, which was rewarded with premium prices. The guilds fined members who deviated from standards. Other greater guilds included those of doctors, druggists, and furriers. Among the lesser guilds, were those for bakers, saddle makers, ironworkers and other artisans. They had a sizable membership, but lacked the political and social standing necessary to influence city affairs.
The guild was made up by experienced and confirmed experts in their field of handicraft. They were called master craftsmen. Before a new employee could rise to the level of mastery, he had to go through a schooling period during which he was first called an apprentice. After this period he could rise to the level of journeyman. Apprentices would typically not learn more than the most basic techniques until they were trusted by their peers to keep the guild's or company's secrets.
Like "journey", the distance that could be travelled in a day, the title 'journeyman' derives from the French words for 'day' ("jour" and "journée") from which came the middle English word "journei". Journeymen were able to work for other masters, unlike apprentices, and generally paid by the day and were thus day labourers. After being employed by a master for several years, and after producing a qualifying piece of work, the apprentice was granted the rank of journeyman and was given documents (letters or certificates from his master and/or the guild itself) which certified him as a journeyman and entitled him to travel to other towns and countries to learn the art from other masters. These journeys could span large parts of Europe and were an unofficial way of communicating new methods and techniques, though by no means all journeymen made such travels — they were most common in Germany and Italy, and in other countries journeymen from small cities would often visit the capital.
After this journey and several years of experience, a journeyman could be received as master craftsman, though in some guilds this step could be made straight from apprentice. This would typically require the approval of all masters of a guild, a donation of money and other goods (often omitted for sons of existing members), and the production of a so-called "masterpiece,' which would illustrate the abilities of the aspiring master craftsman; this was often retained by the guild.
The medieval guild was established by charters or letters patent or similar authority by the city or the ruler and normally held a monopoly on trade in its craft within the city in which it operated: handicraft workers were forbidden by law to run any business if they were not members of a guild, and only masters were allowed to be members of a guild. Before these privileges were legislated, these groups of handicraft workers were simply called 'handicraft associations'.
The town authorities might be represented in the guild meetings and thus had a means of controlling the handicraft activities. This was important since towns very often depended on a good reputation for export of a narrow range of products, on which not only the guild's, but the town's, reputation depended. Controls on the association of physical locations to well-known exported products, e.g. wine from the Champagne and Bordeaux regions of France, tin-glazed earthenwares from certain cities in Holland, lace from Chantilly, etc., helped to establish a town's place in global commerce — this led to modern trademarks.
In many German and Italian cities, the more powerful guilds often had considerable political influence, and sometimes attempted to control the city authorities. In the 14th century, this led to numerous bloody uprisings, during which the guilds dissolved town councils and detained patricians in an attempt to increase their influence. In fourteenth-century north-east Germany, people of Wendish, i.e. Slavic, origin were not allowed to join some guilds. According to Wilhelm Raabe, ""down into the eighteenth century no German guild accepted a Wend.""
Fall of the guilds.
As Ogilvie (2004) shows, the guilds negatively affected quality, skills, and innovation. Through what economists now call "rent-seeking" they imposed deadweight losses on the economy. Ogilvie says they generated no demonstrable positive externalities and notes that industry began to flourish only after the guilds faded away. Guilds persisted over the centuries because they redistributed resources to politically powerful merchants. On the other hand, Ogilvie agrees, guilds created "social capital" of shared norms, common information, mutual sanctions, and collective political action. This social capital benefited guild members, even as it hurt outsiders.
The guild system became a target of much criticism towards the end of the 18th century and the beginning of the 19th century. They were believed to oppose free trade and hinder technological innovation, technology transfer and business development. According to several accounts of this time, guilds became increasingly involved in simple territorial struggles against each other and against free practitioners of their arts.
Two of the most outspoken critics of the guild system were Jean-Jacques Rousseau and Adam Smith, and all over Europe a tendency to oppose government control over trades in favour of laissez-faire free market systems was growing rapidly and making its way into the political and legal system. The French Revolution saw guilds as a last remnant of feudalism. The Le Chapelier Law of 1791 abolished the guilds in France. Smith wrote in "The Wealth of Nations" (Book I, Chapter X, paragraph 72):
Karl Marx in his "Communist Manifesto" also criticized the guild system for its rigid gradation of social rank and the relation of oppressor/oppressed entailed by this system. From this time comes the low regard in which some people hold the guilds to this day. In part due to their own inability to control unruly corporate behavior, the tide turned against the guilds.
Because of industrialization and modernization of the trade and industry, and the rise of powerful nation-states that could directly issue patent and copyright protections — often revealing the trade secrets — the guilds' power faded. After the French Revolution they fell in most European nations through the 19th century, as the guild system was disbanded and replaced by free trade laws. By that time, many former handicraft workers had been forced to seek employment in the emerging manufacturing industries, using not closely guarded techniques but standardized methods controlled by corporations.
Influence of guilds.
Guilds are sometimes said to be the precursors of modern trade unions. Guilds, however, can also be seen as a set of self-employed skilled craftsmen with ownership and control over the materials and tools they needed to produce their goods. Guilds were more like cartels than they were like trade unions (Olson 1982). However, the journeymen organizations, which were at the time illegal, may have been influential.
The exclusive privilege of a guild to produce certain goods or provide certain services was similar in spirit and character with the original patent systems that surfaced in England in 1624. These systems played a role in ending the guilds' dominance, as trade secret methods were superseded by modern firms directly revealing their techniques, and counting on the state to enforce their legal monopoly.
Some guild traditions still remain in a few handicrafts, in Europe especially among shoemakers and barbers. Some ritual traditions of the guilds were conserved in order organizations such as the Freemasons, allegedly deriving from the Masons Guild, and the Oddfellows, allegedly derived from various smaller guilds. These are, however, not very important economically except as reminders of the responsibilities of some trades toward the public.
Modern antitrust law could be said to derive in some ways from the original statutes by which the guilds were abolished in Europe.
Economic consequences.
The economic consequences of guilds have led to heated debates among economic historians. On the one side, scholars say that since merchant guilds persisted over long periods they must have been efficient institutions (since inefficient institutions die out). Others say they persisted not because they benefited the entire economy but because they benefited the owners, who used political power to protect them. Ogilvie (2011) says they regulated trade for their own benefit, were monopolies, distorted markets, fixed prices, and restricted entrance into the guild. Ogilvie (2008) argues that their long apprenticeships were unnecessary to acquire skills, and their conservatism reduced the rate of innovation and made the society poorer. She says their main goal was rent seeking, that is, to shift money to the membership at the expense of the entire economy.
Epstein and Prak's book (2008) rejects Ogilvie's conclusions. Specifically, Epstein argues that guilds were cost-sharing rather than rent-seeking institutions. They located and matched masters and likely apprentices through monitored learning. Whereas the acquisition of craft skills required experience-based learning, he argues that this process necessitated many years in apprenticeship.
The extent to which guilds were able to monopolize markets is also debated.
Modern guilds.
Modern guilds exist in different forms around the world. Scholars from the history of ideas have noticed that consultants play a part similar to that of the journeymen of the guild systems: they often travel a lot, work at many companies and spread new practices and knowledge between companies and corporations.
Professional organizations replicate guild structure and operation.
Professions such as architecture, engineering, geology, and land surveying require varying lengths of apprenticeships before one can gain a "professional" certification. These certifications hold great legal weight: most states make them a prerequisite to practicing there.
Thomas W. Malone champions a modern variant of the guild structure for modern "e-lancers", professionals who do mostly telework for multiple employers. Insurance including any professional liability, intellectual capital protections, an ethical code perhaps enforced by peer pressure and software, and other benefits of a strong association of producers of knowledge, benefit from economies of scale, and may prevent cut-throat competition that leads to inferior services undercutting prices. And, as with historical guilds, such a structure will resist foreign competition. The free software community has from time to time explored a guild-like structure to unite against competition from Microsoft, e.g. Advogato assigns journeyer and master ranks to those committing to work only or mostly on free software.
Europe.
In many European countries guilds have experienced a revival as local organizations for craftsmen, primarily in traditional skills. They may function as forums for developing competence and are often the local units of a national employer's organization.
In the City of London, the ancient guilds survive as Livery Companies, all of which play a ceremonial role in the City's many customs. The City of London Livery Companies maintain strong links with their respective trade, craft or profession, some still retain regulatory, inspection or enforcement roles. The senior members of the City of London Livery Companies (known as Liverymen) elect the Sheriffs and approve the candidates for the office of Lord Mayor of London. Guilds also survive in many other towns and cities the UK including in Preston, Lancashire, as the Preston Guild Merchant where among other celebrations descendants of Burgesses are still admitted into membership. With the City of London Livery Companies the UK have over 300 extant guilds and growing.
In 1878 the London Livery companies established the City and Guilds of London Institute the forerunner of the engineering school (still called City and Guilds college) at Imperial College London. The aim of the City and Guilds of London Institute was the Advancement of Technical Education. "City and Guilds" operates as an examining and accreditation body for vocational, managerial and engineering qualifications from entry-level craft and trade skills up to post-doctoral achievement.
The Finnish equivalents of honor societies in universities function as guilds.
In Germany there are no longer any "Zünfte" (or "Gilden" - the terms used were rather different from town to town), nor any restriction of a craft to a privileged corporation. However, under one other name they used to have (albeit more rarely), to wit, "Innungen", guilds continue to exist. These corporations are corporations under public law, albeit the membership is voluntary; the president normally comes from the ranks of master-craftsmen and is called "Obermeister" ("Master-in-chief"). Journeymen elect their own representative bodies, with their president having the traditional title of "Altgesell" (Senior Journeyman).<br>
There are also "Craft Chambers" ("Handwerkskammern"), which have less resemblance to ancient guilds in that they are organized for all crafts in a certain region, not just one. In them membership is mandatory, and they serve to establish self-governance of the crafts.
North America.
In the United States guilds exist in several fields.
In the film and television industry, guild membership is generally a prerequisite for working on major productions in certain capacities. The Screen Actors Guild, Directors Guild of America, Writers Guild of America, East, Writers Guild of America, West and other profession-specific guilds have the ability to exercise strong control in Hollywood as a result of a rigid system of intellectual-property rights and a history of power-brokers also holding guild membership (e.g., DreamWorks founder Steven Spielberg was, and is, a DGA member). These guilds maintain their own contracts with production companies to ensure a certain number of their members are hired for roles in each film or television production, and that their members are paid a minimum of guild "scale," along with other labor protections. These guilds set high standards for membership, and exclude professional actors, writers, etc. who do not abide by the strict rules for competing within the film and television industry in America.
The Newspaper Guild is a labor union for journalists and other newspaper workers, with over 30,000 members in North America.
Real-estate brokerage offers an example of a modern American guild system. Signs of guild behavior in real-estate brokerage include: standard pricing (6% of the home price), strong affiliation among all practitioners, self-regulation (see National Association of Realtors), strong cultural identity (see realtor), little price variation with quality differences, and traditional methods in use by all practitioners. In September 2005 the U.S. Department of Justice filed an antitrust lawsuit against the National Association of Realtors, challenging NAR practices that (the DOJ asserted) prevent competition from practitioners who use different methods. The DOJ and the Federal Trade Commission in 2005 advocated against state laws, supported by NAR, that disadvantage new kinds of brokers. "U.S. v. National Assoc. of Realtors", Civil Action No. 05C-5140 (N.D. Ill. Sept. 7, 2005).
The practice of law in the United States also exemplifies modern guilds at work. Every state maintains its own bar association, supervised by that state's highest court. The court decides the criteria for entering and staying in the legal profession. In most states, every attorney must become a member of that state's bar association in order to practice law. State laws forbid any person from engaging in the unauthorized practice of law and practicing attorneys are subject to rules of professional conduct that are enforced by the state's high court.
Medical associations comparable to guilds include the state Medical Boards, the American Medical Association, and the American Dental Association. Medical licensing in most states requires specific training, tests and years of low-paid apprenticeship (internship and residency) under harsh working conditions. Even qualified international or out-of-state doctors may not practice without acceptance by the local medical guild (Medical board). Similarly, nurses and physicians' practitioners have their own guilds. A doctor cannot work as a physician's assistant unless (s)he separately trains, tests and apprentices as one.
Australia.
Australia is home to The Pharmacy Guild of Australia (the peak association in the pharmacy industry) and the Guild of Commercial Filmmakers (an association of makers of commercial, short and feature films). Australia's fine jewellery industry has members of the Gold and Silversmith's Guild of Australia (GSGA) who practice their manufacturing locally.
Virtual world guilds.
Groups called guilds exist in online communities such as massively multiplayer online games.
These guilds usually represent a group of individuals that share the same interests and goals. While they may be organized around in-game economic production, they generally do not control production. Guilds in online games can range in size from a small group of a few players to massive guilds that have players from around the world.

</doc>
<doc id="12372" url="https://en.wikipedia.org/wiki?curid=12372" title="Gradius (video game)">
Gradius (video game)

The arcade version of "Gradius" was released internationally outside Japan under the title of Nemesis, although later releases kept the original title. Home versions were released for various platforms, such as the Famicom/NES, the MSX home computer, and the PC Engine, among other formats. The original arcade game and some of the home versions has also been included in various compilation releases and are available for download in services such as the Virtual Console and PlayStation Network.
Gameplay.
The player controls the trans-dimensional spaceship Vic Viper, and must battle waves of enemies through various environments.
The game became synonymous with the phrase, "Destroy the core!", as the standard of boss battles in the "Gradius" series involved combat with a giant craft, in the center of which would be situated one to several blue colored spheres. These bosses would be designed in such a way that there would be a straight passage from the exterior of the giant craft which leads directly to one of these cores. The player must fire shots into this passage while avoiding attack patterns from weapon emplacements on the body of the boss. However, small but destructible walls are situated in this passage, impeding the bullet shots from damaging the core, and must be whittled away by repeated well-placed shots. In a way, these tiny walls represent the boss' shielding gauge until its core is finally vulnerable to attack. Some bosses have the ability to regenerate these walls. When the core has sustained enough hits, it usually changes color from blue to red, indicating that it is in critical condition and its destruction is imminent. Upon the destruction of a core, a piece of the boss may be put out of commission, seeing that it is no longer powered by a core, or if all of the cores are destroyed, the entire boss is defeated and explodes satisfyingly. Note that these cores are not present on the more organic bosses of "Gradius". Such bosses have weak spots in places such as a mouth, head or eye.
Weapon system.
When gameplay begins, the Vic Viper is relatively slow and has only a weak gun. This level of capability is generally insufficient for engaging enemies, but the Vic Viper can gain greater capabilities by collecting and using power-up items.
While most arcade games utilize distinct power up-items that each correspond to a specific effect on the player character, "Gradius" has a single power-up item. The effect of this power-up item is to advance the currently selected item in a power-up menu that appears at the bottom of the screen. When the desired power-up is highlighted, the player can obtain it by pressing the power-up button, returning the menu to its initial state in which no power-up is highlighted.
Development.
Release.
Ports of "Gradius" were also done for the Amstrad CPC, Commodore 64, Microsoft Windows, MSX, NEC PC-8801, Famicom/NES, PC Engine, Virtual Console, Sharp X1, Sharp X68000, Mobile phones, Sega Saturn, PlayStation and Sinclair ZX Spectrum. The game went to number 2 in the UK sales charts, behind "Feud". It was also released on Windows Store on December 20, 2013, GameNow on May 2014 and for PlayStation 4's Arcade Archives on January 25 in Japan. The NES version of "Gradius" introduced a cheat code that would later become known as the Konami Code, as it would be used in numerous future Konami games. In this game, inputting the code while pausing the game would grant the player's ship multiple power-ups instantly.
"Gradius" was also converted for the Nintendo Vs. Series arcade platform. It is identical to the NES version, but includes no cheat codes and allows the player to continue indefinitely.
The arcade version of "Gradius" is included in the "Gradius Collection" for the PlayStation Portable and in "" for the Nintendo DS.
A version for the Game Boy was also released in 1990 under the European name "Nemesis". It is the first portable game in the Gradius series and contains five levels which play similarly to previous Gradius games. Players select the stage and the number of available extra lives at the start. The game was later included in the compilation "Konami GB Collection Vol. 1", where it is titled "Gradius".
Reception.
The Western cover art for the NES version claimed that it had sold one million copies in Japan.
Legacy.
"Gradius" spawned several sequels, the first of which was 1986's "Salamander". The series has continued into the seventh generation with "Gradius ReBirth".
GameSpot stated that "Gradius" was one of the toughest side-scrolling shooter games available on the NES, second only to "Contra". IGN has given the game a rating 7 out of 10 for its re-release on the Wii Virtual Console and has hailed it as one of the greatest classic side-scrolling shooter games.

</doc>
<doc id="12373" url="https://en.wikipedia.org/wiki?curid=12373" title="Gamemaster">
Gamemaster

A gamemaster (GM; also known as game master, game manager, game moderator or referee) is a person who acts as an organizer, officiant for questions regarding rules, arbitrator, and moderator for a multiplayer role-playing game. They are most common in co-operative games in which players work together and are less common in competitive games in which players oppose each other. The act performed by a gamemaster is sometimes referred to as "Gamemastering" or simply "GM'ing".
The role of a gamemaster in a traditional role-playing game is to weave the other participants' player-character stories together, control the non-player aspects of the game, create environments in which the players can interact, and solve any player disputes. The basic role of the gamemaster is the same in almost all traditional role-playing games, although differing rule sets make the specific duties of the gamemaster unique to that system.
The role of a gamemaster in an online game is to enforce the game's rules and provide general customer service. Also, unlike gamemasters in traditional role-playing games, gamemasters for online games in some cases are paid employees.
History and variants of the term.
The term "gamemaster" and the role associated with it could be found in the postal gaming hobby.
In a role-playing game context, it was first used by "Chivalry & Sorcery". Previous usage in a wargaming context includes Guidon Games 1973 ruleset, "Ironclad". In typical play-by-mail games, players control armies or civilizations and mail their chosen actions to the GM. The GM then mails the updated game state to all players on a regular basis.
Each gaming system has its own name for the role of the gamemaster, such as "judge", "narrator", "referee", "director", or "storyteller", and these terms not only describe the role of the gamemaster in general but also help define how the game is intended to be run. For example, the Storyteller System used in White Wolf Game Studio's storytelling games calls its GM the "storyteller", while the rules- and setting-focused "Marvel Super Heroes" role-playing game calls its GM the "judge". The cartoon inspired role-playing game "Toon" calls its GM the "animator". A few games apply system- or setting-specific flavorful names to the GM, such as the Hollyhock God ("Nobilis", in which the hollyhock represents vanity), or the most famous of such terms, "Dungeon Master" (or "DM") in "Dungeons & Dragons".
Gamemasters in traditional role-playing games.
The gamemaster prepares the game session for the players and the characters they play (known as player characters or PCs), describes the events taking place and decides on the outcomes of players' decisions. The gamemaster also keeps track of non-player characters (NPCs) and random encounters, as well as of the general state of the game world. The game session (or "adventure") can be metaphorically described as a play, in which the players are the lead actors, and the GM provides the stage, the scenery, the basic plot on which the improvisational script is built, as well as all the bit parts and supporting characters. Gamemasters can also be in charge of RPG board games making the events and setting challenges.
GMs may choose to run a game based on a published game world, with the maps and history already in place; such game worlds often have pre-written adventures. Alternatively, the GM may build their own world and script their own adventures.
A good gamemaster draws the players into the adventure, making it enjoyable for everyone. Good gamemasters have quick minds, sharp wits, and rich imaginations. Gamemasters must also maintain game balance: hideously overpowered monsters "or" players are no fun. It was noted, in 1997, that those who favor their left-brain such as skilled code writers usually do not make it in the ethereal gamemaster world of storytelling and verse.
Gamemasters in online games.
In early virtual worlds gamemasters served as a moderator or administrator; in MUD game masters were called "wizards". Gamemastering in the form found in traditional role-playing games has also been used in a semi-automatic virtual worlds. However, human moderation was sometimes considered unfair or out of context in an otherwise automated world.
As online games expanded, gamemaster duties expanded to include being a customer service representative for an online community. A gamemaster in such a game is either an experienced volunteer player or an employee of the game's publisher. They enforce the game's rules by banishing spammers, player killers, cheaters, and hackers and by solving players' problems by providing general customer service. For their tasks they use special tools and characters that allow them to do things like teleport to players, summon items, and browse logs that record players' activities. Often, players who feel dissatisfied with the game will blame the GMs directly for any errors or glitches. However, this blame is misdirected as most GMs are not developers and cannot resolve those types of problems.
The now defunct America Online Online Gaming Forum used to use volunteers selected by applications from its user base. These people were simply referred to as OGFs by other members, and their screennames were indicative of their position (i.e., OGF Moose, etc.). While membership in the Online Gaming Forum had only one real requirement (that is, be a member of AOL), OGFs were given powers quite similar to AOL "Guides" and could use them at will to discipline users as they saw appropriate.
"World of Warcraft" has employees of Blizzard Entertainment that serve as gamemasters to help users with various problems in gameplay, chat, and other things like account and billing issues. A gamemaster in this game will communicate with players through chat that has blue text and they will also have a special "GM" tag and Blizzard logo in front of their names.
"RuneScape" has more than 500 moderators employed by Jagex Games Studio to assist players and perform administrative duties in-game and on the site forums. These "Jagex Moderators", as they are called, usually have the word "Mod" and a gold crown preceding their account names which ordinary players are not permitted to use. The game also has "Player Moderators" and "Forum Moderators" who are player volunteers helping with moderation, having the ability to mute (block from chatting) other players who violate rules.
"Battleground Europe", a medium-sized MMOFPS has a team of "Game Moderators", anonymous volunteers who moderate the game.
"Miniconomy", a smaller text-based MMO has a team of "Federals", experienced players that help moderate the game and interactions.
"Transformice", an MMORPG, has a team of volunteer moderators called "Mods" who are experienced players that help moderate the game and interactions.
Note that a few games, notably "Neverwinter Nights" and "", are video game adaptations of tabletop role-playing games that are played online with one player acting as a traditional gamemaster.
Gamemasters in pervasive games.
Gamemastering, sometimes referred to as Orchestration is used in pervasive games to guide players along a trajectory desired by the game author. To ensure proper gamemastering can take place, four components are needed: some kind of sensory system to the game allowing the game masters to know current events, providing dynamic game information; dynamic and static game information lets game masters make informed decisions; decisions need to be actuated into the game, either through the game system or through manual intervention; and finally a communication structure is needed for both diegetic or non-diegetic communication.
Effective gamemastering can require specialized user interfaces that are highly game specific.
Gamemasters in online chat environments.
Sometimes, tabletop GMs simply can not find players interested in either the same setting, product line, or play style in their local neighborhood. The advent of the networked personal computer provided a solution in the form of online chat programs. Appropriately equipped gamemasters can find players online and a group can meet via chat rooms, forums, or other electronic means.
In contrast to standard tabletop procedure (and to games "designed" to be played online), this online chat format significantly changed the balance of duties for a prospective gamemaster. Descriptive text required more preparation, if only via cut-and-paste; acting and voice skills could not be utilized to get the personality of NPCs and monsters across, increasing the value of background music ('assigned' in advance or individually chosen) as a playing aid. The GM was likely to need copies of player-character records, being unable to glance at the originals as in normal face-to-face procedure. The format also forced the issue (particularly when participants were not personally acquainted) of whether to leave all rolling of dice to the GM (making one's own rolls is a privilege not readily surrendered by some players), or to trust all players to honestly report the results of their rolls (the honor system may be strained when it is in a player's best interest to roll well).
However, workarounds to these challenges have only increased over time. The use of Wiki software helps GMs and players alike keep track of all manner of game data, sometimes evolving into a home-made gaming supplement. Scripting software allows unwieldy mechanics (e.g. a complicated formula or repetitive die-rolling) to be resolved at the push of a button. Teleconferencing enhances group communication through voice, video, and a shared whiteboard. The use of technology to enable online play is growing, as reflected in products like the D&D Insider.

</doc>
<doc id="12383" url="https://en.wikipedia.org/wiki?curid=12383" title="Genetic engineering">
Genetic engineering

Genetic engineering, also called genetic modification, is the direct manipulation of an organism's genome using biotechnology. It is a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms. New DNA may be inserted in the host genome by first isolating and copying the genetic material of interest using molecular cloning methods to generate a DNA sequence, or by synthesizing the DNA, and then inserting this construct into the host organism. Genes may be removed, or "knocked out", using a nuclease. Gene targeting is a different technique that uses homologous recombination to change an endogenous gene, and can be used to delete a gene, remove exons, add a gene, or introduce point mutations.
An organism that is generated through genetic engineering is considered to be a genetically modified organism (GMO). The first GMOs were bacteria generated in 1973 and GM mice in 1974. Insulin-producing bacteria were commercialized in 1982 and genetically modified food has been sold since 1994. GloFish, the first GMO designed as a pet, was first sold in the United States in December 2003.
Genetic engineering techniques have been applied in numerous fields including research, agriculture, industrial biotechnology, and medicine. Enzymes used in laundry detergent and medicines such as insulin and human growth hormone are now manufactured in GM cells, experimental GM cell lines and GM animals such as mice or zebrafish are being used for research purposes, and genetically modified crops have been commercialized.
Definition.
Genetic engineering alters the genetic make-up of an organism using techniques that remove heritable material or that introduce DNA prepared outside the organism either directly into the host or into a cell that is then fused or hybridized with the host. This involves using recombinant nucleic acid (DNA or RNA) techniques to form new combinations of heritable genetic material followed by the incorporation of that material either indirectly through a vector system or directly through micro-injection, macro-injection and micro-encapsulation techniques.
Genetic engineering does not normally include traditional animal and plant breeding, in vitro fertilisation, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. However the European Commission has also defined genetic engineering broadly as including selective breeding and other means of artificial selection. Cloning and stem cell research, although not considered genetic engineering, are closely related and genetic engineering can be used within them. Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesized material from raw materials into an organism.
If genetic material from another species is added to the host, the resulting organism is called transgenic. If genetic material from the same species or a species that can naturally breed with the host is used the resulting organism is called cisgenic. Genetic engineering can also be used to remove genetic material from the target organism, creating a gene knockout organism. In Europe genetic modification is synonymous with genetic engineering while within the United States of America it can also refer to conventional breeding methods. The Canadian regulatory system is based on whether a product has novel features regardless of method of origin. In other words, a product is regulated as genetically modified if it carries some trait not previously found in the species whether it was generated using traditional breeding methods (e.g., selective breeding, cell fusion, mutation breeding) or genetic engineering. Within the scientific community, the term "genetic engineering" is not commonly used; more specific terms such as "transgenic" are preferred.
Genetically modified organisms.
Plants, animals or micro organisms that have changed through genetic engineering are termed genetically modified organisms or GMOs. Bacteria were the first organisms to be genetically modified. Plasmid DNA containing new genes can be inserted into the bacterial cell and the bacteria will then express those genes. These genes can code for medicines or enzymes that process food and other substrates. Plants have been modified for insect protection, herbicide resistance, virus resistance, enhanced nutrition, tolerance to environmental pressures and the production of edible vaccines. Most commercialised GMO's are insect resistant and/or herbicide tolerant crop plants. Genetically modified animals have been used for research, model animals and the production of agricultural or pharmaceutical products.
The genetically modified animals include animals with genes knocked out, increased susceptibility to disease, hormones for extra growth and the ability to express proteins in their milk.
History.
Humans have altered the genomes of species for thousands of years through selective breeding, or artificial selection as contrasted with natural selection, and more recently through mutagenesis. Genetic engineering as the direct manipulation of DNA by humans outside breeding and mutations has only existed since the 1970s. The term "genetic engineering" was first coined by Jack Williamson in his science fiction novel "Dragon's Island", published in 1951 – one year before DNA's role in heredity was confirmed by Alfred Hershey and Martha Chase, and two years before James Watson and Francis Crick showed that the DNA molecule has a double-helix structure – though the general concept of direct genetic manipulation was explored in rudimentary form in Stanley G. Weinbaum's 1936 science fiction story "Proteus Island".
In 1972, Paul Berg created the first recombinant DNA molecules by combining DNA from the monkey virus SV40 with that of the lambda virus. In 1973 Herbert Boyer and Stanley Cohen created the first transgenic organism by inserting antibiotic resistance genes into the plasmid of an "E. coli" bacterium. A year later Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world’s first transgenic animal.
In 1976 Genentech, the first genetic engineering company, was founded by Herbert Boyer and Robert Swanson and a year later the company produced a human protein (somatostatin) in "E.coli". Genentech announced the production of genetically engineered human insulin in 1978. In 1980, the U.S. Supreme Court in the "Diamond v. Chakrabarty" case ruled that genetically altered life could be patented. The insulin produced by bacteria, branded humulin, was approved for release by the Food and Drug Administration in 1982.
In the 1970s graduate student Steven Lindow of the University of Wisconsin–Madison with D.C. Arny and C. Upper found a bacterium he identified as "P. syringae" that played a role in ice nucleation, and in 1977 he discovered a mutant ice-minus strain. Dr. Lindow (who is now a plant pathologist at the University of California-Berkeley) later successfully created a recombinant ice-minus strain. In 1987, the ice-minus strain of "P. syringae" became the first genetically modified organism (GMO) to be released into the environment when a strawberry field and a potato field in California were sprayed with it. Both test fields were attacked by activist groups the night before the tests occurred: "The world's first trial site attracted the world's first field trasher".
The first field trials of genetically engineered plants occurred in France and the USA in 1986, tobacco plants were engineered to be resistant to herbicides. The People’s Republic of China was the first country to commercialize transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the Flavr Savr tomato, a tomato engineered to have a longer shelf life. In 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialized in Europe. In 1995, Bt Potato was approved safe by the Environmental Protection Agency, after having been approved by the FDA, making it the first pesticide producing crop to be approved in the USA. In 2009 11 transgenic crops were grown commercially in 25 countries, the largest of which by area grown were the USA, Brazil, Argentina, India, Canada, China, Paraguay and South Africa.
In 2010, scientists at the J. Craig Venter Institute created the first synthetic life form by adding a synthetic genome to an empty bacterial cell. The resulting bacterium was named Synthia. In 2014, a bacterium was developed that replicated a plasmid containing a unique base pair, creating the first organism engineered to use an expanded genetic alphabet.
Process.
The first step is to choose and isolate the gene that will be inserted into the genetically modified organism. The gene can be isolated using restriction enzymes to cut DNA into fragments and gel electrophoresis to separate them out according to length. Polymerase chain reaction (PCR) can also be used to amplify up a gene segment, which can then be isolated through gel electrophoresis. If the chosen gene or the donor organism's genome has been well studied it may be present in a genetic library. If the DNA sequence is known, but no copies of the gene are available, it can be artificially synthesized.
The gene to be inserted into the genetically modified organism must be combined with other genetic elements in order for it to work properly. The gene can also be modified at this stage for better expression or effectiveness. As well as the gene to be inserted most constructs contain a promoter and terminator region as well as a selectable marker gene. The promoter region initiates transcription of the gene and can be used to control the location and level of gene expression, while the terminator region ends transcription. The selectable marker, which in most cases confers antibiotic resistance to the organism it is expressed in, is needed to determine which cells are transformed with the new gene. The constructs are made using recombinant DNA techniques, such as restriction digests, ligations and molecular cloning. The manipulation of the DNA generally occurs within a plasmid.
The most common form of genetic engineering involves inserting new genetic material randomly within the host genome. Other techniques allow new genetic material to be inserted at a specific location in the host genome or generate mutations at desired genomic loci capable of knocking out endogenous genes. The technique of gene targeting uses homologous recombination to target desired changes to a specific endogenous gene. This tends to occur at a relatively low frequency in plants and animals and generally requires the use of selectable markers. The frequency of gene targeting can be greatly enhanced with the use of engineered nucleases such as zinc finger nucleases, engineered homing endonucleases, or nucleases created from TAL effectors.
In addition to enhancing gene targeting, engineered nucleases can also be used to introduce mutations at endogenous genes that generate a gene knockout.
Transformation.
Only about 1% of bacteria are naturally capable of taking up foreign DNA. However, this ability can be induced in other bacteria via stress (e.g. thermal or electric shock), thereby increasing the cell membrane's permeability to DNA; up-taken DNA can either integrate with the genome or exist as extrachromosomal DNA. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell's nuclear envelope directly into the nucleus or through the use of viral vectors. In plants the DNA is generally inserted using "Agrobacterium"-mediated recombination or biolistics.
In "Agrobacterium"-mediated recombination, the plasmid construct contains T-DNA, DNA which is responsible for insertion of the DNA into the host plants genome. This plasmid is transformed into "Agrobacterium" containing no plasmids prior to infecting the plant cells. The "Agrobacterium" will then naturally insert the genetic material into the plant cells. In biolistics transformation particles of gold or tungsten are coated with DNA and then shot into young plant cells or plant embryos. Some genetic material will enter the cells and transform them. This method can be used on plants that are not susceptible to "Agrobacterium" infection and also allows transformation of plant plastids. Another transformation method for plant and animal cells is electroporation. Electroporation involves subjecting the plant or animal cell to an electric shock, which can make the cell membrane permeable to plasmid DNA. In some cases the electroporated cells will incorporate the DNA into their genome. Due to the damage caused to the cells and DNA the transformation efficiency of biolistics and electroporation is lower than agrobacterial mediated transformation and microinjection.
As often only a single cell is transformed with genetic material the organism must be regenerated from that single cell. As bacteria consist of a single cell and reproduce clonally regeneration is not necessary. In plants this is accomplished through the use of tissue culture. Each plant species has different requirements for successful regeneration through tissue culture. If successful an adult plant is produced that contains the transgene in every cell. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Selectable markers are used to easily differentiate transformed from untransformed cells. These markers are usually present in the transgenic organism, although a number of strategies have been developed that can remove the selectable marker from the mature transgenic plant. When the offspring is produced they can be screened for the presence of the gene. All offspring from the first generation will be heterozygous for the inserted gene and must be mated together to produce a homozygous animal.
Further testing uses PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene. These tests can also confirm the chromosomal location and copy number of the inserted gene. The presence of the gene does not guarantee it will be expressed at appropriate levels in the target tissue so methods that look for and measure the gene products (RNA and protein) are also used. These include northern hybridization, quantitative RT-PCR, Western blot, immunofluorescence, ELISA and phenotypic analysis. For stable transformation the gene should be passed to the offspring in a Mendelian inheritance pattern, so the organism's offspring are also studied.
Genome editing.
Genome editing is a type of genetic engineering in which DNA is inserted, replaced, or removed from a genome using artificially engineered nucleases, or "molecular scissors." The nucleases create specific double-stranded breaks (DSBs) at desired locations in the genome, and harness the cell’s endogenous mechanisms to repair the induced break by natural processes of homologous recombination (HR) and nonhomologous end-joining (NHEJ). There are currently four families of engineered nucleases: meganucleases, zinc finger nucleases (ZFNs), transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from the CRISPR prokarotic immune system). In contrast to artificial genome editing natural genome editing occurs through viral and sub-viral agents competent in identification of genetic syntax structures for insertion/deletion processes with the result of conserved selection processes.
Applications.
Genetic engineering has applications in medicine, research, industry and agriculture and can be used on a wide range of plants, animals and micro organisms.
Medicine.
In medicine, genetic engineering has been used in manufacturing drugs, to create model animals and do laboratory research, and in gene therapy.
Manufacturing.
Genetic engineering is used to mass-produce insulin, human growth hormones, follistim (for treating infertility), human albumin, monoclonal antibodies, antihemophilic factors, vaccines and many other drugs. Mouse hybridomas, cells fused together to create monoclonal antibodies, have been humanised through genetic engineering to create human monoclonal antibodies. Genetically engineered viruses are being developed that can still confer immunity, but lack the infectious sequences.
Research.
Genetic engineering is used to create animal models of human diseases. Genetically modified mice are the most common genetically engineered animal model. They have been used to study and model cancer (the oncomouse), obesity, heart disease, diabetes, arthritis, substance abuse, anxiety, aging and Parkinson disease. Potential cures can be tested against these mouse models. Also genetically modified pigs have been bred with the aim of increasing the success of pig to human organ transplantation.
Gene therapy.
Gene therapy is the genetic engineering of humans, generally by replacing defective genes with effective ones. This can occur in somatic tissue or germline tissue.
Somatic gene therapy has been studied in clinical research in several diseases, including X-linked SCID, chronic lymphocytic leukemia (CLL), and Parkinson's disease. In 2012, Glybera became the first gene therapy treatment to be approved for clinical use in either Europe or the United States after its endorsement by the European Commission.
With regard to germline gene therapy, the scientific community has been opposed to attempts to alter genes in humans in inheritable ways using biotechnology since the technology was first introduced, and the caution has continued as the technology has progressed. With the advent of new techniques like CRISPR, in March 2015 scientists urged a worldwide ban on clinical use of gene editing technologies to edit the human genome in a way that can be inherited. In April 2015, Chinese researchers sparked controversy when they reported results of basic research experiments in which they edited the DNA of non-viable human embryos using CRISPR. In December 2015, scientists of major world academies called for a moratorium on inheritable human genome edits, including those related to CRISPR-Cas9 technologies.
There are also ethical concerns should the technology be used not just for treatment, but for enhancement, modification or alteration of a human beings' appearance, adaptability, intelligence, character or behavior. The distinction between cure and enhancement can also be difficult to establish. Transhumanists consider the enhancement of humans desirable.
Research.
Genetic engineering is an important tool for natural scientists. Genes and other genetic information from a wide range of organisms are transformed into bacteria for storage and modification, creating genetically modified bacteria in the process. Bacteria are cheap, easy to grow, clonal, multiply quickly, relatively easy to transform and can be stored at -80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria providing an unlimited supply for research.
Organisms are genetically engineered to discover the functions of certain genes. This could be the effect on the phenotype of the organism, where the gene is expressed or what other genes it interacts with. These experiments generally involve loss of function, gain of function, tracking and expression.
Industrial.
Using genetic engineering techniques one can transform microorganisms such as bacteria or yeast, or transform cells from multicellular organisms such as insects or mammals, with a gene coding for a useful protein, such as an enzyme, so that the transformed organism will overexpress the desired protein. One can manufacture mass quantities of the protein by growing the transformed organism in bioreactor equipment using techniques of industrial fermentation, and then purifying the protein. Some genes do not work well in bacteria, so yeast, insect cells, or mammalians cells, each a eukaryote, can also be used. These techniques are used to produce medicines such as insulin, human growth hormone, and vaccines, supplements such as tryptophan, aid in the production of food (chymosin in cheese making) and fuels. Other applications involving genetically engineered bacteria being investigated involve making the bacteria perform tasks outside their natural cycle, such as making biofuels, cleaning up oil spills, carbon and other toxic waste and detecting arsenic in drinking water. Certain genetically modified microbes can also be used in biomining and bioremediation, due to their ability to extract heavy metals from their environment and incorporate them into compounds that are more easily recoverable.
Experimental, lab scale industrial applications.
In materials science, a genetically modified virus has been used in an academic lab as a scaffold for assembling a more environmentally friendly lithium-ion battery.
Bacteria have been engineered to function as sensors by expressing a fluorescent protein under certain environmental conditions.
Agriculture.
One of the best-known and controversial applications of genetic engineering is the creation and use of genetically modified crops or genetically modified organisms, such as genetically modified fish, which are used to produce genetically modified food and materials with diverse uses. There are four main goals in generating genetically modified crops.
One goal, and the first to be realized commercially, is to provide protection from environmental threats, such as cold (in the case of Ice-minus bacteria), or pathogens, such as insects or viruses, and/or resistance to herbicides. There are also fungal and virus resistant crops developed or in development. They have been developed to make the insect and weed management of crops easier and can indirectly increase crop yield.
Another goal in generating GMOs is to modify the quality of produce by, for instance, increasing the nutritional value or providing more industrially useful qualities or quantities. The Amflora potato, for example, produces a more industrially useful blend of starches. Cows have been engineered to produce more protein in their milk to facilitate cheese production. Soybeans and canola have been genetically modified to produce more healthy oils.
Another goal consists of driving the GMO to produce materials that it does not normally make. One example is "pharming", which uses crops as bioreactors to produce vaccines, drug intermediates, or drug themselves; the useful product is purified from the harvest and then used in the standard pharmaceutical production process. Cows and goats have been engineered to express drugs and other proteins in their milk, and in 2009 the FDA approved a drug produced in goat milk.
Another goal in generating GMOs, is to directly improve yield by accelerating growth, or making the organism more hardy (for plants, by improving salt, cold or drought tolerance). Salmon have been genetically modified with growth hormones to increase their size.
The genetic engineering of agricultural crops can increase the growth rates and resistance to different diseases caused by pathogens and parasites. This is beneficial as it can greatly increase the production of food sources with the usage of fewer resources that would be required to host the world's growing populations. These modified crops would also reduce the usage of chemicals, such as fertilizers and pesticides, and therefore decrease the severity and frequency of the damages produced by these chemical pollution.
Ethical and safety concerns have been raised around the use of genetically modified food. A major safety concern relates to the human health implications of eating genetically modified food, in particular whether toxic or allergic reactions could occur. Gene flow into related non-transgenic crops, off target effects on beneficial organisms and the impact on biodiversity are important environmental issues. Ethical concerns involve religious issues, corporate control of the food supply, intellectual property rights and the level of labeling needed on genetically modified products.
BioArt and entertainment.
Genetic engineering is also being used to create BioArt. Some bacteria have been genetically engineered to create black and white photographs.
Genetic engineering has also been used to create novelty items such as lavender-colored carnations, blue roses, and glowing fish.
Regulation.
The regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the development and release of genetically modified crops. There are differences in the regulation of GM crops between countries, with some of the most marked differences occurring between the USA and Europe. Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety. Starting in the late 1980s, guidance on assessing the safety of genetically engineered plants and food emerged from organizations including the FAO and WHO.
Controversy.
Critics have objected to use of genetic engineering per se on several grounds, including ethical concerns, ecological concerns, and economic concerns raised by the fact GM techniques and GM organisms are subject to intellectual property law. GMOs also are involved in controversies over GM food with respect to whether food produced from GM crops is safe, whether it should be labeled, and whether GM crops are needed to address the world's food needs. See the genetically modified food controversies article for discussion of issues about GM crops and GM food. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries.

</doc>
<doc id="12384" url="https://en.wikipedia.org/wiki?curid=12384" title="Gettysburg Address">
Gettysburg Address

The Gettysburg Address is a speech by U.S. President Abraham Lincoln, one of the best-known in American history. It was delivered by Lincoln during the American Civil War, on the afternoon of Thursday, November 19, 1863, at the dedication of the Soldiers' National Cemetery in Gettysburg, Pennsylvania, four and a half months after the Union armies defeated those of the Confederacy at the Battle of Gettysburg.
Abraham Lincoln's carefully crafted address, secondary to other presentations that day, was one of the greatest and most influential statements of national purpose. In just over two minutes, Lincoln reiterated the principles of human equality espoused by the Declaration of Independence and proclaimed the Civil War as a struggle for the preservation of the Union sundered by the secession crisis, with "a new birth of freedom" that would bring true equality to all of its citizens. Lincoln also redefined the Civil War as a struggle not just for the Union, but also for the principle of human equality.
Beginning with the now-iconic phrase "Four score and seven years ago"—referring to the start of the American Revolution in 1776—Lincoln examined the founding principles of the United States as stated in the Declaration of Independence. In the context of the Civil War, Lincoln also memorialized the sacrifices of those who gave their lives at Gettysburg and extolled virtues for the listeners (and the nation) to ensure the survival of America's representative democracy: that "government of the people, by the people, for the people, shall not perish from the earth."
Despite the speech's prominent place in the history and popular culture of the United States, the exact wording and location of the speech are disputed. The five known manuscripts of the Gettysburg Address in Lincoln's hand differ in a number of details, and also differ from contemporary newspaper reprints of the speech. Modern scholarship locates the speakers' platform 40 yards (or more) away from the "Traditional Site" within Soldiers' National Cemetery at the Soldiers' National Monument and entirely within private, adjacent Evergreen Cemetery.
Background.
Following the Battle of Gettysburg on July 1–3, 1863, reburial of Union soldiers from the Gettysburg Battlefield graves began on October 17. David Wills, of the committee for the November 19 Consecration of the National Cemetery at Gettysburg, invited President Lincoln: "It is the desire that, after the Oration, you, as Chief Executive of the nation, formally set apart these grounds to their sacred use by a few appropriate remarks." Lincoln's address followed the oration by Edward Everett, who subsequently included a copy of the Gettysburg Address in his 1864 book about the event ("Address of the Hon. Edward Everett At the Consecration of the National Cemetery At Gettysburg, 19th November 1863, with the Dedicatory Speech of President Lincoln, and the Other Exercises of the Occasion; Accompanied by An Account of the Origin of the Undertaking and of the Arrangement of the Cemetery Grounds, and by a Map of the Battle-field and a Plan of the Cemetery").
During the train trip from Washington, D.C., to Gettysburg on November 18, Lincoln remarked to John Hay that he felt weak. On the morning of November 19, Lincoln mentioned to John Nicolay that he was dizzy. In the railroad car the President rode with his secretary, John G. Nicolay, his assistant secretary, John Hay, the three members of his Cabinet who accompanied him, William Seward, John Usher and Montgomery Blair, several foreign officials and others. Hay noted that during the speech Lincoln's face had 'a ghastly color' and that he was 'sad, mournful, almost haggard.' After the speech, when Lincoln boarded the 6:30 pm train for Washington, D.C., he was feverish and weak, with a severe headache. A protracted illness followed, which included a vesicular rash and was diagnosed as a mild case of smallpox. It thus seems highly likely that Lincoln was in the prodromal period of smallpox when he delivered the Gettysburg address.
Program and Everett's "Gettysburg Oration".
The program organized for that day by Wills and his committee included:
Music, by Birgfeld's Band ("Homage d'uns Heros" by Adolph Birgfeld)
Prayer, by Reverend T. H. Stockton, D.D.
Music, by the Marine Band ("Old Hundred"), directed by Francis Scala
Oration, by Hon. Edward Everett ("The Battles of Gettysburg")
Music, Hymn ("Consecration Chant") by B. B. French, Esq., music by Wilson G Horner, sung by Baltimore Glee Club
Dedicatory Remarks, by the President of the United States
Dirge ("Oh! It is Great for Our Country to Die", words by James G. Percival, music by Alfred Delaney), sung by Choir selected for the occasion
Benediction, by Reverend H. L. Baugher, D.D.
While it is Lincoln's short speech that has gone down in history as one of the finest examples of English public oratory, it was Everett's two-hour oration that was slated to be the "Gettysburg address" that day. His now seldom-read 13,607-word oration began:
Standing beneath this serene sky, overlooking these broad fields now reposing from the labors of the waning year, the mighty Alleghenies dimly towering before us, the graves of our brethren beneath our feet, it is with hesitation that I raise my poor voice to break the eloquent silence of God and Nature. But the duty to which you have called me must be performed;—grant me, I pray you, your indulgence and your sympathy.
And ended two hours later with:
But they, I am sure, will join us in saying, as we bid farewell to the dust of these martyr-heroes, that wheresoever throughout the civilized world the accounts of this great warfare are read, and down to the latest period of recorded time, in the glorious annals of our common country, there will be no brighter page than that which relates the Battles of Gettysburg.
Lengthy dedication addresses like Everett's were common at cemeteries in this era. The tradition began in 1831 when Justice Joseph Story delivered the dedication address at Mount Auburn Cemetery in Cambridge, Massachusetts. Those addresses often linked cemeteries to the mission of Union.
Text of Gettysburg Address.
Shortly after Everett's well-received remarks, Lincoln spoke for only a few minutes. With a "few appropriate remarks", he was able to summarize his view of the war in just ten sentences.
Despite the historical significance of Lincoln's speech, modern scholars disagree as to its exact wording, and contemporary transcriptions published in newspaper accounts of the event and even handwritten copies by Lincoln himself differ in their wording, punctuation, and structure. Of these versions, the Bliss version, written well after the speech as a favor for a friend, is viewed by many as the standard text. Its text differs, however, from the written versions prepared by Lincoln before and after his speech. It is the only version to which Lincoln affixed his signature, and the last he is known to have written.
Lincoln's sources.
In "Lincoln at Gettysburg", Garry Wills notes the parallels between Lincoln's speech and Pericles's Funeral Oration during the Peloponnesian War as described by Thucydides. (James McPherson notes this connection in his review of Wills's book. Gore Vidal also draws attention to this link in a BBC documentary about oration.) Pericles' speech, like Lincoln's, begins with an acknowledgment of revered predecessors: "I shall begin with our ancestors: it is both just and proper that they should have the honor of the first mention on an occasion like the present"; then praises the uniqueness of the State's commitment to democracy: "If we look to the laws, they afford equal justice to all in their private differences"; honors the sacrifice of the slain, "Thus choosing to die resisting, rather than to live submitting, they fled only from dishonor, but met danger face to face"; and exhorts the living to continue the struggle: "You, their survivors, must determine to have as unfaltering a resolution in the field, though you may pray that it may have a happier issue." In contrast, writer Adam Gopnik, in "The New Yorker", notes that while Everett's Oration was explicitly neoclassical, referring directly to Marathon and Pericles, "Lincoln's rhetoric is, instead, deliberately Biblical. (It is difficult to find a single obviously classical reference in any of his speeches.) Lincoln had mastered the sound of the King James Bible so completely that he could recast abstract issues of constitutional law in Biblical terms, making the proposition that Texas and New Hampshire should be forever bound by a single post office sound like something right out of Genesis."
Several theories have been advanced by Lincoln scholars to explain the provenance of Lincoln's famous phrase "government of the people, by the people, for the people".
The Prologue to John Wycliffe's first English translation of the Bible, which first appeared in 1384, includes the phrase: 
In a discussion "A more probable origin of a famous Lincoln phrase", in "The American Monthly Review of Reviews", Albert Shaw credits a correspondent with pointing out the writings of William Herndon, Lincoln's law partner, who wrote in the 1888 work "Abraham Lincoln: The True Story of A Great Life" that he had brought to Lincoln some of the sermons of abolitionist minister Theodore Parker, of Massachusetts, and that Lincoln was moved by Parker's use of this idea:
Craig R. Smith, in "Criticism of Political Rhetoric and Disciplinary Integrity", suggested Lincoln's view of the government as expressed in the Gettysburg Address was influenced by the noted speech of Massachusetts Senator Daniel Webster, the "Second Reply to Hayne", in which Webster famously thundered "Liberty and Union, now and forever, one and inseparable!" Specifically, in this speech on January 26, 1830, before the United States Senate, Webster described the federal government as: "made for the people, made by the people, and answerable to the people", foreshadowing Lincoln's "government of the people, by the people, for the people". Webster also noted, "This government, Sir, is the independent offspring of the popular will. It is not the creature of State legislatures; nay, more, if the whole truth must be told, the people brought it into existence, established it, and have hitherto supported it, for the very purpose, amongst others, of imposing certain salutary restraints on State sovereignties."
A source predating these others with which Lincoln was certainly familiar was Chief Justice John Marshall's opinion in McCulloch v. Maryland (1819), a case asserting federal authority to create a national bank and to be free from the State's powers to tax. In asserting the superiority of federal power over the states, Chief Justice Marshall stated: "The government of the Union, then (whatever may be the influence of this fact on the case), is, emphatically and truly, a government of the people. In form, and in substance, it emanates from them. Its powers are granted by them, and are to be exercised directly on them, and for their benefit." Lincoln, a lawyer and President engaged in the greatest struggle of federalism, was (more eloquently) echoing the preeminent case that had solidified federal power over the States.
Wills observed Lincoln's usage of the imagery of birth, life, and death in reference to a nation "brought forth", "conceived", and that shall not "perish". Others, including Allen C. Guelzo, the director of Civil War Era studies at Gettysburg College in Pennsylvania, suggested that Lincoln's formulation "four score and seven" was an allusion to the King James Version of the Bible's , in which man's lifespan is given as "threescore years and ten; and if by reason of strength they be fourscore years".
Five manuscripts.
Each of the five known manuscript copies of the Gettysburg Address is named for the person who received it from Lincoln. Lincoln gave copies to his private secretaries, John Nicolay and John Hay. Both of these drafts were written around the time of his November 19 address, while the other three copies of the address, the Everett, Bancroft, and Bliss copies, were written by Lincoln for charitable purposes well after November 19. In part because Lincoln provided a title and signed and dated the Bliss copy, it has become the standard text of Lincoln's Gettysburg Address.
Nicolay and Hay were appointed custodians of Lincoln's papers by Lincoln's son Robert Todd Lincoln in 1874. After appearing in facsimile in an article written by John Nicolay in 1894, the Nicolay copy was presumably among the papers passed to Hay by Nicolay's daughter Helen upon Nicolay's death in 1901. Robert Lincoln began a search for the original copy in 1908, which resulted in the discovery of a handwritten copy of the Gettysburg Address among the bound papers of John Hay—a copy now known as the "Hay copy" or "Hay draft".
The Hay draft differed from the version of the Gettysburg Address published by John Nicolay in 1894 in a number of significant ways: it was written on a different type of paper, had a different number of words per line and number of lines, and contained editorial revisions in Lincoln's hand.
Both the Hay and Nicolay copies of the Address are within the Library of Congress, encased in specially designed, temperature-controlled, sealed containers with argon gas in order to protect the documents from oxidation and continued deterioration.
Nicolay copy.
The Nicolay copy is often called the "first draft" because it is believed to be the earliest copy that exists. Scholars disagree over whether the Nicolay copy was actually the reading copy Lincoln held at Gettysburg on November 19. In an 1894 article that included a facsimile of this copy, Nicolay, who had become the custodian of Lincoln's papers, wrote that Lincoln had brought to Gettysburg the first part of the speech written in ink on Executive Mansion stationery, and that he had written the second page in pencil on lined paper before the dedication on November 19. Matching folds are still evident on the two pages, suggesting it could be the copy that eyewitnesses say Lincoln took from his coat pocket and read at the ceremony. Others believe that the delivery text has been lost, because some of the words and phrases of the Nicolay copy do not match contemporary transcriptions of Lincoln's original speech. The words "under God", for example, are missing in this copy from the phrase "that this nation shall have a new birth of freedom ..." In order for the Nicolay draft to have been the reading copy, either the contemporary transcriptions were inaccurate, or Lincoln would have had to depart from his written text in several instances. This copy of the Gettysburg Address apparently remained in John Nicolay's possession until his death in 1901, when it passed to his friend and colleague John Hay. It used to be on display as part of the American Treasures exhibition of the Library of Congress in Washington, D.C.
Hay copy.
The existence of the Hay copy was first announced to the public in 1906, after the search for the "original manuscript" of the Address among the papers of John Hay brought it to light. Significantly, it differs somewhat from the manuscript of the Address described by John Nicolay in his article, and contains numerous omissions and inserts in Lincoln's own hand, including omissions critical to the basic meaning of the sentence, not simply words that would be added by Lincoln to strengthen or clarify their meaning. In this copy, as in the Nicolay copy, the words "under God" are not present.
This version has been described as "the most inexplicable" of the drafts and is sometimes referred to as the "second draft". The "Hay copy" was made either on the morning of the delivery of the Address, or shortly after Lincoln's return to Washington. Those who believe that it was completed on the morning of his address point to the fact that it contains certain phrases that are not in the first draft but are in the reports of the address as delivered and in subsequent copies made by Lincoln. It is probable, they conclude, that, as stated in the explanatory note accompanying the original copies of the first and second drafts in the Library of Congress, Lincoln held this second draft when he delivered the address. Lincoln eventually gave this copy to his other personal secretary, John Hay, whose descendants donated both it and the Nicolay copy to the Library of Congress in 1916.
Everett copy.
The Everett copy, also known as the "Everett-Keyes copy", was sent by President Lincoln to Edward Everett in early 1864, at Everett's request. Everett was collecting the speeches at the Gettysburg dedication into one bound volume to sell for the benefit of stricken soldiers at New York's Sanitary Commission Fair. The draft Lincoln sent became the third autograph copy, and is now in the possession of the Illinois State Historical Library in Springfield, Illinois, where it is currently on display in the Treasures Gallery of the Abraham Lincoln Presidential Library and Museum.
Bancroft copy.
The Bancroft copy of the Gettysburg Address was written out by President Lincoln in February 1864 at the request of George Bancroft, the famed historian and former Secretary of the Navy, whose comprehensive ten-volume "History of the United States" later led him to be known as the "father of American History". Bancroft planned to include this copy in "Autograph Leaves of Our Country's Authors", which he planned to sell at a Soldiers' and Sailors' Sanitary Fair in Baltimore. As this fourth copy was written on both sides of the paper, it proved unusable for this purpose, and Bancroft was allowed to keep it. This manuscript is the only one accompanied both by a letter from Lincoln transmitting the manuscript and by the original envelope addressed and franked by Lincoln. This copy remained in the Bancroft family for many years, was sold to various dealers and purchased by Nicholas and Marguerite Lilly Noyes, who donated the manuscript to Cornell in 1949. It is now held by the Division of Rare and Manuscript Collections in the Carl A. Kroch Library at Cornell University. It is the only one of the five copies to be privately owned.
Bliss copy.
Discovering that his fourth written copy could not be used, Lincoln then wrote a fifth draft, which was accepted for the purpose requested. The Bliss copy, named for Colonel Alexander Bliss, Bancroft's stepson and publisher of "Autograph Leaves", is the only draft to which Lincoln affixed his signature. Lincoln is not known to have made any further copies of the Gettysburg Address. Because of the apparent care in its preparation, and in part because Lincoln provided a title and signed and dated this copy, it has become the standard version of the address and the source for most facsimile reproductions of Lincoln's Gettysburg Address. It is the version that is inscribed on the South wall of the Lincoln Memorial.
This draft is now displayed in the Lincoln Room of the White House, a gift of Oscar B. Cintas, former Cuban Ambassador to the United States. Cintas, a wealthy collector of art and manuscripts, purchased the Bliss copy at a public auction in 1949 for $54,000 ($ as of ), at that time the highest price ever paid for a document at public auction. Cintas' properties were claimed by the Castro government after the Cuban Revolution in 1959, but Cintas, who died in 1957, willed the Gettysburg Address to the American people, provided it would be kept at the White House, where it was transferred in 1959.
Garry Wills concluded the Bliss copy "is stylistically preferable to others in one significant way: Lincoln removed 'here' from 'that cause for which they (here) gave ...' The seventh 'here' is in all other versions of the speech." Wills noted the fact that Lincoln "was still making such improvements", suggesting Lincoln was more concerned with a perfected text than with an 'original' one.
From November 21, 2008, to January 1, 2009, the Albert H. Small Documents Gallery at the Smithsonian Institution National Museum of American History hosted a limited public viewing of the Bliss copy, with the support of then-First Lady Laura Bush. The Museum also launched an online exhibition and interactive gallery to enable visitors to look more closely at the document.
Others.
Another contemporary source of the text is the Associated Press dispatch, transcribed from the shorthand notes taken by reporter Joseph L. Gilbert. It also differs from the drafted text in a number of minor ways.
Contemporary sources and reaction.
Eyewitness reports vary as to their view of Lincoln's performance. In 1931, the printed recollections of 87-year-old Mrs. Sarah A. Cooke Myers, who was 19 when she attended the ceremony, suggest a dignified silence followed Lincoln's speech: "I was close to the President and heard all of the Address, but it seemed short. Then there was an impressive silence like our Menallen Friends Meeting. There was no applause when he stopped speaking." According to historian Shelby Foote, after Lincoln's presentation, the applause was delayed, scattered, and "barely polite". In contrast, Pennsylvania Governor Curtin maintained, "He pronounced that speech in a voice that all the multitude heard. The crowd was hushed into silence because the President stood before them ... It was so Impressive! It was the common remark of everybody. Such a speech, as they said it was!" Reinterment of soldiers' remains from field graves into the cemetery, which had begun within months of the battle, was less than half complete on the day of the ceremony.
In an oft-repeated legend, Lincoln is said to have turned to his bodyguard Ward Hill Lamon and remarked that his speech, like a bad plow, "won't scour". According to Garry Wills, this statement has no basis in fact and largely originates from the unreliable recollections of Lamon. In Garry Wills's view, " had done what he wanted to do ".
In a letter to Lincoln written the following day, Everett praised the President for his eloquent and concise speech, saying, "I should be glad if I could flatter myself that I came as near to the central idea of the occasion, in two hours, as you did in two minutes." Lincoln replied that he was glad to know the speech was not a "total failure".
Other public reaction to the speech was divided along partisan lines. The Democratic-leaning "Chicago Times" observed, "The cheek of every American must tingle with shame as he reads the silly, flat and dishwatery utterances of the man who has to be pointed out to intelligent foreigners as the President of the United States." In contrast, the Republican-leaning "New York Times" was complimentary and printed the speech. In Massachusetts, the "Springfield Republican" also printed the entire speech, calling it "a perfect gem" that was "deep in feeling, compact in thought and expression, and tasteful and elegant in every word and comma". The "Republican" predicted that Lincoln's brief remarks would "repay further study as the model speech". On the sesquicentennial of the address, "The Patriot-News" of Harrisburg, Pennsylvania, formerly the "Patriot & Union", retracted its original reaction ("silly remarks" deserving "the veil of oblivion") stating: "Seven score and ten years ago, the forefathers of this media institution brought forth to its audience a judgment so flawed, so tainted by hubris, so lacking in the perspective history would bring, that it cannot remain unaddressed in our archives. ... the "Patriot & Union" failed to recognize speech's momentous importance, timeless eloquence, and lasting significance. The "Patriot-News" regrets the error."
Foreign newspapers also criticized Lincoln's remarks. "The Times" of London commented: "The ceremony Gettysburg was rendered ludicrous by some of the luckless sallies of that poor President Lincoln."
Congressman Joseph A. Goulden, then an eighteen-year-old school teacher, was present and heard the speech. He served in the United States Marine Corps during the war, and later had a successful career in insurance in Pennsylvania and New York City before entering Congress as a Democrat. In his later life, Goulden was often asked about the speech, since the passage of time made him one of a dwindling number of individuals who had been present for it. He commented on the event and Lincoln's speech in favorable terms, naming Lincoln's address as one of the inspirations for him to enter military service. Goulden's recollections included remarks to the House of Representatives in 1914.
Audio recollections.
William R. Rathvon is the only known eyewitness of both Lincoln's arrival at Gettysburg and the address itself to have left an audio recording of his recollections. One year before his death in 1939, Rathvon's reminiscences were recorded on February 12, 1938, at the Boston studios of radio station WRUL, including his reading the address, itself, and a 78 rpm record was pressed. The title of the 78 record was "I Heard Lincoln That Day – William R. Rathvon, TR Productions". A copy wound up at National Public Radio (NPR) during a "Quest for Sound" project in 1999. NPR continues to air it around Lincoln's birthday.
Like most people who came to Gettysburg, the Rathvon family was aware that Lincoln was going to make some remarks. The family went to the town square where the procession was to form to go out to the cemetery that had not been completed yet. At the head of the procession rode Lincoln on a gray horse preceded by a military band that was the first the young boy had ever seen. Rathvon describes Lincoln as so tall and with such long legs that they went almost to the ground; he also mentions the long eloquent speech given by Edward Everett of Massachusetts whom Rathvon accurately described as the "most finished orator of the day". Rathvon then goes on to describe how Lincoln stepped forward and "with a manner serious almost to sadness, gave his brief address". During the delivery, along with some other boys, young Rathvon wiggled his way forward through the crowd until he stood within 15 feet of Mr. Lincoln and looked up into what he described as Lincoln's "serious face". Rathvon recalls candidly that, although he listened "intently to every word the president uttered and heard it clearly", he explains, "boylike, I could not recall any of it afterwards". But he explains that if anyone said anything disparaging about "honest Abe", there would have been a "junior battle of Gettysburg". In the recording Rathvon speaks of Lincoln's speech allegorically "echoing through the hills".
Photographs.
The only known and confirmed photograph of Lincoln at Gettysburg, taken by photographer David Bachrach was identified in the Mathew Brady collection of photographic plates in the National Archives and Records Administration in 1952. While Lincoln's speech was short and may have precluded multiple pictures of him while speaking, he and the other dignitaries sat for hours during the rest of the program. Given the length of Everett's speech and the length of time it took for 19th-century photographers to get "set up" before taking a picture, it is quite plausible that the photographers were ill-prepared for the brevity of Lincoln's remarks.
Usage of "under God".
The words "under God" do not appear in the Nicolay and Hay drafts but are included in the three later copies (Everett, Bancroft, and Bliss). Accordingly, some skeptics maintain that Lincoln did not utter the words "under God" at Gettysburg. However, at least three reporters telegraphed the text of Lincoln's speech on the day the Address was given with the words "under God" included. Historian William E. Barton argues that:
The reporters present included Joseph Gilbert, from the Associated Press; Charles Hale, from the "Boston Advertiser"; John R. Young (who later became the Librarian of Congress), from the "Philadelphia Press"; and reporters from the "Cincinnati Commercial", "New York Tribune", and "The New York Times". Charles Hale "had notebook and pencil in hand, took down the slow-spoken words of the President". "He took down what he declared was the exact language of Lincoln's address, and his declaration was as good as the oath of a court stenographer. His associates confirmed his testimony, which was received, as it deserved to be, at its face value." One explanation is that Lincoln deviated from his prepared text and inserted the phrase when he spoke. Ronald C. White, visiting professor of history at the University of California – Los Angeles and professor of American religious history emeritus at the San Francisco Theological Seminary, wrote in this context of Lincoln's insertion and usage of "under God":
It was an uncharacteristically spontaneous revision for a speaker who did not trust extemporaneous speech. Lincoln had added impromptu words in several earlier speeches, but always offered a subsequent apology for the change. In this instance, he did not. And Lincoln included "under God" in all three copies of the address he prepared at later dates. "Under God" pointed backward and forward: back to "this nation", which drew its breath from both political and religious sources, but also forward to a "new birth". Lincoln had come to see the Civil War as a ritual of purification. The old Union had to die. The old man had to die. Death became a transition to a new Union and a new humanity.
The phrase "under God" was used frequently in works published before 1860, usually with the meaning "with God's help".
Platform location.
Outside the Cemetery and within sight of the cross-walk, a historical marker proclaims:
Nearby, Nov. 19, 1863, in dedicating the National Cemetery, Abraham Lincoln gave the address which he had written in Washington and revised after his arrival at Gettysburg the evening of November 18.
Directly inside the Taneytown Road entrance are located the Rostrum and the "Lincoln Address Memorial." Neither of these is located within 300 yards of any of the five (or more) claimed locations for the dedicatory platform.
Pre-modern.
Colonel W. Yates Selleck was a marshal in the parade on Consecration Day and was seated on the platform when Lincoln made the address. Selleck marked a map with the position of the platform and described it as "350 feet almost due north of Soldiers' National Monument, 40 feet from a point in the outer circle of lots where Michigan and New York [burial sections are separated by a path". A location which approximates this description is 39°49.243′N, 77°13.869′W.
As pointed out in 1973 by retired park historian Frederick Tilberg, the "Selleck Site" is 25 feet lower than the crest of Cemetery Hill, and only the crest presents a panoramic view of the battlefield. A spectacular view from the location of the speech was noted by many eyewitnesses, is consistent with the "Traditional Site" at the Soldiers' National Monument (and other sites on the crest) but is inconsistent with the "Selleck Site."
The "Kentucky Memorial" was erected in 1975, is located directly adjacent to the Soldiers' National Monument, and states, "Kentucky honors her son, Abraham Lincoln, who delivered his immortal address at the site now marked by the soldiers' monument." With its position at the center of the concentric rings of soldiers' graves and the continuing endorsement of Lincoln's native state the Soldiers' National Monument persists as a credible location for the speech.
Writing a physical description of the layout for the Gettysburg National Cemetery under construction in November 1863, the correspondent from the "Cincinnati Daily Commercial" described the dividing lines between the state grave plots as "the radii of a common center, where a flag pole is now raised, but where it is proposed to erect a national monument". With the inclusion of this quotation Tilberg inadvertently verifies a central principle of future photographic analyses—a flagpole, rather than the speakers' platform, occupied the central point of the soldiers' graves. In fact, the precision of the photo-analyses relies upon the coincidence of position between this temporary flag pole and the future monument.
Confusing to today's tourist, the "Kentucky Memorial" is contradicted by a newer marker which was erected nearby by the Gettysburg National Military Park and locates the speakers' platform inside Evergreen Cemetery. Similarly, outdated National Park Service documents which pinpoint the location at the Soldiers' National Monument have not been systematically revised since the placement of the newer marker. Miscellaneous web pages perpetuate the "Traditional Site."
Photo analysis.
2-D and optical stereoscopy.
Based upon photographic analysis, the Gettysburg National Military Park (G.N.M.P.) placed a marker (near ) which states, "The speakers' platform was located in Evergreen Cemetery to your left." The observer of this marker stands facing the fence which separates the two cemeteries (one public and one private).
In 1982, Senior Park Historian Kathleen Georg Harrison first analyzed photographs and proposed a location in Evergreen Cemetery but has not published her analysis. Speaking for Harrison without revealing details, two sources characterize her proposed location as "on or near Brown family vault" in Evergreen Cemetery.
William A. Frassanito, a former military intelligence analyst, documented a comprehensive photographic analysis in 1995, and it associates the location of the platform with the position of specific modern headstones in Evergreen Cemetery. According to Frassanito, the extant graves of Israel Yount (died 1892)(), John Koch (died 1913)(), and George E. Kitzmiller (died 1874)() are among those which occupy the location of the 1863 speaker's stand.
3-D photo-rendering and -animation.
Assistant Professor of New Media at the University of North Carolina at Asheville, Christopher Oakley and his students are "working to produce a lifelike virtual 3-D re-creation of Lincoln delivering the Gettysburg Address" as part of the "Virtual Lincoln Project." After taking precise measurements, some using lasers, and countless photographs on Cemetery Hill in 2013, Oakley's team used 3-D animation software Maya to estimate locations for the platform and the photographers who recorded its occupants. This work remains under development.
Resolution.
The GNMP marker, Wills' interpretation of Harrison's analysis, and the Frassanito analysis concur that the platform was located in private Evergreen Cemetery, rather than public Soldiers' National Cemetery. The National Park Service's "National Cemetery Walking Tour" brochure is one NPS document which agrees:
The Soldiers' National Monument, long misidentified as the spot from which Lincoln spoke, honors the fallen soldiers. location of the speech was actually on the crown of this hill, a short distance on the other side of the iron fence and inside the Evergreen Cemetery, where President Lincoln delivered the Gettysburg Address to a crowd of some 15,000 people.
While the GNMP marker is unspecific, providing only "to your left", the locations determined by the Harrison/Wills analysis and the Frassanito analysis differ by 40 yards. Frassanito has documented 1) his own conclusion, 2) his own
methods and 3) a refutation of the Harrison site, but neither the GNMP nor Harrison has provided any documentation. Each of the three points to a location in Evergreen Cemetery, as do modern NPS publications.
Although Lincoln dedicated the Gettysburg National Cemetery, the monument at the Cemetery's center actually has nothing to do with Lincoln or his famous speech. Intended to symbolize Columbia paying tribute to her fallen sons, its appreciation has been commandeered by the thirst for a tidy home for the speech. Freeing the Cemetery and Monument to serve their original purpose, honoring of Union departed, is as unlikely as a resolution to the location controversy and the erection of a public monument to the speech in the exclusively private Evergreen Cemetery.
Legacy.
The importance of the Gettysburg Address in the history of the United States is underscored by its enduring presence in American culture. In addition to its prominent place carved into a stone cella on the south wall of the Lincoln Memorial in Washington, D.C., the Gettysburg Address is frequently referred to in works of popular culture, with the implicit expectation that contemporary audiences will be familiar with Lincoln's words.
In the many generations that have passed since the Address, it has remained among the most famous speeches in American history, and is often taught in classes about history or civics. Lincoln's Gettysburg Address is itself referenced in another of those famed orations, Martin Luther King, Jr.'s "I Have a Dream" speech. Standing on the steps of the Lincoln Memorial in August 1963, King began with a reference, by the style of his opening phrase, to President Lincoln and his enduring words: "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice."
Phrases from the Address are often used or referenced in other works. The current Constitution of France states that the principle of the Republic of France is ""gouvernement du peuple, par le peuple et pour le peuple" ("government of the people, by the people, and for the people"), a literal translation of Lincoln's words. Sun Yat-Sen's "Three Principles of the People" were inspired from that phrase as well. The aircraft carrier has as its ship's motto the phrase "shall not perish".
U.S. Senator Charles Sumner of Massachusetts wrote of the address and its enduring presence in American culture after Lincoln's assassination in April 1865: "That speech, uttered at the field of Gettysburg ... and now sanctified by the martyrdom of its author, is a monumental act. In the modesty of his nature he said 'the world will little note, nor long remember what we say here; but it can never forget what they did here.' He was mistaken. The world at once noted what he said, and will never cease to remember it."
U.S. President John F. Kennedy stated in July 1963 about the battle and Lincoln's speech: "Five score years ago the ground on which we here stand shuddered under the clash of arms and was consecrated for all time by the blood of American manhood. Abraham Lincoln, in dedicating this great battlefield, has expressed, in words too eloquent for paraphrase or summary, why this sacrifice was necessary." Sadly, Kennedy would meet the same fate as Abraham Lincoln only three days after the Gettysburg Address centennial.
In 2015, the Abraham Lincoln Presidential Library Foundation compiled "Gettysburg Replies: The World Responds to Abraham Lincoln's Gettysburg Address". The work challenges leaders to craft 272 word responses to celebrate Abraham Lincoln, the Gettysburg Address, or a related topic.
One of the replies was by astrophysicist Neil deGrasse Tyson in which he made the point that one of Lincoln's greatest legacies was establishing, in the same year of the Gettysburg Address, the National Academy of Sciences, which had the longterm effect of "setting our Nation on a course of scientifically enlightened governance, without which we all may perish from this Earth".

</doc>
<doc id="12385" url="https://en.wikipedia.org/wiki?curid=12385" title="Genetic code">
Genetic code

The genetic code is the set of rules by which information encoded within genetic material (DNA or mRNA sequences) can be both translated into proteins by living cells or transcribed into non-coding RNAs that serve as regulatory tools in gene regulation. Biological decoding is accomplished by the ribosome, which links amino acids in an order specified by mRNA, using transfer RNA (tRNA) molecules to carry amino acids and to read the mRNA three nucleotides at a time. The genetic code is highly similar among all organisms and can be expressed in a simple table with 64 entries.
The code defines how sequences of nucleotide triplets, called "codons", specify which amino acid will be added next during protein synthesis. With some exceptions, a three-nucleotide codon in a nucleic acid sequence specifies a single amino acid. Because the vast majority of genes are encoded with exactly the same code (see the RNA codon table), this particular code is often referred to as the canonical or standard genetic code, or simply "the" genetic code, though in fact some variant codes have evolved. For example, protein synthesis in human mitochondria relies on a genetic code that differs from the standard genetic code.
While the genetic code determines the protein sequence for a given coding region, other genomic regions can influence when and where these proteins are produced.
Discovery.
Serious efforts to understand how proteins are encoded began after the structure of DNA was discovered in 1953. George Gamow postulated that sets of three bases must be employed to encode the 20 standard amino acids used by living cells to build proteins. With four different nucleotides, a code of 2 nucleotides would allow for only a maximum of 16 amino acids. A code of 3 nucleotides could code for a maximum of 64 amino acids.
The Crick, Brenner et al. experiment first demonstrated that codons consist of three DNA bases; Marshall Nirenberg and Heinrich J. Matthaei were the first to elucidate the nature of a codon in 1961 at the National Institutes of Health. They used a cell-free system to translate a poly-uracil RNA sequence (i.e., UUUUU...) and discovered that the polypeptide that they had synthesized consisted of only the amino acid phenylalanine. They thereby deduced that the codon UUU specified the amino acid phenylalanine. This was followed by experiments in Severo Ochoa's laboratory that demonstrated that the poly-adenine RNA sequence (AAAAA...) coded for the polypeptide poly-lysine and that the poly-cytosine RNA sequence (CCCCC...) coded for the polypeptide poly-proline. Therefore, the codon AAA specified the amino acid lysine, and the codon CCC specified the amino acid proline. Using different copolymers most of the remaining codons were then determined. Subsequent work by Har Gobind Khorana identified the rest of the genetic code. Shortly thereafter, Robert W. Holley determined the structure of transfer RNA (tRNA), the adapter molecule that facilitates the process of translating RNA into protein. This work was based upon earlier studies by Severo Ochoa, who received the Nobel Prize in Physiology or Medicine in 1959 for his work on the enzymology of RNA synthesis.
Extending this work, Nirenberg and Philip Leder revealed the triplet nature of the genetic code and deciphered the codons of the standard genetic code. In these experiments, various combinations of mRNA were passed through a filter that contained ribosomes, the components of cells that translate RNA into protein. Unique triplets promoted the binding of specific tRNAs to the ribosome. Leder and Nirenberg were able to determine the sequences of 54 out of 64 codons in their experiments. In 1968, Khorana, Holley and Nirenberg received the Nobel Prize in Physiology or Medicine for their work.
Salient features.
Sequence reading frame.
A codon is defined by the initial nucleotide from which translation starts. For example, the string GGGAAACCC, if read from the first position, contains the codons GGG, AAA, and CCC; and, if read from the second position, it contains the codons GGA and AAC; if read starting from the third position, GAA and ACC. Every sequence can, thus, be read in its 5' → 3' direction in three reading frames, each of which will produce a different amino acid sequence (in the given example, Gly-Lys-Pro, Gly-Asn, or Glu-Thr, respectively). With double-stranded DNA, there are six possible reading frames, three in the forward orientation on one strand and three reverse on the opposite strand. The actual frame from which a protein sequence is translated is defined by a start codon, usually the first AUG codon in the mRNA sequence.
Start/stop codons.
Translation starts with a chain initiation codon or start codon. Unlike stop codons, the codon alone is not sufficient to begin the process. Nearby sequences such as the Shine-Dalgarno sequence in "E. coli" and initiation factors are also required to start translation. The most common start codon is AUG, which is read as methionine or, in bacteria, as formylmethionine. Alternative start codons depending on the organism include "GUG" or "UUG"; these codons normally represent valine and leucine, respectively, but as start codons they are translated as methionine or formylmethionine.
The three stop codons have been given names: UAG is "amber", UGA is "opal" (sometimes also called "umber"), and UAA is "ochre". "Amber" was named by discoverers Richard Epstein and Charles Steinberg after their friend Harris Bernstein, whose last name means "amber" in German. The other two stop codons were named "ochre" and "opal" in order to keep the "color names" theme. Stop codons are also called "termination" or "nonsense" codons. They signal release of the nascent polypeptide from the ribosome because there is no cognate tRNA that has anticodons complementary to these stop signals, and so a release factor binds to the ribosome instead.
Effect of mutations.
During the process of DNA replication, errors occasionally occur in the polymerization of the second strand. These errors, called mutations, can have an impact on the phenotype of an organism, especially if they occur within the protein coding sequence of a gene. Error rates are usually very low—1 error in every 10–100 million bases—due to the "proofreading" ability of DNA polymerases.
Missense mutations and nonsense mutations are examples of point mutations, which can cause genetic diseases such as sickle-cell disease and thalassemia respectively. Clinically important missense mutations generally change the properties of the coded amino acid residue between being basic, acidic, polar or non-polar, whereas nonsense mutations result in a stop codon.
Mutations that disrupt the reading frame sequence by indels (insertions or deletions) of a non-multiple of 3 nucleotide bases are known as frameshift mutations. These mutations usually result in a completely different translation from the original, and are also very likely to cause a stop codon to be read, which truncates the creation of the protein. These mutations may impair the function of the resulting protein, and are thus rare in "in vivo" protein-coding sequences. One reason inheritance of frameshift mutations is rare is that, if the protein being translated is essential for growth under the selective pressures the organism faces, absence of a functional protein may cause death before the organism is viable. Frameshift mutations may result in severe genetic diseases such as Tay-Sachs disease.
Although most mutations that change protein sequences are harmful or neutral, some mutations have a beneficial effect on an organism. These mutations may enable the mutant organism to withstand particular environmental stresses better than wild-type organisms, or reproduce more quickly. In these cases a mutation will tend to become more common in a population through natural selection. Viruses that use RNA as their genetic material have rapid mutation rates, which can be an advantage, since these viruses will evolve constantly and rapidly, and thus evade the defensive responses of e.g. the human immune system. In large populations of asexually reproducing organisms, for example, "E. coli", multiple beneficial mutations may co-occur. This phenomenon is called clonal interference and causes competition among the mutations.
Degeneracy.
Degeneracy is the redundancy of the genetic code. The genetic code has redundancy but no ambiguity (see the codon tables below for the full correlation). For example, although codons GAA and GAG both specify glutamic acid (redundancy), neither of them specifies any other amino acid (no ambiguity). The codons encoding one amino acid may differ in any of their three positions. For example, the amino acid leucine is specified by YUR or CUN (UUA, UUG, CUU, CUC, CUA, or CUG) codons (difference in the first or third position indicated using IUPAC notation), while the amino acid serine is specified by UCN or AGY (UCA, UCG, UCC, UCU, AGU, or AGC) codons (difference in the first, second, or third position). A practical consequence of redundancy is that errors in the third position of the triplet codon cause only a silent mutation or an error that would not affect the protein because the hydrophilicity or hydrophobicity is maintained by equivalent substitution of amino acids; for example, a codon of NUN (where N = any nucleotide) tends to code for hydrophobic amino acids. NCN yields amino acid residues that are small in size and moderate in hydropathy; NAN encodes average size hydrophilic residues. The genetic code is so well-structured for hydropathy that a mathematical analysis (Singular Value Decomposition) of 12 variables (4 nucleotides x 3 positions) yields a remarkable correlation (C = 0.95) for predicting the hydropathy of the encoded amino acid directly from the triplet nucleotide sequence, "without translation." Note in the table, below, eight amino acids are not affected at all by mutations at the third position of the codon, whereas in the figure above, a mutation at the second position is likely to cause a radical change in the physicochemical properties of the encoded amino acid.
Transfer of information via the genetic code.
The genome of an organism is inscribed in DNA, or, in the case of some viruses, RNA. The portion of the genome that codes for a protein or an RNA is called a gene. Those genes that code for proteins are composed of tri-nucleotide units called codons, each coding for a single amino acid. Each nucleotide sub-unit consists of a phosphate, a deoxyribose sugar, and one of the four nitrogenous nucleobases. The purine bases adenine (A) and guanine (G) are larger and consist of two aromatic rings. The pyrimidine bases cytosine (C) and thymine (T) are smaller and consist of only one aromatic ring. In the double-helix configuration, two strands of DNA are joined to each other by hydrogen bonds in an arrangement known as base pairing. These bonds almost always form between an adenine base on one strand and a thymine base on the other strand, or between a cytosine base on one strand and a guanine base on the other. This means that the number of A and T bases will be the same in a given double helix, as will the number of G and C bases. In RNA, thymine (T) is replaced by uracil (U), and the deoxyribose is substituted by ribose.
Each protein-coding gene is transcribed into a molecule of the related RNA polymer. In prokaryotes, this RNA functions as messenger RNA or mRNA; in eukaryotes, the transcript needs to be processed to produce a mature mRNA. The mRNA is, in turn, translated on a ribosome into a chain of amino acids otherwise known as a polypeptide. The process of translation requires transfer RNAs which are covalently attached to a specific amino acid, guanosine triphosphate as an energy source, and a number of translation factors. tRNAs have anticodons complementary to the codons in an mRNA and can be covalently "charged" with specific amino acids at their 3' terminal CCA ends by enzymes known as aminoacyl tRNA synthetases, which have high specificity for both their cognate amino acid and tRNA. The high specificity of these enzymes is a major reason why the fidelity of protein translation is maintained.
There are 4³ = 64 different codon combinations possible with a triplet codon of three nucleotides; all 64 codons are assigned to either an amino acid or a stop signal. If, for example, an RNA sequence UUUAAACCC is considered and the reading frame starts with the first U (by convention, 5' to 3'), there are three codons, namely, UUU, AAA, and CCC, each of which specifies one amino acid. Therefore, this 9 base RNA sequence will be translated into an amino acid sequence that is three amino acids long. A given amino acid may be encoded by between one and six different codon sequences. A comparison may be made using bioinformatics tools wherein the codon is similar to a word, which is the standard data "chunk" and a nucleotide is similar to a bit, in that it is the smallest unit. This allows for powerful comparisons across species as well as within organisms.
The standard genetic code is shown in the following tables. Table 1 shows which amino acid each of the 64 codons specifies. Table 2 shows which codons specify each of the 20 standard amino acids involved in translation. These are called forward and reverse codon tables, respectively. For example, the codon "AAU" represents the amino acid asparagine, and "UGU" and "UGC" represent cysteine (standard three-letter designations, Asn and Cys, respectively).
DNA codon table.
The DNA codon table is essentially identical to that for RNA, but with U replaced by T.
Codon frequency.
The frequency of codons varies from species to species, and also intraspecifically. The following table is for the human genome.
"Human Genome"
Variations to the standard genetic code.
While slight variations on the standard code had been predicted earlier, none were discovered until 1979, when researchers studying human mitochondrial genes discovered they used an alternative code.
Many slight variants have been discovered since then, including various alternative mitochondrial codes, and small variants such as translation of the codon UGA as tryptophan in "Mycoplasma" species, and translation of CUG as a serine rather than a leucine in yeasts of the "CTG clade" ("Candida albicans" is member of this group). Because viruses must use the same genetic code as their hosts, modifications to the standard genetic code could interfere with the synthesis or functioning of viral proteins. However, some viruses (such as totiviruses) have adapted to the genetic code modification of the host. In bacteria and archaea, GUG and UUG are common start codons, but in rare cases, certain proteins may use alternative start codons not normally used by that species.
In certain proteins, non-standard amino acids are substituted for standard stop codons, depending on associated signal sequences in the messenger RNA. For example, UGA can code for selenocysteine and UAG can code for pyrrolysine. Selenocysteine is now viewed as the 21st amino acid, and pyrrolysine is viewed as the 22nd. Unlike selenocysteine, pyrrolysine encoded UAG is translated with the participation of a dedicated aminoacyl-tRNA synthetase. Both selenocysteine and pyrrolysine may be present in the same organism. Although the genetic code is normally fixed in an organism the achaeal prokaryote "Acetohalobium arabaticum" can expand its genetic code from 20 to 21 amino acids (by including pyrrolysine) under different conditions of growth.
Despite these differences, all known naturally-occurring codes are very similar to each other, and the coding mechanism is the same for all organisms: three-base codons, tRNA, ribosomes, reading the code in the same direction and translating the code three letters at a time into sequences of amino acids.
Predicting the genetic code.
The genetic code used by a genome can be predicted by identifying the genes encoded on that genome, and comparing the codons on the DNA to the amino acids in homologous proteins in other genomes. The evolutionary conservation of protein sequences makes it possible to predict the amino acid translation for each codon as the one that is most often aligned to that codon. The program FACIL allows the automated prediction of the genetic code, searching which amino acids in homologous protein domains are most often aligned to every codon. The resulting amino acid probabilities for each codon are displayed in a genetic code logo, that also shows the support for a stop codon.
Expanded genetic code.
Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.
H. Murakami and M. Sisido have extended some codons to have four and five bases. Steven A. Benner constructed a functional 65th ("in vivo") codon.
Origin.
The origin of the genetic code is a part of the question of the origin of life. Under the main hypothesis for the origin of life, the RNA world hypothesis, any model for the emergence of genetic code is intimately related to a model of the transfer from ribozymes (RNA enzymes) to proteins as the principal enzymes in cells.
In line with the RNA world hypothesis, transfer RNA molecules appear to have evolved before modern aminoacyl-tRNA synthetases, so the latter cannot be part of the explanation of its patterns.
There are three main ideas for the origin of the genetic code, and many models belong to either one of them or to a combination thereof:
Many hypotheses stand as a combination of these three basic ideas, and run through four themes:
Non-randomness.
If amino acids were randomly assigned to triplet codons, then there would be 1.5 × 1084 possible genetic codes to choose from. This number is found by calculating how many ways there are to place 21 items (20 amino acids plus one stop) in 64 bins, wherein each item is used at least once. [http://community.wolfram.com/groups/-/m/t/319970] 
In fact, the distribution of codon assignments in the genetic code is nonrandom. In particular, the genetic code clusters certain amino acid assignments. For example:
Further models.
Models based on signaling games combine elements of game theory, natural selection and information channels. Such models have been used to suggest that the first polypeptides were likely short and had some use other than enzymatic function. Game theoretic models have also suggested that the organization of RNA strings into cells may have been necessary to prevent "deceptive" use of the genetic code, i.e. preventing the ancient equivalent of viruses from overwhelming the RNA world.
It has been suggested that robust hypothesis for the origin of genetic code should also address or predict the following gross features of the codon table:
As an example for addressing the latter requirement, it has been suggested that the stop codons are such that they are most likely to terminate translation early in the case of a frame shift error.

</doc>
<doc id="12386" url="https://en.wikipedia.org/wiki?curid=12386" title="Golden ratio">
Golden ratio

In mathematics, two quantities are in the golden ratio if their ratio is the same as the ratio of their sum to the larger of the two quantities. The figure on the right illustrates the geometric relationship. Expressed algebraically, for quantities "a" and "b" with "a" > "b" > 0,
where the Greek letter phi (formula_2 or formula_3) represents the golden ratio. Its value is:
The golden ratio also is called the golden mean or golden section (Latin: "sectio aurea"). Other names include extreme and mean ratio, medial section, divine proportion, divine section (Latin: "sectio divina"), golden proportion, golden cut, and golden number.
Some twentieth-century artists and architects, including Le Corbusier and Dalí, have proportioned their works to approximate the golden ratio—especially in the form of the golden rectangle, in which the ratio of the longer side to the shorter is the golden ratio—believing this proportion to be aesthetically pleasing. The golden ratio appears in some patterns in nature, including the spiral arrangement of leaves and other plant parts.
Mathematicians since Euclid have studied the properties of the golden ratio, including its appearance in the dimensions of a regular pentagon and in a golden rectangle, which may be cut into a square and a smaller rectangle with the same aspect ratio. The golden ratio has also been used to analyze the proportions of natural objects as well as man-made systems such as financial markets, in some cases based on dubious fits to data.
Calculation.
Two quantities "a" and "b" are said to be in the "golden ratio" if
One method for finding the value of is to start with the left fraction. Through simplifying the fraction and substituting in b/a = 1/,
Therefore,
Multiplying by gives
which can be rearranged to
Using the quadratic formula, two solutions are obtained:
and
Because is the ratio between positive quantities is necessarily positive:
History.
The golden ratio has been claimed to have held a special fascination for at least 2,400 years, though without reliable evidence. According to Mario Livio:
Ancient Greek mathematicians first studied what we now call the golden ratio because of its frequent appearance in geometry. The division of a line into "extreme and mean ratio" (the golden section) is important in the geometry of regular pentagrams and pentagons. Euclid's "Elements" (Greek: ) provides the first known written definition of what is now called the golden ratio: "A straight line is said to have been "cut in extreme and mean ratio" when, as the whole line is to the greater segment, so is the greater to the lesser." Euclid explains a construction for cutting (sectioning) a line "in extreme and mean ratio", i.e., the golden ratio. Throughout the "Elements", several propositions (theorems in modern terminology) and their proofs employ the golden ratio.
The golden ratio is explored in Luca Pacioli's book "De divina proportione" of 1509.
The first known approximation of the (inverse) golden ratio by a decimal fraction, stated as "about 0.6180340", was written in 1597 by Michael Maestlin of the University of Tübingen in a letter to his former student Johannes Kepler.
Since the 20th century, the golden ratio has been represented by the Greek letter φ (phi, after Phidias, a sculptor who is said to have employed it) or less commonly by τ (tau, the first letter of the ancient Greek root τομή—meaning "cut").
Timeline.
Timeline according to Priya Hemenway:
Applications and observations.
Aesthetics.
"De Divina Proportione", a three-volume work by Luca Pacioli, was published in 1509. Pacioli, a Franciscan friar, was known mostly as a mathematician, but he was also trained and keenly interested in art. "De Divina Proportione" explored the mathematics of the golden ratio. Though it is often said that Pacioli advocated the golden ratio's application to yield pleasing, harmonious proportions, Livio points out that the interpretation has been traced to an error in 1799, and that Pacioli actually advocated the Vitruvian system of rational proportions. Pacioli also saw Catholic religious significance in the ratio, which led to his work's title. "De Divina Proportione" contains illustrations of regular solids by Leonardo da Vinci, Pacioli's longtime friend and collaborator.
Architecture.
The Parthenon's façade as well as elements of its façade and elsewhere are said by some to be circumscribed by golden rectangles. Other scholars deny that the Greeks had any aesthetic association with golden ratio. For example, Midhat J. Gazalé says, "It was not until Euclid, however, that the golden ratio's mathematical properties were studied. In the "Elements" (308 BC) the Greek mathematician merely regarded that number as an interesting irrational number, in connection with the middle and extreme ratios. Its occurrence in regular pentagons and decagons was duly observed, as well as in the dodecahedron (a regular polyhedron whose twelve faces are regular pentagons). It is indeed exemplary that the great Euclid, contrary to generations of mystics who followed, would soberly treat that number for what it is, without attaching to it other than its factual properties." And Keith Devlin says, "Certainly, the oft repeated assertion that the Parthenon in Athens is based on the golden ratio is not supported by actual measurements. In fact, the entire story about the Greeks and golden ratio seems to be without foundation. The one thing we know for sure is that Euclid, in his famous textbook "Elements", written around 300 BC, showed how to calculate its value." Later sources like Vitruvius exclusively discuss proportions that can be expressed in whole numbers, i.e. commensurate as opposed to irrational proportions.
A 2004 geometrical analysis of earlier research into the Great Mosque of Kairouan reveals a consistent application of the golden ratio throughout the design, according to Boussora and Mazouz. They found ratios close to the golden ratio in the overall proportion of the plan and in the dimensioning of the prayer space, the court, and the minaret. The authors note, however, that the areas where ratios close to the golden ratio were found are not part of the original construction, and theorize that these elements were added in a reconstruction.
The Swiss architect Le Corbusier, famous for his contributions to the modern international style, centered his design philosophy on systems of harmony and proportion. Le Corbusier's faith in the mathematical order of the universe was closely bound to the golden ratio and the Fibonacci series, which he described as "rhythms apparent to the eye and clear in their relations with one another. And these rhythms are at the very root of human activities. They resound in man by an organic inevitability, the same fine inevitability which causes the tracing out of the Golden Section by children, old men, savages and the learned."
Le Corbusier explicitly used the golden ratio in his Modulor system for the scale of architectural proportion. He saw this system as a continuation of the long tradition of Vitruvius, Leonardo da Vinci's "Vitruvian Man", the work of Leon Battista Alberti, and others who used the proportions of the human body to improve the appearance and function of architecture. In addition to the golden ratio, Le Corbusier based the system on human measurements, Fibonacci numbers, and the double unit. He took suggestion of the golden ratio in human proportions to an extreme: he sectioned his model human body's height at the navel with the two sections in golden ratio, then subdivided those sections in golden ratio at the knees and throat; he used these golden ratio proportions in the Modulor system. Le Corbusier's 1927 Villa Stein in Garches exemplified the Modulor system's application. The villa's rectangular ground plan, elevation, and inner structure closely approximate golden rectangles.
Another Swiss architect, Mario Botta, bases many of his designs on geometric figures. Several private houses he designed in Switzerland are composed of squares and circles, cubes and cylinders. In a house he designed in Origlio, the golden ratio is the proportion between the central section and the side sections of the house.
In a recent book, author Jason Elliot speculated that the golden ratio was used by the designers of the Naqsh-e Jahan Square and the adjacent Lotfollah mosque.
Painting.
The 16th-century philosopher Heinrich Agrippa drew a man over a pentagram inside a circle, implying a relationship to the golden ratio.
Leonardo da Vinci's illustrations of polyhedra in "De divina proportione" ("On the Divine Proportion") and his views that some bodily proportions exhibit the golden ratio have led some scholars to speculate that he incorporated the golden ratio in his paintings. But the suggestion that his "Mona Lisa", for example, employs golden ratio proportions, is not supported by anything in Leonardo's own writings. Similarly, although the "Vitruvian Man" is often shown in connection with the golden ratio, the proportions of the figure do not actually match it, and the text only mentions whole number ratios.
Salvador Dalí, influenced by the works of Matila Ghyka, explicitly used the golden ratio in his masterpiece, "The Sacrament of the Last Supper". The dimensions of the canvas are a golden rectangle. A huge dodecahedron, in perspective so that edges appear in golden ratio to one another, is suspended above and behind Jesus and dominates the composition.
Mondrian has been said to have used the golden section extensively in his geometrical paintings, though other experts (including critic Yve-Alain Bois) have disputed this claim.
A statistical study on 565 works of art of different great painters, performed in 1999, found that these artists had not used the golden ratio in the size of their canvases. The study concluded that the average ratio of the two sides of the paintings studied is 1.34, with averages for individual artists ranging from 1.04 (Goya) to 1.46 (Bellini). On the other hand, Pablo Tosto listed over 350 works by well-known artists, including more than 100 which have canvasses with golden rectangle and root-5 proportions, and others with proportions like root-2, 3, 4, and 6.
Book design.
According to Jan Tschichold,
There was a time when deviations from the truly beautiful page proportions 2:3, 1:√3, and the Golden Section were rare. Many books produced between 1550 and 1770 show these proportions exactly, to within half a millimeter.
Design.
Some sources claim that the golden ratio is commonly used in everyday design, for example in the shapes of postcards, playing cards, posters, wide-screen televisions, photographs, light switch plates and cars.
Music.
Ernő Lendvai analyzes Béla Bartók's works as being based on two opposing systems, that of the golden ratio and the acoustic scale, though other music scholars reject that analysis. French composer Erik Satie used the golden ratio in several of his pieces, including "Sonneries de la Rose+Croix". The golden ratio is also apparent in the organization of the sections in the music of Debussy's "Reflets dans l'eau (Reflections in Water)", from "Images" (1st series, 1905), in which "the sequence of keys is marked out by the intervals 34, 21, 13 and 8, and the main climax sits at the phi position."
The musicologist Roy Howat has observed that the formal boundaries of "La Mer" correspond exactly to the golden section. Trezise finds the intrinsic evidence "remarkable," but cautions that no written or reported evidence suggests that Debussy consciously sought such proportions.
Pearl Drums positions the air vents on its Masters Premium models based on the golden ratio. The company claims that this arrangement improves bass response and has applied for a patent on this innovation.
Though Heinz Bohlen proposed the non-octave-repeating 833 cents scale based on combination tones, the tuning features relations based on the golden ratio. As a musical interval the ratio 1.618... is 833.090... cents ().
Nature.
Adolf Zeising, whose main interests were mathematics and philosophy, found the golden ratio expressed in the arrangement of parts such as leaves and branches along the stems of plants and of veins in leaves. He extended his research to the skeletons of animals and the branchings of their veins and nerves, to the proportions of chemical compounds and the geometry of crystals, even to the use of proportion in artistic endeavors. In these patterns in nature he saw the golden ratio operating as a universal law. In connection with his scheme for golden-ratio-based human body proportions, Zeising wrote in 1854 of a universal law "in which is contained the ground-principle of all formative striving for beauty and completeness in the realms of both nature and art, and which permeates, as a paramount spiritual ideal, all structures, forms and proportions, whether cosmic or individual, organic or inorganic, acoustic or optical; which finds its fullest realization, however, in the human form."
In 2010, the journal "Science" reported that the golden ratio is present at the atomic scale in the magnetic resonance of spins in cobalt niobate crystals.
Since 1991, several researchers have proposed connections between the golden ratio and human genome DNA.
However, some have argued that many apparent manifestations of the golden ratio in nature, especially in regard to animal dimensions, are fictitious.
Optimization.
The golden ratio is key to the golden section search.
Perceptual studies.
Studies by psychologists, starting with Fechner, have been devised to test the idea that the golden ratio plays a role in human perception of beauty. While Fechner found a preference for rectangle ratios centered on the golden ratio, later attempts to carefully test such a hypothesis have been, at best, inconclusive.
Mathematics.
Irrationality.
The golden ratio is an irrational number. Below are two short proofs of irrationality:
Contradiction from an expression in lowest terms.
Recall that:
If we call the whole "n" and the longer part "m", then the second statement above becomes
or, algebraically
To say that is rational means that is a fraction "n"/"m" where "n" and "m" are integers. We may take "n"/"m" to be in lowest terms and "n" and "m" to be positive. But if "n"/"m" is in lowest terms, then the identity labeled (*) above says "m"/("n" − "m") is in still lower terms. That is a contradiction that follows from the assumption that is rational.
Derivation from irrationality of √5.
Another short proof—perhaps more commonly known—of the irrationality of the golden ratio makes use of the closure of rational numbers under addition and multiplication. If formula_14 is rational, then formula_15 is also rational, which is a contradiction if it is already known that the square root of a non-square natural number is irrational.
Minimal polynomial.
The golden ratio is also an algebraic number and even an algebraic integer. It has minimal polynomial
Having degree 2, this polynomial actually has two roots, the other being the golden ratio conjugate.
Golden ratio conjugate.
The conjugate root to the minimal polynomial x2 - x - 1 is
The absolute value of this quantity (≈ 0.618) corresponds to the length ratio taken in reverse order (shorter segment length over longer segment length, "b/a"), and is sometimes referred to as the "golden ratio conjugate". It is denoted here by the capital Phi (formula_18):
Alternatively, formula_18 can be expressed as
This illustrates the unique property of the golden ratio among positive numbers, that
or its inverse:
This means 0.61803...:1 = 1:1.61803...
Alternative forms.
The formula = 1 + 1/ can be expanded recursively to obtain a continued fraction for the golden ratio:
and its reciprocal:
The convergents of these continued fractions (1/1, 2/1, 3/2, 5/3, 8/5, 13/8, ..., or 1/1, 1/2, 2/3, 3/5, 5/8, 8/13, ...) are ratios of successive Fibonacci numbers.
The equation 2 = 1 + likewise produces the continued square root, or infinite surd, form:
An infinite series can be derived to express phi:
Also:
These correspond to the fact that the length of the diagonal of a regular pentagon is times the length of its side, and similar relations in a pentagram.
Geometry.
The number turns up frequently in geometry, particularly in figures with pentagonal symmetry.
The length of a regular pentagon's diagonal is times its side.
The vertices of a regular icosahedron are those of three mutually orthogonal golden rectangles.
There is no known general algorithm to arrange a given number of nodes evenly on a sphere, for any of several definitions of even distribution (see, for example, "Thomson problem"). However, a useful approximation results from dividing the sphere into parallel bands of equal surface area and placing one node in each band at longitudes spaced by a golden section of the circle, i.e. 360°/ ≅ 222.5°. This method was used to arrange the 1500 mirrors of the student-participatory satellite Starshine-3.
Dividing a line segment by exterior division.
Application examples you can see in the articles Pentagon with a given side length, Decagon with given circumcircle and Decagon with a given side length.
The both above displayed different algorithms produce geometric constructions that divides a line segment into two line segments where the ratio of the longer to the shorter line segment is the golden ratio.
Golden triangle, pentagon and pentagram.
Golden triangle.
The golden triangle can be characterized as an isosceles triangle ABC with the property that bisecting the angle C produces a new triangle CXB which is a similar triangle to the original.
If angle BCX = α, then XCA = α because of the bisection, and CAB = α because of the similar triangles; ABC = 2α from the original isosceles symmetry, and BXC = 2α by similarity. The angles in a triangle add up to 180°, so 5α = 180, giving α = 36°. So the angles of the golden triangle are thus 36°-72°-72°. The angles of the remaining obtuse isosceles triangle AXC (sometimes called the golden gnomon) are 36°-36°-108°.
Suppose XB has length 1, and we call BC length . Because of the isosceles triangles XC=XA and BC=XC, so these are also length φ. Length AC = AB, therefore equals  + 1. But triangle ABC is similar to triangle CXB, so AC/BC = BC/BX, AC/ = φ/1, and so AC also equals 2. Thus 2 = φ + 1, confirming that is indeed the golden ratio.
Similarly, the ratio of the area of the larger triangle AXC to the smaller CXB is equal to , while the inverse ratio is φ − 1.
Pentagon.
In a regular pentagon the ratio between a side and a diagonal is formula_18 (i.e. 1/), while intersecting diagonals section each other in the golden ratio.
Odom's construction.
George Odom has given a remarkably simple construction for involving an equilateral triangle: if an equilateral triangle is inscribed in a circle and the line segment joining the midpoints of two sides is produced to intersect the circle in either of two points, then these three points are in golden proportion. This result is a straightforward consequence of the intersecting chords theorem and can be used to construct a regular pentagon, a construction that attracted the attention of the noted Canadian geometer H. S. M. Coxeter who published it in Odom's name as a diagram in the "American Mathematical Monthly" accompanied by the single word "Behold!" 
Pentagram.
The golden ratio plays an important role in the geometry of pentagrams. Each intersection of edges sections other edges in the golden ratio. Also, the ratio of the length of the shorter segment to the segment bounded by the two intersecting edges (a side of the pentagon in the pentagram's center) is , as the four-color illustration shows.
The pentagram includes ten isosceles triangles: five acute and five obtuse isosceles triangles. In all of them, the ratio of the longer side to the shorter side is . The acute triangles are golden triangles. The obtuse isosceles triangles are golden gnomons.
Ptolemy's theorem.
The golden ratio properties of a regular pentagon can be confirmed by applying Ptolemy's theorem to the quadrilateral formed by removing one of its vertices. If the quadrilateral's long edge and diagonals are "b", and short edges are "a", then Ptolemy's theorem gives "b"2 = "a"2 + "ab" which yields
Scalenity of triangles.
Consider a triangle with sides of lengths "a", "b", and "c" in decreasing order. Define the "scalenity" of the triangle to be the smaller of the two ratios "a"/"b" and "b"/"c". The scalenity is always less than and can be made as close as desired to .
Triangle whose sides form a geometric progression.
If the side lengths of a triangle form a geometric progression and are in the ratio 1 : "r" : "r"2, where "r" is the common ratio, then "r" must lie in the range −1 < "r" < , which is a consequence of the triangle inequality (the sum of any two sides of a triangle must be strictly bigger than the length of the third side). If "r" = then the shorter two sides are 1 and but their sum is 2, thus "r" < . A similar calculation shows that "r" > −1. A triangle whose sides are in the ratio 1 : √ : is a right triangle (because 1 + = 2) known as a Kepler triangle.
Golden triangle, rhombus, and rhombic triacontahedron.
A golden rhombus is a rhombus whose diagonals are in the golden ratio. The rhombic triacontahedron is a convex polytope that has a very special property: all of its faces are golden rhombi. In the rhombic triacontahedron the dihedral angle between any two adjacent rhombi is 144°, which is twice the isosceles angle of a golden triangle and four times its most acute angle.
Relationship to Fibonacci sequence.
The mathematics of the golden ratio and of the Fibonacci sequence are intimately interconnected. The Fibonacci sequence is:
The closed-form expression for the Fibonacci sequence involves the golden ratio:
The golden ratio is the limit of the ratios of successive terms of the Fibonacci sequence (or any Fibonacci-like sequence), as originally shown by Kepler:
Therefore, if a Fibonacci number is divided by its immediate predecessor in the sequence, the quotient approximates ; e.g., 987/610  1.6180327868852. These approximations are alternately lower and higher than , and converge on as the Fibonacci numbers increase, and:
More generally:
where above, the ratios of consecutive terms of the Fibonacci sequence, is a case when formula_38.
Furthermore, the successive powers of obey the Fibonacci recurrence:
This identity allows any polynomial in to be reduced to a linear expression. For example:
The reduction to a linear expression can be accomplished in one step by using the relationship
where formula_42 is the "k"th Fibonacci number.
However, this is no special property of , because polynomials in any solution "x" to a quadratic equation can be reduced in an analogous manner, by applying:
for given coefficients "a", "b" such that "x" satisfies the equation. Even more generally, any rational function (with rational coefficients) of the root of an irreducible "n"th-degree polynomial over the rationals can be reduced to a polynomial of degree "n" ‒ 1. Phrased in terms of field theory, if α is a root of an irreducible "n"th-degree polynomial, then formula_44 has degree "n" over formula_45, with basis formula_46.
Symmetries.
The golden ratio and inverse golden ratio formula_47 have a set of symmetries that preserve and interrelate them. They are both preserved by the fractional linear transformations formula_48 – this fact corresponds to the identity and the definition quadratic equation.
Further, they are interchanged by the three maps formula_49 – they are reciprocals, symmetric about formula_50, and (projectively) symmetric about 2.
More deeply, these maps form a subgroup of the modular group formula_51 isomorphic to the symmetric group on 3 letters, formula_52 corresponding to the stabilizer of the set formula_53 of 3 standard points on the projective line, and the symmetries correspond to the quotient map formula_54 – the subgroup formula_55 consisting of the 3-cycles and the identity formula_56 fixes the two numbers, while the 2-cycles interchange these, thus realizing the map.
Other properties.
The golden ratio has the simplest expression (and slowest convergence) as a continued fraction expansion of any irrational number (see "Alternate forms" above). It is, for that reason, one of the worst cases of Lagrange's approximation theorem and it is an extremal case of the Hurwitz inequality for Diophantine approximations. This may be why angles close to the golden ratio often show up in phyllotaxis (the growth of plants).
The defining quadratic polynomial and the conjugate relationship lead to decimal values that have their fractional part in common with :
The sequence of powers of contains these values 0.618..., 1.0, 1.618..., 2.618...; more generally,
any power of is equal to the sum of the two immediately preceding powers:
As a result, one can easily decompose any power of into a multiple of and a constant. The multiple and the constant are always adjacent Fibonacci numbers. This leads to another property of the positive powers of :
If formula_60, then:
When the golden ratio is used as the base of a numeral system (see Golden ratio base, sometimes dubbed "phinary" or "-nary"), every integer has a terminating representation, despite being irrational, but every fraction has a non-terminating representation.
The golden ratio is a fundamental unit of the algebraic number field formula_63 and is a Pisot–Vijayaraghavan number. In the field formula_63 we have formula_65, where formula_66 is the formula_67-th Lucas number.
The golden ratio also appears in hyperbolic geometry, as the maximum distance from a point on one side of an ideal triangle to the closer of the other two sides: this distance, the side length of the equilateral triangle formed by the points of tangency of a circle inscribed within the ideal triangle, is formula_68.
Decimal expansion.
The golden ratio's decimal expansion can be calculated directly from the expression
with √5 ≈ 2.2360679774997896964 . The square root of 5 can be calculated with the Babylonian method, starting with an initial estimate such as "x" = 2 and iterating
for "n" = 1, 2, 3, ..., until the difference between "x""n" and "x""n"−1 becomes zero, to the desired number of digits.
The Babylonian algorithm for √5 is equivalent to Newton's method for solving the equation "x"2 − 5 = 0. In its more general form, Newton's method can be applied directly to any algebraic equation, including the equation "x"2 − x − 1 = 0 that defines the golden ratio. This gives an iteration that converges to the golden ratio itself,
for an appropriate initial estimate "x" such as "x" = 1. A slightly faster method is to rewrite the equation as "x" − 1 − 1/"x" = 0, in which case the Newton iteration becomes
These iterations all converge quadratically; that is, each step roughly doubles the number of correct digits. The golden ratio is therefore relatively easy to compute with arbitrary precision. The time needed to compute "n" digits of the golden ratio is proportional to the time needed to divide two "n"-digit numbers. This is considerably faster than known algorithms for the transcendental numbers pi and e (mathematical constant).
An easily programmed alternative using only integer arithmetic is to calculate two large consecutive Fibonacci numbers and divide them. The ratio of Fibonacci numbers "F" 25001 and "F" 25000, each over 5000 digits, yields over 10,000 significant digits of the golden ratio.
The golden ratio has been calculated to an accuracy of several millions of decimal digits . Alexis Irlande performed computations and verification of the first 17,000,000,000 digits.
Pyramids.
Both Egyptian pyramids and the regular square pyramids that resemble them can be analyzed with respect to the golden ratio and other ratios.
Mathematical pyramids and triangles.
A pyramid in which the apothem (slant height along the bisector of a face) is equal to times the semi-base (half the base width) is sometimes called a "golden pyramid". The isosceles triangle that is the face of such a pyramid can be constructed from the two halves of a diagonally split golden rectangle (of size semi-base by apothem), joining the medium-length edges to make the apothem. The height of this pyramid is formula_73 times the semi-base (that is, the slope of the face is formula_73); the square of the height is equal to the area of a face, times the square of the semi-base.
The medial right triangle of this "golden" pyramid (see diagram), with sides formula_75 is interesting in its own right, demonstrating via the Pythagorean theorem the relationship formula_76 or formula_77. This "Kepler triangle"
is the only right triangle proportion with edge lengths in geometric progression, just as the 3–4–5 triangle is the only right triangle proportion with edge lengths in arithmetic progression. The angle with tangent formula_73 corresponds to the angle that the side of the pyramid makes with respect to the ground, 51.827... degrees (51° 49' 38").
A nearly similar pyramid shape, but with rational proportions, is described in the Rhind Mathematical Papyrus (the source of a large part of modern knowledge of ancient Egyptian mathematics), based on the 3:4:5 triangle; the face slope corresponding to the angle with tangent 4/3 is 53.13 degrees (53 degrees and 8 minutes). The slant height or apothem is 5/3 or 1.666... times the semi-base. The Rhind papyrus has another pyramid problem as well, again with rational slope (expressed as run over rise). Egyptian mathematics did not include the notion of irrational numbers, and the rational inverse slope (run/rise, multiplied by a factor of 7 to convert to their conventional units of palms per cubit) was used in the building of pyramids.
Another mathematical pyramid with proportions almost identical to the "golden" one is the one with perimeter equal to 2 times the height, or h:b = 4:. This triangle has a face angle of 51.854° (51°51'), very close to the 51.827° of the Kepler triangle. This pyramid relationship corresponds to the coincidental relationship formula_79.
Egyptian pyramids very close in proportion to these mathematical pyramids are known.
Egyptian pyramids.
In the mid-nineteenth century, Röber studied various Egyptian pyramids including Khafre, Menkaure and some of the Giza, Sakkara, and Abusir groups, and was interpreted as saying that half the base of the side of the pyramid is the middle mean of the side, forming what other authors identified as the Kepler triangle; many other mathematical theories of the shape of the pyramids have also been explored.
One Egyptian pyramid is remarkably close to a "golden pyramid"—the Great Pyramid of Giza (also known as the Pyramid of Cheops or Khufu). Its slope of 51° 52' is extremely close to the "golden" pyramid inclination of 51° 50' and the -based pyramid inclination of 51° 51'; other pyramids at Giza (Chephren, 52° 20', and Mycerinus, 50° 47') are also quite close. Whether the relationship to the golden ratio in these pyramids is by design or by accident remains open to speculation. Several other Egyptian pyramids are very close to the rational 3:4:5 shape.
Adding fuel to controversy over the architectural authorship of the Great Pyramid, Eric Temple Bell, mathematician and historian, claimed in 1950 that Egyptian mathematics would not have supported the ability to calculate the slant height of the pyramids, or the ratio to the height, except in the case of the 3:4:5 pyramid, since the 3:4:5 triangle was the only right triangle known to the Egyptians and they did not know the Pythagorean theorem, nor any way to reason about irrationals such as or .
Michael Rice asserts that principal authorities on the history of Egyptian architecture have argued that the Egyptians were well acquainted with the golden ratio and that it is part of mathematics of the Pyramids, citing Giedon (1957). Historians of science have always debated whether the Egyptians had any such knowledge or not, contending rather that its appearance in an Egyptian building is the result of chance.
In 1859, the pyramidologist John Taylor claimed that, in the Great Pyramid of Giza, the golden ratio is represented by the ratio of the length of the face (the slope height), inclined at an angle θ to the ground, to half the length of the side of the square base, equivalent to the secant of the angle θ. The above two lengths were about 186.4 and 115.2 meters respectively. The ratio of these lengths is the golden ratio, accurate to more digits than either of the original measurements. Similarly, Howard Vyse, according to Matila Ghyka, reported the great pyramid height 148.2 m, and half-base 116.4 m, yielding 1.6189 for the ratio of slant height to half-base, again more accurate than the data variability.
Disputed observations.
Examples of disputed observations of the golden ratio include the following:

</doc>
<doc id="12388" url="https://en.wikipedia.org/wiki?curid=12388" title="Genome">
Genome

In modern molecular biology and genetics, the genome is the genetic material of an organism. It consists of DNA (or RNA in RNA viruses). The genome includes both the genes and the non-protein-coding information of the DNA/RNA.
Origin of term.
The term was created in 1920 by Hans Winkler, professor of botany at the University of Hamburg, Germany. The Oxford Dictionary suggests the name to be a blend of the words "gene" and "chromosome". However, see omics for a more thorough discussion. A few related "-ome" words already existed—such as "biome", "rhizome", forming a vocabulary into which "genome" fits systematically.
Overview.
Some organisms have multiple copies of chromosomes: diploid, triploid, tetraploid and so on. In classical genetics, in a sexually reproducing organism (typically eukarya) the gamete has half the number of chromosomes of the somatic cell and the genome is a full set of chromosomes in a diploid cell. The halving of the genetic material in gametes is accomplished by the segregation of homologous chromosomes during meiosis. In haploid organisms, including cells of bacteria, archaea, and in organelles including mitochondria and chloroplasts, or viruses, that similarly contain genes, the single or set of circular or linear chains of DNA (or RNA for some viruses), likewise constitute the genome. The term "genome" can be applied specifically to mean what is stored on a complete set of nuclear DNA (i.e., the "nuclear genome") but can also be applied to what is stored within organelles that contain their own DNA, as with the "mitochondrial genome" or the "chloroplast genome". Additionally, the genome can comprise non-chromosomal genetic elements such as viruses, plasmids, and transposable elements.
Typically, when it is said that the genome of a sexually reproducing species has been "sequenced", it refers to a determination of the sequences of one set of autosomes and one of each type of sex chromosome, which together represent both of the possible sexes. Even in species that exist in only one sex, what is described as a "genome sequence" may be a composite read from the chromosomes of various individuals. Colloquially, the phrase "genetic makeup" is sometimes used to signify the genome of a particular individual or organism. The study of the global properties of genomes of related organisms is usually referred to as genomics, which distinguishes it from genetics which generally studies the properties of single genes or groups of genes.
Both the number of base pairs and the number of genes vary widely from one species to another, and there is only a rough correlation between the two (an observation known as the C-value paradox). At present, the highest known number of genes is around 60,000, for the protozoan causing trichomoniasis (see List of sequenced eukaryotic genomes), almost three times as many as in the human genome.
An analogy to the human genome stored on DNA is that of instructions stored in a book:
Sequencing and mapping.
In 1976, Walter Fiers at the University of Ghent (Belgium) was the first to establish the complete nucleotide sequence of a viral RNA-genome (Bacteriophage MS2). The next year Fred Sanger completed the first DNA-genome sequence: Phage Φ-X174, of 5386 base pairs. The first complete genome sequences among all three domains of life were released within a short period during the mid-1990s: The first bacterial genome to be sequenced was that of Haemophilus influenzae, completed by a team at The Institute for Genomic Research in 1995. A few months later, the first eukaryotic genome was completed, with sequences of the 16 chromosomes of budding yeast "Saccharomyces cerevisiae" published as the result of a European-led effort begun in the mid-1980s. The first genome sequence for an archaeon, "Methanococcus jannaschii", was completed in 1996, again by The Institute for Genomic Research.
The development of new technologies has made it dramatically easier and cheaper to do sequencing, and the number of complete genome sequences is growing rapidly. The US National Institutes of Health maintains one of several comprehensive databases of genomic information. Among the thousands of completed genome sequencing projects include those for rice, a mouse, the plant "Arabidopsis thaliana", the puffer fish, and the bacteria E. coli. In December 2013, scientists first sequenced the entire "genome" of a Neanderthal, an extinct species of humans. The genome was extracted from the toe bone of a 130,000-year-old Neanderthal found in a Siberian cave.
New sequencing technologies, such as massive parallel sequencing have also opened up the prospect of personal genome sequencing as a diagnostic tool, as pioneered by Manteia Predictive Medicine. A major step toward that goal was the completion in 2007 of the full genome of James D. Watson, one of the co-discoverers of the structure of DNA.
Whereas a genome sequence lists the order of every DNA base in a genome, a genome map identifies the landmarks. A genome map is less detailed than a genome sequence and aids in navigating around the genome. The Human Genome Project was organized to map and to sequence the human genome. A fundamental step in the project was the release of a detailed genomic map by Jean Weissenbach and his team at the Genoscope in Paris.
Genome compositions.
Genome composition is used to describe the make up of contents of a haploid genome, which should include genome size, proportions of non-repetitive DNA and repetitive DNA in details. By comparing the genome compositions between genomes, scientists can better understand the evolutionary history of a given genome.
When talking about genome composition, one should distinguish between prokaryotes and eukaryotes as the big differences on contents structure they have. In prokaryotes, most of the genome (85–90%) is non-repetitive DNA, which means coding DNA mainly forms it, while non-coding regions only take a small part. On the contrary, eukaryotes have the feature of exon-intron organization of protein coding genes; the variation of repetitive DNA content in eukaryotes is also extremely high. In mammals and plants, the major part of the genome is composed of repetitive DNA.
Most biological entities that are more complex than a virus sometimes or always carry additional genetic material besides that which resides in their chromosomes. In some contexts, such as sequencing the genome of a pathogenic microbe, "genome" is meant to include information stored on this auxiliary material, which is carried in plasmids. In such circumstances then, "genome" describes all of the genes and information on non-coding DNA that have the potential to be present.
In eukaryotes such as plants, protozoa and animals, however, "genome" carries the typical connotation of only information on chromosomal DNA. So although these organisms contain chloroplasts or mitochondria that have their own DNA, the genetic information contained by DNA within these organelles is not considered part of the genome. In fact, mitochondria are sometimes said to have their own genome often referred to as the "mitochondrial genome". The DNA found within the chloroplast may be referred to as the "plastome".
Genome size.
Genome size is the total number of DNA base pairs in one copy of a haploid genome. The genome size is positively correlated with the morphological complexity among prokaryotes and lower eukaryotes; however, after mollusks and all the other higher eukaryotes above, this correlation is no longer effective. This phenomenon also indicates the mighty influence coming from repetitive DNA act on the genomes.
Since genomes are very complex, one research strategy is to reduce the number of genes in a genome to the bare minimum and still have the organism in question survive. There is experimental work being done on minimal genomes for single cell organisms as well as minimal genomes for multi-cellular organisms (see Developmental biology). The work is both "in vivo" and "in silico".
Here is a table of some significant or representative genomes. See #See also for lists of sequenced genomes.
Proportion of non-repetitive DNA.
The proportion of non-repetitive DNA is calculated by using the length of non-repetitive DNA divided by genome size. Protein-coding genes and RNA-coding genes are generally non-repetitive DNA. A bigger genome does not mean more genes, and the proportion of non-repetitive DNA decreases along with increasing genome size in higher eukaryotes.
It had been found that the proportion of non-repetitive DNA can vary a lot between species. Some "E. coli" as prokaryotes only have non-repetitive DNA, lower eukaryotes such as "C. elegans" and fruit fly, still possess more non-repetitive DNA than repetitive DNA. Higher eukaryotes tend to have more repetitive DNA than non-repetitive ones. In some plants and amphibians, the proportion of non-repetitive DNA is no more than 20%, becoming a minority component.
Proportion of repetitive DNA.
The proportion of repetitive DNA is calculated by using length of repetitive DNA divide by genome size. There are two categories of repetitive DNA in genome: tandem repeats and interspersed repeats.
Tandem repeats.
Tandem repeats are usually caused by slippage during replication, unequal crossing-over and gene conversion, satellite DNA and microsatellites are forms of tandem repeats in the genome. Although tandem repeats count for a significant proportion in genome, the largest proportion in mammalian is the other type, interspersed repeats.
Interspersed repeats.
Interspersed repeats mainly come from transposable elements (TEs), but they also include some protein coding gene families and pseudogenes. Transposable elements are able to integrate into the genome at another site within the cell. It is believed that TEs are an important driving force on genome evolution of higher eukaryotes. TEs can be classified into two categories, Class 1 (retrotransposons) and Class 2 (DNA transposons).
Retrotransposons.
Retrotransposons can be transcribed into RNA, which are then duplicated at another site into the genome. Retrotransposons can be divided into Long terminal repeats (LTRs) and Non-Long Terminal Repeats (Non-LTR).
DNA transposons.
DNA transposons generally move by "cut and paste" in the genome, but duplication has also been observed. Class 2 TEs do not use RNA as intermediate and are popular in bacteria, in metazoan it has also been found.
Genome evolution.
Genomes are more than the sum of an organism's genes and have traits that may be measured and studied without reference to the details of any particular genes and their products. Researchers compare traits such as "chromosome number" (karyotype), genome size, gene order, codon usage bias, and GC-content to determine what mechanisms could have produced the great variety of genomes that exist today (for recent overviews, see Brown 2002; Saccone and Pesole 2003; Benfey and Protopapas 2004; Gibson and Muse 2004; Reese 2004; Gregory 2005).
Duplications play a major role in shaping the genome. Duplication may range from extension of short tandem repeats, to duplication of a cluster of genes, and all the way to duplication of entire chromosomes or even entire genomes. Such duplications are probably fundamental to the creation of genetic novelty.
Horizontal gene transfer is invoked to explain how there is often extreme similarity between small portions of the genomes of two organisms that are otherwise very distantly related. Horizontal gene transfer seems to be common among many microbes. Also, eukaryotic cells seem to have experienced a transfer of some genetic material from their chloroplast and mitochondrial genomes to their nuclear chromosomes.

</doc>
<doc id="12393" url="https://en.wikipedia.org/wiki?curid=12393" title="Gaia philosophy">
Gaia philosophy

Gaia philosophy (named after Gaia, Greek goddess of the Earth) is a broadly inclusive term for related concepts that living organisms on a planet will affect the nature of their environment in order to make the environment more suitable for life. This set of theories holds that all organisms on a life-giving planet regulate the biosphere in such a way as to promote its habitability. Gaia concept draws a connection between the survivability of a species (hence its evolutionary course) and its usefulness to the survival of other species.
While there were a number of precursors to Gaia theory, the first scientific form of this idea was proposed as the Gaia hypothesis by James Lovelock, a UK chemist, in 1970. The Gaia hypothesis deals with the concept of Biological homeostasis, and claims the resident life forms of a host planet coupled with their environment have acted and act like a single, self-regulating system. This system includes the near-surface rocks, the soil, and the atmosphere. Today many scientists consider such ideas to be unsupported by, or at odds with, the available evidence (see recent criticism). These theories are however significant in green politics.
Predecessors to the Gaia theory.
There are some mystical, scientific and religious predecessors to the Gaia philosophy, which had a Gaia-like conceptual basis. Many religious mythologies had a view of Earth as being a whole that is greater than the sum of its parts (e.g. some Native American religions and various forms of shamanism).
Lewis Thomas believed that Earth should be viewed as a single cell; he derived this view from Johannes Kepler's view of Earth as a single round organism.
Isaac Newton wrote of the earth, "“Thus this Earth resembles a great animall or rather inanimate vegetable, draws in æthereall breath for its dayly refreshment & vitall ferment & transpires again with gross exhalations, And according to the condition of all other things living ought to have its times of beginning youth old age & perishing.”
Pierre Teilhard de Chardin, a paleontologist and geologist, believed that evolution unfolded from cell to organism to planet to solar system and ultimately the whole universe, as we humans see it from our limited perspective. Teilhard later influenced Thomas Berry and many Catholic humanist thinkers of the 20th century.
Buckminster Fuller is generally credited with making the idea respectable in Western scientific circles in the 20th century. Building to some degree on his observations and artifacts, e.g. the Dymaxion map of the Earth he created, others began to ask if there was a way to make the Gaia theory scientifically sound.
Oberon Zell-Ravenheart in 1970 in an article in "Green Egg" Magazine, independently articulated the Gaia Thesis. 
None of these ideas are considered scientific hypotheses; by definition a scientific hypothesis must make testable predictions. As the above claims are not testable, they are outside the bounds of current science.
These are conjectures and perhaps can only be considered as social and maybe political philosophy; they may have implications for theology, or "thealogy" as Zell-Ravenheart and Isaac Bonewits put it.
Range of views.
According to James Kirchner there is a spectrum of Gaia hypotheses, ranging from the undeniable to radical. At one end is the undeniable statement that the organisms on the Earth have radically altered its composition. A stronger position is that the Earth's biosphere effectively acts as if it is a self-organizing system which works in such a way as to keep its systems in some kind of equilibrium that is conducive to life. Today many scientists consider that such a view (and any stronger views) are unlikely to be correct. An even stronger claim is that all lifeforms are part of a single planetary being, called Gaia. In this view, the atmosphere, the seas, the terrestrial crust would be the result of interventions carried out by Gaia, through the coevolving diversity of living organisms.
The most extreme form of Gaia theory is that the entire Earth is a single unified organism with a highly intelligent mind that arose as an emergent property of the whole biosphere. In this view, the Earth's biosphere is "consciously" manipulating the climate in order to make conditions more conducive to life. Scientists contend that there is no evidence at all to support this last point of view, and it has come about because many people do not understand the concept of homeostasis. Many non-scientists instinctively and incorrectly see homeostasis as a process that requires conscious control .
The more speculative versions of Gaia, including versions in which it is believed that the Earth is actually conscious, sentient, and highly intelligent, are usually considered outside the bounds of what is usually considered science.
Gaia in biology and science.
Buckminster Fuller has been credited as the first to incorporate scientific ideas into a Gaia theory, which he did with his Dymaxion map of the Earth.
The first scientifically rigorous theory was the Gaia hypothesis by James Lovelock, a UK chemist. This view is no longer considered plausible by many scientists.
A variant of this hypothesis was developed by Lynn Margulis, a microbiologist, in 1979.
Her version is sometimes called the "Gaia Theory" (note uppercase-T). Her model is more limited in scope than the one that Lovelock proposed.
Whether this sort of system is present on Earth is still open to debate. Some relatively simple homeostatic mechanisms are generally accepted. For example, when atmospheric carbon dioxide levels rise, plants are able to grow better and thus remove more carbon dioxide from the atmosphere. Other biological effects and feedbacks exist, but the extent to which these mechanisms have stabilized and modified the Earth's overall climate is largely not known.
The Gaia hypothesis is sometimes viewed from significantly different philosophical perspectives. Some environmentalists view it as an almost conscious process, in which the Earth's ecosystem is literally viewed as a single unified organism. Some evolutionary biologists, on the other hand, view it as an undirected emergent property of the ecosystem: as each individual species pursues its own self-interest, their combined actions tend to have counterbalancing effects on environmental change. Proponents of this view sometimes point to examples of life's actions in the past that have resulted in dramatic change rather than stable equilibrium, such as the conversion of the Earth's atmosphere from a reducing environment to an oxygen-rich one.
Depending on how strongly the case is stated, the hypothesis conflicts with mainstream neo-Darwinism. Most biologists would accept Daisyworld-style homeostasis as possible, but would certainly not accept the idea that this equates to the whole biosphere acting as one organism.
A very small number of scientists, and a much larger number of environmental activists, claim that Earth's biosphere is "consciously" manipulating the climate in order to make conditions more conducive to life. Scientists contend that there is no evidence to support this belief.
Gaia in the social sciences.
A social science view of Gaia theory is the role of humans as a keystone species who may be able to accomplish global homeostasis. Whilst a few social scientists who draw inspiration from 'organic' views of society have embraced Gaia philosophy as a way to explain the human-nature interconnections, most professional social scientists are more involved in reflecting upon the way Gaia philosophy is used and engaged with within sub-sections of society. Alan Marshall, in the Department of Social Sciences at Mahidol University, for example, reflects upon the way Gaia philosophy has been used and advocated by environmentalists, spiritualists, managers, economists, and scientists and engineers (see The Unity of Nature, 2002, Imperial College Press: London and Singapore). Social Scientists themselves in the 1960s gave up on systems ideas of society since they were interpreted as supporting conservatism and traditionalism.
Gaia in politics.
Some radical political environmentalists who accept some form of the Gaia theory call themselves Gaians. They actively seek to restore the Earth's homeostasis — whenever they see it out of balance, e.g. to prevent manmade climate change, primate extinction, or rainforest loss. In effect, they seek to cooperate to become the "system consciously manipulating to make conditions more conducive to life". Such activity defines the homeostasis, but for leverage it relies on deep investigation of the homeorhetic balances, if only to find places to intervene in a system which is changing in undesirable ways.
Tony Bondhus brings up the point in his book, "Society of Conceivia", that if Gaia is alive, then societies are living things as well. This suggests that our understanding of Gaia can be used to create a better society and to design a better political system.
Other intellectuals in the environmental movement, like Edward Goldsmith, have used Gaia in the completely opposite way; to stake a claim about how Gaia's focus on natural balance and resistance and resilience, should be emulated to design a conservative political system (as explored in Alan Marshall's 2002 book "The Unity of Nature", (Imperial College Press: London).
Gaians do not passively ask "what is going on", but rather, "what to do next", e.g. in terraforming or climate engineering or even on a small scale, such as gardening. Changes can be planned, agreed upon by many people, being very deliberate, as in urban ecology and especially industrial ecology. "See arcology for more on this 'active' view."
Gaians argue that it is a human duty to act as such - committing themselves in particular to the Precautionary Principle. Such views began to influence the Green Parties, Greenpeace, and a few more radical wings of the environmental movement such as the Gaia Liberation Front and the Earth Liberation Front. These views dominate some such groups, e.g. the Bioneers. Some refer to this political activity as a separate and radical branch of the ecology movement, one that takes the axioms of the science of ecology in general, and Gaia theory in particular, and raises them to a kind of theory of personal conduct or moral code.
Gaia in religion.
Anne Primavesi is an ecologist and theologian she is the author of two books dealing with the Gaia hypothesis and theology.
Rosemary Radford Ruether the American feminist scholar and theologian wrote a book called "Gaia and God: An Ecofeminist Theology of Earth Healing".
A book edited by Allan Hunt Badiner called Dharma Gaia explores the ground where Buddhism and ecology meet through writings by the Dalai Lama, Gary Snyder, Thich Nhat Hanh, Allen Ginsberg, Joanna Macy, Robert Aitken, and 25 other Buddhists and ecologists.
Many new age authors have written books which mix New Age teachings with Gaia philosophy this is known as New Age Gaian. Often referred to as Gaianism, or the Gaian Religion, this spiritual aspect of the philosophy is very broad and inclusive, making it adaptable to other religions: Taoism, Neo-Paganism, Pantheism, Judeo-Christian Religions, and many others.
Semantic debate.
The question of "what is an organism", and at what scale is it rational to speak about organisms vs. biospheres, gives rise to a semantic debate. We are all ecologies in the sense that our (human) bodies contain gut bacteria, parasite species, etc., and to them our body is not organism but rather more of a microclimate or biome. Applying that thinking to whole planets:
The argument is that these symbiotic organisms, being unable to survive apart from each other and their climate and local conditions, form an organism in their own right, under a wider conception of the term organism than is conventionally used. It is a matter for often heated debate whether this is a valid usage of the term, but ultimately it appears to be a semantic dispute. In this sense of the word organism, it is argued under the theory that the entire biomass of the Earth is a single organism (as Johannes Kepler thought).
Unfortunately, many supporters of the various Gaia theories do not state exactly where they sit on this spectrum; this makes discussion and criticism difficult.
Much effort on behalf of those analyzing the theory currently is an attempt to clarify what these different hypotheses are, and whether they are proposals to 'test' or 'manipulate' outcomes. Both Lovelock's and Margulis's understanding of Gaia are considered scientific hypotheses, and like all scientific theories are constantly put to the test.
More speculative versions of Gaia, including all versions in which it is held that the Earth is actually conscious, are currently held to be outside the bounds of science, and are not supported by either Lovelock or Margulis.
Gaian reproduction.
One of the most problematic issues with referring to Gaia as an organism is its apparent failure to meet the biological criterion of being able to reproduce. Richard Dawkins has asserted that the planet is not the offspring of any parents and is unable to reproduce.
In popular culture.
Isaac Asimov in his 1982 novel Foundation's Edge describes a planet known as Gaia, which is a 'superorganism'. All things on Gaia participate in a larger, group consciousness, while still retaining any individual awareness they might have, such as among the Gaian humans. Gaians were important in shaping the future course of Asimov's universe.
At least one work of fiction, the film "", uses Gaia philosophy as a central point to the plot, and may arguably represent a fictional parallel to Sir James Lovelock in the character of Dr. Cid, who is met with skepticism from the scientific and social community when he promotes the idea of a "living Earth". In the film, Dr. Cid attempts to create a "waveform" from the positive energy signature of the Earth's spirit, in order to combat the films antagonists, the negative energy "Phantoms", through use of phase inversion canceling.
In addition, Gaia philosophy is prominent in the video game "Final Fantasy VII" where The theme of a living planet where all life is one symbolized by the idea of the Lifestream. The Lifestream is not only a philosophical theme present in the game, but it actually acts as a plot device, "erupting" at certain points in the game. In the context of Final Fantasy VII and its various spin-offs (which include three games and a movie), the Lifestream is a collection of all the souls and energy on the earth, and is semi-sentient. In fact, in Dirge of The Cerberus, a spin-off game, it is revealed that the Lifestream can and will transplant itself from a planet when that place becomes too dangerous.
Computer game "Sid Meier's Alpha Centauri" and its expansion "Sid Meier's Alien Crossfire" are set on the planet Chiron in the Alpha Centauri system where all indigenous life appears to behave in accordance with the Gaia philosophy. The intelligent force behind this behavior is called simply "Planet" and, in the expansion, is revealed to be artificially created by an alien race. At the time the game takes place, Planet is nearing its self-awareness threshold. Normally, the nature of Planet's life causes it never to attain full sentience; however, human presence adds an unknown variable into the equation.
The Gaia philosophy is a guiding principle for terrorists in the Tom Clancy novel "Rainbow Six".
The film "Avatar" depicts a world (Pandora) that functions like a single organism, in which various species of earth and sky cooperate with the humanoid population (the Na'vi) to defend the planet against a corporate-military invasion.

</doc>
<doc id="12395" url="https://en.wikipedia.org/wiki?curid=12395" title="Greenhouse effect">
Greenhouse effect

The greenhouse effect is the process by which radiation from a planet's atmosphere warms the planet's surface to a temperature above what it would be without its atmosphere. 
If a planet's atmosphere contains radiatively active gases (i.e., greenhouse gases) the atmosphere will radiate energy in all directions. Part of this radiation is directed towards the surface, warming it. The downward component of this radiation – that is, the strength of the greenhouse effect – will depend on the atmosphere's temperature and on the amount of greenhouse gases that the atmosphere contains. 
On Earth, the atmosphere is warmed by absorption of infrared thermal radiation from the underlying surface, absorption of shorter wavelength radiant energy from the sun, and convective heat fluxes from the surface. Greenhouse gases in the atmosphere radiate energy, some of which is directed to the surface and lower atmosphere. The mechanism that produces this difference between the actual surface temperature and the effective temperature is due to the atmosphere and is known as the greenhouse effect.
Earth’s natural greenhouse effect is critical to supporting life. Human activities, primarily the burning of fossil fuels and clearing of forests, have intensified the natural greenhouse effect, causing global warming.
The mechanism is named after a faulty analogy with the effect of solar radiation passing through glass and warming a greenhouse. The way a greenhouse retains heat is fundamentally different, as a greenhouse works by reducing airflow and retaining warm air inside the structure.
History.
The existence of the greenhouse effect was argued for by Joseph Fourier in 1824. The argument and the evidence was further strengthened by Claude Pouillet in 1827 and 1838, and reasoned from experimental observations by John Tyndall in 1859. The effect was more fully quantified by Svante Arrhenius in 1896. However, the term "greenhouse" was not used to refer to this effect by any of these scientists; the term was first used in this way by Nils Gustaf Ekholm in 1901.
In 1917 Alexander Graham Bell wrote "unchecked burning of fossil fuels would have a sort of greenhouse effect", and "The net result is the greenhouse becomes a sort of hot-house." Bell went on to also advocate the use of alternate energy sources, such as solar energy.
Mechanism.
Earth receives energy from the Sun in the form of ultraviolet, visible, and near-infrared radiation. Of the total amount of solar energy available at the top of the atmosphere, about 26% is reflected to space by the atmosphere and clouds and 19% is absorbed by the atmosphere and clouds. Most of the remaining energy is absorbed at the surface of Earth. Because it is warm, the surface radiates at wavelengths that are much longer than the wavelengths that were absorbed. Most of this thermal radiation is absorbed by the atmosphere, thereby warming it. In addition to the absorption of solar and thermal radiation, the atmosphere further gains heat by sensible and latent heat fluxes from the surface. The atmosphere radiates energy both upwards and downwards; the part radiated downwards is absorbed by the surface of Earth. This leads to a higher equilibrium temperature than if the atmosphere were absent.
An ideal thermally conductive blackbody at the same distance from the Sun as Earth would have a temperature of about 5.3 °C. However, because Earth reflects about 30% of the incoming sunlight, this idealized planet's effective temperature (the temperature of a blackbody that would emit the same amount of radiation) would be about −18 °C. The surface temperature of this hypothetical planet is 33 °C below Earth's actual surface temperature of approximately 14 °C. 
The basic mechanism can be qualified in a number of ways, none of which affect the fundamental process. The atmosphere near the surface is largely opaque to thermal radiation (with important exceptions for "window" bands), and most heat loss from the surface is by sensible heat and latent heat transport. Radiative energy losses become increasingly important higher in the atmosphere, largely because of the decreasing concentration of water vapor, an important greenhouse gas. It is more realistic to think of the greenhouse effect as applying to a "surface" in the mid-troposphere, which is effectively coupled to the surface by a lapse rate. The simple picture also assumes a steady state, but in the real world there are variations due to the diurnal cycle as well as the seasonal cycle and weather disturbances. Solar heating only applies during daytime. During the night, the atmosphere cools somewhat, but not greatly, because its emissivity is low. Diurnal temperature changes decrease with height in the atmosphere.
Within the region where radiative effects are important, the description given by the idealized greenhouse model becomes realistic. Earth's surface, warmed to a temperature around 255 K, radiates long-wavelength, infrared heat in the range of 4–100 μm. At these wavelengths, greenhouse gases that were largely transparent to incoming solar radiation are more absorbent. Each layer of atmosphere with greenhouses gases absorbs some of the heat being radiated upwards from lower layers. It reradiates in all directions, both upwards and downwards; in equilibrium (by definition) the same amount as it has absorbed. This results in more warmth below. Increasing the concentration of the gases increases the amount of absorption and reradiation, and thereby further warms the layers and ultimately the surface below.
Greenhouse gases—including most diatomic gases with two different atoms (such as carbon monoxide, CO) and all gases with three or more atoms—are able to absorb and emit infrared radiation. Though more than 99% of the dry atmosphere is IR transparent (because the main constituents—N2, O2, and Ar—are not able to directly absorb or emit infrared radiation), intermolecular collisions cause the energy absorbed and emitted by the greenhouse gases to be shared with the other, non-IR-active, gases.
Greenhouse gases.
By their percentage contribution to the greenhouse effect on Earth the four major gases are:
It is not physically realistic to assign a specific percentage to each gas because the absorption and emission bands of the gases overlap (hence the ranges given above). The major non-gas contributor to Earth's greenhouse effect, clouds, also absorb and emit infrared radiation and thus have an effect on the radiative properties of the atmosphere.
Role in climate change.
Strengthening of the greenhouse effect through human activities is known as the enhanced (or anthropogenic) greenhouse effect. This increase in radiative forcing from human activity is attributable mainly to increased atmospheric carbon dioxide levels. According to the latest Assessment Report from the Intergovernmental Panel on Climate Change, ""atmospheric concentrations of carbon dioxide, methane and nitrous oxide are unprecedented in at least the last 800,000 years. Their effects, together with those of other anthropogenic drivers, have been detected throughout the climate system and are extremely likely to have been the dominant cause of the observed warming since the mid-20th century"".
CO2 is produced by fossil fuel burning and other activities such as cement production and tropical deforestation. Measurements of CO2 from the Mauna Loa observatory show that concentrations have increased from about 313 ppm in 1960 to about 389 ppm in 2010. It reached the 400ppm milestone on May 9, 2013. The current observed amount of CO2 exceeds the geological record maxima (~300 ppm) from ice core data. The effect of combustion-produced carbon dioxide on the global climate, a special case of the greenhouse effect first described in 1896 by Svante Arrhenius, has also been called the Callendar effect.
Over the past 800,000 years, ice core data shows that carbon dioxide has varied from values as low as 180 parts per million (ppm) to the pre-industrial level of 270ppm. Paleoclimatologists consider variations in carbon dioxide concentration to be a fundamental factor influencing climate variations over this time scale.
Real greenhouses.
The "greenhouse effect" of the atmosphere is named by analogy to greenhouses which get warmer in sunlight. The explanation given in most sources for the warmer temperature in an actual greenhouse is that incident solar radiation in the visible, long-wavelength ultraviolet, and short-wavelength infrared range of the spectrum passes through the glass roof and walls and is absorbed by the floor, earth, and contents, which become warmer and re-emit the energy as longer-wavelength infrared radiation. Glass and other materials used for greenhouse walls do not transmit infrared radiation, so the infrared cannot escape via radiative transfer. As the structure is not open to the atmosphere, heat also cannot escape via convection, so the temperature inside the greenhouse rises. The greenhouse effect, due to infrared-opaque "greenhouse gases" including carbon dioxide and methane instead of glass, also affects Earth as a whole; there is no convective cooling because no significant amount of air escapes from Earth.
However the mechanism by which the atmosphere retains heat—the "greenhouse effect"—is different; a greenhouse is not primarily warmed by the "greenhouse effect".
A greenhouse works primarily by allowing sunlight to warm surfaces inside the structure, but then preventing absorbed heat from leaving the structure through convection. The "greenhouse effect" heats Earth because greenhouse gases absorb outgoing radiative energy, heating the atmosphere which then emits radiative energy with some of it going back towards Earth.
A greenhouse is built of any material that passes sunlight, usually glass, or plastic. It mainly warms up because the sun warms the ground and contents inside, which then warms the air in the greenhouse. The air continues to heat because it is confined within the greenhouse, unlike the environment outside the greenhouse where warm air near the surface rises and mixes with cooler air aloft. This can be demonstrated by opening a small window near the roof of a greenhouse: the temperature will drop considerably. It was demonstrated experimentally (R. W. Wood, 1909) that a "greenhouse" with a cover of rock salt (which is transparent to infra red) heats up an enclosure similarly to one with a glass cover. Thus greenhouses work primarily by preventing convective cooling.
More recent quantitative studies suggest that the effect of infrared radiative cooling is not negligibly small, and may have economic implications in a heated greenhouse. Analysis of issues of near-infrared radiation in a greenhouse with screens of a high coefficient of reflection concluded that installation of such screens reduced heat demand by about 8%, and application of dyes to transparent surfaces was suggested. Composite less-reflective glass, or less effective but cheaper anti-reflective coated simple glass, also produced savings.
Bodies other than Earth.
In the Solar System, there also greenhouse effects on Mars, Venus, and Titan. The greenhouse effect on Venus is particularly large because its dense atmosphere consisting mainly of carbon dioxide. Titan has an anti-greenhouse effect, in that its atmosphere absorbs solar radiation but is relatively transparent to infrared radiation. Pluto is also colder than would be expected, because evaporation of nitrogen cools it.
A runaway greenhouse effect occurs if positive feedbacks lead to the evaporation of all greenhouse gases into the atmosphere. A runaway greenhouse effect involving carbon dioxide and water vapor is thought to have occurred on Venus.

</doc>
<doc id="12396" url="https://en.wikipedia.org/wiki?curid=12396" title="Group homomorphism">
Group homomorphism

In mathematics, given two groups, ("G", ∗) and ("H", ·), a group homomorphism from ("G", ∗) to ("H", ·) is a function "h" : "G" → "H" such that for all "u" and "v" in "G" it holds that
where the group operation on the left hand side of the equation is that of "G" and on the right hand side that of "H".
From this property, one can deduce that "h" maps the identity element "eG" of "G" to the identity element "eH" of "H", and it also maps inverses to inverses in the sense that 
Hence one can say that "h" "is compatible with the group structure".
Older notations for the homomorphism "h"("x") may be "x""h", though this may be confused as an index or a general subscript. A more recent trend is to write group homomorphisms on the right of their arguments, omitting brackets, so that "h"("x") becomes simply "x h". This approach is especially prevalent in areas of group theory where automata play a role, since it accords better with the convention that automata read words from left to right.
In areas of mathematics where one considers groups endowed with additional structure, a "homomorphism" sometimes means a map which respects not only the group structure (as above) but also the extra structure. For example, a homomorphism of topological groups is often required to be continuous.
Intuition.
The purpose of defining a group homomorphism is to create functions that preserve the algebraic structure. An equivalent definition of group homomorphism is: The function "h" : "G" → "H" is a group homomorphism if whenever "a" ∗ "b" = "c" we have "h"("a") ⋅ "h"("b") = "h"("c"). In other words, the group "H" in some sense has a similar algebraic structure as "G" and the homomorphism "h" preserves that.
Image and kernel.
We define the "kernel of h" to be the set of elements in "G" which are mapped to the identity in "H"
and the "image of h" to be
The kernel and image of a homomorphism can be interpreted as measuring how close it is to being an isomorphism. The First Isomorphism Theorem states that the image of a group homomorphism, "h"("G") is isomorphic to the quotient group "G"/ker "h".
The kernel of h is a normal subgroup of "G" and the image of h is a subgroup of "H":
If and only if }, the homomorphism, "h", is a "group monomorphism"; i.e., "h" is injective (one-to-one). Injection directly gives that there is a unique element in the kernel, and a unique element in the kernel gives injection:
The category of groups.
If and are group homomorphisms, then so is . This shows that the class of all groups, together with group homomorphisms as morphisms, forms a category.
Homomorphisms of abelian groups.
If "G" and "H" are abelian (i.e., commutative) groups, then the set of all group homomorphisms from "G" to "H" is itself an abelian group: the sum of two homomorphisms is defined by
The commutativity of "H" is needed to prove that is again a group homomorphism.
The addition of homomorphisms is compatible with the composition of homomorphisms in the following sense: if "f" is in , "h", "k" are elements of , and "g" is in , then 
Since the composition is associative, this shows that the set End("G") of all endomorphisms of an abelian group forms a ring, the "endomorphism ring" of "G". For example, the endomorphism ring of the abelian group consisting of the direct sum of "m" copies of Z/"n"Z is isomorphic to the ring of "m"-by-"m" matrices with entries in Z/"n"Z. The above compatibility also shows that the category of all abelian groups with group homomorphisms forms a preadditive category; the existence of direct sums and well-behaved kernels makes this category the prototypical example of an abelian category.

</doc>
<doc id="12397" url="https://en.wikipedia.org/wiki?curid=12397" title="Group isomorphism">
Group isomorphism

In abstract algebra, a group isomorphism is a function between two groups that sets up a one-to-one correspondence between the elements of the groups in a way that respects the given group operations. If there exists an isomorphism between two groups, then the groups are called isomorphic. From the standpoint of group theory, isomorphic groups have the same properties and need not be distinguished.
Definition and notation.
Given two groups (G, ∗) and (H, formula_1), a "group isomorphism" from (G, ∗) to (H, formula_1) is a bijective group homomorphism from G to H. Spelled out, this means that a group isomorphism is a bijective function formula_3 such that for all u and v in G it holds that
The two groups (G, ∗) and (H, formula_1) are isomorphic if there exists an isomorphism from one to the other. This is written:
Often shorter and simpler notations can be used. When the relevant group operations are unambiguous they are omitted and one writes:
Sometimes one can even simply write G = H. Whether such a notation is possible without confusion or ambiguity depends on context. For example, the equals sign is not very suitable when the groups are both subgroups of the same group. See also the examples.
Conversely, given a group (G, ∗), a set H, and a bijection formula_3, we can make H a group (H, formula_1) by defining
If H = G and formula_1 = ∗ then the bijection is an automorphism ("q.v.").
Intuitively, group theorists view two isomorphic groups as follows: For every element "g" of a group "G", there exists an element "h" of "H" such that "h" 'behaves in the same way' as "g" (operates with other elements of the group in the same way as "g"). For instance, if "g" generates "G", then so does "h". This implies in particular that "G" and "H" are in bijective correspondence. Thus, the definition of an isomorphism is quite natural.
An isomorphism of groups may equivalently be defined as an invertible morphism in the category of groups, where invertible here means has a two-sided inverse.
Examples.
An isomorphism is given by
for every x in formula_12.
Some groups can be proven to be isomorphic, relying on the axiom of choice, but the proof does not indicate how to construct a concrete isomorphism. Examples:
Cyclic groups.
All cyclic groups of a given order are isomorphic to formula_33.
Let "G" be a cyclic group and "n" be the order of "G". "G" is then the group generated by formula_34. 
We will show that
Define 
Then
Consequences.
From the definition, it follows that any isomorphism formula_3 will map the identity element of G to the identity element of H, 
that it will map inverses to inverses,
and more generally, "n"th powers to "n"th powers,
for all u in G,
and that the inverse map formula_45 is also a group isomorphism.
The relation "being isomorphic" satisfies all the axioms of an equivalence relation. If f is an isomorphism between two groups G and H, then everything that is true about G that is only related to the group structure can be translated via f into a true ditto statement about H, and vice versa.
Automorphisms.
An isomorphism from a group (G, ∗) to itself is called an automorphism of this group. Thus it is a bijection formula_46 such that
An automorphism always maps the identity to itself. The image under an automorphism of a conjugacy class is always a conjugacy class (the same or another). The image of an element has the same order as that element.
The composition of two automorphisms is again an automorphism, and with this operation the set of all automorphisms of a group G, denoted by Aut(G), forms itself a group, the "automorphism group" of G.
For all abelian groups there is at least the automorphism that replaces the group elements by their inverses. However, in groups where all elements are equal to their inverse this is the trivial automorphism, e.g. in the Klein four-group. For that group all permutations of the three non-identity elements are automorphisms, so the automorphism group is isomorphic to S3 and Dih3.
In Zp for a prime number p, one non-identity element can be replaced by any other, with corresponding changes in the other elements. The automorphism group is isomorphic to . For example, for , multiplying all elements of Z7 by 3, modulo 7, is an automorphism of order 6 in the automorphism group, because , while lower powers do not give 1. Thus this automorphism generates Z6. There is one more automorphism with this property: multiplying all elements of Z7 by 5, modulo 7. Therefore, these two correspond to the elements 1 and 5 of Z6, in that order or conversely.
The automorphism group of Z6 is isomorphic to Z2, because only each of the two elements 1 and 5 generate Z6, so apart from the identity we can only interchange these.
The automorphism group of has order 168, as can be found as follows. All 7 non-identity elements play the same role, so we can choose which plays the role of (1,0,0). Any of the remaining 6 can be chosen to play the role of (0,1,0). This determines which corresponds to (1,1,0). For (0,0,1) we can choose from 4, which determines the rest. Thus we have automorphisms. They correspond to those of the Fano plane, of which the 7 points correspond to the 7 non-identity elements. The lines connecting three points correspond to the group operation: "a", "b", and "c" on one line means , , and . See also general linear group over finite fields.
For abelian groups all automorphisms except the trivial one are called outer automorphisms.
Non-abelian groups have a non-trivial inner automorphism group, and possibly also outer automorphisms.

</doc>
<doc id="12398" url="https://en.wikipedia.org/wiki?curid=12398" title="Geographic information system">
Geographic information system

A geographic information system or geographical information system (GIS) is a system designed to capture, store, manipulate, analyze, manage, and present all types of spatial or geographical data. The acronym GIS is sometimes used for geographic information science (GIScience) to refer to the academic discipline that studies geographic information systems and is a large domain within the broader academic discipline of geoinformatics. What goes beyond a GIS is a spatial data infrastructure, a concept that has no such restrictive boundaries.
In a general sense, the term describes any information system that integrates, stores, edits, analyzes, shares, and displays geographic information. GIS applications are tools that allow users to create interactive queries (user-created searches), analyze spatial information, edit data in maps, and present the results of all these operations. Geographic information science is the science underlying geographic concepts, applications, and systems.
GIS is a broad term that can refer to a number of different technologies, processes, and methods. It is attached to many operations and has many applications related to engineering, planning, management, transport/logistics, insurance, telecommunications, and business. For that reason, GIS and location intelligence applications can be the foundation for many location-enabled services that rely on analysis and visualization.
GIS can relate unrelated information by using location as the key index variable. Locations or extents in the Earth space–time may be recorded as dates/times of occurrence, and x, y, and z coordinates representing, longitude, latitude, and elevation, respectively. All Earth-based spatial–temporal location and extent references should, ideally, be relatable to one another and ultimately to a "real" physical location or extent. This key characteristic of GIS has begun to open new avenues of scientific inquiry.
History of development.
The first known use of the term "geographic information system" was by Roger Tomlinson in the year 1968 in his paper "A Geographic Information System for Regional Planning". Tomlinson is also acknowledged as the "father of GIS".
Previously, one of the first applications of spatial analysis in epidemiology is the 1832 ""Rapport sur la marche et les effets du choléra dans Paris et le département de la Seine"". The French geographer Charles Picquet represented the 48 districts of the city of Paris by halftone color gradient according to the number of deaths by cholera per 1,000 inhabitants. In 1854 John Snow determined the source of a cholera outbreak in London by marking points on a map depicting where the cholera victims lived, and connecting the cluster that he found with a nearby water source. This was one of the earliest successful uses of a geographic methodology in epidemiology. While the basic elements of topography and theme existed previously in cartography, the John Snow map was unique, using cartographic methods not only to depict but also to analyze clusters of geographically dependent phenomena.
The early 20th century saw the development of photozincography, which allowed maps to be split into layers, for example one layer for vegetation and another for water. This was particularly used for printing contours – drawing these was a labour-intensive task but having them on a separate layer meant they could be worked on without the other layers to confuse the draughtsman. This work was originally drawn on glass plates but later plastic film was introduced, with the advantages of being lighter, using less storage space and being less brittle, among others. When all the layers were finished, they were combined into one image using a large process camera. Once color printing came in, the layers idea was also used for creating separate printing plates for each color. While the use of layers much later became one of the main typical features of a contemporary GIS, the photographic process just described is not considered to be a GIS in itself – as the maps were just images with no database to link them to.
Computer hardware development spurred by nuclear weapon research led to general-purpose computer "mapping" applications by the early 1960s.
The year 1960 saw the development of the world's first true operational GIS in Ottawa, Ontario, Canada by the federal Department of Forestry and Rural Development. Developed by Dr. Roger Tomlinson, it was called the Canada Geographic Information System (CGIS) and was used to store, analyze, and manipulate data collected for the Canada Land Inventory – an effort to determine the land capability for rural Canada by mapping information about soils, agriculture, recreation, wildlife, waterfowl, forestry and land use at a scale of 1:50,000. A rating classification factor was also added to permit analysis.
CGIS was an improvement over "computer mapping" applications as it provided capabilities for overlay, measurement, and digitizing/scanning. It supported a national coordinate system that spanned the continent, coded lines as arcs having a true embedded topology and it stored the attribute and locational information in separate files. As a result of this, Tomlinson has become known as the "father of GIS", particularly for his use of overlays in promoting the spatial analysis of convergent geographic data.
CGIS lasted into the 1990s and built a large digital land resource database in Canada. It was developed as a mainframe-based system in support of federal and provincial resource planning and management. Its strength was continent-wide analysis of complex datasets. The CGIS was never available commercially.
In 1964 Howard T. Fisher formed the Laboratory for Computer Graphics and Spatial Analysis at the Harvard Graduate School of Design (LCGSA 1965–1991), where a number of important theoretical concepts in spatial data handling were developed, and which by the 1970s had distributed seminal software code and systems, such as SYMAP, GRID, and ODYSSEY – that served as sources for subsequent commercial development—to universities, research centers and corporations worldwide.
By the late 1970s two public domain GIS systems (MOSS and GRASS GIS) were in development, and by the early 1980s, M&S Computing (later Intergraph) along with Bentley Systems Incorporated for the CAD platform, Environmental Systems Research Institute (ESRI), CARIS (Computer Aided Resource Information System), MapInfo Corporation and ERDAS (Earth Resource Data Analysis System) emerged as commercial vendors of GIS software, successfully incorporating many of the CGIS features, combining the first generation approach to separation of spatial and attribute information with a second generation approach to organizing attribute data into database structures.
In 1986, Mapping Display and Analysis System (MIDAS), the first desktop GIS product emerged for the DOS operating system. This was renamed in 1990 to MapInfo for Windows when it was ported to the Microsoft Windows platform. This began the process of moving GIS from the research department into the business environment.
By the end of the 20th century, the rapid growth in various systems had been consolidated and standardized on relatively few platforms and users were beginning to explore viewing GIS data over the Internet, requiring data format and transfer standards. More recently, a growing number of free, open-source GIS packages run on a range of operating systems and can be customized to perform specific tasks. Increasingly geospatial data and mapping applications are being made available via the world wide web.
Several authoritative articles on the history of GIS have been published.
GIS techniques and technology.
Modern GIS technologies use digital information, for which various digitized data creation methods are used. The most common method of data creation is digitization, where a hard copy map or survey plan is transferred into a digital medium through the use of a CAD program, and geo-referencing capabilities. With the wide availability of ortho-rectified imagery (from satellites, aircraft, Helikites and UAVs), heads-up digitizing is becoming the main avenue through which geographic data is extracted. Heads-up digitizing involves the tracing of geographic data directly on top of the aerial imagery instead of by the traditional method of tracing the geographic form on a separate digitizing tablet (heads-down digitizing).
Relating information from different sources.
GIS uses spatio-temporal (space-time) location as the key index variable for all other information. Just as a relational database containing text or numbers can relate many different tables using common key index variables, GIS can relate otherwise unrelated information by using location as the key index variable. The key is the location and/or extent in space-time.
Any variable that can be located spatially, and increasingly also temporally, can be referenced using a GIS. Locations or extents in Earth space–time may be recorded as dates/times of occurrence, and x, y, and z coordinates representing, longitude, latitude, and elevation, respectively. These GIS coordinates may represent other quantified systems of temporo-spatial reference (for example, film frame number, stream gage station, highway mile-marker, surveyor benchmark, building address, street intersection, entrance gate, water depth sounding, POS or CAD drawing origin/units). Units applied to recorded temporal-spatial data can vary widely (even when using exactly the same data, see map projections), but all Earth-based spatial–temporal location and extent references should, ideally, be relatable to one another and ultimately to a "real" physical location or extent in space–time.
Related by accurate spatial information, an incredible variety of real-world and projected past or future data can be analyzed, interpreted and represented. This key characteristic of GIS has begun to open new avenues of scientific inquiry into behaviors and patterns of real-world information that previously had not been systematically correlated.
GIS uncertainties.
GIS accuracy depends upon source data, and how it is encoded to be data referenced. Land surveyors have been able to provide a high level of positional accuracy utilizing the GPS-derived positions. High-resolution digital terrain and aerial imagery, powerful computers and Web technology are changing the quality, utility, and expectations of GIS to serve society on a grand scale, but nevertheless there are other source data that have an impact on overall GIS accuracy like paper maps, though these may be of limited use in achieving the desired accuracy since the aging of maps affects their dimensional stability.
In developing a digital topographic database for a GIS, topographical maps are the main source, and aerial photography and satellite imagery are extra sources for collecting data and identifying attributes which can be mapped in layers over a location facsimile of scale. The scale of a map and geographical rendering area representation type are very important aspects since the information content depends mainly on the scale set and resulting locatability of the map's representations. In order to digitize a map, the map has to be checked within theoretical dimensions, then scanned into a raster format, and resulting raster data has to be given a theoretical dimension by a rubber sheeting/warping technology process.
A quantitative analysis of maps brings accuracy issues into focus. The electronic and other equipment used to make measurements for GIS is far more precise than the machines of conventional map analysis. All geographical data are inherently inaccurate, and these inaccuracies will propagate through GIS operations in ways that are difficult to predict.
Data representation.
GIS data represents real objects (such as roads, land use, elevation, trees, waterways, etc.) with digital data determining the mix. Real objects can be divided into two abstractions: discrete objects (e.g., a house) and continuous fields (such as rainfall amount, or elevations). Traditionally, there are two broad methods used to store data in a GIS for both kinds of abstractions mapping references: raster images and vector. Points, lines, and polygons are the stuff of mapped location attribute references. A new hybrid method of storing data is that of identifying point clouds, which combine three-dimensional points with RGB information at each point, returning a "3D color image". GIS thematic maps then are becoming more and more realistically visually descriptive of what they set out to show or determine.
For a list of popular GIS file formats, such as shapefiles, see .
Data capture.
Data capture—entering information into the system—consumes much of the time of GIS practitioners. There are a variety of methods used to enter data into a GIS where it is stored in a digital format.
Existing data printed on paper or PET film maps can be digitized or scanned to produce digital data. A digitizer produces vector data as an operator traces points, lines, and polygon boundaries from a map. Scanning a map results in raster data that could be further processed to produce vector data.
Survey data can be directly entered into a GIS from digital data collection systems on survey instruments using a technique called coordinate geometry (COGO). Positions from a global navigation satellite system (GNSS) like Global Positioning System can also be collected and then imported into a GIS. A current trend in data collection gives users the ability to utilize field computers with the ability to edit live data using wireless connections or disconnected editing sessions. This has been enhanced by the availability of low-cost mapping-grade GPS units with decimeter accuracy in real time. This eliminates the need to post process, import, and update the data in the office after fieldwork has been collected. This includes the ability to incorporate positions collected using a laser rangefinder. New technologies also allow users to create maps as well as analysis directly in the field, making projects more efficient and mapping more accurate.
Remotely sensed data also plays an important role in data collection and consist of sensors attached to a platform. Sensors include cameras, digital scanners and lidar, while platforms usually consist of aircraft and satellites. In England in the mid 1990s, hybrid kite/balloons called Helikites first pioneered the use of compact airborne digital cameras as airborne Geo-Information Systems. Aircraft measurement software, accurate to 0.4 mm was used to link the photographs and measure the ground. Helikites are inexpensive and gather more accurate data than aircraft. Helikites can be used over roads, railways and towns where UAVs are banned.
Recently with the development of miniature UAVs, aerial data collection is becoming possible with them. For example, the Aeryon Scout was used to map a 50-acre area with a Ground sample distance of in only 12 minutes.
The majority of digital data currently comes from photo interpretation of aerial photographs. Soft-copy workstations are used to digitize features directly from stereo pairs of digital photographs. These systems allow data to be captured in two and three dimensions, with elevations measured directly from a stereo pair using principles of photogrammetry. Analog aerial photos must be scanned before being entered into a soft-copy system, for high-quality digital cameras this step is skipped.
Satellite remote sensing provides another important source of spatial data. Here satellites use different sensor packages to passively measure the reflectance from parts of the electromagnetic spectrum or radio waves that were sent out from an active sensor such as radar. Remote sensing collects raster data that can be further processed using different bands to identify objects and classes of interest, such as land cover.
When data is captured, the user should consider if the data should be captured with either a relative accuracy or absolute accuracy, since this could not only influence how information will be interpreted but also the cost of data capture.
After entering data into a GIS, the data usually requires editing, to remove errors, or further processing. For vector data it must be made "topologically correct" before it can be used for some advanced analysis. For example, in a road network, lines must connect with nodes at an intersection. Errors such as undershoots and overshoots must also be removed. For scanned maps, blemishes on the source map may need to be removed from the resulting raster. For example, a fleck of dirt might connect two lines that should not be connected.
Raster-to-vector translation.
Data restructuring can be performed by a GIS to convert data into different formats. For example, a GIS may be used to convert a satellite image map to a vector structure by generating lines around all cells with the same classification, while determining the cell spatial relationships, such as adjacency or inclusion.
More advanced data processing can occur with image processing, a technique developed in the late 1960s by NASA and the private sector to provide contrast enhancement, false color rendering and a variety of other techniques including use of two dimensional Fourier transforms. Since digital data is collected and stored in various ways, the two data sources may not be entirely compatible. So a GIS must be able to convert geographic data from one structure to another. In so doing, the implicit assumptions behind different ontologies and classifications require analysis. Object ontologies have gained increasing prominence as a consequence of object-oriented programming and sustained work by Barry Smith and co-workers.
Projections, coordinate systems, and registration.
The earth can be represented by various models, each of which may provide a different set of coordinates (e.g., latitude, longitude, elevation) for any given point on the Earth's surface. The simplest model is to assume the earth is a perfect sphere. As more measurements of the earth have accumulated, the models of the earth have become more sophisticated and more accurate. In fact, there are models called datums that apply to different areas of the earth to provide increased accuracy, like NAD83 for U.S. measurements, and the World Geodetic System for worldwide measurements.
Spatial analysis with geographical information system (GIS).
GIS spatial analysis is a rapidly changing field, and GIS packages are increasingly including analytical tools as standard built-in facilities, as optional toolsets, as add-ins or 'analysts'. In many instances these are provided by the original software suppliers (commercial vendors or collaborative non commercial development teams), while in other cases facilities have been developed and are provided by third parties. Furthermore, many products offer software development kits (SDKs), programming languages and language support, scripting facilities and/or special interfaces for developing one's own analytical tools or variants. The website "Geospatial Analysis" and associated book/ebook attempt to provide a reasonably comprehensive guide to the subject. The increased availability has created a new dimension to business intelligence termed "spatial intelligence" which, when openly delivered via intranet, democratizes access to geographic and social network data. Geospatial intelligence, based on GIS spatial analysis, has also become a key element for security. GIS as a whole can be described as conversion to a vectorial representation or to any other digitisation process.
Slope and aspect.
Slope can be defined as the steepness or gradient of a unit of terrain, usually measured as an angle in degrees or as a percentage. Aspect can be defined as the direction in which a unit of terrain faces. Aspect is usually expressed in degrees from north. Slope, aspect, and surface curvature in terrain analysis are all derived from neighborhood operations using elevation values of a cell's adjacent neighbours. Slope is a function of resolution, and the spatial resolution used to calculate slope and aspect should always be specified. Authors such as Skidmore, Jones and Zhou and Liu have compared techniques for calculating slope and aspect.
The following method can be used to derive slope and aspect:
The elevation at a point or unit of terrain will have perpendicular tangents (slope) passing through the point, in an east-west and north-south direction. These two tangents give two components, ∂z/∂x and ∂z/∂y, which then be used to determine the overall direction of slope, and the aspect of the slope. The gradient is defined as a vector quantity with components equal to the partial derivatives of the surface in the x and y directions.
The calculation of the overall 3x3 grid slope "S" and aspect "A" for methods that determine east-west and north-south component use the following formulas respectively:
formula_1
formula_2
Zhou and Liu describe another formula for calculating aspect, as follows:
formula_3
Data analysis.
It is difficult to relate wetlands maps to rainfall amounts recorded at different points such as airports, television stations, and schools. A GIS, however, can be used to depict two- and three-dimensional characteristics of the Earth's surface, subsurface, and atmosphere from information points. For example, a GIS can quickly generate a map with isopleth or contour lines that indicate differing amounts of rainfall. Such a map can be thought of as a rainfall contour map. Many sophisticated methods can estimate the characteristics of surfaces from a limited number of point measurements. A two-dimensional contour map created from the surface modeling of rainfall point measurements may be overlaid and analyzed with any other map in a GIS covering the same area. This GIS derived map can then provide additional information - such as the viability of water power potential as a renewable energy source. Similarly, GIS can be used to compare other renewable energy resources to find the best geographic potential for a region.
Additionally, from a series of three-dimensional points, or digital elevation model, isopleth lines representing elevation contours can be generated, along with slope analysis, shaded relief, and other elevation products. Watersheds can be easily defined for any given reach, by computing all of the areas contiguous and uphill from any given point of interest. Similarly, an expected thalweg of where surface water would want to travel in intermittent and permanent streams can be computed from elevation data in the GIS.
Topological modeling.
A GIS can recognize and analyze the spatial relationships that exist within digitally stored spatial data. These topological relationships allow complex spatial modelling and analysis to be performed. Topological relationships between geometric entities traditionally include adjacency (what adjoins what), containment (what encloses what), and proximity (how close something is to something else).
Geometric networks.
Geometric networks are linear networks of objects that can be used to represent interconnected features, and to perform special spatial analysis on them. A geometric network is composed of edges, which are connected at junction points, similar to graphs in mathematics and computer science. Just like graphs, networks can have weight and flow assigned to its edges, which can be used to represent various interconnected features more accurately. Geometric networks are often used to model road networks and public utility networks, such as electric, gas, and water networks. Network modeling is also commonly employed in transportation planning, hydrology modeling, and infrastructure modeling.
Hydrological modeling.
GIS hydrological models can provide a spatial element that other hydrological models lack, with the analysis of variables such as slope, aspect and watershed or catchment area. Terrain analysis is fundamental to hydrology, since water always flows down a slope. As basic terrain analysis of a digital elevation model (DEM) involves calculation of slope and aspect, DEMs are very useful for hydrological analysis. Slope and aspect can then be used to determine direction of surface runoff, and hence flow accumulation for the formation of streams, rivers and lakes. Areas of divergent flow can also give a clear indication of the boundaries of a catchment. Once a flow direction and accumulation matrix has been created, queries can be performed that show contributing or dispersal areas at a certain point. More detail can be added to the model, such as terrain roughness, vegetation types and soil types, which can influence infiltration and evapotranspiration rates, and hence influencing surface flow. One of the main uses of hydrological modeling is in environmental contamination research.
Cartographic modeling.
The term "cartographic modeling" was probably coined by Dana Tomlin in his PhD dissertation and later in his book which has the term in the title. Cartographic modeling refers to a process where several thematic layers of the same area are produced, processed, and analyzed. Tomlin used raster layers, but the overlay method (see below) can be used more generally. Operations on map layers can be combined into algorithms, and eventually into simulation or optimization models.
Map overlay.
The combination of several spatial datasets (points, lines, or polygons) creates a new output vector dataset, visually similar to stacking several maps of the same region. These overlays are similar to mathematical Venn diagram overlays. A union overlay combines the geographic features and attribute tables of both inputs into a single new output. An intersect overlay defines the area where both inputs overlap and retains a set of attribute fields for each. A symmetric difference overlay defines an output area that includes the total area of both inputs except for the overlapping area.
Data extraction is a GIS process similar to vector overlay, though it can be used in either vector or raster data analysis. Rather than combining the properties and features of both datasets, data extraction involves using a "clip" or "mask" to extract the features of one data set that fall within the spatial extent of another dataset.
In raster data analysis, the overlay of datasets is accomplished through a process known as "local operation on multiple rasters" or "map algebra," through a function that combines the values of each raster's matrix. This function may weigh some inputs more than others through use of an "index model" that reflects the influence of various factors upon a geographic phenomenon.
Geostatistics.
Geostatistics is a branch of statistics that deals with field data, spatial data with a continuous index. It provides methods to model spatial correlation, and predict values at arbitrary locations (interpolation).
When phenomena are measured, the observation methods dictate the accuracy of any subsequent analysis. Due to the nature of the data (e.g. traffic patterns in an urban environment; weather patterns over the Pacific Ocean), a constant or dynamic degree of precision is always lost in the measurement. This loss of precision is determined from the scale and distribution of the data collection.
To determine the statistical relevance of the analysis, an average is determined so that points (gradients) outside of any immediate measurement can be included to determine their predicted behavior. This is due to the limitations of the applied statistic and data collection methods, and interpolation is required to predict the behavior of particles, points, and locations that are not directly measurable.
Interpolation is the process by which a surface is created, usually a raster dataset, through the input of data collected at a number of sample points. There are several forms of interpolation, each which treats the data differently, depending on the properties of the data set. In comparing interpolation methods, the first consideration should be whether or not the source data will change (exact or approximate). Next is whether the method is subjective, a human interpretation, or objective. Then there is the nature of transitions between points: are they abrupt or gradual. Finally, there is whether a method is global (it uses the entire data set to form the model), or local where an algorithm is repeated for a small section of terrain.
Interpolation is a justified measurement because of a spatial autocorrelation principle that recognizes that data collected at any position will have a great similarity to, or influence of those locations within its immediate vicinity.
Digital elevation models, triangulated irregular networks, edge-finding algorithms, Thiessen polygons, Fourier analysis, (weighted) moving averages, inverse distance weighting, kriging, spline, and trend surface analysis are all mathematical methods to produce interpolative data.
Address geocoding.
Geocoding is interpolating spatial locations (X,Y coordinates) from street addresses or any other spatially referenced data such as ZIP Codes, parcel lots and address locations. A reference theme is required to geocode individual addresses, such as a road centerline file with address ranges. The individual address locations have historically been interpolated, or estimated, by examining address ranges along a road segment. These are usually provided in the form of a table or database. The software will then place a dot approximately where that address belongs along the segment of centerline. For example, an address point of 500 will be at the midpoint of a line segment that starts with address 1 and ends with address 1,000. Geocoding can also be applied against actual parcel data, typically from municipal tax maps. In this case, the result of the geocoding will be an actually positioned space as opposed to an interpolated point. This approach is being increasingly used to provide more precise location information.
Reverse geocoding.
Reverse geocoding is the process of returning an estimated street address number as it relates to a given coordinate. For example, a user can click on a road centerline theme (thus providing a coordinate) and have information returned that reflects the estimated house number. This house number is interpolated from a range assigned to that road segment. If the user clicks at the midpoint of a segment that starts with address 1 and ends with 100, the returned value will be somewhere near 50. Note that reverse geocoding does not return actual addresses, only estimates of what should be there based on the predetermined range.
Multi-criteria decision analysis.
Coupled with GIS, multi-criteria decision analysis methods support decision-makers in analysing a set of alternative spatial solutions, such as the most likely ecological habitat for restoration, against multiple criteria, such as vegetation cover or roads. MCDA uses decision rules to aggregate the criteria, which allows the alternative solutions to be ranked or prioritised. GIS MCDA may reduce costs and time involved in identifying potential restoration sites.
Data output and cartography.
Cartography is the design and production of maps, or visual representations of spatial data. The vast majority of modern cartography is done with the help of computers, usually using GIS but production of quality cartography is also achieved by importing layers into a design program to refine it. Most GIS software gives the user substantial control over the appearance of the data.
Cartographic work serves two major functions:
First, it produces graphics on the screen or on paper that convey the results of analysis to the people who make decisions about resources. Wall maps and other graphics can be generated, allowing the viewer to visualize and thereby understand the results of analyses or simulations of potential events. Web Map Servers facilitate distribution of generated maps through web browsers using various implementations of web-based application programming interfaces (AJAX, Java, Flash, etc.).
Second, other database information can be generated for further analysis or use. An example would be a list of all addresses within one mile (1.6 km) of a toxic spill.
Graphic display techniques.
Traditional maps are abstractions of the real world, a sampling of important elements portrayed on a sheet of paper with symbols to represent physical objects. People who use maps must interpret these symbols. Topographic maps show the shape of land surface with contour lines or with shaded relief.
Today, graphic display techniques such as shading based on altitude in a GIS can make relationships among map elements visible, heightening one's ability to extract and analyze information. For example, two types of data were combined in a GIS to produce a perspective view of a portion of San Mateo County, California.
A GIS was used to register and combine the two images to render the three-dimensional perspective view looking down the San Andreas Fault, using the Thematic Mapper image pixels, but shaded using the elevation of the landforms. The GIS display depends on the viewing point of the observer and time of day of the display, to properly render the shadows created by the sun's rays at that latitude, longitude, and time of day.
An archeochrome is a new way of displaying spatial data. It is a thematic on a 3D map that is applied to a specific building or a part of a building. It is suited to the visual display of heat-loss data.
Spatial ETL.
Spatial ETL tools provide the data processing functionality of traditional Extract, Transform, Load (ETL) software, but with a primary focus on the ability to manage spatial data. They provide GIS users with the ability to translate data between different standards and proprietary formats, whilst geometrically transforming the data en route. These tools can come in the form of add-ins to existing wider-purpose software such as Microsoft Excel.
GIS data mining.
GIS or spatial data mining is the application of data mining methods to spatial data. Data mining, which is the partially automated search for hidden patterns in large databases, offers great potential benefits for applied GIS-based decision making. Typical applications include environmental monitoring. A characteristic of such applications is that spatial correlation between data measurements require the use of specialized algorithms for more efficient data analysis.
Applications.
The implementation of a GIS is often driven by jurisdictional (such as a city), purpose, or application requirements. Generally, a GIS implementation may be custom-designed for an organization. Hence, a GIS deployment developed for an application, jurisdiction, enterprise, or purpose may not be necessarily interoperable or compatible with a GIS that has been developed for some other application, jurisdiction, enterprise, or purpose.
GIS provides, for every kind of location-based organization, a platform to update geographical data without wasting time to visit the field and update a database manually. GIS when integrated with other powerful enterprise solutions like SAP, helps creating powerful decision support system at enterprise level.
Many disciplines can benefit from GIS technology. An active GIS market has resulted in lower costs and continual improvements in the hardware and software components of GIS, and usage in the fields of science, government, business, and industry, with applications including real estate, public health, crime mapping, national defense, sustainable development, natural resources, climatology, landscape architecture, archaeology, regional and community planning, transportation and logistics. GIS is also diverging into location-based services, which allows GPS-enabled mobile devices to display their location in relation to fixed objects (nearest restaurant, gas station, fire hydrant) or mobile objects (friends, children, police car), or to relay their position back to a central server for display or other processing.
Open Geospatial Consortium standards.
The Open Geospatial Consortium (OGC) is an international industry consortium of 384 companies, government agencies, universities, and individuals participating in a consensus process to develop publicly available geoprocessing specifications. Open interfaces and protocols defined by OpenGIS Specifications support interoperable solutions that "geo-enable" the Web, wireless and location-based services, and mainstream IT, and empower technology developers to make complex spatial information and services accessible and useful with all kinds of applications. Open Geospatial Consortium protocols include Web Map Service, and Web Feature Service.
GIS products are broken down by the OGC into two categories, based on how completely and accurately the software follows the OGC specifications.
"Compliant Products" are software products that comply to OGC's OpenGIS Specifications. When a product has been tested and certified as compliant through the OGC Testing Program, the product is automatically registered as "compliant" on this site.
"Implementing Products" are software products that implement OpenGIS Specifications but have not yet passed a compliance test. Compliance tests are not available for all specifications. Developers can register their products as implementing draft or approved specifications, though OGC reserves the right to review and verify each entry.
Web mapping.
In recent years there has been an explosion of mapping applications on the web such as Google Maps and Bing Maps. These websites give the public access to huge amounts of geographic data.
Some of them, like Google Maps and OpenLayers, expose an API that enable users to create custom applications. These toolkits commonly offer street maps, aerial/satellite imagery, geocoding, searches, and routing functionality. Web mapping has also uncovered the potential of crowdsourcing geodata in projects like OpenStreetMap, which is a collaborative project to create a free editable map of the world.
Adding the dimension of time.
The condition of the Earth's surface, atmosphere, and subsurface can be examined by feeding satellite data into a GIS. GIS technology gives researchers the ability to examine the variations in Earth processes over days, months, and years. As an example, the changes in vegetation vigor through a growing season can be animated to determine when drought was most extensive in a particular region. The resulting graphic represents a rough measure of plant health. Working with two variables over time would then allow researchers to detect regional differences in the lag between a decline in rainfall and its effect on vegetation.
GIS technology and the availability of digital data on regional and global scales enable such analyses. The satellite sensor output used to generate a vegetation graphic is produced for example by the Advanced Very High Resolution Radiometer (AVHRR). This sensor system detects the amounts of energy reflected from the Earth's surface across various bands of the spectrum for surface areas of about 1 square kilometer. The satellite sensor produces images of a particular location on the Earth twice a day. AVHRR and more recently the Moderate-Resolution Imaging Spectroradiometer (MODIS) are only two of many sensor systems used for Earth surface analysis. More sensors will follow, generating ever greater amounts of data.
In addition to the integration of time in environmental studies, GIS is also being explored for its ability to track and model the progress of humans throughout their daily routines. A concrete example of progress in this area is the recent release of time-specific population data by the U.S. Census. In this data set, the populations of cities are shown for daytime and evening hours highlighting the pattern of concentration and dispersion generated by North American commuting patterns. The manipulation and generation of data required to produce this data would not have been possible without GIS.
Using models to project the data held by a GIS forward in time have enabled planners to test policy decisions using spatial decision support systems.
Semantics.
Tools and technologies emerging from the W3C's Data Activity are proving useful for data integration problems in information systems. Correspondingly, such technologies have been proposed as a means to facilitate interoperability and data reuse among GIS applications. and also to enable new analysis mechanisms.
Ontologies are a key component of this semantic approach as they allow a formal, machine-readable specification of the concepts and relationships in a given domain. This in turn allows a GIS to focus on the intended meaning of data rather than its syntax or structure. For example, reasoning that a land cover type classified as "deciduous needleleaf trees" in one dataset is a specialization or subset of land cover type "forest" in another more roughly classified dataset can help a GIS automatically merge the two datasets under the more general land cover classification. Tentative ontologies have been developed in areas related to GIS applications, for example the hydrology ontology developed by the Ordnance Survey in the United Kingdom and the SWEET ontologies developed by NASA's Jet Propulsion Laboratory. Also, simpler ontologies and semantic metadata standards are being proposed by the W3C Geo Incubator Group to represent geospatial data on the web. GeoSPARQL is a standard developed by the Ordnance Survey, United States Geological Survey, Natural Resources Canada, Australia's Commonwealth Scientific and Industrial Research Organisation and others to support ontology creation and reasoning using well-understood OGC literals (GML, WKT), topological relationships (Simple Features, RCC8, DE-9IM), RDF and the SPARQL database query protocols.
Recent research results in this area can be seen in the International Conference on Geospatial Semantics and the Terra Cognita – Directions to the Geospatial Semantic Web workshop at the International Semantic Web Conference.
Society.
With the popularization of GIS in decision making, scholars have begun to scrutinize the social implications of GIS. It has been argued that the production, distribution, utilization, and representation of geographic information are largely related with the social context. Other related topics include discussion on copyright, privacy, and censorship. A more optimistic social approach to GIS adoption is to use it as a tool for public participation.

</doc>
<doc id="12401" url="https://en.wikipedia.org/wiki?curid=12401" title="Graph theory">
Graph theory

In mathematics and computer science, graph theory is the study of "graphs", which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of "vertices", "nodes", or "points" which are connected by "edges", "arcs", or "lines". A graph may be "undirected", meaning that there is no distinction between the two vertices associated with each edge, or its edges may be "directed" from one vertex to another; see Graph (discrete mathematics) for more detailed definitions and for other variations in the types of graph that are commonly considered. Graphs are one of the prime objects of study in discrete mathematics.
Refer to the glossary of graph theory for basic definitions in graph theory.
Definitions.
Definitions in graph theory vary. The following are some of the more basic ways of defining graphs and related mathematical structures.
Graph.
In the most common sense of the term, a graph is an ordered pair comprising a set "V" of "vertices" or "nodes" or "points" together with a set "E" of "edges" or "arcs" or "lines", which are 2-element subsets of "V" (i.e. an edge is related with two vertices, and the relation is represented as an unordered pair of the vertices with respect to the particular edge). To avoid ambiguity, this type of graph may be described precisely as undirected and simple.
Other senses of "graph" stem from different conceptions of the edge set. In one more generalized notion, "V" is a set together with a relation of "incidence" that associates with each edge two vertices. In another generalized notion, "E" is a multiset of unordered pairs of (not necessarily distinct) vertices. Many authors call this type of object a multigraph or pseudograph.
All of these variants and others are described more fully below.
The vertices belonging to an edge are called the "ends" or "end vertices" of the edge. A vertex may exist in a graph and not belong to an edge.
"V" and "E" are usually taken to be finite, and many of the well-known results are not true (or are rather different) for infinite graphs because many of the arguments fail in the infinite case. The "order" of a graph is |"V"|, its number of vertices. The "size" of a graph is |"E"|, its number of edges. The "degree" or "valency" of a vertex is the number of edges that connect to it, where an edge that connects a vertex to itself (a loop) is counted twice.
For an edge }, graph theorists usually use the somewhat shorter notation "xy".
Applications.
Graphs can be used to model many types of relations and processes in physical, biological, social and information systems. Many practical problems can be represented by graphs.
In computer science, graphs are used to represent networks of communication, data organization, computational devices, the flow of computation, etc. For instance, the link structure of a website can be represented by a directed graph, in which the vertices represent web pages and directed edges represent links from one page to another. A similar approach can be taken to problems in social media, travel, biology, computer chip design, and many other fields. The development of algorithms to handle graphs is therefore of major interest in computer science. The transformation of graphs is often formalized and represented by graph rewrite systems. Complementary to graph transformation systems focusing on rule-based in-memory manipulation of graphs are graph databases geared towards transaction-safe, persistent storing and querying of graph-structured data.
Graph-theoretic methods, in various forms, have proven particularly useful in linguistics, since natural language often lends itself well to discrete structure. Traditionally, syntax and compositional semantics follow tree-based structures, whose expressive power lies in the principle of compositionality, modeled in a hierarchical graph. More contemporary approaches such as head-driven phrase structure grammar model the syntax of natural language using typed feature structures, which are directed acyclic graphs. 
Within lexical semantics, especially as applied to computers, modeling word meaning is easier when a given word is understood in terms of related words; semantic networks are therefore important in computational linguistics. Still other methods in phonology (e.g. optimality theory, which uses lattice graphs) and morphology (e.g. finite-state morphology, using finite-state transducers) are common in the analysis of language as a graph. Indeed, the usefulness of this area of mathematics to linguistics has borne organizations such as TextGraphs, as well as various 'Net' projects, such as WordNet, VerbNet, and others.
Graph theory is also used to study molecules in chemistry and physics. In condensed matter physics, the three-dimensional structure of complicated simulated atomic structures can be studied quantitatively by gathering statistics on graph-theoretic properties related to the topology of the atoms. In chemistry a graph makes a natural model for a molecule, where vertices represent atoms and edges bonds. This approach is especially used in computer processing of molecular structures, ranging from chemical editors to database searching. In statistical physics, graphs can represent local connections between interacting parts of a system, as well as the dynamics of a physical process on such
systems. Similarly, in computational neuroscience graphs can be used to represent functional connections between brain areas that interact to give rise to various cognitive processes, where the vertices represent different areas of the brain and the edges represent the connections between those areas. Graphs are also used to represent the micro-scale channels of porous media, in which the vertices represent the pores and the edges represent the smaller channels connecting the pores.
Graph theory is also widely used in sociology as a way, for example, to measure actors' prestige or to explore rumor spreading, notably through the use of social network analysis software. Under the umbrella of social networks are many different types of graphs. Acquaintanceship and friendship graphs describe whether people know each other. Influence graphs model whether certain people can influence the behavior of others. Finally, collaboration graphs model whether two people work together in a particular way, such as acting in a movie together.
Likewise, graph theory is useful in biology and conservation efforts where a vertex can represent regions where certain species exist (or inhabit) and the edges represent migration paths, or movement between the regions. This information is important when looking at breeding patterns or tracking the spread of disease, parasites or how changes to the movement can affect other species.
In mathematics, graphs are useful in geometry and certain parts of topology such as knot theory. Algebraic graph theory has close links with group theory.
A graph structure can be extended by assigning a weight to each edge of the graph. Graphs with weights, or weighted graphs, are used to represent structures in which pairwise connections have some numerical values. For example, if a graph represents a road network, the weights could represent the length of each road.
History.
The paper written by Leonhard Euler on the "Seven Bridges of Königsberg" and published in 1736 is regarded as the first paper in the history of graph theory. This paper, as well as the one written by Vandermonde on the "knight problem," carried on with the "analysis situs" initiated by Leibniz. Euler's formula relating the number of edges, vertices, and faces of a convex polyhedron was studied and generalized by Cauchy and L'Huillier, and represents the beginning of the branch of mathematics known as topology.
More than one century after Euler's paper on the bridges of Königsberg and while Listing was introducing the concept of topology, Cayley was led by an interest in particular analytical forms arising from differential calculus to study a particular class of graphs, the "trees". This study had many implications for theoretical chemistry. The techniques he used mainly concern the enumeration of graphs with particular properties. Enumerative graph theory then arose from the results of Cayley and the fundamental results published by Pólya between 1935 and 1937. These were generalized by De Bruijn in 1959. Cayley linked his results on trees with contemporary studies of chemical composition. The fusion of ideas from mathematics with those from chemistry began what has become part of the standard terminology of graph theory.
In particular, the term "graph" was introduced by Sylvester in a paper published in 1878 in "Nature", where he draws an analogy between "quantic invariants" and "co-variants" of algebra and molecular diagrams:
The first textbook on graph theory was written by Dénes Kőnig, and published in 1936. Another book by Frank Harary, published in 1969, was "considered the world over to be the definitive textbook on the subject", and enabled mathematicians, chemists, electrical engineers and social scientists to talk to each other. Harary donated all of the royalties to fund the Pólya Prize.
One of the most famous and stimulating problems in graph theory is the four color problem: "Is it true that any map drawn in the plane may have its regions colored with four colors, in such a way that any two regions having a common border have different colors?" This problem was first posed by Francis Guthrie in 1852 and its first written record is in a letter of De Morgan addressed to Hamilton the same year. Many incorrect proofs have been proposed, including those by Cayley, Kempe, and others. The study and the generalization of this problem by Tait, Heawood, Ramsey and Hadwiger led to the study of the colorings of the graphs embedded on surfaces with arbitrary genus. Tait's reformulation generated a new class of problems, the "factorization problems", particularly studied by Petersen and Kőnig. The works of Ramsey on colorations and more specially the results obtained by Turán in 1941 was at the origin of another branch of graph theory, "extremal graph theory".
The four color problem remained unsolved for more than a century. In 1969 Heinrich Heesch published a method for solving the problem using computers. A computer-aided proof produced in 1976 by Kenneth Appel and Wolfgang Haken makes fundamental use of the notion of "discharging" developed by Heesch. The proof involved checking the properties of 1,936 configurations by computer, and was not fully accepted at the time due to its complexity. A simpler proof considering only 633 configurations was given twenty years later by Robertson, Seymour, Sanders and Thomas.
The autonomous development of topology from 1860 and 1930 fertilized graph theory back through the works of Jordan, Kuratowski and Whitney. Another important factor of common development of graph theory and topology came from the use of the techniques of modern algebra. The first example of such a use comes from the work of the physicist Gustav Kirchhoff, who published in 1845 his Kirchhoff's circuit laws for calculating the voltage and current in electric circuits.
The introduction of probabilistic methods in graph theory, especially in the study of Erdős and Rényi of the asymptotic probability of graph connectivity, gave rise to yet another branch, known as "random graph theory", which has been a fruitful source of graph-theoretic results.
Graph drawing.
Graphs are represented visually by drawing a dot or circle for every vertex, and drawing an arc between two vertices if they are connected by an edge. If the graph is directed, the direction is indicated by drawing an arrow.
A graph drawing should not be confused with the graph itself (the abstract, non-visual structure) as there are several ways to structure the graph drawing. All that matters is which vertices are connected to which others by how many edges and not the exact layout. In practice it is often difficult to decide if two drawings represent the same graph. Depending on the problem domain some layouts may be better suited and easier to understand than others.
The pioneering work of W. T. Tutte was very influential in the subject of graph drawing. Among other achievements, he introduced the use of linear algebraic methods to obtain graph drawings.
Graph drawing also can be said to encompass problems that deal with the crossing number and its various generalizations. The crossing number of a graph is the minimum number of intersections between edges that a drawing of the graph in the plane must contain. For a planar graph, the crossing number is zero by definition.
Drawings on surfaces other than the plane are also studied.
Graph-theoretic data structures.
There are different ways to store graphs in a computer system. The data structure used depends on both the graph structure and the algorithm used for manipulating the graph. Theoretically one can distinguish between list and matrix structures but in concrete applications the best structure is often a combination of both. List structures are often preferred for sparse graphs as they have smaller memory requirements. Matrix structures on the other hand provide faster access for some applications but can consume huge amounts of memory.
List structures include the incidence list, an array of pairs of vertices, and the adjacency list, which separately lists the neighbors of each vertex: Much like the incidence list, each vertex has a list of which vertices it is adjacent to.
Matrix structures include the incidence matrix, a matrix of 0's and 1's whose rows represent vertices and whose columns represent edges, and the adjacency matrix, in which both the rows and columns are indexed by vertices. In both cases a 1 indicates two adjacent objects and a 0 indicates two non-adjacent objects. The Laplacian matrix is a modified form of the adjacency matrix that incorporates information about the degrees of the vertices, and is useful in some calculations such as Kirchhoff's theorem on the number of spanning trees of a graph.
The distance matrix, like the adjacency matrix, has both its rows and columns indexed by vertices, but rather than containing a 0 or a 1 in each cell it contains the length of a shortest path between two vertices.
Problems in graph theory.
Enumeration.
There is a large literature on graphical enumeration: the problem of counting graphs meeting specified conditions. Some of this work is found in Harary and Palmer (1973).
Subgraphs, induced subgraphs, and minors.
A common problem, called the subgraph isomorphism problem, is finding a fixed graph as a subgraph in a given graph. One reason to be interested in such a question is that many graph properties are "hereditary" for subgraphs, which means that a graph has the property if and only if all subgraphs have it too.
Unfortunately, finding maximal subgraphs of a certain kind is often an NP-complete problem. For example:
A similar problem is finding induced subgraphs in a given graph. Again, some important graph properties are hereditary with respect to induced subgraphs, which means that a graph has a property if and only if all induced subgraphs also have it. Finding maximal induced subgraphs of a certain kind is also often NP-complete. For example:
Still another such problem, the minor containment problem, is to find a fixed graph as a minor of a given graph. A minor or subcontraction of a graph is any graph obtained by taking a subgraph and contracting some (or no) edges. Many graph properties are hereditary for minors, which means that a graph has a property if and only if all minors have it too. For example:
Another class of problems has to do with the extent to which various species and generalizations of graphs are determined by their "point-deleted subgraphs". For example:
Graph coloring.
Many problems have to do with various ways of coloring graphs, for example:
Subsumption and unification.
Constraint modeling theories concern families of directed graphs related by a partial order. In these applications, graphs are ordered by specificity, meaning that more constrained graphs—which are more specific and thus contain a greater amount of information—are subsumed by those that are more general. Operations between graphs include evaluating the direction of a subsumption relationship between two graphs, if any, and computing graph unification. The unification of two argument graphs is defined as the most general graph (or the computation thereof) that is consistent with (i.e. contains all of the information in) the inputs, if such a graph exists; efficient unification algorithms are known.
For constraint frameworks which are strictly compositional, graph unification is the sufficient satisfiability and combination function. Well-known applications include automatic theorem proving and modeling the elaboration of linguistic structure.
Network flow.
There are numerous problems arising especially from applications that have to do with various notions of flows in networks, for example:
Covering problems.
Covering problems in graphs are specific instances of subgraph-finding problems, and they tend to be closely related to the clique problem or the independent set problem.
Decomposition problems.
Decomposition, defined as partitioning the edge set of a graph (with as many vertices as necessary accompanying the edges of each part of the partition), has a wide variety of question. Often, it is required to decompose a graph into subgraphs isomorphic to a fixed graph; for instance, decomposing a complete graph into Hamiltonian cycles. Other problems specify a family of graphs into which a given graph should be decomposed, for instance, a family of cycles, or decomposing a complete graph "K""n" into specified trees having, respectively, 1, 2, 3, …, edges.
Some specific decomposition problems that have been studied include:
Graph classes.
Many problems involve characterizing the members of various classes of graphs. Some examples of such questions are below:

</doc>
<doc id="12405" url="https://en.wikipedia.org/wiki?curid=12405" title="Gumby">
Gumby

Gumby is an American clay animation franchise, centered on a green clay humanoid character created and modeled by Art Clokey. The character has been the subject of two television series as well as a feature-length film and other media. Since the original series' run, he has become well known as an example of stop motion clay animation and an influential cultural icon, spawning many tributes, parodies, and merchandising.
Overview.
"Gumby" follows the titular character and his adventures through different environments and times in history. Gumby's principal sidekick is Pokey, a talking orange pony. His nemeses are the Blockheads, a pair of humanoid, red-colored figures with cube-shaped heads, who wreak mischief and havoc. The Blockheads were inspired by The Katzenjammer Kids, who were always getting into scrapes and causing discomfort to others. Other characters are Prickle, a yellow dinosaur who sometimes styles himself as a detective with pipe and deerstalker hat like Sherlock Holmes, and Goo, a flying blue mermaid who spits blue goo balls and can change shape at will. Also featured are Gumby's dog Nopey, whose entire vocabulary is the word "nope," and Gumby's parents, Gumbo and Gumba. The later syndicated series in 1987 added Gumby's sister Minga and mastodon friend Denali.
History.
1953–1969: Origins.
Gumby was created by Art Clokey in the early 1950s after he finished film school at the University of Southern California. Clokey's first animated film was a 1953 three-minute student film called "Gumbasia", a surreal montage of moving and expanding lumps of clay set to music in a parody of Disney's "Fantasia". "Gumbasia" was created in a style Clokey's professor Slavko Vorkapić taught at USC called Kinesthetic Film Principles. Described as "massaging of the eye cells," this technique of camera movements and editing was responsible for much of the Gumby look and feel. In 1955 Clokey showed "Gumbasia" to movie producer Sam Engel, who encouraged him to develop his technique by animating figures into children's stories.
Clokey moved forward producing a pilot featuring the character Gumby, which derived its name from the muddy clay found at Clokey's grandparents' farm that his family referred to as "gumbo". The look of Gumby was inspired by a suggestion from his then-wife Ruth (née Parkander) that Clokey base his character on The Gingerbread Man. The color green was then chosen because Clokey saw it as a racially neutral color, as well as being a symbol of life. Gumby's legs and feet were made wide for pragmatic reasons: they ensured the clay character would stand up during stop-motion filming. The famous slanted shape of Gumby's head was based on the hair style of Clokey's father Charles Farrington in an old photograph.
NBC executive Thomas Warren Sarnoff saw and loved Clokey's first pilot and had Clokey make another one ("Gumby on the Moon"). This became a huge hit on "Howdy Doody", leading Sarnoff to order Gumby his own series in 1955 entitled "The Gumby Show". In 1955 and 1956, 22 eleven-minute episodes aired on NBC. Gumby's voice was originally provided by Ruth Eggleston, wife of the show's art director Al Eggleston, until Dallas McKennon became the primary voice of Gumby in 1957. Because of its variety-type format, the show not only featured Clokey's puppet films but interviews and games as well. During this time, the show went through a succession of two hosts: Robert Nicholson ("Nick") and Pinky Lee.
In 1959, the show entered syndication and more episodes were later produced in the 1960s. Production continued through 1968, by which time Norma MacMillan voiced Gumby. On some occasions during this time, Gumby's voice was provided by Ginny Tyler and Dick Beals.
1987: Revival.
Beginning in 1982, Eddie Murphy began a parody of Gumby on "Saturday Night Live". According to Murphy’s parody, when the television cameras were turned off, the sweet Gumby reverted to his true self: a cigar chomping, irascible celebrity who was highly demanding of the production executives. Whenever the executives refused to give in to his demands, Gumby would assert his star status by saying “I’m "Gumby", dammit!”
In 1987, the original Gumby shorts enjoyed a revival on home video. The following year, the character appeared in "The Puppetoon Movie".
This renewed interest led to a new incarnation of the series consisting of ninety-nine brand new 7-minute episodes produced for television syndication in association with Lorimar-Telepictures in 1987. Dallas McKennon returned as the voice of Gumby in the new adventures that would take Gumby and his pals beyond their toyland-type setting and establish themselves as a sing-a-long band. The show also included new characters, such as Gumby's little sister Minga and a mastodon named Denali.
In addition to the new episodes, the classic 1950s and 1960s shorts were re-run as part of the series, but with newly recorded soundtracks, with the voices re-recorded and the original music replaced by Jerry Gerber's synthesizer score from the 1988 series. Clokey's rights to use the original Capitol Records production tracks could not be renewed at the time, due to legal issues.
1990–present: Feature film and reruns.
In 1995, Clokey's production company produced an independently released theatrical film, ' (a.k.a. "Gumby 1"), marking the clay character's first feature-length adventure. In it, the villainous Blockheads replace Gumby and his band with robots and kidnap their dog, Lowbelly. The movie featured in-joke homages to such sci-fi classics as "Star Wars", "The Terminator", and '. Starting in 1992, TV channels like Nickelodeon and Cartoon Network aired re-runs of "Gumby" episodes. In 1998, the "Gumby" episode "Robot Rumpus" was featured on "Mystery Science Theatre 3000".
On March 16, 2007, YouTube announced that all Gumby episodes would appear in their full-length form on its site, digitally remastered and with their original soundtracks. This deal also extended to other video sites, including AOL. In March 2007, KQED-TV broadcast an hour-long documentary "Gumby Dharma" as part of their "Truly CA" series.
In 2012, Me-TV began airing "Gumby" as a part of a weekend morning animation block. The show remained part of the channel's programming until the end of the year.
On April 8, 2015, it was announced that there is a new "Gumby" series in the works which will be co-produced by the Jim Henson Company.
Reception and legacy.
In 1993, "TV Guide" named "Gumby" the best cartoon series of the 1950s in its issue celebrating 40 years of television.
Beginning in 1994, the Library of Congress used Gumby as a spokescharacter due to a common sequence in the show where Gumby walks into a book and experiences the world within the book as a tangible place. This then led to a traveling exhibit called "Adventures into Books: Gumby's World", a promotion for the Center for the Book's national reading campaign from 1997 to 2000. By the end of the 90s, Gumby and Pokey had also appeared in commercials for Cheerios cereal, most notably Frosted Cheerios.
On August 4, 2006, the Center for Puppetry Arts in Atlanta opened "Art Clokey's Gumby: The First Fifty Years", an exhibition featuring many of the original Puppets and sets; along with screening the films of Art Clokey. The event, conceived by David Scheve of T.D.A. Animation and Joe Clokey of Premavision was one of several exhibits that opened around the country, celebrating the fiftieth anniversary of "The Gumby Show". The children's book "Gumby Goes to the Sun" was also published that year to coincide with the anniversary. Written and illustrated by Clokey's daughter, Holly Harman, the book was originally created in the 1980s.
In 2007, the "Gumby" comic book series was nominated for two Eisner Awards, winning one of them, Best Publication For a Younger Audience.
On October 12, 2011, Google paid tribute to Art Clokey’s 90th birthday featuring clay balls transforming into characters from Gumby. The doodle was composed of five clay balls in the Google colors placed beside a toy block with a "G" on it. Clicking any of the balls revealed the Blockheads, Prickle, Goo, Gumby, and Pokey.
In a 2014 episode of the Disney XD series "Gravity Falls" called "Little Gift Shop of Horrors", the character of Soos Ramierez appears in the "Clay Day" segment of that episode as a character that looks very much like Gumby.
Merchandising.
Various Gumby merchandise has been produced over the years, the most prominent item being bendable figures. Several single packs and multi-figure sets by Jesco (later Trendmasters), as well as a 50th anniversary collection, have been made of the Gumby characters. Also included in the Gumby merchandise catalog are plush dolls, keychains, mugs, a 1988 Colorforms set, a 1995 Trendmasters playset, and a Kubricks set by Medicom. A tribute album, "Gumby: The Green Album", produced by Shepard Stern was released in 1989 through Buena Vista Records.
In August 2005, the first video game featuring Gumby, "Gumby vs. the Astrobots", was released by Namco for the Game Boy Advance. In it, Gumby must rescue Pokey, Prickle, and Goo after they are captured by the Blockheads and their cohorts, the Astrobots.
The Gumby images and toys are registered trademarks of Prema Toy Company. Premavision owns the distribution rights to the "Gumby" cartoons, having been reverted from previous distributor Warner Bros. Television in 2003, and had licensed the rights to Classic Media until September 30, 2012. At this time, Classic Media was officially acquired by DreamWorks Animation and branded as DreamWorks Classics.
As of April 2015, NCircle Entertainment owns home video and digital distribution rights to the cartoons.

</doc>
<doc id="12406" url="https://en.wikipedia.org/wiki?curid=12406" title="Gioachino Rossini">
Gioachino Rossini

Gioachino Antonio Rossini (; 29 February 179213 November 1868) was an Italian composer who wrote 39 operas as well as sacred music, chamber music, songs, and some instrumental and piano pieces.
His best-known operas include the Italian comedies "Il barbiere di Siviglia" ("The Barber of Seville") and "La Cenerentola" "(Cinderella)", and the French-language epics "Moïse et Pharaon" and "Guillaume Tell" "(William Tell)". A tendency for inspired, song-like melodies is evident throughout his scores, which led to the nickname "The Italian Mozart".
Until his retirement in 1829, Rossini had been the most popular opera composer in history. He is quoted as joking, "Give me the laundress' bill and I will even set that to music."
Early life.
Gioachino Antonio Rossini was born into a family of musicians in Pesaro, a town on the Adriatic coast of Italy which was then part of the Papal States. His father, Giuseppe, was a horn player and inspector of slaughterhouses. His mother, Anna, was a singer and a baker's daughter. Rossini's parents began his musical training early, and by the age of six he was playing the triangle in his father's musical group.
Rossini's father was sympathetic to the French Revolution and welcomed Napoleon's troops when they arrived in northern Italy. When Austria restored the old regime, Rossini's father was sent to prison in 1799, where he remained until June 1800. Rossini's mother took him to Bologna, making a living as leading singer at various theatres of the Romagna region. Her husband would ultimately join her in Bologna. During this time, Rossini was frequently left in the care of his aging grandmother, who had difficulty supervising the boy.
He remained at Bologna in the care of a pork butcher while his father played the horn in the orchestras of the theatres at which his wife sang. The boy had three years of instruction in the playing of the harpsichord from Giuseppe Prinetti, originally from Novara, who played the scale with two fingers only; Prinetti also owned a business selling beer and had a propensity to fall asleep while standing. These qualities made him a subject for ridicule in the eyes of the young Rossini.
Education.
He was eventually taken from Prinetti and apprenticed to a blacksmith. In Angelo Tesei, he found a congenial music master, and learned to sight-read, play accompaniments on the piano and sing well enough to take solo parts in the church when he was ten years of age. Important products of this period are six "sonate a quattro", or string sonatas, composed in three days, unusually scored for two violins, cello and double bass. The original scores, dating from 1804, when the composer was twelve, were found in the Library of Congress in Washington D.C. Often transcribed for string orchestra, these sonatas reveal the young composer's affinity for Haydn and Mozart, already showing signs of operatic tendencies, punctuated by frequent rhythmic changes and dominated by clear, songlike melodies.
In 1805, he appeared at the theatre of the Commune in Ferdinando Paer's "Camilla", his only public appearance as a singer. He was also a capable horn player, treading in the footsteps of his father. Around this time, he composed individual numbers to a libretto by Vincenza Mombelli called "Demetrio e Polibio", which was handed to the boy in pieces. Though it was Rossini's first opera, written when he was thirteen or fourteen, the work was not staged until the composer was twenty years old, premiering as his sixth official opera.
In 1806, Rossini became a cello student under Cavedagni at the Conservatorio di Bologna. The following year he was admitted to the counterpoint class of Padre Stanislao Mattei (1750–1825). He learned to play the cello with ease, but the pedantic severity of Mattei's views on counterpoint served only to drive the young composer's views toward a freer school of composition. His insight into orchestral resources is generally ascribed not to the strict compositional rules that he learned from Mattei, but to knowledge gained independently while scoring the quartets and symphonies of Haydn and Mozart. At Bologna, he was known as "il Tedeschino" ("the Little German") on account of his devotion to Mozart.
Career as a composer.
Early years: "Demetrio e Polibio" (1812) to "Torvaldo e Dorliska" (1815).
Through the friendly interposition of the Marquis Cavalli, his first opera, "La cambiale di matrimonio" ("The Marriage Contract"), was produced at Venice when he was a youth of 18 years. Two years before this he had already received the prize at the Conservatorio of Bologna for his cantata "Il pianto d'Armonia sulla morte d'Orfeo". Between 1810 and 1813 at Bologna, Rome, Venice and Milan, Rossini produced operas of varying success, most notably "La pietra del paragone" and "Il signor Bruschino", with its brilliant and unique overture. In 1813, "Tancredi" and "L'italiana in Algeri" were even bigger successes, and catapulted the 20-year-old composer to international fame.
The libretto for "Tancredi" was an arrangement by Gaetano Rossi of Voltaire's tragedy "Tancrède". Traces of Ferdinando Paer and Giovanni Paisiello were undeniably present in fragments of the music. But any critical feeling on the part of the public was drowned by appreciation of such melodies as ""Di tanti palpiti... Mi rivedrai, ti rivedrò"", which became so popular that the Italians would sing it in crowds at the law courts until called upon by the judge to desist.
By the age of 21, Rossini had established himself as the idol of the Italian opera public. He continued to write operas for Venice and Milan during the next few years, but their reception was tame and in some cases unsatisfactory after the success of "Tancredi." In 1815 he retired to his home in Bologna, where Domenico Barbaia, the impresario of the Naples theatre, contracted an agreement that made him musical director of the Teatro di San Carlo and the Teatro del Fondo at Naples. He would compose one opera a year for each. His payment was to be 200 ducats per month; he was also to receive a share from the gambling tables set in the theatre's "ridotto", amounting to about 1000 ducats per annum. This was an extraordinarily lucrative arrangement for any professional musician at that time.
He visited the Naples conservatory, and, although less than four years senior to Mercadante, he said to the Director Niccolò Zingarelli, "My compliments Maestro – your young pupil Mercadante begins where we finish."
Some older composers in Naples, notably Zingarelli and Paisiello, were inclined to intrigue against the success of the youthful composer, but all hostility was rendered futile by the enthusiasm that greeted the court performance of his "Elisabetta, regina d'Inghilterra", in which Isabella Colbran, who subsequently became the composer's wife, took a leading part. The libretto of this opera by Giovanni Schmidt was in many of its incidents an anticipation of those presented to the world a few years later in Sir Walter Scott's "Kenilworth". The opera was the first in which Rossini wrote out the ornaments of the arias instead of leaving them to the fancy of the singers, and also the first in which the recitativo "secco" was replaced by a recitative accompanied by a string quartet.
The resounding success of "The Barber of Seville" (1816).
Rossini's most famous opera was produced on 20 February 1816, at the Teatro Argentina in Rome. The libretto, a version of Pierre Beaumarchais' stage play "Le Barbier de Séville", was newly written by Cesare Sterbini and not the same as that already used by Giovanni Paisiello in his own "Barbiere", an opera which had enjoyed European popularity for more than a quarter of a century. Much is made of how quickly Rossini's opera was written, scholarship generally agreeing upon two or three weeks. Later in life, Rossini claimed to have written the opera in only twelve days. It was a colossal failure when it premiered as "Almaviva"; Paisiello's admirers were extremely indignant, sabotaging the production by whistling and shouting during the entire first act. However, not long after the second performance, the opera became so successful that the fame of Paisiello's opera was transferred to Rossini's, to which the title "The Barber of Seville" passed as an inalienable heritage.
Later in 1822, a 30-year-old Rossini succeeded in meeting Ludwig van Beethoven, who was then aged 51, deaf, cantankerous and in failing health. Communicating in writing, Beethoven noted: "Ah, Rossini. So you're the composer of "The Barber of Seville". I congratulate you. It will be played as long as Italian opera exists. Never try to write anything else but opera buffa; any other style would do violence to your nature."
Middle years: "La gazzetta" (1816) to "Semiramide" (1823).
Between 1815 and 1823 Rossini produced 20 operas. Of these, "Otello" formed the climax to his reform of serious opera, and offers a suggestive contrast with the treatment of the same subject at a similar point of artistic development by the composer Giuseppe Verdi. In Rossini's time, the tragic ending was so distasteful to the public of Rome that it was necessary to invent a happy conclusion to "Otello".
Conditions of stage production in 1817 are illustrated by Rossini's acceptance of the subject of Cinderella for a libretto only on the condition that the supernatural element should be omitted. The opera "La Cenerentola" was as successful as "Barbiere". The absence of a similar precaution in construction of his "Mosè in Egitto" led to disaster in the scene depicting the passage of the Israelites through the Red Sea, when the defects in stage contrivance always raised a laugh, so that the composer was at length compelled to introduce the chorus "Dal tuo stellato soglio" to divert attention from the dividing waves.
In 1822, four years after the production of this work, Rossini married the renowned opera singer Isabella Colbran. In the same year, he moved from Italy to Vienna, where his operas were the rage of the audiences. He directed his "Cenerentola" in Vienna, where "Zelmira" was also performed. After this he returned to Bologna, but an invitation from Metternich to the Congress of Verona to "assist in the general re-establishment of harmony" was too tempting to refuse, and he arrived at the Congress in time for its opening on 20 October 1822. Here he made friends with Chateaubriand and Dorothea Lieven.
In 1823, at the suggestion of the manager of the King's Theatre, London, he came to Britain, being much fêted on his way through Paris. He was given a generous welcome, which included an introduction to King George IV and the receipt of £7000 (£ today) after a residence of five months. The next year, he became musical director of the Théâtre des Italiens in Paris at a salary of £800 (£ today) per annum. Rossini's popularity in Paris was so great that Charles X gave him a contract to write five new operas a year, and at the expiration of the contract, he was to receive a generous pension for life.
Composing for Paris: "Il viaggio a Reims" (1825) to "Guillaume Tell" (1829).
During his Paris years, Rossini created the comic operas "Le comte Ory" and "Guillaume Tell" ("William Tell"). The production of the latter in 1829 brought his career as a writer of opera to a close. He was thirty-eight years old and had already composed thirty-eight operas. "Guillaume Tell" was a political epic adapted from Schiller's play "Wilhelm Tell" (1804) about the 13th-century Swiss patriot who rallied his country against the Austrians. The libretto was by Étienne Jouy and , but their version was revised by Armand Marrast.
The music is remarkable for its freedom from the conventions discovered and utilized by Rossini in his earlier works, and marks a transitional stage in the history of opera, the overture serving as a model for romantic overtures throughout the 19th century. Though an excellent opera, it is rarely heard uncut today, as the original score runs more than four hours in performance. The overture is one of the most famous and frequently recorded works in the classical repertoire.
In 1829 he returned to Bologna. His mother had died in 1827, and he was anxious to be with his father. Arrangements for his subsequent return to Paris on a new agreement were temporarily upset by the abdication of Charles X and the July Revolution of 1830. Rossini, who had been considering the subject of Faust for a new opera, did return, however, to Paris in November of that year.
Six movements of his "Stabat Mater" were written in 1832 by Rossini himself and the other six by Giovanni Tadolini, a good musician who was asked by Rossini to complete the work. However, Rossini composed the rest of the score in 1841. The success of the work bears comparison with his achievements in opera, but his comparative silence during the period from 1832 to his death in 1868 makes his biography appear almost like the narrative of two lives—the life of swift triumph and the long life of seclusion, of which biographers give us pictures in stories of the composer's cynical wit, his speculations in fish mongering, his mask of humility and indifference.
In Paris: the later years.
His first wife died in 1845, and on 16 August 1846, he married Olympe Pélissier, who had sat for Vernet for his picture of "Judith and Holofernes". Political disturbances compelled Rossini to leave Bologna in 1848. After living for a time in Florence, he settled in Paris in 1855, where he hosted many artistic and literary figures in his apartment at 2 Rue de la Chaussée-d'Antin. Rossini had been a well-known gourmand and an excellent amateur chef his entire life, but he indulged these two passions fully once he retired from composing, and today there are a number of dishes with the appendage "alla Rossini" to their names that were created either by or specifically for him. Probably the most famous of these is tournedos Rossini, still served by many restaurants today.
In the meantime, after years of various physical and mental illnesses, he had slowly returned to music, composing obscure little works intended for private performance. These included his Péchés de vieillesse ("Sins of Old Age"), which are grouped into 14 volumes, mostly for solo piano, occasionally for voice and various chamber ensembles. Often whimsical, these pieces display Rossini's natural ease of composition and gift for melody, showing obvious influences of Beethoven and Chopin, with many flashes of the composer's long buried desire for serious, academic composition. They also underpin the fact that Rossini himself was an outstanding pianist whose playing attracted high praise from people such as Franz Liszt, Sigismond Thalberg, Camille Saint-Saëns and Louis Diémer.
He died at the age of 76 from pneumonia at his country house at Passy on Friday, 13 November 1868. He was buried in Père Lachaise Cemetery in Paris, France. In 1887, his remains were moved to the Basilica of Santa Croce, Florence, at the request of the Italian government.
Legacy.
According to Herbert Weinstock's 1968 biography, the composer's estate was valued at 2.5 million francs upon his death in 1868, the equivalent of about 1.4 million US dollars. According to one contemporary account, at the time of Rossini's death, his estate yielded revenues of 150,000 francs per year. Apart from some individual legacies in favour of his wife and relatives, Rossini willed his entire estate to the Comune of Pesaro. The inheritance was invested to establish a (Conservatory) in the town. In 1940, the was put under state control and turned into the Conservatorio Statale di Musica "Gioachino Rossini". The corporate body which managed Rossini's inheritance assumed the name Fondazione G. Rossini. The aims of the institution, which is still active, are to support the conservatory and promote the figure, the memory, and the works of Rossini. The institution has been a major sponsor of the Rossini Opera Festival since its beginning.
Rossini's estate funded the Prix Rossini, a prize awarded to young French composers and librettists. The prize began to be awarded in 1878 on the death of his widow and is given by the Académie des Beaux-Arts. Prize-winning works were produced by the Société des Concerts, Institut de France, from 1885 to 1911. The bequest sought to reward composers of music which emphasized melody, which Rossini wrote "today is neglected" ("melodia, oggi si trascurata"). The prize for librettists was to be given to writers who observed "the laws of morality, which the modern writers completely ignore" ("osservando le leggi della morale di cui i moderni scrittori piu non tengono verun conto"). The prizes were exclusively for French composers and librettists (""exclusivamente per I Francesi"").
Honors and tributes.
Rossini was a foreign associate of the institute, Grand Officer of the Legion of Honour and recipient of innumerable orders.
Immediately after Rossini's death, Giuseppe Verdi proposed to collaborate with twelve other Italian composers on a "Requiem for Rossini", to be performed on the first anniversary of Rossini's death, conducted by Angelo Mariani. The music was written, but the performance was abandoned shortly before its scheduled premiere. Verdi re-used the "Libera me, Domine" he had written for the Rossini Requiem in his 1872 "Requiem for Manzoni". In 1989 the conductor Helmuth Rilling recorded the original "Requiem for Rossini" in its world premiere.
In 1900, Giuseppe Cassioli created a monument to Rossini in the Basilica of Santa Croce, Florence.
Rossiniana.
Mauro Giuliani (who died in 1829) wrote six sets of variations for guitar on themes by Rossini, Opp. 119–124 (c. 1820–1828). Each set was called "Rossiniana", and collectively they are called "Rossiniane". This was the first known tribute by one composer to another using a title with the ending -ana.
In 1925, Ottorino Respighi orchestrated four pieces from "Péchés de vieillesse" as the suite "Rossiniana" (he had earlier used pieces from the same collection as the basis of his ballet "La Boutique fantasque").
Music.
According to the "Oxford History of Western Music", "Rossini's fame surpassed that of any previous composer, and so, for a long time, did the popularity of his works. Audiences took to his music as if to an intoxicating drug – or, to put it more decorously, to champagne, with which Rossini's bubbly music was constantly compared."
Rossini took existing operatic genres and forms and perfected them in his own style. Through his own work, as well as through that of his followers and imitators, Rossini's style dominated Italian opera throughout the first half of the 19th century.
In his compositions, Rossini plagiarized freely from himself, a common practice among deadline-pressed opera composers of the time. Few of his operas are without such admixtures, frankly introduced in the form of arias or overtures. For example, in "Il Barbiere" there is an aria for the Count (often omitted) "Cessa di più resistere", which Rossini used (with minor changes) in the cantata "Le Nozze di Teti e di Peleo" and in "La Cenerentola" (the cabaletta for Angelina's rondo is almost unchanged). Moreover, four of his best known overtures ("La cambiale di matrimonio", "Tancredi", "La Cenerentola" and "The Barber of Seville") share operas apart from those with which they are most famously associated.
A characteristic mannerism in Rossini's orchestral scoring is a long, steady building of sound over an ostinato figure, creating "tempests in teapots by beginning in a whisper and rising to a flashing, glittering storm," which earned him the nickname of "Signor Crescendo".
A few of Rossini's operas remained popular throughout his lifetime and continuously since his death; others were resurrected from semi-obscurity in the last half of the 20th century, during the so-called "Rossini Renaissance".
Rossini himself correctly predicted that his "Barber of Seville" would continue to find favor with posterity, telling a friend:
External links.
Texts, books
Sheet music
Performances

</doc>
<doc id="12407" url="https://en.wikipedia.org/wiki?curid=12407" title="Gibberish">
Gibberish

Gibberish and gobbledygook refer to speech or other use of language that is nonsense, or that appears to be nonsense. It may include speech sounds that are not actual words, or forms such as language games or highly specialized jargon that seems non-sensical to outsiders. Gibberish should not be confused with literary nonsense such as that used in the poem "Jabberwocky" by Lewis Carroll.
The word "gibberish" is more commonly applied to informal speech, while "gobbledygook" (sometimes "gobbledegook", "gobbledigook" or "gobbledegoo") is more often applied to writing. "Officialese", "legalese", or "bureaucratese" are forms of gobbledygook. The related word "jibber-jabber" refers to rapid talk that is difficult to understand.
Etymology.
The term "gibberish" was first seen in English in the early 16th century. Its etymology is not certain, but it is generally thought to be onomatopoeia imitative of speech, similar to the related words "jabber" (to talk rapidly) and "gibber" (to speak inarticulately).
Another theory is that gibberish came from the name of a famous 8th-century Islamic alchemist, Jābir ibn Hayyān, whose name was Latinized as "Geber." Thus, "gibberish" was a reference to the incomprehensible technical jargon used by Jabir and other alchemists. 
Less widely accepted theories assert that it is derived from the Irish word "gob" or "gab" (mouth) or from the Irish phrase "Geab ar ais" (back talk, backward chat). The latter Irish etymology was suggested by Daniel Cassidy, whose work has been criticised by linguists and scholars. The terms "geab" and "geabaire" are certainly Irish words, but the phrase "geab ar ais" does not exist, and the word gibberish exists as a loan-word in Irish as "gibiris".
The term "gobbledygook" was coined by Maury Maverick, a former congressman from Texas and former mayor of San Antonio. When Maverick was chairman of the Smaller War Plants Corporation during World War II, he sent a memorandum that said: "Be short and use Plain English. . . . Stay off gobbledygook language." Later, writing in the "New York Times Magazine", he defined gobbledygook as "talk or writing which is long, pompous, vague, involved, usually with Latinized words." The allusion was to a turkey, "always gobbledygobbling and strutting with ridiculous pomposity."
Usage.
The term "gobbledygook" has a long history of usage in politics. Nixon's Oval Office tape from June 14, 1971, showed H. R. Haldeman describing a situation to Nixon as "a bunch of gobbledygook. But out of the gobbledygook comes a very clear thing: you can't trust the government; you can't believe what they say." President Ronald Reagan explained tax law revisions in an address to the nation with the word, May 28, 1985, saying that "most didn’t improve the system; they made it more like Washington itself: complicated, unfair, cluttered with gobbledygook and loopholes designed for those with the power and influence to hire high-priced legal and tax advisers."
Michael Shanks, former chairman to the National Consumer Council of Great Britain, characterizes professional gobbledygook as sloppy jargon intended to confuse nonspecialists: "'Gobbledygook' may indicate a failure to think clearly, a contempt for one's clients, or more probably a mixture of both. A system that can't or won't communicate is not a safe basis for a democracy."
Utilizing gibberish whilst acting can be used as an exercise in performance art education. Another usage of Gibberish is as part of Osho's "Gibberish meditation" which has been derived from an old Sufi practice.
Other terms and usage.
The terms "officialese" or "bureaucratese" refer to language used by officials or authorities. "Legalese" is a closely related concept, referring to language used by lawyers, legislators, and others involved with the law. The language used in these fields may contain complex sentences and specialized jargon or buzzwords, making it difficult for those outside the field to understand. Speakers or writers of officialese or legalese may recognize that it is confusing or even meaningless to outsiders, but view its use as appropriate within their organization or group.
Bafflegab is a synonym, a slang term referring to confusing or a generally unintelligible use of jargon.

</doc>
<doc id="12408" url="https://en.wikipedia.org/wiki?curid=12408" title="Gnaeus Julius Agricola">
Gnaeus Julius Agricola

Gnaeus Julius Agricola (; 13 June 40 – 23 August 93) was a Gallo-Roman general responsible for much of the Roman conquest of Britain. Written by his son-in-law Tacitus, the "De vita et moribus Iulii Agricolae" is the primary source for most of what is known about him, along with detailed archaeological evidence from northern Britain.
Agricola began his military career in Britain, serving under governor Gaius Suetonius Paulinus. His subsequent career saw him serve in a variety of positions; he was appointed quaestor in Asia province in 64, then Plebeian Tribune in 66, and praetor in 68. He supported Vespasian during the Year of the Four Emperors (69), and was given a military command in Britain when the latter became emperor. When his command ended in 73, he was made patrician in Rome and appointed governor of Gallia Aquitania. He was made consul and governor of Britannia in 77. While there, he completed the conquest of what is now Wales and northern England, and led his army to the far north of Scotland, establishing forts across much of the Lowlands. He was recalled from Britain in 85 after an unusually lengthy service, and thereafter retired from military and public life.
Early life.
Agricola was born in the "colonia" of Forum Julii, Gallia Narbonensis (now Fréjus, France). Agricola's parents were from noted Gallo-Roman political families of senatorial rank, his ancestors were Romanised Gauls of local origin. Both of his grandfathers served as imperial governors. His father, Lucius Julius Graecinus, was a "praetor" and had become a member of the Roman Senate in the year of his birth. Graecinus had become distinguished by his interest in philosophy. Between August 40 and January 41, the Roman Emperor Caligula ordered his death because he refused to prosecute the Emperor's second cousin Marcus Junius Silanus.
His mother was Julia Procilla. The Roman historian Tacitus describes her as "a lady of singular virtue". Tacitus states that Procilla had a fond affection for her son. Agricola was educated in Massilia (Marseille), and showed what was considered an unhealthy interest in philosophy.
Political career.
He began his career in Roman public life as a military tribune, serving in Britain under Gaius Suetonius Paulinus from 58 to 62. He was probably attached to the "Legio II Augusta", but was chosen to serve on Suetonius's staff and thus almost certainly participated in the suppression of Boudica's uprising in 61.
Returning from Britain to Rome in 62, he married Domitia Decidiana, a woman of noble birth. Their first child was a son. Agricola was appointed as "quaestor" for 64, which he served in the province of Asia under the corrupt proconsul Lucius Salvius Otho Titianus. While he was there, his daughter, Julia Agricola, was born, but his son died shortly afterwards. He was tribune of the plebs in 66 and "praetor" on June 68, during which time he was ordered by the Governor of Spain Galba to take an inventory of the temple treasures.
In June 68, the emperor Nero was deposed and committed suicide, and the period of civil war known as the Year of the Four Emperors began. Galba succeeded Nero, but was murdered in early 69 by Otho, who took the throne. Agricola's mother was murdered on her estate in Liguria by Otho's marauding fleet. Hearing of Vespasian's bid for the empire, Agricola immediately gave him his support. Otho meanwhile committed suicide after being defeated by Vitellius.
After Vespasian had established himself as emperor, Agricola was appointed to the command of the "Legio XX Valeria Victrix", stationed in Britain, in place of Marcus Roscius Coelius, who had stirred up a mutiny against the governor, Marcus Vettius Bolanus. Britain had suffered revolt during the year of civil war, and Bolanus was a mild governor. Agricola reimposed discipline on the legion and helped to consolidate Roman rule. In 71, Bolanus was replaced by a more aggressive governor, Quintus Petillius Cerialis, and Agricola was able to display his talents as a commander in campaigns against the Brigantes in northern England.
When his command ended in 73, Agricola was enrolled as a patrician and appointed to govern Gallia Aquitania. There he stayed for almost three years. In 76 or 77, he was recalled to Rome and appointed suffect consul, and betrothed his daughter to Tacitus. The following year, Tacitus and Julia married; Agricola was appointed to the College of Pontiffs, and returned to Britain for a third time, as its governor ("Legatus Augusti pro praetore").
Governor of Britain.
Arriving in midsummer of 77, Agricola found the Ordovices of north Wales had virtually destroyed the Roman cavalry stationed in their territory. He immediately moved against them and defeated them. He then moved north to the island of Mona (Anglesey), which Suetonius Paulinus had failed to subjugate in 60 because of the outbreak of the Boudican rebellion, and forced its inhabitants to sue for peace. He established a good reputation as an administrator, as well as a commander, by reforming the widely corrupt corn levy. He introduced Romanising measures, encouraging communities to build towns on the Roman model and educating the sons of the native nobility in the Roman manner.
He also expanded Roman rule north into Caledonia (modern Scotland). In the summer of 79, he pushed his armies to the estuary of the river Taus, usually interpreted as the Firth of Tay, virtually unchallenged, and established some forts. Though their location is left unspecified, the close dating of the fort at Elginhaugh in Midlothian makes it a possible candidate.
Agricola in Ireland?
In 81, Agricola "crossed in the first ship" and defeated peoples unknown to the Romans until then. Tacitus, in Chapter 24 of "Agricola", does not tell us what body of water he crossed, although most scholars believe it was the Clyde or Forth, and some translators even add the name of their preferred river to the text; however, the rest of the chapter exclusively concerns Ireland, so southwest Scotland is perhaps to be preferred. The text of the "Agricola" has been emended here to record the Romans "crossing into trackless wastes", referring to the wilds of the Galloway peninsula. Agricola fortified the coast facing Ireland, and Tacitus recalls that his father-in-law often claimed the island could be conquered with a single legion and auxiliaries. He had given refuge to an exiled Irish king whom he hoped he might use as the excuse for conquest. This conquest never happened, but some historians believe the crossing referred to was in fact a small-scale exploratory or punitive expedition to Ireland, though no Roman camps have been identified to confirm such a suggestion.
Irish legend provides a striking parallel. Tuathal Teachtmhar, a legendary High King, is said to have been exiled from Ireland as a boy, and to have returned from Britain at the head of an army to claim the throne. The traditional date of his return is 76–80, and archaeology has found Roman or Romano-British artefacts in several sites associated with Tuathal.
The invasion of Caledonia (Scotland).
The following year, Agricola raised a fleet and encircled the tribes beyond the Forth, and the Caledonians rose in great numbers against him. They attacked the camp of the "Legio IX Hispana" at night, but Agricola sent in his cavalry and they were put to flight. The Romans responded by pushing further north. Another son was born to Agricola this year, but he died before his first birthday.
In the summer of 83, Agricola faced the massed armies of the Caledonians, led by Calgacus, at the Battle of Mons Graupius. Tacitus estimates their numbers at more than 30,000. Agricola put his auxiliaries in the front line, keeping the legions in reserve, and relied on close-quarters fighting to make the Caledonians' unpointed slashing swords useless as they were unable to swing them properly or utilise thrusting attacks. Even though the Caledonians were put to rout and therefore lost this battle, two thirds of their army managed to escape and hide in the Highlands or the "trackless wilds" as Tacitus calls them. Battle casualties were estimated by Tacitus to be about 10,000 on the Caledonian side and 360 on the Roman side.
A number of authors have reckoned the battle to have occurred in the Grampian Mounth within sight of the North Sea. In particular, Roy, Surenne, Watt, Hogan and others have advanced notions that the site of the battle may have been Kempstone Hill, Megray Hill or other knolls near the Raedykes Roman camp; these points of high ground are proximate to the Elsick Mounth, an ancient trackway used by Romans and Caledonians for military manoeuvres. However, following the discovery of the Roman camp at Durno in 1975, most scholars now believe that the battle took place on the ground around Bennachie in Aberdeenshire.
Satisfied with his victory, Agricola extracted hostages from the Caledonian tribes. He may have marched his army to the northern coast of Britain, as evidenced by the probable discovery of a Roman fort at Cawdor (near Inverness).
He also instructed the prefect of the fleet to sail around the north coast, confirming (allegedly for the first time) that Britain was in fact an island.
Later years.
Agricola was recalled from Britain in 85, after an unusually long tenure as governor. Tacitus claims Domitian ordered his recall because Agricola's successes outshone the Emperor's own modest victories in Germany. He re-entered Rome unobtrusively, reporting as ordered to the palace at night. The relationship between Agricola and the Emperor is unclear; on the one hand, Agricola was awarded triumphal decorations and a statue (the highest military honours apart from an actual triumph); on the other, Agricola never again held a civil or military post, in spite of his experience and renown. He was offered the governorship of the province of Africa, but declined it, whether due to ill health or (as Tacitus claims) the machinations of Domitian.
In 93, Agricola died on his family estates in Gallia Narbonensis aged fifty-three. Rumours circulated attributing the death to a poison administered by the Emperor Domitian, but no positive evidence for this was ever produced.

</doc>
<doc id="12417" url="https://en.wikipedia.org/wiki?curid=12417" title="Guanosine">
Guanosine

Guanosine is a purine nucleoside comprising guanine attached to a ribose (ribofuranose) ring via a β-N9-glycosidic bond. Guanosine can be phosphorylated to become guanosine monophosphate (GMP), cyclic guanosine monophosphate (cGMP), guanosine diphosphate (GDP), and guanosine triphosphate (GTP). These forms play important roles in various biochemical processes such as synthesis of nucleic acids and proteins, photosynthesis, muscle contraction, and intracellular signal transduction (cGMP). When guanine is attached by its N9 nitrogen to the C1 carbon of a deoxyribose ring it is known as deoxyguanosine.
The antiviral drug aciclovir, often used in herpes treatment, and the anti-HIV drug abacavir, are structurally similar to guanosine.
Guanosine is required for an RNA splicing reaction in mRNA, when a "self-splicing" intron removes itself from the mRNA message by cutting at both ends, re-ligating, and leaving just the exons on either side to be translated into protein.

</doc>
<doc id="12420" url="https://en.wikipedia.org/wiki?curid=12420" title="Gödel's ontological proof">
Gödel's ontological proof

Gödel's ontological proof is a formal argument for God's existence by the mathematician Kurt Gödel (1906–1978).
It is in a line of development that goes back to Anselm of Canterbury (1033–1109). St. Anselm's ontological argument, in its most succinct form, is as follows: "God, by definition, is that for which no greater can be conceived. God exists in the understanding. If God exists in the understanding, we could imagine Him to be greater by existing in reality. Therefore, God must exist." A more elaborate version was given by Gottfried Leibniz (1646–1716); this is the version that Gödel studied and attempted to clarify with his ontological argument.
Gödel left a fourteen-point outline of his philosophical beliefs in his papers. Points relevant to the ontological proof include
History of Gödel's proof.
The first version of the ontological proof in Gödel's papers is dated "around 1941". Gödel is not known to have told anyone about his work on the proof until 1970, when he thought he was dying. In February, he allowed Dana Scott to copy out a version of the proof, which circulated privately. In August 1970, Gödel told Oskar Morgenstern that he was "satisfied" with the proof, but Morgenstern recorded in his diary entry for 29 August 1970, that Gödel would not publish because he was afraid that others might think "that he actually believes in God, whereas he is only engaged in a logical investigation (that is, in showing that such a proof with classical assumptions (completeness, etc.) correspondingly axiomatized, is possible)." Gödel died January 14, 1978. Another version, slightly different from Scott's, was found in his papers. It was finally published, together with Scott's version, in 1987.
Morgenstern's diary is an important and usually reliable source for Gödel's later years, but the implication of the August 1970 diary entry—that Gödel did not believe in God—is not consistent with the other evidence. In letters to his mother, who was not a churchgoer and had raised Kurt and his brother as freethinkers, Gödel argued at length for a belief in an afterlife. He did the same in an interview with a skeptical Hao Wang, who said: "I expressed my doubts as G spoke [...] Gödel smiled as he replied to my questions, obviously aware that his answers were not convincing me." Wang reports that Gödel's wife, Adele, two days after Gödel's death, told Wang that "Gödel, although he did not go to church, was religious and read the Bible in bed every Sunday morning." In an unmailed answer to a questionnaire, Gödel described his religion as "baptized Lutheran (but not member of any religious congregation). My belief is "theistic", not pantheistic, following Leibniz rather than Spinoza."
Outline of Gödel's proof.
The proof uses modal logic, which distinguishes between "necessary" truths and "contingent" truths. In the most common semantics for modal logic, many "possible worlds" are considered. A truth is "necessary" if it is true in all possible worlds. By contrast, a truth is "contingent" if it just happens to be the case, for instance, that "more than half of the planet is covered by water". If a statement happens to be true in our world, but is false in another world, then it is a contingent truth. A statement that is true in some world (not necessarily our own) is called a "possible" truth.
Furthermore, the proof uses higher-order (modal) logic because the definition of God employs an explicit quantification over properties.
From axioms 1 through 4, Gödel argued that in "some" possible world there exists God. He used a sort of modal plenitude principle to argue this from the logical consistency of Godlikeness. Note that this property is itself positive, since it is the conjunction of the (infinitely many) positive properties.
Then, Gödel defined "essences": if "x" is an object in some world, then the property "P" is said to be an essence of "x" if "P"("x") is true in that world and if "P" entails all other properties that "x" has in that world. We also say that "x" "necessarily exists" if for every essence "P" the following is true: in every possible world, there is an element "y" with "P"("y").
Since necessary existence is positive, it must follow from Godlikeness. Moreover, Godlikeness is an essence of God, since it entails all positive properties, and any nonpositive property is the negation of some positive property, so God cannot have any nonpositive properties. Since any Godlike object is necessarily existent, it follows that any Godlike object in one world is a Godlike object in all worlds, by the definition of necessary existence. Given the existence of a Godlike object in one world, proven above, we may conclude that there is a Godlike object in every possible world, as required.
From these hypotheses, it is also possible to prove that there is only one God in each world by Leibniz's law, the identity of indiscernibles: two or more objects are identical (are one and the same) if they have all their properties in common, and so, there would only be one object in each world that possesses property G. Gödel did not attempt to do so however, as he purposely limited his proof to the issue of existence, rather than uniqueness. This was more to preserve the logical precision of the argument than due to a penchant for polytheism. This uniqueness proof will only work if one supposes that the positiveness of a property is independent of the object to which it is applied, a claim which some have considered to be suspect .
To formalize the argument sketched above, the following definitions and axioms are needed:
Axiom 4 assumes that it is possible to single out "positive" properties from among all properties. Gödel comments that "Positive means positive in the moral aesthetic sense (independently of the accidental structure of the world)... It may also mean pure "attribution" as opposed to "privation" (or containing privation)." (Gödel 1995). Axioms 1, 2 and 3 can be summarized by saying that positive properties form a principal ultrafilter.
From these axioms and definitions and a few other axioms from modal logic, the following theorems can be proved:
Symbolically:
formula_1
There is an ongoing open-source effort to formalize Gödel's proof to a level that is suitable for automated theorem proving or at least computer verification via proof assistants. The effort made headlines in German newspapers. According to the authors of this effort, they were inspired by Melvin Fitting's book.
Criticism.
Most criticism of Gödel's proof is aimed at its axioms: As with any proof in any logical system, if the axioms the proof depends on are doubted, then the conclusions can be doubted. This is particularly applicable to Gödel's proof, because it rests on five axioms that are all questionable. The proof does not say that the conclusion has to be correct, but rather that if you accept the axioms, then the conclusion is correct.
Many philosophers have questioned the axioms. The first layer of attack is simply that there are no arguments presented that give reasons why the axioms are true. A second layer is that these particular axioms lead to unwelcome conclusions. This line of thought was argued by Sobel, showing that if the axioms are accepted, they lead to a modal collapse where every statement that is true is necessarily true.
There are suggested amendments to the proof, presented by C. A. Anderson presents an amended version of the proof, but argued to be refutable by C. A. Anderson and Michael Gettings. Sobel's proof of modal collapse has been questioned by, but a counter-defence by Sobel has been given.
The proof has also been questioned by Oppy, asking whether lots of other almost-gods would also be "proven" by Godel's axioms. This counter-argument has been questioned by Gettings, who agrees that the axioms might be questioned, but disagrees that Oppy's particular counter-example can be shown from Godel's axioms.
There are many more criticisms, most focussing on the philosophically interesting question of whether these axioms *must* be rejected to avoid odd conclusions. The broader criticism is that even if the axioms cannot be shown to be false, that does not mean that they are true.
Ontological Proof in Literature.
A humorous variant of Godel's Ontological proof is mentioned in Quentin Canterel's novel "The Jolly Coroner"

</doc>
<doc id="12422" url="https://en.wikipedia.org/wiki?curid=12422" title="List of gymnasts">
List of gymnasts

Gymnasts are people who participate in the sport of gymnastics. This sport contains disciplines that include, but are not limited to:
This list is of those who are considered to be notable in their chosen discipline.
See gymnasium (ancient Greece) for the origin of the word "gymnast" from gymnastikos.

</doc>
<doc id="12424" url="https://en.wikipedia.org/wiki?curid=12424" title="Genetic programming">
Genetic programming

In artificial intelligence, genetic programming (GP) is a technique whereby computer programs are encoded as a set of genes that are then modified (evolved) using an evolutionary algorithm (often a genetic algorithm). The result is a computer program able to perform well in a predefined task. Often confused to be a kind of genetic algorithm, GP can indeed be seen as an application of genetic algorithms to problems where each individual is a computer program. The methods used to encode a computer program in an artificial chromosome and to evaluate its fitness with respect to the predefined task are central in the GP technique and still the subject of active research.
History.
In 1954, pioneering work on what is today known as artificial life was carried out by Nils Aall Barricelli using the very early computers. In the 1960s and early 1970s, evolutionary algorithms became widely recognized as optimization methods. Ingo Rechenberg and his group were able to solve complex engineering problems through evolution strategies as documented in his 1971 PhD thesis and the resulting 1973 book. John Holland was highly influential during the 1970s. The establishment of evolutionary algorithms in the scientific community allowed, by then, the first concrete steps to study the GP idea.
In 1964, Lawrence J. Fogel, one of the earliest practitioners of the GP methodology, applied evolutionary algorithms to the problem of discovering finite-state automata. Later GP-related work grew out of the learning classifier system community, which developed sets of sparse rules describing optimal policies for Markov decision processes. 
In 1981 Richard Forsyth evolved tree rules to classify heart disease.
The first statement of modern "tree-based" genetic programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators) was given by Nichael L. Cramer (1985). This work was later greatly expanded by John R. Koza, a main proponent of GP who has pioneered the application of genetic programming in various complex optimization and search problems. Gianna Giavelli, a student of Koza's, later pioneered the use of genetic programming as a technique to model DNA expression.
In the 1990s, GP was mainly used to solve relatively simple problems because it is very computationally intensive. Recently GP has produced many novel and outstanding results in areas such as quantum computing, electronic design, game playing, cyberterrorism prevention, sorting, and searching, due to improvements in GP technology and the exponential growth in CPU power.
These results include the replication or development of several post-year-2000 inventions. GP has also been applied to evolvable hardware as well as computer programs.
Developing a theory for GP has been very difficult and so in the 1990s GP was considered a sort of outcast among search techniques.
Program representation.
GP evolves computer programs, traditionally represented in memory as tree structures. Trees can be easily evaluated in a recursive manner. Every tree node has an operator function and every terminal node has an operand, making mathematical expressions easy to evolve and evaluate. Thus traditionally GP favors the use of programming languages that naturally embody tree structures (for example, Lisp; other functional programming languages are also suitable).
Non-tree representations have been suggested and successfully implemented, such as linear genetic programming which suits the more traditional imperative languages for example, Banzhaf "et al." (1998). The commercial GP software Discipulus uses automatic induction of binary machine code ("AIM") to achieve better performance. µGP uses directed multigraphs to generate programs that fully exploit the syntax of a given assembly language
Most non-tree representations have structurally noneffective code (introns).
Such non-coding genes may seem to be useless, because they have no effect on the performance of any one individual.
However, experiments seem to show faster convergence when using program representations—such as linear genetic programming and Cartesian genetic programming—that allow such non-coding genes, compared to tree-based program representations that do not have any non-coding genes.
Other approaches.
The basic ideas of genetic programming have been modified and extended in a variety of ways:
Meta-Genetic Programming.
Meta-Genetic Programming is the proposed meta learning technique of evolving a genetic programming system using genetic programming itself. It suggests that chromosomes, crossover, and mutation were themselves evolved, therefore like their real life counterparts should be allowed to change on their own rather than being determined by a human programmer. Meta-GP was formally proposed by Jürgen Schmidhuber in 1987. Doug Lenat's Eurisko is an earlier effort that may be the same technique. It is a recursive but terminating algorithm, allowing it to avoid infinite recursion.
Critics of this idea often say this approach is overly broad in scope. However, it might be possible to constrain the fitness criterion onto a general class of results, and so obtain an evolved GP that would more efficiently produce results for sub-classes. This might take the form of a Meta evolved GP for producing human walking algorithms which is then used to evolve human running, jumping, etc. The fitness criterion applied to the Meta GP would simply be one of efficiency.
For general problem classes there may be no way to show that Meta GP will reliably produce results more efficiently than a created algorithm other than exhaustion.

</doc>
<doc id="12425" url="https://en.wikipedia.org/wiki?curid=12425" title="Gustav Klimt">
Gustav Klimt

Gustav Klimt (July 14, 1862 – February 6, 1918) was an Austrian symbolist painter and one of the most prominent members of the Vienna Secession movement. Klimt is noted for his paintings, murals, sketches, and other objets d'art. Klimt's primary subject was the female body, and his works are marked by a frank eroticism. In addition to his figurative works, which include allegories and portraits, he painted landscapes. Among the artists of the Vienna Secession, Klimt was the most influenced by Japanese art and its methods.
Early in his artistic career, he was a successful painter of architectural decorations in a conventional manner. As he developed a more personal style, his work was the subject of controversy that culminated when the paintings he completed around 1900 for the ceiling of the Great Hall of the University of Vienna were criticized as pornographic. He subsequently accepted no more public commissions, but achieved a new success with the paintings of his "golden phase," many of which include gold leaf. Klimt's work was an important influence on his younger contemporary Egon Schiele.
Life and work.
Early life and education.
Gustav Klimt was born in Baumgarten, near Vienna in Austria-Hungary, the second of seven children—three boys and four girls. His mother, Anna Klimt ("née" Finster), had an unrealized ambition to be a musical performer. His father, Ernst Klimt the Elder, formerly from Bohemia, was a gold engraver. All three of their sons displayed artistic talent early on. Klimt's younger brothers were Ernst Klimt and Georg Klimt.
Klimt lived in poverty while attending the Vienna School of Arts and Crafts ("Kunstgewerbeschule"), where he studied architectural painting until 1883. He revered Vienna's foremost history painter of the time, Hans Makart. Klimt readily accepted the principles of a conservative training; his early work may be classified as academic. In 1877 his brother, Ernst, who, like his father, would become an engraver, also enrolled in the school. The two brothers and their friend, Franz Matsch, began working together and by 1880 they had received numerous commissions as a team that they called the "Company of Artists". They also helped their teacher in painting murals in the Kunsthistorisches Museum in Vienna. Klimt began his professional career painting interior murals and ceilings in large public buildings on the Ringstraße, including a successful series of "Allegories and Emblems".
In 1888 Klimt received the Golden Order of Merit from Emperor Franz Josef I of Austria for his contributions to murals painted in the Burgtheater in Vienna. He also became an honorary member of the University of Munich and the University of Vienna. In 1892 Klimt's father and brother Ernst both died, and he had to assume financial responsibility for his father's and brother's families. The tragedies also affected his artistic vision and soon he would move towards a new personal style. 
Characteristic of his style at the end of the 19th century is the inclusion of "Nuda Veritas" ("nude truth") as a symbolic figure in some of his works, including "Ancient Greece and Egypt" (1891), "Pallas Athene" (1898) and "Nuda Veritas" (1899). Historians believe that Klimt with the "nuda veritas" denounced both the policy of the Habsburgs and the Austrian society, which ignored all political and social problems of that time. 
In the early 1890s Klimt met Emilie Louise Flöge (a sibling of his sister-in-law) who was to be his companion until the end of his life. His painting, The Kiss (1907–08), is thought to be an image of them as lovers. He designed many costumes she created and modeled in his works.
During this period Klimt fathered at least fourteen children.
Vienna secession years.
Klimt became one of the founding members and president of the "Wiener Sezession" (Vienna Secession) in 1897 and of the group's periodical, "Ver Sacrum" ("Sacred Spring"). He remained with the Secession until 1908. The goals of the group were to provide exhibitions for unconventional young artists, to bring the works of the best foreign artists to Vienna, and to publish its own magazine to showcase the work of members. The group declared no manifesto and did not set out to encourage any particular style—Naturalists, Realists, and Symbolists all coexisted. The government supported their efforts and gave them a lease on public land to erect an exhibition hall. The group's symbol was Pallas Athena, the Greek goddess of just causes, wisdom, and the arts—of whom Klimt painted his radical version in 1898.
In 1894, Klimt was commissioned to create three paintings to decorate the ceiling of the Great Hall of the University of Vienna. Not completed until the turn of the century, his three paintings, "Philosophy", "Medicine", and "Jurisprudence" were criticized for their radical themes and material, and were called "pornographic". Klimt had transformed traditional allegory and symbolism into a new language that was more overtly sexual and hence more disturbing to some. The public outcry came from all quarters—political, aesthetic and religious. As a result, the paintings "(seen in gallery below)" were not displayed on the ceiling of the Great Hall. This would be the last public commission accepted by the artist.
All three paintings were destroyed by retreating SS forces in May 1945.
His "Nuda Veritas" (1899) defined his bid to further "shake up" the establishment. The starkly naked red-headed woman holds the mirror of truth, while above her is a quotation by Friedrich Schiller in stylized lettering, ""If you cannot please everyone with your deeds and your art, please only a few. To please many is bad.""
In 1902, Klimt finished the Beethoven Frieze for the Fourteenth Vienna Secessionist exhibition, which was intended to be a celebration of the composer and featured a monumental polychrome sculpture by Max Klinger. Intended for the exhibition only, the frieze was painted directly on the walls with light materials. After the exhibition the painting was preserved, although it was not displayed again until 1986. The face on the Beethoven portrait resembled the composer and Vienna Court Opera director Gustav Mahler.
During this period Klimt did not confine himself to public commissions. Beginning in the late 1890s he took annual summer holidays with the Flöge family on the shores of Attersee and painted many of his landscapes there. These landscapes constitute the only genre aside from figure painting that seriously interested Klimt. In recognition of his intensity, the locals called him Waldschrat ("Forest demon").
Klimt's Attersee paintings are of sufficient number and quality as to merit separate appreciation. Formally, the landscapes are characterized by the same refinement of design and emphatic patterning as the figural pieces. Deep space in the Attersee works is flattened so efficiently to a single plane, that it is believed that Klimt painted them by using a telescope.
Golden phase and critical success.
Klimt's 'Golden Phase' was marked by positive critical reaction and financial success. Many of his paintings from this period included gold leaf. Klimt had previously used gold in his "Pallas Athene" (1898) and "Judith I" (1901), although the works most popularly associated with this period are the "Portrait of Adele Bloch-Bauer I" (1907) and "The Kiss" (1907–08).
Klimt travelled little, but trips to Venice and Ravenna, both famous for their beautiful mosaics, most likely inspired his gold technique and his Byzantine imagery. In 1904, he collaborated with other artists on the lavish Palais Stoclet, the home of a wealthy Belgian industrialist that was one of the grandest monuments of the Art Nouveau age. Klimt's contributions to the dining room, including both "Fulfillment" and "Expectation", were some of his finest decorative works, and as he publicly stated, "probably the ultimate stage of my development of ornament."
In 1905, Klimt created a painted portrait of Margarete Wittgenstein, Ludwig Wittgenstein's sister, on the occasion of her marriage. Then, between 1907 and 1909, Klimt painted five canvases of society women wrapped in fur. His apparent love of costume is expressed in the many photographs of Flöge modeling clothing he had designed.
As he worked and relaxed in his home, Klimt normally wore sandals and a long robe with no undergarments. His simple life was somewhat cloistered, devoted to his art, family, and little else except the Secessionist Movement. He avoided café society and seldom socialized with other artists. Klimt's fame usually brought patrons to his door and he could afford to be highly selective. His painting method was very deliberate and painstaking at times and he required lengthy sittings by his subjects. Although very active sexually, he kept his affairs discreet and he avoided personal scandal.
Klimt wrote little about his vision or his methods. He wrote mostly postcards to Flöge and kept no diary. In a rare writing called "Commentary on a non-existent self-portrait", he states "I have never painted a self-portrait. I am less interested in myself as a subject for a painting than I am in other people, above all women... There is nothing special about me. I am a painter who paints day after day from morning to night... Who ever wants to know something about me... ought to look carefully at my pictures."
In 1901 Herman Bahr wrote, in his "Speech on Klimt": "Just as only a lover can reveal to a man what life means to him and develop its innermost significance, I feel the same about these paintings."
Later life and posthumous success.
In 1911 his painting "Death and Life" received first prize in the world exhibitions in Rome. In 1915 Anna, his mother, died. Klimt died three years later in Vienna on February 6, 1918, having suffered a stroke and pneumonia due to the influenza epidemic of that year. He was buried at the Hietzinger Cemetery in Hietzing, Vienna. Numerous paintings by him were left unfinished.
Klimt's paintings have brought some of the highest prices recorded for individual works of art. In November 2003, Klimt's "Landhaus am Attersee" sold for $29,128,000, but that sale was soon eclipsed by prices paid for other Klimts.
In 2006, the 1907 portrait, "Adele Bloch-Bauer I", was purchased for the Neue Galerie New York by Ronald Lauder reportedly for US $135 million, surpassing Picasso's 1905 "Boy With a Pipe" (sold May 5, 2004 for $104 million), as the highest reported price ever paid for a painting.
On August 7, 2006, Christie's auction house announced it was handling the sale of the remaining four works by Klimt that were recovered by Maria Altmann and her co-heirs after their long legal battle against Austria (see Republic of Austria v. Altmann). Her struggle became the subject of the film the "Woman in Gold", a movie inspired by "Stealing Klimt", the documentary featuring Maria Altmann herself. The portrait of Adele Bloch-Bauer II was sold at auction in November 2006 for $88 million, the third-highest priced piece of art at auction at the time. "The Apple Tree I" (ca. 1912) sold for $33 million, "Birch Forest" (1903) sold for $40.3 million, and "Houses in Unterach on Lake Atter" (1916) sold for $31 million. Collectively, the five restituted paintings netted more than $327 million. The painting "Litzlberg am Attersee" was auctioned for $40.4 million at Sotheby's in November 2011.
The city of Vienna, Austria had many special exhibitions commemorating the 150th anniversary of Klimt's birth in 2012.
Folios.
Gustav Klimt: "Das Werk".
The only folio set produced in Klimt's lifetime, "Das Werk Gustav Klimts", was published initially by H. O. Miethke (of Gallerie Miethke, Klimt's exclusive gallery in Vienna) from 1908 to 1914 in an edition of 300, supervised personally by the artist. Fifty images depicting Klimt's most important paintings (1893–1913) were reproduced using collotype lithography and mounted on a heavy, cream-colored wove paper with deckled edges. Thirty-one of the images (ten of which are multicolored) are printed on "Chine-collé". The remaining nineteen are high quality halftones prints. Each piece was marked with a unique signet—designed by Klimt—which was impressed into the wove paper in gold metallic ink. The prints were issued in groups of ten to subscribers, in unbound black paper folders embossed with Klimt's name. Because of the delicate nature of collotype lithography, as well as the necessity for multicolored prints (a feat difficult to reproduce with collotypes), and Klimt's own desire for perfection, the series that was published in mid-1908 was not completed until 1914.
Each of the fifty prints was categorized among five themes:
The monochrome collotypes as well as the halftone works were printed with a variety of colored inks ranging from sepia to blue and green. Emperor Franz Joseph I of Austria was the first to purchase a folio set of "Das Werk Gustav Klimts" in 1908.
"Fünfundzwanzig Handzeichnungen".
"Fünfundzwanzig Handzeichnungen" ("Twenty-five Drawings") was released the year after Klimt's death. Many of the drawings in the collection were erotic in nature and just as polarizing as his painted works. Published in Vienna in 1919 by Gilhofer & Ranschburg, the edition of 500 features twenty-five monochrome and two-color collotype reproductions, nearly indistinguishable from the original works. While the set was released a year after Klimt's death, some art historians suspect he was involved with production planning due to the meticulous nature of the printing (Klimt had overseen the production of the plates for "Das Werk Gustav Klimts", making sure each one was to his exact specifications, a level of quality carried through similarly in "Fünfundzwanzig Handzeichnungen"). The first ten editions also each contained an original Klimt drawing.
Many of the works contained in this volume depict erotic scenes of nude women, some of whom are masturbating alone or are coupled in sapphic embraces. When a number of the original drawings were exhibited to the public, at Gallerie Miethke in 1910 and the International Exhibition of Prints and Drawings in Vienna in 1913, they were met by critics and viewers who were hostile towards Klimt's contemporary perspective. There was an audience for Klimt's erotic drawings, however, and fifteen of his drawings were selected by Viennese poet Franz Blei for his translation of Hellenistic satirist Lucian's "Dialogues of the Courteseans". The book, limited to 450 copies, provided Klimt the opportunity to show these more lurid depictions of women and avoided censorship thanks to an audience composed of a small group of (mostly male) affluent patrons.
"Gustav Klimt An Aftermath".
Composed in 1931 by editor Max Eisler and printed by the Austrian State Printing Office, "Gustav Klimt An Aftermath" was intended to complete the lifetime folio "Das Werk Gustav Klimts". The folio contains thirty colored collotypes (fourteen of which are multicolored) and follows a similar format found in "Das Werk Gustav Klimts", replacing the unique Klimt-designed signets with gold-debossed plate numbers. One hundred and fifty sets were produced in English, with twenty of them (Nos. I–XX) presented as a "gala edition" bound in gilt leather. The set contains detailed images from previously released works (Hygeia from the University Mural "Medicine", 1901; a section of the third University Mural "Jurisprudence", 1903), as well as the unfinished paintings ("Adam and Eve", "Bridal Progress").
Legacy.
Visual art.
According to the writer Frank Whitford: "Klimt of course, is an important artist—he's a very "popular" artist—but in terms of the history of art, he's a very unimportant artist. Although he sums up so much in his work, about the society in which he found himself—in art historical terms his effect was negligible. So he's an artist really in a cul-de-sac." Klimt's work had a strong influence on the paintings of Egon Schiele, with whom he would collaborate to found the "Kunsthalle" (Hall of Art) in 1917, to try to keep local artists from going abroad. Artists who reinterpreted Klimt's work include Slovak artist Rudolf Fila.
Cultural influence.
Writers who have been inspired by Klimt include the Romanian poet Sebastian Reichmann, who in 2008 published a book called "Mocheta lui Klimt" ("Klimt's Carpet"). As the author says in an interview, and in one of the poems from the book, the title was inspired by a carpet that reminded him of Klimt's paintings. The book's front cover depicts an Art Nouveau-styled passage from Bucharest.
South Korean novelist Kim Young-ha frequently refers to Klimt, particularly "Judith", in his first novel "I Have The Right To Destroy Myself". One of the main characters in this novel is referred to by the other characters as Judith because of her resemblance to Klimt's painting.
"Klimt" is a musical composition by Claudio Ottaviano Trio included in the album "Notturno" (NuomRecords 2013). 
Japanese rock band Buck-Tick based the cover artwork of their 2012 album, "Yume Miru Uchuu", on Klimt's "Gold Fish".
Several of Klimt's most famous works from his golden period inspired the title sequence for the animated adaptation of the manga series, "Elfen Lied", in which the art is recreated to fit with the series' own characters and is arranged as a montage with the song "Lilium". The opening to the anime "Sound of the Sky" also is largely inspired by Klimt's works, which was also directed by the same director as "Elfen Lied". The design of the land of Centopia on the TV series "Mia and Me" is inspired by Klimt's works. The art of the video game Transistor also uses patterns and embellishments inspired by Klimt.
Couturier John Galliano found inspiration for the Christian Dior Spring-Summer 2008 haute couture collection in Klimt's work.
Gustav Klimt and his work have been the subjects of many collector coins and medals, such as the 100 Euro Painting Gold Coin, issued on November 5, 2003, by the Austrian Mint. The obverse depicts Klimt in his studio with two unfinished paintings on easels.
Commemoration of 150th anniversary of birth.
In addition to the permanent exhibitions on display, the city of Vienna, Austria celebrated the 150th anniversary of the birth of Klimt with special exhibitions throughout the city. Guided walking tours through the city allowed people to see some of the buildings where Klimt worked.
Google commemorated Gustav Klimt with a Google doodle celebrating Klimt's painting "The Kiss" on his 150th birthday, 14 July 2012.
In 2012, the Austrian Mint began a five-coin gold series to coincide with the 150th anniversary of Klimt's birth. The first 50 Euro gold coin was issued on January 25, 2012 and featured a portrait of Klimt on the obverse and a portion of his painting of Adele Bloch-Bauer.
Gustav Klimt Foundation.
In 2013, the Gustav Klimt Foundation was set up by Ursula Ucicky, widow of Klimt's illegitimate son Gustav Ucicky, with a mission to "preserve and disseminate Gustav Klimt's legacy." The managing director of the Leopold Museum, Peter Weinhäupl, was appointed as Chairman of the foundation. As a reaction, the museum's director Tobias G. Natter resigned in protest, citing Ucicky's past as a Nazi propaganda film-maker.

</doc>
<doc id="12426" url="https://en.wikipedia.org/wiki?curid=12426" title="Groucho Marx">
Groucho Marx

Julius Henry Marx (October 2, 1890 – August 19, 1977), known professionally as Groucho Marx, was an American comedian and film and television star. He was known as a master of quick wit and is widely considered one of the best comedians of the modern era. His rapid-fire, often impromptu delivery of innuendo-laden patter earned him many admirers and imitators.
He made 13 feature films with his siblings the Marx Brothers, of whom he was the third-born. He also had a successful solo career, most notably as the host of the radio and television game show "You Bet Your Life".
His distinctive appearance, carried over from his days in vaudeville, included quirks such as an exaggerated stooped posture, glasses, cigar, and a thick greasepaint mustache and eyebrows. These exaggerated features resulted in the creation of one of the world's most ubiquitous and recognizable novelty disguises, known as "Groucho glasses": a one-piece mask consisting of horn-rimmed glasses, large plastic nose, bushy eyebrows and mustache.
Early life.
Julius Marx was born on October 2, 1890, in New York City, New York.
Marx stated that he was born in a room above a butcher's shop on East 78th Street in New York City, "Between Lexington & 3rd", as told to Dick Cavett in a 1969 television interview. The Marx children grew up on East 93rd Street off Lexington Avenue in a neighborhood now known as Carnegie Hill on the Upper East Side of the borough of Manhattan, in New York City. The turn-of-the-century building that his brother Harpo called "the first real home they ever knew" (in his memoir "Harpo Speaks") was populated with European immigrants, mostly artisans. Just across the street were the oldest brownstones in the area, owned by people such as the well-connected Loew Brothers and William Orth. The Marx family lived at this location "for about 14 years", Groucho also told Cavett.
Marx's family was Jewish. Groucho's mother was Miene "Minnie" Schoenberg, whose family came from Dornum in northern Germany when she was 16 years old. His father was Simon "Sam" Marx, who changed his name from Marrix, and was called "Frenchie" by his sons throughout his life because he and his family came from Alsace in France. Minnie's brother was Al Schoenberg, who shortened his name to Al Shean when he went into show business as half of Gallagher and Shean, a noted vaudeville act of the early 20th century. According to Groucho, when Shean visited he would throw the local waifs a few coins so that when he knocked at the door he would be surrounded by adoring fans. Marx and his brothers respected his opinions and asked him on several occasions to write some material for them.
Minnie Marx did not have an entertainment industry career but had intense ambition for her sons to go on the stage like their uncle. While pushing her eldest son Leonard (Chico Marx) in piano lessons she found that Julius had a pleasant soprano voice and the ability to remain on key. Julius's early career goal was to become a doctor, but the family's need for income forced him out of school at the age of twelve. By that time young Julius had become a voracious reader, particularly fond of Horatio Alger. Marx would continue to overcome his lack of formal education by becoming very well-read.
After a few stabs at entry-level office work and jobs suitable for adolescents, Julius took to the stage as a boy singer in 1905. Marx reputedly claimed that he was "hopelessly average" as a vaudevillian, but this was typically Marx, wisecracking in his true form. By 1909 Minnie Marx had assembled her sons into a forgettable-quality vaudeville singing group billed as "The Four Nightingales". The brothers Julius, Milton (Gummo Marx) and Arthur (originally Adolph, from 1911 Harpo Marx) and another boy singer, Lou Levy, traveled the U.S. vaudeville circuits to little fanfare. After exhausting their prospects in the East the family moved to La Grange, Illinois, to play the Midwest.
After a particularly dispiriting performance in Nacogdoches, Texas, Julius, Milton, and Arthur began cracking jokes onstage for their own amusement. Much to their surprise, the audience liked them better as comedians than as singers. They modified the then-popular Gus Edwards comedy skit "School Days" and renamed it "Fun In Hi Skule". The Marx Brothers would perform variations on this routine for the next seven years.
For a time in vaudeville all the brothers performed using ethnic accents. Leonard, the oldest, developed the Italian accent he used as Chico Marx to convince some roving bullies that he was Italian, not Jewish. Arthur, the next oldest, donned a curly red wig and became "Patsy Brannigan", a stereotypical Irish character. His discomfort speaking on stage led to his uncle Al Shean's suggestion that he stop speaking altogether and play the role in mime. Julius Marx's character from "Fun In Hi Skule" was an ethnic German, so Julius played him with a German accent. After the sinking of the in 1915, public anti-German sentiment was widespread, and Marx's German character was booed, so he quickly dropped the accent and developed the fast-talking wise-guy character that became his trademark.
The Marx Brothers became the biggest comedic stars of the Palace Theatre in New York City, which billed itself as the "Valhalla of Vaudeville". Brother Chico's deal-making skills resulted in three hit plays on Broadway. No comedy routine had ever so infected the Broadway circuit.
All of this predated their Hollywood career. By the time the Marxes made their first movie, they were major stars with sharply honed skills, and when Groucho was relaunched to stardom on "You Bet Your Life", he had already been performing successfully for half a century.
Career.
Hollywood.
Groucho Marx made 26 movies, 13 of them with his brothers Chico and Harpo. Marx developed a routine as a wisecracking hustler with a distinctive chicken-walking lope, an exaggerated greasepaint mustache and eyebrows, and an ever-present cigar, improvising insults to stuffy dowagers (often played by Margaret Dumont) and anyone else who stood in his way. As the Marx Brothers, he and his brothers starred in a series of popular stage shows and movies.
Their first movie was a silent film made in 1921 that was never released, and is believed to have been destroyed at the time. A decade later, the team made some of their Broadway hits into movies, including "The Cocoanuts" and "Animal Crackers". Other successful films were "Monkey Business", "Horse Feathers", "Duck Soup", and "A Night at the Opera". One quip from Marx concerned his response to Sam Wood, the director of "A Night at the Opera". Furious with the Marx Brothers' ad-libs and antics on the set, Wood yelled in disgust: "You can't make an actor out of clay." Groucho responded, "Nor a director out of Wood."
Marx also worked as a radio comedian and show host. One of his earliest stints was a short-lived series in 1932, "Flywheel, Shyster, and Flywheel," costarring Chico. Though most of the scripts and discs were thought to have been destroyed, all but one of the scripts were found in 1988 in the Library of Congress.
In 1947 Marx was asked to host a radio quiz program "You Bet Your Life." It was broadcast by ABC and then CBS before moving to NBC. It moved from radio to television on October 5, 1950 and ran for eleven years. Filmed before a live audience, the show consisted of Marx bantering with the contestants and ad-libbing jokes before briefly quizzing them. The show was responsible for popularizing the phrases "Say the secret woid and the duck will come down and give you fifty dollars," "Who's buried in Grant's Tomb?" and "What color is the White House?" (asked to reward a losing contestant a consolation prize).
Throughout his career he introduced a number of memorable songs in films, including "Hooray for Captain Spaulding" and "Hello, I Must Be Going", in "Animal Crackers", "Whatever It Is, I'm Against It", "Everyone Says I Love You" and "Lydia the Tattooed Lady". Frank Sinatra, who once quipped that the only thing he could do better than Marx was sing, made a film with Marx and Jane Russell in 1951 entitled "Double Dynamite".
Mustache, eyebrows, and walk.
In public and off-camera, Harpo and Chico were hard to recognize, without their wigs and costumes, but it was almost impossible for fans to recognize Groucho without his trademark eyeglasses, fake eyebrows, and mustache.
The greasepaint mustache and eyebrows originated spontaneously prior to a vaudeville performance in the early 1920s when he did not have time to apply the pasted-on mustache he had been using (or, according to his autobiography, simply did not enjoy the removal of the mustache every night because of the effects of tearing an adhesive bandage off the same patch of skin every night). After applying the greasepaint mustache, a quick glance in the mirror revealed his natural hair eyebrows were too undertoned and did not match the rest of his face, so Marx added the greasepaint to his eyebrows and headed for the stage. The absurdity of the greasepaint was never discussed on-screen, but in a famous scene in "Duck Soup," where both Chicolini (Chico) and Pinky (Harpo) disguise themselves as Groucho, they are briefly seen applying the greasepaint, implicitly answering any question a viewer might have had about where he got his mustache and eyebrows.
Marx was asked to apply the greasepaint mustache once more for "You Bet Your Life" when it came to television, but he refused, opting instead to grow a real one, which he wore for the rest of his life. By this time, his eyesight had weakened enough for him actually to need corrective lenses; before then, his eyeglasses had merely been a stage prop. He debuted this new, and now much-older, appearance in "Love Happy," the Marx Brothers's last film as a comedy team.
He did paint the old character mustache over his real one on a few rare performing occasions, including a TV sketch with Jackie Gleason on the latter's variety show in the 1960s (in which they performed a variation on the song "Mister Gallagher and Mister Shean," co-written by Marx's uncle Al Shean) and the 1968 Otto Preminger film "Skidoo". In his late 70s at the time, Marx remarked on his appearance: "I looked like I was embalmed." He played a mob boss called "God" and, according to Marx, "both my performance and the film were God-awful!"
The exaggerated walk, with one hand on the small of his back and his torso bent almost 90 degrees at the waist was a parody of a fad from the 1880s and 1890s. Fashionable young men of the upper classes would affect a walk with their right hand held fast to the base of their spines, and with a slight lean forward at the waist and a very slight twist toward the right with the left shoulder, allowing the left hand to swing free with the gait. (Edmund Morris, in his biography "The Rise of Theodore Roosevelt", describes a young Roosevelt, newly elected to the State Assembly, walking into the House Chamber for the first time in this trendy, affected gait, somewhat to the amusement of the older and more rural members.) Groucho exaggerated this fad to a marked degree, and the comedy effect was enhanced by how out of date the fashion was by the 1940s and 1950s.
Personal life.
Groucho's three marriages all ended in divorce. His first wife was chorus girl Ruth Johnson. He was 29 and she 19 at the time of their wedding. The couple had two children, Arthur Marx and Miriam Marx. His second wife was Kay Marvis (m. 1945–51), Catherine Dittig, former wife of Leo Gorcey. Groucho was 54 and Kay 21 at the time of their marriage. They had a daughter, Melinda Marx. His third wife was actress Eden Hartford. She was 24 when she married the 63-year-old Groucho.
During the early 1950s, Groucho described his perfect woman: “Someone who looks like Marilyn Monroe and talks like George S. Kaufman.”
Groucho was denied membership in an informal symphonietta of friends (including Harpo) organized by Ben Hecht, because he could play only the mandolin. When the group began its first rehearsal at Hecht's home, Groucho rushed in and demanded silence from the "lousy amateurs". The musicians discovered him conducting a recorded performance of "Tannhäuser" in Hecht's living room. Groucho was allowed to join the symphonietta.
Later in life, Groucho would sometimes note to talk show hosts, not entirely jokingly, that he was unable to actually insult anyone, because the target of his comment would assume that it was a Groucho-esque joke, and would laugh.
Despite his lack of formal education, he wrote many books, including his autobiography, "Groucho and Me" (1959) and "Memoirs of a Mangy Lover" (1963). He was a friend of such literary figures as T. S. Eliot and Carl Sandburg. Much of his personal correspondence with those and other figures is featured in the book "The Groucho Letters" (1967) with an introduction and commentary on the letters written by Groucho, who donated his letters to the Library of Congress.
Groucho made serious efforts to learn to play the guitar. In the 1932 film "Horse Feathers", Groucho performs the film’s love theme “Everyone Says I Love You” for costar Thelma Todd on a Gibson L-5.
Irving Berlin quipped, "The world would not be in such a snarl, had Marx been Groucho instead of Karl". In his book "The Groucho Phile", Marx says "I've been a liberal Democrat all my life", and "I frankly find Democrats a better, more sympathetic crowd... I'll continue to believe that Democrats have a greater regard for the common man than Republicans do". "Marx & Lennon: The Parallel Sayings" was published in 2005; the book records similar sayings between Groucho Marx and John Lennon.
Later years.
"You Bet Your Life".
Groucho's radio life was not as successful as his life on stage and in film, though historians such as Gerald Nachman and Michael Barson suggest that, in the case of the single-season "Flywheel, Shyster, and Flywheel" (1932), the failure may have been a combination of a poor time slot and the Marx Brothers' returning to Hollywood to make another film.
In the mid-1940s, during a depressing lull in his career (his radio show "Blue Ribbon Town" had failed, he failed to sell his proposed sitcom "The Flotsam Family" only to see it become a huge hit as "The Life of Riley" with William Bendix in the title role, and the Marx Brothers as film performers were well past their prime), Groucho was scheduled to appear on a radio show with Bob Hope. Annoyed that he was made to wait in the waiting room for 40 minutes, Groucho went on the air in a foul mood.
Hope started by saying "Why, it's Groucho Marx, ladies and gentlemen! ("applause") Groucho, what brings you here from the hot desert?" Groucho retorted, "Hot desert my foot, I've been standing in the cold waiting room for forty minutes!" Groucho continued to ignore the script, and although Hope was a formidable ad-libber in his own right, he could not begin to keep up with Groucho, who lengthened the scene well beyond its allotted time slot with a veritable onslaught of improvised wisecracks.
Listening in on the show was producer John Guedel, who had a brainstorm. He approached Groucho about doing a quiz show, to which Groucho derisively retorted, "A "quiz show"? Only actors who are completely washed up resort to a quiz show!" Undeterred, Guedel explained that the quiz would be only a backdrop for Groucho's interviews of people, and the storm of ad-libbing that they would elicit. Groucho said, "Well, I've had no success in radio, and I can't hold on to a sponsor. At this point, I'll try anything!"
"You Bet Your Life" debuted in October 1947 on radio on ABC (which aired it from 1947 to 1949), sponsored by costume jewelry manufacturer Allen Gellman; and then on CBS (1949–50), and finally NBC, continuing until May 1961—on radio only, 1947–1950; on both radio and television, 1950–1960; and on television only, 1960–1961. The show proved a huge hit, being one of the most popular on television by the mid-1950s. With George Fenneman as his announcer and straight man, Groucho entertained his audiences with improvised conversation with his guests. Since "You Bet Your Life" was mostly ad-libbed and unscripted—although writers did pre-interview the guests and feed Groucho ready-made lines in advance—the producers insisted that the network prerecord it (instead of it being broadcast live). There were two reasons for this: prerecording provided Groucho with time to fish around for funny exchanges and any intervening dead spots to be edited out; and secondly to protect the network, since Groucho was a notorious loose cannon and known to say almost anything. The television show ran for 11 successful seasons until it was canceled in 1961. Automobile "marque" DeSoto was a longtime major sponsor. For the DeSoto ads Marx would sometimes say: "Tell 'em Groucho sent you", or "Try a DeSoto before you decide".
The program's theme music was an instrumental version of "Hooray for Captain Spaulding", which became increasingly identified as Groucho's personal theme song. A recording of the song with Groucho and the Ken Lane singers with an orchestra directed by Victor Young was released in 1952. Another recording made by Groucho during this period was "The Funniest Song in the World", released on the Young People's Records label in 1949. It was a series of five original children's songs with a connecting narrative about a monkey and his fellow zoo creatures.
The show's most infamous remark supposedly occurred as Groucho was interviewing Charlotte Story, who had borne 19 children. When Marx asked why she had chosen to raise such a large family, Mrs. Story is said to have replied, "I love my husband"; to which Marx responded, "I love my cigar, but I take it out of my mouth once in awhile." The remark was judged too risqué to be aired, according to the anecdote, and was edited out before broadcast.
Marion and Charlotte Story—parents of 20 children, not 19—did in fact appear as contestants on the radio version of the show, in 1950. Audio recordings of the interview exist, and a reference to cigars is made ("With each new kid, do you go around passing out cigars?"), but there is no evidence of the famous line. Marx and Fenneman both denied that the incident took place. In a 1972 "Esquire" interview, Marx told Roger Ebert, "I never said that." Marx's 1976 memoir recounts the episode as fact, but co-writer Hector Arce relied mostly on sources other than Marx himself — who was by then in his mid eighties and mentally compromised — and was probably unaware that Marx had specifically denied making the legendary observation.
Other work.
By the time "You Bet Your Life" debuted on TV on October 5, 1950, Groucho had grown a real mustache (which he had already sported earlier in the films "Copacabana" and "Love Happy").
During a tour of Germany in 1958, accompanied by then-wife Eden, daughter Melinda, Robert Dwan and Dwan's daughter Judith, he climbed a pile of rubble that marked the site of Adolf Hitler's bunker, the site of Hitler's death, and performed a two-minute Charleston. He later remarked to Richard J. Anobile in "The Marx Brothers Scrapbook," "Not much satisfaction after he killed six million Jews!"
In 1960, Groucho, a lifelong devotee of the comic operas of Gilbert and Sullivan, appeared as Koko the Lord High Executioner in a televised production of "The Mikado" on NBC's "Bell Telephone Hour". A clip of this is in rotation on Classic Arts Showcase.
Another TV show, "Tell It To Groucho", premiered January 11, 1962 on CBS, but only lasted five months. On October 1, 1962, Groucho, after acting as occasional guest host of "The Tonight Show" during the six-month interval between Jack Paar and Johnny Carson, introduced Carson as the new host. In 1965, a weekly show for British TV titled "Groucho" was poorly received and lasted only 11 weeks.
In 1964, Marx starred in the "Time for Elizabeth" episode of "Bob Hope Presents the Chrysler Theatre", a truncated version of a play that Groucho Marx and Norman Krasna wrote in 1948.
Groucho appeared as a gangster named God in the movie "Skidoo" (1968), directed by Otto Preminger, and costarring Jackie Gleason and Carol Channing. It was released by the studio where the Marx Brothers began their film career, Paramount Pictures. The film received almost universally negative reviews. As a side note, writer Paul Krassner published a story in the February 1981 issue of "High Times", relating how Groucho prepared for the LSD-themed movie by taking a dose of the drug in Krassner's company, and had a moving, largely pleasant experience. Four years later came Groucho's last theatrical film appearance, a brief, uncredited cameo in Michael Ritchie's "The Candidate" (1972).
Groucho developed friendships with rock star Alice Cooper—the two were photographed together for "Rolling Stone" magazine—and television host Dick Cavett, becoming a frequent guest on Cavett's late-night talk show, even appearing in a one-man, 90-minute interview. He befriended Elton John when the British singer was staying in California in 1972, insisting on calling him "John Elton." According to writer Philip Norman, when Groucho jokingly pointed his index fingers as if holding a pair of six-shooters, Elton John put up his hands and said, "Don't shoot me, I'm only the piano player," thereby naming the album he had just completed. A film poster for the Marx Bros. movie "Go West" is visible on the album cover photograph as an homage to Groucho. Elton John accompanied Groucho to a performance of "Jesus Christ Superstar". As the lights went down, Groucho called out, "Does it have a happy ending?" And during the Crucifixion scene, he declared, "This is sure to offend the Jews."
Groucho's previous work regained popularity; new books of transcribed conversations were published by Richard J. Anobile and Charlotte Chandler. In a BBC interview in 1975, Groucho called his greatest achievement having a book selected for cultural preservation in the Library of Congress. As a man who never had formal schooling, to have his writings declared culturally important was a point of great satisfaction. As he passed his 81st birthday in 1971, however, Groucho became increasingly frail, physically and mentally, as a result of a succession of minor strokes. 
In 1972, largely at the behest of his companion Erin Fleming, Groucho staged a live one-man show at Carnegie Hall that was later released as a double album, "An Evening with Groucho", on A&M Records. He also made an appearance in 1973 on a short-lived variety show hosted by Bill Cosby. Fleming's influence on Marx was controversial. Some close to Marx believed that she did much to revive his popularity, and the relationship with a younger woman boosted his ego and vitality. Others described her as a Svengali, exploiting an increasingly senile Marx in pursuit of her own stardom. Marx's children, particularly Arthur, felt strongly that Fleming was pushing their weak father beyond his physical and mental limits. Writer Mark Evanier concurred.
On the 1974 Academy Awards telecast, Marx's final major public appearance, Jack Lemmon presented him with an honorary Academy Award to a standing ovation. Noticeably frail, Groucho took a bow for his deceased brothers. "I wish that Harpo and Chico could be here to share with me this great honor," he said. He also praised the late Margaret Dumont as a great straight woman who never understood any of his jokes. Groucho's final appearance was a brief sketch with George Burns in the Bob Hope television special "Joys" in 1976. His health continued to decline the following year; he was never told of his brother Gummo's death, at age 84 on April 21, 1977, for fear of eliciting still further deterioration.
Groucho maintained his irrepressible sense of humor to the very end, however. When a nurse approached him with a thermometer during his final hospitalization, explaining that she wanted to see if he had a temperature, he responded, "Don't be silly—everybody has a temperature." George Fenneman, his radio and TV announcer, good-natured foil, and lifelong friend, often related a story of one of his final visits to Groucho's home: When the time came to end the visit, Fenneman lifted Groucho from his wheelchair, put his arms around his torso, and began to "walk" the frail comedian backwards across the room towards his bed. As he did, he heard a weak voice in his ear: "Fenneman," whispered Groucho, "you always were a lousy dancer." Actor Elliott Gould recalled a similar incident: "I was privileged to be Groucho Marx’s friend in his latter days," he said. "And I recall the last time I saw Groucho, he was in the hospital, and he had tubes in his nose and what have you. And when he saw me, he was weak, but he was there; and he put his fingers on the tubes and played them like it was a clarinet. Groucho played the tubes for me, which brings me to tears."
Death.
Marx was hospitalized at Cedars-Sinai Medical Center with pneumonia on June 22, 1977 and died at the age of 86 on August 19, four months after Gummo.
Marx was cremated and the ashes were interred in the Eden Memorial Park Cemetery in Los Angeles. Groucho had the longest lifespan of all the Marx Brothers and was survived by his children and younger brother Zeppo, who outlived him by two years. His death was somewhat overshadowed by the death of Elvis Presley, three days earlier. His gravestone bears no epitaph; but in one of his last interviews, he suggested one: "Excuse me, I can't stand up."
Protracted court battles over the disposition of his estate lasted well into the 1980s. Eventually, Arthur Marx was awarded the bulk of the estate's assets, and Fleming was ordered to repay $472,000. Fleming died of a self-inflicted gunshot wound in 2003.
Legacy.
Groucho Marx was, and remains, the most recognizable and well-known of the Marx Brothers. Groucho-like characters and references have appeared in popular culture both during and after his life, some aimed at audiences who may never have seen a Marx Brothers movie. Groucho's trademark eyeglasses, nose, mustache, and cigar have become icons of comedy—glasses with fake noses and mustaches (referred to as "Groucho glasses", "nose-glasses," and other names) are sold by novelty and costume shops around the world.
Nat Perrin, close friend of Groucho Marx and writer of several Marx Brothers films, inspired John Astin's portrayal of Gomez Addams on the 1960s TV series "The Addams Family" with similarly thick mustache, eyebrows, sardonic remarks, backward logic, and ever-present cigar (pulled from his breast pocket already lit).
Two albums by British rock band Queen, "A Night at the Opera" (1975) and "A Day at the Races" (1976), are named after Marx Brothers films. In March 1977, Groucho invited Queen to visit him in his Los Angeles home; there they performed "'39" a cappella. A long-running ad campaign for Vlasic Pickles features an animated stork that imitates Groucho's mannerisms and voice. On the famous Hollywood Sign in California, one of the "O"s is dedicated to Groucho. Alice Cooper contributed over $27,000 to remodel the sign, in memory of his friend.
Actor Frank Ferrante has performed as Groucho Marx on stage for more than two decades. He continues to tour under rights granted by the Marx family in a show entitled "An Evening with Groucho" in theaters throughout the United States and Canada with supporting actors and piano accompanist Jim Furmston. In the late 1980s Ferrante starred as Groucho in the off-Broadway and London show "" penned by Groucho's son Arthur. Ferrante portrayed the comedian from age 15 to 85. The show was later filmed for PBS in 2001. In 1982, Gabe Kaplan filmed a version of the same show, entitled "Groucho".
Woody Allen's 1996 musical "Everyone Says I Love You", in addition to being named for one of Groucho's signature songs, ends with a Groucho-themed New Year's Eve party in Paris, which some of the stars, including Allen and Goldie Hawn, attend in full Groucho costume. The highlight of the scene is an ensemble song-and-dance performance of "Hooray for Captain Spaulding"—done entirely in French.
The BBC remade the radio sitcom "Flywheel, Shyster, and Flywheel", with contemporary actors playing the parts of the original cast. The series was repeated on digital radio station BBC7. Scottish playwright Louise Oliver wrote a play named "Waiting for Groucho" about Chico and Harpo waiting for Groucho to turn up for the filming of their last project together. This was performed by Glasgow theatre company Rhymes with Purple Productions at the Edinburgh Fringe and in Glasgow and Hamilton in 2007–08. Groucho was played by Scottish actor Frodo McDaniel.

</doc>
<doc id="12430" url="https://en.wikipedia.org/wiki?curid=12430" title="Game Boy Advance">
Game Boy Advance

The , often shortened to GBA, is a 32-bit handheld video game console developed, manufactured and marketed by Nintendo. It is the successor to the Game Boy Color. It was released in Japan on March 21, 2001; in North America on June 11, 2001; in Australia and Europe on June 22, 2001; and in the People's Republic of China on June 8, 2004 (excluding Hong Kong).
Nintendo's competitors in the handheld market were the Neo Geo Pocket Color, WonderSwan, GP32, Tapwave Zodiac, and the N-Gage. Despite the competitors' best efforts, Nintendo maintained a majority market share with the Game Boy Advance.
As of June 30, 2010, the Game Boy Advance series has sold 81.51 million units worldwide. Its successor, the Nintendo DS, was released in November 2004.
History.
Contrary to the previous Game Boy models, which were all following the "portrait" form factor of the original Game Boy (designed by Gunpei Yokoi), the Game Boy Advance was designed in a "landscape" form factor, putting the buttons to the sides of the device instead of below the screen. The Game Boy Advance was designed by the French designer Gwénaël Nicolas and his Tokyo-based design studio Curiosity Inc.
Project Atlantis.
In 1996, magazines including "Electronic Gaming Monthly", issues 53 and 54 of "Total!" and the July 1996 issue of "Game Informer" featured reports of a new Game Boy, codenamed Project Atlantis. Although the expected release date of "early 1997" would make that machine seem to be the Game Boy Color, it was described as having a 32-bit RISC processor, a 3-by-2-inch color LCD screen, and a link port—a description that more closely matches the Game Boy Advance. It also may have referred to the unnamed, unreleased Game Boy Color successor prototype that was revealed at 2009's Game Developers Conference. It was announced that Nintendo Co., Ltd. (NCL) was working on a game for the system called "Mario's Castle".
Technical specifications.
The technical specifications of the original Game Boy Advance are, as provided by Nintendo:
Backward compatibility for Game Boy and Game Boy Color games is provided by an 4/8 MHz Z80 coprocessor (Game Boy Advance software can use the audio tone generators to supplement the primary sound system), while a link port at the top of the unit allows it to be connected to other devices via use of a Nintendo Game Link cable or GameCube link cable. When playing Game Boy or Game Boy Color games on the Game Boy Advance, the L and R buttons can be used to toggle between a stretched widescreen format and the original screen ratio of the Game Boy . Game Boy games can be played using the same selectable color palettes as on the Game Boy Color.
Every Nintendo handheld system following the release of the Game Boy Advance SP has included a built-in light and rechargeable battery.
The Game Boy Advance and Nintendo DS 2D graphics hardware have scaling and rotation for traditional tiled backgrounds in its modes 1 and 2 and scaling and rotation for bitmaps in modes 3 through 5 (used less often on the GBA because of technical limitations). On each machine supporting this effect, to draw a flat plane in a perspective projection. More complex effects such as fuzz are possible by using other equations for the position, scaling, and rotation of each line.
Games.
With hardware comparable to the Super NES, the Game Boy Advance represents progress for sprite-based technology. The Game Boy Advance has platformers, SNES-style role-playing video games, and classic games ported from various 8-bit and 16-bit systems of the previous generations. This includes the "Super Mario Advance" series, as well as the system's backward compatibility with all earlier Game Boy titles.
"Final Fantasy VI Advance" was the final licensed Japanese GBA game release. Released November 2006, it was the final Nintendo-published game for the system. "" was the final European GBA game, released November 2007. "Samurai Deeper Kyo" was the final North American GBA game, released in February 2008.
Accessories.
Official.
Nintendo released many addons for the Game Boy Advance. These include:
Unofficial.
Other accessories for the Game Boy Advance are:
Emulation.
Due to its simple hardware, many popular emulators are available for the Game Boy Advance, such as VisualBoyAdvance and NO$GBA.
Revisions.
Game Boy Advance SP.
In early 2003, Nintendo introduced a new form-factor for the handheld, known as the Game Boy Advance SP (model AGS-001). The redesigned unit resembles a pocket-size laptop computer, including a folding case approximately one-half the size of the original unit. It also supports a rechargeable lithium ion battery, a significantly brighter LCD screen, and an internal front-light that can be toggled on and off. The redesign was intended to address some common complaints about the original Game Boy Advance, which had been criticized for being somewhat uncomfortable to use, especially due to an overly dark screen.
Around the same time as the release of the Game Boy Micro, Nintendo released a new backlit version of the SP (model AGS-101) in North America (commonly referred to as the "GBA SP+", SPII, or SP2). The switch that controls the light now toggles between "normal" (which itself is already brighter than the original Game Boy Advance SP's screen), and "bright", an intense brightness level similar to an LCD television set.
Game Boy Micro.
In September 2005, Nintendo released a second redesign of the Game Boy Advance. This model, dubbed the Game Boy Micro, is similar in style to the original Game Boy Advance's horizontal orientation, but is much smaller and sleeker. The Game Boy Micro also allows the user to switch between several colored faceplates to allow customization, a feature which Nintendo advertised heavily around the Game Boy Micro's launch. Nintendo also hoped that this "fashion" feature would help target audiences outside of typical video game players. Unlike the previous Game Boy Advance models, Game Boy Micro is unable to support Game Boy and Game Boy Color titles. The Game Boy Micro did not make much of an impact in the video game market as it was overshadowed by Nintendo's other portable, the Nintendo DS.
Unit colors.
The Game Boy Advance, SP, and Micro had numerous colors and limited editions.
Game Boy Advance.
The Game Boy Advance was initially available in Arctic, Black, Orange, Fuchsia, Glacier (translucent blue/purple) and Indigo. Later in the system's availability, additional colours and special editions were released. These editions include: Red, Clear Orange/Black, Platinum, White, Gold, Hello Kitty edition (pink with Hello Kitty and logo on bezel), King of Fighters edition (black with images on bezel and buttons), Chobits edition (translucent light blue, with images on bezel and buttons), Battle Network Rockman EXE 2 (light blue with images on bezel), Mario Bros. edition (Glacier with Mario and Luigi on bezel) and Yumiuri Giant edition (Glacier with images on bezel).
A number of Pokémon-themed limited-edition systems were made available in Pokémon Center stores in Japan. These editions include: Gold Pokémon edition (Gold with Pikachu and Pichu on bezel), Suicune edition (blue/grey with greyscale Pikachu and Pichu on bezel, and a Pokémon Center sticker on the back), Celebi edition (olive green with Celebi images on bezel), and Latias/Latios edition (pink/red and purple, with images of Latias and Latios on bezel).
Sales.
On December 1, 2006, Nintendo of America released launch-to-date information indicating that the company had sold 33.6 million units of the Game Boy Advance series in the United States. In a Kotaku article published on January 18, 2008, Nintendo revealed that the Game Boy Advance series has sold 36.2 million units in the United States, as of January 1, 2008. As of December 31, 2009, the Game Boy Advance series has sold 81.51 million units worldwide, of which 43.57 million are Game Boy Advance SP units and 2.42 million are Game Boy Micro units.
After the Game Boy Advance's support lessened, the most popular software became mostly games oriented to younger gamers.
Legacy.
Nintendo did not initially release GBA games for the Nintendo 3DS Virtual Console, but later made ten titles available to the platform as part of the Nintendo 3DS Ambassador Program. Regardless of this, no plans have been made to release the games to the general public. Satoru Iwata stated Game Boy Advance games will be available on the Wii U Virtual Console during April 2014. On April 3, 2014, the first of the announced GBA games ("Advance Wars", "Metroid Fusion" and "") were released for the Wii U Virtual Console.

</doc>
<doc id="12431" url="https://en.wikipedia.org/wiki?curid=12431" title="Google Search">
Google Search

Google Search, commonly referred to as Google Web Search or Google, is a web search engine owned by Google Inc. It is the most-used search engine on the World Wide Web, handling more than three billion searches each day. it is the most used search engine in the US with 64.5% market share.
The order of search on Google's search-results pages is based, in part, on a priority rank called a "PageRank". Google Search provides many different options for customized search, using Boolean operators such as: exclusion ("-xx"), alternatives ("xx OR yy OR zz"), and wildcards ("Winston * Churchill" returns "Winston Churchill", "Winston Spencer Churchill", etc.). The same and other options can be specified in a different way on an Advanced Search page.
The main purpose of Google Search is to hunt for text in publicly accessible documents offered by web servers, as opposed to other data, such as images or data contained in databases. It was originally developed by Larry Page and Sergey Brin in 1997. Google Search provides several features beyond searching for words. These include synonyms, weather forecasts, time zones, stock quotes, maps, earthquake data, movie showtimes, airports, home listings, and sports scores. There are special features for numbers, dates, and some specific forms, including ranges, prices, temperatures, money and measurement unit conversions, calculations, package tracking, patents, area codes, and language translation. In June 2011 Google introduced "Google Voice Search" to search for spoken, rather than typed, words. In May 2012 Google introduced a Knowledge Graph semantic search feature in the U.S.
Analysis of the frequency of search terms may indicate economic, social and health trends. Data about the frequency of use of search terms on Google can be openly inquired via Google Trends and have been shown to correlate with flu outbreaks and unemployment levels, and provide the information faster than traditional reporting methods and surveys.
Competitors of Google include Baidu and Soso.com in China; Naver.com and Daum.net in South Korea; Yandex in Russia; Seznam.cz in the Czech Republic; Yahoo! in Japan, Taiwan and the US, as well as Bing and DuckDuckGo. Some smaller search engines offer facilities not available with Google, e.g. not storing any private or tracking information; one such search engine is Ixquick.
Search.
PageRank.
In a potential hint of Google's future direction for their Search algorithm, Eric Schmidt, Google's then chief executive, said in a 2007 interview with the "Financial Times": "The goal is to enable Google users to be able to ask the question such as 'What shall I do tomorrow?' and 'What job shall I take?'". Schmidt reaffirmed this during a 2010 interview with the Wall Street Journal: "I actually think most people don't want Google to answer their questions, they want Google to tell them what they should be doing next."
In 2013 the European Commission found that Google Search favored Google's own products, instead of offering consumers the best result for their needs. In February 2015 Google announced a major change to its mobile search algorithm which would favor mobile friendly over other websites. Nearly 60% of Google's online search traffic comes from mobile phones. Google wants its users to have access to premium quality websites. Those websites which lack a mobile friendly interface would be demoted and it is expected that this update will cause a shake-up of ranks. Businesses who fail to update their websites accordingly could see a dip in their regular websites traffic.
Search products.
The exact percentage of the total of web pages that Google indexes is not known, as it is very difficult to accurately calculate. Google presents a two-line summary and also a preview of each search result, which includes a link to a cached (stored), usually older version of the page.
Google's cache link in its search results provides a way of retrieving information from websites that have recently gone down and a way of retrieving data more quickly than by clicking the direct link. This feature is still available, but many users are not aware of this because it has been moved to the previews of the search results presented next to these.
Google not only indexes and caches web pages, but also takes "snapshots" of other file types, which include PDF, Word documents, Excel spreadsheets, Flash SWF, plain text files, and so on. Except in the case of text and SWF files, the cached version is a conversion to (X)HTML, allowing those without the corresponding viewer application to read the file. Users can customize the search engine, by setting a default language, using the "SafeSearch" filtering technology and set the number of results shown on each page. Google has been criticized for placing long-term cookies on users' machines to store these preferences, a tactic which also enables them to track a user's search terms and retain the data for more than a year. For any query, up to the first 1000 results can be shown with a maximum of 100 displayed per page. The ability to specify the number of results is available only if "Instant Search" is not enabled. If "Instant Search" is enabled, only 10 results are displayed, regardless of this setting.
In 2012, Google changed its rankings to demote sites that had been accused of piracy, except the Google-owned YouTube site.
Non-indexable data.
Despite its immense index, there is also a considerable amount of data available in online databases which are accessible by means of queries but not by links. This so-called invisible or deep Web is minimally covered by Google and other search engines. The deep Web contains library catalogs, official legislative documents of governments, phone books, and other content which is dynamically prepared to respond to a query.
Google optimization.
Because Google is the most popular search engine, many webmasters have become eager to influence their website's Google rankings. An industry of consultants has arisen to help websites increase their rankings on Google and on other search engines. This field, called search engine optimization, attempts to discern patterns in search engine listings, and then develop a methodology for improving rankings to draw more searchers to their client's sites. Search engine optimization encompasses both "on page" factors (like body copy, title elements, H1 heading elements and image alt attribute values) and Off Page Optimization factors (like anchor text and PageRank). The general idea is to affect Google's relevance algorithm by incorporating the keywords being targeted in various places "on page", in particular the title element and the body copy (note: the higher up in the page, presumably the better its keyword prominence and thus the ranking). Too many occurrences of the keyword, however, cause the page to look suspect to Google's spam checking algorithms. Google has published guidelines for website owners who would like to raise their rankings when using legitimate optimization consultants. It has been hypothesized, and, allegedly, is the opinion of the owner of one business about which there have been numerous complaints, that negative publicity, for example, numerous consumer complaints, may serve as well to elevate page rank on Google Search as favorable comments. The particular problem addressed in "The New York Times" article, which involved DecorMyEyes, was addressed shortly thereafter by an undisclosed fix in the Google algorithm. According to Google, it was not the frequently published consumer complaints about DecorMyEyes which resulted in the high ranking but mentions on news websites of events which affected the firm such as legal actions against it. Google Webmaster Tools helps to check for websites that use duplicate or copyright content.
Universal search.
Universal search was launched by Google on May 16, 2007. It was an idea which merged the results from different searches into one. Prior to Universal search, a standard Google search would consist of links to different websites. Universal search incorporates a wide variety of information such as websites, news, pictures, maps, blogs, videos, and more to display as search results. Marissa Mayer, VP of Search Products & User Experience during Universal search launch, described the goal of universal search, "With Universal search, we're attempting to break down the walls that traditionally separated our various search properties and integrate the vast amounts of information available into one simple set of search results… We want to help you find the very best answer, even if you don't know where to look."
Functionality.
Google search consists of a series of localized websites. The largest of those, the google.com site, is the top most-visited website in the world. Some of its features include a definition link for most searches including dictionary words, the number of results you got on your search, links to other searches (e.g. for words that Google believes to be misspelled, it provides a link to the search results using its proposed spelling), and many more.
Search syntax.
Google's search engine normally accepts queries as a simple text, and breaks up the user's text into a sequence of search terms, which will usually be words that are to occur in the results, but one can also use Boolean operators, such as: quotations marks (") for a phrase, a prefix such as "+", "-" for qualified terms (no longer valid, the '+' was removed from Google on October 19, 2011), or one of several advanced operators, such as "site:". The webpages of "Google Search Basics" describe each of these additional queries and options ("see below:" Search options).
Google's Advanced Search web form gives several additional fields which may be used to qualify searches by such criteria as date of first retrieval.
Query expansion.
Google applies query expansion to the submitted search query, transforming it into the query that will actually be used to retrieve results. As with page ranking, the exact details of the algorithm Google uses are deliberately obscure, but certainly the following transformations are among those that occur:
"I'm Feeling Lucky".
Google's homepage includes a button labeled "I'm Feeling Lucky". Prior to a change in 2012, when a user typed in a search and clicked on the button the user would be taken directly to the first search result, bypassing the search engine results page. The idea was that if a user is "feeling lucky", the search engine would return the perfect match the first time without having to page through the search results. According to a study by Tom Chavez of "Rapt", this feature cost Google $110 million a year as 1% of all searches use this feature and bypass all advertising.
With the introduction of Google Instant, the functionality of the button behaves differently. Currently, the "I'm Feeling Lucky" button changes based on the user's settings and what webpage users are at. If Google Instant is turned off, the button will work as it previously did or, if the search box is empty, redirect to the Google Doodles gallery. If Google Instant is turned on and a user hovers over the button, the button text will spin and land on a phrase that starts with "I'm feeling" (e.g. "I'm feeling hungry" or "I'm feeling smart"). Each phrase links to a Google page related to the associated phrase.
Google Chrome and Mozilla Firefox used "I'm Feeling Lucky" as the default search string when the user entered a query in the location bar; this functionality was deprecated in later versions.
Rich snippets.
On May 12, 2009, Google announced that they would be parsing the hCard, hReview, and hProduct microformats and using them to populate search result pages with what they called "Rich Snippets".
Special features.
Besides the main search-engine feature of searching for text, Google Search has more than 22 "special features" (activated by entering any of dozens of "trigger words") when searching:
Search options.
The webpages maintained by the Google Help Center have text describing more than 15 various search options.
The Google operator
Some of the query options are as follows:
The page-display options (or query types) are:
Error messages.
Some searches will give a 403 Forbidden error with the text
"We're sorry...
sometimes followed by a CAPTCHA prompt. 
The screen was first reported in 2005, and was a response to the heavy use of Google by search engine optimization companies to check on ranks of sites they were optimizing. Google says the message is triggered only by high volumes of requests from a single IP address, however the use of the "allintext" operator a few times in a period of minutes has the same effect. Google apparently uses the Google cookie as part of its determination of refusing service.
In June 2009, after the death of pop superstar Michael Jackson, this message appeared to many internet users who were searching Google for news stories related to the singer, and was assumed by Google to be a DDoS attack, although many queries were submitted by legitimate searchers.
January 2009 malware bug.
Google flags search results with the message "This site may harm your computer" if the site is known to install malicious software in the background or otherwise surreptitiously. Google does this to protect users against visiting sites that could harm their computers. For approximately 40 minutes on January 31, 2009, all search results were mistakenly classified as malware and could therefore not be clicked; instead a warning message was displayed and the user was required to enter the requested URL manually. The bug was caused by human error. The URL of "/" (which expands to all URLs) was mistakenly added to the malware patterns file.
Google Doodles.
On certain occasions, the logo on Google's webpage will change to a special version, known as a "Google Doodle". This is a picture, drawing, or animation that includes the logo. It is usually done for a special event or day although not all of them are well known. Clicking on the Doodle links to a string of Google search results about the topic. The first was a reference to the Burning Man Festival in 1998, and others have been produced for the birthdays of notable people like Albert Einstein, historical events like the interlocking Lego block's 50th anniversary and holidays like Valentine's Day. Some Google Doodles have interactivity beyond a simple search, such as the famous "Google Pacman" version that appeared on May 21, 2010.
Google Caffeine.
In August 2009, Google announced the rollout of a new search architecture, codenamed "Caffeine".
The new architecture was designed to return results faster and to better deal with rapidly updated information from services including Facebook and Twitter.
Google developers noted that most users would notice little immediate change, but invited developers to test the new search in its sandbox.
Differences noted for their impact upon search engine optimization included heavier keyword weighting and the importance of the domain's age.
The move was interpreted in some quarters as a response to Microsoft's recent release of an upgraded version of its own search service, renamed Bing.
Google announced completion of Caffeine on June 8, 2010, claiming 50% fresher results due to continuous updating of its index.
With Caffeine, Google moved its back-end indexing system away from MapReduce and onto BigTable, the company's distributed database platform. Caffeine is also based on Colossus, or GFS2, an overhaul of the GFS distributed file system.
Conversational search (OK Google).
During the Google I/O conference in May 2013, Google's Amit Singhal presented on the future of search, explaining that a search engine's three primary functions will need to evolve and that search will need to: 1. Answer, 2. Converse, and 3. Anticipate. As part of his keynote talk, Singhal stated, "A computer you can talk to? And it will answer everything you ask it? Little did I know, I would grow up to become the person responsible for building my dream for the entire world." Conversational search technology was then featured and Singhal introduced the term "hot-wording" to describe search without the need for an interface, whereby the user simply prompts the Google search engine by stating, "OK Google." The I/O audience was then shown a demonstration in which a user asked a question and the search engine answered back in "conversation," in addition to the presentation of results for the query.
The conversational search function was incorporated into the latest version of the Chrome browser during the week beginning May 20, 2013. The "OK Google" search prompt was not included into the upgrade and users are required to click on a microphone icon that appears on the right-hand side of the search box. Google displays its answer to the user's question in the form of "cards" at the top of the search results while the information is conveyed verbally—according to one search engine writer, Google continues to work through the feature's bugs.
Hummingbird update.
The "Hummingbird" update was announced as part of Google's 15-year anniversary and a "Guardian" technology journalist described it as "the biggest change to the inner workings of the world's most popular search engine since Google's "Caffeine" update in 2010." The update was progressively introduced over the month prior to the announcement and will benefit more modern forms of search, whereby users ask Google a question rather than entering keywords into the search box.
Privacy.
Searches made by search engines, including Google, leave traces. This raises concerns about privacy. In principle, if details of a user's searches are found, those with access to the information—principally state agencies responsible for law enforcement and similar matters—can make deductions about the user's activities. This has been used for the detection and prosecution of lawbreakers; for example a murderer was found and convicted after searching for terms such as "tips with killing with a baseball bat".
A search may leave traces both on a computer used to make the search, and in records kept by the search provider. When using a search engine through a browser program on a computer, search terms and other information may be stored on the computer by default, unless the browser is set not to do this, or they are erased. Saved terms may be discovered on forensic analysis of the computer. An Internet Service Provider (ISP) or search engine provider (e.g., Google) may store records which relate search terms to an IP address and a time. Whether such logs are kept, and access to them by law enforcement agencies, is subject to legislation in different jurisdictions and working practices; the law may mandate, prohibit, or say nothing about logging of various types of information. Some search engines, located in jurisdictions where it is not illegal, make a feature of not storing user search information.
Encrypted search.
Various search engines provide encrypted Web search facilities. In May 2010 Google rolled out SSL-encrypted web search. The encrypted search can be accessed at codice_21
FTC Fines.
In 2012 the US Federal Trade Commission fined Google US$22.5 million for violating their agreement not to violate the privacy of users of the Apple Safari (web browser). The FTC was also continuing to investigate if Google's favoring of their own services in their search results violated antitrust regulations.
Instant Search.
Google Instant, a feature that displays suggested results while the user types, was introduced in the US on September 8, 2010. In concert with the Google Instant launch, Google disabled the ability of users to choose to see more than 10 search results per page. At the time of the announcement, Google expected Instant to save users 2 to 5 seconds in every search, collectively about 11 million seconds per hour. Search engine marketing experts speculated that Google Instant would have a great impact on local and paid search. Google Search is a turn from a static HTML page into an AJAX application.
Instant Search can be disabled via Google's "preferences" menu, but autocomplete-style search suggestions cannot be disabled, by intention.
The publication "" compiled a list of words that Google Instant did not show. Most banned terms are those considered rude, but some apparently irrelevant searches including "Myleak" are removed.
In September 2012 several sources reported that Google had removed bisexual from the list of blacklisted terms for Instant Search. the word bisexual still did not autocomplete, and LGBT activists renewed efforts to have it whitelisted. "bisexuality" (but not "bisexual") and "myleak" were found.
Redesign.
In late June 2011, Google introduced a new look to the Google home page in order to boost the use of the Google+ social tools.
One of the major changes was replacing the classic navigation bar with a black one. Google's digital creative director Chris Wiggins explains: "We're working on a project to bring you a new and improved Google experience, and over the next few months, you'll continue to see more updates to our look and feel." The new navigation bar has been negatively received by a vocal minority.
In November 2013, Google started testing yellow labels for advertisements displayed in search results, to improve user experience. The new labels, highlighted in yellow color, and aligned to the left of each sponsored link help users clearly differentiate between organic and sponsored results.
Smartphone app.
A Google Search mobile app is available for Android, Windows Phone and iOS devices. In addition to allowing users to perform web searches, the app implements Google Now, Google's voice recognition and intelligent personal assistant software. Google Now uses a natural language user interface to answer questions, make recommendations, and perform actions by delegating requests to a set of web services. Along with answering user-initiated queries, Google Now passively delivers information to the user that it predicts they will want, based on their search habits. Google Search for Android was originally introduced in 2007, the same year the Android operating system was introduced. On January 11, 2012, Google introduced an update where they included an updated and simplified user interface, along with other improvements.
International.
Google is available in many languages and has been localized completely or partly for many countries.
The interface has also been made available in some languages for humorous purpose:
In addition to the main URL Google.com, Google Inc. owns 160 domain names for each of the countries/regions in which it has been localized.
On September 29, 2015, an Ex-Googler Sanmay Ved managed to buy the domain Google.com from Google via Google Domains, and gain full webmaster control. Google later acknowledged the purchase, and rewarded Ved who in turn requested that the reward be donated to charity. As a result, Google doubled the reward.
Search products.
In addition to its tool for searching webpages, Google also provides services for searching images, Usenet newsgroups, news websites, videos, searching by locality, maps, and items for sale online. In 2012, Google has indexed over 30 trillion web pages, and received 100 billion queries per month. It also caches much of the content that it indexes. Google operates other tools and services including Google News, Google Shopping, Google Maps, Google Custom Search, Google Earth, Google Docs, Picasa, Panoramio, YouTube, Google Translate, Google Blog Search and Google Desktop Search.
There are also products available from Google that are not directly search-related. Gmail, for example, is a webmail application, but still includes search features; Google Browser Sync does not offer any search facilities, although it aims to organize your browsing time.
Also Google starts many new beta products, like Google Social Search or Google Image Swirl.
Energy consumption.
Google claims that a search query requires altogether about 1 kJ or 0.0003 kW·h, which is enough to raise the temperature of one liter of water by 0.24 °C.
Possible misuse of search results.
In 2007, a group of Austrian researchers observed a tendency to misuse the Google engine as a "reality interface". Ordinary users as well as journalists tend to rely on the first pages of Google search, assuming that everything not listed there is either not important or merely does not exist. The researchers say that "Google has become the main interface for our whole reality. To be precise: with the Google interface the user gets the impression that the search results imply a kind of totality. In fact, one only sees a small part of what one could see if one also integrates other research tools".
Predicting behavior.
At the 2016 New Hampshire primary, the top-searched Democratic candidate was Bernie Sanders with 72% of the searches and won with 60% of the vote, according to real-time results of Google's trending search queries, and Hillary Clinton received 28% of the queries and 38% of the vote. The top-searched Republican candidate was Donald Trump, who received 41% of the searches an hour before the polls closed and won with 35% of the vote and John Kasich got 16% of both the vote and the searches.

</doc>
<doc id="12432" url="https://en.wikipedia.org/wiki?curid=12432" title="Genius">
Genius

A genius is a person who displays exceptional intellectual ability or originality, typically to a degree that is associated with the achievement of new advances in a domain of knowledge. 
Someone who can coach a team to 1-5 in the AFL. Despite the presence of scholars in many subjects throughout history, many geniuses have shown high achievements only in a single subject. There is no scientifically precise definition of genius, and the question of whether the notion itself has any real meaning has long been a subject of debate, although psychologists are converging on a definition that emphasizes creativity and eminent achievement.
Etymology.
In ancient Rome, the "genius" (plural in Latin "genii") was the guiding spirit or tutelary deity of a person, family "(gens)", or place "(genius loci)". The noun is related to the Latin verb "genui, genitus", "to bring into being, create, produce". Because the achievements of exceptional individuals seemed to indicate the presence of a particularly powerful "genius", by the time of Augustus the word began to acquire its secondary meaning of "inspiration, talent". The term "genius" acquired its modern sense in the eighteenth century, and is a conflation of two Latin terms: "genius", as above, and "ingenium", a related noun referring to our innate dispositions, talents and inborn nature. Beginning to blend the concepts of the divine and the talented, the "Encyclopédie" article on genius (génie) describes such a person as "he whose soul is more expansive and struck by the feelings of all others; interested by all that is in nature never to receive an idea unless it evokes a feeling; everything excites him and on which nothing is lost." 
Historical development.
Galton.
The assessment of intelligence was initiated by Francis Galton (1822–1911) and James McKeen Cattell. They had advocated the analysis of reaction time and sensory acuity as measures of "neurophysiological efficiency" and the analysis of sensory acuity as a measure of intelligence.
Galton is regarded as the founder of psychometry. He studied the work of his older half-cousin Charles Darwin about biological evolution. Hypothesizing that eminence is inherited from ancestors, Galton did a study of families of eminent people in Britain, publishing it in 1869 as "Hereditary Genius". Galton's ideas were elaborated from the work of two early 19th-century pioneers in statistics: Carl Friedrich Gauss and Adolphe Quetelet. Gauss discovered the normal distribution (bell-shaped curve): given a large number of measurements of the same variable under the same conditions, they vary at random from a most frequent value, the "average," to two least frequent values at maximum differences greater and lower than the most frequent value. Quetelet discovered that the bell-shaped curve applied to social statistics gathered by the French government in the course of its normal processes on large numbers of people passing through the courts and the military. His initial work in criminology led him to observe "the greater the number of individuals observed the more do peculiarities become effaced..." This ideal from which the peculiarities were effaced became "the average man".
Galton was inspired by Quetelet to define the average man as "an entire normal scheme"; that is, if one combines the normal curves of every measurable human characteristic, one will in theory perceive a syndrome straddled by "the average man" and flanked by persons that are different. In contrast to Quetelet, Galton's average man was not statistical, but was theoretical only. There was no measure of general averageness, only a large number of very specific averages. Setting out to discover a general measure of the average, Galton looked at educational statistics and found bell-curves in test results of all sorts; initially in mathematics grades for the final honors examination and in entrance examination scores for Sandhurst.
Galton's method in "Hereditary Genius" was to count and assess the eminent relatives of eminent men. He found that the number of eminent relatives was greater with closer degree of kinship. This work is considered the first example of historiometry, an analytical study of historical human progress. The work is controversial and has been criticised for several reasons. Galton then departed from Gauss in a way that became crucial to the history of the 20th century AD. The bell-shaped curve was not random, he concluded. The differences between the average and the upper end were due to a non-random factor, "natural ability," which he defined as "those qualities of intellect and disposition, which urge and qualify men to perform acts that lead to reputation ... a nature which, when left to itself, will, urged by an inherent stimulus, climb the path that leads to eminence." The apparent randomness of the scores was due to the randomness of this natural ability in the population as a whole, in theory.
Criticisms include that Galton's study fails to account for the impact of social status and the associated availability of resources in the form of economic inheritance, meaning that inherited "eminence" or "genius" can be gained through the enriched environment provided by wealthy families. Galton went on to develop the field of eugenics.
Psychology.
Genius is expressed in a variety of forms (e.g., mathematical, literary, musical performance). Persons with genius tend to have strong intuitions about their domains, and they build on these insights with tremendous energy. Carl Rogers, a founder of the Humanistic Approach to Psychology, expands on the idea of a genius trusting his or her intuition in a given field, writing: "El Greco, for example, must have realized as he looked at some of his early work, that 'good artists do not paint like that.' But somehow he trusted his own experiencing of life, the process of himself, sufficiently that he could go on expressing his own unique perceptions. It was as though he could say, 'Good artists don't paint like this, but "I" paint like this.' Or to move to another field, Ernest Hemingway was surely aware that "good writers do not write like this." But fortunately he moved toward being Hemingway, being himself, rather than toward someone else's conception of a good writer."
A number of people commonly regarded as geniuses have been diagnosed with mental disorders, for example Vincent van Gogh, Virginia Woolf, John Forbes Nash, Jr, and Ernest Hemingway.
There is a link between genius and mental illness (schizophrenia and bipolar disorder).
IQ and genius.
Galton was a pioneer in investigating both eminent human achievement and mental testing. In his book "Hereditary Genius", written before the development of IQ testing, he proposed that hereditary influences on eminent achievement are strong, and that eminence is rare in the general population. Lewis Terman chose "'near' genius or genius" as the classification label for the highest classification on his 1916 version of the Stanford-Binet test. By 1926, Terman began publishing about a longitudinal study of California schoolchildren who were referred for IQ testing by their schoolteachers, called Genetic Studies of Genius, which he conducted for the rest of his life. Catherine M. Cox, a colleague of Terman's, wrote a whole book, "The Early Mental Traits of 300 Geniuses", published as volume 2 of The Genetic Studies of Genius book series, in which she analyzed biographical data about historic geniuses. Although her estimates of childhood IQ scores of historical figures who never took IQ tests have been criticized on methodological grounds, Cox's study was thorough in finding out what else matters besides IQ in becoming a genius. By the 1937 second revision of the Stanford-Binet test, Terman no longer used the term "genius" as an IQ classification, nor has any subsequent IQ test. In 1939, David Wechsler specifically commented that "we are rather hesitant about calling a person a genius on the basis of a single intelligence test score".
The Terman longitudinal study in California eventually provided historical evidence regarding how genius is related to IQ scores. Many California pupils were recommended for the study by schoolteachers. Two pupils who were tested but rejected for inclusion in the study (because their IQ scores were too low) grew up to be Nobel Prize winners in physics, William Shockley, and Luis Walter Alvarez. Based on the historical findings of the Terman study and on biographical examples such as Richard Feynman, who had an IQ of 125 and went on to win the Nobel Prize in physics and become widely known as a genius, the current view of psychologists and other scholars of genius is that a minimum level of IQ (approximately 125) is necessary for genius but not sufficient, and must be combined with personality characteristics such as drive and persistence, plus the necessary opportunities for talent development.
Philosophy.
Various philosophers have proposed definitions of what genius is and what that implies in the context of their philosophical theories.
In the philosophy of David Hume, the way society perceives genius is similar to the way society perceives the ignorant. Hume states that a person with the characteristics of a genius is looked at as a person disconnected from society, as well as a person who works remotely, at a distance, away from the rest of the world. On the other hand, the mere ignorant is still more despised; nor is any thing deemed a surer sign of an illiberal genius in an age and nation where the sciences flourish, than to be entirely destitute of all relish for those noble entertainments. The most perfect character is supposed to lie between those extremes; retaining an equal ability and taste for books, company, and business; preserving in conversation that discernment and delicacy which arise from polite letters; and in business, that probity and accuracy which are the natural result of a just philosophy.
In the philosophy of Immanuel Kant, genius is the ability to independently arrive at and understand concepts that would normally have to be taught by another person. For Kant, originality was the essential character of genius. This genius is a talent for producing ideas which can be described as non-imitative. Kant's discussion of the characteristics of genius is largely contained within the "Critique of Judgement" and was well received by the Romantics of the early 19th century. In addition, much of Schopenhauer's theory of genius, particularly regarding talent and freedom from constraint, is directly derived from paragraphs of Part I of Kant's "Critique of Judgment".
In the philosophy of Arthur Schopenhauer, a genius is someone in whom intellect predominates over "will" much more than within the average person. In Schopenhauer's aesthetics, this predominance of the intellect over the will allows the genius to create artistic or academic works that are objects of pure, disinterested contemplation, the chief criterion of the aesthetic experience for Schopenhauer. Their remoteness from mundane concerns means that Schopenhauer's geniuses often display maladaptive traits in more mundane concerns; in Schopenhauer's words, they fall into the mire while gazing at the stars, an allusion to Plato's dialogue "Theætetus", in which Socrates tells of Thales (the first philosopher) being ridiculed for falling in such circumstances. As he says in Volume 2 of "The World as Will and Representation":
In the philosophy of Bertrand Russell, genius entails that an individual possesses unique qualities and talents that make the genius especially valuable to the society in which he or she operates, once given the chance to contribute to society. Russell's philosophy further maintains, however, that it is possible for such geniuses to be crushed in their youth and lost forever when the environment around them is unsympathetic to their potential maladaptive traits. Russell rejected the notion he believed was popular during his lifetime that, "genius will out."
Further reading.
Sources listed in chronological order of publication within each category.

</doc>
<doc id="12434" url="https://en.wikipedia.org/wiki?curid=12434" title="Grain (disambiguation)">
Grain (disambiguation)

Grains are coarse particles such as sand particles, salt particles or seeds:
Or, more generally:
Grain may also refer to:

</doc>
<doc id="12435" url="https://en.wikipedia.org/wiki?curid=12435" title="Grass (disambiguation)">
Grass (disambiguation)

Grass may refer to:

</doc>
