<doc id="8349" url="https://en.wikipedia.org/wiki?curid=8349" title="Denarius">
Denarius

In the Roman currency system, the denarius (Anglicised pronunciation: ; plural: denarii ) was a small silver coin first minted about 211 BC during the Second Punic War. It became the most common coin produced for circulation but was slowly debased in weight and silver content until its replacement by the double denarius, called the antoninianus, early in the 3rd century AD. The word "denarius" is derived from the Latin "dƒìnƒ´" "containing ten", as its value was 10 asses, although in the middle of the 2nd century BC it was recalibrated so that it was now worth sixteen asses or four sestertii. It is the origin of several modern words such as the currency name dinar; it is also the origin for the common noun for money in Italian "denaro", in Portuguese "dinheiro" and in Spanish "dinero". Its symbol is êÜñ (XÃ∂ a letter x with stroke).
History.
A predecessor of the denarius was first struck in 267 BC, five years before the first Punic War with an average weight of 6.81¬†grams, or of a Roman pound. Contact with the Greeks prompted a need for silver coinage in addition to the bronze currency that the Romans were using during that time. The predecessor of the denarius was a Greek-styled silver coin, very similar to the didrachm and drachma struck in Metapontion and other Greek cities in southern Italy. These coins were inscribed for Rome but closely resemble their Greek counterparts. They were most likely used for trade purposes and were seldom used in Rome.
The first distinctively Roman silver coin appeared around 226 BC. Classic historians sometimes called these coins denarii in the past, but they are classified by modern numismatists as "quadrigati", which is derived from the quadriga, or four-horse chariot, on the reverse, and which with a two-horse chariot or biga was the prototype for the most common designs used on Roman silver coins for the next 150 years.
Rome overhauled its coinage around 211 BC and introduced the denarius alongside a short-lived denomination called the victoriatus. This denarius contained an average 4.5¬†grams, or of a Roman pound of silver. It formed the backbone of Roman currency throughout the Roman republic.
The denarius began to undergo slow debasement toward the end of the republican period. Under the rule of Augustus, (63 BC-AD 14) its silver content fell to 3.9¬†grams (a theoretical weight of of a Roman pound). It remained at nearly this weight until the time of Nero (AD 37-68), when it was reduced to of a pound, or 3.4¬†grams. Debasement of the coin's silver content continued after Nero. Later Roman emperors reduced its content to 3¬†grams around the late third century.
The value at its introduction was 10 asses, giving the denarius its name, which translates as "containing ten". In about 141 BC, it was re-tariffed at 16 asses, to reflect the decrease in weight of the as. The denarius continued to be the main coin of the Roman Empire until it was replaced by the antoninianus in the middle of the third century. The last issuance of this coin occurred in bronze form by Aurelian, between AD 270 and 275, and in the first years of the reign of Diocletian. For more details, see 'Denarius', in "A Dictionary of Ancient Roman Coins", by John R. Melville-Jones (1990).
Debasement and evolution.
The denarius has a link from the Roman times to the British penny and US 1 cent piece (colloquially called 'penny').
Comparisons and silver content.
It is difficult to give even rough comparative values for money from before the 20th century, as the range of products and services available for purchase was different. Classical historians often say that in the late Roman Republic and early Roman Empire (~27BC) the daily wage for an unskilled laborer and common soldier was 1 denarius (with no tax deductions) or about US$28 in bread. During the republic (509‚Äì27 BC), legionary (professional soldier) pay was 112.5 denarii per year (0.3/day), later doubled by Julius Caesar to 225 denarii (0.6/day), with soldiers having to pay for their own food and arms. Centurions received considerably higher pay; under Augustus, the lowest rank of centurion was paid 3,750 denarii and the highest rank, 15,000 denarii.
The silver content of the denarius under the Roman Empire (After Nero) was about 50 grains, 3.24 grams, or (0.105ozt) troy ounce. On June 6, 2011, this was about US$3.62 in value if the silver were 0.999 pure.
The fineness of the silver content varied with political and economic circumstances. From a purity of greater than 90% silver in the first century A.D., the denarius fell to under 60% purity by the end of the second century A.D., and plummeted to 5% purity by the end of the third century A.D. By the reign of Gallienus, the antoninianus was a copper coin with a thin silver wash.
By comparison, a laborer earning the minimum wage in the United States in January 2014 made US$58 for an 8-hour day, before taxes (utilizing the mode value of $7.25 per hour, which was true then in 20 states) and a labourer earning the minimum wage in the United Kingdom in 2014 made GBP¬£52 for an 8-hour day, before taxes.
Influence.
In the final years of the first century BC Tincomarus the ruler of part of Britain started issuing coins that appear to have been made from melted down Denarii.
Even after the denarius was no longer regularly issued, it continued to be used as a unit of account, and the name was applied to later Roman coins in a way that is not understood. The Arabs who conquered large parts of the land that once belonged to the Eastern Roman Empire issued their own gold dinar. The lasting legacy of the denarius can be seen in the use of "d" as the abbreviation for the British penny prior to 1971. It survived in France as the name of a coin, the denier. The denarius also survives in the common Arabic name for a currency unit, the "dinar" used from pre-Islamic times, and still used in several modern Arabic-speaking nations. The major currency unit in former Principality of Serbia, Kingdom of Serbia and former Yugoslavia was "dinar", and it is still used in present-day Serbia. The Macedonian currency "denar" is also derived from the Roman denarius. The Italian word "denaro", the Spanish word "dinero", the Portuguese word "dinheiro", and the Slovene word "", all meaning money, are also derived from Latin "denarius".
Value.
The gold "aureus" seems to have been a "currency of account," a denomination not commonly seen in daily transactions due to its high value. Numismatists think that the aureus was used to pay bonuses to the legions at the accession of new emperors. It was valued at 25 denarii.
1 gold aureus = 2 gold quinarii = 25 silver denarii = 50 silver quinarii = 100 bronze sestertii = 200 bronze dupondii = 400 copper asses = 800 copper semisses = 1600 copper quadrantes
Use in the Bible.
In the New Testament, the gospels refer to the denarius as a day's wage for a common laborer (Matthew 20:2, John 12:5). In the Book of Revelation, during the Third Seal: Black Horse, a choinix (or quart) of wheat and three quarts of barley were each valued at one denarius. Bible scholar Robert H. Mounce says the price of the wheat and barley as described in the vision appears to be ten to twelve times their normal cost in ancient times. Revelation describes a condition where basic goods are sold at greatly inflated prices. Thus, the black horse rider depicts times of deep scarcity or famine but not of starvation. The English word "quart" translates choinix. Apparently, a choinix of wheat was the daily ration of one adult. Thus, in the conditions pictured by Revelation 6 the normal income for a working-class family would buy enough food for only one person. The less costly barley would feed three people for one day's wages.
In popular culture.
The silver denarius is one of the two main units of currency in Rick Riordan's "The Heroes of Olympus" series, along with the golden drachma.
Physical Bitcoin coin manufacturer Denarium has derived its name from denarius. Denarium coins are in circulation and they contain Bitcoin digital currency.

</doc>
<doc id="8350" url="https://en.wikipedia.org/wiki?curid=8350" title="Della Rovere">
Della Rovere

The House of Della Rovere (literally "of the Oak Tree") was a noble family of Italy. Coming from modest beginnings in Savona, Liguria, the family rose to prominence through nepotism and ambitious marriages arranged by two della Rovere popes, Francesco della Rovere, who ruled as Pope Sixtus IV (1471‚Äì1484) and his nephew Giuliano (Pope Julius II, 1503‚Äì1513). Pope Sixtus IV built the Sistine Chapel, which is named for him. The Basilica San Pietro in Vincoli in Rome is the family church of the della Rovere.
Guidobaldo da Montefeltro adopted Francesco Maria I della Rovere, his sister's child and nephew of Pope Julius II. Guidobaldo I, who was heirless, called Francesco Maria at his court, and named him as heir of the Duchy of Urbino in 1504, this through the intercession of Julius II. In 1508, Francesco Maria inherited the duchy thereby starting the line of Rovere Dukes of Urbino. That dynasty ended in 1626 when Pope Urban VIII incorporated Urbino into the papal dominions. As compensation to the last sovereign duke, the title only could be continued by Francesco Maria II, and after his death by his heir, Federico Ubaldo.
Vittoria, last descendant of the della Rovere family (she was the only child of Federico Ubaldo), married Ferdinando II de' Medici, Grand Duke of Tuscany. They had two children: Cosimo III, Tuscany's longest reigning monarch, and Francesco Maria de' Medici, a prince of the Church.
Family tree.
Dotted lines indicate duplicates (where a person appears more than once in the tree).<br>
Small caps text indicates the surname of the children (regardless of number) of a union.<br>
All persons have the surname Della Rovere unless otherwise indicated.

</doc>
<doc id="8351" url="https://en.wikipedia.org/wiki?curid=8351" title="David Mamet">
David Mamet

David Alan Mamet (; born November 30, 1947) is an American playwright, essayist, screenwriter, and film director. As a playwright, Mamet has won a Pulitzer Prize and received Tony nominations for "Glengarry Glen Ross" (1984) and "Speed-the-Plow" (1988). As a screenwriter, he has received Oscar nominations for "The Verdict" (1982) and "Wag the Dog" (1997). Mamet's books include: "The Old Religion" (1997), a novel about the lynching of Leo Frank; "Five Cities of Refuge: Weekly Reflections on Genesis, Exodus, Leviticus, Numbers and Deuteronomy" (2004), a Torah commentary with Rabbi Lawrence Kushner; "The Wicked Son" (2006), a study of Jewish self-hatred and antisemitism; "Bambi vs. Godzilla", a commentary on the movie business; "The Secret Knowledge: On the Dismantling of American Culture" (2011), a commentary on cultural and political issues; and "Three War Stories" (2013), a trio of novellas about the physical and psychological effects of war.
Feature films that Mamet both wrote and directed include "Redbelt" (2008), "The Spanish Prisoner" (1997), "House of Games" (1987) (which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and "Film of the Year" for the 1989 London Critics Circle Film Awards), "Spartan" (2004), "Heist" (2001), "State and Main" (2000) (Winner of a Best Acting - Ensemble award from the National Board of Review), "The Winslow Boy" (1999), and "Oleanna" (1994). This was accompanied by "Homicide" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a "Screenwriter of the Year" award for Mamet from the London Critics Circle Film Awards and Best Cinematography for Roger Deakins from the Los Angeles Film Critics Association Awards), "Things Change" (1988) (which won the Volpi Cup for Best Actor at 1988 Venice Film Festival for Don Ameche and Joe Mantegna), and most recently the 2013 HBO film "Phil Spector", starring Al Pacino as Spector with Helen Mirren and Jeffrey Tambor. His drama "Glengarry Glen Ross", in 1992, was adapted by Mamet into a film version which also received an Academy Award nomination.
Mamet has also written the screenplays for such films as "The Verdict" (1982), directed by Sidney Lumet, "The Postman Always Rings Twice" (1981), directed by Bob Rafelson, "The Untouchables" (1987) directed by Brian De Palma, "Hoffa" (1992), "Ronin" (1998), "Wag The Dog" (1997), "The Edge" (1997), and "Hannibal" (2001). Mamet was also the executive producer and frequent writer for the TV show "The Unit."
Early life.
Mamet was born in 1947 in Chicago to Jewish parents, Lenore June (n√©e Silver), a teacher, and Bernard Morris Mamet, an attorney. One of his first jobs was as a busboy at Chicago's The Second City. He was educated at the progressive Francis W. Parker School and at Goddard College in Plainfield, Vermont. At the Chicago Public Library Foundation 20th anniversary fundraiser in 2006, though, Mamet announced "My alma mater is the Chicago Public Library. I got what little educational foundation I got in the third-floor reading room, under the tutelage of a Coca-Cola sign".
Career.
Theater.
Mamet is a founding member of the Atlantic Theater Company; he first gained acclaim for a trio of off-Broadway plays in 1976, "The Duck Variations," "Sexual Perversity in Chicago," and "American Buffalo." He was awarded the Pulitzer Prize in 1984 for "Glengarry Glen Ross," which received its first Broadway revival in the summer of 2005. His play "Race", which opened on Broadway on December 6, 2009 and featured James Spader, David Alan Grier, Kerry Washington, and Richard Thomas in the cast, received mixed reviews. His play "The Anarchist", starring Patti LuPone and Debra Winger, in her Broadway debut, opened on Broadway on November 13, 2012 in previews and was scheduled to close on December 16, 2012.
In 2002, Mamet was inducted into the American Theatre Hall of Fame. Mamet later received the PEN/Laura Pels International Foundation for Theater Award for Grand Master of American Theater in 2010.
Film.
Mamet's feature films, which he both wrote and directed, include in chronological order: his feature directorial debut "House of Games" (1987) (which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and "Film of the Year" for the 1989 London Critics Circle Film Awards), "Things Change" (1988), "Homicide" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a "Screenwriter of the Year" award for Mamet from the London Critics Circle Film Awards and Best Cinematography from Roger Deakins from the Los Angeles Film Critics Association Awards), "Oleanna" (1994), "The Spanish Prisoner" (1997), "The Winslow Boy" (1999), "State and Main" (2000), "Heist" (2001), "Spartan" (2004), "Redbelt" (2008), and in 2012 a bio-pic TV movie "Phil Spector" about the American record producer and songwriter Phil Spector starring Al Pacino as Spector, as well as Helen Mirren and Jeffrey Tambor. His latest feature-length film, a thriller titled "Blackbird", is slated for release in 2015. "Blackbird" will star James Badge Dale as ‚Äúa military major who is trying to discover the truth about the political secrets of a woman‚Äôs grandfather who worked for the U.S. special ops during the 1960s,‚Äù according to Deadline.com.
Mamet has also written the screenplays for such classic films as "The Verdict" (1982), directed by Sidney Lumet, "The Postman Always Rings Twice" (1981), "The Untouchables" (1987) directed by Brian De Palma, "Hoffa" (1992), "The Edge" (1997), "Wag The Dog" (1997), "Ronin" (1998), and "Hannibal" (2001).
Mamet's first produced screenplay was the 1981 production of "The Postman Always Rings Twice" (directed by Bob Rafelson), based upon James M. Cain's novel. He received an Academy Award nomination one year later for his first script, "The Verdict", written in the late 1970s. He also wrote the screenplay for "The Untouchables."
In 1987, Mamet made his film directing debut with "House of Games", starring his then-wife, Lindsay Crouse, and a host of longtime stage associates. He uses friends as actors, especially in one early scene in the movie, which featured Vermont poker-playing friends. He is quoted as saying, "It was my first film as a director and I needed support, so I stacked the deck." Two of the four poker friends included in the film were fellow Goddard College graduates Allen Soule and Bob Silverstein. Three of Mamet's own films, "House of Games", "The Spanish Prisoner", and "Heist," have involved the world of con artists.
Mamet adapted "Glengarry Glen Ross" for the cinema in 1992, writing an additional part (including the monologue "Coffee's for closers") for Alec Baldwin.
Mamet remains a writer and director, and has assembled an informal repertory company for his films, including Crouse, William H. Macy, Joe Mantegna, Rebecca Pidgeon, and Ricky Jay, as well as some of the aforementioned poker associates. Mamet has funded his own films with payments he receives for credited and uncredited rewrites of typically big-budget films. For instance, Mamet did a rewrite of the script for "Ronin" under the pseudonym "Richard Weisz" and turned in an early version of a script for "Malcolm X" that director Spike Lee rejected. In 2000, Mamet directed a film version of "Catastrophe," a one-act play by Samuel Beckett featuring Harold Pinter and John Gielgud (in his final screen performance). In 2008, he directed and wrote the mixed martial arts movie "Redbelt," about a martial arts instructor tricked into fighting in a professional bout. Mamet teamed up with his wife Rebecca Pidgeon to adapt the novel "Come Back to Sorrento" as a screenplay. The film was in development during 2010. He is also director of the TV film "Phil Spector".
In "On Directing Film," Mamet asserts that directors should focus on getting the point of a scene across, rather than simply following a protagonist, or adding visually beautiful or intriguing shots. Films should create order from disorder in search of the objective.
Books.
In 1990 Mamet published "The Hero Pony", a 55-page collection of poetry. He has also published a series of short plays, monologues and three novels, "The Village" (1994), "The Old Religion" (1997), and "Wilson: A Consideration of the Sources" (2000). He has written several non-fiction texts, and children's stories. In 2004 he published a lauded version of the classical Faust story, "Faustus", however, the play, when staged in San Francisco during the spring of 2004, was not well received by critics. On May 1, 2010, Mamet released a graphic novel "The Trials of Roderick Spode (The Human Ant)".
On June 2, 2011, "The Secret Knowledge: On the Dismantling of American Culture", Mamet's book detailing his conversion from modern liberalism to "a reformed liberal" was released.
Mamet published "Three War Stories", a collection of novellas, on November 11, 2013. In an interview with Newsmax TV, Mamet said he wanted to write about war, despite never having served. Moreover, the book allowed Mamet to free characters that had occupied his mind for years. On the subject of characters as a reason for writing, Mamet told the host, ‚ÄúYou want to get these guys out of your head. You just want them to stop talking to you."
Television and radio.
Mamet wrote the "Wasted Weekend" episode of "Hill Street Blues" that aired in 1987. His then-wife, Lindsay Crouse, appeared in numerous episodes (including that one) as Officer McBride. Mamet is also the creator, producer and frequent writer of the television series "The Unit", where he wrote a well-circulated memo to the writing staff. He directed a third season episode of "The Shield" with Shawn Ryan. In 2007, Mamet directed two television commercials for Ford Motor Company. The two 30-second ads featured the Ford Edge and were filmed in Mamet's signature style of fast-paced dialogue and clear, simple imagery. Mamet's sister, Lynn, is a producer and writer for television shows, such as "The Unit" and "Law & Order".
Mamet has contributed several dramas to BBC Radio through Jarvis & Ayres Productions, including an adaptation of "Glengarry Glen Ross" for BBC Radio 3 and new dramas for BBC Radio 4. The comedy "Keep Your Pantheon (or On the Whole I'd Rather Be in Mesopotamia)" was aired in 2007.
Other media and political views.
Since May 2005 he has been a contributing blogger at "The Huffington Post", drawing satirical cartoons with themes including political strife in Israel. In a 2008 article for the "Village Voice" headlined "Why I Am No Longer a 'Brain-Dead Liberal'" he revealed that he had gradually rejected political correctness and progressivism and embraced conservatism. Mamet has spoken in interviews of changes in his views, highlighting his agreement with free market theorists such as Friedrich Hayek the historian Paul Johnson, and economist Thomas Sowell, whom Mamet called "one of our greatest minds".
During promotion of a book, Mamet was criticized for claiming that the British people had "a taint of anti-semitism," claiming they "want to give away." In the same interview, Mamet went on to say that "there are famous dramatists and novelists [in the UK whose works are full of anti-Semitic filth," but that he could not specify to whom he was referring for fear of litigation. He is known for his pro-Israel positions; in his book "The Secret Knowledge" he claimed that "Israelis would like to live in peace within their borders; the Arabs would like to kill them all."
In November 2012 Mamet penned an article for the "The Jewish Journal of Greater Los Angeles" imploring fellow Jewish Americans to vote for Republican nominee Mitt Romney.
January 29, 2013, Mamet wrote an essay for "Newsweek" in which he argued against gun control laws, writing that "was intended to guard us against this inevitable decay of government that the Constitution was written. Its purpose was and is not to enthrone a Government superior to an imperfect and confused electorate, but to protect us from such a government."
Critical reception of Mamet.
‚ÄòMamet speak‚Äô.
Mamet's style of writing dialogue, marked by a cynical, street-smart edge, precisely crafted for effect, is so distinctive that it has come to be called "Mamet speak." Mamet has recognized an association of his edgy narrative style by noting his debt to Harold Pinter, to whom he dedicated "Glengarry Glen Ross". He often uses italics and quotation marks to highlight particular words and to draw attention to his characters' frequent manipulation and deceitful use of language. His characters frequently interrupt one another, their sentences trail off unfinished, and their dialogue overlaps. Moreover, certain expressions and figures of speech are deliberately misrepresented to show that the character is not paying close attention to every detail of his dialogue (e.g., "or so forth" instead of "and so forth"). Mamet himself has criticized his (and other writers') tendency to write "pretty" at the expense of sound, logical plots.
When asked how he developed his style for writing dialogue, Mamet said, "In my family, in the days prior to television, we liked to while away the evenings by making ourselves miserable, based solely on our ability to speak the language viciously. That's probably where my ability was honed."
One instance of Mamet's dialogue style can be found in "Glengarry Glen Ross", in which two down-on-their-luck real estate salesmen are considering stealing from their employer's office. George Aaronow and Dave Moss equivocate on the meaning of "talk" and "speak", turning language and meaning to deceptive purposes:
Mamet dedicated "Glengarry Glen Ross" to Harold Pinter, who was instrumental in its being first staged at the Royal National Theatre, (London) in 1983, and whom Mamet has acknowledged as an influence on its success, and on his other work.
Mamet and gender issues.
Arthur Holmberg in his 2014 book "David Mamet and Male Friendship", has reconsidered the gender issue in many of Mamet's plays throughout his career by asserting a prominent and recurrent reversed sexual orientation of portrayed male gender preferences.
Personal life.
Mamet and actress Lindsay Crouse were married in 1977 and divorced in 1990. He and Crouse have two children, Willa and Zosia. Willa is a professional photographer and Zosia is an actress. Mamet has been married to actress and singer-songwriter Rebecca Pidgeon since 1991. They have two children, Clara and Noah.
Archive.
The papers of David Mamet were sold to the Harry Ransom Center at the University of Texas at Austin in 2007 and first opened for research in 2009. The growing collection consists mainly of manuscripts and related production materials for most of his plays, films, and other writings, but also includes his personal journals from 1966 to 2005. In 2015, the Ransom Center secured a second major addition to Mamet's papers that include more recent works. Additional materials relating to Mamet and his career can be found in the Ransom Center's collections of Robert De Niro, Mel Gussow, Tom Stoppard, Sam Shepard, Paul Schrader, Don DeLillo, and John Russell Brown.
Works.
Mamet is credited as writer of these works except where noted.

</doc>
<doc id="8352" url="https://en.wikipedia.org/wiki?curid=8352" title="December 6">
December 6


</doc>
<doc id="8353" url="https://en.wikipedia.org/wiki?curid=8353" title="December 5">
December 5


</doc>
<doc id="8354" url="https://en.wikipedia.org/wiki?curid=8354" title="December 4">
December 4


</doc>
<doc id="8355" url="https://en.wikipedia.org/wiki?curid=8355" title="December 3">
December 3


</doc>
<doc id="8356" url="https://en.wikipedia.org/wiki?curid=8356" title="December 2">
December 2


</doc>
<doc id="8357" url="https://en.wikipedia.org/wiki?curid=8357" title="December 1">
December 1


</doc>
<doc id="8359" url="https://en.wikipedia.org/wiki?curid=8359" title="December 24">
December 24


</doc>
<doc id="8360" url="https://en.wikipedia.org/wiki?curid=8360" title="December 26">
December 26


</doc>
<doc id="8361" url="https://en.wikipedia.org/wiki?curid=8361" title="Definable real number">
Definable real number

Definable real numbers are those that can be uniquely specified by a description. The description may be expressed as a construction or as a formula of a formal language. For example, the positive square root of 2, formula_1, can be defined as the unique positive solution to the equation formula_2, and it can be constructed with a compass and straightedge. 
Different notions of description give rise to different notions of definability. Specific varieties of definable numbers include the constructible numbers of geometry, the algebraic numbers, and the computable numbers. 
Constructible numbers.
One way of specifying a real number uses geometric techniques. A real number "r" is a constructible number if there is a method to construct a line segment of length "r" using a compass and straightedge, beginning with a fixed line segment of length 1. 
Each positive integer, and each positive rational number, is constructible. The positive square root of 2 is constructible. However, the cube root of 2 is not constructible; this is related to the impossibility of doubling the cube. 
Algebraic numbers.
A real number "r" is called an algebraic number if there is a polynomial "p"("x"), with only integer coefficients, so that "r" is a root of "p", that is, "p"("r")=0. 
Each algebraic number can be defined individually using the order relation on the reals. For example, if a polynomial "q"("x") has 5 roots, the third one can be defined as the unique "r" such that "q"("r") = 0 and such that there are two distinct numbers less than "r" for which "q" is zero. 
All rational numbers are algebraic, and all constructible numbers are algebraic. 
The algebraic numbers form a subfield of the real numbers. This means that 0 and 1 are algebraic numbers and, moreover, if "a" and "b" are algebraic numbers, then so are "a"+"b", "a"-"b", "ab" and, if "b" is nonzero, "a"/"b". 
The algebraic numbers also have the property, which goes beyond being a subfield of the reals, that for each positive integer "n" and each algebraic number "a", all of the "n"th roots of "a" that are real numbers are also algebraic.
There are only countably many algebraic numbers, but there are uncountably many real numbers, so in the sense of cardinality most real numbers are not algebraic. This nonconstructive proof that not all real numbers are algebraic was first published by
Georg Cantor in his 1874 paper "On a Property of the Collection of All Real Algebraic Numbers".
Specific examples of non-algebraic numbers, which are called transcendental numbers, include œÄ and Euler's number "e".
Computable real numbers.
A real number is a computable number if there is an algorithm that, given a natural number "n", produces a decimal expansion for the number accurate to "n" decimal places. This notion was introduced by Alan Turing in 1936.
The computable numbers include the algebraic numbers along with many transcendental numbers including œÄ and¬†"e". Like the algebraic numbers, the computable numbers also form a subfield of the real numbers. 
Not all real numbers are computable. The entire set of computable numbers is countable, so most reals are not computable. Specific examples of noncomputable real numbers include the limits of Specker sequences, and algorithmically random real numbers such as Chaitin's Œ© numbers.
Definability in models of ZFC.
A real number "a" is first-order definable in the language of set theory, without parameters, if there is a formula "œÜ" in the language of set theory, with one free variable, such that "a" is the unique real number such that "œÜ(a)" holds in the standard model of set theory (see ). This notion cannot be expressed as a formula in the language of set theory.
Assuming they form a set, the real numbers definable in a model of ZFC form a field containing all familiar real numbers such as 0, 1, Pi, "e", et cetera. In particular, this field contains all the computable numbers, which include all the numbers named in the mathematical constants article and all algebraic numbers (and therefore all rational numbers).
Each set model "M" of ZFC set theory that contains uncountably many real numbers must contain real numbers that are not definable within "M" (without parameters). This follows from the fact that there are only countably many formulas, and so only countably many elements of "M" can be definable over "M". Thus, if "M" has uncountably many real numbers, we can prove from "outside" "M" that not every real number of "M" is definable over "M". 
This argument becomes more problematic if it is applied to class models of ZFC, such as the von Neumann universe . The argument that applies to set models cannot be directly generalized to class models in ZFC because the property "the real number "x" is definable over the class model "N"" cannot be expressed as a formula of ZFC. Similarly, the question whether the von Neumann universe contains real numbers that it cannot define cannot be expressed as a sentence in the language of ZFC. Moreover, there are models of ZFC in which all real numbers, all sets of real numbers, functions on the reals, etc. are definable .
Definability in arithmetic.
Another notion of definability comes from the formal theories of arithmetic, such as Peano arithmetic. The language of arithmetic has symbols for 0, 1, the successor operation, addition, and multiplication, intended to be interpreted in the usual way over the natural numbers. Because no variables of this language range over the real numbers, a different sort of definability is needed to refer to real numbers. A positive real number "a" is "definable in the language of arithmetic" (or "arithmetical") if its Dedekind cut can be defined as a predicate in that language; that is, if there is a first-order formula "œÜ" in the language of arithmetic, with two free variables, such that
The second-order language of arithmetic is the same as the first-order language, except that variables and quantifiers are allowed to range over sets of naturals. A real that is second-order definable in the language of arithmetic is called "analytical".
Every computable real number is arithmetical, and the arithmetical numbers form a subfield of the reals, as do the analytical numbers. Every arithmetical number is analytical, but not every analytical number is arithmetical. Because there are only countably many analytical numbers, most real numbers are not analytical, and thus also not arithmetical.

</doc>
<doc id="8362" url="https://en.wikipedia.org/wiki?curid=8362" title="Diego de Almagro">
Diego de Almagro

Diego de Almagro, (c. 1475 ‚Äì July 8, 1538), also known as El Adelantado and El Viejo (The Elder), was a Spanish conquistador and a companion and later rival of Francisco Pizarro. He participated in the Spanish conquest of Peru and is credited as the first European discoverer of Chile.
Almagro lost his left eye battling with coastal natives in the New World. In 1525 he joined the Pizarro brothers and Hern√°ndo de Luque at Panama for the conquest of Peru.
Early years.
Diego de Almagro was born and raised in Almagro, Ciudad Real, Spain.
Arrival in America.
Diego de Almagro arrived in the New World on June 30, 1514, under the expedition that Ferdinand II of Aragon had sent under the guidance of Pedrarias D√°vila. The expedition had landed in the city of Santa Mar√≠a la Antigua del Dari√©n, Panama, where many other future conquistadors had already arrived, among them Francisco Pizarro.
There are not many details of Almagro's activities during this period, but it is known that he accompanied various sailors who departed from the city of Darien between 1514 and 1515. Almagro eventually returned and settled in Darien, where he was granted an encomienda. He built a house and made a living from agriculture.
Almagro undertook his first conquest on November 1515, commanding 260 men as he founded Villa del Acla, named after the Indian place. Due to illness he had to leave behind this mission to the licenciate Gaspar de Espinosa.
Espinosa decided to undertake a new expedition, which departed in December of 1515 with 200 men, including Almagro and Francisco Pizarro, who for the first time was designated as a captain. During this expedition, which lasted 14 months, Almagro, Pizarro and Hernando de Luque became close friends.
Also during this time Almagro established a friendship with Vasco N√∫√±ez de Balboa, who was in charge of Acla. Almagro wanted to have a ship built with the remaining materials of the Espinosa expedition, to be finished on the coast of the "Great South Sea," as the Pacific Ocean was first called by the Spanish. Current historians do not believe that Almagro was expected to participate in Balboa's expedition and probably returned to Darien.
Almagro took part in the various expeditions that took place in the Gulf of Panama, taking part again in Espinosa's parties. Espinosa was supported by using Balboa's ships. Almagro was recorded as a witness on the lists of natives whom Espinosa ordered to be carried. Almagro remained as an early settler in the newly founded city of Panama. For four years he stayed there, working at the management of his properties and those of Pizarro. He took Ana Mart√≠nez, an indigenous woman, as a common-law wife. In this period, his first son, el "Mozo", was born to them.
Conquest of Peru.
By 1524 an association of conquest regarding South America was formalized among Almagro, Pizarro and Luque. By the beginning of August 1524, they had received the requisite permission to discover and conquer lands further south. Almagro would remain in Panama to recruit men and gather supplies for the expeditions led by Pizarro.
After several expeditions to South America, Pizarro secured his stay in Peru with the "Capitulation" on 6 July 1529. During Pizarro's continued exploration of Incan territory, he and his men succeeded in defeating the Inca army under Emperor Atahualpa during the Battle of Cajamarca in 1532. Almagro joined Pizarro soon afterward, bringing more men and arms.
After Peru fell to the Spanish, both Pizarro and Almagro initially worked together in the founding of new cities to consolidate their dominions. As such, Pizarro dispatched Almagro to pursue Quizquiz, fleeing to the Inca Empire's northern city of Quito. Their fellow conquistador Sebasti√°n de Belalc√°zar, who had gone forth without Pizarro's approval, had already reached Quito and witnessed the destruction of the city by Inca general Rumi√±awi. The Inca warrior had ordered the city to be burned and its gold to be buried at an undisclosed location where the Spanish could never find it. The arrival of Pedro de Alvarado from Guatemala, in search of Inca gold further complicated the situation for Almagro and Belalc√°zar. Alvarado's presence, however, did not last long as he left South America in exchange for monetary compensation from Pizarro.
In an attempt to claim Quito ahead of Belalc√°zar, in August 1534 Almagro founded a city on the shores of Laguna de Colta (Colta Lake) in the foothills of Chimborazo, some 90 miles south of present-day Quito, and named it "Santiago de Quito." Four months later would come the foundation of the Peruvian city of Trujillo, which Almagro named as "Villa Trujillo de Nueva Castilla" (the Village of Trujillo in New Castille) in honor of Francisco Pizarro's birthplace, Trujillo in Extremadura, Spain. These events were the height of the Pizarro-Almagro friendship, which historians describe as one of the last events in which their friendship soon faded and entered a period of turmoil for the control of the Incan capital of Cuzco.
Conflict with Pizarro.
After splitting the treasure of Inca emperor Atahualpa, both Pizarro and Almagro left towards Cuzco and took the city in 1533. However, Almagro's friendship with Pizarro showed signs of deterioration in 1526 when Pizarro, in the name of the rest of the conquistadors, called forth the "Capitulacion de Toledo" law in which King Charles I of Spain had laid out his authorization for the conquest of Peru and the awards every conquistador would receive from it. Long before, however, each conquistador had promised to equally split the benefits. Pizarro managed to have a larger stake and awards for himself. Despite this, Almagro still obtained an important fortune for his services, and the King awarded him in November 1532 the noble title of "Don" and he was assigned a personal coat of arms.
Although by this time Diego de Almagro had already acquired sufficient wealth in the conquest of Peru and was living a luxurious life in Cuzco, the prospect of conquering the lands further south was very attractive to him. Given that the dispute with Pizarro over Cuzco had kept intensifying, Almagro spent a great deal of time and money equipping a company of 500 men for a new exploration south of Peru.
By 1534 the Spanish crown had determined to split the region in two parallel lines, forming the governorship of "Nueva Castilla" (from the 1¬∞ to the 14¬∞ latitude, close to Pisco), and that of "Nueva Toledo" (from the 14¬∞ to the 25¬∞ latitude, in Taltal, Chile), assigning the first to Francisco Pizarro and the second to Diego de Almagro. The crown had previously assigned Almagro the governorship of Cuzco, and as such Almagro was heading there when Charles V divided the territory between Nueva Castilla and Nueva Toledo. This might have been the reason why Almagro did not immediately confront Pizarro for Cuzco, and promptly decided to embark on his new quest for the discovery of the riches of Chile.
Discovery of Chile.
The preparations.
Charles V had given Diego a grant extending two hundred leagues south of Francisco Pizarro's. Francisco and Diego concluded a new contract on 12 June 1535, in which they agreed to share future discoveries equally. Diego raised an expedition for Chile, expecting it "would lead to even greater riches than they had found in Peru." Almagro prepared the way by sending ahead three of his Spanish soldiers, the religious chief of the Inca empire, "Willaq Umu," and Paullo Topa, brother of "Manco Inca Yupanqui." Almagro sent Juan de Saavedra forward with one hundred and fifty men, and soon followed them with additional forces.
Following the Inca Trail and crossing the Andes.
Almagro left Cuzco on July 3, 1535 with his supporters and stopped at Moina until the 20th of that month. Meanwhile, Francisco Pizarro's brother, Juan Pizarro, had arrested Inca Manco Inca Yupanqui, further complicating Almagro's plans as it heavily increased the dissatisfaction of the Indians submitted to Spanish rule. Not having formally been appointed governor of any territories in the Capitulation of Toledo in 1528, however, forcing him to declare himself "adelantado" (governor) of Nueva Toledo, or southern Peru and present-day Chile. Some sources suggest Almagro received such a requirement in 1534 by the Spanish king and was officially declared governor of New Toledo.
Once he left Moina, Almagro followed the Inca trail followed by 750 Spaniards deciding to join him in quest for the gold lost in the ransom of Atahualpa, which had mainly benefited the Pizarro brothers and their supporters. After crossing the Bolivian mountain range and traveling past Lake Titicaca, Almagro arrived on the shores of the Desaguadero River and finally set up camp in Tupiza. From there, the expedition stopped at Chicoana and then turned to the southeast to cross the Andes mountains.
The expedition turned out to be a difficult and exhausting endeavor. The hardest phase was the crossing of the Andes cordillera: the cold, hunger and tiredness meant the death of various Spaniards and natives, but mainly slaves who were not accustomed to such rigorous climate.
Upon this point, Almagro determined everything was a failure. He ordered a small group under Rodrigo Orgonez on a reconnaissance of the country to the south.
By luck, these men found the Valley of Copiap√≥, where Gonzalo Calvo Barrientos, a Spaniard whom Pizarro had expelled from Peru for stealing objects the Inca had offered for his ransom, had already established a friendship with the local natives. There, in the valley of the river Copiap√≥, Almagro took official possession of Chile and claimed it in the name of King Charles V.
Dismayed in Chile.
Almagro promptly initiated the exploration of the new territory, starting up the valley the Aconcagua River, where he was well received by the natives. However, the intrigues of his interpreter, Felipillo, who had previously helped Pizarro in dealing with "Atahualpa", almost thwarted Almagro's efforts. Felipillo had secretly urged the local natives to attack the Spanish, but they desisted, not understanding the dangers that they posed. Almagro directed G√≥mez de Alvarado along with 100 horsemen and 100 foot to continue the exploration, which ended in the confluence of the √ëuble and Itata rivers. The Battle of Reinohuel√©n between the Spanish and hostile Mapuche Indians forced the explorers to return to the north.
Almagro's own reconnaissance of the land and the bad news of G√≥mez de Alvarado's encounter with the fierce Mapuche, along with the bitter cold winter that settled ferociously upon them, only served to confirm that everything had failed. He never found gold or the cities which Incan scouts had told him lay ahead, only communities of the indigenous population who lived from subsistence agriculture. Local tribes put up fierce resistance to the Spanish forces. The exploration of the territories of Nueva Toledo, which lasted 2 years, was marked by a complete failure for Almagro. Despite this, at first he thought staying and founding a city would serve well for his honor. The initial optimism that led Almagro to bring his son he had with the indigenous Panamanian Ana Mart√≠nez to Chile had faded.
Some historians have suggested that, but for the urging of his senior explorers, Almagro would probably have stayed permanently in Chile. He was urged to return to Peru and this time take definitive possession of Cuzco, so as to consolidate an inheritance for his son. Dismayed with his experience in the south, Almagro made plans of return to Peru. He never officially founded a city in the territory of what is now Chile.
The withdrawal of the Spanish from valleys of Chile was violent: Almagro authorized his soldiers to ransack the natives' properties, leaving their soil desolate. In addition, the Spanish soldiers took natives captive to serve as slaves. The locals were captured, tied together, and forced to carry the heavy loads belonging to the conquistadors.
Return to Peru.
After the exhausting crossing of the Atacama Desert, mainly due to the weather conditions, Almagro finally reached Cuzco, Peru, in 1537. According to some authors, it was during this time that the Spanish term ""roto"" (torn), used by Peruvians to refer to Chileans, was first coined. Almagro's disappointed troops returned to Cuzco with their "torn clothes" due to the extensive and laborious passage on foot by the Atacama Desert.
After his return, Almagro was surprised to learn of the Inca Manco's rebellion. Almagro sent an embassy to the Inca, but they mistrusted all of the Spaniards by this time. Hernando Pizarro's men formed an uneasy truce with Almagro's men, surveying to determine the boundaries of their leaders' royal grants. They needed to determine in which portion the city of Cuzco was located. However, Almagro's troops quickly took the city and imprisoned the Pizarro brothers, Hernando and Gonzalo, on the night of 8 April 1537.
After occupying Cuzco, Almagro confronted an army sent by Francisco Pizarro to liberate his brothers. Alonso de Alvarado commanded it and was defeated during the Battle of Abancay on July 12, 1537. He and some of his men were imprisoned. Later, Gonzalo Pizarro and Alvarado escaped prison. Subsequent negotiations between Francisco Pizarro and Almagro concluded with the liberation of Hernando, the third Pizarro brother, in return for conceding control and administration of Cuzco to Almagro. Pizarro never intended to give up the city permanently, but was buying time to organize an army strong enough to defeat Almagro's troops.
During this time Almagro fell ill, and Pizarro and his brothers grabbed the opportunity to defeat him and his followers. The Almagristas were defeated at Las Salinas in April 1538, with Org√≥√±ez being killed on the field of battle. Almagro fled to Cuzco, still in the hands of his loyal supporters, but found only temporary refuge; the forces of the Pizarro brothers entered the city without resistance. Once captured, Almagro was humiliated by Hernando Pizarro and his requests to appeal to the King were ignored.
As Almagro begged for his life, Hernando responded:
"-he was surprised to see Almagro demean himself in a manner so unbecoming a brave cavalier, that his fate was no worse than had befallen many a soldier before him; and that, since God had given him the grace to be a Christian, he should employ his remaining moments in making up his account with Heaven!"
Almagro was condemned to death and executed by "garrote" in his dungeon, and then decapitated, on July 8, 1538. His corpse was taken to the public Plaza Mayor of Cuzco, where a herald proclaimed his crimes. Hernan Ponce de Leon took his body and buried him in the church of Our Lady of Mercy in Cuzco.
El Mozo.
Diego de Almagro II (1520‚Äì1542), known as "El Mozo" (The Lad), son of Diego de Almagro I, whose mother was an Indian girl of Panama, became the foil of the conspirators who had put Pizarro to the sword. Pizarro was murdered on June 26, 1541; the conspirators promptly proclaimed the lad Almagro Governor of Peru. From various causes, all of the conspirators either died or were killed except for one, who was executed after the lad Almagro gave an order. The lad Almagro fought the desperate battle of Chupas on September 16, 1542, escaped to Cuzco, but was arrested, immediately condemned to death, and executed in the great square of the city.

</doc>
<doc id="8363" url="https://en.wikipedia.org/wiki?curid=8363" title="Divinity">
Divinity

In religious terms, divinity or godhead is the state of things that come from a supernatural power or deity, such as a god, supreme being, creator deity, or spirits, and are therefore regarded as sacred and holy.
Such things are regarded as "divine" due to their transcendental origins, and/or because their attributes or qualities are superior or supreme relative to things of the Earth. Divine things are regarded as eternal and based in truth, while material things are regarded as ephemeral and based in illusion. Such things that may qualify as "divine" are apparitions, visions, prophecies, miracles, and in some views also the soul, or more general things like resurrection, immortality, grace, and salvation. Otherwise what is or is not divine may be loosely defined, as it is used by different belief systems.
The root of the word "divine" is literally "godly" (from the Latin "deus", cf. "Dyaus", closely related to Greek "zeus", "div" in Persian and "deva" in Sanskrit), but the use varies significantly depending on which deity is being discussed. This article outlines the major distinctions in the conventional use of the terms.
For specific related academic terms, see Divinity (academic discipline), or Divine (Anglican).
Usages.
Divinity as a quality has two distinct usages:
Overlap occurs between these usages because deities or godly entities are often identical with and/or identified by the powers and forces that are credited to them¬†‚Äî in many cases a deity is merely a power or force personified¬†‚Äî and these powers and forces may then be extended or granted to mortal individuals. For instance, Jehovah is closely associated with storms and thunder throughout much of the Old Testament. He is said to speak in thunder, and thunder is seen as a token of his anger. This power was then extended to prophets like Moses and Samuel, who caused thunderous storms to rain down on their enemies. (See and 1 Samuel 12:18.)
Divinity always carries connotations of goodness, beauty, beneficence, justice, and other positive, pro-social attributes. In monotheistic faiths there is an equivalent cohort of malefic supranormal beings and powers, such as demons, devils, afreet, etc., which are not conventionally referred to as divine; "demonic" is often used instead. Pantheistic and polytheistic faiths make no such distinction; gods and other beings of transcendent power often have complex, ignoble, or even irrational motivations for their acts. Note that while the terms "demon" and "demonic" are used in monotheistic faiths as antonyms to "divine", they are in fact derived from the Greek word "daim√≥n" (Œ¥Œ±ŒØŒºœâŒΩ), which itself translates as "divinity".
There are three distinct usages of "divinity" and "divine" in religious discourse:
Entity.
In monotheistic faiths, the word "divinity" is often used to refer to the singular God central to that faith. Often the word takes the definite article and is capitalized¬†‚Äî ""the Divinity""¬†‚Äî as though it were a proper name or definitive honorific. 
"Divine"¬†‚Äî capitalized¬†‚Äî may be used as an adjective to refer to the manifestations of such a Divinity or its powers: e.g. "basking in the Divine presence..."
The terms "divinity" and "divine"¬†‚Äî uncapitalized, and lacking the definite article¬†‚Äî are sometimes used as to denote 'god(s) or certain other beings and entities which fall short of absolute Godhood but lie outside the human realm. These include (by no means an exhaustive list):
Divine force or power.
As previously noted, divinities are closely related to the transcendent force(s) or power(s) credited to them, so much so that in some cases the powers or forces may themselves be invoked independently. This leads to the second usage of the word "divine" (and a less common usage of "divinity"): to refer to the operation of transcendent power in the world.
In its most direct form, the operation of transcendent power implies some form of divine intervention. For pan- and polytheistic faiths this usually implies the direct action of one god or another on the course of human events. In Greek legend, for instance, it was Poseidon (god of the sea) who raised the storms which blew Odysseus' craft off course on his return journey, and Japanese tradition holds that a god-sent wind saved them from Mongol invasion. Prayers or propitiations are often offered to specific gods of pantheisms to garner favorable interventions in particular enterprises: e.g. safe journeys, success in war, or a season of bountiful crops. Many faiths around the world¬†‚Äî from Japanese Shinto and Chinese traditional religion, to certain African practices and the faiths derived from those in the Caribbean, to Native American beliefs¬†‚Äî hold that ancestral or household spirits offer daily protection and blessings. In monotheistic religions, divine intervention may take very direct forms: miracles, visions, or intercessions by blessed figures.
Transcendent force or power may also operate through more subtle and indirect paths. Monotheistic faiths generally support some version of divine providence, which acknowledges that the divinity of the faith has a profound but unknowable plan always unfolding in the world. Unforeseeable, overwhelming, or seemingly unjust events are often thrown on 'the will of the Divine', in deferences like the Muslim "inshallah" ('as God wills it') and Christian 'God works in mysterious ways'. Often such faiths hold out the possibility of divine retribution as well, where the divinity will unexpectedly bring evil-doers to justice through the conventional workings of the world; from the subtle redressing of minor personal wrongs, to such large-scale havoc as the destruction of Sodom and Gomorrah or the biblical Great Flood. Other faiths are even more subtle: the doctrine of "karma" shared by Buddhism and Hinduism is a divine law similar to divine retribution but without the connotation of punishment: our acts, good or bad, intentional or unintentional, reflect back on us as part of the natural working of the universe. Philosophical Taoism also proposes a transcendent operant principle¬†‚Äî transliterated in English as "tao" or "dao", meaning 'the way'¬†‚Äî which is neither an entity or a being per se, but reflects the natural ongoing process of the world. Modern western mysticism and new age philosophy often use the term 'the Divine' as a noun in this latter sense: a non-specific principle and/or being that gives rise to the world, and acts as the source or wellspring of life. In these latter cases the faiths do not promote deference, as happens in monotheisms; rather each suggests a path of action that will bring the practitioner into conformance with the divine law: "ahimsa"¬†‚Äî 'no harm'¬†‚Äî for Buddhist and Hindu faiths; "de" or "te"¬†‚Äî 'virtuous action'¬†‚Äî in Taoism; and any of numerous practices of peace and love in new age thinking.
Mortals.
In the third usage, extensions of divinity and divine power are credited to living, mortal individuals. Political leaders are known to have claimed actual divinity in certain early societies¬†‚Äî the ancient Egyptian Pharaohs being the premier case¬†‚Äî taking a role as objects of worship and being credited with superhuman status and powers. More commonly, and more pertinent to recent history, leaders merely claim some form of divine mandate, suggesting that their rule is in accordance with the will of God. The doctrine of the divine right of kings was introduced as late as the 17th century, proposing that kings rule by divine decree; Japanese Emperors ruled by divine mandate until the inception of the Japanese constitution after World War II
Less politically, most faiths have any number of people that are believed to have been touched by divine forces: saints, prophets, heroes, oracles, martyrs, and enlightened beings, among others. Saint Francis of Assisi, in Catholicism, is said to have received instruction directly from God and it is believed that he grants plenary indulgence to all who confess their sins and visit his chapel on the appropriate day. In Greek mythology, Achilles' mother bathed him in the river Styx to give him immortality, and Hercules¬†‚Äî as the son of Zeus¬†‚Äî inherited near-godly powers. In religious Taoism, Lao Tsu is venerated as a saint with his own powers. Various individuals in the Buddhist faith, beginning with Siddhartha, are considered to be enlightened, and in religious forms of Buddhism they are credited with divine powers. Muhammad and Christ, in their respective traditions, are each said to have performed divine miracles.
In general, mortals with divine qualities are carefully distinguished from the deity or deities in their religion's main pantheon. Even the Christian faith, which generally holds Christ to be identical to God, distinguishes between God the Father and Christ the begotten Son. There are, however, certain esoteric and mystical schools of thought, present in many faiths¬†‚Äî Sufis in Islam, Gnostics in Christianity, Advaitan Hindus, Zen Buddhists, as well as several non-specific perspectives developed in new age philosophy¬†‚Äî which hold that all humans are in essence divine, or unified with the Divine in a non-trivial way. Such divinity, in these faiths, would express itself naturally if it were not obscured by the social and physical worlds we live in; it needs to be brought to the fore through appropriate spiritual practices.
Christianity.
In traditional Christian theology, the concept and nature of divinity always has its source ultimately from God himself. It's the state or quality of being divine, and the term can denote Godly nature or character. In Hebrew, the terms would usually be "el", "elohim", and in Greek usually "theos", or "theias". The divinity in the Bible is considered the Godhead itself, or God in general. Or it may have reference to a deity. Even angels in the Psalms are considered divine or "elohim", as spirit beings, in God's form. Redeemed Christians, when taken to heaven as immortalized born-again believers, according to Biblical verses, are said to partake of the "divine nature". (Psalm 8:5; Hebrews 2:9; 2 Peter 1:4)
In the Christian Greek Scriptures of the Bible, the Greek word Œ∏Œµ·øñŒøŒΩ ("theion") in the Douay Version, is translated as "divinity". Examples are below:
The word translated as either "deity", "Godhead", or "divinity" in the Greek New Testament is also the Greek word Œ∏ŒµœåœÑŒ∑œÑŒøœÇ ("theotƒìtos"), and the one Verse that contains it is this:
Colossians 2:9
The word "divine" in the New Testament is the Greek word Œ∏ŒµŒØŒ±œÇ ("theias"), and is the adjective form of "divinity". Biblical examples from the King James Bible are below:
Latter-day Saints.
The most prominent conception of divine entities in The Church of Jesus Christ of Latter-day Saints (LDS Church) is the Godhead, a divine council of three distinct beings: Elohim (the Father), Jehovah (the Son, or Jesus), and the Holy Spirit. Joseph Smith described a nontrinitarian Godhead, with God the Father and Jesus Christ each having individual physical bodies, and the Holy Spirit as a distinct personage with a spirit body. Smith also introduced the existence of a Heavenly Mother in the King Follett Discourse, but very little is acknowledged or known beyond her existence.
Mormons hold a belief in the divine potential of humanity; Smith taught a form of divinization where mortal men and women can become like god through salvation and exaltation. Lorenzo Snow succinctly summarized this using a couplet, which is often repeated within the LDS Church: "As man now is, God once was: As God now is, man may be."

</doc>
<doc id="8367" url="https://en.wikipedia.org/wiki?curid=8367" title="Depth of field">
Depth of field

In optics, particularly as it relates to film and photography, depth of field (DOF), also called "focus range" or "effective focus range", is the distance between the nearest and farthest objects in a scene that appear acceptably sharp in an image. Although a lens can precisely focus at only one distance at a time, the decrease in sharpness is gradual on each side of the focused distance, so that within the DOF, the unsharpness is imperceptible under normal viewing conditions.
In some cases, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, a small DOF may be more effective, emphasizing the subject while de-emphasizing the foreground and background. In cinematography, a large DOF is often called deep focus, and a small DOF is often called shallow focus.
Circle of confusion criterion for depth of field.
Precise focus is possible at only one distance; at that distance, a point object will produce a point image. At any other distance, a point object is "defocused", and will produce a blur spot shaped like the aperture, which for the purpose of analysis is usually assumed to be circular. When this circular spot is sufficiently small, it is indistinguishable from a point, and appears to be in focus; it is rendered as "acceptably sharp". The diameter of the circle increases with distance from the point of focus; the largest circle that is indistinguishable from a point is known as the "acceptable circle of confusion", or informally, simply as the "circle of confusion". The acceptable circle of confusion is influenced by visual acuity, viewing conditions, and the amount by which the image is enlarged (Ray 2000, 52‚Äì53). The increase of the circle diameter with defocus is gradual, so the limits of depth of field are not hard boundaries between sharp and unsharp.
Motion picture.
For 35¬†mm motion pictures, the image area on the film is roughly 22¬†mm by 16¬†mm. The limit of tolerable error was traditionally set at 0.05¬†mm (0.002¬†in) diameter, while for 16¬†mm¬†film, where the size is about half as large, the tolerance is stricter, 0.025¬†mm (0.001¬†in). More modern practice for 35¬†mm productions set the circle of confusion limit at 0.025¬†mm (0.001¬†in).
Still photography.
For full-frame 35mm still photography, the circle of confusion is usually chosen to be about 1/30¬†mm. Because the human eye is capable of resolving a spot with diameter about 1/4¬†mm at 25¬†cm distance from the viewing eye, and the 35¬†mm negative needs about an 8X enlargement to make an 8x10 inch print, it is sometimes argued that the criterion should be about 1/32¬†mm on the 35mm negative, but 1/30¬†mm is close enough.
For 6x6 cm format enlarged to 8x8 inches and viewed at 25¬†cm, the enlargement is 3.4X, hence the circle of confusion criterion is about 1/(3.4 x 4) = 0.07¬†mm.
Similarly, for subminiature photography (for example Tessina) with a frame format of 14x21mm, 8x12 inches corresponds to 14.5X enlargement, hence circle of confusion limit about 0.017¬†mm.
Many sources propose CoC limits as a fraction of the film format diagonal, typically 1/1000 in the early twentieth century to 1/1500 more recently. The three formats above at fraction 1/1500 would use 0.029 (about 1/32), 0.056, and 0.017¬†mm.
Object field methods.
Traditional depth-of-field formulas and tables assume equal circles of confusion for near and far objects. Some authors, such as Merklinger (1992), have suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, do not need to be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the "object field method" by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.
Other authors (Adams 1980, 51) have taken the opposite position, maintaining that slight unsharpness in foreground objects is usually more disturbing than slight unsharpness in distant parts of a scene.
Moritz von Rohr also used an object field method, but unlike Merklinger, he used the conventional criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear depths of field.
Factors affecting depth of field.
Several other factors, such as subject matter, movement, camera-to-subject distance, lens focal length, selected lens "f"-number, format size, and circle of confusion criteria also influence when a given defocus becomes noticeable. The combination of focal length, subject distance, and format size defines magnification at the film / sensor plane.
DOF is determined by subject magnification at the film / sensor plane and the selected lens aperture or "f"-number. For a given "f"-number, increasing the magnification, either by moving closer to the subject or using a lens of greater focal length, decreases the DOF; decreasing magnification increases DOF. For a given subject magnification, increasing the "f"-number (decreasing the aperture diameter) increases the DOF; decreasing "f"-number decreases DOF.
If the original image is enlarged to make the final image, the circle of confusion in the original image must be smaller than that in the final image by the ratio of enlargement. Cropping an image and enlarging to the same size final image as an uncropped image taken under the same conditions is equivalent to using a smaller format under the same conditions, so the cropped image has less DOF. (Stroebel 1976, 134, 136‚Äì37).
When focus is set to the hyperfocal distance, the DOF extends from half the hyperfocal distance to infinity, and the DOF is the largest possible for a given "f"-number.
Relationship of DOF to format size.
The comparative DOFs of two different format sizes depend on the conditions of the comparison. The DOF for the smaller format can be either more than or less than that for the larger format. In the discussion that follows, it is assumed that the final images from both formats are the same size, are viewed from the same distance, and are judged with the same circle of confusion criterion. (Derivations of the effects of format size are given under Derivation of the DOF formulas.)
"Same picture" for both formats.
When the "same picture" is taken in two different format sizes from the same distance at the same "f"-number with lenses that give the same angle of view, and the final images (e.g., in prints, or on a projection screen or electronic display) are the same size, DOF is, to a first approximation, inversely proportional to format size (Stroebel 1976, 139). Though commonly used when comparing formats, the approximation is valid only when the subject distance is large in comparison with the focal length of the larger format and small in comparison with the hyperfocal distance of the smaller format.
Moreover, the larger the format size, the longer a lens will need to be to capture the same framing as a smaller format. In motion pictures, for example, a frame with a 12 degree horizontal field of view will require a 50¬†mm lens on 16¬†mm film, a 100¬†mm lens on 35¬†mm film, and a 250¬†mm lens on 65¬†mm film. Conversely, using the same focal length lens with each of these formats will yield a progressively wider image as the film format gets larger: a 50¬†mm lens has a horizontal field of view of 12¬†degrees on 16¬†mm film, 23.6¬†degrees on 35¬†mm film, and 55.6¬†degrees on 65¬†mm film. Therefore, because the larger formats require longer lenses than the smaller ones, they will accordingly have a smaller depth of field. Compensations in exposure, framing, or subject distance need to be made in order to make one format look like it was filmed in another format.
Same focal length for both formats.
Many small-format digital SLR camera systems allow using many of the same lenses on both full-frame and "cropped format" cameras. If, for the same focal length setting, the subject distance is adjusted to provide the "same field of view" at the subject, at the same "f"-number and final-image size, the smaller format has "greater" DOF, as with the "same picture" comparison above. If pictures are taken from the "same distance" using the same "f"-number, same focal length, and the final images are the same size, the smaller format has "less" DOF. If pictures taken from the same subject distance using the same focal length, are given the "same enlargement", both final images will have the "same" DOF. The pictures from the two formats will differ because of the different angles of view. If the larger format is cropped to the captured area of the smaller format, the final images will have the same angle of view, have been given the same enlargement, and have the same DOF.
Same DOF for both formats.
In many cases, the DOF is fixed by the requirements of the desired image. For a given DOF and field of view, the required "f"-number is proportional to the format size. For example, if a 35¬†mm camera required 11, a 4√ó5 camera would require 45 to give the same DOF. For the same ISO speed, the exposure time on the 4√ó5 would be sixteen times as long; if the 35¬†camera required 1/250 second, the 4√ó5 camera would require 1/15 second. The longer exposure time with the larger camera might result in motion blur, especially with windy conditions, a moving subject, or an unsteady camera.
Adjusting the "f"-number to the camera format is equivalent to maintaining the same absolute aperture diameter; when set to the same absolute aperture diameters, both formats have the same DOF.
Comparison of fast standard lenses in the four main formats when used for portraiture with appropriate circles of confusion to produce an uncropped image at 10x8 inches to be viewed at 25¬†cm show that the following settings with similar aperture diameters produce similar DoF:
For any of these, doubling the f-number will approximately double the depth of field.
Camera movements and DOF.
When the lens axis is perpendicular to the image plane, as is normally the case, the plane of focus (POF) is parallel to the image plane, and the DOF extends between parallel planes on either side of the POF. When the lens axis is not perpendicular to the image plane, the POF is no longer parallel to the image plane; the ability to rotate the POF is known as the Scheimpflug principle. Rotation of the POF is accomplished with camera movements (tilt, a rotation of the lens about a horizontal axis, or swing, a rotation about a vertical axis). Tilt and swing are available on most view cameras, and are also available with specific lenses on some small- and medium-format cameras.
When the POF is rotated, the near and far limits of DOF are no longer parallel; the DOF becomes wedge-shaped, with the apex of the wedge nearest the camera (Merklinger 1993, 31‚Äì32; Tillmanns 1997, 71). With tilt, the height of the DOF increases with distance from the camera; with swing, the width of the DOF increases with distance.
In some cases, rotating the POF can better fit the DOF to the scene, and achieve the required sharpness at a smaller f-number. Alternatively, rotating the POF, in combination with a small f-number, can minimize the part of an image that is within the DOF.
Effect of lens aperture.
For a given subject framing and camera position, the DOF is controlled by the lens aperture diameter, which is usually specified as the f-number, the ratio of lens focal length to aperture diameter. Reducing the aperture diameter (increasing the f-number) increases the DOF because the circle of confusion is shrunk directly and indirectly by reducing the light hitting the outside of the lens which is focused to a different point than light hitting the inside of the lens due to spherical aberration caused by the construction of the lens; however, it also reduces the amount of light transmitted, and increases diffraction, placing a practical limit on the extent to which DOF can be increased by reducing the aperture diameter.
Motion pictures make only limited use of this control; to produce a consistent image quality from shot to shot, cinematographers usually choose a single aperture setting for interiors and another for exteriors, and adjust exposure through the use of camera filters or light levels. Aperture settings are adjusted more frequently in still photography, where variations in depth of field are used to produce a variety of special effects.
Digital techniques affecting DOF.
The advent of digital technology in photography has provided additional means of controlling the extent of image sharpness; some methods allow extended DOF that would be impossible with traditional techniques, and some allow the DOF to be determined after the image is made.
Focus stacking is a digital image processing technique which combines multiple images taken at different focus distances to give a resulting image with a greater depth of field than any of the individual source images. Available programs for multi-shot DOF enhancement include Adobe Photoshop, Syncroscopy AutoMontage, PhotoAcute Studio, Helicon Focus and CombineZ. Getting sufficient depth of field can be particularly challenging in macro photography. The images to the right illustrate the extended DOF that can be achieved by combining multiple images.
Wavefront coding is a method that convolves rays in such a way that it provides an image where fields are in focus simultaneously with all planes out of focus by a constant amount.
A plenoptic camera uses a microlens array to capture 4D light field information about a scene.
Colour apodization is a technique combining a modified lens design with image processing to achieve an increased depth of field. The lens is modified such that each colour channel has a different lens aperture. For example, the red channel may be f/2.4, green may be f/2.4, whilst the blue channel may be f/5.6. Therefore, the blue channel will have a greater depth of field than the other colours. The image processing identifies blurred regions in the red and green channels and in these regions copies the sharper edge data from the blue channel. The result is an image that combines the best features from the different f-numbers, (Kay 2011).
In 2013, Nokia implemented DOF control in some of its high-end smartphones, called Refocus, which can change a picture's depth of field after the picture is taken. It works best when there are close-up and distant objects in the frame.
Diffraction and DOF.
If the camera position and image framing (i.e., angle of view) have been chosen, the only means of controlling DOF is the lens aperture. Most DOF formulas imply that any arbitrary DOF can be achieved by using a sufficiently large f-number. Because of diffraction, however, this isn't really true. Once a lens is stopped down to where most aberrations are well corrected, stopping down further will decrease sharpness in the plane of focus. At the DOF limits, however, further stopping down decreases the size of the defocus blur spot, and the overall sharpness may still increase. Eventually, the defocus blur spot becomes negligibly small, and further stopping down serves only to decrease sharpness even at DOF limits (Gibson 1975, 64). There is thus a tradeoff between sharpness in the POF and sharpness at the DOF limits. But the sharpness in the POF is always greater than that at the DOF limits; if the blur at the DOF limits is imperceptible, the blur in the POF is imperceptible as well.
For general photography, diffraction at DOF limits typically becomes significant only at fairly large f-numbers; because large f-numbers typically require long exposure times, motion blur may cause greater loss of sharpness than the loss from diffraction. The size of the diffraction blur spot depends on the effective f-number formula_1, however, so diffraction is a greater issue in close-up photography, and the tradeoff between DOF and overall sharpness can become quite noticeable (Gibson 1975, 53; Lefkowitz 1979, 84).
DOF scales.
Many lenses for small- and medium-format cameras include scales that indicate the DOF for a given focus distance and f-number; the 35¬†mm lens in the image is typical. That lens includes distance scales in feet and meters; when a marked distance is set opposite the large white index mark, the focus is set to that distance. The DOF scale below the distance scales includes markings on either side of the index that correspond to f-numbers. When the lens is set to a given f-number, the DOF extends between the distances that align with the f-number markings.
Some cameras have the DOF scale not on lens barrel, but on focusing knob or dial; for example, the Rolleiflex TLR has its DOF scale on the focusing knob; the subminiature camera Tessina has DOF a scale on the focusing dial.
Zone focusing.
When the 35¬†mm lens above is set to f/11 and focused at approximately 1.3¬†m, the DOF (a "zone" of acceptable sharpness) extends from 1¬†m to 2¬†m. Conversely, the required focus and f-number can be determined from the desired DOF limits by locating the near and far DOF limits on the lens distance scale and setting focus so that the index mark is centered between the near and far distance marks. The required f-number is determined by finding the markings on the DOF scale that are closest to the near and far distance marks (Ray 1994, 315). For the 35¬†mm lens above, if it were desired for the DOF to extend from 1¬†m to 2¬†m, focus would be set so that index mark was centered between the marks for those distances, and the aperture would be set to f/11.
The focus so determined would be about 1.3¬†m, the approximate harmonic mean of the near and far distances. See the section Focus and "f"-number from DOF limits for additional discussion.
If the marks for the near and far distances fall outside the marks for the largest f-number on the DOF scale, the desired DOF cannot be obtained; for example, with the 35¬†mm lens above, it is not possible to have the DOF extend from 0.7¬†m to infinity. The DOF limits can be determined visually, by focusing on the farthest object to be within the DOF and noting the distance mark on the lens distance scale, and repeating the process for the nearest object to be within the DOF.
Some distance scales have markings for only a few distances; for example, the 35¬†mm lens above shows only 3¬†ft and 5¬†ft on its upper scale. Using other distances for DOF limits requires visual interpolation between marked distances. Since the distance scale is nonlinear, accurate interpolation can be difficult. In most cases, English and metric distance markings are not coincident, so using both scales to note focused distances can sometimes lessen the need for interpolation. Many autofocus lenses have smaller distance and DOF scales and fewer markings than do comparable manual-focus lenses, so that determining focus and f-number from the scales on an autofocus lens may be more difficult than with a comparable manual-focus lens. In most cases, determining these settings using the lens DOF scales on an autofocus lens requires that the lens or camera body be set to manual focus.
On a view camera, the focus and f-number can be obtained by measuring the "focus spread" and performing simple calculations. The procedure is described in more detail in the section Focus and f-number from DOF limits. Some view cameras include DOF calculators that indicate focus and f-number without the need for any calculations by the photographer (Tillmanns 1997, 67‚Äì68; Ray 2002, 230‚Äì31).
Hyperfocal distance.
The hyperfocal distance is the nearest focus distance at which the DOF extends to infinity; focusing the camera at the hyperfocal distance results in the largest possible depth of field for a given f-number (Ray 2000, 55). Focusing "beyond" the hyperfocal distance does not increase the far DOF (which already extends to infinity), but it does decrease the DOF in front of the subject, decreasing the total DOF. Some photographers consider this wasting DOF; however, see Object field methods above for a rationale for doing so. Focusing on the hyperfocal distance is a special case of zone focusing in which the far limit of DOF is at infinity.
If the lens includes a DOF scale, the hyperfocal distance can be set by aligning the infinity mark on the distance scale with the mark on the DOF scale corresponding to the f-number to which the lens is set. For example, with the 35¬†mm lens shown above set to f/11, aligning the infinity mark with the '11' to the left of the index mark on the DOF scale would set the focus to the hyperfocal distance.
Hyperfocusing.
Some cameras have their hyperfocal distance marked on the focus dial. For example, on the Minox LX focusing dial there is a red dot between 2 m and infinity; when the lens is set at the red dot, that is, focused at the hyperfocal distance, the depth of field stretches from 2 m to infinity.
The Zeiss Ikon Contessa camera has 20¬†ft marked in red, and aperture 8 marked in red; this is the snapshot hyperfocal setting.
Limited DOF: selective focus.
Depth of field can be anywhere from a fraction of a millimeter to virtually infinite. In some cases, such as landscapes, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, artistic considerations may dictate that only a part of the image be in focus, emphasizing the subject while de-emphasizing the background, perhaps giving only a suggestion of the environment (Langford 1973, 81). For example, a common technique in melodramas and horror films is a closeup of a person's face, with someone just behind that person visible but out of focus. A portrait or close-up still photograph might use a small DOF to isolate the subject from a distracting background. The use of limited DOF to emphasize one part of an image is known as "selective focus", "differential focus" or "shallow focus".
Although a small DOF implies that other parts of the image will be unsharp, it does not, by itself, determine "how" unsharp those parts will be. The amount of background (or foreground) blur depends on the distance from the plane of focus, so if a background is close to the subject, it may be difficult to blur sufficiently even with a small DOF. In practice, the lens f-number is usually adjusted until the background or foreground is acceptably blurred, often without direct concern for the DOF.
Sometimes, however, it is desirable to have the entire subject sharp while ensuring that the background is sufficiently unsharp. When the distance between subject and background is fixed, as is the case with many scenes, the DOF and the amount of background blur are not independent. Although it is not always possible to achieve both the desired subject sharpness and the desired background unsharpness, several techniques can be used to increase the separation of subject and background.
For a given scene and subject magnification, the background blur increases with lens focal length. If it is not important that background objects be unrecognizable, background de-emphasis can be increased by using a lens of longer focal length and increasing the subject distance to maintain the same magnification. This technique requires that sufficient space in front of the subject be available; moreover, the perspective of the scene changes because of the different camera position, and this may or may not be acceptable.
The situation is not as simple if it is important that a background object, such as a sign, be unrecognizable. The magnification of background objects also increases with focal length, so with the technique just described, there is little change in the recognizability of background objects. However, a lens of longer focal length may still be of some help; because of the narrower angle of view, a slight change of camera position may suffice to eliminate the distracting object from the field of view.
Although tilt and swing are normally used to maximize the part of the image that is within the DOF, they also can be used, in combination with a small f-number, to give selective focus to a plane that isn't perpendicular to the lens axis. With this technique, it is possible to have objects at greatly different distances from the camera in sharp focus and yet have a very shallow DOF. The effect can be interesting because it differs from what most viewers are accustomed to seeing.
Near:far distribution.
The DOF beyond the subject is always greater than the DOF in front of the subject. When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, so the ratio is 1:‚àû; as the subject distance decreases, near:far DOF ratio increases, approaching unity at high magnification. For large apertures at typical portrait distances, the ratio is still close to 1:1. The oft-cited rule that 1/3 of the DOF is in front of the subject and 2/3 is beyond (a 1:2 ratio) is true only when the subject distance is 1/3 the hyperfocal distance.
Optimal f-number.
As a lens is stopped down, the defocus blur at the DOF limits decreases but diffraction blur increases. The presence of these two opposing factors implies a point at which the combined blur spot is minimized (Gibson 1975, 64); at that point, the f-number is optimal for image sharpness.
If the final image is viewed under normal conditions (e.g., an 8‚Ä≥√ó10‚Ä≥ image viewed at 10‚Ä≥), it may suffice to determine the f-number using criteria for minimum required sharpness, and there may be no practical benefit from further reducing the size of the blur spot. But this may not be true if the final image is viewed under more demanding conditions, e.g., a very large final image viewed at normal distance, or a portion of an image enlarged to normal size (Hansma 1996). Hansma also suggests that the final-image size may not be known when a photograph is taken, and obtaining the maximum practicable sharpness allows the decision to make a large final image to be made at a later time.
Determining combined defocus and diffraction.
Hansma (1996) and Peterson (1996) have discussed determining the combined effects of defocus and diffraction using a root-square combination of the individual blur spots. Hansma's approach determines the f-number that will give the maximum possible sharpness; Peterson's approach determines the minimum f-number that will give the desired sharpness in the final image, and yields a maximum focus spread for which the desired sharpness can be achieved. In combination, the two methods can be regarded as giving a maximum and minimum f-number for a given situation, with the photographer free to choose any value within the range, as conditions (e.g., potential motion blur) permit. Gibson (1975), 64) gives a similar discussion, additionally considering blurring effects of camera lens aberrations, enlarging lens diffraction and aberrations, the negative emulsion, and the printing paper. Couzin (1982) gave a formula essentially the same as Hansma's for optimal "f"-number, but did not discuss its derivation.
Hopkins (1955), Stokseth (1969), and Williams and Becklund (1989) have discussed the combined effects using the modulation transfer function. Conrad's Depth of Field in Depth (PDF), and Jacobson's Photographic Lenses Tutorial discuss the use of Hopkins's method specifically in regard to DOF.
Other applications.
Photolithography.
In semiconductor photolithography applications, depth of field is extremely important as integrated circuit layout features must be printed with high accuracy at extremely small size. The difficulty is that the wafer surface is not perfectly flat, but may vary by several micrometres. Even this small variation causes some distortion in the projected image, and results in unwanted variations in the resulting pattern. Thus photolithography engineers take extreme measures to maximize the optical depth of field of the photolithography equipment. To minimize this distortion further, semiconductor manufacturers may use chemical mechanical polishing to make the wafer surface even flatter before lithographic patterning.
Ophthalmology and optometry.
A person may sometimes experience better vision in daylight than at night because of an increased depth of field due to constriction of the pupil (i.e., miosis).
DOF formulae.
The basis of these formulas is given in the section Derivation of the DOF formulae; refer to the diagram in that section for illustration of the quantities discussed below.
Hyperfocal distance.
Let formula_2 be the lens focal length,
formula_3 be the lens f-number, and formula_4 be the
circle of confusion for a given image format. The
hyperfocal distance formula_5 is given by
Moderate-to-large distances.
Let formula_7 be the distance at which the camera is focused (the
"subject distance"). When formula_7 is large in comparison with the
lens focal length, the distance formula_9 from the
camera to the near limit of DOF and the distance formula_10
from the camera to the far limit of DOF are
and
The depth of field formula_13 is
Substituting for formula_5 and rearranging, DOF can be expressed as
Thus, for a given image format, depth of field is determined
by three factors: the focal length of the lens, the f-number of the
lens opening (the aperture), and the camera-to-subject distance.
When the subject distance is the hyperfocal distance,
and
For formula_19, the far limit of DOF is at infinity and the DOF
is infinite; of course, only objects at or beyond the near limit of DOF
will be recorded with acceptable sharpness.
Close-up.
When the subject distance formula_7 approaches the focal length, using the formulas given above can result in significant errors. For close-up work, the hyperfocal distance has little applicability, and it usually is more convenient to express DOF in terms of image magnification. Let formula_21 be the magnification; when the subject distance is small in
comparison with the hyperfocal distance,
so that for a given magnification, DOF is independent of focal length. Stated otherwise, for the same subject magnification, at the same "f"-number, all focal lengths
used on a given image format give approximately the same DOF. This statement is true "only" when the subject distance is small in comparison with the hyperfocal distance, however.
The discussion thus far has assumed a symmetrical lens for which the
entrance and exit pupils coincide with the front and rear nodal planes, and for which the pupil magnification (the ratio of exit pupil diameter to that of the entrance pupil) is unity. Although this assumption usually is reasonable for large-format lenses, it
often is invalid for medium- and small-format lenses.
When formula_23, the DOF for an asymmetrical lens is
where formula_25 is the pupil magnification. When the
pupil magnification is unity, this equation reduces to that for a
symmetrical lens.
Except for close-up and macro photography, the effect of lens asymmetry is minimal. At unity magnification, however, the errors from neglecting the
pupil magnification can be significant. Consider a telephoto lens with formula_26 and a retrofocus wide-angle lens with formula_27, at formula_28. The asymmetrical-lens formula gives formula_29 and formula_30, respectively. The symmetrical-lens formula gives formula_31 in either case. The errors are ‚àí33% and 33%, respectively.
Focus and f-number from DOF limits.
For given near and far DOF limits formula_9 and formula_10, the required f-number is smallest when focus is set to
the harmonic mean of the near and far distances. When the subject distance is large in comparison with the lens focal length, the required f-number is
When the far limit of DOF is at infinity,
and
In practice, these settings usually are determined on the image side of the lens, using measurements on the bed or rail with a view camera, or using lens DOF scales on manual-focus lenses for small- and medium-format cameras. If formula_38 and formula_39 are the image distances that correspond to the near and far limits of DOF,
the required f-number is minimized when the image distance
formula_40 is
In practical terms, focus is set to halfway between the near and far
image distances. The required f-number is
The image distances are measured from the camera's image plane to the
lens's image nodal plane, which is not always easy to locate. In most cases, focus and f-number can be determined with sufficient accuracy using the approximate formulas above, which require only the difference between the near and far image distances; view camera users sometimes refer to the difference formula_43 as the "focus spread" (Hansma 1996, 55). Most lens DOF scales are based on the same concept.
The focus spread is related to the depth of focus. Ray (2000, 56) gives two definitions of the latter. The first is the tolerance of the position of the image plane for which an object remains acceptably sharp; the second is that the limits of depth of focus are the image-side conjugates of the near and far limits of DOF. With the first definition, focus spread and depth of focus are usually close in value though conceptually different. With the second definition, focus spread and depth of focus are the same.
Foreground and background blur.
If a subject is at distance formula_7 and the foreground or background is at distance formula_45, let the distance between the subject and the foreground or background be indicated by
The blur disk diameter formula_47 of a detail at distance formula_48 from the subject can be expressed as a function of the subject magnification formula_49, focal length formula_2, f-number formula_3 or alternatively the diameter of the entrance pupil formula_52 (often called the aperture) according to
The minus sign applies to a foreground object, and the plus sign applies to a background object.
The blur increases with the distance from the subject; when formula_54, the detail
is within the depth of field, and the blur is imperceptible. If the detail is only slightly outside the DOF, the blur may be only barely perceptible.
For a given subject magnification, f-number, and distance from the subject of the foreground or background detail, the degree of detail blur varies with the lens focal length. For a background detail, the blur increases with focal length; for a foreground detail, the blur decreases with focal length. For a given scene, the positions of the subject, foreground, and background usually are fixed, and the distance between subject and the foreground or background remains constant regardless of the camera position; however, to maintain constant magnification, the subject distance must vary if the focal length is changed. For small distance between the foreground or background detail, the effect of focal length is small; for large distance, the effect can be significant. For a reasonably distant background detail, the blur disk diameter is
depending only on focal length.
The blur diameter of foreground details is very large if the details are close to the lens.
The magnification of the detail also varies with focal length; for a given detail, the ratio of the blur disk diameter to imaged size of the detail is independent of focal length, depending only on the detail size and its distance from the subject. This ratio can be useful when it is important that the background be recognizable (as usually is the case in evidence or surveillance photography), or unrecognizable (as might be the case for a pictorial photographer using selective focus to isolate the subject from a distracting background). As a general rule, an object is recognizable if the blur disk diameter is one-tenth to one-fifth the size of the object or smaller (Williams 1990, 205), and unrecognizable when the blur disk diameter is the object size or greater.
The effect of focal length on background blur is illustrated in van Walree's article on Depth of field.
Practical complications.
The distance scales on most medium- and small-format lenses indicate
distance from the camera's image plane. Most DOF formulas, including those in this article, use the object distance
formula_7 from the lens's front nodal plane, which often is not easy to
locate. Moreover, for many zoom lenses and internal-focusing non-zoom lenses, the location of the front nodal plane, as well as focal length, changes with subject distance. When the subject distance is large in comparison with the lens focal length, the exact location of the front nodal plane is not critical; the distance is essentially the same whether measured from the front of the lens, the image plane, or the actual nodal
plane. The same is not true for close-up photography; at unity magnification, a slight error in the location of the front nodal plane can result in a DOF error greater than the errors from any approximations in the DOF equations.
The asymmetrical lens formulas require knowledge of the pupil magnification, which usually is not specified for medium- and small-format lenses. The pupil magnification can be estimated by looking
into the front and rear of the lens and measuring the diameters of the apparent apertures, and computing the ratio of rear diameter to front diameter (Shipman 1977, 144). However, for many zoom lenses and internal-focusing non-zoom lenses, the pupil magnification changes with subject distance, and several measurements may be required.
Limitations.
Most DOF formulas, including those discussed in this article, employ
several simplifications:
The lens designer cannot restrict analysis to Gaussian optics and cannot
ignore lens aberrations. However, the requirements of practical
photography are less demanding than those of lens design, and despite the
simplifications employed in development of most DOF formulas, these
formulas have proven useful in determining camera settings that result in
acceptably sharp pictures. It should be recognized that DOF limits are not
hard boundaries between sharp and unsharp, and that there is little point
in determining DOF limits to a precision of many significant figures.
Derivation of the DOF formulae.
DOF limits.
A symmetrical lens is illustrated at right. The subject, at distance
formula_7, is in focus at image distance formula_40. Point objects
at distances formula_59 and formula_60 would be
in focus at image distances formula_61 and formula_62, respectively; at image distance formula_40, they are imaged
as blur spots. The depth of field is controlled by the aperture stop
diameter formula_52; when the blur spot diameter is equal to the
acceptable circle of confusion formula_4, the near and far limits
of DOF are at formula_60 and formula_59. From
similar triangles,
and
It usually is more convenient to work with the lens f-number
than the aperture diameter; the f-number formula_3 is
related to the lens focal length formula_2 and the aperture diameter
formula_52 by
The image distance formula_40 is related to an object distance
formula_7 by the thin lens equation
formula_77...(5)
formula_78...(6)
Solve the equations set (1) to (6) and obtain the exact solutions without any simplification
and
Hyperfocal distance.
Solving equation (8) for the focus distance formula_7 and setting the far limit of DOF
formula_10 to infinity gives
where formula_5 is the hyperfocal distance. Setting the subject
distance to the hyperfocal distance and solving for the near limit of DOF
gives
Substituting the expression for hyperfocal distance into the
formulas (7) and (8) for the near and far limits of DOF gives
formula_86...(9)
formula_87...(10)
For any practical value of formula_5, the focal length is negligible
in comparison, so that
Substituting the approximate expression for hyperfocal distance into the
formulas for the near and far limits of DOF gives
and
Combining, the depth of field formula_13 is
Hyperfocal magnification.
Magnification formula_21 can be expressed as
at the hyperfocal distance, the magnification formula_96 then is
Substituting formula_98 for formula_5 and simplifying gives
DOF in terms of magnification.
It is sometimes convenient to express DOF in terms of magnification formula_21. Substituting
and
into the formula for DOF and rearranging gives
after Larmore (1965), 163).
DOF vs. focal length.
Multiplying the numerator and
denominator of the exact formula above by
gives
If the "f"-number and circle of confusion are constant,
decreasing the focal length formula_2 increases the second term in the
denominator, decreasing the denominator and increasing the value of the
right-hand side, so that a shorter focal length gives greater DOF.
The term in parentheses in the denominator is the hyperfocal magnification
formula_96, so that
A subject distance is decreased, the subject magnification increases, and eventually
becomes large in comparison with the hyperfocal magnification.
Thus the effect of focal length is greatest near the hyperfocal distance, and
decreases as subject distance is decreased. However, the near/far
perspective will differ for different focal lengths, so the difference in
DOF may not be readily apparent.
When formula_23, formula_111, and
so that for a given magnification, DOF is essentially independent of focal length.
Stated otherwise, for the same subject magnification and the same "f"-number, all focal lengths for
a given image format give approximately the same DOF. This
statement is true only when the subject distance is small in comparison
with the hyperfocal distance, however.
Moderate-to-large distances.
When the subject distance is large in comparison with the lens focal length,
and
so that
For formula_19, the far limit of DOF is at infinity and the DOF
is infinite; of course, only objects at or beyond the near limit of DOF
will be recorded with acceptable sharpness.
Close-up.
When the subject distance formula_7 approaches the lens focal length,
the focal length no longer is negligible, and the approximate formulas (11),(12)
above cannot be used without introducing significant error. Use formular (9) and (10) instead.
It usually is more convenient to express DOF in terms of magnification. The distance
is small in comparison with the hyperfocal distance, so the simplified formula
can be used with good accuracy. For a given magnification,
DOF is independent of focal length.
Near:far DOF ratio.
From the "exact" equations for near and far limits of DOF, the DOF in front of the subject is
and the DOF beyond the subject is
The near:far DOF ratio is
This ratio is always less than unity; at moderate-to-large subject distances, formula_122, and
When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, and the near:far ratio is zero. It's commonly stated that approximately 1/3 of the DOF is in front of the subject and approximately 2/3 is beyond; however, this is true only when formula_124.
At closer subject distances, it's often more convenient to express the DOF ratio in terms of the magnification
substitution into the "exact" equation for DOF ratio gives
As magnification increases, the near:far ratio approaches a limiting value of unity.
DOF vs. format size.
When the subject distance is much less than hyperfocal, the total DOF is given to good approximation by
When additionally the magnification is small compared to unity, the value of formula_21 in the numerator can be neglected, and the formula further simplifies to
The DOF ratio for two different formats is then
Essentially the same approach is described in Stroebel (1976), 136‚Äì39).
"Same picture" for both formats.
The results of the comparison depend on what is assumed. One approach is to assume that essentially the same picture is taken with each format and enlarged to produce the same size final image, so the subject distance remains the same, the focal length is adjusted to maintain the same angle of view, and to a first approximation, magnification is in direct proportion to some characteristic dimension of each format. If both pictures are enlarged to give the same size final images with the same sharpness criteria, the circle of confusion is also in direct proportion to the format size. Thus if formula_131 is the characteristic dimension of the format,
With the same "f"-number, the DOF ratio is then
so the DOF ratio is in inverse proportion to the format size. This ratio is approximate, and breaks down in the macro range of the larger format (the value of formula_21 in the numerator is no longer negligible) or as distance approaches the hyperfocal distance for the smaller format (the DOF of the smaller format approaches infinity).
If the formats have approximately the same aspect ratios, the characteristic dimensions can be the format diagonals; if the aspect ratios differ considerably (e.g., 4√ó5 vs. 6√ó17), the dimensions must be chosen more carefully, and the DOF comparison may not even be meaningful.
If the DOF is to be the same for both formats the required "f"-number is in direct proportion to the format size:
Adjusting the "f"-number in proportion to format size is equivalent to using the same absolute aperture diameter for both formats, discussed in detail below in Use of absolute aperture diameter.
Same focal length for both formats.
If the same lens focal length is used in both formats, magnifications can be maintained in the ratio of the format sizes by adjusting subject distances; the DOF ratio is the same as that given above, but the images differ because of the different perspectives and angles of view.
If the same DOF is required for each format, an analysis similar to that above shows that the required "f"-number is in direct proportion to the format size.
Another approach is to use the same focal length with both formats at the same subject distance, so the magnification is the same, and with the same "f"-number,
so the DOF ratio is in "direct" proportion to the format size. The perspective is the same for both formats, but because of the different angles of view, the pictures are not the same.
Cropping.
Cropping an image and enlarging to the same size final image as an uncropped image taken under the same conditions is equivalent to using a smaller format; the cropped image requires greater enlargement and consequently has a smaller circle of confusion. A cropped then enlarged image has less DOF than the uncropped image.
Use of absolute aperture diameter.
The aperture diameter is normally given in terms of the "f"-number because all lenses set to the same "f"-number give approximately the same image illuminance (Ray 2002, 130), simplifying exposure settings. In deriving the basic DOF equations, formula_137 can be substituted for the absolute aperture diameter formula_52, giving the DOF in terms of the absolute aperture diameter:
after Larmore (1965), 163). When the subject distance formula_7 is small in comparison with the hyperfocal distance, the second term in the denominator can be neglected, leading to
With the same subject distance and angle of view for both formats, formula_142, and
so the DOFs are in inverse proportion to the absolute aperture diameters. When the diameters are the same, the two formats have the same DOF. Von Rohr (1906) made this same observation, saying "At this point it will be sufficient to note that all these formulae involve quantities relating exclusively to the entrance-pupil and its position with respect to the object-point, whereas the focal length of the transforming system does not enter into them." Lyon's Depth of Field Outside the Box describes an approach very similar to that of von Rohr.
Using the same absolute aperture diameter for both formats with the "same picture" criterion is equivalent to adjusting the "f"-number in proportion to the format sizes, discussed above under "Same picture" for both formats
Focus and f-number from DOF limits.
Object-side relationships.
The equations for
the DOF limits can be combined to eliminate formula_144 and solve for
the subject distance. For given near and far DOF limits
formula_9 and formula_10, the
subject distance is
the harmonic mean of the near and far distances. The equations for DOF limits also can be combined to eliminate
formula_7 and solve for the required f-number, giving
When the subject distance is large in comparison with the lens focal
length, this simplifies to
When the far limit of DOF is at infinity, the equations for formula_7 and formula_3 give indeterminate results. But if all terms in the numerator and denominator on the right-hand side of the equation for formula_7 are divided by formula_154, it is seen that when formula_154 is at infinity,
Similarly, if all terms in the numerator and denominator on the right-hand side of the equation for formula_3 are divided by formula_154, it is seen that when formula_154 is at infinity,
Image-side relationships.
Most discussions of DOF concentrate on the object side of the lens,
but the formulas are simpler and the measurements usually easier to make on the
image side. If the basic image-side equations
and
are combined and solved for the image distance formula_40, the result is
the harmonic mean of the near and far image distances. The basic image-side equations can also be combined and solved for formula_3, giving
The image distances are measured from the camera's image plane to the
lens's image nodal plane, which is not always easy to locate. The harmonic mean is always less than the arithmentic mean, but when the difference between the near and far image distances is reasonably small, the two means are close to equal, and focus can be set with sufficient accuracy using
This formula requires only the "difference"
formula_43 between the near and far image distances.
View camera users often refer to this difference as the "focus spread";
it usually is measured on the bed or focusing rail.
Focus is simply set to halfway between the near and far image distances.
Substituting formula_169 into the equation for formula_3 and rearranging gives
One variant of the thin-lens equation is formula_172, where formula_21 is the magnification; substituting this into the equation for formula_3 gives
At moderate-to-large subject distances, formula_21 is small compared to unity, and the
f-number can often be determined with sufficient accuracy using
For close-up photography, the magnification cannot be ignored, and the f-number should be determined using the first approximate formula.
As with the approximate formula for formula_40, the approximate formulas for
formula_3 require only the focus spread
formula_43 rather than the absolute image distances.
When the far limit of DOF is at infinity, formula_181.
On manual-focus small- and medium-format lenses, the focus and f-number
usually are determined using the lens DOF scales, which
often are based on the approximate equations above.
Foreground and background blur.
If the equation for the far limit of DOF is solved for formula_4, and the far distance
replaced by an arbitrary distance formula_45, the blur disk diameter
formula_47 at that distance is
When the background is at the far limit of DOF, the blur disk diameter is equal to the circle
of confusion formula_4, and the blur is just imperceptible. The diameter of the background
blur disk increases with the distance to the background. A similar relationship holds for the
foreground; the general expression for a defocused object at distance formula_45 is
For a given scene, the distance between the subject and a foreground or background object is usually
fixed; let that distance be represented by
then
or, in terms of subject distance,
with the minus sign used for foreground objects and the plus sign used for background objects.
For a relatively distant background object,
In terms of subject magnification, the subject distance is
so that, for a given f-number and subject magnification,
Differentiating formula_47 with respect to formula_2 gives
With the plus sign, the derivative is everywhere positive,
so that for a background object, the blur disk size increases with focal length.
With the minus sign, the derivative is everywhere negative,
so that for a foreground object, the blur disk size decreases with focal length.
The magnification of the defocused object also varies with focal length; the magnification of the
defocused object is
where formula_199 is the image distance of the subject. For a defocused object
with some characteristic dimension formula_200, the imaged size of that object is
The ratio of the blur disk size to the imaged size of that object then is
so for a given defocused object, the ratio of the blur disk diameter to object size
is independent of focal length, and depends only on the object size and its distance from the subject.
Asymmetrical lenses.
This discussion thus far has assumed a symmetrical lens for which the
entrance and exit pupils coincide with the object and image
nodal planes, and for which the pupil magnification is unity.
Although this assumption usually is reasonable for large-format lenses, it
often is invalid for medium- and small-format lenses.
For an asymmetrical lens, the DOF ahead of the subject distance and the
DOF beyond the subject distance are given by
and
where formula_25 is the pupil magnification.
Combining gives the total DOF:
When formula_23, the second term in the denominator becomes
small in comparison with the first, and (Shipman 1977, 147)
When the pupil magnification is unity, the equations for asymmetrical
lenses reduce to those given earlier for symmetrical lenses.
Effect of lens asymmetry.
Except for close-up and macro photography, the effect of lens asymmetry is
minimal. A slight rearrangement of the last equation gives
As magnification decreases, the formula_210 term becomes smaller in
comparison with the formula_211 term, and eventually the effect of
pupil magnification becomes negligible.

</doc>
<doc id="8368" url="https://en.wikipedia.org/wiki?curid=8368" title="Dumnonii">
Dumnonii

The Dumnonii or Dumnones were British tribe who inhabited Dumnonia, the area now known as Devon and Cornwall (and some areas of present-day Dorset and Somerset) in the farther parts of the South West peninsula of Britain, from at least the Iron Age up to the early Saxon period. They were bordered to the east by the Durotriges tribe.
Etymology.
William Camden, in his 1607 edition of "Britannia", describes Cornwall and Devon as being two parts of the same 'country' which:
Camden had learnt some Welsh during the course of his studies and it would appear that he is the origin of the interpretation of Dumnonii as "deep valley dwellers" from his understanding of the Welsh of his time. John Rhys later theorized that the tribal name was derived from the name of a goddess, "Domnu", probably meaning "the goddess of the deep". The proto-Celtic root *dubno- or *dumno- meaning "the deep" or "the earth" (or alternatively meaning "dark" or "gloomy") appears in personal names such as Dumnorix and Dubnovellaunus. Another group with a similar name but with no known links were the Fir Domnann of Connacht.
The Roman name of the town of Exeter, "Isca Dumnoniorum" ("Isca of the Dumnonii"), contains the root "*iska-" "water" for "Water of the Dumnonii". The Latin name suggests that the city was already an "oppidum", or walled town, on the banks on the River Exe before the foundation of the Roman city, in about AD 50. The Dumnonii gave their name to the English county of Devon, and their name is represented in Britain's two extant Brythonic languages as "Dewnans" in Cornish and "Dyfnaint" in Welsh. Am√©d√©e Thierry ("Histoire des Gaulois", 1828), one of the inventors of the "historic race" of Gauls, could confidently equate them with the Cornish ("les Cornouailles").
Victorian historians often referred to the tribe as the Damnonii, which is also the name of another people from lowland Scotland, although there are no known links between the two populations.
Language.
The people of Dumnonia spoke a Southwestern Brythonic dialect similar to the forerunner of more recent Cornish and Breton. Irish immigrants, the D√©isi, are evidenced by the Ogham-inscribed stones they have left behind, confirmed and supplemented by toponymical studies. The stones are sometimes inscribed in Latin, sometimes in both scripts. Tristram Risdon suggested the continuance of a Brythonic dialect in the South Hams, Devon, as late as the 14th century, in addition to its use in Cornwall.
Territory.
Ptolemy's 2nd century "Geography" places the Dumnonii to the west of the Durotriges. The name "purocoronavium" that appears in the Ravenna Cosmography implies the existence of a sub-tribe called the Cornavii or Cornovii, perhaps the ancestors of the Cornish people.
In the sub-Roman period a Brythonic kingdom called Dumnonia emerged, covering the entire peninsula, although it is believed by some to have effectively been a collection of sub-kingdoms.
A kingdom of Domnon√©e (and of Cornouaille alongside) was established in the province of Armorica directly across the English Channel, and has apparent links with the British population, suggesting an ancient connection of peoples along the western Atlantic seaboard.
Settlements.
Isca Dumnoniorum.
The Latin name for Exeter is Isca Dumnoniorum ("Water of the Dumnonii"). This oppidum (a Latin term meaning an important town) on the banks of the River Exe certainly existed prior to the foundation of the Roman city in about AD 50. "Isca" is derived from the Brythonic word for flowing water, which was given to the River Exe. This is reflected in the Welsh name for Exeter: "Caerwysg" meaning "fortified settlement on the river Uisc".
Isca Dumnoniorum originated with a settlement that developed around the Roman fortress of the Legio II Augusta and is one of the four "poleis" (cities) attributed to the tribe by Ptolemy. It is also listed in two routes of the late 2nd century Antonine Itinerary.
A legionary bath-house was built inside the fortress sometime between 55 and 60 and underwent renovation shortly afterwards (c. 60-65) but by c. 68 (perhaps even 66) the legion had transferred to a newer fortress at Gloucester. This saw the dismantling of the Isca fortress, and the site was then abandoned. Around AD 75, work on the "civitas forum" and "basilica" had commenced on the site of the former "principia" and by the late 2nd century the "civitas" walls had been completed. They were 3 metres thick and 6 metres high and enclosed exactly the same area as the earlier fortress. However, by the late 4th century the "civitas" was in decline.
Other settlements.
As well as Isca Dumnoniorum, Ptolemy's 2nd century "Geography" names three other towns:
The Ravenna Cosmography includes the last two names (in slightly different forms, as "Tamaris" and "Uxelis"), and adds several more names which may be settlements in the territory. These include:
Other Romano-British sites in Dumnonia include:
New settlements continued to be built throughout the Roman period, including sites at Chysauster and Trevelgue Head. The style is native in form with no Romanised features. Near Padstow, a Roman site of some importance now lies buried under the sands on the opposite side of the Camel estuary near St. Enodoc's Church, and may have been a western coastal equivalent of a Saxon Shore Fort. At Magor Farm in Illogan, near Camborne, an archaeological site has been identified as being a villa.
Archaeology.
The Dumnonii are thought to have occupied relatively isolated territory in Cornwall, Devon, Somerset and possibly part of Dorset. Their cultural connections, as expressed in their ceramics, were with the peninsula of Armorica across the Channel, rather than with the southeast of Britain. They do not seem to have been politically centralised: coins are relatively rare, none of them locally minted, and the structure, distribution and construction of Bronze Age and Iron Age hill forts, "rounds" and defensible farmsteads in the south west point to a number of smaller tribal groups living alongside each other.
Dumnonia is noteworthy for its many settlements that have survived from the Romano-British period, but also for its lack of a villa system. Local archaeology has revealed instead the isolated enclosed farmsteads known locally as "rounds". These seem to have survived the Roman abandonment of Britain, but were subsequently replaced, in the 6th and 7th centuries, by the unenclosed farms taking the Brythonic toponymic "tre-".
As in most other Brythonic areas, Iron Age hill forts, such as Hembury Castle, were refortified for the use of chieftains or kings. Other high-status settlements such as Tintagel seem to have been reconstructed during this period. Post-Roman imported pottery has been excavated from many sites across the region, and the apparent surge in late 5th century Mediterranean and/or Byzantine imports is yet to be explained satisfactorily.
Industries.
Apart from fishing and agriculture, the main economic resource of the Dumnonii was tin mining. The area of Dumnonia had been mined since ancient times, and the tin was exported from the ancient trading port of Ictis (St Michael's Mount). Tin extraction (mainly by streaming) had existed here from the early Bronze Age around the 22nd century BC. West Cornwall, around Mount's Bay, was traditionally thought to have been visited by metal traders from the eastern Mediterranean
During the first millennium BC trade became more organised, first with the Phoenicians, who settled Gades (Cadiz) around 1100 BC, and later with the Greeks, who had settled Massilia (Marseilles) and Narbo (Narbonne) around 600 BC. Smelted Cornish tin was collected at Ictis whence it was conveyed across the Bay of Biscay to the mouth of the Loire and then to Gades via the Loire and Rhone valleys. It went then through the Mediterranean Sea in ships to Gades.
During the period c. 500-450 BC, the tin deposits seem to have become more important, and fortified settlements appear such as at Chun Castle and Kenidjack Castle, to protect both the tin smelters and mines.
The earliest account of Cornish tin mining was written by Pytheas of Massilia late in the 4th century BC after his circumnavigation of the British Isles. Underground mining was described in this account, although it cannot be determined when it had started. Pytheas's account was noted later by other writers including Pliny the Elder and Diodorus Siculus.
It is likely that tin trade with the Mediterranean was later on under the control of the Veneti. Britain was one of the places proposed for the "Cassiterides", that is Tin Islands. Tin working continued throughout Roman occupation although it appears that output declined because of new supplies brought in from the deposits discovered in Iberia (Spain and Portugal). However, when these supplies diminished, production in Dumnonia increased and appears to have reached a peak during the 3rd century AD.
Sub-Roman and post-Roman Dumnonia.
The Sub-Roman or Post-Roman history of Dumnonia comes from a variety of sources and is considered exceedingly difficult to interpret given that historical fact, legend and confused pseudo-history are compounded by a variety of sources in Middle Welsh and Latin. The main sources available for discussion of this period include Gildas's "De Excidio Britanniae" and Nennius's "Historia Brittonum", the "Annales Cambriae", "Anglo-Saxon Chronicle", William of Malmesbury's "Gesta Regum Anglorum" and "De Antiquitate Glastoniensis Ecclesiae", along with texts from the "Black Book of Carmarthen" and the "Red Book of Hergest", and Bede's "Historia ecclesiastica gentis Anglorum" as well as "The Descent of the Men of the North" ("Bonedd Gw≈∑r y Gogledd", in Peniarth MS 45 and elsewhere) and the "Book of Baglan".

</doc>
<doc id="8372" url="https://en.wikipedia.org/wiki?curid=8372" title="Declaration of independence">
Declaration of independence

A declaration of independence or declaration of statehood is an assertion by a defined territory that it is independent and constitutes a state. Such places are usually declared from part or all of the territory of another nation or failed nation, or are breakaway territories from within the larger state. In 2010, the UN's International Court of Justice ruled in an advisory opinion in Kosovo that "International law contains no prohibition on declarations of independence", though the state from which the territory wishes to secede may regard the declaration as rebellion, which may lead to a war of independence or a constitutional settlement to resolve the crisis. Not all declarations of independence succeed in the formation of an independent state.

</doc>
<doc id="8373" url="https://en.wikipedia.org/wiki?curid=8373" title="Drag racing">
Drag racing

Drag racing is a type of motor racing in which automobiles or motorcycles (usually specially prepared for the purpose) compete, usually two at a time, to be first to cross a set finish line. The race follows a short, straight course from a standing start over a measured distance, most commonly ¬º mile (), with a shorter 3/16 mile 10 feet () used by nitromethane powered Top Fuel dragsters and funny cars along with some bracket races, while (1/8¬†mi) is also popular in some circles. Electronic timing and speed sensing systems have been used to record race results since the 1960s.
Drag racing has existed in both street racing and regulated motorsport forms since automobiles and motorcycles were developed. The street racing form, which is usually illegal, is covered elsewhere; this article covers the legal sport.
Basics of drag racing.
Before each race (commonly known as a pass), each driver is allowed to perform a burnout, which heats the driving tires and lays rubber down at the beginning of the track, improving traction. Each driver then lines up (or stages) at the starting line.
Modern professional races are started electronically by a system known as a "Christmas tree", which consists of a column of lights for each driver/lane, and two light beam sensors per lane on the track at the starting line. Current NHRA trees, for example, feature one blue light (split into halves), then three amber, one green, and one red. When the first light beam is broken by a vehicle's front tire(s), the vehicle is "pre-staged" (approximately from the starting line), and the pre-stage indicator on the tree is lit. When the second light beam is broken, the vehicle is "staged", and the stage indicator on the tree is lit. Vehicles may then leave the pre-stage beam, but must remain in the stage beam until the race starts.
Once one competitor is staged, their opponent has a set amount of time to stage or they will be instantly disqualified, indicated by a red light on the tree. Otherwise, once both drivers are staged, the system chooses a short delay at random (to prevent a driver being able to anticipate the start), then starts the race. The light sequence at this point varies slightly. For example, in NHRA Professional classes, three amber lights on the tree flash simultaneously, followed 0.4 seconds later by a green light (this is also known as a "pro tree"). In NHRA Sportsman classes, the amber lights illuminate in sequence from top to bottom, 0.5 seconds apart, followed 0.5 seconds later by the green light (this is also known as a "sportsman tree" or "full tree"). If a vehicle leaves the start line before the green light illuminates, the red light for that lane illuminates instead, and the driver is disqualified (also known as "redlighting"). In a handicap start, the green light automatically lights up for the first driver, and the red light is only lit in the proper lane after both cars have launched if one driver leaves early, or if both drivers left early, the driver whose reaction time is worse (if one lane has a -.015 and the other lane has a -.022, the lane of the driver who committed a 0.022 is given the red light after both cars have left)., as a red light infraction is only assessed to the driver with the worse infraction, if both drivers leave early. Even if both drivers leave early, the green light is automatically lit for the driver that left last, and they still may win the pass (as in the 2014 NHRA Auto Club Finals Pro stock class, Erica Enders-Stevens and Jason Line both committed red light infractions; only Line was assessed with a red light, as he was -.011 versus Enders-Stevens' -.002).
Several measurements are taken for each race: reaction time, elapsed time, and speed. Reaction time is the period from the green light illuminating to the vehicle leaving the starting line. Elapsed time is the period from the vehicle leaving the starting line to crossing the finish line. Speed is measured through a speed trap covering the final to the finish line, indicating average speed of the vehicle during the run last 66 feet (20m).
Except where a breakout rule is in place, the winner is the first vehicle to cross the finish line, and therefore the driver with the lowest combined reaction time and elapsed time. Because these times are measured separately, a driver with a slower elapsed time can actually win if that driver's advantage in reaction time exceeds the elapsed time difference. In heads-up racing, this is known as a "holeshot win". In categories where a breakout rule is in effect (for example, NHRA Junior Dragster, Super Comp, Super Gas, Super Stock, and Stock classes, as well as some dial-in classes), if a competitor is faster than their predetermined time (a "breakout"), that competitor loses. If both are faster than their predetermined time, the competitor that breaks out by less time wins. Regardless, a red light foul is worse than a breakout, except in Junior Dragster where exceeding the absolute limit is a cause for disqualification.
Most race events use a traditional bracket system, where the losing car and driver are eliminated from the event while the winner advances to the next round, until a champion is crowned. Events typically use 4, 8, or 16 car brackets. Drivers are typically seeded by elapsed times in qualifying. In bracket racing without a breakout (such as NHRA Competition Eliminator), pairings are based on times compared to their index (faster than index for class is better). In bracket racing with a breakout (Stock, Super Stock, but also the NHRA's Super classes), the closest to the index is favourable.
A popular alternative to the standard eliminations format is the Chicago Style format (also called the Three Round format in Australia), named for the US 30 Dragstrip in suburban Gary, Indiana where a midweek meet featured this format. All entered cars participate in one qualifying round, and then are paired for the elimination round. The two fastest times among winners from this round participate in the championship round. Depending on the organisation, the next two fastest times may play for third, then fifth, and so forth, in consolation rounds.
Racing organization.
North America.
The National Hot Rod Association (NHRA) oversees the majority of drag racing events in North America. The next largest organization is the International Hot Rod Association (IHRA). Nearly all drag strips are associated with one sanctioning body or the other.
Besides NHRA and IHRA, there are niche organizations for muscle cars and nostalgia vehicles. The Nostalgia Drag Racing League (NDRL) based in Brownsburg, IN, runs a series of 1/4 mile (400m) drag races in the Midwest for 1979 and older nostalgic appearing cars, with four classes of competition running in an index system. Pro 7.0 and Pro 7.50 run heads up 200 mile per hour (320 kilometre per hour) passes, while Pro Comp and Pro Gas run 8.0 to 10.0 indices. NDRL competition vehicles typically include Front Engine Dragsters, Altereds, Funny Cars, early Pro Stock clones, Super Stocks and Gassers.
The National Electric Drag Racing Association (NEDRA) races electric vehicles against high performance gasoline-powered vehicles such as Dodge Vipers or classic muscle cars in 1/4 and 1/8¬†mile (400m ¬† 200m) races. The current electric drag racing record is [http://www.nedra.com/200mph_club.html] 6.940 seconds at 201.37¬†mph (324.0736 kph) for a quarter mile (400m). Another niche organization is the VWDRC which run a VW-only championship with vehicles running under 7 seconds.
Prior to the founding of the NHRA and IHRA, smaller organizations sanctioned drag racing in the early years.
Australia.
The first Australian Nationals event was run in 1965 at Riverside raceway, near Melbourne. The Australian National Drag Racing Association (ANDRA) was established in 1973, and today they claim they are the "best in the world outside the United States". ANDRA sanctions races throughout Australia and throughout the year at all levels, from Junior Dragster to Top Fuel.
The ANDRA Pro Series is for professional drivers and riders and includes Top Fuel, Top Alcohol, Top Doorslammer (similar to the USA Pro Modified class), Pro Stock (using 400 cubic inch engines (6.5 litres)), Top Bike and Pro Stock Motorcycle. ANDRA is the only organisation that officially sanctions ¬º mile drag racing for Top Fuel.
The Rocket Allstars Racing Series is for sportsman drivers and riders and includes Competition, Super Stock, Super Compact, Competition Bike, Supercharged Outlaws, Modified, Super Sedan, Modified Bike, Super Street and Junior Dragster.
Broadcasting is provided on SBS Speedweek.
Europe.
Drag racing was imported to Europe by American NATO troops during the Cold War. Races were held in West Germany beginning in the 1960s at the airbases at Ramstein and Sembach and in the UK at various airstrips and racing circuits before the opening of Europe's first permanent drag strip at Santa Pod Raceway in 1966.
The FIA organises a Europe-wide four wheeled championship for the Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock classes. FIM Europe organises a similar championship for bike classes. In addition, championships are run for sportsman classes in many countries throughout Europe by the various national motorsport governing bodies.
New Zealand.
Drag racing in New Zealand started in the 1960s. The New Zealand Hot Rod Association (NZHRA) sanctioned what is believed to have been the first drag meeting at an open cut coal mine at Kopuku, south of Auckland, sometime in 1966. In 1973, the first and only purpose built drag strip opened in Meremere by the Pukekohe Hot Rod Club. In April 1993 the governance of drag racing was separated from the NZHRA and the New Zealand Drag Racing Association (NZDRA) was formed. In 2014, New Zealand's second purpose built drag strip - Masterton Motorplex - opened.
The first New Zealand Drag Racing Nationals was held in the 1966/67 season at Kopuku, near Auckland.
There are now two governing bodies operating drag racing in New Zealand with the IHRA sanctioning both of New Zealands major tracks at Ruapuna (Pegasus Bay Drag Racing Association) on the South Island and Meremere Dragway Inc in the North Island. NZDRA being the other organisation now run the Street car races on old airstrips & closed roads. IHRA nz are the predominant governing body.
South America.
A lot of countries in South America race use 200 meters unlike United states and places like Australia who use the 400 meters 1/4 mile.
Organized drag racing in Colombia is Club G3's responsibility, which is a private organization. The events take part at Aut√≥dromo de Tocancip√°.
Caribbean.
Cura√ßao
On the island of Cura√ßao, organization of drag racing events is handled by the Cura√ßao Autosport Foundation (FAC)
All racing events, including street legal competitions, happen at the Cura√ßao International Raceway.
South Asia.
Organized drag racing is rapidly growing in India. "Autocar India" organised the country's first drag race meet in Mumbai in 2002.
Drag racing is also gaining popularity in Pakistan, with private organizations organizing such events. The Bahria Town housing project recently organized a drag racing event in Rawalpindi, with the help of some of the country's best drivers.
Sri Lanka has seen an immense growth in Drag racing through legal meets held by the Ceylon Motor Sports Club, an FiA sanctioned body. In recent years, exotic cars and Japanese power houses have been taking part in these popular events.
Middle East.
Qatar Racing Club is the home of Motorsports in the Middle East. QRC provides access to the best drag strip and drift skid pad in the world, which allows participants to unleash the power of their cars and bikes in a safe and controlled environment. QRC with the help of the fine Racing Organizations wish to establish common rules and seeks parity amongst classes within the Gulf Region. The goal of the QRC is to help, along with the other organizations to promote World Wide Awareness of the sport of Drag Racing & Drifting.
Driver can compete in a number of competitions including ADRL, QATAR MILE, NATIONAL STREET DRAG CHAMPIONSHIP, QATAR DRIFT CHAMPIONSHIP, FREESTYLE DRIFT and SEALINE SAND DRAGS.
South Africa.
Drag racing is an established sport in South Africa, with a number of strips around the country including Tarlton International Raceway and ODI Raceway. Drag racing is controlled by Motorsport South Africa and all drivers are required to hold a valid Motorsport South Africa license. Drivers can compete in a number of categories including Top Eliminator, Senior Eliminator, Super Competition Eliminator, Competition Eliminator, Pro Street Bikes, Superbike Eliminator, Supersport Shootout (motorcycle), Street Modified, and Factory Stock.
Classes.
There are hundreds of classes in drag racing, each with different requirements and restrictions on things such as weight, engine size, body style, modifications, and many others. NHRA and IHRA share some of these classes, but many are solely used by one sanctioning body or the other. The NHRA boasts over 200 classes, while the IHRA has fewer. Some IHRA classes have multiple sub-classes in them to differentiate by engine components and other features. There is even a class for aspiring youngsters, Junior Dragster, which typically uses an eighth-mile track, also favored by VW racers.
In 1997, the FIA (cars) and UEM (bikes) began sanctioning drag racing in Europe with a fully established European Drag Racing Championship, in cooperation (and rules compliance) with NHRA. The major European drag strips include Santa Pod Raceway in Podington, England; Alastaro Circuit, Finland; Mantorp Park, Sweden; Gardermoen Raceway, Norway and the Hockenheimring in Germany. The major difference is the nitro-class distance, which is 300 meters at some tracks, although the NHRA and FIA are likely to discuss the distance change in the future.
There is a somewhat arbitrary definition of what constitutes a "professional" class. The NHRA includes 5 pro classes; Top Fuel, Funny Car, Pro Stock, Pro Modified and Pro Stock Motorcycle. The FIA features a different set of 5 pro classes; Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock. Other sanctioning bodies have similarly different definitions. A partial list of classes includes:
A complete listing of all classes can be found on the respective NHRA and IHRA official websites.
The UEM also has a different structure of professional categories with Top Fuel Bike, Super Twin Top Fuel Bike, and Pro Stock Bike contested, leaving the entire European series with a total of 8 professional categories.
To allow different cars to compete against each other, some competitions are raced on a handicap basis, with faster cars delayed on the start line enough to theoretically even things up with the slower car. This may be based on rule differences between the cars in stock, super stock, and modified classes, or on a competitor's chosen "dial-in" in bracket racing.
For a list of drag racing world records in each class, see Dragstrip#Quarter mile times.
Dial-in.
A "dial-in" is a time the driver estimates it will take his or her car to cross the finish line, and is generally displayed on one or more windows so the starter can adjust the starting lights on the tree accordingly. The slower car will then get a head start equal to the difference in the two dial-ins, so if both cars perform perfectly, they would cross the finish line dead even. If either car goes faster than its dial-in (called breaking out), it is disqualified regardless of who has the lower elapsed time; if both cars break out, the one who breaks out by the smallest amount wins. However, if a driver had jump-started (red light) or crossed a boundary line, both violations override any break out (except in some classes with an absolute break out rule such as Junior classes). This eliminates any advantage from putting a slower time on the windshield to get a head start. The effect of the bracket racing rules is to place a premium on consistency of performance of the driver and car rather than on raw speed, in that victory goes to the driver able to precisely predict elapsed time, whether it is fast or slow. This in turn makes victory much less dependent on large infusions of money, and more dependent on skill. Therefore, bracket racing is popular with casual weekend racers. Many of these recreational racers will drive their vehicles to the track, race them, and then simply drive them home. As most tracks host only one NHRA national event, and two or three regional events (smaller tours, car shows, "etc.") annually, on most weekends these tracks host local casual and weekend racers. Organizationally, however, the tracks are run according to the rules of either the NHRA or the IHRA with regional points and a championship on the line. Even street vehicles must pass a safety inspection prior to being allowed to race.

</doc>
<doc id="8375" url="https://en.wikipedia.org/wiki?curid=8375" title="Draugr">
Draugr

The draugr or draug (, plural ; modern , and Danish, Swedish and ), also called , literally "again-walker" () is an undead creature from Norse mythology, a subset of Germanic mythology.
The word "draugr" can be traced to a Proto-Indo European stem "*" "phantom", from "*" "deceive".
The Old Norse meaning of the word is a revenant.
The will appears to be strong, strong enough to draw the "hugr" will back to one's body. These reanimated individuals were known as "draugar". However, though the dead might live again, they could also die again. "Draugar" die a "second death" as Chester Gould calls it, when their bodies decay, are burned, dismembered or otherwise destroyed. 
Draugar live in their graves, often guarding treasure buried with them in their burial mound. They are animated corpses ‚Äî unlike ghosts they have a corporeal body with similar physical abilities as in life. Older literature makes clear distinctions between sea-draugar and land-draugar.
Traits.
Draugar possess superhuman strength, can increase their size at will, and carry the unmistakable stench of decay. "The appearance of a "draugr" was that of a dead body: swollen, blackened and generally hideous to look at." They are undead figures from Norse and Icelandic mythology that appear to retain some semblance of intelligence. They exist either to guard their treasure, wreak havoc on living beings, or torment those who had wronged them in life. The draugr's ability to increase its size also increased its weight, and the body of the draugr was described as being extremely heavy. Thorolf of Eyrbyggja saga was "uncorrupted, and with an ugly look about him... swollen to the size of an ox," and his body was so heavy that it could not be raised without levers. They are also noted for the ability to rise from the grave as wisps of smoke and "swim" through solid rock, which would be useful as a means of exiting their graves.
In folklore, draugar slay their victims through various methods including crushing them with their enlarged forms, devouring their flesh, devouring them whole in their enlarged forms, indirectly killing them by driving them mad, and by drinking their blood. Animals feeding near the grave of a draugr may be driven mad by the creature's influence. They may also die from being driven mad. Thorolf, for example, caused birds that flew over his bowl barrow to drop dead. Draugar are also noted as being able to drive living people insane.
The draugr's victims were not limited to trespassers in its howe. The roaming undead decimated livestock by running the animals to death while either riding them or pursuing them in some hideous, half-flayed form. Shepherds, whose duties to their flocks left them out of doors at night time, were also particular targets for the hunger and hatred of the undead:
Draugar are noted for having numerous magical abilities (referred to as "trollskap") resembling those of living witches and wizards such as shape-shifting, controlling the weather and seeing into the future. Among the creatures that a draugr may turn into are a seal, a great flayed bull, a grey horse with a broken back but no ears or tail and a cat that would sit upon a sleeper's chest and grow steadily heavier until the victim suffocated. The draugr √ûr√°inn (Thrain) shape-shifted into a "cat-like creature" ("kattakyn") in "Hr√≥mundar saga Gripssonar":
Draugar have the ability to enter into the dreams of the living, "but it generally happens even so that they leave beside the living person some gift, by which, on awakening, the living person may be assured of the tangible nature of the visit." Draugar also have the ability to curse a victim, as shown in the Grettis saga, where Grettir is cursed to be unable to become any stronger. Draugar also brought disease to a village and could create temporary darkness in daylight hours. While the draugr certainly preferred to be active during the night, it did not appear to be vulnerable to sunlight like some other revenants.
A draugr's presence may be shown by a great light that glowed from the mound like foxfire. This fire would form a barrier between the land of the living and the land of the dead. The draugr could also move magically through the earth, swimming through solid stone as does Killer-Hrapp:
Some draugar are immune to weapons, and only a hero has the strength and courage needed to stand up to so formidable an opponent. In legends the hero would often have to wrestle the draugr back to his grave, thereby defeating him, since weapons would do no good. A good example of this kind of fight is found in "Hr√≥mundar saga Gripssonar". Although iron could injure a draugr, as is the case with many supernatural creatures, it would not be sufficient to stop it. Sometimes the hero is required to dispose of the body in unconventional ways. The preferred method is to cut off the draugr's head, burn the body, and dump the ashes in the sea; the emphasis being on making absolutely sure the draugr was dead and gone.
The draugar were said to be either "hel-bl√°r" ("death-blue") or, conversely, "n√°r-f√∂lr" ("corpse-pale"). The "death-blue" color was not actually grey but was a dark blue or maroon hue that covered the entire body. Gl√°mr, the undead shepherd of "Grettis saga", was reported to be dark blue in color and in Laxd√¶la saga, the bones of a dead sorceress who had appeared in dreams were dug up and found to be "blue and evil looking."
The resting place of the draugr was a tomb that served much as a workable home for the creature. Draugar are able to leave this dwelling place and visit the living during the night. Such visits are supposed to be universally horrible events that often end in death for one or more of the living, which would then warrant the exhumation of the draugr by a hero.
The motivation of the actions of a draugr was primarily jealousy and greed. The greed of a draugr causes it to viciously attack any would-be grave robbers, but the draugr also expresses an innate jealousy of the living, stemming from a longing for the things of the life it once had. This idea is clearly expressed in "Fri√∞√æj√≥fs saga", where a dying king declared:
This desire for the friendship experienced in life is one example of the manifestation of this aspect of the draugr. Draugar also exhibit an immense and nearly insatiable appetite, as shown in the encounter of Aran and Asmund, sword brothers who made an oath that if one should die, the other would sit vigil with him for three days inside the burial mound. When Aran died, Asmund brought his own possessions into the barrow: banners, armor, hawk, hound, and horse. Then Asmund set himself to wait the agreed upon three days:
Creation of draugar.
After a person‚Äôs death, the main indication that the person will become a draugr is that the corpse is not in a horizontal position. In most cases, the corpse is found in an upright or sitting position, and this is an indication that the dead might return. Any mean, nasty, or greedy person can become a draugr. As noted by √Årmann, ‚Äúmost medieval Icelandic ghosts are evil or marginal people. If not dissatisfied or evil, they are unpopular‚Äù. This is the prime way that draugar share characteristics with ghosts, since any person can become a ghost.
In many Western mythologies, ghosts are generally people with unfinished business or those who are so evil their spirit makes an impact on the place they lived. Ghosts and draugar refuse to follow the prescribed path of death, selfishly staying on Earth when they are supposed to move on. This is easily understandable because, ‚Äúselfishness is an important attribute of every ghost, and therefore it is no wonder that ghosts tend to be people who were troublesome during their lifetime‚Äù.
However, unlike ghosts, draugar can also come about through infection by another draugr such as in the story of Gl√°mr. When Gl√°mr arrives in the haunted valley in "Grettis saga", "the previous evil spirits are relegated to the sidelines and, when Gl√°mr is found dead, they disappear, whereas he takes over their role as ghost of the valley." Although Gl√°mr is an arguably marginal character to begin with, it is only after his fight with the first malignant spirit that the first spirit leaves the valley, and Gl√°mr takes its place wreaking havoc. Similarly, in "Eyrbyggja saga", a shepherd is killed by a draugr and rises the next night as one himself.
Means of prevention.
Traditionally, a pair of open iron scissors were placed on the chest of the recently deceased, and straws or twigs might be hidden among their clothes. The big toes were tied together or needles were driven through the soles of the feet in order to keep the dead from being able to walk. Tradition also held that the coffin should be lifted and lowered in three different directions as it was carried from the house to confuse a possible draugr's sense of direction.
The most effective means of preventing the return of the dead was believed to be the corpse door. A special door was built, through which the corpse was carried feet-first with people surrounding it so the corpse couldn't see where it was going. The door was then bricked up to prevent a return. It is speculated that this belief began in Denmark and spread throughout the Norse culture. The belief was founded on the idea that the dead could only leave through the way they entered.
In "Eyrbyggja saga", the draugar infesting the home of the Icelander Kiartan were driven off by holding a "door-doom". One by one the draugar were summoned to the door-doom and given judgment and were forced out of the home by this legal method. The home was then purified with holy water to ensure they never came back.
Similar creatures.
A variation of the draugr is the "haugbui". The haugbui (from Old Norse "haugr"' "howe, barrow, tumulus") was a mound-dweller, the dead body living on within its tomb. The notable difference between the two was that the haugbui is unable to leave its grave site and only attacks those that trespass upon their territory.
The haugbui was rarely found far from its burial place and is a type of undead commonly found in Norse saga material. The creature is said to either swim alongside boats or sail around them in a partially submerged vessel, always on their own. In some accounts, witnesses portray them as shapeshifters who take on the appearance of seaweed or moss-covered stones on the shoreline.
The words "dragon" and "draugr" are not linguistically related. However, both the serpent and the spirit serve as jealous guardians of the graves of kings or ancient civilizations. Dragons that act as draugar appear in "Beowulf" as well as in some of the heroic lays of the "Poetic Edda" (in the form of Fafnir).
Folklore.
Icelandic Sagas.
One of the best-known draugar is Gl√°mr, who is defeated by the hero in "Grettis saga". After Gl√°mr dies on Christmas Eve, "people became aware that Gl√°mr was not resting in peace. He wrought such havoc that some people fainted at the sight of him, while others went out of their minds". After a mundane battle, Grettir eventually gets Gl√°mr on his back. Just before Grettir kills him, Gl√°mr curses Grettir because "Gl√°mr was endowed with more evil force than most other ghosts", and thus he was able to speak and leave Grettir with his curse after his death.
A somewhat ambivalent, alternative view of the draugr is presented by the example of Gunnar H√°mundarson in "Nj√°l's saga":
In the "Eyrbyggja saga", a shepherd is assaulted by a blue-black draugr. The shepherd's neck is broken during the ensuing scuffle. The shepherd rises the next night as a draugr.
Recent.
In more recent Scandinavian folklore, the draug (the modern spelling used in Denmark, Norway, and Sweden) is often identified with the spirits of mariners drowned at sea. The creature is said to possess a distinctly human form, with the exception that its head is composed entirely of seaweed. In other tellings, the draug is described as being a headless fisherman, dressed in oilskin and sailing in half a boat (the Norwegian municipality of B√∏, Nordland has the half-boat in its coat-of-arms). This trait is common in the northernmost part of Norway, where life and culture was based on fishing more than anywhere else. The reason for this may be that the fishermen often drowned in great numbers, and the stories of restless dead coming in from sea were more common up north than anywhere else in the country.
A recorded legend from Tr√∏ndelag tells how a cadaver lying on a beach became the object of a quarrel between the two types of draug (headless and seaweed-headed). A similar source even tells of a third type, the "gleip", known to hitch themselves to sailors walking ashore and make them slip on the wet rocks.
But, though the draug usually presages death, there is an amusing account in Northern Norway of a northerner who managed to outwit him:
Literature.
The modern and popular connection between the draug and the sea can be traced back to the author Jonas Lie and the story-teller Regine Nordmann, as well as the drawings of Theodor Kittelsen, who spent some years living in Svolv√¶r. Up north, the tradition of sea-draugs is especially vivid.
Arne Garborg describes land-draugs coming fresh from the graveyards, and the term "draug" is even used of vampires. The notion of draugs who live in the mountains is present in the poetic works of Henrik Ibsen ("Peer Gynt"), and Aasmund Olavsson Vinje. The Nynorsk translation of "The Lord of the Rings" used the term for both Nazg√ªl and the dead men of Dunharrow.
The term "draug" has come to be used to describe any type of revenant in Nordic folklore.

</doc>
<doc id="8376" url="https://en.wikipedia.org/wiki?curid=8376" title="Day">
Day

A day is a unit of time. In common usage, it is either an interval equal to 24 hours or daytime, the consecutive period of time during which the Sun is above the horizon. The period of time during which the Earth completes one rotation with respect to the Sun is called a "solar day". Several definitions of this universal human concept are used according to context, need and convenience. In 1960, the second was redefined in terms of the orbital motion of the Earth, and was designated the SI base unit of time. The unit of measurement "day", redefined in 1960 as 86 400 SI seconds and symbolized "d", is not an SI unit, but is accepted for use with SI. A civil day is usually 86 400 seconds, plus or minus a possible leap second in Coordinated Universal Time (UTC), and occasionally plus or minus an hour in those locations that change from or to daylight saving time. The word "day" may also refer to a day of the week or to a calendar date, as in answer to the question "On which day?" The life patterns of humans and many other species are related to Earth's solar day and the day-night cycle (see circadian rhythms).
In recent decades the average length of a solar day on Earth has been about 86 400.002 seconds (24.000 000 6 hours) and there are about 365.242 2 solar days in one mean tropical year. Because celestial orbits are not perfectly circular, and thus objects travel at different speeds at various positions in their orbit, a solar day is not the same length of time throughout the orbital year. A "day", understood as the span of time it takes for the Earth to make one entire rotation
with respect to the celestial background or a distant star (assumed to be fixed), is called a "stellar day". This period of rotation is about 4 minutes less than 24 hours (23 hours 56 minutes and 4.1 seconds) and there are about 366.242 2 stellar days in one mean tropical year (one stellar day more than the number of solar days). Mainly due to tidal effects, the Earth's rotational period is not constant, resulting in further minor variations for both solar days and stellar "days". Other planets and moons have stellar and solar days of different lengths to Earth's.
Introduction.
Besides the day of 24 hours (86 400 seconds), the word "day" is used for several different spans of time based on the rotation of the Earth around its axis. An important one is the solar day, defined as the time it takes for the Sun to return to its culmination point (its highest point in the sky). Because the Earth orbits the Sun elliptically as the Earth spins on an inclined axis, this period can be up to 7.9 seconds more than (or less than) 24 hours. On average over the year this day is equivalent to 24 hours (86 400 seconds).
A day, in the sense of daytime that is distinguished from night-time, is commonly defined as the period during which sunlight directly reaches the ground, assuming that there are no local obstacles. The length of daytime averages slightly more than half of the 24-hour day. Two effects make daytime on average longer than nights. The Sun is not a point, but has an apparent size of about 32 minutes of arc. Additionally, the atmosphere refracts sunlight in such a way that some of it reaches the ground even when the Sun is below the horizon by about 34 minutes of arc. So the first light reaches the ground when the centre of the Sun is still below the horizon by about 50 minutes of arc. The difference in time depends on the angle at which the Sun rises and sets (itself a function of latitude), but can amount to around seven minutes.
Ancient custom has a new day start at either the rising or setting of the Sun on the local horizon (Italian reckoning, for example). The exact moment of, and the interval between, two sunrises or sunsets depends on the geographical position (longitude as well as latitude), and the time of year (as indicated by ancient hemispherical sundials).
A more constant day can be defined by the Sun passing through the local meridian, which happens at local noon (upper culmination) or midnight (lower culmination). The exact moment is dependent on the geographical longitude, and to a lesser extent on the time of the year. The length of such a day is nearly constant (24 hours ¬± 30 seconds). This is the time as indicated by modern sundials.
A further improvement defines a fictitious mean Sun that moves with constant speed along the celestial equator; the speed is the same as the average speed of the real Sun, but this removes the variation over a year as the Earth moves along its orbit around the Sun (due to both its velocity and its axial tilt).
The Earth's day has increased in length over time. This phenomenon is due to tides raised by the Moon which slow Earth's rotation. Because of the way the second is defined, the mean length of a day is now about 86 400.002 seconds, and is increasing by about 1.7 milliseconds per century (an average over the last 2 700 years). (See tidal acceleration for details.) The length of a day circa 620 million years ago has been estimated from rhythmites (alternating layers in sandstone) as having been about 21.9 hours. The length of day for the Earth before the moon was created is still unknown.
Etymology.
The term comes from the Old English "d√¶g", with its cognates such as "dagur" in Icelandic, "Tag" in German, and "dag" in Norwegian, Danish, Swedish and Dutch. All of them from the Indo-European root dyau which explains the similarity with Latin dies though the word is known to come from the Germanic branch. As of October 17, 2015, "day" is the 205th most common word in US English, and the 210th most common in UK English.
International System of Units (SI).
A day, symbol "d", is defined as 86 400 seconds. The Second is the base unit of time in SI units.
A day according to Coordinated Universal Time (UTC) can include a negative or positive leap second, and can therefore have a length of either 86 399 or 86 401 seconds.
In 1967‚Äì68, during the 13th CGPM (Resolution 1), the International Bureau of Weights and Measures (BIPM) redefined a second as ‚Ä¶ the duration of 9 192 631 770 periods of the radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium 133 atom.
This makes the SI-based day last exactly 794 243 384 928 000 of those periods.
Decimal and metric time.
In the 19th century, an idea circulated to make a decimal fraction ( or ) of an astronomical day the base unit of time. This was an afterglow of the short-lived movement toward a decimalisation of timekeeping and the calendar, which had been given up already due to its difficulty in transitioning from traditional, more familiar units. The most successful alternative is the "centiday", equal to 14.4 minutes (864 seconds), being not only a shorter multiple of an hour (0.24 vs 2.4) but also closer to the SI multiple "kilosecond" (1 000 seconds) and equal to the traditional Chinese unit, "ke".
Astronomy.
A day of exactly 86 400 SI seconds is the base unit of time in astronomy (the second is not preferred).
For a given planet, there are three types of day defined in astronomy:
For Earth, the stellar day and the sidereal day are nearly of the same length and about 3 minutes 56 seconds shorter than the solar day. Relative to the fixed stars, the Earth spins just over 366 times upon its axis during one complete orbit. The Earth's orbit around the Sun reduces (by one) the number of transits the Sun makes across the Earth's sky in a sidereal year.
Colloquial.
The word refers to various similarly defined ideas, such as:
Civil day.
For civil purposes, a common clock time is typically defined for an entire region based on the local mean solar time at a central meridian. Such "time zones" began to be adopted about the middle of the 19th century when railroads with regularly occurring schedules came into use, with most major countries having adopted them by 1929. As of 2015, throughout the world, 40 such zones are now in use: the central zone, from which all others are defined as offsets, is known as , which uses Coordinated Universal Time (UTC).
The most common convention starts the civil day at midnight: this is near the time of the lower culmination of the Sun on the central meridian of the time zone. Such a day may be referred to as a calendar day.
A day is commonly divided into 24 hours of 60 minutes, with each minute composed of 60 seconds.
Leap seconds.
In order to keep the civil day aligned with the apparent movement of the Sun, positive or negative leap seconds may be inserted from time to time. Therefore, although typically 86 400 SI seconds in duration, a civil day can be either 86 401 or 86 399 SI seconds long on such a day.
Leap seconds are announced in advance by the International Earth Rotation and Reference Systems Service (IERS), which measures the Earth's rotation and determines whether a leap second is necessary. Leap seconds occur only at the end of a UTC-calculated month, and have only ever been inserted at the end of June 30 or December 31.
Boundaries.
For most diurnal animals, the day naturally begins at dawn and ends at sunset. Humans, with their cultural norms and scientific knowledge, have employed several different conceptions of the day's boundaries. The Jewish day begins at either sunset or nightfall (when three second-magnitude stars appear). Medieval Europe also followed this tradition, known as Florentine reckoning: in this system, a reference like "two hours into the day" meant "two hours after sunset" and thus times during the evening need to be shifted back one calendar day in modern reckoning. Days such as Christmas Eve, Halloween, and the Eve of Saint Agnes are remnants of the older pattern when holidays began during the prior evening. Common convention in modern times is for the civil day to begin at midnight, i.e. 00:00, and last a full 24 hours until 24:00 (i.e. 00:00 of the next day). Prior to 1926, Turkey had two time systems: Turkish (counting the hours from sunset) and French (counting the hours from midnight).
In ancient Egypt, the day was reckoned from sunrise to sunrise. Muslims fast from sunrise to sunset each day during the month of Ramadan. The "Damascus Document", copies of which were also found among the Dead Sea scrolls, states regarding the observance of the Sabbath that "No one is to do any work on Friday "from the moment that the Sun's disk stands distant from the horizon by the length of its own diameter"," presumably indicating that the monastic community responsible for producing this work counted the day as ending shortly before the Sun had begun to set. 
In many cultures, nights are named after the previous day. For example,"Friday night" usually means the entire night between Friday and Saturday. This difference from the civil day often leads to confusion. Events starting at midnight are often announced as occurring the day before. TV-guides tend to list nightly programs at the previous day, although programming a VCR requires the strict logic of starting the new day at 00:00 (to further confuse the issue, VCRs set to the 12-hour clock notation will label this "12:00 AM"). Expressions like "today", "yesterday" and "tomorrow" become ambiguous during the night. Because Jews and Muslims begin their days at nightfall, "Saturday" (Arabic word) night, for example, is what most people would call Friday night.
Validity of tickets, passes, etc., for a day or a number of days may end at midnight, or closing time, when that is earlier. However, if a service (e.g., public transport) operates from for example, 6:00 to 1:00 the next day (which may be noted as 25:00), the last hour may well count as being part of the previous day. For services depending on the day ("closed on Sundays", "does not run on Fridays", and so on) there is a risk of ambiguity. For example, a day ticket on the Nederlandse Spoorwegen (Dutch Railways) is valid for 28 hours, from 0:00 to 28:00 (that is, 4:00 the next day); the validity of a pass on Transport for London (TfL) services is until the end of the "transport day"‚Äîthat is to say, until 4:30 am on the day after the "expiry" date stamped on the pass.
24 hours vs daytime.
To distinguish between a full day and daytime, the word "nychthemeron" (from Greek for a night and a day) may be used in English for the former, or more colloquially the term . In other languages, the latter is also often used. Other languages also have a separate word for a full day, such as "vuorokausi" in Finnish, "√∂√∂p√§ev" in Estonian, "dygn" in Swedish, "d√∏gn" in Danish, "d√∏gn" in Norwegian, "s√≥larhringur" in Icelandic, "etmaal" in Dutch, "doba" in Polish, "—Å—É—Ç–∫–∏" ("sutki") in Russian, "—Å—É—Ç–∫—ñ" ("sutki") in Belarusian, "–¥–æ–±–∞ÃÅ" ("doba") in Ukrainian, "–¥–µ–Ω–æ–Ω–æ—â–∏–µ" in Bulgarian and ◊ô◊û◊û◊î in Hebrew. In Italian, "giorno" is used to indicate a full day, while "d√¨" means daytime. In ancient India, "Ahoratra" is used to represent a full day. In Spanish, "singladura" is used, but only as a marine unit of length, being the distance covered in 24 hours.

</doc>
<doc id="8377" url="https://en.wikipedia.org/wiki?curid=8377" title="Database">
Database

A database is an organized collection of data. It is the collection of schemas, tables, queries, reports, views and other objects.
The data are typically organized to model aspects of reality in a way that supports processes requiring information, such as modelling the availability of rooms in hotels in a way that supports finding a hotel with vacancies.
A database management system (DBMS) is a computer software application that interacts with the user, other applications, and the database itself to capture and analyze data. A general-purpose DBMS is designed to allow the definition, creation, querying, update, and administration of databases. Well-known DBMSs include MySQL, PostgreSQL, Microsoft SQL Server, Oracle, Sybase, SAP HANA, and IBM DB2. A database is not generally portable across different DBMSs, but different DBMS can interoperate by using standards such as SQL and ODBC or JDBC to allow a single application to work with more than one DBMS. Database management systems are often classified according to the database model that they support; the most popular database systems since the 1980s have all supported the relational model as represented by the SQL language. Sometimes a DBMS is loosely referred to as a 'database'.
Terminology and overview.
Formally, a "database" refers to a set of related data and the way it is organized. Access to these data is usually provided by a "database management system" (DBMS) consisting of an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized.
Because of the close relationship between them, the term "database" is often used casually to refer to both a database and the DBMS used to manipulate it.
Outside the world of professional information technology, the term "database" is often used to refer to any collection of related data (such as a spreadsheet or a card index). This article is concerned only with databases where the size and usage requirements necessitate use of a database management system.
Existing DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups:
Both a database and its DBMS conform to the principles of a particular database model. "Database system" refers collectively to the database model, database management system, and database.
Physically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. RAID is used for recovery of data if any of the disks fail. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large volume transaction processing environments. DBMSs are found at the heart of most database applications. DBMSs may be built around a custom multitasking kernel with built-in networking support, but modern DBMSs typically rely on a standard operating system to provide these functions. from databases before the inception of Structured Query Language (SQL). The data recovered was disparate, redundant and disorderly, since there was no proper method to fetch it and arrange it in a concrete structure.
Since DBMSs comprise a significant economical market, computer and storage vendors often take into account DBMS requirements in their own development plans.
Databases and DBMSs can be categorized according to the database model(s) that they support (such as relational or XML), the type(s) of computer they run on (from a server cluster to a mobile phone), the query language(s) used to access the database (such as SQL or XQuery), and their internal engineering, which affects performance, scalability, resilience, and security.
Applications.
Databases are used to support internal operations of organizations and to underpin online interactions with customers and suppliers (see Enterprise software).
Databases are used to hold administrative information and more specialized data, such as engineering data or economic models. Examples of database applications include computerized library systems, flight reservation systems, computerized parts inventory systems, and many content management systems that store websites as collections of webpages in a database.
General-purpose and special-purpose DBMSs.
A DBMS has evolved into a complex software system and its development typically requires thousands of human years of development effort. Some general-purpose DBMSs such as Adabas, Oracle and DB2 have been undergoing upgrades since the 1970s. General-purpose DBMSs aim to meet the needs of as many applications as possible, which adds to the complexity. However, the fact that their development cost can be spread over a large number of users means that they are often the most cost-effective approach. However, a general-purpose DBMS is not always the optimal solution: in some cases a general-purpose DBMS may introduce unnecessary overhead. Therefore, there are many examples of systems that use special-purpose databases. A common example is an email system that performs many of the functions of a general-purpose DBMS such as the insertion and deletion of messages composed of various items of data or associating messages with a particular email address; but these functions are limited to what is required to handle email and don't provide the user with all of the functionality that would be available using a general-purpose DBMS.
Many other databases have application software that accesses the database on behalf of end-users, without exposing the DBMS interface directly. Application programmers may use a wire protocol directly, or more likely through an application programming interface. Database designers and database administrators interact with the DBMS through dedicated interfaces to build and maintain the applications' databases, and thus need some more knowledge and understanding about how DBMSs operate and the DBMSs' external interfaces and tuning parameters.
History.
Following the technology progress in the areas of processors, computer memory, computer storage and computer networks, the sizes, capabilities, and performance of databases and their respective DBMSs have grown in orders of magnitude. The development of database technology can be divided into three eras based on data model or structure: navigational, SQL/relational, and post-relational.
The two main early navigational data models were the hierarchical model, epitomized by IBM's IMS system, and the CODASYL model (network model), implemented in a number of products such as IDMS.
The relational model, first proposed in 1970 by Edgar F. Codd, departed from this tradition by insisting that applications should search for data by content, rather than by following links. The relational model employs sets of ledger-style tables, each used for a different type of entity. Only in the mid-1980s did computing hardware become powerful enough to allow the wide deployment of relational systems (DBMSs plus applications). By the early 1990s, however, relational systems dominated in all large-scale data processing applications, and they remain dominant : IBM DB2, Oracle, MySQL and Microsoft SQL Server are the top DBMS. The dominant database language, standardised SQL for the relational model, has influenced database languages for other data models.
Object databases were developed in the 1980s to overcome the inconvenience of object-relational impedance mismatch, which led to the coining of the term "post-relational" and also the development of hybrid object-relational databases.
The next generation of post-relational databases in the late 2000s became known as NoSQL databases, introducing fast key-value stores and document-oriented databases. A competing "next generation" known as NewSQL databases attempted new implementations that retained the relational/SQL model while aiming to match the high performance of NoSQL compared to commercially available relational DBMSs.
1960s, navigational DBMS.
The introduction of the term "database" coincided with the availability of direct-access storage (disks and drums) from the mid-1960s onwards. The term represented a contrast with the tape-based systems of the past, allowing shared interactive use rather than daily batch processing. The Oxford English Dictionary cites a 1962 report by the System Development Corporation of California as the first to use the term "data-base" in a specific technical sense.
As computers grew in speed and capability, a number of general-purpose database systems emerged; by the mid-1960s a number of such systems had come into commercial use. Interest in a standard began to grow, and Charles Bachman, author of one such product, the Integrated Data Store (IDS), founded the "Database Task Group" within CODASYL, the group responsible for the creation and standardization of COBOL. In 1971 the Database Task Group delivered their standard, which generally became known as the "CODASYL approach", and soon a number of commercial products based on this approach entered the market.
The CODASYL approach relied on the "manual" navigation of a linked data set which was formed into a large network. Applications could find records by one of three methods:
Later systems added B-trees to provide alternate access paths. Many CODASYL databases also added a very straightforward query language. However, in the final tally, CODASYL was very complex and required significant training and effort to produce useful applications.
IBM also had their own DBMS in 1966, known as Information Management System (IMS). IMS was a development of software written for the Apollo program on the System/360. IMS was generally similar in concept to CODASYL, but used a strict hierarchy for its model of data navigation instead of CODASYL's network model. Both concepts later became known as navigational databases due to the way data was accessed, and Bachman's 1973 Turing Award presentation was "The Programmer as Navigator". IMS is classified as a hierarchical database. IDMS and Cincom Systems' TOTAL database are classified as network databases. IMS remains in use .
1970s, relational DBMS.
Edgar Codd worked at IBM in San Jose, California, in one of their offshoot offices that was primarily involved in the development of hard disk systems. He was unhappy with the navigational model of the CODASYL approach, notably the lack of a "search" facility. In 1970, he wrote a number of papers that outlined a new approach to database construction that eventually culminated in the groundbreaking "A Relational Model of Data for Large Shared Data Banks". 
In this paper, he described a new system for storing and working with large databases. Instead of records being stored in some sort of linked list of free-form records as in CODASYL, Codd's idea was to use a "table" of fixed-length records, with each table used for a different type of entity. A linked-list system would be very inefficient when storing "sparse" databases where some of the data for any one record could be left empty. The relational model solved this by splitting the data into a series of normalized tables (or "relations"), with optional elements being moved out of the main table to where they would take up room only if needed. Data may be freely inserted, deleted and edited in these tables, with the DBMS doing whatever maintenance needed to present a table view to the application/user.
The relational model also allowed the content of the database to evolve without constant rewriting of links and pointers. The relational part comes from entities referencing other entities in what is known as one-to-many relationship, like a traditional hierarchical model, and many-to-many relationship, like a navigational (network) model. Thus, a relational model can express both hierarchical and navigational models, as well as its native tabular model, allowing for pure or combined modeling in terms of these three models, as the application requires.
For instance, a common use of a database system is to track information about users, their name, login information, various addresses and phone numbers. In the navigational approach all of this data would be placed in a single record, and unused items would simply not be placed in the database. In the relational approach, the data would be "normalized" into a user table, an address table and a phone number table (for instance). Records would be created in these optional tables only if the address or phone numbers were actually provided.
Linking the information back together is the key to this system. In the relational model, some bit of information was used as a "key", uniquely defining a particular record. When information was being collected about a user, information stored in the optional tables would be found by searching for this key. For instance, if the login name of a user is unique, addresses and phone numbers for that user would be recorded with the login name as its key. This simple "re-linking" of related data back into a single collection is something that traditional computer languages are not designed for.
Just as the navigational approach would require programs to loop in order to collect records, the relational approach would require loops to collect information about any "one" record. Codd's solution to the necessary looping was a set-oriented language, a suggestion that would later spawn the ubiquitous SQL. Using a branch of mathematics known as tuple calculus, he demonstrated that such a system could support all the operations of normal databases (inserting, updating etc.) as well as providing a simple system for finding and returning "sets" of data in a single operation.
Codd's paper was picked up by two people at Berkeley, Eugene Wong and Michael Stonebraker. They started a project known as INGRES using funding that had already been allocated for a geographical database project and student programmers to produce code. Beginning in 1973, INGRES delivered its first test products which were generally ready for widespread use in 1979. INGRES was similar to System R in a number of ways, including the use of a "language" for data access, known as QUEL. Over time, INGRES moved to the emerging SQL standard.
IBM itself did one test implementation of the relational model, PRTV, and a production one, Business System 12, both now discontinued. Honeywell wrote MRDS for Multics, and now there are two new implementations: Alphora Dataphor and Rel. Most other DBMS implementations usually called "relational" are actually SQL DBMSs.
In 1970, the University of Michigan began development of the MICRO Information Management System based on D.L. Childs' Set-Theoretic Data model. MICRO was used to manage very large data sets by the US Department of Labor, the U.S. Environmental Protection Agency, and researchers from the University of Alberta, the University of Michigan, and Wayne State University. It ran on IBM mainframe computers using the Michigan Terminal System. The system remained in production until 1998.
Integrated approach.
In the 1970s and 1980s attempts were made to build database systems with integrated hardware and software. The underlying philosophy was that such integration would provide higher performance at lower cost. Examples were IBM System/38, the early offering of Teradata, and the Britton Lee, Inc. database machine.
Another approach to hardware support for database management was ICL's CAFS accelerator, a hardware disk controller with programmable search capabilities. In the long term, these efforts were generally unsuccessful because specialized database machines could not keep pace with the rapid development and progress of general-purpose computers. Thus most database systems nowadays are software systems running on general-purpose hardware, using general-purpose computer data storage. However this idea is still pursued for certain applications by some companies like Netezza and Oracle (Exadata).
Late 1970s, SQL DBMS.
IBM started working on a prototype system loosely based on Codd's concepts as "System R" in the early 1970s. The first version was ready in 1974/5, and work then started on multi-table systems in which the data could be split so that all of the data for a record (some of which is optional) did not have to be stored in a single large "chunk". Subsequent multi-user versions were tested by customers in 1978 and 1979, by which time a standardized query language ‚Äì SQL ‚Äì had been added. Codd's ideas were establishing themselves as both workable and superior to CODASYL, pushing IBM to develop a true production version of System R, known as "SQL/DS", and, later, "Database 2" (DB2).
Larry Ellison's Oracle started from a different chain, based on IBM's papers on System R, and beat IBM to market when the first version was released in 1978.
Stonebraker went on to apply the lessons from INGRES to develop a new database, Postgres, which is now known as PostgreSQL. PostgreSQL is often used for global mission critical applications (the .org and .info domain name registries use it as their primary data store, as do many large companies and financial institutions).
In Sweden, Codd's paper was also read and Mimer SQL was developed from the mid-1970s at Uppsala University. In 1984, this project was consolidated into an independent enterprise. In the early 1980s, Mimer introduced transaction handling for high robustness in applications, an idea that was subsequently implemented on most other DBMSs.
Another data model, the entity‚Äìrelationship model, emerged in 1976 and gained popularity for database design as it emphasized a more familiar description than the earlier relational model. Later on, entity‚Äìrelationship constructs were retrofitted as a data modeling construct for the relational model, and the difference between the two have become irrelevant.
1980s, on the desktop.
The 1980s ushered in the age of desktop computing. The new computers empowered their users with spreadsheets like Lotus 1-2-3 and database software like dBASE. The dBASE product was lightweight and easy for any computer user to understand out of the box. C. Wayne Ratliff the creator of dBASE stated: "dBASE was different from programs like BASIC, C, FORTRAN, and COBOL in that a lot of the dirty work had already been done. The data manipulation is done by dBASE instead of by the user, so the user can concentrate on what he is doing, rather than having to mess with the dirty details of opening, reading, and closing files, and managing space allocation." dBASE was one of the top selling software titles in the 1980s and early 1990s.
1990s, object-oriented.
The 1990s, along with a rise in object-oriented programming, saw a growth in how data in various databases were handled. Programmers and designers began to treat the data in their databases as objects. That is to say that if a person's data were in a database, that person's attributes, such as their address, phone number, and age, were now considered to belong to that person instead of being extraneous data. This allows for relations between data to be relations to objects and their attributes and not to individual fields. The term "object-relational impedance mismatch" described the inconvenience of translating between programmed objects and database tables. Object databases and object-relational databases attempt to solve this problem by providing an object-oriented language (sometimes as extensions to SQL) that programmers can use as alternative to purely relational SQL. On the programming side, libraries known as object-relational mappings (ORMs) attempt to solve the same problem.
2000s, NoSQL and NewSQL.
XML databases are a type of structured document-oriented database that allows querying based on XML document attributes. XML databases are mostly used in enterprise database management, where XML is being used as the machine-to-machine data interoperability standard. XML database management systems include commercial software MarkLogic and Oracle Berkeley DB XML, and a free use software Clusterpoint Distributed XML/JSON Database. All are enterprise software database platforms and support industry standard ACID-compliant transaction processing with strong database consistency characteristics and high level of database security.
NoSQL databases are often very fast, do not require fixed table schemas, avoid join operations by storing denormalized data, and are designed to scale horizontally. The most popular NoSQL systems include MongoDB, Couchbase, Riak, Memcached, Redis, CouchDB, Hazelcast, Apache Cassandra and HBase, which are all open-source software products.
In recent years there was a high demand for massively distributed databases with high partition tolerance but according to the CAP theorem it is impossible for a distributed system to simultaneously provide consistency, availability and partition tolerance guarantees. A distributed system can satisfy any two of these guarantees at the same time, but not all three. For that reason many NoSQL databases are using what is called eventual consistency to provide both availability and partition tolerance guarantees with a reduced level of data consistency.
NewSQL is a class of modern relational databases that aims to provide the same scalable performance of NoSQL systems for online transaction processing (read-write) workloads while still using SQL and maintaining the ACID guarantees of a traditional database system. Such databases include ScaleBase, Clustrix, EnterpriseDB, MemSQL, NuoDB and VoltDB.
Research.
Database technology has been an active research topic since the 1960s, both in academia and in the research and development groups of companies (for example IBM Research). Research activity includes theory and development of prototypes. Notable research topics have included models, the atomic transaction concept and related concurrency control techniques, query languages and query optimization methods, RAID, and more.
The database research area has several dedicated academic journals (for example, "ACM Transactions on Database Systems"-TODS, "Data and Knowledge Engineering"-DKE) and annual conferences (e.g., ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE).
Examples.
One way to classify databases involves the type of their contents, for example: bibliographic, document-text, statistical, or multimedia objects. Another way is by their application area, for example: accounting, music compositions, movies, banking, manufacturing, or insurance. A third way is by some technical aspect, such as the database structure or interface type. This section lists a few of the adjectives used to characterize different kinds of databases.
Design and modeling.
The first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity-relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organisation, like "can a customer also be a supplier?", or "if a product is sold with two different forms of packaging, are those the same product or different products?", or "if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.
Producing the conceptual data model sometimes involves input from business processes, or the analysis of workflow in the organization. This can help to establish what information is needed in the database, and what can be left out. For example, it can help when deciding whether the database needs to hold historic data as well as current data.
Having produced a conceptual data model that users are happy with, the next stage is to translate this into a schema that implements the relevant data structures within the database. This process is often called logical database design, and the output is a logical data model expressed in the form of a schema. Whereas the conceptual data model is (in theory at least) independent of the choice of database technology, the logical data model will be expressed in terms of a particular database model supported by the chosen DBMS. (The terms "data model" and "database model" are often used interchangeably, but in this article we use "data model" for the design of a specific database, and "database model" for the modelling notation used to express that design.)
The most popular database model for general-purpose databases is the relational model, or more precisely, the relational model as represented by the SQL language. The process of creating a logical database design using this model uses a methodical approach known as normalization. The goal of normalization is to ensure that each elementary "fact" is only recorded in one place, so that insertions, updates, and deletions automatically maintain consistency.
The final stage of database design is to make the decisions that affect performance, scalability, recovery, security, and the like. This is often called "physical database design". A key goal during this stage is data independence, meaning that the decisions made for performance optimization purposes should be invisible to end-users and applications. Physical design is driven mainly by performance requirements, and requires a good knowledge of the expected workload and access patterns, and a deep understanding of the features offered by the chosen DBMS.
Another aspect of physical database design is security. It involves both defining access control to database objects as well as defining security levels and methods for the data itself.
Models.
A database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized, and manipulated. The most popular example of a database model is the relational model (or the SQL approximation of relational), which uses a table-based format.
Common logical data models for databases include:
An object-relational database combines the two related structures.
Physical data models include:
Other models include:
Specialized models are optimized for particular types of data:
External, conceptual, and internal views.
A database management system provides three views of the database data:
While there is typically only one conceptual (or logical) and physical (or internal) view of the data, there can be any number of different external views. This allows users to see database information in a more business-related way rather than from a technical, processing viewpoint. For example, a financial department of a company needs the payment details of all employees as part of the company's expenses, but does not need details about employees that are the interest of the human resources department. Thus different departments need different "views" of the company's database.
The three-level database architecture relates to the concept of "data independence" which was one of the major initial driving forces of the relational model. The idea is that changes made at a certain level do not affect the view at a higher level. For example, changes in the internal level do not affect application programs written using conceptual level interfaces, which reduces the impact of making physical changes to improve performance.
The conceptual view provides a level of indirection between internal and external. On one hand it provides a common view of the database, independent of different external view structures, and on the other hand it abstracts away details of how the data are stored or managed (internal level). In principle every level, and even every external view, can be presented by a different data model. In practice usually a given DBMS uses the same data model for both the external and the conceptual levels (e.g., relational model). The internal level, which is hidden inside the DBMS and depends on its implementation, requires a different level of detail and uses its own types of data structure types.
Separating the "external", "conceptual" and "internal" levels was a major feature of the relational database model implementations that dominate 21st century databases.
Languages.
Database languages are special-purpose languages, which do one or more of the following:
Database languages are specific to a particular data model. Notable examples include:
A database language may also incorporate features like:
Performance, security, and availability.
Because of the critical importance of database technology to the smooth running of an enterprise, database systems include complex mechanisms to deliver the required performance, security, and availability, and allow database administrators to control the use of these features.
Storage.
Database storage is the container of the physical materialization of a database. It comprises the "internal" (physical) "level" in the database architecture. It also contains all the information needed (e.g., metadata, "data about the data", and internal data structures) to reconstruct the "conceptual level" and "external level" from the internal level when needed. Putting data into permanent storage is generally the responsibility of the database engine a.k.a. "storage engine". Though typically accessed by a DBMS through the underlying operating system (and often utilizing the operating systems' file systems as intermediates for storage layout), storage properties and configuration setting are extremely important for the efficient operation of the DBMS, and thus are closely maintained by database administrators. A DBMS, while in operation, always has its database residing in several types of storage (e.g., memory and external storage). The database data and the additional needed information, possibly in very large amounts, are coded into bits. Data typically reside in the storage in structures that look completely different from the way the data look in the conceptual and external levels, but in ways that attempt to optimize (the best possible) these levels' reconstruction when needed by users and programs, as well as for computing additional types of needed information from the data (e.g., when querying the database).
Some DBMSs support specifying which character encoding was used to store data, so multiple encodings can be used in the same database.
Various low-level database storage structures are used by the storage engine to serialize the data model so it can be written to the medium of choice. Techniques such as indexing may be used to improve performance. Conventional storage is row-oriented, but there are also column-oriented and correlation databases.
Materialized views.
Often storage redundancy is employed to increase performance. A common example is storing "materialized views", which consist of frequently needed "external views" or query results. Storing such views saves the expensive computing of them each time they are needed. The downsides of materialized views are the overhead incurred when updating them to keep them synchronized with their original updated database data, and the cost of storage redundancy.
Replication.
Occasionally a database employs storage redundancy by database objects replication (with one or more copies) to increase data availability (both to improve performance of simultaneous multiple end-user accesses to a same database object, and to provide resiliency in a case of partial failure of a distributed database). Updates of a replicated object need to be synchronized across the object copies. In many cases the entire database is replicated.
Security.
Database security deals with all various aspects of protecting the database content, its owners, and its users. It ranges from protection from intentional unauthorized database uses to unintentional database accesses by unauthorized entities (e.g., a person or a computer program).
Database access control deals with controlling who (a person or a certain computer program) is allowed to access what information in the database. The information may comprise specific database objects (e.g., record types, specific records, data structures), certain computations over certain objects (e.g., query types, or specific queries), or utilizing specific access paths to the former (e.g., using specific indexes or other data structures to access information). Database access controls are set by special authorized (by the database owner) personnel that uses dedicated protected security DBMS interfaces.
This may be managed directly on an individual basis, or by the assignment of individuals and privileges to groups, or (in the most elaborate models) through the assignment of individuals and groups to roles which are then granted entitlements. Data security prevents unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or subsets of it called "subschemas". For example, an employee database can contain all the data about an individual employee, but one group of users may be authorized to view only payroll data, while others are allowed access to only work history and medical data. If the DBMS provides a way to interactively enter and update the database, as well as interrogate it, this capability allows for managing personal databases.
Data security in general deals with protecting specific chunks of data, both physically (i.e., from corruption, or destruction, or removal; e.g., see physical security), or the interpretation of them, or parts of them to meaningful information (e.g., by looking at the strings of bits that they comprise, concluding specific valid credit-card numbers; e.g., see data encryption).
Change and access logging records who accessed which attributes, what was changed, and when it was changed. Logging services allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this to the database. Monitoring can be set up to attempt to detect security breaches.
Transactions and concurrency.
Database transactions can be used to introduce some level of fault tolerance and data integrity after recovery from a crash. A database transaction is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special transaction commands).
The acronym ACID describes some ideal properties of a database transaction: Atomicity, Consistency, Isolation, and Durability.
Migration.
A database built with one DBMS is not portable to another DBMS (i.e., the other DBMS cannot run it). However, in some situations it is desirable to move, migrate a database from one DBMS to another. The reasons are primarily economical (different DBMSs may have different total costs of ownership or TCOs), functional, and operational (different DBMSs may have different capabilities). The migration involves the database's transformation from one DBMS type to another. The transformation should maintain (if possible) the database related application (i.e., all related application programs) intact. Thus, the database's conceptual and external architectural levels should be maintained in the transformation. It may be desired that also some aspects of the architecture internal level are maintained. A complex or large database migration may be a complicated and costly (one-time) project by itself, which should be factored into the decision to migrate. This in spite of the fact that tools may exist to help migration between specific DBMSs. Typically a DBMS vendor provides tools to help importing databases from other popular DBMSs.
Building, maintaining, and tuning.
After designing a database for an application, the next stage is building the database. Typically an appropriate general-purpose DBMS can be selected to be utilized for this purpose. A DBMS provides the needed user interfaces to be utilized by database administrators to define the needed application's data structures within the DBMS's respective data model. Other user interfaces are used to select needed DBMS parameters (like security related, storage allocation parameters, etc.).
When the database is ready (all its data structures and other needed components are defined) it is typically populated with initial application's data (database initialization, which is typically a distinct project; in many cases using specialized DBMS interfaces that support bulk insertion) before making it operational. In some cases the database becomes operational while empty of application data, and data are accumulated during its operation.
After the database is created, initialised and populated it needs to be maintained. Various database parameters may need changing and the database may need to be tuned (tuning) for better performance; application's data structures may be changed or added, new related application programs may be written to add to the application's functionality, etc.
Backup and restore.
Sometimes it is desired to bring a database back to a previous state (for many reasons, e.g., cases when the database is found corrupted due to a software error, or if it has been updated with erroneous data). To achieve this a backup operation is done occasionally or continuously, where each desired database state (i.e., the values of its data and their embedding in database's data structures) is kept within dedicated backup files (many techniques exist to do this effectively). When this state is needed, i.e., when it is decided by a database administrator to bring the database back to this state (e.g., by specifying this state by a desired point in time when the database was in this state), these files are utilized to restore that state.
Static Analysis.
Static analysis techniques for software verification can be applied also in the scenario of query languages. In particular, the *Abstract interpretation framework has been extended to the field of query languages for relational databases as a way to support sound approximation techniques. The semantics of query languages can be tuned according to suitable abstractions of the concrete domain of data. The abstraction of relational database system has many interesting applications, in particular, for security purposes, such as fine grained access control, watermarking, etc.
Other.
Other DBMS features might include:

</doc>
<doc id="8378" url="https://en.wikipedia.org/wiki?curid=8378" title="Dipole">
Dipole

In electromagnetism, there are two kinds of dipoles:
Dipoles can be characterized by their dipole moment, a vector quantity. For the simple electric dipole given above, the electric dipole moment points from the negative charge towards the positive charge, and has a magnitude equal to the strength of each charge times the separation between the charges. (To be precise: for the definition of the dipole moment, one should always consider the "dipole limit", where, for example, the distance of the generating charges should "converge" to 0 while simultaneously, the charge strength should "diverge" to infinity in such a way that the product remains a positive constant.)
For the current loop, the magnetic dipole moment points through the loop (according to the right hand grip rule), with a magnitude equal to the current in the loop times the area of the loop.
In addition to current loops, the electron, among other fundamental particles, has a magnetic dipole moment. That is because it generates a magnetic field that is identical to that generated by a very small current loop. However, the electron's magnetic moment is not due to a current loop, but is instead an intrinsic property of the electron. It is also possible that the electron has an "electric" dipole moment although it has not yet been observed (see electron electric dipole moment for more information).
A permanent magnet, such as a bar magnet, owes its magnetism to the intrinsic magnetic dipole moment of the electron. The two ends of a bar magnet are referred to as poles (not to be confused with monopoles), and may be labeled "north" and "south". In terms of the Earth's magnetic field, they are respectively "north-seeking" and "south-seeking" poles: if the magnet were freely suspended in the Earth's magnetic field, the north-seeking pole would point towards the north and the south-seeking pole would point twards the south. The dipole moment of the bar magnet points from its magnetic south to its magnetic north pole. The north pole of a bar magnet in a compass points north. However, that means that Earth's geomagnetic north pole is the "south" pole (south-seeking pole) of its dipole moment and vice versa.
The only known mechanisms for the creation of magnetic dipoles are by current loops or quantum-mechanical spin since the existence of magnetic monopoles has never been experimentally demonstrated.
The term comes from the Greek Œ¥ŒØœÇ ("dis"), "twice" and œÄœåŒªŒøœÇ ("p√≤los"), "axis".
Classification.
A "physical dipole" consists of two equal and opposite point charges: in the literal sense, two poles. Its field at large distances (i.e., distances large in comparison to the separation of the poles) depends almost entirely on the dipole moment as defined above. A "point (electric) dipole" is the limit obtained by letting the separation tend to 0 while keeping the dipole moment fixed. The field of a point dipole has a particularly simple form, and the order-1 term in the multipole expansion is precisely the point dipole field.
Although there are no known magnetic monopoles in nature, there are magnetic dipoles in the form of the quantum-mechanical spin associated with particles such as electrons (although the accurate description of such effects falls outside of classical electromagnetism). A theoretical magnetic "point dipole" has a magnetic field of exactly the same form as the electric field of an electric point dipole. A very small current-carrying loop is approximately a magnetic point dipole; the magnetic dipole moment of such a loop is the product of the current flowing in the loop and the (vector) area of the loop.
Any configuration of charges or currents has a 'dipole moment', which describes the dipole whose field is the best approximation, at large distances, to that of the given configuration. This is simply one term in the multipole expansion when the total charge ("monopole moment") is 0 ‚Äî as it "always" is for the magnetic case, since there are no magnetic monopoles. The dipole term is the dominant one at large distances: Its field falls off in proportion to 1/"r"3, as compared to 1/"r"4 for the next (quadrupole) term and higher powers of 1/"r" for higher terms, or 1/"r"2 for the monopole term.
Molecular dipoles.
Many molecules have such dipole moments due to non-uniform distributions of positive and negative charges on the various atoms. Such is the case with polar compounds like hydrogen fluoride (HF), where electron density is shared unequally between atoms. Therefore, a molecule's dipole is an electric dipole with an inherent electric field which should not be confused with a magnetic dipole which generates a magnetic field.
The physical chemist Peter J. W. Debye was the first scientist to study molecular dipoles extensively, and, as a consequence, dipole moments are measured in units named "debye" in his honor.
For molecules there are three types of dipoles:
More generally, an induced dipole of "any" polarizable charge distribution "œÅ" (remember that a molecule has a charge distribution) is caused by an electric field external to "œÅ". This field may, for instance, originate from an ion or polar molecule in the vicinity of "œÅ" or may be macroscopic (e.g., a molecule between the plates of a charged capacitor). The size of the induced dipole is equal to the product of the strength of the
external field and the dipole polarizability of "œÅ".
Dipole moment values can be obtained from measurement of the dielectric constant. Some typical gas phase values in debye units are:
KBr has one of the highest dipole moments because it is a very ionic molecule (which only exists as a molecule in the gas phase).
For example the zero dipole of CO2 implies that the two C=O bond dipole moments cancel so that the molecule must be linear. For H2O the O-H bond moments do not cancel because the molecule is bent. For ozone (O3) which is also a bent molecule, the bond dipole moments are not zero even though the O-O bonds are between similar atoms. This agrees with the Lewis structures for the resonance forms of ozone which show a positive charge on the central oxygen atom. 
An example in organic chemistry of the role of geometry in determining dipole moment is the "cis" and "trans" isomers of 1,2-dichloroethene. In the cis isomer the two polar C-Cl bonds are on the same side of the C=C double bond and the molecular dipole moment is 1.90 D. In the trans isomer, the dipole moment is zero because the two C-Cl bond are on opposite sides of the C=C and cancel (and the two bond moments for the much less polar C-H bonds also cancel).
Another example of the role of molecular geometry is boron trifluoride, which has three polar bonds with a difference in electronegativity greater than the traditionally cited threshold of 1.7 for ionic bonding. However, due to the equilateral triangular distribution of the fluoride ions about the boron cation center, the molecule as a whole does not exhibit any identifiable pole: one cannot construct a plane that divides the molecule into a net negative part and a net positive part.
Quantum mechanical dipole operator.
Consider a collection of "N" particles with charges "qi" and position vectors r"i". For instance, this collection may be a molecule consisting of electrons, all with charge ‚àí"e", and nuclei with charge "eZi", where "Zi" is the atomic number of the "i"‚Äâth nucleus.
The dipole observable (physical quantity) has the quantum mechanical dipole operator:
Notice that this definition is valid only for non-charged dipoles, i.e. total charge equal to zero. To a charged dipole we have the next equation:
where formula_3 is the center of mass of the molecule/group of particles.
Atomic dipoles.
A non-degenerate (S-state) atom can have only a zero permanent dipole. This fact follows quantum mechanically from the inversion symmetry of atoms. All 3 components of the dipole operator are antisymmetric under inversion with respect to the nucleus,
where formula_5 is the dipole operator and formula_6 is the inversion operator.
The permanent dipole moment of an atom in a non-degenerate state (see degenerate energy level) is given as the expectation (average) value of the dipole operator,
where formula_8 is an S-state, non-degenerate, wavefunction, which
is symmetric or antisymmetric under inversion: formula_9.
Since the product of the wavefunction (in the ket) and its complex conjugate (in the bra) is always symmetric under inversion and its inverse,
it follows that the expectation value changes sign under inversion. We used here the fact that
formula_11, being a symmetry operator, is unitary:
formula_12 and by definition
the Hermitian adjoint formula_13 may be moved from bra to ket and then becomes formula_14.
Since the only quantity that is equal to minus itself is the zero, the expectation value vanishes,
In the case of open-shell atoms with degenerate energy levels, one could define a dipole moment by the aid of the first-order Stark effect. This gives a non-vanishing dipole (by definition proportional to a non-vanishing first-order Stark shift) only if some of the wavefunctions belonging to the degenerate energies have opposite parity; i.e., have different behavior under inversion. This is a rare occurrence, but happens for the excited H-atom, where 2s and 2"p" states are "accidentally" degenerate (see article Laplace‚ÄìRunge‚ÄìLenz vector for the origin of this degeneracy) and have opposite parity (2s is even and 2p is odd).
Field of a static magnetic dipole.
Magnitude.
The far-field strength, "B", of a dipole magnetic field is given by
where
Conversion to cylindrical coordinates is achieved using and
where "œÅ" is the perpendicular distance from the "z"-axis. Then,
Vector form.
The field itself is a vector quantity:
where
This is "exactly" the field of a point dipole, "exactly" the dipole term in the multipole expansion of an arbitrary field, and "approximately" the field of any dipole-like configuration at large distances.
Magnetic vector potential.
The vector potential A of a magnetic dipole is
with the same definitions as above.
Field from an electric dipole.
The electrostatic potential at position r due to an electric dipole at the origin is given by:
where
This term appears as the second term in the multipole expansion of an arbitrary electrostatic potential Œ¶(r). If the source of Œ¶(r) is a dipole, as it is assumed here, this term is the only non-vanishing term in the multipole expansion of Œ¶(r). The electric field from a dipole can be found from the gradient of this potential:
where E is the electric field and "Œ¥"3 is the 3-dimensional delta function. This is formally identical to the magnetic H field of a point magnetic dipole with only a few names changed.
Torque on a dipole.
Since the direction of an electric field is defined as the direction of the force on a positive charge, electric field lines point away from a positive charge and toward a negative charge.
When placed in an electric or magnetic field, equal but opposite forces arise on each side of the dipole creating a torque œÑ:
for an electric dipole moment p (in coulomb-meters), or
for a magnetic dipole moment m (in ampere-square meters).
The resulting torque will tend to align the dipole with the applied field, which in the case of an electric dipole, yields a potential energy of
The energy of a magnetic dipole is similarly
Dipole radiation.
In addition to dipoles in electrostatics, it is also common to consider an electric or magnetic dipole that is oscillating in time. It is an extension, or a more physical next-step, to spherical wave radiation.
In particular, consider a harmonically oscillating electric dipole, with angular frequency œâ and a dipole moment formula_29 along the formula_30 direction of the form
In vacuum, the exact field produced by this oscillating dipole can be derived using the retarded potential formulation as:
formula_32
formula_33
For formula_34, the far-field takes the simpler form of a radiating "spherical" wave, but with angular dependence embedded in the cross-product:
The time-averaged Poynting vector
formula_37
is not distributed isotropically, but concentrated around the directions lying perpendicular to the dipole moment, as a result of the non-spherical electric and magnetic waves. In fact, the spherical harmonic function (formula_38) responsible for such "donut-shaped" angular distribution is precisely the formula_39 "p" wave.
The total time-average power radiated by the field can then be derived from the Poynting vector as
Notice that the dependence of the power on the fourth power of the frequency of the radiation is in accordance with the Rayleigh scattering, and the underlying effects why the sky consists of mainly blue colour.
A circular polarized dipole is described as a superposition of two linear dipoles.

</doc>
<doc id="8386" url="https://en.wikipedia.org/wiki?curid=8386" title="Dynamics">
Dynamics

Dynamics (from Greek Œ¥œÖŒΩŒ±ŒºŒπŒ∫œåœÇ "dynamikos" "powerful", from Œ¥œçŒΩŒ±ŒºŒπœÇ "dynamis" "power") may refer to:

</doc>
<doc id="8387" url="https://en.wikipedia.org/wiki?curid=8387" title="Draught beer">
Draught beer

Draught beer, also spelt draft, is beer served from a cask or keg rather than from a bottle or can. Draught beer served from a pressurised keg is also known as 
Name.
Until Joseph Bramah patented the beer engine in 1785, beer was served directly from the barrel and carried to the customer. The Old English "" ("carry; pull") developed into a series of related words including "drag", "draw", and "draught". By the time Bramah's beer pumps became popular, the use of the term "draught" to refer to the acts of serving or drinking beer was well established and transferred easily to beer served via the hand pumps. In time, the word came to be restricted to only such beer. The usual spelling is now "draught" in the United Kingdom, Ireland, Australia, and New Zealand and more commonly "draft" in North America, although it can be spelt either way. Regardless of spelling, the word is pronounced or depending on the region the speaker is from.
Canned draught is beer served from a pressurised container featuring a widget. Smooth flow (also known as cream flow, nitrokeg, or smooth) is the name brewers give to draught beers pressurised with a partial nitrogen gas blend.
History.
In 1691, an article in the "London Gazette" mentioned John Lofting, who held a patent for a fire engine: "The said patentee has also projected a very useful engine for starting of beer, and other liquors which will draw from 20 to 30 barrels an hour, which are completely fixed with brass joints and screws at reasonable rates".
In the early 20th century, draught beer started to be served from pressurised containers. Artificial carbonation was introduced in the United Kingdom in 1936, with Watney‚Äôs experimental pasteurised beer Red Barrel. Though this method of serving beer did not take hold in the U.K. until the late 1950s, it did become the favored method in the rest of Europe, where it is known by such terms as "en pression". The carbonation method of serving beer subsequently spread to the rest of the world; by the early 1970s the term "draught beer" almost exclusively referred to beer served under pressure as opposed to the traditional cask or barrel beer.
In Britain, the Campaign for Real Ale was founded in 1971 to protect traditional - unpressurised beer and brewing methods. The group devised the term "real ale" to differentiate between beer served from the cask and beer served under pressure. The term "real ale" has since been expanded to include bottle-conditioned beer.
Keg beer.
Keg beer is often filtered and/or pasteurised, both of which are processes that render the yeast inactive.
A tap hole near the edge of the top, and a spile hole on the side used for conditioning the unfiltered and unpasteurised beer. A keg has a single opening in the centre of the top to which a flow pipe is attached. Kegs are artificially pressurised after fermentation with carbon dioxide or a mixture of carbon dioxide and nitrogen gas.
"Keg" has become a term of contempt used by some, particularly in Britain, since the 1960s when pasteurised draught beers started replacing traditional cask beers.
Keg beer was replacing traditional cask ale in all parts of the UK, primarily because it requires less care to handle. Since 1971, the Campaign for Real Ale (CAMRA) has conducted a consumer campaign on behalf of those who prefer traditional cask beer. CAMRA has lobbied the British Parliament to ensure support for cask ale and microbreweries have sprung up to serve those consumers who prefer traditional cask beer.
Pressurised CO2 in the keg's headspace maintains carbonation in the beer. The CO2 pressure varies depending on the amount of CO2 already in the beer and the keg storage temperature. Occasionally the CO2 gas is blended with nitrogen gas. CO2 / nitrogen blends are used to allow a higher operating pressure in complex dispensing systems.
Nitrogen is used under high pressure when dispensing dry stouts (such as Guinness) and other creamy beers because it displaces CO2 to (artificially) form a rich tight head and a less carbonated taste. This makes the beer feel smooth on the palate and gives a foamy appearance. Premixed bottled gas for creamy beers is usually 75% nitrogen and 25% CO2. This premixed gas which only works well with creamy beers is often referred to as Guinness Gas, Beer Gas, or Aligal. Using "Beer Gas" with other beer styles can cause the last 5% to 10% of the beer in each keg to taste very flat and lifeless.
In the UK, the term keg beer would imply the beer is pasteurized, in contrast to unpasteurised cask beer. Some of the newer microbreweries may offer a nitro keg stout which is filtered but not pasteurized.
Storage and serving temperature.
Cask beer should be stored and served at a cellar temperature of 12¬∞C (54¬∞F). Once a cask is opened, it should be consumed within three days. Keg beer is given additional cooling just prior to being served either by flash coolers or a remote cooler in the cellar. This chills the beer down to temperatures between 3¬∞C and 8¬∞C.
Canned and bottled "draught".
The words "draft" and "draught" have been used as marketing terms to describe canned or bottled beers, implying that they taste and appear like beers from a cask or keg. Commercial brewers use this as a marketing tool although it is incorrect to call any beer not drawn from a cask or keg "draught". Two examples are Miller Genuine Draft, a pale lager which is produced using a patented cold filtering system, and Guinness stout in patented "Draught-flow" cans and bottles. Guinness is an example of beers that use a nitrogen widget to create a smooth beer with a very dense head. Guinness has recently replaced the widget system from their bottled "draught" beer with a coating of cellulose fibres on the inside of the bottle. Statements indicate a new development in bottling technology that enables the mixture of nitrogen and carbon dioxide to be present in the beer without using a widget, making it according to Guinness "more drinkable" from the bottle.
In some countries such as Japan, the term "draft" applied to canned or bottled beer indicates that the beer is not pasteurized (though it may be filtered), giving it a fresher taste but shorter shelf life than conventional packaged beers.

</doc>
<doc id="8388" url="https://en.wikipedia.org/wiki?curid=8388" title="Director">
Director

Director may refer to:

</doc>
<doc id="8389" url="https://en.wikipedia.org/wiki?curid=8389" title="Major depressive disorder">
Major depressive disorder

Major depressive disorder (MDD), often simply called depression, is a mental disorder characterized by a pervasive and persistent low mood that is accompanied by low self-esteem and by a loss of interest or pleasure in normally enjoyable activities. The term "depression" is used in a number of different ways. It is often used to mean this syndrome but may refer to other mood disorders or simply to a low mood. Major depressive disorder is a disabling condition that adversely affects a person's family, work or school life, sleeping and eating habits, and general health. In the United States, around 3.4% of people with major depression die by suicide, and up to 60% of people who die by suicide had depression or another mood disorder.
The diagnosis of major depressive disorder is based on the patient's self-reported experiences, behavior reported by relatives or friends, and a mental status examination. There is no laboratory test for major depression, although physicians generally request tests for physical conditions that may cause similar symptoms. The most common time of onset is between the ages of 20 and 30 years, with a later peak between 30 and 40 years.
Typically, people are treated with antidepressant medication and, in many cases, also receive counseling, particularly cognitive behavioral therapy (CBT). Medication appears to be effective, but the effect may only be significant in the most severely depressed. Hospitalization may be necessary in cases with associated self-neglect or a significant risk of harm to self or others. A minority are treated with electroconvulsive therapy (ECT). The course of the disorder varies widely, from one episode lasting weeks to a lifelong disorder with recurrent major depressive episodes. Depressed individuals have shorter life expectancies than those without depression, in part because of greater susceptibility to medical illnesses and suicide. It is unclear whether medications affect the risk of suicide. Current and former patients may be stigmatized.
The understanding of the nature and causes of depression has evolved over the centuries, though this understanding is incomplete and has left many aspects of depression as the subject of discussion and research. Proposed causes include psychological, psycho-social, hereditary, evolutionary and biological factors. Long-term substance abuse may cause or worsen depressive symptoms. Psychological treatments are based on theories of personality, interpersonal communication, and learning. Most biological theories focus on the monoamine chemicals serotonin, norepinephrine and dopamine, which are naturally present in the brain and assist communication between nerve cells. This cluster of symptoms (syndrome) was named, described and classified as one of the mood disorders in the 1980 edition of the American Psychiatric Association's diagnostic manual.
Symptoms and signs.
Major depression significantly affects a person's family and personal relationships, work or school life, sleeping and eating habits, and general health. Its impact on functioning and well-being has been compared to that of chronic medical conditions such as diabetes.
A person having a major depressive episode usually exhibits a very low mood, which pervades all aspects of life, and an inability to experience pleasure in activities that were formerly enjoyed. Depressed people may be preoccupied with, or ruminate over, thoughts and feelings of worthlessness, inappropriate guilt or regret, helplessness, hopelessness, and self-hatred. In severe cases, depressed people may have symptoms of psychosis. These symptoms include delusions or, less commonly, hallucinations, usually unpleasant. Other symptoms of depression include poor concentration and memory (especially in those with melancholic or psychotic features), withdrawal from social situations and activities, reduced sex drive, and thoughts of death or suicide. Insomnia is common among the depressed. In the typical pattern, a person wakes very early and cannot get back to sleep. Hypersomnia, or oversleeping, can also happen. Some antidepressants may also cause insomnia due to their stimulating effect.
A depressed person may report multiple physical symptoms such as fatigue, headaches, or digestive problems; physical complaints are the most common presenting problem in developing countries, according to the World Health Organization's criteria for depression. Appetite often decreases, with resulting weight loss, although increased appetite and weight gain occasionally occur. Family and friends may notice that the person's behavior is either agitated or lethargic. Older depressed people may have cognitive symptoms of recent onset, such as forgetfulness, and a more noticeable slowing of movements. Depression often coexists with physical disorders common among the elderly, such as stroke, other cardiovascular diseases, Parkinson's disease, and chronic obstructive pulmonary disease.
Depressed children may often display an irritable mood rather than a depressed mood, and show varying symptoms depending on age and situation. Most lose interest in school and show a decline in academic performance. They may be described as clingy, demanding, dependent, or insecure. Diagnosis may be delayed or missed when symptoms are interpreted as normal moodiness. Depression may also coexist with attention deficit hyperactivity disorder (ADHD), complicating the diagnosis and treatment of both.
Comorbidity.
Major depression frequently co-occurs with other psychiatric problems. The 1990‚Äì92 "National Comorbidity Survey" (US) reports that half of those with major depression also have lifetime anxiety and its associated disorders such as generalized anxiety disorder. Anxiety symptoms can have a major impact on the course of a depressive illness, with delayed recovery, increased risk of relapse, greater disability and increased suicide attempts. American neuroendocrinologist Robert Sapolsky similarly argues that the relationship between stress, anxiety, and depression could be measured and demonstrated biologically. There are increased rates of alcohol and drug abuse and particularly dependence, and around a third of individuals diagnosed with ADHD develop comorbid depression. Post-traumatic stress disorder and depression often co-occur.
Depression and pain often co-occur. One or more pain symptoms are present in 65% of depressed patients, and anywhere from 5 to 85% of patients with pain will be suffering from depression, depending on the setting; there is a lower prevalence in general practice, and higher in specialty clinics. The diagnosis of depression is often delayed or missed, and the outcome worsens. The outcome can also worsen if the depression is noticed but completely misunderstood.
Depression is also associated with a 1.5- to 2-fold increased risk of cardiovascular disease, independent of other known risk factors, and is itself linked directly or indirectly to risk factors such as smoking and obesity. People with major depression are less likely to follow medical recommendations for treating and preventing cardiovascular disorders, which further increases their risk of medical complications. In addition, cardiologists may not recognize underlying depression that complicates a cardiovascular problem under their care.
Causes.
The biopsychosocial model proposes that biological, psychological, and social factors all play a role in causing depression. The diathesis‚Äìstress model specifies that depression results when a preexisting vulnerability, or diathesis, is activated by stressful life events. The preexisting vulnerability can be either genetic, implying an interaction between nature and nurture, or schematic, resulting from views of the world learned in childhood.
Depression may be directly caused by damage to the cerebellum as is seen in cerebellar cognitive affective syndrome.
These interactive models have gained empirical support. For example, researchers in New Zealand took a prospective approach to studying depression, by documenting over time how depression emerged among an initially normal cohort of people. The researchers concluded that variation among the serotonin transporter (5-HTT) gene affects the chances that people who have dealt with very stressful life events will go on to experience depression. To be specific, depression may follow such events, but seems more likely to appear in people with one or two short alleles of the 5-HTT gene. In addition, a Swedish study estimated the heritability of depression‚Äîthe degree to which individual differences in occurrence are associated with genetic differences‚Äîto be around 40% for women and 30% for men, and evolutionary psychologists have proposed that the genetic basis for depression lies deep in the history of naturally selected adaptations. A substance-induced mood disorder resembling major depression has been causally linked to long-term drug use or drug abuse, or to withdrawal from certain sedative and hypnotic drugs.
Biological.
Monoamine hypothesis.
Most antidepressant medications increase the levels of one or more of the monoamines‚Äîthe neurotransmitters serotonin, norepinephrine and dopamine‚Äîin the synaptic cleft between neurons in the brain. Some medications affect the monoamine receptors directly.
Serotonin is hypothesized to regulate other neurotransmitter systems; decreased serotonin activity may allow these systems to act in unusual and erratic ways. According to this "permissive hypothesis", depression arises when low serotonin levels promote low levels of norepinephrine, another monoamine neurotransmitter. Some antidepressants enhance the levels of norepinephrine directly, whereas others raise the levels of dopamine, a third monoamine neurotransmitter. These observations gave rise to the monoamine hypothesis of depression. In its contemporary formulation, the monoamine hypothesis postulates that a deficiency of certain neurotransmitters is responsible for the corresponding features of depression: "Norepinephrine may be related to alertness and energy as well as anxiety, attention, and interest in life; of serotonin to anxiety, obsessions, and compulsions; and dopamine to attention, motivation, pleasure, and reward, as well as interest in life." The proponents of this theory recommend the choice of an antidepressant with mechanism of action that impacts the most prominent symptoms. Anxious and irritable patients should be treated with SSRIs or norepinephrine reuptake inhibitors, and those experiencing a loss of energy and enjoyment of life with norepinephrine- and dopamine-enhancing drugs.
Besides the clinical observations that drugs that increase the amount of available monoamines are effective antidepressants, advances in psychiatric genetics indicate that phenotypic variation in central monoamine function may be marginally associated with vulnerability to depression. Despite these findings, the cause of depression is not simply monoamine deficiency. In the past two decades, research has revealed multiple limitations of the monoamine hypothesis, and its explanatory inadequacy has been highlighted within the psychiatric community. A counterargument is that the mood-enhancing effect of MAO inhibitors and SSRIs takes weeks of treatment to develop, even though the boost in available monoamines occurs within hours. Another counterargument is based on experiments with pharmacological agents that cause depletion of monoamines; while deliberate reduction in the concentration of centrally available monoamines may slightly lower the mood of unmedicated depressed patients, this reduction does not affect the mood of healthy people. The monoamine hypothesis, already limited, has been further oversimplified when presented to the public as a mass marketing tool, usually phrased as a "chemical imbalance".
In 2003 a gene-environment interaction (GxE) was hypothesized to explain why life stress is a predictor for depressive episodes in some individuals, but not in others, depending on an allelic variation of the serotonin-transporter-linked promoter region (5-HTTLPR); a 2009 meta-analysis showed stressful life events were associated with depression, but found no evidence for an association with the 5-HTTLPR genotype. Another 2009 meta-analysis agreed with the latter finding. A 2010 review of studies in this area found a systematic relationship between the method used to assess environmental adversity and the results of the studies; this review also found that both 2009 meta-analyses were significantly biased toward negative studies, which used self-report measures of adversity.
Other hypotheses.
MRI scans of patients with depression have revealed a number of differences in brain structure compared to those who are not depressed. Meta-analyses of neuroimaging studies in major depression reported that, compared to controls, depressed patients had increased volume of the lateral ventricles and adrenal gland and smaller volumes of the basal ganglia, thalamus, hippocampus, and frontal lobe (including the orbitofrontal cortex and gyrus rectus). Hyperintensities have been associated with patients with a late age of onset, and have led to the development of the theory of vascular depression.
There may be a link between depression and neurogenesis of the hippocampus, a center for both mood and memory. Loss of hippocampal neurons is found in some depressed individuals and correlates with impaired memory and dysthymic mood. Drugs may increase serotonin levels in the brain, stimulating neurogenesis and thus increasing the total mass of the hippocampus. This increase may help to restore mood and memory. Similar relationships have been observed between depression and an area of the anterior cingulate cortex implicated in the modulation of emotional behavior. One of the neurotrophins responsible for neurogenesis is brain-derived neurotrophic factor (BDNF). The level of BDNF in the blood plasma of depressed subjects is drastically reduced (more than threefold) as compared to the norm. Antidepressant treatment increases the blood level of BDNF. Although decreased plasma BDNF levels have been found in many other disorders, there is some evidence that BDNF is involved in the cause of depression and the mechanism of action of antidepressants.
There is some evidence that major depression may be caused in part by an overactive hypothalamic-pituitary-adrenal axis (HPA axis) that results in an effect similar to the neuro-endocrine response to stress. Investigations reveal increased levels of the hormone cortisol and enlarged pituitary and adrenal glands, suggesting disturbances of the endocrine system may play a role in some psychiatric disorders, including major depression. Oversecretion of corticotropin-releasing hormone from the hypothalamus is thought to drive this, and is implicated in the cognitive and arousal symptoms.
The hormone estrogen has been implicated in depressive disorders due to the increase in risk of depressive episodes after puberty, the antenatal period, and reduced rates after menopause. On the converse, the premenstrual and postpartum periods of low estrogen levels are also associated with increased risk. Sudden withdrawal of, fluctuations in or periods of sustained low levels of estrogen have been linked to significant mood lowering. Clinical recovery from depression postpartum, perimenopause, and postmenopause was shown to be effective after levels of estrogen were stabilized or restored.
Other research has explored potential roles of molecules necessary for overall cellular functioning: cytokines. The symptoms of major depressive disorder are nearly identical to those of sickness behavior, the response of the body when the immune system is fighting an infection. This raises the possibility that depression can result from a maladaptive manifestation of sickness behavior as a result of abnormalities in circulating cytokines. The involvement of pro-inflammatory cytokines in depression is strongly suggested by a meta-analysis of the clinical literature showing higher blood concentrations of IL-6 and TNF-Œ± in depressed subjects compared to controls. These immunological abnormalities may cause excessive prostaglandin E‚ÇÇ production and likely excessive COX-2 expression. Abnormalities in how indoleamine 2,3-dioxygenase enzyme activates as well as the metabolism of tryptophan-kynurenine may lead to excessive metabolism of tryptophan-kynurenine and lead to increased production of the neurotoxin quinolinic acid, contributing to major depression. NMDA activation leading to excessive glutamatergic neurotransmission, may also contribute. A number of factors that increase inflammation have been linked to depression including a poor diet, smoking, and obesity.
Psychological.
Various aspects of personality and its development appear to be integral to the occurrence and persistence of depression, with negative emotionality as a common precursor. Although depressive episodes are strongly correlated with adverse events, a person's characteristic style of coping may be correlated with his or her resilience. In addition, low self-esteem and self-defeating or distorted thinking are related to depression. Depression is less likely to occur, as well as quicker to remit, among those who are religious. It is not always clear which factors are causes and which are effects of depression; however, depressed persons that are able to reflect upon and challenge their thinking patterns often show improved mood and self-esteem.
American psychiatrist Aaron T. Beck, following on from the earlier work of George Kelly and Albert Ellis, developed what is now known as a cognitive model of depression in the early 1960s. He proposed that three concepts underlie depression: a triad of negative thoughts composed of cognitive errors about oneself, one's world, and one's future; recurrent patterns of depressive thinking, or "schemas"; and distorted information processing. From these principles, he developed the structured technique of cognitive behavioral therapy (CBT). Further support for the concept of distorted information processing in individuals with depression has been provided from several areas of research. These include attention and reward and punishment processing. According to American psychologist Martin Seligman, depression in humans is similar to learned helplessness in laboratory animals, who remain in unpleasant situations when they are able to escape, but do not because they initially learned they had no control.
Attachment theory, which was developed by English psychiatrist John Bowlby in the 1960s, predicts a relationship between depressive disorder in adulthood and the quality of the earlier bond between the infant and the adult caregiver. In particular, it is thought that "the experiences of early loss, separation and rejection by the parent or caregiver (conveying the message that the child is unlovable) may all lead to insecure internal working models ... Internal cognitive representations of the self as unlovable and of attachment figures as unloving untrustworthy would be consistent with parts of Beck's cognitive triad". While a wide variety of studies has upheld the basic tenets of attachment theory, research has been inconclusive as to whether self-reported early attachment and later depression are demonstrably related.
Depressed individuals often blame themselves for negative events, and, as shown in a 1993 study of hospitalized adolescents with self-reported depression, those who blame themselves for negative occurrences may not take credit for positive outcomes. This tendency is characteristic of a depressive attributional, or pessimistic explanatory style. According to Albert Bandura, a Canadian social psychologist associated with social cognitive theory, depressed individuals have negative beliefs about themselves, based on experiences of failure, observing the failure of social models, a lack of social persuasion that they can succeed, and their own somatic and emotional states including tension and stress. These influences may result in a negative self-concept and a lack of self-efficacy; that is, they do not believe they can influence events or achieve personal goals.
An examination of depression in women indicates that vulnerability factors‚Äîsuch as early maternal loss, lack of a confiding relationship, responsibility for the care of several young children at home, and unemployment‚Äîcan interact with life stressors to increase the risk of depression. For older adults, the factors are often health problems, changes in relationships with a spouse or adult children due to the transition to a care-giving or care-needing role, the death of a significant other, or a change in the availability or quality of social relationships with older friends because of their own health-related life changes.
The understanding of depression has also received contributions from the psychoanalytic and humanistic branches of psychology. From the classical psychoanalytic perspective of Austrian psychiatrist Sigmund Freud, depression, or "melancholia", may be related to interpersonal loss and early life experiences. Existential therapists have connected depression to the lack of both meaning in the present and a vision of the future.
Social.
Poverty and social isolation are associated with increased risk of mental health problems in general. Child abuse (physical, emotional, sexual, or neglect) is also associated with increased risk of developing depressive disorders later in life. Such a link has good face validity given that it is during the years of development that a child is learning how to become a social being. Abuse of the child by the caregiver is bound to distort the developing personality and create a much greater risk for depression and many other debilitating mental and emotional states. Disturbances in family functioning, such as parental (particularly maternal) depression, severe marital conflict or divorce, death of a parent, or other disturbances in parenting are additional risk factors. In adulthood, stressful life events are strongly associated with the onset of major depressive episodes. In this context, life events connected to social rejection appear to be particularly related to depression. Evidence that a first episode of depression is more likely to be immediately preceded by stressful life events than are recurrent ones is consistent with the hypothesis that people may become increasingly sensitized to life stress over successive recurrences of depression.
The relationship between stressful life events and social support has been a matter of some debate; the lack of social support may increase the likelihood that life stress will lead to depression, or the absence of social support may constitute a form of strain that leads to depression directly. There is evidence that neighborhood social disorder, for example, due to crime or illicit drugs, is a risk factor, and that a high neighborhood socioeconomic status, with better amenities, is a protective factor. Adverse conditions at work, particularly demanding jobs with little scope for decision-making, are associated with depression, although diversity and confounding factors make it difficult to confirm that the relationship is causal.
Depression can be caused by prejudice. This can occur when people hold negative self-stereotypes about themselves. This "deprejudice" can be related to a group membership (e.g., Me-Gay-Bad) or not (Me-Bad). If someone has prejudicial beliefs about a stigmatized group and then becomes a member of that group, they may internalize their prejudice and develop depression. For example, a boy growing up in the United States may learn the negative stereotype that gay men are immoral. When he grows up and realizes he is gay, he may direct this prejudice inward on himself and become depressed. People may also show prejudice internalization through self-stereotyping because of negative childhood experiences such as verbal and physical abuse.
Evolutionary.
From the standpoint of evolutionary theory, major depression is hypothesized, in some instances, to increase an individual's reproductive fitness. Evolutionary approaches to depression and evolutionary psychology posit specific mechanisms by which depression may have been genetically incorporated into the human gene pool, accounting for the high heritability and prevalence of depression by proposing that certain components of depression are adaptations, such as the behaviors relating to attachment and social rank. Current behaviors can be explained as adaptations to regulate relationships or resources, although the result may be maladaptive in modern environments.
From another viewpoint, a counseling therapist may see depression not as a biochemical illness or disorder but as "a species-wide evolved suite of emotional programs that are mostly activated by a perception, almost always over-negative, of a major decline in personal usefulness, that can sometimes be linked to guilt, shame or perceived rejection". This suite may have manifested in aging hunters in humans' foraging past, who were marginalized by their declining skills, and may continue to appear in alienated members of today's society. The feelings of uselessness generated by such marginalization could in theory prompt support from friends and kin. In addition, in a manner analogous to that in which physical pain has evolved to hinder actions that may cause further injury, "psychic misery" may have evolved to prevent hasty and maladaptive reactions to distressing situations.
Drug and alcohol use.
Very high levels of substance abuse occur in the psychiatric population, especially alcohol, sedatives and cannabis. Depression and other mental health problems can have a substance induced cause; making a differential or dual diagnosis regarding whether mental ill-health is substance related or not or co-occurring is an important part of a psychiatric evaluation. According to the DSM-IV, a diagnosis of mood disorder cannot be made if the cause is believed to be due to "the direct physiological effects of a substance"; when a syndrome resembling major depression is believed to be caused immediately by substance abuse or by an adverse drug reaction, it is referred to as, "substance-induced mood disturbance". Alcoholism or excessive alcohol consumption significantly increases the risk of developing major depression. Like alcohol, the benzodiazepines are central nervous system depressants; this class of medication is commonly used to treat insomnia, anxiety, and muscular spasms. Similar to alcohol, benzodiazepines increase the risk of developing major depression. This increased risk of depression may be due in part to the adverse or toxic effects of sedative-hypnotic drugs including alcohol on neurochemistry, such as decreased levels of serotonin and norepinephrine, or activation of immune mediated inflammatory pathways in the brain. Chronic use of benzodiazepines also can cause or worsen depression, or depression may be part of a protracted withdrawal syndrome. About a quarter of people recovering from alcoholism experience anxiety and depression, which can persist for up to 2 years. Methamphetamine abuse is also commonly associated with depression.
Diagnosis.
Clinical assessment.
A diagnostic assessment may be conducted by a suitably trained general practitioner, or by a psychiatrist or psychologist, who records the person's current circumstances, biographical history, current symptoms, and family history. The broad clinical aim is to formulate the relevant biological, psychological, and social factors that may be impacting on the individual's mood. The assessor may also discuss the person's current ways of regulating mood (healthy or otherwise) such as alcohol and drug use. The assessment also includes a mental state examination, which is an assessment of the person's current mood and thought content, in particular the presence of themes of hopelessness or pessimism, self-harm or suicide, and an absence of positive thoughts or plans. Specialist mental health services are rare in rural areas, and thus diagnosis and management is left largely to primary-care clinicians. This issue is even more marked in developing countries. The mental health examination may include the use of a rating scale such as the Hamilton Rating Scale for Depression or the Beck Depression Inventory or the Suicide Behaviors Questionnaire-Revised. The score on a rating scale alone is insufficient to diagnose depression to the satisfaction of the DSM or ICD, but it provides an indication of the severity of symptoms for a time period, so a person who scores above a given cut-off point can be more thoroughly evaluated for a depressive disorder diagnosis. Several rating scales are used for this purpose. Screening programs have been advocated to improve detection of depression, but there is evidence that they do not improve detection rates, treatment, or outcome. The United States Preventive Services Task Force (USPSTF) recommends screening in adult populations, though is unable to specify interval time between screening.
Primary-care physicians and other non-psychiatrist physicians have difficulty diagnosing depression, in part because they are trained to recognize and treat physical symptoms, and depression can cause myriad physical (psychosomatic) symptoms. Non-psychiatrists miss two-thirds of cases and unnecessarily treat other patients.
Before diagnosing a major depressive disorder, in general a doctor performs a medical examination and selected investigations to rule out other causes of symptoms. These include blood tests measuring TSH and thyroxine to exclude hypothyroidism; basic electrolytes and serum calcium to rule out a metabolic disturbance; and a full blood count including ESR to rule out a systemic infection or chronic disease. Adverse affective reactions to medications or alcohol misuse are often ruled out, as well. Testosterone levels may be evaluated to diagnose hypogonadism, a cause of depression in men.
Subjective cognitive complaints appear in older depressed people, but they can also be indicative of the onset of a dementing disorder, such as Alzheimer's disease. Cognitive testing and brain imaging can help distinguish depression from dementia. A CT scan can exclude brain pathology in those with psychotic, rapid-onset or otherwise unusual symptoms. In general, investigations are not repeated for a subsequent episode unless there is a medical indication.
No biological tests confirm major depression. Biomarkers of depression have been sought to provide an objective method of diagnosis. There are several potential biomarkers, including Brain-Derived Neurotrophic Factor and various functional MRI techniques. One study developed a decision tree model of interpreting a series of fMRI scans taken during various activities. In their subjects, the authors of that study were able to achieve a sensitivity of 80% and a specificity of 87%, corresponding to a negative predictive value of 98% and a positive predictive value of 32% (positive and negative likelihood ratios were 6.15, 0.23, respectively). However, much more research is needed before these tests could be used clinically.
DSM-IV-TR and ICD-10 criteria.
The most widely used criteria for diagnosing depressive conditions are found in the American Psychiatric Association's revised fourth edition of the "Diagnostic and Statistical Manual of Mental Disorders" (DSM-IV-TR), and the World Health Organization's "International Statistical Classification of Diseases and Related Health Problems" (ICD-10), which uses the name "depressive episode" for a single episode and "recurrent depressive disorder" for repeated episodes. The latter system is typically used in European countries, while the former is used in the US and many other non-European nations, and the authors of both have worked towards conforming one with the other.
Both DSM-IV-TR and ICD-10 mark out typical (main) depressive symptoms. ICD-10 defines three typical depressive symptoms (depressed mood, anhedonia, and reduced energy), two of which should be present to determine depressive disorder diagnosis. According to DSM-IV-TR, there are two main depressive symptoms‚Äîdepressed mood and anhedonia. At least one of these must be present to make a diagnosis of major depressive episode.
Major depressive disorder is classified as a mood disorder in DSM-IV-TR. The diagnosis hinges on the presence of single or recurrent major depressive episodes. Further qualifiers are used to classify both the episode itself and the course of the disorder. The category Depressive Disorder Not Otherwise Specified is diagnosed if the depressive episode's manifestation does not meet the criteria for a major depressive episode. The ICD-10 system does not use the term "major depressive disorder" but lists very similar criteria for the diagnosis of a depressive episode (mild, moderate or severe); the term "recurrent" may be added if there have been multiple episodes without mania.
Major depressive episode.
A major depressive episode is characterized by the presence of a severely depressed mood that persists for at least two weeks. Episodes may be isolated or recurrent and are categorized as mild (few symptoms in excess of minimum criteria), moderate, or severe (marked impact on social or occupational functioning). An episode with psychotic features‚Äîcommonly referred to as "psychotic depression"‚Äîis automatically rated as severe. If the patient has had an episode of mania or markedly elevated mood, a diagnosis of bipolar disorder is made instead. Depression without mania is sometimes referred to as "unipolar" because the mood remains at one emotional state or "pole".
DSM-IV-TR excludes cases where the symptoms are a result of bereavement, although it is possible for normal bereavement to evolve into a depressive episode if the mood persists and the characteristic features of a major depressive episode develop. The criteria have been criticized because they do not take into account any other aspects of the personal and social context in which depression can occur. In addition, some studies have found little empirical support for the DSM-IV cut-off criteria, indicating they are a diagnostic convention imposed on a continuum of depressive symptoms of varying severity and duration: Excluded are a range of related diagnoses, including dysthymia, which involves a chronic but milder mood disturbance; recurrent brief depression, consisting of briefer depressive episodes; minor depressive disorder, whereby only some symptoms of major depression are present; and adjustment disorder with depressed mood, which denotes low mood resulting from a psychological response to an identifiable event or stressor.
Subtypes.
The DSM-IV-TR recognizes five further subtypes of MDD, called "specifiers", in addition to noting the length, severity and presence of psychotic features:
Differential diagnoses.
To confer major depressive disorder as the most likely diagnosis, other potential diagnoses must be considered, including dysthymia, adjustment disorder with depressed mood, or bipolar disorder. Dysthymia is a chronic, milder mood disturbance in which a person reports a low mood almost daily over a span of at least two years. The symptoms are not as severe as those for major depression, although people with dysthymia are vulnerable to secondary episodes of major depression (sometimes referred to as "double depression"). Adjustment disorder with depressed mood is a mood disturbance appearing as a psychological response to an identifiable event or stressor, in which the resulting emotional or behavioral symptoms are significant but do not meet the criteria for a major depressive episode. Bipolar disorder, also known as "manic‚Äìdepressive disorder", is a condition in which depressive phases alternate with periods of mania or hypomania. Although depression is currently categorized as a separate disorder, there is ongoing debate because individuals diagnosed with major depression often experience some hypomanic symptoms, indicating a mood disorder continuum.
Other disorders need to be ruled out before diagnosing major depressive disorder. They include depressions due to physical illness, medications, and substance abuse. Depression due to physical illness is diagnosed as a mood disorder due to a general medical condition. This condition is determined based on history, laboratory findings, or physical examination. When the depression is caused by a substance abused including a drug of abuse, a medication, or exposure to a toxin, it is then diagnosed as a substance-induced mood disorder.
Prevention.
Preventative efforts may result in decreases in rates of the condition of between 22 and 38%. Eating large amounts of fish may also reduce the risk.
Behavioral interventions, such as interpersonal therapy and cognitive-behavioral therapy, are effective at preventing new onset depression. Because such interventions appear to be most effective when delivered to individuals or small groups, it has been suggested that they may be able to reach their large target audience most efficiently through the Internet.
However, an earlier meta-analysis found preventive programs with a competence-enhancing component to be superior to behavior-oriented programs overall, and found behavioral programs to be particularly unhelpful for older people, for whom social support programs were uniquely beneficial. In addition, the programs that best prevented depression comprised more than eight sessions, each lasting between 60 and 90 minutes, were provided by a combination of lay and professional workers, had a high-quality research design, reported attrition rates, and had a well-defined intervention.
The Netherlands mental health care system provides preventive interventions, such as the "Coping with Depression" course (CWD) for people with sub-threshold depression. The course is claimed to be the most successful of psychoeducational interventions for the treatment and prevention of depression (both for its adaptability to various populations and its results), with a risk reduction of 38% in major depression and an efficacy as a treatment comparing favorably to other psychotherapies.
Management.
The three most common treatments for depression are psychotherapy, medication, and electroconvulsive therapy. Psychotherapy is the treatment of choice (over medication) for people under 18. The UK National Institute for Health and Care Excellence (NICE) 2004 guidelines indicate that antidepressants should not be used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressants treatment in combination with psychosocial interventions should be considered for:
The guidelines further note that antidepressant treatment should be continued for at least six months to reduce the risk of relapse, and that SSRIs are better tolerated than tricyclic antidepressants.
American Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors including severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned.
Treatment options are much more limited in developing countries, where access to mental health staff, medication, and psychotherapy is often difficult. Development of mental health services is minimal in many countries; depression is viewed as a phenomenon of the developed world despite evidence to the contrary, and not as an inherently life-threatening condition. A 2014 Cochrane review found insufficient evidence to determine the effectiveness of psychological versus medical therapy in children.
Psychotherapy.
Psychotherapy can be delivered, to individuals, groups, or families by mental health professionals. A 2015 review found that cognitive behavioral therapy appears to be similar to antidepressant medication in terms of effect. A 2012 review found psychotherapy to be better than no treatment but not other treatments. With more complex and chronic forms of depression, a combination of medication and psychotherapy may be used. A 2014 Cochrane review found that work-directed interventions combined with clinical interventions helped to reduce sick days taken by people with depression.
Psychotherapy has been shown to be effective in older people. Successful psychotherapy appears to reduce the recurrence of depression even after it has been terminated or replaced by occasional booster sessions.
Cognitive behavioral therapy.
Cognitive behavioral therapy (CBT) currently has the most research evidence for the treatment of depression in children and adolescents, and CBT and interpersonal psychotherapy (IPT) are preferred therapies for adolescent depression. In people under 18, according to the National Institute for Health and Clinical Excellence, medication should be offered only in conjunction with a psychological therapy, such as CBT, interpersonal therapy, or family therapy. Cognitive behavioral therapy has also been shown to reduce the number of sick days taken by people with depression, when used in conjunction with primary care.
The most-studied form of psychotherapy for depression is CBT, which teaches clients to challenge self-defeating, but enduring ways of thinking (cognitions) and change counter-productive behaviors. Research beginning in the mid-1990s suggested that CBT could perform as well or as better than antidepressants in patients with moderate to severe depression. CBT may be effective in depressed adolescents, although its effects on severe episodes are not definitively known. Several variables predict success for cognitive behavioral therapy in adolescents: higher levels of rational thoughts, less hopelessness, fewer negative thoughts, and fewer cognitive distortions. CBT is particularly beneficial in preventing relapse.
Variants.
Several variants of cognitive behavior therapy have been used in those with depression, the most notable being rational emotive behavior therapy, and mindfulness-based cognitive therapy. Mindfulness based stress reduction programs may reduce depression symptoms. Mindfulness programs also appear to be a promising intervention in youth.
Psychoanalysis.
Psychoanalysis is a school of thought, founded by Sigmund Freud, which emphasizes the resolution of unconscious mental conflicts. Psychoanalytic techniques are used by some practitioners to treat clients presenting with major depression. A more widely practiced, eclectic technique, called psychodynamic psychotherapy, is loosely based on psychoanalysis and has an additional social and interpersonal focus. In a meta-analysis of three controlled trials of Short Psychodynamic Supportive Psychotherapy, this modification was found to be as effective as medication for mild to moderate depression.
Antidepressants.
Conflicting results have arisen from studies that look at the effectiveness of antidepressants in people with acute, mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.
While small benefits were found, researchers Irving Kirsch and Thomas Moore state they may be due to issues with the trials rather than a true effect of the medication. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance. Similar results were obtained in a meta analysis by Fornier.
A review commissioned by the National Institute for Health and Care Excellence concluded that there is strong evidence that SSRIs have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. Similarly, a Cochrane systematic review of clinical trials of the generic antidepressant amitriptyline concluded that there is strong evidence that its efficacy is superior to placebo.
In 2014 the U.S. FDA published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.
To find the most effective antidepressant medication with minimal side-effects, the dosages can be adjusted, and if necessary, combinations of different classes of antidepressants can be tried. Response rates to the first antidepressant administered range from 50‚Äì75%, and it can take at least six to eight weeks from the start of medication to remission. Antidepressant medication treatment is usually continued for 16 to 20 weeks after remission, to minimize the chance of recurrence, and even up to one year of continuation is recommended. People with chronic depression may need to take medication indefinitely to avoid relapse.
Selective serotonin reuptake inhibitors (SSRIs) are the primary medications prescribed, owing to their relatively mild side-effects, and because they are less toxic in overdose than other antidepressants. Patients who do not respond to one SSRI can be switched to another antidepressant, and this results in improvement in almost 50% of cases. Another option is to switch to the atypical antidepressant bupropion. Venlafaxine, an antidepressant with a different mechanism of action, may be modestly more effective than SSRIs. However, venlafaxine is not recommended in the UK as a first-line treatment because of evidence suggesting its risks may outweigh benefits, and it is specifically discouraged in children and adolescents.
For adolescent depression, fluoxetine is recommended Antidepressants appear to have only slight benefit in children. There is also insufficient evidence to determine effectiveness in those with depression complicated by dementia. Any antidepressant can cause low serum sodium levels (also called hyponatremia); nevertheless, it has been reported more often with SSRIs. It is not uncommon for SSRIs to cause or worsen insomnia; the sedating antidepressant mirtazapine can be used in such cases.
Irreversible monoamine oxidase inhibitors, an older class of antidepressants, have been plagued by potentially life-threatening dietary and drug interactions. They are still used only rarely, although newer and better-tolerated agents of this class have been developed. The safety profile is different with reversible monoamine oxidase inhibitors such as moclobemide where the risk of serious dietary interactions is negligible and dietary restrictions are less strict.
For children, adolescents, and probably young adults between 18 and 24 years old, there is a higher risk of both suicidal ideations and suicidal behavior in those treated with SSRIs. For adults, it is unclear whether SSRIs affect the risk of suicidality. One review found no connection; another an increased risk; and a third no risk in those 25‚Äì65 years old and a decrease risk in those more than 65. A black box warning was introduced in the United States in 2007 on SSRI and other antidepressant medications due to increased risk of suicide in patients younger than 24 years old. Similar precautionary notice revisions were implemented by the Japanese Ministry of Health.
Other medications.
There is some evidence that fish oil supplements containing high levels of eicosapentaenoic acid (EPA) to docosahexaenoic acid (DHA) may be effective in major depression, but other meta-analysis of the research conclude that positive effects may be due to publication bias. There is some preliminary evidence that COX-2 inhibitors have a beneficial effect on major depression. Lithium appears effective at lowering the risk of suicide in those with bipolar disorder and unipolar depression to nearly the same levels as the general population. There is a narrow range of effective and safe dosages of lithium thus close monitoring may be needed. Low-dose thyroid hormone may be added to existing antidepressants to treat persistent depression symptoms in people who have tried multiple courses of medication.
Electroconvulsive therapy.
Electroconvulsive therapy (ECT) is a standard psychiatric treatment in which seizures are electrically induced in patients to provide relief from psychiatric illnesses. ECT is used with informed consent as a last line of intervention for major depressive disorder.
A round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Follow-up treatment is still poorly studied, but about half of people who respond, relapse with twelve months.
Aside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia. Immediately following treatment, the most common adverse effects are confusion and memory loss. ECT is considered one of the least harmful treatment options available for severely depressed pregnant women.
A usual course of ECT involves multiple administrations, typically given two or three times per week until the patient is no longer suffering symptoms ECT is administered under anesthetic with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT.
ECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.
Repetitive transcranial magnetic stimulation.
Transcranial magnetic stimulation (TMS) or deep transcranial magnetic stimulation is a noninvasive method used to stimulate small regions of the brain. TMS was approved by the FDA for treatment-resistant major depressive disorder in 2008 and as of 2014 evidence supports this use. The American Psychiatric Association the Canadian Network for Mood and Anxiety Disorders, and the Royal Australia and New Zealand College of Psychiatrists have endorsed rTMS for trMDD.
Other.
Bright light therapy reduces depression symptom severity, with benefit was found for both seasonal affective disorder and for nonseasonal depression, and an effect similar to those for conventional antidepressants. For non-seasonal depression, adding light therapy to the standard antidepressant treatment was not effective. For non-seasonal depression where light was used mostly in combination with antidepressants or wake therapy a moderate effect was found, with response better than control treatment in high-quality studies, in studies that applied morning light treatment, and with people who respond to total or partial sleep deprivation. Both analyses noted poor quality, short duration, and small size of most of the reviewed studies.
There is a small amount of evidence that skipping a night's sleep may help. Physical exercise is recommended for management of mild depression, and has a moderate effect on symptoms. It is equivalent to the use of medications or psychological therapies in most people. In the older people it does appear to decrease depression. In unblinded, non-randomized observational studies smoking cessation has benefits in depression as large as or larger than those of medications. Cognitive behavioral therapy and occupational programs (including modification of work activities and assistance) have been shown to be effective in reducing sick days taken by workers with depression.
Prognosis.
Major depressive episodes often resolve over time whether or not they are treated. Outpatients on a waiting list show a 10‚Äì15% reduction in symptoms within a few months, with approximately 20% no longer meeting the full criteria for a depressive disorder. The median duration of an episode has been estimated to be 23 weeks, with the highest rate of recovery in the first three months.
Studies have shown that 80% of those suffering from their first major depressive episode will suffer from at least 1 more during their life, with a lifetime average of 4 episodes. Other general population studies indicate that around half those who have an episode recover (whether treated or not) and remain well, while the other half will have at least one more, and around 15% of those experience chronic recurrence. Studies recruiting from selective inpatient sources suggest lower recovery and higher chronicity, while studies of mostly outpatients show that nearly all recover, with a median episode duration of 11 months. Around 90% of those with severe or psychotic depression, most of whom also meet criteria for other mental disorders, experience recurrence.
Recurrence is more likely if symptoms have not fully resolved with treatment. Current guidelines recommend continuing antidepressants for four to six¬†months after remission to prevent relapse. Evidence from many randomized controlled trials indicates continuing antidepressant medications after recovery can reduce the chance of relapse by 70% (41% on placebo vs. 18% on antidepressant). The preventive effect probably lasts for at least the first 36¬†months of use.
Those people experiencing repeated episodes of depression require ongoing treatment in order to prevent more severe, long-term depression. In some cases, people must take medications for long periods of time or for the rest of their lives.
Cases when outcome is poor are associated with inappropriate treatment, severe initial symptoms that may include psychosis, early age of onset, more previous episodes, incomplete recovery after 1 year, pre-existing severe mental or medical disorder, and family dysfunction as well.
Depressed individuals have a shorter life expectancy than those without depression, in part because depressed patients are at risk of dying by suicide. However, they also have a higher rate of dying from other causes, being more susceptible to medical conditions such as heart disease. Up to 60% of people who die by suicide have a mood disorder such as major depression, and the risk is especially high if a person has a marked sense of hopelessness or has both depression and borderline personality disorder. The lifetime risk of suicide associated with a diagnosis of major depression in the US is estimated at 3.4%, which averages two highly disparate figures of almost 7% for men and 1% for women (although suicide attempts are more frequent in women). The estimate is substantially lower than a previously accepted figure of 15%, which had been derived from older studies of hospitalized patients.
Depression is often associated with unemployment and poverty. Major depression is currently the leading cause of disease burden in North America and other high-income countries, and the fourth-leading cause worldwide. In the year 2030, it is predicted to be the second-leading cause of disease burden worldwide after HIV, according to the World Health Organization. Delay or failure in seeking treatment after relapse, and the failure of health professionals to provide treatment, are two barriers to reducing disability.
Epidemiology.
[[File:Unipolar depressive disorders world map - DALY - WHO2004.svg|thumb|250px|Disability-adjusted life year for unipolar depressive disorders per 100,000 inhabitants in 2004.
Depression is a major cause of morbidity worldwide. It is believed to currently affect approximately 298¬†million people as of 2010 (4.3% of the global population). Lifetime prevalence varies widely, from 3% in Japan to 17% in the United States. In most countries the number of people who have depression during their lives falls within an 8‚Äì12% range. In North America, the probability of having a major depressive episode within a year-long period is 3‚Äì5% for males and 8‚Äì10% for females. Population studies have consistently shown major depression to be about twice as common in women as in men, although it is unclear why this is so, and whether factors unaccounted for are contributing to this. The relative increase in occurrence is related to pubertal development rather than chronological age, reaches adult ratios between the ages of 15 and 18, and appears associated with psychosocial more than hormonal factors.
People are most likely to suffer their first depressive episode between the ages of 30 and 40, and there is a second, smaller peak of incidence between ages 50 and 60. The risk of major depression is increased with neurological conditions such as stroke, Parkinson's disease, or multiple sclerosis, and during the first year after childbirth. It is also more common after cardiovascular illnesses, and is related more to a poor outcome than to a better one. Studies conflict on the prevalence of depression in the elderly, but most data suggest there is a reduction in this age group. Depressive disorders are more common to observe in urban than in rural population and the prevalence is in groups with stronger socioeconomic factors i.e. homelessness.
History.
The Ancient Greek physician Hippocrates described a syndrome of melancholia as a distinct disease with particular mental and physical symptoms; he characterized all "fears and despondencies, if they last a long time" as being symptomatic of the ailment. It was a similar but far broader concept than today's depression; prominence was given to a clustering of the symptoms of sadness, dejection, and despondency, and often fear, anger, delusions and obsessions were included.
The term "depression" itself was derived from the Latin verb "deprimere", "to press down". From the 14th¬†century, "to depress" meant to subjugate or to bring down in spirits. It was used in 1665 in English author Richard Baker's "Chronicle" to refer to someone having "a great depression of spirit", and by English author Samuel Johnson in a similar sense in 1753. The term also came into use in physiology and economics. An early usage referring to a psychiatric symptom was by French psychiatrist Louis Delasiauve in 1856, and by the 1860s it was appearing in medical dictionaries to refer to a physiological and metaphorical lowering of emotional function. Since Aristotle, melancholia had been associated with men of learning and intellectual brilliance, a hazard of contemplation and creativity. The newer concept abandoned these associations and through the 19th¬†century, became more associated with women.
Although "melancholia" remained the dominant diagnostic term, "depression" gained increasing currency in medical treatises and was a synonym by the end of the century; German psychiatrist Emil Kraepelin may have been the first to use it as the overarching term, referring to different kinds of melancholia as "depressive states".
Sigmund Freud likened the state of melancholia to mourning in his 1917 paper "Mourning and Melancholia". He theorized that objective loss, such as the loss of a valued relationship through death or a romantic break-up, results in subjective loss as well; the depressed individual has identified with the object of affection through an unconscious, narcissistic process called the "libidinal cathexis" of the ego. Such loss results in severe melancholic symptoms more profound than mourning; not only is the outside world viewed negatively but the ego itself is compromised. The patient's decline of self-perception is revealed in his belief of his own blame, inferiority, and unworthiness. He also emphasized early life experiences as a predisposing factor. Adolf Meyer put forward a mixed social and biological framework emphasizing "reactions" in the context of an individual's life, and argued that the term "depression" should be used instead of "melancholia". The first version of the DSM (DSM-I, 1952) contained "depressive reaction" and the DSM-II (1968) "depressive neurosis", defined as an excessive reaction to internal conflict or an identifiable event, and also included a depressive type of manic-depressive psychosis within Major affective disorders.
In the mid-20th century, researchers theorized that depression was caused by a chemical imbalance in neurotransmitters in the brain, a theory based on observations made in the 1950s of the effects of reserpine and isoniazid in altering monoamine neurotransmitter levels and affecting depressive symptoms.
The term "unipolar" (along with the related term "bipolar") was coined by the neurologist and psychiatrist Karl Kleist, and subsequently used by his disciples Edda Neele and Karl Leonhard.
The term "Major depressive disorder" was introduced by a group of US clinicians in the mid-1970s as part of proposals for diagnostic criteria based on patterns of symptoms (called the "Research Diagnostic Criteria", building on earlier Feighner Criteria), and was incorporated into the DSM-III in 1980. To maintain consistency the ICD-10 used the same criteria, with only minor alterations, but using the DSM diagnostic threshold to mark a "mild depressive episode", adding higher threshold categories for moderate and severe episodes. The ancient idea of "melancholia" still survives in the notion of a melancholic subtype.
The new definitions of depression were widely accepted, albeit with some conflicting findings and views. There have been some continued empirically based arguments for a return to the diagnosis of melancholia. There has been some criticism of the expansion of coverage of the diagnosis, related to the development and promotion of antidepressants and the biological model since the late 1950s.
Society and culture.
People's conceptualizations of depression vary widely, both within and among cultures. "Because of the lack of scientific certainty," one commentator has observed, "the debate over depression turns on questions of language. What we call it‚Äî'disease,' 'disorder,' 'state of mind'‚Äîaffects how we view, diagnose, and treat it." There are cultural differences in the extent to which serious depression is considered an illness requiring personal professional treatment, or is an indicator of something else, such as the need to address social or moral problems, the result of biological imbalances, or a reflection of individual differences in the understanding of distress that may reinforce feelings of powerlessness, and emotional struggle.
The diagnosis is less common in some countries, such as China. It has been argued that the Chinese traditionally deny or somatize emotional depression (although since the early 1980s, the Chinese denial of depression may have modified drastically). Alternatively, it may be that Western cultures reframe and elevate some expressions of human distress to disorder status. Australian professor Gordon Parker and others have argued that the Western concept of depression "medicalizes" sadness or misery. Similarly, Hungarian-American psychiatrist Thomas Szasz and others argue that depression is a metaphorical illness that is inappropriately regarded as an actual disease. There has also been concern that the DSM, as well as the field of descriptive psychiatry that employs it, tends to reify abstract phenomena such as depression, which may in fact be social constructs. American archetypal psychologist James Hillman writes that depression can be healthy for the soul, insofar as "it brings refuge, limitation, focus, gravity, weight, and humble powerlessness." Hillman argues that therapeutic attempts to eliminate depression echo the Christian theme of resurrection, but have the unfortunate effect of demonizing a soulful state of being.
Historical figures were often reluctant to discuss or seek treatment for depression due to social stigma about the condition, or due to ignorance of diagnosis or treatments. Nevertheless, analysis or interpretation of letters, journals, artwork, writings, or statements of family and friends of some historical personalities has led to the presumption that they may have had some form of depression. People who may have had depression include English author Mary Shelley, American-British writer Henry James, and American president Abraham Lincoln. Some well-known contemporary people with possible depression include Canadian songwriter Leonard Cohen and American playwright and novelist Tennessee Williams. Some pioneering psychologists, such as Americans William James and John B. Watson, dealt with their own depression.
There has been a continuing discussion of whether neurological disorders and mood disorders may be linked to creativity, a discussion that goes back to Aristotelian times. British literature gives many examples of reflections on depression. English philosopher John Stuart Mill experienced a several-months-long period of what he called "a dull state of nerves", when one is "unsusceptible to enjoyment or pleasurable excitement; one of those moods when what is pleasure at other times, becomes insipid or indifferent". He quoted English poet Samuel Taylor Coleridge's "Dejection" as a perfect description of his case: "A grief without a pang, void, dark and drear, / A drowsy, stifled, unimpassioned grief, / Which finds no natural outlet or relief / In word, or sigh, or tear." English writer Samuel Johnson used the term "the black dog" in the 1780s to describe his own depression, and it was subsequently popularized by depression sufferer former British Prime Minister Sir Winston Churchill.
Social stigma of major depression is widespread, and contact with mental health services reduces this only slightly. Public opinions on treatment differ markedly to those of health professionals; alternative treatments are held to be more helpful than pharmacological ones, which are viewed poorly. In the UK, the Royal College of Psychiatrists and the Royal College of General Practitioners conducted a joint Five-year Defeat Depression campaign to educate and reduce stigma from 1992 to 1996; a MORI study conducted afterwards showed a small positive change in public attitudes to depression and treatment.
Research.
Trials are looking at the effects of botulinum toxins on depression. The idea is that the drug is used to make the person look less frowning and that this stops the negative facial feedback from the face. In 2015 it turned out, however, that the partly positive effects that had been observed until then could have been placebo effects.

</doc>
<doc id="8391" url="https://en.wikipedia.org/wiki?curid=8391" title="Diana (mythology)">
Diana (mythology)

In Roman mythology, Diana () was the goddess of the hunt, the moon and childbirth, being associated with wild animals and woodland, and having the power to talk to and control animals. She was eventually equated with the Greek goddess Artemis, though she had an independent origin in Italy. Diana was worshipped in ancient Roman religion and is revered in Roman Neopaganism and Stregheria. Diana was known to be the virgin goddess of childbirth and women. She was one of the three maiden goddesses ‚Äî along with Minerva and Vesta ‚Äî who swore never to marry.
Oak groves were especially sacred to her. According to mythology (in common with the Greek religion and their deity Artemis), Diana was born with her twin brother Apollo on the island of Delos, daughter of Jupiter and Latona. Diana made up a triad with two other Roman deities: Egeria the water nymph, her servant and assistant midwife; and Virbius, the woodland god.
Etymology.
Diana (pronounced with long 'ƒ´' and 'ƒÅ') is an adjectival form developed from an ancient *"divios", corresponding to later 'divus', 'dius', as in Dius Fidius, Dea Dia and in the neuter form "dium" meaning the sky.
It is rooted in Indoeuropean *d(e)y(e)w, meaning bright sky or daylight, from which also derived the name of Vedic god Dyaus and the Latin deus, (god), "dies", (day, daylight), and " diurnal", (daytime).
On the Tablets of Pylos a theonym Œ¥ŒπœùŒπŒ± ("diwia") is supposed as referring to a deity precursor of Artemis. Modern scholars mostly accept the identification.
The ancient Latin writers Varro and Cicero considered the etymology of Dƒ´ƒÅna as allied to that of "dies" and connected to the shine of the Moon.
Mythology.
The persona of Diana is complex and contains a number of archaic features. According to Georges Dum√©zil it falls into a particular subset of celestial gods, referred to in histories of religion as "frame gods". Such gods, while keeping the original features of celestial divinities, i.e. transcendent heavenly power and abstention from direct rule in worldly matters, did not share the fate of other celestial gods in Indoeuropean religions‚Äîthat of becoming "dei otiosi" or gods without practical purpose, since they did retain a particular sort of influence over the world and mankind.
The celestial character of Diana is reflected in her connection with light, inaccessibility, virginity, and her preference for dwelling on high mountains and in sacred woods.
Diana therefore reflects the heavenly world ("diuum" means sky or open air) in its sovereignty, supremacy, impassibility, and indifference towards such secular matters as the fates of mortals and states. At the same time, however, she is seen as active in ensuring the succession of kings and in the preservation of humankind through the protection of childbirth.
These functions are apparent in the traditional institutions and cults related to the goddess.
According to Dumezil the forerunner of all "frame gods" is an Indian epic hero who was the image (avatar) of the Vedic god Dyaus. Having renounced the world, in his roles of father and king, he attained the status of an immortal being while retaining the duty of ensuring that his dynasty is preserved and that there is always a new king for each generation.
The Scandinavian god Heimdallr performs an analogous function: he is born first and will die last. He too gives origin to kingship and the first king, bestowing on him regal prerogatives.
Diana, although a female deity, has exactly the same functions, preserving mankind through childbirth and royal succession.
F. H. Pairault in her essay on Diana qualifies Dum√©zil's theory as ""impossible to verify"".
Dumezil's interpretation appears deliberately to ignore that of James G. Frazer, who links Diana with the male god Janus as a divine couple. This looks odd as Dum√©zil's definition of the concept of "frame god" would fit well the figure of Janus. Frazer identifies the two with the supreme heavenly couple Jupiter-Juno and additionally ties in these figures to the overarching Indoeuropean religious complex. This regality is also linked to the cult of trees, particularly oaks.
In this interpretative schema, the institution of the Rex Nemorensis and related ritual should be seen as related to the theme of the dying god and the kings of May.
Physical description.
As a goddess of hunting, Diana often wears a short tunic and hunting boots. She is often portrayed holding a bow, and carrying a quiver on her shoulder, accompanied by a deer or hunting dogs. Like Venus, she was portrayed as beautiful and youthful. The crescent moon, sometimes worn as a diadem, is a major attribute of the goddess.
Worship.
Diana was initially just the hunting goddess, associated with wild animals and woodlands. She also later became a moon goddess, supplanting Titan goddess Luna. She also became the goddess of childbirth and ruled over the countryside. Catullus wrote a poem to Diana in which she has more than one alias: Latonia, Lucina, Iuno, Trivia, Luna.
In Rome the cult of Diana should have been almost as old as the city itself as Varro mentions her in the list of deities to whom king Titus Tatius vowed a shrine. It is noteworthy that the list includes Luna and Diana Lucina as separate entities.
Another testimony to the high antiquity of her cult is to be found in the "lex regia" of king Tullus Hostilius that condemns those guilty of incest to the "sacratio" to the goddess.
Diana was worshipped at a festival on August 13, when King Servius Tullius, himself born a slave, dedicated her temple on the Aventine Hill in the mid-6th century BC. Being placed on the Aventine, and thus outside the "pomerium", meant that Diana's cult essentially remained a "foreign" one, like that of Bacchus; she was never officially "transferred" to Rome as Juno was after the sack of Veii. It seems that her cult originated in Aricia, where her priest, the Rex Nemorensis remained. There the simple open-air fane was held in common by the Latin tribes, which Rome aspired to weld into a league and direct. Diana of the wood was soon thoroughly Hellenized, "a process which culminated with the appearance of Diana beside Apollo in the first "lectisternium" at Rome". Diana was regarded with great reverence and was a patroness of lower-class citizens, called plebeians, and slaves; slaves could receive asylum in her temples. This fact is of difficult interpretation. Georg Wissowa proposed the explanation that it might be because the first slaves of the Romans must have been Latins of the neighbouring tribes. However, in Ephesus too there was the same custom of the asylum (Œ±œÉœÖŒªŒπŒøŒΩ).
According to Fran√ßoise H√©l√®ne Pairault's study, historical and archaeological evidence point to the fact that both Diana of the Aventine and Diana Nemorensis were the product of the direct or indirect influence of the cult of Artemis spread by the Phoceans among the Greek towns of Campania Cuma and Capua, which in turn passed it over to the Etruscans and the Latins by the 6th and 5th centuries BC.
The origin of the ritual of the rex Nemorensis should have to be traced to the legend of Orestes and Iphigenia more than that of Hippolitos. The formation of the Latin League led by Laevius (or Baebius) Egerius happened under the influence of an alliance with the tyrant of Cuma Aristodemos and is probably connected to the political events at end of the 6th century narrated by Livy and Dionysius, such as the siege of Aricia by Porsenna's son Arruns. It is remarkable that the composition of this league does not reflect that of the Latin people who took part in the Latiar or Feriae Latinae given by Pliny and it has not as its leader the "rex Nemorensis" but a "dictator Latinus". It should thence be considered a political formation and not a traditional society founded on links of blood.
It looks as if the confrontation happened between two groups of Etruscans who fought for supremacy, those from Tarquinia, Vulci and Caere (allied with the Greeks of Capua) and those of Clusium. This is reflected in the legend of the coming of Orestes to Nemi and of the inhumation of his bones in the Roman Forum near the temple of Saturn. The cult introduced by Orestes at Nemi is apparently that of the Artemis Tauropolos. The literary amplification reveals a confused religious background: different Artemis were conflated under the epithet. As far as Nemi's Diana is concerned there are two different versions, by Strabo and Servius Honoratus. Strabo's version looks to be the most authoritative as he had access to first hand primary sources on the sanctuaries of Artemis, i.e. the priest of Artemis Artemidoros of Ephesus. The meaning of "Tauropolos" denotes an Asiatic goddess with lunar attributes, lady of the herds. The only possible "interpretatio graeca" of high antiquity concerning "Diana Nemorensis" could have been the one based upon this ancient aspect of deity of light, master of wildlife. "Tauropolos" is an ancient epithet attached to Hecate, Artemis and even Athena. According to the legend Orestes founded Nemi together with Iphigenia. At Cuma the Sybil is the priestess of both Phoibos and Trivia. Hesiod and Stesichorus tell the story according to which after her death Iphigenia was divinised under the name of Hecate, fact which would support the assumption that Artemis Tauropolos had a real ancient alliance with the heroine, who was her priestess in Taurid and her human paragon. This religious complex is in turn supported by the triple statue of Artemis-Hecate. A coin minted by P. Accoleius Lariscolus in 43 BC has been acknowledged as representing the archaic statue of Diana Nemorensis. It represents Artemis with the bow at one extremity, Luna-Selene with flowers at the other and a central deity not immediately identifiable, all united by a horizontal bar.
The iconographical analysis allows the dating of this image to the 6th century at which time there are Etruscan models. Two heads found in the sanctuary and the Roman theatre at Nemi, which have a hollow on their back, lend support to this interpretation of an archaic Diana Trivia, in whom three different elements are associated. The presence of a Hellenised Diana at Nemi should be related to the presence of the cult in Campania, as Diana "Tifatina" was appelled "Trivia" in an imperial age inscription which mentions a "flamen Virbialis" dedicated by "eques" C. Octavius Verus. Cuma too had a cult of a chthonic Hecate and certainly had strict contacts with Latium. The theological complex present in Diana looks very elaborated and certainly Hellenic, while an analogous Latin concept of Diana Trivia seems uncertain, as Latin sources reflect a Hellenised character of the goddess.
Diana was one of the triple goddess, the same goddess being called Luna in heaven, Diana on earth, and Proserpina in hell. Michael Drayton praises the Triple Diana in poem "The Man in the Moone" (1606): "So these great three most powerful of the rest, Phoebe, Diana, Hecate, do tell. Her sovereignty in Heaven, in Earth and Hell".
Though some Roman patrons ordered marble replicas of the specifically Anatolian "Diana" of Ephesus, where the Temple of Artemis stood, Diana was usually depicted for educated Romans in her Greek guise. If she is accompanied by a deer, as in the "Diana of Versailles" ("illustration, above right") this is because Diana was the patroness of hunting. The deer may also offer a covert reference to the myth of Acteon (or Actaeon), who saw her bathing naked. Diana transformed Acteon into a stag and set his own hunting dogs to kill him.
Worship of Diana is mentioned in the Bible. In Acts of the Apostles, Ephesian metal smiths who felt threatened by Saint Paul‚Äôs preaching of Christianity, jealously rioted in her defense, shouting ‚Äú"Great is Diana of the Ephesians!"‚Äù (Acts 19:28, New English Bible). After the city secretary (Œ≥œÅŒ±ŒºŒºŒ±œÑŒµœçœÇ) quieted the crowd, he said, ‚Äú"Men of Ephesus, what person is there who does not know that the city of the Ephesians is the keeper (guardian) of the temple of the great Diana and of her image that fell from heaven ?"" (Acts 19:36)
Sanctuaries.
Diana was an ancient goddess common to all Latin tribes. Therefore, many sanctuaries were dedicated to her in the lands inhabited by Latins. The first one is supposed to have been near Alba Longa before the town was destroyed by the Romans.
The Arician wood sanctuary near the lake of Nemi was Latin confederal as testified by the dedicatory epigraph quoted by Cato.
She had a shrine in Rome on the Aventine hill, according to tradition dedicated by king Servius Tullius. Its location is remarkable as the Aventine is situated outside the pomerium, i.e. original territory of the city, in order to comply with the tradition that Diana was a goddess common to all Latins and not exclusively of the Romans.
Other sanctuaries we know about are listed below:
Legacy.
In religion.
Diana's cult has been related in Early Modern Europe to the cult of Nicevenn (a.k.a. Dame Habond, Perchta, Herodiana, etc.). She was related to myths of a female Wild Hunt.
Wicca.
Today there is a branch of Wicca named for her, which is characterized by an exclusive focus on the feminine aspect of the Divine. Diana's name is also used as the third divine name in a Wiccan energy chant- "Isis Astarte Diana Hecate Demeter Kali Inanna".
Stregheria.
In Italy the old religion of Stregheria embraced the goddess Diana as Queen of the Witches; witches being the wise women healers of the time. Diana was said to have created the world of her own being having in herself the seeds of all creation yet to come. It was said that out of herself she divided the darkness and the light, keeping for herself the darkness of creation and creating her brother Apollo, the light. Diana was believed to have loved and ruled with her brother Apollo, the god of the Sun.
In language.
Both the Romanian words for "fairy" "Z√¢nƒÉ" and S√¢nzianƒÉ, the Leonese and Portuguese word for "water nymph" "xana", and the Spanish word for "shooting target" and "morning call" ("diana") seem to come from the name of Diana.
In the arts.
Since the Renaissance the myth of Diana has often been represented in the visual and dramatic arts, including the opera "L'arbore di Diana". In the 16th century, Diana's image figured prominently at the ch√¢teaus of Fontainebleau, Chenonceau, & at Anet, in deference to Diane de Poitiers, mistress of Henri of France. At Versailles she was incorporated into the Olympian iconography with which Louis XIV, the Apollo-like "Sun King" liked to surround himself. Diana is also a character in the 1876 L√©o Delibes ballet "Sylvia". The plot deals with Sylvia, one of Diana's nymphs and sworn to chastity, and Diana's assault on Sylvia's affections for the shepherd Amyntas.
In painting and sculpture.
Diana has been one of the most popular themes in art. Painters like Titian, Peter Paul Rubens, Fran√ßois Boucher, Nicholas Poussin made use of her myth as a major theme. Most depictions of Diana in art featured the stories of Diana and Actaeon, or Callisto,or depicted her resting after hunting. Some famous work of arts with a Diana theme are :
In "beaux arts".
Beaux Arts architecture and garden design (late 19th and early 20th centuries) used classic references in a modernized form. Two of the most popular of the period were of Pomona (goddess of orchards) as a metaphor for Agriculture, and Diana, representing Commerce, which is a perpetual hunt for advantage and profits.

</doc>
<doc id="8396" url="https://en.wikipedia.org/wiki?curid=8396" title="December 11">
December 11


</doc>
<doc id="8397" url="https://en.wikipedia.org/wiki?curid=8397" title="Danny Elfman">
Danny Elfman

Daniel Robert Elfman (born May 29, 1953) is an American composer, singer, songwriter, and record producer. From 1976 to 1995 he was the lead singer and songwriter for the rock band Oingo Boingo.
In 1976 Elfman entered the film industry as an actor. In 1982 he scored his first film, "Forbidden Zone", directed by his older brother Richard Elfman. Among his honors are four Academy Award nominations, a Grammy for "Batman", an Emmy for "Desperate Housewives", the 2002 Richard Kirk Award, and the Disney Legend Award.
Early life and career.
Danny Elfman was born in Los Angeles, California, into a Jewish family. He is the son of Blossom Elfman (n√©e Bernstein), a writer and teacher, and Milton Elfman, a teacher who was in the Air Force. He was raised in a racially mixed community in the Baldwin Hills area of Los Angeles. He spent much of his time in the local movie theatre, adoring the music of such film composers as Bernard Herrmann and Franz Waxman. Stating that he hung out with the "band geeks" in high school, he started a ska band. After dropping out of high school, he followed his brother Richard to France, where he performed with Le Grand Magic Circus, an avant-garde musical theater group. Violin in tow, Elfman next journeyed to Africa where he traveled through Ghana, Mali, and Upper Volta, absorbing new musical styles, including the Ghanaian highlife genre which would eventually influence his own music. 
He contracted malaria during his one-year stay and was often sick. Eventually he returned home to the United States, where he began to take Balinese music lessons at CalArts. During this time, he was romantically involved with Kim Gordon, who would later go on to form Sonic Youth. He was never officially a student at the institute; nonetheless, the instructor encouraged him to continue learning. Elfman stated, "He just laughed, and said, 'Sit. Play.' I continued to sit and play for a couple years." At this time, his brother was forming a new musical theater group.
Oingo Boingo.
In 1972 Richard Elfman founded the American new wave band/performance art group, originally called The Mystic Knights of the Oingo Boingo. They played several shows throughout the 1970s until Richard Elfman left the band to become a filmmaker. As a send-off to the band's original concept, Richard Elfman created the film "Forbidden Zone" based on their stage performances. Danny Elfman composed his first score for the film and played the role of Satan (the other band members played his minions). By the time the movie was completed, they had taken the name Oingo Boingo and begun recording and touring as a rock group. From 1976 and on, it was led by Danny Elfman, until 1995 when they suddenly retired. The semi-theatrical music and comedy troupe had transformed into a ska-influenced new wave band in 1979, and then changed again towards a more guitar-oriented rock sound, in the late 1980s.. Oingo Boingo, still led by Danny Elfman, performed as themselves in the 1986 movie Back to School. Additionally, Danny Elfman and Oingo Boingo guitarist Steve Bartek reunited on October 31, 2015 to perform the song "Dead Man's Party" during an encore at a Halloween celebration at the Hollywood Bowl "for the first time in 20 years to the day", as Elfman said to the audience.
Elfman and Tim Burton.
In 1985, Tim Burton and Paul Reubens invited Elfman to write the score for their first feature film, "Pee-wee's Big Adventure". Elfman was apprehensive at first, because of his lack of formal training, but with orchestration assistance from Oingo Boingo guitarist and arranger Steve Bartek, he achieved his goal of emulating the mood of such composers as Nino Rota and Bernard Herrmann. In the booklet for the first volume of "Music for a Darkened Theatre", Elfman described the first time he heard his music played by a full orchestra as one of the most thrilling experiences of his life. Elfman immediately developed a rapport with Burton and has gone on to score all but three of Burton's major studio releases: "Ed Wood", which was under production while Elfman and Burton were having a serious disagreement, "", and most recently "Miss Peregrine's Home for Peculiar Children". Elfman also provided the singing voice for Jack Skellington in Tim Burton's "The Nightmare Before Christmas" and the voices of both Barrel and the "Clown with the Tear-Away Face". Years later he provided the voice for Bonejangles the skeleton in "Corpse Bride".
Burton has said of his relationship with Elfman: "We don't even have to talk about the music. We don't even have to intellectualize ‚Äì which is good for both of us, we're both similar that way. We're very lucky to connect". (Breskin, 1997)
2004 ‚Äì present.
In 2004 Elfman composed "Serenada Schizophrana" for the American Composers Orchestra. It was conducted by John Mauceri on its recording and by Steven Sloane at its premiere at Carnegie Hall in New York City on February 23, 2005. After its premiere, it was recorded in studio and released onto SACD on October 3, 2006. The meeting with Mauceri proved fruitful as the composer was encouraged then to write a new concert piece for Mauceri and the Hollywood Bowl Orchestra. Elfman composed an "overture to a non-existent musical" and called the piece "The Overeager Overture". He also continues to compose his film scores in addition to these other projects. 
In November 2010, it was reported that Danny Elfman was writing the music for a planned musical based on the life of Harry Houdini. But, as of January 2012, he was no longer attached to the project.
In 2011 Elfman composed the music for the Cirque du Soleil show "Iris", which was performed at the Dolby Theatre in Hollywood from July 21, 2011 to January 19, 2013. 
In October 2013, Elfman returned to the stage to sing his vocal parts to a handful of "Nightmare Before Christmas" songs as part of a concert titled "Danny Elfman's Music from the Films of Tim Burton". He composed the film score for "Oz the Great and Powerful" (2013), and composed additional music for "" (2015) together with Brian Tyler.
Musical influences.
Modern classicist composers, including B√©la Bart√≥k, Philip Glass, Lou Harrison, Carl Orff, Harry Partch, Sergei Prokofiev, Maurice Ravel, Erik Satie, Igor Stravinsky, and Pyotr Ilyich Tchaikovsky have influenced the style of Elfman's music. Elfman cited his first time noticing film music being when he heard Bernard Hermann's score to "The Day the Earth Stood Still" as an eleven-year-old and being a fan of film music since then. Other influences based in film music include Erich Wolfgang Korngold, Max Steiner, David Tamkin, and Franz Waxman. Also, Nino Rota served as a significant influence and was the main inspiration for Elfman's score to "Pee-wee's Big Adventure".
Personal life.
Elfman has three children: Lola (born 1979), Mali (born 1984), and Oliver (born 2005). On November 29, 2003, he married actress Bridget Fonda. In 1997, he scored "A Simple Plan", his only score for one of her films to date (although he did compose a cue for the film "Army of Darkness", in which Fonda has a cameo). In the late 1960s and early 1970s, he dated Sonic Youth's Kim Gordon.
He is the uncle of actor Bodhi Elfman, who is married to actress Jenna Elfman.
Describing his politics during the 1980s, Elfman said, "I'm not a doomist. My attitude is always to be critical of what's around you, but not ever to forget how lucky we are. I've traveled around the world. I left thinking I was a revolutionary. I came back real right-wing patriotic. Since then, I've kind of mellowed in between." In 2008, he expressed support for Barack Obama and said that Sarah Palin was his "worst nightmare".
Hearing damage.
When asked during a 2007 phone-in interview on XETRA-FM if he ever had any notions of performing in an Oingo Boingo reunion, Elfman immediately rejected the idea and stated that in the last few years with the band he had begun to develop significant and irreversible hearing damage as a result of his continuous exposure to the high noise levels involved in performing in a rock band. He went on to say that he believes his hearing damage is partially due to a genetic predisposition to hearing loss, and that he will never return to the stage for fear of worsening not only his condition but also that of his band mates.
However, Elfman did indeed return to the stage at the Hollywood Bowl on October 31, 2015 and November 1, 2015 to perform Dead Man's Party as the encore to an evening featuring the full length score and performances from The Nightmare Before Christmas. 
Awards and nominations.
American Film Institute.
Elfman's scores for "Batman" and "Edward Scissorhands" were nominated for AFI's 100 Years of Film Scores.

</doc>
<doc id="8398" url="https://en.wikipedia.org/wiki?curid=8398" title="Dimension">
Dimension

[[File:Squarecubetesseract.png|thumb
]]
In physics and mathematics, the dimension of a mathematical space (or object) is informally defined as the minimum number of coordinates needed to specify any point within it. Thus a line has a dimension of one because only one coordinate is needed to specify a point on itfor example, the point at 5 on a number line. A surface such as a plane or the surface of a cylinder or sphere has a dimension of two because two coordinates are needed to specify a point on itfor example, both a latitude and longitude are required to locate a point on the surface of a sphere. The inside of a cube, a cylinder or a sphere is three-dimensional because three coordinates are needed to locate a point within these spaces.
In classical mechanics, space and time are different categories and refer to absolute space and time. That conception of the world is a four-dimensional space but not the one that was found necessary to describe electromagnetism. The four dimensions of spacetime consist of events that are not absolutely defined spatially and temporally, but rather are known relative to the motion of an observer. Minkowski space first approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity. Ten dimensions are used to describe string theory, and the state-space of quantum mechanics is an infinite-dimensional function space.
The concept of dimension is not restricted to physical objects. High-dimensional spaces frequently occur in mathematics and the sciences. They may be parameter spaces or configuration spaces such as in Lagrangian or Hamiltonian mechanics; these are abstract spaces, independent of the physical space we live in.
In mathematics.
In mathematics, the dimension of an object is an intrinsic property independent of the space in which the object is embedded. For example, a point on the unit circle in the plane can be specified by two Cartesian coordinates, but a single polar coordinate (the angle) would be sufficient, so the circle is 1-dimensional even though it exists in the 2-dimensional plane. This "intrinsic" notion of dimension is one of the chief ways the mathematical notion of dimension differs from its common usages.
The dimension of Euclidean -space is . When trying to generalize to other types of spaces, one is faced with the question "what makes -dimensional?" One answer is that to cover a fixed ball in by small balls of radius , one needs on the order of such small balls. This observation leads to the definition of the Minkowski dimension and its more sophisticated variant, the Hausdorff dimension, but there are also other answers to that question. For example, the boundary of a ball in looks locally like and this leads to the notion of the inductive dimension. While these notions agree on , they turn out to be different when one looks at more general spaces.
A tesseract is an example of a four-dimensional object. Whereas outside mathematics the use of the term "dimension" is as in: "A tesseract "has four dimensions"", mathematicians usually express this as: "The tesseract "has dimension 4"", or: "The dimension of the tesseract "is" 4".
Although the notion of higher dimensions goes back to Ren√© Descartes, substantial development of a higher-dimensional geometry only began in the 19th century, via the work of Arthur Cayley, William Rowan Hamilton, Ludwig Schl√§fli and Bernhard Riemann. Riemann's 1854 Habilitationsschrift, Schl√§fli's 1852 "Theorie der vielfachen Kontinuit√§t", Hamilton's 1843 discovery of the quaternions and the construction of the Cayley algebra marked the beginning of higher-dimensional geometry.
The rest of this section examines some of the more important mathematical definitions of the dimensions.
Complex dimension.
A complex number ("x" + "iy") has a real part "x" and an imaginary part "iy" whose magnitude is "y". A single complex coordinate system may be applied to an object having two real dimensions. For example, an ordinary two-dimensional spherical surface, when given a complex metric, becomes a Riemann sphere of one complex dimension. Complex dimensions appear in the study of complex manifolds and algebraic varieties.
Dimension of a vector space.
The dimension of a vector space is the number of vectors in any basis for the space, i.e. the number of coordinates necessary to specify any vector. This notion of dimension (the cardinality of a basis) is often referred to as the "Hamel dimension" or "algebraic dimension" to distinguish it from other notions of dimension.
Manifolds.
A connected topological manifold is locally homeomorphic to Euclidean -space, and the number is called the manifold's dimension. One can show that this yields a uniquely defined dimension for every connected topological manifold.
For connected differentiable manifolds, the dimension is also the dimension of the tangent vector space at any point.
In geometric topology, the theory of manifolds is characterized by the way dimensions 1 and 2 are relatively elementary, the high-dimensional cases are simplified by having extra space in which to "work"; and the cases and are in some senses the most difficult. This state of affairs was highly marked in the various cases of the Poincar√© conjecture, where four different proof methods are applied.
Varieties.
The dimension of an algebraic variety may be defined in various equivalent ways. The most intuitive way is probably the dimension of the tangent space at any regular point. Another intuitive way is to define the dimension as the number of hyperplanes that are needed in order to have an intersection with the variety that is reduced to a finite number of points (dimension zero). This definition is based on the fact that the intersection of a variety with a hyperplane reduces the dimension by one unless if the hyperplane contains the variety.
An algebraic set being a finite union of algebraic varieties, its dimension is the maximum of the dimensions of its components. It is equal to the maximal length of the chains formula_1 of sub-varieties of the given algebraic set (the length of such a chain is the number of "formula_2").
Each variety can be considered as an algebraic stack, and its dimension as variety agrees with its dimension as stack. There are however many stacks which do not correspond to varieties, and some of these have negative dimension. Specifically, if "V" is a variety of dimension "m" and "G" is an algebraic group of dimension "n" acting on "V", then the quotient stack ["V"/"G"] has dimension "m"‚àí"n".
Krull dimension.
The Krull dimension of a commutative ring is the maximal length of chains of prime ideals in it, a chain of length "n" being a sequence formula_3 of prime ideals related by inclusion. It is strongly related to the dimension of an algebraic variety, because of the natural correspondence between sub-varieties and prime ideals of the ring of the polynomials on the variety.
For an algebra over a field, the dimension as vector space is finite if and only if its Krull dimension is 0.
Lebesgue covering dimension.
For any normal topological space , the Lebesgue covering dimension of is defined to be n if "n" is the smallest integer for which the following holds: any open cover has an open refinement (a second open cover where each element is a subset of an element in the first cover) such that no point is included in more than elements. In this case dim . For a manifold, this coincides with the dimension mentioned above. If no such integer exists, then the dimension of is said to be infinite, and one writes dim . Moreover, has dimension ‚àí1, i.e. dim if and only if is empty. This definition of covering dimension can be extended from the class of normal spaces to all Tychonoff spaces merely by replacing the term "open" in the definition by the term "functionally open".
Inductive dimension.
An inductive definition of dimension can be created as follows. Consider a discrete set of points (such as a finite collection of points) to be 0-dimensional. By dragging a 0-dimensional object in some direction, one obtains a 1-dimensional object. By dragging a 1-dimensional object in a "new direction", one obtains a 2-dimensional object. In general one obtains an ()-dimensional object by dragging an -dimensional object in a "new" direction.
The inductive dimension of a topological space may refer to the "small inductive dimension" or the "large inductive dimension", and is based on the analogy that balls have -dimensional boundaries, permitting an inductive definition based on the dimension of the boundaries of open sets.
Hausdorff dimension.
For structurally complicated sets, especially fractals, the Hausdorff dimension is useful. The Hausdorff dimension is defined for all metric spaces and, unlike the dimensions considered above, can also attain non-integer real values. The box dimension or Minkowski dimension is a variant of the same idea. In general, there exist more definitions of fractal dimensions that work for highly irregular sets and attain non-integer positive real values. Fractals have been found useful to describe many natural objects and phenomena.
Hilbert spaces.
Every Hilbert space admits an orthonormal basis, and any two such bases for a particular space have the same cardinality. This cardinality is called the dimension of the Hilbert space. This dimension is finite if and only if the space's Hamel dimension is finite, and in this case the above dimensions coincide.
In physics.
Spatial dimensions.
Classical physics theories describe three physical dimensions: from a particular point in space, the basic directions in which we can move are up/down, left/right, and forward/backward. Movement in any other direction can be expressed in terms of just these three. Moving down is the same as moving up a negative distance. Moving diagonally upward and forward is just as the name of the direction implies; "i.e.", moving in a linear combination of up and forward. In its simplest form: a line describes one dimension, a plane describes two dimensions, and a cube describes three dimensions. (See Space and Cartesian coordinate system.)
Time.
A temporal dimension is a dimension of time. Time is often referred to as the "fourth dimension" for this reason, but that is not to imply that it is a spatial dimension. A temporal dimension is one way to measure physical change. It is perceived differently from the three spatial dimensions in that there is only one of it, and that we cannot move freely in time but subjectively move in one direction.
The equations used in physics to model reality do not treat time in the same way that humans commonly perceive it. The equations of classical mechanics are symmetric with respect to time, and equations of quantum mechanics are typically symmetric if both time and other quantities (such as charge and parity) are reversed. In these models, the perception of time flowing in one direction is an artifact of the laws of thermodynamics (we perceive time as flowing in the direction of increasing entropy).
The best-known treatment of time as a dimension is Poincar√© and Einstein's special relativity (and extended to general relativity), which treats perceived space and time as components of a four-dimensional manifold, known as spacetime, and in the special, flat case as Minkowski space.
Additional dimensions.
In physics, three dimensions of space and one of time is the accepted norm. However, there are theories that attempt to unify the four fundamental forces by introducing extra dimensions. Most notably, superstring theory requires 10 spacetime dimensions, and originates from a more fundamental 11-dimensional theory tentatively called M-theory which subsumes five previously distinct superstring theories. To date, no experimental or observational evidence is available to confirm the existence of these extra dimensions. If extra dimensions exist, they must be hidden from us by some physical mechanism. One well-studied possibility is that the extra dimensions may be "curled up" at such tiny scales as to be effectively invisible to current experiments. Limits on the size and other properties of extra dimensions are set by particle experiments such as those at the Large Hadron Collider.
At the level of quantum field theory, Kaluza‚ÄìKlein theory unifies gravity with gauge interactions, based on the realization that gravity propagating in small, compact extra dimensions is equivalent to gauge interactions at long distances. In particular when the geometry of the extra dimensions is trivial, it reproduces electromagnetism. However at sufficiently high energies or short distances, this setup still suffers from the same pathologies that famously obstruct direct attempts to describe quantum gravity. Therefore, these models still require a UV completion, of the kind that string theory is intended to provide. In particular, superstring theory requires six compact dimensions forming a Calabi‚ÄìYau manifold. Thus Kaluza-Klein theory may be considered either as an incomplete description on its own, or as a subset of string theory model building.
In addition to small and curled up extra dimensions, there may be extra dimensions that instead aren't apparent because the matter associated with our visible universe is localized on a subspace. Thus the extra dimensions need not be small and compact but may be large extra dimensions. D-branes are dynamical extended objects of various dimensionalities predicted by string theory that could play this role. They have the property that open string excitations, which are associated with gauge interactions, are confined to the brane by their endpoints, whereas the closed strings that mediate the gravitational interaction are free to propagate into the whole spacetime, or "the bulk". This could be related to why gravity is exponentially weaker than the other forces, as it effectively dilutes itself as it propagates into a higher-dimensional volume.
Some aspects of brane physics have been applied to cosmology. For example, brane gas cosmology attempts to explain why there are three dimensions of space using topological and thermodynamic considerations. According to this idea it would be because three is the largest number of spatial dimensions where strings can generically intersect. If initially there are lots of windings of strings around compact dimensions, space could only expand to macroscopic sizes once these windings are eliminated, which requires oppositely wound strings to find each other and annihilate. But strings can only find each other to annihilate at a meaningful rate in three dimensions, so it follows that only three dimensions of space are allowed to grow large given this kind of initial configuration.
Extra dimensions are said to be universal if all fields are equally free to propagate within them.
Networks and dimension.
Some complex networks are characterized by fractal dimensions. The concept of dimension can be generalized to include networks embedded in space. The dimension characterize their spatial constraints.
In literature.
Science fiction texts often mention the concept of "dimension" when referring to parallel or alternate universes or other imagined planes of existence. This usage is derived from the idea that to travel to parallel/alternate universes/planes of existence one must travel in a direction/dimension besides the standard ones. In effect, the other universes/planes are just a small distance away from our own, but the distance is in a fourth (or higher) spatial (or non-spatial) dimension, not the standard ones.
One of the most heralded science fiction stories regarding true geometric dimensionality, and often recommended as a starting point for those just starting to investigate such matters, is the 1884 novella "Flatland" by Edwin A. Abbott. Isaac Asimov, in his foreword to the Signet Classics 1984 edition, described "Flatland" as "The best introduction one can find into the manner of perceiving dimensions."
The idea of other dimensions was incorporated into many early science fiction stories, appearing prominently, for example, in Miles J. Breuer's "The Appendix and the Spectacles" (1928) and Murray Leinster's "The Fifth-Dimension Catapult" (1931); and appeared irregularly in science fiction by the 1940s. Classic stories involving other dimensions include Robert A. Heinlein's "‚ÄîAnd He Built a Crooked House" (1941), in which a California architect designs a house based on a three-dimensional projection of a tesseract; and Alan E. Nourse's "Tiger by the Tail" and "The Universe Between" (both 1951). Another reference is Madeleine L'Engle's novel "A Wrinkle In Time" (1962), which uses the fifth dimension as a way for "tesseracting the universe" or "folding" space in order to move across it quickly. The fourth and fifth dimensions were also a key component of the book "The Boy Who Reversed Himself" by William Sleator.
In philosophy.
Immanuel Kant, in 1783, wrote: "That everywhere space (which is not itself the boundary of another space) has three dimensions and that space in general cannot have more dimensions is based on the proposition that not more than three lines can intersect at right angles in one point. This proposition cannot at all be shown from concepts, but rests immediately on intuition and indeed on pure intuition "a priori" because it is apodictically (demonstrably) certain."
"Space has Four Dimensions" is a short story published in 1846 by German philosopher and experimental psychologist Gustav Fechner under the pseudonym "Dr. Mises". The protagonist in the tale is a shadow who is aware of and able to communicate with other shadows, but who is trapped on a two-dimensional surface. According to Fechner, this "shadow-man" would conceive of the third dimension as being one of time. The story bears a strong similarity to the "Allegory of the Cave" presented in Plato's "The Republic" (c. 380¬†BC).
Simon Newcomb wrote an article for the "Bulletin of the American Mathematical Society" in 1898 entitled "The Philosophy of Hyperspace". Linda Dalrymple Henderson coined the term "hyperspace philosophy", used to describe writing that uses higher dimensions to explore metaphysical themes, in her 1983 thesis about the fourth dimension in early-twentieth-century art. Examples of "hyperspace philosophers" include Charles Howard Hinton, the first writer, in 1888, to use the word "tesseract"; and the Russian esotericist P. D. Ouspensky.
See also.
Topics by dimension.
Zero
One
Two
Three
Four
Higher dimensionsin mathematics
Infinite

</doc>
<doc id="8400" url="https://en.wikipedia.org/wiki?curid=8400" title="Duodecimal">
Duodecimal

The duodecimal system (also known as base 12 or dozenal) is a positional notation numeral system using twelve as its base. In this system, the number ten may be written by a rotated "2" (2) and the number eleven by a rotated "3" (3). This notation was introduced by Sir Isaac Pitman. These digit forms are available as Unicode characters on computerized systems since June 2015 as ‚Üä (Code point 218A) and ‚Üã (Code point 218B), respectively. Other notations use "A", "T", or "X" for ten and "B" or "E" for eleven. The number twelve (that is, the number written as "12" in the base ten numerical system) is instead written as "10" in duodecimal (meaning "1 dozen and 0 units", instead of "1 ten and 0 units"), whereas the digit string "12" means "1 dozen and 2 units" (i.e. the same number that in decimal is written as "14"). Similarly, in duodecimal "100" means "1 gross", "1000" means "1 great gross", and "0.1" means "1 twelfth" (instead of their decimal meanings "1 hundred", "1 thousand", and "1 tenth").
The number twelve, a superior highly composite number, is the smallest number with four non-trivial factors (2, 3, 4, 6), and the smallest to include as factors all four numbers (1 to 4) within the subitizing range. As a result of this increased factorability of the radix and its divisibility by a wide range of the most elemental numbers (whereas ten has only two non-trivial factors: 2 and 5, and not 3, 4, or 6), duodecimal representations fit more easily than decimal ones into many common patterns, as evidenced by the higher regularity observable in the duodecimal multiplication table. As a result, duodecimal has been described as the optimal number system. Of its factors, 2 and 3 are prime, which means the reciprocals of all 3-smooth numbers (such as 2, 3, 4, 6, 8, 9...) have a terminating representation in duodecimal. In particular, the five most elementary fractions (, , , and ) all have a short terminating representation in duodecimal (0.6, 0.4, 0.8, 0.3 and 0.9, respectively), and twelve is the smallest radix with this feature (because it is the least common multiple of 3 and 4). This all makes it a more convenient number system for computing fractions than most other number systems in common use, such as the decimal, vigesimal, binary, octal and hexadecimal systems. Although the trigesimal and sexagesimal systems (where the reciprocals of all 5-smooth numbers terminate) do even better in this respect, this is at the cost of unwieldy multiplication tables and a much larger number of symbols to memorize.
Origin.
Languages using duodecimal number systems are uncommon. Languages in the Nigerian Middle Belt such as Janji, Gbiri-Niragu (Gure-Kahugu), Piti, and the Nimbia dialect of Gwandara; the Chepang language of Nepal and the Mahl language of Minicoy Island in India are known to use duodecimal numerals. In fiction, J. R. R. Tolkien's Elvish languages can express numbers either decimally (in Quenya, "maquan√≥ti√´" "hand-counting" or *"quaistan√≥ti√´" "tenth-counting") or duodecimally (presumably *"rastan√≥ti√´" "dozen-counting").
Germanic languages have special words for 11 and 12, such as "eleven" and "twelve" in English. However, they are considered to come from Proto-Germanic *"ainlif" and *"twalif" (respectively "one left" and "two left"), both of which were decimal.
Historically, units of time in many civilizations are duodecimal. There are twelve signs of the zodiac, twelve months in a year, and the Babylonians had twelve hours in a day (although at some point this was changed to 24). Traditional Chinese calendars, clocks, and compasses are based on the twelve Earthly Branches. There are 12 inches in an imperial foot, 12 troy ounces in a troy pound, 12 old British pence in a shilling, 24 (12√ó2) hours in a day, and many other items counted by the dozen, gross (144, square of 12) or great gross (1728, cube of 12). The Romans used a fraction system based on 12, including the uncia which became both the English words "ounce" and "inch". Pre-decimalisation, Ireland and the United Kingdom used a mixed duodecimal-vigesimal currency system (12 pence = 1 shilling, 20 shillings or 240 pence to the pound sterling or Irish pound), and Charlemagne established a monetary system that also had a mixed base of twelve and twenty, the remnants of which persist in many places.
The importance of 12 has been attributed to the number of lunar cycles in a year, and also to the fact that humans have 12 finger bones (phalanges) on one hand (three on each of four fingers). It is possible to count to 12 with the thumb acting as a pointer, touching each finger bone in turn. A traditional finger counting system still in use in many regions of Asia works in this way, and could help to explain the occurrence of numeral systems based on 12 and 60 besides those based on 10, 20 and 5. In this system, the one (usually right) hand counts repeatedly to 12, displaying the number of iterations on the other (usually left), until five dozens, i. e. the 60, are full.
Notations and pronunciations.
In a duodecimal place system, ten can be written as 2, ·òî, or ‚Üä (a rotated digit two); eleven can be written as 3, ∆ê, or ‚Üã (a reversed digit three); and twelve is written as 10. For alternative symbols, see below.
According to this notation, duodecimal 50 expresses the same quantity as decimal 60 (= five times twelve), duodecimal 60 is equivalent to decimal 72 (= six times twelve = half a gross), duodecimal 100 has the same value as decimal 144 (= twelve times twelve = one gross), etc.
2 is pronounced as 'dek', 3 is pronounced 'el', and 10 is pronounced 'doh'. Multiple digits in duodecimal are pronounced differently. 12 in duodecimal is one-doh-two, 30 is three-doh, 100 is one-gros (pronounced 'groh'), and 329 is pronounced el-gros-dek-doh-nine.
Comparison to other numeral systems.
The number 12 has six factors, which are 1, 2, 3, 4, 6, and 12, of which 2 and 3 are prime. The decimal system has only four factors, which are 1, 2, 5, and 10; of which 2 and 5 are prime. Vigesimal adds two factors to those of ten, namely 4 and 20, but no additional prime factor. Although twenty has 6 factors, 2 of them prime, similarly to twelve, it is also a much larger base (i.e. the digit set and the multiplication table are much larger). Binary has only two factors, 1 and 2, the latter being prime. Hexadecimal has five factors, adding 4, 8 and 16 to those of 2, but no additional prime. Trigesimal is the smallest system that has three different prime factors (all of the three smallest primes: 2, 3 and 5) and it has eight factors in total (1, 2, 3, 5, 6, 10, 15, and 30). Sexagesimal‚Äîwhich the ancient Sumerians and Babylonians among others actually used‚Äîadds the four convenient factors 4, 12, 20, and 60 to this but no new prime factors. The smallest system that has four different prime factors is base 210 and the pattern follows the primorials. In all base systems, there are similarities to the representation of multiples of numbers which are one less than the base.
Conversion tables to and from decimal.
To convert numbers between bases, one can use the general conversion algorithm (see the relevant section under positional notation). Alternatively, one can use digit-conversion tables. The ones provided below can be used to convert any duodecimal number between 0.01 and ∆ê∆ê∆ê,∆ê∆ê∆ê.∆ê∆ê to decimal, or any decimal number between 0.01 and 999,999.99 to duodecimal. To use them, the given number must first be decomposed into a sum of numbers with only one significant digit each. For example:
123,456.78 = 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08
This decomposition works the same no matter what base the number is expressed in. Just isolate each non-zero digit, padding them with as many zeros as necessary to preserve their respective place values. If the digits in the given number include zeroes (for example, 102,304.05), these are, of course, left out in the digit decomposition (102,304.05 = 100,000 + 2,000 + 300 + 4 + 0.05). Then the digit conversion tables can be used to obtain the equivalent value in the target base for each digit. If the given number is in duodecimal and the target base is decimal, we get:
(duodecimal) 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08 = (decimal) 248,832 + 41,472 + 5,184 + 576 + 60 + 6 + 0.58333333333... + 0.05555555555...
Now, because the summands are already converted to base ten, the usual decimal arithmetic is used to perform the addition and recompose the number, arriving at the conversion result:
That is, (duodecimal) 123,456.78 equals (decimal) 296,130.63 ‚âà 296,130.64
If the given number is in decimal and the target base is duodecimal, the method is basically same. Using the digit conversion tables:
(decimal) 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08 = (duodecimal) 49,·òî54 + ∆ê,6·òî8 + 1,8·òî0 + 294 + 42 + 6 + 0.84972497249724972497... + 0.0∆ê62...
However, in order to do this sum and recompose the number, now the addition tables for the duodecimal system have to be used, instead of the addition tables for decimal most people are already familiar with, because the summands are now in base twelve and so the arithmetic with them has to be in duodecimal as well. In decimal, 6 + 6 equals 12, but in duodecimal it equals 10; so, if using decimal arithmetic with duodecimal numbers one would arrive at an incorrect result. Doing the arithmetic properly in duodecimal, one gets the result:
That is, (decimal) 123,456.78 equals (duodecimal) 5∆ê,540.9... ‚âà 5∆ê,540.94
Fractions and irrational numbers.
Fractions.
Duodecimal fractions may be simple:
or complicated:
As explained in recurring decimals, whenever an irreducible fraction is written in radix point notation in any base, the fraction can be expressed exactly (terminates) if and only if all the prime factors of its denominator are also prime factors of the base. Thus, in base-ten (=¬†2√ó5) system, fractions whose denominators are made up solely of multiples of 2 and 5 terminate: ¬†=¬†, ¬†=¬† and ¬†=¬† can be expressed exactly as 0.125, 0.05 and 0.002 respectively. and , however, recur (0.333... and 0.142857142857...). In the duodecimal (=¬†2√ó2√ó3) system, is exact; and recur because they include 5 as a factor; is exact; and recurs, just as it does in decimal.
The number of denominators which give terminating fractions within a given number of digits, say "n", in a base "b" is the number of factors (divisors) of "bn", the "n"th power of the base "b" (although this includes the divisor 1, which does not produce fractions when used as the denominator). The number of factors of "bn" is given using its prime factorization.
For decimal, 10"n" = 2"n" * 5"n". The number of divisors is found by adding one to each exponent of each prime and multiplying the resulting quantities together.
Factors of 10"n" = ("n"+1)("n"+1) = ("n"+1)2.
For example, the number 8 is a factor of 103 (1000), so 1/8 and other fractions with a denominator of 8 can not require more than 3 fractional decimal digits to terminate. 5/8 = 0.625ten
For duodecimal, 12"n" = 22"n" * 3"n". This has (2"n"+1)("n"+1) divisors. The sample denominator of 8 is a factor of a gross (122 = 144), so eighths can not need more than two duodecimal fractional places to terminate. 5/8 = 0.76twelve
Because both ten and twelve have two unique prime factors, the number of divisors of "bn" for "b" = 10 or 12 grows quadratically with the exponent "n" (in other words, of the order of "n"2).
Recurring digits.
The Dozenal Society of America argues that factors of 3 are more commonly encountered in real-life division problems than factors of 5. Thus, in practical applications, the nuisance of repeating decimals is encountered less often when duodecimal notation is used. Advocates of duodecimal systems argue that this is particularly true of financial calculations, in which the twelve months of the year often enter into calculations.
However, when recurring fractions "do" occur in duodecimal notation, they are less likely to have a very short period than in decimal notation, because 12 (twelve) is between two prime numbers, 11 (eleven) and 13 (thirteen), whereas ten is adjacent to the composite number 9. Nonetheless, having a shorter or longer period doesn't help the main inconvenience that one does not get a finite representation for such fractions in the given base (so rounding, which introduces inexactitude, is necessary to handle them in calculations), and overall one is more likely to have to deal with infinite recurring digits when fractions are expressed in decimal than in duodecimal, because one out of every three consecutive numbers contains the prime factor 3 in its factorization, whereas only one out of every five contains the prime factor 5. All other prime factors, except 2, are not shared by either ten or twelve, so they do not
influence the relative likeliness of encountering recurring digits (any irreducible fraction that contains any of these other factors in its denominator will recur in either base). Also, the prime factor 2 appears twice in the factorization of twelve, whereas only once in the factorization of ten; which means that most fractions whose denominators are powers of two will have a shorter, more convenient terminating representation in duodecimal than in decimal representation (e.g. 1/(22) = 0.25 ten = 0.3 twelve; 1/(23) = 0.125 ten = 0.16 twelve; 1/(24) = 0.0625 ten = 0.09 twelve; 1/(25) = 0.03125 ten = 0.046 twelve; etc.).
Values in bold indicate that value is exact.
The duodecimal period length of 1/"n" are
The duodecimal period length of 1/("n"th prime) are
Smallest prime with duodecimal period "n" are
Irrational numbers.
As for irrational numbers, none of them have a finite representation in "any" of the rational-based positional number systems (such as the decimal and duodecimal ones); this is because a rational-based positional number system is essentially nothing but a way of expressing quantities as a sum of fractions whose denominators are powers of the base, and by definition no "finite" sum of rational numbers can ever result in an irrational number. For example, 123.456 = 1 √ó 102 + 2 √ó 101 + 3 √ó 100 + 4 √ó 1/101 + 5 √ó 1/102 + 6 √ó 1/103 (this is also the reason why fractions that contain prime factors in their denominator not in common with those of the base do not have a terminating representation in that base). Moreover, the infinite series of digits of an irrational number does not exhibit a pattern of repetition; instead, the different digits succeed in a seemingly random fashion. The following chart compares the first few digits of the decimal and duodecimal representation of several of the most important algebraic and transcendental irrational numbers. Some of these numbers may be perceived as having fortuitous patterns, making them easier to memorize, when represented in one base or the other.
The first few digits of the decimal and duodecimal representation of another important number, the Euler‚ÄìMascheroni constant (the status of which as a rational or irrational number is not yet known), are:
Advocacy and "dozenalism".
The case for the duodecimal system was put forth at length in F. Emerson Andrews' 1935 book "New Numbers: How Acceptance of a Duodecimal Base Would Simplify Mathematics". Emerson noted that, due to the prevalence of factors of twelve in many traditional units of weight and measure, many of the computational advantages claimed for the metric system could be realized "either" by the adoption of ten-based weights and measure "or" by the adoption of the duodecimal number system.
Rather than the symbols "A" for ten and "B" for eleven as used in hexadecimal notation and vigesimal notation (or "T" and "E" for ten and eleven), he suggested in his book and used a script X and a script E, formula_1 (U+1D4B3) and (U+2130), to represent the digits ten and eleven respectively, because, at least on a page of Roman script, these characters were distinct from any existing letters or numerals, yet were readily available in printers' fonts. He chose formula_1 for its resemblance to the Roman numeral X, and as the first letter of the word "eleven".
Another popular notation, introduced by Sir Isaac Pitman, is to use a rotated 2 (·òî) (resembling a script "œÑ" for "ten") to represent ten and a rotated or horizontally flipped 3 (∆ê) to represent eleven. This is the convention commonly employed by the Dozenal Society of Great Britain and has the advantage of being easily recognizable as digits because of their resemblance in shape to existing digits. On the other hand, the Dozenal Society of America adopted for some years the convention of using a sextile ‚öπ for ten and a hash ‚åó for eleven. The reason was that the symbol ‚öπ resembles a struck-through X, whereas the symbol ‚åó resembles a doubly struck-through 11, and both symbols are already present in telephone dials. However, critics pointed out these symbols do not look anything like digits. Some other systems write 10 as Œ¶ (a combination of 1 and 0) and eleven as a cross of two lines (+, x, or ‚Ä† for example).
Problems with these symbols are evident, most notably that most of them cannot be represented in the seven-segment display of most calculator displays (formula_1 and being an exception, although "E" is used on calculators to indicate an error message, and formula_1 requiring some distortion). However, 10 and 11 do fit, both within a single digit (11 fits as is, whereas the 10 has to be tilted sideways, resulting in a character that resembles an O with a macron, ≈ç or o). A and B also fit (although B must be represented as lowercase "b" and as such, 6 must have a bar over it to distinguish the two figures) and are used on calculators for bases higher than ten.
Other problems relate to the current usage of most of the proposed symbols as variables or quantities in physics and mathematics. Of particular concern to mathematicians is formula_1 which has ubiquitous usage as an unknown quantity in algebra.
In "Little Twelvetoes", American television series "Schoolhouse Rock!" portrayed an alien child using base-twelve arithmetic, using "dek", "el" and "doh" as names for ten, eleven and twelve, and Andrews' script-X and script-E for the digit symbols. ("Dek" is from the prefix "deca", "el" being short for "eleven" and "doh" an apparent shortening of "dozen".)
The Dozenal Society of America and the Dozenal Society of Great Britain promote widespread adoption of the base-twelve system. They use the word "dozenal" instead of "duodecimal" because the latter comes from Latin roots that express twelve in base-ten terminology.
The renowned mathematician and mental calculator Alexander Craig Aitken was an outspoken advocate of the advantages and superiority of duodecimal over decimal:
In Leo Frankowski's Conrad Stargard novels, Conrad introduces a duodecimal system of arithmetic at the suggestion of a merchant, who is accustomed to buying and selling goods in dozens and grosses, rather than tens or hundreds. He then invents an entire system of weights and measures in base twelve, including a clock with twelve hours in a day, rather than twenty-four hours.
In Lee Carroll's "Kryon: Alchemy of the Human Spirit", a chapter is dedicated to the advantages of the duodecimal system. The duodecimal system is supposedly suggested by Kryon (a fictional entity believed in by New Age circles) for all-round use, aiming at better and more natural representation of nature of the Universe through mathematics. An individual article "Mathematica" by James D. Watt (included in the above publication) exposes a few of the unusual symmetry connections between the duodecimal system and the golden ratio, as well as provides numerous number symmetry-based arguments for the universal nature of the base-12 number system.
Duodecimal metric systems.
Systems of measurement proposed by dozenalists include:
Duodecimal digits on computerized writing systems.
In March 2013, a proposal was submitted to include the digit forms for ten and eleven propagated by the Dozenal Societies of Great Britain and America in the Unicode Standard. Of these, the British forms were accepted for encoding as characters at code points U+218A (‚Üä) and U+218B (‚Üã) They have been included in the Unicode 8.0 release in June 2015.
Few fonts support these new characters in late 2015, but Abibas, EB Garamond, Everson Mono, Squarish Sans CT, and Symbola do.
Also, the turned digits two and three are available in LaTeX as codice_1 and codice_2.
Practicality of switching over.
Converting the current numbering system to dozenal system is currently impractical. According to dozenalist Donald Goodman, currency and finance would be reliably the first area to see the conversion, followed by an organized educational campaign. Goodman told the "Guardians" that it is only up to people who can use the dozenal system. But "as time goes on, and as more people learn about dozenals, more people will use them; after a while, people won't want to use decimals anymore."

</doc>
<doc id="8401" url="https://en.wikipedia.org/wiki?curid=8401" title="David Hayes Agnew">
David Hayes Agnew

David Hayes Agnew (November 24, 1818 ‚Äì March 22, 1892) was an American surgeon.
Biography.
Agnew was born on November 24, 1818, Nobleville, Pennsylvania, (present-day Christiana) in Lancaster County, Pennsylvania, to Robert Agnew and the former Agnes Noble. He graduated from the medical department of the University of Pennsylvania in 1838, and a few years later set up in practice at Philadelphia and became a lecturer at the Philadelphia School of Anatomy. He married Margaret Irwin in 1841. He also helped found the Irwin & Agnew Iron Foundry in 1846.
In 1852, he bought and revived the Philadelphia School of Anatomy, where he continued to work through 1862. 
He was appointed surgeon at the Philadelphia Hospital in 1854 and was the founder of its pathological museum.
For 26 years (1863‚Äì1889) he was connected with the medical faculty of the medical school of the University of Pennsylvania, being elected professor of operative surgery in 1870 and professor of the principles and practice of surgery in the following year. From 1865 to 1884‚Äîexcept for a brief interval‚Äîhe was a surgeon at the Pennsylvania Hospital.
In 1889, he became the subject of the largest painting ever made by the Philadelphia artist Thomas Eakins, called "The Agnew Clinic", in which he is shown conducting a mastectomy operation before a gallery of students and doctors. The artist can also be found to the right of the painting.
During the American Civil War he was consulting surgeon in the Mower Army Hospital, near Philadelphia, and acquired considerable reputation for his operations in cases of gunshot wounds. He attended as operating surgeon when President Garfield was fatally wounded by the bullet of an assassin in 1881.
He was the author of several works, the most important being "The Principles and Practice of Surgery" (1878‚Äì1883). 
He died at Philadelphia on March 22, 1892, and is buried in West Laurel Hill Cemetery.

</doc>
<doc id="8402" url="https://en.wikipedia.org/wiki?curid=8402" title="Diving">
Diving

Diving is the sport of jumping or falling into water from a platform or springboard, usually while performing acrobatics. Diving is an internationally recognized sport that is part of the Olympic Games. In addition, unstructured and non-competitive diving is a recreational pastime.
Diving is one of the most popular Olympic sports with spectators. Competitors possess many of the same characteristics as gymnasts and dancers, including strength, flexibility, kinaesthetic judgment and air awareness. Some professional divers were originally gymnasts or dancers as both the sports have similar characteristics to diving.
History.
Plunging.
Although diving has been a popular pastime across the world since ancient times, the first modern diving competitions were held in England in the 1880s. The exact origins of the sport are unclear, though it likely derives from the act of diving at the start of swimming races. The 1904 book "Swimming" by Ralph Thomas notes English reports of plunging records dating back to at least 1865. The 1877 edition to "British Rural Sports" by John Henry Walsh makes note of a "Mr. Young" plunging 56 feet in 1870, and also states that 25 years prior, a swimmer named Drake could cover 53 feet.
The English Amateur Swimming Association (at the time called the Swimming Association of Great Britain) first started a "plunging championship" in 1883. The Plunging Championship was discontinued in 1937.
Fancy diving.
Diving into a body of water had also been a method used by gymnasts in Germany and Sweden since the early 19th century. The soft landing allowed for more elaborate gymnastic feats in midair as the jump could be made at a greater distance. This tradition evolved into 'fancy diving', while diving as a preliminary to swimming became known as 'Plain diving'.
In England, the practice of high diving ‚Äì diving from a great height ‚Äì gained popularity; the first diving stages were erected at the Highgate Ponds at a height of 15 feet in 1893 and the first world championship event, the National Graceful Diving Competition, was held there by the Royal Life Saving Society in 1895. The event consisted of standing and running dives from either 15 or 30 feet.
It was at this event that the Swedish tradition of fancy diving was introduced to the sport by the athletes Otto Hagborg and C F Mauritzi. They demonstrated their acrobatic techniques from the 10m diving board at Highgate Pond and stimulated the establishment of the Amateur Diving Association in 1901, the first organization devoted to diving in the world (later amalgamated with the Amateur Swimming Association). Fancy diving was formally introduced into the championship in 1903.
Olympic era.
Plain diving was first introduced into the Olympics at the 1904 event. The 1908 Olympics in London added 'fancy diving' and introduced elastic boards rather than fixed platforms. Women were first allowed to participate in the diving events for the 1912 Olympics in Stockholm.
In the 1928 Olympics, 'plain' and 'fancy' diving was amalgamated into one event ‚Äì 'Highboard Diving'. The diving event was first held indoors in the Empire Pool for the 1934 British Empire Games and 1948 Summer Olympics in London.
Competitive diving.
Most diving competitions consist of three disciplines: 1¬†m and 3¬†m springboards, and the platform. Competitive athletes are divided by gender, and often by age group. In platform events, competitors are allowed to perform their dives on either the five, seven and a half (generally just called seven), nine, or ten meter towers. In major diving meets, including the Olympic Games and the World Championships, platform diving is from the 10 meter height.
Divers have to perform a set number of dives according to established requirements, including somersaults and twists. Divers are judged on whether and how well they completed all aspects of the dive, the conformance of their body to the requirements of the dive, and the amount of splash created by their entry to the water. A possible score out of ten is broken down into three points for the takeoff (meaning the hurdle), three for the flight (the actual dive), and three for the entry (how the diver hits the water), with one more available to give the judges flexibility.
The raw score is multiplied by a difficulty factor, derived from the number and combination of movements attempted. The diver with the highest total score after a sequence of dives is declared the winner.
Synchronized diving.
Synchronized diving was adopted as an Olympic sport in 2000. Two divers form a team and perform dives simultaneously. The dives are identical. It used to be possible to dive opposites, also known as a pinwheel, but this is no longer part of competitive synchronized diving. For example, one diver would perform a forward dive and the other an inward dive in the same position, or one would do a reverse and the other a back movement. In these events, the diving would be judged both on the quality of execution and the synchronicity ‚Äì in timing of take-off and entry, height and forward travel.
Scoring the dive.
There are rules governing the scoring of a dive. Usually a score considers three elements of the dive: the approach, the flight, and the entry. The primary factors affecting the scoring are:
To reduce the subjectivity of scoring in major meets, panels of five or seven judges are assembled. If five judges then the highest and lowest scores are discarded and the middle three are summed and multiplied by the "degree of difficulty" (DD), which is determined from a combination of the moves undertaken, in which position and from what height. In major international events, there are seven judges in which case the highest and lowest scores are again discarded and the middle five are summed, then ratioed by , and multiplied by the DD, so as to provide consistent comparison with 5-judge events. Accordingly, it is extremely difficult for one judge to manipulate scores.
This seven-judge procedure has been modified as of the 2012 London Olympics: rather than eliminating one high and one low award and then reducing the total by as in previous international events, the two highest awards and the two lowest are disregarded, leaving three to be summed and multiplied by the difficulty rating.
There is a general misconception about scoring and judging. In serious meets, the absolute score is somewhat meaningless. It is the relative score, not the absolute score that wins meets. Accordingly, good judging implies consistent scoring across the dives. Specifically, if a judge consistently gives low scores for all divers, or consistently gives high scores for the same divers, the judging will yield fair relative results and will cause divers to place in the correct order. However, absolute scores have significance to the individual divers. Besides the obvious instances of setting records, absolute scores are also used for rankings and qualifications for higher level meets.
In synchronised diving events, there is a panel of seven, nine, or eleven judges; two or three to mark the execution of one diver, two or three to mark the execution of the other, and the remaining three or five to judge the synchronisation. The execution judges are positioned two on each side of the pool, and they score the diver which is nearer to them. The 2012 London Olympics saw the first use of eleven judges.
The score is computed similarly to the scores from other diving events, but has been modified starting with the 2012 London Olympics for the use of the larger judging panels. Each group of judges will have the highest and lowest scores dropped, leaving the middle score for each diver's execution and the three middle scores for synchronization. The total is then weighted by and multiplied by the DD. The result is that the emphasis is on the synchronization of the divers.
The synchronisation scores are based on:
The judges may also disqualify the diver for certain violations during the dive, including:
Competitive strategy.
To win dive meets, divers create a dive list in advance of the meet. To win the meet the diver must accumulate more points than other divers. Often, simple dives with low DDs will look good to spectators but will not win meets. The competitive diver will attempt the highest DD dives possible with which they can achieve consistent, high scores. If divers are scoring 8 or 9 on most dives, it may be a sign of their extreme skill, or it may be a sign that their dive list is not competitive, and they may lose the meet to a diver with higher DDs and lower scores.
In competition, divers must submit their lists beforehand, and once past a deadline (usually when the event is announced or shortly before it begins) they cannot change their dives. If they fail to perform the dive announced, even if they physically cannot execute the dive announced or if they perform a more difficult dive, they will receive a score of zero. Under exceptional circumstances, a redive may be granted, but these are exceedingly rare (usually for very young divers just learning how to compete, or if some event outside the diver's control has caused them to be unable to perform-such as a loud noise).
In the Olympics or other highly competitive meets, many divers will have nearly the same list of dives as their competitors. The importance for divers competing at this level is not so much the DD, but how they arrange their list. Once the more difficult rounds of dives begin it is important to lead off with a confident dive to build momentum. They also tend to put a very confident dive in front of a very difficult dive to ensure that they will have a good mentality for the difficult dive. Most divers have pre-dive and post-dive rituals that help them either maintain or regain focus. Coaches also play a role in this aspect of the sport. Many divers rely on their coaches to help keep their composure during the meet. In a large meet coaches are rarely allowed on the deck to talk to their athlete so it is common to see coaches using hand gestures or body movements to communicate.
There are some American meets which will allow changes of the position of the dive even after the dive has been announced immediately before execution, but these are an exception to the rules generally observed internationally.
Generally, NCAA rules allow for dives to be changed while the diver is on the board, but the diver must request the change directly after the dive is announced. This applies especially in cases where the wrong dive is announced. If the diver pauses during his or her hurdle to ask for a change of dive, it will be declared a balk (when the diver stops mid-hurdle) and the change of dive will not be permitted.
Under FINA law, no dive may be changed after the deadline for the dive-sheet to be submitted (generally a period ranging from one hour to 24 hours, depending on the rulings made by the event organiser).
It is the diver's responsibility to ensure that the dive-sheet is filled in correctly, and also to correct the referee or announcer before the dive if they describe it incorrectly. If a dive is performed which is as submitted but not as (incorrectly) announced, it is declared failed and scores zero according to a strict reading of the FINA law. But in practice, a re-dive would usually be granted in these circumstances.
Governance.
The global governing body of diving is FINA, which also governs swimming, synchronized swimming, water polo and open water swimming. Almost invariably, at national level, diving shares a governing body with the other aquatic sports.
This is frequently a source of political friction as the committees are naturally dominated by swimming officials who do not necessarily share or understand the concerns of the diving community. Divers often feel, for example, that they do not get adequate support over issues like the provision of facilities. Other areas of concern are the selection of personnel for the specialised Diving committees and for coaching and officiating at events, and the team selection for international competitions.
There are sometimes attempts to separate the governing body as a means to resolve these frustrations, but they are rarely successful. For example, in the UK the Great Britain Diving Federation was formed in 1992 with the intention of taking over the governance of Diving from the ASA (Amateur Swimming Association). Although it initially received widespread support from the diving community, the FINA requirement that international competitors had to be registered with their National Governing Body was a major factor in the abandonment of this ambition a few years later.
Since FINA refused to rescind recognition of the ASA as the British governing body for all aquatic sports including diving, this meant that the elite divers had to belong to ASA-affiliated clubs to be eligible for selection to international competition.
In the United States scholastic diving is almost always part of the school's swim team. Diving is a separate sport in Olympic and Club Diving. The NCAA will separate diving from swimming in special diving competitions after the swim season is completed.
Safety.
Despite the apparent risk, the statistical incidence of injury in supervised training and competition is extremely low.
The majority of accidents that are classified as 'diving-related' are incidents caused by individuals jumping from structures such as bridges or piers into water of inadequate depth. Many accidents also occur when divers do not account for rocks and logs in the water. Because of this many beaches and pools prohibit diving in shallow waters or when a lifeguard is not on duty.
After an incident in Washington in 1993, most US and other pool builders are reluctant to equip a residential swimming pool with a diving springboard so home diving pools are much less common these days. In the incident, 14-year-old Shawn Meneely made a "suicide dive" (his hands at his sides ‚Äì so his head hit the bottom first) in a private swimming pool and became a tetraplegic. The lawyers for the family, Jan Eric Peterson and Fred Zeder, successfully sued the diving board manufacturer, the pool builder, and the National Spa and Pool Institute over the inappropriate depth of the pool.
The NSPI had specified a minimum depth of 7¬†ft 6 in (2.29 m) which proved to be insufficient in the above case. The pool into which Meneely dived was not constructed to the published standards. The standards had changed after the diving board was installed on the non-compliant pool by the homeowner. But the courts held that the pool "was close enough" to the standards to hold NSPI liable. The multimillion-dollar lawsuit was eventually resolved in 2001 for US$6.6¬†million ($8¬†million after interest was added) in favor of the plaintiff. The NSPI was held to be liable, and was financially strained by the case. It filed twice for Chapter 11 bankruptcy protection and was successfully reorganized into a new swimming pool industry association.
In competitive diving, FINA takes regulatory steps to ensure that athletes are protected from the inherent dangers of the sport. For example, they impose restrictions according to age on the heights of platforms which divers may compete on.
Group D divers have only recently been allowed to compete on the tower. In the past, the age group could compete only springboard, to discourage children from taking on the greater risks of tower diving. Group D tower was introduced to counteract the phenomenon of coaches pushing young divers to compete in higher age categories, thus putting them at even greater risk.
However, some divers may safely dive in higher age categories to dive on higher platforms. Usually this occurs when advanced Group C divers wish to compete on the 10¬†m.
Points on pool depths in connection with safety:
Dive groups.
There are six "groups" into which dives are classified: "Forward, Back, Inward, Reverse, Twist," and "Armstand". The latter applies only to Platform competitions, whereas the other five apply to both Springboard and Platform.
Dive positions.
During the flight of the dive, one of four positions is assumed:
These positions are referred to by the letters A, B, C and D respectively.
Additionally, some dives can be started in a flying position. The body is kept straight with the arms extended to the side, and the regular dive position is assumed at about half the dive.
Difficulty is rated according to the Degree of Difficulty of the dives. Some divers may find pike easier in a flip than tuck, and most find straight the easiest in a front/back dive, although it is still rated the most difficult because of the risk of overrotation.
Dive numbers.
In competition, the dives are referred to by a schematic system of three- or four-digit numbers. The letter to indicate the position is appended to the end of the number.
The first digit of the number indicates the dive group as defined above.
For groups 1 to 4, the number consists of three digits and a letter of the alphabet. The third digit represents the number of half-somersaults. The second digit is either 0 or 1, with 0 representing a normal somersault, and 1 signifying a "flying" variation of the basic movement (i.e. the first half somersault is performed in the straight position, and then the pike or tuck shape is assumed). No flying dive has been competed at a high level competition for many years.
For example:
For Group 5, the dive number has 4 digits. The first digit indicates that it is a twisting dive. The second digit indicates the group (1‚Äì4) of the underlying movement; the third digit indicates the number of half-somersaults, and the fourth indicates the number of half-twists.
For example:
For Group 6 ‚Äì Armstand ‚Äì the dive number has either three or four digits: Three digits for dives without twist and four for dives with twists.
In non-twisting armstand dives, the second digit indicates the direction of rotation (0 = no rotation, 1 = forward, 2 = backward, 3 = reverse, 4 = inward) and the third digit indicates the number of half-somersaults. Inward-rotating armstand dives have never been performed, and are generally regarded as physically impossible.
For example:
For twisting Armstand dives, the dive number again has 4 digits, but rather than beginning with the number 5, the number 6 remains as the first digit, indicating that the "twister" will be performed from an Armstand. The second digit indicates the direction of rotation ‚Äì as above, the third is the number of half-somersaults, and the fourth is the number of half-twists:
e.g. 6243D ‚Äì armstand back double-somersault with one and a half twists in the free position
All of these dives come with DD (degree of difficulty) this is an indication of how difficult/complex a dive is. The score that the dive receives is multiplied by the DD (also known as tariff) to give the dive a final score. Before a diver competes they must decide on a "list" this is a number of optional dives and compulsory dives. The optionals come with a DD limit. this means that a diver must select X number of dives and the combined DD limit must be no more than the limit set by the competition/organisation etc.
Until the mid-1990s the tariff was decided by the FINA diving committee, and divers could only select from the range of dives in the published tariff table. Since then, the tariff is calculated by a formula based on various factors such as the number of twist and somersaults, the height, the group etc., and divers are free to submit new combinations. This change was implemented because new dives were being invented too frequently for an annual meeting to accommodate the progress of the sport.
Mechanics of diving.
At the moment of take-off, two critical aspects of the dive are determined, and cannot subsequently be altered during the execution. One is the trajectory of the dive, and the other is the magnitude of the angular momentum.
The speed of rotation ‚Äì and therefore the total amount of rotation ‚Äì may be varied from moment to moment by changing the shape of the body, in accordance with the law of conservation of angular momentum.
The center of mass of the diver follows a parabolic path in free-fall under the influence of gravity (ignoring the effects of air resistance, which are negligible at the speeds involved).
Trajectory.
Since the parabola is symmetrical, the travel away from the board as the diver passes it is twice the amount of the forward travel at the peak of the flight. Excessive forward distance to the entry point is penalized when scoring a dive, but obviously an adequate clearance from the diving board is essential on safety grounds.
The greatest possible height that can be achieved is desirable for several reasons:
Control of rotation.
The magnitude of angular momentum remains constant throughout the dive, but since
and the moment of inertia is larger when the body has an increased radius, the speed of rotation may be increased by moving the body into a compact shape, and reduced by opening out into a straight position.
Since the tucked shape is the most compact, it gives the most control over rotational speed, and dives in this position are easier to perform. Dives in the straight position are hardest, since there is almost no scope for altering the speed, so the angular momentum must be created at take-off with a very high degree of accuracy. (A small amount of control is available by moving the position of the arms and by a slight hollowing of the back).
The opening of the body for the entry does not stop the rotation, but merely slows it down. The vertical entry achieved by expert divers is largely an illusion created by starting the entry slightly short of vertical, so that the legs are vertical as they disappear beneath the surface. A small amount of additional tuning is available by 'entry save' techniques, whereby underwater movements of the upper body and arms against the viscosity of the water affect the position of the legs.
Twisting.
Dives with multiple twists and somersaults are some of the most spectacular movements, as well as the most challenging to perform.
The rules state that twisting 'must not be generated manifestly on take-off'. Consequently, divers must use some of the somersaulting angular momentum to generate twisting movements. The physics of twisting can be explained by looking at the components of the angular momentum vector.
As the diver leaves the board, the total angular momentum vector is horizontal, pointing directly to the left for a forward dive for example. For twisting rotation to exist, it is necessary to tilt the body sideways after takeoff, so that there is now a small component of this horizontal angular momentum vector along the body's long axis. The tilt can be seen in the photo.
The tilting is done by the arms, which are outstretched to the sides just before the twist. When one arm is moved up and the other is moved down (like turning a big steering wheel), the body reacts by tilting to the side, which then begins the twisting rotation. At the completion of the required number of twist rotations, the arm motion is reversed (the steering wheel is turned back), which removes the body's tilt and stops the twisting rotation.
An alternative explanation is that the moving arms have precession torque on them which set the body into twisting rotation. Moving the arms back produces opposite torque which stops the twisting rotation.
Entry.
The rules state that the body should be vertical, or nearly so, for entry. Strictly speaking, it is physically impossible to achieve a literally vertical position throughout the entry as there will inevitably still be some rotational momentum while the body is entering the water. Divers therefore attempt to create the illusion of being vertical, especially when performing rapidly rotating multiple somersault movements. For back entries, one technique is to allow the upper body to enter slightly short of vertical so that the continuing rotation leaves the final impression of the legs entering vertically. This is called "Pike save". Another is to use "knee save" movements of scooping the upper body underwater in the direction of rotation so as to counteract the rotation of the legs.
The arms must be beside the body for feet-first dives, which are typically competed only on the 1m springboard and only at fairly low levels of 3m springboard, and extended forwards in line for "head-first" dives, which are much more common competitively. It used to be common for the hands to be interlocked with the fingers extended towards the water, but a different technique has become favoured during the last few decades. Now the usual practice is for one hand to grasp the other with palms down to strike the water with a flat surface. This creates a vacuum between the hands, arms and head which, with a vertical entry, will pull down and under any splash until deep enough to have minimal effect on the surface of the water (the so-called "rip entry").
Once a diver is completely under the water they may choose to roll or scoop in the same direction their dive was rotating to pull their legs into a more vertical position. Apart from aesthetic considerations, it is important from a safety point of view that divers reinforce the habit of rolling in the direction of rotation, especially for forward and inward entries. Especially when diving from the higher levels, attempting to re-surface in the opposite direction can cause hyperextention back injuries.
By country.
United States.
Summer diving.
In the United States, summer diving is usually limited to one meter diving at community or country club pools. Some pools organize to form intra-pool competitions. These competitions are usually designed to accommodate all school-age children. One of the largest and oldest summer leagues in the United States is found in the Northern Virginia area where teams from 47 pools compete against each other every summer. NVSL-Dive annually holds the Wally Martin 3-Meter Championship and concludes the season with its Individual All Stars Championship. In addition, NVSL-Dive annually hosts the largest one-day dive meet in the world, with over 350 developmental divers in NVSL's "Cracker Jack" Invitational! Champions from each of these events have gone on to compete at the collegiate and Olympic levels.
High school diving.
In the United States scholastic diving at the high school level is usually limited to one meter diving (but some schools use three meter springboards.). Scores from those one meter dives contribute to the swim team's overall score. High school diving and swimming concludes their season with a state competition. Depending on the state and the number of athletes competing in the state, certain qualifications must be achieved to compete in the state's championship meet. There are often regional championships and district championships which are necessary to compete in before reaching the state meet to narrow the field to only the most competitive athletes. Most state championship meets consist of eleven dives. The eleven dives are usually split up between two categories: five required (voluntary) dives and six optional dives.
Club diving.
In the United States, pre-college divers interested in learning one and three meter or platform diving should consider a club sanctioned by either USA Diving or AAU Diving. In USA Diving, Future Champions is the entry level or novice diver category with 8 levels of competition. From Future Champions, divers graduate to "Junior Olympic", or JO. JO divers compete in age groups at inter-club competitions, at invitationals, and if qualified, at regional, zone and national competitions. Divers over the age of 19 years of age cannot compete in these events as a JO diver.
USA Diving sanctions the Winter Nationals championship with one, three meter, and platform events. In the summer USA Diving sanctions the Summer Nationals including all three events with both Junior and Senior divers. USA Diving is sanctioned by the United States Olympic Committee to select team representatives for international diving competitions including the World Championships and Olympic Games.
AAU Diving sanctions one national event per year in the summer. AAU competes on the one, three, and tower to determine the All-American team.
College diving.
In the United States scholastic diving at the college level requires one and three meter diving. Scores from the one and three meter competition contribute to the swim team's overall meet score. College divers interested in tower diving may compete in the NCAA separate from swim team events. NCAA Divisions II and III do not usually compete platform; if a diver wishes to compete platform in college, he or she must attend a Division I school.
Each division also has rules on the number of dives in each competition. Division II schools compete with 10 dives in competition whereas Division III schools compete with 11. Division I schools only compete with 6 dives in competition. These 6 dives consist of either 5 optionals and 1 voluntary, or 6 optionals. If the meet is a 5 optional meet, then the divers will perform 1 optional from each category (Front, Back, Inward, Reverse, and Twister) and then 1 voluntary from the category of their choice. The voluntary in this type of meet is always worth a DD (Degree of Difficulty) of 2.0 even if the real DD is worth more or less on a DD sheet. In a 6 optional meet, the divers will yet again perform one dive from each category, but this time they will perform a 6th optional from the category of their choosing, which is worth its actual DD from the DD sheet.
The highest level of collegiate competition is the NCAA Division 1 Swimming and Diving Championship. Events at the championship include 1 meter springboard, 3 meter springboard, and platform, as well as various swimming individual and relay events. The points scored by swimmers and divers are combined to determine a team swimming & diving champion. To qualify for a diving event at the NCAA championships, a competitor must first finish in the top three at one of five zone championships, which are held after the various conference championship meets. A diver who scores at least 310 points on the 3 meter springboard and 300 points on the 1 meter springboard in a 6 optional meet can participate in the particular zone championship corresponding to the geographic region in which his or her school lies.
A number of colleges and universities offer scholarships to men and women who have competitive diving skills. These scholarships are usually offered to divers with age-group or club diving experience.
The NCAA limits the number of years a college student can represent any school in competitions. The limit is four years, but could be less under certain circumstances.
Masters' Diving.
Divers who continue diving past their college years can compete in Masters' Diving programs. Masters' diving programs are frequently offered by college or club programs.
Masters' Diving events are normally conducted in age-groups separated by five or ten years, and attract competitors of a wide range of ages and experience (many, indeed, are newcomers to the sport); the oldest competitor in a Masters' Diving Championship was Viola Krahn, who at the age of 101 was the first person in any sport, male or female, anywhere in the world, to compete in an age-group of 100+ years in a nationally organized competition.
Britain.
In Britain, diving competitions on all boards run throughout the year. National Masters' Championships are held two or three times per year.
Republic of Ireland.
In the Republic of Ireland facilities are limited to one pool at the National Aquatic Centre in Dublin.
National championships.
National championships take place late in the year, usually during November. The competition is held at the National Aquatic Centre in Dublin and consists of four events:
Canada.
Most provincial level competitions consist of events for 6 age groups (Groups A, B, C, D, E, and Open) for both genders on each of the three board levels. These age groups roughly correspond to those standardized by FINA, with the addition of a youngest age group for divers 9 and younger, Group E, which does not compete nationally and does not have a tower event (although divers of this age may choose to compete in Group D). The age group Open is so called because divers of any age, including those over 18, may compete in these events, so long as their dives meet a minimum standard of difficulty.
Although Canada is internationally a fairly strong country in diving, the vast majority of Canadian high schools and universities do not have diving teams, and many Canadian divers accept athletic scholarships from American colleges.
Adult divers who are not competitive at an elite level may compete in masters diving. Typically, masters are either adults who never practiced the sport as children or teenagers, or former elite athletes who have retired but still seek a way to be involved in the sport. Many diving clubs have masters teams in addition to their primary competitive ones, and while some masters dive only for fun and fitness, there are also masters competitions, which range from the local to world championship level.
National championships.
Divers can qualify to compete at the age group national championships, or junior national championships, in their age groups as assigned by FINA up to the age of 18. This competition is held annually in July. Qualification is based on achieving minimum scores at earlier competitions in the season, although athletes who place very highly at a national championship will be automatically qualified to compete at the next. Divers must qualify at two different competitions, at least one of which must be a level 1 competition, i.e. a competition with fairly strict judging patterns. Such competitions include the Polar Bear Invitational in Winnipeg, the Sting in Victoria, and the Alberta Provincial Championships in Edmonton or Calgary. The qualifying scores are determined by DPC according to the results of the preceding year's national competition, and typically do not have much variation from year to year.
Divers older than 18, or advanced divers of younger ages, can qualify for the senior national championships, which are held twice each year, once roughly in March and once in June or July. Once again, qualification is based on achieving minimum scores at earlier competitions (in this case, within the 12 months preceding the national championships, and in an Open age group event), or high placements in previous national championships or international competitions. It is no longer the case that divers may use results from age group events to qualify for senior nationals, or results from Open events to qualify for age group nationals.
Non-competitive diving.
Diving is also popular as a non-competitive activity. Such diving usually emphasizes the airborne experience, and the height of the dive, but does not emphasize what goes on once the diver enters the water. The ability to dive underwater can be a useful emergency skill, and is an important part of watersport and navy safety training. Entering water from a height is an enjoyable leisure activity, as is underwater swimming.
Such non-competitive diving can occur indoors and outdoors. Outdoor diving typically takes place from cliffs or other rock formations either into fresh or salt water. However, man-made diving platforms are sometimes constructed in popular swimming destinations. Outdoor diving requires knowledge of the water depth and currents as conditions can be dangerous.
High Diving.
A recently developing section of the sport is "High Diving" (e.g. see 2013 World Aquatics Championships), conducted in open air locations, usually from improvised platforms up to high (as compared with as used in Olympic and World Championship events). Entry to the water is invariably feet-first to avoid the risk of injury that would be involved in head-first entry from that height. The final half-somersault is almost always performed backwards, enabling the diver to spot the entry point and control their rotation.

</doc>
<doc id="8406" url="https://en.wikipedia.org/wiki?curid=8406" title="Dative case">
Dative case

The dative case (abbreviated , or sometimes when it is a core argument) is a grammatical case generally used to indicate the noun to which something is given, as in "Maria gave Jacob a drink". Here, Jacob is an indirect dative.
In general, the dative marks the indirect object of a verb, although in some instances, the dative is used for the direct object of a verb pertaining directly to an act of giving something. This may be a tangible object (e.g., "a book" or "a tapestry"), or an intangible abstraction (e.g., "an answer" or "help").
Sometimes the dative has functions unrelated to giving. In Scottish Gaelic and Irish, the term "dative case" is used in traditional grammars to refer to the prepositional case-marking of nouns following simple prepositions and the definite article. In Georgian, the dative case also marks the subject of the sentence with some verbs and some tenses. This is called the dative construction.
The dative was common among early Indo-European languages and has survived to the present in the Balto-Slavic branch and the Germanic branch, among others. It also exists in similar forms in several non-Indo-European languages, such as the Uralic family of languages, and Altaic languages. In some languages, the dative case has assimilated the functions of other now-extinct cases. In Ancient Greek, the dative has the functions of the Proto-Indo-European locative and instrumental as well as those of the original dative.
Under the influence of English, which uses the preposition "to" for both indirect objects ("give to") and directions of movement ("go to"), the term "dative" has sometimes been used to describe cases that in other languages would more appropriately be called lative.
Etymology.
"Dative" comes from Latin "cƒÅsus datƒ´vus" ("case for giving"), a translation of Greek Œ¥ŒøœÑŒπŒ∫·Ω¥ œÄœÑ·ø∂œÉŒπœÇ, "dotikƒì pt√¥sis" ("inflection for giving"), from its use with the verb "did√≥nai" "to give". Dionysius Thrax in his Art of Grammar also refers to it as "epistaltikƒìÃÅ" "for sending (a letter)", from the verb "epist√©ll≈ç" "send to", a word from the same root as epistle.
English.
The Old English language, current until approximately sometime after the time of the Norman Conquest in 1066, had a dative case; however, the English case system gradually fell into disuse during the Middle English period, when in pronouns, the accusative and dative merged into a single oblique case that was also used for all prepositions. This conflation of case in Middle and Modern English has led most modern grammarians to discard the "accusative" and "dative" labels as obsolete, often using the term "objective" for oblique.
Set expressions.
While the dative case is no longer very common in modern English usage, it survives in a few set expressions. One good example is the word "methinks", with the meaning "it seems to me". It survives in this fixed form from the days of Old English (having undergone, however, phonetic changes with the rest of the language), in which it was constructed as "" + "me" (the dative case of the personal pronoun) + "thinks" (i.e., "seems", < Old English thyncan, "to seem", a verb closely related to the verb thencan, "to think", but distinct from it in Old English; later it merged with "think" and lost this meaning).
The dative case also survives, albeit rarely, in the ethic dative, used to express one's interest in a matter. This only occurs with pronouns. For instance, in the phrase, "cry me a river," "me" is used not only to express the recipient of the action but the form is used sarcastically in American English to express the speaker's disinterest in the action.
Relic pronouns.
The pronoun whom is a remnant of the dative case in English, descending from the Old English dative pronoun "hwƒÅm" (as opposed to the nominative "who", which descends from Old English "hwƒÅ") ‚Äî though "whom" "also" absorbed the functions of the Old English accusative pronoun "hwone". It is also cognate to the word ""wem"" (the dative form of ""wer"") in German. The OED defines all classical uses of the word "whom" in situations where the indirect object "is not known" ‚Äì in effect, indicating the anonymity of the indirect object.
Likewise, some of the object forms of personal pronouns are remnants of Old English datives. For example, "him" goes back to the Old English dative "him" (accusative was "hine"), and "her" goes back to the dative "hire" (accusative was "hƒ´e"). These pronouns are not proper datives anymore in modern English, because they are also used for functions of the accusative.
Modern English.
In Modern English, an indirect object is often expressed with a prepositional phrase of "to" or "for". If there is a direct object, the indirect object can be expressed by being placed between the verb and the direct object. For example, "He gave that to me" and "He built a snowman for me" are the same as "He gave me that" and "He built me a snowman". Here, the object pronoun "me" has the same function as a dative pronoun in a language that distinguishes accusative and dative cases.
German.
In general, the dative is used to mark the indirect object of a German sentence. For example:
In English, the first sentence may be rendered: "I sent "the man" the book." The indirect object here is marked by standing in front of the direct object. The normal word order in German is also to put the dative in front of the accusative (as in the example above). However, since the German dative is marked in form, it can also be put "after" the accusative: "Ich schickte das Buch dem Mann(e). The (e)" after "Mann" and "Kind" signifies a now largely archaic -e ending for certain nouns in the dative (known in German as the "Dativ-e"). It survives today almost exclusively in set phrases such as "zu Hause," "im Zuge," and "am Tage," as well as in occasional usage in formal prose, poetry, and songs.
Some masculine nouns (and one neuter noun, "Herz"), referred to as "weak nouns" or "n-nouns", take an -n or -en in the dative singular and plural. Many are masculine nouns ending in -e in the nominative (such as "Name," "Beamte," and "Junge"), although not all such nouns follow this rule. Many also, whether or not they fall into the former category, refer to people, animals, professions, or titles; exceptions to this include the aforementioned "Herz" and "Name," as well as "Buchstabe," "Friede," "Obelisk," "Planet," and others.
Certain German prepositions require the dative: "aus", "au√üer", "bei", "entgegen", "mit", "nach", "seit", "von", "zu", and "gegen√ºber". Other prepositions ("an", "auf", "hinter", "in", "neben", "√ºber", "unter", "vor", and "zwischen") may be used with dative (indicating current location), or accusative (indicating direction toward something). "Das Buch liegt auf dem Tisch(e)" (dative: the book is lying on the table), but "Ich lege das Buch auf den Tisch" (accusative: I put the book onto the table).
In addition the four prepositions "wegen" ("because of"), "trotz" ("in spite of"), "statt" ("in place of") and "w√§hrend" ("during"), which require the genitive in modern formal language, are most commonly used with the dative in colloquial German. For example, "because of the weather" is expressed as "wegen dem Wetter" instead of the formally correct "wegen des Wetters". Other prepositions requiring the genitive in formal language, are combined with "von" ("of") in colloquial style, e.g. "au√üerhalb vom Garten" instead of "au√üerhalb des Gartens" ("outside the garden").
Note that the concept of an indirect object may be rendered by a prepositional phrase. In this case, the noun's or pronoun's case is determined by the preposition, NOT by its function in the sentence. Consider this sentence: 
Here, the subject, "Ich", is in the nominative case, the direct object, "das Buch", is in the accusative case, and "zum Verleger" is in the dative case, since "zu" always requires the dative ("zum" is a contraction of "zu" + "dem"). However:
In this sentence, "Freund" is the indirect object, but, because it follows "an" (direction), the accusative is required, not the dative.
All of the articles change in the dative case.
Some German verbs require the dative for their direct objects. Common examples include "folgen", "helfen", and "antworten". In each case, the direct object of the verb is rendered in dative. For example:
These verbs cannot be used in normal passive constructions, because German allows these only for verbs with accusative objects. It is therefore ungrammatical to say: *"Ich werde geholfen." "I am helped." Instead a special construction called "impersonal passive" must be used: "Mir wird geholfen", literally: "To me is helped." A colloquial (non-standard) and rarely used way to form the passive voice for dative verbs is the following: "Ich kriege geholfen", or: "Ich bekomme geholfen", literally: "I get helped". The use of the verb "to get" here reminds us that the dative case has something to do with giving and receiving. In German, help is not something you "perform on" somebody, but rather something you "offer" them.
The dative case is also used with reflexive ("sich") verbs when specifying what part of the self the verb is being done to:
Cf. the respective "accord in French: "Les enfants se sont lav√©s" ("the children have washed themselves") vs. "Les enfants se sont lav√©" "les mains" ("... their hands").
German can use two datives to make sentences like: "Sei mir meinem Sohn(e) gn√§dig!" "For my sake, have mercy on my son!" Literally: "Be to me to my son merciful." The first dative "mir" ("to me") expresses the speaker's commiseration (much like the "dativus ethicus" in Latin, see below). The second dative "meinem Sohn(e)" ("to my son") names the actual object of the plea. Mercy is to be given "to" the son "for" or "on behalf of" his mother/father.
Adjective endings also change in the dative case. There are three possible inflection possibilities depending on what precedes the adjective. They most commonly use "weak inflection" when preceded by a definite article (the), "mixed inflection" after an indefinite article (a/an), and "strong inflection" when a quantity is indicated (many green apples).
Latin.
Except the main case ("Dativus"), there are several other kinds:
Greek.
Ancient.
In addition to its main function as the "dativus", the dative case has other functions in Classical Greek: (The chart below uses the Latin names for the types of dative; the Greek name for the dative is Œ¥œâœÑŒπŒ∫ŒÆ œÄœÑœéœÉŒ∑, like its Latin equivalent, derived from the verb "to give"; in Ancient Greek, Œ¥ŒØŒ¥œâŒºŒπ.)
The articles in the Greek dative are
Nouns as well as adjectives receive suffixes. These vary according to the declension.
Modern.
The dative case, strictly speaking, no longer exists in Modern Greek, except in fossilized expressions like Œ¥œåŒæŒ± œÑœâ ŒòŒµœé (from the ecclesiastical œÑ·ø∑ ŒòŒµ·ø∑ Œ¥œåŒæŒ±, "Glory to God") or ŒµŒΩ œÑŒ¨ŒæŒµŒπ (·ºëŒΩ œÑŒ¨ŒæŒµŒπ, lit. "in order", i.e. "all right" or "OK"). Otherwise, most of the functions of the dative have been subsumed in the accusative.
Slavic languages.
In Russian, the dative case is used for indicating the indirect object of an action (that to which something is given, thrown, read, etc.). In the instance where a person is the goal of motion, dative is used instead of accusative to indicate motion toward. This is usually achieved with the preposition "Œ∫" + destination in dative case; "–ö –≤—Ä–∞—á—É", meaning "to the doctor."
Dative is also the necessary case taken by certain prepositions when expressing certain ideas. For instance, when the preposition "–ø–æ" is used to mean "along," its object is always in dative case, as in "–ü–æ –±–æ–∫–∞–º", meaning "along the sides."
Other Slavic languages apply the dative case (and the other cases) more or less the same way as does Russian, some languages may use the dative in other ways. The following examples are from Polish:
Some other kinds of dative use as found in the Serbo-Croatian language are: "Dativus finalis" (Titaniku u pomoƒá "to Titanic's rescue"), "Dativus commodi/incommodi" (Operi svojoj majci suƒëe "Wash the dishes for your mother"), "Dativus possessivus" (Ovcama je dlaka gusta "Sheep's hair is thick"), "Dativus ethicus" (≈†ta mi radi Boni? "What is Boni doing? (I am especially interested in what it is)") and Dativus auctoris (Izgleda mi okej "It seems okay to me").
Unusual in other Indo-European branches but common among Slavic languages, endings of nouns and adjectives are different based on grammatical function. Other factors are gender and number. In some cases, the ending may not be obvious, even when those three factors (function, gender, number) are considered. For example, in Polish, 'syn' ("son") and 'ojciec' ("father") are both masculine singular nouns, yet appear as "syn ‚Üí synowi" and "ojciec ‚Üí ojcu" in the dative.
Baltic languages.
Both Lithuanian and Latvian have a distinct dative case in the system of nominal declensions.
Lithuanian nouns preserve Indo-European inflections in the dative case fairly well: (o-stems) vaikas -> sg. vaikui, pl. vaikams; (ƒÅ-stems) ranka -> sg. rankai, pl. rankoms; (i-stems) viltis -> sg. vilƒçiai, pl. viltims; (u-stems) s≈´nus -> sg. s≈´nui, pl. s≈´nums; (consonant stems) vanduo -> sg. vandeniui, pl. vandenims.
Adjectives in the dative case receive pronominal endings (this might be the result of a more recent development): tas geras vaikas -> sg. tam geram vaikui, pl. tiems geriems vaikams.
The dative case in Latvian underwent further simplifications - the original masculine endings of "both" nouns and adjectives have been replaced with pronominal inflections: tas vƒ´rs -> sg. tam vƒ´ram, pl. vƒ´riem. Also, the final "s" in all Dative forms has been dropped. The only exception is personal pronouns in the plural: mums (to us), jums (to you). Note that in colloquial Lithuanian the final "s" in the dative is often omitted, as well: time geriem vaikam.
In both Latvian and Lithuanian, the main function of the dative case is to render the indirect object in a sentence: (lt) a≈° duodu vyrui knygƒÖ; (lv) es dodu vƒ´ram grƒÅmatu - "I am giving a book to the man".
The dative case can also be used with gerundives to indicate an action preceding or simultaneous with the main action in a sentence: (lt) jam ƒØƒójus, visi atsistojo - "when he walked in, everybody stood up", lit. "to him having walked in, all stood up"; (lt) jai miegant, visi dirbo - "while she slept, everybody was working", lit. "to her sleeping, all were working".
In modern standard Lithuanian, Dative case is not required by prepositions, although in many dialects it is done frequently: (dial.) iki (+D) ≈°iai dienai, (stand.) iki (+G) ≈°ios dienos - "up until this day".
In Latvian, the dative case is taken by several prepositions in the singular and all prepositions in the plural (due to peculiar historical changes): sg. bez (+G) tevis "(without thee)" ~ pl. bez (+D) jums "(without you)"; sg. pa (+A) ceƒºu "(along the road)" ~ pl. pa (+D) ceƒºiem "(along the roads)".
Armenian.
In modern Eastern Armenian, the dative is attained by adding any article to the genitive:
"dog" = ’∑’∏÷Ç’∂
GEN > ’∑’°’∂ "(of the dog; dog's)" with no articles
DAT > ’∑’°’∂’® or ’∑’°’∂’∂ "(to the dog)" with definite articles (-’∂ if preceding a vowel)
DAT > ’¥’´ ’∑’°’∂ "(to a dog)" with indefinite article
DAT > ’∑’°’∂’Ω "(to my dog)" with 1st person possessive article
DAT > ’∑’°’∂’§ "(to your dog)" with 2nd person possessive article
There is a general tendency to view -’´’∂ as the standard dative suffix, but only because that is its most productive (and therefore common) form. The suffix -’´’∂ as a dative marker is nothing but the standard, most common, genitive suffix -’´ accompanied by the definite article -’∂. But the dative case encompasses indefinite objects as well, which will not be marked by -’´’∂:
Definite DAT > ‘µ’Ω ’£’´÷Ä÷Ñ’® ’ø’æ’•÷Å’´ ’ø’≤’°’µ’´’∂: "(I gave the book to the boy)"
Indefinite DAT> ‘µ’Ω ’£’´÷Ä÷Ñ’® ’ø’æ’•÷Å’´ ’¥’´ ’ø’≤’°’µ’´: "(I gave the book to a boy)"
The main function of the dative marking in Armenian is to indicate the receiving end of an action, more commonly the indirect object which in English is preceded by the preposition "to". In the use of "giving" verbs like "give, donate, offer, deliver, sell, bring..." the dative marks the recipient. With communicative verbs like "tell, say, advise, explain, ask, answer..." the dative marks the listener. Other verbs whose indirect objects are marked by the dative case in Armenian are "show, reach, look, approach..."
Eastern Armenian also uses the dative case to mark the time of an event, in the same way English uses the preposition "at", as in "Meet me at nine o' clock."
Sanskrit.
The dative case is known as the "fourth case" (chaturthi-vibhakti) in the usual procedure in the declension of nouns. Its use is mainly for the indirect object as Sanskrit has seven other cases including an instrumental. The term "dative" is grammatically similar to the Sanskrit word "datta". "Datta" means "gift" or "the act of giving".
Non-Indo-European languages.
Hungarian.
As with many other languages, the dative case is used in Hungarian to show the indirect object of a verb. For example, "D√°nielnek adtam ezt a k√∂nyvet" (I gave this book to D√°niel).
It has two suffixes, -nak and -nek; the correct is selected by vowel harmony. The personal dative pronouns follow the -nek version: "nekem", "neked", etc.
This case is also used to express "for" in certain circumstances, such as "I bought a gift for Mother".
In possessive constructions the nak/nek endings are also used but this is NOT the dative form (rather, the attributive or possessive case)
Finnish.
Finnish does not have a separate dative case. However, the allative case can fulfill essentially the same role as dative, beyond its primary meaning of directional movement (that is, going somewhere or approaching someone). For example: "He lahjoittivat kaikki rahansa k√∂yhille (They donated all their money to the poor.)
Tsez.
In the Northeast Caucasian languages, such as Tsez, the dative also takes the functions of the lative case in marking the direction of an action. By some linguists, they are still regarded as two separate cases in those languages, although the suffixes are exactly the same for both cases. Other linguists list them separately only for the purpose of separating syntactic cases from locative cases. An example with the ditransitive verb "show" (literally: "make see") is given below:
The dative/lative is also used to indicate possession, as in the example below, because there is no such verb as "to have".
As in the examples above, the dative/lative case usually occurs in combination with another suffix as poss-lative case; this should not be regarded as a separate case, however, as many of the locative cases in Tsez are constructed analytically; hence, they are, in fact, a combination of two case suffixes. See Tsez language#Locative case suffixes for further details.
Verbs of perception or emotion (like "see", "know", "love", "want") also require the logical subject to stand in the dative/lative case. Note that in this example the "pure" dative/lative without its POSS-suffix is used.

</doc>
<doc id="8407" url="https://en.wikipedia.org/wiki?curid=8407" title="Dodecahedron">
Dodecahedron

In geometry, a dodecahedron (Greek , from "d≈çdeka" "twelve" + "h√©dra" "base", "seat" or "face") is any polyhedron with twelve flat faces. The most familiar dodecahedron is the regular dodecahedron, which is a Platonic solid. There are also three regular star dodecahedra, which are constructed as stellations of the convex form. All of these have icosahedral symmetry, order 120.
The pyritohedron is an irregular pentagonal dodecahedron, having the same topology as the regular one but pyritohedral symmetry while the tetartoid has tetrahedral symmetry. The rhombic dodecahedron, seen as a limiting case of the pyritohedron has octahedral symmetry. The elongated dodecahedron and trapezo-rhombic dodecahedron variations, along with the rhombic dodecahedra are space-filling. There are a large number of other dodecahedra.
Pentagonal dodecahedron.
The convex regular dodecahedron is one of the five regular Platonic solids and can be represented by its Schl√§fli symbol {5, 3}.
The dual polyhedron is the regular icosahedron {3, 5}, having five equilateral triangles around each vertex.
In crystallography, two important dodecahedra can occur as crystal forms in some symmetry classes of the cubic crystal system that are topologically equivalent to the regular dodecahedron but less symmetrical: the pyritohedron with pyritohedral symmetry, and the tetartoid with tetrahedral symmetry:
Pyritohedron.
A pyritohedron is a dodecahedron with pyritohedral (Th) symmetry. Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not constrained to be regular, and the underlying atomic arrangement has no true fivefold symmetry axes. Its 30 edges are divided into two sets ‚Äì containing 24 and 6 edges of the same length. The only axes of rotational symmetry are three mutually perpendicular twofold axes and four threefold axes..
Although regular dodecahedra do not exist in crystals, the pyritohedron form occurs in the crystals of the mineral pyrite, and it may be an inspiration for the discovery of the regular Platonic solid form. Note that the true regular dodecahedron can occur as a shape for quasicrystals with icosahedral symmetry, which includes true fivefold rotation axes.
Crystal pyrite.
Its name comes from one of the two common crystal habits shown by pyrite, the other one being the cube.
Cartesian coordinates.
The coordinates of the eight vertices of the original cube are:
The coordinates of the 12 vertices of the cross-edges are:
where "h" is the height of the wedge-shaped "roof" above the faces of the cube. When "h"¬†=¬†1, the six cross-edges degenerate to points and a rhombic dodecahedron is formed. When "h"¬†=¬†0, the cross-edges are absorbed in the facets of the cube, and the pyritohedron reduces to a cube. When "h"¬†=¬†, the inverse of the golden ratio, the result is a regular dodecahedron.
[[File:Compound_pyritohedron_and_dual.png|thumb|left|Pyritohedra in dual positions
<BR>]]A reflected pyritohedron is made by swapping the nonzero coordinates above. The two pyritohedra can be superimposed to give the compound of two dodecahedra as seen in the image here.
Geometric freedom.
The pyritohedron has a geometric degree of freedom with limiting cases of a cubic convex hull at one limit of colinear edges, and a rhombic dodecahedron as the other limit as 6 edges are degenerated to length zero. The regular dodecahedron represents a special intermediate case where all edges and angles are equal.
Tetartoid.
A tetartoid (also tetragonal pentagonal dodecahedron, pentagon-tritetrahedron, and tetrahedric pentagon dodecahedron) is a dodecahedron with chiral tetrahedral symmetry (T). Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not regular and the figure has no fivefold symmetry axes.
Although regular dodecahedra do not exist in crystals, the tetartoid form does. The name tetartoid comes from the Greek root for one-fourth because it has one fourth of full octahedral symmetry, and half of pyritohedral symmetry. The mineral cobaltite can have this symmetry form.
Its topology can be as a cube with square faces bisected into 2 rectangles like the pyritohedron, and then the bisection lines are slanted retaining 3-fold rotation at the 8 corners.
Cartesian coordinates.
The following points are vertices of a tetartoid pentagon under tetrahedral symmetry:
under the following conditions:
Variations.
It can be seen as a tetrahedron, with edges divided into 3 segments, along with a center point of each triangular face. In Conway polyhedron notation it can be seen as gT, a gyro tetrahedron.
Rhombic dodecahedron.
The "rhombic dodecahedron" is a zonohedron with twelve rhombic faces and octahedral symmetry. It is dual to the quasiregular cuboctahedron (an Archimedean solid) and occurs in nature as a crystal form. The rhombic dodecahedron packs together to fill space.
The "rhombic dodecahedron" can be seen as a degenerate pyritohedron where the 6 special edges have been reduced to zero length, reducing the pentagons into rhombic faces.
The rhombic dodecahedron has several stellations, the first of which is also a parallelohedral spacefiller.
Another important rhombic dodecahedron has twelve faces congruent to those of the rhombic triacontahedron, i.e. the diagonals are in the ratio of the golden ratio. It is also a zonohedron and was described by Bilinski in 1960. This figure is another spacefiller, and can also occur in non-periodic spacefillings along with the rhombic triacontahedron, the rhombic icosahedron and rhombic hexahedra.
Other dodecahedra.
There are 6,384,634 topologically distinct "convex" dodecahedra, excluding mirror images, having at least 8 vertices. (Two polyhedra are "topologically distinct" if they have intrinsically different arrangements of faces and vertices, such that it is impossible to distort one into the other simply by changing the lengths of edges or the angles between edges or faces.)
Topologically distinct dodecahedra (excluding pentagonal and rhombic forms)

</doc>
<doc id="8408" url="https://en.wikipedia.org/wiki?curid=8408" title="Darwin, Northern Territory">
Darwin, Northern Territory

Darwin 
is the capital city of the Northern Territory, Australia. Situated on the Timor Sea, Darwin is the largest city in the sparsely populated Northern Territory, with a population of 136,245. It is the smallest and most northerly of the Australian capital cities, and acts as the Top End's regional centre. Darwin was originally a pioneer outpost.
Darwin's proximity to South East Asia makes it an important Australian gateway to countries such as Indonesia and East Timor. The Stuart Highway begins in Darwin, ending at Port Augusta in South Australia. The city itself is built on a low bluff overlooking the harbour. Its suburbs spread out over some area, beginning at Lee Point in the north and stretching to Berrimah in the east. Past Berrimah, the Stuart Highway goes on to Darwin's satellite city, Palmerston, and its suburbs. The Darwin region, like the rest of the Top End, has a tropical climate, with a wet and a dry season. The city is noted for its consistently warm to hot climate, all throughout the year. Prone to cyclone activity during the wet season, Darwin experiences heavy monsoonal downpours and spectacular lightning shows. During the dry season, the city is met with blue skies and gentle sea breezes from the harbour.
The greater Darwin area is the ancestral home of the Larrakia people. On 9 September 1839, sailed into Darwin harbour during its surveying of the area. John Clements Wickham named the region "Port Darwin" in honour of their former shipmate Charles Darwin, who had sailed with them on the ship's previous voyage which had ended in October 1836. The settlement there became the town of Palmerston in 1869, and was renamed Darwin in 1911. The city has been almost entirely rebuilt twice, once due to Japanese air raids during World War II, and again after being devastated by Cyclone Tracy in 1974.
History.
Ancient history to the end of the 19th century.
The Aboriginal people of the Larrakia language group are the traditional custodians and the first inhabitants of the greater Darwin area. They had trading routes with Southeast Asia (see Macassan contact with Australia), and imported goods from as far afield as South and Western Australia. Established songlines penetrated throughout the country, allowing stories and histories to be told and retold along the routes.
The Dutch visited Australia's northern coastline in the 1600s, and created the first European maps of the area. This accounts for the Dutch names in the area, such as Arnhem Land and Groote Eylandt. The first British person to see Darwin harbour appears to have been Lieutenant John Lort Stokes of on 9 September 1839. The ship's captain, Commander John Clements Wickham, named the port after Charles Darwin, the British naturalist who had sailed with them both on the earlier second expedition of the "Beagle". In the early 1870s Darwin felt the effects of a gold rush at Pine Creek after employees of the Australian Overland Telegraph Line found gold while digging holes for telegraph poles.
In 1859 the colony of Queensland was excised from New South Wales and initially included the area of the Northern Territory. Four years later in 1863, the Northern Territory was annexed from Queensland by the colony of South Australia. On 5 February 1869, George Goyder, the Surveyor-General of South Australia, established a small settlement of 135 people at Port Darwin. Goyder named the settlement Palmerston, after the British Prime Minister Lord Palmerston. In 1870, the first poles for the Overland Telegraph were erected in Darwin, connecting Australia to the rest of the world. The discovery of gold by employees of the Australian Overland Telegraph Line digging holes for telegraph poles at Pine Creek in the 1880s spawned a gold rush which further boosted the young colony's development.
In early 1875 Darwin's European population had grown to approximately 300 because of the gold rush. On 17 February 1875 the left Darwin "en route" for Adelaide. The approximately 88 passengers and 34 crew (surviving records vary) included government officials, circuit-court judges, Darwin residents taking their first furlough, and miners. While travelling south along the north Queensland coast, the "Gothenburg" encountered a cyclone-strength storm and was wrecked on a section of the Great Barrier Reef. Only 22 men survived, while between 98 and 112 people perished. Many passengers who perished were Darwin residents and news of the tragedy severely affected the small community, which reportedly took several years to recover.
20th century begins.
Darwin became the city's official name in 1911.
The period between 1911 and 1919 was filled with political turmoil, particularly with trade union unrest, which culminated on 17 December 1918. Led by Harold Nelson, some 1000 demonstrators marched to Government House at Liberty Square in Darwin where they burnt an effigy of the Administrator of the Northern Territory John Gilruth and demanded his resignation. The incident became known as the 'Darwin Rebellion'. Their grievances were against the two main Northern Territory employers: Vestey's Meatworks and the federal government. Both Gilruth and the Vestey company left Darwin soon afterwards.
Around 10,000 Australian and other Allied troops arrived in Darwin at the outset of World War II, in order to defend Australia's northern coastline. On 19 February 1942 at 0957, 188 Japanese warplanes attacked Darwin in two waves. It was the same fleet that had bombed Pearl Harbor, though a considerably larger number of bombs were dropped on Darwin than on Pearl Harbor. The attack killed at least 243 people and caused immense damage to the town. These were by far the most serious attacks on Australia in time of war, in terms of fatalities and damage. They were the first of many raids on Darwin.
Despite this major attack, Darwin was further developed after the war, with sealed roads constructed connecting the region to Alice Springs in the south and Mount Isa in the south-east, and Manton Dam built in the south to provide the city with water. On Australia Day (26 January) 1959, Darwin was granted city status.
1970-present day.
On 25 December 1974, Darwin was struck by Cyclone Tracy, which killed 71 people and destroyed over 70% of the town's buildings, including many old stone buildings such as the Palmerston Town Hall, which could not withstand the lateral forces generated by the strong winds. After the disaster, 30,000 people of a then population of 46,000 were evacuated, in what turned out to be the biggest airlift in Australia's history. The town was subsequently rebuilt with newer materials and techniques during the late 1970s by the Darwin Reconstruction Commission, led by former Brisbane Lord Mayor Clem Jones. A satellite city of Palmerston was built south of Darwin in the early 1980s.
On 17 September 2003 the Adelaide‚ÄìDarwin railway was completed, with the opening of the Alice Springs-Darwin standard gauge line.
Geography.
Darwin lies in the Northern Territory, on the Timor Sea. The city proper occupies a low bluff overlooking Darwin Harbour, flanked by Frances Bay to the east and Cullen Bay to the west. The remainder of the city is flat and low-lying, and coastal areas are home to recreational reserves, extensive beaches, and excellent fishing.
Darwin is closer to the capitals of five other countries than to the capital of Australia: Darwin is away from Canberra. Dili (East Timor) is , Port Moresby (Papua New Guinea) is , Jakarta (Indonesia) is , Bandar Seri Begawan (Brunei) is , and Melekeok (Palau) is from Darwin.
Even Malaysia and Singapore are only slightly farther away at , as is Manila (Philippines) at , and Honiara (Solomon Islands) at . Ambon, Indonesia, is only away from Darwin.
Along with its importance as a gateway to Asia, Darwin also acts as an access point for the Kakadu National Park, Arnhem Land, and northerly islands such as Groote Eylandt and the Tiwi Islands. As the largest city in the area, it provides services for these remote settlements.
City and suburbs.
Darwin and its suburbs spread in an approximately triangular shape, with the older south-western suburbs‚Äîand the city itself‚Äîforming one corner, the newer northern suburbs in another, and the eastern suburbs, progressing towards Palmerston, forming the third.
The older part of Darwin is separated from the newer northern suburbs by Darwin International Airport and Royal Australian Air Force Base. Palmerston is a satellite city south of Darwin that was established in the 1980s and is one of the fastest growing municipalities in Australia. The rural areas of Darwin including Howard Springs, Humpty Doo and Berry Springs are experiencing strong growth.
Darwin's central business district is bounded by Daly Street in the north-west, McMinn Street in the north-east, Mitchell Street on the south-west and Bennett Street on the south-east. The CBD has been the focus of a number of major projects, including the billion dollar redevelopment of the Stokes Hill wharf waterfront area including a convention centre with seating for 1500 people and approximately of exhibition space. The development will also include hotels, residential apartments and public space. The city's main industrial areas are along the Stuart Highway going towards Palmerston, centred on Winnellie. The largest shopping precinct in the area is Casuarina Square.
The most expensive residential areas stand along the coast in suburbs such as Larrakeyah and Brinkin, despite the slight risk these low-lying regions face during cyclones and higher tides. The inner northern suburbs of Millner and Coconut Grove and the eastern suburb of Karama are home to lower-income households, although low-income Territory Housing units are scattered throughout the metropolitan area. The suburb of Lyon was an addition to the Northern Suburbs. Development and constructor took place in 2009 and 2010 and became home for a number of affluent Darwin residents and local/recently posted military families above the rank of Sergeant or Flying Officer.
Climate.
Darwin has a tropical savanna climate (K√∂ppen "Aw") with distinct wet and dry seasons and the average maximum temperature is remarkably similar all year round. The dry season runs from about May to September, during which nearly every day is sunny, and afternoon humidity averages around 30%.
The driest period of the year, seeing only approximately of monthly rainfall on average, is between May and September. In the coolest months of June and July, the daily minimum temperature may dip as low as , but very rarely lower, and a temperature lower than has never been recorded in the city centre. Outer suburbs away from the coast however can occasionally record temperatures as low as in the dry season. For an exceedingly lengthy 147¬†day period during the 2012 dry season, from 5 May to 29 September, Darwin recorded no precipitation whatsoever. Prolonged periods of no precipitation are common in the dry season in Northern Australia (particularly in the Northern Territory and northern regions of Western Australia) although a no-rainfall event of this extent is rare. The 3pm dewpoint average in the wet season is at around .
The highest temperature recorded in Darwin was on 17 October 1892 at the Darwin Post Office station, while the lowest was on 29 July 1942 at the Darwin Airport station, which is further from the coast and routinely records cooler temperatures than the post office station which is located in Darwin's CBD. The lowest maximum temperature on record was on 3 June 1904 while the highest minimum was on 18 January 1928.
The wet season is associated with tropical cyclones and monsoon rains. The majority of rainfall occurs between December and March (the southern hemisphere summer), when thunderstorms are common and afternoon relative humidity averages over 70 percent during the wettest months. It does not rain every day during the wet season, but most days have plentiful cloud cover; January averages under 6 hours of bright sunshine daily. Darwin's highest Bureau of Meteorology verified daily rainfall total is , which fell when Cyclone Carlos bore down on the Darwin area on 16 February 2011. February 2011 was also Darwin's wettest month ever recorded, with recorded for the month at the airport.
The hottest month is November, just before the onset of the main rain season. The heat index sometimes rises above , while the actual temperature is usually below , because of humidity levels that most would find uncomfortable. Because of its long dry season, Darwin has the second most daily average sunshine hours (8.4) of any Australian capital with the most sunshine from April to November; only Perth, Western Australia averages more (8.8). The sun passes directly overhead in mid October and mid February. Climatically Darwin has more in common with Manila than Sydney because it sits well inside the tropical zone.
Darwin occupies one of the most lightning-prone areas in Australia. On 31 January 2002 an early-morning squall line produced over 5,000 cloud-to-ground lightning strikes within a radius of Darwin alone ‚Äì about three times the amount of lightning that Perth, Western Australia, experiences on average in an entire year.
Demographics.
In 2006, the largest ancestry groups in Darwin were, Australian (42,221 or 36.9%), English (29,766 or 26%), Irish (9,561 or 8.3%), Scottish (7,815 or 6.8%), Chinese (3,502 or 3%), Greek (2,828 or 2.4%), and Italian (2,367 or 2%)
Darwin's population is notable for the highest proportional population of Indigenous Australians of any Australian capital city. In the 2006 census 10,259 (9.7 per cent) of Darwin's population was Aboriginal.
Darwin's population changed after the Second World War. Darwin, like many other Australian cities, experienced influxes from Europe, with significant numbers of Italians and Greeks during the 1960s and 1970s. Darwin also started to experience an influx from other European countries, which included the Dutch, Germans, and many others. A significant percentage of Darwin's residents are recent immigrants from South East Asia (Asian Australians were 9.3% of Darwin's population in 2001).
Darwin's population comprises people from many ethnic backgrounds. The 2006 Census revealed that the most common places of birth for overseas migrants were the United Kingdom (3.4 per cent), New Zealand (2.1 per cent), the Philippines (1.4 per cent) and East Timor (0.9 per cent). 18.3 percent of the city's population was born overseas, which is less than the Australian average of 22%.
Darwin has a youthful population with an average age of 33 years (compared to the national average of around 37 years) assisted to a large extent by the military presence and the fact that many people opt to retire elsewhere.
The most common languages spoken in Darwin after English are Greek, Italian, Indonesian, Vietnamese and Cantonese.
Religion.
Darwin is essentially a multicultural secular city, however, Christianity has the most adherents in Darwin with 56,613 followers accounting for 49.5 per cent of the population of the city. The largest denominations of Christianity are Roman Catholicism (24,538 or 21.5 per cent), Anglicanism (14,028 or 12.3 per cent) and Greek Orthodoxy (2,964 or 2.6 per cent). Buddhists, Muslims, Hindus and Jews account for 3.2 per cent of Darwin's population. There were 26,695 or 23.3 per cent of people professing no religion.
Population growth.
Darwin is one of the fastest growing capital cities in Australia, with an annual growth rate of 2.6 per cent since the 2006 census. In recent years, the Palmerston and Litchfield parts of the Darwin statistical division have recorded the highest growth in population of any Northern Territory local government area and by 2016 Litchfield could overtake Palmerston as the second largest municipality in metropolitan Darwin. It is predicted by 2021 that the combined population of both Palmerston and Litchfield would be 101,546 people.
Law and government.
The Darwin City Council (Incorporated under the Northern Territory Local Government Act 1993) governs the City of Darwin which takes in the CBD and the suburbs. The Darwin City Council has governed the City of Darwin since 1957. The Darwin City Council consists of 13 elected members, the Lord Mayor and 12 aldermen.
The City of Darwin electorate is organised into four electoral units or wards. The names of the wards are Chan, Lyons, Richardson, and Waters. The constituents of each ward are directly responsible for electing three aldermen. Constituents of all wards are directly responsible for electing the Lord Mayor of Darwin. The mayor is Katrina Fong Lim after council elections in March 2012.
The rest of the Darwin area is divided into 2 local government areas--the Palmerston City Council and the Shire of Coomalie. These areas have elected councils which are responsible for functions delegated to them by the Northern Territory Government, such as planning and garbage collection.
The Legislative Assembly of the Northern Territory convenes in Darwin in the Northern Territory Parliament House. Government House, the official residence of the Administrator of the Northern Territory, is located on The Esplanade.
Also located on the Esplanade is the Supreme Court of the Northern Territory. Darwin has a Magistrate's Court also which is located on the corner of Cavenagh and Bennett Streets quite close to the Darwin City Council Chambers.
Darwin's police force are members of the Northern Territory Police Force. Darwin's Mitchell Street, with its numerous pubs, clubs and other entertainment venues, is policed by the CitySafe Unit. The CitySafe unit was recently credited with reducing violent crime in and around Darwin City. Darwin has a long record of alcohol abuse and violent crime with 6,000 assaults in 2009, of which 350 resulted in broken jaws and noses ‚Äì more than anywhere else in the world, according to the Royal Darwin Hospital.
Darwin is split between nine electoral divisions in the Legislative Assembly--Port Darwin, Fannie Bay, Fong Lim, Nightcliff, Sanderson, Johnston, Casuarina, Wanguri, and Karama. Historically, Darwin was a stronghold for the Country Liberal Party. However, since the turn of the century, Labor has been much more competitive, particularly in the more diverse northern section.
Economy.
The two largest economic sectors are mining and tourism. Mining and energy industry production exceeds $2.5¬†billion per annum. The most important mineral resources are gold, zinc and bauxite, along with manganese and many others. The energy production is mostly off shore with oil and natural gas from the Timor Sea, although there are significant uranium deposits near Darwin. Tourism employs 8% of Darwin residents, and is expected to grow as domestic and international tourists are now spending time in Darwin during the Wet and Dry seasons. Federal spending is a major contributor to the local economy as well.
The military presence that is maintained both within Darwin, and the wider Northern Territory, is a substantial source of employment.
Darwin's importance as a port is expected to grow, due to the increased exploitation of petroleum in the nearby Timor Sea, and to the completion of the railway link and continued expansion in trade with Asia.
During 2005, a number of major construction projects started in Darwin. One is the redevelopment of the Wharf Precinct, which includes a large convention and exhibition centre, apartment housing including Outrigger Pandanas and Evolution on Gardiner, retail and entertainment outlets including a large wave pool and safe swimming lagoon. The Chinatown project has also started with plans to construct multi-level carparks and Chinese-themed retail and dining outlets.
Education.
Education is overseen territory-wide by the Department of Education and Training (DET), whose role is to continually improve education outcomes for all students, with a focus on Indigenous students.
Preschool, primary and secondary.
Darwin is served by a number of public and private schools that cater to local and overseas students. Over 16,500 primary and secondary students are enrolled in schools in Darwin, with 10,524 students attending primary education, and 5,932 students attending secondary education. There are over 12,089 students enrolled in government schools and 2,124 students enrolled in independent schools.
There were 9,764 students attending schools in the City of Darwin area. 6,045 students attended primary schools and 3,719 students attended secondary schools. There are over 7,161 students enrolled in government schools and 1,108 students enrolled in independent schools. There are over 35 primary and pre ‚Äì schools, and 12 secondary schools including both government and non-government. Most schools in the city are secular, but there are a small number of Christian, Catholic and Lutheran institutions. Students intending to complete their secondary education can work towards either the Northern Territory Certificate of Education or the International Baccalaureate (only offered at Kormilda College). Schools have been restructured into Primary, Middle and High schools since the beginning of 2007.
Tertiary and vocational.
Darwin's largest University is the Charles Darwin University, which is the central provider of tertiary education in the Northern Territory. It covers both vocational and academic courses, acting as both a university and an Institute of TAFE. There are over 5,500 students enrolled in tertiary and further education courses.
Recreation and culture.
Events and festivals.
On 1 July, Territorians celebrate Territory Day. This is the only day of the year, apart from the Chinese New Year and New Year's Eve, when fireworks are permitted. In Darwin, the main celebrations occur at Mindil Beach, where a large firework display is commissioned by the government.
Weekly markets include Mindil Beach Sunset Markets (Thursdays and Sundays during the dry season), Parap Market, Nightcliff Market and Rapid Creek market. Mindil Beach Sunset Markets are very popular with locals and tourists alike and feature food, souvenirs, clothes and local performing artists.
The Darwin Festival held annually, includes comedy, dance, theatre, music, film and visual art and the NT Indigenous Music Awards. Other festivals include the Glenti, which showcases Darwin's large Greek community, and India@Mindil, a similar festival held by the smaller Indian community. The Chinese New Year is also celebrated with great festivity, highlighting the Asian influence in Darwin.
The Seabreeze festival, which first started in 2005, is held on the second week of May in the suburb of Nightcliff. It offers the opportunity for local talent to be showcased and a popular event is Saturday family festivities along the Nightcliff foreshore which is one of Darwin's most popular fitness tracks.
The Speargrass Festival is held annually the week prior to July's first full moon and celebrates the alternative Top End lifestyle. The festival activities include music, screening of locally produced films, screen printing, basket weaving, sweat lodge, water slides, human pyramid, hot tub, frisbee golf, spear throwing, Kubb competition, bingo, communal organic cooking, morning yoga, meditation, greasy pig and healing circles. The festival occurs at the Speargrass property, northeast of Pine Creek.
The Darwin beer-can regatta, held in August, celebrates Darwin's love affair with beer and contestants' race boats made exclusively of beer cans. Also in Darwin during the month of August, are the Darwin Cup horse race, and the Rodeo and Mud Crab Tying Competition.
The World Solar Challenge race attracts teams from around the world, most of which are fielded by universities or corporations although some are fielded by high schools. The race has a 20-year history spanning nine races, with the inaugural event taking place in 1987.
Arts and entertainment.
The Darwin Symphony Orchestra was first assembled in 1989, and has performed throughout the Territory. The Darwin Theatre Company is a locally produced professional theatre production company, performing locally and nationally.
The Darwin Entertainment Centre is the city's main concert venue and hosts theatre and orchestral performances. Other theatres include the Darwin Convention Centre, opened in July 2008. The Darwin Convention Centre is part of the $1.1¬†billion Darwin Waterfront project.
Darwin's only casino opened in 1981 as the Diamond Beach Casino, it later became the MGM Grand Darwin, before it changed to Skycity Darwin after Skycity Entertainment Group purchased the hotel in 2004.
The Northern Territory Museum and Art Gallery (MAGNT) in Darwin gives an overview of the history of the area, including exhibits on Cyclone Tracy and the boats of the Pacific Islands. The MAGNT also organises the annual Telstra National Aboriginal and Torres Strait Islander Art Award, the oldest and most prestigious Indigenous art award in Australia. The MAGNT also manages the Defence of Darwin Experience, a multi-media installation that tells the story of the Japanese air raids on Darwin during World War II.
The Darwin Festival and the Darwin Fringe Festival are annual events. A range of art galleries including specialised Aboriginal art galleries are a feature of Darwin.
Local and visiting musical bands can be heard at venues including the Darwin Entertainment Centre, The Vic Hotel, Happy Yess, and Brown's Mart. A yearly music festival, Bass in the Grass, is very popular with youth from the surrounding area. Artists such as Jessica Mauboy and The Groovesmiths call Darwin home.
There have been no major films set in Darwin; however, some scenes for Australia by Baz Luhrmann and Black Water were both shot in Darwin in 2007
Mitchell Street in the central business district is lined with nightclubs, takeaways, and restaurants. This is the city's entertainment hub. There are several smaller theatres, three cinema complexes (CBD, Casuarina, and Palmerston), and the Deckchair Cinema. This is an open-air cinema which operates through the dry season, from April to October, and screens independent and arthouse films.
Recreation.
The city has many kilometres of wide, unpolluted beaches, including the Casuarina Beach and well renowned Mindil Beach, home of the Mindil Beach markets. Darwin City Council has designated an area of Casuarina Beach as a free beach which offers a designated nudist beach area since 1976.
Swimming in the sea during the months of October‚ÄìMay should be avoided due to the presence of deadly box jellyfish, known locally as stingers.
Saltwater crocodiles are very common in all waterways surrounding Darwin and are even occasionally found swimming in Darwin Harbour and on local beaches.
Fishing is one of the recreations of Darwin locals. Visitors from around the world flock to Darwin aiming to catch the prized barramundi, an iconic fish for the region. The Mary River, Daly River, South and East Alligator River are just a few of the water bodies where the barramundi thrive.
Blue-water fishing is also available off the coast of Darwin; Spanish mackerel, Black Jewfish, queenfish, snapper and other varieties are all found in the area and accessible in a day trip from Darwin. Lake Alexander is a man-made swimming lake which is located at East Point Reserve. It is generally considered crocodile and jellyfish safe, however a freak outbreak of non-deadly jellyfish in 2003 caused its closure for a brief period of time. 
The Darwin Surf Lifesaving Club operates long boats and surf skis and provides events and lifesaving accreditations.
Parks and gardens.
Darwin has extensive parks and gardens. These include the George Brown Darwin Botanic Gardens, East Point Reserve, Casuarina Coastal Reserve, Charles Darwin National Park, Knuckey Lagoons Conservation Reserve, Leanyer Recreation Park, the Nightcliff Foreshore, Bicentennial Park and the Jingili Water Gardens.
Sports.
The Marrara Sports Complex near the airport has stadiums for Aussie Rules (TIO Stadium), cricket, rugby union, basketball (and indoor court sports), soccer, athletics and field hockey. Every two years since 1991 (excluding 2003 due to the SARS outbreak), Darwin has played host to the Arafura Games, a major regional sporting event. In July 2003, the city hosted its first international test cricket match between Australia and Bangladesh, followed by Australia and Sri Lanka in 2004.
Australian-rules football is played all year round. Melbourne's Western Bulldogs Australian Football League side plays one home game at Marrara Oval each year. The ATSIC Aboriginal All-Stars also participate in the AFL pre-season competition. In 2003, a record crowd of 17,500 attended a pre-season game between the All-Stars and Carlton Football Club at Marrara.
Rugby League and Rugby Union club competitions are played in Darwin each year, organised by the NTRL and NTRU respectively. The Heineken Hottest 7s in the World tournament is hosted in Darwin each January, with Rugby Sevens club teams from countries including Australia, New Zealand, Papua New Guinea, Malaysia, and Singapore competing. Darwin's Hottest 7s is the richest Rugby 7s tournament in the Southern Hemisphere.
Darwin hosts a round of the V8 Supercars every year bringing thousands of motorsports fans to the Hidden Valley Raceway. Also located Hidden Valley, adjacent to the road racing circuit, is Darwin's Dirt track racing venue, Northline Speedway. The speedway has hosted a number of Australian Championships over the years for different categories including Sprintcars, Speedcars, and Super Sedans.
The Darwin Cup culminating on the first Monday of August is a very popular horse race event for Darwin and draws large crowds every year to Fannie Bay Racecourse. While it is not as popular as the Melbourne Cup, it does draw a crowd and, in 2003, Sky Racing began televising most of the races. The Darwin Cup day is a public holiday for the Northern Territory (Picnic Day public holiday).
Media.
Darwin's major newspapers are the "Northern Territory News" (Monday ‚Äì Saturday), "The Sunday Territorian" (Sunday), and the national daily, "The Australian" (Monday‚ÄìFriday) and "The Weekend Australian" (Saturday), all published by News Limited. Free weekly community newspapers include the "Darwin Sun", the "Litchfield Sun", and "Palmerston Sun"; all published by a News Limited subsidiary.
Five free-to-air channels service Darwin. Commercial television channels are provided by Southern Cross Darwin (Seven Network affiliate), Channel Nine Darwin (formerly branded as Channel 8) and Darwin Digital Television (Network Ten relay), which launched on 28 April 2008. The two Government owned national broadcast services in Darwin are the ABC and SBS. Subscription Television (Pay TV) service Austar is available via cable in the Darwin region.
Darwin has radio stations on both AM and FM frequencies. ABC stations include ABC News Radio (102.5FM), ABC Local Radio (105.7FM), ABC Radio National (657AM), ABC Classic FM (107.3FM) and Triple J (103.3FM). SBS (100.9FM) also broadcasts its national radio network to Darwin.
Darwin has two commercial radio stations Hot 100 and Mix 104.9. Other stations in Darwin include university-based station 104.1 Territory FM, dance music station KIK FM 91.5, Italian-language channel Rete Italia 1611AM, community based stations includes Radio Larrakia 94.5 and Yolngu Radio 1530AM and Rhema FM 97.7.
Infrastructure.
Health.
The Government of the Northern Territory Department of Health and Families oversees one public hospital in the Darwin metropolitan region. The Royal Darwin Hospital, located in Tiwi, is the city's major teaching and referral hospital, and the largest in the Northern Territory.
There is one major private hospital Darwin Private Hospital located at Tiwi, adjacent to the Royal Darwin Hospital.
Transport.
The Territory's public transport services are managed by the Department of Lands and Planning, Public Transport Division. Darwin has a bus network serviced by a range of contracted bus operators, which provides transport to the main suburbs of Darwin.
Darwin has no commuter rail system, however long distance passenger rail services do operate out of the city. The Alice Springs to Darwin rail line was completed in 2003 linking Darwin to Adelaide. The first service ran in 2004. The Ghan passenger train service from Adelaide via Alice Springs and Katherine runs two to three times per week depending on the season.
Darwin International Airport, located in the suburb of Marrara, is Darwin's only airport, which shares its runways with the Royal Australian Air Force's RAAF Base Darwin.
Darwin can be reached via the Stuart Highway which runs the length of the Northern Territory from Darwin through Katherine, Tennant Creek, Alice Springs and on to Adelaide. Other major roads in Darwin include, Tiger Brennan Drive, Amy Johnson Avenue, Dick Ward Drive, Bagot Road, Trower Road and McMillans Road. Bus service in the greater Darwin area is served by Darwinbus.
Ferries leave from Port Darwin to island locations, mainly for tourists. A ferry service to the Tiwi Islands, the "Arafura Pearl" operates from Cullen Bay.
Darwin has a new deepwater port, East Arm Wharf, which opened in 2000. It has 754-meters of wharfline and is capable of handling Panamax-sized ships of a maximum length of 274 meters and a DWT of up to 80,000 tonnes.
Utilities.
Water storage, supply and Power for Darwin is managed by Power and Water Corporation, which is owned by the Government of the Northern Territory. The corporation is also responsible for management of sewage and the major water catchments in the region. Water is mainly stored in the largest dam, The Darwin River Dam which holds up to 90% of Darwin's water supply. For many years, Darwin's principal water supply came from Manton Dam.
Darwin, its suburbs, Palmerston and Katherine are powered by the Channel Island Power Station, The largest power plant in the Northern Territory.
A new power plant, the Weddell Power Station, is near completion. The first two generators came on line in 2008‚Äì09. The third generator is due to be completed in 2011‚Äì12. When the power station is fully operational, it will add 30% capacity to Darwin's power supply.
Tourism.
Tourism is one of Darwin's largest industries. Tourism is a major industry and employment sector for the Northern Territory.
In 2005/06, 1.38¬†million people visited the Northern Territory. They stayed for 9.2¬†million nights and spent over $1.5¬†billion.
The tourism industry directly employed 8,391 Territorians in June 2006 and when indirect employment is included, tourism typically accounts for more than 14,000 jobs across the Territory.
Darwin is a hub for tours to Kakadu National Park, Litchfield National Park and Katherine Gorge.
The Territory is traditionally divided into the wet and dry, but there are up to six traditional seasons in Darwin.
It is warm and sunny from May to September. Humidity rises during the green season, from October to April bringing thunderstorms and monsoonal rains which rejuvenates the landscape. Tourism is largely seasonal with most tourists visiting during the cooler dry season which runs from April to September.
Aviation history.
Darwin has played host to many of aviation's early pioneers. On 10 December 1919 Captain Ross Smith and his crew landed in Darwin and won a ¬£10,000 Prize from the Australian Government for completing the first flight from London to Australia in under thirty days. Smith and his Crew flew a Vickers Vimy, G-EAOU and landed on an airstrip that has now become Ross Smith Avenue.
Other aviation pioneers include Amy Johnson, Amelia Earhart, Sir Charles Kingsford Smith and Bert Hinkler. The original QANTAS Empire Airways Ltd Hangar, part of the original Darwin Civil Aerodrome in Parap, is now a museum and still bears scars from the bombing of Darwin during World War II.
Darwin was home to Australian and US pilots during the war, with air strips being built in and around Darwin. Today Darwin provides a staging ground for military exercises.
Darwin was a compulsory stop over/check point in the London to Melbourne Centenary Air Race in 1934. The official name of the race was the MacRobertson Air Race. Winners of the great race were Tom Campbell Black and C. W. A. Scott.
The following is an excerpt from "Time" magazine, 29 October 1934, Volume XXIV, Number 18.
The Australian Aviation Heritage Centre is located approximately from the City centre on the Stuart Highway and is one of only two places outside the United States where a B52 bomber (on permanent loan from the United States Air Force) is on public display.
US military presence.
On 16 November 2011, Prime Minister Julia Gillard and President Barack Obama announced that the United States would station troops in Australia for the first time since World War II. The agreement between the United States and Australia would involve a contingent of 250 Marines arriving in Darwin in 2012, with the total number rising to a maximum of 2,500 troops by 2017 on six-month rotations as well as a supporting air element including F-22 Raptors, F-35 Joint Strike Fighters and KC-135 refuelers. China and Indonesia have expressed concern about the decision. Some analysts have argued that an expanded U.S. presence could pose a threat to security
Gillard announced that the first 200 U.S. Marines had arrived in Darwin from Hawaii on late 3 April 2012. In 2013, further news of other expansion vectors was aired in USA media, with no comment or confirmation from Australian authorities. The agreement between the two governments remains hidden from public scrutiny. Marine numbers based in Darwin have increased to more than 1150 troops by 2014.
Darwin hosts biennial multi-nation exercises named "Pitch Black";</ref> in 2014 this involved military personnel from Australia, Singapore, Thailand, United Arab Emirates, and the United States.

</doc>
<doc id="8409" url="https://en.wikipedia.org/wiki?curid=8409" title="Dictator">
Dictator

A dictator is a ruler who wields absolute authority. A state ruled by a dictator is called a dictatorship. The word originated as the title of a magistrate in ancient Rome appointed by the Senate to rule the republic in times of emergency (see Roman dictator and "justitium").
Like the term "tyrant" (which was originally a respectable Ancient Greek title), and to a lesser degree "autocrat", "dictator" came to be used almost exclusively as a non-titular term for oppressive, even abusive rule, yet had rare modern titular use.
In modern usage, the term "dictator" is generally used to describe a leader who holds and/or abuses an extraordinary amount of personal power, especially the power to make laws without effective restraint by a legislative assembly. Dictatorships are often characterised by some of the following traits: suspension of elections and of civil liberties; proclamation of a state of emergency; rule by decree; repression of political opponents without abiding by rule of law procedures; these include one-party state, and cult of personality.
The term "dictator" is comparable to but not synonymous with the ancient concept of a tyrant; initially "tyrant", like "dictator", did not carry negative connotations. A wide variety of leaders coming to power in a number of different kinds of regimes, such as military juntas, one-party states and civilian governments under personal rule, have been described as dictators. They may hold left or right-wing views, or may be apolitical.
Etymology.
Originally an emergency legal appointment in the Roman Republic, the term "Dictator" did not have the negative meaning it has now. A Dictator was a magistrate given sole power for a limited duration. Usual procedure was authority divided equally between two consuls. At the end of the term, the Dictators power returned to normal Consular rule whereupon a dictator provided accountability, though not all dictators accepted a return to power sharing.
The term started to get its modern negative meaning with Cornelius Sulla's ascension to the dictatorship following Sulla's second civil war, making himself the first Dictator in more than a century (during which the office was ostensibly abolished) as well as "de facto" eliminating the time limit and need of senatorial acclamation, although he avoided a major constitutional crisis by resigning the office after about one year, dying a few years later. Julius Caesar followed the example in 49 BC and in February 44 BC was proclaimed "Dictator perpetuo", "Dictator in perpetuity", officially doing away with any limitations on his power, which he kept until his assassination the following month.
Garibaldi as a positive dictator.
Still, even in the 19th Century, the term "Dictator" did not always have negative connotations. For example, the Italian revolutionary Garibaldi, during his famous Expedition of the Thousand in 1860, proclaimed himself "Dictator of Sicily", which did not prevent him from being extremely popular in Italian and international public opinion. His usage of the term was clearly derived from the original Roman sense i.e., a person taking power for a limited time in order to deal with an emergency (in this case, the need to unite Italy) and with the task done Garibaldi handed over power to the government of Victor Emmanuel II of Italy. A few years later, during the Polish January Uprising of 1863, General Romuald Traugutt also bore the title of "Dictator" as an official and positive designation - possibly directly influenced by the then fresh example of Garibaldi.
Garibaldi's case was, however, an exception. In general, the term "dictator" came to be a negative term, not a title used by rulers to call themselves but a term used by the foes of an oppressive ruler. Such was the case with Maximillien Robespierre, whose supporters knew him as "The Incorruptible", while his opponents called him "dictateur sanguinaire", French for "bloodthirsty dictator".
Modern era.
In popular usage, "dictatorship" is often associated with brutality and oppression. As a result, it is often also used as a term of abuse for political opponents. The term has also come to be associated with megalomania. Many dictators create a cult of personality and have come to favor increasingly grandiloquent titles and honours for themselves. For instance, Idi Amin Dada, who had been a British army lieutenant prior to Uganda's independence from Britain in October 1962, subsequently styled himself as ""His Excellency, President for Life, Field Marshal Al Hadji Doctor Idi Amin Dada, VC, DSO, MC, Conqueror of the British Empire in Africa in General and Uganda in Particular"". In the movie "The Great Dictator" (1940), Charlie Chaplin satirized not only Adolf Hitler but the institution of dictatorship itself.
The association between the dictator and the military is a common one; many dictators take great pains to emphasize their connections with the military and often wear military uniforms. In some cases, this is perfectly legitimate; Francisco Franco was a lieutenant general in the Spanish Army before he became Chief of State of Spain; Manuel Noriega was officially commander of the Panamanian Defense Forces. In other cases, the association is mere pretense.
Modern use in formal titles.
Because of the negative associations, modern leaders very rarely (if ever) use the term in their formal titles. In the 19th century, however, official use was more common:
Human rights abuses.
Under the dictatorship of Soviet leader Joseph Stalin, tens of millions of people were executed, starved to death or imprisoned in Gulag forced-labour camps.
Pol Pot became leader of Cambodia in 1975. In all, an estimated 1.7 million people (out of a population of 7 million) died due to the policies of his four-year dictatorship. As a result, Pol Pot is sometimes described as "the Hitler of Cambodia" and "a genocidal tyrant".
The International Criminal Court issued an arrest warrant for Sudan's military dictator Omar al-Bashir over alleged war crimes in Darfur.
Dictators in game theory.
In social choice theory, the notion of a dictator is formally defined as a person who can achieve any feasible social outcome he/she wishes. The formal definition yields an interesting distinction between two different types of dictators.
Note that these definitions disregard some alleged dictators who are not interested in the actual achieving of social goals, as much as in propaganda and controlling public opinion. Monarchs and military dictators are also excluded from these definitions, because their rule relies on the consent of other political powers (the barons or the army).

</doc>
<doc id="8410" url="https://en.wikipedia.org/wiki?curid=8410" title="Decibel">
Decibel

The decibel (dB) is a logarithmic unit used to express the ratio of two values of a physical quantity, often power or intensity. One of these values is often a standard reference value, in which case the decibel is used to express the level of the other value relative to this reference. The number of decibels is ten times the logarithm to base 10 of the ratio of two power quantities, or of the ratio of the squares of two field amplitude quantities. One decibel is one tenth of one bel, named in honor of Alexander Graham Bell; however, the bel is seldom used.
The definition of the decibel is based on the measurement of power in telephony of the early 20th century in the Bell System in the United States. Today, the unit is used for a wide variety of measurements in science and engineering, most prominently in acoustics, electronics, and control theory. In electronics, the gains of amplifiers, attenuation of signals, and signal-to-noise ratios are often expressed in decibels. The decibel confers a number of advantages, such as the ability to conveniently represent very large or small numbers, and the ability to carry out multiplication of ratios by simple addition and subtraction. By contrast, use of the decibel complicates operations of addition and subtraction.
A change in power by a factor of 10 corresponds to a 10¬†dB change in level. At the half power point an audio circuit or an antenna exhibits an attenuation of approximately 3¬†dB. A change in voltage by a factor of 10 results in a change in power by a factor of 100, which corresponds to a 20¬†dB change in level. A change in voltage ratio by a factor of 2 (equivalently factor of 4 in power change) approximately corresponds to a 6¬†dB change in level.
The decibel symbol is often qualified with a suffix that indicates the reference quantity that has been used or some other property of the quantity being measured. For example, dBm indicates a reference power of one milliwatt, while dBu is referenced to 0.775 volts RMS.
In the International System of Quantities, the decibel is defined as a unit of measurement for quantities of type level or level difference, which are defined as the logarithm of the ratio of power- or field-type quantities.
History.
The decibel originates from methods used to quantify signal loss in telegraph and telephone circuits. The unit for loss was originally "Miles of Standard Cable" (MSC). 1¬†MSC corresponded to the loss of power over a 1 mile (approximately 1.6¬†km) length of standard telephone cable at a frequency of 5000 radians per second (795.8¬†Hz), and matched closely the smallest attenuation detectable to the average listener. The standard telephone cable implied was "a cable having uniformly distributed resistance of 88 ohms per loop mile and uniformly distributed shunt capacitance of 0.054 microfarad per mile" (approximately 19 gauge).
In 1924, Bell Telephone Laboratories received favorable response to a new unit definition among members of the International Advisory Committee on Long Distance Telephony in Europe and replaced the MSC with the "Transmission Unit" (TU). 1¬†TU was defined such that the number of TUs was ten times the base-10 logarithm of the ratio of measured power to a reference power level.
The definition was conveniently chosen such that 1¬†TU approximated 1¬†MSC; specifically, 1¬†MSC was 1.056¬†TU. In 1928, the Bell system renamed the TU into the decibel, being one tenth of a newly defined unit for the base-10 logarithm of the power ratio. It was named the "bel", in honor of the telecommunications pioneer Alexander Graham Bell.
The bel is seldom used, as the decibel was the proposed working unit.
The naming and early definition of the decibel is described in the NBS Standard's Yearbook of 1931:
In April 2003, the International Committee for Weights and Measures (CIPM) considered a recommendation for the inclusion of the decibel in the International System of Units (SI), but decided against the proposal. However, the decibel is recognized by other international bodies such as the International Electrotechnical Commission (IEC) and International Organization for Standardization (ISO). The IEC permits the use of the decibel with field quantities as well as power and this recommendation is followed by many national standards bodies, such as NIST, which justifies the use of the decibel for voltage ratios. The term "field quantity" is deprecated by ISO 80000-1, which favors root-power. In spite of their widespread use, suffixes (such as in dBA or dBV) are not recognized by the IEC or ISO.
Definition.
The ISO Standard 80000-3:2006 defines the following quantities. The decibel (dB) is one tenth of the bel (B): . The bel is ¬†ln(10) nepers (Np): . The neper is the change in the level of a field quantity when the field quantity changes by a factor of "e", that is (thereby relating all of the units as nondimensional natural log of field-quantity ratios, . Finally, the level of a quantity is the logarithm of the ratio of the value of that quantity to a reference value of the same quantity.
Therefore, the bel represents the logarithm of a ratio between two power quantities of 10:1, or the logarithm of a ratio between two field quantities of ‚àö10:1.
Two signals whose levels differ by one decibel have a power ratio of 101/10, which is approximately 1.25892, and an amplitude (field) ratio of 10 (1.12202).
Although permissible, the bel is rarely used with other SI unit prefixes than "deci". It is preferred to use "hundredths of a decibel" rather than "millibels".
The method of expressing a ratio as a level in decibels depends on whether the measured property is a "power quantity" or a "field quantity"; see Field, power, and root-power quantities for details.
Power quantities.
When referring to measurements of "power" quantities, a ratio can be expressed as a level in decibels by evaluating ten times the base-10 logarithm of the ratio of the measured quantity to reference value. Thus, the ratio of "P" (measured power) to "P"0 (reference power) is represented by "L""P", that ratio expressed in decibels, which is calculated using the formula:
The base-10 logarithm of the ratio of the two power levels is the number of bels. The number of decibels is ten times the number of bels (equivalently, a decibel is one-tenth of a bel). "P" and "P"0 must measure the same type of quantity, and have the same units before calculating the ratio. If in the above equation, then "L""P" = 0. If "P" is greater than "P"0 then "L""P" is positive; if "P" is less than "P"0 then "L""P" is negative.
Rearranging the above equation gives the following formula for "P" in terms of "P"0 and "L""P":
Field quantities and root-power quantities.
When referring to measurements of field quantities, it is usual to consider the ratio of the squares of "F" (measured field) and "F"0 (reference field). This is because in most applications power is proportional to the square of field, and it is desirable for the two decibel formulations to give the same result in such typical cases. Thus, the following definition is used:
The formula may be rearranged to give
Similarly, in electrical circuits, dissipated power is typically proportional to the square of voltage or current when the impedance is held constant. Taking voltage as an example, this leads to the equation:
where "V" is the voltage being measured, "V"0 is a specified reference voltage, and "G"dB is the power gain expressed in decibels. A similar formula holds for current.
The term "root-power quantity" is introduced by ISO Standard 80000-1:2009 as a substitute of "field quantity". The term "field quantity" is deprecated by that standard.
Conversions.
Since logarithm differences measured in these units are used to represent power ratios and field ratios, the values of the ratios represented by each unit are also included in the table.
Examples.
All of these examples yield dimensionless answers in dB because they are relative ratios expressed in decibels. The unit dBW is often used to denote a ratio for which the reference is 1 W, and similarly dBm for a reference point.
, illustrating the consequence from the definitions above that "G"dB has the same value, 30, regardless of whether it is obtained from powers or from amplitudes, provided that in the specific system being considered power ratios are equal to amplitude ratios squared.
A change in power ratio by a factor of 10 corresponds to a change in level of . A change in power ratio by a factor of 2 is approximately a change of 3¬†dB. More precisely, the factor is 10, or 1.9953, about 0.24% different from exactly 2. Similarly, an increase of implies an increase in voltage by a factor of approximately , or about 1.41, an increase of corresponds to approximately four times the power and twice the voltage, and so on. In exact terms the power ratio is 10, or about 3.9811, a relative error of about 0.5%.
Properties.
The decibel has the following properties:
Advantages and disadvantages.
Supporting arguments.
According to Mitschke, "The advantage of using a logarithmic measure is that in a transmission chain, there are many elements concatenated, and each has its own gain or attenuation. To obtain the total, addition of decibel values is much more convenient than multiplication of the individual factors."
The human perception of the intensity of sound and light approximates the logarithm of intensity rather than a linear relationship (Weber‚ÄìFechner law), making the dB scale a useful measure.
Decibels are still the commonly used units to express ratios in a number of fields, even when the original meaning of the term is obscured. Decibels are the traditional way of expressing gain or margin in such diverse disciplines as control theory, antenna and radio frequency transmission theory, and even assessment of nuclear hardness.
Criticism.
Various published articles have criticized the unit decibel as having shortcomings that hinder its understanding and use: According to its critics, the decibel creates confusion, obscures reasoning, is more related to the era of slide rules than to modern digital processing, are cumbersome and difficult to interpret.
Representing the equivalent of zero watts is not possible, causing problems in conversions. Hickling concludes "Decibels are a useless affectation, which is impeding the development of noise control as an engineering discipline".
A common source of confusion in using the decibel occurs when deciding about the use of 10¬†√ó¬†log or 20¬†√ó¬†log. In the original definition, it was a power measurement, and as employed in that context, the formulation 10¬†√ó¬†log should be used, as "deci" means one tenth. The user must be clear whether the quantity expressed is power or amplitude. It is useful to consider how power or energy is expressed, e.g., current¬†√ó¬†current¬†√ó¬†resistance, ¬†√ó¬†velocity¬†√ó¬†velocity¬†√ó¬†mass. Where the power is a square function of a field variable (such as voltage, current, or pressure), then 10¬†√ó¬†log is the correct expression for the square, or 20¬†√ó¬†log for the field variable itself.
Quantities in decibels are not necessarily additive, thus being "of unacceptable form for use in dimensional analysis".
For the same reason that humans excel at additive operation over multiplication, decibels are awkward in inherently additive operations: "if two machines each individually produce a pressure level of, say, 90¬†dB at a certain point, then when both are operating together we should expect the combined sound pressure level to increase to 93¬†dB, but certainly not to 180¬†dB!" "suppose that the noise from a machine is measured (including the contribution of background noise) and found to be 87¬†dBA but when the machine is switched off the background noise alone is measured as 83¬†dBA. ... the machine noise (alone) may be obtained by 'subtracting' the 83¬†dBA background noise from the combined level of 87¬†dBA; i.e., 84.8¬†dBA." "in order to find a representative value of the sound level in a room a number of measurements are taken at different positions within the room, and an average value is calculated. (...) Compare the logarithmic and arithmetic averages of ... 70¬†dB and 90¬†dB: logarithmic average = 87¬†dB; arithmetic average = 80¬†dB."
Uses.
Acoustics.
The decibel is commonly used in acoustics as a unit of sound pressure level. The reference pressure in air is set at the typical threshold of perception of an average human and there are common comparisons used to illustrate different levels of sound pressure. Sound pressure is a field quantity, therefore the field version of the unit definition is used:
where "p"ref is the standard reference sound pressure of 20 micropascals in air or 1 micropascal in water.
The human ear has a large dynamic range in sound reception. The ratio of the sound intensity that causes permanent damage during short exposure to the quietest sound that the ear can hear is greater than or equal to 1 trillion (1012). Such large measurement ranges are conveniently expressed in logarithmic scale: the base-10 logarithm of 1012 is 12, which is expressed as a sound pressure level of 120¬†dB re 20¬†ŒºPa. Since the human ear is not equally sensitive to all sound frequencies, noise levels at maximum human sensitivity, somewhere between 2 and 4¬†kHz, are factored more heavily into some measurements using frequency weighting. (See also Stevens' power law.)
Electronics.
In electronics, the decibel is often used to express power or amplitude ratios (gains), in preference to arithmetic ratios or percentages. One advantage is that the total decibel gain of a series of components (such as amplifiers and attenuators) can be calculated simply by summing the decibel gains of the individual components. Similarly, in telecommunications, decibels denote signal gain or loss from a transmitter to a receiver through some medium (free space, waveguide, coaxial cable, fiber optics, etc.) using a link budget.
The decibel unit can also be combined with a suffix to create an absolute unit of electric power. For example, it can be combined with "m" for "milliwatt" to produce the "dBm". Zero dBm is the level corresponding to one milliwatt, and 1 dBm is one decibel greater (about 1.259¬†mW).
In professional audio specifications, a popular unit is the dBu. The dBu is a root mean square (RMS) measurement of voltage that uses as its reference approximately 0.775¬†VRMS. Chosen for historical reasons, the reference value is the voltage level which delivers 1¬†mW of power in a 600-ohm resistor, which used to be the standard reference impedance in telephone circuits.
Optics.
In an optical link, if a known amount of optical power, in dBm (referenced to 1¬†mW), is launched into a fiber, and the losses, in dB (decibels), of each component (e.g., connectors, splices, and lengths of fiber) are known, the overall link loss may be quickly calculated by addition and subtraction of decibel quantities.
In spectrometry and optics, the blocking unit used to measure optical density is equivalent to ‚àí1 B.
Video and digital imaging.
In connection with video and digital image sensors, decibels generally represent ratios of video voltages or digitized light levels, using 20 log of the ratio, even when the represented optical power is directly proportional to the voltage or level, not to its square, as in a CCD imager where response voltage is linear in intensity.
Thus, a camera signal-to-noise ratio or dynamic range of 40¬†dB represents a power ratio of 100:1 between signal power and noise power, not 10,000:1.
Sometimes the 20 log ratio definition is applied to electron counts or photon counts directly, which are proportional to intensity without the need to consider whether the voltage response is linear.
However, as mentioned above, the 10 log intensity convention prevails more generally in physical optics, including fiber optics, so the terminology can become murky between the conventions of digital photographic technology and physics. Most commonly, quantities called "dynamic range" or "signal-to-noise" (of the camera) would be specified in 20 log dB, but in related contexts (e.g. attenuation, gain, intensifier SNR, or rejection ratio) the term should be interpreted cautiously, as confusion of the two units can result in very large misunderstandings of the value.
Photographers typically use an alternative base-2 log unit, the f-stop, to describe light intensity or dynamic range.
Suffixes and reference values.
Suffixes are commonly attached to the basic dB unit in order to indicate the reference value by which the ratio is calculated. For example, dBm indicates power measurement relative to 1 milliwatt.
In cases where the unit value of the reference is stated, the decibel value is known as "absolute". If the unit value of the reference is not explicitly stated, as in the dB gain of an amplifier, then the decibel value is considered relative.
The SI does not permit attaching qualifiers to units, whether as suffix or prefix, other than standard SI prefixes. Therefore, even though the decibel is accepted for use alongside SI units, the practice of attaching a suffix to the basic dB unit, forming compound units such as dBm, dBu, dBA, etc., is not. The proper way, according to the IEC 60027-3, is either as "L""x" (re "x"ref) or as "L""x"/"x"ref, where "x" is the quantity symbol and "x"ref is the value of the reference quantity, e.g., "L""E" (re 1 ŒºV/m) = "L""E"/(1 ŒºV/m) for the electric field strength "E" relative to 1 ŒºV/m reference value.
Outside of documents adhering to SI units, the practice is very common as illustrated by the following examples. There is no general rule, with various discipline-specific practices. Sometimes the suffix is a unit symbol ("W","K","m"), sometimes it is a transliteration of a unit symbol ("uV" instead of ŒºV for microvolt), sometimes it is an acronym for the unit's name ("sm" for square meter, "m" for milliwatt), other times it is a mnemonic for the type of quantity being calculated ("i" for antenna gain with respect to an isotropic antenna, "Œª" for anything normalized by the EM wavelength), or otherwise a general attribute or identifier about the nature of the quantity ("A" for A-weighted sound pressure level). The suffix is often connected with a dash (dB-Hz), with a space (dB HL), with no intervening character (dBm), or enclosed in parentheses, dB(sm).
Voltage.
Since the decibel is defined with respect to power, not amplitude, conversions of voltage ratios to decibels must square the amplitude, or use the factor of 20 instead of 10, as discussed above.
dBV
dBu or dBv
dBmV
dBŒºV or dBuV
Acoustics.
Probably the most common usage of "decibels" in reference to sound level is dB SPL, sound pressure level referenced to the nominal threshold of human hearing: The measures of pressure (a field quantity) use the factor of 20, and the measures of power (e.g. dB SIL and dB SWL) use the factor of 10.
dB SPL
An RMS sound pressure of one pascal corresponds to a level of 94¬†dB SPL.
dB SIL
dB SWL
dB(A), dB(B), and dB(C)
dB HL or dB hearing level is used in audiograms as a measure of hearing loss. The reference level varies with frequency according to a minimum audibility curve as defined in ANSI and other standards, such that the resulting audiogram shows deviation from what is regarded as 'normal' hearing.
dB Q is sometimes used to denote weighted noise level, commonly using the ITU-R 468 noise weighting
Audio electronics.
dBm
dBFS
dBTP
dBm0
Radar.
dBZ
dBsm
Antenna measurements.
dBi
dBd
dBiC
dBq
dBsm
dBm‚àí1
Other measurements.
dB-Hz
dBov or dBO
dBr
dBrn
dBrnC
dBK
dB/K
Related units.
Np or cNp
Fractions.
Attenuation constants, in fields such as optical fiber communication and radio propagation path loss, are often expressed as a fraction or ratio to distance of transmission. "dB/m" means decibels per meter, "dB/mi" is decibels per mile, for example. These quantities are to be manipulated obeying the rules of dimensional analysis, e.g., a 100-meter run with a 3.5¬†dB/km fiber yields a loss of 0.35¬†dB = 3.5¬†dB/km √ó 0.1¬†km.

</doc>
<doc id="8411" url="https://en.wikipedia.org/wiki?curid=8411" title="Darwinism">
Darwinism

Darwinism is a theory of biological evolution developed by the English naturalist Charles Darwin (1809-1882) and others, stating that all species of organisms arise and develop through the natural selection of small, inherited variations that increase the individual's ability to compete, survive, and reproduce. Also called Darwinian theory, it originally included the broad concepts of transmutation of species or of evolution which gained general scientific acceptance after Darwin published "On the Origin of Species" in 1859, including concepts which predated Darwin's theories, but subsequently referred to specific concepts of natural selection, of the Weismann barrier or in genetics of the central dogma of molecular biology. Though the term usually refers strictly to biological evolution, creationists have appropriated it to refer to the origin of life, and it has even been applied to concepts of cosmic evolution, both of which have no connection to Darwin's work. It is therefore considered the belief and acceptance of Darwin's and of his predecessors' work‚Äîin place of other theories, including divine design and extraterrestrial origins.
English biologist Thomas Henry Huxley coined the term "Darwinism" in April 1860. It was used to describe evolutionary concepts in general, including earlier concepts published by English philosopher Herbert Spencer. Many of the proponents of Darwinism at that time, including Huxley, had reservations about the significance of natural selection, and Darwin himself gave credence to what was later called Lamarckism. The strict neo-Darwinism of German evolutionary biologist August Weismann gained few supporters in the late 19th century. During the approximate period of the 1880s to about 1920, sometimes called "the eclipse of Darwinism," scientists proposed various alternative evolutionary mechanisms which eventually proved untenable. The development of the modern evolutionary synthesis from the 1930s to the 1950s, incorporating natural selection with population genetics and Mendelian genetics, revived Darwinism in an updated form.
While the term "Darwinism" has remained in use amongst the public when referring to modern evolutionary theory, it has increasingly been argued by science writers such as Olivia Judson and Eugenie Scott that it is an inappropriate term for modern evolutionary theory. For example, Darwin was unfamiliar with the work of the Moravian scientist and Augustinian friar Gregor Mendel, and as a result had only a vague and inaccurate understanding of heredity. He naturally had no inkling of later theoretical developments and, like Mendel himself, knew nothing of genetic drift, for example. In the United States, creationists often use the term "Darwinism" as a pejorative term in reference to beliefs such as scientific materialism, but in the United Kingdom the term has no negative connotations, being freely used as a shorthand for the body of theory dealing with evolution, and in particular, with evolution by natural selection.
Conceptions of Darwinism.
While the term "Darwinism" had been used previously to refer to the work of Erasmus Darwin in the late 18th century, the term as understood today was introduced when Charles Darwin's 1859 book "On the Origin of Species" was reviewed by Thomas Henry Huxley in the April 1860 issue of the "Westminster Review". Having hailed the book as "a veritable Whitworth gun in the armoury of liberalism" promoting scientific naturalism over theology, and praising the usefulness of Darwin's ideas while expressing professional reservations about Darwin's gradualism and doubting if it could be proved that natural selection could form new species, Huxley compared Darwin's achievement to that of Nicolaus Copernicus in explaining planetary motion:
Another important evolutionary theorist of the same period was the Russian geographer and prominent anarchist Peter Kropotkin who, in his book "" (1902), advocated a conception of Darwinism counter to that of Huxley. His conception was centred around what he saw as the widespread use of co-operation as a survival mechanism in human societies and animals. He used biological and sociological arguments in an attempt to show that the main factor in facilitating evolution is cooperation between individuals in free-associated societies and groups. This was in order to counteract the conception of fierce competition as the core of evolution, which provided a rationalisation for the dominant political, economic and social theories of the time; and the prevalent interpretations of Darwinism, such as those by Huxley, who is targeted as an opponent by Kropotkin. Kropotkin's conception of Darwinism could be summed up by the following quote:
19th-century usage.
"Darwinism" soon came to stand for an entire range of evolutionary (and often revolutionary) philosophies about both biology and society. One of the more prominent approaches, summed in the 1864 phrase "survival of the fittest" by Herbert Spencer, later became emblematic of Darwinism even though Spencer's own understanding of evolution (as expressed in 1857) was more similar to that of Jean-Baptiste Lamarck than to that of Darwin, and predated the publication of Darwin's theory in 1859. What is now called "Social Darwinism" was, in its day, synonymous with "Darwinism"‚Äîthe application of Darwinian principles of "struggle" to society, usually in support of anti-philanthropic political agenda. Another interpretation, one notably favoured by Darwin's half-cousin Francis Galton, was that "Darwinism" implied that because natural selection was apparently no longer working on "civilized" people, it was possible for "inferior" strains of people (who would normally be filtered out of the gene pool) to overwhelm the "superior" strains, and voluntary corrective measures would be desirable‚Äîthe foundation of eugenics.
In Darwin's day there was no rigid definition of the term "Darwinism," and it was used by opponents and proponents of Darwin's biological theory alike to mean whatever they wanted it to in a larger context. The ideas had international influence, and Ernst Haeckel developed what was known as "Darwinismus" in Germany, although, like Spencer's "evolution," Haeckel's "Darwinism" had only a rough resemblance to the theory of Charles Darwin, and was not centered on natural selection. In 1886, Alfred Russel Wallace went on a lecture tour across the United States, starting in New York and going via Boston, Washington, Kansas, Iowa and Nebraska to California, lecturing on what he called "Darwinism" without any problems.
In his book "Darwinism" (1889), Wallace had used the term "pure-Darwinism" which proposed a "greater efficacy" for natural selection. George Romanes dubbed this view as "Wallaceism", noting that in contrast to Darwin, this position was advocating a "pure theory of natural selection to the exclusion of any supplementary theory." Taking influence from Darwin, Romanes was a proponent of both natural selection and the inheritance of acquired characteristics. The latter was denied by Wallace who was a strict selectionist. Romanes' definition of Darwinism conformed directly with Darwin's views and was contrasted with Wallace's definition of the term.
Other uses.
The term "Darwinism" is often used in the United States by promoters of creationism, notably by leading members of the intelligent design movement, as an epithet to attack evolution as though it were an ideology (an "ism") of philosophical naturalism, or atheism. For example, UC Berkeley law professor and author Phillip E. Johnson makes this accusation of atheism with reference to Charles Hodge's book "What Is Darwinism?" (1874). However, unlike Johnson, Hodge confined the term to exclude those like American botanist Asa Gray who combined Christian faith with support for Darwin's natural selection theory, before answering the question posed in the book's title by concluding: "It is Atheism." Creationists use the term "Darwinism", often pejoratively, to imply that the theory has been held as true only by Darwin and a core group of his followers, whom they cast as dogmatic and inflexible in their belief. In the 2008 documentary film "", which promotes intelligent design (ID), American writer and actor Ben Stein refers to scientists as Darwinists. Reviewing the film for "Scientific American", John Rennie says "The term is a curious throwback, because in modern biology almost no one relies solely on Darwin's original ideas... Yet the choice of terminology isn't random: Ben Stein wants you to stop thinking of evolution as an actual science supported by verifiable facts and logical arguments and to start thinking of it as a dogmatic, atheistic ideology akin to Marxism." 
However, "Darwinism" is also used neutrally within the scientific community to distinguish the modern evolutionary synthesis, sometimes called "neo-Darwinism," from those first proposed by Darwin. "Darwinism" also is used neutrally by historians to differentiate his theory from other evolutionary theories current around the same period. For example, "Darwinism" may be used to refer to Darwin's proposed mechanism of natural selection, in comparison to more recent mechanisms such as genetic drift and gene flow. It may also refer specifically to the role of Charles Darwin as opposed to others in the history of evolutionary thought‚Äîparticularly contrasting Darwin's results with those of earlier theories such as Lamarckism or later ones such as the modern evolutionary synthesis.
In political discussions in the United States, the term is mostly used by its enemies. "It's a rhetorical device to make evolution seem like a kind of faith, like 'Maoism,'" says Harvard University biologist E. O. Wilson. He adds, "Scientists don't call it 'Darwinism'." In the United Kingdom the term often retains its positive sense as a reference to natural selection, and for example British ethologist and evolutionary biologist Richard Dawkins wrote in his collection of essays "A Devil's Chaplain", published in 2003, that as a scientist he is a Darwinist.
In his 1995 book "Darwinian Fairytales", Australian philosopher David Stove used the term "Darwinism" in a different sense than the above examples. Describing himself as non-religious and as accepting the concept of natural selection as a well-established fact, Stove nonetheless attacked what he described as flawed concepts proposed by some "Ultra-Darwinists." Stove alleged that by using weak or false "ad hoc" reasoning, these Ultra-Darwinists used evolutionary concepts to offer explanations that were not valid (e.g., Stove suggested that sociobiological explanation of altruism as an evolutionary feature was presented in such a way that the argument was effectively immune to any criticism). Philosopher Simon Blackburn wrote a rejoinder to Stove, though a subsequent essay by Stove's protegee James Franklin's suggested that Blackburn's response actually "confirms Stove's central thesis that Darwinism can 'explain' anything."

</doc>
