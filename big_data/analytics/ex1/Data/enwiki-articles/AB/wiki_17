<doc id="7770" url="https://en.wikipedia.org/wiki?curid=7770" title="Christmas tree">
Christmas tree

A Christmas tree is a decorated tree, usually an evergreen conifer such as spruce, pine, or fir or an artificial tree of similar appearance, associated with the celebration of Christmas. Originally a Celtic custom, the Christmas tree developed in early modern Germany (where it is today called "Weihnachtsbaum" or "Christbaum") with predecessors that can be traced to the 16th and possibly 15th century, in which devout Christians brought decorated trees into their homes. It acquired popularity beyond Germany during the second half of the 19th century, at first among the upper classes.
The tree was traditionally decorated with edibles such as apples, nuts, or other foods. In the 18th century, it began to be illuminated by candles which were ultimately replaced by Christmas lights after the advent of electrification. Today, there is a wide variety of traditional ornaments, such as garland, tinsel, and candy canes. An angel or star might be placed at the top of the tree to represent the archangel Gabriel or the Star of Bethlehem from the Nativity.
The Christmas tree has also been known as the "Yule-tree", especially in discussions of its folkloric origins.
History.
Possible predecessors.
While it is clear that the modern Christmas tree originated during the Renaissance of early modern Germany, there are a number of speculative theories as to its ultimate origin. Its 16th-century origins are sometimes associated with Protestant Christian reformer Martin Luther who is said to have first added lighted candles to an evergreen tree.
It is frequently traced to the symbolism of trees in pre-Christian winter rites, in particular through the story of Donar's Oak and the popularized story of Saint Boniface and the conversion of the German pagans, in which Saint Boniface cuts down an oak tree that the German pagans worshipped, and replaces it with an evergreen tree, telling them about how its triangular shape reminds humanity of the Trinity and how it points to heaven.
According to the "Encyclopædia Britannica", "The use of evergreen trees, wreaths, and garlands to symbolize eternal life was a custom of the ancient Egyptians, Chinese, and Hebrews. Tree worship was common among the pagan Europeans and survived their conversion to Christianity in the Scandinavian customs of decorating the house and barn with evergreens at the New Year to scare away the devil and of setting up a tree for the birds during Christmastime."
Alternatively, it is identified with the "tree of paradise" of medieval mystery plays that were given on 24 December, the commemoration and name day of Adam and Eve in various countries. In such plays, a tree decorated with apples (to represent the forbidden fruit) and wafers (to represent the Eucharist and redemption) was used as a setting for the play. Like the Christmas crib, the Paradise tree was later placed in homes. The apples were replaced by round objects such as shiny red balls.
Georgia.
The Georgians have their own traditional Christmas tree called Chichilaki, made from dried up hazelnut or walnut branches that are shaped to form a small coniferous tree. These pale-colored ornaments differ in height from to . Chichilakis are most common in the Guria and Samegrelo regions of Georgia near the Black Sea, but they can also be found in some stores around the capital of Tbilisi.
Georgians believe that Chichilaki resembles the famous beard of St. Basil the Great, who is thought to visit people during Christmas similar to the Santa Claus tradition.
Poland.
There was an old pagan custom of suspending at the ceiling a branch of fir, spruce or pine called Podłaźniczka associated with Koliada. The branches were decorated with apples, nuts, cookies, colored paper, stars made of straw, ribbons and colored wafers. Some people believed that the tree had magical powers that were linked with harvesting and success in the next year.
In the late eighteenth and early nineteenth century, these traditions were almost completely replaced by the German custom of decorating the Christmas tree.
Estonia and Latvia.
Customs of erecting decorated trees in wintertime can be traced to Christmas celebrations in Renaissance-era guilds in Northern Germany and Livonia. The first evidence of decorated trees associated with Christmas Day are trees in guildhalls decorated with sweets to be enjoyed by the apprentices and children. In Livonia (present-day Latvia and Estonia), in 1441, 1442, 1510 and 1514, the Brotherhood of Blackheads erected a tree for the holidays in their guild houses in Riga and Reval (now Tallinn). On the last night of the celebrations leading up to the holidays, the tree was taken to the Town Hall Square where the members of the brotherhood danced around it. A Bremen guild chronicle of 1570 reports that a small tree decorated with "apples, nuts, dates, pretzels and paper flowers" was erected in the guild-house for the benefit of the guild members' children, who collected the dainties on Christmas Day. In 1584, the pastor and chronicler Balthasar Russow in his "" (1584) wrote of an established tradition of setting up a decorated spruce at the market square where the young men "went with a flock of maidens and women, first sang and danced there and then set the tree aflame".
After the Protestant Reformation, such trees are seen in the houses of upper-class Protestant families as a counterpart to the Catholic Christmas cribs. This transition from the guild hall to the bourgeois family homes in the Protestant parts of Germany ultimately gives rise to the modern tradition as it developed in the 18th and 19th centuries.
18th to early 20th centuries.
Germany.
By the early 18th century, the custom had become common in towns of the upper Rhineland, but it had not yet spread to rural areas. Wax candles, expensive items at the time, are found in attestations from the late 18th century.
Along the lower Rhine, an area of Roman Catholic majority, the Christmas tree was largely regarded as a Protestant custom. As a result, it remained confined to the upper Rhineland for a relatively long period of time. The custom did eventually gain wider acceptance beginning around 1815 by way of Prussian officials who emigrated there following the Congress of Vienna.
In the 19th century, the Christmas tree was taken to be an expression of German culture and of "", especially among emigrants overseas.
A decisive factor in winning general popularity was the German army's decision to place Christmas trees in its barracks and military hospitals during the Franco-Prussian War. Only at the start of the 20th century did Christmas trees appear inside churches, this time in a new brightly lit form.
Adoption by European nobility.
In the early 19th century, the custom became popular among the nobility and spread to royal courts as far as Russia. Princess Henrietta of Nassau-Weilburg introduced the Christmas tree to Vienna in 1816, and the custom spread across Austria in the following years. In France, the first Christmas tree was introduced in 1840 by the duchesse d'Orléans. In Denmark a Danish newspaper claims that the first attested Christmas tree was lit in 1808 by countess Wilhemine of Holsteinborg. It was the aging countess who told the story of the first Danish Christmas tree to the Danish writer Hans Christian Andersen in 1865. He had published a fairy-tale called "The Fir-Tree" in 1844, recounting the fate of a fir-tree being used as a Christmas tree.
Britain.
Although the tradition of decorating the home with evergreens was long established, the custom of decorating an entire small tree was unknown in Britain until some two centuries ago. At the time of the personal union with Hanover, George III's German-born wife, Charlotte of Mecklenburg-Strelitz, introduced a Christmas tree at a party she gave for children in 1800. The custom did not at first spread much beyond the royal family. Queen Victoria as a child was familiar with it and a tree was placed in her room every Christmas. In her journal for Christmas Eve 1832, the delighted 13-year-old princess wrote: "After dinner... we then went into the drawing-room near the dining-room... There were two large round tables on which were placed two trees hung with lights and sugar ornaments. All the presents being placed round the trees..." After Victoria's marriage to her German cousin Prince Albert, by 1841 the custom became even more widespread as wealthier middle-class families followed the fashion. In 1842 a newspaper advert for Christmas trees makes clear their smart cachet, German origins and association with children and gift-giving. An illustrated book, "The Christmas Tree", describing their use and origins in detail, was on sale in December 1844. In 1847, Prince Albert wrote: "I must now seek in the children an echo of what Ernest brother and I were in the old time, of what we felt and thought; and their delight in the Christmas-trees is not less than ours used to be". A boost to the trend was given in 1848 when "The Illustrated London News", in a report picked up by other papers, described the trees in Windsor Castle in detail and showed the main tree, surrounded by the royal family, on its cover. In fewer than ten years their use in better-off homes was widespread. By 1856 a northern provincial newspaper contained an advert alluding casually to them, as well as reporting the accidental death of a woman whose dress caught fire as she lit the tapers on a Christmas tree. They had not yet spread down the social scale though, as a report from Berlin in 1858 contrasts the situation there where "Every family has its own" with that of Britain, where Christmas trees were still the preserve of the wealthy or the "romantic".
Their use at public entertainments, charity bazaars and in hospitals made them increasingly familiar however, and in 1906 a charity was set up specifically to ensure even poor children in London slums 'who had never seen a Christmas tree' would enjoy one that year. Anti-German sentiment after World War I briefly reduced their popularity but the effect was short-lived and by the mid-1920s the use of Christmas trees had spread to all classes. In 1933 a restriction on the importation of foreign trees led to the 'rapid growth of a new industry' as the growing of Christmas trees within Britain became commercially viable due to the size of demand. By 2013 the number of trees grown in Britain for the Christmas market was approximately 8 million and their display in homes, shops and public spaces a normal part of the Christmas season.
North America.
The tradition was introduced to Canada in the winter of 1781 by Brunswick soldiers stationed in the Province of Quebec to garrison the colony against American attack. General Friedrich Adolf Riedesel and his wife, the Baroness von Riedesel, held a Christmas party at Sorel, delighting their guests with a fir tree decorated with candles and fruits.
A woodcut of the British Royal family with their Christmas tree at Windsor Castle, initially published in "The Illustrated London News" December 1848, was copied in the United States at Christmas 1850, in "Godey's Lady's Book". "Godey's" copied it exactly, except for the removal of the Queen's tiara and Prince Albert's moustache, to remake the engraving into an American scene. The republished "Godey's" image became the first widely circulated picture of a decorated evergreen Christmas tree in America. Art historian Karal Ann Marling called Prince Albert and Queen Victoria, shorn of their royal trappings, "the first influential American Christmas tree". Folk-culture historian Alfred Lewis Shoemaker states, "In all of America there was no more important medium in spreading the Christmas tree in the decade 1850–60 than "Godey's Lady's Book"". The image was reprinted in 1860, and by the 1870s, putting up a Christmas tree had become common in America.
Several cities in the United States with German connections lay claim to that country's first Christmas tree: Windsor Locks, Connecticut, claims that a Hessian soldier put up a Christmas tree in 1777 while imprisoned at the Noden-Reed House, while the "First Christmas Tree in America" is also claimed by Easton, Pennsylvania, where German settlers purportedly erected a Christmas tree in 1816. In his diary, Matthew Zahm of Lancaster, Pennsylvania, recorded the use of a Christmas tree in 1821, leading Lancaster to also lay claim to the first Christmas tree in America. Other accounts credit Charles Follen, a German immigrant to Boston, for being the first to introduce to America the custom of decorating a Christmas tree. August Imgard, a German immigrant living in Wooster, Ohio, is the first to popularize the practice of decorating a tree with candy canes. In 1847, Imgard cut a blue spruce tree from a woods outside town, had the Wooster village tinsmith construct a star, and placed the tree in his house, decorating it with paper ornaments and candy canes. German immigrant Charles Minnegerode accepted a position as a professor of humanities at the College of William & Mary in Williamsburg, Virginia, in 1842, where he taught Latin and Greek. Entering into the social life of the Virginia Tidewater, Minnigerode introduced the German custom of decorating an evergreen tree at Christmas at the home of law professor St. George Tucker, thereby becoming another of many influences that prompted Americans to adopt the practice at about that time.An 1853 article on Christmas customs in Pennsylvania defines them as mostly "German in origin", including the Christmas tree, which is "planted in a flower pot filled with earth, and its branches are covered with presents, chiefly of confectionary, for the younger members of the family." The article distinguishes between customs in different states however, claiming that in New England generally "Christmas is not much celebrated", whereas in Pennsylvania and New York it is.
The lyrics sung in the United States to the German tune ' begin "O Christmas tree", giving rise to the mistaken idea that the German word ' (fir tree) means "Christmas tree", the German word for which is instead "".
When Johnson was Vice President of the Edison Electric Light Company, a predecessor of Con Edison, he created the first known electrically illuminated Christmas tree at his home in New York City in 1882. Edward H. Johnson became the Father of Electric Christmas Tree Lights.
1935 to present.
In Russia, the Christmas tree was banned after the October Revolution but then reinstated as a "New-year spruce" () in 1935. It became a fully secular icon of the New Year holiday, for example, the crowning star was regarded not as a symbol of Bethlehem Star, but as the Red star. Decorations, such as figurines of airplanes, bicycles, space rockets, cosmonauts, and characters of Russian fairy tales, were produced. This tradition persists after the fall of the USSR, with the New Year holiday outweighing the Christmas (7 January) for a wide majority of Russian people.
The TV special "A Charlie Brown Christmas" (1965) was influential on the pop culture surrounding the Christmas tree. Aluminum Christmas trees were popular during the early 1960s in the US. They were satirized in the Charlie Brown show and came to be seen as symbolizing the commercialization of Christmas. The term "Charlie Brown Christmas tree", describing any poor-looking or malformed little tree, also derives from the 1965 TV special, based on the appearance of Charlie Brown's Christmas tree.
Public Christmas trees.
Since the early 20th century, it has become common in many cities, towns, and department stores to put up public Christmas trees outdoors, such as the Macy's Great Tree in Atlanta (since 1948), the Rockefeller Center Christmas Tree in New York City, and the large Christmas tree at Victoria Square in Adelaide.
The use of fire retardant allows many indoor public areas to place real trees -and be compliant with code. Licensed applicants of fire retardant solution spray the tree, tag the tree, and provide a certificate for inspection. Real trees are popular with high end visual merchandising displays around the world. Leading global retailers like Apple often place real trees in their window display. In 2009 Apple placed 2 Fraser fir for every store in the world.
The United States' National Christmas Tree has been lit each year since 1923 on the South Lawn of the White House. Today, the lighting of the National Christmas Tree is part of what has become a major holiday event at the White House. President Jimmy Carter lit only the crowning star atop the tree in 1979 in honor of the Americans being held hostage in Iran. The same was true in 1980, except that the tree was fully lit for 417 seconds, one second for each day the hostages had been in captivity.
During most of the 1970s and 1980s, the largest decorated Christmas tree in the world was put up every year on the property of the "National Enquirer" in Lantana, Florida. This tradition grew into one of the most spectacular and celebrated events in the history of southern Florida, but was discontinued on the death of the paper's founder in the late 1980s.
In some cities, a Festival of Trees is organized around the decoration and display of multiple trees as charity events.
The giving of Christmas trees has also often been associated with the end of hostilities. After the signing of the Armistice in 1918 the city of Manchester sent a tree, and £500 to buy chocolate and cakes, for the children of the much-bombarded town of Lille in northern France. In some cases the trees represent special commemorative gifts, such as in Trafalgar Square in London, where the City of Oslo, Norway presents a tree to the people of London as a token of appreciation for the British support of Norwegian resistance during the Second World War; in Boston, where the tree is a gift from the province of Nova Scotia, in thanks for rapid deployment of supplies and rescuers to the 1917 ammunition ship explosion that leveled the city of Halifax; and in Newcastle upon Tyne, where the main civic Christmas tree is an annual gift from the city of Bergen, in thanks for the part played by soldiers from Newcastle in liberating Bergen from Nazi occupation. Norway also annually gifts a Christmas tree to Washington, D.C. as a symbol of friendship between Norway and the US and as an expression of gratitude from Norway for the help received from the US during World War II.
Customs and traditions.
Setting up and taking down.
Both setting up and taking down a Christmas tree are associated with specific dates. Traditionally, Christmas trees were not brought in and decorated until Christmas Eve (24 December) or, in the traditions celebrating Christmas Eve rather than the first day of Christmas, 23 December, and then removed the day after Twelfth Night (5 January); to have a tree up before or after these dates was even considered bad luck.
In many areas, it has become customary to set up one's Christmas tree at the beginning of the Advent season. Some families in the U.S. and Canada will put up a Christmas tree a week prior to American Thanksgiving (the fourth Thursday of November), and Christmas decorations can show up even earlier in retail stores, often the day after Halloween (31 October). In Canada many families wait until after Remembrance Day, as to show respect to fallen soldiers. Some households do not put up the tree until the second week of December, and leave it up until 6 January (Epiphany). In Germany, traditionally the tree is put up on 24 December and taken down on 7 January, though many start one or two weeks earlier, and in Roman Catholic homes the tree may be kept until February 2 (Candlemas).
In Italy and Argentina, along with many countries in Latin America, the Christmas tree is put up on 8 December (Immaculate Conception day) and left up until 6 January. In Australia, the Christmas tree is usually put up on 1 December, which occurs about a 2 weeks before the school summer holidays (except for South Australia, where most people put up their tree after the Adelaide Christmas Pageant in late November) and is left up until it is taken down. Some traditions suggest that Christmas trees may be kept up until no later than 2 February, the feast of the Presentation of Jesus at the Temple (Candlemas), when the Christmas season effectively closes. Superstitions say that it is a bad sign if Christmas greenery is not removed by Candlemas Eve.
Decoration.
Christmas ornaments are decorations (usually made of glass, metal, wood, or ceramics) that are used to decorate a Christmas tree. The first decorated trees were adorned with apples, white candy canes and pastries in the shapes of stars, hearts and flowers. Glass baubles were first made in Lauscha, Germany, garlands of glass beads and tin figures that could be hung on trees. The popularity of these decorations grew into the production of glass figures made by highly skilled artisans with clay molds.
The ornaments were hand-painted and topped with a cap and hook.
Tinsel and several types of garland or ribbon are commonly used to decorate a Christmas tree. Silvered saran-based tinsel was introduced later. Delicate mold-blown and painted colored glass Christmas ornaments were a specialty of the glass factories in the Thuringian Forest, especially in Lauscha in the late 19th century, and have since become a large industry, complete with famous-name designers. Baubles are another common decoration, consisting of small hollow glass or plastic spheres coated with a thin metallic layer to make them reflective, with a further coating of a thin pigmented polymer in order to provide coloration. Lighting with electric lights (fairy lights) is commonly done. A tree-topper, sometimes an angel but more frequently a star, completes the decoration.
Individuals' decorations typically include a mix of family traditions and personal tastes; even a small unattractive ornament, if passed down from a parent or grandparent, may come to carry considerable emotional value and be given a place of pride on the tree. Conversely, trees decorated by professional designers for department stores and other institutions will usually have a "theme"; a set of predominant colors, multiple instances of each type of ornament, and larger decorations that may be more complicated to set up correctly. Some churches decorate with Chrismon trees, which use handmade ornaments depicting various Chrismon symbols.
Many people also decorate outdoor trees with food that birds and other wildlife will enjoy, such as garlands made from unsalted popcorn or cranberries, orange halves, and seed-covered suet cakes.
Because candles were used to light trees until electric bulbs came about, a mat (UK) or skirt (US) was often placed on the floor below the tree to collect wax drippings and also any needles that fell. Even when drip less candles, electric lights and artificial trees have been used, a skirt is still usually used as a decorative feature: among other things, it hides the Christmas tree stand, which may be unsightly yet an important safety feature of home trees. What began as ordinary cloth has now often become much more ornate, some having embroidery or being put together like a quilt.
A nativity scene, model train, or Christmas village may be placed on the mat or skirt. As Christmas presents arrive, they are generally placed underneath the tree on the tree skirt (depending on tradition, all Christmas gifts, or those too large to be hung on the tree, as in "presents on the tree" of the song "I'll Be Home for Christmas").
Generally, the difference between a mat and skirt is simply that a mat is placed "under" the Christmas tree stand, while a skirt is placed "over" it, having a hole in the middle for the trunk, with a slot cut to the outside edge so that it can be placed around the tree (beneath the branches) easily. A plain mat of fabric or plastic may also be placed under the stand and skirt to protect the floor from scratches or water.
A Christmas tree stand is an object designed to support a cut, natural Christmas tree or an artificial Christmas tree. Christmas tree stands appeared as early as 1876 and have had various designs over the years. Those stands designed for natural trees have a water reservoir to hydrate the live tree. Artificial Christmas trees usually have a plastic or metal stand, with three legs shaping like a Y.
In the 1940s and 1950s flocking was very popular on the West Coast of the United States. There were home flocking kits that could be used with vacuum cleaners. In the 1980s some trees were sprayed with fluffy white flocking to simulate snow. Typically it would be sprayed all over the tree from the sides, which produced a look different from real snow, which settles in clumps atop branches. Flocking can be done with a professional sprayer at a tree lot (or an artificial tree's manufacturer), or at home from a spray can. This tradition seems to be most popular on the west coast and southern parts of the United States. Because flock contains flame retardants, a flocked tree can be placed in a public building in accordance with local fire safety codes.
In the late 1800s and, most probably, long before, home-made white Christmas trees were made by wrapping strips of cotton batting around leafless branches creating the appearance of a snow-laden tree. This family tradition eliminated killing and care of a live tree and needle drop in the house while providing a beautiful way of displaying ornaments. After Christmas, the cotton batting was unwrapped and stored with the Christmas presents and the branches were burnt or discarded. It is thought these home-made white trees at least, in part, inspired flocking popularized by Hollywood films in the late 1930s.
Production.
Each year, 33 to 36 million Christmas trees are produced in America, and 50 to 60 million are produced in Europe. In 1998, there were about 15,000 growers in America (a third of them "choose and cut" farms). In that same year, it was estimated that Americans spent $1.5 billion on Christmas trees.
Natural trees.
The most commonly used species are fir ("Abies"), which have the benefit of not shedding their needles when they dry out, as well as retaining good foliage color and scent; but species in other genera are also used.
In northern Europe most commonly used are:
In North America, Central America and South America most commonly used are:
Several other species are used to a lesser extent. Less-traditional conifers are sometimes used, such as giant sequoia, Leyland cypress, Monterey cypress and eastern juniper. Various types of spruce tree are also used for Christmas trees (including the blue spruce and, less commonly, the white spruce); but spruces begin to lose their needles rapidly upon being cut, and spruce needles are often sharp, making decorating uncomfortable. Virginia pine is still available on some tree farms in the southeastern United States; however, its winter color is faded. The long-needled eastern white pine is also used there, though it is an unpopular Christmas tree in most parts of the country, owing also to its faded winter coloration and limp branches, making decorating difficult with all but the lightest ornaments. Norfolk Island pine is sometimes used, particularly in Oceania, and in Australia, some species of the genera "Casuarina" and "Allocasuarina" are also occasionally used as Christmas trees. But, by far, the most common tree is the Monterey pine. "Adenanthos sericeus" or Albany woolly bush is commonly sold in southern Australia as a potted living Christmas tree. Hemlock species are generally considered unsuitable as Christmas trees due to their poor needle retention and inability to support the weight of lights and ornaments.
Some trees, frequently referred to as "living Christmas trees", are sold live with roots and soil, often from a plant nursery, to be stored at nurseries in planters or planted later outdoors and enjoyed (and often decorated) for years or decades. Others are produced in a container and sometimes as topiary for a porch or patio. However, when done improperly, the combination of root loss caused by digging, and the indoor environment of high temperature and low humidity is very detrimental to the tree's health; additionally, the warmth of an indoor climate will bring the tree out of its natural winter dormancy, leaving it little protection when put back outside into a cold outdoor climate. Often Christmas trees are a large attraction for living animals, including mice and spiders. Thus, the survival rate of these trees is low. However, when done properly, replanting provides higher survival rates.
European tradition prefers the open aspect of naturally grown, unsheared trees, while in North America (outside western areas where trees are often wild-harvested on public lands) there is a preference for close-sheared trees with denser foliage, but less space to hang decorations.
In the past, Christmas trees were often harvested from wild forests, but now almost all are commercially grown on tree farms. Almost all Christmas trees in the United States are grown on Christmas tree farms where they are cut after about ten years of growth and new trees planted. According to the United States Department of Agriculture's agriculture census for 2007, 21,537 farms were producing conifers for the cut Christmas tree market in America, were planted in Christmas trees.
The life cycle of a Christmas tree from the seed to a tree takes, depending on species and treatment in cultivation, between 8 and 12 years. First, the seed is extracted from cones harvested from older trees. These seeds are then usually grown in nurseries and then sold to Christmas tree farms at an age of 3–4 years. The remaining development of the tree greatly depends on the climate, soil quality, as well as the cultivation and how the trees are tended by the Christmas tree farmer.
Artificial trees.
The first artificial Christmas trees were developed in Germany during the 19th century, though earlier examples exist. These "trees" were made using goose feathers that were dyed green., as one response by Germans to continued deforestation. Feather Christmas trees ranged widely in size, from a small tree to a large tree sold in department stores during the 1920s. Often, the tree branches were tipped with artificial red berries which acted as candle holders.
Over the years, other styles of artificial Christmas trees have evolved and become popular. In 1930, the U.S.-based Addis Brush Company created the first artificial Christmas tree made from brush bristles. Another type of artificial tree is the aluminum Christmas tree, first manufactured in Chicago in 1958, and later in Manitowoc, Wisconsin, where the majority of the trees were produced. Most modern artificial Christmas trees are made from plastic recycled from used packaging materials, such as polyvinyl chloride (PVC). Approximately 10% of artificial Christmas trees are using virgin suspension PVC resin; despite being plastic most artificial trees are not recyclable or biodegradable.
Other trends have developed in the early 2000s as well. Optical fiber Christmas trees come in two major varieties; one resembles a traditional Christmas tree. One Dallas-based company offers "holographic mylar" trees in many hues. Tree-shaped objects made from such materials as cardboard, glass, ceramic or other materials can be found in use as tabletop decorations. Upside-down artificial Christmas trees became popular for a short time and were originally introduced as a marketing gimmick; they allowed consumers to get closer to ornaments for sale in retail stores and opened up floor space for more products.
Artificial trees became increasingly popular during the late 20th century. Users of artificial Christmas trees assert that they are more convenient, and, because they are reusable, much cheaper than their natural alternative. They are also considered much safer as natural trees can be a significant fire hazard. Between 2001 and 2007 artificial Christmas tree sales in the U.S. jumped from 7.3 million to 17.4 million.
Environmental issues.
The debate about the environmental impact of artificial trees is ongoing. Generally, natural tree growers contend that artificial trees are more environmentally harmful than their natural counterparts. However, trade groups such as the American Christmas Tree Association, continue to refute that artificial trees are more harmful to the environment, and maintain that the PVC used in Christmas trees has excellent recyclable properties.
Live trees are typically grown as a crop and replanted in rotation after cutting, often providing suitable habitat for wildlife. Alternately, live trees can be donated to livestock farmers of such animals like goats who find that such trees uncontaminated by chemical additives are excellent fodder. In some cases management of Christmas tree crops can result in poor habitat since it sometimes involves heavy input of pesticides.
Concerns have been raised about people cutting down old and rare conifers, such as the "Keteleeria evelyniana", for Christmas trees.
Real or cut trees are used only for a short time, but can be recycled and used as mulch, wildlife habitat, or used to prevent erosion. Real trees are carbon-neutral, they emit no more carbon dioxide by being cut down and disposed of than they absorb while growing. However, emissions can occur from farming activities and transportation. An independent life-cycle assessment study, conducted by a firm of experts in sustainable development, states that a natural tree will generate of greenhouse gases every year (based on purchasing from home) whereas the artificial tree will produce over its lifetime. Some people use living Christmas or potted trees for several seasons, providing a longer life cycle for each tree. Living Christmas trees can be purchased or rented from local market growers. Rentals are picked up after the holidays, while purchased trees can be planted by the owner after use or donated to local tree adoption or urban reforestation services.
Most artificial trees are made of recycled PVC rigid sheets using tin stabilizer in the recent years. In the past, lead was often used as a stabilizer in PVC, but is now banned by Chinese laws.
The use of lead stabilizer in Chinese imported trees has been an issue of concern among politicians and scientists over recent years. A 2004 study found that while in general artificial trees pose little health risk from lead contamination, there do exist "worst-case scenarios" where major health risks to young children exist. A 2008 United States Environmental Protection Agency report found that as the PVC in artificial Christmas trees aged it began to degrade. The report determined that of the 50 million artificial trees in the United States approximately 20 million were 9 or more years old, the point where dangerous lead contamination levels are reached. A professional study on the life-cycle assessment of both real and artificial Christmas trees revealed that one must use an artificial Christmas tree at least 20 years to leave an environmental footprint as small as the natural Christmas tree.
Religious issues.
The Christmas tree was first used by German Lutherans in the 16th Century, with records indicating that a Christmas tree was placed in the Cathedral of Strassburg in 1539, under the leadership of the Protestant Reformer, Martin Bucer. In the United States, these "German Lutherans brought the decorated Christmas tree with them; the Moravians put lighted candles on those trees." When decorating the Christmas tree, many individuals place a star at the top of the tree symbolizing the Star of Bethlehem, a fact recorded by "The School Journal" in 1897. Professor David Albert Jones of Oxford University writes that in the 19th century, it became popular for people to also use an angel to top the Christmas tree in order to symbolize the angels mentioned in the accounts of the Nativity of Jesus.
Under the Marxist-Leninist doctrine of state atheism in the Soviet Union, after its foundation in 1917, Christmas celebrations—along with other religious holidays—were prohibited as a result of the Soviet anti-religious campaign. The League of Militant Atheists encouraged school pupils to campaign against Christmas traditions, among them being the Christmas tree, as well as other Christian holidays, including Easter; the League established an anti-religious holiday to be the 31st of each month as a replacement. With the Christmas tree being prohibited in accordance with Soviet anti-religious legislation, people supplanted the former Christmas custom with New Year's trees. In 1935 the tree was brought back as New Year tree and became a secular, not a religious holiday.
Pope John Paul II introduced the Christmas tree custom to the Vatican in 1982. Although at first disapproved of by some as out of place at the centre of the Roman Catholic Church, the Vatican Christmas Tree has become an integral part of the Vatican Christmas celebrations, and in 2005 Pope Benedict XVI spoke of it as part of the normal Christmas decorations in Catholic homes. In 2004, Pope John Paul called the Christmas tree a symbol of Christ. This very ancient custom, he said, exalts the value of life, as in winter what is evergreen becomes a sign of undying life, and it reminds Christians of the "tree of life" of , an image of Christ, the supreme gift of God to humanity. In the previous year he said: "Beside the crib, the Christmas tree, with its twinkling lights, reminds us that with the birth of Jesus the tree of life has blossomed anew in the desert of humanity. The crib and the tree: precious symbols, which hand down in time the true meaning of Christmas." The Catholic Church's official "Book of Blessings" has a service for the blessing of the Christmas tree in a home. Likewise the Protestant Episcopal Church in "The Anglican Family Prayer Book", which has the imprimatur of The Rt. Rev. Catherine S. Roskam of the Anglican Communion, has long had a ritual titled "Blessing of a Christmas Tree", as well as "Blessing of a Crèche", for use in the church and the home.
In 2006, the Seattle–Tacoma International Airport removed all of its Christmas trees in the middle of the night rather than allow a rabbi to put up a menorah near the largest tree display. Officials feared that one display would open the door for other religious displays, and, in 2007, they opted to display a grove of birches in polyethylene terephthalate snow rather than religious symbols or Christmas trees. In 2005, the city of Boston renamed the spruce tree used to decorate the Boston Common a "Holiday Tree" rather than a "Christmas Tree". The name change drew a poor response from the public and it was reversed after the city was threatened with several lawsuits. At the Bilbao airport 2005 displayed a Christmas tree and a Santa Claus and Christmas elf alongside the Basque Olentzero, as a way of syncretising traditions in Northern Spain.
"Chrismon trees" are a variety developed in 1957 by a Lutheran laywoman in Virginia, as a specifically religious version appropriate for a church's Christmas celebrations, although most Christian churches continue to display the traditional Christmas tree in their sanctuaries during Christmastide.

</doc>
<doc id="7772" url="https://en.wikipedia.org/wiki?curid=7772" title="Carrier battle group">
Carrier battle group

A carrier battle group (CVBG) consists of an aircraft carrier (designated CV) and its large number of escorts, together defining the group. The first naval task forces built around carriers appeared just prior to and during World War II. The Imperial Japanese Navy, IJN, was the first to assemble a large number of carriers into a single task force, known as Kido Butai. This task force was used with devastating effect in the Imperial Japanese Navy's Attack on Pearl Harbor. Kido Butai operated as the IJN's main carrier battle group until four of its carriers were sunk at the Battle of Midway. In contrast, the United States Navy deployed its large carriers in separate formations, with each carrier assigned its own cruiser and destroyer escorts. These single-carrier formations would often be paired or grouped together for certain assignments, most notably the Battle of the Coral Sea and Midway. By 1943 however, large numbers of fleet and light carriers became available, which required larger formations of three or four carriers. These groups eventually formed the Fast Carrier Task Force, which became the primary battle unit of the U.S. Fifth and Third Fleets.
With the construction of the large super carriers of the Cold War era, the practice of operating each carrier in a single formation was revived. During the Cold War, the main role of the CVBG in case of conflict with the Soviet Union would have been to protect Atlantic supply routes between the United States and Europe, while the role of the Soviet Navy would have been to interrupt these sea lanes, a fundamentally easier task. Because the Soviet Union had no large carriers of its own, a situation of dueling aircraft carriers would have been unlikely. However, a primary mission of the Soviet Navy's attack submarines was to track every allied battle group and, on the outbreak of hostilities, sink the carriers. Understanding this threat, the CVBG expended enormous resources in its own anti-submarine warfare mission.
Carrier battle groups in crises.
In the late 20th and early 21st centuries, most of the uses of CVBGs by the United States as well as that of other nations have been in situations in which their use has been uncontested by other comparable forces.
Carriers in the 1956 Suez Crisis.
British and French carrier battle groups were involved in the 1956 Suez Crisis.
Carriers in the 1982 Falklands War.
During the Cold War, an important battle scenario was an attack against a CVBG using a large number of antiship missiles.
The first attempted use of antiship missiles against a carrier battle group was part of Argentina's efforts against British Armed Forces during the Falklands War. This was the last conflict so far in which two belligerents employed aircraft carriers, although Argentina made little use of its sole carrier, originally built in the United Kingdom.
Bangladesh Liberation War (Indo-Pakistan war of 1971).
During the Indo-Pakistan war of 1971 India used its carrier strike group centered on INS Vikrant to impose a naval blockade upon East Pakistan. Air strikes were carried out initially on shipping in the Chittagong and Cox's Bazar harbours, sinking or incapacitating most ships there. Further strikes were carried out on Cox's Bazar from 60 nautical miles (110 km) offshore. On the evening of 4 December, the air group struck Chittagong Harbour. Later strikes targeted Khulna and the Port of Mongla. Air strikes continued until 10 December 1971.
Lebanon.
The United States Sixth Fleet assembled a force of three carrier battle groups and a battleship during the Lebanese Civil War in 1983. Daily reconnaissance flights were flown over the Bekaa Valley and a strike was flown against targets in the area resulting in loss of an A-6 Intruder and an A-7 Corsair.
Gulf of Sidra.
Carrier battle groups routinely operated in the Gulf of Sidra inside the "Line of Death" proclaimed by Libya resulting in aerial engagements in 1981, 1986 and 1989 between U.S. Navy Tomcats and Libyan Su-22 aircraft, SA-5 surface-to-air missiles and MiG-23 fighters. During the 1986 clashes, three carrier battle groups deployed to the Gulf of Sidra and ultimately two of them conducted strikes against Libya in Operation El Dorado Canyon.
Libya.
During the international military intervention in the 2011 Libyan civil war, the French Navy deployed its aircraft carrier, , off Libya. The "Charles de Gaulle" was accompanied by several frigates as , , , the replenishment tanker "Meuse" and two nuclear attack submarines.
U.S. Navy Battle Groups.
Carrier strike group.
In modern United States Navy carrier air operations, the moniker of carrier strike group (CSG) has replaced the traditional term of carrier battle group (CVBG or CARBATGRU). The Navy maintains 11 carrier strike groups, 9 of which are based in the United States and one that is forward deployed in Japan. CSG or CVBG normally consist of 1 Aircraft Carrier, 1 Guided Missile Cruiser (for Air Defense), 2 LAMPS (Light Airborne Multi-Purpose System) Capable Warships (focusing on Anti-Submarine and Surface Warfare), and 1–2 Anti Submarine Destroyers or Frigates. The large number of CSGs used by the United States reflects, in part, a division of roles and missions allotted during the Cold War, in which the United States assumed primary responsibility for blue water operations and for safeguarding supply lines between the United States and Europe, while the NATO allies assumed responsibility for brown and green water operations.
Expeditionary Strike Group.
An Expeditionary Strike Group is composed of an Amphibious Assault Ship (LHA/LHD), a Dock Landing Ship (LSD), an Amphibious transport dock (LPD), a Marine expeditionary unit, AV-8B Harrier II aircraft, CH-53E Super Stallion helicopters and CH-46E Sea Knight helicopters or, more recently, MV-22B tiltrotors. Cruisers, destroyers and attack submarines are deployed with either an Expeditionary Strike Group or a Carrier Strike Group.
Battleship battle group.
During the period when the American navy recommissioned all four of its s, it sometimes used a similar formation centered on a battleship, referred to as a battleship battle group (BBBG). It was alternately referred to as a Surface Action Group (SAG).
The battleship battle group typically consisted of one modernized battleship, one , one or , one , three s and one support ship, such as a fleet oiler.
Carrier battle groups.
Brazil.
The forms Brazil's only carrier battle group, together with 4 frigates from Type-22/1 class frigates and Vosper Mk.10 class frigates (known as the ), 1 or 2 s, and one replenishment oiler (), with VF-1 "Falcão" Air Wing equipped with 6 to 9 Attack Aircraft AF-1 Skyhawk (A-4Ku), and 3 more Helicopters Squadrons for Attack, ASW and Multi-Mission (between AS332 Super Puma, AS532 Cougar, Super Lynx, Esquilo, EC 725 (16 ordered) SH-3 (being replaced by 6 new SH-60B)) and 2 more Fixed Wings Squadrons for AEW, COD, and REVO (C-1A Trader and S-2 Tracker ordered). The "São Paulo" was formerly the , a design used by the French Navy until 1997.
United Kingdom.
The Royal Navy did maintain two task forces concurrently (one based on an aircraft carrier and one based on an Amphibious Command Ship). At least one task group would be deployed at any one time. The last of the Royal Navy s were decommissioned in 2014. The Royal Navy also utilises the "Ocean"-class LPH as well as the two LPDs as Amphibious Command Ships at the centre of a task group. The two new s are currently under construction and will operate the F-35, replacing the retired "Invincible" class in 2019.
China.
The CNS "Liaoning" was recently spotted alongside 4 Type 052C/Type 052D destroyers, 2 Type 054A frigates, 1-2 Type 093 Shang nuclear submarine and 1 supply ship. Future carrier battle groups may include the Type 055 destroyer.
France.
The only serving French carrier is the , which also serves as the flagship of the Marine Nationale. The Carrier Battle Group (Groupe Aéronaval, GAN, in French) of the Force d'Action Navale is usually composed, in addition to the aircraft carrier, of:
This group is commanded by a rear admiral (contre-amiral, in French) on board the aircraft carrier. The commanding officer of the air group (usually a capitaine de frégate—equivalent to commander) is subordinate to the commanding officer of the aircraft carrier, a senior captain. The escort destroyers (called frigates in the French denomination) are commanded by more junior captains.
India.
The Indian Navy has been operating carrier battle groups since 1961, with its first carrier battle group formed around the now decommissioned INS "Vikrant". As of 2014, the Indian Navy operates two carrier battle groups, one centered on and the other around . "Viraat" is an updated "Centaur"-class light carrier originally built for the Royal Navy as , which was laid down in 1944 and commissioned in 1959. It was purchased by India in 1986, and is expected to be decommissioned in 2016. India commissioned in 2013 and will follow this with a third carrier, the new INS "Vikrant" in 2018. INS "Vikramaditya" is the modified , INS "Vikrant" will be the first indigenous Indian aircraft carrier. India plans to have three carrier battle groups by 2025, each centered on "Vikrant", "Vikramaditya" and "Vishal", the second, larger and is expected to be nuclear-powered Vikrant-class carrier.
The Indian Navy's carrier battle group centered on "Viraat" consists of two destroyers, usually of the (previously s were used), two or more frigates, usually of the , Godavari or Nilgiri classes, and one support ship.
The navy's new carrier battle group centered on "Vikramaditya" consists of the modern Kolkata class destroyers, Shivalik and Talwar-class frigates, Kamorta-class anti-submarine warfare corvettes and new tankers. INS Chakra II is expected to fill the sub-surface component.
Italy.
The CVS–ASW (Aircraft Carrier with Anti-Submarine Warfare) is Italy's first carrier. The battle group based in Taranto called COMFORAL is formed by the carrier "Giuseppe Garibaldi", two s, two support ships "Etna" and "Elettra", and three amphibious/support ships ("San Giusto", "San Marco" and "San Giorgio").
After 2010, the Italian battle group will be formed by the new carrier , 5–6 new warships (including destroyers "Horizon" and frigates FREMM), one new support ship, some minehunters and new submarines (the COMFORAL will be a reserve group).
Russia.
The sole Russian aircraft carrier, the is rarely out to sea. Of the few sorties the carrier has conducted, most have been solo missions and without a large escort. However, the "Kuznetsov" has been observed sailing together with a cruiser (CGN), (CG), (ASuW), (ASW) and "Krivak" I/II FFG (ASW). These escorts, especially the heavily armed "Kirov"-class cruiser, use advanced sensors and carry a variety of weaponry. However, ships like the "Kirov" would likely be used in offensive operations rather than fleet escort in the event of war. Carrier escort would then be conducted by smaller vessels such as a "Slava" class accompanied by several "Sovremenny", "Udaloy" and "Krivak" vessels.
The "Admiral Kuznetsov" is designed specifically to sail alone and carries greater firepower than its U.S. counterparts. This includes 12x SS-N-19 'Shipwreck' (long range, high speed, sea-skimming) SSMs, 24x VLS units loaded with 192 SA-N-9 'Gauntlet' SAMs, and 8x Kashtan CIWS with dual 30 mm guns, and 8x AK-630 CIWS. Compared to the 4x Phalanx CIWS and 4x Sea Sparrow launchers, each with 6 missiles carried by the "Nimitz" class, the "Kuznetsov" is well armed for both air-defence and offensive operations against hostile shipping.
Spain.
The Spanish Navy currently operates the Buque de Proyección Estratégica (Strategic Projection Vessel) , which can be used as a light aircraft carrier. The group includes two escort squadrons: the 41st, with ASW s, and the 31st, with AEGIS AAW frigates.
Underway replenishment.
Since its origins, the viability of the carrier battle group has been dependent on its ability to remain at sea for extended periods. Specialized ships were developed to provide underway replenishment of fuel (for the carrier and its aircraft), ordnance, and other supplies necessary to sustain operations. Carrier battle groups devote a great deal of planning to efficiently conduct underway replenishment to minimize the time spent conducting replenishment. The carrier can also provide replenishment on a limited basis to its escorts, but typically a replenishment ship such as a fast combat support ship (AOE) or replenishment oiler (AOR) pulls alongside a carrier and conducts simultaneous operations with the carrier on its port side and one of the escorts on its starboard side. The advent of the helicopter provides the ability to speed replenishment by lifting supplies at the same time that fuelling hoses and lines are delivering other goods.
Debate on future viability.
There is debate in naval warfare circles as to the viability of carrier battle groups in 21st century naval warfare. Proponents of the CVBG argue that it provides unmatched firepower and force projection capabilities. Opponents argue that CVBGs are increasingly vulnerable to arsenal ships and cruise missiles, especially those with supersonic or even hypersonic flight and the ability to perform radical trajectory changes to avoid anti-missile systems. It is also noted that CVBGs were designed for Cold War scenarios, and are less useful in establishing control of areas close to shore. It is argued however that such missiles and arsenal ships pose no serious threat as they would be eliminated due to increasing improvement in ship defenses such as Cooperative Engagement Capability (CEC), DEW technology and missile technology.
However, carriers have been called upon to be first responders even when conventional land based aircraft were employed. During Desert Shield, the U.S. Navy sortied additional carriers to augment the on station assets eventually maintaining six carriers for Desert Storm. Although the U.S. Air Force sent fighters such as the F-16 to theater in Desert Shield, they had to carry bombs with them as no stores were in place for sustained operations whereas the carriers arrived on scene with full magazines and had support ships to allow them to conduct strikes indefinitely.
The Global War on Terror has shown the flexibility and responsiveness of the carrier on multiple occasions when land based air was not feasible or able to respond in a timely fashion. After the September 11 terrorist attacks on the U.S., carriers immediately headed to the Arabian Sea to support Operation Enduring Freedom and took up station, building to a force of three carriers. Their steaming location was closer to the targets in Afghanistan than any land based assets and thereby more responsive. The was adapted to be a support base for special operations helicopters. Carriers were used again in Operation Iraqi Freedom and even provided aircraft to be based ashore on occasion and have done so periodically when special capabilities are needed. This precedent was established during World War II in the Battle of Guadalcanal.
Regardless of the debate over viability, the United States has made a major investment in the development of a new carrier class—the s (formerly designated CVN-X, or the X Carrier)—to replace the existing s. The new "Ford"-class carriers are designed to be modular and are easily adaptable as technology and equipment needed on board changes.

</doc>
<doc id="7773" url="https://en.wikipedia.org/wiki?curid=7773" title="Boeing Vertol CH-46 Sea Knight">
Boeing Vertol CH-46 Sea Knight

The Boeing Vertol CH-46 Sea Knight is a medium-lift tandem rotor transport helicopter powered by twin turboshaft aircraft engines. It was used by the United States Marine Corps (USMC) to provide all-weather, day-or-night assault transport of combat troops, supplies and equipment until it was replaced by the MV-22 Osprey. Additional tasks included combat support, search and rescue (SAR), support for forward refueling and rearming points, CASEVAC and Tactical Recovery of Aircraft and Personnel (TRAP).
The Sea Knight was also the U.S. Navy's standard medium-lift utility helicopter until it was phased out in favor of the MH-60S Knighthawk in the early 2000s. Canada also operated the Sea Knight, designated as CH-113, and operated them in the SAR role until 2004. Other export customers include Japan, Sweden, and Saudi Arabia. The commercial version is the BV 107-II, commonly referred to simply as the "Vertol".
Development.
Origins.
Piasecki Helicopter was a pioneering developer of tandem-rotor helicopters, with the most famous previous helicopter being the H-21 "Flying Banana". Piasecki Helicopter became Vertol in 1955 and work began on a new tandem rotor helicopter designated the "Vertol Model 107" or V-107 in 1956. The V-107 prototype had two Lycoming T53 turboshaft engines, producing 877 shp (640 kW) each. The first flight of the V-107 took place on 22 April 1958. The V-107 was then put through a flight demonstration tour in the United States and overseas. In June 1958, the U.S. Army awarded a contract to Vertol for ten production aircraft designated "YHC-1A".
The order was later decreased to three, so that the Army could divert funds for the V-114, also a turbine powered tandem, but larger than the V-107. The Army's three YHC-1As were powered by GE-T-58 engines. The YHC-1As first flew in August 1959, and were followed by an improved commercial/export model, the 107-II. During 1960, the U.S. Marine Corps evolved a requirement for a medium-lift, twin-turbine troop/cargo assault helicopter to replace the piston-engined types then in use. That same year Boeing acquired Vertol and renamed the group Boeing Vertol. Following a competition, Boeing Vertol was selected to build its model 107M as the HRB-1, early in 1961. In 1962 the U.S. Air Force ordered 12 XCH-46B Sea Knights with the "XH-49A" designation, but later cancelled the order due to a delivery delay and opted for the Sikorsky S-61R instead.
Following the Sea Knight's first flight in August 1962, the designation was changed to CH-46A. In November 1964, introduction of the Marines' CH-46A and the Navy's UH-46As began. The UH-46A variant was modified for the vertical replenishment role. The CH-46A was equipped with a pair of T58-GE8-8B turboshaft engines rated at 1,250 shp (930 kW) each and could carry 17 passengers or 4,000 pounds (1,815 kg) of cargo.
Further developments.
Production of the improved CH-46D followed with deliveries beginning in 1966. Its improvements included modified rotor blades and more powerful T58-GE-10 turboshaft engines rated at each. The increased power allowed the D-model to carry 25 troop or of cargo. The CH-46D was introduced to the Vietnam theater in late 1967, supplementing the U.S. Marine Corps' existing unreliable and problematic CH-46A fleet. Along with the USMC's CH-46Ds, the U.S. Navy received a small number of UH-46Ds for ship resupply. Also, approximately 33 CH-46As were upgraded to CH-46Ds.
The Marines also received CH-46Fs from 1968 to 1971. The F-model retained the D-model's T58-GE-10 engines but revised the avionics and included other modifications. The CH-46F was the final production model. The Sea Knight has undergone upgrades and modifications. Most of the U.S. Marine Corps' Sea Knights were upgraded to CH-46E standard. The CH-46E features fiberglass rotor blades, airframe reinforcement, and further uprated T58-GE-16 engines producing each. Some CH-46Es have been given double fuel capacity. The Dynamic Component Upgrade (DCU), incorporated starting in the mid-1990s, provides for increased capability through strengthened drive systems and rotor controls.
The commercial variant, the "BV 107-II", was first ordered by New York Airways in 1960. They took delivery of their first three aircraft, configured for 25 passengers, in July 1962. In 1965, Boeing Vertol sold the manufacturing rights of the 107 to Kawasaki Heavy Industries. Under this arrangement, all Model 107 civilian and military aircraft built in Japan are known as "KV 107". On 15 December 2006, Columbia Helicopters, Inc acquired the type certificate for the Boeing Vertol 107-II, and is in the process of acquiring a Production Certificate from the FAA. Plans for actual production of the aircraft have not been announced.
Design.
The CH-46 has tandem counter-rotating rotors powered by two GE T58 turboshaft engines. The engines are mounted on each side of the rear rotor pedestal with a driveshaft to the forward rotor. The engines are coupled so either could power both rotors in an emergency. The rotors feature three blades and can be folded for on-ship operations. The CH-46 has fixed tricycle landing gear, with twin wheels on all three landing gear legs. The gear configuration causes a nose-up stance to facilitate cargo loading and unloading. The main gear are fitted in rear sponsons that also contain fuel tanks with a total capacity of 350 US gallons (1,438 L).
The CH-46 has a cargo bay with a rear loading ramp that could be removed or left open in flight for extended cargo or for parachute drops. An internal winch is mounted in the forward cabin and can be used to pull external cargo on pallets into the aircraft via the ramp and rollers. A belly sling hook (cargo hook) which is usually rated at . could be attached for carrying external cargo. Although the hook is rated at ., the limited power produced by the engines precludes the lifting of such weight. It usually has a crew of three, but can accommodate a larger crew depending on mission specifics. For example, a Search and Rescue variant will usually carry a crew of five (Pilot, Co-Pilot, Crew Chief, Swimmer, and Medic) to facilitate all aspects of such a mission. A pintle-mounted 0.50 in (12.7 mm) Browning machine gun is mounted on each side of the helicopter for self-defense. Service in southeast Asia resulted in the addition of armor with the guns.
Operational history.
United States.
Known colloquially as the "Phrog", the Sea Knight was used in all U.S. Marine operational environments between its introduction during the Vietnam War and its frontline retirement in 2014. The type's longevity and reputation for reliability led to mantras such as "phrogs phorever" and "never trust a helicopter under 30". CH-46s transported personnel, evacuated wounded, supplied forward arming and refueling points (FARP), performed vertical replenishment, search and rescue, recovered downed aircraft and crews and other tasks.
During the Vietnam War, the CH-46 was one of the prime US troop transport helicopters in the theatre, slotting between the smaller Bell UH-1 Iroquois and larger Sikorsky CH-53 Sea Stallion. During the 1972 Easter Offensive, Sea Knights saw heavy use to convey US and South Vietnamese ground forces to and around the front lines. CH-46 operations were plagued by major technical problems; the engines, being prone to foreign object damage (FOD) from debris being ingested when hovering close to the ground and subsequently suffering a compressor stall, had a lifespan as low as 85 flight hours; on 21 July 1966, all CH-46s were grounded until more efficient filters had been fitted. By the end of US military operations in Vietnam, over a hundred Sea Knights had been lost to enemy fire.
In February 1968 the Marine Corps Development and Education Command obtained several CH-46s to perform herbicide dissemination tests using HIDAL (Helicopter, Insecticide Dispersal Apparatus, Liquid) systems; testing indicated the need for redesign and further study. Tandem-rotor helicopters were often used to transport nuclear warheads; the CH-46A was evaluated to deploy Naval Special Forces with the Special Atomic Demolition Munition (SADM). Nuclear Weapon Accident Exercise 1983 (NUWAX-83), simulating the crash of a Navy CH-46E carrying 3 nuclear warheads, was conducted at the Nevada Test Site on behalf of several federal agencies; the exercise, which used real radiological agents, was depicted in a Defense Nuclear Agency-produced documentary.
U.S. Marine CH-46s were used to deploy the 8th Marine Regiment into Grenada during Operation Urgent Fury, evacuated the surviving crew-member of a downed AH-1 Cobra, and then carried infantry from the 75th Ranger Regiment to secure an evacuate U.S. students at the Grand Anse campus of St. George's University, though one crashed after colliding with a palm tree.
CH-46E Sea Knights were also used by the U.S. Marine Corps during the 2003 invasion of Iraq. In one incident on 1 April 2003, Marine CH-46Es and CH-53Es carried U.S. Army Rangers and Special Operations troops on an extraction mission for captured Army Private Jessica Lynch from an Iraqi hospital. During the subsequent occupation of Iraq and counter-insurgency operations, the CH-46E was heavily used in the CASEVAC role, being required to maintain 24/7 availability regardless of conditions. According to authors Williamson Murray and Robert H Scales, the Sea Knight displayed serious reliability and maintenance problems during its deployment to Iraq, as well as "limited lift capabilities". Following the loss of numerous US helicopters in the Iraqi theatre, the Marines opted to equip their CH-46s with more advanced anti-missile countermeasures.
The U.S. Navy retired the type on 24 September 2004, replacing it with the MH-60S Seahawk; the Marine Corps maintained its fleet as the MV-22 Osprey was fielded. In March 2006 Marine Medium Helicopter Squadron 263 (HMM-263) was deactivated and redesignated VMM-263 to serve as the first MV-22 squadron. The replacement process continued through the other medium helicopter squadrons into 2014. On 5 October 2014, the Sea Knight performed its final service flight with the U.S. Marine Corps at Marine Corps Air Station Miramar. HMM-364 was the last squadron to use it outside the United States, landing it aboard the USS America (LHA-6) on her maiden transit. On 9 April 2015, the CH-46 was retired by the Marine Medium Helicopter Training Squadron 164, the last Marine Corps squadron to transition to the MV-22. The USMC retired the CH-46 in a formal ceremony on 1 August 2015.
Canada.
The Royal Canadian Air Force procured six CH-113 Labrador helicopters for the SAR role and the Canadian Army acquired 12 of the similar "CH-113A Voyageur" for the medium-lift transport role. The RCAF Labradors were delivered first with the first one entering service on 11 October 1963. When the larger CH-147 Chinook was procured by the Canadian Forces in the mid-1970s, the Voyageur fleet was converted to Labrador specifications to undertake SAR missions. The refurbished Voyageurs were re-designated as CH-113A Labradors, thus a total of 15 Labradors were ultimately in service.
The Labrador was fitted with a watertight hull for marine landings, a 5,000 kilogram cargo hook and an external rescue hoist mounted over the right front door. It featured a 1,110 kilometer flying range, emergency medical equipment and an 18-person passenger capacity. By the 1990s, heavy use and hostile weather conditions had taken their toll on the Labrador fleet, resulting in increasing maintenance costs and the need for prompt replacement. In 1981, a mid-life upgrade of the fleet was carried out by Boeing Canada in Arnprior, Ontario. Known as the SAR-CUP (Search and Rescue Capability Upgrade Program), the refit scheme included new instrumentation, a nose-mounted weather radar, a tail-mounted auxiliary power unit, a new high-speed rescue hoist mounted over the side door and front-mounted searchlights. A total of six CH-113s and five CH-113As were upgraded with the last delivered in 1984.
In 1992, it was announced that the Labradors were to be replaced by 15 new helicopters, a variant of the AgustaWestland EH101, designated "CH-149 Chimo". The order was subsequently cancelled by the Jean Chrétien Liberal government in 1993, resulting in cancellation penalties, as well as extending the service life of the Labrador fleet. However, in 1998, a CH-113 from CFB Greenwood crashed on Quebec's Gaspé Peninsula while returning from a SAR mission, resulting in the deaths of all crewmembers on board. The crash placed pressure upon the government to procure a replacement, thus an order was placed with the manufacturers of the EH101 for 15 aircraft to perform the search-and-rescue mission, designated "CH-149 Cormorant". CH-149 deliveries began in 2003, allowing the last CH-113 to be retired in 2004. In October 2005 Columbia Helicopters of Aurora, Oregon purchased eight of the retired CH-113 Labradors to add to their fleet of 15 Vertol 107-II helicopters.
Sweden.
In 1963, Sweden procured ten UH-46B from the US as a transport and anti-submarine helicopter for the Swedish armed forces, designated Hkp 4A. In 1973, a further eight Kawasaki-built KV-107, which were accordingly designated Hkp 4B, were acquired to replace the older Piasecki H-21. During the Cold War, the fleet's primary missions were anti-submarine warfare and troop transportation, they were also frequently employed in the search and rescue role. In the 1980s, the Hkp 4A was phased out, having been replaced by the Eurocopter AS332 Super Puma; the later Kawasaki-built Sea Knights continued in operational service until 2011, they were replaced by the UH-60 Black Hawk & NH90.
Civilian.
The civilian version, designated as the BV 107-II "Vertol", was developed prior to the military CH-46. It was operated commercially by New York Airways, Pan American World Airways and later on by Columbia Helicopters. Among the diversity of tasks was pulling a hover barge, and constructing transmission towers for overhead power lines.
In December 2006, Columbia Helicopters purchased the type certificate of the Model 107 from Boeing, with the aim of eventually producing new-build aircraft themselves.
Variants.
Japanese versions.
Source:

</doc>
<doc id="7774" url="https://en.wikipedia.org/wiki?curid=7774" title="Chief of Naval Operations">
Chief of Naval Operations

The Chief of Naval Operations (CNO) is a statutory office () held by a four-star admiral in the United States Navy, and is the most senior naval officer assigned to serve in the Department of the Navy. The office is a military adviser and deputy to the Secretary of the Navy. In a separate capacity as a member of the Joint Chiefs of Staff () the CNO is a military adviser to the National Security Council, the Homeland Security Council, the Secretary of Defense, and the President. The current Chief of Naval Operations is Admiral John M. Richardson.
The Chief of Naval Operations is an administrative position based in the Pentagon, and while the CNO does not have operational command authority over Naval forces as the title implies (that is nowadays within the purview of the Combatant Commanders who report to the Secretary of Defense), the CNO does exercise supervision of Navy organizations as the designee of the Secretary of the Navy.
Responsibilities.
Department of the Navy.
The CNO reports directly to the Secretary of the Navy for the command, utilization of resources, and operating efficiency of the operating forces of the Navy and of the Navy shore activities assigned by the Secretary. Under the authority of the Secretary of the Navy, the CNO also designates naval personnel and naval resources to the commanders of Unified Combatant Commands. The CNO also performs all other functions prescribed under and those assigned by the secretary or delegates those duties and responsibilities to other officers in his administration. The CNO is typically the highest-ranking officer on active duty in the Navy unless the Chairman and/or the Vice Chairman of the Joint Chiefs of Staff are naval officers. Like the other joint chiefs, the CNO is an administrative position and has no operational command authority over United States naval forces.
Office of the Chief of Naval Operations.
The Chief of Naval Operations presides over the Office of the Chief of Naval Operations (OpNav), which is one of three headquarters staffs in Department of the Navy (the others being the Office of the Secretary of the Navy and Headquarters Marine Corps.)
Policy documents are issued in the form of OPNAV Instructions.
Appointment.
The Chief of Naval Operations is nominated by the President for appointment and must be confirmed by the Senate. A requirement for being Chief of Naval Operations is having significant experience in joint duty assignments, which includes at least one full tour of duty in a joint duty assignment as a flag officer. However, the president may waive those requirements if he determines that appointing the officer is necessary for the national interest. By statute, the CNO is appointed as a four-star admiral.
Official Residence.
Number One Observatory Circle, located on the northeast grounds of the United States Naval Observatory in Washington, DC, was built in 1893 for its superintendent. The Chief of Naval Operations liked the house so much that in 1923 he took over the house as his own official residence. It remained the residence of the CNO until 1974, when Congress authorized its transformation to an official residence for the Vice President. The Chief of Naval Operations currently resides in Quarters A in the Washington Naval Yard.
List of Chiefs of Naval Operations (1915–present).
The position of CNO replaced the position of Aide for Naval Operations, which was a position established by regulation rather than statutory law.

</doc>
<doc id="7775" url="https://en.wikipedia.org/wiki?curid=7775" title="Clara Petacci">
Clara Petacci

Clara Petacci, known as Claretta Petacci (; 28 February 1912 – 28 April 1945) was the mistress of the Italian dictator Benito Mussolini, and was executed with him by partisans.
Relationship with Mussolini.
Petacci had a long-standing relationship with Mussolini while he was married to Rachele Mussolini. Mussolini was twenty-eight years Petacci's senior.
Part of their correspondence is still the subject of a dispute with the National Archives, based on privacy.
Death.
On 27 April 1945, Mussolini and Petacci were captured by partisans while traveling with a convoy of Italian Social Republic members.
On 28 April, she and Mussolini were taken to Mezzegra and shot. On the following day, 29 April, Mussolini's and Petacci's bodies were taken to the Piazzale Loreto in Milan and hung upside down in front of a petrol station. The bodies were photographed as a crowd vented their rage upon them.

</doc>
<doc id="7780" url="https://en.wikipedia.org/wiki?curid=7780" title="Costa Smeralda">
Costa Smeralda

The Costa Smeralda (, , ) is a coastal area and tourist destination in northern Sardinia, Italy, with a length of some 20 km, although the term originally designated only a small stretch in the commune of Arzachena. With white sand beaches, golf clubs, private jet and helicopter services and exclusive hotels, the area has drawn celebrities, business leaders and other affluent visitors. In a study released by the European luxury real estate brokerage Engel & Völkers, Costa Smeralda, is the most expensive location in Europe. House prices reach up to 30,000 euros per square meter.
The main towns and villages in the area, built according to a detailed urban plan, are Porto Cervo, Liscia di Vacca, Capriccioli and Romazzino. Archaeological sites include the Li Muri Giants' graves.
Each September the Sardinia Cup sailing regatta is held off the coast. Polo matches are held between April and October at Gershan near Arzachena. Other attractions include a film festival in Tavolara and a vintage car rally.
Development of the area started in 1961, and was financed by a consortium of companies led by Prince Karim Aga Khan. Spiaggia del Principe, one of the beaches along the Costa Smeralda, was named after this Ishmaelite prince. Architects involved in the project included Michele Busiri Vici, Jacques Couëlle, Savin Couëlle and Vietti.

</doc>
<doc id="7781" url="https://en.wikipedia.org/wiki?curid=7781" title="Chianti">
Chianti

A Chianti wine is any wine produced in the Chianti region, in central Tuscany, Italy. It was historically associated with a squat bottle enclosed in a straw basket, called a "fiasco" ("flask"; "pl. fiaschi"); however, the "fiasco" is only used by a few makers of the wine now; most Chianti is now bottled in more standard shaped wine bottles. Baron Bettino Ricasoli (later Prime Minister of the Kingdom of Italy) created the Chianti recipe of 70% Sangiovese, 15% Canaiolo and 15% Malvasia bianca in the middle of the nineteenth century.
The first definition of a wine-area called "Chianti" was made in 1716. It described the area near the villages of Gaiole, Castellina and Radda; the so-called "Lega del Chianti" and later "Provincia del Chianti" (Chianti province). In 1932 the Chianti area was completely re-drawn and divided in seven sub-areas: Classico, Colli Aretini, Colli Fiorentini, Colline Pisane, Colli Senesi, Montalbano and Rùfina. Most of the villages that in 1932 were suddenly included in the new Chianti Classico area added "in Chianti" to their name-such as Greve in Chianti which amended its name in 1972. Wines labelled "Chianti Classico" come from the biggest sub-area of Chianti, that includes the original Chianti heartland. Only Chianti from this sub-zone may boast the black rooster seal (known in Italian as a "gallo nero") on the neck of the bottle, which indicates that the producer of the wine is a member of the Chianti Classico Consortium, the local association of producers. Other variants, with the exception of Rufina from the north-east side of Florence and Montalbano in the south of Pistoia, originate in the respective named provinces: Siena for the Colli Senesi, Florence for the Colli Fiorentini, Arezzo for the Colli Aretini and Pisa for the Colline Pisane. In 1996 part of the Colli Fiorentini sub-area was renamed "Montespertoli".
During the 1970s producers started to reduce the quantity of white grapes in Chianti. In 1995 it became legal to produce a Chianti with 100% Sangiovese. For a wine to retain the name of Chianti, it must be produced with at least 80% Sangiovese grapes. Aged Chianti (38 months instead of 4–7), may be labelled as Riserva. Chianti that meets more stringent requirements (lower yield, higher alcohol content and dry extract) may be labelled as Chianti Superiore, although Chianti from the "Classico" sub-area is not allowed in any event to be labelled as "Superiore".
History.
The earliest documentation of a "Chianti wine" dates back to the thirteenth century when viticulture was known to flourish in the ""Chianti Mountains"" around Florence. The merchants in the nearby townships of Castellina, Gaiole and Radda formed the "Lega del Chianti" (League of Chianti) to produce and promote the local wine. In 1398, records note that the earliest incarnation of Chianti was as a white wine. In 1716 Cosimo III de' Medici, Grand Duke of Tuscany issued an edict legislating that the three villages of the "Lega del Chianti" (Castellina in Chianti, Gaiole in Chianti, and Radda in Chianti) as well as the village of Greve and a of hillside north of Greve near Spedaluzzo as the only officially recognized producers of Chianti. This delineation existed until July 1932, when the Italian government expanded the Chianti zone to include the outlying areas of Barberino Val d'Elsa, Chiocchio, Robbiano, San Casciano in Val di Pesa and Strada. Subsequent expansions in 1967 would eventually bring the Chianti zone to cover a very large area all over central Tuscany.
By the eighteenth century, Chianti was widely recognized as a red wine, but the exact composition and grape varieties used to make Chianti at this point is unknown. Ampelographers find clues about which grape varieties were popular at the time in the writings of Italian writer Cosimo Villifranchi who noted that Canaiolo was widely planted variety in the area along with Sangiovese, Mammolo and Marzemino. It was not until the work of the Italian statesman Bettino Ricasoli that the modern "Chianti recipe" as a Sangiovese-based wine would take shape. Prior to Ricasoli, Canaiolo was emerging as the dominant variety in the Chianti blend with Sangiovese and Malvasia playing supporting roles. In the mid-nineteenth century, Ricasoli developed a recipe for Chianti that was based primarily on Sangiovese. His recipe called for 70% Sangiovese, 15% Canaiolo, 10% Malvasia (later amended to include Trebbiano) and 5% other local red varieties. In 1967, the Denominazione di origine controllata (DOC) regulation set by the Italian government firmly established the "Ricasoli formula" of a Sangiovese-based blend with 10–30% Malvasia and Trebbiano.
The late nineteenth century saw a period of economic and political upheaval. First came oidium and then the phylloxera epidemic would take its toll on the vineyards of Chianti just as they had ravaged vineyards across the rest of Europe. The chaos and poverty following the "Risorgimento" heralded the beginning of the Italian diaspora that would take Italian vineyard workers and winemakers abroad as immigrants to new lands. Those that stayed behind and replanted choose high-yielding varieties like Trebbiano and Sangiovese clones such as the "Sangiovese di Romagna" from the nearby Romagna region. Following World War II, the general trend in the world wine market for cheap, easy-drinking wine saw a brief boom for the region. With over-cropping and an emphasis on quantity over quality, the reputation of Chianti among consumers eventually plummeted. By the 1950s, Trebbiano (which is known for its neutral flavours) made up to 30% of many mass-market Chiantis. By the late twentieth century, Chianti was often associated with basic Chianti sold in a squat bottle enclosed in a straw basket, called a "fiasco". However, during the same period, a group of ambitious producers began working outside the boundaries of DOC regulations to make what they believed would be a higher quality style of Chianti. These wines eventually became known as the "Super Tuscans".
Many of the producers behind the Super Tuscan movement were originally Chianti producers who were rebelling against what they felt were antiquated DOC regulations. Some of these producers wanted to make Chiantis that were 100% varietal Sangiovese. Others wanted the flexibility to experiment with blending French grape varieties such as Cabernet Sauvignon and Merlot or to not be required to blend in any white grape varieties. The late twentieth century saw a flurry of creativity and innovation in the Chianti zones as producers experimented with new grape varieties and introduced modern wine-making techniques such as the use of new oak barrels. The prices and wine ratings of some Super Tuscans would regularly eclipse those of DOC sanctioned Chiantis. The success of the Super Tuscans encouraged government officials to reconsider the DOC regulations in order to bring some of these wines back into the fold labelled as Chianti.
Chianti subregions.
The Chianti region covers a vast area of Tuscany and includes within its boundaries several overlapping "Denominazione di origine controllata" (DOC) and "Denominazione di Origine Controllata e Garantita" (DOCG) regions. Other well known Sangiovese-based Tuscan wines such as Brunello di Montalcino and Vino Nobile di Montepulciano could be bottled and labeled under the most basic designation of "Chianti" if their producers chose to do so. Within the collective Chianti region more than 8 million cases of wines classified as DOC level or above are produced each year. Today, most Chianti falls under two major designations of Chianti DOCG, which includes basic level Chianti, as well as that from seven designated sub-zones, and Chianti Classico DOCG. Together, these two Chianti zones produce the largest volume of DOC/G wines in Italy.
The Chianti DOCG covers all the Chianti wine and includes a large stretch of land encompassing the western reaches of the province of Pisa near the coast of the Tyrrhenian Sea, the Florentine hills in the province of Florence to the north, to the province of Arezzo in the east and the Siena hills to the south. Within this regions are vineyards that overlap the DOCG regions of Brunello di Montalcino, Vino Nobile di Montepulciano and Vernaccia di San Gimignano. Any Sangiovese-based wine made according to the Chianti guidelines from these vineyards can be labelled and marked under the basic Chianti DOCG should the producer wish to use the designation.
Within the Chianti DOCG there are eight defined sub-zones that are permitted to affix their name to the wine label. Wines that are labeled as simply Chianti are made either from a blend from these sub-zones or include grapes from peripheral areas not within the boundaries of a sub-zone. The sub-zones are (clockwise from the north): the Colli Fiorentini which is located south of the city of Florence; Chianti Rufina in the northeastern part of the zone located around the commune of Rufina; Classico in the centre of Chianti, across the provinces of Florence and Siena; Colli Aretini in the Arezzo province to the east; Colli Senesi south of Chianti Classico in the Siena hills, which is the largest of the sub-zones and includes the Brunello di Montalcino and Vino Nobile di Montepulciano areas; Colline Pisane, the westernmost sub-zone in the province of Pisa; Montespertoli located within the Colli Fiorentini around the commune of Montespertoli; Montalbano in the north-west part of the zone which includes the Carmignano DOCG. , there were under production in Montalbano, in the Colli Fiorentini, in Montespertoli, in Rufina, in the Colli Senesi, in Colline Pisane, in the Colli Aretini, and an additional in the peripheral areas that do not fall within one of the sub-zone classifications. Wines produced from these vineyards are labelled simply "Chianti".
Chianti Classico.
The original area dictated by the edict of Cosimo III de' Medici would eventually be considered the heart of the modern "Chianti Classico" subregion. , there were of vineyards in the Chianti Classico subregion. The Chianti Classico subregion covers an area of approximate between the city of Florence to the north and Siena to the south. The four communes of Castellina in Chianti, Gaiole in Chianti, Greve in Chianti and Radda in Chianti are located entirely within the boundaries of the Classico area with parts of Barberino Val d'Elsa, San Casciano in Val di Pesa and Tavarnelle Val di Pesa in the province of Florence as well as Castelnuovo Berardenga and Poggibonsi in the province of Siena included within the permitted boundaries of Chianti Classico. The soil and geography of this subregion can be quite varied, with altitudes ranging from , and rolling hills producing differing macroclimates. There are two main soil types in the area: a weathered sandstone known as "alberese" and a bluish-gray chalky marlstone known as "galestro". The soil in the north is richer and more fertile with more "galestro", with the soil gradually becoming harder and stonier with more "albarese" in the south. In the north, the Arno river can have an influence on the climate, keeping the temperatures slightly cooler, an influence that diminishes further south in the warmer Classico territory towards Castelnuovo Berardenga.
Chianti Classico are premium Chianti wines that tend to be medium-bodied with firm tannins and medium-high to high acidity. Floral, cherry and light nutty notes are characteristic aromas with the wines expressing more notes on the mid-palate and finish than at the front of the mouth. As with Bordeaux, the different zones of Chianti Classico have unique characteristics that can be exemplified and perceived in some wines from those areas. According to Master of Wine Mary Ewing-Mulligan, Chianti Classico wines from the Castellina area tend to have a very delicate aroma and flavor, Castelnuovo Berardegna wines tend to be the most ripe and richest tasting, wines from Gaiole tend to have been characterized by their structure and firm tannins while wines from the Greve area tend to have very concentrated flavours.
The production of Chianti Classico is realised under the supervision of Consorzio del Vino Chianti Classico, a union of producers in the Chianti Classico subregion. The Consorzio was founded with the aim of promoting the wines of the subregion, improving quality and preventing wine fraud. Since the 1980s, the foundation has sponsored extensive research into the viticultural and winemaking practice of the Chianti Classico area, particularly in the area of clonal research. In the last three decades, more than 50% of the vineyards in the Chianti Classico subregion have been replanted with improved Sangiovese clones and modern vineyard techniques as part of the Consorzio Chianti Classico's project "Chianti 2000".
In 2014 a new category of Chianti Classico was introduced: Chianti Classico Gran Selezione. Gran Selezione is made exclusively from a winery’s own grapes grown according to stricter regulations compared to regular Chianti Classico. Gran Selezione is granted to a Chianti Classico after it passes a suitability test conducted
by authorized laboratories and after it is approved by a special tasting committee.
Greater Chianti region.
Outside of the Chianti Classico area, the wines of the Chianti sub-zone of Rufina are among the most widely recognized and exported from the Chianti region. Located in the Arno valley near the town of Pontassieve, the Rufina region includes much area in the Pomino region, an area that has a long history of wine production. The area is noted for the cool climate of its elevated vineyards located up to . The vineyard soils of the area are predominantly marl and chalk. The Florentine merchant families of the Antinori and Frescobaldi own the majority of the vineyards in Rufina. Chianti from the Rufina area is characterized by its multi-layered complexity and elegance.
The Colli Fiorentini subregion has seen an influx of activity and new vineyard development in recent years as wealthy Florentine business people move to the country to plant vineyards and open wineries. Many foreign "flying winemakers" have had a hand in this development, bringing global viticulture and winemaking techniques to the Colli Fiorentini. Located in the hills between the Chianti Classico area and Arno valley, the wines of the Colli Fiorentini vary widely depending on producer, but tend to have a simple structure with strong character and fruit notes. The Montespertoli sub-zone was part of the Colli Fiorentini sub-zone until 2002 when it became its own tiny enclave.
The Montalbano subregion is located in the shadow of the Carmignano DOCG, with much of the best Sangiovese going to that wine. A similar situation exists in the Colli Senesi which includes the well known DOCG region of Vino Nobile di Montepulciano. Both regions rarely appear on wine labels that are exported out of Tuscany. The Colli Pisane area produces typical Chiantis with the lightest body and color. The Colli Aretini is a relatively new and emerging area that has seen an influx of investment and new winemaking in recent years.
Grapes and classification.
Since 1996 the blend for Chianti and Chianti Classico has been 75–100% Sangiovese, up to 10% Canaiolo and up to 20% of any other approved red grape variety such as Cabernet Sauvignon, Merlot or Syrah. Since 2006, the use of white grape varieties such as Malvasia and Trebbiano have been prohibited in Chianti Classico. Chianti Classico must have a minimum alcohol level of at least 12% with a minimum of 7 months aging in oak, while Chianti Classico's labeled "riserva" must be aged at least 24 months at the winery, with a minimum alcohol level of at least 12.5%. The harvest yields for Chianti Classico are restricted to no more than . For basic Chianti, the minimum alcohol level is 11.5% with yields restricted to .
The aging for basic Chianti DOCG is much less stringent with most varieties allowed to be released to the market on 1 March following the vintage year. The sub-zones of Colli Fiorentini, Montespertoli and Rufina must be aged for a further three months and not released until 1 June. All Chianti Classicos must be held back until 1 October in the year following the vintage.
Jancis Robinson notes that Chianti is sometimes called the "Bordeaux of Italy". The flexibility in the blending recipe for Chianti accounts for some of the variability in styles among Chiantis. Lighter bodied styles will generally have a higher proportion of white grape varieties blended in, while Chiantis that have only red grape varieties will be fuller and richer. While only 15% of Cabernet Sauvignon is permitted in the blend, the nature of the grape variety can have a dominant personality in the Chianti blend and be a strong influence in the wine.
Chianti Classico wines are characterized in their youth by their predominantly floral and cinnamon spicy bouquet. As the wine ages, aromas of tobacco and leather can emerge. Chiantis tend to have medium-high acidity and medium tannins. The acidity in the wines make them very flexible with food and wine pairings, particularly with Italian cuisines that feature red sauce, as well as with beef, lamb and game. Basic level Chianti is often characterized by its juicy fruit notes of cherry, plum and raspberry and can range from simple quaffing wines to those approaching the level of Chianti Classico. Wine expert Tom Stevenson notes that these basic everyday-drinking Chiantis are at their peak drinking qualities often between three and five years after vintage with premium examples having the potential to age for four to eight years. Well-made examples of Chianti Classico often have the potential to age and improve in the bottle for six to twenty years.
Chianti Superiore.
Chianti Superiore is an Italian DOCG wine produced in the provinces of Arezzo, Florence, Pisa, Pistoia, Prato and Siena, in Tuscany. Superiore is a specification for wines produced with a stricter rule of production than other Chianti wines. Chianti Superiore has been authorized since 1996. Chianti Superiore wines can be produced only from grapes cultivated in the Chianti wine areas except from those vineyards that are registered in the Chianti Classico sub-zone. Vineyards registered in Chianti sub-zones other than Classico can produce Chianti Superiore wines but must omit the sub-zone name on the label. Aging is calculated from 1 January after the picking. Chianti Superiore cannot be sold to the consumer before nine months of aging, of which three must be in the bottle. Therefore, it cannot be bottled before the June after picking or sold to consumers before the next September.
Special editions.
Chianti Classico was promoted as the “Official wine of the 2013 UCI Road World Championships” and sold bottles dedicated to the Championships with special labels.

</doc>
<doc id="7783" url="https://en.wikipedia.org/wiki?curid=7783" title="Coriolis force">
Coriolis force

In physics, the Coriolis force is an inertial force (also called a "fictitious force") that acts on objects that are in motion relative to a rotating reference frame. In a reference frame with clockwise rotation, the force acts to the left of the motion of the object. In one with anticlockwise rotation, the force acts to the right. Though recognized previously by others, the mathematical expression for the Coriolis force appeared in an 1835 paper by French scientist Gaspard-Gustave de Coriolis, in connection with the theory of water wheels. Early in the 20th century, the term "Coriolis force" began to be used in connection with meteorology. Deflection of an object due to the Coriolis force is called the 'Coriolis effect'.
Newton's laws of motion describe the motion of an object in an inertial (non-accelerating) frame of reference. When Newton's laws are transformed to a rotating frame of reference, the Coriolis force and centrifugal force appear. Both forces are proportional to the mass of the object. The Coriolis force is proportional to the rotation rate and the centrifugal force is proportional to its square. The Coriolis force acts in a direction perpendicular to the rotation axis and to the velocity of the body in the rotating frame and is proportional to the object's speed in the rotating frame. The centrifugal force acts outwards in the radial direction and is proportional to the distance of the body from the axis of the rotating frame. These additional forces are termed inertial forces, fictitious forces or "pseudo forces". They allow the application of Newton's laws to a rotating system. They are correction factors that do not exist in a non-accelerating or inertial reference frame.
A commonly encountered rotating reference frame is the Earth. The Coriolis effect is caused by the rotation of the Earth and the inertia of the mass experiencing the effect. Because the Earth completes only one rotation per day, the Coriolis force is quite small, and its effects generally become noticeable only for motions occurring over large distances and long periods of time, such as large-scale movement of air in the atmosphere or water in the ocean. Such motions are constrained by the surface of the Earth, so only the horizontal component of the Coriolis force is generally important. This force causes moving objects on the surface of the Earth to be deflected to the right (with respect to the direction of travel) in the Northern Hemisphere and to the left in the Southern Hemisphere. The horizontal deflection effect is greater near the poles and smallest at the equator, since the rate of change in the diameter of the circles of latitude when travelling north or south, increases the closer the object is to the poles. Rather than flowing directly from areas of high pressure to low pressure, as they would in a non-rotating system, winds and currents tend to flow to the right of this direction north of the equator and to the left of this direction south of it. This effect is responsible for the rotation of large cyclones (see Coriolis effects in meteorology). To explain this intuitively, consider how an object that moves northwards from the equator has a tendency to maintain its greater speed at the equator (rotating around towards the right as you look at the sphere of the Earth), where the "horizontal diameter" is larger, and therefore tends to move towards the right as it passed northwards where the "horizontal diameter" of the Earth (the rings of latitude) is smaller, and the linear speed of local objects on the Earth's surface at that latitude is slower.
History.
Italian scientist Giovanni Battista Riccioli and his assistant Francesco Maria Grimaldi described the effect in connection with artillery in the 1651 "Almagestum Novum", writing that rotation of the Earth should cause a cannonball fired to the north to deflect to the east. The effect was described in the tidal equations of Pierre-Simon Laplace in 1778.
Gaspard-Gustave Coriolis published a paper in 1835 on the energy yield of machines with rotating parts, such as waterwheels. That paper considered the supplementary forces that are detected in a rotating frame of reference. Coriolis divided these supplementary forces into two categories. The second category contained a force that arises from the cross product of the angular velocity of a coordinate system and the projection of a particle's velocity into a plane perpendicular to the system's axis of rotation. Coriolis referred to this force as the "compound centrifugal force" due to its analogies with the centrifugal force already considered in category one. The effect was known in the early 20th century as the "acceleration of Coriolis", and by 1920 as "Coriolis force".
In 1856, William Ferrel proposed the existence of a circulation cell in the mid-latitudes with air being deflected by the Coriolis force to create the prevailing westerly winds.
Understanding the kinematics of how exactly the rotation of the Earth affects airflow was partial at first. Late in the 19th century, the full extent of the large scale interaction of pressure gradient force and deflecting force that in the end causes air masses to move 'along' isobars was understood.
Formula.
In non-vector terms: at a given rate of rotation of the observer, the magnitude of the Coriolis acceleration of the object is proportional to the velocity of the object and also to the sine of the angle between the direction of movement of the object and the axis of rotation.
The vector formula for the magnitude and direction of the Coriolis acceleration is
where (here and below) formula_2 is the acceleration of the particle in the rotating system, formula_3 is the velocity of the particle with respect to the rotating system, and Ω is the angular velocity vector having magnitude equal to the rotation rate ω, with direction along the axis of rotation of the rotating reference frame, and the × symbol represents the cross product operator.
The equation may be multiplied by the mass of the relevant object to produce the Coriolis force:
See "fictitious force" for a derivation.
The "Coriolis effect" is the behavior added by the "Coriolis acceleration". The formula implies that the Coriolis acceleration is perpendicular both to the direction of the velocity of the moving mass and to the frame's rotation axis. So in particular:
The vector cross product can be evaluated as the determinant of a matrix:
where the vectors i, j, k are unit vectors in the "x", "y" and "z" directions.
Causes.
The Coriolis force exists only when one uses a rotating reference frame. In the rotating frame it behaves exactly like a real force (that is to say, it causes acceleration and has real effects). However, the Coriolis force is a consequence of inertia, and is not attributable to an identifiable originating body, as is the case for electromagnetic or nuclear forces, for example. From an analytical viewpoint, to use Newton's second law in a rotating system, the Coriolis force is mathematically necessary, but it disappears in a non-accelerating, inertial frame of reference. For example, consider two children on opposite sides of a spinning roundabout (Merry-go-round ), who are throwing a ball to each other. From the children's point of view, this ball's path is curved sideways by the Coriolis force. Suppose the roundabout spins anticlockwise when viewed from above. From the thrower's perspective, the deflection is to the right. From the non-thrower's perspective, deflection is to left. "For a mathematical formulation see Mathematical derivation of fictitious forces."
An observer in a rotating frame, such as an astronaut in a rotating space station, very probably will find the interpretation of everyday life in terms of the Coriolis force accords more simply with intuition and experience than a cerebral reinterpretation of events from an inertial standpoint. For example, nausea due to an experienced push may be more instinctively explained by the Coriolis force than by the law of inertia. See also Coriolis effect (perception). In meteorology, a rotating frame (the Earth) with its Coriolis force provides a more natural framework for explanation of air movements than a non-rotating, inertial frame without Coriolis forces. In long-range gunnery, sight corrections for the Earth's rotation are based upon the Coriolis force. These examples are described in more detail below.
The acceleration entering the Coriolis force arises from two sources of change in velocity that result from rotation: the first is the change of the velocity of an object in time. The same velocity (in an inertial frame of reference where the normal laws of physics apply) is seen as different velocities at different times in a rotating frame of reference. The apparent acceleration is proportional to the angular velocity of the reference frame (the rate at which the coordinate axes change direction), and to the component of velocity of the object in a plane perpendicular to the axis of rotation. This gives a term formula_6. The minus sign arises from the traditional definition of the cross product (right hand rule), and from the sign convention for angular velocity vectors.
The second is the change of velocity in space. Different positions in a rotating frame of reference have different velocities (as seen from an inertial frame of reference). For an object to move in a straight line, it must accelerate so that its velocity changes from point to point by the same amount as the velocities of the frame of reference. The force is proportional to the angular velocity (which determines the relative speed of two different points in the rotating frame of reference), and to the component of the velocity of the object in a plane perpendicular to the axis of rotation (which determines how quickly it moves between those points). This also gives a term formula_6.
Length scales and the Rossby number.
The time, space and velocity scales are important in determining the importance of the Coriolis force. Whether rotation is important in a system can be determined by its Rossby number, which is the ratio of the velocity, "U", of a system to the product of the Coriolis parameter,formula_8, and the length scale, "L", of the motion:
The Rossby number is the ratio of inertial to Coriolis forces. A small Rossby number indicates a system is strongly affected by Coriolis forces, and a large Rossby number idicates a system in which inertial forces dominate. For example, in tornadoes, the Rossby number is large, in low-pressure systems it is low, and in oceanic systems it is around 1. As a result, in tornadoes the Coriolis force is negligible, and balance is between pressure and centrifugal forces. In low-pressure systems, centrifugal force is negligible and balance is between Coriolis and pressure forces. In the oceans all three forces are comparable.
An atmospheric system moving at "U" =  occupying a spatial distance of "L" = , has a Rossby number of approximately 0.1.
A baseball pitcher may throw the ball at U =  for a distance of L = . The Rossby number in this case would be 32,000.
Baseball players don't care about which hemisphere they're playing in. However, an unguided missile obeys exactly the same physics as a baseball, but can travel far enough and be in the air long enough to experience the effect of Coriolis force. Long-range shells in the Northern Hemisphere landed close to, but to the right of, where they were aimed until this was noted. (Those fired in the Southern Hemisphere landed to the left.) In fact, it was this effect that first got the attention of Coriolis himself.
Simple cases.
Cannon on turntable.
The animation at the top of this article is a classic illustration of Coriolis force. Another visualization of the Coriolis and centrifugal forces is this animation clip.
Given the radius "R" of the turntable in that animation, the rate of angular rotation ω, and the speed of the cannonball (assumed constant) "v", the correct angle θ to aim so as to hit the target at the edge of the turntable can be calculated.
The inertial frame of reference provides one way to handle the question: calculate the time to interception, which is "tf" = "R" / "v" . Then, the turntable revolves an angle ω "tf" in this time. If the cannon is pointed an angle θ = ω "tf" = ω "R" / "v", then the cannonball arrives at the periphery at position number 3 at the same time as the target.
No discussion of Coriolis force can arrive at this solution as simply, so the reason to treat this problem is to demonstrate Coriolis formalism in an easily visualized situation.
Trajectory in the Inertial Frame.
The trajectory in the inertial frame (denoted "A") is a straight line radial path at angle θ. The position of the cannonball in ("x", "y") coordinates at time "t" is:
In the turntable frame (denoted "B"), the "x"- "y" axes rotate at angular rate ω, so the trajectory becomes:
and three examples of this result are plotted in the figure.
Accelerations.
Components of Acceleration.
To determine the components of acceleration, a general expression is used from the article fictitious force:
in which the term in Ω × vB is the Coriolis acceleration and the term in Ω × ( Ω × rB) is the centrifugal acceleration. The results are (let α = θ − ω"t"):
Producing Accelerations.
Producing a centrifugal acceleration:
Also:
producing a Coriolis acceleration:
These accelerations are shown in the diagrams for a particular example.
It is seen that the Coriolis acceleration not only cancels the centrifugal acceleration, but together they provide a net "centripetal", radially inward component of acceleration (that is, directed toward the center of rotation):
and an additional component of acceleration perpendicular to rB "(t)":
The "centripetal" component of acceleration resembles that for circular motion at radius "r"B, while the perpendicular component is velocity dependent, increasing with the radial velocity "v" and directed to the right of the velocity. The situation could be described as a circular motion combined with an "apparent Coriolis acceleration" of 2ω"v". However, this is a rough labelling: a careful designation of the true centripetal force refers to a local reference frame that employs the directions normal and tangential to the path, not coordinates referred to the axis of rotation.
These results also can be obtained directly by two time differentiations of rB "(t)". Agreement of the two approaches demonstrates that one could start from the general expression for fictitious acceleration above and derive the trajectories shown here. However, working from the acceleration to the trajectory is more complicated than the reverse procedure used here, which, of course, is made possible in this example by knowing the answer in advance.
As a result of this analysis an important point appears: "all" the fictitious accelerations must be included to obtain the correct trajectory. In particular, besides the Coriolis acceleration, the centrifugal force plays an essential role. It is easy to get the impression from verbal discussions of the cannonball problem, which focus on displaying the Coriolis effect particularly, that the Coriolis force is the only factor that must be considered, but that is not so. A turntable for which the Coriolis force "is" the only factor is the parabolic turntable. A somewhat more complex situation is the idealized example of flight routes over long distances, where the centrifugal force of the path and aeronautical lift are countered by gravitational attraction.
Tossed ball on a rotating carousel.
The figure illustrates a ball tossed from 12:00 o'clock toward the center of a counter-clockwise rotating carousel. On the left, the ball is seen by a stationary observer above the carousel, and the ball travels in a straight line to the center, while the ball-thrower rotates counter-clockwise with the carousel. On the right the ball is seen by an observer rotating with the carousel, so the ball-thrower appears to stay at 12:00 o'clock. The figure shows how the trajectory of the ball as seen by the rotating observer can be constructed.
On the left, two arrows locate the ball relative to the ball-thrower. One of these arrows is from the thrower to the center of the carousel (providing the ball-thrower's line of sight), and the other points from the center of the carousel to the ball.(This arrow gets shorter as the ball approaches the center.) A shifted version of the two arrows is shown dotted.
On the right is shown this same dotted pair of arrows, but now the pair are rigidly rotated so the arrow corresponding to the line of sight of the ball-thrower toward the center of the carousel is aligned with 12:00 o'clock. The other arrow of the pair locates the ball relative to the center of the carousel, providing the position of the ball as seen by the rotating observer. By following this procedure for several positions, the trajectory in the rotating frame of reference is established as shown by the curved path in the right-hand panel.
The ball travels in the air, and there is no net force upon it. To the stationary observer the ball follows a straight-line path, so there is no problem squaring this trajectory with zero net force. However, the rotating observer sees a "curved" path. Kinematics insists that a force (pushing to the "right" of the instantaneous direction of travel for a "counter-clockwise" rotation) must be present to cause this curvature, so the rotating observer is forced to invoke a combination of centrifugal and Coriolis forces to provide the net force required to cause the curved trajectory.
Bounced ball.
The figure describes a more complex situation where the tossed ball on a turntable bounces off the edge of the carousel and then returns to the tosser, who catches the ball. The effect of Coriolis force on its trajectory is shown again as seen by two observers: an observer (referred to as the "camera") that rotates with the carousel, and an inertial observer. The figure shows a bird's-eye view based upon the same ball speed on forward and return paths. Within each circle, plotted dots show the same time points. In the left panel, from the camera's viewpoint at the center of rotation, the tosser (smiley face) and the rail both are at fixed locations, and the ball makes a very considerable arc on its travel toward the rail, and takes a more direct route on the way back. From the ball tosser's viewpoint, the ball seems to return more quickly than it went (because the tosser is rotating toward the ball on the return flight).
On the carousel, instead of tossing the ball straight at a rail to bounce back, the tosser must throw the ball toward the right of the target and the ball then seems to the camera to bear continuously to the left of its direction of travel to hit the rail ("left" because the carousel is turning "clockwise"). The ball appears to bear to the left from direction of travel on both inward and return trajectories. The curved path demands this observer to recognize a leftward net force on the ball. (This force is "fictitious" because it disappears for a stationary observer, as is discussed shortly.) For some angles of launch, a path has portions where the trajectory is approximately radial, and Coriolis force is primarily responsible for the apparent deflection of the ball (centrifugal force is radial from the center of rotation, and causes little deflection on these segments). When a path curves away from radial, however, centrifugal force contributes significantly to deflection.
The ball's path through the air is straight when viewed by observers standing on the ground (right panel). In the right panel (stationary observer), the ball tosser (smiley face) is at 12 o'clock and the rail the ball bounces from is at position one (1). From the inertial viewer's standpoint, positions one (1), two (2), three (3) are occupied in sequence. At position 2 the ball strikes the rail, and at position 3 the ball returns to the tosser. Straight-line paths are followed because the ball is in free flight, so this observer requires that no net force is applied.
Applied to the Earth.
An important case where the Coriolis force is observed is the rotating Earth. Unless otherwise stated, directions of forces and motion apply to the Northern Hemisphere.
Intuitive explanation.
As the Earth turns around its axis, everything attached to it turns with it (imperceptibly to our senses). An object that is moving without being dragged along with this rotation travels in a straight motion over the turning Earth. From our rotating perspective on the planet, its direction of motion changes as it moves, bending in the opposite direction to our actual motion. When viewed from a stationary point in space above, any land feature in the Northern Hemisphere turns anticlockwise—and, fixing our gaze on that location, any other location in that hemisphere rotates around it the same way. The traced ground path of a freely moving body travelling from one point to another therefore bends the opposite way, clockwise, which is conventionally labeled as "right," where it will be if the direction of motion is considered "ahead," and "down" is defined naturally.
Rotating sphere.
Consider a location with latitude "φ" on a sphere that is rotating around the north-south axis. A local coordinate system is set up with the "x" axis horizontally due east, the "y" axis horizontally due north and the "z" axis vertically upwards. The rotation vector, velocity of movement and Coriolis acceleration expressed in this local coordinate system (listing components in the order east ("e"), north ("n") and upward ("u")) are:
When considering atmospheric or oceanic dynamics, the vertical velocity is small, and the vertical component of the Coriolis acceleration is small compared to gravity. For such cases, only the horizontal (east and north) components matter. The restriction of the above to the horizontal plane is (setting "vu" = 0):
where formula_8 is called the Coriolis parameter.
By setting "vn" = 0, it can be seen immediately that (for positive φ and ω) a movement due east results in an acceleration due south. Similarly, setting "ve" = 0, it is seen that a movement due north results in an acceleration due east. In general, observed horizontally, looking along the direction of the movement causing the acceleration, the acceleration always is turned 90° to the right and of the same size regardless of the horizontal orientation.
As a different case, consider equatorial motion setting φ = 0°. In this case, Ω is parallel to the north or "n"-axis, and:
Accordingly, an eastward motion (that is, in the same direction as the rotation of the sphere) provides an upward acceleration known as the Eötvös effect, and an upward motion produces an acceleration due west.
Meteorology.
Perhaps the most important impact of the Coriolis effect is in the large-scale dynamics of the oceans and the atmosphere. In meteorology and oceanography, it is convenient to postulate a rotating frame of reference wherein the Earth is stationary. In accommodation of that provisional postulation, the centrifugal and Coriolis forces are introduced. Their relative importance is determined by the applicable Rossby numbers. Tornadoes have high Rossby numbers, so, while tornado-associated centrifugal forces are quite substantial, Coriolis forces associated with tornadoes are for practical purposes negligible.
Because ocean currents are driven by the movement of wind over the water's surface, the Coriolis force also affects the movement of ocean currents and cyclones as well. Many of the ocean's largest currents circulate around warm, high-pressure areas called gyres. Though the circulation is not as significant as that in the air, the deflection caused by the Coriolis effect is what creates the spiraling pattern in these gyres. The spiraling wind pattern helps the hurricane form. The stronger the force from the Coriolis effect, the faster the wind spins and picks up additional energy, increasing the strength of the hurricane.
Air within high-pressure systems rotates in a direction such that the Coriolis force is directed radially inwards, and nearly balanced by the outwardly radial pressure gradient. As a result, air travels clockwise around high pressure in the Northern Hemisphere and anticlockwise in the Southern Hemisphere. Air within low-pressure systems rotates in the opposite direction, so that the Coriolis force is directed radially outward and nearly balances an inwardly radial pressure gradient.
Flow around a low-pressure area.
If a low-pressure area forms in the atmosphere, air tends to flow in towards it, but is deflected perpendicular to its velocity by the Coriolis force. A system of equilibrium can then establish itself creating circular movement, or a cyclonic flow. Because the Rossby number is low, the force balance is largely between the pressure gradient force acting towards the low-pressure area and the Coriolis force acting away from the center of the low pressure.
Instead of flowing down the gradient, large scale motions in the atmosphere and ocean tend to occur perpendicular to the pressure gradient. This is known as geostrophic flow. On a non-rotating planet, fluid would flow along the straightest possible line, quickly eliminating pressure gradients. Note that the geostrophic balance is thus very different from the case of "inertial motions" (see below), which explains why mid-latitude cyclones are larger by an order of magnitude than inertial circle flow would be.
This pattern of deflection, and the direction of movement, is called Buys-Ballot's law. In the atmosphere, the pattern of flow is called a cyclone. In the Northern Hemisphere the direction of movement around a low-pressure area is anticlockwise. In the Southern Hemisphere, the direction of movement is clockwise because the rotational dynamics is a mirror image there. At high altitudes, outward-spreading air rotates in the opposite direction. Cyclones rarely form along the equator due to the weak Coriolis effect present in this region.
Inertial circles.
An air or water mass moving with speed formula_44 subject only to the Coriolis force travels in a circular trajectory called an 'inertial circle'. Since the force is directed at right angles to the motion of the particle, it moves with a constant speed around a circle whose radius formula_45 is given by:
where formula_47 is the Coriolis parameter formula_48, introduced above (where formula_49 is the latitude). The time taken for the mass to complete a full circle is therefore formula_50. The Coriolis parameter typically has a mid-latitude value of about 10−4 s−1; hence for a typical atmospheric speed of the radius is , with a period of about 17 hours. For an ocean current with a typical speed of , the radius of an inertial circle is . These inertial circles are clockwise in the Northern Hemisphere (where trajectories are bent to the right) and anticlockwise in the Southern Hemisphere.
If the rotating system is a parabolic turntable, then formula_47 is constant and the trajectories are exact circles. On a rotating planet, formula_47 varies with latitude and the paths of particles do not form exact circles. Since the parameter formula_47 varies as the sine of the latitude, the radius of the oscillations associated with a given speed are smallest at the poles (latitude = ±90°), and increase toward the equator.
Other terrestrial effects.
The Coriolis effect strongly affects the large-scale oceanic and atmospheric circulation, leading to the formation of robust features like jet streams and western boundary currents. Such features are in geostrophic balance, meaning that the Coriolis and "pressure gradient" forces balance each other. Coriolis acceleration is also responsible for the propagation of many types of waves in the ocean and atmosphere, including Rossby waves and Kelvin waves. It is also instrumental in the so-called Ekman dynamics in the ocean, and in the establishment of the large-scale ocean flow pattern called the Sverdrup balance.
Eötvös effect.
The practical impact of the "Coriolis effect" is mostly caused by the horizontal acceleration component produced by horizontal motion.
There are other components of the Coriolis effect. Westward-travelling objects are deflected downwards (feel heavier), while Eastward-travelling objects are deflected upwards (feel lighter). This is known as the Eötvös effect. This aspect of the Coriolis effect is greatest near the equator. The force produced by this effect is similar to the horizontal component, but the much larger vertical forces due to gravity and pressure mean that it is generally unimportant dynamically.
In addition, objects travelling upwards ("i.e.", out) or downwards ("i.e.", in) are deflected to the west or east respectively. This effect is also the greatest near the equator. Since vertical movement is usually of limited extent and duration, the size of the effect is smaller and requires precise instruments to detect. However, in the case of large changes of momentum, such as a spacecraft being launched into orbit, the effect becomes significant. The fastest and most fuel-efficient path to orbit is a launch from the equator that curves to a directly eastward heading.
Intuitive example.
Imagine a train that travels through a frictionless railway line along the equator. Assume that, when in motion, it moves at the necessary speed to complete a trip around the world in one day (465 m/s). The Coriolis effect can be considered in three cases: when the train travels west, when it is at rest, and when it travels east. In each case, the Coriolis effect can be calculated from the rotating frame of reference on Earth first, and then checked against a fixed inertial frame. The image below illustrates the three cases in an inertial frame as observed from a fixed point above Earth along its axis of rotation:
This also explains why high speed projectiles that travel west are deflected up, and those that travel east are deflected down. This vertical component of the Coriolis effect is called the Eötvös effect.
The above example can be used to explain why the Eötvös effect starts diminishing on an object travelling westward as its tangential speed increases above Earth's rotation (465 m/s). If the westward train in the above example increases speed, part of the force of gravity that pushes against the track accounts for the centripetal force needed to keep it in circular motion on the inertial frame. Once the train doubles its westward speed at 930 m/s that centripetal force becomes equal to the force the train experiences when it stops. From the inertial frame, in both cases it rotates at the same speed but in the opposite directions. Thus, the force is the same cancelling completely the Eötvös effect. Any object that moves westward at a speed above 930 m/s experiences an upward force instead. In the figure, the Eötvös effect is illustrated for a 10 gram object on the train at different speeds. The parabolic shape is because the centripetal force is proportional to the square of the tangential speed. On the inertial frame, the bottom of the parabola is centered at the origin. The offset is because this argument uses the Earth's rotating frame of reference. The graph shows that the Eötvös effect is not symmetrical, and that the resulting downward force experienced by an object that travels west at high velocity is less than the resulting upward force when it travels east at the same speed.
Draining in bathtubs and toilets.
Contrary to popular misconception, water rotation in home bathrooms under "normal" circumstances is not related to the Coriolis effect or to the rotation of the Earth, and no consistent difference in rotation direction between toilet drainage in the Northern and Southern Hemispheres can be observed. The formation of a vortex over the plug hole may be explained by the conservation of angular momentum: The radius of rotation decreases as water approaches the plug hole, so the rate of rotation increases, for the same reason that an ice skater's rate of spin increases as they pull their arms in. Any rotation around the plug hole that is initially present accelerates as water moves inward.
Of course, the Coriolis force does still impact the direction of the flow of water, but only minutely. Only if the water is so still that the effective rotation rate of the Earth is faster than that of the water relative to its container, and if externally applied torques (such as might be caused by flow over an uneven bottom surface) are small enough, the Coriolis effect may indeed determine the direction of the vortex. Without such careful preparation, the Coriolis effect is likely to be much smaller than various other influences on drain direction such as any residual rotation of the water and the geometry of the container. Despite this, the idea that toilets and bathtubs drain differently in the Northern and Southern Hemispheres has been popularized by several television programs and films, including "Escape Plan", "Wedding Crashers", "The Simpsons" episode "Bart vs. Australia", and "The X-Files" episode "Die Hand Die Verletzt". Several science broadcasts and publications, including at least one college-level physics textbook, have also stated this.
In 1908, the Austrian physicist Ottokar Tumlirz described careful and effective experiments that demonstrated the effect of the rotation of the Earth on the outflow of water through a central aperture. The subject was later popularized in a famous 1962 article in the journal "Nature", which described an experiment in which all other forces to the system were removed by filling a tank with of water and allowing it to settle for 24 hours (to allow any movement due to filling the tank to die away), in a room where the temperature had stabilized. The drain plug was then very slowly removed, and tiny pieces of floating wood were used to observe rotation. During the first 12 to 15 minutes, no rotation was observed. Then, a vortex appeared and consistently began to rotate in an anticlockwise direction (the experiment was performed in Boston, Massachusetts, in the Northern Hemisphere). This was repeated and the results averaged to make sure the effect was real. The report noted that the vortex rotated, "about 30,000 times faster than the effective rotation of the Earth in 42° North (the experiment's location)". This shows that the small initial rotation due to the Earth is amplified by gravitational draining and conservation of angular momentum to become a rapid vortex and may be observed under carefully controlled laboratory conditions.
Ballistic trajectories.
The Coriolis force became important in external ballistics for calculating the trajectories of very long-range artillery shells. The most famous historical example was the Paris gun, used by the Germans during World War I to bombard Paris from a range of about . Similarly, a bullet does not fly straight from the barrel to a target. The Coriolis force minutely changes the trajectory of a bullet, curving the path of the projectile into a more arched 'semi-circle' shape. This effect only affects accuracy at extremely long distances and is therefore adjusted for by accurate long-distance shooters, such as snipers and other trained professionals.
The effects of the Coriolis force on ballistic trajectories should not be confused with the curvature of the paths of missiles, satellites, and similar objects when the paths are plotted on two-dimensional (flat) maps, such as the Mercator projection. The projections of the three-dimensional curved surface of the Earth to a two-dimensional surface (the map) necessarily results in distorted features. The apparent curvature of the path is a consequence of the sphericity of the Earth and would occur even in a non-rotating frame.
Visualization of the Coriolis effect.
To demonstrate the Coriolis effect, a parabolic turntable can be used.
On a flat turntable, the inertia of a co-rotating object forces it off the edge. However, if the turntable surface has the correct paraboloid (parabolic bowl) shape (see the figure) and rotates at the corresponding rate, the force components shown in the figure make the component of gravity tangential to the bowl surface exactly equal to the centripetal force necessary to keep the object rotating at its velocity and radius of curvature (assuming no friction). (See .) This carefully contoured surface allows the Coriolis force to be displayed in isolation.
Discs cut from cylinders of dry ice can be used as pucks, moving around almost frictionlessly over the surface of the parabolic turntable, allowing effects of Coriolis on dynamic phenomena to show themselves. To get a view of the motions as seen from the reference frame rotating with the turntable, a video camera is attached to the turntable so as to co-rotate with the turntable, with results as shown in the figure. In the left panel of the figure, which is the viewpoint of a stationary observer, the gravitational force in the inertial frame pulling the object toward the center (bottom ) of the dish is proportional to the distance of the object from the center. A centripetal force of this form causes the elliptical motion. In the right panel, which shows the viewpoint of the rotating frame, the inward gravitational force in the rotating frame (the same force as in the inertial frame) is balanced by the outward centrifugal force (present only in the rotating frame). With these two forces balanced, in the rotating frame the only unbalanced force is Coriolis (also present only in the rotating frame), and the motion is an "inertial circle". Analysis and observation of circular motion in the rotating frame is a simplification compared to analysis or observation of elliptical motion in the inertial frame.
Because this reference frame rotates several times a minute rather than only once a day like the Earth, the Coriolis acceleration produced is many times larger and so easier to observe on small time and spatial scales than is the Coriolis acceleration caused by the rotation of the Earth.
In a manner of speaking, the Earth is analogous to such a turntable. The rotation has caused the planet to settle on a spheroid shape, such that the normal force, the gravitational force and the centrifugal force exactly balance each other on a "horizontal" surface. (See equatorial bulge.)
The Coriolis effect caused by the rotation of the Earth can be seen indirectly through the motion of a Foucault pendulum.
Coriolis effects in other areas.
Coriolis flow meter.
A practical application of the Coriolis effect is the mass flow meter, an instrument that measures the mass flow rate and density of a fluid flowing through a tube. The operating principle involves inducing a vibration of the tube through which the fluid passes. The vibration, though not completely circular, provides the rotating reference frame that gives rise to the Coriolis effect. While specific methods vary according to the design of the flow meter, sensors monitor and analyze changes in frequency, phase shift, and amplitude of the vibrating flow tubes. The changes observed represent the mass flow rate and density of the fluid.
Molecular physics.
In polyatomic molecules, the molecule motion can be described by a rigid body rotation and internal vibration of atoms about their equilibrium position. As a result of the vibrations of the atoms, the atoms are in motion relative to the rotating coordinate system of the molecule. Coriolis effects are therefore present, and make the atoms move in a direction perpendicular to the original oscillations. This leads to a mixing in molecular spectra between the rotational and vibrational levels, from which Coriolis coupling constants can be determined.
Gyroscopic precession.
When an external torque is applied to a spinning gyroscope along an axis that is at right angles to the spin axis, the rim velocity that is associated with the spin becomes radially directed in relation to the external torque axis. This causes a Coriolis force to act on the rim in such a way as to tilt the gyroscope at right angles to the direction that the external torque would have tilted it. This tendency has the effect of keeping spinning bodies stably aligned in space.
Insect flight.
Flies (Diptera) and some moths (Lepidoptera) exploit the Coriolis effect in flight with specialized appendages and organs that relay information about the angular velocity of their bodies. Coriolis forces resulting from linear motion of these appendages are detected within the rotating frame of reference of the insects' bodies. In the case of flies, their specialized appendages are dumbbell shaped organs located just behind their wings called halteres. The halteres oscillate in a plane at the same beat frequency as the main wings so that any body rotation results in lateral deviation of the halteres from their plane of motion. In moths, their antennae are responsible for the sensing of Coriolis forces in the similar manner as with the halteres in flies. In both flies and moths, a collection of mechanosensors at the base of the appendage are sensitive to deviations at the beat frequency, correlating to rotation in the pitch and roll planes, and at twice the beat frequency, correlating to rotation in the yaw plane.

</doc>
<doc id="7786" url="https://en.wikipedia.org/wiki?curid=7786" title="Challenger Deep">
Challenger Deep

The Challenger Deep is the deepest known point in the Earth's seabed hydrosphere, with a depth of by direct measurement from submersibles, and slightly more by sonar bathymetry (see below). It is in the Pacific Ocean, at the southern end of the Mariana Trench near the Mariana Islands group. The Challenger Deep is a relatively small slot-shaped depression in the bottom of a considerably larger crescent-shaped oceanic trench, which itself is an unusually deep feature in the ocean floor. Its bottom is about long and wide, with gently sloping sides. The closest land to the Challenger Deep is Fais Island (one of the outer islands of Yap), southwest, and Guam, to the northeast. It is located in the ocean territory of the Federated States of Micronesia, from its border with ocean territory associated with Guam.
The depression is named after the British Royal Navy survey ship HMS "Challenger", whose expedition of 1872–1876 made the first recordings of its depth. According to the August 2011 version of the GEBCO Gazetteer of Undersea Feature Names, the location and depth of the Challenger Deep are and ±.
June 2009 sonar mapping of the Challenger Deep by the Simrad EM120 (sonar multibeam bathymetry system for 300–11,000 m deep water mapping) aboard the RV "Kilo Moana" indicated a depth of . The sonar system uses phase and amplitude bottom detection, with a precision of 0.2% to 0.5% of water depth; this is an error of about at this depth. Further soundings made by the US Center for Coastal & Ocean Mapping in October 2010 are in agreement with this figure, preliminarily placing the deepest part of the Challenger Deep at , with an estimated vertical uncertainty of ±. A 2014 study concludes that with the best of 2010 multibeam echosounder technologies a depth uncertainty of ± (95% confidence level) on 9 degrees of freedom and a positional uncertainty of ± (2drms) remain and the location of the deepest depth recorded in the 2010 mapping is at ().
Only four descents have ever been achieved. The first descent by any vehicle was by the manned bathyscaphe "Trieste" in 1960. This was followed by the unmanned ROVs "Kaikō" in 1995 and "Nereus" in 2009. In March 2012 a manned solo descent was made by the deep-submergence vehicle "Deepsea Challenger".
These expeditions measured very similar depths of .
History of depth mapping from the surface.
Over the years the search for the point of maximum depth has involved many vessels.
In 2014, a study was conducted regarding the determination of the depth and location of the Challenger Deep based on data collected previous to and during the 2010 sonar mapping of the Mariana Trench with a Kongsberg Maritime EM 122 multibeam echosounder system aboard the USNS Sumner (T-AGS-61). This study by James. V. Gardner et al. of the Center for Coastal & Ocean Mapping-Joint Hydrographic Center (CCOM/JHC), Chase Ocean Engineering Laboratory of the University of New Hampshire splits the measurement attempt history into three main groups: early single-beam echo sounders (1950s - 1970's), early multibeam echo sounders (1980s - 21st century), and modern (i.e., post-GPS, high-resolution) multibeam echo sounders. Taking uncertainties in depth measurements and position estimation into account the raw data of the 2010 bathymetry of the Challenger Deep vicinity consisting of 2,051,371 soundings from eight survey lines was analyzed. The study concludes that with the best of 2010 multibeam echosounder technologies after the analysis a depth uncertainty of ± (95% confidence level) on 9 degrees of freedom and a positional uncertainty of ± (2drms) remain and the location of the deepest depth recorded in the 2010 mapping is at . The depth measurement uncertainty is a composite of measured uncertainties in the spatial variations in sound-speed through the water volume, the ray-tracing and bottom-detection algorithms of the multibeam system, the accuracies and calibration of the motion sensor and navigation systems, estimates of spherical spreading, attenuation throughout the water volume, and so forth.
The 2009 and 2010 maximal depths were not confirmed by the series of dives "Nereus" made to the bottom during an expedition in May–June 2009. The direct descent measurements by the four expeditions which have reported from the bottom, have fixed depths in a narrow range from 10,916 m ("Trieste") to 10,911 m ("Kaikō"), to 10,902 m ("Nereus") to 10,898 m ("Deepsea Challenger") Although an attempt was made to correlate locations, it could not be absolutely certain that Nereus (or the other descents) reached exactly the same points found to be maximally deep by the sonar/echo sounders of previous mapping expeditions, even though one of these echo soundings was made by "Nereus" mothership.
Descents.
Manned descents.
"Trieste".
On 23 January 1960, the Swiss-designed bathyscaphe "Trieste", originally built in Italy and acquired by the U.S. Navy, descended to the ocean floor in the trench manned by Jacques Piccard (who co-designed the submersible along with his father, Auguste Piccard) and USN Lieutenant Don Walsh. Their crew compartment was inside a spherical pressure vessel, which was a heavy-duty replacement (of the Italian original) built by Krupp Steel Works of Essen, Germany. Their descent took almost five hours and the two men spent barely twenty minutes on the ocean floor before undertaking the three-hour-and-fifteen-minute ascent. Their early departure from the ocean floor was due to their concern over a crack in the outer window caused by the temperature differences during their descent. The measured depth at the bottom was measured with a manometer at ±.
"Deepsea Challenger".
On 26 March 2012 (local time), Canadian film director James Cameron made a solo manned descent in the DSV "Deepsea Challenger" to the bottom of the Challenger Deep.
At approximately 05:15 ChST on 26 March (19:15 UTC on 25 March), the descent began.
At 07:52 ChST (21:52 UTC), "Deepsea Challenger" arrived at the bottom. The descent lasted 2 hours and 36 minutes and the recorded depth was when "Deepsea Challenger" touched down.
Cameron had planned to spend about six hours near the ocean floor exploring but decided to start the ascent to the surface after only 2 hours and 34 minutes. The time on the bottom was shortened because a hydraulic fluid leak in the lines controlling the manipulator arm obscured the visibility out the only viewing port. It also caused the loss of the submersible's starboard thrusters. At around 12:00 ChST (02:00 UTC on 26 March), the Deepsea Challenge website says the sub resurfaced after a 90-minute ascent, although Paul Allen's tweets indicate the ascent took only about 67 minutes.
During a post-dive press conference Cameron said: "I landed on a very soft, almost gelatinous flat plain. Once I got my bearings, I drove across it for quite a distance ... and finally worked my way up the slope." The whole time, Cameron said, he didn't see any fish, or any living creatures more than an inch (2.5 cm) long: "The only free swimmers I saw were small amphipods"—shrimplike bottom-feeders.
Planned manned descents.
Several other manned expeditions are planned. These include:
Unmanned descents.
"Kaikō".
On 24 March 1995, the Japanese robotic deep-sea probe "Kaikō" broke the depth record for unmanned probes when it reached close to the surveyed bottom of the Challenger Deep. Created by the Japan Agency for Marine-Earth Science and Technology (JAMSTEC), it was one of the few unmanned deep-sea probes in operation that could dive deeper than . The manometer measured depth of ± at for the Challenger Deep is believed to be the most accurate measurement taken yet. "Kaikō" also collected sediment cores containing marine organisms from the bottom of the deep. "Kaikō" made many unmanned descents to the Mariana Trench during three expeditions in 1995, 1996 and 1998. The greatest depth measured by "Kaikō" in 1996 was at and in 1998 at .
"ABISMO".
On 3 June 2008, the Japanese robotic deep-sea probe "ABISMO" (Automatic Bottom Inspection and Sampling Mobile) reached the bottom of the Mariana Trench about east of the Challenger Deep and collected core samples of the deep sea sediment and water samples of the water column. Created by the Japan Agency for Marine-Earth Science and Technology (JAMSTEC), it is the only unmanned deep-sea probe in use that can dive deeper than after the loss of "Nereus". During "ABISMO"'s deepest Mariana Trench dive its manometer measured a depth of ±
"Nereus".
On 31 May 2009 the United States sent the "Nereus" hybrid remotely operated vehicle (HROV) to the Challenger Deep. Nereus thus became the first vehicle to reach the Mariana Trench since 1998 and the deepest-diving vehicle then in operation. Project manager and developer Andy Bowen heralded the achievement as "the start of a new era in ocean exploration". "Nereus", unlike "Kaikō", did not need to be powered or controlled by a cable connected to a ship on the ocean surface.
"Nereus" spent over 10 hours at the bottom of the Challenger Deep and measured a depth of at , while sending live video and data back to its mothership "RV Kilo Moana" at the surface and collecting geological and biological samples from the Challenger Deep bottom with its manipulator arm for further scientific analysis.
The "Nereus" was operated by the Woods Hole Oceanographic Institution. It was lost on May 10, 2014.
Lifeforms.
The Summary Report of the HMS "Challenger" expedition lists radiolaria from the two dredged samples taken when the Challenger Deep was first discovered. These (Nassellaria and Spumellaria) were reported in the Report on Radiolaria (1887) written by Ernst Haeckel.
On their 1960 descent, the crew of the "Trieste" noted that the floor consisted of diatomaceous ooze and reported observing "some type of flatfish" lying on the seabed.
Many marine biologists are now skeptical of this supposed sighting, and it is suggested that the creature may instead have been a sea cucumber. The video camera on board the "Kaiko" probe spotted a sea cucumber, a scale worm and a shrimp at the bottom. At the bottom of the Challenger deep, the "Nereus" probe spotted one polychaete worm (a multi-legged predator) about an inch long.
An analysis of the sediment samples collected by "Kaiko" found large numbers of simple organisms at . While similar lifeforms have been known to exist in shallower ocean trenches (> 7,000 m) and on the abyssal plain, the lifeforms discovered in the Challenger Deep possibly represent taxa distinct from those in shallower ecosystems.
Most of the organisms collected were simple, soft-shelled foraminifera (432 species according to National Geographic), with four of the others representing species of the complex, multi-chambered genera "Leptohalysis" and "Reophax". Eighty-five percent of the specimens were organic, soft-shelled allogromiids, which is unusual compared to samples of sediment-dwelling organisms from other deep-sea environments, where the percentage of organic-walled foraminifera ranges from 5% to 20%. As small organisms with hard, calcareous shells have trouble growing at extreme depths because of the high solubility of calcium carbonate in the pressurized water, scientists theorize that the preponderance of soft-shelled organisms in the Challenger Deep may have resulted from the typical biosphere present when the Challenger Deep was shallower than it is now. Over the course of six to nine million years, as the Challenger Deep grew to its present depth, many of the species present in the sediment died out or were unable to adapt to the increasing water pressure and changing environment.} The species that survived the change in depth were the ancestors of the Challenger Deep's current denizens.
On 17 March 2013, researchers reported data that suggested microbial life forms thrive in the Challenger Deep. Other researchers reported related studies that microbes thrive inside rocks up to 1900 feet below the sea floor under 8500 feet of ocean off the coast of the northwestern United States. According to one of the researchers, "You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are."

</doc>
<doc id="7787" url="https://en.wikipedia.org/wiki?curid=7787" title="Claude Louis Berthollet">
Claude Louis Berthollet

Claude Louis Berthollet (9 December 1748 Talloires, France – 6 November 1822 Arcueil, France) was a Savoyard-French chemist who became vice president of the French Senate in 1804. He is known for his scientific contributions to theory of chemical equilibria via the mechanism of reverse chemical reactions, and for his contribution to modern chemical nomenclature. On a practical basis, Berthollet was the first to demonstrate the bleaching action of chlorine gas, and was first to develop a solution of sodium hypochlorite as a modern bleaching agent.
Biography.
Claude Louis Berthollet was born in Talloires, near Annecy, then part of the Duchy of Savoy, in 1749.
He started his studies at Chambéry and then in Turin where he graduated in medicine. Berthollet's great new developments in works regarding chemistry made him, in a short period of time, an active participant of the Academy of Science in 1780.
Berthollet, along with Antoine Lavoisier and others, devised a chemical nomenclature, or a system of names, which serves as the basis of the modern system of naming chemical compounds.
He also carried out research into dyes and bleaches, being first to introduce the use of chlorine gas as a commercial bleach in 1785. He first produced a modern bleaching liquid in 1789 in his laboratory on the quay Javel in Paris, France, by passing chlorine gas through a solution of sodium carbonate. The resulting liquid, known as ""Eau de Javel"" ("Javel water"), was a weak solution of sodium hypochlorite. Another strong chlorine oxidant and bleach which he investigated and was the first to produce, potassium chlorate (KClO3), is known as "Berthollet's Salt".
Bertholett first determined the elemental composition of the gas ammonia, in 1785.
Berthollet was one of the first chemists to recognize the characteristics of a reverse reaction, and hence, chemical equilibrium.
Berthollet was engaged in a long-term battle with another French chemist Joseph Proust on the validity of the law of definite proportions. While Proust believed that chemical compounds are composed of a fixed ratio of their constituent elements irrespective of the methods of production, Berthollet believed that this ratio can change according to the ratio of the reactants initially taken. Although Proust proved his theory by accurate measurements, his theory was not immediately accepted partially due to Berthollet's authority. His law was finally accepted when Berzelius confirmed it in 1811. But it was found later that Berthollet was not completely wrong because there exists a class of compounds that do not obey the law of definite proportions. These non-stoichiometric compounds are also named "berthollides" in his honor.
Berthollet was one of several scientists who went with Napoleon to Egypt, and was a member of the physics and natural history section of the Institut d'Égypte.
In April, 1789 he was elected a Fellow of the Royal Society of London. In 1801, he was elected a foreign member of the Royal Swedish Academy of Sciences. He was elected an Honorary Fellow of the Royal Society of Edinburgh in 1820 and a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822.
Berthollet was an accused of being an atheist.
He died in Arcueil, France in 1822.
Family.
Berthollet married Marguerite Baur in 1788.

</doc>
<doc id="7791" url="https://en.wikipedia.org/wiki?curid=7791" title="Constitution of Chile">
Constitution of Chile

The current Political Constitution of the Republic of Chile, approved by Chilean voters in a controversial plebiscite on September 11, 1980, under the military dictatorship of Augusto Pinochet, partially effective March 11, 1981, fully effective 11 March 1990 and amended considerably on August 17, 1989 (via referendum) and on September 22, 2005 (legislatively), and also in 1991, 1994, 1997, 1999, 2000, 2001, 2003, 2007, 2008, 2009 and 2010, replaced the earlier constitution of 1925. It is Chile's eighth constitution. 
Legitimacy.
According to law professor, Camel Cazor Aliste, the Constitution of 1980 has problems of legitimacy stemming from two facts: First, the writing commission was not representative of the political spectrum of Chile. Its members were hand-picked by the dictatorship of Pinochet and deliberately excluded opponents of the regime. Secondly, the constitution "approval" was achieved through the controversial and tightly government-controlled referendum of 1980.

</doc>
<doc id="7794" url="https://en.wikipedia.org/wiki?curid=7794" title="Crystallography">
Crystallography

Crystallography is the experimental science of determining the arrangement of atoms in the crystalline solids (see crystal structure). The word "crystallography" derives from the Greek words "crystallon" "cold drop, frozen drop", with its meaning extending to all solids with some degree of transparency, and "grapho" "I write". In July 2012, the United Nations recognised the importance of the science of crystallography by proclaiming that 2014 would be the International Year of Crystallography. X-ray crystallography is used to determine the structure of large biomolecules such as proteins. 
Before the development of X-ray diffraction crystallography (see below), the study of crystals was based on physical measurements of their geometry. This involved measuring the angles of crystal faces relative to each other and to theoretical reference axes (crystallographic axes), and establishing the symmetry of the crystal in question. This physical measurement is carried out using a goniometer. The position in 3D space of each crystal face is plotted on a stereographic net such as a Wulff net or Lambert net. The pole to each face is plotted on the net. Each point is labelled with its Miller index. The final plot allows the symmetry of the crystal to be established.
Crystallographic methods now depend on analysis of the diffraction patterns of a sample targeted by a beam of some type. X-rays are most commonly used; other beams used include electrons or neutrons. This is facilitated by the wave properties of the particles. Crystallographers often explicitly state the type of beam used, as in the terms "X-ray crystallography, neutron diffraction" and "electron diffraction". These three types of radiation interact with the specimen in different ways. 
Because of these different forms of interaction, the three types of radiation are suitable for different crystallographic studies.
Theory.
An image of a small object is made using a lens to focus the beam, similar to a lens in a microscope. However, the wavelength of visible light (about 4000 to 7000 ångström) is three orders of magnitude longer than the length of typical atomic bonds and atoms themselves (about 1 to 2 Å). Therefore, obtaining information about the spatial arrangement of atoms requires the use of radiation with shorter wavelengths, such as X-ray or neutron beams. Employing shorter wavelengths implied abandoning microscopy and true imaging, however, because there exists no material from which a lens capable of focusing this type of radiation can be created. (Nevertheless, scientists have had some success focusing X-rays with microscopic Fresnel zone plates made from gold, and by critical-angle reflection inside long tapered capillaries.) Diffracted X-ray or neutron beams cannot be focused to produce images, so the sample structure must be reconstructed from the diffraction pattern. Sharp features in the diffraction pattern arise from periodic, repeating structure in the sample, which are often very strong due to coherent reflection of many photons from many regularly spaced instances of similar structure, while non-periodic components of the structure result in diffuse (and usually weak) diffraction features - areas with a higher density and repetition of atom order tend to reflect more light toward one point in space when compared to those areas with fewer atoms and less repetition.
Because of their highly ordered and repetitive structure, crystals give diffraction patterns of sharp Bragg reflection spots, and are ideal for analyzing the structure of solids.
Technique.
Some materials that have been analyzed using crystallography, such as proteins, do not occur naturally as crystals. Typically, such molecules are placed in solution and allowed to slowly crystallize through vapor diffusion. A drop of solution containing the molecule, buffer, and precipitants is sealed in a container with a reservoir containing a hygroscopic solution. Water in the drop diffuses to the reservoir, slowly increasing the concentration and allowing a crystal to form. If the concentration were to rise more quickly, the molecule would simply precipitate out of solution, resulting in disorderly granules rather than an orderly and hence usable crystal.
Once a crystal is obtained, data can be collected using a beam of radiation. Although many universities that engage in crystallographic research have their own X-ray producing equipment, synchrotrons are often used as X-ray sources, because of the purer and more complete patterns such sources can generate. Synchrotron sources also have a much higher intensity of X-ray beams, so data collection takes a fraction of the time normally necessary at weaker sources. Complementary neutron crystallography techniques are used to identify the positions of hydrogen atoms, since X-rays only interact very weakly with light elements such as hydrogen.
Producing an image from a diffraction pattern requires sophisticated mathematics and often an iterative process of modelling and refinement. In this process, the mathematically predicted diffraction patterns of an hypothesized or "model" structure are compared to the actual pattern generated by the crystalline sample. Ideally, researchers make several initial guesses, which through refinement all converge on the same answer. Models are refined until their predicted patterns match to as great a degree as can be achieved without radical revision of the model. This is a painstaking process, made much easier today by computers.
The mathematical methods for the analysis of diffraction data only apply to "patterns," which in turn result only when waves diffract from orderly arrays. Hence crystallography applies for the most part only to crystals, or to molecules which can be coaxed to crystallize for the sake of measurement. In spite of this, a certain amount of molecular information can be deduced from patterns that are generated by fibers and powders, which while not as perfect as a solid crystal, may exhibit a degree of order. This level of order can be sufficient to deduce the structure of simple molecules, or to determine the coarse features of more complicated molecules. For example, the double-helical structure of DNA was deduced from an X-ray diffraction pattern that had been generated by a fibrous sample.
In materials science.
Crystallography is used by materials scientists to characterize different materials. In single crystals, the effects of the crystalline arrangement of atoms is often easy to see macroscopically, because the natural shapes of crystals reflect the atomic structure. In addition, physical properties are often controlled by crystalline defects. The understanding of crystal structures is an important prerequisite for understanding crystallographic defects. Mostly, materials do not occur as a single crystal, but in poly-crystalline form (i.e., as an aggregate of small crystals with different orientations). Because of this, the powder diffraction method, which uses diffraction patterns of polycrystalline samples with a large number of crystals, plays an important role in structural determination.
Other physical properties are also linked to crystallography. For example, the minerals in clay form small, flat, platelike structures. Clay can be easily deformed because the platelike particles can slip along each other in the plane of the plates, yet remain strongly connected in the direction perpendicular to the plates. Such mechanisms can be studied by crystallographic texture measurements.
In another example, iron transforms from a body-centered cubic (bcc) structure to a face-centered cubic (fcc) structure called austenite when it is heated. The fcc structure is a close-packed structure unlike the bcc structure; thus the volume of the iron decreases when this transformation occurs.
Crystallography is useful in phase identification. When performing any process on a material, it may be desired to find out what compounds and what phases are present in the material. Each phase has a characteristic arrangement of atoms. X-ray or neutron diffraction can be used to identify which patterns are present in the material, and thus which compounds are present. Crystallography covers the enumeration of the symmetry patterns which can be formed by atoms in a crystal and for this reason has a relation to group theory and geometry.
Biology.
X-ray crystallography is the primary method for determining the molecular conformations of biological macromolecules, particularly protein and nucleic acids such as DNA and RNA. In fact, the double-helical structure of DNA was deduced from crystallographic data. The first crystal structure of a macromolecule was solved in 1958, a three-dimensional model of the myoglobin molecule obtained by X-ray analysis. The Protein Data Bank (PDB) is a freely accessible repository for the structures of proteins and other biological macromolecules. Computer programs such as RasMol or Pymol can be used to visualize biological molecular structures.
Neutron crystallography is often used to help refine structures obtained by X-ray methods or to solve a specific bond; the methods are often viewed as complementary, as X-rays are sensitive to electron positions and scatter most strongly off heavy atoms, while neutrons are sensitive to nucleus positions and scatter strongly even off many light isotopes, including hydrogen and deuterium.
Electron crystallography has been used to determine some protein structures, most notably membrane proteins and viral capsids.

</doc>
<doc id="7796" url="https://en.wikipedia.org/wiki?curid=7796" title="Claude Auchinleck">
Claude Auchinleck

Field Marshal Sir Claude John Eyre Auchinleck (21 June 1884 – 23 March 1981), nicknamed "The Auk", was a British Army commander during the Second World War. He was a career soldier who spent much of his military career in India, where he rose to become Commander-in-Chief of the Indian Army by early 1941. In July 1941 he was appointed Commander-in-Chief of the Middle East theatre, but after initial successes the war in North Africa turned against the British, and he was relieved of the post in 1942 during the crucial Alamein campaign. In June 1943 he was once more appointed Commander-in-Chief India, where his support through the organisation of supply, maintenance and training for Slim's Fourteenth Army played an important role in its success. He served as Commander-in-Chief India until Partition in 1947, when he assumed the role of Supreme Commander of all British forces in India and Pakistan until late 1948. He retired to the United Kingdom but at the age of 84 emigrated to Morocco, where he died at the age of 96.
Early life and career.
Born in Aldershot, the son of Colonel John Claudius Auchinleck and Mary (May) Auchinleck (née Eyre), Auchinleck attended Eagle House School at Crowthorne and then Wellington College on scholarships. After attending the Royal Military College, Sandhurst, Auchinleck was commissioned as an unattached second lieutenant in the Indian Army on 21 January 1903 and joined to the 62nd Punjabis in April 1904. He learnt Punjabi and, able to speak fluently with his soldiers, he absorbed a knowledge of local dialects and customs: this familiarity engendered a lasting mutual respect, enhanced by his own personality. He was promoted to lieutenant on 21 April 1905 and then spent the next two years in Tibet and Sikkim before moving to Benares in 1907 where he caught diphtheria. After briefly serving with the Royal Inniskilling Fusiliers at Aldershot he returned Benares in 1909 and became adjutant of the 62nd Punjabis with promotion to captain on 21 January 1912.
Auchinleck saw active service in the First World War and was deployed with his regiment to defend the Suez Canal: in February 1915 he was in action against the Turks at Ismaïlia. His regiment moved into Aden to counter the Turkish threat there in July 1915. The 6th Indian Division, of which the 62nd Punjabis were a part, was landed at Basra on 31 December 1915 for the Mesopotamian campaign. In July 1916 Auchinleck was promoted acting major and made second in command of the regiment. He took part in a series of fruitless attacks on the Turks at the Battle of Hanna in January 1916 and was one of the few British officers in his regiment to survive these actions. He became acting commanding officer of his regiment in February 1917 and led his regiment at the Second Battle of Kut in February 1917 and the Fall of Baghdad in March 1917. Having been mentioned in despatches and having received the Distinguished Service Order in 1917 for his service in Mesopotamia, he was promoted to the substantive rank of major on 21 January 1918, to temporary lieutenant-colonel on 23 May 1919 and to brevet lieutenant-colonel on 15 November 1919 for his "distinguished service in Southern and Central Kurdistan" on the recommendation of the Commander-in-Chief of the Mesopotamia Expeditionary Force.
Between the world wars.
Auchinleck attended the Staff College, Quetta between 1920 and 1921. He married Jessie Stewart in 1921. Jessie had been born in 1900 in Tacoma, Washington, to Alexander Stewart, head of the Blue Funnel Line that plied the west coast of the United States. When he died about 1919, their mother took her, her twin brother Alan and her younger brother Hepburne back to Bun Rannoch, the family estate at Innerhadden in Perthshire. Holidaying at Grasse on the French Riviera, Auchinleck, who was on leave from India at the time, met Jessie on the tennis courts. She was a high-spirited, blue-eyed beauty. Things moved quickly, and they were married within five months. Sixteen years younger than Auchinleck, Jessie became known as 'the little American girl' in India, but adapted readily to life there.
Auchinleck became temporary deputy assistant quartermaster-general at Army Headquarters in February 1923 and then second-in-command of his regiment, which in the 1923 reorganisation of the British Indian Army had become the 1st battalion, 1st Punjab Regiment, in September 1925. He attended the Imperial Defence College in 1927 and, having been promoted to lieutenant-colonel on 21 January 1929 he was appointed to command his regiment. Promoted to full colonel on 1 February 1930 with seniority from 15 November 1923, he became an instructor at the Staff College, Quetta in February 1930 where he remained until April 1933. He was promoted to temporary brigadier on 1 July 1933 and given command of the Peshawar Brigade, which was active in the pacification of the adjacent tribal areas during the Mohmand and Bajaur Operations between July and October 1933: during his period of command he was mentioned in despatches. He led a second punitive expedition during the Second Mohmand Campaign in August 1935 for which he was again mentioned in despatches, promoted to major-general on 30 November 1935 and appointed a Companion of the Order of the Star of India on 8 May 1936.
On leaving his brigade command in April 1936 Auchinleck was on the unemployed list (on half pay) until September 1936 when he was appointed Deputy Chief of the General Staff and Director of Staff Duties in Delhi. He was then appointed to command the Meerut District in India in July 1938. In 1938 Auchinleck was appointed to chair a committee to consider the modernisation, composition and re-equipment of the British Indian Army: the committee's recommendations formed the basis of the 1939 Chatfield Report which outlined the transformation of the Indian Army – it grew from 183,000 in 1939 to over 2,250,000 men by the end of the war.
Second World War.
Norway 1940.
On the outbreak of war Auchinleck was appointed to command the Indian 3rd Infantry Division but in January 1940 was summoned to the United Kingdom to command IV Corps, the only time in the war that a wholly British corps was commanded by an Indian Army officer. He received promotion to acting lieutenant-general on 1 February 1940 and to the substantive rank of lieutenant-general on 16 March 1940. In May 1940 Auchinleck took over command of the Anglo-French ground forces in Norway, a military operation that was doomed to fail. After the fall of Norway, in June 1940 he briefly commanded V Corps before becoming General Officer Commanding-in-Chief, Southern Command in July 1940, where he had an uneasy relationship with his subordinate Bernard Montgomery, the new V Corps commander. Montgomery later wrote: "In the 5th Corps I first served under Auchinleck... I cannot recall that we ever agreed on anything."
India and Iraq January–May 1941.
Promoted to full general on 26 December 1940, Auchinleck was recalled to India in January 1941 to become Commander-in-Chief, India in which position he also was appointed to the Executive Council of the Governor-General of India and appointed ADC General to the King which ceremonial position he held until after the end of the War.
In April 1941 RAF Habbaniya was threatened by the new pro-Axis regime of Rashid Ali. This large Royal Air Force station was west of Baghdad in Iraq and General Archibald Wavell, Commander-in-Chief Middle East Command, was reluctant to intervene, despite the urgings of Winston Churchill, because of his pressing commitments in the Western Desert and Greece. Auchinleck, however, acted decisively, sending a battalion of the King's Own Royal Regiment by air to Habbaniya and shipping the Indian 10th Infantry Division by sea to Basra. Wavell was prevailed upon by London to send "Habforce", a relief column, from the British Mandate of Palestine but by the time it arrived in Habbaniya on 18 May the Anglo-Iraqi War was virtually over.
North Africa July 1941 – August 1942.
Following the see-saw of Allied and Axis successes and reverses in North Africa, Auchinleck was appointed to succeed General Sir Archibald Wavell as Commander-in-Chief Middle East Command in July 1941; Wavell took up Auchinleck's post as Commander-in-Chief of the Indian Army, swapping jobs with him.
As Commander-in-Chief Middle East Auchinleck, based in Cairo, held responsibility not just for North Africa but also for Persia and the Middle East. He launched an offensive in the Western Desert, Operation Crusader, in November 1941: despite some tactical reverses during the fighting which resulted in Auchinleck replacing the Eighth Army commander Alan Cunningham with Neil Ritchie, by the end of December the besieged garrison of Tobruk had been relieved and Rommel obliged to withdraw to El Agheila. Auchinleck appears to have believed that enemy had been defeated, writing on 12 January 1942 that the Axis forces were "beginning to feel the strain" and were "hard pressed". In fact the Axis forces had managed to withdraw in good order and a few days after Auchinleck's optimistic appreciation, having reorganised and been reinforced, struck at the dispersed and weakened British forces, driving them back to the Gazala positions near Tobruk. The British Chief of Imperial General staff, Alan Brooke, wrote in his diary that it was "Nothing less than bad generalship on the part of Auchinleck". Rommel's attack at the Battle of Gazala of 26 May 1942 resulted in a significant defeat for the British. Auchinlek's appreciation of the situation written to Ritchie on 20 May had suggested that the armoured reserves be concentrated in a position suitable to meet both a flanking attack around the south of the front or a direct attack through the centre (which was the likelihood more favoured by Auchinleck). In the event, Ritchie chose a more dispersed and rearward positioning of his two armoured divisions and when the attack in the centre came, it proved to be a diversion and the main attack, by Rommel's armoured formations, came round the southern flank. Poor initial positioning and subsequent handling and coordination of Allied formations by Ritchie and his corps commanders resulted in their heavy defeat and the Eighth Army retreating into Egypt; Tobruk fell to the Axis on 21 June 1942.
On 24 June Auchinleck stepped in to take direct command of the Eighth Army, having lost confidence in Neil Ritchie's ability to control and direct his forces. Auchinleck discarded Ritchie's plan to stand at Mersa Matruh, deciding to fight only a delaying action there, while withdrawing to the more easily defendable position at El Alamein. Here Auchinleck tailored a defence that took advantage of the terrain and the fresh troops at his disposal, stopping the exhausted German/Italian advance in the First Battle of El Alamein. Enjoying a considerable superiority of material and men over the weak German/Italian forces, Auchinleck organised a series of counter-attacks. Poorly conceived and badly coordinated, these attacks achieved little.
"The Auk", as he was known, appointed a number of senior commanders who proved to be unsuitable for their positions, and command arrangements were often characterised by bitter personality clashes. Auchinleck was an Indian Army officer and was criticised for apparently having little direct experience or understanding of British and Dominion troops. His controversial chief of operations, Major-General Dorman-Smith, was regarded with considerable distrust by many of the senior commanders in Eighth Army. By July 1942 Auchinleck had lost the confidence of Dominion commanders and relations with his British commanders had become strained.
Like his foe Rommel (and his predecessor Wavell and successor Montgomery), Auchinleck was subjected to constant political interference, having to weather a barrage of hectoring telegrams and instructions from Prime Minister Churchill throughout late 1941 and the spring and summer of 1942. Churchill constantly sought an offensive from Auchinleck, and was downcast at the military reverses in Egypt and Cyrenaica. Churchill was desperate for some sort of British victory before the planned Allied landings in North Africa, Operation Torch, scheduled for November 1942. He badgered Auchinleck immediately after the Eighth Army had all but exhausted itself after the first battle of El Alamein. Churchill and the Chief of the Imperial General Staff, Alan Brooke, flew to Cairo in early August 1942, to meet Auchinleck, where it emerged he had lost the confidence of both men. He was replaced as Commander-in-Chief Middle East Command by General Sir Harold Alexander (later Field Marshal Earl Alexander of Tunis).
India 1942–1945.
Churchill offered Auchinleck command of the newly created Persia and Iraq Command (this having been separated from Alexander's command), but Auchinleck declined this post, as he believed that separating the area from the Middle East Command was not good policy and the new arrangements would not be workable. He set his reasons out in his letter to the Chief of the Imperial General Staff dated 14 August 1942. Instead he returned to India, where he spent almost a year "unemployed" before in June 1943 being again appointed Commander-in-Chief of the Indian Army, General Wavell meanwhile having been appointed Viceroy: on this appointment it was announced that responsibility for the prosecution of the war with Japan would move from the C-in-C India to a newly created South East Asia Command. However, the appointment of the new command's Supreme Commander, Admiral Louis Mountbatten, was not announced until August 1943 and until Mountbatten could set up his headquarters and assume control (in November) Auchinleck retained responsibility for operations in India and Burma while conducting a review and revision of Allied plans based on the decisions taken by the Allied Combined Chiefs of Staff at the Quadrant Conference which ended in August.
Following Mountbatten's arrival, Auchinleck's India Command (which had equal status with South East Asia Command in the military hierarchy) was responsible for the internal security of India, the defence of the North West Frontier and the buildup of India as a base, including most importantly the reorganisation of the Indian Army, the training of forces destined for SEAC and the lines of communication carrying men and material to the forward areas and to China. Auchinleck made the supply of Fourteenth Army, with probably the worst lines of communication of the war, his immediate priority; as William Slim, commander of the Fourteenth Army was later to write:
Divorce.
Auchinleck suffered a personal disappointment when his wife Jessie left him for his friend Air Chief Marshal Sir Richard Peirse. Peirse and Auchinleck had been students together at the Imperial Defence College, but that was long before. Peirse was now Allied Air Commander-in-Chief, South-East Asia, and also based in India. The affair became known to Mountbatten in early 1944, and he passed the information to the Chief of the RAF, Sir Charles Portal, hoping that Peirse would be recalled. The affair was common knowledge by September 1944, and Peirse was neglecting his duties. Mountbatten sent Peirse and Lady Auchinleck back to England on 28 November 1944, where they lived together at a Brighton hotel. Peirse had his marriage dissolved, and Auchinleck obtained a divorce in 1946. Auchinleck was reportedly very badly affected. According to his sister, he was never the same after the break-up. He always carried a photograph of Jessie in his wallet even after the divorce.
Partition of India and later years.
Auchinleck continued as Commander-in-Chief of the Indian Army after the end of the war helping, though much against his own convictions, to prepare the future Indian and Pakistani armies for the Partition of India: in November 1945 he was forced to commute the more serious judicial sentences awarded against officers of the Indian National Army in face of growing unease and unrest both within the Indian population, and the British Indian Army. On 1 June 1946 he was promoted to field marshal, but he refused to accept a peerage, lest he be thought associated with a policy (i.e. Partition) that he thought fundamentally dishonourable. 
Sending a report to British Government on 28 September 1947 Auchinleck wrote: "I have no hesitation, whatever, in affirming that the present Indian Cabinet are implacably determined to do all in their power to prevent the establishment of the Dominion of Pakistan on firm basis."
When partition was effected in August 1947, Auchinleck was appointed Supreme Commander of all British forces remaining in India and Pakistan and remained in this role until the winding up and closure of the Supreme H.Q. at the end of November 1948. This marked his effective retirement from the army (although technically field marshals in the British Army never retire, remaining on the active list on half pay). He left India on 1 December.
After a brief period in Italy in connection with an unsuccessful business project, Auchinleck retired to London, where he occupied himself with a number of charitable and business interests and became a respectably skilled watercolour painter. In 1960 he settled in Beccles in the county of Suffolk, remaining there for seven years until, at the age of eighty-four, he decided to emigrate and set up home in Marrakesh, where he died on 23 March 1981.
Memorials.
Auchinleck was buried in Ben M'Sik European Cemetery, Casablanca, in the Commonwealth War Graves Commission plot in the cemetery, next to the grave of Raymond Steed who was the second youngest non-civilian Commonwealth casualty of the Second World War.
A memorial plaque was erected in the crypt of St Paul's Cathedral. The tour guides relate how in 1979, as plaques for the other great Second World War military leaders were being installed, no one in the establishment had been in contact with his family for some years. Cathedral officials telephoned to enquire the date of his death only to be told "Auchinleck here – but I won't be keeping you much longer!"

</doc>
<doc id="7797" url="https://en.wikipedia.org/wiki?curid=7797" title="Camilla Hall">
Camilla Hall

Camilla Christine Hall (March 24, 1945 - May 17, 1974) was an artist, college trained social worker, and an early member of the Symbionese Liberation Army. She is most well known for being one of the kidnappers of heiress Patricia Hearst.
Early life.
On March 24, 1945, Camilla Christine Hall was born in Saint Peter, Minnesota. Her parents, George Fridolph Hall (1908-2000) and Lorena Daeschner Hall (1911-1995), worked at Gustavus Adolphus College in Saint Peter, Minnesota from 1938-1952. In addition, her father was a minister in the Augustana Evangelical Lutheran Church, Lutheran Church in America, and later the Evangelical Lutheran Church in America. Her mother, Lorena (Daeschner) Hall, helped found Gustavus Adolphus College's Art Department and served as the department head. Camilla Hall was the only surviving child of four; two of her siblings died of a kidney disorder, Peter and Nan, and a third, Terry, of congenital heart disease.
In 1952, the Hall family moved to what is now Tanzania in East Africa. George and Lorena Hall taught in schools and did mission work, while Camilla and Nan played with the native children. In 1954, when Camilla was nine, the family moved back to Saint Peter, because of seven-year-old Nan's poor health. While Camilla Hall attended elementary school in Minnesota, the family moved to Montclair, New Jersey until Hall was to start high school.
After moving back to Minnesota, Hall went to Washburn High School in Minneapolis where she was involved in many activities. The 1963 Washburn Yearbook says, "Candy was a member of Blue Tri, Class Play, Poplars Staff, Quill Club, Forensics, Pep Club, and Hall of Fame" Blue Tri club was an organization that encouraged Christian ideals and put together service projects. In addition, Camilla Hall was voted class clown in High School. In 1963, she graduated from Washburn High School.
College life.
Camilla Hall attended Gustavus Adolphus College in St. Peter, Minnesota. She transferred to the University of Minnesota after her freshman year at Gustavus. Hall attended special lectures, exhibits, and concerts at the University. On June 10, 1967, Hall graduated with a humanities degree from the University of Minnesota.
Post-college.
Following graduation, Hall moved to Duluth, Minnesota where she was a caseworker for St. Louis County, Minnesota. In early 1968 she was elected to carry the Eugene McCarthy banner, in support of the Eugene McCarthy Presidential Campaign, for the St. Louis County precinct. Even though Hall enjoyed helping people in her work, she found it difficult to separate her feelings while being a caseworker. For her job in Duluth, Minnesota, Hall used her musical and poetic talents in an advertising campaign.
In June 1968, Hall returned to Minneapolis, Minnesota and worked as a caseworker for the Hennepin County, Minnesota welfare office. Co-workers and friends of Hall described her as witty, sympathetic, helpful, and compassionate. Also, she had an outgoing personality and had a passion for literature. At the same time, Hall frequently talked with family and friends about philosophy and how she was disappointed with the state of welfare. In 1968, Hall was 23 years old and carefully monitored the political situation in America, including the 1968 Democratic National Convention. She was active in the peace movement and food boycotts, including the Mobilization Committee to End the War in Vietnam. Despite her active participation in urging social change and working as a caseworker, Hall's mother says Camilla became dissatisfied with her work.
In California.
In November 1969, Hall moved to Topanga, a northern suburb of Los Angeles, California. In March, she moved into Los Angeles proper in west Los Angeles. According to Rachael Hanel, "She lived off her savings, interest income from a trust, money from her parents, and selling her simple, Rubenesque line drawings." Even though Hall didn't express dissatisfaction at being an artist, she decided to move again.
Hall moved to Berkeley in February 1971. In May 1971, Hall moved into an apartment complex on Channing Way where she met Patricia Soltysik. Previous to this relationship, Hall had not lived publicly in a lesbian relationship. Patricia Soltysik was the object of Hall's love poem named "Mizmoon".
In Berkeley, Hall continued being politically active. She was one of the activists who took over Berkeley Park in the People's Park demonstration of the summer of 1972. In October 1972, Hall travelled to Europe and stayed with friends while she traveled for three months. Once she returned, she continued being politically active and was involved with the Symbionese Liberation Army.
While a member of the radical terrorist organization known as the SLA, Hall participated in numerous terrorist acts including the murder of school superintendent Marcus Foster, various bank robberies, and most famously, the kidnapping and torture of heiress Patricia Hearst.
LA Shootout.
Hall died in a shootout (May 17, 1974) with police in which five other SLA members were killed. As their hideout burned, Hall and fellow SLA member Nancy Ling Perry exited from the back door. Police claimed that Perry came out firing a revolver while Hall was firing an automatic pistol. Police shot them immediately, killing both. Perry was shot twice. One shot hit her right lung, the other shot severed her spine. Hall was shot once in the forehead.
Investigators working for Hall's parents claimed that Perry had come walking out of the house intending to surrender.

</doc>
<doc id="7800" url="https://en.wikipedia.org/wiki?curid=7800" title="Clone">
Clone

Clone may refer to:

</doc>
<doc id="7801" url="https://en.wikipedia.org/wiki?curid=7801" title="Critical psychology">
Critical psychology

Critical psychology is a perspective on psychology that draws extensively on critical theory. Critical psychology challenges mainstream psychology and attempts to apply psychological understandings in more progressive ways, often looking towards social change as a means of preventing and treating psychopathology.
One of critical psychology's main criticisms of conventional psychology is that it fails to consider or deliberately ignores the way power differences between social classes and groups can impact the mental and physical well-being of individuals or groups of people. It does this, in part, because it tends to explain behavior at the level of the individual.
Origins.
Criticisms of mainstream psychology consistent with current critical psychology usage have existed since psychology's modern development in the late 19th century. Use of the term "critical psychology" started in the 1970s in Berlin at Freie Universität Berlin. The German branch of critical psychology predates and has developed largely separately from the rest of the field. As of May 2007, only a few works have been translated into English. The German Critical Psychology movement is rooted in the post-war babyboomers' student revolt of the late '60s; see German student movement. Marx's "Critique of Political Economy" played an important role in the German branch of the student revolt, which was centered in Berlin. Then Berlin was a capitalist city surrounded by communist-ruled East Germany, represented a "hot spot" of political and ideological controversy for the revolting German students. The sociological foundations of critical psychology are decidedly Marxist.
Klaus Holzkamp.
One of the most important and sophisticated books in the field is the "Grundlegung der Psychologie" ("Foundations of Psychology") by Klaus Holzkamp, who might be considered the theoretical founder of critical psychology. Holzkamp, who had written two books on theory of science and one on sensory perception before publishing the "Grundlegung der Psychologie" in 1983, thought this major work provided a solid paradigm for psychological research, as he viewed psychology as a pre-paradigmatic scientific discipline (T.S. Kuhn had used the term "pre-paradigmatic" for social science).
Holzkamp mostly based his sophisticated attempt to provide a comprehensive and integrated set of categories defining the field of psychological research on Aleksey Leontyev's approach to cultural–historical psychology and activity theory. Leontyev had seen human action as a result of biological as well as cultural evolution and, drawing on Marx's materialist conception of culture, stressed that individual cognition is always part of social action which in turn is mediated by man-made tools (cultural artifacts), language and other man-made systems of symbols, which he viewed as a major distinguishing feature of human culture and, thus, human cognition. Another important source was Lucien Séve's theory of personality, which provided the concept of "social activity matrices" as mediating structure between individual and social reproduction. At the same time, the "Grundlegung" systematically integrated previous specialized work done at Free University of Berlin in the '70s by critical psychologists who also had been influenced by Marx, Leontyev and Seve. This included books on animal behavior/ethology, sensory perception, motivation and cognition. He also incorporated ideas from Freud's psychoanalysis and Merleau-Ponty's phenomenology into his approach.
One core result of Holzkamp's historical and comparative analysis of human reproductive action, perception and cognition is a very specific concept of meaning that identifies symbolic meaning as historically and culturally constructed, purposeful conceptual structures that humans create in close relationship to material culture and within the context of historically specific formations of social reproduction.
Coming from this phenomenological perspective on culturally mediated and socially situated action, Holzkamp launched a devastating and original methodological attack on behaviorism (which he termed S–R (stimulus–response) psychology) based on linguistic analysis, showing in minute detail the rhetorical patterns by which this approach to psychology creates the illusion of "scientific objectivity" while at the same time losing relevance for understanding culturally situated, intentional human actions. Against this approach, he developed his own approach to generalization and objectivity, drawing on ideas from Kurt Lewin in Chapter 9 of "Grundlegung der Psychologie".
His last major publication before his death in 1995 was about learning. It appeared in 1993 and contained a phenomenological theory of learning from the standpoint of the subject. One important concept Holzkamp developed was "reinterpretation" of theories developed by conventional psychology. This meant to look at these concepts from the standpoint of the paradigm of critical psychology, thereby integrating their useful insights into critical psychology while at the same time identifying and criticizing their limiting implications, which in the case of S–R psychology were the rhetorical elimination of the subject and intentional action, and in the case of cognitive psychology which did take into account subjective motives and intentional actions, methodological individualism. 
The first part of the book thus contains an extensive look at the history of psychological theories of learning and a minute re-interpretation of those concepts from the perspective of the paradigm of critical psychology, which focuses on intentional action situated in specific socio-historical/cultural contexts. The conceptions of learning he found most useful in his own detailed analysis of "classroom learning" came from cognitive anthropologists Jean Lave (situated learning) and Edwin Hutchins (distributed cognition). 
The book's second part contained an extensive analysis on the modern state's institutionalized forms of "classroom learning" as the cultural–historical context that shapes much of modern learning and socialization. In this analysis, he heavily drew upon Michel Foucault's Discipline and Punish. Holzkamp felt that classroom learning as the historically specific form of learning does not make full use of student's potentials, but rather limits her or his learning potentials by a number of "teaching strategies." Part of his motivation for the book was to look for alternative forms of learning that made use of the enormous potential of the human psyche in more fruitful ways. Consequently, in the last section of the book, Holzkamp discusses forms of "expansive learning" that seem to avoid the limitations of classroom learning, such as apprenticeship and learning in contexts other than classrooms. 
This search culminated in plans to write a major work on life leadership in the specific historical context of modern (capitalist) society. Due to his death in 1995, this work never got past the stage of early (and premature) conceptualizations, some of which were published in the journals "Forum Kritische Psychologie" and "Argument".
1960 through 1970.
In the 1960s and 1970s the term "radical psychology" was used by psychologists to denote a branch of the field which rejected conventional psychology's focus on the individual as the basic unit of analysis and sole source of psychopathology. Instead, radical psychologists examined the role of society in causing and treating problems and looked towards social change as an alternative to therapy to treat mental illness and as a means of preventing psychopathology. Within psychiatry the term "anti-psychiatry" was often used and now British activists prefer the term "critical psychiatry". "Critical psychology" is currently the preferred term for the discipline of psychology keen to find alternatives to the way the discipline of psychology reduces human experience to the level of the individual and thereby strips away possibilities for radical social change.
In the 1990s.
Starting in the 1990s a new wave of books started to appear on critical psychology, the most influential being the edited book "Critical Psychology" by Dennis Fox and Isaac Prilleltensky. Various introductory texts to critical psychology written in the United Kingdom have tended to focus on discourse, but this has been seen by some proponents of critical psychology as a reduction of human experience to language which is as politically dangerous as the way mainstream psychology reduces experience to the individual mind. Attention to language and ideological processes, others would argue, is essential to effective critical psychology - it is not simply a matter of applying mainstream psychological concepts to issues of social change.
Ian Parker.
In 1999 Ian Parker published an influential manifesto in both the online journal "Radical Psychology" and the Annual Review of Critical Psychology. This manifesto argues that critical psychology should include the following four components:
Critical psychology today.
There are a few international journals devoted to critical psychology, including the no longer published "International Journal of Critical Psychology" (continued in the journal Subjectivity) and the "Annual Review of Critical Psychology". The journals still tend to be directed to an academic audience, though the "Annual Review of Critical Psychology" runs as an open-access online journal. There are close links between critical psychologists and critical psychiatrists in Britain through the Asylum Collective. Critical psychology courses and research concentrations are available at Manchester Metropolitan University, York St Johns University, the University of East London, the University of Edinburgh, the University of KwaZulu Natal, the Graduate Center of the City University of New York, and the University of West Georgia.
Extensions.
Like many critical applications, critical psychology has expanded beyond Marxist and feminist roots to benefit from other critical approaches. Consider ecopsychology and transpersonal psychology. Critical psychology and related work has also sometimes been labelled radical psychology and liberation psychology. In the field of developmental psychology, the work of Erica Burman has been influential.
Various sub-disciplines within psychology have begun to establish their own critical orientations. Perhaps the most extensive are critical health psychology and community psychology.
Critical psychology internationally.
Germany.
At FU-Berlin, critical psychology was not really seen as a division of psychology and followed its own methodology, trying to reformulate traditional psychology on an unorthodox Marxist base and drawing from Soviet ideas of cultural–historical psychology, particularly Aleksey Leontyev. Some years ago the department of critical psychology at FU-Berlin was merged into the traditional psychology department.
An April 2009 issue of the Sage journal "Theory & Psychology" (edited by Desmond Painter, Athanasios Marvakis, and Leendert Mos) is devoted to an examination of German critical psychology.
South Africa.
The University of KwaZulu-Natal in Durban, South Africa, is one of few worldwide to offer a Master's course in critical psychology. For an overview of critical psychology in South Africa, see Desmond Painter and Martin Terre Blanche's article on Critical Psychology in South Africa: Looking back and looking forwards. They have also now started a critical psychology blog.
United States and Canada.
Critical psychology in the United States and Canada has, for the most part, focused on critiques of mainstream psychology's support for an unjust "status quo". No departments of critical psychology exist, with the exception of the Bachelor's Completion Program with a minor in Critical Psychology, offered at the California Institute of Integral Studies in San Francisco, though critical perspectives are sometimes encountered in traditional universities, perhaps especially within community psychology programs. The University of West Georgia offers a Ph.D. in Consciousness and Society with critical psychology being one of the main three theoretical orientations. North American efforts include the 1993 founding of RadPsyNet, the 1997 publication of "Critical Psychology: An Introduction" (edited by Dennis Fox and Isaac Prilleltensky; expanded 2009 edition edited by Dennis Fox, Isaac Prilleltensky, and Stephanie Austin), the 2001 Monterey Conference on Critical Psychology, and in underlying themes of many contributions to the Journal of Social Action in Counseling and Psychology.

</doc>
<doc id="7803" url="https://en.wikipedia.org/wiki?curid=7803" title="Crossfire">
Crossfire

A crossfire (also known as interlocking fire) is a military term for the siting of weapons (often automatic weapons such as assault rifles or sub-machine guns) so that their arcs of fire overlap. This tactic came to prominence in World War I.
Siting weapons this way is an example of the application of the defensive principle of "mutual support". The advantage of siting weapons that mutually support one another is that it is difficult for an attacker to find a covered approach to any one defensive position. 
Use of armour, air support, indirect fire support, and stealth are tactics that may be used to assault a defensive position. However, when combined with land mines, snipers, barbed wire, and air cover, crossfire became a difficult tactic to counter in the early 20th century.
Trench warfare.
The tactic of using overlapping arcs of fire came to prominence during World War I where it was a feature of trench warfare. Machine guns were placed in groups, called machine-gun nests, and they protected the front of the trenches. Many lives were lost in futile attempts to charge across the no man's land where these crossfires were set up.
"Caught in the crossfire".
To be "caught in the crossfire" is an expression that often refers to unintended casualties (bystanders, etc.) who were killed or wounded by being exposed to the gunfire of a battle or gun fight, such as in a position to be hit by bullets of either side. The phrase has come to mean any injury, damage or harm (physical or otherwise) caused to a third party due to the action of belligerents (collateral damage).

</doc>
<doc id="7805" url="https://en.wikipedia.org/wiki?curid=7805" title="CNO">
CNO

CNO is a three-letter initialism. It can mean:
CNO may also refer to:

</doc>
<doc id="7806" url="https://en.wikipedia.org/wiki?curid=7806" title="Cruising (maritime)">
Cruising (maritime)

Cruising by boat is a lifestyle that involves living for extended time on a vessel while traveling from place to place for pleasure. Cruising generally refers to trips of a few days or more, and can extend to round-the-world voyages.
History.
Boats were almost exclusively used for working purposes prior to the nineteenth century. In 1857, the philosopher Henry David Thoreau, with his book "Canoeing in Wilderness" chronicling his canoe voyaging in the wilderness of Maine, was the first to convey the enjoyment of spiritual and lifestyle aspects of cruising.
The modern conception of cruising for pleasure was first popularised by the Scottish explorer and sportsman John MacGregor. He was introduced to the canoes and kayaks of the Native Americans on a camping trip in 1858, and on his return to the United Kingdom constructed his own 'double-ended' canoe in Lambeth. The boat, nicknamed 'Rob Roy' after a famous relative of his, was built of lapstrake oak planking, decked in cedar covered with rubberized canvas with an open cockpit in the center. He cruised around the waterways of Britain, Europe and the Middle East and wrote a popular book about his experiences, "A Thousand Miles in the Rob Roy Canoe".
In 1866, Macgregor was a moving force behind the establishment of the Royal Canoe Club, the first club in the world to promote pleasure cruising. The first recorded regatta was held at on 27 April 1867, and it received Royal patronage in 1873. The latter part of the century saw cruising for leisure being enthusiastically taken up by the middle class. The author Robert Louis Stevenson wrote "An Inland Voyage" in 1877 as a travelogue on his canoeing trip through France and Belgium. Stevenson and his companion, Sir Walter Grindlay Simpson travelled in two 'Rob Roys' along the Oise River and witnessed the Romantic beauty of rural Europe.
The Canadian-American Joshua Slocum was one of the first people to carry out a long-distance sailing voyage for pleasure, circumnavigating the world between 1895 and 1898. Despite opinion that such a voyage was impossible, Slocum rebuilt a derelict sloop "Spray" and sailed her single-handed around the world. His book "Sailing Alone Around the World" was a classic adventure, and inspired many others to take to the seas.
Other cruising authors have provided both inspiration and instruction to prospective cruisers. Key among these during the post World War II period are Electa and Irving Johnson, Miles and Beryl Smeeton, Bernard Moitessier, Peter Pye, and Eric and Susan Hiscock. During the 1970s - 1990s Robin Lee Graham, Lin and Larry Pardey, Annie Hill, Herb Payson, Linda and Steve Dashew, Margaret and Hal Roth, and Beth Leonard & Evans Starzinger have provided inspiration for people to set off voyaging.
The development of ocean crossing rallies, most notably the ARC (Atlantic Rally for Cruisers), have encouraged less experienced sailors to undertake ocean crossings. These rallies provide a group of sailors crossing the same ocean at the same time with safety inspections, weather information and social functions.
Types of boats used.
Cruising is done on both sail and power boats, monohulls and multihulls although sail predominates over longer distances, as ocean-going power boats are considerably more expensive to purchase and operate. The size of the typical cruising boat has increased over the years and is currently in the range of 10 to 15 metres although smaller boats have been used in around-the-world trips, but are generally not recommended given the dangers involved. Many cruisers are "long term" and travel for many years, the most adventurous among them circle the globe over a period of three to ten years. Many others take a year or two off from work and school for shorter trips and the chance to experience the cruising lifestyle.
Blue-water Cruising and Coastal Cruising.
Blue-water cruising is more involved and inherently more dangerous than coastal cruising. 
Before embarking on an open-ocean voyage, planning and preparation will include studying charts, weather reports/warnings, almanacs and navigation books of the route to be followed. In addition, supplies need to be stocked (including fresh water and fuel), navigation instruments checked and the ship itself needs to be inspected and the crew needs to be given exact instruction on the jobs are expected to perform (e.g. the watch; which is generally 4 hours on and 4 hours off, navigation, steering, rigging sails, ...). In addition, the crew needs to be well trained at working together and with the ship in question. Finally, the sailor must be mentally prepared for dealing with harsh situations. There have been many well-documented cases where sailors had to be rescued simply because they were not sufficiently prepared (the sailors as well as the ship) or lacked experience for their venture and ran into serious trouble.
Sailing near the coast (coastal cruising) gives a certain amount of safety. A ship is always granted 'innocent passage' through the country (most countries usually claim up to off the coast). When this method is practiced however, one must still remember that if the ship needs to stop (e.g. for repairs), a trip to a customs checkpoint to have passports checked would be required.
Equipment.
Cruisers use a variety of equipment and techniques to make their voyages possible, or simply more comfortable. 
The use of wind vane self steering was common on long distance cruising yachts but is increasingly being supplemented or replaced by electrical auto-pilots.
Though in the past many cruisers had no means of generating electricity on board and depended on kerosene and dry-cell batteries, today electrical demands are much higher and nearly all cruisers have electrical devices such as lights, communications equipment and refrigeration. Although most boats can generate power from their inboard engines, an increasing number carry auxiliary generators. Carrying sufficient fuel to power engine and generator over a long voyage can be a problem, so many cruising boats are equipped with other ancillary generating devices such as solar panels, wind turbines and towed turbines. Cruisers choosing to spend extended time in very remote locations with minimal access to marinas can opt to equip their vessels with watermakers (reverse-osmosis seawater desalination units) used to convert sea water to potable fresh water.
Satellite communications are becoming more common on cruising boats. Many boats are now equipped with satellite telephone systems; however, these systems can be expensive to use, and may operate only in certain areas. Many cruisers still use short wave maritime SSB and amateur radio, which has no running costs. These radios provide two-way voice communications, can receive weather fax graphics or GRIB files via a laptop computer, and with a compatible modem (e.g. PACTOR) can send and receive email at very slow speed. Such emails are usually limited to basic communication using plain text, without HTML formatting or attachments.
Awareness of impending weather conditions is particularly important to cruising sailors who are often far from safe harbours and need to steer clear of dangerous weather conditions. Most cruising boats are equipped with a barometer or a weather station that records barometric pressure as well as temperature and provides rudimentary forecasting. For more sophisticated weather forecasting, cruisers rely on their ability to receive forecasts by radio, phone or satellite.
In order to avoid collisions with other vessels, cruisers rely on a maintaining a regular watch schedule. At night, color-coded running lights help determine the position and orientation of vessels. Radar and AIS systems are often employed to detect vessels positions and movement in all conditions (day, night, rain and fog).
Cruisers navigate using paper charts and radar. Modern yachts are often also equipped with a chartplotter which enables the use of electronic charts and is linked to GPS satellites that provide position reports. Some chartplotters have the ability to interface charts and radar images. Those that still wish to work with traditional charts as well as with GPS may do so using a Yeoman Plotter. Certain advanced sailing vessels have a completely automated sailing system which includes a plotter, as well as course correcting through a link with the ship's steering organs (e.g. sails, propeller). One such device can be found at the Maltese Falcon.
Expense.
Purchasing and maintaining a yacht can be costly. Most cruising sailors do not own a house and consider their boat their home during the duration of their cruise. Many cruisers find they spend, on average, 4% of their boat's purchase price annually on boat maintenance.
Like living a conventional life on land, the cost of cruising is variable. How much a person ends up spending depends largely on their spending habits (for example, eating out a lot and frequenting marinas vs. preparing local foods aboard and anchoring out) and the type of boat (fancy modern production boats are very expensive to purchase and maintain, whilst low-key cruising boats often involve much lower expenses). Most long-term cruisers prefer to live a simple life, usually with far lower expenses than people who live ashore.
An alternative solution is to sail on someone else's yacht. Those who know how to sail can sometimes find boats looking for an extra crewmember for a long trip, whilst some non-sailors are also able to find boats willing to carry a hitch-hiker. Crew-finding websites exist to help match-up people looking for a crossing with yachts with a berth available or looking for a temporary crewmember, Find a Crew for example. Another common tactic for finding a yacht is to visit local yacht clubs and marinas and get to know the sailors there, in the hope that one of them will be able to provide a berth.
Safety.
Travel by water brings hazards: collision, weather, and equipment failure can lead to dangerous situations such as a sinking or severely disabled and dangerous vessel. For this reason many long distance cruising yachts carry with them emergency equipment such as SARTs, EPIRBs and liferafts or proactive lifeboats. Medical emergencies are also of concern, as a medical emergency can occur on a long passage when the closest port is over a week away. For this reason before going cruising many people go through first aid training and carry medical kits. In some parts of the world (e.g., near the Horn of Africa) piracy can be a problem.

</doc>
<doc id="7807" url="https://en.wikipedia.org/wiki?curid=7807" title="Cavitation">
Cavitation

Cavitation is the formation of vapour cavities in a liquid – i.e. small liquid-free zones ("bubbles" or "voids") – that are the consequence of forces acting upon the liquid. It usually occurs when a liquid is subjected to rapid changes of pressure that cause the formation of cavities where the pressure is relatively low. When subjected to higher pressure, the voids implode and can generate an intense shock wave.
Cavitation is a significant cause of wear in some engineering contexts. Collapsing voids that implode near to a metal surface cause cyclic stress through repeated implosion. This results in surface fatigue of the metal causing a type of wear also called "cavitation". The most common examples of this kind of wear are to pump impellers, and bends where a sudden change in the direction of liquid occurs. Cavitation is usually divided into two classes of behavior: inertial (or transient) cavitation and non-inertial cavitation.
Inertial cavitation is the process where a void or bubble in a liquid rapidly collapses, producing a shock wave. Inertial cavitation occurs in nature in the strikes of mantis shrimps and pistol shrimps, as well as in the vascular tissues of plants. In man-made objects, it can occur in control valves, pumps, propellers and impellers.
Non-inertial cavitation is the process in which a bubble in a fluid is forced to oscillate in size or shape due to some form of energy input, such as an acoustic field. Such cavitation is often employed in ultrasonic cleaning baths and can also be observed in pumps, propellers, etc.
Since the shock waves formed by collapse of the voids are strong enough to cause significant damage to moving parts, cavitation is usually an undesirable phenomenon. It is very often specifically avoided in the design of machines such as turbines or propellers, and eliminating cavitation is a major field in the study of fluid dynamics. However, it is sometimes useful and does not cause damage when the bubbles collapse away from machinery, such as in supercavitation.
Physics.
Inertial cavitation was first studied by Lord Rayleigh in the late 19th century, when he considered the collapse of a spherical void within a liquid. When a volume of liquid is subjected to a sufficiently low pressure, it may rupture and form a cavity. This phenomenon is coined "cavitation inception" and may occur behind the blade of a rapidly rotating propeller or on any surface vibrating in the liquid with sufficient amplitude and acceleration. A fast-flowing river can cause cavitation on rock surfaces, particularly when there is a drop-off, such as on a waterfall.
Other ways of generating cavitation voids involve the local deposition of energy, such as an intense focused laser pulse (optic cavitation) or with an electrical discharge through a spark. Vapor gases evaporate into the cavity from the surrounding medium; thus, the cavity is not a perfect vacuum, but has a relatively low gas pressure. Such a low-pressure bubble in a liquid begins to collapse due to the higher pressure of the surrounding medium. As the bubble collapses, the pressure and temperature of the vapor within increases. The bubble eventually collapses to a minute fraction of its original size, at which point the gas within dissipates into the surrounding liquid via a rather violent mechanism which releases a significant amount of energy in the form of an acoustic shock wave and as visible light. At the point of total collapse, the temperature of the vapor within the bubble may be several thousand kelvin, and the pressure several hundred atmospheres. 
Inertial cavitation can also occur in the presence of an acoustic field. Microscopic gas bubbles that are generally present in a liquid will be forced to oscillate due to an applied acoustic field. If the acoustic intensity is sufficiently high, the bubbles will first grow in size and then rapidly collapse. Hence, inertial cavitation can occur even if the rarefaction in the liquid is insufficient for a Rayleigh-like void to occur. High-power ultrasonics usually utilize the inertial cavitation of microscopic vacuum bubbles for treatment of surfaces, liquids, and slurries.
The physical process of cavitation inception is similar to boiling. The major difference between the two is the thermodynamic paths that precede the formation of the vapor. Boiling occurs when the local vapor pressure of the liquid rises above its local ambient pressure and sufficient energy is present to cause the phase change to a gas. Cavitation inception occurs when the local pressure falls sufficiently far below the saturated vapor pressure, a value given by the tensile strength of the liquid at a certain temperature.
In order for cavitation inception to occur, the cavitation "bubbles" generally need a surface on which they can nucleate. This surface can be provided by the sides of a container, by impurities in the liquid, or by small undissolved microbubbles within the liquid. It is generally accepted that hydrophobic surfaces stabilize small bubbles. These pre-existing bubbles start to grow unbounded when they are exposed to a pressure below the threshold pressure, termed Blake's threshold.
The vapor pressure here differs from the meteorological definition of vapor pressure, which describes the partial pressure of water in the atmosphere at some value less than 100% saturation. Vapor pressure as relating to cavitation refers to the vapor pressure in equilibrium conditions and can therefore be more accurately defined as the equilibrium (or saturated) vapor pressure.
Non-inertial cavitation is the process in which small bubbles in a liquid are forced to oscillate in the presence of an acoustic field, when the intensity of the acoustic field is insufficient to cause total bubble collapse. This form of cavitation causes significantly less erosion than inertial cavitation, and is often used for the cleaning of delicate materials, such as silicon wafers.
Hydrodynamic cavitation.
Hydrodynamic cavitation describes the process of vaporisation, bubble generation and bubble implosion which occurs in a flowing liquid as a result of a decrease and subsequent increase in local pressure. Cavitation will only occur if the local pressure declines to some point below the saturated vapor pressure of the liquid and subsequent recovery above the vapor pressure. If the recovery pressure is not above the vapor pressure then flashing is said to have occurred. In pipe systems, cavitation typically occurs either as the result of an increase in the kinetic energy (through an area constriction) or an increase in the pipe elevation.
Hydrodynamic cavitation can be produced by passing a liquid through a constricted channel at a specific flow velocity or by mechanical rotation of an object through a liquid. In the case of the constricted channel and based on the specific (or unique) geometry of the system, the combination of pressure and kinetic energy can create the hydrodynamic cavitation cavern downstream of the local constriction generating high energy cavitation bubbles.
The process of bubble generation, and the subsequent growth and collapse of the cavitation bubbles, results in very high energy densities and in very high local temperatures and local pressures at the surface of the bubbles for a very short time. The overall liquid medium environment, therefore, remains at ambient conditions. When uncontrolled, cavitation is damaging; by controlling the flow of the cavitation, however, the power can be harnessed and non-destructive. Controlled cavitation can be used to enhance chemical reactions or propagate certain unexpected reactions because free radicals are generated in the process due to disassociation of vapors trapped in the cavitating bubbles. .
Orifices and venturi are reported to be widely used for generating cavitation. A venturi has an inherent advantage over an orifice because of its smooth converging and diverging sections, such that that it can generate a higher flow velocity at the throat for a given pressure drop across it. On the other hand, an orifice has an advantage that it can accommodate more number of holes (larger perimeter of holes) in a given cross sectional area of the pipe.
The cavitation phenomenon can be controlled to enhance the performance of high-speed marine vessels and projectiles, as well as in material processing technologies, in medicine, etc. Controlling the cavitating flows in liquids can be achieved only by advancing the mathematical foundation of the cavitation processes. These processes are manifested in different ways, the most common ones and promising for control being bubble cavitation and supercavitation. The first exact classical solution should perhaps be credited to the well- known solution by H. Helmholtz in 1868. The earliest distinguished studies of academic type on the theory of a cavitating flow with free boundaries and supercavitation were published in the book followed by. Widely used in these books was the well-developed theory of conformal mappings of functions of a complex variable, allowing one to derive a large number of exact solutions of plane problems. Another venue combining the existing exact solutions with approximated and heuristic models was explored in the work that refined the applied calculation techniques based on the principle of cavity expansion independence, theory of pulsations and stability of elongated axisymmetric cavities, etc. and in.
A natural continuation of these studies was recently presented in – an encyclopedic work encompassing all the best advances in this domain for the last three decades, and blending the classical methods of mathematical research with the modern capabilities of computer technologies. These include elaboration of nonlinear numerical methods of solving 3D cavitation problems, refinement of the known plane linear theories, development of asymptotic theories of axisymmetric and nearly axisymmetric flows, etc. As compared to the classical approaches, the new trend is characterized by expansion of the theory into the 3D flows. It also reflects a certain correlation with current works of an applied character on the hydrodynamics of supercavitating bodies.
Hydrodynamic cavitation can also improve some industrial processes. For instance, cavitated corn slurry shows higher yields in ethanol production compared to uncavitated corn slurry in dry milling facilities.
This is also used in the mineralization of bio-refractory compounds which otherwise would need extremely high temperature and pressure conditions since free radicals are generated in the process due to the dissociation of vapors trapped in the cavitating bubbles, which results in either the intensification of the chemical reaction or may even result in the propagation of certain reactions not possible under otherwise ambient conditions.
Applications.
Chemical engineering.
In industry, cavitation is often used to homogenize, or mix and break down, suspended particles in a colloidal liquid compound such as paint mixtures or milk. Many industrial mixing machines are based upon this design principle. It is usually achieved through impeller design or by forcing the mixture through an annular opening that has a narrow entrance orifice with a much larger exit orifice. In the latter case, the drastic decrease in pressure as the liquid accelerates into a larger volume induces cavitation. This method can be controlled with hydraulic devices that control inlet orifice size, allowing for dynamic adjustment during the process, or modification for different substances. The surface of this type of mixing valve, against which surface the cavitation bubbles are driven causing their implosion, undergoes tremendous mechanical and thermal localized stress; they are therefore often constructed of super-hard or tough materials such as stainless steel, Stellite, or even polycrystalline diamond (PCD).
Cavitating water purification devices have also been designed, in which the extreme conditions of cavitation can break down pollutants and organic molecules. Spectral analysis of light emitted in sonochemical reactions reveal chemical and plasma-based mechanisms of energy transfer. The light emitted from cavitation bubbles is termed sonoluminescence.
Use of this technology has been tried successfully in alkali refining of vegetable oils.
Hydrophobic chemicals are attracted underwater by cavitation as the pressure difference between the bubbles and the liquid water forces them to join together. This effect may assist in protein folding.
Biomedical.
Cavitation plays an important role for the destruction of kidney stones in shock wave lithotripsy. Currently, tests are being conducted as to whether cavitation can be used to transfer large molecules into biological cells (sonoporation). Nitrogen cavitation is a method used in research to lyse cell membranes while leaving organelles intact.
Cavitation plays a key role in non-thermal non-invasive fractionation of tissue for treatment of a variety of diseases. Cavitation also probably plays a role in HIFU, a thermal noninvasive treatment methodology for cancer.
Ultrasound is sometimes used to increase bone formation, for instance in post-surgical applications.
Ultrasound treatments and/or exposure can create cavitation that can potentially "result in a syndrome involving manifestations of nausea, headache, tinnitus, pain, dizziness, and fatigue.".
It has been suggested that the sound of "cracking" knuckles derives from the collapse of cavitation in the synovial fluid within the joint. Movements that cause cracking expand the joint space, thus reducing pressure to the point of cavitation. It remains controversial whether this is associated with clinically significant joint injury such as osteoarthritis. Some physicians say that osteoarthritis is caused by cracking knuckles regularly, as this causes wear and tear and may cause the bone to weaken. It is not the "bubbles popping," but rather the bones' rubbing together that causes osteoarthritis.
Cleaning.
In industrial cleaning applications, cavitation has sufficient power to overcome the particle-to-substrate adhesion forces, loosening contaminants. The threshold pressure required to initiate cavitation is a strong function of the pulse width and the power input. This method works by generating controlled acoustic cavitation in the cleaning fluid, picking up and carrying contaminant particles away so that they do not reattach to the material being cleaned.
Cavitation damage.
Cavitation is, in many cases, an undesirable occurrence. In devices such as propellers and pumps, cavitation causes a great deal of noise, damage to components, vibrations, and a loss of efficiency. Cavitation has also become a concern in the renewable energy sector as it may occur on the blade surface of tidal stream turbines.
When the cavitation bubbles collapse, they force energetic liquid into very small volumes, thereby creating spots of high temperature and emitting shock waves, the latter of which are a source of noise. The noise created by cavitation is a particular problem for military submarines, as it increases the chances of being detected by passive sonar.
Although the collapse of a small cavity is a relatively low-energy event, highly localized collapses can erode metals, such as steel, over time. The pitting caused by the collapse of cavities produces great wear on components and can dramatically shorten a propeller or pump's lifetime.
After a surface is initially affected by cavitation, it tends to erode at an accelerating pace. The cavitation pits increase the turbulence of the fluid flow and create crevices that act as nucleation sites for additional cavitation bubbles. The pits also increase the components' surface area and leave behind residual stresses. This makes the surface more prone to stress corrosion.
Pumps and propellers.
Major places where cavitation occurs are in pumps, on propellers, or at restrictions in a flowing liquid.
As an impeller's (in a pump) or propeller's (as in the case of a ship or submarine) blades move through a fluid, low-pressure areas are formed as the fluid accelerates around and moves past the blades. The faster the blade moves, the lower the pressure around it can become. As it reaches vapor pressure, the fluid vaporizes and forms small bubbles of gas. This is cavitation. When the bubbles collapse later, they typically cause very strong local shock waves in the fluid, which may be audible and may even damage the blades.
Cavitation in pumps may occur in two different forms:
Suction cavitation.
Suction cavitation occurs when the pump suction is under a low-pressure/high-vacuum condition where the liquid turns into a vapor at the eye of the pump impeller. This vapor is carried over to the discharge side of the pump, where it no longer sees vacuum and is compressed back into a liquid by the discharge pressure. This imploding action occurs violently and attacks the face of the impeller. An impeller that has been operating under a suction cavitation condition can have large chunks of material removed from its face or very small bits of material removed, causing the impeller to look spongelike. Both cases will cause premature failure of the pump, often due to bearing failure. Suction cavitation is often identified by a sound like gravel or marbles in the pump casing.
In automotive applications, a clogged filter in a hydraulic system (power steering, power brakes) can cause suction cavitation making a noise that rises and falls in synch with engine RPM. It is fairly often a high pitched whine, like set of nylon gears not quite meshing correctly.
Discharge cavitation.
Discharge cavitation occurs when the pump discharge pressure is extremely high, normally occurring in a pump that is running at less than 10% of its best efficiency point. The high discharge pressure causes the majority of the fluid to circulate inside the pump instead of being allowed to flow out the discharge. As the liquid flows around the impeller, it must pass through the small clearance between the impeller and the pump housing at extremely high flow velocity. This flow velocity causes a vacuum to develop at the housing wall (similar to what occurs in a venturi), which turns the liquid into a vapor. A pump that has been operating under these conditions shows premature wear of the impeller vane tips and the pump housing. In addition, due to the high pressure conditions, premature failure of the pump's mechanical seal and bearings can be expected. Under extreme conditions, this can break the impeller shaft.
Discharge cavitation in joint fluid is thought to cause the popping sound produced by bone joint cracking, for example by deliberately cracking one's knuckles.
Cavitation solutions.
Since all pumps require well-developed inlet flow to meet their potential, a pump may not perform or be as reliable as expected due to a faulty suction piping layout such as a close-coupled elbow on the inlet flange. When poorly developed flow enters the pump impeller, it strikes the vanes and is unable to follow the impeller passage. The liquid then separates from the vanes causing mechanical problems due to cavitation, vibration and performance problems due to turbulence and poor filling of the impeller. This results in premature seal, bearing and impeller failure, high maintenance costs, high power consumption, and less-than-specified head and/or flow.
To have a well-developed flow pattern, pump manufacturer's manuals recommend about 10 diameters of straight pipe run upstream of the pump inlet flange. Unfortunately, piping designers and plant personnel must contend with space and equipment layout constraints and usually cannot comply with this recommendation. Instead, it is common to use an elbow close-coupled to the pump suction which creates a poorly developed flow pattern at the pump suction.
With a double-suction pump tied to a close-coupled elbow, flow distribution to the impeller is poor and causes reliability and performance shortfalls. The elbow divides the flow unevenly with more channeled to the outside of the elbow. Consequently, one side of the double-suction impeller receives more flow at a higher flow velocity and pressure while the starved side receives a highly turbulent and potentially damaging flow. This degrades overall pump performance (delivered head, flow and power consumption) and causes axial imbalance which shortens seal, bearing and impeller life.
To overcome cavitation:
Increase suction pressure if possible.
Decrease liquid temperature if possible.
Throttle back on the discharge valve to decrease flow-rate.
Vent gases off the pump casing.
Control valves.
Cavitation can occur in control valves. If the actual pressure drop across the valve as defined by the upstream and downstream pressures in the system is greater than the sizing calculations allow, pressure drop flashing or cavitation may occur. The change from a liquid state to a vapor state results from the increase in flow velocity at or just downstream of the greatest flow restriction which is normally the valve port. To maintain a steady flow of liquid through a valve the flow velocity must be greatest at the vena contracta or the point where the cross sectional area is the smallest. This increase in flow velocity is accompanied by a substantial decrease in the fluid pressure which is partially recovered downstream as the area increases and flow velocity decreases. This pressure recovery is never completely to the level of the upstream pressure. If the pressure at the vena contracta drops below the vapor pressure of the fluid bubbles will form in the flow stream. If the pressure recovers after the valve to a pressure that is once again above the vapor pressure, then the vapor bubbles will collapse and cavitation will occur.
Spillways.
When water flows over a dam spillway, the irregularities on the spillway surface will cause small areas of flow separation in a high speed flow, and, in these regions, the pressure will be lowered. If the flow velocities are high enough the pressure may fall to below the local vapor pressure of the water and vapor bubbles will form. When these are carried downstream into a high pressure region the bubbles collapse giving rise to high pressures and possible cavitation damage.
Experimental investigations show that the damage on concrete chute and tunnel spillways can start at clear water flow velocities of between 12 to 15 m/s, and, up to flow velocities of 20 m/s, it may be possible to protect the surface by streamlining the boundaries, improving the surface finishes or using resistant materials.
When some air is present in the water the resulting mixture is compressible and this damps the high pressure caused
by the bubble collapses. If the flow velocities near the spillway invert are sufficiently high, aerators (or aeration devices) must be introduced to prevent cavitation. Although these have been installed for some years, the mechanisms of air entrainment at the aerators and the slow movement of the air away from the spillway surface are still challenging.
The spillway aeration device design is based upon a small deflection of the spillway bed (or sidewall) such as a ramp and offset to deflect the high flow velocity flow away from the spillway surface. In the cavity formed below the nappe, a local subpressure beneath the nappe is produced by which air is sucked into the flow. The complete design includes the deflection device (ramp, offset) and the air supply system.
Engines.
Some larger diesel engines suffer from cavitation due to high compression and undersized cylinder walls. Vibrations of the cylinder wall induce alternating low and high pressure in the coolant against the cylinder wall. The result is pitting of the cylinder wall, which will eventually let cooling fluid leak into the cylinder and combustion gases to leak into the coolant.
It is possible to prevent this from happening with the use of chemical additives in the cooling fluid that form a protective layer on the cylinder wall. This layer will be exposed to the same cavitation, but rebuilds itself. Additionally a regulated overpressure in the cooling system (regulated and maintained by the coolant filler cap spring pressure) prevents the forming of cavitation.
From about the 1980s, new designs of smaller gasoline engines also displayed cavitation phenomena. One answer to the need for smaller and lighter engines was a smaller coolant volume and a correspondingly higher coolant flow velocity. This gave rise to rapid changes in flow velocity and therefore rapid changes of static pressure in areas of high heat transfer. Where resulting vapor bubbles collapsed against a surface, they had the effect of first disrupting protective oxide layers (of cast aluminium materials) and then repeatedly damaging the newly formed surface, preventing the action of some types of corrosion inhibitor (such as silicate based inhibitors). A final problem was the effect that increased material temperature had on the relative electrochemical reactivity of the base metal and its alloying constituents. The result was deep pits that could form and penetrate the engine head in a matter of hours when the engine was running at high load and high speed. These effects could largely be avoided by the use of organic corrosion inhibitors or (preferably) by designing the engine head in such a way as to avoid certain cavitation inducing conditions.
In nature.
Geology.
Some hypotheses relating to diamond formation posit a possible role for cavitation—namely cavitiation in the kimberlite pipes providing the extreme pressure needed to change pure carbon into the rare allotrope that is diamond.
The loudest three sounds ever recorded, during the 1883 eruption of Krakatoa, are now understood as the bursts of three huge cavitation bubbles, each larger than the last, formed in the volcano's throat. Rising magma, filled with dissolved gasses and under immense pressure, encountered a different magma that compressed easily, allowing bubbles to grow and combine. 
Vascular plants.
Cavitation occurs in the xylem of vascular plants when the tension of water within the xylem becomes so great that liquid water (or sap) vaporizes locally and dissolved air within the water expands to fill either the vessel elements or tracheids. Plants are generally able to repair cavitated xylem in a number of ways. For plants less than 50 cm tall, root pressure can be sufficient to redissolve air. For larger plants, they must repair cavitation by importing solutes into the xylem via "ray cells", or in tracheids, via osmosis through bordered pits; this causes water to enter as well, which can then redissolve the air. In some trees, the sound of the cavitation is clearly audible, particularly in summer, when the rate of evapotranspiration is highest, and can be used to determine the rate of cavitation. Deciduous trees shed leaves in the autumn partly because cavitation increases as temperatures decrease.
Marine life.
Just as cavitation bubbles form on a fast-spinning boat propeller, they may also form on the tails and fins of aquatic animals. The effects of cavitation are especially important near the surface of the ocean, where the ambient water pressure is relatively low and cavitation is more likely to occur.
For powerful swimming animals like dolphins and tuna, cavitation may be detrimental, because it limits their maximum swimming speed. Even if they have the power to swim faster, dolphins may have to restrict their speed because collapsing cavitation bubbles on their tail are very painful. Cavitation also slows tuna, but for a different reason. Unlike dolphins, these fish do not feel the painful bubbles, because they have bony fins without nerve endings. Nevertheless, they cannot swim faster because the cavitation bubbles create a vapor film around their fins that limits their speed. Lesions have been found on tuna that are consistent with cavitation damage.
Cavitation is not always a limitation for sea life; some animals have found ways to use it to their advantage when hunting prey. The pistol shrimp snaps a specialized claw to create cavitation, which can kill small fish. The mantis shrimp (of the "smasher" variety) uses cavitation as well in order to stun, smash open, or kill the shellfish that it feasts upon.
Thresher sharks use 'tail slaps' to debilitate their small fish prey and cavitation bubbles have been seen rising from the apex of the tail arc.
Coastal erosion.
In the last half-decade, coastal erosion in the form of inertial cavitation has been generally accepted. Vapor pockets in an incoming wave are forced into cracks in the cliff being eroded, then the force of the wave compresses the vapor pockets until the bubble implodes, becoming liquid, giving off various forms of energy that blast apart the rock.

</doc>
<doc id="7808" url="https://en.wikipedia.org/wiki?curid=7808" title="Cyprinodontiformes">
Cyprinodontiformes

Cyprinodontiformes is an order of ray-finned fish, comprising mostly small, freshwater fish. Many popular aquarium fish, such as killifish and live-bearers, are included. They are closely related to the Atheriniformes and are occasionally included with them. A colloquial term for the order as a whole is toothcarps, though they are not actually close relatives of the true carps – the latter belong to the superorder Ostariophysi, while the toothcarps are Acanthopterygii.
The families of Cyprinodontiformes can be divided into three groups: viviparous and ovoviviparous (all species give live birth), and oviparous (all species egg-laying). The live-bearing groups differ in whether the young are carried to term within (ovoviviparous) or without (viviparous) an enclosing eggshell. Phylogenetically however, one of the two suborders – the Aplocheiloidei – contains oviparous species exclusively, as do two of the four superfamilies of the other suborder (the Cyprinodontoidea and Valencioidea of the Cyprinodontoidei). Vivipary and ovovivipary have evolved independently from oviparous ancestors, the latter possibly twice.
Description.
Members of this order are notable for inhabiting harsh environments, such as saline or very warm waters, water of poor quality, or isolated situations where no other types of fish occur. They are typically omnivores, and often live near the surface, where the oxygen-rich water compensates for environmental disadvantages.
They are small to medium-sized fish, with small mouths, large eyes, a single dorsal fin, and a rounded caudal fin. The largest species is the "cuatro ojos" ("Anableps dowi"), which measures in length, while the smallest, the least killifish ("Heterandria formosa"), is just long as an adult.
Systematics.
CYPRINODONTIFORMES

</doc>
<doc id="7810" url="https://en.wikipedia.org/wiki?curid=7810" title="Church of the Holy Sepulchre">
Church of the Holy Sepulchre

The Church of the Holy Sepulchre (; also called the Church of the Resurrection or Church of the "Anastasis" by Orthodox Christians (, "Kanissat al-Qiyama"; , "Surb Harut’ian Tachar"; , "Naos tes Anastaseos"), is a church within the Christian Quarter of the Old City of Jerusalem. It is a few steps away from the Muristan.
The church contains, according to traditions dating back at least to the fourth century, the two holiest sites in Christendom: the site where Jesus of Nazareth was crucified, known as "Calvary" in Latin and "Golgotha" in Greek, and Jesus's empty tomb, where he is said to have been buried and resurrected. Within the church proper are the last four (or, by some definitions, five) Stations of the Via Dolorosa, representing the final episodes of Jesus' Passion. The church has been a major Christian pilgrimage destination since its creation in the fourth century, as the traditional site of the Resurrection of Christ, thus its original Greek name, Church of the Anastasis.
Today the wider complex accumulated during the centuries around the Church of the Holy Sepulchre also serves as the headquarters of the Greek Orthodox Patriarch of Jerusalem, while control of the church itself is shared between several Christian denominations and secular entities in complicated arrangements essentially unchanged for over 160 years, and some for much longer. The main denominations sharing property over parts of the church are the Greek Orthodox, Armenian Orthodox and Roman Catholic, and to a lesser degree the Egyptian Copts, Syriacs and Ethiopians. Meanwhile, Protestants including Anglicans have no permanent presence in the Church and they generally prefer the Garden Tomb, elsewhere in Jerusalem, as either the true place of Jesus' crucifixion and resurrection, or at least a more evocative site to commemorate those events.
History.
Construction.
According to Eusebius of Caesarea, the Roman emperor Hadrian in the 2nd century AD built a temple dedicated to the goddess Aphrodite in order to bury the cave in which Jesus had been buried. The first Christian emperor, Constantine the Great, ordered in about 325/326 that the temple be replaced by a church. During the building of the Church, Constantine's mother, Helena, is believed to have rediscovered the "True Cross", which tradition holds that when she found three crosses she tested each by having it held over a corpse and when the corpse rose up under one, that was the true cross, and a tomb (although there are some discrepancies among authors). Socrates Scholasticus (born c. 380), in his "Ecclesiastical History," gives a full description of the discovery. 
Constantine's church was built as two connected churches over the two different holy sites, including a great basilica (the "Martyrium" visited by Egeria in the 380s), an enclosed colonnaded atrium (the "Triportico") with the traditional site of "Golgotha" in one corner, and a rotunda, called the "Anastasis" ("Resurrection" in Greek), which contained the remains of a rock-cut room that Helena and Macarius identified as the burial site of Jesus.
According to tradition, Constantine arranged for the rockface to be removed from around the tomb, without harming it, in order to isolate the tomb; in the centre of the rotunda is a small building called the "Kouvouklion" in Greek or the "Aedicula" in Latin, which encloses this tomb. The remains are completely enveloped by a marble sheath placed some 500 years before to protect the ledge from Ottoman attacks. However, there are several thick window wells extending through the marble sheath, from the interior to the exterior that are not marble clad. They appear to reveal an underlying limestone rock, which may be part of the original living rock of the tomb.
The church was built starting in 325/326, and was consecrated on 13 September 335. From pilgrim reports it seems that the chapel housing the tomb of Jesus was freestanding at first, and that the Rotunda was only erected around the chapel in the 380s.
Each year, the Eastern Orthodox Church celebrates the anniversary of the consecration of the Church of the Resurrection (Holy Sepulchre) on 13 September.
Damage and destruction.
This building was damaged by fire in May of 614 when the Sassanid Empire, under Khosrau II, invaded Jerusalem and captured the True Cross which was restored in 630 by the Emperor Heraclius when he recaptured and rebuilt the church. After Jerusalem was captured by the Arabs, it remained a Christian church, with the early Muslim rulers protecting the city's Christian sites. A story reports that the Caliph Umar ibn al-Khattab visited the church and stopped to pray on the balcony; but at the time of prayer, he turned away from the church and prayed outside. He feared that future generations would misinterpret this gesture, taking it as a pretext to turn the church into a mosque. Eutychius added that Umar wrote a decree prohibiting Muslims from praying at this location. The building suffered severe damage due to an earthquake in 746.
Early in the ninth century, another earthquake damaged the dome of the Anastasis. The damage was repaired in 810 by Patriarch Thomas. In the year 841, the church suffered a fire. In 935, the Orthodox Christians prevented the construction of a Muslim mosque adjacent the Church. In 938, a new fire damaged the inside of the basilica and came close to the roundabout. In 966, due to a defeat of Muslim armies in the region of Syria, a riot broke out and was followed by reprisals. The basilica was burned again. The doors and roof were burnt, and the Patriarch John VII was murdered.
On 18 October 1009, Fatimid caliph Al-Hakim bi-Amr Allah ordered the complete destruction of the church as part of a more general campaign against Christian places of worship in Palestine and Egypt. The damage was extensive, with few parts of the early church remaining. Christian Europe reacted with shock and expulsions of Jews (for example, Cluniac monk Rodulfus Glaber blamed the Jews, with the result that Jews were expelled from Limoges and other French towns) and an impetus to later Crusades.
Reconstruction.
In wide ranging negotiations between the Fatimids and the Byzantine Empire in 1027–8, an agreement was reached whereby the new Caliph Ali az-Zahir (Al-Hakim's son) agreed to allow the rebuilding and redecoration of the Church. The rebuilding was finally completed with the financing at a huge expense by Emperor Constantine IX Monomachos and Patriarch Nicephorus of Constantinople in 1048. As a concession, the mosque in Constantinople was re-opened and sermons were to be pronounced in az-Zahir's name. Muslim sources say a by-product of the agreement was the recanting of Islam by many Christians who had been forced to convert under Al-Hakim's persecutions. In addition, the Byzantines, while releasing 5,000 Muslim prisoners, made demands for the restoration of other churches destroyed by Al-Hakim and the re-establishment of a Patriarch in Jerusalem. Contemporary sources credit the emperor with spending vast sums in an effort to restore the Church of the Holy Sepulchre after this agreement was made. Despite the Byzantines spending vast sums on the project, "a total replacement was far beyond available resources. The new construction was concentrated on the rotunda and its surrounding buildings: the great basilica remained in ruins." The rebuilt church site consisted of "a court open to the sky, with five small chapels attached to it." The chapels were to the east of the court of resurrection, where the wall of the great church had been. They commemorated scenes from the passion, such as the location of the prison of Christ and of his flagellation, and presumably were so placed because of the difficulties of free movement among shrines in the streets of the city. The dedication of these chapels indicates the importance of the pilgrims' devotion to the suffering of Christ. They have been described as 'a sort of Via Dolorosa in miniature'... since little or no rebuilding took place on the site of the great basilica. Western pilgrims to Jerusalem during the eleventh century found much of the sacred site in ruins." Control of Jerusalem, and thereby the Church of the Holy Sepulchre, continued to change hands several times between the Fatimids and the Seljuk Turks (loyal to the Abbasid caliph in Baghdad) until the arrival of the Crusaders in 1099.
Crusader period.
Many historians maintain that the main concern of Pope Urban II, when calling for the First Crusade, was the threat to Constantinople from the Turkish invasion of Asia Minor in response to the appeal of Byzantine Emperor Alexios I Komnenos. Historians agree that the fate of Jerusalem and thereby the Church of the Holy Sepulchre was of concern if not the immediate goal of papal policy in 1095. The idea of taking Jerusalem gained more focus as the Crusade was underway. The rebuilt church site was taken from the Fatimids (who had recently taken it from the Abassids) by the knights of the First Crusade on 15 July 1099.
The First Crusade was envisioned as an armed pilgrimage, and no crusader could consider his journey complete unless he had prayed as a pilgrim at the Holy Sepulchre. Crusader Prince Godfrey of Bouillon, who became the first crusader monarch of Jerusalem, decided not to use the title "king" during his lifetime, and declared himself "Advocatus Sancti Sepulchri" ("Protector Defender of the Holy Sepulchre"). By the crusader period, a cistern under the former basilica was rumoured to have been the location where Helena had found the True Cross, and began to be venerated as such; although the cistern later became the "Chapel of the Invention of the Cross," there is no evidence for the rumour prior to the 11th century, and modern archaeological investigation has now dated the cistern to 11th century repairs by Monomachos.
According to the German clergyman and orient pilgrim Ludolf von Sudheim, the keys of the Chapel of the Holy Sepulchre were in hands of the "ancient Georgians" and the food, alms, candles and oil for lamps were given them by the pilgrims in the south door of the church.
William of Tyre, chronicler of the Crusader Kingdom of Jerusalem, reports on the renovation of the Church in the mid-12th century. The crusaders investigated the eastern ruins on the site, occasionally excavating through the rubble, and while attempting to reach the cistern, they discovered part of the original ground level of Hadrian's temple enclosure; they decided to transform this space into a chapel dedicated to Helena (the Chapel of Saint Helena), widening their original excavation tunnel into a proper staircase. The crusaders began to refurnish the church in a Romanesque style and added a bell tower. These renovations unified the small chapels on the site and were completed during the reign of Queen Melisende in 1149, placing all the Holy places under one roof for the first time. The church became the seat of the first Latin Patriarchs, and was also the site of the kingdom's scriptorium. The church was lost to Saladin, along with the rest of the city, in 1187, although the treaty established after the Third Crusade allowed for Christian pilgrims to visit the site. Emperor Frederick II (r. 1220–50) regained the city and the church by treaty in the 13th century, while he himself was under a ban of excommunication, leading to the curious result of the holiest church in Christianity being laid under interdict. The church seems to have been largely in Greek Orthodox Patriarch Athanasius II of Jerusalem's hands, ca. 1231–47, during the Latin control of Jerusalem. Both city and church were captured by the Khwarezmians in 1244.
Later periods.
The Franciscan friars renovated it further in 1555, as it had been neglected despite increased numbers of pilgrims. The Franciscans rebuilt the Aedicule, extending the structure to create an ante-chamber. After the renovation of 1555, control of the church oscillated between the Franciscans and the Orthodox, depending on which community could obtain a favorable "firman" from the "Sublime Porte" at a particular time, often through outright bribery, and violent clashes were not uncommon. There was no agreement about this question, although it was discussed at the negotiations to the Treaty of Karlowitz in 1699. In 1767, weary of the squabbling, the "Porte" issued a "firman" that divided the church among the claimants.
A fire severely damaged the structure again in 1808, causing the dome of the Rotunda to collapse and smashing the Edicule's exterior decoration. The Rotunda and the Edicule's exterior were rebuilt in 1809–1810 by architect Nikolaos Ch. Komnenos of Mytilene in the then current Ottoman Baroque style. The fire did not reach the interior of the Aedicule, and the marble decoration of the Tomb dates mainly to the 1555 restoration, although the interior of the ante-chamber, now known as the "Chapel of the Angel," was partly rebuilt to a square ground-plan, in place of the previously semi-circular western end. Another decree in 1853 from the sultan solidified the existing territorial division among the communities and set a "status quo" for arrangements to "remain forever," causing differences of opinion about upkeep and even minor changes, including disagreement on the removal of the "Immovable Ladder," an exterior ladder under one of the windows; this ladder has remained in the same position since then.
The cladding of red marble applied to the Aedicule by Komnenos has deteriorated badly and is detaching from the underlying structure; since 1947 it has been held in place with an exterior scaffolding of iron girders installed by the British Mandate. Plans were announced in 2016 for a careful renovation, to be underwritten by a $3.4 million (USD) gift from Abdullah II of Jordan.
The current dome dates from 1870, although it was restored between 1994–1997, as part of extensive modern renovations to the church which have been ongoing since 1959. During the 1970–1978 restoration works and excavations inside the building, and under the nearby Muristan, it was found that the area was originally a quarry, from which white "meleke" limestone was struck. To the east of the "Chapel of Saint Helena", the excavators discovered a void containing a 2nd-century drawing of a Roman ship, two low walls which supported the platform of Hadrian's 2nd-century temple, and a higher 4th-century wall built to support Constantine's basilica. After the excavations of the early 1970s, the Armenian authorities converted this archaeological space into the Chapel of Saint Vartan, and created an artificial walkway over the quarry on the north of the chapel, so that the new Chapel could be accessed (by permission) from the "Chapel of Saint Helena".
There was some controversy in 2010 when Israel threatened to cut off water to the site, demanding payment for all water use since the occupation began in 1967.
Entrance and parvis.
The entrance to the church, a single door in the south transept—through the crusader facade—is found past a group of streets winding through the outer Via Dolorosa, by way of a local souq in the Muristan. This narrow way of access to such a large structure has proven to be hazardous at times. For example, when a fire broke out in 1840, dozens of pilgrims were trampled to death.
Historically, two large, arched doors allowed access to the church. However, only the left-hand entrance is currently accessible, as the right door has long since been bricked up. These entrances are located in the parvis of a larger courtyard, or plaza.
Also located along the parvis are a few smaller structures and openings:
Broken columns—once forming part of an arcade—flank the church's front, which is covered in crusader graffiti mostly consisting of crosses. In the 13th century, the tops of the columns were removed and sent to Mecca by the Khwarezmids.
The church's bell tower is located to the left of the facade. It is currently almost half its original size.
The historic Immovable Ladder stands beneath a window on the facade.
Calvary (Golgotha).
On the south side of the altar, via the ambulatory, is a stairway climbing to Calvary (Golgotha), traditionally regarded as the site of Jesus' crucifixion and the most lavishly decorated part of the church. The main altar there belongs to the Greek Orthodox, which contains the Rock of Calvary (12th Station of the Cross). The rock can be seen under glass on both sides of the altar, and beneath the altar there is a hole said to be the place where the cross was raised. Due to the significance of this, it is the most visited site in the Church of the Holy Sepulchre. The Roman Catholics (Franciscans) have an altar to the side, the Chapel of the Nailing of the Cross (11th Station of the Cross). On the left of the altar, towards the Eastern Orthodox chapel, there is a statue of Mary, believed by some to be miraculous (the 13th Station of the Cross, where Jesus' body was removed from the cross and given to his family).
Beneath the Calvary and the two chapels there, on the main floor, there is the Chapel of Adam. According to tradition, Jesus was crucified over the place where Adam's skull was buried. According to some, at the crucifixion, the blood of Christ ran down the cross and through the rocks to fill the skull of Adam. The Rock of Calvary appears cracked through a window on the altar wall, with the crack traditionally claimed to be caused by the earthquake that occurred when Jesus died on the cross, while some scholars claim it to be the result of quarrying against a natural flaw in the rock.
Stone of Anointing.
Just inside the entrance to the church is the Stone of Anointing (also Stone of the Anointing or Stone of Unction), which tradition believes to be the spot where Jesus' body was prepared for burial by Joseph of Arimathea. However, this tradition is only attested since the crusader era (notably by the Italian Dominican pilgrim Riccoldo da Monte di Croce in 1288), and the present stone was only added in the 1810 reconstruction.
The wall behind the stone is defined by its striking blue balconies and tau cross-bearing red banners (depicting the insignia of the Brotherhood of the Holy Sepulchre), and is decorated with lamps. The modern mosaic along the wall depicts the anointing of Jesus' body.
The wall was a temporary addition to support the arch above it, which had been weakened after the damage in the 1808 fire; it blocks the view of the rotunda, separates the entrance from the Catholicon, sits on top of the now-empty and desecrated graves of four 12th-century crusader kings—including Godfrey of Bouillon and Baldwin I of Jerusalem—and is no longer structurally necessary. There is a difference of opinion as to whether it is the 13th Station of the Cross, which others identify as the lowering of Jesus from the cross and locate between the 11th and 12th stations up on Calvary.
The lamps that hang over the Stone of Unction, adorned with cross-bearing chain links, are contributed by Armenians, Copts, Greeks and Latins.
Immediately to the left of the entrance is a bench that has traditionally been used by the church's Muslim doorkeepers, along with some Christian clergy, as well as electrical wiring. To the right of the entrance is a wall along the ambulatory containing, to the very right, the staircase leading to Golgatha. Further along the same wall is the entrance to the Chapel of Adam.
Rotunda and Aedicule.
The Rotunda is located in the centre of the Anastasis, beneath the larger of the church's two domes. In the center of the Rotunda is the chapel called the Aedicule, which contains the Holy Sepulchre itself. The Aedicule has two rooms, the first holding the Angel's Stone, which is believed to be a fragment of the large stone that sealed the tomb; the second is the tomb itself. Due to the fact that pilgrims lay their hands on the tomb, a marble plaque was placed in the fourteenth century on the tomb to prevent further damage to the tomb.
Under the "status quo", the Eastern Orthodox, Roman Catholic, and Armenian Apostolic Churches all have rights to the interior of the tomb, and all three communities celebrate the Divine Liturgy or Holy Mass there daily. It is also used for other ceremonies on special occasions, such as the Holy Saturday ceremony of the Holy Fire led by the Greek Orthodox Patriarch (with the participation of the Coptic and Armenian patriarchs). To its rear, within a chapel constructed of iron latticework upon a stone base semicircular in plan, lies the altar used by the Coptic Orthodox. Historically, the Georgians also retained the key to the Aedicule.
Beyond that to the rear of the Rotunda is a rough-hewn chapel containing an opening to a chamber cut from the rock, from which several "kokh"-tombs radiate. Although this space was discovered recently, and contains no identifying marks, many Christians believe it to be the tomb of Joseph of Arimathea, and it is where the Syriac Orthodox celebrate their Liturgy on Sundays. To the right of the Sepulchre on the southeastern edge of the Rotunda is the Chapel of the Apparition, which is reserved for Roman Catholic use.
Catholicon and Ambulatory.
East of this is a large iconostasis demarcating the Orthodox sanctuary before which is set the throne of the Greek Orthodox Patriarch of Jerusalem on the south side facing the throne of the Greek Orthodox Patriarch of Antioch on the north side.
Further to the east in the ambulatory are three chapels (from south to north):
Armenian compound.
South of the Aedicule.
The three Greek Orthodox chapels of St. James the Just, St. John the Baptist and of the Forty Martyrs of Sebaste, south of the rotunda and on the west side of the front courtyard originally formed the baptistery complex of the Constantinean church, the southernmost chapel being the vestibule, the middle chapel being the actual baptistery and the north chapel being the chamber in which the patriarch chrismated the newly baptized before leading them into the rotunda north of this complex.
Syriac Chapel.
The Syriac Orthodox Chapel of Saint Joseph of Arimathea and Saint Nicodemus. On Sundays and feast days it is furnished for the celebration of Mass.
On the far side of the chapel is the low entrance to two complete 1st-century Jewish tombs. Since Jews always buried their dead outside the city, this proves that the Holy Sepulchre site was outside the city walls at the time of the crucifixion. There is a tradition that Joseph of Arimathea and Nicodemus were buried here.
Status quo.
The Sultan's firman (decree) of 1853, known as the "status quo", pinned down the now permanent statutes of property and the regulations concerning the roles of the different denominations and other custodians.
The primary custodians are the Greek Orthodox, Armenian Apostolic, and Roman Catholic Churches, with the Greek Orthodox Church having the lion's share. In the 19th century, the Coptic Orthodox, the Ethiopian Orthodox and the Syriac Orthodox acquired lesser responsibilities, which include shrines and other structures within and around the building. Times and places of worship for each community are strictly regulated in common areas. The Greek Orthodox act through the Greek Orthodox Patriarchate as well as through the Brotherhood of the Holy Sepulchre. The Roman Catholics act through the Franciscan Custody of the Holy Land.
The establishment of the 1853 status quo did not halt the violence, which continues to break out every so often even in modern times. On a hot summer day in 2002, a Coptic monk moved his chair from its agreed spot into the shade. This was interpreted as a hostile move by the Ethiopians, and eleven were hospitalized after the resulting fracas.
In another incident in 2004, during Orthodox celebrations of the Exaltation of the Holy Cross, a door to the Franciscan chapel was left open. This was taken as a sign of disrespect by the Orthodox and a fistfight broke out. Some people were arrested, but no one was seriously injured.
On Palm Sunday, in April 2008, a brawl broke out when a Greek monk was ejected from the building by a rival faction. Police were called to the scene but were also attacked by the enraged brawlers. On Sunday, 9 November 2008, a clash erupted between Armenian and Greek monks during celebrations for the Feast of the Cross.
Under the "status quo", no part of what is designated as common territory may be so much as rearranged without consent from all communities. This often leads to the neglect of badly needed repairs when the communities cannot come to an agreement among themselves about the final shape of a project. Just such a disagreement has delayed the renovation of the "edicule", where the need is now dire, but also where any change in the structure might result in a change to the "status quo", disagreeable to one or more of the communities.
A less grave sign of this state of affairs is located on a window ledge over the church's entrance. A wooden ladder was placed there at some time before 1852, when the "status quo" defined both the doors and the window ledges as common ground. This ladder, the "Immovable Ladder", remains to this day, in almost exactly the same position it occupied in century-old photographs and engravings. An engraving by David Roberts in 1839 also shows the same ladder in the same position.
No one controls the main entrance. In 1192, Saladin (Salah ad-Din Yusuf al-Ayyubi) assigned door keeping responsibilities to the Muslim Nuseibeh family. The wooden doors that compose the main entrance are the original, highly carved doors. The Joudeh Al-Goudia family were entrusted as custodian to the keys of the Holy Sepulchre by Saladin in 1187. This arrangement has persisted into modern times.
Connection to Temple of Aphrodite.
The site of the Church had been a temple of Aphrodite prior to Constantine's edifice being built. Hadrian's temple had actually been located there because it was the junction of the main north-south road with one of the two main east-west roads and directly adjacent to the forum (which is now the location of the (smaller) Muristan); the forum itself had been placed, as is traditional in Roman towns, at the junction of the main north-south road with the (other) main east-west road (which is now El-Bazar/David Street). The temple and forum together took up the entire space between the two main east-west roads (a few above-ground remains of the east end of the temple precinct still survive in the Alexander Nevsky Church complex of the "Russian Mission in Exile").
From the archaeological excavations in the 1970s, it is clear that construction took over most of the site of the earlier temple enclosure and that the "Triportico" and "Rotunda" roughly overlapped with the temple building itself; the excavations indicate that the temple extended at least as far back as the Aedicule, and the temple enclosure would have reached back slightly further. Virgilio Canio Corbo, a Franciscan priest and archaeologist, who was present at the excavations, estimated from the archaeological evidence that the western retaining wall, of the temple itself, would have passed extremely close to the east side of the supposed tomb; if the wall had been any further west any "tomb" would have been crushed under the weight of the wall (which would be immediately above it) if it had not already been destroyed when foundations for the wall were made.
Other archaeologists have criticized Corbo's reconstructions. Dan Bahat, the former city archaeologist of Jerusalem, regards them as unsatisfactory, as there is no known temple of Aphrodite matching Corbo's design, and no archaeological evidence for Corbo's suggestion that the temple building was on a platform raised high enough to avoid including anything sited where the Aedicule is now; indeed Bahat notes that many temples to Aphrodite have a rotunda-like design, and argues that there is no archaeological reason to assume that the present rotunda was not based on a rotunda in the temple previously on the site.
Location.
The Bible describes Jesus' tomb as being outside the city wall, as was normal for burials across the ancient world, which were regarded as unclean. Today, the site of the Church is within the current walls of the old city of Jerusalem. It has been well documented by archaeologists that in the time of Jesus, the walled city was smaller and the wall then was to the east of the current site of the Church. In other words, the city had been much narrower in Jesus' time, with the site then having been outside the walls; since Herod Agrippa (41–44) is recorded by history as extending the city to the north (beyond the present northern walls), the required repositioning of the western wall is traditionally attributed to him as well. The church is a part of the UNESCO World Heritage Site Old City of Jerusalem.
The area immediately to the south and east of the sepulchre was a quarry and outside the city during the early 1st century as excavations under the Lutheran Church of the Redeemer across the street demonstrated.
Influence.
From the 9th century, the construction of churches inspired in the Anastasis was extended across Europe. One example is Santo Stefano in Bologna, Italy, an agglomeration of seven churches recreating shrines of Jerusalem.
Several churches and monasteries in Europe, for instance, in Germany and Russia, and at least one church in the United States have been modeled on the Church of the Resurrection, some even reproducing other holy places for the benefit of pilgrims who could not travel to the Holy Land. They include the Heiliges Grab of Görlitz, constructed between 1481 and 1504,the New Jerusalem Monastery in Moscow Oblast, constructed by Patriarch Nikon between 1656 and 1666, and Mount St. Sepulchre Franciscan Monastery built by the Franciscans in Washington, DC in 1898.

</doc>
<doc id="7811" url="https://en.wikipedia.org/wiki?curid=7811" title="Cernunnos">
Cernunnos

Cernunnos is the conventional name given in Celtic studies to depictions of the "horned god" (sometimes referred to as Herne the Hunter) of Celtic polytheism. The name itself is only attested once, on the 1st-century Pillar of the Boatmen, but depictions of a horned or antlered figure, often seated cross-legged and often associated with animals and holding or wearing torcs, are known from over 50 examples in the Gallo-Roman period, mostly in north-eastern Gaul.
Nothing is known about the god from literary sources, and details about his name, his followers or his significance in Celtic religion are unknown. Speculative interpretations identify him as a god of nature or fertility.
Name.
The theonym "ernunnos" appears on the Pillar of the Boatmen, a Gallo-Roman monument dating to the early 1st century CE, to label a god depicted with stag's antlers in their early stage of annual growth. Both antlers have torcs hanging from them.
The name has been compared to a divine epithet "Carnonos" in a Celtic inscription written in Greek characters at Montagnac, Hérault (as καρνονου, "karnonou", in the dative case).
A Gallo-Latin adjective "carnuātus", "horned," is also found.
The Proto-Celtic form of the theonym is reconstructed as either *"Cerno-on-os" or *"Carno-on-os". The augmentative "-on-" is characteristic of theonyms, as in Maponos, Epona, Matronae, and Sirona.
Maier (2010) states that the etymology of "Cernunnos" is unknown, as the Celtic word for "horn" has an "a" (as in "Carnonos").
Gaulish "karnon" "horn" is cognate with Latin "cornu" and Germanic "*hurnaz", English "horn", ultimately from Proto-Indo-European "".
The etymon "karn-" "horn" appears in both Gaulish and Galatian branches of Continental Celtic. Hesychius of Alexandria glosses the Galatian word "karnon" (κάρνον) as "Gallic trumpet", that is, the Celtic military horn listed as the carnyx (κάρνυξ) by Eustathius of Thessalonica, who notes the instrument's animal-shaped bell. The root also appears in the names of Celtic polities, most prominent among them the Carnutes, meaning something like "the Horned Ones," and in several personal names found in inscriptions.
Epigraphic evidence.
The name "Cernunnos" occurs only on the "Pillar of the Boatmen" ("Pilier des nautes"), now displayed in the Musée National du Moyen Age in Paris. Constructed by Gaulish sailors probably in 14 CE, it was discovered in 1710 within the foundations of the cathedral of Notre-Dame de Paris, site of ancient Lutetia, the "civitas" capital of the Celtic Parisii. The distinctive stone pillar is an important monument of Gallo-Roman religion. Its low reliefs depict and label by name several Roman deities such as Jupiter, Vulcan, and Castor and Pollux, along with Gallic deities such as Esus, Smertrios, and Tarvos Trigaranus. The name "Cernunnos" can be read clearly on 18th century drawings of the inscriptions, but the initial letter has been obscured since, so that today only a reading "ernunnos" can be verified
Additional evidence is given by one inscription on a metal plaque from Steinsel-Rëlent in Luxembourg, in the territory of the Celtic Treveri. This inscription read "Deo Ceruninco", "to the God Cerunincos", assumed to be the same deity. The Gaulish inscription from Montagnac reads αλλετ[ει]υος καρνονου αλ[ι]σο[ντ]εας "(alleteiuos karnonou alisonteas)", with the last word possibly a place name based on "alisia", "service-tree" or "rock" (compare Alesia, Gaulish "Alisiia").
Iconography.
The god labelled "ernunnos" on the Pillar of the Boatmen is depicted with stag's antlers in their early stage of annual growth. Both antlers have torcs hanging from them. The lower part of the relief is lost, but the dimensions suggest that the god was sitting cross-legged, providing a direct parallel to the antlered figure on the Gundestrup cauldron.
In spite of the name "Cernunnos" being attested nowhere else, it is commonly used in Celtological literature as describing all comparable depictions of horned/antlered deities.
This "Cernunnos" type in Celtic iconography is often portrayed with animals, in particular the stag, and also frequently associated with the ram-horned serpent, and less frequently bulls (at Rheims), dogs and rats. Because of his frequent association with creatures, scholars often describe Cernunnos as the "Lord of the Animals" or the "Lord of Wild Things", and Miranda Green describes him as a "peaceful god of nature and fruitfulness".
The "Pilier des nautes" links him with sailors and with commerce, suggesting that he was also associated with material wealth as does the coin pouch from the Cernunnos of Rheims (Marne, Champagne, France)—in antiquity, Durocortorum, the "civitas" capital of the Remi tribe—and the stag vomiting coins from Niedercorn-Turbelslach (Luxembourg) in the lands of the Treveri. The god may have symbolised the fecundity of the stag-inhabited forest.
Other examples of "Cernunnos" images include a petroglyph in Val Camonica in Cisalpine Gaul. The antlered human figure has been dated as early as the 7th century BCE or as late as the 4th. An antlered child appears on a relief from Vendeuvres, flanked by serpents and holding a purse and a torc. The best known image appears on the Gundestrup cauldron found on Jutland, dating to the 1st century BC, thought to depict Celtic subject matter though usually regarded as of Thracian workmanship.
Among the Celtiberians, horned or antlered figures of the Cernunnos type include a "Janus-like" god from Candelario (Salamanca) with two faces and two small horns; a horned god from the hills of Ríotinto (Huelva); and a possible representation of the deity Vestius Aloniecus near his altars in Lourizán (Pontevedra). The horns are taken to represent "aggressive power, genetic vigor and fecundity."
Divine representations of the Cernunnos type are exceptions to the often-expressed view that the Celts only began to picture their gods in human form after the Roman conquest of Gaul.
The Celtic "horned god", while well attested in iconography, cannot be identified in description of Celtic religion in Roman ethnography and does not appear to have been given any "interpretatio romana", perhaps due to being too distinctive to be translatable into the Roman pantheon.
While Cernunnos was never assimilated, scholars have sometimes compared him functionally to Greek and Roman divine figures such as Mercury, Actaeon, specialized forms of Jupiter, and Dis Pater, the latter of whom Julius Caesar said was considered the ancestor of the Gauls.
Possible reflexes in Insular Celtic.
There have been attempts to find the "cern" root in the name of Conall Cernach, the foster brother of the Irish hero Cuchulainn in the Ulster Cycle. In this line of interpretation, "Cernach" is taken as an epithet with a wide semantic field — "angular; victorious; bearing a prominent growth" — and Conall is seen as "the same figure" as the ancient Cernunnos.
Possible connection to Saint Ciarán.
Some see the qualities of Cernunnos subsumed into the "life" of Saint Ciarán of Saighir, one of the Twelve Apostles of Ireland. When he was building his first tiny cell, as his hagiograph goes, his first disciple and monk was a boar that had been rendered gentle by God. This was followed by a fox, a badger, a wolf and a stag.
Neopaganism.
In Wicca and other forms of Neopaganism a Horned God is revered; this divinity syncretises a number of horned or antlered gods from various cultures, including Cernunnos. The Horned God reflects the seasons of the year in an annual cycle of life, death and rebirth.
In the tradition of Gardnerian Wicca, the Horned God is sometimes specifically referred to as Cernunnos, or sometimes also as Kernunno.

</doc>
<doc id="7816" url="https://en.wikipedia.org/wiki?curid=7816" title="Click consonant">
Click consonant

Clicks are speech sounds that occur as consonants in many languages of Southern Africa and in three languages of East Africa. Examples familiar to English-speakers are the "tsk! tsk!" (American spelling) or "tut-tut" (British spelling) used to express disapproval or pity, the "tchick!" used to spur on a horse, and the "clip-clop!" sound children make with their tongue to imitate a horse trotting.
Technically, clicks are obstruents articulated with two closures (points of contact) in the mouth, one forward and one at the back. The enclosed pocket of air is rarefied by a sucking action of the tongue (in technical terminology, clicks have a lingual ingressive airstream mechanism). The forward closure is then released, producing what may be the loudest consonants in the language, but in some languages such as Hadza and Sandawe, clicks can be more subtle and may even be mistaken for ejectives.
What clicks sound like.
Click consonants occur at five principal places of articulation. IPA represents a click by placing the assigned symbol for the place of click articulation adjacent to a symbol for a non-click sound at the rear place of articulation. The IPA symbols are used in writing most Khoisan languages, but Bantu languages such as Zulu typically use Latin , and for dental, lateral, and alveolar clicks respectively.
The above clicks sound like affricates, in that they involve a lot of friction. The other two families are more abrupt sounds that do not have this friction.
Languages with clicks.
Clicks occur in all three Khoisan language families of southern Africa, where they may be the most numerous consonants. To a lesser extent they occur in three neighbouring groups of Bantu languages—which borrowed them, directly or indirectly, from Khoisan. In the southeast, in eastern South Africa, Swaziland, Lesotho, Zimbabwe, and southern Mozambique, they were adopted from a Tuu language or languages by the languages of the Nguni cluster (especially Zulu, Xhosa, and Phuthi, but also to a lesser extent Swazi and Ndebele), and spread from them in a reduced fashion to the Zulu-based pidgin Fanagalo, Sesotho, Tsonga, Ronga, the Mzimba dialect of Tumbuka, and more recently to Ndau and urban varieties of Pedi, where the spread of clicks continues. The second point of transfer was near the Caprivi Strip and the Okavango River where, apparently, the Yeyi language borrowed the clicks from a West Kalihari Khoe language; a separate development led to a smaller click inventory in the neighboring Mbukushu, Kwangali, Gciriku, Kuhane, and Fwe languages in Angola, Namibia, Botswana, and Zambia. These sounds occur not only in borrowed vocabulary, but have spread to native Bantu words as well, in the case of Nguni at least partially due to a type of word taboo called hlonipha. Some creolized varieties of Afrikaans, such as Oorlams, retain clicks in Khoekhoe words.
Three languages in East Africa use clicks: Sandawe and Hadza of Tanzania, and Dahalo, an endangered South Cushitic language of Kenya that has clicks in only a few dozen words. It is thought the latter may remain from an episode of language shift.
The only non-African language known to have clicks as regular speech sounds is Damin, a ritual code used by speakers of Lardil in Australia. One of the clicks in Damin is actually an egressive click, using the tongue to compress the air in the mouth for an outward (egressive) "spurt".
For the most part, the Southern African Khoisan languages only utilize root-initial clicks. Hadza, Sandawe, and several Bantu languages also allow syllable-initial clicks within roots, but in no language does a click close a syllable or end a word. Once clicks are borrowed into a language as regular speech sounds, they may spread to native words, as has happened due to "hlonipa" word-taboo in the Nguni languages. In Gciriku, for example, the European loanword "tomate" (tomato) appears as "cumáte" with a click "c", though it begins with a "t" in all neighboring languages.
Scattered clicks are found in ideophones in other languages, such as Kongo , Mijikenda , and Hadza (Hadza does not otherwise have labial clicks). Ideophones often utilize phonemic distinctions not found in normal vocabulary.
English and many other languages may use bare clicks in interjections, without the accompaniment of vowels, such as the dental "tsk-tsk" sound used to express disapproval, or the lateral "tchick" used with horses. In Ningdu Chinese (a variety of Hakka), flapped nasal clicks are used in nursery rhymes. In Bulgarian, Greek, Levantine Arabic, Maltese, Persian, Turkish, as well as southern Italian languages such as Sicilian, a bare dental click accompanied by tipping the head upwards signifies "no". Libyan Arabic apparently has three such sounds.
Clicks occasionally turn up elsewhere, as in the special registers twins sometimes develop with each other. In West Africa, clicks have been reported allophonically, and similarly in German, faint clicks have been recorded in rapid speech where the consonants and overlap between words.
Occasionally other languages are said to have click sounds. This is usually a misnomer for ejective consonants, which are found across much of the world.
The airstream.
The essence of a click is a lingual ingressive airstream mechanism. However, in nasal clicks the nasalization involves a separate nasal airstream, generally pulmonic egressive but occasionally pulmonic ingressive. Similarly, voiced clicks require a simultaneous pulmonic egressive airstream to make the voicing possible.
The front articulation may be coronal or, rarely, labial. In the languages in which it has been investigated, the articulations of the front and rear occlusions are interdependent, with the rear contact being uvular or pharyngeal depending on the shape of the front of the tongue.
The rear articulation had been thought to be velar, with a few languages contrasting a uvular place of articulation. However, recent investigations of languages with very complex click systems such as Nǁng have revealed that the supposed velar–uvular contrast is actually a contrast of a simple clicks versus click–plosive airstream contours (or consonant clusters, depending on analysis). Even in languages without such a distinction, such as Xhosa, experiments have shown that when the click release is removed from a recording, the resulting sound is judged to be uvular, not velar. In related Zulu, though nasal assimilation is velar, that only indicates that the onset of the rear articulation is velar; the release is still uvular. Therefore, although not all languages have been investigated on this point, phoneticians have recently come to use the term "lingual" (made with the tongue) as being more accurate for this airstream mechanism than "velaric" (made at the velum).
Types of clicks.
Like other consonants, clicks can be described using four parameters: place of articulation, manner of articulation, phonation (including glottalization), and airstream mechanism. As noted above, clicks necessarily involve at least two closures, which in some cases operate partially independently: an anterior articulation traditionally represented by the special click symbol in the IPA—and a posterior articulation traditionally described as oral or nasal, voiced or voiceless, etc. The literature also describes a contrast between velar and uvular rear articulations for some languages.
However, recent work shows that in languages that make this distinction, all clicks have a uvular, or even pharyngeal, rear closure—and the clicks explicitly described as uvular are in fact clusters/contours of a click plus a pulmonic or ejective component, in which the cluster/contour has two release bursts, the forward (click) and then the rearward (uvular) component. "Velar" clicks in these languages have only a single release burst, that of the forward click release, and the release of the rear articulation isn't separately audible (Miller 2011).
Nonetheless, in most of the literature the stated place of the click is the anterior articulation (called the "release" or "influx)," whereas the manner is ascribed to the posterior articulation (called the "accompaniment" or "efflux)." The anterior articulation defines the "click type" and is written with the IPA letter for the click (dental , alveolar , etc.), whereas the traditional term 'accompaniment' conflates the categories of manner (nasal, affricated), phonation (voiced, aspirated, breathy voiced, glottalized), as well as any change in the airstream with the release of the posterior articulation (pulmonic, ejective), all of which are transcribed with additional letters or diacritics, as in the "nasal alveolar click", or or—to take an extreme example—the "voiced (uvular) ejective alveolar click", .
The size of click inventories ranges from as few as three (in Sesotho) or four (in Dahalo), to dozens in the Kx'a and Tuu (Northern and Southern Khoisan) languages. Taa, the last vibrant language in the latter family, has 45 to 115 click phonemes, depending on analysis (clusters vs. contours), and over 70% of words in the dictionary of this language begin with a click.
Clicks appear more stop-like (sharp/abrupt) or affricate-like (noisy) depending on their place of articulation: In southern Africa, clicks involving an apical alveolar or laminal postalveolar closure are acoustically abrupt and sharp, like stops, whereas labial, dental, and lateral clicks typically have longer and acoustically noisier releases that are superficially more like affricates. In East Africa, however, the alveolar clicks tend to be flapped, whereas the lateral clicks tend to be more sharp.
Transcription.
The five click releases with dedicated symbols in the International Phonetic Alphabet (IPA) are labial , dental , palato-alveolar or "palatal" , (post)alveolar or "retroflex" , and lateral . In most languages, the retroflex and palatal releases are "abrupt"; that is, they are sharp popping sounds with little frication (turbulent airflow). The labial, dental, and lateral releases, on the other hand, are typically "noisy": they are longer, lip- or tooth-sucking sounds with turbulent airflow, and are sometimes called affricates. (This applies to the forward articulation; both may also have either an affricate or non-affricate rear articulation as well.) The apical releases, and , are sometimes called "grave", because their pitch is dominated by low frequencies; whereas the laminal releases, and , are sometimes called "acute", because they are dominated by high frequencies. (At least in the Nǁng language and Juǀʼhoan, this is associated with a difference in the placement of the rear articulation: "grave" clicks are uvular, whereas "acute" clicks are pharyngeal.) Thus the alveolar click sounds something like a cork pulled from a bottle (a low-pitch pop), at least in Xhosa; whereas the dental click is like English "tsk! tsk!," a high-pitched sucking on the incisors. The lateral clicks are pronounced by sucking on the molars of one or both sides. The labial click is different from what many people associate with a kiss: the lips are pressed more-or-less flat together, as they are for a or an , not rounded as they are for a .
The most populous languages with clicks, Zulu and Xhosa, use the letters "c, q, x," by themselves and in digraphs, to write click consonants. Most Khoisan languages, on the other hand (with the notable exceptions of Naro and Sandawe), use a more iconic system based on the pipe . (The exclamation point for the "retroflex" click was originally a pipe with a subscript dot, along the lines of "ṭ, ḍ, ṇ" used to transcribe the retroflex consonants of India.) There are also two main conventions for the second letter of the digraph as well: voicing may be written with "g" and uvular affrication with "x", or voicing with "d" and affrication with "g" (a convention of Afrikaans). In two orthographies of Juǀ’hoan, for example, is written "g!" or "dq", and "!x" or "qg". In languages without , such as Zulu, may be written "gq".
There are a few less-well-attested articulations. A reported subapical retroflex release in Grootfontein !Kung turns out to be alveolar with lateral release, ; Ekoka !Kung has a fricated alveolar click with an s-like release, provisionally transcribed ; and Hadza and Sandawe have a "slapped" alveolar click, provisionally transcribed (in turn, the lateral clicks in Hadza and Sandawe are more abrupt and less noisy than in southern Africa). However, the Khoisan languages are poorly attested, and it is quite possible that, as they become better described, more click releases will be found.
Formerly when a click consonant was transcribed, two symbols were used, one for each articulation, and connected with a tie bar. This is because a click such as was analyzed as a nasal velar rear articulation pronounced simultaneously with the forward ingressive release . The symbols may be written in either order, depending on the analysis: or . However, a tie bar was not often used in practice, and when the manner is tenuis (a simple ), it was often omitted as well. That is, = = = = . Regardless, elements that do not overlap with the release are always written according to their temporal order: Prenasalization is always written first ( = = ), and the non-lingual part of a contour is always written second ( = = ).
However, it has become standard to analyze clicks as simplex segments, as research has shown that the front and rear articulations are not independent, and to use click symbols to cover the rear articulation as well, with diacritics rather than digraphs for the accompaniments. At first this tended to be for , based on the belief that the rear articulation was velar; but as it has become clear that the rear articulation of both "velar" and "uvular" clicks is actually uvular or even pharyngeal, voicing and nasalization diacritics more in keeping with the IPA have started to appear: for .
In practical orthography, the voicing or nasalization is sometimes given the anterior place of articulation: "dc" for and "mʘ" for , for example.
Kirshenbaum transcription uses a very different convention: clicks are denoted by (always ) added to the letter for the stop homorganic to the release, but with the manner of the accompaniment. For example, is a voiceless dental click, and is a nasal bilabial click. This convention is used in the literature on Damin, where the clicks are transcribed as .
Places of articulation.
Places of articulation are often called click "types, releases," or "influxes." There are seven or eight known releases, not counting slapped or egressive clicks. These are "(bi)labial affricated" , or "(bi)labial"; "laminal denti-alveolar affricated" , or "dental"; "apical (post)alveolar plosive" , or "alveolar"; "laminal postalveolar (palato-alveolar) plosive" , or "palatal"; "laminal postalveolar (palato-alveolar) affricated" (known only from Ekoka !Kung); "subapical postalveolar (retroflex)" (only known from Central !Kung and Damin); and "apical postalveolar lateral" . 
Languages illustrating each of these articulations are listed below. Given the poor state of documentation of Khoisan languages, it is quite possible that additional releases will turn up. No language is known to contrast more than five places of articulation, though one publication has reconstructed Proto-Kx'a with six.
Extra-linguistically, Coatlán Zapotec of Mexico uses a linguolabial click, , as mimesis for a pig drinking water, and several languages, such as Wolof, use a velar click , long judged to be physically impossible, for backchanneling and to express approval. A sublingual click ("sucking-teeth") is found across West Africa, the Caribbean, and into the United States. 
Names found in the literature.
The terms for the click releases were originally developed by Bleek in 1911. Since then there has been some conflicting variation. Here are the terms used in some of the main references.
The dental, lateral, and bilabial clicks are rarely confused. However, the palatal and alveolar clicks frequently have the opposite names in older literature, and they were not distinguished in the IPA until 1989. However, since Ladefoged & Traill (1984) clarified the places of articulation, the terms in the left column above have become standard.
The back-vowel constraint.
In several languages, including Nama and Juǀ'hoan, the alveolar click types and only occur, or preferentially occur, before back vowels, whereas the dental and palatal clicks occur before any vowel. The effect is most noticeable with the high front vowel . In Nama, for example, the diphthong is common but is rare after alveolar clicks, whereas the opposite is true after dental and palatal clicks. This is a common effect of uvular or uvularized consonants on vowels in both click and non-click languages. In Taa, for example, the back-vowel constraint is triggered by both alveolar clicks and uvular stops, but not by palatal clicks or velar stops: sequences such as and are rare to non-existent, whereas sequences such as and are common. It is also triggered by labial clicks, though not by labial stops. Clicks subject to this constraint involve a sharp retraction of the tongue during release.
Miller and colleagues (2003) used ultrasound imaging to show that the rear articulation of the alveolar clicks () in Nama is substantially different from that of palatal and dental clicks. Specifically, the shape of the body of the tongue in palatal clicks is very similar to that of the vowel , and involves the same tongue muscles, so that sequences such as involved a simple and quick transition. The rear articulation of the alveolar clicks, however, is several centimeters further back, and involves a different set of muscles in the uvular region. The part of the tongue required to approach the palate for the vowel is deeply retracted in , as it lies at the bottom of the air pocket used to create the vacuum required for click airstream. This makes the transition required for much more complex and the timing more difficult than the shallower and more forward tongue position of the palatal clicks. Consequently, takes 50 ms longer to pronounce than , the same amount of time required to pronounce .
Languages do not all behave alike. In Nǀuu, the simple clicks trigger the and allophones of and , whereas do not. All of the affricated contour clicks, such as , do as well, as do the uvular stops . However, the occlusive contour clicks pattern like the simple clicks, and does not trigger the back-vowel constraint. This is because they involve tongue-root raising rather than tongue-root retraction in the uvular-pharyngeal region. However, in Gǀwi, which is otherwise largely similar, both and trigger the back-vowel constraint (Miller 2009).
Manners of articulation.
Click manners are often called click "accompaniments" or "effluxes", but both terms have met with objections on theoretical grounds.
There is a great variety of click manners, both simplex and complex, the latter variously analysed as consonant clusters or contours. With so few click languages, and so little study of them, it is also unclear to what extent clicks in different languages are equivalent. For example, the of Khoekhoe, of Sandawe, and of Hadza may be essentially the same phone; no language distinguishes them, and the differences in transcription may have more to do with the approach of the linguist than with actual differences in the sounds. Such suspected allophones/allographs are listed on a common row in the table below.
Some Khoisan languages are typologically unusual in allowing mixed voicing in non-click consonant clusters/contours, such as , so it is not surprising that they would allow mixed voicing in clicks as well. This may be an effect of epiglottalized voiced consonants, because voicing is incompatible with epiglottalization.
Phonation.
As do other consonants, clicks vary in phonation. Oral clicks are attested with four phonations: tenuis, aspirated, voiced, and breathy voiced (murmured). Nasal clicks may also vary, with plain voiced, breathy voiced / murmured nasal, aspirated, and unaspirated voiceless clicks attested (the last only in Taa). The aspirated nasal clicks are often said to have 'delayed aspiration'; there is nasal airflow throughout the click, which may become voiced between vowels, though the aspiration itself is voiceless. A few languages also have pre-glottalized nasal clicks, which have very brief prenasalization but have not been phonetically analyzed to the extent that other types of clicks have.
All languages have nasal clicks, and all but Dahalo and Damin also have oral clicks. All languages but Damin have at least one phonation contrast as well.
Complex clicks.
Clicks may be pronounced with a third place of articulation, glottal. A glottal stop is made during the hold of the click; the (necessarily voiceless) click is released, and then the glottal hold is released into the vowel. Glottalized clicks are very common, and they are generally nasalized as well. The nasalization cannot be heard during the click release, as there is no pulmonic airflow, and generally not at all when the click occurs at the beginning of an utterance, but it has the effect of nasalizing preceding vowels, to the extent that the glottalized clicks of Sandawe and Hadza are often described as prenasalized when in medial position. Two languages, Gǀwi and Yeyi, contrast plain and nasal glottalized clicks, but in languages without such a contrast, the glottalized click is nasal. Miller (2011) analyses the glottalization as phonation, and so considers these to be simple clicks.
Various languages also have prenasalized clicks, which may be analyzed as consonant sequences. Sotho, for example, allows a syllabic nasal before its three clicks, as in "nnqane" 'the other side' (prenasalized nasal) and "seqhenqha" 'hunk'.
There is ongoing discussion as to how the distinction between what were historically described as 'velar' and 'uvular' clicks is best described. The 'uvular' clicks are only found in some languages, and have an extended pronunciation that suggests that they are more complex than the simple ('velar') clicks, which are found in all. Nakagawa (1996) describes the extended clicks in Gǀwi as consonant clusters, sequences equivalent to English "st" or "pl", whereas Miller (2011) analyses similar sounds in several languages as click–non-click contours, where a click transitions into a pulmonic or ejective articulation within a single segment, analogous to how English "ch" and "j" transition from occlusive to fricative but still behave as unitary sounds. With ejective clicks, for example, Miller finds that although the ejective release follows the click release, it is the rear closure of the click that is ejective, not an independently articulated consonant. That is, in a simple click, the release of the rear articulation is not audible, whereas in a contour click, the rear (uvular) articulation is audibly released after the front (click) articulation, resulting in a double release.
These contour clicks may be "linguo-pulmonic", that is, they may transition from a click (lingual) articulation to a normal pulmonic consonant like (e.g. ); or "linguo-glottalic" and transition from lingual to an ejective consonant like (e.g. ): that is, a sequence of ingressive (lingual) release + egressive (pulmonic or glottalic) release. In some cases there is a shift in place of articulation as well, and instead of a uvular release, the uvular click transitions to a velar or epigottal release (depending on the description, or ). Although homorganic does not contrast with heterorganic in any known language, they are phonetically quite distinct (Miller 2011).
Apart from Dahalo, Damin, and many of the Bantu languages (Yeyi and Xhosa being exceptions), 'click' languages have glottalized clicks. Contour clicks are restricted to southern Africa, but are very common there: they are found in all members of the Tuu, Kx'a, and Khoe families, as well as in the Bantu language Yeyi.
Variation among languages.
In a comparative study of clicks across various languages, using her own field work as well as phonetic descriptions and data by other field researchers, Miller (2011) posits 21 types of clicks that contrast in manner or airstream. The homorganic and heterorganic affricated ejective clicks do not contrast in any known language, but are judged dissimilar enough to keep separate. Miller's conclusions differ from those of the primary researcher of a language; see the individual languages for details.
Each language below is illustrated with alveolar clicks, apart from Dahalo, which only has dental. Under each language are the orthography (in italics, with old forms in parentheses), the researchers' transcription (in ), or allophonic variation (in ). Some languages also have labialized or prenasalized clicks.
Yeyi also has prenasalized . The original researchers believe that and are allophones.
A DoBeS (2008) study of the Western !Xoo dialect of Taa found several new manners: creaky voiced (the voiced equivalent of glottalized oral), breathy-voiced nasal, prenasalized ɡlottalized (the voiced equivalent of glottalized), and a (pre)voiced ejective. These extra voiced clicks reflect Western !Xoo morphology, where many nouns form their plural by voicing their initial consonant. DoBeS analyses most Taa clicks as clusters, leaving nine basic manners (marked with asterisks in the table). This comes close to Miller's distinction between simple and contour clicks, shaded light and medium grey in the table.
Click genesis and click loss.
Clicks are often portrayed as a primordial feature of human language, a romantic reflection of the primordial lifestyle imagined of the speakers of Khoisan languages. One genetic study concluded that clicks, which occur in the languages of the genetically divergent populations Hadza and !Kung, may be an ancient element of human language. However, this conclusion relies on several dubious assumptions (see Hadza language), and most linguists assume that clicks, being quite complex consonants, arose relatively late in human history. How they arose is not known, but it is generally assumed that they developed from sequences of non-click consonants, as they are found allophonically for doubly articulated consonants in West Africa (Ladefoged 1968), where sequences overlap at word boundaries in German (Fuchs 2007), and for the sequence in Ndau and Tonga. Such developments have also been posited in historical reconstruction. For example, the Sandawe word for 'horn', , with a lateral affricate, may be a cognate with the root found throughout the Khoe family, which has a lateral click. This and other words suggests that at least some Khoe clicks may have formed from consonant clusters when the first vowel of a word was lost; in this instance * > * > .
On the other side of the equation, several non-endangered languages in vigorous use demonstrate click loss. For example, the East Kalahari languages have lost clicks from a large percentage of their vocabulary, presumably due to Bantu influence. As a rule, a click is replaced by a consonant with close to the manner of articulation of the click and the place of articulation of the forward release: alveolar click releases (the family) tend to mutate into a velar stop or affricate, such as ; palatal clicks ( "etc.") tend to mutate into a palatal stop such as , or a post-alveolar affricate ; and dental clicks ( "etc.") tend to mutate into an alveolar affricate .
Difficulty.
Clicks are often presented as difficult sounds to articulate within words. However, children acquire them readily; a two-year-old, for example, may be able to pronounce a word with a lateral click with no problem, but still be unable to pronounce . Lucy Lloyd reported that after long contact with the Khoi and San, it was difficult for her to refrain from using clicks when speaking English.

</doc>
<doc id="7817" url="https://en.wikipedia.org/wiki?curid=7817" title="The Cider House Rules">
The Cider House Rules

The Cider House Rules is a 1985 novel by John Irving. It is Irving's sixth published novel, and has been adapted into a film of the same name and a stage play by Peter Parnell.
Plot.
Homer Wells grows up in an orphanage where he spends his childhood "being of use" as a medical assistant to the director, Dr. Wilbur Larch, whose history is told in flashbacks: After a traumatic misadventure with a prostitute as a young man, Wilbur turns his back on sex and love, choosing instead to help women with unwanted pregnancies give birth and then keeping the babies in an orphanage. He makes a point of maintaining an emotional distance from the orphans, so that they can more easily make the transition into an adoptive family, but when it becomes clear that Homer is going to spend his entire childhood at the orphanage, Wilbur trains the orphan as an obstetrician and then comes to love him like a son.
Wilbur's and Homer's lives are complicated by Wilbur also secretly being an abortionist. Wilbur came to this work reluctantly, but he is driven by having seen the horrors of back-alley operations. Homer, upon learning Wilbur's secret, considers it morally wrong.
As a young man, Homer befriends a young couple, Candy Kendall and Wally Worthington, who come to St. Cloud's for an abortion. Homer leaves the orphanage, and returns with them to Ocean View Orchards (Wally's family's orchard) in Heart's Rock, near the Maine coast. Wally and Homer become best friends and Homer develops a secret love for Candy. Wally goes off to serve in the Second World War and his plane is shot down over Burma. He is presumed missing by the military, but Homer and Candy both believe he is dead and move on with their lives, which includes beginning a romantic relationship. When Candy becomes pregnant, they go back to St. Cloud's Orphanage, where their son is born and named Angel.
Subsequently, Wally is found in Burma and returns home, paralyzed from the waist down. He is still able to have sexual intercourse but is sterile due to an infection received in Burma. They lie to the family about Angel's parentage, claiming that Homer decided to adopt him. Wally and Candy marry shortly afterward, but Candy and Homer maintain a secret affair that lasts some 15 years.
Many years later, teenaged Angel falls in love with Rose. Rose, the daughter of the head migrant worker at the apple orchard, becomes pregnant by her father, and Homer performs an abortion on her. Homer decides to return to the orphanage after the death of Wilbur, to work as the new director. Though he maintains his distaste for abortions, he continues Dr. Larch's legacy of honoring the choice of his patients, and he dreams of the day when abortions are free, legal, and safe, so he'll no longer feel obliged to offer them.
A subplot follows the character Melony, who grew up alongside Homer in the orphanage. She was Homer's first girlfriend in a relationship of circumstances. After Homer leaves the orphanage, so does she in an effort to find him. She eventually becomes an electrician and takes a female lover, Lorna. Melony is an extremely stoic woman, who refuses to press charges against a man who brutally broke her nose and arm so that she can later take revenge herself. She is the catalyst that transforms Homer from his comfortable but not entirely admirable position at the apple orchard to becoming Dr. Larch's replacement at the orphanage.
Background.
The story about Wally being shot down over Burma was based in part on that of Irving's biological father (whom he never met), who had been shot down over Burma and survived.

</doc>
<doc id="7818" url="https://en.wikipedia.org/wiki?curid=7818" title="Consumer">
Consumer

A consumer is a person or organization that uses economic services or commodities.
In economic systems "consumers" are utilities expressed in the decision to trade or not.
Economics and marketing.
The "consumer" is the one who pays to consume goods and services produced. As such, "consumers" play a vital role in the economic system of a nation. Without consumer demand, producers would lack one of the key motivations to produce: to sell to consumers. The "consumer" also forms part of the chain of distribution.
Recently in marketing instead of marketers generating broad demographic profiles and Fisio-graphic profiles of market segments, marketers have started to engage in personalized marketing, permission marketing, and mass customization.
Law and politics.
The law primarily uses the notion of the consumer in relation to consumer protection laws, and the definition of consumer is often restricted to living persons (i.e. not corporations or businesses) and excludes commercial users. A typical legal rationale for protecting the consumer is based on the notion of policing market failures and inefficiencies, such as inequalities of bargaining power between a consumer and a business. As of all potential voters are also consumers, consumer protection takes on a clear political significance.
Concern over the interests of consumers has also spawned activism, as well as incorporation of consumer education into school curricula. There are also various non-profit publications, such as "Which?", "Consumer Reports" and "Choice Magazine", dedicated to assist in consumer education and decision making.
In India, the Consumer Protection Act 1986 differentiates the consummation of a commodity or service for personal use or to earn a livelihood. Only consumers are protected per this act and any person, entity or organization purchasing a commodity for commercial reasons are exempted from any benefits of this act.
Public reaction.
While use of the term "consumer" is widespread among governmental, business and media organisations, many individuals and groups find the label objectionable because it assigns a limited and passive role to their activities.

</doc>
<doc id="7819" url="https://en.wikipedia.org/wiki?curid=7819" title="Cactus">
Cactus

A cactus (plural: "cacti", "cactuses", or "cactus") is a member of the plant family Cactaceae within the order Caryophyllales. The word "cactus" derives, through Latin, from the Ancient Greek , "kaktos", a name originally used by Theophrastus for a spiny plant whose identity is not certain. Cacti occur in a wide range of shapes and sizes. Most cacti live in habitats subject to at least some drought. Many live in extremely dry environments, even being found in the Atacama Desert, one of the driest places on earth. Cacti show many adaptations to conserve water. Almost all cacti are succulents, meaning they have thickened, fleshy parts adapted to store water. Unlike many other succulents, the stem is the only part of most cacti where this vital process takes place. Most species of cacti have lost true leaves, retaining only spines, which are highly modified leaves. As well as defending against herbivores, spines help prevent water loss by reducing air flow close to the cactus and providing some shade. In the absence of leaves, enlarged stems carry out photosynthesis. Cacti are native to the Americas, ranging from Patagonia in the south to parts of western Canada in the north—except for "Rhipsalis baccifera", which also grows in Africa and Sri Lanka.
Cactus spines are produced from specialized structures called areoles, a kind of highly reduced branch. Areoles are an identifying feature of cacti. As well as spines, areoles give rise to flowers, which are usually tubular and multipetaled. Many cacti have short growing seasons and long dormancies, and are able to react quickly to any rainfall, helped by an extensive but relatively shallow root system that quickly absorb any water reaching the ground surface. Cactus stems are often ribbed or fluted, which allows them to expand and contract easily for quick water absorption after rain, followed by long drought periods. Like other succulent plants, most cacti employ a special mechanism called "crassulacean acid metabolism" (CAM) as part of photosynthesis. Transpiration, during which carbon dioxide enters the plant and water escapes, does not take place during the day at the same time as photosynthesis, but instead occurs at night. The plant stores the carbon dioxide it takes in as malic acid, retaining it until daylight returns, and only then using it in photosynthesis. Because transpiration takes place during the cooler, more humid night hours, water loss is significantly reduced.
Many smaller cacti have globe-shaped stems, combining the highest possible volume for water storage, with the lowest possible surface area for water loss from transpiration. The tallest free-standing cactus is "Pachycereus pringlei", with a maximum recorded height of , and the smallest is "Blossfeldia liliputiana", only about in diameter at maturity. A fully grown saguaro ("Carnegiea gigantea") is said to be able to absorb as much as of water during a rainstorm. A few species differ significantly in appearance from most of the family. At least superficially, plants of the genus "Pereskia" resemble other trees and shrubs growing around them. They have persistent leaves, and when older, bark-covered stems. Their areoles identify them as cacti, and in spite of their appearance, they, too, have many adaptations for water conservation. "Pereskia" is considered close to the ancestral species from which all cacti evolved. In tropical regions, other cacti grow as forest climbers and epiphytes (plants that grow on trees). Their stems are typically flattened, almost leaf-like in appearance, with fewer or even no spines, such as the well-known Christmas cactus or Thanksgiving cactus (in the genus "Schlumbergera").
Cacti have a variety of uses: many species are used as ornamental plants, others are grown for fodder or forage, and others for food (particularly their fruit). Cochineal is the product of an insect that lives on some cacti.
Morphology.
The 1,500 to 1,800 species of cacti mostly fall into one of two groups of "core cacti": opuntias (subfamily Opuntioideae) and "cactoids" (subfamily Cactoideae). Most members of these two groups are easily recognizable as cacti. They have fleshy succulent stems that are major organs of photosynthesis. They have absent, small, or transient leaves. They have flowers with ovaries that lie below the sepals and petals, often deeply sunken into a fleshy receptacle (the part of the stem from which the flower parts grow). All cacti have areoles—highly specialized short shoots with extremely short internodes that produce spines, normal shoots, and flowers.
The remaining cacti fall into only two genera, "Pereskia" and "Maihuenia", and are rather different, which means any description of cacti as a whole must frequently make exceptions for them. "Pereskia" species superficially resemble other tropical forest trees. When mature, they have woody stems that may be covered with bark and long-lasting leaves that provide the main means of photosynthesis. Their flowers may have superior ovaries (i.e., above the points of attachment of the sepals and petals), and areoles that produce further leaves. The two species of "Maihuenia" have small, globe-shaped bodies with prominent leaves at the top.
Growth habit.
Cacti show a wide variety of growth habits, which are difficult to divide into clear, simple categories. They can be tree-like (arborescent), meaning they typically have a single more-or-less woody trunk topped by several to many branches. In the genus "Pereskia", the branches are covered with leaves, so the species of this genus may not be recognized as cacti. In most other cacti, the branches are more typically cactus-like, bare of leaves and bark, and covered with spines, as in "Pachycereus pringlei" or the larger opuntias. Some cacti may become tree-sized but without branches, such as larger specimens of "Echinocactus platyacanthus". Cacti may also be described as shrubby, with several stems coming from the ground or from branches very low down, such as in "Stenocereus thurberi".
Smaller cacti may be described as columnar. They consist of erect, cylinder-shaped stems, which may or may not branch, without a very clear division into trunk and branches. The boundary between columnar forms and tree-like or shrubby forms is difficult to define. Smaller and younger specimens of "Cephalocereus senilis", for example, are columnar, whereas older and larger specimens may become tree-like. In some cases, the "columns" may be horizontal rather than vertical. Thus, "Stenocereus eruca" has stems growing along the ground, rooting at intervals.
Cacti whose stems are even smaller may be described as globular (or globose). They consist of shorter, more ball-shaped stems than columnar cacti. Globular cacti may be solitary, such as "Ferocactus latispinus", or their stems may form clusters that can create large mounds. All or some stems in a cluster may share a common root.
Other cacti have a quite different appearance. In tropical regions, some grow as forest climbers and epiphytes. Their stems are typically flattened, almost leaf-like in appearance, with fewer or even no spines. Climbing cacti can be very large; a specimen of "Hylocereus" was reported as long from root to the most distant stem. Epiphytic cacti, such as species of "Rhipsalis" or "Schlumbergera", often hang downwards, forming dense clumps where they grow in trees high above the ground.
Stems.
The leafless, spiny stem is the characteristic feature of the majority of cacti (and all of those belonging to the largest subfamily, the Cactoideae). The stem is typically succulent, meaning it is adapted to store water. The surface of the stem may be smooth (as in some species of "Opuntia") or covered with protuberances of various kinds, which are usually called tubercles. These vary from small "bumps" to prominent, nipple-like shapes in the genus "Mammillaria" and outgrowths almost like leaves in "Ariocarpus" species. The stem may also be ribbed or fluted in shape. The prominence of these ribs depends on how much water the stem is storing: when full (up to 90% of the mass of a cactus may be water), the ribs may be almost invisible on the swollen stem, whereas when the cactus is short of water and the stems shrink, the ribs may be very visible.
The stems of most cacti are some shade of green, often bluish or brownish green. Such stems contain chlorophyll and are able to carry out photosynthesis; they also have stomata (small structures that can open and close to allow passage of gases). Cactus stems are often visibly waxy.
Areoles.
Areoles are structures unique to cacti. Although variable, they typically appear as woolly or hairy areas on the stems from which spines emerge. Flowers are also produced from areoles. In the genus "Pereskia", believed similar to the ancestor of all cacti, the areoles occur in the axils of leaves (i.e. in the angle between the leaf stalk and the stem). In leafless cacti, areoles are often borne on raised areas on the stem where leaf bases would have been.
Areoles are highly specialized and very condensed shoots or branches. In a normal shoot, nodes bearing leaves or flowers would be separated by lengths of stem (internodes). In an areole, the nodes are so close together, they form a single structure. The areole may be circular, elongated into an oval shape, or even separated into two parts; the two parts may be visibly connected in some way (e.g. by a groove in the stem) or appear entirely separate (a dimorphic areole). The part nearer the top of the stem then produces flowers, the other part spines. Areoles often have multicellular hairs (trichomes) that give the areole a hairy or woolly appearance, sometimes of a distinct color such as yellow or brown.
In most cacti, the areoles produce new spines or flowers only for a few years, and then become inactive. This results in a relatively fixed number of spines, with flowers being produced only from the ends of stems, which are still growing and forming new areoles. In "Pereskia", a genus close to the ancestor of cacti, areoles remain active for much longer; this is also the case in "Opuntia" and "Neoraimondia".
Leaves.
The great majority of cacti have no visible leaves; photosynthesis takes place in the stems (which may be flattened and leaflike in some species). Exceptions occur in three groups of cacti. All the species of "Pereskia" are superficially like normal trees or shrubs and have numerous leaves. Many cacti in the opuntia group (subfamily Opuntioideae, opuntioids) also have visible leaves, which may be long-lasting (as in "Pereskiopsis" species) or be produced only during the growing season and then be lost (as in many species of "Opuntia"). The small genus "Maihuenia" also relies on leaves for photosynthesis. The structure of the leaves varies somewhat between these groups. "Pereskia" species have "normal" leaves, with a midrib and a flattened blade (lamina) on either side. Opuntioids and "Maihuenia" have leaves that appear to consist only of a midrib.
Even those cacti without visible photosynthetic leaves do usually have very small leaves, less than long in about half of the species studied and almost always less than long. The function of such leaves cannot be photosynthesis; a role in the production of plant hormones, such as auxin, and in defining axillary buds has been suggested.
Spines.
Botanically, "spines" are distinguished from "thorns": spines are modified leaves, and thorns are modified branches. Cacti produce spines, always from areoles as noted above. Spines are present even in those cacti with leaves, such as "Pereskia", "Pereskiopsis" and "Maihuenia", so they clearly evolved before complete leaflessness. Some cacti only have spines when young, possibly only when seedlings. This is particularly true of tree-living cacti, such as "Rhipsalis" or "Schlumbergera", but some ground-living cacti, such as "Ariocarpus", also lack spines when mature.
The spines of cacti are often useful in identification, since they vary greatly between species in number, color, size, shape and hardness, as well as in whether all the spines produced by an areole are similar or whether they are of distinct kinds. Most spines are straight or at most slightly curved, and are described as hair-like, bristle-like, needle-like or awl-like, depending on their length and thickness. Some cacti have flattened spines (e.g. "Schlerocactus papyracanthus"). Other cacti have hooked spines. Sometimes, one or more central spines are hooked, while outer spines are straight (e.g., "Mammillaria rekoi").
In addition to normal-length spines, members of the subfamily Opuntioideae have relatively short spines, called glochids that are barbed along their length and easily shed. These enter the skin and are difficult to remove, causing long-lasting irritation.
Roots.
Most ground-living cacti have only fine roots, which spread out around the base of the plant for varying distances, close to the surface. Some cacti have taproots; in genera such as "Copiapoa", these are considerably larger and of a greater volume than the body. Taproots may aid in stabilizing the larger columnar cacti. Climbing, creeping and epiphytic cacti may have only adventitious roots, produced along the stems where these come into contact with a rooting medium.
Flowers.
Like their spines, cactus flowers are variable. Typically, the ovary is surrounded by material derived from stem or receptacle tissue, forming a structure called a pericarpel. Tissue derived from the petals and sepals continues the pericarpel, forming a composite tube—the whole may be called a floral tube, although strictly speaking only the part furthest from the base is floral in origin. The outside of the tubular structure often has areoles that produce wool and spines. Typically, the tube also has small scale-like bracts, which gradually change into sepal-like and then petal-like structures, so the sepals and petals cannot be clearly differentiated (and hence are often called "tepals"). Some cacti produce floral tubes without wool or spines (e.g. "Gymnocalycium") or completely devoid of any external structures (e.g. "Mammillaria"). Unlike the flowers of other cacti, "Pereskia" flowers may be borne in clusters.
Cactus flowers usually have many stamens, but only a single style, which may branch at the end into more than one stigma. The stamens usually arise from all over the inner surface of the upper part of the floral tube, although in some cacti, the stamens are produced in one or more distinct "series" in more specific areas of the inside of the floral tube.
The flower as a whole is usually radially symmetrical (actinomorphic), but may be bilaterally symmetrical (zygomorphic) in some species. Flower colors range from white through yellow and red to magenta.
Adaptations for water conservation.
All cacti have some adaptations to promote efficient water use. Most cacti—opuntias and cactoids—specialize in surviving in hot and dry environments (i.e. they are xerophytes), but the first ancestors of modern cacti were already adapted to periods of intermittent drought. A small number of cactus species in the tribes Hylocereeae and Rhipsalideae have become adapted to life as climbers or epiphytes, often in tropical forests, where water conservation is less important.
Leaves and spines.
The absence of visible leaves is one of the most striking features of most cacti. "Pereskia" (which is close to the ancestral species from which all cacti evolved) does have long-lasting leaves, which are, however, thickened and succulent in many species. Other species of cactus with long-lasting leaves, such as the opuntioid "Pereskiopsis", also have succulent leaves. A key issue in retaining water is the ratio of surface area to volume. Water loss is proportional to surface area, whereas the amount of water present is proportional to volume. Structures with a high surface area-to-volume ratio, such as thin leaves, necessarily lose water at a higher rate than structures with a low area-to-volume ratio, such as thickened stems.
Spines, which are modified leaves, are present on even those cacti with true leaves, showing the evolution of spines preceded the loss of leaves. Although spines have a high surface area-to-volume ratio, at maturity they contain little or no water, being composed of fibers made up of dead cells. Spines provide protection from herbivores and camouflage in some species, and assist in water conservation in several ways. They trap air near the surface of the cactus, creating a moister layer that reduces evaporation and transpiration. They can provide some shade, which lowers the temperature of the surface of the cactus, also reducing water loss. When sufficiently moist air is present, such as during fog or early morning mist, spines can condense moisture, which then drips onto the ground and is absorbed by the roots.
Stems.
The majority of cacti are stem succulents, i.e., plants in which the stem is the main organ used to store water. Water may form up to 90% of the total mass of a cactus. Stem shapes vary considerably among cacti. The cylindrical shape of columnar cacti and the spherical shape of globular cacti produce a low surface area-to-volume ratio, thus reducing water loss, as well as minimizing the heating effects of sunlight. The ribbed or fluted stems of many cacti allow the stem to shrink during periods of drought and then swell as it fills with water during periods of availability. A mature saguaro ("Carnegiea gigantea") is said to be able to absorb as much as of water during a rainstorm. The outer layer of the stem usually has a tough cuticle, reinforced with waxy layers, which reduce water loss. These layers are responsible for the grayish or bluish tinge to the stem color of many cacti.
The stems of most cacti have adaptations to allow them to conduct photosynthesis in the absence of leaves. This is discussed further below under Metabolism.
Roots.
Many cacti have roots that spread out widely, but only penetrate a short distance into the soil. In one case, a young saguaro only tall had a root system with a diameter of , but no more than deep. Cacti can also form new roots quickly when rain falls after a drought. The concentration of salts in the root cells of cacti is relatively high. All these adaptations enable cacti to absorb water rapidly during periods of brief or light rainfall. Thus, "Ferocactus cylindraceus" reportedly can take up a significant amount of water within 12 hours of as little as of rainfall, becoming fully hydrated in a few days.
Although in most cacti, the stem acts as the main organ for storing water, some cacti have in addition large taproots. These may be several times the length of the above-ground body in the case of species such as "Copiapoa atacamensis", which grows in one of the driest places in the world, the Atacama Desert in northern Chile.
Metabolism.
Photosynthesis requires plants to take in carbon dioxide gas (). As they do so, they lose water through transpiration. Like other types of succulents, cacti reduce this water loss by the way in which they carry out photosynthesis. "Normal" leafy plants use the C3 mechanism: during daylight hours, is continually drawn out of the air present in spaces inside leaves and converted first into a compound containing three carbon atoms (3-phosphoglycerate) and then into products such as carbohydrates. The access of air to internal spaces within a plant is controlled by stomata, which are able to open and close. The need for a continuous supply of during photosynthesis means the stomata must be open, so water vapor is continuously being lost. Plants using the C3 mechanism lose as much as 97% of the water taken up through their roots in this way. A further problem is that as temperatures rise, the enzyme that captures starts to capture more and more oxygen instead, reducing the efficiency of photosynthesis by up to 25%.
Crassulacean acid metabolism (CAM) is a mechanism adopted by cacti and other succulents to avoid the problems of the C3 mechanism. In full CAM, the stomata open only at night, when temperatures and water loss are lowest. enters the plant and is captured in the form of organic acids stored inside cells (in vacuoles). The stomata remain closed throughout the day, and photosynthesis uses only this stored . CAM uses water much more efficiently at the price of limiting the amount of carbon fixed from the atmosphere and thus available for growth. CAM-cycling is a less efficient system whereby stomata open in the day, just as in plants using the C3 mechanism. At night, or when the plant is short of water, the stomata close and the CAM mechanism is used to store produced by respiration for use later in photosynthesis. CAM-cycling is present in "Pereskia" species.
By studying the ratio of 14C to 13C incorporated into a plant—its isotopic signature—it is possible to deduce how much is taken up at night and how much in the daytime. Using this approach, most of the "Pereskia" species investigated exhibit some degree of CAM-cycling, suggesting this ability was present in the ancestor of all cacti. "Pereskia" leaves are claimed to only have the C3 mechanism with CAM restricted to stems. More recent studies show that "it is highly unlikely that significant carbon assimilation occurs in the stem"; "Pereskia" species are described as having "C3 with inducible CAM." Leafless cacti carry out all their photosynthesis in the stem, using full CAM. , it is not clear whether stem-based CAM evolved once only in the core cacti, or separately in the opuntias and cactoids; CAM is known to have evolved convergently many times.
To carry out photosynthesis, cactus stems have undergone many adaptations. Early in their evolutionary history, the ancestors of modern cacti (other than one group of "Pereskia" species) developed stomata on their stems and began to delay developing bark. However, this alone was not sufficient; cacti with only these adaptations appear to do very little photosynthesis in their stems. Stems needed to develop structures similar to those normally found only in leaves. Immediately below the outer epidermis, a hypodermal layer developed made up of cells with thickened walls, offering mechanical support. Air spaces were needed between the cells to allow carbon dioxide to diffuse inwards. The center of the stem, the cortex, developed "chlorenchyma" – a plant tissue made up of relatively unspecialized cells containing chloroplasts, arranged into a "spongy layer" and a "palisade layer" where most of the photosynthesis occurs.
Taxonomy and classification.
Naming and classifying cacti has been both difficult and controversial since the first cacti were discovered for science. The difficulties began with Carl Linnaeus. In 1737, he placed the cacti he knew into two genera, "Cactus" and "Pereskia". However, when he published "Species Plantarum" in 1753—the starting point for modern botanical nomenclature—he relegated them all to one genus, "Cactus". The word "cactus" is derived through Latin from the Ancient Greek ("kaktos"), a name used by Theophrastus for a spiny plant, which may have been the cardoon ("Cynara cardunculus").
Later botanists, such as Philip Miller in 1754, divided cacti into several genera, which, in 1789, Antoine Laurent de Jussieu placed in his newly created family Cactaceae. By the early 20th century, botanists came to feel Linnaeus's name "Cactus" had become so confused as to its meaning (was it the genus or the family?) that it should not be used as a genus name. The 1905 Vienna botanical congress rejected the name "Cactus" and instead declared "Mammillaria" was the type genus of the family Cactaceae. It did, however, conserve the name Cactaceae, leading to the unusual situation in which the family Cactaceae no longer contains the genus after which it was named.
The difficulties continued, partly because giving plants scientific names relies on "type specimens". Ultimately, if botanists want to know whether a particular plant is an example of, say, "Mammillaria mammillaris", they should be able to compare it with the type specimen to which this name is permanently attached. Type specimens are normally prepared by compression and drying, after which they are stored in herbaria to act as definitive references. However, cacti are very difficult to preserve in this way; they have evolved to resist drying and their bodies do not easily compress. A further difficulty is that many cacti were given names by growers and horticulturalists rather than botanists; as a result, the provisions of the "International Code of Nomenclature for algae, fungi, and plants" (which governs the names of cacti, as well as other plants) were often ignored. Curt Backeberg, in particular, is said to have named or renamed 1,200 species without one of his names ever being attached to a specimen, which, according to David Hunt, ensured he "left a trail of nomenclatural chaos that will probably vex cactus taxonomists for centuries."
Classification.
In 1984, it was decided that the Cactaceae Section of the International Organization for Succulent Plant Study should set up a working party, now called the International Cactaceae Systematics Group (ICSG), to produce consensus classifications down to the level of genera. Their system has been used as the basis of subsequent classifications. Detailed treatments published in the 21st century have divided the family into around 125–130 genera and 1,400–1,500 species, which are then arranged into a number of tribes and subfamilies. The ICSG classification of the cactus family recognizes four subfamilies, the largest of which is divided into nine tribes. The subfamilies are:
Molecular phylogenetic studies have supported the monophyly of three of these subfamilies (not Pereskioideae), but have not supported all of the tribes or even genera below this level; indeed, a 2011 study found only 39% of the genera in the subfamily Cactoideae sampled in the research were monophyletic. Classification of the cacti currently remains uncertain and is likely to change.
Phylogeny and evolution.
Phylogeny.
A 2005 study suggested the genus "Pereskia" was basal within the Cactaceae, but confirmed earlier suggestions it was not monophyletic, i.e., did not include all the descendants of a common ancestor. The Bayesian consensus cladogram from this study is shown below.
A more recent 2011 study using fewer genes but more species also found that "Pereskia" was divided into these two clades, but was unable to resolve the members of the "core cacti" clade. It was accepted that the relationships shown above are "the most robust to date."
The two clades of "Pereskia" differ in their geographical distribution; with one exception, clade A is found around the Gulf of Mexico and the Caribbean Sea, whereas clade B occurs south of the Amazon Basin. Species of "Pereskia" within clade A always lack two key features of the stem present in most of the remaining "caulocacti": like most non-cacti, their stems begin to form bark early in the plants' life and also lack stomata—structures that control admission of air into a plant and hence control photosynthesis. By contrast, caulocacti, including species of "Pereskia" clade B, typically delay forming bark and have stomata on their stems, thus giving the stem the potential to become a major organ for photosynthesis. (The two highly specialized species of "Maihuenia" are something of an exception.)
The first cacti are thought to have been only slightly succulent shrubs or small trees whose leaves carried out photosynthesis. They lived in tropical areas that experienced periodic drought. If "Pereskia" clade A is a good model of these early cacti, then, although they would have appeared superficially similar to other trees growing nearby, they had already evolved strategies to conserve water (some of which are present in members of other families in the order Caryophyllales). These strategies included being able to respond rapidly to periods of rain, and keeping transpiration low by using water very efficiently during photosynthesis. The latter was achieved by tightly controlling the opening of stomata. Like "Pereskia" species today, early ancestors may have been able to switch from the normal C3 mechanism, where carbon dioxide is used continuously in photosynthesis, to CAM cycling, in which when the stomata are closed, carbon dioxide produced by respiration is stored for later use in photosynthesis.
"Pereskia" clade B marks the beginnings of an evolutionary switch to using stems as photosynthetic organs. Stems have stomata and the formation of bark takes place later than in normal trees. The "core cacti" show a steady increase in both stem succulence and photosynthesis accompanied by multiple losses of leaves, more-or-less complete in the Cactoideae. One evolutionary question at present unanswered is whether the switch to full CAM photosynthesis in stems occurred only once in the core cacti, in which case it has been lost in "Maihuenia", or separately in Opuntioideae and Cactoideae, in which case it never evolved in "Maihuenia".
Understanding evolution within the core cacti clade is difficult , since phylogenetic relationships are still uncertain and not well related to current classifications. Thus, a 2011 study found "an extraordinarily high proportion of genera" were not monophyletic, so were not all descendants of a single common ancestor. For example, of the 36 genera in the subfamily Cactoideae sampled in the research, 22 (61%) were found not monophyletic. Nine tribes are recognized within Cactoideae in the International Cactaceae Systematics Group (ICSG) classification; one, Calymmantheae, comprises a single genus, "Calymmanthium". Only two of the remaining eight, Cacteae and Rhipsalideae, were shown to be monophyletic in a 2011 study by Hernández-Hernández et al. For a more detailed discussion of the phylogeny of the cacti, see Classification of the Cactaceae.
Evolutionary history.
No known fossils of cacti exist to throw light on their evolutionary history. However, the geographical distribution of cacti offers some evidence. Except for a relatively recent spread of "Rhipsalis baccifera" to parts of the Old World, cacti are plants of South America and mainly southern regions of North America. This suggests the family must have evolved after the ancient continent of Gondwana split into South America and Africa, which occurred during the Early Cretaceous, around . Precisely when after this split cacti evolved is less clear. Older sources suggest an early origin around 90 – 66 million years ago, during the Late Cretaceous. More recent molecular studies suggest a much younger origin, perhaps in very Late Eocene to early Oligocene periods, around 35–30 million years ago. Based on the phylogeny of the cacti, the earliest diverging group ("Pereskia" clade A) may have originated in Central America and northern South America, whereas the caulocacti, those with more-or-less succulent stems, evolved later in the southern part of South America, and then moved northwards. Core cacti, those with strongly succulent stems, are estimated to have evolved around 25 million years ago. A possible stimulus to their evolution may have been uplifting in the central Andes, some 25–20 million years ago, which was associated with increasing and varying aridity. However, the current species diversity of cacti is thought to have arisen only in the last 10–5 million years (from the late Miocene into the Pliocene). Other succulent plants, such as the Aizoaceae in South Africa, the Didiereaceae in Madagascar and the genus "Agave" in the Americas, appear to have diversified at the same time, which coincided with a global expansion of arid environments.
Distribution.
Cacti inhabit diverse regions, from coastal plains to high mountain areas. With one exception, they are native to the Americas, where their range extends from Patagonia to British Columbia and Alberta in western Canada. A number of centers of diversity exist. For cacti adapted to drought, the three main centers are Mexico and the southwestern United States; the southwestern Andes, where they are found in Peru, Bolivia, Chile and Argentina; and eastern Brazil, away from the Amazon Basin. Tree-living epiphytic and climbing cacti necessarily have different centers of diversity, as they require moister environments. They are mainly found in the coastal mountains and Atlantic forests of southeastern Brazil; in Bolivia, which is the center of diversity for the subfamily Rhipsalideae; and in forested regions of Central America, where the climbing Hylocereeae are most diverse.
"Rhipsalis baccifera" is the exception; it is native to both the Americas and the Old World, where it is found in tropical Africa, Madagascar, and Sri Lanka. One theory is it was spread by being carried as seeds in the digestive tracts of migratory birds; the seeds of "Rhipsalis" are adapted for bird distribution. Old World populations are polyploid, and regarded as distinct subspecies, supporting the idea that the spread was not recent. The alternative theory is the species initially crossed the Atlantic on European ships trading between South America and Africa, after which birds may have spread it more widely.
Many other species have become naturalized outside the Americas after having been introduced by people, especially in Australia, Hawaii, and the Mediterranean region. In Australia, species of "Opuntia", particularly "Opuntia stricta", were introduced in the 19th century for use as natural agricultural fences and in an attempt to establish a cochineal industry. They rapidly became a major weed problem, but are now controlled by biological agents, particularly the moth "Cactoblastis cactorum". The weed potential of Opuntia species in Australia continues however, leading to all opuntioid cacti except "O. ficus-indica" being declared Weeds of National Significance by the Australian Weeds Committee in April 2012.
Reproductive ecology.
Cactus flowers are pollinated by insects, birds and bats. None are known to be wind-pollinated and self-pollination occurs in only a very few species; for example the flowers of some species of "Frailea" do not open (cleistogamy). The need to attract pollinators has led to the evolution of pollination syndromes, which are defined as groups of "floral traits, including rewards, associated with the attraction and utilization of a specific group of animals as pollinators."
Bees are the most common pollinators of cacti; bee-pollination is considered to have been the first to evolve. Day-flying butterflies and nocturnal moths are associated with different pollination syndromes. Butterfly-pollinated flowers are usually brightly colored, opening during the day, whereas moth-pollinated flowers are often white or pale in color, opening only in the evening and at night. As an example, "Pachycereus schottii" is pollinated by a particular species of moth, "Upiga virescens", which also lays its eggs among the developing seeds its caterpillars later consume. The flowers of this cactus are funnel-shaped, white to deep pink, up to long, and open at night.
Hummingbirds are significant pollinators of cacti. Species showing the typical hummingbird-pollination syndrome have flowers with colors towards the red end of the spectrum, anthers and stamens that protrude from the flower, and a shape that is not radially symmetrical, with a lower lip that bends downwards; they produce large amounts of nectar with a relatively low sugar content. "Schlumbergera" species, such as "S. truncata", have flowers that correspond closely to this syndrome. Other hummingbird-pollinated genera include "Cleistocactus" and "Disocactus".
Bat-pollination is relatively uncommon in flowering plants, but about a quarter of the genera of cacti are known to be pollinated by bats—an unusually high proportion, exceeded among eudicots by only two other families, both with very few genera. Columnar cacti growing in semidesert areas are among those most likely to be bat-pollinated; this may be because bats are able to travel considerable distances, so are effective pollinators of plants growing widely separated from one another. The pollination syndrome associated with bats includes a tendency for flowers to open in the evening and at night, when bats are active. Other features include a relatively dull color, often white or green; a radially symmetrical shape, often tubular; a smell described as "musty"; and the production of a large amount of sugar-rich nectar. "Carnegiea gigantea" is an example of a bat-pollinated cactus, as are many species of "Pachycereus" and "Pilosocereus".
The fruits produced by cacti after the flowers have been fertilized vary considerably; many are fleshy, although some are dry. All contain a large number of seeds. Fleshy, colorful and sweet-tasting fruits are associated with seed dispersal by birds. The seeds pass through their digestive systems and are deposited in their droppings. Fruit that falls to the ground may be eaten by other animals; giant tortoises are reported to distribute "Opuntia" seeds in the Galápagos Islands. Ants appear to disperse the seeds of a few genera, such as "Blossfeldia". Drier spiny fruits may cling to the fur of mammals or be moved around by the wind.
Uses.
Early history.
, there is still controversy as to the precise dates when humans first entered those areas of the New World where cacti are commonly found, and hence when they might first have used them. An archaeological site in Chile has been dated to around 15,000 years ago, suggesting cacti would have been encountered before then. Early evidence of the use of cacti includes cave paintings in the Serra da Capivara in Brazil, and seeds found in ancient middens (waste dumps) in Mexico and Peru, with dates estimated at 12,000–9,000 years ago. Hunter-gatherers likely collected cactus fruits in the wild and brought them back to their camps.
It is not known when cacti were first cultivated. Opuntias (prickly pears) were used for a variety of purposes by the Aztecs, whose empire, lasting from the 14th to the 16th century, had a complex system of horticulture. Their capital from the 15th century was Tenochtitlan (now Mexico City); one explanation for the origin of the name is that it includes the Nahuatl word "nōchtli", referring to the fruit of an opuntia. The coat of arms of Mexico shows an eagle perched on a cactus while holding a snake, an image at the center of the myth of the founding of Tenochtitlan. The Aztecs symbolically linked the ripe red fruits of an opuntia to human hearts; just as the fruit quenches thirst, so offering human hearts to the sun god ensured the sun would keep moving.
Europeans first encountered cacti when they arrived in the New World late in the 15th century. Their first landfalls were in the West Indies, where relatively few cactus genera are found; one of the most common is the genus "Melocactus". Thus, melocacti were possibly among the first cacti seen by Europeans. "Melocactus" species were present in English collections of cacti before the end of the 16th century (by 1570 according to one source,) where they were called "Echinomelocactus", later shortened to "Melocactus" by Joseph Pitton de Tourneville in the early 18th century. Cacti, both purely ornamental species and those with edible fruit, continued to arrive in Europe, so Carl Linnaeus was able to name 22 species by 1753. One of these, his "Cactus opuntia" (now part of "Opuntia ficus-indica"), was described as """" (with larger fruit ... now in Spain and Portugal), indicative of its early use in Europe.
Food.
The plant now known as "Opuntia ficus-indica", or the Indian fig cactus, has long been an important source of food. The original species is thought to have come from central Mexico, although this is now obscure because the indigenous people of southern North America developed and distributed a range of horticultural varieties (cultivars), including forms of the species and hybrids with other opuntias. Both the fruit and pads are eaten, the former often under the Spanish name "tuna", the latter under the name "nopal". Cultivated forms are often significantly less spiny or even spineless. The nopal industry in Mexico was said to be worth US$150 million in 2007. The Indian fig cactus was probably already present in the Caribbean when the Spanish arrived, and was soon after brought to Europe. It spread rapidly in the Mediterranean area, both naturally and by being introduced—so much so, early botanists assumed it was native to the area. Outside the Americas, the Indian fig cactus is an important commercial crop in Sicily, Algeria and other North African countries. Fruits of other opuntias are also eaten, generally under the same name, "tuna". Flower buds, particularly of "Cylindropuntia" species, are also consumed.
Almost any fleshy cactus fruit is edible. The word "pitaya" or "pitahaya" (usually considered to have been taken into Spanish from Haitian creole) can be applied to a range of "scaly fruit", particularly those of columnar cacti. The fruit of the saguaro ("Carnegiea gigantea") has long been important to the indigenous peoples of northwestern Mexico and the southwestern United States, including the Sonoran Desert. It can be preserved by boiling to produce syrup and by drying. The syrup can also be fermented to produce an alcoholic drink. Fruits of "Stenocereus" species have also been important food sources in similar parts of North America; "Stenocereus queretaroensis" is cultivated for its fruit. In more tropical southern areas, the climber "Hylocereus undatus" provides "pitahaya orejona", now widely grown in Asia under the name dragon fruit. Other cacti providing edible fruit include species of "Echinocereus", "Ferocactus", "Mammillaria", "Myrtillocactus", "Pachycereus", "Peniocereus" and "Selenicereus". The bodies of cacti other than opuntias are less often eaten, although Anderson reported that "Neowerdermannia vorwerkii" is prepared and eaten like potatoes in upland Bolivia.
Psychoactive agents.
A number of species of cacti have been shown to contain psychoactive agents, chemical compounds that can cause changes in mood, perception and cognition through their effects on the brain. Two species have a long history of use by the indigenous peoples of the Americas: peyote, "Lophophora williamsii", in North America, and the San Pedro cactus, "Echinopsis pachanoi", in South America. Both contain mescaline.
"L. williamsii" is native to northern Mexico and southern Texas. Individual stems are about high with a diameter of , and may be found in clumps up to wide. A large part of the stem is usually below ground. Mescaline is concentrated in the photosynthetic portion of the stem above ground. The center of the stem, which contains the growing point (the apical meristem), is sunken. Experienced collectors of peyote remove a thin slice from the top of the plant, leaving the growing point intact, thus allowing the plant to regenerate. Evidence indicates peyote was in use more than 5,500 years ago; dried peyote buttons presumed to be from a site on the Rio Grande, Texas, were radiocarbon dated to around 3780–3660 BC. Peyote is perceived as a means of accessing the spirit world. Attempts by the Roman Catholic church to suppress its use after the Spanish conquest were largely unsuccessful, and by the middle of the 20th century, peyote was more widely used than ever by indigenous peoples as far north as Canada. It is now used formally by the Native American Church.
"Echinopsis pachanoi" is native to Ecuador and Peru. It is very different in appearance from "L. williamsii". It has tall stems, up to high, with a diameter of , which branch from the base, giving the whole plant a shrubby or tree-like appearance. Archaeological evidence of the use of this cactus appears to date back to 2,000–2,300 years ago, with carvings and ceramic objects showing columnar cacti. Although church authorities under the Spanish attempted to suppress its use, this failed, as shown by the Christian element in the common name "San Pedro cactus"—Saint Peter cactus. Anderson attributes the name to the belief that just as St Peter holds the keys to heaven, the effects of the cactus allow users "to reach heaven while still on earth." It continues to be used for its psychoactive effects, both for spiritual and for healing purposes, often combined with other psychoactive agents, such as "Datura ferox" and tobacco. Several other species of "Echinopsis", including "E. peruviana", also contain mescaline.
Ornamental plants.
Cacti were cultivated as ornamental plants from the time they were first brought from the New World. By the early 1800s, enthusiasts in Europe had large collections (often including other succulents alongside cacti). Rare plants were sold for very high prices. Suppliers of cacti and other succulents employed collectors to obtain plants from the wild, in addition to growing their own. In the late 1800s, collectors turned to orchids, and cacti became less popular, although never disappearing from cultivation.
Cacti are often grown in greenhouses, particularly in regions unsuited to the cultivation of cacti outdoors, such the northern parts of Europe and North America. Here, they may be kept in pots or grown in the ground. Cacti are also grown as houseplants, many being tolerant of the often dry atmosphere. Cacti in pots may be placed outside in the summer to ornament gardens or patios, and then kept under cover during the winter. Less drought-resistant epiphytes, such as epiphyllum hybrids, "Schlumbergera" (the Thanksgiving or Christmas cactus) and "Hatiora" (the Easter cactus), are widely cultivated as houseplants.
Cacti may also be planted outdoors in regions with suitable climates. Concern for water conservation in arid regions has led to the promotion of gardens requiring less watering (xeriscaping). For example, in California, the East Bay Municipal Utility District sponsored the publication of a book on plants and landscapes for summer-dry climates. Cacti are one group of drought-resistant plants recommended for dry landscape gardening.
Other uses.
Cacti have many other uses. They are used for human food and as fodder for animals, usually after burning off their spines. In addition to their use as psychoactive agents, some cacti are employed in herbal medicine. The practice of using various species of "Opuntia" in this way has spread from the Americas, where they naturally occur, to other regions where they grow, such as India.
Cochineal is a red dye produced by a scale insect that lives on species of "Opuntia". Long used by the peoples of Central and North America, demand fell rapidly when European manufacturers began to produce synthetic dyes in the middle of the 19th century. Commercial production has now increased following a rise in demand for natural dyes.
Cacti are used as construction materials. Living cactus fences are employed as barricades. The woody parts of cacti, such as "Cereus repandus" and "Echinopsis atacamensis", are used in buildings and in furniture. The frames of wattle and daub houses built by the Seri people of Mexico may use parts of "Carnegiea gigantea". The very fine spines and hairs (trichomes) of some cacti were used as a source of fiber for filling pillows and in weaving.
Conservation.
All cacti are included in Appendix II of the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES), which "lists species that are not necessarily now threatened with extinction but that may become so unless trade is closely controlled." Control is exercised by making international trade in most specimens of cacti illegal unless permits have been issued, at least for exports. Some exceptions are allowed, e.g., for "naturalized or artificially propagated plants". Some cacti, such as all "Ariocarpus" and "Discocactus" species, are included in the more restrictive Appendix I, used for the "most endangered" species. These may only be moved between countries for scientific purposes, and only then when accompanied by both export and import permits.
The three main threats to cacti in the wild are development, grazing and over-collection. Development takes many forms. The construction of a dam near Zimapan, Mexico, caused the destruction of a large part of the natural habitat of "Echinocactus grusonii". Urban development and highways have destroyed cactus habitats in parts of Mexico, New Mexico and Arizona, including the Sonoran Desert. The conversion of land to agriculture has affected populations of "Ariocarpus kotschoubeyanus" in Mexico, where dry plains were plowed for maize cultivation, and of "Copiapoa" and "Eulychnia" in Chile, where valley slopes were planted with vines. Grazing, in many areas by introduced animals, such as goats, has caused serious damage to populations of cacti (as well as other plants); two examples cited by Anderson are the Galápagos Islands generally and the effect on "Browningia candelaris" in Peru. Over-collection of cacti for sale has greatly affected some species. For example, the type locality of "Pelecyphora strobiliformis" near Miquihuana, Mexico, was virtually denuded of plants, which were dug up for sale in Europe. Illegal collecting of cacti from the wild continues to pose a threat.
Conservation of cacti can be "in situ" or "ex situ". "In situ" conservation involves preserving habits through enforcement of legal protection and the creation of specially protected areas such as national parks and reserves. Examples of such protected areas in the United States include Big Bend National Park, Texas; Joshua Tree National Park, California; and Saguaro National Park, Arizona. Latin American examples include Parque Nacional del Pinacate, Sonora, Mexico and Pan de Azúcar National Park, Chile. "Ex situ" conservation aims to preserve plants and seeds outside their natural habitats, often with the intention of later reintroduction. Botanical gardens play an important role in "ex situ" conservation; for example, seeds of cacti and other succulents are kept in long-term storage at the Desert Botanical Garden, Arizona.
Cultivation.
The popularity of cacti means many books are devoted to their cultivation. Cacti naturally occur in a wide range of habitats and are then grown in many countries with different climates, so precisely replicating the conditions in which a species normally grows is usually not practical. A broad distinction can be made between semidesert cacti and epiphytic cacti, which need different conditions and are best grown separately. This section is primarily concerned with the cultivation of semidesert cacti in containers and under protection, such as in a greenhouse or in the home, rather than cultivation outside in the ground in those climates that permit it. For the cultivation of epiphytic cacti, see Cultivation of "Schlumbergera" (Christmas or Thanksgiving cacti), and Cultivation of epiphyllum hybrids.
Growing medium.
The purpose of the growing medium is to provide support and to store water, oxygen and dissolved minerals to feed the plant. In the case of cacti, there is general agreement that an open medium with a high air content is important. When cacti are grown in containers, recommendations as to how this should be achieved vary greatly; Miles Anderson says that if asked to describe a perfect growing medium, "ten growers would give 20 different answers". Roger Brown suggests a mixture of two parts commercial soilless growing medium, one part hydroponic clay and one part coarse pumice or perlite, with the addition of soil from earthworm castings. The general recommendation of 25–75% organic-based material, the rest being inorganic such as pumice, perlite or grit, is supported by other sources. However, the use of organic material is rejected altogether by others; Hecht says that cacti (other than epiphytes) "want soil that is low in or free of humus", and recommends coarse sand as the basis of a growing medium.
Watering.
Semi-desert cacti need careful watering. General advice is hard to give, since the frequency of watering required depends on where the cacti are being grown, the nature of the growing medium, and the original habitat of the cacti. Brown says that more cacti are lost through the "untimely application of water than for any other reason" and that even during the dormant winter season, cacti need some water. Other sources say that water can be withheld during winter (November to March in the Northern Hemisphere). Another issue is the hardness of the water; where it is necessary to use hard water, regular re-potting is recommended to avoid the build up of salts. The general advice given is that during the growing season, cacti should be allowed to dry out between thorough waterings. A water meter can help in determining when the soil is dry.
Light and temperature.
Although semi-desert cacti may be exposed to high light levels in the wild, they may still need some shading when subjected to the higher light levels and temperatures of a greenhouse in summer. Allowing the temperature to rise above is not recommended. The minimum winter temperature required depends very much on the species of cactus involved. For a mixed collection, a minimum temperature of between and is often suggested, except for cold-sensitive genera such as "Melocactus" and "Discocactus". Some cacti, particularly those from the high Andes, are fully frost-hardy when kept dry (e.g. "Rebutia minuscula" survives temperatures down to in cultivation) and may flower better when exposed to a period of cold.
Propagation.
Cacti can be propagated by seed, cuttings or grafting. Seed sown early in the year produces seedlings that benefit from a longer growing period. Seed is sown in a moist growing medium and then kept in a covered environment, until 7–10 days after germination, to avoid drying out. A very wet growing medium can cause both seeds and seedlings to rot. A temperature range of is suggested for germination; soil temperatures of around promote the best root growth. Low light levels are sufficient during germination, but afterwards semi-desert cacti need higher light levels to produce strong growth, although acclimatization is needed to conditions in a greenhouse, such as higher temperatures and strong sunlight.
Reproduction by cuttings makes use of parts of a plant that can grow roots. Some cacti produce "pads" or "joints" that can be detached or cleanly cut off. Other cacti produce offsets that can be removed. Otherwise, stem cuttings can be made, ideally from relatively new growth. It is recommended that any cut surfaces be allowed to dry for a period of several days to several weeks until a callus forms over the cut surface. Rooting can then take place in an appropriate growing medium at a temperature of around .
Grafting is used for species difficult to grow well in cultivation or that cannot grow independently, such as some chlorophyll-free forms with white, yellow or red bodies, or some forms that show abnormal growth (e.g., cristate or monstrose forms). For the host plant—the "stock"—growers choose one that grows strongly in cultivation and is compatible with the plant to be propagated—the "scion." The grower makes cuts on both stock and scion and joins the two, binding them together while they unite. Various kinds of graft are used—flat grafts, where both scion and stock are of similar diameters, and cleft grafts, where a smaller scion is inserted into a cleft made in the stock.
Commercially, huge numbers of cacti are produced annually. For example, in 2002 in Korea alone, 49 million plants were propagated, with a value of almost US$9 million. Most of them, 31 million plants, were propagated by grafting.
Pests and diseases.
A range of pests attack cacti in cultivation. Those that feed on sap include: mealybugs, living on both stems and roots; scale insects, generally only found on stems; whiteflies, which are said to be an "infrequent" pest of cacti; red spider mites, which are very small but can occur in large numbers, constructing a fine web around themselves and badly marking the cactus via their sap sucking, even if they do not kill it; and thrips, which particularly attack flowers. Some of these pests are resistant to many insecticides, although there are biological controls available. Roots of cacti can be eaten by the larvae of sciarid flies and fungus gnats. Slugs and snails also eat cacti.
Fungi, bacteria and viruses attack cacti, the first two particularly when plants are over-watered. Fusarium rot can gain entry through a wound and cause rotting accompanied by red-violet mold. "Helminosporium rot" is caused by "Bipolaris cactivora" (syn. "Helminosporium cactivorum"); "Phytophthora" species also cause similar rotting in cacti. Fungicides may be of limited value in combating these diseases. Several viruses have been found in cacti, including cactus virus X. These appear to cause only limited visible symptoms, such as chlorotic (pale green) spots and mosaic effects (streaks and patches of paler color). However, in an "Agave" species, cactus virus X has been shown to reduce growth, particularly when the roots are dry. There are no treatments for virus diseases.

</doc>
<doc id="7820" url="https://en.wikipedia.org/wiki?curid=7820" title="CCC">
CCC

CCC may refer to:

</doc>
<doc id="7821" url="https://en.wikipedia.org/wiki?curid=7821" title="Civilian Conservation Corps">
Civilian Conservation Corps

The Civilian Conservation Corps (CCC) was a public work relief program that operated from 1933 to 1942 in the United States for unemployed, unmarried men from relief families as part of the New Deal. Originally for young men ages 18–23, it was eventually expanded to young men ages 17–28. Robert Fechner was the head of the agency. It was a major part of President Franklin D. Roosevelt's New Deal that provided unskilled manual labor jobs related to the conservation and development of natural resources in rural lands owned by federal, state and local governments. The CCC was designed to provide jobs for young men, to relieve families who had difficulty finding jobs during the Great Depression in the United States while at the same time implementing a general natural resource conservation program in every state and territory. Maximum enrollment at any one time was 300,000; in nine years 3 million young men participated in the CCC, which provided them with shelter, clothing, and food, together with a small wage of $30 (about $547 in 2015) a month ($25 of which had to be sent home to their families).
The American public made the CCC the most popular of all the New Deal programs. Principal benefits of an individual's enrollment in the CCC included improved physical condition, heightened morale, and increased employability. Implicitly, the CCC also led to a greater public awareness and appreciation of the outdoors and the nation's natural resources; and the continued need for a carefully planned, comprehensive national program for the protection and development of natural resources.
During the time of the CCC, enrollees planted nearly 3 billion trees to help reforest America, constructed more than 800 parks nationwide and upgraded most state parks, updated forest fire fighting methods, and built a network of service buildings and public roadways in remote areas.
The CCC operated separate programs for veterans and Native Americans.
Despite its popular support, the CCC was never a permanent agency. It depended on emergency and temporary Congressional legislation for its existence. By 1942, with World War II and the draft in operation, need for work relief declined and Congress voted to close the program.
Founding.
As governor of New York, Roosevelt had run a similar program on a much smaller scale. Long interested in conservation, as president, he proposed to Congress a full-scale national program on March 21, 1933:
He promised this law would provide 16 young men with meals, housing, uniforms, and medical care for working in the national forests and other government properties. The Emergency Conservation Work (ECW) Act was introduced to Congress the same day and enacted by voice vote on March 31. Roosevelt issued Executive Order 6101 on April 5, 1933 which established the CCC organization and appointed a director, Robert Fechner, a former labor union official who served until 1939. The organization and administration of the CCC was a new experiment in operations for a federal government agency. The order indicated that the program was to be supervised jointly by four government departments: Labor, which recruited the young men, War, which operated the camps, and Agriculture and Interior, which organized and supervised the work projects. A CCC Advisory Council was composed of a representative from each of the supervising departments. In addition, the Office of Education and Veterans Administration participated in the program. To end the opposition from labor unions (which wanted no training programs started when so many of their men were unemployed) Roosevelt chose Robert Fechner, vice president of the American Machinists Union, as director of the corps. William Green, head of the American Federation of Labor, was taken to the first camp to demonstrate that there would be no job training involved beyond simple manual labor.
US Army.
Reserve officers from the U.S. Army were in charge of the camps, but there was no military training. General Douglas MacArthur was placed in charge of the program but stated that the number of Army officers and soldiers assigned to the camps was affecting the readiness of the Regular Army. The Army found numerous benefits. When the draft began in 1940 the policy was to make CCC alumni corporals and sergeants. CCC provided command experience to Organized Reserve Corps officers. The CCC allowed the Regular Army to assess the leadership performance of both Regular and Reserve Officers. The CCC provided lessons the Army used in developing its wartime and mobilization plans for training camps.
Early Years, 1933–1934.
The legislation and mobilization of the program occurred quite rapidly. Roosevelt made his request to Congress on March 21, 1933; the legislation was submitted to Congress the same day; Congress passed it by voice vote on March 31; Roosevelt signed it the same day, then issued an executive order on April 5 creating the agency, appointing its director (Fechner), and assigning War Department corps area commanders the task to commence enrollment. The first CCC enrollee was selected April 8 and subsequent lists of unemployed men were supplied by state and local welfare and relief agencies for immediate enrollment. On April 17 the first camp, NF-1, Camp Roosevelt, was established at George Washington National Forest near Luray, Virginia. On June 18, the first of 161 soil erosion control camps was opened, in Clayton, Alabama. By July 1, 1933 there were 1,463 working camps with 250,000 junior enrollees (18–25 years of age), 28,000 veterans, 14,000 American Indians, and 25,000 Locally Enrolled (or Experienced) Men (LEM).
Enrollees.
The typical CCC enrollee was a U.S. citizen, unmarried, unemployed male, 18–25 years of age. Normally his family was on local relief. Each enrollee volunteered and, upon passing a physical exam and/or a period of conditioning, was required to serve a minimum six-month period with the option to serve as many as four periods, or up to two years, if employment outside the Corps was not possible. Enrollees worked 40 hours a week over five days, sometimes including Saturdays if poor weather dictated. In return they received $30 a month with a compulsory allotment $22–25 sent to a family dependant, as well as food, clothing, and medical care. Following the second Bonus Army march on Washington D.C., President Roosevelt issued Executive Order 6129 (May 11, 1933) to amend the CCC program, to include work opportunities for veterans. Veteran qualifications differed from the junior enrollee; one needed to be certified by the Veterans Administration by application. They could be any age, and married or single as long as they were in need of work. Veterans were generally assigned to entire veteran camps. Enrollees were eligible for the following "rated" positions to help with camp administration: senior leader, mess steward, store keeper and two cooks; assistant leader, company clerk, assistant educational advisor and three second cooks. These men received additional pay ranging from $36 to $45 per month depending on their rating.
Camps.
Each CCC camp was located in the area of particular conservation work to be performed, and organized around a complement of up to 200 civilian enrollees in a designated numbered "company" unit. The CCC camp was a temporary community in itself, structured to have barracks (initially Army tents) for 50 enrollees each, officer/technical staff quarters, medical dispensary, mess hall, recreation hall, educational building, lavatory and showers, technical/administrative offices, tool room/blacksmith shop and motor pool garages. The company organization of each camp had a dual-authority supervisory staff: firstly, Department of War personnel or Reserve officers (until July 1, 1939), a "company commander" and junior officer, who were responsible for overall camp operation, logistics, education and training; and secondly, ten to fourteen technical service civilians, including a camp "superintendent" and "foreman", employed by either the Departments of Interior or Agriculture, responsible for the particular field work. Also included in camp operation were several non-technical supervisor LEMs, who provided knowledge of the work at hand, "lay of the land" and paternal guidance for inexperienced enrollees. Enrollees were organized into work detail units called "sections" of 25 men each, according to the barracks they resided in. Each section had an enrollee "senior leader" and "assistant leader" who were accountable for the men at work and in the barracks.
Work classifications.
The CCC performed 300 possible types of work projects within ten approved general classifications:
The responses to this seven-month experimental conservation program were enthusiastic, and on October 1, 1933 Director Fechner was instructed to arrange for a second period of enrollment. By January 1934, 300,000 men were enrolled. In July 1934 this cap was increased by 50,000 to include men from midwest states that had been affected by drought. The temporary tent camps had also transitioned from tents to wooden barracks. An education program had been established emphasizing job training and literacy.
Approximately 55% of enrollees were from rural communities, a majority of which were non-farm; 45% came from urban areas. Level of education for the enrollee averaged 3% illiterate, 38% less than eight years of school, 48% did not complete high school, 11% were high school graduates. At the time of entry, 70% of enrollees were malnourished and poorly clothed. Few had work experience beyond occasional odd jobs. Peace was maintained by the threat of "dishonorable discharge". "This is a training station; we're going to leave morally and physically fit to lick 'Old Man Depression,'" boasted the newsletter, "Happy Days", of a North Carolina camp.
Minorities.
The New Deal was racially segregated; blacks and whites rarely worked alongside each other in New Deal programs. In the first few weeks of operation, CCC camps in the North were integrated. By July 1935, however, all the camps in the United States were segregated.
A total of 200,000 blacks were enrolled; they served in 143 all-black camps and received equal pay and housing. Black leaders lobbied to secure leadership roles. Adult white men held the major leadership roles in all the camps. Director Robert Fechner refused to appoint black adults to any supervisory positions except that of education director in the all-black camps.
Indian Division.
The CCC operated an entirely separate division for members of federally recognized tribes: the "Indian Emergency Conservation Work" (IECW or CCC-ID). Native men from reservations worked on roads, bridges, clinics, shelters, and other public works near their reservations. Although classified as camps there were no actual permanent camps; instead, organized groups moved with their family from project to project, for which a rental allowance was issued in their pay. The CCC often provided the only paid work in remote reservations. Enrollees had to be between the ages of 17 and 35. For example, during 1933 about half the male heads of households on the Sioux reservations in South Dakota were employed by the CCC-ID. With grants from the Public Works Administration (PWA), the Indian Division built schools and operated an extensive road-building program in and around many reservations. The mission was to reduce erosion and improve the value of Indian lands. Crews built dams of many types on creeks, then sowed grass on the eroded areas from which the damming materials had been taken. They built roads and planted shelter-belts on federal lands. The steady income created an improved sense of self-worth for participants who used the funds to improve their lifestyles. John Collier the federal Commissioner of Indian Affairs and Daniel Murphy, the director of the CCC-ID, both centered the basic goals of the program around Indian self-rule and the restoration of tribal lands, governments, and cultures. In Collier's words, "no previous undertaking in Indian Service has so largely been the Indians' own undertaking". Education programs also trained participants in gardening, stock raising, safety, native arts, and some academic subjects. IECW differed from other CCC activities in that it explicitly trained men to be carpenters, truck drivers, radio operators, mechanics, surveyors, and technicians. With the passage of the National Defense Vocational Training Act of 1941, enrollees began participating in defense oriented training. The classes were paid for by the government and after course completion and a passed competency test, automatic employment in the defense work was guaranteed. A total of 85,000 Native Americans were enrolled. This proved valuable human capital for the 24,000 alumni who later served in the military and the 40,000 who left the reservations for city jobs supporting the war effort.
Program Expansion, 1935–1936.
Responding to favorable public opinion to alleviate unemployment, Congress approved the Emergency Relief Appropriation Act of 1935, on April 8, 1935, which included continued funding for the CCC program through March 31, 1937. The age limit was also expanded to 18-28 to include more men. From April 1, 1935 to March 31, 1936 was the period of greatest activity and work accomplished by the CCC program. Enrollment had peaked at 505,782 in about 2,900 camps by August 31, 1935, followed by a reduction to 350,000 enrollees in 2,019 camps by June 30, 1936. During this period the public response to the CCC program was overwhelmingly popular. A Gallup poll of April 18, 1936 asked "Are you in favor of the CCC camps?"; 82% of respondents said yes, including 92% of Democrats and 67% of Republicans.
Change of Purpose, 1937–1938.
On June 28, 1937 the Civilian Conservation Corps was legally established, transferred from its original designation as the Emergency Conservation Work program. Funding was also extended for three more years by Public Law No. 163, 75th Congress, effective July 1, 1937. Congress changed the age limits to 17–23 years old, and changed the requirement that enrollees be on relief to ""not regularly in attendance at school, or possessing full time employment"". The 1937 law mandated the inclusion of vocational and academic training for a minimum of 10 hours per week. Another change allowed for those in school to be enrolled during (summer) vacation. During this period, the CCC was called in to help with disaster relief following 1937 floods in New York, Vermont and the Ohio and Mississippi River Valleys, and response and clean-up after the 1938 hurricane in New England.
Conservation to Defense, 1939–1940.
In 1939 Congress ended the independent status of the CCC and transferred control to the Federal Security Agency, along with other agencies such as the National Youth Administration, U.S. Employment Service, the Office of Education and the Works Progress Administration. About 5,000 Reserve officers for the camps were affected, transferred to Civil Service and military ranks and titles were eliminated. Despite this loss of an obvious military leadership in the camps by July 1940, with war in Europe and Asia, an increasing number of CCC projects focused on resources for national defense, developing infrastructure for military training facilities and forest protection. By 1940 the CCC was no longer wholly a relief agency, rapidly losing its non-military character, and becoming a system for work-training as its ranks had become increasingly younger, with life-inexperienced enrollees.
Decline and Disbandment 1941–1942.
Although the CCC was probably the most popular New Deal program, it never became a permanent agency. The program had been reduced in operations as the Depression waned and employment opportunities improved. Fewer eligible young men were available after conscription commenced in 1940. Following the attack on Pearl Harbor in December 1941 all federal programs were revised to emphasize the war effort. Most CCC work, except for wildland firefighting, was shifted onto U.S. military bases to help with construction. The CCC disbanded one year earlier than planned, as the 77th United States Congress ceased funding, causing it to conclude operations formally at the end of the federal fiscal year on June 30, 1942. The end of the CCC program and closing of the camps involved arrangements to leave the incomplete work projects in the best possible state, the separation of about 1,800 appointed employees, the transfer of CCC property to the War and Navy Departments and other agencies, and the preparation of final accountability records. Liquidation of the CCC was ordered by Congress by the Labor-Federal Security Appropriation Act (56 Stat. 569) on July 2, 1942; and virtually completed on June 30, 1943. Liquidation appropriations for the CCC continued through April 20, 1948.
Some former CCC sites in good condition were reactivated from 1941 to 1947 as Civilian Public Service camps where conscientious objectors performed "work of national importance" as an alternative to military service. Other camps were used to hold Japanese, German and Italian Americans interned under the Western Defense Command's Enemy Alien Control Program, as well as Axis prisoners of war. After the CCC disbanded, the federal agencies responsible for administration of public lands organized their own seasonal fire crews, modeled after the CCC, which performed a firefighting function formerly done by the CCC and provided the same sort of outdoor work experience for young people. Approximately 47 young men died while in this line of duty.
Legacy and memory.
Legacy.
In several cities where CCC workers worked, statues were erected to commemorate their presence.
Reception.
"The American Experience" series showcasing documentaries on American history well portrayed the life in Civilian Conservation Corps in the first episode of Season 22. 
"Pride of the Bowery" (1940), the fourth movie in the East Side Kid series, is a movie about friendship, trouble and boxing at a Conservation Corps Camp.
"Hitch – Making Good In Hard Times" by Jeanette Ingold is a novel about how a teenager learns life lessons, skills for work and develops a character for himself in CCC camp.
The CCC model.
The CCC program was never officially terminated. Congress provided funding for closing the remaining camps in 1942 with the equipment being reallocated. It became a model for conservation programs that were implemented in the period after World War II. Present-day corps are national, state and local programs that engage primarily youth and young adults (ages 16–25) in community service, training and educational activities. The nation's approximate 113 corps programs operate in 41 states and the District of Columbia. During 2004, they enrolled more than 23,000 young people. The Corps Network, known originally as the National Association of Service and Conservation Corps (NASCC), works to expand and enhance corps-type programs throughout the country. The Corps Network began in 1985, when the nation's first 24 Corps directors banded together to secure an advocate at the federal level and a repository of information on how best to start and manage a corps. Early financial assistance from the Ford, Hewlett and Mott Foundations was critical to establishing the association.
Another similar program is the National Civilian Community Corps, part of the AmeriCorps program, a team-based national service program in which 18- to 24-year-olds spend 10 months working for non-profit and government organizations.
Student Conservation Association.
The CCC program became a model for the creation of team-based national service youth conservation programs such as the Student Conservation Association (SCA). The SCA, founded in 1959, is a nonprofit organization that offers conservation internships and summer trail crew opportunities to more than 4,000 people each year. The SCA mission is to build a new generation of conservation managers by inspiring lifelong stewardship of the environment and communities by engaging high school and college-age volunteers in hands-on service to the land. SCA program is active nationwide in the USA, including national and state parks, forests, wildlife refuges, seashores and historic sites. SCA National Headquarters is located in Charlestown, New Hampshire with regional offices across the country.
California Conservation Corps.
In 1976, Governor of California Jerry Brown established the California Conservation Corps. This new program had many similar characteristics - residential centers, high expectations for participation, emphasis on hard work on public lands. Young adults from different backgrounds were recruited for a term of one-year. Corps members attended a training session call the Corpsmember Orientation Motivation Education and Training (COMET) program before being assigned to one of the various centers. 
Life at CCC centers is rigorous, starting with early morning exercises, breakfast, roll call and a full day's work. After hours include education, life skills workshops, community meetings, volunteerism. Project work is also similar to the original CCC of the 1930s - work on public forests, state and federal parks.
Texas Conservation Corps.
Established in 1995, Environmental Corps, now Texas Conservation Corps (TxCC), is an American YouthWorks program which allows youth, ages 17 to 28, to contribute to the restoration and preservation of parks and public lands in Texas. The only conservation corps in Texas, TxcC is a 501(c)3 non profit corporation based in Austin, Texas, which serves the entire state. Their work ranges from disaster relief to trail building to habitat restoration. TxCC has done projects in national, state, and city parks.
Montana Conservation Corps.
The Montana Conservation Corps (MCC) is a registered 501(c)3 non-profit organization with a mission to equip young people with the skills and values to be vigorous citizens who improve their communities and environment. Collectively, MCC crews contribute more than 90,000 work hours each year. The MCC was established in 1991 by Montana's Human Resource Development Councils in Billings, Bozeman and Kalispell. Originally, it was a summer program for disadvantaged youth, although it has grown into an AmeriCorps-sponsored non-profit organization with six regional offices that serve Montana, Idaho, Wyoming, and North and South Dakota. All regions also offer MontanaYES (Youth Engaged in Service) summer programs for teenagers who are 14 to 16 years old.
Washington Conservation Corps.
The Washington Conservation Corps (WCC) is a sub-agency of the Washington State Department of Ecology. It employs men and women 18 to 25 years old in a program to protect and enhance Washington's natural resources. WCC is a part of the AmeriCorps program.
Minnesota Conservation Corps.
Conservation Corps Minnesota & Iowa provides environmental stewardship and service-learning opportunities to youth and young adults while accomplishing conservation, natural resource management projects and emergency response work through its Young Adult Program and the Summer Youth Program. These programs emphasize the development of job and life skills by conservation and community service work.
Vermont Youth Conservation Corps.
The Vermont Youth Conservation Corps (VYCC) is a non-profit, youth service and education organization that hires Corps Members, aged 16–24, to work on high-priority conservation projects in Vermont. Through these work projects, Corps Members develop a strong work ethic, strengthen their leadership skills, and learn how to take personal responsibility for their actions. VYCC Crews work at VT State Parks, U.S. Forest Service Campgrounds, in local communities, and throughout the state's back country.
Conservation Legacy.
Conservation Legacy is a non-profit employment, job training, and education organization with locations across the United States including Arizona Conservation Corps in Tucson and Flagstaff, AZ, Southwest Conservation Corps in Durango and Salida, Colorado, and Southeast Conservation Corps in Chattanooga, TN. Conservation Legacy also operates an AmeriCorps VISTA team serving to improve the environment and economies of historic mining communities in the American West and Appalachia. Conservation Legacy also hosts the Environmental Stewards Program - providing internships with federal, state, municipal and NGO land management agencies nationwide. Conservation Legacy formed as a merger of the Southwest Youth Corps, San Luis Valley Youth Corps, The Youth Corps of Southern Arizona, and Coconino Rural Environmental Corps.
Conservation Legacy engages young adults ages 14 to 26 and US military veterans of all ages in personal and professional development experiences involving conservation projects on public lands. Corp members live, work, and learn in teams of six to eight for terms of service ranging from 3 months to 1 year.

</doc>
<doc id="7822" url="https://en.wikipedia.org/wiki?curid=7822" title="Caribbean Sea">
Caribbean Sea

The Caribbean Sea () is a sea of the Atlantic Ocean located in the tropics of the Western Hemisphere. It is bounded by the Yucatán Peninsula of Mexico and Central America to the west and southwest, to the north by the Greater Antilles starting with Cuba, to the east by the Lesser Antilles, and to the south by the north coast of South America.
The entire area of the Caribbean Sea, the numerous islands of the West Indies, and adjacent coasts, are collectively known as 'the Caribbean'. The Caribbean Sea is one of the largest seas and has an area of about 2,754,000 km2 (1,063,000 sq mi). The sea's deepest point is the Cayman Trough, between the Cayman Islands and Jamaica, at 7,686 m (25,220 ft) below sea level. The Caribbean coastline has many gulfs and bays: the Gulf of Gonâve, Gulf of Venezuela, Gulf of Darién, Golfo de los Mosquitos, Gulf of Paria and Gulf of Honduras.
The Caribbean Sea has the second biggest barrier reef in the world, the Mesoamerican Barrier Reef. It runs along the coasts of Mexico, Belize, Guatemala, and Honduras.
History.
The name "Caribbean" derives from the Caribs, one of the dominant Native American groups in the region at the time of European contact during the late 15th century. After the discovery of America by Christopher Columbus in 1492, the Spanish term "Antillas" applied to the lands; stemming from this, "Sea of the Antilles" became a common alternative name for "Caribbean Sea" in various European languages. During the first century of development, Spanish dominance in the region remained undisputed.
From the 16th century, Europeans visiting the Caribbean region identified the "South Sea" (the Pacific Ocean, to the south of the isthmus of Panama) as opposed to the "North Sea" (the Caribbean Sea, to the north of the same isthmus).
The Caribbean Sea had been unknown to the populations of Eurasia until 1492, when Christopher Columbus first sailed into Caribbean waters on a quest to find a sea route to Asia. At that time the Western Hemisphere in general was unknown to Europeans. Following the discovery of the islands by Columbus, the area was quickly colonised by several Western cultures (initially Spain, then later Portugal, England, the Dutch Republic, France, Courland and Denmark). Following the colonisation of the Caribbean islands, the Caribbean Sea became a busy area for European-based marine trading and transport, and this commerce eventually attracted piracy.
Due to the abundance of sunshine, year-round tropical temperatures moderated by the almost constant trade winds, and the great variety of scenic destinations to visit, during the second half of the 20th century and on into the 21st, the Caribbean Sea became a popular place for tourism.
Extent.
The International Hydrographic Organization defines the limits of the Caribbean Sea as follows:
Note that, although Barbados is an island on the same continental shelf, it is considered to be in the Atlantic Ocean rather than the Caribbean Sea.
Geology.
The Caribbean Sea is an oceanic sea largely situated on the Caribbean Plate. The Caribbean Sea is separated from the ocean by several island arcs of various ages. The youngest of them stretches from the Lesser Antilles to the Virgin Islands to the north east of Trinidad and Tobago off the coast of Venezuela. This arc was formed by the collision of the South American Plate with the Caribbean Plate and includes active and extinct volcanoes such as Mount Pelee, the Quill (volcano) on Sint Eustatius in the Caribbean Netherlands and Morne Trois Pitons on Dominica. The larger islands in the northern part of the sea Cuba, Hispaniola, Jamaica and Puerto Rico lie on an older island arc. The geological age of the Caribbean Sea is not known with certainty but is estimated to have an age between 160 and 180 million years and was formed by a horizontal fracture that split the supercontinent called Pangea in the Mesozoic Era. It is assumed that the proto-caribbean basin existed in the Devonian period. In the early Carboniferous movement of Gondwana to the north and its convergence with the Euramerica basin decreased in size. The next stage of the formation of the Caribbean Sea began in the Triassic. Powerful rifting led to the formation of narrow troughs, stretching from modern Newfoundland to the west coast of the Gulf of Mexico which formed siliciclastic sedimentary rocks. In the early Jurassic due to powerful marine transgression, water broke into the present area of the Gulf of Mexico creating a vast shallow pool here. The emergence of deep basins in the Caribbean occurred during the era of the Middle Jurassic rifting. The emergence of these basins marked the beginning of the Atlantic Ocean and contributed to the destruction of Pangaea at the end of the late Jurassic. During the Cretaceous the Caribbean acquired the shape close to that seen today. In the early Paleogene due to Marine regression the Caribbean became separated from the Gulf of Mexico and the Atlantic Ocean by the land of Cuba and Haiti. The Caribbean remained like this for most of the Cenozoic until the Holocene when rising water levels of the oceans restored communication with the Atlantic Ocean.
The floor of the Caribbean is composed of sub-oceanic sediments of deep red clay in the deep basins and troughs. On continental slopes and ridges calcareous silts are found. Clay minerals likely having been deposited by the mainland river Orinoco and the Magdalena River. Deposits on the bottom of the Caribbean Sea and Gulf of Mexico have a thickness of about 1 km. Upper sedimentary layers relate to the period from the Mesozoic to the Cenozoic (250 million years ago to present) and the lower layers from the Paleozoic to the Mesozoic.
The Caribbean sea floor is divided into five basins separated from each other by underwater ridges and mountain ranges. Atlantic Ocean water enters the Caribbean through the "Anegada Passage" lying between the Lesser Antilles and Virgin Islands and the "Windward Passage" located between Cuba and Haiti. The Yucatán Channel between Mexico and Cuba links the Gulf of Mexico with the Caribbean. The deepest points of the sea lie in Cayman Trough with depths reaching approximately 7,686 m (25,220 ft). Despite this, the Caribbean Sea is considered a relatively shallow sea in comparison to other bodies of water.
The pressure of the South American Plate to the east of the Caribbean causes the region of the Lesser Antilles to have high volcanic activity. There was a very serious eruption of Mount Pelée in 1902 which caused many casualties.
The Caribbean sea floor is also home to two oceanic trenches: the Cayman Trench and Puerto Rico Trench, which put the area at a high risk of earthquakes. Underwater earthquakes pose a threat of generating tsunamis which could have a devastating effect on the Caribbean islands. Scientific data reveals that over the last 500 years the area has seen a dozen earthquakes above 7.5 magnitude. Most recently, a 7.1 earthquake struck Haiti on January 12, 2010.
Oceanography.
The hydrology of the sea has a high level of homogeneity. Annual variations in monthly average water temperatures at the surface do not exceed 3 °C. Over the past fifty years the Caribbean has gone through three stages: cooling until 1974; a cold phase with peaks during 1974-1976 and 1984-1986 then; a warming phase with increase in temperature of 0.6 °C per year. Virtually all temperature extremes were associated with the phenomena of el Niño and la Niña. The salinity of sea water is about 3.6% and its density is 1.0235-1.0240 103 kg/m3. The surface water colour is blue-green to green.
Ecology.
The Caribbean is home to about 9% of the world's coral reefs covering about , most of which are located off the Caribbean Islands and the Central American coast. Among them stands out the Belize Barrier Reef with an area of 96,300 ha which was declared a World Heritage Site in 1996. It forms part of the Great Mayan Reef also known as the MBRS and being over a thousand km in length is the world's second longest. It runs along the Caribbean coasts of Mexico, Belize, Guatemala and Honduras.
During the past ten years, unusually warm Caribbean waters have been increasingly threatening Caribbean coral reefs. Coral reefs support some of the most diverse marine habitats in the world, but they are fragile ecosystems. When tropical waters become unusually warm for extended periods of time, microscopic plants called zooxanthellae, which are symbiotic partners living within the coral polyp tissues, die off. These plants provide food for the corals, and give them their color. The result of the death and dispersal of these tiny plants is called coral bleaching, and can lead to the devastation of large areas of reef. Over 42% of corals are completely bleached and 95% are experiencing some type of whitening.
The habitats supported by the reefs are critical to such tourist activities as fishing and diving, and provide an annual economic value to Caribbean nations of $3.1-$4.6 billion. Continued destruction of the reefs could severely damage the region's economy. A "Protocol of the Convention for the Protection and Development of the Marine Environment of the Wider Caribbean Region" came in effect in 1986 to protect the various endangered marine life of the Caribbean through forbidding human activities that would advance the continued destruction of such marine life in various areas. Currently this protocol has been ratified by 15 countries. Also several charitable organisations have been formed to preserve the Caribbean marine life, such as "Caribbean Conservation Corporation" which seeks to study and protect sea turtles while educating others about them.
In connection with the foregoing, the Institute of Marine Sciences and Limnology of the National Autonomous University of Mexico, conducted a regional study, funded by the Department of Technical Cooperation of the International Atomic Energy Agency, in which specialists from 11 Latin American countries (Colombia, Costa Rica, Cuba, Guatemala, Haiti, Honduras, Mexico, Nicaragua, Panama, Dominican Republic, Venezuela plus Jamaica) participated. The findings indicate that heavy metals such as mercury, arsenic and lead, have been identified in the coastal zone of the Caribbean Sea. Analysis of toxic metals and hydrocarbons is based on the investigation of coastal sediments that have accumulated less than 50 meters deep during the last hundred and fifty years. The project results were presented in Vienna in the forum "Water Matters", and the 2011 General Conference of said multilateral organization.
Weather.
The Caribbean weather is influenced by the Gulf Stream and Humboldt Current ocean currents. The tropical location of the sea helps the water to maintain a warm temperature ranging from the low of by the season.
The Caribbean is a focal area for many hurricanes within the Western Hemisphere. A series of low pressure systems develop off the West coast of Africa and make their way across the Atlantic Ocean. While most of these systems do not become tropical storms, some do. The tropical storms can develop into Atlantic hurricanes, often in the low pressure areas of the eastern Caribbean. The Caribbean hurricane season as a whole lasts from June through November, with the majority of hurricanes occurring during August and September. On average around 9 tropical storms form each year, with 5 reaching hurricane strength. According to the National Hurricane Center 385 hurricanes occurred in the Caribbean between 1494 and 1900.
Every year hurricanes represent a potential threat to the islands of the Caribbean, due to the extremely destructive nature of these powerful weather systems. Coral reefs can easily be damaged by violent wave action, and can be destroyed when a hurricane dumps sand or mud onto a reef. When this happens, the coral organisms are smothered and the reef dies and ultimately breaks apart.
Flora and fauna.
The region has a high level of biodiversity and many species are endemic to the Caribbean.
Vegetation.
The vegetation of the region is mostly tropical but differences in topography, soil and climatic conditions increase species diversity. Where there are porous limestone terraced islands these are generally poor in nutrients. It is estimated that 13 thousand species of plants grow in the Caribbean of which 6.5 thousand are endemic. For example, guaiac wood ("Guaiacum officinale"), the flower of which is the national flower of Jamaica and the Bayahibe rose ("Pereskia quisqueyana") which is the national flower of the Dominican Republic and the ceiba which is the national tree of both Puerto Rico and Guatemala. The mahogany is the national tree of the Dominican Republic and Belize. The caimito ("Chrysophyllum cainito") grows throughout the Caribbean. In coastal zones there are coconut palms and in lagoons and estuaries are found thick areas of black mangrove and red mangrove ("Rhizophora mangle").
In shallow water flora and fauna is concentrated around coral reefs where there is little variation in water temperature, purity and salinity. Leeward side of lagoons provide areas of growth for sea grasses. Turtle grass ("Thalassia testudinum") is common in the Caribbean as is manatee grass ("Syringodium filiforme") which can grow together as well as in fields of single species at depths up to 20 metres. Another type shoal grass ("Halodule wrightii") grows on sand and mud surfaces at depths of up to 5 metres. In brackish water of harbours and estuaries at depths less than 2.5 metres widgeongrass ("Ruppia maritima") grows. Representatives of three species belonging to the genus "Halophila", ("Halophila baillonii", "Halophila engelmani" and "Halophila decipiens") are found at depths of up to 30 metres except for "Halophila engelmani" which does not grow below 5 metres and is confined to the Bahamas, Florida, the Greater Antilles and the western part of the Caribbean. "Halophila baillonii" has been found only in the Lesser Antilles.
Fauna.
Marine biota in the region have representatives of both the Indian and Pacific oceans which were caught in the Caribbean before the emergence of the Isthmus of Panama four million years ago. In the Caribbean Sea there are around 1,000 documented species of fish, including sharks (bull shark, tiger shark, silky shark and Caribbean reef shark), flying fish, giant oceanic manta ray, angel fish, spotfin butterflyfish, parrotfish, Atlantic Goliath grouper, tarpon and moray eels. Throughout the Caribbean there is industrial catching of lobster and sardines (off the coast of Yucatán Peninsula).
There are 90 species of mammals in the Caribbean including sperm whales, humpback whales and dolphins. The island of Jamaica is home to seals and manatees. The Caribbean monk seal which lived in the Caribbean is considered extinct. The solenodon is endangered.
There are 500 species of reptiles (94% of which are endemic). Islands are inhabited by some endemic species such as rock iguanas and American crocodile. The green iguana and the blue iguana both endemic to the island of Grand Cayman are endangered. The Mona ground iguana which inhabits the island of Mona, Puerto Rico, is endangered. The rhinoceros iguana from the island of Hispaniola which is shared between Haiti and the Dominican Republic is also endangered. The region has several types of sea turtle (loggerhead, green turtle, hawksbill, leatherback turtle, Atlantic ridley and olive ridley). Some species are threatened with extinction. Their populations have been greatly reduced since the 17th century - the number of green turtles has declined from 91 million to 300,000 and hawksbill turtles from 11 million to less than 30,000 by 2006.
All 170 species of amphibians that live in the region are endemic. The habitats of almost all members of the toad family, poison dart frogs, tree frogs and leptodactylidae (a type of frog) are limited to only one island. The Golden coqui is in serious threat of extinction.
In the Caribbean 600 species of birds have been recorded of which 163 are endemic such as the tody, Fernandina's flicker and palmchat. The American yellow warbler is found in many areas as is the green heron. Of the endemic species 48 are threatened with extinction including the Puerto Rican amazon, yellow-breasted crake and the Zapata wren. According to Birdlife International in 2006 in Cuba 29 species of bird are in danger of extinction and two species officially extinct. The black-fronted piping guan is endangered as is the plain pigeon. The Antilles along with Central America lie in the flight path of migrating birds from North America so the size of populations is subject to seasonal fluctuations. In the forests are found parrots, bananaquit and toucans. Over the open sea can be seen frigatebirds and tropicbirds.
Economy and human activity.
The Caribbean region has seen a significant increase in human activity since the colonisation period. The sea is one of the largest oil production areas in the world, producing approximately 170 million tons per year. The area also generates a large fishing industry for the surrounding countries, accounting for half a million metric tons of fish a year.
Human activity in the area also accounts for a significant amount of pollution, The Pan American Health Organization estimated in 1993 that only about 10% of the sewage from the Central American and Caribbean Island countries is properly treated before being released into the sea.
The Caribbean region supports a large tourist industry. The "Caribbean Tourism Organization" calculates that about 12 million people a year visit the area, including (in 1991–1992) about 8 million cruise ship tourists. Tourism based upon scuba diving and snorkeling on coral reefs of many Caribbean islands makes a major contribution to their economies.
Popular culture.
The Caribbean is the setting for countless literary efforts often related to piracy acts and swashbuckling. One memorable work of pulp fiction has in its title a geographic feature unique in its way to the islands: "Fear Cay", the eleventh Doc Savage adventure by Lester Dent. Many James Bond adventures were set there. All of the action of the Monkey Island series videogames takes place within the Caribbean Sea area. It is also well known as the location of the Pirates of the Caribbean films, featuring Port Royal. Less swashbuckling, but not lacking in man-against-the-sea exploits, is Peter Matthiessen's "Far Tortuga" (1975), which chronicles the adventures of a turtling crew in the late 1960s.
The video game series "Assassin's Creed" features the Caribbean as an important place in its timeline. For example, "", along with its "Freedom Cry" DLC, entirely takes place in the Caribbean Sea, while some events also occur in the Caribbean in "Assassin's Creed III" to stop further British expeditions during the American Revolutionary War.

</doc>
<doc id="7824" url="https://en.wikipedia.org/wiki?curid=7824" title="Colin Maclaurin">
Colin Maclaurin

Colin Maclaurin (February 1698 – 14 June 1746) was a Scottish mathematician who made important contributions to geometry and algebra. The Maclaurin series, a special case of the Taylor series, is named after him.
Owing to changes in orthography since that time (his name was originally rendered as “M‘Laurine”), his surname is alternatively written MacLaurin.
Early life.
Maclaurin was born in Kilmodan, Argyll. His father, Reverend and Minister of Glendaruel John Maclaurin, died when Maclaurin was in infancy, and his mother died before he reached nine years of age. He was then educated under the care of his uncle, the Reverend Daniel Maclaurin, minister of Kilfinan.
Academic career.
At eleven, Maclaurin entered the University of Glasgow. He graduated MA three years later by defending a thesis on "the Power of Gravity," and remained at Glasgow to study divinity until he was 19, when he was elected professor of mathematics in a ten-day competition at the Marischal College in the University of Aberdeen. This record as the world's youngest professor endured until March 2008, when the record was officially given to Alia Sabur.
In the vacations of 1719 and 1721, Maclaurin went to London, where he became acquainted with Sir Isaac Newton, Dr. Hoadley, Dr. Samuel Clarke, Martin Folkes, and other eminent philosophers. He was admitted a member of the Royal Society.
In 1722, having provided a substitute for his class at Aberdeen, he traveled on the Continent as tutor to George Hume, the son of Alexander Hume, 2nd Earl of Marchmont. During their time in Lorraine, he wrote his essay on the "Percussion of Bodies", which gained the prize of the Royal Academy of Sciences in 1724. Upon the death of his pupil at Montpellier, Maclaurin returned to Aberdeen.
In 1725 Maclaurin was appointed deputy to the mathematical professor at Edinburgh, James Gregory (brother of David Gregory and nephew of the esteemed James Gregory), upon the recommendation of Isaac Newton. On 3 November of that year Maclaurin succeeded Gregory, and went on to raise the character of that university as a school of science. Newton was so impressed with Maclaurin that he had offered to pay his salary himself.
Contributions to mathematics.
Maclaurin used Taylor series to characterize maxima, minima, and points of inflection for infinitely differentiable functions in his "Treatise of Fluxions". Maclaurin attributed the series to Taylor, though the series was known before to Newton and Gregory, and in special cases to Madhava of Sangamagrama in fourteenth century India.
Nevertheless, Maclaurin received credit for his use of the series, and the Taylor series expanded around 0 is sometimes known as the "Maclaurin series" .
Maclaurin also made significant contributions to the gravitation attraction of ellipsoids, a subject that furthermore attracted the attention of d'Alembert, A.-C. Clairaut, Euler, Laplace, Legendre, Poisson and Gauss. Maclaurin showed that an oblate spheroid was a possible equilibrium in Newton's theory of gravity. The subject continues to be of scientific interest, and Nobel Laureate Subramanyan Chandrasekhar dedicated a chapter of his book "Ellipsoidal Figures of Equilibrium" to Maclaurin spheroids. 
Independently from Euler and using the same methods, Maclaurin discovered the Euler–Maclaurin formula. He used it to sum powers of arithmetic progressions, derive Stirling's formula, and to derive the Newton-Cotes numerical integration formulas which includes Simpson's rule as a special case. 
Maclaurin contributed to the study of elliptic integrals, reducing many intractable integrals to problems of finding arcs for hyperbolas. His work was continued by d'Alembert and Euler, who gave a more concise approach.
In his Treatise of Algebra (Ch. XII, Sect 86), published in 1748, two years after his death, Maclaurin proved a rule for solving square linear systems in the cases of 2 and 3 unknowns, and discussed the case of 4 unknowns.
Personal life.
In 1733, Maclaurin married Anne Stewart, the daughter of Walter Stewart, the Solicitor General for Scotland, by whom he had seven children.
Maclaurin actively opposed the Jacobite Rebellion of 1745 and superintended the operations necessary for the defence of Edinburgh against the Highland army. Maclaurin compiled a diary of his exertions against the Jacobites, both within and without the city. When the Highland army entered the city, however, he fled to York, where he was invited to stay by the Archbishop of York.
On his journey south, Maclaurin fell from his horse, and the fatigue, anxiety, and cold to which he was exposed on that occasion laid the foundations of dropsy. He returned to Edinburgh after the Jacobite army marched south, but died soon after his return.
He is buried at Greyfriars Kirkyard, Edinburgh.
Mathematician and former MIT President Richard Cockburn Maclaurin was from the same family.
Notable works.
Some of his important works are:
Colin Maclaurin was the name used for the new Mathematics and Actuarial Mathematics and Statistics Building at Heriot-Watt University, Edinburgh.

</doc>
<doc id="7827" url="https://en.wikipedia.org/wiki?curid=7827" title="Covenant-breaker">
Covenant-breaker

A Covenant-breaker or the act of Covenant-breaking is a term used by Bahá'ís to refer to a form of disunity: "The specific mission of Bahá'u'lláh relates to world unity. Since it would be impossible for the Bahá'í Faith to unite the world if it were itself disunited, the role of the covenant as the guarantor of the unity of the Bahá'í community becomes inextricably linked with the goal of world unity: "It is evident that the axis of oneness of the world of humanity is the power of the Covenant and nothing else." (TDP 49, cf GPB 239, SWA 208-9).
Being declared a Covenant-breaker is done by the head of the Faith — which is the Universal House of Justice, which has nine members and is the governing body of the Bahá'ís since 1963. Bahá'ís avoid association with Covenant-breakers, even if they are a family member. 
Definition.
Covenant-breaking does not refer to attacks from non-Bahá'ís or former Baha'is. Rather, it is in reference to internal campaigns of opposition where the Covenant-breaker is challenging the unity of the Faith, causing internal division, or by claiming or supporting an alternate succession of authority or administrative structure. The central purpose of the covenant is to prevent schism and dissension.
In a letter to an individual dated 23 March 1975, the Universal House of Justice wrote:
The term 'Covenant-breaker' or, in Arabic 'naqid al-mithaq' Naqidu 'l-mithaq, was first used by `Abdu'l-Bahá to describe the partisans of his brother Mírzá Muhammad `Alí, who challenged his leadership. In `Abdu'l-Bahá's Will and Testament, He appointed Shoghi Effendi as the "Guardian" of the religion and called for the eventual election of the Universal House of Justice, and defined in the same manner opposition to these two institutions as Covenant-Breaking. `Abdu'l-Bahá advised all Bahá'ís to shun anyone opposing the Covenant: "...one of the greatest and most fundamental principles of the Cause of God is to shun and avoid entirely the Covenant-breakers, for they will utterly destroy the Cause of God, exterminate His Law and render of no account all efforts exerted in the past."
Categorization.
Included categories of people.
While most Covenant-breakers are involved in schismatic groups, that is not always the case. For example, a Bahá'í who refuses to follow guidance on treatment of Covenant-breakers is at risk of being named one. One article originally written for the Bahá'í Encyclopedia, characterized Covenant-breakers that have emerged in the course of Bahá'í history as belonging to one of four categories:
Excluded categories of people.
Shoghi Effendi wrote to the National Spiritual Assembly of Canada in 1957:
Beyond this, many other relationships to the Bahá'í Faith exist, both positive and negative. Covenant-breaking does not apply to most of them. The following is a partial list of those who could not rightly be termed Covenant-breakers:
Bábís.
Bábís are generally regarded as another religion altogether. Since Covenant-breaking presumes that one has submitted oneself to a covenant and then broken it, and Bábís never recognized or swore allegiance to Bahá'u'lláh, they are not Covenant-breakers.
Followers of Subh-i-Azal, Bahá'u'lláh's half-brother who tried to poison him, engaged in active opposition to Bahá'ís, and Shoghi Effendi did inform Bahá'ís that they should avoid contact with his descendants, writing that "No intelligent and loyal Baha'i would associate with a descendant of Azal, if he traced the slightest breath of criticism of our Faith, in any aspect, from that person. In fact these people should be strenuously avoided as having an inherited spiritual disease -- the disease of Covenant-breaking!".
Covenant-Breaking in Shoghi Effendi's immediate family.
Through the influence of Bahiyyih Khanum, the eldest daughter of Bahá'u'lláh, everyone in the household initially rallied around Shoghi Effendi after the death of `Abdu'l-Bahá. For several years his brother Husayn and several cousins served him as secretaries. The only ones publicly opposing him were Mirza Muhammad-Ali and his followers, who were declared Covenant-breakers by `Abdu'l-Bahá. Contrary to `Abdu'l-Bahá's specific instruction, certain family members established illicit links with those declared Covenant-breakers by `Abdu'l-Bahá. After Bahiyyih Khanum died in 1932, Shoghi Effendi's eldest sister--Ruhangiz --married a son of Siyyid Ali Afnan. Bahá'u'lláh's son-in-law was, thus, a long-standing enemy of `Abdu'l-Bahá (who had declared him a Covenant-breaker.) Through Ruhangiz's efforts, Shoghi Effendi's other sister and his cousin Thurayya also married sons of Siyyid Ali Afnan. Presumably being faced with a choice between shunning their disobedient family members and being themselves disobedient to `Abdu'l-Bahá and Shoghi Effendi, his cousins, aunts and uncles chose the latter.
Ruhi Afnan.
After years of silence on these developments, cables sent by Shoghi Effendi on 2 November 1941 provide background to developments among family members. Ruhi Afnan, Shoghi Effendi's cousin through `Abdu'l-Bahá's daughter Tuba:
Then in a 1950 cable:
And in 1953:
Later, Ruhi was presented with a copy of Sohrab's book about his excommunication:
Munib Shahid.
Concerning Munib Shahid, Shoghi Effendi's cousin through `Abdu'l-Bahá's daughter Ruha, Shoghi Effendi sent the following cable to the Bahá'í world in November 1944:
Husayn.
Concerning his own brother Husayn, Shoghi Effendi sent the following cable to the Bahá'í world in April 1945:
Riaz.
Concerning his own brother Riaz, the following cable was sent in December 1951:
Mehrangiz.
He dispatched a cable concerning his younger sister in December 1941:
Resultant groups.
Most of the groups regarded by the larger group of Bahá'ís as Covenant-breakers originated in the claims of Charles Mason Remey to the Guardianship in 1960. The Will and Testament of `Abdu'l-Bahá states that Guardians should be lineal descendants of Bahá'u'lláh, that each Guardian must select his successor during his lifetime, and that the nine Hands of the Cause of God permanently stationed in the holy land must approve the appointment by majority vote. Bahá'ís interpret lineal descendency to mean physical familial relation to Bahá'u'lláh, of which Mason Remey was not.
Almost all of Bahá'ís accepted the determination of the Hands of the Cause that upon the death of Shoghi Effendi, he died "without having appointed his successor". There was an absence of a valid descendant of Bahá'u'lláh who could qualify under the terms of `Abdu'l-Bahá's will. Later the Universal House of Justice, initially elected in 1963, made a ruling on the subject that it was not possible for another Guardian to be appointed.
In 1960 Remey, a Hand of the Cause himself, retracted his earlier position, and claimed to have been coerced. He claimed to be the successor to Shoghi Effendi. He and the small number of people who followed him were expelled from the Faith by the Hands of the Cause. Those close to Remey claimed that he went senile in old age, and by the time of his death he was largely abandoned, with his most prominent followers fighting amongst themselves for leadership. needed.
The largest group of the remaining followers of Remey, members of the so called "Orthodox Bahá'í Faith", believe that legitimate authority passed from Shoghi Effendi to Mason Remey to Joel Marangella. needed. They, therefore, regard the Universal House of Justice in Haifa, Israel to be illegitimate, and its members and followers to be Covenant-breakers. needed.
The present descendants of expelled members of Bahá'u'lláh's family have not specifically been declared Covenant-breakers, though they mostly do not associate themselves with the Bahá'í religion. needed. A small group of Bahá'ís in Northern New Mexico believe that these descendants are eligible for appointment to the Guardianship and are waiting for such a direct descendant of Bahá'u'lláh to arise as the rightful Guardian.
There is also a small group in Montana, originally formed around the personality of Leland Jensen, who claimed a status higher than that of the Guardian. His failed apocalyptic predictions and unsuccessful efforts to reestablish the Guardianship and the administration were apparent by his death in 1996. A dispute among Jensen's followers over the identity of the Guardian resulted in another division in 2001.needed.

</doc>
<doc id="7828" url="https://en.wikipedia.org/wiki?curid=7828" title="Concord, Michigan">
Concord, Michigan

Concord is a village in Jackson County in the U.S. state of Michigan. The population was 1,050 at the 2010 census. The village is located at , west of Spring Arbor, Michigan.
History.
Concord first received a post office in 1836. It was incorporated as a village in 1871.
The Michigan Historical Center operates a museum in Concord called the Mann House. The Mann House is an excellent example of typical middle-class domestic architecture of the early 1880s and features the family's sleigh and buggy as well as Jackson's Michigan State Prison made furniture.
Government.
Concord is a general-law village incorporated within the Township of Concord.
Geography.
According to the United States Census Bureau, the village has a total area of , of which is land and is water.
The village is located within the T3S R3W survey township.
Demographics.
Concord Community Schools (Enrollment 900) participate in Class C and Division 4 of MHSAA athletics. Their teams are known as the Yellow Jackets and play in the Big 8 Conference. The schools' colors are purple and gold. The boys' cross country and track & field teams both claimed MHSAA State Championships during the 2009–10 school year. In 2011 and 2012, the boys cross country team won back to back MHSAA State Championships.
2010 census.
As of the census of 2010, there were 1,050 people, 412 households, and 293 families residing in the village. The population density was . There were 484 housing units at an average density of . The racial makeup of the village was 99.0% White, 0.3% African American, 0.1% Native American, 0.1% Asian, 0.1% from other races, and 0.4% from two or more races. Hispanic or Latino of any race were 1.8% of the population.
There were 412 households of which 33.7% had children under the age of 18 living with them, 54.6% were married couples living together, 10.4% had a female householder with no husband present, 6.1% had a male householder with no wife present, and 28.9% were non-families. 25.7% of all households were made up of individuals and 12.6% had someone living alone who was 65 years of age or older. The average household size was 2.55 and the average family size was 3.02.
The median age in the village was 40.9 years. 26% of residents were under the age of 18; 8.3% were between the ages of 18 and 24; 21.4% were from 25 to 44; 28.7% were from 45 to 64; and 15.6% were 65 years of age or older. The gender makeup of the village was 48.9% male and 51.1% female.
2000 census.
As of the census of 2000, there were 1,101 people, 428 households, and 308 families residing in the village. The population density was 748.4 per square mile (289.2/km²). There were 499 housing units at an average density of 339.2 per square mile (131.1/km²). The racial makeup of the village was 97.91% White, 0.09% Black or African American, 0.27% Native American, 0.73% Asian, 0.64% from other races, and 0.36% from two or more races. 0.82% of the population were Hispanic or Latino of any race.
There were 428 households out of which 34.3% had children under the age of 18 living with them, 57.9% were married couples living together, 10.7% had a female householder with no husband present, and 28.0% were non-families. 25.0% of all households were made up of individuals and 10.5% had someone living alone who was 65 years of age or older. The average household size was 2.57 and the average family size was 3.09.
In the village the population was spread out with 28.1% under the age of 18, 7.5% from 18 to 24, 28.2% from 25 to 44, 21.7% from 45 to 64, and 14.5% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 92.8 males. For every 100 females age 18 and over, there were 87.7 males.
The median income for a household in the village was $46,500, and the median income for a family was $54,531. Males had a median income of $39,167 versus $23,594 for females. The per capita income for the village was $19,348. About 4.8% of families and 5.2% of the population were below the poverty line, including 3.1% of those under age 18 and 7.1% of those age 65 or over.

</doc>
<doc id="7829" url="https://en.wikipedia.org/wiki?curid=7829" title="Chaos Computer Club">
Chaos Computer Club

The Chaos Computer Club (CCC) is Europe's largest association of hackers. The CCC is based in Germany and other German-speaking countries.
The CCC describes itself as "a galactic community of life forms, independent of age, sex, race or societal orientation, which strives across borders for freedom of information..." In general, the CCC advocates more transparency in government, freedom of information, and the human right to communication. Supporting the principles of the hacker ethic, the club also fights for free universal access to computers and technological infrastructure. It has been characterized as "...one of the most influential digital organisations anywhere, the centre of German digital culture, hacker culture, hacktivism, and the intersection of any discussion of democratic and digital rights."
History.
The CCC was founded in Berlin on September 12, 1981 at a table which had previously belonged to the Kommune 1 in the rooms of the newspaper Die Tageszeitung by Wau Holland and others in anticipation of the prominent role that information technology would play in the way people live and communicate.
The CCC became world famous when they drew public attention to the security flaws of the German Bildschirmtext computer network by causing it to debit DM 134,000 in a Hamburg bank in favor of the club. The money was returned the next day in front of the press. Prior to the incident, the system provider had failed to react to proof of the security flaw provided by the CCC, claiming to the public that their system was safe. Bildschirmtext was the biggest commercially available online system targeted at the general public in its region at that time, run and heavily advertised by the German telecommunications agency Deutsche Bundespost which also strove to keep up-to-date alternatives out of the market.
In 1987, the CCC was peripherally involved in the first cyberespionage case to make international headlines. A group of German hackers led by Karl Koch, who was loosely affiliated with the CCC, was arrested for breaking into US government and corporate computers, and then selling operating-system source code to the Soviet KGB.
Several of the CCC's early exploits are documented in a paper, written by Digital Equipment Corporation's lead European Investigator of the CCC's activities in the 1980s and 1990s. These include the CCC protests against French nuclear tests and members of the CCC involved with the German Green Party.
The CCC is more widely known for its public demonstrations of security risks. In 1996, CCC members demonstrated an attack against Microsoft's ActiveX technology, changing personal data in a Quicken database. In April 1998, the CCC successfully demonstrated the cloning of a GSM customer card, breaking the COMP128 encryption algorithm used at that time by many GSM SIMs.
In 2001, the CCC celebrated its twentieth birthday with an interactive light installation dubbed Project Blinkenlights that turned the building Haus des Lehrers in Berlin into a giant computer screen. A follow up installation (dubbed "Arcade") at the Bibliothèque nationale de France was the world's biggest light installation.
In March 2008, the CCC acquired and published the fingerprints of German Minister of the Interior Wolfgang Schäuble. The magazine also included the fingerprint on a film that readers could use to fool fingerprint readers. This was done to protest the use of biometric data in German identity devices such as e-passports.
Later in October 2008, CCC's Project Blinkenlights went to Toronto, Canada with project Stereoscope.
Staatstrojaner.
The Staatstrojaner ("Federal Trojan horse") is a computer surveillance program installed secretly on a suspect's computer, which the German police uses to wiretap Internet telephony. This "source wiretapping" is the only feasible way to wiretap in this case, since Internet telephony programs will usually encrypt the data when it leaves the computer. The Federal Constitutional Court of Germany has ruled that the police may only use such programs for telephony wiretapping, and for no other purpose, and that this restriction should be enforced through technical and legal means.
On October 8, 2011, the CCC published an analysis of the Staatstrojaner software. The software was found to have the ability to remote control the target computer, to capture screenshots, and to fetch and run arbitrary extra code. The CCC says that having this functionality built in is in direct contradiction to the ruling of the constitutional court.
In addition, there were a number of security problems with the implementation. The software was controllable over the Internet, but the commands were sent completely unencrypted, with no checks for authentication or integrity. This leaves any computer under surveillance using this software vulnerable to attack. The captured screenshots and audio files were encrypted, but so incompetently that the encryption was ineffective. All captured data was sent over a proxy server in the United States, which is problematic since the data is then temporarily outside the German jurisdiction.
The CCC's findings were widely reported in the German press. This trojan has also been nicknamed R2D2 because the string "C3PO-r2d2-POE" was found in its code; another alias for it is 0zapftis. According to a Sophos analysis, the trojan's behavior matches that described in a confidential memo between the German Landeskriminalamt and a software firm called DigiTask; the memo was leaked on WikiLeaks in 2008. Among other correlations is the dropper's file name scuinst.exe, short for Skype Capture Unit Installer. The 64-bit Windows version installs a digitally signed driver, but signed by the non-existing certificate authority "Goose Cert". DigiTask later admitted selling spy software to governments.
The Federal Ministry of the Interior released a statement in which they denied that R2D2 has been used by the Federal Criminal Police Office (BKA); this statement however does not eliminate the possibility that it has been used by state-level German police forces. The BKA had previously announced however (in 2007) that they had somewhat similar trojan software that can inspect a computer's hard drive.
Events.
The CCC hosts the annual Chaos Communication Congress, Europe's biggest hacker gathering. The event moved from Berlin to Hamburg in 2012, and drew 9,000 guests attendees in 2013. Every four years, the Chaos Communication Camp is the outdoor alternative for hackers worldwide.
The CCC started a new yearly conference called SIGINT in May 2009 in Cologne, though it was discontinued in 2014.
Another yearly CCC event taking place on the Easter weekend is the Easterhegg, which is more workshop oriented than the other events.
Members of the CCC also participate in various technological and political conferences around the planet.
Publications.
The CCC publishes the quarterly magazine "Datenschleuder" ("data slingshot") since 1984, and the CCC in Berlin also produces a monthly radio show called which picks up various technical and political topics in a two-hour talk radio show. The program is aired on a local radio station named . There is also a podcast spin-off named "CRE", an international podcast called "Chaosradio International" (which as of 2012 has been inactive for several years), and other radio programs offered by some regional Chaos Groups.
Members.
Famous members are co-founder Wau Holland and Andy Müller-Maguhn, who was a member of the ICANN board of directors for Europe until 2002, and Karl Koch, who was a Cold War-era hacker featured in the movie "23". Former WikiLeaks spokesman Daniel Domscheit-Berg was expelled from the national CCC in August 2011, despite not actually being a member, during its quadrennial camp. This decision was revoked on February 2012.
Chaos Computer Club France.
The Chaos Computer Club France (CCCF) was a fake hacker organization created in 1989 in Lyon (France) by Jean-Bernard Condat, under the command of Jean-Luc Delacour, an agent of the Direction de la surveillance du territoire governmental agency. The primary goal of the CCCF was to watch and to gather information about the French hacker community. Journalist Jean Guisnel said that this organization also worked with the French National Gendarmerie.
The name of the organization is directly inspired by the name of the German Chaos Computer Club organization, which in contrast is a real hacker organization.
The CCCF had an electronic magazine called "Chaos Digest (ChaosD)". Between January 4, 1993 and August 5, 1993, seventy-three issues were published ().

</doc>
<doc id="7830" url="https://en.wikipedia.org/wiki?curid=7830" title="Convention (norm)">
Convention (norm)

A convention is a set of agreed, stipulated, or generally accepted standards, norms, social norms, or criteria, often taking the form of a custom.
Certain types of rules or customs may become law and regulatory legislation may be introduced to formalize or enforce the convention (for example, laws that define on which side of the road vehicles must be driven). In a social context, a convention may retain the character of an "unwritten law" of custom (for example, the manner in which people greet each other, such as by shaking each other's hands).
In physical sciences, numerical values (such as constants, quantities, or scales of measurement) are called conventional if they do not represent a measured property of nature, but originate in a convention, for example an average of many measurements, agreed between the scientists working with these values.
General.
A convention is a selection from among two or more alternatives, where the rule or alternative is agreed upon among participants. Often the word refers to unwritten customs shared throughout a community. For instance, it is conventional in many societies that strangers being introduced shake hands. Some conventions are explicitly legislated; for example, it is conventional in the United States and in Germany that motorists drive on the right side of the road, whereas in New Zealand, England, Australia, Mauritius, and Barbados motorists drive on the left. The standardization of time is a human convention based on the solar cycle or calendar. The extent to which justice is conventional (as opposed to natural or objective) is historically an important debate among philosophers.
The nature of conventions has raised long-lasting philosophical discussion. Quine, Davidson, and David Lewis published influential writings on the subject. Lewis's account of convention received an extended critique in Margaret Gilbert's "On Social Facts" (1989), where an alternative account is offered. Another view of convention comes from Ruth Millikan's "Language: A Biological Model" (2005), once more against Lewis.
According to David Kalupahana, The Buddha described conventions — whether linguistic, social, political, moral, ethical, or even religious — as arising dependent on specific conditions. According to his paradigm, when conventions are considered absolute realities, they contribute to dogmatism, which in turn leads to conflict. This does not mean that conventions should be absolutely ignored as unreal and therefore useless. Instead, according to Buddhist thought, a wise person adopts a middle way without holding conventions to be ultimate or ignoring them when they are fruitful.
Customary or social conventions.
Social.
In sociology a "social rule" refers to any social convention commonly adhered to in a society. These "rules" are not written in law or otherwise formalized. In social constructionism there is a great focus on social rules. It is argued that these rules are socially constructed, that these rules act upon every member of a society, but at the same time, are re-produced by the individuals.
Sociologists representing symbolic interactionism argue that social rules are created through the interaction between the members of a society. The focus on active interaction highlights the fluid, shifting character of social rules. These are specific to the social context, a context that varies through time and place. That means a social rule changes over time within the same society. What was acceptable in the past may no longer be the case. Similarly, rules differ across space: what is acceptable in one society may not be so in another.
Social rules reflect what is "acceptable" or "normal" behaviour in any situation. Michel Foucault's concept of discourse is closely related to social rules as it offers a possible explanation how these rules are shaped and change. It is the social rules that tell people what is "normal" behaviour for any specific category. Thus, social rules tell a woman how to behave in a womanly manner, and a man, how to be manly. Other such rules are as follows:
Government.
In government, convention is a set of unwritten rules that participants in the government must follow. These rules can be ignored only if justification is clear, or can be provided. Otherwise, consequences follow. Consequences may include ignoring some other convention that has until now been followed. According to the traditional doctrine (Dicey), conventions cannot be enforced in courts, because they are non-legal sets of rules. Convention is particularly important in the Westminster System of government, where many of the rules are unwritten.
International law.
The term "convention" is also used in international law to refer to certain formal statements of principle such as the Convention on the Rights of the Child. Conventions are adopted by international bodies such as the International Labour Organization and the United Nations. Conventions so adopted usually apply only to countries that ratify them, and do not automatically apply to member states of such bodies. These conventions are generally seen as having the force of international treaties for the ratifying countries. The best known of these are perhaps the several Geneva Conventions.

</doc>
<doc id="7832" url="https://en.wikipedia.org/wiki?curid=7832" title="Complete metric space">
Complete metric space

In mathematical analysis, a metric space "M" is called complete (or a Cauchy space) if every Cauchy sequence of points in "M" has a limit that is also in "M" or, alternatively, if every Cauchy sequence in "M" converges in "M".
Intuitively, a space is complete if there are no "points missing" from it (inside or at the boundary). For instance, the set of rational numbers is not complete, because e.g. square root of 2 is "missing" from it, even though one can construct a Cauchy sequence of rational numbers that converges to it. (See the examples below.) It is always possible to "fill all the holes", leading to the "completion" of a given space, as explained below.
Examples.
The space Q of rational numbers, with the standard metric given by the absolute value of the difference, is not complete. Consider for instance the sequence defined by formula_1 and formula_2. This is a Cauchy sequence of rational numbers, but it does not converge towards any rational limit: If the sequence did have a limit "x", then necessarily "x"2 = 2, yet no rational number has this property. However, considered as a sequence of real numbers, it does converge to the irrational number .
The open interval , again with the absolute value metric, is not complete either. The sequence defined by "x""n" = is Cauchy, but does not have a limit in the given space. However the closed interval unit interval is complete; for example the given sequence does have a limit in this interval and the limit is zero.
The space R of real numbers and the space C of complex numbers (with the metric given by the absolute value) are complete, and so is Euclidean space R"n", with the usual distance metric. In contrast, infinite-dimensional normed vector spaces may or may not be complete; those that are complete are Banach spaces. The space C of continuous real-valued functions on a closed and bounded interval is a Banach space, and so a complete metric space, with respect to the supremum norm. However, the supremum norm does not give a norm on the space C of continuous functions on , for it may contain unbounded functions. Instead, with the topology of compact convergence, C can be given the structure of a Fréchet space: a locally convex topological vector space whose topology can be induced by a complete translation-invariant metric.
The space Q"p" of "p"-adic numbers is complete for any prime number "p". This space completes Q with the "p"-adic metric in the same way that R completes Q with the usual metric.
If "S" is an arbitrary set, then the set "S"N of all sequences in "S" becomes a complete metric space if we define the distance between the sequences ("x""n") and ("y""n") to be , where "N" is the smallest index for which "x""N" is distinct from "y""N", or 0 if there is no such index. This space is homeomorphic to the product of a countable number of copies of the discrete space "S".
Some theorems.
A metric space "X" is complete if and only if every decreasing sequence of non-empty closed subsets of "X", with diameters tending to 0, has a non-empty intersection: if "F""n" is closed and non-empty, for every "n", and diam("F""n") → 0, then there is a point "x" ∈ "X" common to all sets "F""n".
Every compact metric space is complete, though complete spaces need not be compact. In fact, a metric space is compact if and only if it is complete and totally bounded. This is a generalization of the Heine–Borel theorem, which states that any closed and bounded subspace "S" of R"n" is compact and therefore complete.
A closed subspace of a complete space is complete. Conversely, a complete subset of a metric space is closed.
If "X" is a set and "M" is a complete metric space, then the set B("X", "M") of all bounded functions "f" from "X" to "M" is a complete metric space. Here we define the distance in B("X", "M") in terms of the distance in "M" with the supremum norm
If "X" is a topological space and "M" is a complete metric space, then the set Cb("X", "M") consisting of all continuous bounded functions "f" from "X" to "M" is a closed subspace of B("X", "M") and hence also complete.
The Baire category theorem says that every complete metric space is a Baire space. That is, the union of countably many nowhere dense subsets of the space has empty interior.
The Banach fixed point theorem states that a contraction mapping on a complete metric space admits a fixed point. The fixed point theorem is often used to prove the inverse function theorem on complete metric spaces such as Banach spaces.
The expansion constant of a metric space is the infimum of all constants formula_4 such that whenever the family formula_5 intersects pairwise, the intersection
is nonempty. A metric space is complete if and only if its expansion constant is ≤ 2.
Completion.
For any metric space "M", one can construct a complete metric space "M′" (which is also denoted as ), which contains "M" as a dense subspace. It has the following universal property: if "N" is any complete metric space and "f" is any uniformly continuous function from "M" to "N", then there exists a unique uniformly continuous function "f′" from "M′" to "N", which extends "f". The space "M"' is determined up to isometry by this property, and is called the "completion" of "M".
The completion of "M" can be constructed as a set of equivalence classes of Cauchy sequences in "M". For any two Cauchy sequences x=("x""n") and y=("y""n") in "M", we may define their distance as
(This limit exists because the real numbers are complete.) This is only a pseudometric, not yet a metric, since two different Cauchy sequences may have the distance 0. But "having distance 0" is an equivalence relation on the set of all Cauchy sequences, and the set of equivalence classes is a metric space, the completion of "M". The original space is embedded in this space via the identification of an element "x" of "M" with the equivalence class of sequences converging to "x" (i.e., the equivalence class containing the sequence with constant value "x"). This defines an isometry onto a dense subspace, as required. Notice, however, that this construction makes explicit use of the completeness of the real numbers, so completion of the rational numbers needs a slightly different treatment.
Cantor's construction of the real numbers is similar to the above construction; the real numbers are the completion of the rational numbers using the ordinary absolute value to measure distances. The additional subtlety to contend with is that it is not logically permissible to use the completeness of the real numbers in their own construction. Nevertheless, equivalence classes of Cauchy sequences are defined as above, and the set of equivalence classes is easily shown to be a field that has the rational numbers as a subfield. This field is complete, admits a natural total ordering, and is the unique totally ordered complete field (up to isomorphism). It is "defined" as the field of real numbers (see also Construction of the real numbers for more details). One way to visualize this identification with the real numbers as usually viewed is that the equivalence class consisting of those Cauchy sequences of rational numbers that "ought" to have a given real limit is identified with that real number. The truncations of the decimal expansion give just one choice of Cauchy sequence in the relevant equivalence class.
For a prime "p", the "p"-adic numbers arise by completing the rational numbers with respect to a different metric.
If the earlier completion procedure is applied to a normed vector space, the result is a Banach space containing the original space as a dense subspace, and if it is applied to an inner product space, the result is a Hilbert space containing the original space as a dense subspace.
Topologically complete spaces.
Note that completeness is a property of the "metric" and not of the "topology", meaning that a complete metric space can be homeomorphic to a non-complete one. An example is given by the real numbers, which are complete but homeomorphic to the open interval , which is not complete.
In topology one considers "completely metrizable spaces", spaces for which there exists at least one complete metric inducing the given topology. Completely metrizable spaces can be characterized as those spaces that can be written as an intersection of countably many open subsets of some complete metric space. Since the conclusion of the Baire category theorem is purely topological, it applies to these spaces as well.
Completely metrizable spaces are often called "topologically complete". However, the latter term is somewhat arbitrary since metric is not the most general structure on a topological space for which one can talk about completeness (see the section Alternatives and generalizations). Indeed, some authors use the term "topologically complete" for a wider class of topological spaces, the completely uniformizable spaces.
A topological space homeomorphic to a separable complete metric space is called a Polish space.
Alternatives and generalizations.
Since Cauchy sequences can also be defined in general topological groups, an alternative to relying on a metric structure for defining completeness and constructing the completion of a space is to use a group structure. This is most often seen in the context of topological vector spaces, but requires only the existence of a continuous "subtraction" operation. In this setting, the distance between two points "x" and "y" is gauged not by a real number "ε" via the metric "d" in the comparison "d"("x", "y") < "ε", but by an open neighbourhood "N" of 0 via subtraction in the comparison "x" − "y" ∈ "N".
A common generalisation of these definitions can be found in the context of a uniform space, where an entourage is a set of all pairs of points that are at no more than a particular "distance" from each other.
It is also possible to replace Cauchy "sequences" in the definition of completeness by Cauchy "nets" or Cauchy filters. If every Cauchy net (or equivalently every Cauchy filter) has a limit in "X", then "X" is called complete. One can furthermore construct a completion for an arbitrary uniform space similar to the completion of metric spaces. The most general situation in which Cauchy nets apply is Cauchy spaces; these too have a notion of completeness and completion just like uniform spaces.

</doc>
<doc id="7833" url="https://en.wikipedia.org/wiki?curid=7833" title="The Amazing Criswell">
The Amazing Criswell

Jeron Criswell King (August 18, 1907 – October 4, 1982), born Jeron Criswell Konig, and known by his stage-name The Amazing Criswell , was an American psychic known for wildly inaccurate predictions. In person, he went by Charles Criswell King, and was sometimes credited as Jeron King Criswell.
Criswell was flamboyant, with spit curled hair, a stentorian style of speaking, and a sequined tuxedo. He owned a coffin in which he claimed to sleep. He grew up in a troubled family in Indiana with relatives who owned a funeral home, and said that he became comfortable with sleeping in caskets in the storeroom. The casket appeared in one of Ed Wood's later works, the 1971 pornographic film "Necromania".
Career.
Criswell said he had once worked as a radio announcer and news broadcaster. He began buying time on a local Los Angeles television station in the early 1950s to run infomercials for his Criswell Family Vitamins. To fill the time, he began his "Criswell Predicts" part of the show. This made him a minor off-beat celebrity in Los Angeles and around Hollywood, and his friendship with old show-business people such as Mae West and rising fringe celebrities such as Korla Pandit made Criswell an entertaining presence at parties. His fame brought him appearances on "The Jack Paar Show" (1957–1962) which allowed him to publish his predictions in three publications of Spaceway Magazine (February 1955, April 1955, and June 1955), as well as run a weekly syndicated newspaper article. He later published three books of predictions; "From Now to the Year 2000", "Your Next Ten Years", and "Forbidden Predictions". He also recorded a long playing record, "Your Incredible Future" (which was later released on CD), featuring 84 minutes of his predictions in his own voice. Criswell appeared in the movies of writer and director Ed Wood. After Criswell's death, his longtime friend Paul Marco released Criswell's song "Someone Walked Over My Grave" on a 7" record which was recorded by Criswell as a memorial song that he wanted released posthumously.
Predictions.
Criswell's predictions were nationally syndicated and he appeared on the television show "Criswell Predicts" on KLAC Channel 13 (now KCOP-13) in Los Angeles as well as being recorded for syndication. His announcer was Bob Shields, who later played the judge on "Divorce Court". Criswell wore heavy makeup in public after his live program was broadcast in Los Angeles. Only selected people were allowed in the KCOP studio during his broadcast.
Criswell wrote several books of predictions, including 1968's "Criswell Predicts: From Now to the Year 2000." In it, he claimed that Denver would be struck by a ray from space that would cause all metal to adopt the qualities of rubber, leading to horrific accidents at amusement parks. He predicted mass cannibalism and the end of planet Earth, which he set as happening on August 18, 1999.
Criswell was a student of history. He believed history repeated itself, that the United States were the "modern Romans". Each day, he read the "St. Louis Post-Dispatch" looking for clues for his predictions.
Some sources claim Criswell's most famous prediction was on "The Jack Paar Program" (1962–65) in March 1963, when he predicted John F. Kennedy would not run for reelection in 1964 because something was going to happen to him in November 1963.
Sources say that Criswell never claimed to be a real psychic; however, those who knew him, such as actress and fellow "Plan 9" alumna Maila Nurmi ("Vampira"), believed he was. According to writer Charles A. Coulombe, whose family rented an apartment from him, Criswell told Coulombe's father " had the gift, but ... lost it when I started taking money for it."
Private life.
Criswell married a former speakeasy dancer named Halo Meadows, who appeared on "You Bet Your Life", and whom Coulombe describes as "quite mad": "Mrs Criswell had a huge standard poodle (named "Buttercup") which she was convinced was the reincarnation of her cousin Thomas. She spent a great deal of time sunbathing ... which, given her size, was not too pleasing a sight."
Mae West used Criswell as her personal psychic; he once predicted her rise to President of the United States, whereupon she, Criswell and George Liberace, the brother of showman Liberace, would take a rocket to the Moon. Criswell and West were great friends and she would lavish him with home-cooked food she had delivered to the studio that he shared with Maila Nurmi ("Vampira"). It is said that West sold Criswell her old luxury cars for five dollars.
He died in 1982.

</doc>
<doc id="7834" url="https://en.wikipedia.org/wiki?curid=7834" title="Chain reaction">
Chain reaction

A chain reaction is a sequence of reactions where a reactive product or by-product causes additional reactions to take place. In a chain reaction, positive feedback leads to a self-amplifying chain of events.
Chain reactions are one way in which systems which are in thermodynamic non-equilibrium can release energy or increase entropy in order to reach a state of higher entropy. For example, a system may not be able to reach a lower energy state by releasing energy into the environment, because it is hindered or prevented in some way from taking the path that will result in the energy release. If a reaction results in a small energy release making way for more energy releases in an expanding chain, then the system will typically collapse explosively until much or all of the stored energy has been released. 
A macroscopic metaphor for chain reactions is thus a snowball causing a larger snowball until finally an avalanche results ("snowball effect"). This is a result of stored gravitational potential energy seeking a path of release over friction. Chemically, the equivalent to a snow avalanche is a spark causing a forest fire. In nuclear physics, a single stray neutron can result in a prompt critical event, which may be finally be energetic enough for a nuclear reactor meltdown or (in a bomb) a nuclear explosion.
Chemical chain reactions.
History.
In 1913 the German chemist Max Bodenstein first put forth the idea of chemical chain reactions. If two molecules react, not only molecules of the final reaction products are formed, but also some unstable molecules which can further react with the parent molecules with a far larger probability than the initial reactants. In the new reaction, further unstable molecules are formed besides the stable products, and so on.
In 1918, Walther Nernst proposed that the photochemical reaction of hydrogen and chlorine is a chain reaction in order to explain the large quantum yield, meaning that one photon of light is responsible for the formation of as many as 106 molecules of the product HCl. He suggested that the photon dissociates a Cl2 molecule into two Cl atoms which each initiate a long chain of reaction steps forming HCl.
In 1923, Danish and Dutch scientists Christian Christiansen and Hendrik Anthony Kramers, in an analysis of the formation of polymers, pointed out that such a chain reaction need not start with a molecule excited by light, but could also start with two molecules colliding violently due to thermal energy as previously proposed for initiation of chemical reactions by van' t Hoff.
Christiansen and Kramers also noted that if, in one link of the reaction chain, two or more unstable molecules are produced, the reaction chain would branch and grow. The result is in fact an exponential growth, thus giving rise to explosive increases in reaction rates, and indeed to chemical explosions themselves. This was the first proposal for the mechanism of chemical explosions.
A quantitative chain chemical reaction theory was created by Soviet physicist Nikolay Semyonov in 1934. Semyonov shared the Nobel Prize in 1956 with Sir Cyril Norman Hinshelwood, who independently developed many of the same quantitative concepts.
Typical steps.
The main types of steps in chain reaction are of the following types.
The "chain length" is defined as the average number of times the propagation cycle is repeated, and equals the overall reaction rate divided by the initiation rate.
Some chain reactions have complex rate equations with fractional order or mixed order kinetics.
Detailed example: the hydrogen-bromine reaction.
The reaction H2 + Br2 → 2 HBr proceeds by the following mechanism:
As can be explained using the steady-state approximation, the thermal reaction has an initial rate of fractional order (3/2), and a complete rate equation with a two-term denominator (mixed-order kinetics).
Nuclear chain reactions.
A "nuclear" chain reaction was proposed by Leo Szilard in 1933, shortly after the neutron was discovered, yet more than five years before nuclear fission was first discovered. Szilárd knew of "chemical" chain reactions, and he had been reading about an energy-producing nuclear reaction involving high-energy protons bombarding lithium, demonstrated by John Cockcroft and Ernest Walton, in 1932. Now, Szilárd proposed to use neutrons theoretically produced from certain nuclear reactions in lighter isotopes, to induce further reactions in light isotopes that produced more neutrons. This would in theory produce a chain reaction at the level of the nucleus. He did not envision fission as one of these neutron-producing reactions, since this reaction was not known at the time. Experiments he proposed using beryllium and indium failed.
Later, after fission was discovered in 1938, Szilárd immediately realized the possibility of using neutron-induced fission as the particular nuclear reaction necessary to create a chain-reaction, so long as fission also produced neutrons. In 1939, with Enrico Fermi, Szilárd proved this neutron-multiplying reaction in uranium. In this reaction, a neutron plus a fissionable atom causes a fission resulting in a larger number of neutrons than the single one that was consumed in the initial reaction. Thus was born the practical nuclear chain reaction by the mechanism of neutron-induced nuclear fission.
Specifically, if one or more of the produced neutrons themselves interact with other fissionable nuclei, and these also undergo fission, then there is a possibility that the macroscopic overall fission reaction will not stop, but continue throughout the reaction material. This is then a self-propagating and thus self-sustaining chain reaction. This is the principle for nuclear reactors and atomic bombs.
Demonstration of a self-sustaining nuclear chain reaction was accomplished by Enrico Fermi and others, in the successful operation of Chicago Pile-1, the first artificial nuclear reactor, in late 1942.
Electron avalanche in gases.
An electron avalanche happens between two unconnected electrodes in a gas when an electric field exceeds a certain threshold. Random thermal collisions of gas atoms may result in a few free electrons and positively charged gas ions, in a process called impact ionization. Acceleration of these free electrons in a strong electric field causes them to gain energy, and when they impact other atoms, the energy causes release of new free electrons and ions (ionization), which fuels the same process. If this process happens faster than it is naturally quenched by ions recombining, the new ions multiply in successive cycles until the gas breaks down into a plasma and current flows freely in a discharge.
Electron avalanches are essential to the dielectric breakdown process within gases. The process can culminate in corona discharges, streamers, leaders, or in a spark or continuous electric arc that completely bridges the gap. The process may extends to huge sparks — streamers in lightning discharges propagate by formation of electron avalanches created in the high potential gradient ahead of the streamers' advancing tips. Once begun, avalanches are often intensified by the creation of photoelectrons as a result of ultraviolet radiation emitted by the excited medium's atoms in the aft-tip region. The extremely high temperature of the resulting plasma cracks the surrounding gas molecules and the free ions recombine to create new chemical compounds.
The process can also be used to detect radiation that initiates the process, as the passage of a single particles can amplified to large discharges. This is the mechanism of a Geiger counter and also the visualization possible with a spark chamber and other wire chambers.
Avalanche breakdown in semiconductors.
An avalanche breakdown process can happen in semiconductors, which in some ways conduct electricity analogously to a mildly ionized gas. Semiconductors rely on free electrons knocked out of the crystal by thermal vibration for conduction. Thus, unlike metals, semiconductors become better conductors the higher the temperature. This sets up conditions for the same type of positive feedback—heat from current flow causes temperature to rise, which increases charge carriers, lowering resistance, and causing more current to flow. This can continue to the point of complete breakdown of normal resistance at a semiconductor junction, and failure of the device (this may be temporary or permanent depending on whether there is physical damage to the crystal). Certain devices, such as avalanche diodes, deliberately make use of the effect.
In economics.
In 1963 Friedman and Schwartz proposed a positive feedback loop as a mechanism for catastrophic failures in economics: “It happens that a liquidity crisis in a unit fractional reserve banking system is precisely the kind of event that trigger- and often has triggered- a chain reaction. And economic collapse often has the character of a cumulative process. Let it go beyond a certain point, and it will tend for a time to gain strength from its own development as its effects spread and return to intensify the process of collapse”.

</doc>
<doc id="7837" url="https://en.wikipedia.org/wiki?curid=7837" title="Caddy">
Caddy

In golf, a caddy (or caddie) is the person who carries a player's bag and clubs, and gives insightful advice and moral support. A good caddy is aware of the challenges and obstacles of the golf course being played, along with the best strategy in playing it. This includes knowing overall yardage, pin placements and club selection. A caddy is not usually an employee of a private club or resort. They are classified as an "independent contractor," meaning that he or she is basically self-employed and does not receive any benefits from his association with the club. Some clubs and resorts do have caddy programs, although benefits are rarely offered. Particularly in Europe, the vast majority of clubs do not offer caddies, and amateur players will commonly carry or pull their own bags.
Types of caddying.
Traditional caddying involves both the "golfer" and the "caddy" walking the course. The caddy is in charge of carrying the player’s bag, and walks ahead of the golfer to locate his ball and calculate the yardage to the pin and/or hazards. This is the most common method used in golf clubs and is the only method allowed in the PGA (Professional Golf Association) and LPGA (Ladies Professional Golf Association). The three "ups" of caddying are: show up, shut up, and keep up.
Fore-Caddying entails the caddy walking while the players ride in carts. The fore-caddy will give a hole description and then walk ahead to spot the players tee shots. The caddy then gets the players yardage (either with a laser, course knowledge, or sprinkler heads) while the players drive their carts from the tee to their shots. The caddy walks ahead again to spot the golfers next shots. This process is continued until the players reach the green. Once on the green the caddy will read greens (if asked per proper golf etiquette), clean golf balls (if asked), fix ball marks, and attend the flag. The caddy is also responsible for raking traps on the course. Caddies will help with club selection, reading greens, weather variables, and marking balls on the green but should only do so if asked to by the player. More than anything else, the caddy is there to make the player's round enjoyable by taking care of menial tasks, speeding up play, and providing mental support if asked.
Caddy ranks.
Many clubs use a ranking system. Caddies will start as a trainee, and be promoted through the ranks of Intermediate, Captain, Honor, and finally Championship. Many courses start their caddies off at the B level, and after a year move them to A, and on their fourth year (if they have earned it), they will receive the title of Honor caddy. The intermediate and captain ranks can usually be obtained within the first year of caddying, and the honor rank is usually obtained in the second or third year of caddying. Championship takes at least 6 years and often as many as 10 years to obtain. An alternative ranking system often used in the American Mid-West proceeds as B level, A level, AA level, Honor level, and Evans Scholar. Caddies often obtain a promotion in rank once a year, while often Honor takes two years to achieve and Evans Scholars are only produced by winning the venerable Evans Scholarship for university. However, in many American clubs, caddies are divided simply between "B" caddies (usually younger, less experienced caddies who often carry only one bag), and "A" caddies (usually older, more experienced caddies who almost always carry two bags).
Weekly schedule.
Caddies are most frequently employed at clubs on weekends, when the majority of country club golf takes place. Some (but usually not as many) opportunities to caddy exist during the week, as well. Additionally, caddies are often allowed to play the course at which they caddy for free, usually on a Monday (the day that most private clubs choose to close their course for maintenance). On pro golf tours, professional caddies accompany their player to all events, which usually take place from Thursday through Sunday. Additionally, the player may hire their caddy to carry their bag for them during training sessions and practice rounds.
Pay scale.
At most clubs, caddies are paid at the end of the round by cash, or receive a payment ticket for which they can redeem their wages in the clubhouse. Generally, the player will tip the caddy based on their performance during the round, with extra money given for exemplary work. Most American club caddies earn between $80 and $120 per bag, though newer caddies will often earn less than more experienced caddies. Caddies working during a tournament, high-stakes match, or 4-Day member-guest will often earn significantly more, upwards of $150 per round, per bag, at times. It is common for experienced caddies to carry two bags at a time. It is considered acceptable to ask a professional at the course what the average pay for a caddie is, as courses differ.
In a professional golf tour setting, a player often pays their caddy a percentage of their winnings, which can be as high as 10%. A common pay scale is 5% for making the cut, 7% for a top 10, and 10% for a win. The caddy also usually receives a salary, as the player is not guaranteed to win money at every tournament.

</doc>
<doc id="7838" url="https://en.wikipedia.org/wiki?curid=7838" title="Compound turbine">
Compound turbine

A compound turbine is a steam turbine in which there are two casings, a high-pressure casing and a low-pressure casing, operating in concert to extract work from a single source of steam. The steam is partially expanded in the high-pressure casing, then exhausted to the low-pressure casing. 
Tandem compound or cross compound.
The rotor arrangement can be either tandem-compound in which the two axles are joined end to end, or cross-compound in which the two turbines have separate axles. In the cross-compound case two separate generators are usually supplied, although a gearbox can reduce this to one.
Advantages.
The principal advantages of compound turbines are the reduction in size of any one casing, the confinement of the highest pressure to the smaller casing (which may be made of stronger and more expensive materials) and the possibility of divided flow in the low-pressure casing for the purpose of equalizing end thrusts.

</doc>
