<doc id="7482" url="https://en.wikipedia.org/wiki?curid=7482" title="Christian mythology">
Christian mythology

Christian mythology is the body of myths associated with Christianity.
Christian attitudes.
In ancient Greek, "muthos", from which the English word "myth" derives, meant "story, narrative." Early Christians contrasted their sacred stories with "myths", by which they meant false and pagan stories.
A number of modern Christian writers such as C.S. Lewis have described elements of Christianity, particularly the story of Christ, as "myth" which is also "true" ("true myth"). Opposition to the term "myth" stems from a variety of sources: the association of the term "myth" with polytheism, the use of the term "myth" to indicate falsehood or non-historicity, and the lack of an agreed-upon definition of "myth".
George Every claims that the existence of "myths in the Bible would now be admitted by nearly everyone", including "probably all Roman Catholics and a majority of Protestants". As examples of Biblical myths, Every cites the creation account in Genesis 1 and 2 and the story of Eve's temptation. Many Christians believe parts of the Bible to be symbolic or metaphorical (such as the Creation in Genesis).
Historical development.
Old Testament.
According to Bernard McGinn, "mythic patterns" such as "the primordial struggle between good and evil" appear in passages throughout the Hebrew Bible, including passages that describe historical events. Citing Paul Ricoeur, McGinn argues that a distinctive characteristic of the Hebrew Bible is its "reinterpretation of myth on the basis of history". As an example, McGinn cites the apocalypse in the Book of Daniel, which he sees as a record of historical events presented as a prophecy of future events and expressed in terms of "mythic structures", with "the Hellenistic kingdom figured as a terrifying monster that cannot but recall Near Eastern pagan myth of the dragon of chaos".
Mircea Eliade argues that the imagery used in some parts of the Hebrew Bible reflects a "transfiguration of history into myth". For example, Eliade says, the portrayal of Nebuchadnezzar as a dragon in Jeremiah 51:34 is a case in which the Hebrews "interpreted contemporary events by means of the very ancient cosmogonico-heroic myth" of a battle between a hero and a dragon.
According to scholars including Neil Forsyth and John L. McKenzie, the Old Testament incorporates stories, or fragments of stories, from extra-biblical mythology. According to the "New American Bible", a Catholic Bible translation produced by the Confraternity of Christian Doctrine, the story of the Nephilim in Genesis 6:1-4 "is apparently a fragment of an old legend that had borrowed much from ancient mythology", and the "sons of God" mentioned in that passage are "celestial beings of mythology". The "New American Bible" also says that Psalm 93 alludes to "an ancient myth" in which God battles a personified Sea. Some scholars have identified the biblical creature Leviathan as a monster from Canaanite mythology. According to Howard Schwartz, "the myth of the fall of Lucifer" existed in fragmentary form in Isaiah 14:12 and other ancient Jewish literature; Schwartz claims that the myth originated from "the ancient Canaanite myth of Athtar, who attempted to rule the throne of Ba'al, but was forced to descend and rule the underworld instead".
Some scholars have argued that the calm, orderly, monotheistic creation story in Genesis 1 can be interpreted as a reaction against the creation myths of other Near Eastern cultures. In connection with this interpretation, David and Margaret Leeming describe Genesis 1 as a "demythologized myth", and John L. McKenzie asserts that the writer of Genesis 1 has "excised the mythical elements" from his creation story.
Perhaps the most famous topic in the Bible that could possibly be connected with mythical origins is the topic of Heaven (or the sky) as the place where God (or angels, or the saints) resides, with stories such as the ascension of Elijah (who disappeared in the sky), war of man with an angel, flying angels. Even in the New Testament Saint Paul is said to "have visited the third heaven", and Jesus was portrayed in several books as going to return from Heaven on a cloud, in the same way He ascended thereto. The official text repeated by the attendees during Roman Catholic mass (the Apostles' Creed) contains the words "He ascended into Heaven, and is Seated at the Right Hand of God, The Father. From thence He will come again to judge the living and the dead". Medieval cosmology adapted its view of the Cosmos to conform with these scriptures, in the concept of celestial spheres (later attacked, amongst others, by Giordano Bruno). Some famous opponents of religion, including John Lennon and Stephen Hawking, mentioned this in their public works.
New Testament and early Christianity.
According to a number of scholars, the Christ story contains mythical themes such as descent to the underworld, the heroic monomyth, and the "dying god" (see section below on "mythical themes and types").
Some scholars have argued that the Book of Revelation incorporates imagery from ancient mythology. According to the "New American Bible", the image in Revelation 12:1-6 of a pregnant woman in the sky, threatened by a dragon, "corresponds to a widespread myth throughout the ancient world that a goddess pregnant with a savior was pursued by a horrible monster; by miraculous intervention, she bore a son who then killed the monster". Bernard McGinn suggests that the image of the two Beasts in Revelation stems from a "mythological background" involving the figures of Leviathan and Behemoth.
The Pastoral Epistles contain denunciations of "myths" ("muthoi"). This may indicate that Rabbinic or gnostic mythology was popular among the early Christians to whom the epistles were written and that the epistles' author was attempting to resist that mythology.
The Sibylline oracles contain predictions that the dead Roman Emperor Nero, infamous for his persecutions, would return one day as an Antichrist-like figure. According to Bernard McGinn, these parts of the oracles were probably written by a Christian and incorporated "mythological language" in describing Nero's return.
Middle Ages.
According to Mircea Eliade, the Middle Ages witnessed "an upwelling of mythical thought" in which each social group had its own "mythological traditions". Often a profession had its own "origin myth" which established models for members of the profession to imitate; for example, the knights tried to imitate Lancelot or Parsifal. The medieval trouveres developed a "mythology of woman and Love" which incorporated Christian elements but, in some cases, ran contrary to official church teaching.
George Every includes a discussion of medieval legends in his book "Christian Mythology". Some medieval legends elaborated upon the lives of Christian figures such as Christ, the Virgin Mary, and the saints. For example, a number of legends describe miraculous events surrounding Mary's birth and her marriage to Joseph.
In many cases, medieval mythology appears to have inherited elements from myths of pagan gods and heroes. According to Every, one example may be "the myth of St. George" and other stories about saints battling dragons, which were "modelled no doubt in many cases on older representations of the creator and preserver of the world in combat with chaos". Eliade notes that some "mythological traditions" of medieval knights, namely the Arthurian cycle and the Grail theme, combine a veneer of Christianity with traditions regarding the Celtic Otherworld. According to Lorena Laura Stookey, "many scholars" see a link between stories in "Irish-Celtic mythology" about journeys to the Otherworld in search of a cauldron of rejuvenation and medieval accounts of the quest for the Holy Grail.
According to Eliade, "eschatological myths" became prominent during the Middle Ages during "certain historical movements". These eschatological myths appeared "in the Crusades, in the movements of a Tanchelm and an Eudes de l'Etoile, in the elevation of Fredrick II to the rank of Messiah, and in many other collective messianic, utopian, and prerevolutionary phenomena". One significant eschatological myth, introduced by Gioacchino da Fiore's theology of history, was the "myth of an imminent third age that will renew and complete history" in a "reign of the Holy Spirit"; this "Gioacchinian myth" influenced a number of messianic movements that arose in the late Middle Ages.
Renaissance and Reformation.
During the Renaissance, there arose a critical attitude that sharply distinguished between apostolic tradition and what George Every calls "subsidiary mythology"—popular legends surrounding saints, relics, the cross, etc.—suppressing the latter.
The works of Renaissance writers often included and expanded upon Christian and non-Christian stories such as those of creation and the Fall. Rita Oleyar describes these writers as "on the whole, reverent and faithful to the primal myths, but filled with their own insights into the nature of God, man, and the universe". An example is John Milton's "Paradise Lost", an "epic elaboration of the Judeo-Christian mythology" and also a "veritable encyclopedia of myths from the Greek and Roman tradition".
According to Cynthia Stewart, during the Reformation, the Protestant reformers used "the founding myths of Christianity" to critique the church of their time.
Every argues that "the disparagement of myth in our own civilization" stems partly from objections to perceived idolatry, objections which intensified in the Reformation, both among Protestants and among Catholics reacting against the classical mythology revived during the Renaissance.
Enlightenment.
The philosophes of the Enlightenment used criticism of myth as a vehicle for veiled criticisms of the Bible and the church. According to Bruce Lincoln, the philosophes "made irrationality the hallmark of myth and constituted philosophy—rather than the Christian "kerygma"—as the antidote for mythic discourse. By implication, Christianity could appear as a more recent, powerful, and dangerous instance of irrational myth".
Modern period.
Some commentators have categorized a number of modern fantasy works as "Christian myth" or "Christian mythopoeia". Examples include the fiction of C.S. Lewis, Madeleine L'Engle, J.R.R. Tolkien, and George MacDonald.
In "The Eternal Adam and the New World Garden", written in 1968, David W. Noble argued that the Adam figure had been "the central myth in the American novel since 1830". As examples, he cites the works of Cooper, Hawthorne, Melville, Twain, Hemingway, and Faulkner.
Mythical themes and types.
Ascending the mountain.
According to Lorena Laura Stookey, many myths feature sacred mountains as "the sites of revelations": "In myth, the ascent of the holy mountain is a spiritual journey, promising purification, insight, wisdom, or knowledge of the sacred". As examples of this theme, Stookey includes the revelation of the Ten Commandments on Mount Sinai, Christ's ascent of a mountain to deliver his Sermon on the Mount, and Christ's ascension into Heaven from the Mount of Olives.
Axis mundi.
Many mythologies involve a "world center", which is often the sacred place of creation; this center often takes the form of a tree, mountain, or other upright object, which serves as an "axis mundi" or axle of the world. A number of scholars have connected the Christian story of the crucifixion at Golgotha with this theme of a cosmic center. In his "Creation Myths of the World", David Leeming argues that, in the Christian story of the crucifixion, the cross serves as "the "axis mundi", the center of a new creation".
According to a tradition preserved in Eastern Christian folklore, Golgotha was the summit of the cosmic mountain at the center of the world and the location where Adam had been both created and buried. According to this tradition, when Christ is crucified, his blood falls on Adam's skull, buried at the foot of the cross, and redeems him. George Every discusses the connection between the cosmic center and Golgotha in his book "Christian Mythology", noting that the image of Adam's skull beneath the cross appears in many medieval representations of the crucifixion.
In "Creation Myths of the World", Leeming suggests that the Garden of Eden may also be considered a world center.
Combat myth.
Many Near Eastern religions include a story about a battle between a divine being and a dragon or other monster representing chaos—a theme found, for example, in the "Enuma Elish". A number of scholars call this story the "combat myth". A number of scholars have argued that the ancient Israelites incorporated the combat myth into their religious imagery, such as the figures of Leviathan and Rahab, the Song of the Sea, Isaiah 51:9-10's description of God's deliverance of his people from Babylon, and the portrayals of enemies such as Pharaoh and Nebuchadnezzar. The idea of Satan as God's opponent may have developed under the influence of the combat myth. Scholars have also suggested that the Book of Revelation uses combat myth imagery in its descriptions of cosmic conflict.
Descent to the underworld.
According to Christian tradition, Christ descended to hell after his death, in order to free the souls there; this event is known as the harrowing of hell. This story is narrated in the Gospel of Nicodemus and may be the meaning behind 1 Peter 3:18-22. According to David Leeming, writing in "The Oxford Companion to World Mythology", the harrowing of hell is an example of the motif of the hero's descent to the underworld, which is common in many mythologies.
Dying god.
Many myths, particularly from the Near East, feature a god who dies and is resurrected; this figure is sometimes called the "dying god". An important study of this figure is James George Frazer's "The Golden Bough", which traces the dying god theme through a large number of myths. The dying god is often associated with fertility. A number of scholars, including Frazer, have suggested that the Christ story is an example of the "dying god" theme. In the article "Dying god" in "The Oxford Companion to World Mythology", David Leeming notes that Christ can be seen as bringing fertility, though of a spiritual as opposed to physical kind.
In his 2006 homily for Corpus Christi, Pope Benedict XVI noted the similarity between the Christian story of the resurrection and pagan myths of dead and resurrected gods: "In these myths, the soul of the human person, in a certain way, reached out toward that God made man, who, humiliated unto death on a cross, in this way opened the door of life to all of us."
Flood myths.
Many cultures have myths about a flood that cleanses the world in preparation for rebirth. Such stories appear on every inhabited continent on earth. An example is the biblical story of Noah. In "The Oxford Companion to World Mythology", David Leeming notes that, in the Bible story, as in other flood myths, the flood marks a new beginning and a second chance for creation and humanity.
Founding myths.
According to Sandra Frankiel, the records of "Jesus' life and death, his acts and words" provide the "founding myths" of Christianity. Frankiel claims that these founding myths are "structurally equivalent" to the creation myths in other religions, because they are "the pivot around which the religion turns to and which it returns", establishing the "meaning" of the religion and the "essential Christian practices and attitudes". Tom Cain uses the expression "founding myths" more broadly, to encompass such stories as those of the War in Heaven and the fall of man; according to Cain, "the disastrous consequences of disobedience" is a pervasive theme in Christian founding myths.
Hero myths.
In his influential work "The Myth of the Birth of the Hero", Otto Rank argued that the births of many mythical heroes follow a common pattern. Rank includes the story of Christ's birth as a representative example of this pattern.
According to Mircea Eliade, one pervasive mythical theme associates heroes with the slaying of dragons, a theme which Eliade traces back to "the very ancient cosmogonico-heroic myth" of a battle between a divine hero and a dragon. He cites the Christian legend of Saint George as an example of this theme. An example from the later Middle Ages is Dieudonné de Gozon, third Grand Master of the Knights of Rhodes, famous for slaying the dragon of Malpasso. Eliade writes, "Legend, as was natural, bestowed upon him the attributes of St. George, famed for his victorious fight with the monster. […] In other words, by the simple fact that he was regarded as a hero, de Gozon was identified with a category, an archetype, which […] equipped him with a mythical biography from which it was "impossible" to omit combat with a reptilian monster."
In the "Oxford Companion to World Mythology", David Leeming lists Moses, Jesus, and King Arthur as examples of the "heroic monomyth", calling the Christ story "a particularly complete example of the heroic monomyth". Leeming regards resurrection as a common part of the heroic monomyth, in which the heroes are resurrected, often as sources of "material or spiritual food for their people"; in this connection, Leeming notes that Christians regard Jesus as the "bread of life".
In terms of values, Leeming contrasts "the myth of Jesus" with the myths of other "Christian heroes such as St. George, Roland, el Cid, and even King Arthur"; the latter hero myths, Leeming argues, reflect the survival of pre-Christian heroic values—"values of military dominance and cultural differentiation and hegemony"—more than the values expressed in the Christ story.
Paradise.
Many religious and mythological systems contain myths about a paradise. Many of these myths involve the loss of a paradise that existed at the beginning of the world. Some scholars have seen in the story of the Garden of Eden an instance of this general motif.
Sacrifice.
Sacrifice is an element in many religious traditions and often represented in myths. In "The Oxford Companion to World Mythology", David Leeming lists the story of Abraham and Isaac and the story of Christ's death as examples of this theme. Wendy Doniger describes the gospel accounts as a "meta-myth" in which Jesus realizes that he is part of a "new myth [...] of a man who is sacrificed in hate" but "sees the inner myth, the old myth of origins and acceptance, the myth of a god who sacrifices himself in love".
Attitudes toward time.
According to Mircea Eliade, many traditional societies have a cyclic sense of time, periodically reenacting mythical events. Through this reenactment, these societies achieve an "eternal return" to the mythical age. According to Eliade, Christianity retains a sense of cyclical time, through the ritual commemoration of Christ's life and the imitation of Christ's actions; Eliade calls this sense of cyclical time a "mythical aspect" of Christianity.
However, Judeo-Christian thought also makes an "innovation of the first importance", Eliade says, because it embraces the notion of linear, historical time; in Christianity, "time is no longer the circular Time of the Eternal Return; it has become linear and irreversible Time". Summarizing Eliade's statements on this subject, Eric Rust writes, "A new religious structure became available. In the Judaeo-Christian religions—Judaism, Christianity, Islam—history is taken seriously, and linear time is accepted. [... The Christian myth gives such time a beginning in creation, a center in the Christ-event, and an end in the final consummation."
Heinrich Zimmer also notes Christianity's emphasis on linear time; he attributes this emphasis specifically to the influence of Saint Augustine's theory of history. Zimmer does not explicitly describe the cyclical conception of time as itself "mythical" per se, although he notes that this conception "underl Hindu mythology".
Neil Forsyth writes that "what distinguishes both Jewish and Christian religious systems [...] is that they elevate to the sacred status of myth narratives that are situated in historical time".
Legacy.
Concepts of progress.
According to Carl Mitcham, "the Christian mythology of progress toward transcendent salvation" created the conditions for modern ideas of scientific and technological progress. Hayden White describes "the myth of Progress" as the "secular, Enlightenment counterpart" of "Christian myth". Reinhold Niebuhr described the modern idea of ethical and scientific progress as "really a rationalized version of the Christian myth of salvation".
Political and philosophical ideas.
According to Mircea Eliade, the medieval "Gioacchinian myth [...] of universal renovation in a more or less imminent future" has influenced a number of modern theories of history, such as those of Lessing (who explicitly compares his views to those of medieval "enthusiasts"), Fichte, Hegel, and Schelling, and has also influenced a number of Russian writers.
Calling Marxism "a truly messianic Judaeo-Christian ideology", Eliade writes that Marxism "takes up and carries on one of the great eschatological myths of the Middle Eastern and Mediterranean world, namely: the redemptive part to be played by the Just (the 'elect', the 'anointed', the 'innocent', the 'missioners', in our own days the proletariat), whose sufferings are invoked to change the ontological status of the world".
In his article "The Christian Mythology of Socialism", Will Herberg argues that socialism inherits the structure of its ideology from the influence of Christian mythology upon western thought.
In "The Oxford Companion to World Mythology", David Leeming claims that Judeo-Christian messianic ideas have influenced 20th-century totalitarian systems, citing Soviet Communism as an example.
According to Hugh S. Pyper, the biblical "founding myths of the Exodus and the exile, read as stories in which a nation is forged by maintaining its ideological and racial purity in the face of an oppressive great power", entered "the rhetoric of nationalism throughout European history", especially in Protestant countries and smaller nations.
Christmas stories in popular culture.
See Secular Christmas stories, Christmas in the media and Christmas in literature.

</doc>
<doc id="7484" url="https://en.wikipedia.org/wiki?curid=7484" title="Company (disambiguation)">
Company (disambiguation)

A company is a group of more than one persons to carry out an enterprise and so a form of business organization.
Company may also refer to:
In titles and proper names:

</doc>
<doc id="7485" url="https://en.wikipedia.org/wiki?curid=7485" title="Corporation">
Corporation

A corporation is a company or group of people authorized to act as a single entity (legally a person) and recognized as such in law. Early incorporated entities were established by charter (i.e. by an "ad hoc" act granted by a monarch or passed by a parliament or legislature). Most jurisdictions now allow the creation of new corporations through registration.
Corporations come in many different types but are usually divided by the law of the jurisdiction where they are chartered into two kinds: by whether or not they can issue stock, or by whether or not they are for profit.
Where local law distinguishes corporations by ability to issue stock, corporations allowed to do so are referred to as "stock corporations", ownership of the corporation is through stock, and owners of stock are referred to as "stockholders." Corporations not allowed to issue stock are referred to as "non-stock" corporations, those who are considered the owners of the corporation are those who have obtained membership in the corporation, and are referred to as a "member" of the corporation.
Corporations chartered in regions where they are distinguished by whether they are allowed to be for profit or not are referred to as "for profit" and "not-for-profit" corporations, respectively.
There is some overlap between stock/non-stock and for profit/not-for-profit in that not-for-profit corporations are always non-stock as well. A for profit corporation is almost always a stock corporation, but some for profit corporations may choose to be non-stock. To simplify the explanation, whenever "stockholder" is used in the rest of this article to refer to a stock corporation, it is presumed to mean the same as "member" for a non-profit corporation or for profit, non-stock corporation.
Registered corporations have legal personality and are owned by shareholders whose liability is limited to their investment. Shareholders do not typically actively manage a corporation; shareholders instead elect or appoint a board of directors to control the corporation in a fiduciary capacity.
In American English the word "corporation" is most often used to describe large business corporations. In British English and in the Commonwealth countries, the term "company" is more widely used to describe the same sort of entity while the word "corporation" encompasses all incorporated entities. In American English, the word "company" can include entities such as partnerships that would not be referred to as companies in British English as they are not a separate legal entity.
Despite not being human beings, corporations, as far as the law is concerned, are legal persons, and have many of the same rights and responsibilities as natural persons do. Corporations can exercise human rights against real individuals and the state, and they can themselves be responsible for human rights violations. Corporations can be "dissolved" either by statutory operation, order of court, or voluntary action on the part of shareholders. Insolvency may result in a form of corporate failure, when creditors force the liquidation and dissolution of the corporation under court order, but it most often results in a restructuring of corporate holdings. Corporations can even be convicted of criminal offenses, such as fraud and manslaughter. However corporations are not considered living entities in the way that humans are.
History.
The word "corporation" derives from "corpus", the Latin word for body, or a "body of people." By the time of Justinian (reigned 527–565), Roman Law recognized a range of corporate entities under the names "universitas", "corpus" or "collegium". These included the state itself (the "populus Romanus"), municipalities, and such private associations as sponsors of a religious cult, burial clubs, political groups, and guilds of craftsmen or traders. Such bodies commonly had the right to own property and make contracts, to receive gifts and legacies, to sue and be sued, and, in general, to perform legal acts through representatives. Private associations were granted designated privileges and liberties by the emperor.
Entities which carried on business and were the subjects of legal rights were found in ancient Rome, and the Maurya Empire in ancient India. In medieval Europe, churches became incorporated, as did local governments, such as the Pope and the City of London Corporation. The point was that the incorporation would survive longer than the lives of any particular member, existing in perpetuity. The alleged oldest commercial corporation in the world, the Stora Kopparberg mining community in Falun, Sweden, obtained a charter from King Magnus Eriksson in 1347.
In medieval times traders would do business through common law constructs, such as partnerships. Whenever people acted together with a view to profit, the law deemed that a partnership arose. Early guilds and livery companies were also often involved in the regulation of competition between traders.
Mercantilism.
Many European nations chartered corporations to lead colonial ventures, such as the Dutch East India Company (VOC) or the Hudson's Bay Company. These chartered companies became the progenitors of the modern corporation. Acting under a charter sanctioned by the Dutch government, the Dutch East India Company defeated Portuguese forces and established itself in the Moluccan Islands in order to profit from the European demand for spices. Investors in the VOC were issued paper certificates as proof of share ownership, and were able to trade their shares on the original Amsterdam Stock Exchange. Shareholders are also explicitly granted limited liability in the company's royal charter.
In England, the government created corporations under a Royal Charter or an Act of Parliament with the grant of a monopoly over a specified territory. The best known example, established in 1600, was the East India Company of London. Queen Elizabeth I granted it the exclusive right to trade with all countries to the east of the Cape of Good Hope. Some corporations at this time would act on the government's behalf, bringing in revenue from its exploits abroad. Subsequently the Company became increasingly integrated with English and later British military and colonial policy, just as most corporations were essentially dependent on the Royal Navy's ability to control trade routes.
Labeled by both contemporaries and historians as "the grandest society of merchants in the universe", the English East India Company would come to symbolize the dazzlingly rich potential of the corporation, as well as new methods of business that could be both brutal and exploitative. On 31 December 1600, Queen Elizabeth I granted the company a 15-year monopoly on trade to and from the East Indies and Africa. By 1611, shareholders in the East India Company were earning a return on their investment of almost 150 per cent. Subsequent stock offerings demonstrated just how lucrative the Company had become. Its first stock offering in 1613–1616 raised £418,000, its second in 1617–1622 raised £1.6 million.
A similar chartered company, the South Sea Company, was established in 1711 to trade in the Spanish South American colonies, but met with less success. The South Sea Company's monopoly rights were supposedly backed by the Treaty of Utrecht, signed in 1713 as a settlement following the War of Spanish Succession, which gave Great Britain an "assiento" to trade in the region for thirty years. In fact the Spanish remained hostile and let only one ship a year enter. Unaware of the problems, investors in Britain, enticed by extravagant promises of profit from company promoters bought thousands of shares. By 1717, the South Sea Company was so wealthy (still having done no real business) that it assumed the public debt of the British government. This accelerated the inflation of the share price further, as did the Bubble Act 1720, which (possibly with the motive of protecting the South Sea Company from competition) prohibited the establishment of any companies without a Royal Charter. The share price rose so rapidly that people began buying shares merely in order to sell them at a higher price, which in turn led to higher share prices. This was the first speculative bubble the country had seen, but by the end of 1720, the bubble had "burst", and the share price sank from £1000 to under £100. As bankruptcies and recriminations ricocheted through government and high society, the mood against corporations, and errant directors, was bitter.
In the late 18th century, Stewart Kyd, the author of the first treatise on corporate law in English, defined a corporation as:
Modern company law.
Due to the late 18th century abandonment of mercantilist economic theory and the rise of classical liberalism and laissez-faire economic theory due to a revolution in economics led by Adam Smith and other economists, corporations transitioned from being government or guild affiliated entities to being public and private economic entities free of government direction.
Adam Smith wrote in his 1776 work "The Wealth of Nations" that mass corporate activity could not match private entrepreneurship, because people in charge of others' money would not exercise as much care as they would with their own.
Deregulation.
The British Bubble Act 1720's prohibition on establishing companies remained in force until its repeal in 1825. By this point the Industrial Revolution had gathered pace, pressing for legal change to facilitate business activity. The repeal was the beginning of a gradual lifting on restrictions, though business ventures (such as those chronicled by Charles Dickens in "Martin Chuzzlewit") under primitive companies legislation were often scams. Without cohesive regulation, proverbial operations like the "Anglo-Bengalee Disinterested Loan and Life Assurance Company" were undercapitalised ventures promising no hope of success except for richly paid promoters.
The process of incorporation was possible only through a royal charter or a private act and was limited, owing to Parliament's jealous protection of the privileges and advantages thereby granted. As a result, many businesses came to be operated as unincorporated associations with possibly thousands of members. Any consequent litigation had to be carried out in the joint names of all the members and was almost impossibly cumbersome. Though Parliament would sometimes grant a private act to allow an individual to represent the whole in legal proceedings, this was a narrow and necessarily costly expedient, allowed only to established companies.
Then in 1843, William Gladstone became the chairman of a Parliamentary Committee on Joint Stock Companies, which led to the Joint Stock Companies Act 1844, regarded as the first modern piece of company law. The Act created the Registrar of Joint Stock Companies, empowered to register companies by a two-stage process. The first, provisional, stage cost £5 and did not confer corporate status, which arose after completing the second stage for another £5. For the first time in history, it was possible for ordinary people through a simple registration procedure to incorporate. The advantage of establishing a company as a separate legal person was mainly administrative, as a unified entity under which the rights and duties of all investors and managers could be channeled.
Limited liability.
However, there was still no limited liability and company members could still be held responsible for unlimited losses by the company. The next, crucial development, then, was the Limited Liability Act 1855, passed at the behest of the then Vice President of the Board of Trade, Mr Robert Lowe. This allowed investors to limit their liability in the event of business failure to the amount they invested in the company - shareholders were still liable directly to creditors, but just for the unpaid portion of their shares. (The principle that shareholders are liable to the corporation had been introduced in the Joint Stock Companies Act 1844).
The 1855 Act allowed limited liability to companies of more than 25 members (shareholders). Insurance companies were excluded from the act, though it was standard practice for insurance contracts to exclude action against individual members. Limited liability for insurance companies was allowed by the Companies Act 1862.
This prompted the English periodical "The Economist" to write in 1855 that "never, perhaps, was a change so vehemently and generally demanded, of which the importance was so much overrated. " The major error of this judgment was recognised by the same magazine more than 70 years later, when it claimed that, "he economic historian of the future. . . may be inclined to assign to the nameless inventor of the principle of limited liability, as applied to trading corporations, a place of honour with Watt and Stephenson, and other pioneers of the Industrial Revolution. "
These two features - a simple registration procedure and limited liability - were subsequently codified into the landmark 1856 Joint Stock Companies Act. This was subsequently consolidated with a number of other statutes in the Companies Act 1862, which remained in force for the rest of the century, up to and including the time of the decision in "Salomon v A Salomon & Co Ltd".
The legislation shortly gave way to a railway boom, and from then, the numbers of companies formed soared. In the later nineteenth century depression took hold, and just as company numbers had boomed, many began to implode and fall into insolvency. Much strong academic, legislative and judicial opinion was opposed to the notion that businessmen could escape accountability for their role in the failing businesses.
A study, title "Review on the Loss Problem of the Listed Corporations Based on the Valuation", published in International Journal of Trends in Economics Management and Technology (IJTEMT), concluded that to price for the stock of loss listed company, we should not consider single one or several aspects of factors, but should stand in the angle of investor, considering various expected factors to explore the driving path for all kinds of heterogeneity of loss listed company, thereby make a reasonable assessment on the value of loss of listed company. 
Further developments.
The last significant development in the history of companies was the decision of the House of Lords in "Salomon v. Salomon & Co." where the House of Lords confirmed the separate legal personality of the company, and that the liabilities of the company were separate and distinct from those of its owners.
In the United States, forming a corporation usually required an act of legislation until the late 19th century. Many private firms, such as Carnegie's steel company and Rockefeller's Standard Oil, avoided the corporate model for this reason (as a trust). State governments began to adopt more permissive corporate laws from the early 19th century, although these were all restrictive in design, often with the intention of preventing corporations for gaining too much wealth and power.
New Jersey was the first state to adopt an "enabling" corporate law, with the goal of attracting more business to the state, in 1896. In 1899, Delaware followed New Jersey's lead with the enactment of an enabling corporate statute, but Delaware only became the leading corporate state after the enabling provisions of the 1896 New Jersey corporate law were repealed in 1913.
The end of the 19th century saw the emergence of holding companies and corporate mergers creating larger corporations with dispersed shareholders. Countries began enacting anti-trust laws to prevent anti-competitive practices and corporations were granted more legal rights and protections.
The 20th century saw a proliferation of laws allowing for the creation of corporations by registration across the world, which helped to drive economic booms in many countries before and after World War I. Another major post World War I shift was toward the development of conglomerates, in which large corporations purchased smaller corporations to expand their industrial base.
Starting in the 1980s, many countries with large state-owned corporations moved toward privatization, the selling of publicly owned (or 'nationalised') services and enterprises to corporations. Deregulation (reducing the regulation of corporate activity) often accompanied privatization as part of a laissez-faire policy.
Ownership and control.
A corporation is, at least in theory, owned and controlled by its members. In a joint-stock company the members are known as shareholders and each of their shares in the ownership, control and profits of the corporation is determined by the portion of shares in the company that they own. Thus a person who owns a quarter of the shares of a joint-stock company owns a quarter of the company, is entitled to a quarter of the profit (or at least a quarter of the profit given to shareholders as dividends) and has a quarter of the votes capable of being cast at general meetings.
In another kind of corporation the legal document which established the corporation or which contains its current rules will determine who the corporation's members are. Who a member is depends on what kind of corporation is involved. In a worker cooperative the members are people who work for the cooperative. In a credit union the members are people who have accounts with the credit union.
The day-to-day activities of a corporation are typically controlled by individuals appointed by the members. In some cases this will be a single individual but more commonly corporations are controlled by a committee or by committees. Broadly speaking there are two kinds of committee structure.
Formation.
Historically, corporations were created by a charter granted by government. Today, corporations are usually registered with the state, province, or national government and regulated by the laws enacted by that government. Registration is the main prerequisite to the corporation's assumption of limited liability. The law sometimes requires the corporation to designate its principal address, as well as a registered agent (a person or company designated to receive legal service of process). It may also be required to designate an agent or other legal representative of the corporation.
Generally, a corporation files articles of incorporation with the government, laying out the general nature of the corporation, the amount of stock it is authorized to issue, and the names and addresses of directors. Once the articles are approved, the corporation's directors meet to create bylaws that govern the internal functions of the corporation, such as meeting procedures and officer positions.
The law of the jurisdiction in which a corporation operates will regulate most of its internal activities, as well as its finances. If a corporation operates outside its home state, it is often required to register with other governments as a foreign corporation, and is almost always subject to laws of its host state pertaining to employment, crimes, contracts, civil actions, and the like.
Naming.
Corporations generally have a distinct name. Historically, some corporations were named after their membership: for instance, "The President and Fellows of Harvard College." Nowadays, corporations in most jurisdictions have a distinct name that does not need to make reference to their membership. In Canada, this possibility is taken to its logical extreme: many smaller Canadian corporations have no names at all, merely numbers based on a registration number (for example, "12345678 Ontario Limited"), which is assigned by the provincial or territorial government where the corporation incorporates.
In most countries, corporate names include a term or an abbreviation that denotes the corporate status of the entity (for example, "Incorporated" or "Inc." in the United States) or the limited liability of its members (for example, "Limited" or "Ltd."). These terms vary by jurisdiction and language. In some jurisdictions they are mandatory, and in others they are not. Their use puts everybody on constructive notice that they are dealing with an entity whose liability is limited: one can only collect from whatever assets the entity still controls when one obtains a judgment against it.
Some jurisdictions do not allow the use of the word "company" alone to denote corporate status, since the word "company" may refer to a partnership or some other form of collective ownership (in the United States it can be used by a sole proprietorship but this is not generally the case elsewhere).

</doc>
<doc id="7487" url="https://en.wikipedia.org/wiki?curid=7487" title="Fairchild Channel F">
Fairchild Channel F

The Fairchild Channel F is a home video game console released by Fairchild Semiconductor in November 1976 at the retail price of $169.95. It has the distinction of being the first programmable ROM cartridge–based video game console, and the first console to use a microprocessor. It was launched as the Video Entertainment System, or VES, but when Atari released their VCS the next year, Fairchild renamed its machine. By 1977, the Fairchild Channel F had sold 250,000 units and trailed behind the VCS.
The console.
The Channel F electronics were designed by Jerry Lawson using the Fairchild F8 CPU, the first public outing of this processor. The F8 was very complex compared to the typical integrated circuits of the day, and had more inputs and outputs than other contemporary chips. Because chip packaging was not available with enough pins, the F8 was instead fabricated as a pair of chips that had to be used together to form a complete CPU.
Lawson worked with Nick Talesfore and Ron Smith. As manager of Industrial Design, Talesfore was responsible for the design of the hand controllers, console, and video game cartridges. Smith was responsible for the mechanical engineering of the video cartridges and hand controllers. All worked for Wilf Corigan, head of Fairchild Semiconductor, a division of Fairchild Camera & Instrument.
One feature unique to this console is the 'hold' button, which allowed the player to freeze the game, change the time or change the speed of the game during the course of the game. In the original unit, sound is played through an internal speaker, rather than the TV set. However, the System II passed sound to the television through the RF modulator.
Controllers.
The controllers are a joystick without a base; the main body is a large hand grip with a triangular "cap" on top, the top being the portion that actually moved for eight-way directional control. It could be used as both a joystick and paddle (twist), and not only pushed down to operate as a fire button but also pulled up. The model 1 unit contained a small compartment for storing the controllers when moving it. The System II featured detachable controllers and had two holders at the back to wind the cable around and to store the controller in. Zircon later offered a special control which featured an action button on the front of the joystick. It was marketed by Zircon as "Channel F Jet-Stick" in a letter sent out to registered owners before Christmas 1982. They also released it as an Atari-compatible controller called "Video Command", first released without the extra fire button. Before that, only the downwards plunge motion was connected and acted as the fire button; the pull-up and twist actions weren't connected to anything.
Games.
Twenty-seven cartridges, termed 'Videocarts', were officially released to consumers in the United States during the ownership of Fairchild and Zircon, the first twenty-one of which were released by Fairchild. Several of these cartridges were capable of playing more than one game and were typically priced at $19.95. The Videocarts were yellow and approximately the size and overall texture of an 8 track cartridge. They usually featured colorful label artwork. The earlier artwork was created by nationally known artist Tom Kamifuji and art directed by Nick Talesfore. The console contained two built-in games, Tennis and Hockey, which were both advanced "Pong" clones. In Hockey the reflecting bar could be changed to diagonals by twisting the controller, and could move all over the playing field. Tennis was much like the original Pong.
A sales brochure from 1978 listed 'Keyboard Videocarts' for sale. The three shown were "K-1 Casino Poker", "K-2 Space Odyssey", and "K-3 Pro-Football". These were intended to use the Keyboard accessory. All further brochures, released after Zircon took over Fairchild, never listed this accessory nor anything called a Keyboard Videocart.
There was one additional cartridge released numbered Videocart-51 and simply titled 'Demo 1'. This Videocart was shown in a single sales brochure released shortly after Zircon acquired the company. It was never listed for sale after this single brochure which was used for winter of 1979.
List of games.
Homebrewed
Carts listed (as mentioned above) but never released:
Official carts that also exist:
German SABA also released a few compatible carts different from the original carts, translation in Videocart 1 Tic-Tac-Toe to German words, Videocart 3 released with different abbreviations (German), Videocart 18 changed graphics and German word list and the SABA 20, a chess game released only by SABA.
Market impact.
The biggest effect of the Channel F in the market was to spur Atari into improving and releasing their next-generation console which was then in development. Then codenamed "Stella," the machine was also set to utilize cartridges; after seeing the Channel F, Atari realized they needed to release it before the market was flooded with cartridge-based machines. With cash flow dwindling as sales of their existing Pong-based systems dried up, they were forced to sell to Warner Communications to gain the capital they needed. When the Atari VCS gaming system (whose name was coined as a takeoff of the VES) was released a year later, it had considerably better graphics and sound.
Reception.
Ken Uston reviewed 32 games in his book "Ken Uston's Guide to Buying and Beating the Home Video Games" in 1982, and rated some of the Channel F's titles highly; of these, "Alien Invasion" and "Video Whizball" were considered by Uston to be "the finest adult cartridges currently available for the Fairchild Channel F System." The games on the whole, however, rated last on his survey of over 200 games for the Atari, Intellivision, Astrocade and Odyssey consoles, and contemporary games were rated "Average" with future Channel F games rated "below average". Uston rated almost one half of the Channel F games as "high in interest" and called that "an impressive proportion" and further noted that "Some of the Channel F cartridges are timeless; no matter what technological developments occur, they will continue to be of interest." His overall conclusion was that the games "serve a limited, but useful, purpose" and that the "strength of the Channel F offering is in its excellent educational line for children."
In 1983, after Zircon announced its discontinuation of the Channel F, "Video Games" reviewed the console. Calling it "the system nobody knows", the magazine described its graphics and sounds as "somewhat primitive by today's standards". It described "Space War" as perhaps "the most antiquated game of its type still on the market", and rated the 25 games for the console with an average grade of three ("not too good") on a scale from one to ten. The magazine stated, however, that Fairchild "managed to create some fascinating games, even by today's standards", calling "Casino Royale" ("Video Blackjack") "the best card game, from blackjack to bridge, made for "any" TV-game system". It also favorably reviewed "Dodge-It" ("simple but great"), "Robot War" ("Berzerk without guns"), and "Whizball" ("thoroughly original ... hockey "with" guns"), but concluded that only those interested in nostalgia, video game collecting, or card games would purchase the Channel F in 1983.
Technical specifications.
Original Channel F technical specifications:
The Channel F System II.
Some time in 1979, Zircon International bought the rights to the Channel F and released the re-designed console as the Channel F System II to compete with Atari's VCS. This re-designed System II was completed by Nick Talesfore at Fairchild. He was the same industrial designer who designed the original game console. Only six new games were released after the debut of the second system before its death, several of which were developed at Fairchild before they sold it off.
The major changes were in design, with the controllers removable from the base unit instead of being wired directly into it, the storage compartment was moved to the rear of the unit, and the sound was now mixed into the TV signal so the unit no longer needed a speaker. This version also featured a simpler and more modern-looking case design. However, by this time the market was in the midst of the first video game crash, and Fairchild eventually threw in the towel and left the market. A number of licensed versions were released in Europe, including the Luxor Video Entertainment System in Scandinavia (Sweden), Adman Grandstand in the UK, and the Saba Videoplay, Nordmende Teleplay and ITT Tele-Match Processor, from Germany and also Dumont Videoplay and Barco Challenger from the Barco/Dumont company in Italy and Belgium.
Homebrew.
Like many other discontinued consoles, the Channel F lives on through homebrew. For example, a 2009 version of "Pac-Man" was developed and distributed for the Channel F.

</doc>
<doc id="7489" url="https://en.wikipedia.org/wiki?curid=7489" title="Collation">
Collation

Collation is the assembly of written information into a standard order. Many systems of collation are based on numerical order or alphabetical order, or extensions and combinations thereof. Collation is a fundamental element of most office filing systems, library catalogs, and reference books.
Collation differs from "classification" in that classification is concerned with arranging information into logical categories, while collation is concerned with the ordering of items of information, usually based on the form of their identifiers. Formally speaking, a collation method typically defines a total order on a set of possible identifiers, called sort keys, which consequently produces a total preorder on the set of items of information (items with the same identifier are not placed in any defined order).
A collation algorithm such as the Unicode collation algorithm defines an order through the process of comparing two given character strings and deciding which should come before the other. When an order has been defined in this way, a "sorting algorithm" can be used to put a list of any number of items into that order.
The main advantage of collation is that it makes it fast and easy for a user to find an element in the list, or to confirm that it is absent from the list. In automatic systems this can be done using a binary search algorithm or interpolation search; manual searching may be performed using a roughly similar procedure, though this will often be done unconsciously. Other advantages are that one can easily find the first or last elements on the list (most likely to be useful in the case of numerically sorted data), or elements in a given range (useful again in the case of numerical data, and also with alphabetically ordered data when one may be sure of only the first few letters of the sought item or items).
Numerical and chronological order.
Strings representing numbers may be sorted based on the values of the numbers that they represent. For example, "-4", "2.5", "10", "89", "30,000". Note that pure application of this method may provide only a partial ordering on the strings, since different strings can represent the same number (as with "2" and "2.0" or, when scientific notation is used, "2e3" and "2000").
A similar approach may be taken with strings representing dates or other items that can be ordered chronologically or in some other natural fashion.
Alphabetical order.
Alphabetical order is the basis for many systems of collation where items of information are identified by strings consisting principally of letters from an alphabet. The ordering of the strings relies on the existence of a standard ordering for the letters of the alphabet in question. (The system is not limited to alphabets in the strict technical sense; languages that use a syllabary or abugida, for example Cherokee, can use the same ordering principle provided there is a set ordering for the symbols used.)
To decide which of two strings comes first in alphabetical order, initially their first letters are compared. The string whose first letter appears earlier in the alphabet comes first in alphabetical order. If the first letters are the same, then the second letters are compared, and so on, until the order is decided. (If one string runs out of letters to compare, then it is deemed to come first; for example, "cart" comes before "carthorse".) The result of arranging a set of strings in alphabetical order is that words with the same first letter are grouped together, and within such a group words with the same first two letters are grouped together, and so on.
Capital letters are typically treated as equivalent to their corresponding lowercase letters. (For alternative treatments in computerized systems, see Automated collation, below.)
Certain limitations, complications, and special conventions may apply when alphabetical order is used:
In several languages the rules have changed over time, and so older dictionaries may use a different order than modern ones. Furthermore, collation may depend on use. For example, German dictionaries and telephone directories use different approaches.
Radical-and-stroke sorting.
Another form of collation is radical-and-stroke sorting, used for non-alphabetic writing systems such as the hanzi of Chinese and the kanji of Japanese, whose thousands of symbols defy ordering by convention. In this system, common components of characters are identified; these are called radicals in Chinese and logographic systems derived from Chinese. Characters are then grouped by their primary radical, then ordered by number of pen strokes within radicals. When there is no obvious radical or more than one radical, convention governs which is used for collation. For example, the Chinese character 妈 (meaning "mother") is sorted as a six-stroke character under the three-stroke primary radical 女.
The radical-and-stroke system is cumbersome compared to an alphabetical system in which there are a few characters, all unambiguous. The choice of which components of a logograph comprise separate radicals and which radical is primary is not clear-cut. As a result, logographic languages often supplement radical-and-stroke ordering with alphabetic sorting of a phonetic conversion of the logographs. For example, the kanji word ""Tōkyō" (東京), the Japanese name of Tokyo, can be sorted as if it were spelled out in the Japanese characters of the hiragana syllabary as "to-u-ki-yo-u" (とうきょう), using the conventional sorting order for these characters.
In addition, in Greater China, surname stroke ordering is a convention in some official documents where people's names are listed without hierarchy.
The radical-and-stroke system, or some similar pattern-matching and stroke-counting method, was traditionally the only practical method for constructing dictionaries that someone could use to look up a logograph whose pronunciation was unknown. With the advent of computers, dictionary programs are now available that allow one to handwrite a character using a mouse or stylus.
Automated collation.
When information is stored in digital systems, collation may become an automated process. It is then necessary to implement an appropriate collation algorithm that allows the information to be sorted in a satisfactory manner for the application in question. Often the aim will be to achieve an alphabetical or numerical ordering that follows the standard criteria as described in the preceding sections. However, not all of these criteria are easy to automate.
The simplest kind of automated collation is based on the numerical codes of the symbols in a character set, such as ASCII coding (or any of its supersets such as Unicode), with the symbols being ordered in increasing numerical order of their codes, and this ordering being extended to strings in accordance with the basic principles of alphabetical ordering (mathematically speaking, lexicographical ordering). So a computer program might treat the characters "a", "b", "C", "d", and "$" as being ordered "$", "C", "a", "b", "d" (the corresponding ASCII codes are "$" = 36, "a" = 97, "b" = 98, "C" = 67, and "d" = 100). Therefore, strings beginning with "C" (or any other capital letter) would be sorted before strings with lower-case "a", "b", etc. This is sometimes called "ASCIIbetical order".
The above method has the disadvantage that it can deviate from the standard alphabetical order that human users would expect, particularly due to the unexpected ordering of capital letters before all lower-case ones (and possibly the unexpected treatment of spaces and other non-letter characters). It is therefore often applied with certain refinements, the most obvious being the conversion of capitals to lowercase before comparing ASCII values.
In many collation algorithms, the comparison is based not on the numerical codes of the characters, but with reference to the collating sequence – a sequence in which the characters are assumed to come for the purpose of collation – as well as other ordering rules appropriate to the given application. This can serve to apply the correct conventions used for alphabetical ordering in the language in question, dealing properly with differently cased letters, modified letters, digraphs, particular abbreviations, and so on, as mentioned above under Alphabetical order, and in detail in the Alphabetical order article. Such algorithms are potentially quite complex, possibly requiring several passes through the text.
Problems are nonetheless still common when the algorithm has to encompass more than one language. For example, in German dictionaries the word "ökonomisch" comes between "offenbar" and "olfaktorisch", while Turkish dictionaries treat "o" and "ö" as different letters, placing "oyun" before "öbür".
A standard algorithm for collating any collection of strings composed of any standard Unicode symbols is the Unicode Collation Algorithm. This can be adapted to use the appropriate collation sequence for a given language by tailoring its default collation table. Several such tailorings are collected in Common Locale Data Repository.
Sort keys.
In some applications, the strings by which items are collated may differ from the identifiers that are displayed. For example, "The Shining" might be sorted as "Shining, The" (see Alphabetical order above), but it may still be desired to display it as "The Shining". In this case two sets of strings can be stored, one for display purposes, and another for collation purposes. Strings used for collation in this way are called "sort keys".
Issues with numbers.
Sometimes, it is desired to order text with embedded numbers using proper numerical order. For example, "Figure 7b" goes before "Figure 11a", even though '7' comes after '1' in Unicode. This can be extended to Roman numerals. This behavior is not particularly difficult to produce as long as only integers are to be sorted, although it can slow down sorting significantly. For example, Windows XP does this when sorting file names.
Sorting decimals properly is a bit more difficult, because different locales use different symbols for a decimal point, and sometimes the same character used as a decimal point is also used as a separator, for example "Section 3.2.5". There is no universal answer for how to sort such strings; any rules are application dependent.
Ascending order of numbers differs from alphabetical order, e.g. 11 comes alphabetically before 2. This can be fixed with leading zeros: 02 comes alphabetically before 11. See e.g. ISO 8601.
Also −13 comes alphabetically after −12 although it is less. With negative numbers, to make ascending order correspond with alphabetical sorting, more drastic measures are needed such as adding a constant to all numbers to make them all positive.
Labeling of ordered items.
In some contexts, numbers and letters are used not so much as a basis for establishing an ordering, but as a means of labeling items that are already ordered. For example, pages, sections, chapters, and the like, as well as the items of lists, are frequently "numbered" in this way. Labeling series that may be used include ordinary Arabic numerals (1, 2, 3, ...), Roman numerals (I, II, III, ... or i, ii, iii, ...), or letters (A, B, C, ... or a, b, c, ...). (An alternative method for indicating list items, without numbering them, is to use a bulleted list.)
When letters of an alphabet are used for this purpose of enumeration, there are certain language-specific conventions as to which letters are used. For example, the Russian letters Ъ and Ь (which in writing are only used for modifying the preceding consonant), and usually also Ы, Й, and Ё, are usually omitted. Also in many languages that use extended Latin script, the modified letters are often not used in enumeration.

</doc>
<doc id="7490" url="https://en.wikipedia.org/wiki?curid=7490" title="Civil Rights Act">
Civil Rights Act

Civil Rights Act may refer to several acts in the history of civil rights in the United States, including:

</doc>
<doc id="7491" url="https://en.wikipedia.org/wiki?curid=7491" title="Cola">
Cola

Cola is a sweetened, carbonated soft drink, derived from drinks that originally contained caffeine from the kola nut and cocaine from coca leaves, flavored with vanilla and other ingredients. Most colas now use other flavoring (and caffeinating) ingredients with a similar taste. Colas became popular worldwide after pharmacist John Pemberton invented Coca-Cola in 1886. His non-alcoholic recipe was inspired by the coca wine of pharmacist Angelo Mariani, created in 1863.
Modern colas usually contain caramel color, caffeine and sweeteners such as sugar or high fructose corn syrup.
Flavorings.
Despite the name, the primary modern flavoring ingredients in a cola drink are sugar, citrus oils (from oranges, limes, or lemon fruit peel), cinnamon, vanilla, and an acidic flavorant. Manufacturers of cola drinks add trace ingredients to create distinctively different tastes for each brand. Trace flavorings may include nutmeg and a wide variety of ingredients, but the base flavorings that most people identify with a cola taste remain vanilla and cinnamon. Acidity is often provided by phosphoric acid, sometimes accompanied by citric or other isolated acids. Coca-Cola's recipe and several others are maintained as corporate trade secrets.
A variety of different sweeteners may be added to cola, often partly dependent on local agricultural policy. High-fructose corn syrup (HFCS) is predominantly used in the United States and Canada due to the lower cost of government-subsidized corn. In Europe, however, HFCS is subject to production quotas designed to encourage the production of sugar; sugar is thus typically used to sweeten sodas. In addition, stevia or an artificial sweetener may be used; "sugar-free" or "diet" colas typically contain artificial sweeteners only.
Consumers may prefer the taste of cola manufactured with sugar; as in the United States, with imported Mexican Coca-Cola. Kosher for Passover Coca-Cola sold in the U.S. around the Jewish holiday also uses sucrose rather than HFCS and is also highly sought after by people who prefer the original taste. In addition, PepsiCo has recently been marketing versions of its Pepsi and Mountain Dew sodas that are sweetened with sugar instead of HFCS. These are marketed under the name "Throwback" and became "permanent" products on the lineup.
Health.
A 2007 study found that consumption of colas, both those with natural sweetening and those with artificial sweetening, was associated with increased risk of chronic kidney disease. The phosphoric acid used in colas was thought to be a possible cause.
Studies indicate "soda and sweetened drinks are the main source of calories in American diet", so most nutritionists advise that Coca-Cola and other soft drinks can be harmful if consumed excessively, particularly to young children whose soft drink consumption competes with, rather than complements, a balanced diet. Studies have shown that regular soft drink users have a lower intake of calcium, magnesium, ascorbic acid, riboflavin, and vitamin A.
The drink has also aroused criticism for its use of caffeine, which can cause physical dependence (caffeine addiction). A link has been shown between long-term regular cola intake and osteoporosis in older women (but not men). This was thought to be due to the presence of phosphoric acid, and the risk was found to be the same for caffeinated and noncaffeinated colas, as well as the same for diet and sugared colas.
Many soft drinks are sweetened mostly or entirely with high-fructose corn syrup, rather than sugar. Some nutritionists caution against consumption of corn syrup because it may aggravate obesity and type-2 diabetes more than cane sugar.

</doc>
<doc id="7492" url="https://en.wikipedia.org/wiki?curid=7492" title="Capability Maturity Model">
Capability Maturity Model

The Capability Maturity Model (CMM) is a development model created after study of data collected from organizations that contracted with the U.S. Department of Defense, who funded the research. The term "maturity" relates to the degree of formality and optimization of processes, from "ad hoc" practices, to formally defined steps, to managed result metrics, to active optimization of the processes.
The model's aim is to improve existing software-development processes, but it can also be applied to other processes.
Overview.
The Capability Maturity Model was originally developed as a tool for objectively assessing the ability of government contractors' "processes" to implement a contracted software project. The model is based on the process maturity framework first described in the 1989 book "Managing the Software Process" by Watts Humphrey. It was later published in a report in 1993 and as a book by the same authors in 1995.
Though the model comes from the field of software development, it is also used as a general model to aid in business processes generally, and has been used extensively worldwide in government offices, commerce, industry and software-development organizations.
History.
Prior need for software processes.
In the 1960s, the use of computers grew more widespread, more flexible and less costly. Organizations began to adopt computerized information systems, and the demand for software development grew significantly. Many processes for software development were in their infancy, with few standard or "best practice" approaches defined.
As a result, the growth was accompanied by growing pains: project failure was common, the field of computer science was still in its early years, and the ambitions for project scale and complexity exceeded the market capability to deliver adequate products within a planned budget. Individuals such as Edward Yourdon, Larry Constantine, Gerald Weinberg, Tom DeMarco, and David Parnas began to publish articles and books with research results in an attempt to professionalize the software-development processes.
In the 1980s, several US military projects involving software subcontractors ran over-budget and were completed far later than planned, if at all. In an effort to determine why this was occurring, the United States Air Force funded a study at the SEI.
Precursor.
The first application of a staged maturity model to IT was not by CMU/SEI, but rather by Richard L. Nolan, who, in 1973 published the stages of growth model for IT organizations.
Watts Humphrey began developing his process maturity concepts during the later stages of his 27-year career at IBM.
Development at Software Engineering Institute.
Active development of the model by the US Department of Defense Software Engineering Institute (SEI) began in 1986 when Humphrey joined the Software Engineering Institute located at Carnegie Mellon University in Pittsburgh, Pennsylvania after retiring from IBM. At the request of the U.S. Air Force he began formalizing his Process Maturity Framework to aid the U.S. Department of Defense in evaluating the capability of software contractors as part of awarding contracts.
The result of the Air Force study was a model for the military to use as an objective evaluation of software subcontractors' process capability maturity. Humphrey based this framework on the earlier Quality Management Maturity Grid developed by Philip B. Crosby in his book "Quality is Free". Humphrey's approach differed because of his unique insight that organizations mature their processes in stages based on solving process problems in a specific order. Humphrey based his approach on the staged evolution of a system of software development practices within an organization, rather than measuring the maturity of each separate development process independently. The CMM has thus been used by different organizations as a general and powerful tool for understanding and then improving general business process performance.
Watts Humphrey's Capability Maturity Model (CMM) was published in 1988 and as a book in 1989, in "Managing the Software Process".
Organizations were originally assessed using a process maturity questionnaire and a Software Capability Evaluation method devised by Humphrey and his colleagues at the Software Engineering Institute.
The full representation of the Capability Maturity Model as a set of defined process areas and practices at each of the five maturity levels was initiated in 1991, with Version 1.1 being completed in January 1993. The CMM was published as a book in 1995 by its primary authors, Mark C. Paulk, Charles V. Weber, Bill Curtis, and Mary Beth Chrissis.
United States of America
New York, USA.
CMMI.
The CMM model's application in software development has sometimes been problematic. Applying multiple models that are not integrated within and across an organization could be costly in training, appraisals, and improvement activities. The Capability Maturity Model Integration (CMMI) project was formed to sort out the problem of using multiple models for software development processes, thus the CMMI model has superseded the CMM model, though the CMM model continues to be a general theoretical process capability model used in the public domain.
Adapted to other processes.
The CMM was originally intended as a tool to evaluate the ability of government contractors to perform a contracted software project. Though it comes from the area of software development, it can be, has been, and continues to be widely applied as a general model of the maturity of "process" (e.g., IT service management processes) in IS/IT (and other) organizations.
Model topics.
Maturity model.
A maturity model can be viewed as a set of structured levels that describe how well the behaviors, practices and processes of an organization can reliably and sustainably produce required outcomes.
A maturity model can be used as a benchmark for comparison and as an aid to understanding - for example, for comparative assessment of different organizations where there is something in common that can be used as a basis for comparison. In the case of the CMM, for example, the basis for comparison would be the organizations' software development processes.
Structure.
The model involves five aspects:
Levels.
There are five levels defined along the continuum of the model and, according to the SEI: "Predictability, effectiveness, and control of an organization's software processes are believed to improve as the organization moves up these five levels. While not rigorous, the empirical evidence to date supports this belief".
Within each of these maturity levels are Key Process Areas which characterise that level, and for each such area there are five factors: goals, commitment, ability, measurement, and verification. These are not necessarily unique to CMM, representing — as they do — the stages that organizations must go through on the way to becoming mature.
The model provides a theoretical continuum along which process maturity can be developed incrementally from one level to the next. Skipping levels is not allowed/feasible.
At maturity level 5, processes are concerned with addressing statistical "common causes" of process variation and changing the process (for example, to shift the mean of the process performance) to improve process performance. This would be done at the same time as maintaining the likelihood of achieving the established quantitative process-improvement objectives. There are only a few companies in the world that have attained this level 5.
Critique.
The model was originally intended to evaluate the ability of government contractors to perform a software project. It has been used for and may be suited to that purpose, but critics pointed out that process maturity according to the CMM was not necessarily mandatory for successful software development.
Software process framework.
The software process framework documented is intended to guide those wishing to assess an organization's or project's consistency with the Key Process Areas. For each maturity level there are five checklist types:

</doc>
<doc id="7498" url="https://en.wikipedia.org/wiki?curid=7498" title="Centillion">
Centillion

One centillion is a number, which is equal to either 10303 or 10600, depending on the system used.
Short scale.
In areas using the short scale such as Canada, the US, and the UK, a centillion is 10303. It is formed on a pattern starting with a million: a million (1,000,000) has three zeroes more than a thousand (1,000); a billion (1,000,000,000) has two groups of three zeroes more than a thousand, and so on. One centillion has one hundred groups of three zeroes more than one thousand.
A centillion in the short-scale system is equivalent to a quinquagintilliard, or a thousand quinquagintillion, in the long-scale system.
Long scale.
In long scale usage, one centillion is 10600, which is equal to (106)100; that is, it is the number with a hundred times as many zeroes as a million.
A centillion in the long scale is equivalent to a cennovemnonagintillion in the short scale.

</doc>
<doc id="7499" url="https://en.wikipedia.org/wiki?curid=7499" title="RDX">
RDX

RDX, an initialism for Research Department explosive, is an explosive nitroamine widely used in military and industrial applications. It was developed as an explosive which was more powerful than TNT, and it saw wide use in World War II. RDX is also known as Research Department Formula X, cyclonite, hexogen (particularly in German and German-influenced languages), and T4. Its chemical name is cyclotrimethylenetrinitramine; name variants include cyclotrimethylene-trinitramine and cyclotrimethylene trinitramine.
In its pure, synthesized state RDX is a white, crystalline solid. It is often used in mixtures with other explosives and plasticizers, phlegmatizers or desensitizers. RDX is stable in storage and is considered one of the most powerful and brisant of the military high explosives.
Name.
RDX is also known, but less commonly, as cyclonite, hexogen (particularly in Russian, German and German-influenced languages), T4 and chemically as cyclotrimethylenetrinitramine. Tenney L Davis, writing in the US in 1943, stated it was generally known in the US as cyclonite; the Germans called it Hexogen, the Italians T4. In the 1930s, the Royal Arsenal, Woolwich, started investigating cyclonite as an explosive to use against German U-boats that were being built with thicker hulls. Britain wanted an explosive that was more powerful than TNT. For security reasons, Britain termed Cyclonite as "Research Department Explosive" (R.D.X.). The term RDX appeared in the United States in 1946, but the name RDX is given without explanation. The first public reference in the United Kingdom to the name RDX, or R.D.X. to use the official title, appeared in 1948; its authors were the Managing Chemist, ROF Bridgwater, the Chemical Research and Development Department, Woolwich, and the Director of Royal Ordnance Factories, Explosives; again, it was referred to as simply RDX.
Usage.
RDX was widely used during World War II, often in explosive mixtures with TNT such as Torpex, Composition B, Cyclotols, and H6. RDX was used in one of the first plastic explosives. RDX is believed to have been used in many bomb plots including terrorist plots. The bouncing bomb depth charges used in the "Dambusters Raid" each contained of Torpex.
RDX forms the base for a number of common military explosives:
Outside military applications, RDX is also used in controlled demolition to raze structures. The demolition of the Jamestown Bridge in the US state of Rhode Island is one instance where RDX shaped charges were used to remove the span.
Properties.
The velocity of detonation of RDX at a density of 1.76 g/cm3 is 8750 m/s.
It is a colourless solid, of crystal density 1.82 g/cm3. It is obtained by reacting white fuming nitric acid (WFNA) with hexamine, producing dinitromethane and ammonium nitrate as byproducts.
It is a heterocycle and has the molecular shape of a ring. It starts to decompose at about 170 °C and melts at 204 °C. Its structural formula is: hexahydro-1,3,5-trinitro-1,3,5-triazine or (CH2-N-NO2)3.
At room temperature, it is very stable. It burns rather than explodes and detonates only with a detonator, being unaffected even by small arms fire. (This is one of the properties that make it a useful military explosive.) It is less sensitive than pentaerythritol tetranitrate (PETN). Under normal conditions, RDX has a figure of insensitivity of exactly 80 (RDX defines the reference point.).
RDX sublimates in vacuum, which limits its use in pyrotechnic fasteners for spacecraft.
RDX when exploded in air has about 1.5 times the explosive power of TNT per unit weight and about 2.0 times per unit volume.
History.
RDX was used by both sides in World War II. The US produced about per month during WWII and Germany about per month. RDX had the major advantages of possessing greater explosive power than TNT used in the First World War, and requiring no additional raw materials for its manufacture.
Germany.
The discovery of RDX dates from 1898 when Georg Friedrich Henning obtained a German patent (patent No. 104280) for its manufacture, by nitrating hexamine nitrate (hexamethylenetetramine nitrate) with concentrated nitric acid. In this 1898 patent, its properties as a medical compound were mentioned; however, three further German patents obtained by Henning in 1916 proposed its use in smokeless propellants. The German military started investigating its use in 1920 and referred to it as hexogen. Research and development findings were not published further until Edmund von Herz, described as an Austrian and later a German citizen, obtained a British patent in 1921 and a United States patent in 1922. Both patent claims were initiated in Austria; and described the manufacture of RDX by nitrating hexamethylenetetramine. The British patent claims included the manufacture of RDX by nitration, its use with or without other explosives, and its use as a bursting charge and as an initiator. The US patent claim was for the use of a hollow explosive device containing RDX and a detonator cap containing RDX. In the 1930s, Germany developed improved production methods.
During the Second World War, Germany used the code names W Salt, SH Salt, K-method, the E-method and the KA-method. These represented the names of the developers of the various chemical processes used to prepare RDX. The W-method was developed by Wolfram in 1934 and gave RDX the code name "W-Salz". It used sulfamic acid, formaldehyde and nitric acid. SH-Salz (SH salt) was from Schnurr who developed a batch-process in 1937–38 based on nitrating hexamine. The K-method was from Knöffler and was based on adding ammonium nitrate to the hexamine / nitric acid process. The E-method was developed by Ebele, in Germany, and turned out to be identical to the Ross and Schiessler process described later. The KA-method was developed by Knöffler, in Germany, and turned out to be identical to the Bachmann process described later.
The explosive shells fired by the MK 108 cannon and the warhead of the R4M rocket, both used in Luftwaffe fighter aircraft as offensive armament, both used hexogen as their explosive base.
UK.
In the United Kingdom (UK), RDX was manufactured from 1933 by the Research Department in a pilot plant at the Royal Arsenal in Woolwich, London, a larger pilot plant being built at the RGPF Waltham Abbey just outside London in 1939. In 1939 a twin-unit industrial-scale plant was designed to be installed at a new site, ROF Bridgwater, away from London; production of RDX started at Bridgwater on one unit in August 1941. The ROF Bridgwater plant brought in ammonia and methanol as raw materials: the methanol was converted to formaldehyde and some of the ammonia converted to nitric acid, which was concentrated for RDX production. The rest of the ammonia was reacted with formaldehyde to produce hexamine. The hexamine plant was supplied by Imperial Chemical Industries; it incorporated some features based on data obtained from the United States (US). RDX was produced by continually adding hexamine and concentrated nitric acid to a cooled mixture of hexamine and nitric acid in the nitrator. The RDX was purified and processed for its intended use; recovery and reuse of some methanol and nitric acid was also carried out. The hexamine-nitration and RDX purification plants were duplicated (i.e. twin-unit) to provide some insurance against loss of production due to fire, explosion or air attack.
The United Kingdom and British Empire were fighting without allies against Nazi Germany until the middle of 1941 and had to be self-sufficient. At that time (1941), the UK had the capacity to produce (160,000 lb) of RDX per week; both Canada, an allied country and self-governing dominion within the British Empire, and the US were looked upon to supply ammunition and explosives, including RDX. By 1942 the Royal Air Force's annual requirement was forecast to be of RDX, much of which came from North America (Canada and the US).
Canada.
A different method of production to the Woolwich process was found and used in Canada, possibly at the McGill University Department of Chemistry. This was based on reacting paraformaldehyde and ammonium nitrate in acetic anhydride. A UK patent application was made by Robert Walter Schiessler (Pennsylvania State College) and James Hamilton Ross (McGill, Canada) in May 1942; the UK patent was issued in December 1947. Gilman states that the same method of production had been independently discovered by Ebele in Germany prior to Schiessler and Ross, but that this was not known by the Allies. Urbański provides details of five methods of production, and he refers to this method as the (German) E-method.
UK, US and Canadian production and development.
At the beginning of the 1940s, the major US explosive manufacturers, E. I. du Pont de Nemours & Company and Hercules, had several decades of experience of manufacturing trinitrotoluene (TNT) and had no wish to experiment with new explosives. US Army Ordnance held the same viewpoint and wanted to continue using TNT. RDX had been tested by Picatinny Arsenal in 1929 and it was regarded as too expensive and too sensitive. The Navy proposed to continue using ammonium picrate. In contrast, the National Defense Research Committee (NDRC), who had visited The Royal Arsenal, Woolwich, did not share the view that new explosives were unnecessary. James B. Conant, chairman of Division B, wished to involve academic research into this area. Conant therefore set up an Experimental Explosives Research Laboratory at the Bureau of Mines, Bruceton, Pennsylvania, using Office of Scientific Research and Development (OSRD) funding.
Woolwich method.
In 1941, the UK's Tizard Mission visited the US Army and Navy departments and part of the information handed over included details of the "Woolwich" method of manufacture of RDX and its stabilisation by mixing it with beeswax. The UK was asking that the US and Canada, combined, supply (440,000 lb) of RDX per day. A decision was taken by William H. P. Blandy, Chief of the Bureau of Ordnance to adopt RDX for use in mines and torpedoes. Given the immediate need for RDX, the US Army Ordnance, at Blandy's request, built a plant that just copied the equipment and process used at Woolwich. The result was the Wabash River Ordnance Works run by E. I. du Pont de Nemours & Company. At that time, this works had the largest nitric acid plant in the world. The Woolwich process was expensive; it needed of strong nitric acid for every pound of RDX.
By early 1941, the NDRC was researching new processes. The Woolwich or direct nitration process has at least two serious disadvantages: (1) it used large amounts of nitric acid and (2) at least one-half of the formaldehyde is lost. One mole of hexamethylenetetramine could produce at most one mole of RDX. At least three laboratories with no previous explosive experience were tasked to develop better production methods for RDX; they were based at Cornell, Michigan, and Penn State universities. Werner Emmanuel Bachmann, from Michigan, successfully developed the "combination process" by combining the Canadian process with direct nitration. The combination process required large quantities of acetic anhydride instead of nitric acid in the old British "Woolwich process". Ideally, the combination process could produce two moles of RDX from each mole of hexamethylenetetramine.
The vast production of RDX could not continue to rely on the use of natural beeswax to desensitize the RDX. A substitute stabilizer based on petroleum was developed at the Bruceton Explosives Research Laboratory.
Bachmann process.
The NDRC tasked three companies to develop pilot plants. They were the Western Cartridge Company, E. I. du Pont de Nemours & Company and Tennessee Eastman Company, part of Eastman Kodak. At the Eastman Chemical Company (TEC), a leading manufacturer of acetic anhydride, Werner Emmanuel Bachmann successfully developed a continuous-flow manufacturing process for RDX. RDX was crucial to the war effort and the current batch-production process could not keep up. In February 1942, TEC built the Wexler Bend pilot plant and began producing small amounts of RDX. This led to the US government authorizing TEC to design and build Holston Ordnance Works (H.O.W.) in June 1942. By April 1943, RDX was being manufactured there. At the end of 1944, the Holston plant and the Wabash River Ordnance Works (which used the Woolwich process) were making (50 million pounds) of Composition B per month.
The US Bachmann process for RDX was found to be richer in HMX than the United Kingdom's RDX. This later led to a RDX plant using the Bachmann process being set up at ROF Bridgwater in 1955, to produce both RDX and HMX.
Military compositions.
The United Kingdom's intention in World War II was to use "desensitised" RDX. In the original Woolwich process, RDX was phlegmatized with beeswax, but later paraffin wax was used, based on the work carried out at Bruceton. In the event the UK was unable to obtain sufficient RDX to meet its needs, some of the shortfall was met by substituting amatol, a mixture of ammonium nitrate and TNT.
Karl Dönitz was reputed to have claimed that "an aircraft can no more kill a U-boat than a crow can kill a mole". However, by May 1942 Wellington bombers began to deploy depth charges containing Torpex, a mixture of RDX, TNT and aluminium, which had up to 50 percent more destructive power than TNT-filled depth charges. Considerable quantities of the RDX–TNT mixture were produced at the Holston Ordnance Works, with Tennessee Eastman developing an automated mixing and cooling process based around the use of stainless steel conveyor belts.
Terrorism.
The 1993 Bombay bombings used RDX placed into several vehicles as bombs. RDX was the main component used for the 2006 Mumbai train bombings and the Jaipur bombings in 2008. It is also believed to be the explosive used in the 1999 Russian apartment bombings, 2004 Russian aircraft bombings, and 2010 Moscow Metro bombings.
Ahmed Ressam, the al-Qaeda Millennium Bomber, used a small quantity of RDX as one of the components in the explosives that he prepared to bomb Los Angeles International Airport on New Year's Eve 1999/2000; the combined explosives could have produced a blast forty times greater than that of a devastating car bomb.
In July 2012, the Kenyan government arrested two Iranian nationals and charged them with illegal possession of of RDX. According to the Kenyan Police, the Iranians planned to use the RDX for "attacks on Israel, US, UK and Saudi Arabian targets".
RDX was used to assassinate Lebanese prime minister Rafiq Hariri on February 14, 2005.
Toxicity.
RDX has caused convulsions (seizures) in military field personnel ingesting it, and in munition workers inhaling its dust during manufacture. The substance's toxicity has been studied for many years. At least one fatality was attributed to RDX toxicity in a European munitions manufacturing plant. The substance has low to moderate toxicity with a possible human carcinogen classification. However, further research is ongoing and this classification may be revised by the United States Environmental Protection Agency (EPA). Remediating RDX contaminated water supplies has proven to be successful.
Biodegradation.
RDX produces high amounts of carbon dioxide and nitrous oxide when treated with sewage sludge or the fungus Phanaerocheate chrysosporium. A change of a N-NO2 or C-H bond of cyclic nitramine leads to cleavage of the ring, when the C-N bonds weaken. Both wild and transgenic plants can phytoremediate explosives from soil and water.

</doc>
<doc id="7500" url="https://en.wikipedia.org/wiki?curid=7500" title="Celebes (disambiguation)">
Celebes (disambiguation)

Celebes may refer to:

</doc>
<doc id="7502" url="https://en.wikipedia.org/wiki?curid=7502" title="Christianity and Judaism">
Christianity and Judaism

Christianity is rooted in Second Temple Judaism, but the two religions diverged in the first centuries of the Christian Era. Christianity places emphasis on correct belief (or "orthodoxy"), focusing on the New Covenant as mediated through Jesus Christ, as recorded in the New Testament. Judaism places emphasis on right conduct (or "orthopraxy"), focusing on the Mosaic Covenant, as recorded in the Torah and Talmud.
Christians believe in individual salvation from sin through repentance and receiving Jesus Christ as their God and Savior through faith (and in some Christian traditions, good works). Jews believe in individual and collective participation in an eternal dialogue with God through tradition, rituals, prayers and ethical actions. Christianity generally believes in a Triune God, one person of whom became human. Judaism emphasizes the Oneness of God and rejects the Christian concept of God in human form.
Self-identification.
Judaism's purpose is to carry out what it holds to be the only Covenant between God and the Jewish people. The Torah (lit. "teaching"), both written and oral, tell the story of this covenant, and provides Jews with the terms of the covenant. The Oral Torah is the primary guide for Jews to abide by these terms, as expressed in tractate Gittin 60b, "the Holy One, Blessed be He, did not make His covenant with Israel except by virtue of the Oral Law" to help them learn how to live a holy life, and to bring holiness, peace and love into the world and into every part of life, so that life may be elevated to a high level of kedushah, originally through study and practice of the Torah, and since the destruction of the Second Temple, through prayer as expressed in tractate Sotah 49a "Since the destruction of the Temple, every day is more cursed than the preceding one; and the existence of the world is assured only by the kedusha...and the words spoken after the study of Torah." Since the adoption of the Amidah, the acknowledgement of God through the declaration from Yishayah 6:3 "Kadosh , kadosh, kadosh, is HaShem, Master of Legions; the whole world is filled with His glory". as a replacement for the study of Torah, which is a daily obligation for a Jew, and sanctifies God in itself. This continuous maintenance of relationship between the individual Jew and God through either study, or prayer repeated three times daily, is the confirmation of the original covenant. This allows the Jewish people as a community to strive and fulfill the prophecy "I, the Lord, have called you in righteousness, and will hold your hand and keep you. And I will establish you as a Covenant of the people, for a light unto the nations." () (i.e., a role model) over the course of history, and a part of the divine intent of bringing about an age of peace and sanctity where ideally a faithful life and good deeds should be ends in themselves, not means. See also Jewish principles of faith.
The self-described purpose of Christianity is to provide people with what it holds to be the only valid path to salvation as announced by the apostles of what the Book of Acts describes as, "The Way". Only in gentile (non-Jewish) settings is The Way referred to as Christian. According to Christian theologian Alister McGrath, the Jewish Christians affirmed every aspect of then contemporary Second Temple Judaism with the addition of the belief that Jesus was the messiah, with Isaiah 49:6, "an explicit parallel to 42:6" quoted by Paul in Acts 13:47 and reinterpreted by Justin the Martyr. According to Christian writers, most notably Paul, the Bible teaches that people are, in their current state, sinful, and the New Testament reveals that Jesus is both the Son of man and the Son of God, united in the hypostatic union, God the Son, God made incarnate; that Jesus' death by crucifixion was a sacrifice to atone for all of humanity's sins, and that acceptance of Jesus as Savior and Lord saves one from Divine Judgment, giving Eternal life. Jesus is the mediator of the New Covenant. His famous Sermon on the Mount is considered by some Christian scholars to be the proclamation of the New Covenant ethics, in contrast to the Mosaic Covenant of Moses from Mount Sinai. See also Christian theology.
National versus universal.
The subject of the Tanakh, or Hebrew Bible, is the history of the Children of Israel, especially in terms of their relationship with God. Thus, Judaism has also been characterized as a culture or as a civilization. In his work "Judaism as a Civilization", the founder of the Reconstructionist Movement, Rabbi Mordecai Kaplan defines Judaism as an evolving religious civilization. One crucial sign of this is that one need not believe, or even do, anything to be Jewish; the historic definition of 'Jewishness' requires only that one be born of a Jewish mother, or that one convert to Judaism in accord with Jewish law. (Today, Reform and Reconstructionist Jews also include those born of Jewish fathers and Gentile mothers if the children are raised as Jews.)
To many religious Jews, Jewish ethnicity is closely tied to their relationship with God, and thus has a strong theological component. This relationship is encapsulated in the notion that Jews are a chosen people. For strictly observant Jews, being "chosen" fundamentally means that it was God's wish that a group of people would exist in a covenant, and would be bound to obey a certain set of laws as a duty of their covenant, and that the Children of Israel "chose" to enter into this covenant with God. They view their divine purpose as being ideally a "light upon the nations" and a "holy people" (i.e., a people who live their lives fully in accordance with Divine will as an example to others), not "the one path to God". For Jews, salvation comes from God, freely given, and observance of the Law is one way of responding to God's grace.
Jews hold that other nations and peoples are not required (nor expected) to obey the Law of Moses, with the notable exception that the only laws Judaism believes are automatically binding (in order to be assured of a place in the world to come) on other nations are known as the Seven Laws of Noah. Thus, as an ethnic religion, Judaism holds that others may have their own, different, paths to God (or holiness, or "salvation"), as long as they are consistent with the "Seven Laws of Noah".
While ethnicity and culture play a large part in Jewish identity, they are not the only way Jews define themselves as Jews. There are secular Jews, who do use ethnicity and culture as their defining criteria. And there are religious Jews, who do not. Rather, religious Jews define their Jewishness within the context of their Judaism. In this context, a religious convert could "feel" more Jewish than a secular ethnic Jew. While Rabbi Kaplan defines Judaism as a civilization, there are many who would not agree, citing millennia of religious tradition and observance as more than simple civilization. Most observant Jews would say that Judaism is a love story.
Judaism and Christianity share the belief that there is One, True God, who is the only one worthy to be worshipped. Judaism sees this One, True God as a singular, ineffable, undefinable being. Phrases such as "Ground of All Being", "Unfolding Reality" and "Creator and Sustainer of Life" capture only portions of who God is to Jews. While God does not change, our perception of God does, and so, Jews are open to new experiences of God's presence. Christianity, with a few exceptions, sees the One, True God as having triune personhood: God the Father, God the Son (Jesus) and God the Holy Spirit. God is the same yesterday, today and tomorrow, so Christians generally look to the Scriptures (both Hebrew and Christian) for an understanding of who God is.
Christianity is characterized by its claim to universality, which marks a significant break from current Jewish identity and thought, but has its roots in Hellenistic Judaism. Christians believe that Jesus represents the fulfillment of God's promise to Abraham and the nation of Israel, that Israel would be a blessing to all nations. Most Christians believe that the Law was "fulfilled" by Jesus and has become unnecessary to "faith life". Although Christians generally believe their religion to be very inclusive (since not only Jews but all gentiles can be Christian), Jews see Christianity as highly exclusive, because some denominations view non-Christians (such as Jews and Pagans) as having an incomplete or imperfect relationship with God, and therefore excluded from grace, salvation, heaven, or eternal life. For some Christians, it is the stated or "confessed" belief in Jesus as Savior that makes God's grace available to an individual, and salvation can come no other way (Solus Christus in Protestantism, Extra Ecclesiam nulla salus in Catholicism, see dual covenant theology for a traditional view). In Catholicism, Orthodoxy, Anglicanism and 'mainline' Protestantism (Lutherans, Methodists et cetera), sanctifying grace is ordinarily received via the Sacraments. However, God can also work outside the Sacraments. Also see "Invincible Ignorance" as understood in Catholic theology.
This crucial difference between the two religions has other implications. For example, while in a conversion to Judaism a convert must accept basic Jewish principles of faith, and renounce all other religions, the process is more like a form of adoption, or changing national citizenship (i.e. becoming a formal member of the people, or tribe), with the convert becoming a "child of Abraham and Sarah." For many reasons, some historical and some religious, Judaism does not encourage its members to convert others and in fact would require the initiative from the person who would like to convert. In contrast, most Christian denominations actively seek converts, following the Great Commission, and conversion to Christianity is generally a declaration of faith (although some denominations view it specifically as adoption into a community of Christ, and orthodox Christian tradition views it as being a literal joining together of the members of Christ's body).
Both Christianity and Judaism have been affected by the diverse cultures of their respective members. For example, what Jews from Eastern Europe and from North Africa consider "Jewish food" has more in common with the cuisines of non-Jewish Eastern Europeans and North Africans than with each other, although for religious Jews all food-preparation must conform to the same laws of Kashrut. According to non-Orthodox Jews and critical historians, Jewish law too has been affected by surrounding cultures (for example, some scholars argue that the establishment of absolute monotheism in Judaism was a reaction against the dualism of Zoroastrianism that Jews encountered when living under Persian rule; Jews rejected polygamy during the Middle Ages, influenced by their Christian neighbors). According to Orthodox Jews too there are variations in Jewish custom from one part of the world to another. It was for this reason that Joseph Karo's Shulchan Aruch did not become established as the authoritative code of Jewish law until after Moshe Isserlis added his commentary, which documented variations in local custom.
Sacred texts.
The Hebrew Bible is composed of three parts; the Torah (Instruction, the Septuagint translated the Hebrew to "nomos" or "Law"), the Nevi'im (Prophets) and the Ketuvim (Writings). Collectively, these are known as the Tanakh. According to Rabbinic Judaism the Torah was revealed by God to Moses; within it, Jews find 613 Mitzvot (commandments).
Rabbinic tradition asserts that God revealed two Torahs to Moses, one that was written down, and one that was transmitted orally. Whereas the written Torah has a fixed form, the Oral Torah is a living tradition that includes not only specific supplements to the written Torah (for instance, what is the proper manner of "shechita" and what is meant by "Frontlets" in the Shema), but also procedures for understanding and talking about the written Torah (thus, the Oral Torah revealed at Sinai includes debates among rabbis who lived long after Moses). The Oral Law elaborations of narratives in the Bible and stories about the rabbis are referred to as "aggadah". It also includes elaboration of the 613 commandments in the form of laws referred to as "halakha". Elements of the Oral Torah were committed to writing and edited by Judah HaNasi in the Mishnah in 200 CE; much more of the Oral Torah were committed to writing in the Babylonian and Jerusalem Talmuds, which were edited around 600 CE and 450 CE, respectively. The Talmuds are notable for the way they combine law and lore, for their explication of the midrashic method of interpreting tests, and for their accounts of debates among rabbis, which preserve divergent and conflicting interpretations of the Bible and legal rulings.
Since the transcription of the Talmud, notable rabbis have compiled law codes that are generally held in high regard: the Mishneh Torah, the Tur, and the Shulchan Aruch. The latter, which was based on earlier codes and supplemented by the commentary by Moshe Isserles that notes other practices and customs practiced by Jews in different communities, especially among Ashkenazim, is generally held to be authoritative by Orthodox Jews. The Zohar, which was written in the 13th century, is generally held as the most important esoteric treatise of the Jews.
All contemporary Jewish movements consider the Tanakh, and the Oral Torah in the form of the Mishnah and Talmuds as sacred, although movements are divided as to claims concerning their divine revelation, and also their authority. For Jews, the Torah - written and oral - is the primary guide to the relationship between God and man, a living document that has unfolded and will continue to unfold whole new insights over the generations and millennia. A saying that captures this goes, "Turn it Torah's words over and over again, for everything is in it."
Christians accept the Written Torah and other books of the Hebrew Bible (alternatively called Old Testament) as Scripture, although they generally give readings from the Koine Greek Septuagint translation instead of the Biblical Hebrew/Biblical Aramaic Masoretic Text. Two notable examples are:
Instead of the traditional Jewish order and names for the books, Christians organize and name the books closer to that found in the Septuagint. Some Christian denominations (such as Anglican, Roman Catholic, and Eastern Orthodox), include a number of books that are not in the Hebrew Bible (the biblical apocrypha or deuterocanonical books or Anagignoskomena, see Development of the Old Testament canon) in their biblical canon that are not in today's Jewish canon, although they were included in the Septuagint. Christians reject the Jewish Oral Torah, which was still in oral, and therefore unwritten, form in the time of Jesus.
Christians believe that God has established a new covenant with people through Jesus, as recorded in the Gospels, Acts of the Apostles, Epistles, and other books collectively called the New Testament (the word "testament" attributed to Tertullian is commonly interchanged with the word "covenant"). For some Christians, such as Roman Catholics and Orthodox Christians, this New Covenant includes authoritative Sacred Traditions and Canon law. Others, especially Protestants, reject the authority of such traditions and instead hold to the principle of "sola scriptura", which accepts only the Bible itself as the final rule of faith and practice. Anglicans do not believe in Sola Scriptura. For them Scripture is the longest leg of a 3-legged stool: Scripture, Tradition and Reason. Scripture cannot stand on its since it must be interpreted in the light of the Church's patristic teaching and ecumenical creeds. Additionally, some denominations include the "oral teachings of Jesus to the Apostles", which they believe have been handed down to this day by apostolic succession.
Christians refer to the Biblical books about Jesus as the New Testament, and to the canon of Hebrew books as the Old Testament, terms associated with Supersessionism. Judaism does not accept the retronymic labeling of its sacred texts as the "Old Testament", and some Jews refer to the New Testament as the Christian Testament or Christian Bible. Judaism rejects all claims that the Christian New Covenant supersedes, abrogates, fulfills, or is the unfolding or consummation of the covenant expressed in the Written and Oral Torahs. Therefore, just as Christianity does not accept that Mosaic Law has any authority over Christians, Judaism does not accept that the New Testament has any religious authority over Jews.
Many Jews view Christians as having quite an ambivalent view of the Torah, or Mosaic law: on one hand Christians speak of it as God's absolute word, but on the other, they apply its commandments with a certain selectivity (compare Biblical law in Christianity). Some Jews contend that Christians cite commandments from the Old Testament to support one point of view but then ignore other commandments of a similar class and of equal weight. Examples of this are certain commandments that God states explicitly be a "lasting covenant" (NIV ). Some translate the Hebrew as a "perpetual covenant" (). Likewise, some Christians contend that Jews cite some commandments from the Torah to support one view, but then ignore other commandments of a similar class and of equal weight.
Christians explain that such selectivity is based on rulings made by early Jewish Christians in the Book of Acts, at the Council of Jerusalem, that, while believing gentiles did not need to fully convert to Judaism, they should follow some aspects of Torah like avoiding idolatry and fornication and blood, including, according to some interpretations, homosexuality. This view is also reflected by modern Judaism, in that Righteous Gentiles needn't convert to Judaism and need to observe only the Noahide Laws, which also contain prohibitions against idolatry and fornication and blood.
Some Christians agree that Jews who accept Jesus should still observe all of Torah, see for example Dual-covenant theology, based on warnings by Jesus to Jews not to use him as an excuse to disregard it, and they support efforts of those such as Messianic Jews (Messianic Judaism is considered by most Christians and Jews to be a form of Christianity) to do that, but some Protestant forms of Christianity oppose all observance to the Mosaic law, even by Jews, which Luther criticised as "Antinomianism", see Antinomianism#Antinomian Controversies in Lutheranism and Luther#Anti-Antinomianism for details.
A minority view in Christianity, known as Christian Torah-submission, holds that the Mosaic law as it is written is binding on all followers of God under the New Covenant, even for Gentiles, because it views God’s commands as "everlasting" (, ; , ; ) and "good" (; ; ).
Concepts of God.
Traditionally, both Judaism and Christianity believe in the God of Abraham, Isaac and Jacob, for Jews the God of the Tanakh, for Christians the God of the Old Testament, the creator of the universe. Judaism and major sects of Christianity reject the view that God is entirely immanent (although some see this as the concept of the Holy Ghost) and within the world as a physical presence, (although trinitarian Christians believe in the incarnation of God). Both religions reject the view that God is entirely transcendent, and thus separate from the world, as the pre-Christian Greek Unknown God. Both religions reject atheism on one hand and polytheism on the other.
Both religions agree that God shares both transcendent and immanent qualities. How these religions resolve this issue is where the religions differ. Christianity posits that God exists as a Trinity; in this view God exists as three distinct persons who share a single divine essence, or substance. In those three there is one, and in that one there are three; the one God is indivisible, while the three persons are distinct and unconfused, God the Father, God the Son, and God the Holy Spirit. It teaches that God became especially immanent in physical form through the Incarnation of God the Son who was born as Jesus of Nazareth, who is believed to be at once fully God and fully human. There are denominations self-describing as Christian who question one or more of these doctrines, however, see Nontrinitarianism. By contrast, Judaism sees God as a single entity, and views trinitarianism as both incomprehensible and a violation of the Bible's teaching that God is one. It rejects the notion that Jesus or any other object or living being could be 'God', that God could have a literal 'son' in physical form or is divisible in any way, or that God could be made to be joined to the material world in such fashion. Although Judaism provides Jews with a word to label God's transcendence ("Ein Sof", without end) and immanence ("Shekhinah", in-dwelling), these are merely human words to describe two ways of experiencing God; God is one and indivisible.
Shituf.
A minority Jewish view, which appears in some codes of Jewish law, is that while Christian worship is polytheistic (due to the multiplicity of the Trinity), it is permissible for them to swear in God's name, since they are referring to the one God. This theology is referred to in Hebrew as Shituf (literally "partnership" or "association"). Although worship of a trinity is considered to be not different from any other form of idolatry for Jews, it may be an acceptable belief for non-Jews (according to the ruling of some Rabbinic authorities).
Right action.
Faith versus good deeds.
Judaism teaches that the purpose of the Torah is to teach us how to act correctly. God's existence is a given in Judaism, and not something that most authorities see as a matter of required belief. Although some authorities see the Torah as commanding Jews to believe in God, Jews see belief in God as a necessary, but not sufficient, condition for a Jewish life. The quintessential verbal expression of Judaism is the Shema Yisrael, the statement that the God of the Bible is their God, and that this God is unique and one. The quintessential physical expression of Judaism is behaving in accordance with the 613 Mitzvot (the commandments specified in the Torah), and thus live one's life in God's ways.
Thus fundamentally in Judaism, one is enjoined to bring holiness into life (with the guidance of God's laws), rather than removing oneself from life to be holy.
Much of Christianity also teaches that God wants people to perform good works, but all branches hold that good works alone will not lead to salvation, which is called Legalism, the exception being dual-covenant theology. Some Christian denominations hold that salvation depends upon transformational faith in Jesus, which expresses itself in good works as a testament (or witness) to ones faith for others to see (primarily Eastern Orthodox Christianity and Roman Catholicism), while others (including most Protestants) hold that faith alone is necessary for salvation. Some argue that the difference is not as great as it seems, because it really hinges on the definition of "faith" used. The first group generally uses the term "faith" to mean "intellectual and heartfelt assent and submission." Such a faith will not be salvific until a person has allowed it to effect a life transforming conversion (turning towards God) in their being (see Ontotheology). The Christians that hold to "salvation by faith alone" (also called by its Latin name "sola fide") define faith as being implicitly ontological—mere intellectual assent is not termed "faith" by these groups. Faith, then, is life-transforming by definition.
Sin.
In both religions, offenses against the will of God are called sin. These sins can be thoughts, words, or deeds.
Catholicism categorizes sins into various groups. A wounding of the relationship with God is often called venial sin; a complete rupture of the relationship with God is often called mortal sin. Without salvation from sin (see below), a person's separation from God is permanent, causing such a person to enter Hell in the afterlife. Both the Catholic Church and the Orthodox Church define sin more or less as a "macula", a spiritual stain or uncleanliness that constitutes damage to man's image and likeness of God.
Hebrew has several words for sin, each with its own specific meaning. The word "pesha", or "trespass", means a sin done out of rebelliousness. The word "aveira" means "transgression". And the word "avone", or "iniquity", means a sin done out of moral failing. The word most commonly translated simply as "sin", "het", literally means "to go astray." Just as Jewish law, "halakha" provides the proper "way" (or path) to live, sin involves straying from that path. Judaism teaches that humans are born with free will, and morally neutral, with both a "yetzer hatov", (literally, "the good inclination", in some views, a tendency towards goodness, in others, a tendency towards having a productive life and a tendency to be concerned with others) and a "yetzer hara", (literally "the evil inclination", in some views, a tendency towards evil, and in others, a tendency towards base or animal behavior and a tendency to be selfish). In Judaism all human beings are believed to have free will and can choose the path in life that they will take. It does not teach that choosing good is impossible - only at times more difficult. There is almost always a "way back" if a person wills it. (Although texts mention certain categories for whom the way back will be exceedingly hard, such as the slanderer, the habitual gossip, and the malicious person)
The rabbis recognize a positive value to the "yetzer hara": one tradition identifies it with the observation on the last day of creation that God's accomplishment was "very good" (God's work on the preceding days was just described as "good") and explain that without the yetzer ha'ra there would be no marriage, children, commerce or other fruits of human labor; the implication is that yetzer ha'tov and yetzer ha'ra are best understood not as moral categories of good and evil but as selfless versus selfish orientations, either of which used rightly can serve God's will.
In contrast to the Jewish view of being morally balanced, Original Sin refers to the idea that the sin of Adam and Eve's disobedience (sin "at the origin") has passed on a spiritual heritage, so to speak. Christians teach that human beings inherit a corrupted or damaged human nature in which the tendency to do bad is greater than it would have been otherwise, so much so that human nature would not be capable now of participating in the afterlife with God. This is not a matter of being "guilty" of anything; each person is only personally guilty of their own actual sins. However, this understanding of original sin is what lies behind the Christian emphasis on the need for spiritual salvation from a spiritual Saviour, who can forgive and set aside sin even though humans are not inherently pure and worthy of such salvation. St. Paul in Romans and I Corinthians placed special emphasis on this doctrine, and stressed that belief in Jesus would allow Christians to overcome death and attain salvation in the hereafter.
Roman Catholics, Eastern Orthodox Christians, and some Protestants teach the Sacrament of Baptism is the means by which each person's damaged human nature is healed and Sanctifying Grace (capacity to enjoy and participate in the spiritual life of God) is restored. This is referred to as "being born of water and the Spirit", following the terminology in the Gospel of St. John. Most Protestants believe this salvific grace comes about at the moment of personal decision to follow Jesus, and that baptism is a symbol of the grace already received.
Love.
Although love is central to both Christianity and Judaism, literary critic Harold Bloom (in his "Jesus and Yahweh: The Names Divine") argues that their notions of love are fundamentally different. Specifically, he links the Jewish conception of love to justice, and the Christian conception of love to charity.
As in English, the Hebrew word for "love", ahavah אהבה, is used to describe intimate or romantic feelings or relationships, such as the love between parent and child in Genesis 22:2; 25: 28; 37:3; the love between close friends in I Samuel 18:2, 20:17; or the love between a young man and young woman in Song of Songs. Christians will often use the Septuagint to make distinctions between the types of love: "philia" for brotherly, "eros" for romantic and "agape" for self-sacrificing love.
Like many Jewish scholars and theologians, Bloom understands Judaism as fundamentally a religion of love. But he argues that one can understand the Hebrew conception of love only by looking at one of the core commandments of Judaism, Leviticus 19:18, "Love your neighbor as yourself", also called the second Great Commandment. Talmudic sages Hillel and Rabbi Akiva commented that this is a major element of the Jewish religion. Also, this commandment is arguably at the center of the Jewish faith. As the third book of the Torah, Leviticus is literally the central book. Historically, Jews have considered it of central importance: traditionally, children began their study of the Torah with Leviticus, and the midrashic literature on Leviticus is among the longest and most detailed of midrashic literature (see Bamberger 1981: 737). Bernard Bamberger considers Leviticus 19, beginning with God's commandment in verse 3—"You shall be holy, for I the Lord your God, am holy"—to be "the climactic chapter of the book, the one most often read and quoted" (1981:889). Leviticus 19:18 is itself the climax of this chapter.
Abortion.
The only statements in the Tanakh about the status of a fetus state that killing an unborn infant does not have the same status as killing a born human being, and mandates a much lesser penalty (Exodus 21: 22-25) (although this interpretation is disputed, the passage could refer to an injury to a woman that causes a premature, live birth).
The Talmud states that the fetus is not yet a full human being until it has been born (either the head or the body is mostly outside of the woman), therefore killing a fetus is not murder, and abortion - in restricted circumstances - has always been legal under Jewish law. Rashi, the great 12th century commentator on the Bible and Talmud, states clearly of the fetus "lav nefesh hu": "it is not a person." The Talmud contains the expression "ubar yerech imo"—the fetus is as the thigh of its mother,' i.e., the fetus is deemed to be part and parcel of the pregnant woman's body." The Babylonian Talmud Yevamot 69b states that: "the embryo is considered to be mere water until the fortieth day." Afterwards, it is considered subhuman until it is born. Christians who agree with these views may refer to this idea as abortion before the quickening of the fetus.
Judaism unilaterally supports, in fact mandates, abortion if doctors believe that it is necessary to save the life of the woman. Many rabbinic authorities allow abortions on the grounds of gross genetic imperfections of the fetus. They also allow abortion if the woman were suicidal because of such defects. However, Judaism holds that abortion is impermissible for family planning or convenience reasons. Each case must be decided individually, however, and the decision should lie with the pregnant woman, the man who impregnated her and their Rabbi.
War, violence and pacifism.
Jews and Christians accept as valid and binding many of the same moral principles taught in the Torah. There is a great deal of overlap between the ethical systems of these two faiths. Nonetheless, there are some highly significant doctrinal differences.
Judaism has many teachings about peace and compromise, and its teachings make physical violence the last possible option. Nonetheless, the Talmud teaches that "If someone comes with the intention to murder you, then one is obligated to kill in self-defense than be killed". The clear implication is that to bare one's throat would be tantamount to suicide (which Jewish law forbids) and it would also be considered helping a murderer kill someone and thus would "place an obstacle in front of a blind man" (i.e., makes it easier for another person to falter in their ways). The tension between the laws dealing with peace, and the obligation to self-defense, has led to a set of Jewish teachings that have been described as tactical-pacifism. This is the avoidance of force and violence whenever possible, but the use of force when necessary to save the lives of one's self and one's people.
Although killing oneself is forbidden under normal Jewish law as being a denial of God's goodness in the world, under extreme circumstances when there has seemed no choice but to either be killed or forced to betray their religion, Jews have committed suicide or mass suicide (see Masada, First French persecution of the Jews, and York Castle for examples). As a grim reminder of those times, there is even a prayer in the Jewish liturgy for "when the knife is at the throat", for those dying "to sanctify God's Name". (See: "Martyrdom"). These acts have received mixed responses by Jewish authorities. Where some Jews regard them as examples of heroic martyrdom, but others saying that while Jews should always be willing to face martyrdom if necessary, it was wrong for them to take their own lives.
Because Judaism focuses on this life, many questions to do with survival and conflict (such as the classic moral dilemma of two people in a desert with only enough water for one to survive) were analysed in great depth by the rabbis within the Talmud, in the attempt to understand the principles a godly person should draw upon in such a circumstance.
The Sermon on the Mount records that Jesus taught that if someone comes to harm you, then one must turn the other cheek. This has led four Protestant Christian denominations to develop a theology of pacifism, the avoidance of force and violence at all times. They are known historically as the "peace churches", and have incorporated Christ's teachings on nonviolence into their theology so as to apply it to participation in the use of violent force; those denominations are the Quakers, Mennonites, Amish, and the Church of the Brethren. Many other churches have people who hold to the doctrine without making it a part of their doctrines, or who apply it to individuals but not to governments, see also Evangelical counsels. The vast majority of Christian nations and groups have not adopted this theology, nor have they followed it in practice. See also But to bring a sword.
Capital punishment.
Although the Hebrew Bible has many references to capital punishment, the Jewish sages used their authority to make it nearly impossible for a Jewish court to impose a death sentence. Even when such a sentence might have been imposed, the Cities of Refuge and other sanctuaries, were at hand for those unintentionally guilty of capital offences. It was said in the Talmud about the death penalty in Judaism, that if a court killed more than one person in seventy years, it was a barbarous (or "bloody") court and should be condemned as such.
Christianity usually reserved the death penalty for heresy, the denial of the orthodox view of God's view, and witchcraft or similar non-Christian practices. For example, in Spain, unrepentant Jews were exiled, and it was only those crypto-Jews who had accepted baptism under pressure but retained Jewish customs in private, who were punished in this way. It is presently acknowledged by most of Christianity that these uses of capital punishment were deeply immoral.
Taboo food and drink.
Orthodox Jews, unlike most Christians, still practice a restrictive diet that has many rules. Most Christians believe that the kosher food laws have been superseded, for example citing what Jesus taught in Mark 7: what you eat doesn't make you unclean but what comes out of a man's heart makes him unclean — although Roman Catholicism and Eastern Orthodoxy have their own set of dietary observances. Eastern Orthodoxy, in particular has very elaborate and strict rules of fasting, and continues to observe the Council of Jerusalem's apostolic decree of Act 15.
Some Christian denominations observe some biblical food laws, for example the practice of Ital in Rastifarianism. Jehovah's Witnesses do not eat blood products and are known for their refusal to accept blood transfusions based on not "eating blood".
Salvation.
Judaism does not see human beings as inherently flawed or sinful and needful of being saved from it, but rather capable with a free will of being righteous, and unlike Christianity does not closely associate ideas of "salvation" with a New Covenant delivered by a Jewish messiah, although in Judaism Jewish people will have a renewed national commitment of observing God's commandments under the New Covenant, and the Jewish Messiah will also be ruling at a time of global peace and acceptance of God by all people.
Judaism holds instead that proper living is accomplished through good works and heartfelt prayer, as well as a strong faith in God. Judaism also teaches that gentiles can receive a share in "the world to come". This is codified in the Mishna Avot 4:29, the Babylonian Talmud in tractates Avodah Zarah 10b, and Ketubot 111b, and in Maimonides's 12th century law code, the "Mishneh Torah", in "Hilkhot Melachim" (Laws of Kings) 8.11.
The Protestant view is that every human is a sinner, and being saved by God's grace, not simply by the merit of one's own actions, pardons a damnatory sentence to Hell.
Forgiveness.
In Judaism, one must go "to those he has harmed" in order to be entitled to forgiveness. This means that in Judaism a person cannot obtain forgiveness from God for wrongs the person has done to other people. This also means that, unless the victim forgave the perpetrator before he died, murder is unforgivable in Judaism, and they will answer to God for it, though the victims' family and friends can forgive the murderer for the grief they caused them.
Thus the "reward" for forgiving others is not God's forgiveness for wrongs done to others, but rather help "in obtaining forgiveness from the other person."
Sir Jonathan Sacks, Chief Rabbi of the United Hebrew Congregations of the Commonwealth, summarized: "it is not that God forgives, while human beings do not. To the contrary, we believe that just as only God can forgive sins against God, so only human beings can forgive sins against human beings."
In Christianity, forgiveness by God is promised to the repentant even though the wronged party has not forgiven the offender: "If we confess our sins, he is faithful and just and will forgive us our sins and purify us from all unrighteousness." (1 John 1:9 ) Jesus, however, requires his disciples to forgive others if they want to be forgiven themselves. Matthew 6:14,15, which follows the Lord's Prayer, says "For if you forgive men when they sin against you, your heavenly Father will also forgive you. But if you do not forgive men their sins, your Father will not forgive your sins." Forgiveness is not an option to a Christian, rather one must forgive to be a Christian.
Judgment.
Both Christianity and Judaism believe in some form of judgment. Most Christians (the exception is Full Preterism) believe in the future Second Coming of Jesus, which includes the Resurrection of the Dead and the Last Judgment. Those who have accepted Jesus as their personal saviour will be saved and live in God's presence in the Kingdom of Heaven, those who have not accepted Jesus as their saviour,will be cast into the Lake of Fire (eternal torment, finite torment, or simply annihilated), see for example The Sheep and the Goats.
In Jewish liturgy there is significant prayer and talk of a "book of life" that one is written into, indicating that God judges each person each year even after death. This annual judgment process begins on Rosh Hashanah and ends with Yom Kippur. Additionally, God sits daily in judgment concerning a person's daily activities. Upon the anticipated arrival of the Messiah, God will judge the nations for their persecution of Israel during the exile. Later, God will also judge the Jews over their observance of the Torah.
Heaven and Hell.
There is little Jewish literature on heaven or hell as actual places, and there are few references to the afterlife in the Hebrew Bible. One is the ghostly apparition of Samuel, called up by the Witch of Endor at King Saul's command. Another is a mention by the Prophet Daniel of those who sleep in the earth rising to either everlasting life or everlasting abhorrence.
Early Hebrew views were more concerned with the fate of the nation of Israel as a whole, rather than with individual immortality. A stronger belief in an afterlife for each person developed during the Second Temple period but was contested by various Jewish sects. Pharisees believed that in death, people rest in their graves until they are physically resurrected with the coming of the Messiah, and within that resurrected body the soul would exist eternally. Maimonides also included the concept of resurrection in his Thirteen Principles of Faith.
Judaism's view is summed up by a biblical observation about the Torah: in the beginning God clothes the naked (Adam), and at the end God buries the dead (Moses). The Children of Israel mourned for 40 days, then got on with their lives.
In Judaism, Heaven is sometimes described as a place where God debates Talmudic law with the angels, and where Jews spend eternity studying the Written and Oral Torah. Jews do not believe in "Hell" as a place of eternal torment. Gehenna is a place or condition of purgatory where Jews spend up to twelve months purifying to get into heaven, depending on how sinful they have been, although some suggest that certain types of sinners can never be purified enough to go to heaven and rather than facing eternal torment, simply cease to exist. Therefore, some violations like suicide would be punished by separation from the community, such as not being buried in a Jewish cemetery (in practice, rabbis often rule suicides to be mentally incompetent and thus not responsible for their actions). Judaism also does not have a notion of hell as a place ruled by Satan since God's dominion is total and Satan is only one of God's angels.
Catholics also believe in a purgatory for those who are going to heaven, but Christians in general believe that Hell is a fiery place of torment that never ceases, called the Lake of Fire. A small minority believe this is not permanent, and that those who go there will eventually either be saved or cease to exist. Heaven for Christians is depicted in various ways. As the Kingdom of God described in the New Testament and particularly the Book of Revelation, Heaven is a new or restored earth, a World to Come, free of sin and death, with a New Jerusalem led by God, Jesus, and the most righteous of believers starting with 144,000 Israelites from every tribe, and all others who received salvation living peacefully and making pilgrimages to give glory to the city.
In Christianity, promises of Heaven and Hell as rewards and punishments are often used to motivate good and bad behavior, as threats of disaster were used by prophets like Jeremiah to motivate the Israelites. Modern Judaism generally rejects this form of motivation, instead teaching to do the right thing because it's the right thing to do. As Maimonides wrote:
"A man should not say: I shall carry out the precepts of the Torah and study her wisdom in order to receive all the blessings written therein or in order to merit the life of the World to Come and I shall keep away from the sins forbidden by the Torah in order to be spared the curses mentioned in the Torah or in order not to be cut off from the life of the World to Come. It is not proper to serve God in this fashion. For one who serves thus serves out of fear. Such a way is not that of the prophets and sages. Only the ignorant, and the women and children serve God in this way. These are trained to serve out of fear until they obtain sufficient knowledge to serve out of love. One who serves God out of love studies the Torah and practices the precepts and walks in the way of wisdom for no ulterior motive at all, neither out of fear of evil nor in order to acquire the good, but follows the truth because it is true and the good will follow the merit of attaining to it. It is the stage of Abraham our father whom the Holy One, blessed be God, called "My friend" (Isaiah 41:8—"ohavi" = the one who loves me) because he served out of love alone. It is regarding this stage that the Holy One, Blessed be God, commanded us through Moses, as it is said: "You shall love the Lord your God" (Deuteronomy 6:5). When man loves God with a love that is fitting he automatically carries out all the precepts of love.
The Messiah.
Jews believe that a descendant of King David will one day appear to restore the Kingdom of Israel and usher in an era of peace, prosperity, and spiritual understanding for Israel and all the nations of the world. Jews refer to this person as Moshiach or "anointed one", translated as messiah in English. The traditional Jewish understanding of the messiah is that he is fully human and born of human parents without any supernatural element. The messiah is expected to have a relationship with God similar to that of the prophets of the Tanakh. In his commentary on the Talmud, Maimonides (Rabbi Moshe ben Maimon) wrote:
He adds:
He also clarified the nature of the Messiah:
The Christian view of Jesus as Messiah goes beyond such claims and is the fulfillment and union of three anointed offices; a prophet like Moses who delivers God's commands and covenant and frees people from bondage, a High Priest in the order of Melchizedek overshadowing the Levite priesthood and a king like King David ruling over Jews, and like God ruling over the whole world and coming from the line of David.
For Christians, Jesus is also fully human and fully divine as the Word of God who sacrifices himself so that humans can receive salvation. Jesus sits in Heaven at the Right Hand of God and will judge humanity in the end times when he returns to earth.
Christian readings of the Hebrew Bible find many references to Jesus. This takes the form in some cases of specific prophesy, but in most cases of foreshadowing by types or forerunners. Traditionally, most Christian readings of the Bible maintained that almost every prophecy was actually about the coming of Jesus, and that the entire Old Testament of the Bible is a prophecy about the coming of Jesus.
Catholic views.
Catholicism teaches "Extra Ecclesiam Nulla Salus" ("Outside the Church there is no salvation"), which some, like Fr. Leonard Feeney, interpreted as limiting salvation to Catholics only. At the same time, it does not deny the possibility that those not visibly members of the Church may attain salvation as well. In recent times, its teaching has been most notably expressed in the Vatican II council documents "Unitatis Redintegratio" (1964), "Lumen gentium" (1964), "Nostra aetate" (1965), an encyclical issued by Pope John Paul II: "Ut unum sint" (1995), and in a document issued by the Congregation for the Doctrine of the Faith, "Dominus Iesus" in 2000. The latter document has been criticised for claiming that non-Christians are in a "gravely deficient situation" as compared to Catholics, but also adds that "for those who are not formally and visibly members of the Church, salvation in Christ is accessible by virtue of a grace which, while having a mysterious relationship to the Church, does not make them formally part of the Church, but enlightens them in a way which is accommodated to their spiritual and material situation."
Pope John Paul II on October 2, 2000 emphasized that this document did not say that non-Christians were actively denied salvation: "...this confession does not deny salvation to non-Christians, but points to its ultimate source in Christ, in whom man and God are united". On December 6 the Pope issued a statement to further emphasize that the Church continued to support its traditional stance that salvation was available to believers of other faiths: "The gospel teaches us that those who live in accordance with the Beatitudes--the poor in spirit, the pure of heart, those who bear lovingly the sufferings of life--will enter God's kingdom." He further added, "All who seek God with a sincere heart, including those who do not know Christ and his church, contribute under the influence of Grace to the building of this Kingdom." On August 13, 2002 American Catholic bishops issued a joint statement with leaders of Reform and Conservative Judaism, called "Reflections on Covenant and Mission", which affirmed that Christians should not target Jews for conversion. The document stated: "Jews already dwell in a saving covenant with God" and "Jews are also called by God to prepare the world for God's Kingdom." However, many Christian denominations still believe it is their duty to reach out to "unbelieving" Jews.
In December 2015, the Vatican released a 10,000-word document that, among other things, stated that Jews do not need to be converted to find salvation, and that Catholics should work with Jews to fight antisemitism.
Eastern Orthodox views.
Eastern Orthodox Christianity emphasizes a continuing life of repentance or "metanoia", which includes an increasing improvement in thought, belief and action. Regarding the salvation of Jews, Muslims, and other non-Christians, the Orthodox have traditionally taught that there is no salvation outside the church. Orthodoxy recognizes that other religions may contain truth, to the extent that they are in agreement with Christianity.
Many Orthodox theologians believe that all people will have an opportunity to embrace union with God, including Jesus, after their death, and so become part of the Church at that time. God is thought to be good, just, and merciful; it would not seem just to condemn someone because they never heard the Gospel message, or were taught a distorted version of the Gospel by heretics. Therefore, the reasoning goes, they must at some point have an opportunity to make a genuine informed decision. Ultimately, those who persist in rejecting God condemn themselves, by cutting themselves off from the ultimate source of all Life, and from the God who is Love embodied. Jews, Muslims, and members of other faiths, then, are expected to convert to Christianity in the afterlife.
The Church of Jesus Christ of Latter-day Saints (which is not part of Eastern Orthodoxy) also holds this belief, and performs baptism for the dead, in which people are baptized in behalf of their ancestors who, it is believed, are given the opportunity to accept the ordinance.
Proselytizing.
Judaism is not a proselytizing religion. Orthodox Judaism deliberately makes it very difficult to convert and become a Jew, and requires a significant and full-time effort in living, study, righteousness, and conduct over several years. The final decision is by no means a foregone conclusion. A person cannot become Jewish by marrying a Jew, or by joining a synagogue, nor by any degree of involvement in the community or religion, but only by explicitly undertaking intense, formal, and supervised work over years aimed towards that goal. Some less strict versions of Judaism have made this process somewhat easier but it is still far from common.
In the past Judaism was more evangelistic, but this was often more akin just to "greater openness to converts" rather than active soliciting of conversions. Since Jews believe that one need not be a Jew to approach God, there is no religious pressure to convert non-Jews to their faith.
The Chabad-Lubavitch branch of Hasidic Judaism has been an exception to this non-proselytizing standard, since in recent decades it has been actively promoting Noahide Laws for Gentiles as an alternative to Christianity.
By contrast, Christianity is an explicitly evangelistic religion. Christians are commanded by Jesus to "Therefore go and make disciples of all nations". Historically, evangelism has on rare occasions led to forced conversion under threat of death or mass expulsion. While abuses of this sort are no longer common, at certain times and in certain places, evangelism has veered into high-pressure coercion, in those instances causing significant ill-will.
Mutual views.
Common Jewish views of Christianity.
Many Jews view Jesus as one in a long list of failed Jewish claimants to be the Messiah, none of whom fulfilled the tests of a prophet specified in the Law of Moses. Others see Jesus as a teacher who worked with the gentiles and ascribe the messianic claims that Jews find objectionable to his later followers. Because much physical and spiritual violence was done to Jews in the name of Jesus and his followers, and because evangelism is still an active aspect of many church's activities, many Jews are uncomfortable with discussing Jesus and treat him as a non-person. In answering the question "What do Jews think of Jesus", philosopher Milton Steinberg claims, for Jews, Jesus cannot be accepted as anything more than a teacher. "In only a few respects did Jesus deviate from the Tradition," Steinberg concludes, "and in all of them, Jews believe, he blundered."
Judaism does not believe that God requires the sacrifice of any human. This is emphasized in Jewish traditions concerning the story of the Akedah, the binding of Isaac. In the Jewish explanation, this is a story in the Torah whereby God wanted to test Abraham's faith and willingness, and Isaac was never going to be actually sacrificed. Thus, Judaism rejects the notion that anyone can or should die for anyone else's sin. Judaism is more focused on the practicalities of understanding how one may live a sacred life in the world according to God's will, rather than a hope of a future one. Judaism does not believe in the Christian concept of hell but does have a punishment stage in the afterlife (i.e. Gehenna, the New Testament word translated as hell) as well as a Heaven (Gan Eden), but the religion does not intend it as a focus.
Judaism views the worship of Jesus as inherently polytheistic, and rejects the Christian attempts to explain the Trinity as a complex monotheism. Christian festivals have no religious significance in Judaism and are not celebrated, but some secular Jews in the West treat Christmas as a secular holiday.
Common Christian views of Judaism.
Christians believe that Christianity is the fulfillment and successor of Judaism, retaining much of its doctrine and many of its practices including monotheism, the belief in a Messiah, and certain forms of worship like prayer and reading from religious texts. Christians believe that Judaism requires blood sacrifice to atone for sins, and believe that Judaism has abandoned this since the destruction of the Second Temple. Most Christians consider the Mosaic Law to have been a necessary intermediate stage, but that once the crucifixion of Jesus occurred, adherence to civil and ceremonial Law was superseded by the New Covenant.
Some Christians adhere to New Covenant theology, which states that with the arrival of his New Covenant, Jews have ceased being blessed under his Mosaic covenant. This position has been softened or disputed by other Christians, where Jews are recognized to have a special status under the Abrahamic covenant. New Covenant theology is thus in contrast to Dual-covenant theology.
Some Christians who view the Jewish people as close to God seek to understand and incorporate elements of Jewish understanding or perspective into their beliefs as a means to respect their "parent" religion of Judaism, or to more fully seek out and return to their Christian roots. Christians embracing aspects of Judaism are sometimes criticized as Biblical Judaizers by Christians when they pressure Gentile Christians to observe Mosaic teachings rejected by most modern Christians.
Inter-relationship.
In addition to each having varied views on the other as a religion, there has also been a long and often painful history of conflict, persecution and at times, reconciliation, between the two religions, which have influenced their mutual views of their relationship over time.
Persecution, forcible conversion, and forcible displacement of Jews (i.e. hate crimes) occurred for many centuries, with occasional gestures to reconciliation from time to time. Pogroms were common throughout Christian Europe, including organized violence, restrictive land ownership and professional lives, forcible relocation and ghettoization, mandatory dress codes, and at times humiliating actions and torture. All had major effects on Jewish cultures. There have also been non-coercive outreach and missionary efforts such as the Church of England's Ministry Among Jewish People, founded in 1809.
For Martin Buber, Judaism and Christianity were variations on the same theme of messianism. Buber made this theme the basis of a famous definition of the tension between Judaism and Christianity:
Pre-messianically, our destinies are divided. Now to the Christian, the Jew is the incomprehensibly obdurate man who declines to see what has happened; and to the Jew, the Christian is the incomprehensibly daring man who affirms in an unredeemed world that its redemption has been accomplished. This is a gulf which no human power can bridge.
Following the Holocaust, attempts have been made to construct a new Jewish-Christian relationship of mutual respect for differences, through the inauguration of the interfaith body the Council of Christians and Jews in 1942 and International Council of Christians and Jews. The Seelisberg Conference in 1947 established 10 points relating to the sources of Christian antisemitism. The ICCJ's "Twelve points of Berlin" sixty years later aim to reflect a recommitment to interreligious dialogue between the two communities.
In December 2015, the Vatican released a 10,000-word document that, among other things, stated that Jews do not need to be converted to find salvation, and that Catholics should work with Jews to fight antisemitism.

</doc>
<doc id="7504" url="https://en.wikipedia.org/wiki?curid=7504" title="Cesare Borgia">
Cesare Borgia

Cesare Borgia (; Catalan: Cèsar Borja, ; , ; 13 September 1475 or April 1476 – 12 March 1507), Duke of Valentinois, was an Italian "condottiero", nobleman, politician, and cardinal, whose fight for power was a major inspiration for "The Prince" by Machiavelli. He was the illegitimate son of Pope Alexander VI (r. 1492–1503) and his long-term mistress Vannozza dei Cattanei. He was the brother of Lucrezia Borgia; Giovanni Borgia (Juan), Duke of Gandia; and Gioffre Borgia (Jofré in Catalan), Prince of Squillace. He was half-brother to Don Pedro Luis de Borja (1460–88) and Girolama de Borja, children of unknown mothers.
After initially entering the church and becoming a cardinal on his father's election to the Papacy, he became the first person to resign a cardinalcy after the death of his brother in 1498. His father set him up as a prince with territory carved from the Papal States, but after his father's death he was unable to retain power for long. According to Machiavelli this was due to his planning for all possibilities but his own illness.
Early life.
Like nearly all aspects of Cesare Borgia's life, the date of his birth is a subject of dispute. He was born in Rome—in either 1475 or 1476—the illegitimate son of Cardinal Roderic Llançol i de Borja, (usually known as Rodrigo Borgia), later Pope Alexander VI, and his mistress Vannozza dei Cattanei, about whom information is sparse. The Borgia family originally came from the Kingdom of Valencia, and rose to prominence during the mid-15th century; Cesare's grand-uncle Alphonso Borgia (1378–1458), bishop of Valencia, was elected Pope Callixtus III in 1455. Cesare's father, Pope Alexander VI, was the first pope who openly recognized his children born out of wedlock.
Stefano Infessura writes that Cardinal Borgia falsely claimed Cesare to be the legitimate son of another man—Domenico d'Arignano, the nominal husband of Vannozza dei Cattanei. More likely, Pope Sixtus IV granted Cesare a release from the necessity of proving his birth in a papal bull of 1 October 1480.
Career.
Church office.
Cesare was initially groomed for a career in the Church. He was made Bishop of Pamplona at the age of 15. Following school in Perugia and Pisa, Cesare studied law at the "Studium Urbis" (nowadays Sapienza University of Rome), along with his father's elevation to Pope, Cesare was made Cardinal at the age of 18.
Alexander VI staked the hopes of the Borgia family on Cesare's brother Giovanni, who was made captain general of the military forces of the papacy. Giovanni was assassinated in 1497 in mysterious circumstances. Several contemporaries suggested that Cesare might have been his killer, as Giovanni's disappearance could finally open to him a long-awaited military career and also solve the jealousy over Sancha of Aragon, wife of Cesare's younger brother, Gioffre, and mistress of both Cesare and Giovanni. Cesare's role in the act has never been clear. However, he had no definitive motive, as he was likely to be given a powerful secular position, whether or not his brother lived. It is more likely, in fact, that Giovanni was killed as a result of a sexual liaison.
On 17 August 1498, Cesare became the first person in history to resign the cardinalate. On the same day, Louis XII of France named Cesare Duke of Valentinois, and this title, along with his former position as Cardinal of Valencia, explains the nickname "Valentino".
Military.
Cesare's career was founded upon his father's ability to distribute patronage, along with his alliance with France (reinforced by his marriage with Charlotte d'Albret, sister of John III of Navarre), in the course of the Italian Wars. Louis XII invaded Italy in 1499: after Gian Giacomo Trivulzio had ousted its duke Ludovico Sforza, Cesare accompanied the king in his entrance into Milan.
At this point Alexander decided to profit from the favourable situation and carve out for Cesare a state of his own in northern Italy. To this end, he declared that all his vicars in Romagna and Marche were deposed. Though in theory subject directly to the pope, these rulers had been practically independent or dependent on other states for generations. In the view of the citizens, these vicars were cruel and petty. When Cesare eventually took power, he was viewed by the citizens as a great improvement.
Cesare was appointed commander of the papal armies with a number of Italian mercenaries, supported by 300 cavalry and 4,000 Swiss infantry sent by the King of France. Alexander sent him to capture Imola and Forlì, ruled by Caterina Sforza (mother of the Medici "condottiero" Giovanni dalle Bande Nere). Despite being deprived of his French troops after the conquest of those two cities, Borgia returned to Rome to celebrate a triumph and to receive the title of Papal Gonfalonier from his father. In 1500 the creation of twelve new cardinals granted Alexander enough money for Cesare to hire the "condottieri," Vitellozzo Vitelli, Gian Paolo Baglioni, Giulio and Paolo Orsini, and Oliverotto da Fermo, who resumed his campaign in Romagna.
Giovanni Sforza, first husband of Cesare's sister Lucrezia, was soon ousted from Pesaro; Pandolfo Malatesta lost Rimini; Faenza surrendered, its young lord Astorre III Manfredi being later drowned in the Tiber river by Cesare's order. In May 1501 the latter was created duke of Romagna. Hired by Florence, Cesare subsequently added the lordship of Piombino to his new lands.
While his "condottieri" took over the siege of Piombino (which ended in 1502), Cesare commanded the French troops in the sieges of Naples and Capua, defended by Prospero and Fabrizio Colonna. On 24 June 1501 his troops stormed the latter, causing the collapse of Aragonese power in southern Italy.
In June 1502 he set out for Marche, where he was able to capture Urbino and Camerino by treason. He planned to conquer Bologna next. However, his "condottieri", most notably Vitellozzo Vitelli and the Orsini brothers (Giulio, Paolo and Francesco), feared Cesare's cruelty and set up a plot against him. Guidobaldo da Montefeltro and Giovanni Maria da Varano returned to Urbino and Camerino, and Fossombrone revolted. The fact that his subjects had enjoyed his rule thus far meant that his opponents had to work much harder than they would have liked. He eventually recalled his loyal generals to Imola, where he waited for his opponents' loose alliance to collapse. Cesare called for a reconciliation, but imprisoned his "condottieri" in Senigallia, then called Sinigaglia, a feat described as a "wonderful deceiving" by Paolo Giovio, and had them executed.
Later years and death.
Although he was an immensely capable general and statesman, Cesare had trouble maintaining his domain without continued Papal patronage. Niccolò Machiavelli cites Cesare's dependence on the good will of the Papacy, under the control of his father, to be the principal disadvantage of his rule. Machiavelli argued that, had Cesare been able to win the favor of the new Pope, he would have been a very successful ruler. The news of his father's death (1503) arrived when Cesare was planning the conquest of Tuscany. While he was convalescing in Castel Sant'Angelo, his troops controlled the conclave.
The new pope, Pius III, supported Cesare Borgia and reconfirmed him as Gonfalonier; but after a brief pontificate of twenty-six days he died. Borgia's deadly enemy, Giuliano Della Rovere, then succeeded by dexterous diplomacy in tricking the weakened Cesare Borgia into supporting him by offering him money and continued papal backing for Borgia policies in the Romagna; promises which he disregarded upon election. He was elected as Pope Julius II to the papal dignity by the near-unanimous vote of the cardinals. Realizing his mistake by then, Cesare tried to correct the situation to his favor, but Pope Julius II made sure of its failure at every turn.
Cesare Borgia, who was facing the hostility of Ferdinand II of Aragon, was betrayed while in Naples by Gonzalo Fernández de Córdoba, a man he had considered his ally, and imprisoned there, while his lands were retaken by the Papacy. In 1504 he was transferred to Spain and imprisoned first in the Castle of Chinchilla de Montearagón, but after an attempted escape he was moved to the Castle of La Mota, Medina del Campo. He did manage to escape from the Castle of La Mota with assistance, and after running across Santander, Durango and Gipuzkoa, he made it to Pamplona on 3 December 1506, and was much welcomed by King John III of Navarre, who was missing an experienced military commander, ahead of the feared Castilian invasion (1512).
He recaptured Viana, Navarre, then in the hands of forces loyal to the count of Lerín, Ferdinand II of Aragon's conspiratorial ally in Navarre, but not the castle, which he then besieged. In the early morning of 11 March 1507, an enemy party of knights fled from the castle during a heavy storm. Outraged at the ineffectiveness of the siege, the Italian commander chased them only to find himself on his own. The party of knights discovered Borgia was alone, and trapped him in an ambush. Borgia received a fatal injury from a spear. He was then stripped of all his luxurious garments, valuables and a leather mask covering half his face (disfigured possibly by syphilis during his late years). Borgia was left lying naked, with just a red tile covering his genitals.
Remains.
Borgia was originally buried in a marbled mausoleum John III had ordered built at the altar of the Church of Santa María in Viana, set on one of the stops on the Camino de Santiago. In the 16th century the bishop of Mondoñedo, Antonio de Guevara, published from memory what he had seen written on the tomb when he had paid a visit to the church. This epitaph underwent several changes in wording and meter throughout the years and the version most commonly cited today is that published by the priest and historian Francisco de Alesón in the 18th century. It reads:
Borgia was an old enemy of Ferdinand of Aragon, and he was fighting the count who paved the way for Ferdinand's 1512 Castilian invasion against John III and Catherine of Navarre. While the circumstances are not well known, the tomb was destroyed sometime between 1523 and 1608, during which time Santa María was undergoing renovation and expansion. Tradition goes that a bishop of Calahorra considered inappropriate to have the remains of "that degenerate" lying in the church, so the opportunity was taken to tear down the monument and expel Borgia's bones to where they were reburied under the street in front of the church to be trodden on by all who walked through the town.
Vicente Blasco Ibáñez, in "A los pies de Venus", writes that the then Bishop of Santa María had Borgia expelled from the church because his own father had died after being imprisoned under Alexander VI. It was held for many years that the bones were lost, although in fact local tradition continued to mark their place quite accurately and folklore sprung up around Borgia's death and ghost. The bones were in fact dug up twice and reburied once by historians (both local and international—the first dig in 1886 involved the French historian Charles Yriarte, who also published works on the Borgias) seeking the resting place of the infamous Cesare Borgia. After Borgia was unearthed for the second time in 1945 his bones were taken for a rather lengthy forensic examination by Victoriano Juaristi, a surgeon by trade and Borgia aficionado, and the tests concurred with the preliminary ones carried out in the 19th century. There was evidence that the bones belonged to Borgia.
Cesare Borgia's remains then were sent to Viana's town hall, directly across from Santa María, where they remained until 1953. They were then reburied immediately outside of the Church of Santa María, no longer under the street and in direct danger of being stepped on. A memorial stone was placed over it which translated into English declared Borgia the "Generalisimo" of the papal as well as the Navarrese forces. A movement was made in the late 80s to have Borgia dug up once more and put back into Santa María, but this proposal was ultimately rejected by church officials due to recent ruling against the interment of anyone who did not hold the title of pope or cardinal. Since Borgia had renounced the cardinalate it was decided that it would be inappropriate for his bones to be moved into the church. However, Fernando Sebastián Aguilar, the Archbishop of Pamplona, caved in after more than 50 years of petitions and Borgia was finally moved back inside the church on 11 March 2007, the day before the 500th anniversary of his death. "We have nothing against the transfer of his remains. Whatever he may have done in life, he deserves to be forgiven now," said the local church.
Evaluation.
Niccolò Machiavelli met the Duke on a diplomatic mission in his function as Secretary of the Florentine Chancellery. Machiavelli was at Borgia's court from 7 October 1502 through 18 January 1503. During this time he wrote regular dispatches to his superiors in Florence, many of which have survived and are published in Machiavelli's Collected Works. In "The Prince", Machiavelli uses Borgia as an example to elucidate the dangers of acquiring a principality by virtue of another. Although Cesare Borgia's father gave him the power to set up, Cesare ruled the Romagna with skill and tact for the most part. However, when his father died, and a rival to the Borgia family entered the Papal seat, Cesare was overthrown in a matter of months.
Machiavelli attributes two episodes to Cesare Borgia: the method by which the Romagna was pacified, which Machiavelli describes in chapter VII of "The Prince", and the assassination of his captains on New Year's Eve of 1502 in Senigallia.
Machiavelli's use of Borgia is subject to controversy. Some scholars see in Machiavelli's Borgia the precursor of state crimes in the 20th century. Others, including Macaulay and Lord Acton, have historicized Machiavelli's Borgia, explaining the admiration for such violence as an effect of the general criminality and corruption of the time.
Borgia and Leonardo.
Cesare Borgia briefly employed Leonardo da Vinci as military architect and engineer between 1502 and 1503. Cesare provided Leonardo with an unlimited pass to inspect and direct all ongoing and planned construction in his domain. While in Romagna, Leonardo built the canal from Cesena to the Porto Cesenatico. Before meeting Cesare, Leonardo had worked at the Milanese court of Ludovico Sforza for many years, until Louis XII of France drove Sforza out of Italy. After Cesare, Leonardo was unsuccessful in finding another patron in Italy. King Francis I of France was able to convince Leonardo to enter his service, and the last three years of Leonardo's life were spent working in France.
Personal life.
On 10 May 1499, Cesare married Charlotte of Albret (1480 – 11 March 1514). She was a sister of John III of Navarre. They were parents to a daughter, Louise Borgia, Duchess of Valentinois, (1500–1553) who first married Louis II de la Trémoille, Governor of Burgundy, and secondly Philippe de Bourbon (1499–1557), Seigneur de Busset.
Cesare was also father to at least 11 illegitimate children, among them Girolamo Borgia, who married Isabella Contessa di Carpi, and Lucrezia Borgia (the younger), who, after Cesare's death, was moved to Ferrara to the court of her aunt, the elder Lucrezia Borgia.
In fiction.
Theatre.
Nathaniel Lee wrote a play entitled "Caesar Borgia" (1680) in which he appears as the central character.
Alexandru Kiritescu wrote a play entitled "Borgia" (1948)
Music.
Cesare Borgia is mentioned in the song "B.I.B.L.E.", performed by Killah Priest, which appears on GZA's 1995 album "Liquid Swords", as well as Killah Priest's debut album "Heavy Mental". He is also mentioned in the song "Jeshurun" on Priest's album "Behind the Stained Glass".
Video games.
Cesare Borgia is featured as the main antagonist and final boss in the 2010 video game "".
References.
Notes
Sources

</doc>
<doc id="7507" url="https://en.wikipedia.org/wiki?curid=7507" title="Chronicle">
Chronicle

A chronicle (, from Greek , from , "chronos", "time") is a historical account of facts and events ranged in chronological order, as in a time line. Typically, equal weight is given for historically important events and local events, the purpose being the recording of events that occurred, seen from the perspective of the chronicler. This is in contrast to a narrative or history, which sets selected events in a meaningful interpretive context and excludes those the author does not see as important.
Where a chronicler obtained the information varies; some chronicles are written from first-hand knowledge, some are from witnesses or participants in events, still others are accounts passed mouth to mouth prior to being written down. Some made use of written materials; charters, letters, or the works of earlier chroniclers. Still others are tales of such unknown origins so as to hold mythical status. Copyists also affected chronicles in creative copying, making corrections or in updating or continuing a chronicle with information not available to the original author(s). The reliability of a particular chronicle is an important determination for modern historians.
In modern times various contemporary newspapers or other periodicals have adopted "chronicle" as part of their name. Various fictional stories have also adopted "chronicle" as part of their title, to give an impression of epic proportion to their stories. A chronicle which traces world history is called a universal chronicle.
Scholars categorize the genre of chronicle into two subgroups: live chronicles, and dead chronicles. A "dead" chronicle is one where the author gathers his list of events up to the time of his writing, but does not record further events as they occur. A "live" chronicle is where one or more authors add to a chronicle in a regular fashion, recording contemporary events shortly after they occur. Because of the immediacy of the information, historians tend to value live chronicles, such as annals, over dead ones.
The term often refers to a book written by a chronicler in the Middle Ages describing historical events in a country, or the lives of a nobleman or a clergyman, although it is also applied to a record of public events.
Chronicles are the predecessors of modern "time lines" rather than analytical histories. They represent accounts, in prose or verse, of local or distant events over a considerable period of time, both the lifetime of the individual chronicler and often those of several subsequent continuators. If the chronicles deal with events year by year, they are often called annals. Unlike the modern historian, most chroniclers tended to take their information as they found it, and made little attempt to separate fact from legend. The point of view of most chroniclers is highly localised, to the extent that many anonymous chroniclers can be sited in individual abbeys.
The most important English chronicles are the "Anglo-Saxon Chronicle", started under the patronage of King Alfred in the 9th century and continued until the 12th century, and the "Chronicles of England, Scotland and Ireland" (1577–87) by Raphael Holinshed and other writers; the latter documents were important sources of materials for Elizabethan drama. Later 16th century Scottish chronicles, written after the Reformation, shape history according to Catholic or Protestant viewpoints.
It is impossible to say how many chronicles exist, as the many ambiguities in the definition of the genre make it impossible to draw clear distinctions of what should or should not be included. However, the "Encyclopedia of the Medieval Chronicle" lists some 2,500 items written between 300 and 1500 AD.

</doc>
<doc id="7512" url="https://en.wikipedia.org/wiki?curid=7512" title="Concentration">
Concentration

In chemistry, concentration is the abundance of a constituent divided by the total volume of a mixture. Several types of mathematical description can be distinguished: mass concentration, molar concentration, number concentration, and volume concentration. The term concentration can be applied to any kind of chemical mixture, but most frequently it refers to solutes and solvents in solutions. The molar (amount) concentration has variants such as normal concentration and osmotic concentration.
Qualitative description.
Often in informal, non-technical language, concentration is described in a qualitative way, through the use of adjectives such as "dilute" for solutions of relatively low concentration and "concentrated" for solutions of relatively high concentration. To concentrate a solution, one must add more solute (for example, alcohol), or reduce the amount of solvent (for example, water). By contrast, to dilute a solution, one must add more solvent, or reduce the amount of solute. Unless two substances are "fully" miscible there exists a concentration at which no further solute will dissolve in a solution. At this point, the solution is said to be saturated. If additional solute is added to a saturated solution, it will not dissolve, except in certain circumstances, when supersaturation may occur. Instead, phase separation will occur, leading to coexisting phases, either completely separated or mixed as a suspension. The point of saturation depends on many variables such as ambient temperature and the precise chemical nature of the solvent and solute.
Quantitative notation.
There are four quantities that describe concentration:
Mass concentration.
The mass concentration formula_1 is defined as the mass of a constituent formula_2 divided by the volume of the mixture formula_3:
The SI unit is kg/m3 (equal to g/L).
Molar concentration.
The molar concentration formula_5 is defined as the amount of a constituent formula_6 (in moles) divided by the volume of the mixture formula_3:
The SI unit is mol/m3. However, more commonly the unit mol/L (= mol/dm3) is used.
Number concentration.
The number concentration formula_9 is defined as the number of entities of a constituent formula_10 in a mixture divided by the volume of the mixture formula_3:
The SI unit is 1/m3.
Volume concentration.
The volume concentration formula_13 (do not confuse with volume fraction) is defined as the volume of a constituent formula_14 divided by the volume of the mixture formula_3:
Being dimensionless, it is expressed as a number, e.g., 0.18 or 18%; its unit is 1.
Related quantities.
Several other quantities can be used to describe the composition of a mixture. Note that these should not be called concentrations.
Normality.
Normality is defined as the molar concentration formula_5 divided by an equivalence factor formula_18. Since the definition of the equivalence factor depends on context (which reaction is being studied), IUPAC and NIST discourage the use of normality.
Molality.
The molality of a solution formula_19 is defined as the amount of a constituent formula_6 (in moles) divided by the mass of the solvent formula_21 (not the mass of the solution):
The SI unit for molality is mol/kg.
Mole fraction.
The mole fraction formula_23 is defined as the amount of a constituent formula_6 (in moles) divided by the total amount of all constituents in a mixture formula_25:
The SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole fractions.
Mole ratio.
The mole ratio formula_27 is defined as the amount of a constituent formula_6 divided by the total amount of all "other" constituents in a mixture:
If formula_6 is much smaller than formula_25, the mole ratio is almost identical to the mole fraction.
The SI unit is mol/mol. However, the deprecated parts-per notation is often used to describe small mole ratios.
Mass fraction.
The mass fraction formula_32 is the fraction of one substance with mass formula_2 to the mass of the total mixture formula_34, defined as:
The SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass fractions.
Mass ratio.
The mass ratio formula_36 is defined as the mass of a constituent formula_2 divided by the total mass of all "other" constituents in a mixture:
If formula_2 is much smaller than formula_34, the mass ratio is almost identical to the mass fraction.
The SI unit is kg/kg. However, the deprecated parts-per notation is often used to describe small mass ratios.
Dependence on volume.
Concentration depends on the variation of the volume of the solution due mainly to thermal expansion.

</doc>
<doc id="7514" url="https://en.wikipedia.org/wiki?curid=7514" title="Christine Lavin">
Christine Lavin

Christine Lavin (born January 2, 1952) is a New York City-based singer-songwriter and promoter of contemporary folk music. She has recorded numerous solo albums, and has also recorded with other female folk artists under the name Four Bitchin' Babes. She has also put together several compilation albums of contemporary folk artists, including her latest "Just One Angel", 22 singer/songwriters singing Christmas/Hanukah/Solstice/New Year's songs including actor Jeff Daniels, Grammy-winners Janis Ian and Julie Gold, and the Guitar Man Of Central Park David Ippolito.
She is known for her sense of humor, which is expressed in both her music and her onstage performances. Many of her songs alternate between emotional reflections on romance and outright comedy. One of Lavin's songs, ""Regretting What I Said to You When You Called Me 11:00 On a Friday Morning to Tell Me that at 1:00 Friday Afternoon You're Gonna Leave Your Office, Go Downstairs, Hail a Cab to Go Out to the Airport to Catch a Plane to Go Skiing in the Alps for Two Weeks, Not that I Wanted to Go With You, I Wasn't Able to Leave Town, I'm Not a Very Good Skier, I Couldn't Expect You to Pay My Way, But After Going Out With You for Three Years I DON'T Like Surprises!! Subtitled: A Musical Apology"" is notable for its long title. It is the eighth song on her 1984 album "Future Fossils", and is 3:04 (3 minutes and 4 seconds) long.
Lavin worked at Caffe Lena in Saratoga, New York, until Dave Van Ronk convinced her to move to New York City and make a career as a singer-songwriter. She followed his advice and accepted his offer of guitar lessons. Lavin was the original host of "Sunday Breakfast" on WFUV in New York City. She was a founding member of the Four Bitchin' Babes when they were formed in 1990.

</doc>
<doc id="7515" url="https://en.wikipedia.org/wiki?curid=7515" title="Cutter Expansive Classification">
Cutter Expansive Classification

The Cutter Expansive Classification system is a library classification system devised by Charles Ammi Cutter. The system was the basis for the top categories of the Library of Congress Classification.
History of the Expansive Classification.
Charles Ammi Cutter (1837–1903), inspired by the decimal classification of his contemporary Melvil Dewey, and with Dewey's initial encouragement, developed his own classification scheme for the Winchester Town Library and then the Boston Athenaeum, at which he served as librarian for twenty-four years. He began work on it around the year 1880, publishing an overview of the new system in 1882. The same classification would later be used, but with a different notation, also devised by Cutter, at the Cary Library in Lexington.
Many libraries found this system too detailed and complex for their needs, and Cutter received many requests from librarians at small libraries who wanted the classification adapted for their collections. He devised the Expansive Classification in response, to meet the needs of growing libraries, and to address some of the complaints of his critics
. Cutter completed and published an introduction and schedules for the first six classifications of his new system ("Expansive Classification: Part I: The First Six Classifications"), but his work on the seventh was interrupted by his death in 1903.
The Cutter Expansive Classification, although adopted by comparatively few libraries, mostly in New England, has been called one of the most logical and scholarly of American classifications. Library historian Leo E. LaMontagne writes:
Cutter produced the best classification of the nineteenth century. While his system was less "scientific" than that of J. P. Lesley, its other key features – notation, specificity, and versatility – make it deserving of the praise it has received.
Its top level divisions served as a basis for the Library of Congress classification, which also took over some of its features. It did not catch on as did Dewey's system because Cutter died before it was completely finished, making no provision for the kind of development necessary as the bounds of knowledge expanded and scholarly emphases changed throughout the twentieth century.
Structure of the Expansive Classification.
The Expansive Classification uses seven separate schedules, each designed to be used by libraries of different sizes. After the first, each schedule was an expansion of the previous one, and Cutter provided instructions for how a library might change from one expansion to another as it grows.
Summary of the Expansive Classification Schedules.
First Classification.
The first classification is meant for only the very smallest libraries. The first classification has only seven top level classes, and only eight classes in all.
Further Classifications.
Further expansions add more top level classes and subdivisions. Many subclasses arranged systematically, with common divisions, such as those by geography and language, following a consistent system throughout.
By the fifth classification all the letters of the alphabet are in use for top level classes. These are:
These schedules were not meant to be fixed, but were to be adapted to meet the needs of each library. For example, books on the English language may be put in X, and books on language in general in a subclass of X, or this can be reversed. The first option is less logical, but results in shorter marks for most English language libraries.
How Expansive Classification call numbers are constructed.
Most call numbers in the Expansive Classification follow conventions offering clues to the book's subject. The first line represents the subject, the second the author (and perhaps title), the third and fourth dates of editions, indications of translations, and critical works on particular books or authors. All numbers in the Expansive Classification are (or should be) shelved as if in decimal order.
Size of volumes is indicated by points (.), pluses (+), or slashes (/ or //).
For some subjects a numerical geographical subdivision follows the classification letters on the first line. The number 83 stands for the United States—hence, F83 is U.S. history, G83 U.S. travel, JU83 U.S. politics, WP83 U.S. painting. Geographical numbers are often further expanded decimally to represent more specific areas, sometimes followed by a capital letter indicating a particular city.
The second line usually represents the author's name by a capital letter plus one or more numbers arranged decimally. This may be followed by the first letter or letters of the title in lower-case, and/or sometimes the letters a,b,c indicating other printings of the same title. When appropriate, the second line may begin with a 'form' number—e.g., 1 stands for history and criticism of a subject, 2 for a bibliography, 5 for a dictionary, 6 for an atlas or maps, 7 for a periodical, 8 for a society or university publication, 9 for a collection of works by different authors.
On the third line a capital Y indicates a work about the author or book represented by the first two lines, and a capital E (for English—other letters are used for other languages) indicates a translation into English. If both criticism and translation apply to a single title, the number expands into four lines.
Cutter Numbers (Cutter Codes).
One of the features adopted by other systems, including Library of Congress, is the Cutter number. It is an alphanumeric device to code text so that it can be arranged in alphabetical order using the fewest characters. It contains one or two initial letters and Arabic numbers, treated as a decimal. To construct a Cutter number, a cataloguer consults a Cutter table as required by the classification rules. Although Cutter numbers are mostly used for coding the names of authors, the system can be used for titles, subjects, geographic areas, and more.
Initial letters Qa-Qt are assigned Q2-Q29, while entries beginning with numerals have a Cutter number A12-A19, therefore sorting before the first A entry.
So to make the three digit Cutter number for "Cutter", you would start with "C", then looking under "other consonants", find that "u" gives the number 8, and under "additional letters", "t" is 8, giving a Cutter number of "C88".

</doc>
<doc id="7516" url="https://en.wikipedia.org/wiki?curid=7516" title="Cem Karaca">
Cem Karaca

Muhtar Cem Karaca (5 April 1945 – 8 February 2004) was a prominent Turkish rock musician and one of the most important figures in the Anatolian rock movement. He is a graduate of Robert College.
Biography.
He was the only child of Mehmet İbrahim Karaca, a theatre actor of Azerbaijani origin, and İrma Felekyan (Toto Karaca), a popular opera, theatre and movie actress of Armenian origin. His first group was called "Dynamites" and was a classic rock cover band. Later he joined "Jaguars", an Elvis Presley cover band. In 1967, he started to write his own music, joining the band "Apaşlar" (The Rowdies), his first Turkish-language group. The same year, he participated in the Golden Microphone () contest, a popular music contest in which he won second place with his song "Emrah". In 1969, Karaca and bass-player Serhan Karabay left Apaşlar and started an original Anatolian group called "Kardaşlar" (The Brothers).
In 1972, Karaca joined the group "Moğollar" (The Mongols) and wrote one of his best-known songs, ""Namus Belası"". However, Cahit Berkay, the leader of Moğollar, wanted an international name for his band, and he left for France to take the group to the next level. Karaca, who wanted to continue his Anatolian beat sound, left Moğollar and started his own band "Dervişan" (Dervishes) in 1974. Karaca and Dervişan sang poetic and progressive songs.
In the 1970s, Turkey was dealing with political violence between supporters of the left and the right, separatist movements and the rise of Islamism. As the country fell into chaos, the government suspected Cem Karaca of involvement in rebel organisations. He was accused of treason for being a separatist thinker and a Marxist-Leninist. The Turkish government tried to portray Karaca as a man who was unknowingly writing songs to start a revolution. One politician was quoted as saying, "Karaca is simply calling citizens to a bloody war against the state." "Dervişan" was ultimately dissolved at the end of 1977. In 1978, he founded "Edirdahan", an acronym for "from Edirne to Ardahan"; the westernmost and the easternmost provinces of Turkey. He recorded one LP with "Edirdahan".
In early 1979, he left for West Germany for business reasons. Turkey continued to spin out of control with military curfews and eventually a military coup on September 12, 1980. General Kenan Evren took over the government and temporarily banned all the nation's political parties. After the coup, many intellectuals, including writers, artists and journalists, were arrested. A warrant was issued for the arrest of Karaca by the government of Turkey.
The state invited Karaca back several times, but Karaca, not knowing what would happen upon his return, decided not to come back.
While Karaca was in Germany, his father died, but he could not return to attend the funeral. After some time, the Turkish government decided to strip Cem Karaca of his Turkish citizenship, keeping the arrest warrant active.
Several years later, in 1987, the prime minister and leader of the Turkish Motherland Party, Turgut Özal, issued an amnesty for Karaca. Shortly afterwards, he returned to Turkey. His return also brought a new album with it, "Merhaba Gençler ve Her zaman Genç Kalanlar" (""Hello, The Young and The Young at Heart""), one of his most influential works. His return home was received cheerfully by his fans, but during his absence Karaca had lost the young audience and acquired only few new listeners. He died on February 8, 2004 and was interred at Karacaahmet Cemetery in the Üsküdar district of Istanbul.
Discography.
Collection albums.
(1) It was released again with different cover, sort of songs and songs in 2003.
He has also appeared as a guest artist on several recordings.

</doc>
<doc id="7517" url="https://en.wikipedia.org/wiki?curid=7517" title="Calista Flockhart">
Calista Flockhart

Calista Kay Flockhart (born November 11, 1964) is an American actress, known for playing the title role in the Fox television comedy-drama series "Ally McBeal" and for playing Kitty Walker McCallister on the ABC drama "Brothers & Sisters". Since 2015 she has been cast as Cat Grant on CBSs "Supergirl". During her career, she has received a Golden Globe Award, a Screen Actors Guild Award and three Emmy Award nominations.
Early life.
Calista Flockhart was born in Freeport, Illinois, the daughter of Kay, an English teacher, and Ronald Flockhart, a Kraft Foods executive. Her parents are retired and live in Morristown, Tennessee. She has one older brother, Gary. Her mother, Kay Calista, reversed her own first and middle names in naming her Calista Kay.
Because her father's job required the family to move often, Flockhart and her brother grew up in several places including Illinois, Iowa, Minnesota, New Jersey, and Norwich, New York. As a child, she wrote a play called "Toyland" which she performed to a small audience at a dinner party.
Flockhart attended Shawnee High School in Medford Township, New Jersey. Following graduation in 1983, Flockhart attended the Mason Gross School of the Arts at Rutgers University in New Brunswick, New Jersey. While there, she attended a specialized and competitive class, lasting from 6:00 a.m. to 6:00 p.m. In her sophomore year at Rutgers, Flockhart met aspiring actress Jane Krakowski, the best friend of her roommate. Later, they both would work together on "Ally McBeal".
People began recognizing Flockhart's acting ability when William Esper (Mason Gross' theatre director and Flockhart's acting teacher) made an exception to policy by allowing Flockhart to perform on the main stage. Though this venue usually is reserved for juniors and seniors, Harold Scott insisted that Flockhart perform there in his production of William Inge's "Picnic". Flockhart graduated with a Bachelor of Fine Arts degree in Theatre in 1988 as one of the few students who successfully completed the course. Rutgers inducted her into the Hall of Distinguished Alumni on May 3, 2003.
Flockhart moved to New York City in 1989 and began seeking auditions, living with three other women in a two-bedroom apartment and working as a waitress and aerobics instructor. She would remain in the city until 1997.
Career.
Early career.
In spring 1989, Flockhart made her first television appearance in a minor role in an episode of "Guiding Light" as a babysitter. She made her professional debut on the New York stage, appearing in "Beside Herself" alongside Melissa Joan Hart, at the Circle Repertory Theatre. Two years later, Flockhart appeared in the television movie "Darrow". Though she later appeared in films "Naked in New York" (1993) and "Getting In" (1994), her first substantial speaking part in a film was in "Quiz Show", directed by Robert Redford.
Flockhart debuted on Broadway in 1994, as Laura in "The Glass Menagerie". Actress Julie Harris felt Flockhart should be hired without further auditions, claiming that she seemed ideal for the part. Flockhart received a Clarence Derwent Award for her performance. In 1995, Flockhart became acquainted with actors such as Dianne Wiest and Faye Dunaway when she appeared in the movie "Drunks". Later that year, Flockhart starred in "Jane Doe" as a drug addict. In 1996, Flockhart appeared as the daughter of Dianne Wiest and Gene Hackman's characters in "The Birdcage". Throughout that year, she continued to work on Broadway, playing the role of Natasha in Anton Chekhov's "Three Sisters".
"Ally McBeal".
In 1997, Flockhart was asked to audition for the starring role in David E. Kelley's Fox television series, "Ally McBeal". Kelley, having heard of Flockhart, wanted her to audition for the contract part. Though Flockhart at first hesitated due to the necessary commitment to the show in a negotiable contract, she was swayed by the script and traveled to Los Angeles to audition for the part, which she won. She earned a Golden Globe Award for the role in 1998. Flockhart also appeared on the June 29, 1998, cover of "Time" magazine, placed as the newest iteration in the evolution of feminism, relating to the ongoing debate about the role depicted by her character.
Throughout her professional career, Flockhart has maintained her lean figure. However, many have commented that Flockhart had become dangerously thin, particularly when the actress made red carpet appearances in clothing that revealed an emaciated physique. She had maintained throughout the show's run that she was never diagnosed with either anorexia or bulimia, nor was she a user of illegal drugs. She did remark, however, that while starring in the show she refrained from eating sweets, retaining her slimness with intense workouts and running. In 2006, she admitted that she had a problem at the time, and was "exercising too much" and "eating too little".
Other work.
Flockhart played the role of Helena in "A Midsummer Night's Dream", a 1999 film version of Shakespeare's play. In 2000, she appeared in "Things You Can Tell Just by Looking at Her" and "", later accompanying Eve Ensler to Kenya in order to protest violence against women, particularly female genital mutilation. Flockhart also starred in the Off-Broadway production of Ensler's "The Vagina Monologues".
In 2004, Flockhart appeared as Matthew Broderick's deranged girlfriend in "The Last Shot". In the same year, Flockhart travelled to Spain for the filming of "Fragile", which premiered in September 2005 at the Venice Film Festival.
She was offered the role of Susan Mayer on "Desperate Housewives", but declined. The role went to Teri Hatcher.
Flockhart's performed in a starring role as Kitty Walker, opposite Sally Field, Rachel Griffiths and Matthew Rhys, in the ABC critically acclaimed prime time series "Brothers & Sisters", which premiered in September 2006 in the time slot after "Desperate Housewives". The show was cancelled in May 2011 after running for five years. Flockhart's character was significant throughout the series' first four years, but her appearances were reduced for the 2010–2011 season, coinciding with the departure of TV husband Rob Lowe.
In 2014, Flockhart landed a role in "Full Circle"'s second season, as mob boss Ellen. It is expected to air in 2015. This had been Flockhart's first acting role in three years, after her hiatus when "Brothers & Sisters" ended.
In 2015, Flockhart was cast in the television series "Supergirl" as Cat Grant, a "self-made media magnate and founder of CatCo" and boss to Kara (Supergirl's alter ego). The series premiered on October 26, 2015 on CBS.
Personal life.
Flockhart has been in a relationship with actor Harrison Ford since their meeting at the Golden Globe Awards on January 20, 2002. They became engaged on Valentine's Day in 2009, and were married on June 15, 2010, in Santa Fe, New Mexico. The ceremony was presided over by Governor Bill Richardson and New Mexico Supreme Court Chief Justice Charles W. Daniels. Flockhart and Ford have one son together, Liam.
From 2004 to 2014, Flockhart served as the national spokesperson for Peace Over Violence.
External links.
! colspan="3" style="background: #DAA520;" | Theatre World Award

</doc>
<doc id="7519" url="https://en.wikipedia.org/wiki?curid=7519" title="Convolution">
Convolution

In mathematics and, in particular, functional analysis, convolution is a mathematical operation on two functions ("f" and "g"); it produces a third function, that is typically viewed as a modified version of one of the original functions, giving the integral of the pointwise multiplication of the two functions as a function of the amount that one of the original functions is translated. Convolution is similar to cross-correlation. It has applications that include probability, statistics, computer vision, natural language processing, image and signal processing, engineering, and differential equations.
The convolution can be defined for functions on groups other than Euclidean space. For example, periodic functions, such as the discrete-time Fourier transform, can be defined on a circle and convolved by "periodic convolution". (See row 10 at DTFT#Properties.)  A "discrete convolution" can be defined for functions on the set of integers. Generalizations of convolution have applications in the field of numerical analysis and numerical linear algebra, and in the design and implementation of finite impulse response filters in signal processing.
Computing the inverse of the convolution operation is known as deconvolution.
Definition.
The convolution of "f" and "g" is written "f"∗"g", using an asterisk or star. It is defined as the integral of the product of the two functions after one is reversed and shifted. As such, it is a particular kind of integral transform:
While the symbol "t" is used above, it need not represent the time domain. But in that context, the convolution formula can be described as a weighted average of the function "f"("τ") at the moment "t" where the weighting is given by "g"(−"τ") simply shifted by amount "t". As "t" changes, the weighting function emphasizes different parts of the input function.
For functions "f", "g" supported on only formula_1 (i.e., zero for negative arguments), the integration limits can be truncated, resulting in
In this case, the Laplace transform is more appropriate than the Fourier transform below and boundary terms become relevant.
For the multi-dimensional formulation of convolution, see Domain of definition (below).
Notation.
A primarily engineering convention that one often sees is:
which has to be interpreted carefully to avoid confusion. For instance,  f(t)*g(t-t0)  is equivalent to (f*g)(t-t0),  but f(t-t0)*g(t-t0)  is in fact equivalent to just (f*g)(t).
Derivations.
Convolution describes the output (in terms of the input) of an important class of operations known as "linear time-invariant" (LTI). See LTI system theory for a derivation of convolution as the result of LTI constraints. In terms of the Fourier transforms of the input and output of an LTI operation, no new frequency components are created. The existing ones are only modified (amplitude and/or phase). In other words, the output transform is the pointwise product of the input transform with a third transform (known as a transfer function). See Convolution theorem for a derivation of that property of convolution. Conversely, convolution can be derived as the inverse Fourier transform of the pointwise product of two Fourier transforms.
Historical developments.
One of the earliest uses of the convolution integral appeared in D'Alembert's derivation of Taylor's theorem in "Recherches sur différents points importants du système du monde," published in 1754.
Also, an expression of the type:
is used by Sylvestre François Lacroix on page 505 of his book entitled "Treatise on differences and series", which is the last of 3 volumes of the encyclopedic series: "Traité du calcul différentiel et du calcul intégral", Chez Courcier, Paris, 1797-1800. Soon thereafter, convolution operations appear in the works of Pierre Simon Laplace, Jean Baptiste Joseph Fourier, Siméon Denis Poisson, and others. The term itself did not come into wide use until the 1950s or 60s. Prior to that it was sometimes known as "faltung" (which means "folding" in German), "composition product", "superposition integral", and "Carson's integral".
Yet it appears as early as 1903, though the definition is rather unfamiliar in older uses.
The operation:
is a particular case of composition products considered by the Italian mathematician Vito Volterra in 1913.
Circular convolution.
When a function "g""T" is periodic, with period "T", then for functions, "f", such that "f"∗"g""T" exists, the convolution is also periodic and identical to:
where "t"o is an arbitrary choice. The summation is called a periodic summation of the function "f".
When "g""T" is a periodic summation of another function, "g", then "f"∗"g""T" is known as a "circular" or "cyclic" convolution of "f" and "g".<br>
And if the periodic summation above is replaced by "f""T", the operation is called a "periodic" convolution of "f""T" and "g""T".
Discrete convolution.
For complex-valued functions "f", "g" defined on the set Z of integers, the discrete convolution of "f" and "g" is given by:
The convolution of two finite sequences is defined by extending the sequences to finitely supported functions on the set of integers. When the sequences are the coefficients of two polynomials, then the coefficients of the ordinary product of the two polynomials are the convolution of the original two sequences. This is known as the Cauchy product of the coefficients of the sequences.
Thus when "g" has finite support in the set formula_8 (representing, for instance, a finite impulse response), a finite summation may be used:
Circular discrete convolution.
When a function "gN" is periodic, with period "N", then for functions, "f", such that "f"∗"gN" exists, the convolution is also periodic and identical to:
The summation on "k" is called a periodic summation of the function "f".
If "gN" is a periodic summation of another function, "g", then "f"∗"gN" is known as a circular convolution of "f" and "g".
When the non-zero durations of both "f" and "g" are limited to the interval [0, "N" − 1], "f"∗"gN" reduces to these common forms:
] \equiv (f *_N g)
The notation ("f" ∗"N" "g") for "cyclic convolution" denotes convolution over the cyclic group of integers modulo "N".
Circular convolution arises most often in the context of fast convolution with an FFT algorithm.
Fast convolution algorithms.
In many situations, discrete convolutions can be converted to circular convolutions so that fast transforms with a convolution property can be used to implement the computation. For example, convolution of digit sequences is the kernel operation in multiplication of multi-digit numbers, which can therefore be efficiently implemented with transform techniques (; ).
The most common fast convolution algorithms use fast Fourier transform (FFT) algorithms via the circular convolution theorem. Specifically, the circular convolution of two finite-length sequences is found by taking an FFT of each sequence, multiplying pointwise, and then performing an inverse FFT. Convolutions of the type defined above are then efficiently implemented using that technique in conjunction with zero-extension and/or discarding portions of the output. Other fast convolution algorithms, such as the Schönhage–Strassen algorithm or the Mersenne transform, use fast Fourier transforms in other rings.
If one sequence is much longer than the other, zero-extension of the shorter sequence and fast circular convolution is not the most computationally efficient method available. Instead, decomposing the longer sequence into blocks and convolving each block allows for faster algorithms such as the Overlap–save method and Overlap–add method. A hybrid convolution method that combines block and FIR algorithms allows for a zero input-output latency that is useful for real-time convolution computations.
Domain of definition.
The convolution of two complex-valued functions on R"d" is itself a complex-valued function on R"d", defined by:
is well-defined only if "f" and "g" decay sufficiently rapidly at infinity in order for the integral to exist. Conditions for the existence of the convolution may be tricky, since a blow-up in "g" at infinity can be easily offset by sufficiently rapid decay in "f". The question of existence thus may involve different conditions on "f" and "g":
Compactly supported functions.
If "f" and "g" are compactly supported continuous functions, then their convolution exists, and is also compactly supported and continuous . More generally, if either function (say "f") is compactly supported and the other is locally integrable, then the convolution "f"∗"g" is well-defined and continuous.
Convolution of "f" and "g" is also well defined when both functions are locally square integrable on R and supported on an interval of the form (or both supported on [-∞, a).
Integrable functions.
The convolution of "f" and "g" exists if "f" and "g" are both Lebesgue integrable functions in L1(R"d"), and in this case "f"∗"g" is also integrable . This is a consequence of Tonelli's theorem. This is also true for functions in formula_12, under the discrete convolution, or more generally for the convolution on any group.
Likewise, if "f" ∈ "L"1(R"d") and "g" ∈ "L""p"(R"d") where 1 ≤ "p" ≤ ∞, then "f"∗"g" ∈ "L""p"(R"d") and
In the particular case "p" = 1, this shows that "L"1 is a Banach algebra under the convolution (and equality of the two sides holds if "f" and "g" are non-negative almost everywhere).
More generally, Young's inequality implies that the convolution is a continuous bilinear map between suitable "L""p" spaces. Specifically, if 1 ≤ "p","q","r" ≤ ∞ satisfy
then
so that the convolution is a continuous bilinear mapping from "L""p"×"L""q" to "L""r".
The Young inequality for convolution is also true in other contexts (circle group, convolution on Z). The preceding inequality is not sharp on the real line: when , there exists a constant such that:
The optimal value of was discovered in 1975.
A stronger estimate is true provided :
where formula_18 is the weak "Lq" norm. Convolution also defines a bilinear continuous map formula_19 for formula_20
Functions of rapid decay.
In addition to compactly supported functions and integrable functions, functions that have sufficiently rapid decay at infinity can also be convolved. An important feature of the convolution is that if "f" and "g" both decay rapidly, then "f"∗"g" also decays rapidly. In particular, if "f" and "g" are rapidly decreasing functions, then so is the convolution "f"∗"g". Combined with the fact that convolution commutes with differentiation (see Properties), it follows that the class of Schwartz functions is closed under convolution .
Distributions.
Under some circumstances, it is possible to define the convolution of a function with a distribution, or of two distributions. If "f" is a compactly supported function and "g" is a distribution, then "f"∗"g" is a smooth function defined by a distributional formula analogous to
More generally, it is possible to extend the definition of the convolution in a unique way so that the associative law
remains valid in the case where "f" is a distribution, and "g" a compactly supported distribution .
Measures.
The convolution of any two Borel measures μ and ν of bounded variation is the measure λ defined by 
This agrees with the convolution defined above when μ and ν are regarded as distributions, as well as the convolution of L1 functions when μ and ν are absolutely continuous with respect to the Lebesgue measure.
The convolution of measures also satisfies the following version of Young's inequality
where the norm is the total variation of a measure. Because the space of measures of bounded variation is a Banach space, convolution of measures can be treated with standard methods of functional analysis that may not apply for the convolution of distributions.
Properties.
Algebraic properties.
The convolution defines a product on the linear space of integrable functions. This product satisfies the following algebraic properties, which formally mean that the space of integrable functions with the product given by convolution is a commutative algebra without identity . Other linear spaces of functions, such as the space of continuous functions of compact support, are closed under the convolution, and so also form commutative algebras.
for any real (or complex) number formula_29.
No algebra of functions possesses an identity for the convolution. The lack of identity is typically not a major inconvenience, since most collections of functions on which the convolution is performed can be convolved with a delta distribution or, at the very least (as is the case of "L"1) admit approximations to the identity. The linear space of compactly supported distributions does, however, admit an identity under the convolution. Specifically,
where δ is the delta distribution.
Some distributions have an inverse element for the convolution, "S"(−1), which is defined by
The set of invertible distributions forms an abelian group under the convolution.
Integration.
If "f" and "g" are integrable functions, then the integral of their convolution on the whole space is simply obtained as the product of their integrals:
This follows from Fubini's theorem. The same result holds if "f" and "g" are only assumed to be nonnegative measurable functions, by Tonelli's theorem.
Differentiation.
In the one-variable case,
where "d"/"dx" is the derivative. More generally, in the case of functions of several variables, an analogous formula holds with the partial derivative:
A particular consequence of this is that the convolution can be viewed as a "smoothing" operation: the convolution of "f" and "g" is differentiable as many times as "f" and "g" are in total.
These identities hold under the precise condition that "f" and "g" are absolutely integrable and at least one of them has an absolutely integrable (L1) weak derivative, as a consequence of Young's inequality. For instance, when "f" is continuously differentiable with compact support, and "g" is an arbitrary locally integrable function,
These identities also hold much more broadly in the sense of tempered distributions if one of "f" or "g" is a compactly supported distribution or a Schwartz function and the other is a tempered distribution. On the other hand, two positive integrable and infinitely differentiable functions may have a nowhere continuous convolution.
In the discrete case, the difference operator "D" "f"("n") = "f"("n" + 1) − "f"("n") satisfies an analogous relationship:
Convolution theorem.
The convolution theorem states that
where formula_39 denotes the Fourier transform of formula_40, and formula_41 is a constant that depends on the specific normalization of the Fourier transform. Versions of this theorem also hold for the Laplace transform, two-sided Laplace transform, Z-transform and Mellin transform.
See also the less trivial Titchmarsh convolution theorem.
Translation invariance.
The convolution commutes with translations, meaning that
where τ"x"f is the translation of the function "f" by "x" defined by
If "f" is a Schwartz function, then τ"x""f" is the convolution with a translated Dirac delta function τ"x""f" = "f"∗"τ""x" "δ". So translation invariance of the convolution of Schwartz functions is a consequence of the associativity of convolution.
Furthermore, under certain conditions, convolution is the most general translation invariant operation. Informally speaking, the following holds
Thus any translation invariant operation can be represented as a convolution. Convolutions play an important role in the study of time-invariant systems, and especially LTI system theory. The representing function "g""S" is the impulse response of the transformation "S".
A more precise version of the theorem quoted above requires specifying the class of functions on which the convolution is defined, and also requires assuming in addition that "S" must be a continuous linear operator with respect to the appropriate topology. It is known, for instance, that every continuous translation invariant continuous linear operator on "L"1 is the convolution with a finite Borel measure. More generally, every continuous translation invariant continuous linear operator on "L""p" for 1 ≤ "p" < ∞ is the convolution with a tempered distribution whose Fourier transform is bounded. To wit, they are all given by bounded Fourier multipliers.
Convolutions on groups.
If "G" is a suitable group endowed with a measure λ, and if "f" and "g" are real or complex valued integrable functions on "G", then we can define their convolution by
It is not commutative in general. In typical cases of interest "G" is a locally compact Hausdorff topological group and λ is a (left-) Haar measure. In that case, unless "G" is unimodular, the convolution defined in this way is not the same as formula_45. The preference of one over the other is made so that convolution with a fixed function "g" commutes with left translation in the group:
Furthermore, the convention is also required for consistency with the definition of the convolution of measures given below. However, with a right instead of a left Haar measure, the latter integral is preferred over the former.
On locally compact abelian groups, a version of the convolution theorem holds: the Fourier transform of a convolution is the pointwise product of the Fourier transforms. The circle group T with the Lebesgue measure is an immediate example. For a fixed "g" in "L"1(T), we have the following familiar operator acting on the Hilbert space "L"2(T):
The operator "T" is compact. A direct calculation shows that its adjoint "T*" is convolution with
By the commutativity property cited above, "T" is normal: "T"*"T" = "TT"*. Also, "T" commutes with the translation operators. Consider the family "S" of operators consisting of all such convolutions and the translation operators. Then "S" is a commuting family of normal operators. According to spectral theory, there exists an orthonormal basis {"hk"} that simultaneously diagonalizes "S". This characterizes convolutions on the circle. Specifically, we have
which are precisely the characters of T. Each convolution is a compact multiplication operator in this basis. This can be viewed as a version of the convolution theorem discussed above.
A discrete example is a finite cyclic group of order "n". Convolution operators are here represented by circulant matrices, and can be diagonalized by the discrete Fourier transform.
A similar result holds for compact groups (not necessarily abelian): the matrix coefficients of finite-dimensional unitary representations form an orthonormal basis in "L"2 by the Peter–Weyl theorem, and an analog of the convolution theorem continues to hold, along with many other aspects of harmonic analysis that depend on the Fourier transform.
Convolution of measures.
Let "G" be a topological group.
If μ and ν are finite Borel measures on "G", then their convolution μ∗ν is defined by
for each measurable subset "E" of "G". The convolution is also a finite measure, whose total variation satisfies
In the case when "G" is locally compact with (left-)Haar measure λ, and μ and ν are absolutely continuous with respect to a λ, so that each has a density function, then the convolution μ∗ν is also absolutely continuous, and its density function is just the convolution of the two separate density functions.
If μ and ν are probability measures on the topological group then the convolution μ∗ν is the probability distribution of the sum "X" + "Y" of two independent random variables "X" and "Y" whose respective distributions are μ and ν.
Bialgebras.
Let ("X", Δ, ∇, "ε", "η") be a bialgebra with comultiplication Δ, multiplication ∇, unit η, and counit ε. The convolution is a product defined on the endomorphism algebra End("X") as follows. Let φ, ψ ∈ End("X"), that is, φ,ψ : "X" → "X" are functions that respect all algebraic structure of "X", then the convolution φ∗ψ is defined as the composition
The convolution appears notably in the definition of Hopf algebras . A bialgebra is a Hopf algebra if and only if it has an antipode: an endomorphism "S" such that
Applications.
Convolution and related operations are found in many applications in science, engineering and mathematics.

</doc>
<doc id="7521" url="https://en.wikipedia.org/wiki?curid=7521" title="Calico">
Calico

Calico (in British usage, 1505, AmE "muslin") is a plain-woven textile made from unbleached and often not fully processed cotton. It may contain unseparated husk parts, for example. The fabric is less coarse and thick than canvas or denim, but it is still very cheap owing to its unfinished and undyed appearance.
The fabric was originally from the city of Kozhikode (known by the English as "Calicut") in southwestern India. It was made by the traditional weavers called cāliyans. The raw fabric was dyed and printed in bright hues, and calico prints became popular in Europe.
History.
Calico originated in Kozhikode (also known as Calicut, from which the name of the textile came) in southwestern India during the 11th century. The cloth was known as "cāliyan" to the natives.
It was mentioned in Indian literature by the 12th century when the writer Hēmacandra described calico fabric prints with a lotus design. By the 15th century calico from Gujǎrāt made its appearance in Egypt. Trade with Europe followed from the 17th century onwards.
Calico was woven using Sūrat cotton for both the warp and weft.
Politics of cotton.
In the 18th century, England was famous for its woollen and worsted cloth. That industry, centred in the east and south in towns such as Norwich, jealously protected their product. Cotton processing was tiny: in 1701 only of cotton-wool was imported into England, and by 1730 this had fallen to . This was due to commercial legislation to protect the woollen industry. Cheap calico prints, imported by the East India Company from Hindustān (India), had become popular. In 1700 an Act of Parliament was passed to prevent the importation of dyed or printed calicoes from India, China or Persia. This caused grey cloth (calico that had not been finished—dyed or printed) to be imported instead, and these were printed in southern England with the popular patterns. Also, Lancashire businessmen produced grey cloth with linen warp and cotton weft, known as fustian, which they sent to London to be finished. Cotton-wool imports recovered and by 1720 were almost back to their 1701 levels. Again the woollen manufacturers, in true protectionist style, claimed that this was taking away jobs from workers in Coventry. Another law was passed, to fine anyone caught wearing any printed or stained calico; muslins, neckcloths and fustians were exempted. It was this exemption that the Lancashire manufactures exploited. The use of coloured cotton weft with linen warp was permitted by the 1736 Manchester Act. There now was an artificial demand for woven cloth. In 1764, of cotton-wool was imported. It has been noted that this was a key part of the process of the reduction of the Indian economy from sophisticated textile production to a mere supplier of raw materials which occurred under colonial rule, a process described by Nehru and more recent scholars as "de-industrialization."
Calico printing.
Early Indian chintzes, that is a glazed calico with large floral pattern, were primarily produced by painting techniques. Later, the hues were applied by means of wooden blocks, and it was the wooden block printing that was used in London. Confusingly, linen and silk that was printed by this method was known as "linen calicoes" and "silk calicoes". The early European calicoes (1680) would thus be a cheap equal weft and warp plain weave cotton fabric in white, cream or unbleached cotton, with a block printed design using a single alizarin dye, fixed with two mordants giving a red and black pattern. Polychromatic prints could be done, with two sets of blocks and an additional blue dye. The Indian taste was for dark printed backgrounds while the European market preferred a pattern on a cream base. As the century progressed the European preference moved from the large chintz patterns to smaller, tighter patterns.
Thomas Bell patented the technique of printing by copper rollers in 1783, and the first machine was set up by Livesey, Hargreaves and Company near Preston in 1785. Production of printed cloth in Lancashire in 1750 was estimated to be 50,000 pieces of , but in 1850 it was 20,000,000 pieces. From 1888, block printing was limited to short run specialist jobs. After 1880, profits from printing became smaller, there was over capacity and the firms started to form combines. The first was when 3 Scottish firms formed the United Turkey Red Co. Ltd in 1897, and the second, in 1899, was the much larger Calico Printers' Association. 46 printing concerns and 13 merchants combined, representing 85% of the British printing capacity. Some of this capacity was removed and in 1901 they had 48% of the trade. In 1916, they and the other printers joined and formed a trade association. This then set minimum prices for each 'price section' of the industry. This held until 1954 when it was challenged by the government Monopolies Commission. Over the intervening period much trade had been lost overseas.
Terminology.
In the UK, Australia and New Zealand:
In the US:
Printed calico was imported into the United States from Lancashire in the 1780s, and here a linguistic separation occurred, while Europe maintained the word calico for the fabric, in the States it was used to refer to the printed design.
These colorful, small-patterned printed fabrics gave rise to the use of the word calico to describe a cat coat color: "calico cat". The patterned fabric also gave its name to two species of North American crabs; see the calico crab.

</doc>
<doc id="7522" url="https://en.wikipedia.org/wiki?curid=7522" title="Calorimetry">
Calorimetry

Calorimetry is the science or act of measuring changes in state variables of a body for the purpose of deriving the heat transfer associated with changes of its state due for example to chemical reactions, physical changes, or phase transitions under specified constraints. Calorimetry is performed with a calorimeter. The word "calorimetry" is derived from the Latin word "calor", meaning heat and the Greek word "μέτρον" (metron), meaning measure. Scottish physician and scientist Joseph Black, who was the first to recognize the distinction between heat and temperature, is said to be the founder of the science of calorimetry.
Indirect Calorimetry calculates heat that living organisms produce by measuring either their production of carbon dioxide and nitrogen waste (frequently ammonia in aquatic organisms, or urea in terrestrial ones), or from their consumption of oxygen. 
Lavoisier noted in 1780 that heat production can be predicted from oxygen consumption this way, using multiple regression. The Dynamic Energy Budget theory explains why this procedure is correct. Heat generated by living organisms may also be measured by direct calorimetry, in which the entire organism is placed inside the calorimeter for the measurement.
A widely used modern instrument is the differential scanning calorimeter, a device which allows thermal data to be obtained on small amounts of material. It involves heating the sample at a controlled rate and recording the heat flow either into or from the specimen.
Classical calorimetric calculation of heat.
Cases with differentiable equation of state for a one-component body.
Basic classical calculation with respect to volume.
Calorimetry requires that a reference material that changes temperature have known definite thermal constitutive properties. The classical rule, recognized by Clausius and by Kelvin, is that the pressure exerted by the calorimetric material is fully and rapidly determined solely by its temperature and volume; this rule is for changes that do not involve phase change, such as melting of ice. There are many materials that do not comply with this rule, and for them, the present formula of classical calorimetry does not provide an adequate account. Here the classical rule is assumed to hold for the calorimetric material being used, and the propositions are mathematically written:
The thermal response of the calorimetric material is fully described by its pressure formula_1 as the value of its constitutive function formula_2 of just the volume formula_3 and the temperature formula_4. All increments are here required to be very small. This calculation refers to a domain of volume and temperature of the body in which no phase change occurs, and there is only one phase present. An important assumption here is continuity of property relations. A different analysis is needed for phase change.
When a small increment of heat is gained by a calorimetric body, with small increments, formula_5 of its volume, and formula_6 of its temperature, the increment of heat, formula_7, gained by the body of calorimetric material, is given by
where
The latent heat with respect to volume is the heat required for unit increment in volume at constant temperature. It can be said to be 'measured along an isotherm', and the pressure the material exerts is allowed to vary freely, according to its constitutive law formula_18. For a given material, it can have a positive or negative sign or exceptionally it can be zero, and this can depend on the temperature, as it does for water about 4 C. The concept of latent heat with respect to volume was perhaps first recognized by Joseph Black in 1762. The term 'latent heat of expansion' is also used. The latent heat with respect to volume can also be called the 'latent energy with respect to volume'. For all of these usages of 'latent heat', a more systematic terminology uses 'latent heat capacity'.
The heat capacity at constant volume is the heat required for unit increment in temperature at constant volume. It can be said to be 'measured along an isochor', and again, the pressure the material exerts is allowed to vary freely. It always has a positive sign. This means that for an increase in the temperature of a body without change of its volume, heat must be supplied to it. This is consistent with common experience.
Quantities like formula_7 are sometimes called 'curve differentials', because they are measured along curves in the formula_20 surface.
Classical theory for constant-volume calorimetry.
Constant-volume calorimetry is calorimetry performed at a constant volume. This involves the use of a constant-volume calorimeter. Heat is still measured by the above-stated principle of calorimetry.
This means that in a suitably constructed calorimeter, called a bomb calorimeter, the increment of volume formula_5 can be made to vanish, formula_22. For constant-volume calorimetry:
where
Classical heat calculation with respect to pressure.
From the above rule of calculation of heat with respect to volume, there follows one with respect to pressure.
In a process of small increments, formula_26 of its pressure, and formula_6 of its temperature, the increment of heat, formula_7, gained by the body of calorimetric material, is given by
where
The new quantities here are related to the previous ones:
where
and
The latent heats formula_9 and formula_30 are always of opposite sign.
It is common to refer to the ratio of specific heats as
Calorimetry through phase change, equation of state shows one jump discontinuity.
An early calorimeter was that used by Laplace and Lavoisier, as shown in the figure above. It worked at constant temperature, and at atmospheric pressure. The latent heat involved was then not a latent heat with respect to volume or with respect to pressure, as in the above account for calorimetry without phase change. The latent heat involved in this calorimeter was with respect to phase change, naturally occurring at constant temperature. This kind of calorimeter worked by measurement of mass of water produced by the melting of ice, which is a phase change.
Cumulation of heating.
For a time-dependent process of heating of the calorimetric material, defined by a continuous joint progression formula_53 of formula_54 and formula_55, starting at time formula_56 and ending at time formula_57, there can be calculated an accumulated quantity of heat delivered, formula_58 . This calculation is done by mathematical integration along the progression with respect to time. This is because increments of heat are 'additive'; but this does not mean that heat is a conservative quantity. The idea that heat was a conservative quantity was invented by Lavoisier, and is called the 'caloric theory'; by the middle of the nineteenth century it was recognized as mistaken. Written with the symbol formula_59, the quantity formula_58 is not at all restricted to be an increment with very small values; this is in contrast with formula_7.
One can write
This expression uses quantities such as formula_65 which are defined in the section below headed 'Mathematical aspects of the above rules'.
Mathematical aspects of the above rules.
The use of 'very small' quantities such as formula_7 is related to the physical requirement for the quantity formula_2 to be 'rapidly determined' by formula_3 and formula_4; such 'rapid determination' refers to a physical process. These 'very small' quantities are used in the Leibniz approach to the infinitesimal calculus. The Newton approach uses instead 'fluxions' such as formula_70, which makes it more obvious that formula_2 must be 'rapidly determined'.
In terms of fluxions, the above first rule of calculation can be written
where
The increment formula_7 and the fluxion formula_65 are obtained for a particular time formula_73 that determines the values of the quantities on the righthand sides of the above rules. But this is not a reason to expect that there should exist a mathematical function formula_82. For this reason, the increment formula_7 is said to be an 'imperfect differential' or an 'inexact differential'. Some books indicate this by writing formula_84 instead of formula_7. Also, the notation "đQ" is used in some books. Carelessness about this can lead to error.
The quantity formula_62 is properly said to be a functional of the continuous joint progression formula_53 of formula_54 and formula_55, but, in the mathematical definition of a function, formula_62 is not a function of formula_20. Although the fluxion formula_65 is defined here as a function of time formula_73, the symbols formula_94 and formula_82 respectively standing alone are not defined here.
Physical scope of the above rules of calorimetry.
The above rules refer only to suitable calorimetric materials. The terms 'rapidly' and 'very small' call for empirical physical checking of the domain of validity of the above rules.
The above rules for the calculation of heat belong to pure calorimetry. They make no reference to thermodynamics, and were mostly understood before the advent of thermodynamics. They are the basis of the 'thermo' contribution to thermodynamics. The 'dynamics' contribution is based on the idea of work, which is not used in the above rules of calculation.
Experimentally conveniently measured coefficients.
Empirically, it is convenient to measure properties of calorimetric materials under experimentally controlled conditions.
Pressure increase at constant volume.
For measurements at experimentally controlled volume, one can use the assumption, stated above, that the pressure of the body of calorimetric material is can be expressed as a function of its volume and temperature.
For measurement at constant experimentally controlled volume, the isochoric coefficient of pressure rise with temperature, is defined by
Expansion at constant pressure.
For measurements at experimentally controlled pressure, it is assumed that the volume formula_3 of the body of calorimetric material can be expressed as a function formula_98 of its temperature formula_4 and pressure formula_1. This assumption is related to, but is not the same as, the above used assumption that the pressure of the body of calorimetric material is known as a function of its volume and temperature; anomalous behaviour of materials can affect this relation.
The quantity that is conveniently measured at constant experimentally controlled pressure, the isobaric volume expansion coefficient, is defined by
Compressibility at constant temperature.
For measurements at experimentally controlled temperature, it is again assumed that the volume formula_3 of the body of calorimetric material can be expressed as a function formula_98 of its temperature formula_4 and pressure formula_1, with the same provisos as mentioned just above.
The quantity that is conveniently measured at constant experimentally controlled temperature, the isothermal compressibility, is defined by
Relation between classical calorimetric quantities.
Assuming that the rule formula_18 is known, one can derive the function formula_108 that is used above in the classical heat calculation with respect to pressure. This function can be found experimentally from the coefficients formula_109 and formula_110 through the mathematically deducible relation
Connection between calorimetry and thermodynamics.
Thermodynamics developed gradually over the first half of the nineteenth century, building on the above theory of calorimetry which had been worked out before it, and on other discoveries. According to Gislason and Craig (2005): "Most thermodynamic data come from calorimetry..." According to Kondepudi (2008): "Calorimetry is widely used in present day laboratories."
In terms of thermodynamics, the internal energy formula_112 of the calorimetric material can be considered as the value of a function formula_113 of formula_20, with partial derivatives formula_115 and formula_116.
Then it can be shown that one can write a thermodynamic version of the above calorimetric rules:
with
and
Again, further in terms of thermodynamics, the internal energy formula_112 of the calorimetric material can sometimes, depending on the calorimetric material, be considered as the value of a function formula_121 of formula_122, with partial derivatives formula_123 and formula_116, and with formula_3 being expressible as the value of a function formula_126 of formula_122, with partial derivatives formula_128 and formula_129 .
Then, according to Adkins (1975), it can be shown that one can write a further thermodynamic version of the above calorimetric rules:
with
and
Beyond the calorimetric fact noted above that the latent heats formula_9 and formula_30 are always of opposite sign, it may be shown, using the thermodynamic concept of work, that also
Special interest of thermodynamics in calorimetry: the isothermal segments of a Carnot cycle.
Calorimetry has a special benefit for thermodynamics. It tells about the heat absorbed or emitted in the isothermal segment of a Carnot cycle.
A Carnot cycle is a special kind of cyclic process affecting a body composed of material suitable for use in a heat engine. Such a material is of the kind considered in calorimetry, as noted above, that exerts a pressure that is very rapidly determined just by temperature and volume. Such a body is said to change reversibly. A Carnot cycle consists of four successive stages or segments:
(3) another isothermal change in volume from formula_140 to a volume formula_142 at constant temperature formula_143 such as to incur a flow or heat out of the body and just such as to precisely prepare for the following change
(4) another adiabatic change of volume from formula_142 back to formula_136 just such as to return the body to its starting temperature formula_138.
In isothermal segment (1), the heat that flows into the body is given by
and in isothermal segment (3) the heat that flows out of the body is given by
Because the segments (2) and (4) are adiabats, no heat flows into or out of the body during them, and consequently the net heat supplied to the body during the cycle is given by
This quantity is used by thermodynamics and is related in a special way to the net work done by the body during the Carnot cycle. The net change of the body's internal energy during the Carnot cycle, formula_150, is equal to zero, because the material of the working body has the special properties noted above.
Special interest of calorimetry in thermodynamics: relations between classical calorimetric quantities.
Relation of latent heat with respect to volume, and the equation of state.
The quantity formula_9, the latent heat with respect to volume, belongs to classical calorimetry. It accounts for the occurrence of energy transfer by work in a process in which heat is also transferred; the quantity, however, was considered before the relation between heat and work transfers was clarified by the invention of thermodynamics. In the light of thermodynamics, the classical calorimetric quantity is revealed as being tightly linked to the calorimetric material's equation of state formula_18. Provided that the temperature formula_153 is measured in the thermodynamic absolute scale, the relation is expressed in the formula
Difference of specific heats.
Advanced thermodynamics provides the relation
From this, further mathematical and thermodynamic reasoning leads to another relation between classical calorimetric quantities. The difference of specific heats is given by
Practical constant-volume calorimetry (bomb calorimetry) for thermodynamic studies.
Constant-volume calorimetry is calorimetry performed at a constant volume. This involves the use of a constant-volume calorimeter.
No work is performed in constant-volume calorimetry, so the heat measured equals the change in internal energy of the system. The heat capacity at constant volume is assumed to be independent of temperature.
Heat is measured by the principle of calorimetry.
where 
In "constant-volume calorimetry" the pressure is not held constant. If there is a pressure difference between initial and final states, the heat measured needs adjustment to provide the "enthalpy change". One then has
where 

</doc>
<doc id="7525" url="https://en.wikipedia.org/wiki?curid=7525" title="Charles Evans Hughes">
Charles Evans Hughes

Charles Evans Hughes, Sr. (April 11, 1862 – August 27, 1948) was an American statesman, lawyer, and Republican politician from New York. He served as the 36th Governor of New York (1907–1910), Associate Justice of the Supreme Court of the United States (1910–1916), United States Secretary of State (1921–1925), a judge on the Court of International Justice (1928–1930), and the 11th Chief Justice of the United States (1930–1941). He was the Republican nominee in the 1916 U.S. Presidential election, losing narrowly to incumbent President Woodrow Wilson.
Hughes was a professor in the 1890s, a staunch supporter of Britain's New Liberalism, an important leader of the progressive movement of the 20th century, a leading diplomat and New York lawyer in the days of Harding and Coolidge, and was known for being a swing voter when dealing with cases related to the New Deal in the 1930s. Historian Clinton Rossiter has hailed him as a leading American conservative.
Early life.
Charles Evans Hughes was born in Glens Falls, New York, the son of Rev. David C. Hughes and Mary C. (Connelly) Hughes, a sister of State Senator Henry C. Connelly (1832–1912). He was active in the Northern Baptist church, a Mainline Protestant denomination.
Education.
Hughes' early education included attending Lafayette School in Newark, NJ. At the age of 14, he enrolled at Madison University (now Colgate University), where he became a member of Delta Upsilon fraternity. He then transferred to Brown University, continuing as a member of Delta Upsilon. He graduated third in his class at the age of 19, having been elected to Phi Beta Kappa in his junior year. He read law and entered Columbia Law School in 1882, where he graduated in 1884 with highest honors. While studying law, he taught at Delaware Academy.
Marriage and family.
In 1885, Hughes met Antoinette Carter, the daughter of a senior partner of the law firm where he worked, and they were married in 1888. They had one son, Charles Evans Hughes Jr. and three daughters, one of whom was Elizabeth Hughes Gossett, one of the first humans injected with insulin, and who later served as president of the Supreme Court Historical Society. Hughes was the grandfather of Charles Evans Hughes III and H. Stuart Hughes.
Early career.
After graduating Hughes began working for Chamberlain, Carter & Hornblower where he met his future wife. In 1888, shortly after he was married, he became a partner in the firm, and the name was changed to Carter, Hughes & Cravath. Later the name was changed to Hughes, Hubbard & Reed. In 1891, Hughes left the practice of law to become a professor at Cornell Law School. In 1893, he returned to his old law firm in New York City to continue practicing until he ran for governor in 1906. He continued his association with Cornell as a special lecturer at the Law School from 1893 to 1895. He was also a special lecturer for New York University Law School, 1893–1900.
At that time, in addition to practicing law, Hughes taught at New York Law School with Woodrow Wilson, who would later defeat him for the Presidency. In 1905, he was appointed as counsel to the New York state legislative "Stevens Gas Commission", a committee investigating utility rates. His uncovering of corruption led to lower gas rates in New York City. In 1906, he was appointed to the "Armstrong Insurance Commission" to investigate the insurance industry in New York as a special assistant to U.S. Attorney General.
Governor of New York.
Hughes served as the Governor of New York from 1907 to 1910. He defeated William Randolph Hearst in the 1906 election to gain the position, and he was the only Republican statewide candidate to win office. An admirer of Britain's New Liberal philosophy, Hughes campaigned on a platform to improve the state of New York's standard of living by moving it away from laissez-faire tradition and enacting social reforms similar to that which had been enacted in Britain. As a supporter of progressive policies, Hughes was able to play on the popularity of Theodore Roosevelt and weaken the power of the state's conservative Republican officials. In 1908, he was offered the vice-presidential nomination by William Howard Taft, but he declined it to run again for Governor. Theodore Roosevelt became an important supporter of Hughes.
As the Governor, Hughes produced important reform legislation in three areas: improvement of the machinery and processes of government; extension of the state's regulatory authority over businesses engaged in public services; and expansion of governmental police and welfare functions. To counter political corruption, he secured campaign laws in 1906 and 1907 that limited political contributions by corporations and forced candidates to account for their receipts and expenses, legislation that was quickly copied in fifteen other states. He pushed the passage of the Moreland Act, which enabled the governor to oversee city and county officials as well as officials in semi-autonomous state bureaucracies. This allowed him to fire many corrupt officials. He also managed to have the powers of the state's Public Service Commissions increased and fought strenuously, if not completely successfully, to get their decisions exempted from judicial review.
When two bills were passed to reduce railroad fares, Hughes vetoed them on the grounds that the rates should be set by expert commissioners rather than by elected ones. His ideal was not government by the people but for the people. As Hughes put it, "you must have administration by administrative officers."
Hughes, however, would be unsuccessful in achieving one of his main goals as governor: primary voting reform. Hoping to achieve a compromise with the state's party bosses, Hughes rejected the option of a direct primary in which voters could choose between declared candidates and instead proposed a complicated system of nominations by party committees. The state's party bosses, however, rejected this compromise and the state legislature rejected the plan on three occasions in 1909 and 1910.
On social issues, Hughes strongly supported relatively limited social reforms. He endorsed the Page-Prentice Act of 1907, which set an eight-hour day and forty-eight-hour week for factory workers—but only for those under the age of sixteen. By employing the well-established legal distinction between ordinary and hazardous work, the governor also won legislative approval for a Dangerous Trades Act that barred young workers from thirty occupations. To enforce these and other regulations, in 1907 Hughes reorganized the Department of Labor and appointed a well-qualified commissioner. Two years later, the governor created a new bureau for immigrant issues in the Department of Labor and appointed reformer Frances Kellor to head it.
In his final year as the Governor, he had the state comptroller draw up an executive budget. This began a rationalization of state government and eventually it led to an enhancement of executive authority. He also signed the Worker's Compensation Act of 1910, which required a compulsory, employer-paid plan of compensation for workers injured in hazardous industries and a voluntary system for other workers; after the New York Court of Appeals ruled the law unconstitutional in 1911, a popular referendum was held that successfully made the law an amendment in the New York Constitution.
In 1908, Governor Hughes reviewed the clemency petition of Chester Gillette concerning the murder of Grace Brown. The governor denied the petition as well as an application for reprieve, and Gillette was electrocuted in March of that year.
When Hughes left office, a prominent journal remarked "One can distinctly see the coming of a New Statism ... which Gov. Hughes has been a leading prophet and exponent". In 1926, Hughes was appointed by New York Governor Alfred E. Smith to be the chairman of a "State Reorganization Commission" through which Smith's plan to place the Governor as the head of a rationalized state government, was accomplished, bringing to realization what Hughes himself had envisioned.
In 1909, Hughes led an effort to incorporate Delta Upsilon fraternity. This was the first fraternity to incorporate, and he served as its first international president.
Associate Justice.
On April 25, 1910, President William H. Taft nominated Hughes for Associate Justice to fill the vacancy left by the death of Justice David J. Brewer. The Senate confirmed the nomination on May 2, 1910, and Hughes received his commission the same day. As an associate justice of the Supreme Court from 1910 to 1916, Hughes remained an advocate of regulation and authored decisions that weakened the legal foundations of laissez-faire capitalism. He also mastered a new set of issues regarding the Commerce Clause and, in a deliberately restrained manner, wrote constitutional decisions that expanded the regulatory powers of both the state and federal governments.
He wrote for the court in "Bailey v. Alabama" , which held that involuntary servitude encompassed more than just slavery, and "Interstate Commerce Comm. v. Atchison T & SF R Co." , holding that the Interstate Commerce Commission could regulate intrastate rates if they were significantly intertwined with interstate commerce.
On April 15, 1915 in the case of "Frank v. Mangum", the Supreme Court decided (7-2) to deny an appeal made by Leo Frank's attorneys, and instead upheld the decision of lower courts to sustain the guilty verdict against Frank. Justice Hughes and Justice Oliver Wendell Holmes Jr. were the two dissenting votes.
Presidential candidate.
Hughes resigned from the Supreme Court on June 10, 1916, to be the Republican candidate for President in 1916. He is the last sitting Supreme Court justice to surrender his or her seat to run for elected office. He was also endorsed by the Progressive Party, thanks to the support given to him from former President Theodore Roosevelt. Other Republican figures such as former President William Howard Taft endorsed Hughes and felt the accomplishments he made as Governor of New York would establish him as formidable progressive alternative to Wilson. Many former leaders of the Progressive Party, however, endorsed Wilson because Hughes opposed the Adamson Act, the Sixteenth Amendment and diverted his focus away from progressive issues during the course of the campaign. Hughes was defeated by Woodrow Wilson in a close election (separated by 23 electoral votes and 594,188 popular votes). The election hinged on California, where Wilson managed to win by 3,800 votes and its 13 electoral votes and thus Wilson was returned for a second term; Hughes had lost the endorsement of the California governor and Roosevelt's 1912 Progressive running mate Hiram Johnson when he failed to show up for an appointment with him.
Despite coming close to winning the presidency, Hughes did not seek the Republican nomination again in 1920. Hughes also advocated ways to prevent the return of President Wilson's expanded government control over important industries such as the nation's railroads, which he felt would lead to the eventual destruction of individualism and political self-rule. After Robert LaFollette's Progressive Party advocated the return of such regulations during the 1924 US Presidential election, Hughes shifted rightwards believing that the federal bureaucracy should now have limited powers over individual liberties and property rights and that common law should be strictly enforced.
Secretary of State.
Hughes returned to government office in March 1921 as Secretary of State under President Harding. On November 11, 1921, Armistice Day (later changed to Veterans Day), the Washington Naval Conference for the limitation of naval armament among the Great Powers began. The major naval powers of Britain, France, Italy, Japan and the United States were in attendance as well as other nations with concerns about territories in the Pacific — Belgium, the Netherlands, Portugal and China.
The American delegation was headed by Hughes and included Elihu Root, Henry Cabot Lodge, and Oscar Underwood, the Democratic minority leader in the Senate. The conference continued until February 1922 and included the Four-power pact (December 13, 1921), Shantung Treaty (February 4, 1922), Five-Power Treaty, the Nine-Power Treaty (February 6, 1922), the "Six-power pact" that was an agreement between the Big Five Nations plus China to divide the German cable routes in the Pacific, and the Yap Island agreement.
Hughes continued in office after Harding died and was succeeded by Coolidge, but resigned after Coolidge was elected to a full term. On June 30, 1922, he signed the "Hughes–Peynado agreement" that ended the United States's six-year occupation of Dominican Republic.
Various appointments.
In 1907, Gov. Charles Evans Hughes became the first president of the newly formed Northern Baptist Convention—based at Calvary Baptist Church in Washington, DC, of which Hughes was a member. He also served as President of the New York State Bar Association.
After leaving the State Department, he again rejoined his old partners at the Hughes firm, which included his son and future United States Solicitor General Charles E. Hughes Jr., and was one of the nation's most sought-after advocates. From 1925 to 1930, for example, Hughes argued over 50 times before the U.S. Supreme Court. From 1926 to 1930, Hughes also served as a member of the Permanent Court of Arbitration and as a judge of the Permanent Court of International Justice in The Hague, Netherlands from 1928 to 1930. He was additionally a delegate to the Pan American Conference on Arbitration and Conciliation from 1928 to 1930. He was one of the co-founders in 1927 of the National Conference on Christians and Jews, now known as the National Conference for Community and Justice (NCCJ), along with S. Parkes Cadman and others, to oppose the Ku Klux Klan, anti-Catholicism, and anti-Semitism in the 1920s and 1930s.
In 1925–1926, Charles Evans Hughes represented the API (American Petroleum Institute) before the FOCB (Federal Oil Conservation Board).
In 1928 conservative business interests tried to interest Hughes in the GOP presidential nomination of 1928 instead of Herbert Hoover. Hughes, citing his age, turned down the offer.
Chief Justice.
Herbert Hoover, who had appointed Hughes's son as Solicitor General in 1929, appointed Hughes Chief Justice of the United States on February 3, 1930. Hughes was confirmed by the United States Senate on February 13, 1930, and received commission the same day, serving in this capacity until 1941. Hughes replaced former President William Howard Taft, a fellow Republican who had also lost a presidential election to Woodrow Wilson (in 1912) and who, in 1910, had appointed Hughes to his first tenure on the Supreme Court.
Hughes' appointment was opposed by progressive elements in both parties who felt that he was too friendly to big business. Idaho Republican William E. Borah said on the United States Senate floor that confirming Hughes would constitute "placing upon the Court as Chief Justice one whose views are known upon these vital and important questions and whose views, in my opinion, however sincerely entertained, are not which ought to be incorporated in and made a permanent part of our legal and economic system." In addition to his politics, at 67, Hughes was the oldest man ever nominated as Chief Justice. Nonetheless Hughes was confirmed as Chief Justice with a vote of 52 to 26.
Hughes as Chief Justice swore in President Franklin D. Roosevelt in 1933, 1937 and 1941.
Upon his return to the court, more progressives had joined the bench. Hughes seemed determined again to vote progressive and soon bring an end to the longstanding pro-business Lochner era. During his early years as Chief Justice, however, the fear he had developed for an overblown bureaucracy during World War I undermined his optimism. Showing his old progressive image, he upheld legislation protecting civil rights and civil liberties and wrote the opinion for the Court in "Near v. Minnesota" , which held prior restraint against the press is unconstitutional. Concerning economic regulation, he was still willing to uphold legislation that supported "freedom of opportunity" for individuals on the one hand and the "police power" of the state on the other but did not personally favor legislation that linked national economic planning and bureaucratic social welfare together. At first resisting Roosevelt's New Deal and building a consensus of centrist members of the court, Hughes used his influence to limit the collectivist scope of Roosevelt's changes and would often strike down New Deal legislation he felt was poorly drafted and did not clearly specify how they were constitutional. By 1935, Hughes felt the court's four conservative Justices had disregarded common law and sought to curb their power.
Hughes was often aligned with the court's three liberal Justices — Louis Brandeis, Harlan Fiske Stone, and Benjamin Cardozo — in finding some New Deal measures (such as the violation of the gold clauses in contracts and the confiscation of privately owned monetary gold) Constitutional. On one occasion, Hughes would side with the conservatives in striking down the New Deal's Agricultural Adjustment Act in the 1936 case "United States v. Butler", which held that the law was unconstitutional because its so-called tax policy was a coercive regulation rather than a tax measure and the federal government lacked authority to regulate agriculture. But surprisingly he did not assign the majority opinion, a practice usually required for court's most senior justice who agrees with the majority opinion, and allowed Associate Justice Owen Roberts to speak for the entire majority in his own words. It was accepted that he did not agree with the argument that the federal government lacked authority over agriculture and was going to write a separate opinion upholding the act's regulation policy while striking down the act's taxation policy on the grounds that it was a coercive regulation rather than a tax measure. However, Roberts convinced Hughes that he would side with him and the three liberal justices in future cases pertaining to the nation's agriculture that involved the Constitution's General Welfare Clause if he agreed to join his opinion.
By 1936, Hughes sensed the growing hostility in the court and could do little about it. In the 1936 case "Carter v. Carter Coal Company", Hughes took a middle ground for doctrinal and court-management reasons. Writing his own opinion, he joined the three liberal justices in upholding the Bituminous Coal Conservation Act's marketing provision but sided with Roberts and the four conservatives in striking down the act's provision that regulated local labor. By 1937, as the court leaned more in his favor, Hughes would renounce the position he took in the "Carter" case regarding local labor and ruled that the procedural methods that governed the Wagner Act's labor regulation provisions bore resemblance to the procedural methods which governed the railroad rates that the Interstate Commerce Commission was allowed to maintain in the 1914 "Shreveport" decision; he thus demonstrated that Congress could use its commerce power to regulate local industrial labor as well.
In 1937, when Roosevelt attempted to pack the Court with six additional justices, Hughes worked behind the scenes to defeat the effort, which failed in the Senate, by rushing important New Deal legislation — such as Wagner Act and the Social Security Act — through the court and ensuring that the court's majority would uphold their constitutionality. The month after Roosevelt's court-packing announcement, Roberts, who had joined the four conservative Justices in striking down important New Deal legislation, shocked the American public by siding with Hughes and the court's three liberal justices in striking down the court's ruling in the 1923 "Adkins v. Children's Hospital" case — which held that laws requiring minimum wage violated the Fifth Amendment's due process clause — and upholding the constitutionality of Washington state's minimum wage law in "West Coast Hotel Co. v. Parrish". Because Roberts had previously sided with the four conservative justices and used the "Adkins" decision as the basis for striking down a similar minimum wage law the state of New York enforced in "Morehead v. New York ex rel. Tipaldo", it was widely perceived that he only agreed to uphold the constitutionality of minimum wage as a result of the pressure that was put on the Supreme Court by the court-packing plan. However, Hughes and Roberts acknowledged that the Chief Justice had already convinced Roberts to change his method of voting months before Roosevelt announced his court-packing plan and that the effort he put into defeating the plan played only a small significance in determining how the court's majority made their decisions in future cases pertaining to New Deal legislation.
Following the overwhelming support that voters showed for the New Deal through Roosevelt's overwhelming re-election in November 1936, Hughes was not able to persuade Roberts to base his votes on political maneuvering and to side with him in future cases regarding New Deal-related policies. Roberts had voted to grant "certiorari" to hear the "Parrish" case before the election of 1936. Oral arguments occurred on December 16 and 17, 1936, with counsel for Parrish specifically asking the court to reconsider its decision in "Adkins v. Children's Hospital", which had been the basis for striking down a New York minimum wage law in "Morehead v. New York ex rel. Tipaldo" in the late spring of 1936.
Roberts indicated his desire to overturn "Adkins" immediately after oral arguments ended for the Parrish case on December 17, 1936. The initial conference vote on December 19, 1936 was 4-4; with this even division on the Court, the holding of the Washington Supreme Court, finding the minimum wage statute constitutional, would stand. The eight voting justices anticipated Justice Stone — absent due to illness — would be the fifth vote necessary for a majority opinion affirming the constitutionality of the minimum wage law. As Hughes desired a clear and strong 5-4 affirmation of the Washington Supreme Court's judgment, rather than a 4-4 default affirmation, he convinced the other justices to wait until Stone's return before deciding and announcing the case. In one of his notes from 1936, Hughes wrote that Roosevelt's re-election forced the court to depart from its "fortress in public opinion" and severely weakened its capability to base its rulings on personal or political beliefs.
President Roosevelt announced his court reform bill on February 5, 1937, the day of the first conference vote after Stone's February 1, 1937 return to the bench. Roosevelt later made his justifications for the bill to the public on March 9, 1937 during his ninth Fireside Chat. The Court's opinion in "Parrish" was not published until March 29, 1937, after Roosevelt's radio address. Hughes wrote in his autobiographical notes that Roosevelt's court reform proposal "had not the slightest effect on our court's decision," but due to the delayed announcement of its decision the Court was characterized as retreating under fire.
Although Hughes wrote the opinion invalidating the National Recovery Administration in "Schechter Poultry Corp. v. United States" — though the decision was unanimously upheld by all of the court's Justices — he also wrote the opinions for the Court in "NLRB v. Jones & Laughlin Steel Corp.", "NLRB v. Friedman-Harry Marks Clothing Co." and "West Coast Hotel Co. v. Parrish" which approved some New Deal measures. Hughes supervised the move of the Court from its former quarters at the U.S. Capitol to the newly constructed Supreme Court building.
Hughes wrote 199 majority opinions in his time on the bench, from 1930 to 1941. "His opinions, in the view of one commentator, were concise and admirable, placing Hughes in the pantheon of great justices." His "remarkable intellectual and social gifts...made him a superb leader and administrator. He had a photographic memory that few, if any, of his colleagues could match. Yet he was generous, kind, and forebearing in an institution where egos generally come in only one size: extra large!"
Later life.
For many years, he was a member of the Union League Club of New York and served as its president from 1917 to 1919.
In 1907 Hughes, then the Governor of New York, was elected to honorary membership in the Empire State Society of the Sons of the American Revolution. He was assigned national membership number 18,977.
On August 27, 1948, at the age of 86, Hughes died in what is now the Tiffany Cottage of the Wianno Club in Osterville, Massachusetts. He is interred at Woodlawn Cemetery in The Bronx, New York City.

</doc>
<doc id="7527" url="https://en.wikipedia.org/wiki?curid=7527" title="Concept album">
Concept album

A concept album is a studio album where all musical or lyrical ideas contribute to a single overall theme or unified story. In contrast, typical studio albums consist of a number of unconnected songs (lyrically and otherwise) performed by the artist. It has been argued that concept albums should refer only to albums that bring in themes or story lines from outside of music, given that a collection of love songs or songs from within a certain genre are not usually considered to be a "concept album."
Definition.
There is no clear definition of what constitutes a concept album. Fiona Sturges of "The Independent" stated that the concept album "was originally defined as a long-player where the songs were based on one dramatic idea – but the term is subjective." 
AllMusic writes, "A concept album could be a collection of songs by an individual songwriter or a particular theme -- these are the concept LPs that reigned in the '50s [...] the phrase "concept album" is inextricably tied to the late '60s, when rock & rollers began stretching the limits of their art form." 
History.
1940s–50s: origins.
"The Independent" regards Woody Guthrie's "Dust Bowl Ballads" (1940) as perhaps one of the first concept albums, consisting exclusively of semi-autobiographical songs about the hardships of American migrant labourers during the 1930s. In the early 1950s, before the mainstream breakthrough of rock and roll, concept albums were mostly prevalent in jazz music.
Singer Frank Sinatra recorded several concept albums prior to the 1960s rock era, including "In the Wee Small Hours" (1955; songs about loneliness, heartache, introspection, and nightlife), "Where Are You?" (1957; songs about heartache), "Frank Sinatra Sings for Only the Lonely" (1958; songs about loneliness and heartache), "Come Fly with Me" (1958; songs about world travel), and "No One Cares" (1959; songs about loneliness and depression). Often credited as the innovator or originator of the concept album, Sinatra's "The Voice of Frank Sinatra" (1946), "Songs for Young Lovers" (1954), and "In the Wee Small Hours" (1955) are generally considered among the first, if not the first, concept albums.
1960s: early rock concept albums.
In 1966, several albums were deemed as concept albums by their thematically-linked songs, and became inspiration for other artists to follow. The author Carys Wyn Jones observes that the Beach Boys' "Pet Sounds" (1966), the Beatles' "Revolver" (1966) and "Sgt. Pepper's Lonely Hearts Club Band" (1967), and the Who's "Tommy" (1969) are variously cited as "the first concept album", usually for their "uniform excellence rather than some lyrical theme or underlying musical motif". According to music critic Tim Riley, "Strictly speaking, the Mothers of Invention's "Freak Out!" has claims as the first 'concept album', but "Sgt. Pepper" was the record that made that idea convincing to most ears."
"Popmatters" Sarah Zupko notes that while the Who's "Tommy" is "popularly thought of as the first rock opera, an extra-long concept album with characters, a consistent storyline, and a slight bit of pomposity", it is preceded by the shorter concept albums "Ogden's Nut Gone Flake" (Small Faces, 1968) and "S.F. Sorrow" (The Pretty Things, 1968).
1960s–70s: progressive rock.
Author Bill Martin relates albums of the 1960s described as "concept albums" to progressive rock:
According to author Edward Macan, concept albums as a recurrent theme in progressive rock was directly inspired by the counterculture associated with "the proto-progressive bands of the 1960s", observing: "the consistent use of lengthy forms such as the programmatic song cycle of the concept album and the multimovement suite underscores the hippies' new, drug-induced conception of time."
1980s–present: decline and return to popularity.
With the emergence of MTV as a music video network which valued single over album, concept albums became less dominant in the 1980s. Some artists, however, still released concept albums and experienced success in the '90s and 2000s. Dorian Lynskey, writing for "GQ", noted a resurgence of concept albums in the 2010s due to streaming: "This is happening not in spite of the rise of streaming and playlists, but because of it. Threatened with redundancy in the digital era, albums have fought back by becoming more album-like."

</doc>
<doc id="7530" url="https://en.wikipedia.org/wiki?curid=7530" title="Cro-hook">
Cro-hook

The cro-hook, is a special double-ended crochet hook used to make double-sided crochet. 
It employs the use of a long double-ended hook, which permits the maker to work stitches on or off from either end. Because the hook has two ends, two alternating colors of thread can be used simultaneously and freely interchanged, working loops over the hook. Crafts using a double-ended hook are commercially marketed as Cro-hook and Crochenit. Cro-hook is a variation of Tunisian crochet and also shows similarities with the Afghan stitch used to make Afghan scarves, but the fabric is typically softer with greater elasticity.

</doc>
<doc id="7531" url="https://en.wikipedia.org/wiki?curid=7531" title="Clavichord">
Clavichord

The clavichord is a European stringed keyboard instrument known from the late Medieval, through the Renaissance, Baroque and Classical eras. Historically, it was mostly used as a practice instrument and as an aid to composition, not being loud enough for larger performances (a problem that was solved when the Clavinet was invented in the mid-20th century). The clavichord produces sound by striking brass or iron strings with small metal blades called tangents. Vibrations are transmitted through the bridge(s) to the soundboard. The name is derived from the Latin word "clavis", meaning "key" (associated with more common "clavus", meaning "nail, rod, etc.") and "chorda" (from Greek χορδή) meaning "string, especially of a musical instrument".
History and use.
The clavichord was invented in the early fourteenth century. In 1504, the German poem "" mentions the terms clavicimbalum (a term used mainly for the harpsichord) and clavichordium, designating them as the best instruments to accompany melodies.
One of the earliest references to the clavichord in England occurs in the privy-purse expenses of Elizabeth of York, queen of Henry VII, in an entry dated August 1502:
Item. The same day, Hugh Denys for money by him delivered to a stranger that gave the queen a payre of clavycordes. In crowns form his reward iiii libres.
The clavichord was very popular from the 16th century to the 18th century, but mainly flourished in German-speaking lands, Scandinavia, and the Iberian Peninsula in the latter part of this period. It had fallen out of use by 1850. In the late 1890s, Arnold Dolmetsch revived clavichord construction and Violet Gordon-Woodhouse, among others, helped to popularize the instrument. Although most of the instruments built before the 1730s were small (four octaves, four feet long), the latest instruments were built up to seven feet long with a six octave range.
Today clavichords are played primarily by Renaissance, Baroque, and Classical music enthusiasts. They attract many interested buyers, and are manufactured worldwide. There are now numerous clavichord societies around the world, and some 400 recordings of the instrument have been made in the past 70 years. Leading modern exponents of the instrument have included Derek Adlam, Christopher Hogwood, Richard Troeger,Thurston Dart, Wim Winters and Miklos Spányi.
Modern music.
The clavichord has also gained attention in other genres of music, in the form of the Clavinet, which is essentially an electric clavichord that uses a magnetic pickup to produce a signal for amplification. Stevie Wonder uses a Clavinet in many of his songs, such as "Superstition" and "Higher Ground". A Clavinet played through an instrument amplifier with guitar effect pedals is often associated with funky, disco-infused 1970s rock.
Guy Sigsworth has played clavichord in a modern setting with Björk, notably on the studio recording of "All Is Full of Love". Björk also made extensive use of and even played the instrument herself on the song "My Juvenile" of her 2007 album "Volta".
Tori Amos uses the instrument on "Little Amsterdam" from the album "Boys for Pele" and on the song "Smokey Joe" from her 2007 album "American Doll Posse". Amos also featured her use of the Clavinet on her 2004 recording "Not David Bowie", released as part of her 2006 box set, "".
In 1976 Oscar Peterson played (with Joe Pass on acoustic guitar) songs from "Porgy And Bess" on the clavichord. Keith Jarrett also recorded an album entitled "Book of Ways" (1987) in which he plays a series of clavichord improvisations. The Beatles' "For No One" (1966) features Paul McCartney playing the clavichord. Rick Wakeman plays the Clavinet in the track "The Battle" from the album "Journey to the Centre of the Earth".
Structure and action.
In the clavichord, strings run transversely from the hitchpin rail at the left-hand end to tuning pegs on the right. Towards the right end they pass over a curved wooden bridge. The action is simple, with the keys being levers with a small brass tangent, a small piece of metal similar in shape and size to the head of a flat-bladed screwdriver, at the far end. The strings, which are usually of brass, or else a combination of brass and iron, are usually arranged in pairs, like a lute or mandolin. When the key is pressed, the tangent strikes the strings above, causing them to sound in a similar fashion to the "hammering" technique on a guitar. Unlike in a piano action, the tangent does not rebound from the string; rather, it stays in contact with the string as long as the key is held, acting as both the nut and as the initiator of sound. The volume of the note can be changed by striking harder or softer, and the pitch can also be affected by varying the force of the tangent against the string (known as "Bebung"). When the key is released, the tangent loses contact with the string and the vibration of the string is silenced by strips of damping cloth.
The action of the clavichord is unique among all keyboard instruments in that one part of the action simultaneously initiates the sound vibration while at the same time defining the endpoint of the vibrating string, and thus its pitch. Because of this intimate contact between the player's hand and the production of sound, the clavichord has been referred to as the most intimate of keyboard instruments. Despite its many (serious) limitations, including extremely low volume, it has considerable expressive power, the player being able to control attack, duration, volume, and even provide certain subtle effects of swelling of tone and a type of vibrato unique to the clavichord.
Fretting.
Since the string vibrates from the bridge only as far as the tangent, multiple keys with multiple tangents can be assigned to the same string. This is called "fretting". Early clavichords frequently had many notes played on each string, even going so far as the keyed monochord — an instrument with only one string—though most clavichords were triple- or double-fretted. Since only one note can be played at a time on each string, the fretting pattern is generally chosen so that notes rarely heard together (such as C and C) share a string pair. The advantages of this system compared with unfretted instruments (see below) include relative ease of tuning (with around half as many strings to keep in tune), greater volume (though still not really enough for use in chamber music), and a clearer, more direct sound. Among the disadvantages: temperament could not be re-set without bending the tangents; and playing required a further refinement of touch, since notes sharing a single string played in quick succession had to be slightly separated to avoid a disagreeable deadening of the sound, potentially disturbing a legato line.
Some clavichords have been built with a single pair of strings for each note. The first known reference to one was by Johann Speth in 1693 and the earliest such extant signed and dated clavichord was built in 1716 by Johann Michael Heinitz. Such instruments are referred to as "unfretted" whereas instruments using the same strings for several notes are called "fretted". Among the advantages to unfretted instruments are flexibility in tuning (the temperament can be easily altered) and the ability to play any music exactly as written without concern for "bad" notes. Disadvantages include a smaller volume, even though many or most unfretted instruments tend to be significantly larger than fretted instruments; and "many" more strings to keep in tune. Unfretted instruments tend to have a sweeter, less incisive tone due to the greater load on the bridge resulting from the greater number of strings, though the large, late (early 19th century) Swedish clavichords tend to be the loudest of any of the historic clavichords.
Pedal clavichord.
While clavichords were typically single manual instruments, they could be stacked, one clavichord on top of another, to provide multiple keyboards. With the addition of a pedal clavichord, which included a pedal keyboard for the lower notes, a clavichord could be used to practice improvising and, only when printed music became easily available, to learn organ repertoire. Most often, the addition of a pedal keyboard only involved connecting the keys of the pedalboard to the lower notes on the manual clavichord using string so the lower notes on the manual instrument could be operated by the feet. In the era of pipe organs, which used man-powered bellows that required several people to operate, and of churches being heated during church services if at all, organists used pedal harpsichords and pedal clavichords as practice instruments (see also: pedal piano). There is speculation that some works written for organ may have been intended for pedal clavichord. An interesting case is made by that Bach's "Eight Little Preludes and Fugues", now thought spurious, may actually be authentic. The keyboard writing seems unsuited to organ, but Speerstra argues that they are idiomatic on the pedal clavichord. As Speerstra and also note, the compass of the keyboard parts of Bach's six organ trio sonatas BWV 525–530 rarely go below the tenor C, so they could have been played on a single manual pedal clavichord, by moving the left hand down an octave, a customary practice in the 18th century.
Repertoire.
Much of the musical repertoire written for harpsichord and organ from the period circa 1400–1800 can be played on the clavichord; however, it does not have enough (unamplified) volume to participate in chamber music, with the possible exception of providing accompaniment to a soft baroque flute, recorder, or single singer. J. S. Bach's son Carl Philipp Emanuel Bach was a great proponent of the instrument, and most of his German contemporaries regarded it as a central keyboard instrument, for performing, teaching, composing and practicing. The fretting of a clavichord provides new problems for some repertoire, but scholarship suggests that these problems are not insurmountable in Bach's Well-Tempered Clavier (). Among recent clavichord recordings, those by Christopher Hogwood ("The Secret Bach", "The Secret Handel", and "The Secret Mozart"), break new ground. In his liner notes, Hogwood pointed out that these composers would typically have played the clavichord in the privacy of their homes. The English composer Herbert Howells (1892–1983) wrote two significant collections of pieces for clavichord (Lambert's Clavichord & Howells' Clavichord).
References.
Notes
Sources

</doc>
<doc id="7534" url="https://en.wikipedia.org/wiki?curid=7534" title="Centripetal force">
Centripetal force

A centripetal force (from Latin "centrum" "center" and "petere" "to seek") is a force that makes a body follow a curved path. Its direction is always orthogonal to the motion of the body and towards the fixed point of the instantaneous center of curvature of the path. Isaac Newton described it as "a force by which bodies are drawn or impelled, or in any way tend, towards a point as to a centre". In Newtonian mechanics, gravity provides the centripetal force responsible for astronomical orbits.
One common example involving centripetal force is the case in which a body moves with uniform speed along a circular path. The centripetal force is directed at right angles to the motion and also along the radius towards the centre of the circular path. The mathematical description was derived in 1659 by the Dutch physicist Christiaan Huygens.
Formula.
The magnitude of the centripetal force on an object of mass "m" moving at tangential speed "v" along a path with radius of curvature "r" is:
where formula_2 is the centripetal acceleration.
The direction of the force is toward the center of the circle in which the object is moving, or the osculating circle (the circle that best fits the local path of the object, if the path is not circular).
The speed in the formula is squared, so twice the speed needs four times the force. The inverse relationship with the radius of curvature shows that half the radial distance requires twice the force. This force is also sometimes written in terms of the angular velocity "ω" of the object about the center of the circle, related to the tangential velocity by the formula
so that
Expressed using the orbital period "T" for one revolution of the circle,
the equation becomes
In particle accelerators, velocity can be very high (close to the speed of light in vacuum) so the same rest mass now exerts greater inertia (relativistic mass) thereby requiring greater force for the same centripetal acceleration, so the equation becomes:
where
is called the Lorentz factor.
Sources of centripetal force.
In the case of an object that is swinging around on the end of a rope in a horizontal plane, the centripetal force on the object is supplied by the tension of the rope. The rope example is an example involving a 'pull' force. The centripetal force can also be supplied as a 'push' force, such as in the case where the normal reaction of a wall supplies the centripetal force for a wall of death rider.
Newton's idea of a centripetal force corresponds to what is nowadays referred to as a central force. When a satellite is in orbit around a planet, gravity is considered to be a centripetal force even though in the case of eccentric orbits, the gravitational force is directed towards the focus, and not towards the instantaneous center of curvature.
Another example of centripetal force arises in the helix that is traced out when a charged particle moves in a uniform magnetic field in the absence of other external forces. In this case, the magnetic force is the centripetal force that acts towards the helix axis.
Analysis of several cases.
Below are three examples of increasing complexity, with derivations of the formulas governing velocity and acceleration.
Uniform circular motion.
Uniform circular motion refers to the case of constant rate of rotation. Here are two approaches to describing this case.
Calculus derivation.
In two dimensions, the position vector formula_9, which has magnitude (length) formula_10 and directed at an angle formula_11 above the x-axis, can be expressed in Cartesian coordinates using the unit vectors formula_12 and formula_13:
Assume uniform circular motion, which requires three things.
Now find the velocity formula_19 and acceleration formula_20 of the motion by taking derivatives of position with respect to time.
Notice that the term in parenthesis is the original expression of formula_9 in Cartesian coordinates. Consequently,
negative shows that the acceleration is pointed towards the center of the circle (opposite the radius), hence it is called "centripetal" (i.e. "center-seeking"). While objects naturally follow a straight path (due to inertia), this centripetal acceleration describes the circular motion path caused by a centripetal force.
Derivation using vectors.
The image at right shows the vector relationships for uniform circular motion. The rotation itself is represented by the angular velocity vector Ω, which is normal to the plane of the orbit (using the right-hand rule) and has magnitude given by:
with "θ" the angular position at time "t". In this subsection, d"θ"/d"t" is assumed constant, independent of time. The distance traveled dℓ of the particle in time d"t" along the circular path is
which, by properties of the vector cross product, has magnitude "r"d"θ" and is in the direction tangent to the circular path.
Consequently,
Differentiating with respect to time,
Lagrange's formula states:
Applying Lagrange's formula with the observation that Ω • r("t") = 0 at all times,
In words, the acceleration is pointing directly opposite to the radial displacement r at all times, and has a magnitude:
where vertical bars |...| denote the vector magnitude, which in the case of r("t") is simply the radius "r" of the path. This result agrees with the previous section, though the notation is slightly different.
When the rate of rotation is made constant in the analysis of nonuniform circular motion, that analysis agrees with this one.
A merit of the vector approach is that it is manifestly independent of any coordinate system.
Example: The banked turn.
The upper panel in the image at right shows a ball in circular motion on a banked curve. The curve is banked at an angle "θ" from the horizontal, and the surface of the road is considered to be slippery. The objective is to find what angle the bank must have so the ball does not slide off the road. Intuition tells us that, on a flat curve with no banking at all, the ball will simply slide off the road; while with a very steep banking, the ball will slide to the center unless it travels the curve rapidly.
Apart from any acceleration that might occur in the direction of the path, the lower panel of the image above indicates the forces on the ball. There are "two" forces; one is the force of gravity vertically downward through the center of mass of the ball "m"g, where "m" is the mass of the ball and g is the gravitational acceleration; the second is the upward normal force exerted by the road perpendicular to the road surface "m"an. The centripetal force demanded by the curved motion is also shown above. This centripetal force is not a third force applied to the ball, but rather must be provided by the net force on the ball resulting from vector addition of the normal force and the force of gravity. The resultant or net force on the ball found by vector addition of the normal force exerted by the road and vertical force due to gravity must equal the centripetal force dictated by the need to travel a circular path. The curved motion is maintained so long as this net force provides the centripetal force requisite to the motion.
The horizontal net force on the ball is the horizontal component of the force from the road, which has magnitude |Fh| = "m"|an|sin"θ". The vertical component of the force from the road must counteract the gravitational force: |Fv| = "m"|an|cos"θ" = "m"|g|, which implies |an|=|g| / cos"θ". Substituting into the above formula for |Fh| yields a horizontal force to be:
On the other hand, at velocity |v| on a circular path of radius "r", kinematics says that the force needed to turn the ball continuously into the turn is the radially inward centripetal force Fc of magnitude:
Consequently, the ball is in a stable path when the angle of the road is set to satisfy the condition:
or,
As the angle of bank "θ" approaches 90°, the tangent function approaches infinity, allowing larger values for |v|2/"r". In words, this equation states that for faster speeds (bigger |v|) the road must be banked more steeply (a larger value for "θ"), and for sharper turns (smaller "r") the road also must be banked more steeply, which accords with intuition. When the angle "θ" does not satisfy the above condition, the horizontal component of force exerted by the road does not provide the correct centripetal force, and an additional frictional force tangential to the road surface is called upon to provide the difference. If friction cannot do this (that is, the coefficient of friction is exceeded), the ball slides to a different radius where the balance can be realized.
These ideas apply to air flight as well. See the FAA pilot's manual.
Nonuniform circular motion.
As a generalization of the uniform circular motion case, suppose the angular rate of rotation is not constant. The acceleration now has a tangential component, as shown the image at right. This case is used to demonstrate a derivation strategy based on a polar coordinate system.
Let r("t") be a vector that describes the position of a point mass as a function of time. Since we are assuming circular motion, let r("t") = "R"·ur, where "R" is a constant (the radius of the circle) and ur is the unit vector pointing from the origin to the point mass. The direction of ur is described by "θ", the angle between the x-axis and the unit vector, measured counterclockwise from the x-axis. The other unit vector for polar coordinates, uθ is perpendicular to ur and points in the direction of increasing "θ". These polar unit vectors can be expressed in terms of Cartesian unit vectors in the "x" and "y" directions, denoted i and j respectively:
and
One can differentiate to find velocity:
where "ω" is the angular velocity d"θ"/d"t".
This result for the velocity matches expectations that the velocity should be directed tangentially to the circle, and that the magnitude of the velocity should be "rω". Differentiating again, and noting that
we find that the acceleration, a is:
Thus, the radial and tangential components of the acceleration are:
where |v| = "r" ω is the magnitude of the velocity (the speed).
These equations express mathematically that, in the case of an object that moves along a circular path with a changing speed, the acceleration of the body may be decomposed into a perpendicular component that changes the direction of motion (the centripetal acceleration), and a parallel, or tangential component, that changes the speed.
General planar motion.
Polar coordinates.
The above results can be derived perhaps more simply in polar coordinates, and at the same time extended to general motion within a plane, as shown next. Polar coordinates in the plane employ a radial unit vector uρ and an angular unit vector uθ, as shown above. A particle at position r is described by:
where the notation "ρ" is used to describe the distance of the path from the origin instead of "R" to emphasize that this distance is not fixed, but varies with time. The unit vector uρ travels with the particle and always points in the same direction as r("t"). Unit vector uθ also travels with the particle and stays orthogonal to uρ. Thus, uρ and uθ form a local Cartesian coordinate system attached to the particle, and tied to the path traveled by the particle. By moving the unit vectors so their tails coincide, as seen in the circle at the left of the image above, it is seen that uρ and uθ form a right-angled pair with tips on the unit circle that trace back and forth on the perimeter of this circle with the same angle "θ"("t") as r("t").
When the particle moves, its velocity is
To evaluate the velocity, the derivative of the unit vector uρ is needed. Because uρ is a unit vector, its magnitude is fixed, and it can change only in direction, that is, its change duρ has a component only perpendicular to uρ. When the trajectory r("t") rotates an amount d"θ", uρ, which points in the same direction as r("t"), also rotates by d"θ". See image above. Therefore, the change in uρ is
or
In a similar fashion, the rate of change of uθ is found. As with uρ, uθ is a unit vector and can only rotate without changing size. To remain orthogonal to uρ while the trajectory r("t") rotates an amount d"θ", uθ, which is orthogonal to r("t"), also rotates by d"θ". See image above. Therefore, the change duθ is orthogonal to uθ and proportional to d"θ" (see image above):
The image above shows the sign to be negative: to maintain orthogonality, if duρ is positive with d"θ", then duθ must decrease.
Substituting the derivative of uρ into the expression for velocity:
To obtain the acceleration, another time differentiation is done:
Substituting the derivatives of uρ and uθ, the acceleration of the particle is:
As a particular example, if the particle moves in a circle of constant radius "R", then d"ρ"/d"t" = 0, v = vθ, and:
where formula_58
These results agree with those above for nonuniform circular motion. See also the article on non-uniform circular motion. If this acceleration is multiplied by the particle mass, the leading term is the centripetal force and the negative of the second term related to angular acceleration is sometimes called the Euler force.
For trajectories other than circular motion, for example, the more general trajectory envisioned in the image above, the instantaneous center of rotation and radius of curvature of the trajectory are related only indirectly to the coordinate system defined by uρ and uθ and to the length |r("t")| = "ρ". Consequently, in the general case, it is not straightforward to disentangle the centripetal and Euler terms from the above general acceleration equation.
Local coordinates.
Local coordinates mean a set of coordinates that travel with the particle, and have orientation determined by the path of the particle. Unit vectors are formed as shown in the image at right, both tangential and normal to the path. This coordinate system sometimes is referred to as "intrinsic" or "path coordinates" or "nt-coordinates", for "normal-tangential", referring to these unit vectors. These coordinates are a very special example of a more general concept of local coordinates from the theory of differential forms.
Distance along the path of the particle is the arc length "s", considered to be a known function of time.
A center of curvature is defined at each position "s" located a distance "ρ" (the radius of curvature) from the curve on a line along the normal un ("s"). The required distance "ρ"("s") at arc length "s" is defined in terms of the rate of rotation of the tangent to the curve, which in turn is determined by the path itself. If the orientation of the tangent relative to some starting position is "θ"("s"), then "ρ"("s") is defined by the derivative d"θ"/d"s":
The radius of curvature usually is taken as positive (that is, as an absolute value), while the "curvature" "κ" is a signed quantity.
A geometric approach to finding the center of curvature and the radius of curvature uses a limiting process leading to the osculating circle. See image above.
Using these coordinates, the motion along the path is viewed as a succession of circular paths of ever-changing center, and at each position "s" constitutes non-uniform circular motion at that position with radius "ρ". The local value of the angular rate of rotation then is given by:
with the local speed "v" given by:
As for the other examples above, because unit vectors cannot change magnitude, their rate of change is always perpendicular to their direction (see the left-hand insert in the image above):
Consequently, the velocity and acceleration are:
and using the chain-rule of differentiation:
In this local coordinate system, the acceleration resembles the expression for nonuniform circular motion with the local radius "ρ"("s"), and the centripetal acceleration is identified as the second term.
Extending this approach to three dimensional space curves leads to the Frenet–Serret formulas.
Alternative approach.
Looking at the image above, one might wonder whether adequate account has been taken of the difference in curvature between "ρ"("s") and "ρ"("s" + d"s") in computing the arc length as d"s" = "ρ"("s")d"θ". Reassurance on this point can be found using a more formal approach outlined below. This approach also makes connection with the article on curvature.
To introduce the unit vectors of the local coordinate system, one approach is to begin in Cartesian coordinates and describe the local coordinates in terms of these Cartesian coordinates. In terms of arc length "s", let the path be described as:
Then an incremental displacement along the path d"s" is described by:
where primes are introduced to denote derivatives with respect to "s". The magnitude of this displacement is d"s", showing that:
This displacement is necessarily a tangent to the curve at "s", showing that the unit vector tangent to the curve is:
while the outward unit vector normal to the curve is
Orthogonality can be verified by showing that the vector dot product is zero. The unit magnitude of these vectors is a consequence of Eq. 1. Using the tangent vector, the angle "θ" of the tangent to the curve is given by:
The radius of curvature is introduced completely formally (without need for geometric interpretation) as:
The derivative of "θ" can be found from that for sin"θ":
Now:
in which the denominator is unity. With this formula for the derivative of the sine, the radius of curvature becomes:
where the equivalence of the forms stems from differentiation of Eq. 1:
With these results, the acceleration can be found:
as can be verified by taking the dot product with the unit vectors ut("s") and un("s"). This result for acceleration is the same as that for circular motion based on the radius "ρ". Using this coordinate system in the inertial frame, it is easy to identify the force normal to the trajectory as the centripetal force and that parallel to the trajectory as the tangential force. From a qualitative standpoint, the path can be approximated by an arc of a circle for a limited time, and for the limited time a particular radius of curvature applies, the centrifugal and Euler forces can be analyzed on the basis of circular motion with that radius.
This result for acceleration agrees with that found earlier. However, in this approach, the question of the change in radius of curvature with "s" is handled completely formally, consistent with a geometric interpretation, but not relying upon it, thereby avoiding any questions the image above might suggest about neglecting the variation in "ρ".
Example: circular motion.
To illustrate the above formulas, let "x", "y" be given as:
Then:
which can be recognized as a circular path around the origin with radius "α". The position "s" = 0 corresponds to ["α", 0], or 3 o'clock. To use the above formalism, the derivatives are needed:
With these results, one can verify that:
The unit vectors can also be found:
which serve to show that "s" = 0 is located at position ["ρ", 0] and "s" = "ρ"π/2 at "ρ", which agrees with the original expressions for "x" and "y". In other words, "s" is measured counterclockwise around the circle from 3 o'clock. Also, the derivatives of these vectors can be found:
To obtain velocity and acceleration, a time-dependence for "s" is necessary. For counterclockwise motion at variable speed "v"("t"):
where "v"("t") is the speed and "t" is time, and "s"("t" = 0) = 0. Then:
where it already is established that α = ρ. This acceleration is the standard result for non-uniform circular motion.

</doc>
<doc id="7535" url="https://en.wikipedia.org/wiki?curid=7535" title="Commodore">
Commodore

Commodore generally refers to Commodore (rank), a naval rank. It may also refer to:

</doc>
<doc id="7536" url="https://en.wikipedia.org/wiki?curid=7536" title="Conditioning">
Conditioning

Conditioning may refer to:

</doc>
<doc id="7538" url="https://en.wikipedia.org/wiki?curid=7538" title="Checksum">
Checksum

A checksum or hash sum is a small-size datum from a block of digital data for the purpose of detecting errors which may have been introduced during its transmission or storage. It is usually applied to an installation file after it is received from the download server. By themselves checksums are often used to verify data integrity, but should not be relied upon to also verify data authenticity. 
The actual procedure which yields the checksum, given a data input is called a checksum function or checksum algorithm. Depending on its design goals, a good checksum algorithm will usually output a significantly different value, even for small changes made to the input. 
This is especially true of cryptographic hash functions, which may be used to detect many data corruption errors and verify overall data integrity; if the computed checksum for the current data input matches the stored value of a previously computed checksum, there is a very high probability the data has not been accidentally altered or corrupted.
Checksum functions are related to hash functions, fingerprints, randomization functions, and cryptographic hash functions. However, each of those concepts has different applications and therefore different design goals. For instance a function returning the start of a string can provide a hash appropriate for some applications but will never be a suitable checksum. Checksums are used as cryptographic primitives in larger authentication algorithms. For cryptographic systems with these two specific design goals, see HMAC.
Check digits and parity bits are special cases of checksums, appropriate for small blocks of data (such as Social Security numbers, bank account numbers, computer words, single bytes, etc.). Some error-correcting codes are based on special checksums which not only detect common errors but also allow the original data to be recovered in certain cases.
Checksum algorithms.
Parity byte or parity word.
The simplest checksum algorithm is the so-called longitudinal parity check, which breaks the data into "words" with a fixed number "n" of bits, and then computes the exclusive or (XOR) of all those words. The result is appended to the message as an extra word. To check the integrity of a message, the receiver computes the exclusive or of all its words, including the checksum; if the result is not a word with "n" zeros, the receiver knows a transmission error occurred.
With this checksum, any transmission error which flips a single bit of the message, or an odd number of bits, will be detected as an incorrect checksum. However, an error which affects two bits will not be detected if those bits lie at the same position in two distinct words. Also swapping of two or more words will not be detected. If the affected bits are independently chosen at random, the probability of a two-bit error being undetected is 1/"n".
Modular sum.
A variant of the previous algorithm is to add all the "words" as unsigned binary numbers, discarding any overflow bits, and append the two's complement of the total as the checksum. To validate a message, the receiver adds all the words in the same manner, including the checksum; if the result is not a word full of zeros, an error must have occurred. This variant too detects any single-bit error, but the promodular sum is used in SAE J1708.
Position-dependent checksums.
The simple checksums described above fail to detect some common errors which affect many bits at once, such as changing the order of data words, or inserting or deleting words with all bits set to zero. The checksum algorithms most used in practice, such as Fletcher's checksum, Adler-32, and cyclic redundancy checks (CRCs), address these weaknesses by considering not only the value of each word but also its position in the sequence. This feature generally increases the cost of computing the checksum.
General considerations.
A single-bit transmission error then corresponds to a displacement from a valid corner (the correct message and checksum) to one of the "m" adjacent corners. An error which affects "k" bits moves the message to a corner which is "k" steps removed from its correct corner. The goal of a good checksum algorithm is to spread the valid corners as far from each other as possible, so as to increase the likelihood "typical" transmission errors will end up in an invalid corner.
See also.
General topic
Error correction
Hash functions
Related concepts

</doc>
<doc id="7541" url="https://en.wikipedia.org/wiki?curid=7541" title="City University of New York">
City University of New York

The City University of New York (CUNY; pron.: ) is the public university system of New York City, and the largest urban university in the United States. CUNY and SUNY (the State University of New York) are separate and independent university systems, although both are public institutions that receive funding from New York State. CUNY, however, is additionally funded by the City of New York.
Enrollment and demographics.
CUNY is the third-largest university system in the United States, in terms of enrollment, behind the State University of New York (SUNY), and the California State University system. More than 270,000-degree-credit students and 273,000 continuing and professional education students are enrolled at campuses located in all five New York City boroughs.
The university has one of the most diverse student bodies in the United States, with students hailing from 208 countries. The black, white and Hispanic undergraduate populations each comprise more than a quarter of the student body, and Asian undergraduates make up 18 percent. Fifty-eight percent are female, and 28 percent are 25 or older.
Component institutions.
"The following table is 'sortable'; click on a column heading to re-sort the table by values of that column."
History.
Founding.
CUNY was created in 1961, by New York State legislation, signed into law by Governor Nelson Rockefeller. The legislation
integrated existing institutions and a new graduate school into a coordinated system of higher education for the city, under the control of the "Board of Higher Education of the City of New York", which had been created by New York State legislation in 1926. By 1979, the Board of Higher Education had become the "Board of Trustees of the CUNY".
The institutions that were merged in order to create CUNY were:
Accessible education.
CUNY has served a diverse student body, especially those excluded from or unable to afford private universities. Its four-year colleges offered a high quality, tuition-free education to the poor, the working class and the immigrants of New York City who met the grade requirements for matriculated status. During the post-World War I era, when some Ivy League universities, such as Yale University, discriminated against Jews, many Jewish academics and intellectuals studied and taught at CUNY. The City College of New York developed a reputation of being "the Harvard of the proletariat."
As the city's population—and public college enrollment—grew during the early 20th century and the city struggled for resources, the municipal colleges slowly began adopting selective tuition, also known as instructional fees, for a handful of courses and programs. During the Great Depression, with funding for the public colleges severely constrained, limits were imposed on the size of the colleges' free Day Session, and tuition was imposed upon students deemed "competent" but not academically qualified for the day program. Most of these "limited matriculation" students enrolled in the Evening Session, and paid tuition.
Demand in the United States for higher education rapidly grew after World War II, and during the mid-1940s a movement began to create community colleges to provide accessible education and training. In New York City, however, the community-college movement was constrained by many factors including "financial problems, narrow perceptions of responsibility, organizational weaknesses, adverse political factors, and another competing priorities."
Community colleges would have drawn from the same city coffers that were funding the senior colleges, and city higher education officials were of the view that the state should finance them. It wasn't until 1955, under a shared-funding arrangement with New York State, that New York City established its first community college, on Staten Island. Unlike the day college students attending the city's public baccalaureate colleges for free, the community college students had to pay tuition fees under the state-city funding formula. Community college students paid tuition fees for approximately 10 years.
Over time, tuition fees for limited-matriculated students became an important source of system revenues. In fall 1957, for example, nearly 36,000 attended Hunter, Brooklyn, Queens and City Colleges for free, but another 24,000 paid tuition fees of up to $300 a year – the equivalent of $2,413 in 2011. Undergraduate tuition and other student fees in 1957 comprised 17 percent of the colleges' $46.8 million in revenues, about $7.74 million — a figure equivalent to $62.4 million in 2011 buying power.
Three community colleges had been established by early 1961, when the city's public colleges were codified by the state as an single university with a chancellor at the helm and an infusion of state funds. But the city's slowness in creating the community colleges as demand for college seats was intensifying, had resulted in mounting frustration, particularly on the part of minorities, that college opportunities were not available to them.
In 1964, as the city's Board of Higher Education moved to take full responsibility for the community colleges, city officials extended the senior colleges' free tuition policy to them, a change that was included by Mayor Robert Wagner in his budget plans and took effect with the 1964–65 academic year.
In 1969, a group of Black and Puerto Rican students occupied City College demanding the racial integration of CUNY, which at the time had an overwhelmingly white student body.
Student protests.
Students at some campuses became increasingly frustrated with the university's and Board of Higher Education's handling of university administration. At Baruch College in 1967, over a thousand students protested the plan to make the college an upper-division school limited to junior, senior, and graduate students. At Brooklyn College in 1968, students attempted a sit-in to demand the admission of more black and Puerto Rican students and additional black studies curriculum. Students at Hunter College also demanded a Black studies program. Members of the SEEK program, which provided academic support for underprepared and underprivileged students, staged a building takeover at Queens College in 1969 to protest the decisions of the program's director, who would later be replaced by a black professor. Puerto Rican students at Bronx Community College filed a report with the New York State Division of Human Rights in 1970, contending that the intellectual level of the college was inferior and discriminatory. Hunter College was crippled for several days by a protest of 2,000 students who had a list of demands focusing on more student representation in college administration. Across CUNY, students boycotted their campuses in 1970 to protest a rise in student fees and other issues, including the proposed (and later implemented) open admissions plan.
Like many college campuses in 1970, CUNY faced a number of protests and demonstrations after the Kent State shootings and Cambodian Campaign. The Administrative Council of the City University of New York sent U.S. President Richard Nixon a telegram in 1970 stating, "No nation can long endure the alienation of the best of its young people." Some colleges, including John Jay College of Criminal Justice, historically the "college for cops," held teach-ins in addition to student and faculty protests.
Open admissions.
In 1969, the Board of Trustees implemented a new admissions policy. The doors to CUNY were opened wide to all those demanding entrance, assuring all high school graduates entrance to the university without having to fulfill traditional requirements such as exams or grades. This policy was known as open admissions and nearly doubled the number of students enrolling in the CUNY system to 35,000 (compared to 20,000 the year before). With greater numbers came more diversity: Black and Hispanic student enrollment increased threefold. Remedial education, to supplement the training of under-prepared students, became a significant part of CUNY's offerings.
Financial crisis of 1976.
In fall 1976, during New York City's fiscal crisis, the free tuition policy was discontinued under pressure from the federal government, the financial community that had a role in rescuing the city from bankruptcy, and New York State, which would take over the funding of CUNY's senior colleges. Tuition, which had been in place in the State University of New York system since 1963, was instituted at all CUNY colleges.
Meanwhile, CUNY students were added to the state's need-based Tuition Assistance Program (TAP), which had been created to help private colleges. Full-time students who met the income eligibility criteria were permitted to receive TAP, ensuring for the first time that financial hardship would deprive no CUNY student of a college education. Within a few years, the federal government would create its own need-based program, known as Pell Grants, providing the neediest students with a tuition-free college education. By 2011, nearly six of ten full- time undergraduates qualified for a tuition-free education at CUNY due in large measure to state, federal and CUNY financial aid programs. CUNY's enrollment dipped after tuition was re-established, and there were further enrollment declines through the 1980s and into the 1990s.
Financial crisis of 1995.
In 1995, CUNY suffered another fiscal crisis when Governor George Pataki proposed a drastic cut in state financing. Faculty cancelled classes and students staged protests. By May, CUNY adopted deep cuts to college budgets and class offerings. By June, in order to save money spent on remedial programs, CUNY adopted a stricter admissions policy for its senior colleges: students deemed unprepared for college would not be admitted, this a departure from the 1970 Open Admissions program. That year's final state budget cut funding by $102 million, which CUNY absorbed by increasing tuition by $750 and offering a retirement incentive plan for faculty.
In 1999, a task force appointed by Mayor Rudolph Giuliani issued a report that described CUNY as "an institution adrift" and called for an improved, more cohesive university structure and management, as well as more consistent academic standards. Following the report, Matthew Goldstein, a mathematician and City College graduate who had led CUNY's Baruch College and briefly, Adelphi University, was appointed chancellor. CUNY ended its policy of open admissions to its four-year colleges, raised its admissions standards its most selective four-year colleges (Baruch, Brooklyn, City, Hunter and Queens), and required new-enrollees who needed remediation, to begin their studies at a CUNY open-admissions community colleges.
2010 onwards.
CUNY's enrollment of degree-credit students reached 220,727 in 2005 and 262,321 in 2010 as the university broadened its academic offerings. The university added more than 2,000 full-time faculty positions, opened new schools and programs, and expanded the university's fundraising efforts to help pay for them. Fundraising increased from $35 million in 2000 to more than $200 million in 2012.
As of Autumn 2013, all CUNY undergraduates are required to take an administration-dictated common core of courses which have been claimed to meet specific "learning outcomes" or standards. Since the courses are accepted University wide, the administration claims it will be easier for students to transfer course credits between CUNY colleges. It also reduced the number of core courses some CUNY colleges had required, to a level below national norms, particularly in the sciences. The program is the target of several lawsuits by students and faculty, and was the subject of a "no confidence" vote by the faculty, who rejected it by an overwhelming 92% margin.
Chancellor Goldstein retired on July 1, 2013, and was replaced on June 1, 2014 by James Milliken, president of the University of Nebraska, and a graduate of University of Nebraska and New York University Law School.
Management structure.
The forerunner of today's City University of New York was governed by the Board of Education of New York City. Members of the Board of Education, chaired by the President of the board, served as "ex officio" trustees. For the next four decades, the board members continued to serve as "ex officio" trustees of the College of the City of New York and the city's other municipal college, the Normal College of the City of New York.
In 1900, the New York State Legislature created separate boards of trustees for the College of the City of New York and the Normal College, which became Hunter College in 1914. In 1926, the Legislature established the Board of Higher Education of the City of New York, which assumed supervision of both municipal colleges.
In 1961, the New York State Legislature established the City University of New York, uniting what had become seven municipal colleges at the time: the City College of New York, Hunter College, Brooklyn College, Queens College, Staten Island Community College, Bronx Community College and Queensborough Community College. In 1979, the CUNY Financing and Governance Act was adopted by the State and the Board of Higher Education became the City University of New York Board of Trustees.
Today, the City University is governed by the Board of Trustees composed of 17 members, ten of whom are appointed by the Governor of New York "with the advice and consent of the senate," and five by the Mayor of New York City "with the advice and consent of the senate." The final two trustees are "ex officio" members. One is the chair of the university's student senate, and the other is non-voting and is the chair of the university's faculty senate. Both the mayoral and gubernatorial appointments to the CUNY Board are required to include at least one resident of each of New York City's five boroughs. Trustees serve seven-year terms, which are renewable for another seven years. The Chancellor is elected by the Board of Trustees, and is the "chief educational and administrative officer" of the City University.
The administrative offices are in mid-town Manhattan.
Public Safety Department.
CUNY has its own public safety force whose duties are to protect and serve all students and faculty members, and enforce all state and city laws at all of CUNY's universities. The force has more than 1000 officers, making it one of the largest public safety forces in New York City.
The Public Safety Department came under heavy criticism, from student groups, after several students protesting tuition increases tried to occupy the lobby of the Baruch College. The occupiers were forcibly removed from the area and several were arrested on November 21, 2011.
City University Television (CUNY TV).
CUNY also has a broadcast TV service, CUNY TV (channel 75 on Time Warner cable, digital HD broadcast channel 25.3), which airs telecourses, classic and foreign films, magazine shows and panel discussions in foreign languages.
City University Film Festival (CUFF).
CUFF is CUNY's official film festival. The festival was founded in 2009 by Hunter College student Daniel Cowen.
Notable Alumni.
CUNY graduates include 13 Nobel laureates, a Fields Medalist, a U.S. Secretary of State, a Supreme Court Justice, several New York City mayors, members of Congress, state legislators, scientists and artists.

</doc>
<doc id="7543" url="https://en.wikipedia.org/wiki?curid=7543" title="Computational complexity theory">
Computational complexity theory

Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.
A problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying the amount of resources needed to solve them, such as time and storage. Other complexity measures are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do.
Closely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, it tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes computational complexity from computability theory: the latter theory asks what kind of problems can, in principle, be solved algorithmically.
Computational problems.
Problem instances.
A computational problem can be viewed as an infinite collection of "instances" together with a "solution" for every instance. The input string for a computational problem is referred to as a problem instance, and should not be confused with the problem itself. In computational complexity theory, a problem refers to the abstract question to be solved. In contrast, an instance of this problem is a rather concrete utterance, which can serve as the input for a decision problem. For example, consider the problem of primality testing. The instance is a number (e.g. 15) and the solution is "yes" if the number is prime and "no" otherwise (in this case "no"). Stated another way, the "instance" is a particular input to the problem, and the "solution" is the output corresponding to the given input.
To further highlight the difference between a problem and an instance, consider the following instance of the decision version of the traveling salesman problem: Is there a route of at most 2000 kilometres passing through all of Germany's 15 largest cities? The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. For this reason, complexity theory addresses computational problems and not particular problem instances.
Representing problem instances.
When considering computational problems, a problem instance is a string over an alphabet. Usually, the alphabet is taken to be the binary alphabet (i.e., the set {0,1}), and thus the strings are bitstrings. As in a real-world computer, mathematical objects other than bitstrings must be suitably encoded. For example, integers can be represented in binary notation, and graphs can be encoded directly via their adjacency matrices, or by encoding their adjacency lists in binary.
Even though some proofs of complexity-theoretic theorems regularly assume some concrete choice of input encoding, one tries to keep the discussion abstract enough to be independent of the choice of encoding. This can be achieved by ensuring that different representations can be transformed into each other efficiently.
Decision problems as formal languages.
Decision problems are one of the central objects of study in computational complexity theory. A decision problem is a special type of computational problem whose answer is either "yes" or "no", or alternately either 1 or 0. A decision problem can be viewed as a formal language, where the members of the language are instances whose output is yes, and the non-members are those instances whose output is no. The objective is to decide, with the aid of an algorithm, whether a given input string is a member of the formal language under consideration. If the algorithm deciding this problem returns the answer "yes", the algorithm is said to accept the input string, otherwise it is said to reject the input.
An example of a decision problem is the following. The input is an arbitrary graph. The problem consists in deciding whether the given graph is connected, or not. The formal language associated with this decision problem is then the set of all connected graphs—of course, to obtain a precise definition of this language, one has to decide how graphs are encoded as binary strings.
Function problems.
A function problem is a computational problem where a single output (of a total function) is expected for every input, but the output is more complex than that of a decision problem, that is, it isn't just yes or no. Notable examples include the traveling salesman problem and the integer factorization problem.
It is tempting to think that the notion of function problems is much richer than the notion of decision problems. However, this is not really the case, since function problems can be recast as decision problems. For example, the multiplication of two integers can be expressed as the set of triples ("a", "b", "c") such that the relation "a" × "b" = "c" holds. Deciding whether a given triple is a member of this set corresponds to solving the problem of multiplying two numbers.
Measuring the size of an instance.
To measure the difficulty of solving a computational problem, one may wish to see how much time the best algorithm requires to solve the problem. However, the running time may, in general, depend on the instance. In particular, larger instances will require more time to solve. Thus the time required to solve a problem (or the space required, or any measure of complexity) is calculated as a function of the size of the instance. This is usually taken to be the size of the input in bits. Complexity theory is interested in how algorithms scale with an increase in the input size. For instance, in the problem of finding whether a graph is connected, how much more time does it take to solve a problem for a graph with 2"n" vertices compared to the time taken for a graph with "n" vertices?
If the input size is "n", the time taken can be expressed as a function of "n". Since the time taken on different inputs of the same size can be different, the worst-case time complexity T("n") is defined to be the maximum time taken over all inputs of size "n". If T("n") is a polynomial in "n", then the algorithm is said to be a polynomial time algorithm. Cobham's thesis says that a problem can be solved with a feasible amount of resources if it admits a polynomial time algorithm.
Machine models and complexity measures.
Turing machine.
A Turing machine is a mathematical model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a thought experiment representing a computing machine—anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church–Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.
Many types of Turing machines are used to define complexity classes, such as deterministic Turing machines, probabilistic Turing machines, non-deterministic Turing machines, quantum Turing machines, symmetric Turing machines and alternating Turing machines. They are all equally powerful in principle, but when resources (such as time or space) are bounded, some of these may be more powerful than others.
A deterministic Turing machine is the most basic Turing machine, which uses a fixed set of rules to determine its future actions. A probabilistic Turing machine is a deterministic Turing machine with an extra supply of random bits. The ability to make probabilistic decisions often helps algorithms solve problems more efficiently. Algorithms that use random bits are called randomized algorithms. A non-deterministic Turing machine is a deterministic Turing machine with an added feature of non-determinism, which allows a Turing machine to have multiple possible future actions from a given state. One way to view non-determinism is that the Turing machine branches into many possible computational paths at each step, and if it solves the problem in any of these branches, it is said to have solved the problem. Clearly, this model is not meant to be a physically realizable model, it is just a theoretically interesting abstract machine that gives rise to particularly interesting complexity classes. For examples, see non-deterministic algorithm.
Other machine models.
Many machine models different from the standard multi-tape Turing machines have been proposed in the literature, for example random access machines. Perhaps surprisingly, each of these models can be converted to another without providing any extra computational power. The time and memory consumption of these alternate models may vary. What all these models have in common is that the machines operate deterministically.
However, some computational problems are easier to analyze in terms of more unusual resources. For example, a non-deterministic Turing machine is a computational model that is allowed to branch out to check many different possibilities at once. The non-deterministic Turing machine has very little to do with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing computational problems.
Complexity measures.
For a precise definition of what it means to solve a problem using a given amount of time and space, a computational model such as the deterministic Turing machine is used. The "time required" by a deterministic Turing machine "M" on input "x" is the total number of state transitions, or steps, the machine makes before it halts and outputs the answer ("yes" or "no"). A Turing machine "M" is said to operate within time "f"("n"), if the time required by "M" on each input of length "n" is at most "f"("n"). A decision problem "A" can be solved in time "f"("n") if there exists a Turing machine operating in time "f"("n") that solves the problem. Since complexity theory is interested in classifying problems based on their difficulty, one defines sets of problems based on some criteria. For instance, the set of problems solvable within time "f"("n") on a deterministic Turing machine is then denoted by DTIME("f"("n")).
Analogous definitions can be made for space requirements. Although time and space are the most well-known complexity resources, any complexity measure can be viewed as a computational resource. Complexity measures are very generally defined by the Blum complexity axioms. Other complexity measures used in complexity theory include communication complexity, circuit complexity, and decision tree complexity.
The complexity of an algorithm is often expressed using big O notation.
Best, worst and average case complexity.
The best, worst and average case complexity refer to three different ways of measuring the time complexity (or any other complexity measure) of different inputs of the same size. Since some inputs of size "n" may be faster to solve than others, we define the following complexities:
For example, consider the deterministic sorting algorithm quicksort. This solves the problem of sorting a list of integers that is given as the input. The worst-case is when the input is sorted or sorted in reverse order, and the algorithm takes time O("n"2) for this case. If we assume that all possible permutations of the input list are equally likely, the average time taken for sorting is O("n" log "n"). The best case occurs when each pivoting divides the list in half, also needing O("n" log "n") time.
Upper and lower bounds on the complexity of problems.
To classify the computation time (or similar resources, such as space consumption), one is interested in proving upper and lower bounds on the minimum amount of time required by the most efficient algorithm solving a given problem. The complexity of an algorithm is usually taken to be its worst-case complexity, unless specified otherwise. Analyzing a particular algorithm falls under the field of analysis of algorithms. To show an upper bound "T"("n") on the time complexity of a problem, one needs to show only that there is a particular algorithm with running time at most "T"("n"). However, proving lower bounds is much more difficult, since lower bounds make a statement about all possible algorithms that solve a given problem. The phrase "all possible algorithms" includes not just the algorithms known today, but any algorithm that might be discovered in the future. To show a lower bound of "T"("n") for a problem requires showing that no algorithm can have time complexity lower than "T"("n").
Upper and lower bounds are usually stated using the big O notation, which hides constant factors and smaller terms. This makes the bounds independent of the specific details of the computational model used. For instance, if "T"("n") = 7"n"2 + 15"n" + 40, in big O notation one would write "T"("n") = O("n"2).
Complexity classes.
Defining complexity classes.
A complexity class is a set of problems of related complexity. Simpler complexity classes are defined by the following factors:
Of course, some complexity classes have complicated definitions that do not fit into this framework. Thus, a typical complexity class has a definition like the following:
But bounding the computation time above by some concrete function "f"("n") often yields complexity classes that depend on the chosen machine model. For instance, the language {"xx" | "x" is any binary string} can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that "the time complexities in any two reasonable and general models of computation are polynomially related" . This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP.
Important complexity classes.
Many important complexity classes can be defined by bounding the time or space used by the algorithm. Some important complexity classes of decision problems defined in this manner are the following:
The logarithmic-space classes (necessarily) do not take into account the space needed to represent the problem.
It turns out that PSPACE = NPSPACE and EXPSPACE = NEXPSPACE by Savitch's theorem.
Other important complexity classes include BPP, ZPP and RP, which are defined using probabilistic Turing machines; AC and NC, which are defined using Boolean circuits; and BQP and QMA, which are defined using quantum Turing machines. #P is an important complexity class of counting problems (not decision problems). Classes like IP and AM are defined using Interactive proof systems. ALL is the class of all decision problems.
Hierarchy theorems.
For the complexity classes defined in this way, it is desirable to prove that relaxing the requirements on (say) computation time indeed defines a bigger set of problems. In particular, although DTIME("n") is contained in DTIME("n"2), it would be interesting to know if the inclusion is strict. For time and space requirements, the answer to such questions is given by the time and space hierarchy theorems respectively. They are called hierarchy theorems because they induce a proper hierarchy on the classes defined by constraining the respective resources. Thus there are pairs of complexity classes such that one is properly included in the other. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved.
More precisely, the time hierarchy theorem states that
The space hierarchy theorem states that
The time and space hierarchy theorems form the basis for most separation results of complexity classes. For instance, the time hierarchy theorem tells us that P is strictly contained in EXPTIME, and the space hierarchy theorem tells us that L is strictly contained in PSPACE.
Reduction.
Many complexity classes are defined using the concept of a reduction. A reduction is a transformation of one problem into another problem. It captures the informal notion of a problem being at least as difficult as another problem. For instance, if a problem "X" can be solved using an algorithm for "Y", "X" is no more difficult than "Y", and we say that "X" "reduces" to "Y". There are many different types of reductions, based on the method of reduction, such as Cook reductions, Karp reductions and Levin reductions, and the bound on the complexity of reductions, such as polynomial-time reductions or log-space reductions.
The most commonly used reduction is a polynomial-time reduction. This means that the reduction process takes polynomial time. For example, the problem of squaring an integer can be reduced to the problem of multiplying two integers. This means an algorithm for multiplying two integers can be used to square an integer. Indeed, this can be done by giving the same input to both inputs of the multiplication algorithm. Thus we see that squaring is not more difficult than multiplication, since squaring can be reduced to multiplication.
This motivates the concept of a problem being hard for a complexity class. A problem "X" is "hard" for a class of problems "C" if every problem in "C" can be reduced to "X". Thus no problem in "C" is harder than "X", since an algorithm for "X" allows us to solve any problem in "C". Of course, the notion of hard problems depends on the type of reduction being used. For complexity classes larger than P, polynomial-time reductions are commonly used. In particular, the set of problems that are hard for NP is the set of NP-hard problems.
If a problem "X" is in "C" and hard for "C", then "X" is said to be "complete" for "C". This means that "X" is the hardest problem in "C". (Since many problems could be equally hard, one might say that "X" is one of the hardest problems in "C".) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, Π2, to another problem, Π1, would indicate that there is no known polynomial-time solution for Π1. This is because a polynomial-time solution to Π1 would yield a polynomial-time solution to Π2. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that can be solved in polynomial time would mean that P = NP.
Important open problems.
P versus NP problem.
The complexity class P is often seen as a mathematical abstraction modeling those computational tasks that admit an efficient algorithm. This hypothesis is called the Cobham–Edmonds thesis. The complexity class NP, on the other hand, contains many problems that people would like to solve efficiently, but for which no efficient algorithm is known, such as the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem. Since deterministic Turing machines are special non-deterministic Turing machines, it is easily observed that each problem in P is also member of the class NP.
The question of whether P equals NP is one of the most important open questions in theoretical computer science because of the wide implications of a solution. If the answer is yes, many important problems can be shown to have more efficient solutions. These include various types of integer programming problems in operations research, many problems in logistics, protein structure prediction in biology, and the ability to find formal proofs of pure mathematics theorems. The P versus NP problem is one of the Millennium Prize Problems proposed by the Clay Mathematics Institute. There is a US$1,000,000 prize for resolving the problem.
Problems in NP not known to be in P or NP-complete.
It was shown by Ladner that if P ≠ NP then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete.
The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to Laszlo Babai and Eugene Luks has run time 2O() for graphs with "n" vertices.
The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a prime factor less than "k". No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP will equal co-NP). The best known algorithm for integer factorization is the general number field sieve, which takes time O(e(64/9)1/3("n".log 2)1/3(log ("n".log 2))2/3) to factor an "n"-bit integer. However, the best known quantum algorithm for this problem, Shor's algorithm, does run in polynomial time. Unfortunately, this fact doesn't say much about where the problem lies with respect to non-quantum complexity classes.
Separations between other complexity classes.
Many known complexity classes are suspected to be unequal, but this has not been proved. For instance P ⊆ NP ⊆ PP ⊆ PSPACE, but it is possible that P = PSPACE. If P is not equal to NP, then P is not equal to PSPACE either. Since there are many known complexity classes between P and PSPACE, such as RP, BPP, PP, BQP, MA, PH, etc., it is possible that all these complexity classes collapse to one class. Proving that any of these classes are unequal would be a major breakthrough in complexity theory.
Along the same lines, co-NP is the class containing the complement problems (i.e. problems with the "yes"/"no" answers reversed) of NP problems. It is believed that NP is not equal to co-NP; however, it has not yet been proven. It is clear that if these two complexity classes are not equal then P is not equal to NP, since if P=NP we would also have P=co-NP, since problems in NP are dual to those in co-NP.
Similarly, it is not known if L (the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to P. Again, there are many complexity classes between the two, such as NL and NC, and it is not known if they are distinct or equal classes.
It is suspected that P and BPP are equal. However, it is currently open if BPP = NEXP.
Intractability.
Problems that can be solved in theory (e.g., given large but finite time), but which in practice take too long for their solutions to be useful, are known as "intractable" problems. In complexity theory, problems that lack polynomial-time solutions are considered to be intractable for more than the smallest inputs. In fact, the Cobham–Edmonds thesis states that only those problems that can be solved in polynomial time can be feasibly computed on some computational device. Problems that are known to be intractable in this sense include those that are EXPTIME-hard. If NP is not the same as P, then the NP-complete problems are also intractable in this sense. To see why exponential-time algorithms might be unusable in practice, consider a program that makes 2"n" operations before halting. For small "n", say 100, and assuming for the sake of example that the computer does 1012 operations each second, the program would run for about 4 × 1010 years, which is the same order of magnitude as the age of the universe. Even with a much faster computer, the program would only be useful for very small instances and in that sense the intractability of a problem is somewhat independent of technological progress. Nevertheless, a polynomial time algorithm is not always practical. If its running time is, say, "n"15, it is unreasonable to consider it efficient and it is still useless except on small instances.
What intractability means in practice is open to debate. Saying that a problem is not in P does not imply that all large cases of the problem are hard or even that most of them are. For example, the decision problem in Presburger arithmetic has been shown not to be in P, yet algorithms have been written that solve the problem in reasonable times in most cases. Similarly, algorithms can solve the NP-complete knapsack problem over a wide range of sizes in less than quadratic time and SAT solvers routinely handle large instances of the NP-complete Boolean satisfiability problem.
History.
An early example of algorithm complexity analysis is the running time analysis of the Euclidean algorithm done by Gabriel Lamé in 1844.
Before the actual research explicitly devoted to the complexity of algorithmic problems started off, numerous foundations were laid out by various researchers. Most influential among these was the definition of Turing machines by Alan Turing in 1936, which turned out to be a very robust and flexible simplification of a computer.
As point out, the beginning of systematic studies in computational complexity is attributed to the seminal paper "On the Computational Complexity of Algorithms" by Juris Hartmanis and Richard Stearns (1965), which laid out the definitions of time and space complexity and proved the hierarchy theorems. Also, in 1965 Edmonds defined a "good" algorithm as one with running time bounded by a polynomial of the input size.
Earlier papers studying problems solvable by Turing machines with specific bounded resources include John Myhill's definition of linear bounded automata (Myhill 1960), Raymond Smullyan's study of rudimentary sets (1961), as well as Hisao Yamada's paper on real-time computations (1962). Somewhat earlier, Boris Trakhtenbrot (1956), a pioneer in the field from the USSR, studied another specific complexity measure. As he remembers:
In 1967, Manuel Blum developed an axiomatic complexity theory based on his axioms and proved an important result, the so-called, speed-up theorem. The field really began to flourish in 1971 when the US researcher Stephen Cook and, working independently, Leonid Levin in the USSR, proved that there exist practically relevant problems that are NP-complete. In 1972, Richard Karp took this idea a leap forward with his landmark paper, "Reducibility Among Combinatorial Problems", in which he showed that 21 diverse combinatorial and graph theoretical problems, each infamous for its computational intractability, are NP-complete.

</doc>
<doc id="7544" url="https://en.wikipedia.org/wiki?curid=7544" title="Cadence">
Cadence

Cadence may refer to:

</doc>
<doc id="7546" url="https://en.wikipedia.org/wiki?curid=7546" title="Camelot">
Camelot

Camelot is a castle and court associated with the legendary King Arthur. Absent in the early Arthurian material, Camelot first appeared in 12th-century French romances and, after the Lancelot-Grail cycle, eventually came to be described as the fantastic capital of Arthur's realm and a symbol of the Arthurian world. The stories locate it somewhere in Great Britain and sometimes associate it with real cities, though more usually its precise location is not revealed. Most scholars regard it as being entirely fictional, its geography being perfect for romance writers; Arthurian scholar Norris J. Lacy commented that "Camelot, located no where in particular, can be anywhere". Nevertheless, arguments about the location of the "real Camelot" have occurred since the 15th century and continue to rage today in popular works and for tourism purposes.
Early appearances.
The castle is mentioned for the first time in Chrétien de Troyes' poem "Lancelot, the Knight of the Cart", dating to the 1170s, though it does not appear in all the manuscripts. It is mentioned in passing, and is not described:
Nothing in Chrétien's poem suggests the level of importance Camelot would have in later romances. For Chrétien, Arthur's chief court was in Caerleon in Wales; this was the king's primary base in Geoffrey of Monmouth's "Historia Regum Britanniae" and subsequent literature. Chrétien depicts Arthur, like a typical medieval monarch, holding court at a number of cities and castles. It is not until the 13th-century French prose romances, including the Lancelot-Grail and the Post-Vulgate Cycle, that Camelot began to supersede Caerleon, and even then, many descriptive details applied to Camelot derive from Geoffrey's earlier grand depiction of the Welsh town. Most Arthurian romances of this period produced in English or Welsh did not follow this trend; Camelot was referred to infrequently, and usually in translations from French. One exception is "Sir Gawain and the Green Knight", which locates Arthur's court at "Camelot"; however, in Britain, Arthur's court was generally located at Caerleon, or at Carlisle, which is usually identified with the "Carduel" of the French romances. However, in the late 15th century, Thomas Malory created the image of Camelot most familiar to English speakers today in his "Le Morte d'Arthur", a work based mostly on the French romances. He firmly identifies Camelot with Winchester, an identification that remained popular over the centuries, though it was rejected by Malory's own editor, William Caxton, who preferred a Welsh location.
Etymology.
The name's derivation is uncertain. It has numerous different spellings in medieval French Arthurian romance, including: "Camaalot", "Camalot", "Chamalot", "Camehelot" (sometimes read as "Camchilot"), "Camaaloth", "Caamalot", "Camahaloth", "Camaelot", "Kamaalot", "Kamaaloth", "Kaamalot", "Kamahaloth", "Kameloth", "Kamaelot", "Kamelot", "Kaamelot", "Cameloth", "Camelot", "Kamelot", "Kaamelot", and "Gamalaot". Renowned Arthurian scholar Ernst Brugger suggested that it was a corruption of "Camlann", the site of Arthur's final battle in Welsh tradition. Roger Sherman Loomis believed it was derived from "Cavalon", a place name that he suggested was a corruption of Avalon (under the influence of the Breton place name "Cavallon"). He further suggested that "Cavalon/Camelot" became Arthur's capital due to confusion with Arthur's other traditional court at "Carlion" ("Caer Lleon" in Welsh).
Others have suggested a derivation from the Iron Age and Romano-British place name "Camulodunum", one of the first capitals of Roman Britain and which would have significance in Romano-British culture. Indeed, John Morris, the English historian who specialized in the study of the institutions of the Roman Empire and the history of Sub-Roman Britain, suggested in his book "The Age of Arthur" that as the descendants of Romanized Britons looked back to a golden age of peace and prosperity under Rome, the name "Camelot" of Arthurian legend may have referred to the capital of Britannia ("Camulodunum", modern Colchester) in Roman times. It is unclear, however, where Chrétien would have encountered the name "Camulodunum", or why he would render it as "Camaalot", though Urban T. Holmes argued in 1929 that Chretien had access to Book 2 of Pliny's "Natural History", where it is rendered as "Camaloduno". Given Chrétien's known tendency to create new stories and characters, being the first to mention the hero Lancelot's love affair with Queen Guinevere for example, the name might also be entirely invented.
Description in the romances.
The Lancelot-Grail Cycle and the texts it influenced depict the city of Camelot as standing along a river, downstream from Astolat. It is surrounded by plains and forests, and its magnificent cathedral, St. Stephen's, is the religious centre for Arthur's Knights of the Round Table. There, Arthur and Guinevere are married and there are the tombs of many kings and knights. In a mighty castle stands the Round Table; it is here that Galahad conquers the Siege Perilous, and where the knights see a vision of the Holy Grail and swear to find it. Jousts are held in a meadow outside the city. In the "Palamedes" and other works, the castle is eventually destroyed by King Mark of Cornwall after the loss of Arthur at the Battle of Camlann. However maddening to later scholars searching for Camelot's location, its imprecise geography serves the romances well, as Camelot becomes less a literal place than a powerful symbol of Arthur's court and universe. It should be noted, too, that there is a Kamaalot featured as the home of Perceval's mother in the romance "Perlesvaus".
The romancers' versions of Camelot drew on earlier descriptions of Arthur's fabulous court. From Geoffrey's grand description of Caerleon, Camelot gains its impressive architecture, its many churches and the chivalry and courtesy of its inhabitants. Geoffrey's description in turn drew on an already established tradition in Welsh oral tradition of the grandeur of Arthur's court. The tale "Culhwch and Olwen", associated with the "Mabinogion" and perhaps written in the 11th century, draws a dramatic picture of Arthur's hall and his many powerful warriors who go from there on great adventures, placing it in Celliwig, an uncertain locale in Cornwall. Although the court at Celliwig is the most prominent in remaining early Welsh manuscripts, the various versions of the Welsh Triads agree in giving Arthur multiple courts, one in each of the areas inhabited by the Britons: Cornwall, Wales and the Old North. This perhaps reflects the influence of widespread oral traditions common by 800 which are recorded in various place names and features such as Arthur's Seat indicating Arthur was a hero known and associated with many locations across Brittonic areas of Britain as well as Brittany. Even at this stage Arthur could not be tied to one location. Many other places are listed as a location where Arthur holds court in the later romances, Carlisle and London perhaps being the most prominent.
Identifications.
The romancers' versions of Camelot draw on earlier traditions of Arthur's fabulous court. The Celliwig of "Culhwch and Olwen" appears in the Welsh Triads as well; this early Welsh material places Wales' greatest leader outside its national boundaries. Geoffrey's description of Caerleon is probably based on his personal familiarity with the town and its impressive Roman ruins; it is less clear that Caerleon was associated with Arthur before Geoffrey. Several French romances ("Perlesvaus", the Didot "Perceval" attributed to Robert de Boron, and even the early romances of Chretien de Troyes such as "Erec and Enide" and "Yvain, the Knight of the Lion") have Arthur hold court at "Carduel in Wales," a northern city based on the real Carlisle.
Malory's identification of Camelot as Winchester was probably partially inspired by the latter city's history. It had been the capital of Wessex under Alfred the Great, and boasted the Winchester Round Table, an artifact constructed in the 13th century but widely believed to be the original by Malory's time. Malory's editor Caxton rejects the association, saying Camelot was in Wales and that its ruins could still be seen; this is a likely reference to the Roman ruins at Caerwent. Malory associated other Arthurian locations with modern places, for instance locating Astolat at Guildford.
In 1542, John Leland reported the locals around Cadbury Castle, formerly known as Camalet, in Somerset considered it to be the original Camelot. This theory, which was repeated by later antiquaries, is bolstered, or may have derived from, Cadbury's proximity to the River Cam (Somerset) and the villages of Queen Camel and West Camel, and remained popular enough to help inspire a large-scale archaeological dig in the 20th century. These excavations, led by archaeologist Leslie Alcock from 1966–70, were titled "Cadbury-Camelot," and won much media attention, even being mentioned in the film of the musical "Camelot". The dig revealed that the site seems to have been occupied as early as the 4th millennium and to have been refortified and occupied by a major British ruler and his warband from . This early medieval settlement continued until around 580. The works were by far the largest known fortification of the period, double the size of comparative "caers" and with Mediterranean artifacts representing extensive trade and Saxon ones showing possible conquest. The use of the name Camelot and the support of Geoffrey Ashe helped ensure much publicity for the finds, but Alcock himself later grew embarrassed by the supposed Arthurian connection to the site. Following the arguments of David Dumville, Alcock felt the site was too late and too uncertain to be a tenable Camelot. Modern archaeologists follow him in rejecting the name, calling it instead Cadbury Castle hill fort. Despite this, Cadbury remains widely associated with Camelot.
There were two towns in Roman Britain named Camulodunum, Colchester in Essex and Slack in West Yorkshire, derived from the Celtic god Camulos, and this has led to the suggestion that they originated the name. However, the Essex Camulodunum was located well within territory usually thought to have been conquered early in the 5th century by Saxons, so it is unlikely to have been the location of any "true" Camelot. The town was definitely known as Colchester as early as the "Anglo-Saxon Chronicle" in 917. Even Colchester Museum argues strongly regarding the historical Arthur: "It would be impossible and inconceivable to link him to the Colchester area, or to Essex more generally", pointing out that the connection between the name Camuloduum and Colchester was unknown till the 18th century. Other places in Britain with names related to "Camel" have also been suggested, such as Camelford in Cornwall, located down the River Camel from where Geoffrey places Camlann, the scene of Arthur's final battle. The area's connections with Camelot and Camlann are merely speculative.
Later uses.
Camelot has become a permanent fixture in interpretations of the Arthurian legend. The symbolism of Camelot so impressed Alfred, Lord Tennyson that he wrote up a prose sketch on the castle as one of his earliest attempts to treat the Arthurian legend. "A Connecticut Yankee in King Arthur's Court", a novel by Mark Twain in 1889, takes place in Camelot. Recent versions typically retain Camelot's lack of precise location and its status as a symbol of the Arthurian world, though they typically transform the castle itself into romantically lavish visions of a High Middle Ages palace. It lends its name to the 1960 musical "Camelot" by Alan Jay Lerner and Frederick Loewe, which is based on T. H. White's literary version of the legend, "The Once and Future King". The musical was adapted into a 1967 film of the same name, which starred Richard Harris as Arthur, and which featured the Castle of Coca, Segovia as a fittingly opulent Camelot. Some writers of the "realist" strain of modern Arthurian fiction have attempted a more sensible Camelot; inspired by Alcock's Cadbury-Camelot excavation, writers Marion Zimmer Bradley, Mary Stewart, and Catherine Christian place their Camelots in that place and describe it accordingly.
Camelot makes only a brief appearance in the 1975 parody "Monty Python and the Holy Grail": Having recruited several knights, King Arthur (Graham Chapman) invites them to reside with him at Camelot. The camera pans to a castle on a hill, then cuts to the knights as each in succession joyfully exclaims, "Camelot!" (Arthur's servant Patsy, played by co-director Terry Gilliam, grumbles, "It's only a model.") Then, after an interior sequence, in which the resident knights sing, "We're Knights of the Round Table" while engaging in madcap antics, the camera cuts back to Arthur, who decides, "On second thought, let's not go there. It is a silly place."
In American contexts, the word "Camelot" is sometimes used to refer admiringly to the presidency of John F. Kennedy. The Lerner and Loewe musical was still quite recent at the time and his widow Jackie quoted its lines in a 1963 "Life" interview following JFK's assassination. She said the lines, "Don't let it be forgot, that once there was a spot, for one brief shining moment, that was known as Camelot" were Kennedy's favorite in the score, adding that "there'll be great Presidents again, but there'll never be another Camelot again… It will never be that way again."
Camelot Theme Park was a resort and theme park located in the English county of Lancashire, UK.
"Kaamelott" is a French television series that presents a humorous alternative version of the Arthurian legend.
Camelot is featured in "Once Upon a Time". In "Heroes and Villains," Rumplestiltskin once visited Camelot to obtain a magic gauntlet. In "The Dark Swan," Camelot is fully seen. Brocéliande is somewhere near Camelot. According to an interview with Adam Horowitz, Camelot is a few days ride away from the Enchanted Forest and Arendelle.

</doc>
<doc id="7548" url="https://en.wikipedia.org/wiki?curid=7548" title="Contras">
Contras

The contras (some references use the capitalized form, "Contras") is a label given to the various U.S.-backed and funded right-wing rebel groups that were active from 1979 to the early 1990s in opposition to the left-wing, socialist Sandinista Junta of National Reconstruction government in Nicaragua. Among the separate contra groups, the Nicaraguan Democratic Force (FDN) emerged as the largest by far. In 1987, virtually all contra organizations were united, at least nominally, into the Nicaraguan Resistance.
From an early stage, the rebels received financial and military support from the United States government, and their military significance decisively depended on it. After US support was banned by Congress, the Reagan administration covertly continued it. These covert activities culminated in the Iran–Contra affair.
The term "contra" comes from the Spanish "contra," which means "against" but in this case is short for , in English "the counter-revolution". Some rebels disliked being called contras, feeling that it defined their cause only in negative terms, or implied a desire to restore the old order. Rebel fighters usually referred to themselves as ("commandos"); peasant sympathizers also called the rebels ("the cousins"). From the mid-1980s, as the Reagan administration and the rebels sought to portray the movement as the "democratic resistance," members started describing themselves as .
During their war against the Nicaraguan government, the Contras committed a large number of human rights violations and used terrorist tactics and carried out more than 1300 terrorist attacks. These actions were frequently carried out systematically as a part of the strategy of the contras. Supporters of the Contras tried to minimize these violations, particularly the Reagan administration in the US, which engaged in a campaign of white propaganda to alter public opinion in favor of the contras.
History.
Origins.
The Contras were not a monolithic group, but a combination of three distinct elements of Nicaraguan society:
Main groups.
The CIA and Argentine intelligence, seeking to unify the anti-Sandinista cause before initiating large-scale aid, persuaded 15 September Legion, the UDN and several former smaller groups to merge in September 1981 as the Nicaraguan Democratic Force ("Fuerza Democrática Nicaragüense", FDN). Although the FDN had its roots in two groups made up of former National Guardsmen (of the Somoza regime), its joint political directorate was led by businessman and former anti-Somoza activist Adolfo Calero Portocarrero. Edgar Chamorro later stated that there was strong opposition within the UDN against working with the Guardsmen and that the merging only took place because of insistence by the CIA.
Based in Honduras, Nicaragua's northern neighbor, under the command of former National Guard Colonel Enrique Bermúdez, the new FDN commenced to draw in other smaller insurgent forces in the north. Largely financed, trained, equipped, armed and organized by the U.S., it emerged as the largest and most active contra group.
In April 1982, Edén Pastora ("Comandante Cero"), one of the heroes in the fight against Somoza, organized the Sandinista Revolutionary Front (FRS) – embedded in the Democratic Revolutionary Alliance (ARDE) – and declared war on the Sandinista government. Himself a former Sandinista who had held several high posts in the government, he had resigned abruptly in 1981 and defected, believing that the newly found power had corrupted the Sandinista's original ideas. A popular and charismatic leader, Pastora initially saw his group develop quickly. He confined himself to operate in the southern part of Nicaragua; after a press conference he was holding on 30 May 1984 was bombed, he "voluntarily withdrew" from the contra struggle.
A third force, Misurasata, appeared among the Miskito, Sumo and Rama Amerindian peoples of Nicaragua's Atlantic coast, who in December 1981 found themselves in conflict with the authorities following the government's efforts to nationalize Indian land. In the course of this conflict, forced removal of at least 10,000 Indians to relocation centers in the interior of the country and subsequent burning of some villages took place. The Misurasata movement split in 1983, with the breakaway Misura group of Stedman Fagoth Muller allying itself more closely with the FDN, and the rest accommodating themselves with the Sandinistas: On 8 December 1984 a ceasefire agreement known as the Bogota Accord was signed by Misurasata and the Nicaraguan government. A subsequent autonomy statute in September 1987 largely defused Miskito resistance.
Unity efforts.
U.S. officials were active in attempting to unite the Contra groups. In June 1985 most of the groups reorganized as the United Nicaraguan Opposition (UNO), under the leadership of Adolfo Calero, Arturo Cruz and Alfonso Robelo, all originally supporters of the anti-Somoza revolution. After UNO's dissolution early in 1987, the Nicaraguan Resistance (RN) was organized along similar lines in May.
U.S. military and financial assistance.
In front of the International Court of Justice, Nicaragua claimed that the contras were altogether a creation of the U.S. This claim was rejected. However, the evidence of a very close relationship between the contras and the United States was considered overwhelming and incontrovertible. The U.S. played a very large role in financing, training, arming, and advising the contras over a long period, and the contras only became capable of carrying out significant military operations as a result of this support.
Political background.
The US government viewed the leftist Sandinistas as a threat to economic interests of American corporations in Nicaragua and to the national security. US President Ronald Reagan stated in 1983 that “The defense of USA's southern frontier” was at stake. "In spite of the Sandinista victory being declared fair, the United States continued to oppose the left-wing Nicaraguan government." and opposed its ties to Cuba and the Soviet Union. Ronald Reagan, who had assumed the American presidency in January 1981, accused the Sandinistas of importing Cuban-style socialism and aiding leftist guerrillas in El Salvador. The Reagan administration continued to view the Sandinistas as undemocratic despite the 1984 Nicaraguan elections being generally declared fair by foreign observers. Throughout the 1980s the Sandinista government was regarded as "Partly Free" by Freedom House, an organization financed by the U.S. government. 
On 4 January 1982, Reagan signed the top secret National Security Decision Directive 17 (NSDD-17), giving the CIA the authority to recruit and support the contras with $19 million in military aid. The effort to support the contras was one component of the Reagan Doctrine, which called for providing military support to movements opposing Soviet-supported, communist governments.
By December 1981, however, the United States had already begun to support armed opponents of the Sandinista government. From the beginning, the CIA was in charge. The arming, clothing, feeding and supervision of the contras became the most ambitious paramilitary and political action operation mounted by the agency in nearly a decade.
In the fiscal year 1984, the U.S. Congress approved $24 million in contra aid. However, since the contras failed to win widespread popular support or military victories within Nicaragua, opinion polls indicated that a majority of the U.S. public was not supportive of the contras, the Reagan administration lost much of its support regarding its contra policy within Congress after disclosure of CIA mining of Nicaraguan ports, and a report of the Bureau of Intelligence and Research commissioned by the State Department found Reagan's allegations about Soviet influence in Nicaragua "exaggerated", Congress cut off all funds for the contras in 1985 by the third Boland Amendment. The Boland Amendment had first been passed by Congress in December 1982. At this time, it only outlawed U.S. assistance to the contras "for the purpose of overthrowing the Nicaraguan government", while allowing assistance for other purposes. In October 1984, it was amended to forbid action by not only the Defense Department and the Central Intelligence Agency but all U.S. government agencies.
Nevertheless, the case for support of the contras continued to be made in Washington, D.C., by both the Reagan administration and the Heritage Foundation, which argued that support for the contras would counter Soviet influence in Nicaragua.
On 1 May 1985 President Reagan announced that his administration perceived Nicaragua to be "an unusual and extraordinary threat to the national security and foreign policy of the United States", and declared a "national emergency" and a trade embargo against Nicaragua to "deal with that threat". On May 16, 1985, Nicaraguan President Daniel Ortega redeclared "a position of nonalignment" during his failed mission to try and collect military aid from France, Spain, and Italy. Ortega managed to gain warm words of political and economic support but military aid was ruled out. In 1982, France sold Nicaragua about $17 million worth of arms before U.S. anger made them terminate the deal. A French Foreign Ministry official explained that this reticence resulted, "because we have limited power to maneuver in Central America, and after all, the region is in America's backyard."
Illegal covert operations.
With Congress blocking further contra aid, the Reagan administration sought to arrange funding and military supplies by means of third countries and private sources. Between 1984 and 1986, $34 million from third countries and $2.7 million from private sources were raised this way. The secret contra assistance was run by the National Security Council, with officer Lt. Col. Oliver North in charge. With the third-party funds, North created an organization called "The Enterprise" which served as the secret arm of the NSC staff and had its own airplanes, pilots, airfield, ship, operatives and secret Swiss bank accounts. It also received assistance from personnel from other government agencies, especially from CIA personnel in Central America. This operation functioned, however, without any of the accountability required of U.S. government activities. The Enterprise's efforts culminated in the Iran–Contra Affair of 1986–1987, which facilitated contra funding through the proceeds of arms sales to Iran.
According to the National Security Archive, Oliver North had been in contact with Manuel Noriega, the military leader of Panama later convicted on drug charges, whom he personally met. The issue of drug money and its importance in funding the Nicaraguan conflict was the subject of various reports and publications. The contras were funded by drug trafficking, of which the United States was aware. Senator John Kerry's 1988 Committee on Foreign Relations report on Contra drug links concluded that "senior U.S. policy makers were not immune to the idea that drug money was a perfect solution to the Contras' funding problems".
The Reagan administration's support for the Contras continued to stir controversy well into the 1990s. In August 1996, "San Jose Mercury News" reporter Gary Webb published a series titled "Dark Alliance", alleging that the contras contributed to the rise of crack cocaine in California. In his subsequent 1999 book, also titled "Dark Alliance", Webb asserted that the Reagan administration helped harbor known drug traffickers, offering political asylum to some, to help raise funds for the rebel effort.
Propaganda.
During the time the US Congress blocked funding for the contras, the Reagan government engaged in a campaign to alter public opinion and change the vote in Congress on contra aid. For this purpose, the NSC established an interagency working group which in turn coordinated the Office of Public Diplomacy for Latin America and the Caribbean (managed by Otto Reich), which conducted the campaign. The S/LPD produced and widely disseminated a variety of pro-contra publications, arranged speeches and press conferences. It also disseminated "white propaganda"—pro-contra newspaper articles by paid consultants who did not disclose their connection to the Reagan administration.
On top of that, Oliver North helped Carl Channell's tax-exempt organization, the "National Endowment for the Preservation of Liberty", to raise $10 million, by arranging numerous briefings for groups of potential contributors at the premises of the White House and by facilitating private visits and photo sessions with President Reagan for major contributors. Channell in turn, used part of that money to run a series of television advertisements directed at home districts of Congressmen considered to be swing votes on contra aid. Out of the $10 million raised, more than $1 million was spent on pro-contra publicity.
International Court of Justice ruling.
In 1984 the Sandinista government filed a suit in the International Court of Justice (ICJ) against the United States ("Nicaragua v. United States"), which resulted in a 1986 judgment against the United States. The ICJ held that the U.S. had violated international law by supporting the contras in their rebellion against the Nicaraguan government and by mining Nicaragua's harbors. Regarding the alleged human rights violations by the contras, however, the ICJ took the view that the United States could only be held accountable for them if it would have been proven that the U.S. had effective control of the contra operations resulting in these alleged violations. Nevertheless, the ICJ found that the U.S. encouraged acts contrary to general principles of humanitarian law by producing the manual "Psychological Operations in Guerrilla Warfare (Operaciones sicológicas en guerra de guerrillas") and disseminating it to the contras. The manual, amongst other things, advised on how to rationalize killings of civilians and recommended to hire professional killers for specific selective tasks.
The United States, which did not participate in the merits phase of the proceedings, maintained that the ICJ's power did not supersede the Constitution of the United States and argued that the court did not seriously consider the Nicaraguan role in El Salvador, while it accused Nicaragua of actively supporting armed groups there, specifically in the form of supply of arms. The ICJ had found that evidence of a responsibility of the Nicaraguan government in this matter was insufficient. The U.S. argument was affirmed, however, by the dissenting opinion of ICJ member U.S. Judge Schwebel, who concluded that in supporting the contras, the United States acted lawfully in collective self-defence in El Salvador's support. The U.S. blocked enforcement of the ICJ judgment by the United Nations Security Council and thereby prevented Nicaragua from obtaining any actual compensation. The Nicaraguan government finally withdrew the complaint from the court in September 1992 (under the later, post-FSLN, government of Violeta Chamorro), following a repeal of the law requiring the country to seek compensation.
Human rights violations.
Americas Watch – which subsequently became part of Human Rights Watch – accused the Contras of:
Human Rights Watch released a report on the situation in 1989, which stated: "contras were major and systematic violators of the most basic standards of the laws of armed conflict, including by launching indiscriminate attacks on civilians, selectively murdering non-combatants, and mistreating prisoners."
In his affidavit to the World Court, former contra Edgar Chamorro testified that "The CIA did not discourage such tactics. To the contrary, the Agency severely criticized me when I admitted to the press that the FDN had regularly kidnapped and executed agrarian reform workers and civilians. We were told that the only way to defeat the Sandinistas was to...kill, kidnap, rob and torture..."
Contra leader Adolfo Calero denied that his forces deliberately targeted civilians: "What they call a cooperative is also a troop concentration full of armed people. We are not killing civilians. We are fighting armed people and returning fire when fire is directed at us."
Controversy.
U.S. news media published several articles accusing Americas Watch and other bodies of ideological bias and unreliable reporting. It alleged that Americas Watch gave too much credence to alleged Contra abuses and systematically tried to discredit Nicaraguan human rights groups such as the Permanent Commission on Human Rights, which blamed the major human rights abuses on the Sandinistas.
In 1985, the "Wall Street Journal" reported::
Human Rights Watch, the umbrella organization of Americas Watch, replied to these allegations: "Almost invariably, U.S. pronouncements on human rights exaggerated and distorted the real human rights violations of the Sandinista regime, and exculpated those of the U.S.-supported insurgents, known as the contras...The Bush administration is responsible for these abuses, not only because the contras are, for all practical purposes, a U.S. force, but also because the Bush administration has continued to minimize and deny these violations, and has refused to investigate them seriously."
U.S. conservative political scientist Rudolph Rummel estimated that by 1987, the contras had murdered about 500 people while the Sandinistas had murdered 4,000 to 7,000 people in democide. In contrast, Witness for Peace and the Sandinista government claimed at least 736 civilians were murdered by the contras between March 1987 and October 1988 alone.
Military successes and election of Violeta Chamorro.
By 1986 the contras were besieged by charges of corruption, human-rights abuses, and military ineptitude. A much-vaunted early 1986 offensive never materialized, and Contra forces were largely reduced to isolated acts of terrorism. In October 1987, however, the contras staged a successful attack in southern Nicaragua. Then on 21 December 1987, the FDN launched attacks at La Bonanza, La Siuna, and La Rosita in Zelaya province, resulting in heavy fighting. ARDE Frente Sur attacked at El Almendro and along the Rama road. These large-scale raids mainly became possible as the contras were able to use U.S.-provided Redeye missiles against Sandinista Mi-24 helicopter gunships, which had been supplied by the Soviets. Nevertheless, the Contras remained tenuously encamped within Honduras and weren't able to hold Nicaraguan territory.
There were isolated protests among the population against the draft implemented by the Sandinista government, which even resulted in full-blown street clashes in Masaya in 1988. However, polls showed the Sandinista government still enjoyed strong support from Nicaraguans. Political opposition groups were splintered and the Contras began to experience defections, although United States aid maintained them as a viable military force.
After a cutoff in U.S. military support and with both sides facing international pressure to bring an end to the conflict, the contras agreed to negotiations with the FSLN. With the help of five Central American Presidents, including Ortega, it was agreed that a voluntary demobilization of the contras should start in early December 1989, in order to facilitate free and fair elections in Nicaragua in February 1990 (even though the Reagan administration had pushed for a delay of contra disbandment).
In the resulting February 1990 elections, Violeta Chamorro and her party the UNO won an upset victory of 55% to 41% over Daniel Ortega, even though polls leading up to the election had clearly indicated an FSLN victory.
Possible explanations include that the Nicaraguan people were disenchanted with the Ortega regime as well as the fact that already in November 1989, the White House had announced that the economic embargo against Nicaragua would continue unless Violeta Chamorro won. Also, there had been reports of intimidation from the side of the contras, with a Canadian observer mission confirming 42 people killed by the contras in "election violence" in October 1989. This led many commentators to assume that Nicaraguans voted against the Sandinistas out of fear of a continuation of the contra war and economic deprivation.

</doc>
<doc id="7550" url="https://en.wikipedia.org/wiki?curid=7550" title="Craig Venter">
Craig Venter

John Craig Venter (born October 14, 1946) is an American biotechnologist, biochemist, geneticist, and entrepreneur. He is known for being one of the first to sequence the human genome and the first to transfect a cell with a synthetic genome. Venter founded Celera Genomics, The Institute for Genomic Research (TIGR) and the J. Craig Venter Institute (JCVI), and is now CEO of Human Longevity Inc. He was listed on "Time" magazine's 2007 and 2008 Time 100 list of the most influential people in the world. In 2010, the British magazine "New Statesman" listed Craig Venter at 14th in the list of "The World's 50 Most Influential Figures 2010". He is a member of the USA Science and Engineering Festival's Advisory Board.
Early life and education.
Venter was born in Salt Lake City, Utah, the son of Elizabeth and John Venter. In his youth, he did not take his education seriously, preferring to spend his time on the water in boats or surfing. According to his biography, "A Life Decoded", he was said to never be a terribly engaged student, having Cs and Ds on his eighth-grade report cards. He graduated from Mills High School in Millbrae, California.
Although he was against the Vietnam War, Venter was drafted and enlisted in the United States Navy where he worked in the intensive-care ward of a field hospital. While in Vietnam, he attempted suicide by swimming out to sea, but as he got closer to the deep blue sea and was approaching the circling of a shark, he changed his mind more than a mile out.
Being confronted with wounded, maimed, and dying on a daily basis instilled in him a desire to study medicine — although he later switched to biomedical research.
Venter began his college education at a community college, College of San Mateo in California, and later transferred to the University of California, San Diego, where he studied under biochemist Nathan O. Kaplan. He received a BS in biochemistry in 1972, and a PhD in physiology and pharmacology in 1975, both from UCSD. He married former PhD candidate Barbara Rae. After working as an associate professor, and later as full professor, at the State University of New York at Buffalo, he joined the National Institutes of Health in 1984.
In Buffalo, he divorced Dr. Rae-Venter and married his student, Claire M. Fraser, remaining married to her until 2005. In late 2008 he married Heather Kowalski. They live in La Jolla outside San Diego, California where Venter gut-renovated a $6 million home.
Venter is an atheist.
Venter himself recognized his own ADHD behavior in his adolescence, and later found ADHD-linked genes in his own DNA.
Career.
EST controversy.
While an employee of the NIH, Venter used a technique for rapidly identifying all of the mRNA strands present in a cell; and he began to use it to identify genes which are expressed in the human brain. The short cDNA sequence fragments discovered by this method are called expressed sequence tags, or ESTs. The NIH Office of Technology Transfer and Venter decided to use these ESTs in an attempt to patent the genes they identified based on their studies of mRNA expression in the human brain. When Venter disclosed this strategy during a Congressional hearing, a firestorm of controversy erupted. The NIH later stopped the effort and abandoned the patent applications it had filed, following public outcry.
Human Genome Project.
Venter was passionate about the power of genomics to radically transform healthcare. Venter believed that shotgun sequencing was the fastest and most effective way to get useful human genome data. The method was rejected by the Human Genome Project however, since some geneticists felt it would not be accurate enough for a genome as complicated as that of humans, that it would be logistically more difficult, and that it would cost significantly more.
Frustrated with what Venter viewed as the slow pace of progress in the Human Genome project, and unable to get funds for his ideas, he sought funding from the private sector to fund Celera Genomics. The goal of the company was to sequence the entire human genome and release it into the public domain for non-commercial use in much less time and for much less cost than the public human genome project. The company planned to profit from their work by creating a value-added database of genomic data to which users could subscribe for a fee. The goal consequently put pressure on the public genome program and spurred several groups to redouble their efforts to produce the full sequence. DNA from five demographically different individuals was used by Celera to generate the sequence of the human genome; one of the individuals was Venter himself.
In 2000, Venter and Francis Collins of the National Institutes of Health and U.S. Public Genome Project jointly made the announcement of the mapping of the human genome, a full three years ahead of the expected end of the Public Genome Program. The announcement was made along with U.S. President Bill Clinton, and UK Prime Minister Tony Blair. Venter and Collins thus shared an award for "Biography of the Year" from A&E Network.
On the 15 February 2001, the Human Genome Project consortium published the first Human Genome in the journal Nature, and was followed, one day later, by a Celera publication in Science. Despite some claims that shotgun sequencing was in some ways less accurate than the clone-by-clone method chosen by the Human Genome Project, the technique became widely accepted by the scientific community.
Although Celera was originally set to sequence a composite of DNA samples, partway through the sequencing, Venter switched the samples for his own DNA.
After contributing to the Human Genome, and its release into the public domain, Venter was fired by Celera in early 2002. According to his biography, Venter was ready to leave Celera, and was fired due to conflict with the main investor, Tony White, that had existed since day one of the project. Venter writes that his main goal was always to accelerate science and thereby discovery, and he only sought help from the corporate world when he could not find funding in the public sector.
Global Ocean Sampling Expedition.
The Global Ocean Sampling Expedition (GOS) is an ocean exploration genome project with the goal of assessing the genetic diversity in marine microbial communities and to understand their role in nature's fundamental processes. Begun as a Sargasso Sea pilot sampling project in August 2003, Venter announced the full Expedition on 4 March 2004. The project, which used Venter's personal yacht, "Sorcerer II", started in Halifax, Canada, circumnavigated the globe and returned to the U.S. in January 2006.
Synthetic genomics.
Venter is currently the president of the J. Craig Venter Institute, which conducts research in synthetic biology. In June 2005, he co-founded Synthetic Genomics, a firm dedicated to using modified microorganisms to produce clean fuels and biochemicals. In July 2009, ExxonMobil announced a $600 million collaboration with Synthetic Genomics to research and develop next-generation biofuels.
Venter is seeking to patent the first partially synthetic species possibly to be named "Mycoplasma laboratorium". There is speculation that this line of research could lead to producing bacteria that have been engineered to perform specific reactions, for example, produce fuels, make medicines, combat global warming, and so on.
In May 2010, a team of scientists led by Venter became the first to successfully create what was described as "synthetic life". This was done by synthesizing a very long DNA molecule containing an entire bacterium genome, and introducing this into another cell, analogous to the accomplishment of Eckard Wimmer's group, who synthesized and ligated an RNA virus genome and "booted" it in cell lysate. The single-celled organism contains four "watermarks"
written into its DNA to identify it as synthetic and to help trace its descendants. The watermarks include 
On March 25, 2016 Venter reported the creation of Syn 3.0, a synthetic genome having the fewest genes of any freely living organism (473 genes). Their aim was to strip away all nonessential genes, leaving only the minimal set necessary to support life.
This stripped-down, fast reproducing cell is expected to be a valuable tool for researchers in the field.
Individual human genome.
On September 4, 2007, a team led by Sam Levy published the first complete (six-billion-letter) genome of an individual human—Venter's own DNA sequence. Some of the sequences in Venter's genome are associated with wet earwax, increased risk of antisocial behavior, Alzheimer's and cardiovascular diseases. This publication was especially interesting since it contained a diploid instead of a haploid genome and shows promise for personalized medicine via genotyping. This genome, dubbed HuRef by Levy and others, was a landmark accomplishment.
The Human Reference Genome Browser is a web application for the navigation and analysis of Venter's recently published genome. The HuRef database consists of approximately 32 million DNA reads sequenced using microfluidic Sanger sequencing, assembled into 4,528 scaffolds and 4.1 million DNA variations identified by genome analysis. These variants include single-nucleotide polymorphisms (SNPs), block substitutions, short and large indels, and structural variations like insertions, deletions, inversions and copy number changes.
The browser enables scientists to navigate the HuRef genome assembly and sequence variations, and to compare it with the NCBI human build 36 assembly in the context of the NCBI and Ensembl annotations. The browser provides a comparative view between NCBI and HuRef consensus sequences, the sequence multi-alignment of the HuRef assembly, Ensembl and dbSNP annotations, HuRef variants, and the underlying variant evidence and functional analysis. The interface also represents the haplotype blocks from which diploid genome sequence can be inferred and the relation of variants to gene annotations. The display of variants and gene annotations are linked to external public resources including dbSNP, Ensembl, Online Mendelian Inheritance in Man (OMIM) and Gene Ontology (GO).
Users can search the HuRef genome using HUGO gene names, Ensembl and dbSNP identifiers, HuRef contig or scaffold locations, or NCBI chromosome locations. Users can then easily and quickly browse any genomic region via the simple and intuitive pan and zoom controls; furthermore, data relevant to specific loci can be exported for further analysis.
Human Longevity, Inc..
On March 4, 2014 Venter and co-founders Peter Diamandis and Robert Hariri announced the formation of Human Longevity, Inc., a company focused on extending the healthy, "high performance", human lifespan. At the time of the announcement the company had already raised $70 million in venture financing, which was expected to last 18 months. Venter is the chairman and chief executive officer (CEO). The company said that it plans to sequence 40,000 genomes per year, with an initial focus on cancer genomes and the genomes of cancer patients.
Human Longevity's mission is to extend healthy human lifespan by the use of high-resolution big data diagnostics from genomics, metabolomics, microbiomics, and proteomics, and the use of stem cell therapy.
Author of two books.
Venter is the author of two books, the first of which was ostensibly an autobiography titled "A Life Decoded". Venter's second book was titled "Life at the Speed of Light" in which he announced his theory that this is the generation in which there appears to be a dovetailing of the two previously diverse fields of science represented by computer programming and the genetic programming of life by DNA sequencing. He was applauded for his position on this by futurist Ray Kurzweil.
In popular culture.
Venter has been the subject of several biography books, several scientific documentary books, TV documentaries, numerous magazine articles, and many speeches.
Venter has been the subject of articles in several magazines, including "Wired", "The Economist", Australian science magazine "Cosmos", and "The Atlantic". Additionally, he was featured on "The Colbert Report" on both February 27, 2007, and October 30, 2007.
Venter appeared in the "Evolution" episode of the documentary television series "Understanding".
On May 16, 2004, Venter gave the commencement speech at Boston University.
In a 2007 interview with "New Scientist" when asked "Assuming you can make synthetic bacteria, what will you do with them?", Venter replied: "Over the next 20 years, synthetic genomics is going to become the standard for making anything. The chemical industry will depend on it. Hopefully, a large part of the energy industry will depend on it. We really need to find an alternative to taking carbon out of the ground, burning it, and putting it into the atmosphere. That is the single biggest contribution I could make."
He was on the 2007 Time 100 most influential people in the world list made by "Time" magazine. In 2007 he also received the Golden Eurydice Award for contributions to biophilosophy.
On December 4, 2007, Venter gave the Dimbleby lecture for the BBC in London. In February 2008, he gave a speech about his current work at the TED conference.
Venter delivered the 2008 convocation speech for Faculty of Science honours and specialization students at the University of Alberta. A transcription of the speech is available here.
Venter was featured in "Time" magazine's "The Top 10 Everything of 2008" article. Number three in 2008's Top 10 Scientific Discoveries was a piece outlining his work stitching together the 582,000 base pairs necessary to invent the genetic information for a whole new bacterium.
For an episode aired on July 27, 2009, Venter was interviewed on his boat by BBC One for the first episode of TV show "Bang Goes the Theory".
On May 20, 2010, Venter announced the creation of first self-replicating semi-synthetic bacterial cell.
On November 21, 2010 Steve Kroft profiled Venter and his research on "60 Minutes".
In the June 2011 issue of "Men's Journal", Venter was featured as the "Survival Skills" celebrity of the month. He shared various anecdotes, and advice, including stories of his time in Vietnam, as well as mentioning a bout with melanoma upon his back, which subsequently resulted in "giving a pound of flesh" to surgery.
Venter is mentioned, in the season finale of the first season of the science fiction series "Orphan Black", a joint production of Space and BBC America. In the episode, Venter is referenced as patenting an organism and encoding a message in the genome of that organism, an act repeated by the character of Aldous Leekie (played by Matt Frewer). While the clones fear that this renders them as nothing more than property, in reality, in the United States and Canada, where the show primarily takes place, such a patent became unenforceable due to constitutional provisions and laws against owning human beings.
Bibliography.
Venter has authored over 200 publications in scientific journals.

</doc>
<doc id="7552" url="https://en.wikipedia.org/wiki?curid=7552" title="Chemical evolution">
Chemical evolution

Chemical evolution may refer to:

</doc>
<doc id="7554" url="https://en.wikipedia.org/wiki?curid=7554" title="Carl Rogers">
Carl Rogers

Carl Ransom Rogers (January 8, 1902 – February 4, 1987) was an influential American psychologist and among the founders of the humanistic approach (or client-centered approach) to psychology. Rogers is widely considered to be one of the founding fathers of psychotherapy research and was honored for his pioneering research with the Award for Distinguished Scientific Contributions by the American Psychological Association (APA) in 1956.
The person-centered approach, his own unique approach to understanding personality and human relationships, found wide application in various domains such as psychotherapy and counseling (client-centered therapy), education (student-centered learning), organizations, and other group settings. For his professional work he was bestowed the Award for Distinguished Professional Contributions to Psychology by the APA in 1972. In a study by Haggbloom et al. (2002) using six criteria such as citations and recognition, Rogers was found to be the sixth most eminent psychologist of the 20th century and second, among clinicians, only to Sigmund Freud.
Biography.
Rogers was born on January 8, 1902, in Oak Park, Illinois, a suburb of Chicago. His father, Walter A. Rogers, was a civil engineer and his mother, Julia M. Cushing, was a homemaker and devout Pentecostal Christian. Carl was the fourth of their six children.
Rogers was intelligent and could read well before kindergarten. Following an education in a strict religious and ethical environment as an altar boy at the vicarage of Jimpley, he became a rather isolated, independent and disciplined person, and acquired a knowledge and an appreciation for the scientific method in a practical world. His first career choice was agriculture, at the University of Wisconsin–Madison, where he was a part of the fraternity of Alpha Kappa Lambda, followed by history and then religion. At age 20, following his 1922 trip to Peking, China, for an international Christian conference, he started to doubt his religious convictions. To help him clarify his career choice, he attended a seminar entitled "Why am I entering the Ministry?", after which he decided to change his career. In 1924, he graduated from University of Wisconsin and enrolled at Union Theological Seminary.
After two years he left the seminary to attend Teachers College, Columbia University, obtaining an MA in 1928 and a PhD in 1931. While completing his doctoral work, he engaged in child study. In 1930, Rogers served as director of the Society for the Prevention of Cruelty to Children in Rochester, New York. From 1935 to 1940 he lectured at the University of Rochester and wrote "The Clinical Treatment of the Problem Child" (1939), based on his experience in working with troubled children. He was strongly influenced in constructing his client-centered approach by the post-Freudian psychotherapeutic practice of Otto Rank. In 1940 Rogers became professor of clinical psychology at Ohio State University, where he wrote his second book, "Counseling and Psychotherapy" (1942). In it, Rogers suggested that the client, by establishing a relationship with an understanding, accepting therapist, can resolve difficulties and gain the insight necessary to restructure their life.
In 1945, he was invited to set up a counseling center at the University of Chicago. In 1947 he was elected President of the American Psychological Association. While a professor of psychology at the University of Chicago (1945–57), Rogers helped to establish a counseling center connected with the university and there conducted studies to determine the effectiveness of his methods. His findings and theories appeared in "Client-Centered Therapy" (1951) and "Psychotherapy and Personality Change" (1954). One of his graduate students at the University of Chicago, Thomas Gordon, established the Parent Effectiveness Training (P.E.T.) movement. In 1956, Rogers became the first President of the American Academy of Psychotherapists. He taught psychology at the University of Wisconsin, Madison (1957–63), during which time he wrote one of his best-known books, "On Becoming a Person" (1961). Carl Rogers and Abraham Maslow (1908–70) pioneered a movement called humanistic psychology which reached its peak in the 1960s. In 1961, he was elected a Fellow of the American Academy of Arts and Sciences. Carl Rogers was also one of the people who questioned the rise of McCarthyism in 1950s. Through articles, he criticized society of its backward-looking affinities.
Rogers continued teaching at University of Wisconsin until 1963, when he became a resident at the new Western Behavioral Sciences Institute (WBSI) in La Jolla, California. Rogers left the WBSI to help found the Center for Studies of the Person in 1968. His later books include "Carl Rogers on Personal Power" (1977) and "Freedom to Learn for the 80's" (1983). He remained a resident of La Jolla for the rest of his life, doing therapy, giving speeches and writing until his sudden death in 1987. In 1987, Rogers suffered a fall that resulted in a fractured pelvis: he had life alert and was able to contact paramedics. He had a successful operation, but his pancreas failed the next night and he died a few days later.
Rogers's last years were devoted to applying his theories in situations of political oppression and national social conflict, traveling worldwide to do so. In Belfast, Northern Ireland, he brought together influential Protestants and Catholics; in South Africa, blacks and whites; in Brazil people emerging from dictatorship to democracy; in the United States, consumers and providers in the health field. His last trip, at age 85, was to the Soviet Union, where he lectured and facilitated intensive experiential workshops fostering communication and creativity. He was astonished at the numbers of Russians who knew of his work.
Together with his daughter, Natalie Rogers, and psychologists Maria Bowen, Maureen O'Hara, and John K. Wood, between 1974 and 1984, Rogers convened a series of residential programs in the US, Europe, Brazil and Japan, the Person-Centered Approach Workshops, which focused on cross-cultural communications, personal growth, self-empowerment, and learning for social change.
Theory.
Rogers' theory of the self is considered to be humanistic, existential, and phenomenological. His theory is based directly on the "phenomenal field" personality theory of Combs and Snygg (1949). Rogers' elaboration of his own theory is extensive. He wrote 16 books and many more journal articles describing it. Prochaska and Norcross (2003) states Rogers "consistently stood for an empirical evaluation of psychotherapy. He and his followers have demonstrated a humanistic approach to conducting therapy and a scientific approach to evaluating therapy need not be incompatible."
Nineteen propositions.
His theory (as of 1951) was based on 19 propositions:
Additionally, Rogers is known for practicing "unconditional positive regard," which is defined as accepting a person "without negative judgment of ... person's basic worth."
Development of the personality.
With regard to development, Rogers described principles rather than stages. The main issue is the development of a self-concept and the progress from an undifferentiated self to being fully differentiated.
In the development of the self-concept, he saw conditional and unconditional positive regard as key. Those raised in an environment of unconditional positive regard have the opportunity to fully actualize themselves. Those raised in an environment of conditional positive regard feel worthy only if they match conditions (what Rogers describes as "conditions of worth") that have been laid down for them by others.
Fully functioning person.
Optimal development, as referred to in proposition 14, results in a certain process rather than static state. He describes this as "the good life", where the organism continually aims to fulfill its full potential. He listed the characteristics of a fully functioning person (Rogers 1961):
Incongruence.
Rogers identified the "real self" as the aspect of one's being that is founded in the actualizing tendency, follows organismic valuing, needs and receives positive regard and self-regard. It is the "you" that, if all goes well, you will become. On the other hand, to the extent that our society is out of sync with the actualizing tendency, and we are forced to live with conditions of worth that are out of step with organismic valuing, and receive only conditional positive regard and self-regard, we develop instead an "ideal self". By ideal, Rogers is suggesting something not real, something that is always out of our reach, the standard we cannot meet. This gap between the real self and the ideal self, the "I am" and the "I should" is called "incongruity".
Psychopathology.
Rogers described the concepts of "congruence" and "incongruence" as important ideas in his theory. In proposition #6, he refers to the actualizing tendency. At the same time, he recognized the need for "positive regard". In a fully congruent person realizing their potential is not at the expense of experiencing positive regard. They are able to lead lives that are authentic and genuine. Incongruent individuals, in their pursuit of positive regard, lead lives that include falseness and do not realize their potential. Conditions put on them by those around them make it necessary for them to forgo their genuine, authentic lives to meet with the approval of others. They live lives that are not true to themselves, to who they are on the inside out.
Rogers suggested that the incongruent individual, who is always on the defensive and cannot be open to all experiences, is not functioning ideally and may even be malfunctioning. They work hard at maintaining/protecting their self-concept. Because their lives are not authentic this is a difficult task and they are under constant threat. They deploy "defense mechanisms" to achieve this. He describes two mechanisms: "distortion" and "denial". Distortion occurs when the individual perceives a threat to their self-concept. They distort the perception until it fits their self-concept.
This defensive behavior reduces the consciousness of the threat but not the threat itself. And so, as the threats mount, the work of protecting the self-concept becomes more difficult and the individual becomes more defensive and rigid in their self structure. If the incongruence is immoderate this process may lead the individual to a state that would typically be described as neurotic. Their functioning becomes precarious and psychologically vulnerable. If the situation worsens it is possible that the defenses cease to function altogether and the individual becomes aware of the incongruence of their situation. Their personality becomes disorganised and bizarre; irrational behavior, associated with earlier denied aspects of self, may erupt uncontrollably.
Applications.
Person-centered therapy.
Rogers originally developed his theory to be the foundation for a system of therapy. He initially called this "non-directive therapy" but later replaced the term "non-directive" with the term "client-centered" and then later used the term "person-centered". Even before the publication of "Client-Centered Therapy" in 1951, Rogers believed that the principles he was describing could be applied in a variety of contexts and not just in the therapy situation. As a result, he started to use the term "person-centered approach" later in his life to describe his overall theory. Person-centered therapy is the application of the person-centered approach to the therapy situation. Other applications include a theory of personality, interpersonal relations, education, nursing, cross-cultural relations and other "helping" professions and situations. In 1946 Rogers co-authored "Counseling with Returned Servicemen," with John L. Wallen (the creator of the behavioral model known as "The Interpersonal Gap"), documenting the application of person-centered approach to counseling military personnel returning from the second world war.
The first empirical evidence of the effectiveness of the client-centered approach was published in 1941 at the Ohio State University by Elias Porter, using the recordings of therapeutic sessions between Carl Rogers and his clients. Porter used Rogers' transcripts to devise a system to measure the degree of directiveness or non-directiveness a counselor employed. The attitude and orientation of the counselor were demonstrated to be instrumental in the decisions made by the client.
Learner-centered teaching.
The application to education has a large robust research tradition similar to that of therapy with studies having begun in the late 1930s and continuing today (Cornelius-White, 2007). Rogers described the approach to education in "Client-Centered Therapy" and wrote "Freedom to Learn" devoted exclusively to the subject in 1969. "Freedom to Learn" was revised two times. The new Learner-Centered Model is similar in many regards to this classical person-centered approach to education.
Rogers and Harold Lyon began a book prior to Rogers death, entitled "On Becoming an Effective Teacher -- Person-centered Teaching, Psychology, Philosophy, and Dialogues with Carl R. Rogers and Harold Lyon", which was completed by Lyon and Reinhard Tausch and published in 2013 containing Rogers last unpublished writings on person-centered teaching. Rogers had the following five hypotheses regarding learner-centered education:
Rogerian rhetorical approach.
In 1970, Richard Young, Alton L. Becker, and Kenneth Pike published "Rhetoric: Discovery and Change", a widely influential college writing textbook that used a Rogerian approach to communication to revise the traditional Aristotelian framework for rhetoric. The Rogerian method of argument involves each side restating the other's position to the satisfaction of the other. In a paper, it can be expressed by carefully acknowledging and understanding the opposition, rather than dismissing them.
Cross-cultural relations.
The application to cross-cultural relations has involved workshops in highly stressful situations and global locations including conflicts and challenges in South Africa, Central America, and Ireland. Along with Alberto Zucconi and Charles Devonshire, he co-founded the Istituto dell'Approccio Centrato sulla Persona (Person-Centered Approach Institute) in Rome, Italy.
His international work for peace culminated in the Rust Peace Workshop which took place in November 1985 in Rust, Austria. Leaders from 17 nations convened to discuss the topic "The Central America Challenge". The meeting was notable for several reasons: it brought national figures together as people (not as their positions), it was a private event, and was an overwhelming positive experience where members heard one another and established real personal ties, as opposed to stiffly formal and regulated diplomatic meetings.
CIA.
Carl Rogers served on the board of the Human Ecology Fund from the late 50s into the 60s, which was a CIA funded organization that provided grants to researchers looking into personality. He received money as well. In addition, "he and other people in the field of personality and psychotherapy were given a lot of information about Khrushchev. 'We were asked to figure out what we thought of him and what would be the best way of dealing with him. And that seemed to be an entirely principled and legitimate aspect. I don't think we contributed very much, but, anyway, we tried.' ".
More on the Human Ecology Fund and Carl Rogers: [http://www.counsellingtutor.com/wp-content/uploads/2011/10/Carl-rogers-CIA.pdf, [https://file.wikileaks.org/file/AT-june07-Price-PT1.pdf]
Further reading.
Mearns and Thorne, Person Centred Counselling in Action (Sage 1999)

</doc>
<doc id="7555" url="https://en.wikipedia.org/wiki?curid=7555" title="Casimir effect">
Casimir effect

In quantum field theory, the Casimir effect and the Casimir–Polder force are physical forces arising from a quantized field. They are named after the Dutch physicist Hendrik Casimir.
The typical example is of the two uncharged conductive plates in a vacuum, placed a few nanometers apart. In a classical description, the lack of an external field means that there is no field between the plates, and no force would be measured between them. When this field is instead studied using the QED vacuum of quantum electrodynamics, it is seen that the plates do affect the virtual photons which constitute the field, and generate a net force—either an attraction or a repulsion depending on the specific arrangement of the two plates. Although the Casimir effect can be expressed in terms of virtual particles interacting with the objects, it is best described and more easily calculated in terms of the zero-point energy of a quantized field in the intervening space between the objects. This force has been measured and is a striking example of an effect captured formally by second quantization. However, the treatment of boundary conditions in these calculations has led to some controversy.
In fact, "Casimir's original goal was to compute the van der Waals force between polarizable molecules" of the conductive plates. Thus it can be interpreted without any reference to the zero-point energy (vacuum energy) of quantum fields.
Dutch physicists Hendrik Casimir and Dirk Polder at Philips Research Labs proposed the existence of a force between two polarizable atoms and between such an atom and a conducting plate in 1947, and, after a conversation with Niels Bohr who suggested it had something to do with zero-point energy, Casimir alone formulated the theory predicting a force between neutral conducting plates in 1948; the former is called the Casimir–Polder force while the latter is the Casimir effect in the narrow sense. Predictions of the force were later extended to finite-conductivity metals and dielectrics by Lifshitz and his students, and recent calculations have considered more general geometries. It was not until 1997, however, that a direct experiment, by S. Lamoreaux, described above, quantitatively measured the force (to within 15% of the value predicted by the theory), although previous work van Blockland and Overbeek (1978) had observed the force qualitatively, and indirect validation of the predicted Casimir energy had been made by measuring the thickness of liquid helium films by Sabisky and Anderson in 1972. Subsequent experiments approach an accuracy of a few percent.
Because the strength of the force falls off rapidly with distance, it is measurable only when the distance between the objects is extremely small. On a submicron scale, this force becomes so strong that it becomes the dominant force between uncharged conductors. In fact, at separations of 10 nm—about 100 times the typical size of an atom—the Casimir effect produces the equivalent of about 1 atmosphere of pressure (the precise value depending on surface geometry and other factors).
In modern theoretical physics, the Casimir effect plays an important role in the chiral bag model of the nucleon; in applied physics, it is significant in some aspects of emerging microtechnologies and nanotechnologies.
Any medium supporting oscillations has an analogue of the Casimir effect. For example, beads on a string as well as plates submerged in noisy water or gas illustrate the Casimir force.
Overview.
The Casimir effect can be understood by the idea that the presence of conducting metals and dielectrics alters the vacuum expectation value of the energy of the second quantized electromagnetic field. Since the value of this energy depends on the shapes and positions of the conductors and dielectrics, the Casimir effect manifests itself as a force between such objects.
Possible causes.
Vacuum energy.
The causes of the Casimir effect are described by quantum field theory, which states that all of the various fundamental fields, such as the electromagnetic field, must be quantized at each and every point in space. In a simplified view, a "field" in physics may be envisioned as if space were filled with interconnected vibrating balls and springs, and the strength of the field can be visualized as the displacement of a ball from its rest position. Vibrations in this field propagate and are governed by the appropriate wave equation for the particular field in question. The second quantization of quantum field theory requires that each such ball-spring combination be quantized, that is, that the strength of the field be quantized at each point in space. At the most basic level, the field at each point in space is a simple harmonic oscillator, and its quantization places a quantum harmonic oscillator at each point. Excitations of the field correspond to the elementary particles of particle physics. However, even the vacuum has a vastly complex structure, so all calculations of quantum field theory must be made in relation to this model of the vacuum.
The vacuum has, implicitly, all of the properties that a particle may have: spin, or polarization in the case of light, energy, and so on. On average, most of these properties cancel out: the vacuum is, after all, "empty" in this sense. One important exception is the vacuum energy or the vacuum expectation value of the energy. The quantization of a simple harmonic oscillator states that the lowest possible energy or zero-point energy that such an oscillator may have is
Summing over all possible oscillators at all points in space gives an infinite quantity. Since only "differences" in energy are physically measurable (with the notable exception of gravitation, which remains beyond the scope of quantum field theory), this infinity may be considered a feature of the mathematics rather than of the physics. This argument is the underpinning of the theory of renormalization. Dealing with infinite quantities in this way was a cause of widespread unease among quantum field theorists before the development in the 1970s of the renormalization group, a mathematical formalism for scale transformations that provides a natural basis for the process.
When the scope of the physics is widened to include gravity, the interpretation of this formally infinite quantity remains problematic. There is currently no compelling explanation as to why it should not result in a cosmological constant that is many orders of magnitude larger than observed. However, since we do not yet have any fully coherent quantum theory of gravity, there is likewise no compelling reason as to why it should.
Relativistic van der Waals force.
Alternatively, a 2005 paper by Robert Jaffe of MIT states that "Casimir effects
can be formulated and Casimir forces can be computed without reference to zero-point energies.
They are relativistic, quantum forces between charges and currents. The Casimir force (per unit
area) between parallel plates vanishes as alpha, the fine structure constant, goes to zero, and the standard result, which appears to be independent of alpha, corresponds to the alpha approaching infinity limit," and that "The Casimir force is simply the (relativistic, retarded) van der Waals force between the metal plates."
Coupled ground-state energy.
A third way of understanding Casimir forces has been suggested, based on canonical macroscopic quantum electrodynamics. In this interpretation, there exists a ground (vacuum) state of the "coupled" system of matter and fields, which determines the ground-state properties of the electromagnetic field, giving rise to a force. The Casimir force is fundamentally a property of the coupled system of matter and fields, in which the interaction between the plates is mediated by the zero-point fields. In more traditional interpretations, however, the emphasis has fallen either on the electromagnetic field or the fluctuating material in the plates.
Effects.
Casimir's observation was that the second-quantized quantum electromagnetic field, in the presence of bulk bodies such as metals or dielectrics, must obey the same boundary conditions that the classical electromagnetic field must obey. In particular, this affects the calculation of the vacuum energy in the presence of a conductor or dielectric.
Consider, for example, the calculation of the vacuum expectation value of the electromagnetic field inside a metal cavity, such as, for example, a radar cavity or a microwave waveguide. In this case, the correct way to find the zero-point energy of the field is to sum the energies of the standing waves of the cavity. To each and every possible standing wave corresponds an energy; say the energy of the "n"th standing wave is formula_2. The vacuum expectation value of the energy of the electromagnetic field in the cavity is then
with the sum running over all possible values of "n" enumerating the standing waves. The factor of 1/2 corresponds to the fact that the zero-point energies are being summed (it is the same 1/2 as appears in the equation formula_4). Written in this way, this sum is clearly divergent; however, it can be used to create finite expressions.
In particular, one may ask how the zero-point energy depends on the shape "s" of the cavity. Each energy level formula_2 depends on the shape, and so one should write formula_6 for the energy level, and formula_7 for the vacuum expectation value. At this point comes an important observation: the force at point "p" on the wall of the cavity is equal to the change in the vacuum energy if the shape "s" of the wall is perturbed a little bit, say by formula_8, at point "p". That is, one has
This value is finite in many practical calculations.
Attraction between the plates can be easily understood by focusing on the one-dimensional situation. Suppose that a moveable conductive plate is positioned at a short distance "a" from one of two widely separated plates (distance "L" apart). With "a" Â« "L", the states within the slot of width "a" are highly constrained so that the energy "E" of any one mode is widely separated from that of the next. This is not the case in open region "L", where there is a large number (about "L"/"a") of states with energy evenly spaced between "E" and the next mode in the narrow slot---in other words, all slightly larger than "E". Now on shortening "a" by d"a" (< 0), the mode in the slot shrinks in wavelength and therefore increases in energy proportional to -d"a"/"a", whereas all the outside "L"/"a" states lengthen and correspondingly lower energy proportional to d"a"/"L" (note the denominator). The net change is slightly negative, because all the "L"/"a" modes' energies are slightly larger than the single mode in the slot.
Derivation of Casimir effect assuming zeta-regularization.
In the original calculation done by Casimir, he considered the space between a pair of conducting metal plates at distance formula_10 apart. In this case, the standing waves are particularly easy to calculate, because the transverse component of the electric field and the normal component of the magnetic field must vanish on the surface of a conductor. Assuming the parallel plates lie in the xy-plane, the standing waves are
where formula_12 stands for the electric component of the electromagnetic field, and, for brevity, the polarization and the magnetic components are ignored here. Here, formula_13 and formula_14 are the wave vectors in directions parallel to the plates, and
is the wave-vector perpendicular to the plates. Here, "n" is an integer, resulting from the requirement that ψ vanish on the metal plates. The frequency of this wave is
where "c" is the speed of light. The vacuum energy is then the sum over all possible excitation modes. Since the area of the plates is large, we may sum by integrating over two of the dimensions in k-space. The assumption of periodic boundary conditions yields,
where "A" is the area of the metal plates, and a factor of 2 is introduced for the two possible polarizations of the wave. This expression is clearly infinite, and to proceed with the calculation, it is convenient to introduce a regulator (discussed in greater detail below). The regulator will serve to make the expression finite, and in the end will be removed. The zeta-regulated version of the energy per unit-area of the plate is
In the end, the limit formula_19 is to be taken. Here "s" is just a complex number, not to be confused with the shape discussed previously. This integral/sum is finite for "s" real and larger than 3. The sum has a pole at "s" = 3, but may be analytically continued to "s" = 0, where the expression is finite. The above expression simplifies to:
where polar coordinates formula_21 were introduced to turn the double integral into a single integral. The formula_22 in front is the Jacobian, and the formula_23 comes from the angular integration. The integral converges if Re["s"] > 3, resulting in
The sum diverges at "s" in the neighborhood of zero, but if the damping of large-frequency excitations corresponding to analytic continuation of the Riemann zeta function to "s" = 0 is assumed to make sense physically in some way, then one has
But 
and so one obtains
The analytic continuation has evidently lost an additive positive infinity, somehow exactly accounting for the zero-point energy (not included above) outside the slot between the plates, but which changes upon plate movement within a closed system. The Casimir force per unit area formula_28 for idealized, perfectly conducting plates with vacuum between them is
where
The force is negative, indicating that the force is attractive: by moving the two plates closer together, the energy is lowered. The presence of formula_30 shows that the Casimir force per unit area formula_28 is very small, and that furthermore, the force is inherently of quantum-mechanical origin.
NOTE: In Casimir's original derivation [http://www.dwc.knaw.nl/DL/publications/PU00018547.pdf], a moveable conductive plate is positioned at a short distance "a" from one of two widely separated plates (distance "L" apart). The 0-point energy on "both" sides of the plate is considered. Instead of the above "ad hoc" analytic continuation assumption, non-convergent sums and integrals are computed using Euler–Maclaurin summation with a regularizing function (e.g., exponential regularization) not so anomalous as formula_35 in the above.
More recent theory.
Casimir's analysis of idealized metal plates was generalized to arbitrary dielectric and realistic metal plates by Lifshitz and his students. Using this approach, complications of the bounding surfaces, such as the modifications to the Casimir force due to finite conductivity, can be calculated numerically using the tabulated complex dielectric functions of the bounding materials. Lifshitz' theory for two metal plates reduces to Casimir's idealized 1/"a"4 force law for large separations "a" much greater than the skin depth of the metal, and conversely reduces to the 1/"a"3 force law of the London dispersion force (with a coefficient called a Hamaker constant) for small "a", with a more complicated dependence on "a" for intermediate separations determined by the dispersion of the materials.
Lifshitz' result was subsequently generalized to arbitrary multilayer planar geometries as well as to anisotropic and magnetic materials, but for several decades the calculation of Casimir forces for non-planar geometries remained limited to a few idealized cases admitting analytical solutions. For example, the force in the experimental sphere–plate geometry was computed with an approximation (due to Derjaguin) that the sphere radius "R" is much larger than the separation "a", in which case the nearby surfaces are nearly parallel and the parallel-plate result can be adapted to obtain an approximate "R"/"a"3 force (neglecting both skin-depth and higher-order curvature effects). However, in the 2000s a number of authors developed and demonstrated a variety of numerical techniques, in many cases adapted from classical computational electromagnetics, that are capable of accurately calculating Casimir forces for arbitrary geometries and materials, from simple finite-size effects of finite plates to more complicated phenomena arising for patterned surfaces or objects of various shapes.
Measurement.
One of the first experimental tests was conducted by Marcus Sparnaay at Philips in Eindhoven (Netherlands), in 1958, in a delicate and difficult experiment with parallel plates, obtaining results not in contradiction with the Casimir theory, but with large experimental errors. Some of the experimental details as well as some background information on how Casimir, Polder and Sparnaay arrived at this point are highlighted in a 2007 interview with Marcus Sparnaay.
The Casimir effect was measured more accurately in 1997 by Steve K. Lamoreaux of Los Alamos National Laboratory, and by Umar Mohideen and Anushree Roy of the University of California, Riverside. In practice, rather than using two parallel plates, which would require phenomenally accurate alignment to ensure they were parallel, the experiments use one plate that is flat and another plate that is a part of a sphere with a large radius.
In 2001, a group (Giacomo Bressi, Gianni Carugno, Roberto Onofrio and Giuseppe Ruoso) at the University of Padua (Italy) finally succeeded in measuring the Casimir force between parallel plates using microresonators.
Regularisation.
In order to be able to perform calculations in the general case, it is convenient to introduce a regulator in the summations. This is an artificial device, used to make the sums finite so that they can be more easily manipulated, followed by the taking of a limit so as to remove the regulator.
The heat kernel or exponentially regulated sum is
where the limit formula_37 is taken in the end. The divergence of the sum is typically manifested as
for three-dimensional cavities. The infinite part of the sum is associated with the bulk constant "C" which "does not" depend on the shape of the cavity. The interesting part of the sum is the finite part, which is shape-dependent. The Gaussian regulator
is better suited to numerical calculations because of its superior convergence properties, but is more difficult to use in theoretical calculations. Other, suitably smooth, regulators may be used as well. The zeta function regulator
is completely unsuited for numerical calculations, but is quite useful in theoretical calculations. In particular, divergences show up as poles in the complex "s" plane, with the bulk divergence at "s" = 4. This sum may be analytically continued past this pole, to obtain a finite part at "s" = 0.
Not every cavity configuration necessarily leads to a finite part (the lack of a pole at "s" = 0) or shape-independent infinite parts. In this case, it should be understood that additional physics has to be taken into account. In particular, at extremely large frequencies (above the plasma frequency), metals become transparent to photons (such as X-rays), and dielectrics show a frequency-dependent cutoff as well. This frequency dependence acts as a natural regulator. There are a variety of bulk effects in solid state physics, mathematically very similar to the Casimir effect, where the cutoff frequency comes into explicit play to keep expressions finite. (These are discussed in greater detail in "Landau and Lifshitz", "Theory of Continuous Media".)
Generalities.
The Casimir effect can also be computed using the mathematical mechanisms of functional integrals of quantum field theory, although such calculations are considerably more abstract, and thus difficult to comprehend. In addition, they can be carried out only for the simplest of geometries. However, the formalism of quantum field theory makes it clear that the vacuum expectation value summations are in a certain sense summations over so-called "virtual particles".
More interesting is the understanding that the sums over the energies of standing waves should be formally understood as sums over the eigenvalues of a Hamiltonian. This allows atomic and molecular effects, such as the van der Waals force, to be understood as a variation on the theme of the Casimir effect. Thus one considers the Hamiltonian of a system as a function of the arrangement of objects, such as atoms, in configuration space. The change in the zero-point energy as a function of changes of the configuration can be understood to result in forces acting between the objects.
In the chiral bag model of the nucleon, the Casimir energy plays an important role in showing the mass of the nucleon is independent of the bag radius. In addition, the spectral asymmetry is interpreted as a non-zero vacuum expectation value of the baryon number, cancelling the topological winding number of the pion field surrounding the nucleon.
Dynamical Casimir effect.
The dynamical Casimir effect is the production of particles and energy from an accelerated "moving mirror". This reaction was predicted by certain numerical solutions to quantum mechanics equations made in the 1970s. In May 2011 an announcement was made by researchers at the Chalmers University of Technology, in Gothenburg, Sweden, of the detection of the dynamical Casimir effect. In their experiment, microwave photons were generated out of the vacuum in a superconducting microwave resonator. These researchers used a modified SQUID to change the effective length of the resonator in time, mimicking a mirror moving at the required relativistic velocity. If confirmed this would be the first experimental verification of the dynamical Casimir effect.
Analogies.
A similar analysis can be used to explain Hawking radiation that causes the slow "evaporation" of black holes (although this is generally visualized as the escape of one particle from a virtual particle-antiparticle pair, the other particle having been captured by the black hole).
Constructed within the framework of quantum field theory in curved spacetime, the dynamical Casimir effect has been used to better understand acceleration radiation such as the Unruh effect.
Dynamical Casimir effect and the Big Bang.
From a Scalar field model of the Big Bang the Geometric phase is used in a paper by O'Brien "Dynamical Casimir effect and the Big Bang" to relate the Hartle-Hawking State, Guth's and Linde's Inflationary Model and Baryon asymmetry into a single model.
Using the premise of the Feynman–Stueckelberg interpretation that antiparticles travel backwards in time to reflect off the infinite potential boundary of the Scalar field. The Scalar field undergoes a Dynamical Casimir effect during an adiabatic transition, this adiabatic transition is cyclic and satisfies the requirement of a cyclic adiabatic process. This provides a mechanism for matter-antimatter asymmetry and the formation of real on-mass matter, and all takes place as the universe inflates (Guth & Linde mechanism) from Euclidean geometry to a Minkowski spacetime satisfying the Hartle-Hawking State.
Repulsive forces.
There are few instances wherein the Casimir effect can give rise to repulsive forces between uncharged objects. Evgeny Lifshitz showed (theoretically) that in certain circumstances (most commonly involving liquids), repulsive forces can arise. This has sparked interest in applications of the Casimir effect toward the development of levitating devices. An experimental demonstration of the Casimir-based repulsion predicted by Lifshitz was recently carried out by Munday et al. Other scientists have also suggested the use of gain media to achieve a similar levitation effect, though this is controversial because these materials seem to violate fundamental causality constraints and the requirement of thermodynamic equilibrium (Kramers-Kronig relations). Casimir and Casimir-Polder repulsion can in fact occur for sufficiently anisotropic electrical bodies; for a review of the issues involved with repulsion see Milton et al.
Applications.
It has been suggested that the Casimir forces have application in nanotechnology, in particular silicon integrated circuit technology based micro- and nanoelectromechanical systems, silicon array propulsion for space drives, and so-called Casimir oscillators.
The Casimir effect shows that quantum field theory allows the energy density in certain regions of space to be negative relative to the ordinary vacuum energy, and it has been shown theoretically that quantum field theory allows states where the energy can be "arbitrarily" negative at a given point, Many physicists such as Stephen Hawking, Kip Thorne, and others therefore argue that such effects might make it possible to stabilize a traversable wormhole. Miguel Alcubierre has suggested using the effect to obtain the negative energy density required for his Alcubierre Drive.
On 4 June 2013 it was reported that a conglomerate of scientists from Hong Kong University of Science and Technology, University of Florida, Harvard University, Massachusetts Institute of Technology, and Oak Ridge National Laboratory have for the first time demonstrated a compact integrated silicon chip that can measure the Casimir force.

</doc>
<doc id="7558" url="https://en.wikipedia.org/wiki?curid=7558" title="Coin">
Coin

A coin is a piece of hard material used primarily as a medium of exchange or legal tender. They are standardized in weight, and produced in large quantities at a mint in order to facilitate trade. They are most often issued by a government.
Coins are usually metal or alloy, or sometimes made of synthetic materials. They are usually disc shaped. Coins made of valuable metal are stored in large quantities as bullion coins. Other coins are used as money in everyday transactions, circulating alongside banknotes. Usually the highest value coin in circulation (i.e. excluding bullion coins) is worth less than the lowest-value note. In the last hundred years, the face value of circulation coins has occasionally been lower than the value of the metal they contain, for example due to inflation. If the difference becomes significant, the issuing authority may decide to withdraw these coins from circulation, or the public may decide to melt the coins down or hoard them (see Gresham's law).
Exceptions to the rule of face value being higher than content value also occur for some bullion coins made of copper, silver, or gold (and, rarely, other metals, such as platinum or palladium), intended for collectors or investors in precious metals. Examples of modern gold collector/investor coins include the British sovereign minted by the United Kingdom, the American Gold Eagle minted by the United States, the Canadian Gold Maple Leaf minted by Canada, and the Krugerrand, minted by South Africa. While the Eagle, Maple Leaf, and Sovereign coins have nominal (purely symbolic) face values; the Krugerrand does not.
Historically, a great quantity of coinage metals (including alloys) and other materials (e.g. porcelain) have been used to produce coins for circulation, collection, and metal investment: bullion coins often serve as more convenient stores of assured metal quantity and purity than other bullion.
History.
The first coins were developed independently in Iron Age Anatolia and Archaic Greece, India and China around the 7th and 6th centuries BCE. Coins spread rapidly in the 6th and 5th centuries BCE, throughout Greece and Persia, and further to the Balkans.
Standardized Roman currency was used throughout the Roman Empire. Important Roman gold and silver coins were continued into the Middle Ages (see Gold dinar, Solidus, Aureus, Denarius). Ancient and early medieval coins in theory had the value of their metal content, although there have been many instances throughout history of the metal content of coins being debased, so that the inferior coins were worth less in metal than their face value. Fiat money first arose in medieval China, with the jiaozi paper money. Early paper money was introduced in Europe in the later Middle Ages, but some coins continued to have the value of the gold or silver they contained throughout the Early Modern period. The penny was minted as a silver coin until the 17th century.
The first copper pennies were minted in the United States in the 1790s. Silver content was reduced in many coins in the 19th century (use of billon), and the first coins made entirely of base metal (e.g. nickel, cupronickel, aluminium bronze), representing values higher than the value of their metal, were minted in the mid 19th century.
Coins were an evolution of "currency" systems of the Late Bronze Age, where standard-sized ingots, and tokens such as knife money, were used to store and transfer value. In the late Chinese Bronze Age, standardized cast tokens were made, such as those discovered in a tomb near Anyang. These were replicas in bronze of earlier Chinese currency, cowrie shells, so they were named Bronze Shell.
Iron Age.
According to Aristotle (fr. 611,37,ed. V. Rose) and Pollux (Onamastikon IX.83), the first issuer of coins was Hermodike of Kyme
The earliest coins are mostly associated with Iron Age Anatolia, especially with the kingdom of Lydia.
Early electrum coins were not standardized in weight, and in their earliest stage may have been ritual objects, such as badges or medals, issued by priests.
Many early Lydian and Greek coins were minted under the authority of private individuals and are thus more akin to tokens or badges than to modern coins, though due to their numbers it is evident that some were official state issues, with King Alyattes of Lydia being a frequently mentioned originator of coinage.
The first Lydian coins were made of electrum, a naturally occurring alloy of silver and gold that was further alloyed with added silver and copper.
Most of the early Lydian coins include no writing ("legend" or "inscription"), only an image of a symbolic animal. Therefore, the dating of these coins relies primarily on archaeological evidence, with the most commonly cited evidence coming from excavations at the Temple of Artemis at Ephesus, also called the Ephesian Artemision (which would later evolve into one of the Seven Wonders of the Ancient World). Because the oldest lion head "coins" were discovered in that temple, and they do not appear to have been used in commerce, these objects may not have been coins but badges or medals issued by the priests of that temple. Anatolian Artemis was the "Πὀτνια Θηρῶν" (Potnia Thêrôn, "Mistress of Animals"), whose symbol was the stag.
A small percentage of early Lydian/Greek coins have a legend. A famous early electrum coin, the most ancient inscribed coin at present known, is from nearby Caria. This coin has a Greek legend reading "phaenos emi sema" interpreted variously as "I am the badge of Phanes", or "I am the sign of light", or "I am the tomb of light", or "I am the tomb of Phanes".
The coins of Phanes are known to be amongst the earliest of Greek coins, a hemihekte of the issue was found in the foundation deposit of the temple of Artemis at Ephesos (the oldest deposit of electrum coins discovered). One assumption is that Phanes was a wealthy merchant, another that this coin is associated with Apollo-Phanes and, due to the Deer, with Artemis (twin sister of the god of light Apollo-Phaneos). Although only seven Phanes type coins were discovered, it is also notable that 20% of all early electrum coins also have the lion of Artemis and the sun burst of Apollo-Phaneos.
Alternatively, Phanes may have been the Halicarnassian mercenary of Amasis mentioned by Herodotus, who escaped to the court of Cambyses, and became his guide in the invasion of Egypt in 527 or 525 BCE. According to Herodotus, this Phanes was buried alive by a sandstorm, together with 50,000 Persian soldiers, while trying to conquer the temple of Amun–Zeus in Egypt. The fact that the Greek word "Phanes" also means light (or lamp), and the word "sema" also means tomb makes this coin a famous and controversial one.
Another candidate for the site of the earliest coins is Aegina, where Chelone ("turtle") coins were first minted on 700 BCE, either by the local Aegina people or by Pheidon king of Argos (who first set the standards of weights and measures). In the Bibliothèque Nationale, Paris, there is a unique electrum stater of Aegina.
Coins from Athens and Corinth appeared shortly thereafter, known to exist at least since the late 6th century BCE.
Classical antiquity.
Coinage followed Greek colonization and influence first around the Mediterranean and soon after to North Africa (including Egypt), Syria, Persia, and the Balkans.
Coins were minted in the Achaemenid Empire, including the gold "darics" and silver "sigloi". With the Achemenid conquest of Gandhara under Darius the Great c. 520 BCE, the practice spread to the Indo-Gangetic Plain. The coins of this period were called "Puranas", "Karshapanas" or "Pana". These earliest Indian coins, however, are unlike those circulated in Persia, which were derived from the Greek/Anatolian type; they not disk-shaped but rather stamped bars of metal, suggesting that the innovation of stamped currency was added to a pre-existing form of token currency which had already been present in the Mahajanapada kingdoms of the Indian Iron Age. Mahajanapadas that minted their own coins included Gandhara, Kuntala, Kuru, Panchala, Shakya, Surasena and Surashtra.
In China, early round coins appeared in the 4th century BCE.
The first Roman coins, which were crude, heavy cast bronzes, were issued c. 289 BCE.
Middle Ages.
The first European coin to use Arabic numerals to date the year in which the coin was minted was the St. Gall silver "Plappart" of 1424.
Value.
Currency.
Most coins presently are made of a base metal, and their value comes from their status as fiat money. This means that the value of the coin is decreed by government fiat (law), and thus is determined by the free market only in as much as national currencies are used in domestic trade and also traded internationally on foreign exchange markets. Thus, these coins are monetary tokens, just as paper currency is: they are usually not backed by metal, but rather by some form of government guarantee. Some have suggested that such coins not be considered to be "true coins" (see below). Thus, there is very little economic difference between notes and coins of equivalent face value.
Coins may be in circulation with fiat values lower than the value of their component metals, but they are never initially issued with such value, and the shortfall only arises over time due to inflation, as market values for the metal overtake the fiat declared face value of the coin. Examples are the pre-1965 US dime, quarter, half dollar, and dollar, US nickel, and pre-1982 US penny. As a result of the increase in the value of copper, the United States greatly reduced the amount of copper in each penny. Since mid-1982, United States pennies are made of 97.5% zinc, with the remaining 2.5% being a coating of copper. Extreme differences between fiat values and metal values of coins causes coins to be hoarded or removed from circulation by illicit smelters in order to realise the value of their metal content. This is an example of Gresham's law. The United States Mint, in an attempt to avoid this, implemented new interim rules on December 14, 2006, subject to public comment for 30 days, which criminalized the melting and export of pennies and nickels. Violators can be fined up to $10,000 and/or imprisoned for up to five years.
Collector's item.
A coin's value as a collector's item or as an investment generally depends on its condition, specific historical significance, rarity, quality, beauty of the design and general popularity with collectors. If a coin is greatly lacking in all of these, it is unlikely to be worth much. The value of bullion coins is also influenced to some extent by those factors, but is largely based on the value of their gold, silver, or platinum content. Sometimes non-monetized bullion coins such as the Canadian Maple Leaf and the American Gold Eagle are minted with nominal face values less than the value of the metal in them, but as such coins are never intended for circulation, these face values have no relevance.
Medium of expression.
Coins can be used as creative medium of expression – from fine art sculpture to the penny machines that can be found in most amusement parks. In the Code of Federal Regulations (CFR) in the United States there are some regulations specific to nickels and pennies that are informative on this topic. 31 CFR § 82.1 forbids unauthorized persons from exporting, melting, or treating any 5 or 1 cent coins.
This has been a particular problem with nickels and dimes (and with some comparable coins in other currencies) because of their relatively low face value and unstable commodity prices. For a while the copper in US pennies was worth more than one cent, so people would hoard pennies and then melt them down for their metal value. It cost more than face value to manufacture pennies or nickels, so any widespread loss of the coins in circulation could be expensive for the US Treasury. This was more of a problem when coins were still made of precious metals like silver and gold, so strict laws against alteration make more sense historically.
31 CFR § 82.2 goes on to state that: "(b) The prohibition contained in § 82.1 against the treatment of 5-cent coins and one-cent coins shall not apply to the treatment of these coins for educational, amusement, novelty, jewelry, and similar purposes as long as the volumes treated and the nature of the treatment makes it clear that such treatment is not intended as a means by which to profit solely from the value of the metal content of the coins."
Debasement.
Throughout history, monarchs and governments have often created more coinage than their supply of precious metals would allow if the coins were pure metal. By replacing some fraction of a coin's precious metal content with a base metal (often copper or nickel), the intrinsic value of each individual coin was reduced (thereby "debasing" the money), allowing the coining authority to produce more coins than would otherwise be possible. Debasement occasionally occurs in order to make the coin physically harder and therefore less likely to be worn down as quickly, but the more usual reason is to profit from the difference between face value and metal value. Debasement of money almost always leads to price inflation. Sometimes price controls are at the same time also instituted by the governing authority, but historically these have generally proved unworkable.
The United States is unusual in that it has only slightly modified its coinage system (except for the images and symbols on the coins, which have changed a number of times) to accommodate two centuries of inflation. The one-cent coin has changed little since 1856 (though its composition was changed in 1982 to remove virtually all copper from the coin) and still remains in circulation, despite a greatly reduced purchasing power. On the other end of the spectrum, the largest coin in common circulation is valued at 25 cents, a very low value for the largest denomination coin compared to many other countries. Increases in the prices of copper, nickel, and zinc meant that both the US one- and five-cent coins became worth more for their raw metal content than their face (fiat) value. In particular, copper one-cent pieces (those dated prior to 1982 and some 1982-dated coins) contained about two cents' worth of copper.
Some denominations of circulating coins that were formerly minted in the United States are no longer made. These include coins with a face value of a half cent, two cents, three cents, and twenty cents. (The half dollar and dollar coins are still produced, but mostly for vending machines and collectors.) In the past, the US also coined the following denominations for circulation in gold: One dollar, $2.50, three dollars, five dollars, ten dollars, and twenty dollars. In addition, cents were originally slightly larger than the modern quarter and weighed nearly half an ounce, while five-cent coins (known then as "half dimes") were smaller than a dime and made of a silver alloy. Dollar coins were also much larger, and weighed approximately an ounce. One-dollar gold coins are no longer produced and rarely used. The US also issues bullion and commemorative coins with the following denominations: 50¢, $1, $5, $10, $25, $50, and $100.
Other uses.
Some convicted criminals from the British Isles who were sentenced to transportation to Australia in the 18th and 19th centuries used coins to leave messages of remembrance to loved ones left behind in Britain. The coins were defaced, smoothed and inscribed, either by stippling or engraving, with sometimes touching words of loss. These coins were called "convict love tokens" or "leaden hearts". A number of these tokens are in the collection of the National Museum of Australia.
Features of modern coins.
Circulating coins commonly suffered from "shaving" or "clipping": the public would cut off small amounts of precious metal from their edges to sell it and then pass on the mutilated coins at full value. Unmilled British sterling silver coins were sometimes reduced to almost half their minted weight. This form of debasement in Tudor England was commented on by Sir Thomas Gresham, whose name was later attached to Gresham's law. The monarch would have to periodically recall circulating coins, paying only the bullion value of the silver, and reminting them. This, also known as recoinage, is a long and difficult process that was done only occasionally. Many coins have milled or reeded edges, originally designed to make it easier to detect clipping.
The side of a coin carrying an image of a monarch or other authority, or a national emblem, is usually called the "obverse", or colloquially, "heads"; "see also List of people on coins". The other side, which may carry the denomination, is usually called the "reverse", or colloquially, "tails". The year of minting is usually shown on the obverse, although some Chinese coins, most Canadian coins, the pre-2008 British 20p coin, and all Japanese coins, are exceptions.
In cases where a correctly oriented coin is flipped about its horizontal axis to show the other side correctly oriented, the coin is said to have coin orientation. In cases where a coin is flipped about its vertical axis to show the other side correctly oriented, it is said to have medallic orientation. While coins of the United States dollar display coin orientation, those of the Euro and pound sterling have medallic orientation.
Bimetallic coins are sometimes used for higher values and for commemorative purposes. In the 1990s, France used a tri-metallic coin. Common circulating bimetallic examples include the €1, €2, British £2 and Canadian $2 and several Peso coins in Mexico.
The "exergue" is the space on a coin beneath the main design, often used to show the coin's date, although it is sometimes left blank or containing a mint mark, privy mark, or some other decorative or informative design feature. Many coins do not have an exergue at all, especially those with few or no legends, such as the Victorian bun penny.
Not all coins are round. The Australian 50 cent coin, for example, has twelve flat sides. Some coins have wavy edges, e.g. the $2 and 20-cent coins of Hong Kong and the 10 cent coins of Bahamas. Some are square-shaped, such as the 15 cent coin of the Bahamas. During the 1970s, Swazi coins were minted in several shapes, including squares, polygons, and wavy edged circles with 8 and 12 waves.
Some other coins, like the British 20 and 50 pence coins and the Canadian Loonie, have an odd number of sides, with the edges rounded off. This way the coin has a constant diameter, recognisable by vending machines whichever direction it is inserted.
A triangular coin with a face value of £5 (produced to commemorate the 2007/2008 Tutankhamun exhibition at The O2 Arena) was commissioned by the Isle of Man: it became legal tender on 6 December 2007. Other triangular coins issued earlier include: Cabinda coin, Bermuda coin, 2 Dollar Cook Islands 1992 triangular coin, Uganda Millennium Coin and Polish Sterling-Silver 10-Zloty Coin.
Guitar-shaped and motorcycle-shaped coins were once issued in Somalia. Poland once issued a fan-shaped 10 złoty coin and the 2002 $10 coin from Nauru was Europe-shaped.
Some mediaeval coins, called bracteates, were so thin they were struck on only one side.
Many coins over the years have been manufactured with integrated holes such as Chinese "cash" coins, Japanese coins, Colonial French coins, etc.
The Royal Canadian Mint is now able to produce holographic-effect gold and silver coinage. However, this procedure is not limited to only bullion or commemorative coinage. The 500 yen coin from Japan was subject to a massive amount of counterfeiting. The Japanese government in response produced a circulatory coin with a holographic image.
The Royal Canadian Mint has also released several coins that are coloured, the first of which was in commemoration of Remembrance Day. The subject was a coloured poppy on the reverse of a 25 cent piece.
An example of non-metallic composite coins (sometimes incorrectly called plastic coins) was introduced into circulation in Transnistria on 22 August 2014. Most of these coins are also non-circular, with different shapes corresponding to different coin values.
For a list of many pure metallic elements and their alloys which have been used in actual circulation coins and for trial experiments, see coinage metals.
Physics.
Flipping.
Coins are popularly used as a sort of two-sided dice; in order to choose between two options with a random possibility, one choice will be labeled "heads" and the other "tails", and a coin will be flipped or tossed to see whether the heads or tails side comes up on top – see coin flipping. Mathematically, this is known as a Bernoulli trial: a fair coin is defined to have the probability of heads (in the parlance of Bernoulli trials, a "success") of exactly 0.5.
Spinning.
Coins can also be spun on a flat surface such as a table. This results in the following phenomenon: as the coin falls over and rolls on its edge, it spins faster and faster (formally, the precession rate of the symmetry axis of the coin, i.e., the axis passing from one face of the coin to the other) before coming to an abrupt stop. This is mathematically modeled as a finite-time singularity – the precession rate is accelerating to infinity, before it suddenly stops, and has been studied using high speed photography and devices such as Euler's Disk. The slowing down is predominantly caused by rolling friction (air resistance is minor), and the singularity (divergence of the precession rate) can be modeled as a power law with exponent approximately −1/3.
Chemistry.
Odor.
Iron coins have a characteristic metallic smell that is produced upon contact with oils in the skin. Perspiration is chemically reduced upon contact with iron, which causes the skin oils to decompose, forming the volatile molecule 1-octen-2-one.

</doc>
<doc id="7560" url="https://en.wikipedia.org/wiki?curid=7560" title="College of the City of New York">
College of the City of New York

College of the City of New York may refer to:

</doc>
<doc id="7561" url="https://en.wikipedia.org/wiki?curid=7561" title="Classical Kuiper belt object">
Classical Kuiper belt object

A classical Kuiper belt object, also called a cubewano ( "QB1-o"), is a low-eccentricity Kuiper belt object (KBO) that orbits beyond Neptune and is not controlled by an orbital resonance with Neptune. Cubewanos have orbits with semi-major axes in the 40–50 AU range and, unlike Pluto, do not cross Neptune’s orbit. That is, they have low-eccentricity and sometimes low-inclination orbits like the classical planets. 
The name "cubewano" derives from the first trans-Neptunian object (TNO) found after Pluto and Charon, . Similar objects found later were often called "QB1-o's", or "cubewanos", after this object, though the term "classical" is much more frequently used in the scientific literature.
Objects identified as cubewanos include:
Haumea was provisionally listed as a cubewano by the Minor Planet Center in 2006, but turned out to be resonant.
Orbits: 'hot' and 'cold' populations.
Most cubewanos are found between the 2:3 orbital resonance with Neptune (populated by plutinos) and the 1:2 resonance. 50000 Quaoar, for example, has a near-circular orbit close to the ecliptic. Plutinos, on the other hand, have more eccentric orbits bringing some of them closer to the Sun than Neptune.
The majority of objects (the so-called 'cold population'), have low inclinations and near-circular orbits. A smaller population (the 'hot population') is characterised by highly inclined, more eccentric orbits.
The Deep Ecliptic Survey reports the distributions of the two populations; one with the inclination centered at 4.6° (named "Core") and another with inclinations extending beyond 30° ("Halo").
Distribution.
The vast majority of KBOs (more than two-thirds) have inclinations of less than 5° and eccentricities of less than 0.1. Their semi-major axes show a preference for the middle of the main belt; arguably, smaller objects close to the limiting resonances have been either captured into resonance or have their orbits modified by Neptune.
The 'hot' and 'cold' populations are strikingly different: more than 30% of all cubewanos are in low inclination, near-circular orbits. The parameters of the plutinos’ orbits are more evenly distributed, with a local maximum in moderate eccentricities in 0.15–0.2 range and low inclinations 5–10°.
See also the comparison with scattered disk objects.
When the orbital eccentricities of cubewanos and plutinos are compared, it can be seen that the cubewanos form a clear 'belt' outside Neptune's orbit, whereas the plutinos approach, or even cross Neptune's orbit. When orbital inclinations are compared, 'hot' cubewanos can be easily distinguished by their higher inclinations, as the plutinos typically keep orbits below 20°. (No clear explanation currently exists for the inclinations of 'hot' cubewanos.)
Cold and hot populations: physical characteristics.
In addition to the distinct orbital characteristics, the two populations display different physical characteristics.
The difference in colour between the red cold population and more heterogeneous hot population was observed as early as in 2002.
Recent studies, based on a larger data set, indicate the cut-off inclination of 12° (instead of 5°) between the cold and hot populations and confirm the distinction between the homogenous red cold population and the bluish hot population.
Another difference between the low-inclination (cold) and high-inclination (hot) classical objects is the observed number of binary objects. Binaries are quite common on low-inclination orbits and are typically similar-brightness systems. Binaries are less common on high-inclination orbits and their components typically differ in brightness. This correlation, together with the differences in colour, support further the suggestion that the currently observed classical objects belong to at least two different overlapping populations, with different physical properties and orbital history.
Toward a formal definition.
There is no official definition of 'cubewano' or 'classical KBO'. However, the terms are normally used to refer to objects free from significant perturbation from Neptune, thereby excluding KBOs in orbital resonance with Neptune (resonant trans-Neptunian objects). The Minor Planet Center (MPC) and the Deep Ecliptic Survey (DES) do not list cubewanos (classical objects) using the same criteria. Many TNOs classified as cubewanos by the MPC are classified as ScatNear (possibly scattered by Neptune) by the DES. Dwarf planet Makemake is such a borderline classical cubewano/scatnear object. may be an inner cubewano near the plutinos. Furthermore, there is evidence that the Kuiper belt has an 'edge', in that an apparent lack of low-inclination objects beyond 47–49 AU was suspected as early as 1998 and shown with more data in 2001. Consequently, the traditional usage of the terms is based on the orbit’s semi-major axis, and includes objects situated between the 2:3 and 1:2 resonances, that is between 39.4 and 47.8 AU (with exclusion of these resonances and the minor ones in-between).
These definitions lack precision: in particular the boundary between the classical objects and the scattered disk remains blurred. As of 2010, there are 377 objects with perihelion (q) > 40 AU and aphelion (Q) < 47 AU.
DES classification.
Introduced by the report from the Deep Ecliptic Survey by J. L. Elliott et al. in 2005 uses formal criteria based on the mean orbital parameters. Put informally, the definition includes the objects that have never crossed the orbit of Neptune. According to this definition, an object qualifies as a classical KBO if:
SSBN07 classification.
An alternative classification, introduced by B. Gladman, B. Marsden and C. van Laerhoven in 2007, uses a 10-million-year orbit integration instead of the Tisserand's parameter. Classical objects are defined as not resonant and not being currently scattered by Neptune.
Formally, this definition includes as "classical" all objects with their "current" orbits that
Unlike other schemes, this definition includes the objects with major semi-axis less than 39.4 AU (2:3 resonance)—termed inner classical belt, or more than 48.7 (1:2 resonance) – termed outer classical belt, and reserves the term main classical belt for the orbits between these two resonances.
Families.
The first known collisional family in the classical Kuiper belt—a group of objects thought to be remnants from the breakup of a single body—is the Haumea family. It includes Haumea, its moons, and seven smaller bodies.† The objects not only follow similar orbits but also share similar physical characteristics. Unlike many other KBO their surface contains large amounts of ice (H2O) and no or very little tholins. The surface composition is inferred from their neutral (as opposed to red) colour and deep absorption at 1.5 and 2. μm in infrared spectrum.
†As of 2008. The four brightest objects of the family are situated on the graphs "inside" the circle representing Haumea.
List of objects.
Here is a very generic list of classical Kuiper belt objects. As of 2014, there are about 473 objects with q > 40 (AU) and Q < 48 (AU).

</doc>
