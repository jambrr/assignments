<doc id="80197" url="https://en.wikipedia.org/wiki?curid=80197" title="Soviet–Afghan War">
Soviet–Afghan War

The Soviet–Afghan War lasted over nine years from December 1979 to February 1989. Insurgent groups ("the Mujahideen") fought against the Soviet Army and allied Afghan forces. Between 850,000–1.5 million civilians were killed and millions of Afghans fled the country as refugees, mostly to Pakistan and Iran.
Prior to the arrival of Soviet troops, the pro-Soviet Nur Mohammad Taraki government took power in a 1978 coup and initiated a series of radical modernization reforms throughout the country. Vigorously suppressing any opposition from among the traditional Muslim Afghans, the government arrested thousands and executed as many as 27,000 political prisoners. By April 1979 large parts of the country were in open rebellion and by December the government had lost control of territory outside of the cities. In response to Afghan government requests, the Soviet government under leader Leonid Brezhnev first sent covert troops to advise and support the Afghan government, but on December 24, 1979, began the first of the 40th Army. Arriving in the capital Kabul, they staged a coup, killing the Afghan President, and installing a rival Afghan socialist (Babrak Karmal).
In January 1980, foreign ministers from 34 nations of the Islamic Conference adopted a resolution demanding "the immediate, urgent and unconditional withdrawal of Soviet troops" from Afghanistan, while the UN General Assembly passed a resolution protesting the Soviet intervention by a vote of 104–18. Afghan insurgents began to receive massive amounts of aid, military training in neighboring Pakistan and China, paid for primarily by the United States and Arab monarchies in the Persian Gulf. As documented by the National Security Archive, "the Central Intelligence Agency (CIA) played a significant role in inserting U.S. influence in Afghanistan by funding military operations designed to frustrate the Soviet invasion of that country. CIA covert action worked through Pakistani intelligence services to reach Afghani rebel groups." Soviet troops occupied the cities and main arteries of communication, while the mujahideen waged guerrilla war in small groups operating in the almost 80 percent of the country that escaped government and Soviet control. Soviets used their air power to deal harshly with both rebels and civilians, leveling villages to deny safe haven to the enemy, destroying vital irrigation ditches, and laying millions of land mines.
By the mid-1980s the Soviet contingent was increased to 108,800 and fighting increased throughout the country, but the military and diplomatic cost of the war to the USSR was high. By mid-1987 the Soviet Union, now under reformist leader Mikhail Gorbachev, announced it would start withdrawing its forces. The final troop withdrawal started on May 15, 1988, and ended on February 15, 1989. The war was considered part of the Cold War. Due to its length it has sometimes been referred to as the "Soviet Union's Vietnam War" or the "Bear Trap" by the Western media, and thought to be a contributing factor to the fall of the Soviet Union.
Background.
The Democratic Republic of Afghanistan was formed after the Saur Revolution on April 27, 1978. The government was one with a pro-poor, pro-farmer and socialist agenda. It had close relations with the Soviet Union. On December 5, 1978, a friendship treaty was signed between the Soviet Union and Afghanistan.
Russian military involvement in Afghanistan has a long history, going back to Tsarist expansions in the so-called "Great Game" between Russia and Britain. This began in the 19th century with such events as the Panjdeh Incident, a military skirmish that occurred in 1885 when Russian forces seized Afghan territory south of the Oxus River around an oasis at Panjdeh. This interest in the region continued on through the Soviet era, with billions in economic and military aid sent to Afghanistan between 1955 and 1978.
In February 1979 the United States Ambassador to Afghanistan, Adolph Dubs, was kidnapped by Setami Milli militants and was later killed during an assault carried out by the Afghan police, assisted by Soviet advisers. Dubs' death led to a major deterioration in Afghanistan–United States relations.
In Southwestern Asia, drastic changes were taking place concurrent with the upheavals in Afghanistan. In February 1979, the Iranian Revolution ousted the American-backed Shah from Iran, losing the United States one of its most powerful allies. The United States then deployed twenty ships to the Persian Gulf and the Arabian Sea including two aircraft carriers, and there was a constant stream of threats of warfare between the US and Iran.
March 1979 marked the signing of the US-backed peace agreement between Israel and Egypt. The Soviet leadership saw the agreement as a major advantage for the United States. One Soviet newspaper stated that Egypt and Israel were now "gendarmes of the Pentagon". The Soviets viewed the treaty not only as a peace agreement between their erstwhile allies in Egypt and the US-supported Israelis but also as a military pact. In addition, the US sold more than 5,000 missiles to Saudi Arabia and also supplied the Royalist rebels in the North Yemen Civil War against the Nasserist government. Also, the Soviet Union's previously strong relations with Iraq had recently soured. In June 1978, Iraq began entering into friendlier relations with the Western world and buying French and Italian-made weapons, though the vast majority still came from the Soviet Union, its Warsaw Pact allies, and China.
Saur Revolution.
King Mohammed Zahir Shah ascended to the throne and reigned from 1933 to 1973. Zahir's cousin, Mohammad Daoud Khan, served as Prime Minister from 1954 to 1963. The Marxist People's Democratic Party of Afghanistan's (PDPA's) strength grew considerably in these years. In 1967, the PDPA split into two rival factions, the Khalq (Masses) faction headed by Nur Muhammad Taraki and Hafizullah Amin and the Parcham (Flag) faction led by Babrak Karmal.
Former Prime Minister Daoud seized power in a military coup on July 17, 1973, after allegations of corruption and poor economic conditions against the king's government. Daoud put an end to the monarchy, and his time in power was widely popular among the general populace but unpopular among PDPA supporters.
Intense opposition from factions of the PDPA was sparked by the repression imposed on them by Daoud's regime and the death of a leading PDPA member, Mir Akbar Khyber. The mysterious circumstances of Khyber's death sparked massive anti-Daoud demonstrations in Kabul, which resulted in the arrest of several prominent PDPA leaders.
On April 27, 1978, the Afghan army, which had been sympathetic to the PDPA cause, overthrew and executed Daoud along with members of his family. Nur Muhammad Taraki, Secretary General of the PDPA, became President of the Revolutionary Council and Prime Minister of the newly established Democratic Republic of Afghanistan.
Factions inside the PDPA.
After the revolution, Taraki assumed the Presidency, Prime Ministership and General Secretaryship of the PDPA. The government was divided along factional lines, with President Taraki and Deputy Prime Minister Hafizullah Amin of the Khalq faction against Parcham leaders such as Babrak Karmal and Mohammad Najibullah. Within the PDPA, conflicts resulted in exiles, purges and executions of Parcham members.
During its first 18 months of rule, the PDPA applied a Soviet-style program of modernizing reforms, many of which were viewed by conservatives as opposing Islam. Decrees setting forth changes in marriage customs and land reform were not received well by a population deeply immersed in tradition and Islam, particularly by the powerful landowners who were harmed economically by the abolition of usury (although usury is prohibited in Islam) and the cancellation of farmers' debts. By mid-1978, a rebellion started, with rebels attacking the local military garrison in the Nuristan region of eastern Afghanistan and soon civil war spread throughout the country. In September 1979, Deputy Prime Minister Hafizullah Amin seized power, arresting and killing President Taraki. Over two months of instability overwhelmed Amin's regime as he moved against his opponents in the PDPA and the growing rebellion.
Soviet–Afghan relations.
The Union of Soviet Socialist Republics (USSR) had been a major power broker and influential mentor in the politics of its poorer and much smaller neighbor. Its involvement ranging from civil-military infrastructure to Afghan society. Since 1947, Afghanistan had been under the influence of the Soviet government and received large amounts of aid, economic assistance, military equipment training and military hardware from the Soviet Union. Economic assistance and aid had been provided to Afghanistan as early as 1919, shortly after the Russian Revolution and when the regime was facing the Russian Civil War. Provisions were given in the form of small arms, ammunition, a few aircraft, and (according to debated Soviet sources) a million gold rubles to support the resistance during the Third Anglo-Afghan War. In 1942, the USSR again moved to strengthen the Afghan Armed Forces, by providing small arms and aircraft, and establishing training centers in Tashkent (Uzbek Soviet Socialist Republic). Soviet-Afghan military cooperation began on a regular basis in 1956, and further agreements were made in the 1970s, which saw the USSR send advisers and specialists.
In 1978, after witnessing India's nuclear test, "Smiling Buddha", President Daud Khan initiated a military buildup to counter Pakistan's armed forces and Iranian military influence in Afghan politics. A final pre-war treaty, signed in December 1978, allowed the PDPA to call upon the Soviet Union for military support.
Following the Herat uprising, President Taraki contacted Alexei Kosygin, chairman of the USSR Council of Ministers, and asked for "practical and technical assistance with men and armament". Kosygin was unfavorable to the proposal on the basis of the negative political repercussions such an action would have for his country, and he rejected all further attempts by Taraki to solicit Soviet military aid in Afghanistan. Following Kosygin's rejection, Taraki requested aid from Leonid Brezhnev, the general secretary of the Communist Party of the Soviet Union and Soviet head of state, who warned Taraki that full Soviet intervention "would only play into the hands of our enemies – both yours and ours". Brezhnev also advised Taraki to ease up on the drastic social reforms and to seek broader support for his regime.
In 1979, Taraki attended a conference of the Non-Aligned Movement in Havana, Cuba. On his way back, he stopped in Moscow on March 20 and met with Brezhnev, Soviet Foreign Minister Andrei Gromyko and other Soviet officials. It was rumoured that Karmal was present at the meeting in an attempt to reconcile Taraki's Khalq faction and the Parcham against Amin and his followers. At the meeting, Taraki was successful in negotiating some Soviet support, including the redeployment of two Soviet armed divisions at the Soviet-Afghan border, the sending of 500 military and civilian advisers and specialists and the immediate delivery of Soviet armed equipment sold at 25 percent below the original price; however, the Soviets were not pleased about the developments in Afghanistan and Brezhnev impressed upon Taraki the need for party unity. Despite reaching this agreement with Taraki, the Soviets continued to be reluctant to intervene further in Afghanistan and repeatedly refused Soviet military intervention within Afghan borders during Taraki's rule as well as later during Amin's short rule.
Initiation of the insurgency.
Afghanistan cemented regional problems with Pakistan, after Daoud pressed his hard-line Pashtunistan policies to Pakistan. Pakistan retaliated, and Prime minister Zulfikar Ali Bhutto authorized a covert operation under MI's Major-General Naseerullah Babar. In 1974, Bhutto authorized another secret operation in Kabul where the "ISI" and the "AI" extradited Burhanuddin Rabbani and Gulbadin Hekmatyar to Peshawar, amid fear that Rabbani and Hekmatyar might be assassinated by Daoud. According to Baber, Bhutto's operation was an excellent idea and it had hard-hitting impact on Daoud and his government which forced Daoud to increase his desire to make peace with Bhutto. Another part of this operation was to train hard-line Jamiat-e Islami militants against the Daoud's secular government. However, this operation went into cold-storage after Bhutto was removed from power.
In June 1975, militants from the Jamiat Islami party attempted to overthrow the government. They started their rebellion in the Panjshir valley (a part of the greater Parwan province), in the present day Panjshir province, some 100 kilometers north of Kabul, and in a number of other provinces of the country. However, government forces easily defeated the insurgency and a sizable portion of the insurgents sought refuge in Pakistan where they enjoyed the support of Zulfikar Ali Bhutto's government, which had been alarmed by Daoud's revival of the Pashtunistan issue.
In 1978, the Taraki government initiated a series of reforms, including a radical modernization of the traditional Islamic civil and especially marriage law, aimed at "uprooting feudalism" in Afghan society. The government brooked no opposition to the reforms and responded with violence to unrest. Between April 1978 and the Soviet Intervention of December 1979, thousands of prisoners, perhaps as many as 27,000, were executed at the notorious Pul-e-Charkhi prison, including many village mullahs and headmen. Other members of the traditional elite, the religious establishment and intelligentsia fled the country.
Large parts of the country went into open rebellion. The Parcham Government claimed that 11,000 were executed during the Amin/Taraki period in response to the revolts. The revolt began in October among the Nuristani tribes of the Kunar Valley in the northeastern part of the country near the border with Pakistan, and rapidly spread among the other ethnic groups. By the spring of 1979, 24 of the 28 provinces had suffered outbreaks of violence. The rebellion began to take hold in the cities: in March 1979 in Herat, rebels led by Ismail Khan revolted. Between 3,000 and 5,000 people were killed and wounded during the Herat revolt. Some 100 Soviet citizens and their families were killed.
Killing of the US ambassador.
In 1979, the contentious law and order situation led to a serious diplomatic incident involving United States, Soviet Union and Afghanistan when U.S. Ambassador to Afghanistan Adolph "Spike" Dubs was kidnapped by four militants belonging to radical communist faction, "Settam-e-Melli" (lit. "National Oppression"). The National Oppression demanded the release of their communist leader Badruddin Bahes, whom the Afghan government denied holding. The government refused categorically to negotiate with the militants, in spite of the U.S. embassy's demands. The U.S. increased pressure on the Afghan government and the Soviet Union, forcefully demanding peaceful negotiations for the release of their ambassador.
Dubs was held in Room 117 of the Kabul Hotel, where the United States sent its embassy and diplomatic staff to negotiate with the communist faction. The Afghan security forces, accompanied by the Russian advisers, swarmed the hallway and surrounding rooftops of the hotel. When negotiations stalled, there was an intense exchange of fire after Russian advisers ordered an assault. Documents released from the Soviet KGB bureau archives by Vasily Mitrokhin in the early 1990s suggest that the Afghan government authorized the assault and that the KGB adviser on scene, Sergei Batrukihn, may have recommended the assault, as well as the execution of a kidnapper before U.S. experts could interrogate him. All attempts at negotiation failed, and U.S. Ambassador Adolph Dubs was caught in the crossfire, leading to his death. Afterwards the United States formally expressed to Soviet Union its disapproval of the assault by the security forces, putting more stress on U.S.-Soviet relations.
Despite these drastic measures, by the end of 1980, out of the 80,000 soldiers strong Afghan Army, more than half had either deserted or joined the rebels.
Soviet operations 1979-85.
Deployment.
The Afghan government, having secured a treaty in December 1978 that allowed them to call on Soviet forces, repeatedly requested the introduction of troops in Afghanistan in the spring and summer of 1979. They requested Soviet troops to provide security and to assist in the fight against the mujahideen rebels. On April 14, 1979, the Afghan government requested that the USSR send 15 to 20 helicopters with their crews to Afghanistan, and on June 16, the Soviet government responded and sent a detachment of tanks, BMPs, and crews to guard the government in Kabul and to secure the Bagram and Shindand airfields. In response to this request, an airborne battalion, commanded by Lieutenant Colonel A. Lomakin, arrived at the Bagram Air Base on July 7. They arrived without their combat gear, disguised as technical specialists. They were the personal bodyguards for President Taraki. The paratroopers were directly subordinate to the senior Soviet military advisor and did not interfere in Afghan politics. Several leading politicians at the time such as Alexei Kosygin and Andrei Gromyko were against intervention.
After a month, the Afghan requests were no longer for individual crews and subunits, but for regiments and larger units. In July, the Afghan government requested that two motorized rifle divisions be sent to Afghanistan. The following day, they requested an airborne division in addition to the earlier requests. They repeated these requests and variants to these requests over the following months right up to December 1979. However, the Soviet government was in no hurry to grant them.
Based on information from the KGB, Soviet leaders felt that Prime Minister Hafizullah Amin's actions had destabilized the situation in Afghanistan. Following his initial coup against and killing of President Taraki, the KGB station in Kabul warned Moscow that Amin's leadership would lead to "harsh repressions, and as a result, the activation and consolidation of the opposition."
The Soviets established a special commission on Afghanistan, comprising KGB chairman Yuri Andropov, Boris Ponomarev from the Central Committee and Dmitriy Ustinov, the Minister of Defence. In late April 1978, the committee reported that Amin was purging his opponents, including Soviet loyalists, that his loyalty to Moscow was in question and that he was seeking diplomatic links with Pakistan and possibly the People's Republic of China (which at the time had poor relations with the Soviet Union). Of specific concern were Amin's secret meetings with the U.S. chargé d'affaires, J. Bruce Amstutz, which, while never amounting to any agreement between Amin and the United States, sowed suspicion in the Kremlin.
Information obtained by the KGB from its agents in Kabul provided the last arguments to eliminate Amin. Supposedly, two of Amin's guards killed the former president Nur Muhammad Taraki with a pillow, and Amin, himself, was suspected to be a CIA agent. The latter, however, is still disputed with Amin repeatedly demonstrating friendliness toward the various delegates of the Soviet Union who would arrive in Afghanistan. Soviet General Vasily Zaplatin, a political advisor of Premier Brezhnev at the time, claimed that four of President Taraki's ministers were responsible for the destabilization. However, Zaplatin failed to emphasize this in discussions and was not heard.
By the late 1970s, rapprochement between the USSR and the US had been well-established, which had led to growing tendencies toward détente and as such, attempts toward disarmament. Of note was the SALT I treaty, which was created to encourage cooperation in matters of nuclear weaponry and technology between the two nations. A second round of talks between Soviet premier Brezhnev and President Carter yielded the SALT II treaty in June 1979. (the United States Senate later failed to ratify the treaty due to the Soviet-Afghan conflict). Conservatives believe that this process was reflective of growing Soviet political influence in the world and that Soviet intervention in Afghanistan in December 1979 was an attempt to preserve, stabilize and militarily intervene on behalf of the communist regime there and thus, their own political standing.
During meetings between President Taraki and Soviet leaders in March 1979, the Soviets promised political support and to send military equipment and technical specialists, but upon repeated requests by Taraki for direct Soviet intervention, the leadership adamantly opposed him; reasons included that they would be met with "bitter resentment" from the Afghan people, that intervening in another country's civil war would hand a propaganda victory to their opponents, and Afghanistan's overall inconsequential weight in international affairs, in essence realizing they had little to gain by taking over a country with a poor economy, unstable government, and hostile populous to outsiders. However, as the situation continued to deteriorate from May-December 1979, Moscow changed its mind on dispatching Soviet troops. The reasons for this complete turnabout are not entirely clear, and several speculative arguments include the grave internal situation and inability for the Afghan government, later headed by Amin, to quell the rebellion, the effects of the Iranian Revolution that brought an Islamic theocracy into power, leading to fears that religious fanaticism would spread through Afghanistan and into Soviet Muslim Central Asian republics, and the deteriorating ties with the United States with the failure of Congress to ratify the SALT II treaty and the impression that détente was "already effectively dead."
Soviet intervention and coup.
On October 31, 1979 Soviet informants to the Afghan Armed Forces who were under orders from the inner circle of advisors under Soviet premier Brezhnev, relayed information for them to undergo maintenance cycles for their tanks and other crucial equipment. Meanwhile, telecommunications links to areas outside of Kabul were severed, isolating the capital. With a deteriorating security situation, large numbers of Soviet Airborne Forces joined stationed ground troops and began to land in Kabul on December 25. Simultaneously, Amin moved the offices of the president to the Tajbeg Palace, believing this location to be more secure from possible threats. According to Colonel General Tukharinov and Merimsky, Amin was fully informed of the military movements, having requested Soviet military assistance to northern Afghanistan on December 17. His brother and General Dmitry Chiangov met with the commander of the 40th Army before Soviet troops entered the country, to work out initial routes and locations for Soviet troops.
On December 27, 1979, 700 Soviet troops dressed in Afghan uniforms, including KGB and GRU special forces officers from the "Alpha Group" and "Zenith Group", occupied major governmental, military and media buildings in Kabul, including their primary target – the Tajbeg Presidential Palace.
That operation began at 19:00 hr., when the KGB-led Soviet "Zenith Group" destroyed Kabul's communications hub, paralyzing Afghan military command. At 19:15, the assault on Tajbeg Palace began; as planned, president Hafizullah Amin was killed. Simultaneously, other objectives were occupied (e.g., the Ministry of Interior at 19:15). The operation was fully complete by the morning of December 28, 1979.
The Soviet military command at Termez, Uzbek SSR, announced on Radio Kabul that Afghanistan had been liberated from Amin's rule. According to the Soviet Politburo they were complying with the 1978 "Treaty of Friendship, Cooperation and Good Neighborliness" and Amin had been "executed by a tribunal for his crimes" by the Afghan Revolutionary Central Committee. That committee then elected as head of government former Deputy Prime Minister Babrak Karmal, who had been demoted to the relatively insignificant post of ambassador to Czechoslovakia following the Khalq takeover, and announced that it had requested Soviet military assistance.
Soviet ground forces, under the command of Marshal Sergei Sokolov, entered Afghanistan from the north on December 27. In the morning, the 103rd Guards 'Vitebsk' Airborne Division landed at the airport at Bagram and the deployment of Soviet troops in Afghanistan was underway. The force that entered Afghanistan, in addition to the 103rd Guards Airborne Division, was under command of the 40th Army and consisted of the 108th and 5th Guards Motor Rifle Divisions, the 860th Separate Motor Rifle Regiment, the 56th Separate Airborne Assault Brigade, the 36th Mixed Air Corps. Later on the 201st and 58th Motor Rifle Divisions also entered the country, along with other smaller units. In all, the initial Soviet force was around 1,800 tanks, 80,000 soldiers and 2,000 AFVs. In the second week alone, Soviet aircraft had made a total of 4,000 flights into Kabul. With the arrival of the two later divisions, the total Soviet force rose to over 100,000 personnel.
International positions on Soviet intervention.
Foreign ministers from 34 Islamic nations adopted a resolution which condemned the Soviet intervention and demanded "the immediate, urgent and unconditional withdrawal of Soviet troops" from the Muslim nation of Afghanistan. The UN General Assembly passed a resolution protesting the Soviet intervention in Afghanistan by a vote of 104–18. According to political scientist Gilles Kepel, the Soviet intervention or "invasion" was "viewed with horror" in the West, considered to be a "fresh twist" on the geo-political "Great Game" of the 19th Century, whereby Russia sought access to the Indian Ocean; and posed "a threat to Western security", explicitly violating "the world balance of power agreed upon at Yalta" in 1945.
Weapons supplies were made available through numerous countries; the United States purchased all of Israel's captured Soviet weapons clandestinely, and then funnelled the weapons to the Mujahideen, while Egypt upgraded their own army's weapons, and sent the older weapons to the militants, Turkey sold their World War II stockpiles to the warlords, and the British and Swiss provided Blowpipe missiles and Oerlikon anti-aircraft guns respectively, after they were found to be poor models for their own forces. China provided the most relevant weapons, likely due to their own experience with guerrilla warfare, and kept meticulous record of all the shipments.
December 1979 – February 1980: Occupation.
The first phase began with the Soviet intervention in Afghanistan and their first battles with various opposition groups. Soviet troops entered Afghanistan along two ground routes and one air corridor, quickly taking control of the major urban centers, military bases and strategic installations. However, the presence of Soviet troops did not have the desired effect of pacifying the country. On the contrary, it exacerbated a nationalistic feeling, causing the rebellion to spread further. Babrak Karmal, Afghanistan's new president, charged the Soviets with causing an increase in the unrest, and demanded that the 40th Army step in and quell the rebellion, as his own army had proved untrustworthy. Thus, Soviet troops found themselves drawn into fighting against urban uprisings, tribal armies (called "lashkar"), and sometimes against mutinying Afghan Army units. These forces mostly fought in the open, and Soviet airpower and artillery made short work of them.
March 1980 – April 1985: Soviet offensives.
The war now developed into a new pattern: the Soviets occupied the cities and main axis of communication, while the mujahideen, (which the Soviet Army soldiers called 'Dushman,' meaning 'enemy') divided into small groups, waged a guerrilla war. Almost 80 percent of the country escaped government control. Soviet troops were deployed in strategic areas in the northeast, especially along the road from Termez to Kabul. In the west, a strong Soviet presence was maintained to counter Iranian influence. Incidentally, special Soviet units would have also performed secret attacks on Iranian territory to destroy suspected mujahideen bases, and their helicopters then got engaged in shootings with Iranian jets. Conversely, some regions such as Nuristan, in the northeast, and Hazarajat, in the central mountains of Afghanistan, were virtually untouched by the fighting, and lived in almost complete independence.
Periodically the Soviet Army undertook multi-divisional offensives into mujahideen-controlled areas. Between 1980 and 1985, nine offensives were launched into the strategically important Panjshir Valley, but government control of the area did not improve. Heavy fighting also occurred in the provinces neighbouring Pakistan, where cities and government outposts were constantly under siege by the mujahideen. Massive Soviet operations would regularly break these sieges, but the mujahideen would return as soon as the Soviets left. In the west and south, fighting was more sporadic, except in the cities of Herat and Kandahar, that were always partly controlled by the resistance.
The Soviets did not, at first, foresee taking on such an active role in fighting the rebels and attempted to play down their role there as giving light assistance to the Afghan army. However, the arrival of the Soviets had the opposite effect as it incensed instead of pacified the people, causing the mujahideen to gain in strength and numbers. Originally the Soviets thought that their forces would strengthen the backbone of the Afghan army and provide assistance by securing major cities, lines of communication and transportation. The Afghan army forces had a high desertion rate and were loath to fight, especially since the Soviet forces pushed them into infantry roles while they manned the armored vehicles and artillery. The main reason though that the Afghan soldiers were so ineffective was their lack of morale as many of them were not truly loyal to the communist government but simply collecting a paycheck. Once it became apparent that the Soviets would have to get their hands dirty, they followed three main strategies aimed at quelling the uprising. Intimidation was the first strategy, in which the Soviets would use airborne attacks as well as armored ground attacks to destroy villages, livestock and crops in trouble areas. The Soviets would bomb villages that were near sites of guerrilla attacks on Soviet convoys or known to support resistance groups. Local peoples were forced to either flee their homes or die as daily Soviet attacks made it impossible to live in these areas. By forcing the people of Afghanistan to flee their homes, the Soviets hoped to deprive the guerillas of resources and safe havens. The second strategy consisted of subversion which entailed sending spies to join resistance groups and report information as well as bribing local tribes or guerrilla leaders into ceasing operations. Finally, the Soviets used military forays into contested territories in an effort to root out the guerillas and limit their options. Classic search and destroy operations were implemented using Mil Mi-24 helicopter gunships that would provide cover for ground forces in armored vehicles. Once the villages were occupied by Soviet forces, inhabitants who remained were frequently interrogated and tortured for information or killed.
To complement their brute force approach to weeding out the insurgency, the Soviets used KHAD (Afghan secret police) to gather intelligence, infiltrate the mujahideen, spread false information, bribe tribal militias into fighting and organize a government militia. While it is impossible to know exactly how successful the KHAD was in infiltrating mujahideen groups, it is thought that they succeeded in penetrating a good many resistance groups based in Afghanistan, Pakistan and Iran. KHAD is thought to have had particular success in igniting internal rivalries and political divisions amongst the resistance groups, rendering some of them completely useless because of infighting. The KHAD had some success in securing tribal loyalties but many of these relationships were fickle and temporary. Often KHAD secured neutrality agreements rather than committed political alignment. The Sarandoy, a KHAD controlled government militia, had mixed success in the war. Large salaries and proper weapons attracted a good number of recruits to the cause, even if they were not necessarily "pro-communist". The problem was that many of the recruits they attracted were in fact mujahideen who would join up to procure arms, ammunition and money while also gathering information about forthcoming military operations.
In 1985, the size of the LCOSF (Limited Contingent of Soviet Forces) was increased to 108,800 and fighting increased throughout the country, making 1985 the bloodiest year of the war. However, despite suffering heavily, the mujahideen were able to remain in the field, mostly because they received thousands of new volunteers daily, and continue resisting the Soviets. 
1980s: Insurrection.
In the mid-1980s, the Afghan resistance movement, assisted by the United States, Pakistan, Saudi Arabia, the United Kingdom, Egypt, the People's Republic of China and others, contributed to Moscow's high military costs and strained international relations. The U.S. viewed the conflict in Afghanistan as an integral Cold War struggle, and the CIA provided assistance to anti-Soviet forces through the Pakistani intelligence services, in a program called Operation Cyclone.
As well as money, Muslim countries provided thousands of volunteer fighters known as "Afghan Arabs", who wished to wage jihad against the atheist communists. Notable among them was a young Saudi named Osama bin Laden, whose Arab group eventually evolved into al-Qaeda. Despite their numbers, the contribution has been called a "curious sideshow to the real fighting," with only an estimated 2000 of them fighting "at any one time", compared with about a 250,000 Afghan fighters and 125,000 Soviet troops. Their efforts were also sometimes counterproductive as in the March 1989 battle for Jalalabad. Instead of being the beginning of the collapse of the Afghan Communist government forces after their abandonment by the Soviets, the Afghan communists rallied to break the siege of Jalalabad and to win the first major government victory in years, provoked by the sight of a truck filled with dismembered bodies of Communists chopped to pieces after surrendering by radical non-Afghan salafists eager to show the enemy the fate awaiting the infidels. "This success reversed the government's demoralization from the withdrawal of Soviet forces, renewed its determination to fight on, and allowed it to survive three more years." 
In the course of the guerrilla war, leadership came to be distinctively associated with the title of "commander". It applied to independent leaders, eschewing identification with elaborate military bureaucracy associated with such ranks as general. As the war produced leaders of reputation, "commander" was conferred on leaders of fighting units of all sizes, signifying pride in independence, self-sufficiency, and distinct ties to local communities. The title epitomized Afghan pride in their struggle against a powerful foe. Segmentation of power and religious leadership were the two values evoked by nomenclature generated in the war. Neither had been favored in the ideology of the former Afghan state.
Afghanistan's resistance movement was born in chaos, spread and triumphed chaotically, and did not find a way to govern differently. Virtually all of its war was waged locally by regional warlords. As warfare became more sophisticated, outside support and regional coordination grew. Even so, the basic units of mujahideen organization and action continued to reflect the highly segmented nature of Afghan society.
Olivier Roy estimates that after four years of war, there were at least 4,000 bases from which mujahideen units operated. Most of these were affiliated with the seven expatriate parties headquartered in Pakistan, which served as sources of supply and varying degrees of supervision. Significant commanders typically led 300 or more men, controlled several bases and dominated a district or a sub-division of a province. Hierarchies of organization above the bases were attempted. Their operations varied greatly in scope, the most ambitious being achieved by Ahmad Shah Massoud of the Panjshir valley north of Kabul. He led at least 10,000 trained troopers at the end of the Soviet war and had expanded his political control of Tajik-dominated areas to Afghanistan's northeastern provinces under the Supervisory Council of the North.
Roy also describes regional, ethnic and sectarian variations in mujahideen organization. In the Pashtun areas of the east, south and southwest, tribal structure, with its many rival sub-divisions, provided the basis for military organization and leadership. Mobilization could be readily linked to traditional fighting allegiances of the tribal "lashkar" (fighting force). In favorable circumstances such formations could quickly reach more than 10,000, as happened when large Soviet assaults were launched in the eastern provinces, or when the mujahideen besieged towns, such as Khost in Paktia province in July 1983. But in campaigns of the latter type the traditional explosions of manpower—customarily common immediately after the completion of harvest—proved obsolete when confronted by well dug-in defenders with modern weapons. Lashkar durability was notoriously short; few sieges succeeded.
Mujahideen mobilization in non-Pashtun regions faced very different obstacles. Prior to the intervention, few non-Pashtuns possessed firearms. Early in the war they were most readily available from army troops or gendarmerie who defected or were ambushed. The international arms market and foreign military support tended to reach the minority areas last. In the northern regions, little military tradition had survived upon which to build an armed resistance. Mobilization mostly came from political leadership closely tied to Islam. Roy contrasts the social leadership of religious figures in the Persian- and Turkic-speaking regions of Afghanistan with that of the Pashtuns. Lacking a strong political representation in a state dominated by Pashtuns, minority communities commonly looked to pious learned or charismatically revered "pirs" (saints) for leadership. Extensive Sufi and maraboutic networks were spread through the minority communities, readily available as foundations for leadership, organization, communication and indoctrination. These networks also provided for political mobilization, which led to some of the most effective of the resistance operations during the war.
The mujahideen favoured sabotage operations. The more common types of sabotage included damaging power lines, knocking out pipelines and radio stations, blowing up government office buildings, air terminals, hotels, cinemas, and so on. In the border region with Pakistan, the mujahideen would often launch 800 rockets per day. Between April 1985 and January 1987, they carried out over 23,500 shelling attacks on government targets. The mujahideen surveyed firing positions that they normally located near villages within the range of Soviet artillery posts, putting the villagers in danger of death from Soviet retaliation. The mujahideen used land mines heavily. Often, they would enlist the services of the local inhabitants, even children.
They concentrated on both civilian and military targets, knocking out bridges, closing major roads, attacking convoys, disrupting the electric power system and industrial production, and attacking police stations and Soviet military installations and air bases. They assassinated government officials and PDPA members, and laid siege to small rural outposts. In March 1982, a bomb exploded at the Ministry of Education, damaging several buildings. In the same month, a widespread power failure darkened Kabul when a pylon on the transmission line from the Naghlu power station was blown up. In June 1982 a column of about 1,000 young communist party members sent out to work in the Panjshir valley were ambushed within 30 km of Kabul, with heavy loss of life. On September 4, 1985, insurgents shot down a domestic Bakhtar Airlines plane as it took off from Kandahar airport, killing all 52 people aboard.
Mujahideen groups used for assassination had three to five men in each. After they received their mission to kill certain government officials, they busied themselves with studying his pattern of life and its details and then selecting the method of fulfilling their established mission. They practiced shooting at automobiles, shooting out of automobiles, laying mines in government accommodation or houses, using poison, and rigging explosive charges in transport.
In May 1985, the seven principal rebel organizations formed the Seven Party Mujahideen Alliance to coordinate their military operations against the Soviet army. Late in 1985, the groups were active in and around Kabul, unleashing rocket attacks and conducting operations against the communist government.
Media reaction.
International journalistic perception of the mujahideen varied. At least some, such as leftist journalist Alexander Cockburn, were unsympathetic, criticizing Afghanistan as "an unspeakable country filled with unspeakable people, sheepshaggers and smugglers, who have furnished in their leisure hours some of the worst arts and crafts ever to penetrate the occidental world. I yield to none in my sympathy to those prostrate beneath the Russian jackboot, but if ever a country deserved rape it's Afghanistan." Robert D. Kaplan on the other hand, thought any perception of mujahideen as "barbaric" was unfair: "Documented accounts of mujahidin savagery were relatively rare and involved enemy troops only. Their cruelty toward civilians was unheard of during the war, while Soviet cruelty toward civilians was common." Lack of interest in the mujahideen cause, Kaplan believed, was not the lack of intrinsic interest to be found in a war between a small, poor country and a superpower were a million civilians were killed, but the result of the great difficulty and unprofitability of media coverage. Kaplan note that "none of the American TV networks had a bureau for a war", and television cameramen venturing to follow the mujahideen "trekked for weeks on little food, only to return ill and half starved". In October 1994 the Soviet ambassador to Pakistan, Vitaly Smirnov, told Agence France Presse "that journalists traveling with the mujahidin 'will be killed. And our units in Afghanistan will help the Afghan forces to do it.'" Unlike Vietnam and Lebanon, Afghanistan had "absolutely no clash between the strange and the familiar", no "rock-video quality" of "zonked-out GIs in headbands" or "rifle-wielding Shiite terrorists wearing Michael Jackson T-shirts" that provided interesting "visual materials" for newscasts.
1986: Stinger Missile and "Stinger effect".
Whether the introduction of the personal, portable, infrared-homing surface-to-air "Stinger" missile in September 1986 was a turning point in the war is disputed.
Many Western military analysts credit the Stinger with a kill ratio of about 70% and with responsibility for most of the over 350 Soviet or Afghan government aircraft and helicopters downed in the last two years of the war. Some military analysts considered it a "game changer" coined the term "Stinger effect" to describe it.
According to US Congressman Charlie Wilson who was instrumental in funding the Stingers for the Mujahideen, before the Stinger the Mujahideen never won a set piece battle with the Soviets but after it was introduced, the Mujahideen never again lost one.
However many Russian military analysts tend to be dismissive of the impact to the Stinger. According to Alan J. Kuperman, Soviet leader Mikhail Gorbachev decided to withdraw from Afghanistan a year before the mujahideen fired their first Stinger missiles, motivated by U.S. sanctions, not military losses. The stingers did make an impact at first but within a few months flares, beacons, and exhaust baffles were installed to disorient the missiles, along with night operation and terrain-hugging tactics to prevent the rebels from getting a clear shot. By 1988, Kuperman states, the mujahideen had all but stopped firing them. Another source (Jonathan Steele) states that stingers forced Soviet helicopters and ground attack planes to bomb from higher altitudes with less accuracy, but did not bring down many more aircraft than Chinese heavy machine guns and other less sophisticated antiaircraft weaponry.
Exit.
April 1985 – January 1987: Exit strategy.
The first step of the Soviet Union's exit strategy was to transfer the burden of fighting the mujahideen to the Afghan armed forces, with the aim of preparing them to operate without Soviet help. During this phase, the Soviet contingent was restricted to supporting the DRA forces by providing artillery, air support and technical assistance, though some large-scale operations were still carried out by Soviet troops.
Under Soviet guidance, the DRA armed forces were built up to an official strength of 302,000 in 1986. To minimize the risk of a coup d'état, they were divided into different branches, each modeled on its Soviet counterpart. The ministry of defence forces numbered 132,000, the ministry of interior 70,000 and the ministry of state security (KHAD) 80,000. However, these were theoretical figures: in reality each service was plagued with desertions, the army alone suffering 32,000 per year.
The decision to engage primarily Afghan forces was taken by the Soviets, but was resented by the PDPA, who viewed the departure of their protectors without enthusiasm. In May 1987 a DRA force attacked well-entrenched mujahideen positions in the Arghandab District, but the mujahideen held their ground, and the attackers suffered heavy casualties. In the spring of 1986, an offensive into Paktia Province briefly occupied the mujahideen base at Zhawar only at the cost of heavy losses. Meanwhile, the mujahideen benefited from expanded foreign military support from the United States, Saudi Arabia, Pakistan and other Muslim nations. The US tended to favor the Afghan resistance forces led by Ahmed Shah Massoud, and US support for Massoud's forces increased considerably during the Reagan administration in what US military and intelligence forces called "Operation Cyclone". Primary advocates for supporting Massoud included two Heritage Foundation foreign policy analysts, Michael Johns and James A. Phillips, both of whom championed Massoud as the Afghan resistance leader most worthy of US support under the Reagan Doctrine.
January 1987 – February 1989: Withdrawal.
The arrival of Mikhail Gorbachev on the scene in 1985 and his 'new thinking' on foreign and domestic policy was likely an important factor in the Soviets' decision to withdraw. Gorbachev had been attempting to remove the Soviet Union from the economic stagnation that had set in, under the leadership of Premier Brezhnev, and reform the Soviet Union's economy and image across the board with Glasnost and Perestroika. Gorbachev had also been attempting to ease cold war tensions by signing the Intermediate-Range Nuclear Forces Treaty in 1987 with the U.S. and withdrawing the troops from Afghanistan whose presence had garnered so much international condemnation. Gorbachev regarded confrontation with China and resulting military build ups on that border as one of Brezhnev's biggest mistakes. Beijing had stipulated that a normalization of relations would have to wait until Moscow withdrew its army from Afghanistan (among other things) and in 1989 the first Sino-Soviet summit in 30 years took place. At the same time, Gorbachev pressured his Cuban allies in Angola to scale down activities and withdraw even though Soviet allies were faring somewhat better there. The Soviets also pulled many of their troops out of Mongolia in 1987 where they were also having a far easier time than in Afghanistan and restrained the Vietnamese invasion of Kampuchea to the point of an all out withdrawal in 1988. This mass withdrawal of Soviet forces from such highly contested areas shows the Soviet government's decision to leave Afghanistan as being based upon a general change in Soviet foreign policy- from that of confrontation to avoidance of conflict wherever possible.
In the last phase, Soviet troops prepared and executed their withdrawal from Afghanistan, whilst limiting the launching of offensive operations by those who hadn't withdrawn yet.
By mid-1987 the Soviet Union announced it would start withdrawing its forces. Sibghatullah Mojaddedi was selected as the head of the Interim Islamic State of Afghanistan, in an attempt to reassert its legitimacy against the Moscow-sponsored Kabul regime. Mojaddedi, as head of the Interim Afghan Government, met with then Vice President of the United States George H. W. Bush, achieving a critical diplomatic victory for the Afghan resistance. Defeat of the Kabul government was their solution for peace. This confidence, sharpened by their distrust of the United Nations, virtually guaranteed their refusal to accept a political compromise.
In September 1988, Soviet MiG-23 fighters shot down one Pakistani F-16 and two Iranian AH-1J Cobra, who intruded in Afghan airspace.
"Operation Magistral", has been one of the final offensive operations undertaken by the Soviets; a successful sweep operation that cleared the road between Gardez and Khost. This operation did not have any lasting effect on the outcome of the conflict nor the soiled political and military status of the Soviets in the eyes of the West, but was a symbolic gesture that marked the end of their widely condemned presence in the country with a victory.
The first half of the Soviet contingent was withdrawn from May 15 to August 16, 1988 and the second from November 15 to February 15, 1989. In order to ensure a safe passage the Soviets had negotiated ceasefires with local mujahideen commanders, so the withdrawal was generally executed peacefully, except for the operation "Typhoon".
General Yazov, the Defense Minister of Soviet Union, ordered the 40th Army to violate the agreement with Ahmed Shah Masood, who commanded a large force in the Panjshir Valley, and attack his relaxed and exposed forces. The Soviet attack was initiated to protect Najibullah, who did not have a cease fire in effect with Masood, and who rightly feared an offensive by Masood's forces after the Soviet withdrawal. General Gromov, the 40th Army Commander, objected to the operation, but reluctantly obeyed the order. "Typhoon" began on January 23 and continued for three days. To minimize their own losses the Soviets abstained from close-range fight, instead they used long-range artillery, surface-to-surface and air-to-surface missiles. Numerous civilian casualties were reported. Masood had not threatened the withdrawal to this point, and did not attack Soviet forces after they breached the agreement. Overall, the Soviet attack represented a defeat for Masood's forces, who lost 600 fighters killed and wounded.
After the withdrawal of the Soviets the DRA forces were left fighting alone and had to abandon some provincial capitals, and it was widely believed that they would not be able to resist the mujahideen for long. However, in the spring of 1989 DRA forces inflicted a sharp defeat on the mujahideen at Jalalabad.
The government of President Karmal, a puppet regime, was largely ineffective. It was weakened by divisions within the PDPA and the Parcham faction, and the regime's efforts to expand its base of support proved futile. Moscow came to regard Karmal as a failure and blamed him for the problems. Years later, when Karmal's inability to consolidate his government had become obvious, Mikhail Gorbachev, then General Secretary of the Soviet Communist Party, said:
In November 1986, Mohammad Najibullah, former chief of the Afghan secret police (KHAD), was elected president and a new constitution was adopted. He also introduced in 1987 a policy of "national reconciliation," devised by experts of the Communist Party of the Soviet Union, and later used in other regions of the world. Despite high expectations, the new policy neither made the Moscow-backed Kabul regime more popular, nor did it convince the insurgents to negotiate with the ruling government.
Informal negotiations for a Soviet withdrawal from Afghanistan had been underway since 1982. In 1988, the governments of Pakistan and Afghanistan, with the United States and Soviet Union serving as guarantors, signed an agreement settling the major differences between them known as the Geneva Accords. The United Nations set up a special Mission to oversee the process. In this way, Najibullah had stabilized his political position enough to begin matching Moscow's moves toward withdrawal. On July 20, 1987, the withdrawal of Soviet troops from the country was announced. The withdrawal of Soviet forces was planned out by Lt. Gen. Boris Gromov, who, at the time, was the commander of the 40th Army.
Among other things the Geneva accords identified the US and Soviet non-intervention in the internal affairs of Pakistan and Afghanistan and a timetable for full Soviet withdrawal. The agreement on withdrawal held, and on February 15, 1989, the last Soviet troops departed on schedule from Afghanistan.
Impact.
International reaction.
President Jimmy Carter placed a trade embargo against the Soviet Union on shipments of commodities such as grain and weapons. This resulted in newly increased tensions between the two nations. On top of recently sparked apprehensions in the West directed toward the tens of thousands of Soviet troops which were of close proximity to oil-rich regions in the Persian Gulf, the Soviet invasion of Afghanistan effectively brought about the end of détente.
The international diplomatic response was severe, ranging from stern warnings from the UN to a US-led boycott of the 1980 Summer Olympics in Moscow (in which Afghanistan competed). The intervention, along with other events, such as the Iranian revolution and the US hostage stand-off that accompanied it, the Iran–Iraq War, the 1982 Lebanon War and the escalating tensions between Pakistan and India, contributed to the volatility of the Middle East and South Asian regions in the 1980s.
The Non-Aligned Movement was sharply divided between those who believed the Soviet deployment to be a legitimate police action and others who considered the deployment an illegal invasion. Among the Warsaw Pact countries, the intervention was condemned only by Romania. India, a close ally of the Soviet Union, refused to support the Afghan war, though by the end of the hostilities offered to provide humanitarian assistance to the Afghan government.
Foreign involvement and aid to the mujahideen.
The Afghan Mujahideen were supported by several other countries, with the U.S. and Saudi Arabia offering the greatest financial support. United States President Carter insisted that what he termed "Soviet aggression" could not be viewed as an isolated event of limited geographical importance but had to be contested as a potential threat to US influence in the Persian Gulf region. The US was also worried about the USSR gaining access to the Indian Ocean by coming to an arrangement with Pakistan. (The Soviet air base outside of Kandahar was "30 minutes flying time by strike aircraft or naval bomber" to the Persian Gulf according to Robert Kaplan. It "became the heart of the southernmost concentration of Soviet soldier" in the 300-year history of Russian expansion in central Asia.)
National Security Advisor Zbigniew Brzezinski, known for his hardline policies on the Soviet Union, initiated in 1979 a campaign supporting mujaheddin in Pakistan and Afghanistan, which was run by Pakistani security services with financial support from the Central Intelligence Agency and Britain's MI6. Years later, in a 1997 CNN/National Security Archive interview, Brzezinski detailed the strategy taken by the Carter administration against the Soviets in 1979:
We immediately launched a twofold process when we heard that the Soviets had entered Afghanistan. The first involved direct reactions and sanctions focused on the Soviet Union, and both the State Department and the National Security Council prepared long lists of sanctions to be adopted, of steps to be taken to increase the international costs to the Soviet Union of their actions. And the second course of action led to my going to Pakistan a month or so after the Soviet invasion of Afghanistan, for the purpose of coordinating with the Pakistanis a joint response, the purpose of which would be to make the Soviets bleed for as much and as long as is possible; and we engaged in that effort in a collaborative sense with the Saudis, the Egyptians, the British, the Chinese, and we started providing weapons to the Mujaheddin, from various sources again – for example, some Soviet arms from the Egyptians and the Chinese. We even got Soviet arms from the Czechoslovak communist government, since it was obviously susceptible to material incentives; and at some point we started buying arms for the Mujaheddin from the Soviet army in Afghanistan, because that army was increasingly corrupt.
The supplying of billions of dollars in arms to the Afghan mujahideen militants was one of the CIA's longest and most expensive covert operations. The CIA provided assistance to the fundamentalist insurgents through the Pakistani secret services, Inter-Services Intelligence (ISI), in a program called Operation Cyclone. At least 3 billion in U.S. dollars were funneled into the country to train and equip troops with weapons. Together with similar programs by Saudi Arabia, Britain's MI6 and SAS, Egypt, Iran, and the People's Republic of China, the arms included FIM-43 Redeye, shoulder-fired, antiaircraft weapons that they used against Soviet helicopters. Pakistan's secret service, Inter-Services Intelligence (ISI), was used as an intermediary for most of these activities to disguise the sources of support for the resistance.
According to the New Republic, the CIA had fewer than 10 operatives in the region because it was "skittish" and "feared it would be blamed, like in Guatemala." According to Pakistani Brigadier Mohammad Yousaf, the scarcity of CIA personnel was because "a cardinal rule of Pakistan's policy" was that "no Americans ever become involved with the distribution of funds or arms once they arrived" in Pakistan. "No Americans ever trained or had direct contact with the mujahideen, and no American official ever went inside Afghanistan.
Shortly after the intervention, Pakistan's military ruler General Muhammad Zia-ul-Haq called for a meeting of senior military members and technocrats of his military government. At this meeting, General Zia-ul-Haq asked the Chief of Army Staff General Khalid Mahmud Arif and the Chairman of the Joint Chiefs of Staff Admiral Muhammad Shariff to lead a specialized civil-military team to formulate a geo-strategy to counter the Soviet aggression. At this meeting, the Director-General of the "ISI" at that time, Lieutenant-General Akhtar Abdur Rahman advocated for an idea of covert operation in Afghanistan by arming the Islamic extremist, and was loudly heard saying: ""Kabul must burn! Kabul must burn!"". As for Pakistan, the Soviet war with Islamist mujaheddin was viewed as retaliation for the Soviet Union's long unconditional support of regional rival, India, notably during the 1965 and the 1971 wars, which led the loss of East Pakistan.
After the Soviet deployment, Pakistan's military ruler General Muhammad Zia-ul-Haq started accepting financial aid from the Western powers to aid the mujahideen. In 1981, following the election of US President Ronald Reagan, aid for the mujahideen through Zia's Pakistan significantly increased, mostly due to the efforts of Texas Congressman Charlie Wilson and CIA officer Gust Avrakotos.
The early foundations of al-Qaeda were allegedly built in part on relationships and weaponry that came from the billions of dollars in U.S. support for the Afghan mujahideen during the war to expel Soviet forces from that country. However, scholars such as Jason Burke, Steve Coll, Peter Bergen, Christopher Andrew, and Vasily Mitrokhin have argued that Osama Bin Laden was "outside of CIA eyesight" and that there is "no support" in any "reliable source" for "the claim that the CIA funded bin Laden or any of the other Arab volunteers who came to support the mujahideen."
Pakistan's "ISI" and Special Service Group (SSG) were actively involved in the conflict. The SSG are widely suspected of participating in Operation Hill 3234, near the Pakistani border where nearly 200 suspected SSG personnel were killed in a futile attempt to assault the Soviet held hill.
The theft of large sums of aid spurred Pakistan's economic growth, but along with the war in general had devastating side effects for that country. The siphoning off of aid weapons, in which the weapons logistics and coordination were put under the Pakistan Navy in the port city of Karachi, contributed to disorder and violence there, while heroin entering from Afghanistan to pay for arms contributed to addiction problems. The Navy went into covert war and coordinated the foreign weapons into Afghanistan, while some of its high-ranking admirals were responsible for storing the weapons in the Navy depot, later coordinated the weapons supply to mujahideen.
In retaliation for Pakistan's assistance to the insurgents, the KHAD Afghan security service, under leader Mohammad Najibullah, carried out (according to the Mitrokhin Archives and other sources) a large number of operations against Pakistan. In 1987, 127 incidents resulted in 234 deaths in Pakistan. In April 1988, an ammunition depot outside the Pakistani capital of Islamabad was blown up killing 100 and injuring more than 1000 people. The KHAD and KGB were suspected in the perpetration of these acts. Soviet and Afghan fighters and bombers occasionally bombed Pakistani villages along the Pakistani-Afghan border. These attacks are known to have caused at least 300 civilian deaths and extensive damage. Sometimes they got involved in shootings with the Pakistani jets defending the airspace.
Pakistan took in millions of Afghan refugees (mostly Pashtun) fleeing the Soviet occupation. Although the refugees were controlled within Pakistan's largest province, Balochistan under then-martial law ruler General Rahimuddin Khan, the influx of so many refugees – believed to be the largest refugee population in the world – spread into several other regions.
All of this had a heavy impact on Pakistan and its effects continue to this day. Pakistan, through its support for the mujahideen, played a significant role in the eventual withdrawal of Soviet military personnel from Afghanistan.
During the Sino-Soviet split, strained relations between China and Soviet Russia resulted in bloody border clashes and mutual backing for the opponent's enemies. China and Afghanistan had neutral relations with each other during the King's rule. When the pro Soviet Afghan Communists seized power in Afghanistan in 1978, relations between China and the Afghan communists quickly turned hostile. The Afghan pro Soviet communists supported China's enemies in Vietnam and blamed China for supporting Afghan anti communist militants. China responded to the Soviet war in Afghanistan by supporting the Afghan mujahideen and ramping up their military presence near Afghanistan in Xinjiang. China acquired military equipment from America to defend itself from Soviet attack.
The Chinese People's Liberation Army trained and supported the Afghan mujahideen during the war. The training camps were moved from Pakistan into China itself. Anti-aircraft missiles, rocket launchers and machine guns, valued at hundreds of millions, were given to the mujahideen by the Chinese. Chinese military advisors and army troops were present with the Mujahidin during training.
Soviet personnel strengths and casualties.
Between December 25, 1979, and February 15, 1989, a total of 620,000 soldiers served with the forces in Afghanistan (though there were only 80,000–104,000 serving at one time): 525,000 in the Army, 90,000 with border troops and other KGB sub-units, 5,000 in independent formations of MVD Internal Troops, and police forces. A further 21,000 personnel were with the Soviet troop contingent over the same period doing various white collar and blue collar jobs.
The total irrecoverable personnel losses of the Soviet Armed Forces, frontier, and internal security troops came to 14,453. Soviet Army formations, units, and HQ elements lost 13,833, KGB sub-units lost 572, MVD formations lost 28, and other ministries and departments lost 20 men. During this period 312 servicemen were missing in action or taken prisoner; 119 were later freed, of whom 97 returned to the USSR and 22 went to other countries.
Of the troops deployed, 53,753 were wounded, injured, or sustained concussion and 415,932 fell sick. A high proportion of casualties were those who fell ill. This was because of local climatic and sanitary conditions, which were such that acute infections spread rapidly among the troops. There were 115,308 cases of infectious hepatitis, 31,080 of typhoid fever, and 140,665 of other diseases. Of the 11,654 who were discharged from the army after being wounded, maimed, or contracting serious diseases, 10,751 men, were left disabled.
Material losses were as follows:
Use of chemical weapons.
There have also been numerous reports of chemical weapons being used by Soviet forces in Afghanistan, often indiscriminately against civilians. A declassified CIA report from 1982 states that between 1979 and 1982 there were 43 separate chemical weapons attacks which caused more than 3000 deaths. By early 1980, attacks with chemical weapons were reported in "all areas with concentrated resistance activity".
Causes of withdrawal.
Some of the causes of the Soviet Union's withdrawal from Afghanistan leading to the Afghanistan regime's eventual defeat include
Destruction in Afghanistan.
Civilian death and destruction from the war was considerable.
Estimates of Afghan civilian deaths vary from 850,000 to 1,500,000. 5–10 million Afghans fled to Pakistan and Iran, 1/3 of the prewar population of the country, and another 2 million were displaced within the country. In the 1980s, half of all refugees in the world were Afghan.
Felix Ermacora, the UN Special Rapporteur to Afghanistan, said that heavy fighting in combat areas cost the lives of more than 35,000 civilians in 1985, 15,000 in 1986, and around 14,000 in 1987. R.J. Rummel, an analyst of political killings, estimated that Soviet forces were responsible for 250,000 democidal killings during the war and that the government of Afghanistan was responsible for 178,000 democidal killings. There were also a number of reports of large scale executions of hundreds of civilians by Soviet and DRA soldiers. Anti-government forces were also responsible for some casualties. Rocket attacks on Kabul's residential areas caused more than 4000 civilian deaths in 1987 according to the UN's Ermacora.
Along with fatalities were 1.2 million Afghans disabled (mujahideen, government soldiers and noncombatants) and 3 million maimed or wounded (primarily noncombatants).
Irrigation systems, crucial to agriculture in Afghanistan's arid climate, were destroyed by aerial bombing and strafing by Soviet or government forces. In the worst year of the war, 1985, well over half of all the farmers who remained in Afghanistan had their fields bombed, and over one quarter had their irrigation systems destroyed and their livestock shot by Soviet or government troops, according to a survey conducted by Swedish relief experts
The population of Afghanistan's second largest city, Kandahar, was reduced from 200,000 before the war to no more than 25,000 inhabitants, following a months-long campaign of carpet bombing and bulldozing by the Soviets and Afghan communist soldiers in 1987. Land mines had killed 25,000 Afghans during the war and another 10–15 million land mines, most planted by Soviet and government forces, were left scattered throughout the countryside. The International Committee of the Red Cross estimated in 1994 that it would take 4,300 years to remove all the Soviet land mines in Afghanistan.
A great deal of damage was done to the civilian children population by land mines. A 2005 report estimated 3–4% of the Afghan population were disabled due to Soviet and government land mines. In the city of Quetta, a survey of refugee women and children taken shortly after the Soviet withdrawal found child mortality at 31%, and over 80% of the children refugees to be unregistered. Of children who survived, 67% were severely malnourished, with malnutrition increasing with age.
Critics of Soviet and Afghan government forces describe their effect on Afghan culture as working in three stages: first, the center of customary Afghan culture, Islam, was pushed aside; second, Soviet patterns of life, especially amongst the young, were imported; third, shared Afghan cultural characteristics were destroyed by the emphasis on so-called nationalities, with the outcome that the country was split into different ethnic groups, with no language, religion, or culture in common.
The Geneva Accords of 1988, which ultimately led to the withdrawal of the Soviet forces in early 1989, left the Afghan government in ruins. The accords had failed to address adequately the issue of the post-occupation period and the future governance of Afghanistan. The assumption among most Western diplomats was that the Soviet-backed government in Kabul would soon collapse; however, this was not to happen for another three years. During this time the Interim Islamic Government of Afghanistan (IIGA) was established in exile. The exclusion of key groups such as refugees and Shias, combined with major disagreements between the different mujaheddin factions, meant that the IIGA never succeeded in acting as a functional government.
Before the war, Afghanistan was already one of the world's poorest nations. The prolonged conflict left Afghanistan ranked 170 out of 174 in the UNDP's "Human Development Index", making Afghanistan one of the least developed countries in the world.
Once the Soviets withdrew, US interest in Afghanistan slowly decreased over the following four years, much of it administered through the DoD Office of Humanitarian Assistance, under the then Director of HA, George M. Dykes III. With the first years of the Clinton Administration in Washington, DC, all aid ceased. The US decided not to help with reconstruction of the country, instead handing the interests of the country over to US allies Saudi Arabia and Pakistan. Pakistan quickly took advantage of this opportunity and forged relations with warlords and later the Taliban, to secure trade interests and routes. The ten years following the war saw much ecological and agrarian destruction—from wiping out the country's trees through logging practices, which has destroyed all but 2% of forest cover country-wide, to substantial uprooting of wild pistachio trees for the exportation of their roots for therapeutic uses, to opium agriculture.
Captain Tarlan Eyvazov, a soldier in the Soviet forces during the war, stated that the Afghan children's future is destined for war. Eyvazov said, "Children born in Afghanistan at the start of the war... have been brought up in war conditions, this is their way of life." Eyvazov's theory was later strengthened when the Taliban movement developed and formed from orphans or refugee children who were forced by the Soviets to flee their homes and relocate their lives in Pakistan. The swift rise to power, from the young Taliban in 1996, was the result of the disorder and civil war that had warlords running wild because of the complete breakdown of law and order in Afghanistan after the departure of the Soviets.
The "CIA World Fact Book" reported that as of 2004, Afghanistan still owed $8 billion in bilateral debt, mostly to Russia, however, in 2007 Russia agreed to cancel most of the debt.
Refugees.
5.5 million Afghans were made refugees by the war—a full one third of the country's pre-war population—fleeing the country to Pakistan or Iran.
A total of 3.3 million Afghan refugees were housed in Pakistan by 1988, some of whom continue to live in the country up until today. Of this total, about 100,000 were based in the city of Peshawar, while more than 2 million were located in other parts of the northwestern province of Khyber Pakhtunkhwa (then known as the North-West Frontier Province). At the same time, close to two million Afghans were living in Iran. Over the years Pakistan and Iran have put on tighter controls for refugees that has resulted in numerous returnees. In 2012 Pakistan banned extension of visas to foreigners. Afghan refugees have also settled in India and became Indian citizens over time. Some also made their way into North America, the European Union, Australia, and other parts of the world. The photo of Sharbat Gula placed on "National Geographic" cover in 1985 became a symbol both of the 1980s Afghan conflict and of the refugee situation.
Aftermath.
Weakening of the Soviet Union.
According to at least scholars Rafael Reuveny and Aseem Prakash, the war contributed to the fall of the Soviet Union by undermining the image of the Red Army as invincible, undermining Soviet legitimacy, and by creating new forms of political participation.
The war created a cleavage between the party and the military in the Soviet Union where the efficacy of using the Soviet military to maintain the USSR's overseas interests was now put in doubt. In the non-Russian republics, those interested in independence were emboldened by the army's defeat. In Russia the war created cleavage between the party and the military, changing the perceptions of leaders about the ability to put down anti-Soviet resistance militarily (as it had in Czechoslovakia in 1968, Hungary in 1956, and East Germany in 1953). As the war was viewed as "a Russian war fought by non Russians against Afghans", outside of Russia it undermined the legitimacy of the Soviet Union as a trans-national political union. The war created new forms of political participation, in the form of new civil organizations of war veterans (Afghansti) which weakened the political hegemony of the communist party. It also started the transformation of the press/media which continued under glasnost.
Civil war.
The war did not end with the withdrawal of the Soviet Army. The Soviet Union left Afghanistan deep in winter, with intimations of panic among Kabul officials. The Afghan mujahideen were poised to attack provincial towns and cities and eventually Kabul, if necessary. Najibullah's government, though failing to win popular support, territory, or international recognition, was able to remain in power until 1992.
Civil war between the Afghan army and mujahideen continued and about 400,000 Afghan civilians had lost their lives in the chaos and civil war of the 1990s. Ironically, until demoralized by the defections of its senior officers, the Afghan Army had achieved a level of performance it had never reached under direct Soviet tutelage. Kabul had achieved a stalemate that exposed the mujahideen's weaknesses, political and military. But for nearly three years, while Najibullah's government successfully defended itself against mujahideen attacks, factions within the government had also developed connections with its opponents.
According to Russian publicist Andrey Karaulov, the main trigger for Najibullah losing power was Russia's refusal to sell oil products to Afghanistan in 1992 for political reasons (the new Yeltsin government did not want to support the former communists), which effectively triggered an embargo. The defection of General Abdul Rashid Dostam and his Uzbek militia, in March 1992, further undermined Najibullah's control of the state. In April, Najibullah and his communist government fell to the mujahideen, who replaced Najibullah with a new governing council for the country.
Grain production declined an average of 3.5% per year between 1978 and 1990 due to sustained fighting, instability in rural areas, prolonged drought, and deteriorated infrastructure. Soviet efforts to disrupt production in rebel-dominated areas also contributed to this decline. During the withdrawal of Soviet troops, Afghanistan's natural gas fields were capped to prevent sabotage. Restoration of gas production has been hampered by internal strife and the disruption of traditional trading relationships following the dissolution of the Soviet Union.
Extremism and "blowback".
Following Soviet withdrawal, some of the foreign volunteers (including Osama bin Laden's Al Qaeda) and young Afghan refugees, went on to continue violent jihad in Afghanistan, Pakistan and abroad. Some of the thousands of Afghan Arabs who left Afghanistan went on to become "capable leaders, religious ideologues and military commanders," who played "vital roles" as insurgents or terrorists in places such as Algeria, Egypt, Bosnia and Chechnya. Tens of thousands of Afghan refugee children in Pakistan were educated in madrasses "in a spirit of conservatism and religious rigor", and went on to fill the ranks and leadership of the Taliban in Afghanistan and Sipah-e-Sahaba in Afghanistan. The groups embodied new varieties of Political Islam -- "Salafi jihadism" among the foreign volunteers, and a "hybrid" Deobandi jihadism among the madrassa-educated.
As many as 35,000 non-Afghan Muslim fighters went to Afghanistan between 1982 and 1992. Thousands more came and did not fight but attended schools with "former and future fighters".
These "Afghan-Arabs" had a marginal impact in the jihad against the Soviets, but a much greater effect after the Soviets left and in other countries. (After the Soviets left, training continued and "tens of thousands" from "some 40 nations" came to prepare for armed insurrection "to bring the struggle back home". )
The man instrumental in not only generating international support but inspiring these volunteers to travel to Afghanistan for the jihad was a Palestinian Muslim Brotherhood cleric, Abdullah Azzam. Touring the Muslim world and the United States, he inspired young Muslims with stories of miraculous deeds, such as mujahideen who defeated vast columns of Soviet troops virtually single-handedly, angels riding into battle on horseback, and falling bombs intercepted by birds.
When back in the volunteer camps and training centers that he helped set up around Peshawar, Pakistan, Azzam exercised a "strong influence." He preached the importance of jihad: "those who believe that Islam can flourish be victorious without Jihad, fighting, and blood are deluded and have no understanding of the nature of this religion"; of not compromising: "Jihad and the rifle alone: no negotiations, no conferences and no dialogues"; and that Afghanistan was only the beginning: jihad would "remain an individual obligation" for Muslims until all other formerly-Muslim lands — "Palestine, Bukhara, Lebanon, Chad, Eritrea, Somalia, the Philippines, Burma, South Yemen, Tashkent, Andalusia" — were reconquered.
The volunteers also influenced each other. Many "unexpected" religious-political ideas resulted from the "cross-pollination" during the "great gathering" of Islamists from dozens of countries in the camps and training centers. One in particular was a "variant of Islamist ideology based on armed struggle and extreme religious vigour", known as Salafi jihadism.
When the Soviet Union fell shortly after their withdrawal from Afghanistan, the volunteers were "exultant", believing that—in the words of Osama bin Laden—the credit for "the dissolution of the Soviet Union ... goes to God and the mujahideen in Afghanistan ... the US had no mentionable role," (Soviet economic troubles and United States aid to mujahideen notwithstanding). They eagerly sought to duplicate their jihad in other countries.
Three such countries were Bosnia, Algeria and Egypt. In Bosnia the Salafi jihadist Afghan Arabs fought against Bosnian Serb and Croat militias but failed to establish a Salafi state. In Algeria and Egypt thousand of volunteers returned and fought but were even less successful. In Algeria Salafi jihadist helped lead and fight for the GIA, deliberately killing thousands of civilians. In Egypt the Al-Gama'a al-Islamiyya killed more than a thousand people between 1990 and 1997 but also failed to overthrow the government.
Among the approximately three million Afghan refugees in Pakistan, thousands of children were educated in madrasa boarding schools financed by aid from the US and Gulf monarchies. Since that aid was distributed according to the conservative Islamist ideological criteria of Pakistan's General Muhammad Zia-ul-Haq and Saudi Arabia (and ignoring native Afghan traditions), the schools were part of networks of the favored Hizb-e-Islami party and the Pakistan Deobandi. (Iran provided similar help to Shia Islamist groups and punishments to moderate Shia nationalist Afghans.)
Cut off from families and local traditions, the madrassa students were "educated to put Deobandi doctrines into action through obedience to the fatwas produced in the madrasses in a spirit of conservatism and religious rigor." As the Afghans students came of age, they formed "the mainstay" of the Taliban in Afghanistan and of the anti-Shia Sipah-e-Sahaba Sunni terror group in Pakistan. But unlike the traditionally non-violent Deobandi, this "hybrid movement" embraced the violence of jihad, and unlike the Islamists of Hizb-e-Islami they were uninterested in "islamizing modernity" of western knowledge or in western knowledge at all. The culture of religious purification, absolute obedience to leaders, and disinterest in anything else, is thought to explain the willingness of Hizb-e-Islami-trained soldiers to bombard Kabul with artillery and kill thousands of civilians, reassured by their commander that the civilians they killed would "be rewarded" in heaven if they were "good Muslims".
From 2008-2014 "thousands of Shia" have been killed by Sunni extremists according to Human Rights Watch.
Blowback, or unintended consequences of funding the mujahideen, was said to have come to the United States in the 1993 World Trade Center bombing and the September 11 attacks. In the 1993 bombing, all of the participants in the bombing "either had served in Afghanistan or were linked to a Brooklyn-based fund-raising organ for the Afghan jihad" that was later "revealed to be al Qaeda's de facto U.S. headquarters". Principals in the 2001 attack—Osama Bin Laden, Khalid Sheikh Mohammed — had both fought in Afghanistan, and bin Laden was a lieutenant of Abdullah Azzam. His group Al Qaeda, returned to Afghanistan to take refuge with the Taliban after being expelled from Sudan. Before the 9/11 attack, Al Qaeda had bombed two U.S. embassies in Africa in 1998, and nearly sank the U.S.S. Cole in Yemen in 2000.
Perception in the former USSR.
Commemorating the intervention of December 25, 1979, in December 2009, veterans of the Soviet war in Afghanistan were honoured by the Duma or Parliament of the Russian Federation. On December 25, the lower house of the parliament defended the Soviet war in Afghanistan on the 30th anniversary of its start, and praised the veterans of the conflict. Differing assessments of the war "mustn't erode the Russian people's respect for the soldiers who honestly fulfilled their duty in implementing tasks to combat international terrorism and religious extremists".
Duma member Semyon Bagdasarov (Just Russia) advocated that Russia had to reject Western calls for stronger assistance to the US-led ISAF-coalition in Afghanistan and also had to establish contacts with the "anti-Western forces"; the Taliban, in case they regain power.

</doc>
<doc id="80200" url="https://en.wikipedia.org/wiki?curid=80200" title="Dean Rusk">
Dean Rusk

David Dean Rusk KBE (February 9, 1909December 20, 1994) was the United States Secretary of State from 1961 to 1969 under presidents John F. Kennedy and Lyndon B. Johnson. Rusk is the joint-second-longest serving U.S. Secretary of State of all time, behind only Cordell Hull and tied with William H. Seward.
Childhood and education.
David Dean Rusk was born in a rural district of Cherokee County, Georgia, to Robert Hugh Rusk and Frances Elizabeth (née Clotfelter) Rusk. He was educated in Atlanta's public schools, graduated from Boys High School in 1925, and spent two years working for an Atlanta lawyer before working his way through Davidson College. Rusk was coached in football by William "Monk" Younger and was a member of the Kappa Alpha Order Sigma chapter, and the national military honor society Scabbard and Blade becoming a Cadet Lieutenant Colonel commanding the Reserve Officers' Training Corps battalion. He graduated Phi Beta Kappa in 1931. While studying in England as a Rhodes Scholar at St. John's College, Oxford, he received the Cecil Peace Prize in 1933.
Rusk married the former Virginia Foisie (October 5, 1915 – February 24, 1996) on June 9, 1937. They had three children: David, Richard and Peggy Rusk.
Rusk taught at Mills College in Oakland, California from 1934 to 1949, and he earned a law degree at the University of California, Berkeley in 1940.
Career prior to 1961.
During World War II he joined the infantry as a reserve captain, and served as a staff officer in the China Burma India Theater. At war's end he was a colonel, decorated with the Legion of Merit with Oak Leaf Cluster.
He returned to America to work briefly for the War Department in Washington. He joined the Department of State in February 1945, and worked for the office of United Nations Affairs. In the same year, he suggested splitting Korea into spheres of U.S. and of Soviet influence at the 38th parallel north. He was made Deputy Under Secretary of State in 1949. He was made Assistant Secretary of State for Far Eastern Affairs in 1950 and played an influential part in the US decision to become involved in the Korean War, and also in Japan's postwar compensation for victorious countries, such as the Rusk documents. However he was a cautious diplomat and always sought international support.
Rusk was a Rockefeller Foundation trustee from 1950 to 1961. In 1952 he succeeded Chester L. Barnard as president of the Foundation.
Secretary of State.
On December 12, 1960, Democratic President-elect John F. Kennedy nominated Rusk to be Secretary of State. According to historian and former Special Assistant to President Kennedy Arthur Schlesinger Jr., Rusk was not Kennedy's first choice, but rather the "lowest common denominator", as Kennedy's first choice, J. William Fulbright, proved too controversial. David Halberstam also described Rusk as "everybody's number two". Rusk was sworn in on January 21, 1961.
As Secretary of State he believed in the use of military action to combat communism. Despite private misgivings about the Bay of Pigs invasion, he remained noncommittal during the Executive Council meetings leading up to the attack and never opposed it outright. During the Cuban Missile Crisis he supported diplomatic efforts. A careful review by Sheldon Stern, Head of the JFK Library, of Kennedy's audio recordings of the EXCOMM meetings suggests that Rusk's contributions to the discussions probably averted a nuclear war. Early in his tenure, he had strong doubts about US intervention in Vietnam, but later his vigorous public defense of US actions in the Vietnam War made him a frequent target of anti-war protests. Outside of his work against communism, he continued his Rockefeller Foundation ideas of aid to developing nations and also supported low tariffs to encourage world trade. Rusk also drew the ire of supporters of Israel after he let it be known that he believed the USS "Liberty" incident was a deliberate attack on the ship, rather than an accident.
As he recalled in his autobiography, "As I Saw It", Rusk did not have a good relationship with President Kennedy. The president was often irritated by Rusk's reticence in advisory sessions and felt that the State Department was "like a bowl of jelly" and that it "never comes up with any new ideas". Special Counsel to the President Ted Sorensen believed that Kennedy, being well versed and practiced in foreign affairs, acted as his own Secretary of State. Sorensen also said that the president often expressed impatience with Rusk and felt him under-prepared for emergency meetings and crises. Rusk repeatedly offered his resignation, but it was never accepted. Rumors of Rusk's dismissal leading up to the 1964 election abounded prior to President Kennedy's trip to Dallas in 1963. Shortly after Kennedy was assassinated, Rusk offered his resignation to the new president, Lyndon B. Johnson. However, Johnson refused Rusk's resignation and retained him as the Secretary of State throughout his administration.
When Johnson died in 1973, Rusk eulogized the former President when he lay in state.
After President of France Charles de Gaulle withdrew France from the common NATO military command in February 1966 and ordered all American military forces to leave France, President Johnson asked Rusk to seek further clarification from President de Gaulle by asking whether the bodies of buried American soldiers must leave France as well. Rusk recorded in his autobiography that de Gaulle did not respond when asked, "Does your order include the bodies of American soldiers in France's cemeteries?"
Rusk offered or planned to offer to resign in the summer of 1967, because "his daughter planned to marry a black classmate at Stanford University, and he could not impose such a political burden on the president" after it became known that his daughter, Peggy, planned to marry Guy Smith, "a black Georgetown grad working at NASA". In fact, the "Richmond News Leader" stated that it found the wedding offensive, further saying that "anything which diminishes personal acceptability is an affair of state".[http://www.time.com/time/magazine/article/0,9171,943987,00.html He decided not to resign after talking first to Robert S. McNamara and Lyndon Johnson.
A year after his daughter's wedding, Rusk was invited to join the faculty of the University of Georgia Law School, only to have his appointment denounced by Roy Harris, an ally of Alabama Governor George Wallace and a member of the university's board of regents, who stated that his opposition was because of Peggy Rusk's interracial marriage. The university nonetheless appointed Rusk to the position.
Retirement.
Rusk received both the Sylvanus Thayer Award and the Presidential Medal of Freedom, with Distinction, in 1969.
Following his retirement, he taught international law at the University of Georgia School of Law in Athens, Georgia (1970–1984). Rusk died of heart failure in Athens, Georgia on December 20, 1994, at the age of 85. He and his wife are buried at the Oconee Hill Cemetery in Athens-Clarke County, Georgia.
Rusk Eating House, the first women’s eating house at Davidson College, was founded in 1977 and is named in his honor. The Dean Rusk International Studies Program at Davidson College is also named in his honor.
Dean Rusk Middle School, located in Canton, Georgia, was named in his honor, as was Dean Rusk Hall on the campus of the University of Georgia.

</doc>
<doc id="80207" url="https://en.wikipedia.org/wiki?curid=80207" title="Sodium chloride">
Sodium chloride

Sodium chloride , also known as salt or halite, is an ionic compound with the chemical formula NaCl, representing a 1:1 ratio of sodium and chloride ions. Sodium chloride is the salt most responsible for the salinity of seawater and of the extracellular fluid of many multicellular organisms. In the form of edible or table salt it is commonly used as a condiment and food preservative. Large quantities of sodium chloride are used in many industrial processes, and it is a major source of sodium and chlorine compounds used as feedstocks for further chemical syntheses. A second major consumer of sodium chloride is de-icing of roadways in sub-freezing weather.
Chemistry.
Solid sodium chloride.
In solid sodium chloride, each ion is surrounded by six ions of the opposite charge as expected on electrostatic grounds. The surrounding ions are located at the vertices of a regular octahedron. In the language of close-packing, the larger chloride ions are arranged in a cubic array whereas the smaller sodium ions fill all the cubic gaps (octahedral voids) between them. This same basic structure is found in many other compounds and is commonly known as the halite or rock-salt crystal structure. It can be represented as a face-centered cubic (fcc) lattice with a two-atom basis or as two interpenetrating face centered cubic lattices. The first atom is located at each lattice point, and the second atom is located half way between lattice points along the fcc unit cell edge.
Solid sodium chloride has a melting point of 801 °C. Thermal conductivity of sodium chloride as a function of temperature has a maximum of 2.03 W/(cm K) at and decreases to 0.069 at . It also decreases with doping.
Aqueous solutions.
The attraction between the Na+ and Cl− ions in the solid is so strong that only highly polar solvents like water dissolve NaCl well.
When dissolved in water, the sodium chloride framework disintegrates as the Na+ and Cl− ions become surrounded by the polar water molecules. These solutions consist of metal aquo complex with the formula [Na(H2O)8]+, with the Na–O distance of 250 pm. The chloride ions are also strongly solvated, each being surrounded by an average of 6 molecules of water. Solutions of sodium chloride have very different properties from pure water. The freezing point is for 23.31 wt% of salt, and the boiling point of saturated salt solution is near . From cold solutions, salt crystallises as the dihydrate NaCl·2H2O.
Unexpected stable stoichiometric variants.
Common salt has a well-established 1:1 molar ratio of sodium and chlorine. In 2013, compounds of sodium and chloride of different stoichiometries have been discovered by a team at Stony Brook University; five new compounds were predicted (e.g., Na3Cl, Na2Cl, Na3Cl2, NaCl3, and NaCl7). The existence of some of them has been tested and experimentally confirmed: cubic and orthorhombic NaCl3 and two-dimensional metallic tetragonal Na3Cl. This indicates that compounds violating chemical intuition are possible, in simple systems under nonambient conditions.
Occurrence.
Small particles of sea salt are the dominant cloud condensation nuclei far out at sea, which allow the formation of clouds in otherwise non-polluted air.
Production.
Salt is currently mass-produced by evaporation of seawater or brine from brine wells and salt lakes. Mining of rock salt is also a major source. China is the world's main supplier of salt. In 2010, world production was estimated at 270 million tonnes, the top five producers (in million tonnes) being China (60.0), United States (45.0), Germany (16.5), India (15.8) and Canada (14.0). Salt is also a byproduct of potassium mining.
Uses.
In addition to the familiar domestic uses of salt, more dominant applications of the approximately 250 megatons/year production (2008 data) include chemicals and de-icing.
Chemicals production.
Salt is used, directly or indirectly, in the production of many chemicals, which consume most of the world's production.
Chlor-alkali industry.
It is the starting point for the chloralkali process, which provides the world with chlorine and sodium hydroxide according to the chemical equation
This electrolysis is conducted in either a mercury cell, a diaphragm cell, or a membrane cell. Each of those use a different method to separate the chlorine from the sodium hydroxide. Other technologies are under development due to the high energy consumption of the electrolysis, whereby small improvements in the efficiency can have large economic paybacks. Some applications of chlorine include PVC, disinfectants, and solvents. Sodium hydroxide enables industries that produce paper, soap, and aluminium.
Soda ash industry.
Via the Solvay process, sodium chloride is used to produce sodium carbonate and calcium chloride. Sodium carbonate is used to produce glass, sodium bicarbonate, and dyes as well as a myriad of other chemicals. In the Mannheim process and in the Hargreaves process, it is used for the production of sodium sulfate and hydrochloric acid.
Standard.
Sodium chloride has an international standard that is created by ASTM International. The standard is named ASTM E534-13 and it is the standard test methods for chemical analysis of sodium chloride. These methods listed provide procedures for analyzing sodium chloride to determine if it is suitable for its intended use and application.
Miscellaneous industrial uses.
Sodium chloride is heavily used, so even miscellaneous applications can consume massive quantities. In oil and gas exploration, salt is an important component of drilling fluids in well drilling. It is used to flocculate and increase the density of the drilling fluid to overcome high downwell gas pressures. Whenever a drill hits a salt formation, salt is added to the drilling fluid to saturate the solution and to minimize the dissolution within the salt stratum. Salt is also used to increase the curing of concrete in cemented casings.
In textiles and dyeing, salt is used as a brine rinse to separate organic contaminants, to promote “salting out” of dyestuff precipitates, and to blend with concentrated dyes to standardize them. One of its main roles is to provide the positive ion charge to promote the absorption of negatively charged ions of dyes.
It also is used in processing aluminium, beryllium, copper, steel and vanadium. In the pulp and paper industry, salt is used to bleach wood pulp. It also is used to make sodium chlorate, which is added along with sulfuric acid and water to manufacture chlorine dioxide, an excellent oxygen-based bleaching chemical. The chlorine dioxide process, which originated in Germany after World War I, is becoming more popular because of environmental pressures to reduce or eliminate chlorinated bleaching compounds. In tanning and leather treatment, salt is added to animal hides to inhibit microbial activity on the underside of the hides and to attract moisture back into the hides.
In rubber manufacture, salt is used to make buna, neoprene and white rubber types. Salt brine and sulfuric acid are used to coagulate an emulsified latex made from chlorinated butadiene.
Salt also is added to secure the soil and to provide firmness to the foundation on which highways are built. The salt acts to minimize the effects of shifting caused in the subsurface by
changes in humidity and traffic load.
Water softening.
Hard water contains calcium and magnesium ions that interfere with action of soap and contribute to the buildup of a scale or film of alkaline mineral deposits in household and industrial equipment and pipes. Commercial and residential water-softening units use ion exchange resins to remove the offending ions that cause the hardness. These resins are generated and regenerated using sodium chloride.
Road salt.
The second major application of salt is for de-icing and anti-icing of roads, both in grit bins and spread by winter service vehicles. In anticipation of snowfall, roads are optimally "anti-iced" with brine (concentrated solution of salt in water), which prevents bonding between the snow-ice and the road surface. This procedure obviates the heavy use of salt after the snowfall. For de-icing, mixtures of brine and salt are used, sometimes with additional agents such as calcium chloride and/or magnesium chloride. The use of salt or brine becomes ineffective below .
Salt for de-icing in the United Kingdom predominantly comes from a single mine in Winsford in Cheshire. Prior to distribution it is mixed with <100 ppm of sodium hexacyanoferrate(II) as an anti-caking agent, which enables rock salt to flow freely out of the gritting vehicles despite being stockpiled prior to use. In recent years this additive has also been used in table salt. Other additives had been used in road salt to reduce the total costs. For example, in the US, a byproduct carbohydrate solution from sugar beet processing was mixed with rock salt and adhered to road surfaces about 40% better than loose rock salt alone. Because it stayed on the road longer, the treatment did not have to be repeated several times, saving time and money.
In the technical terms of physical chemistry, the minimum freezing point of a water-salt mixture is for 23.31 wt% of salt. Freezing near this concentration is however so slow that the eutectic point of can be reached with about 25 wt% of salt.
Environmental effects.
Road salt ends up in fresh water bodies and could harm aquatic plants and animals by disrupting their osmoregulation ability. The omnipresence of salt poses a problem in any coastal coating application, as trapped salts cause great problems in adhesion. Naval authorities and ship builders monitor the salt concentrations on surfaces during construction. Maximum salt concentrations on surfaces are dependent on the authority and application. The IMO regulation is mostly used and sets salt levels to a maximum of 50 mg/m2 soluble salts measured as sodium chloride. These measurements are done by means of a Bresle test.
In highway de-icing, salt has been associated with corrosion of bridge decks, motor vehicles, reinforcement bar and wire, and unprotected steel structures used in road construction. Surface runoff, vehicle spraying, and windblown actions also affect soil, roadside vegetation, and local surface water and groundwater supplies. Although evidence of environmental loading of salt has been found during peak usage, the spring rains and thaws usually dilute the concentrations of sodium in the area where salt was applied. A 2009 study found that approximately 70 percent of the road salt being applied in the Minneapolis-St Paul metro area is retained in the local watershed.
Food industry, medicine and agriculture.
Many microorganisms cannot live in an overly salty environment: water is drawn out of their cells by osmosis. For this reason salt is used to preserve some foods, such as smoked bacon, fish, or cabbage.
Salt is added to food, either by the food producer or by the consumer, as a flavor enhancer, preservative, binder, fermentation-control additive, texture-control agent and color developer. The salt consumption in the food industry is subdivided, in descending order of consumption, into other food processing, meat packers, canning, baking, dairy and grain mill products. Salt is added to promote color development in bacon, ham and other processed meat products. As a preservative, salt inhibits the growth of bacteria. Salt acts as a binder in sausages to form a binding gel made up of meat, fat, and moisture. Salt also acts as a flavor enhancer and as a tenderizer.
In many dairy industries, salt is added to cheese as a color-, fermentation-, and texture-control agent. The dairy subsector includes companies that manufacture creamery butter, condensed and evaporated milk, frozen desserts, ice cream, natural and processed cheese, and specialty dairy products. In canning, salt is primarily added as a flavor enhancer and preservative. It also is used as a carrier for other ingredients, dehydrating agent, enzyme inhibitor and tenderizer. In baking, salt is added to control the rate of fermentation in bread dough. It also is used to strengthen the gluten (the elastic protein-water complex in certain doughs) and as a flavor enhancer, such as a topping on baked goods. The food-processing category also contains grain mill products. These products consist of milling flour and rice and manufacturing cereal breakfast food and blended or prepared flour. Salt is also used a seasoning agent, e.g. in potato chips, pretzels, cat and dog food.
Sodium chloride is used in veterinary medicine as emesis causing agent. It is given as warm saturated solution. Emesis can also be caused by pharyngeal placement of small amount of plain salt or salt crystals.
Firefighting.
Sodium chloride is the principal extinguishing agent in fire extinguishers (Met-L-X, Super D) used on combustible metal fires such as magnesium, potassium, sodium, and NaK alloys (Class D). Thermoplastic powder is added to the mixture, along with waterproofing (metal stearates) and anti-caking materials (tricalcium phosphate) to form the extinguishing agent. When it is applied to the fire, the salt acts like a heat sink, dissipating heat from the fire, and also forms an oxygen-excluding crust to smother the fire. The plastic additive melts and helps the crust maintain its integrity until the burning metal cools below its ignition temperature. This type of extinguisher was invented in the late 1940s as a cartridge-operated unit, although stored pressure versions are now popular. Common sizes are portable and wheeled.
Cleanser.
Since at least medieval times, people have used salt as a cleansing agent rubbed on household surfaces. It is also used in many brands of shampoo, toothpaste and popularly to de-ice driveways and patches of ice.
Optical usage.
Defect-free NaCl crystals have an optical transmittance of about 90% between 200 nm and 20 µm. They were therefore used in optical components (windows and prisms) operating in the infrared spectral range, where few non-absorbing alternatives exist and where requirements for absence of microscopic inhomogeneities are less strict than in the visible range. While inexpensive, NaCl crystals are soft and hygroscopic – when exposed to the ambient air they gradually cover with "frost". This limits application of NaCl to dry environments or for short-term uses such as prototyping. Nowadays materials like zinc selenide (ZnSe), which are stronger mechanically and are less sensitive to moisture, are used instead of NaCl for the IR spectral range.
Biological functions.
The long held belief that a high-salt diet raises the risk of cardio-vascular disease is coming under scrutiny. More recently, dietary salt was demonstrated to attenuate nitric oxide production. Nitric oxide (NO) contributes to vessel homeostasis by inhibiting vascular smooth muscle contraction and growth, platelet aggregation, and leukocyte adhesion to the endothelium.

</doc>
<doc id="80208" url="https://en.wikipedia.org/wiki?curid=80208" title="William Westmoreland">
William Westmoreland

William Childs Westmoreland (March 26, 1914 – July 18, 2005) was a United States Army general, who most notably commanded U.S. forces during the Vietnam War from 1964 to 1968.
From Westmoreland’s arrival in South Vietnam in January 1964, his brief was to achieve outright victory over the Northern-backed Viet Cong, with minimal US casualties, without provoking the Chinese by attacks on the North. Even some of his critics acknowledged that these demands were contradictory, and when casualties inevitably mounted, he was accused of pursuing a war of attrition. During his period of command, both the Battle of Ia Drang (Nov. 1965) and the Tet Offensive (Jan. 1968) were technically US victories, but public discord with the war was sowed by media broadcasting and college students (who had deferred their draft status) were putting pressure through protesting on the government to end the war. By the time he left to become Army chief of staff, US manpower in Vietnam had reached a peak of 535,000. Westmoreland’s strategy, based on artillery and air power, was tactically successful but politically allowed the enemy to destroy the American public's support for the war.
Early life.
William Westmoreland was born in Spartanburg County, South Carolina, to Eugenia Talley Childs and James Ripley Westmoreland. His upper middle class family was involved in the local banking and textile industries. At the age of 15, William became an Eagle Scout at Troop 1 Boy Scouts, and was recipient of the Distinguished Eagle Scout Award and Silver Buffalo from the Boy Scouts of America as a young adult. After spending a year at The Citadel in 1932 he was appointed to attend the United States Military Academy. His motive for entering West Point was "to see the world". He was a member of a distinguished West Point class that also included Creighton Abrams and Benjamin O. Davis Jr. Westmoreland graduated as first captain—the highest cadet rank—and received the Pershing Sword, which is "presented to cadet with highest level of military proficiency". Westmoreland also served as the superintendent of the Protestant Sunday School Teachers.
Start of career.
Following graduation in 1936, he became a artillery officer and served in several with the 18th Field Artillery at Fort Sill. In 1939 he was promoted to first lieutenant, after which he was a battery commander and battalion staff officer with the 8th Field Artillery at Schofield Barracks, Hawaii. 
World War II.
In World War II he saw combat in Tunisia, Sicily, France and Germany. He reached the temporary wartime rank of colonel, and on October 13, 1944, was appointed the chief of staff of the 9th Infantry Division.
Westmoreland established a balanced reputation as a stern taskmaster who cared about his men and took a great interest in their welfare. One called him "the most caring officer, for soldiers, that I have ever known".
Post-World War II.
Westmoreland completed Airborne training at the Infantry School in 1946, after which he commanded 504th Parachute Infantry Regiment, 82d Airborne Division. From 1947 to 1950 he served as chief of staff for the 82d Airborne Division. Westmoreland was an instructor at the Army Command and General Staff College from 1950 to 1951. He completed the Army war College as a student in 1951, and stayed as an instructor from 1951 to 1952.
Korean War.
He commanded the 187th Airborne Regimental Combat Team in operations in Korea from 1952 to 1953. After returning to the United States, Westmoreland was deputy assistant chief of staff, G–1, for manpower control on the Army staff from 1953 to 1955. In 1954 he completed a three-month management program at Harvard Business School. As Stanley Karnow noted, "Westy was a corporation executive in uniform."
Post-Korean War.
From 1955 to 1958 Westmoreland was the Army's Secretary of the General Staff. He commanded the 101st Airborne Division from 1958 to 1960. From 1960 to 1963 he was Superintendent of the United States Military Academy. Westmoreland commanded XVIII Airborne Corps from 1963 to 1964.
In 1962 Westmoreland was admitted as an honorary member of the Massachusetts Society of the Cincinnati.
Vietnam.
Background and overview.
The colonial struggle in Vietnam became part of the global Cold War in October 1949 when a victorious Chinese communist army arrived on Vietnam's northern border and culminated in a decisive French defeat at the Battle of Dien Bien Phu. China, the Soviet Union and other communist nations recognized the North while the United States and other non-communist states recognized the South as the legitimate government. By the time Westmoreland became army commander in South Vietnam, the option of a Korea-type settlement with a large demilitarised zone separating north and south, favored by military and diplomatic figures, had been rejected by the US government, whose objectives were to achieve a decisive victory, and not to use vastly greater resources. The infiltration by regular North Vietnam forces into the South could not be dealt with by aggressive action against the northern state because intervention by China was something the US government was concerned to avoid, but President Lyndon B. Johnson had given commitments to uphold South Vietnam against communist North Vietnam.
Chief of Staff of the United States Army, Harold Keith Johnson, and subsequently historians such as Harry G. Summers, Jr. came to see US goals as having become mutually inconsistent, because defeating the Communists would require declaring a national emergency and fully mobilising the resources of the US. General Johnson was critical of Westmoreland's defused corporate style, considering him over attentive to what government wanted to hear. Nonetheless, Westmoreland was operating within long standing army protocols of subordinating the military to civilian policymakers. The most important constraint was staying on the strategic defensive out of fear of Chinese intervention, but at the same time President Lyndon B. Johnson had made it clear that there was a higher commitment to defending Vietnam. Much of the thinking about defense was by academics turned government advisors who concentrated on nuclear weapons, seen as making conventional war obsolete. The fashion for counter-insurgency thinking also denigrated the role of conventional warfare. Despite the inconclusive outcome of the Korean conflict, Americans expected their wars to end with the unconditional surrender of the enemy.
The Gulf of Tonkin incident of 2 August 1964 led to a dramatic increase in direct American participation in the war, with nearly 200,000 troops deployed by the end of the year. Viet Cong and PAVN strategy, organization and structure meant Westmoreland faced a dual threat. Regular North Vietnamese army units infiltrating across the remote border were apparently concentrating to mount an offensive and Westmoreland considered this the danger that had to be tackled immediately. There was also entrenched guerrilla subversion throughout the heavily populated coastal regions by the Viet Cong. Consistent with the enthusiasm of Robert McNamara for statistics, Westmoreland placed emphasis on body count and cited the Battle of Ia Drang as evidence the communists were losing. However, the government wished to win at low cost, and policymakers received McNamara's interpretation indicating huge American casualties in prospect, prompting a reassessment of what could be achieved. Moreover, the Battle of Ia Drang was unusual in that US troops brought a large enemy formation to battle. After talking to junior officers General Johnson became skeptical about localised concentrated search and destroy sweeps of short duration, because the Communist forces controlled whether there were military engagements, giving an option to simply avoid battle with US forces if the situation warranted it. The alternative of sustained countrywide pacification operations, which would require massive use of US manpower, was never available to Westmoreland, because it was considered politically unacceptable.
In public at least, he continued to be sanguine about the progress being made throughout his time in Vietnam, though supportive journalist James Reston thought Westmoreland's characterizing of the conflict as attrition warfare presented his generalship in a misleading light. Westmoreland's critics say his successor, General Creighton Abrams, deliberately switched emphasis away from what Westmoreland dubbed attrition. Revisionists point to Abrams's first big operation being a tactical success that disrupted North Vietnamese build up, but resulted in the Battle of Hamburger Hill, a political disaster that effectively curtailed Abrams's freedom to continue with such operations.
Vietnam commander.
In January 1964, he became deputy commander of Military Assistance Command, Vietnam. Secretary of Defense Robert McNamara told President Lyndon B. Johnson in April that Westmoreland was "the best we have, without question". As the head of the MACV he was known for highly publicized, positive assessments of U.S. military prospects in Vietnam. However, as time went on, the strengthening of communist combat forces in the South led to regular requests for increases in U.S. troop strength, from 16,000 when he arrived to its peak of 535,000 in 1968 when he was promoted to Army chief of staff.
On April 28, 1967, Westmoreland addressed a joint session of Congress. "In evaluating the enemy strategy," he said, "it is evident to me that he believes our Achilles heel is our resolve. ... Your continued strong support is vital to the success of our mission. ... Backed at home by resolve, confidence, patience, determination, and continued support, we will prevail in Vietnam over the communist aggressor!" Westmoreland claimed that under his leadership, United States forces "won every battle". The turning point of the war was the 1968 Tet Offensive, in which communist forces attacked cities and towns throughout South Vietnam. At the time, Westmoreland was focused on the Battle of Khe Sanh and considered the Tet Offensive to be a diversionary attack. It is not clear if Khe Sanh was meant to be distraction for the Tet Offensive or vice versa. See the Riddle of Khe Sanh. Regardless, U.S. and South Vietnamese troops successfully fought off the attacks during the Tet Offensive, and the communist forces took heavy losses, but the ferocity of the assault shook public confidence in Westmoreland's previous assurances about the state of the war. Political debate and public opinion led the Johnson administration to limit further increases in U.S. troop numbers in Vietnam. Nine months afterward, when the My Lai Massacre reports started to break, Westmoreland resisted pressure from the incoming Nixon administration for a cover-up, and pressed for a full and impartial investigation by Lieutenant General William R. Peers. However, a few days after the tragedy, he had praised the same involved unit on the "outstanding job", for the "U.S. infantrymen had killed 128 Communists ["sic"] in a bloody day-long battle". Post 1969 Westmoreland also made efforts to investigate the Phong Nhị and Phong Nhất massacre a year after the event occurred.
Westmoreland was convinced that the Vietnamese communists could be destroyed by fighting a war of attrition that, theoretically, would render the Vietnam People's Army unable to fight. His war strategy was marked by heavy use of artillery and airpower and repeated attempts to engage the communists in large-unit battles, and thereby exploit the US's vastly superior firepower and technology. However, the North Vietnamese Army (NVA) and the National Liberation Front of South Vietnam (NLF) were able to dictate the pace of attrition to fit their own goals: by continuing to fight a guerrilla war and avoiding large-unit battles, they denied the Americans the chance to fight the kind of war they were best at, and they ensured that attrition would wear down the American public's support for the war faster than they.
Westmoreland repeatedly rebuffed or suppressed attempts by John Paul Vann and Lew Walt to shift to a "pacification" strategy. Westmoreland had little appreciation of the patience of the American public for his time frame, and was struggling to persuade President Johnson to approve widening the war into Cambodia and Laos in order to interdict the Ho Chi Minh trail. He was unable to use the absolutist stance, "we can't win unless we expand the war" Cambodia and Laos. Instead, he focused on "positive indicators," which ultimately turned worthless when the Tet Offensive occurred, since all his pronouncements of "positive indicators" didn't hint at the possibility of such a last-gasp dramatic event. Tet outmaneuvered all of Westmoreland's pronouncements on "positive indicators" in the minds of the American public. Although the communists were severely depleted by the heavy fighting at Khe Sanh when their conventional assaults were battered by American firepower, as well as tens of thousands of deaths in the Tet Offensive, American political opinion and the panic engendered by the communist surprise sapped U.S. support for the war, even though the events of early 1968 put the United States and South Vietnam into a much stronger military position.
Post-Vietnam.
Westmoreland was replaced by General Creighton Abrams in June 1968, the decision being announced shortly after the Tet Offensive. Although the decision had been made in late 1967, it was widely seen in the media as a punishment for being caught off guard by the communist assault.
Westmoreland served as Chief of Staff of the United States Army from 1968 to 1972. In 1970, as Chief of Staff, in response to the My Lai Massacre by U.S. Army forces (and subsequent cover up by the Army chain of command), he commissioned an Army investigation that compiled a comprehensive and seminal study of leadership within the Army during the Vietnam War demonstrating a severe erosion of adherence to the Army's officer code of "Duty, Honor, Country". The report, entitled 'Study on Military Professionalism', had a profound influence on Army policies, beginning with Westmoreland's decision to end the policy that officers serving in Vietnam would be rotated into a different post after only six months. However, to lessen the impact of this damaging report, Westmoreland ordered that the document be kept on "close hold" across the entire Army for a period of two years and not disseminated to War College attendees. The report only became known to the public after Westmoreland retired in 1972.
Many military historians have pointed out that Westmoreland became chief of staff at the worst time in history with regard to the Army. Guiding the Army as it transitioned to an all-volunteer force, he issued many directives to try to make Army life better and more palatable for United States youth—e.g., allowing soldiers to wear sideburns and to drink beer in the mess hall. However, many hard-liners scorned these as too liberal. Westmoreland ran unsuccessfully for governor of South Carolina in 1974. He published his autobiography the following year. Westmoreland later served on a task force to improve educational standards in the state of South Carolina. He was mentioned in a "Time" magazine article as a potential candidate for the 1968 Republican nomination.
In 1986, Westmoreland served as grand marshal of the Chicago Vietnam Veterans parade. The parade, attended by 200,000 Vietnam veterans and more than half a million spectators, did much to repair the rift between Vietnam veterans and the American public.
Westmoreland versus CBS: "The Uncounted Enemy".
Mike Wallace interviewed Westmoreland for the CBS special "The Uncounted Enemy: A Vietnam Deception". The documentary, shown on January 23, 1982, and prepared largely by CBS producer George Crile III, alleged that Westmoreland and others had deliberately underestimated Viet Cong troop strength during 1967 in order to maintain U.S. troop morale and domestic support for the war. Westmoreland filed a lawsuit against CBS.
In "Westmoreland v. CBS", Westmoreland sued Wallace and CBS for libel, and a lengthy legal process began. While the trial was in progress, Westmoreland suddenly settled with CBS for an apology, no more than CBS had originally offered. Some contend that Judge Leval's instructions to the jury over what constituted "actual malice" to prove libel convinced Westmoreland's lawyers that he was certain to lose. Others point out that the settlement occurred after two of Westmoreland's former intelligence officers, Major General Joseph McChristian and Colonel Gains Hawkins, testified to the accuracy of the substantive allegations of the broadcast, which were that Westmoreland ordered changes in intelligence reports on Viet Cong troop strengths for political reasons. Disagreements persist about the appropriateness of some of the methods of CBS's editors.
A deposition by McChristian indicates that his organization developed improved intelligence on the number of irregular Viet Cong combatants shortly before he left Vietnam on a regularly scheduled rotation. The numbers troubled Westmoreland, who feared that the press would not understand them. He did not order them changed, but instead did not include the information in reporting to Washington, which in his view was a decision that the data was not appropriate to report.
Based on later analysis of the information from all sides, it appears clear that Westmoreland could not sustain a libel suit because CBS's principal allegation was that he had caused intelligence officers to suppress facts. Westmoreland's anger was caused by the implication of the broadcast that his intent was fraudulent and that he ordered others to lie.
During the acrimonious trial, Mike Wallace was hospitalized for depression, and despite the legal conflict separating the two, Westmoreland and his wife sent him flowers. Wallace's memoir is generally sympathetic to Westmoreland, although he makes it clear he disagreed with him on issues surrounding the Vietnam War and the Nixon Administration's policies in Southeast Asia.
Views.
In a 1998 interview for "George" magazine, Westmoreland criticized the battlefield prowess of his direct opponent, North Vietnamese general Vo Nguyen Giap. "Of course, he was a formidable adversary", Westmoreland told correspondent W. Thomas Smith Jr. "Let me also say that Giap was trained in small-unit, guerrilla tactics, but he persisted in waging a big-unit war with terrible losses to his own men. By his own admission, by early 1969, I think, he had lost, what, a half million soldiers? He reported this. Now such a disregard for human life may make a formidable adversary, but it does not make a military genius. An American commander losing men like that would hardly have lasted more than a few weeks." In the 1974 film "Hearts and Minds", Westmoreland opined that "The Oriental doesn't put the same high price on life as does a Westerner. ... We value life and human dignity. They don't care about life and human dignity."
Westmoreland's view has been heavily criticized by Nick Turse, the author of the book "Kill Anything That Moves: The Real American War in Vietnam". Turse said that many of the Vietnamese killed were actually innocent civilians, and the Vietnamese casualties were not just caused by military cross-fire but were a direct result of the U.S. policy and tactics, for example the policy "kill everything that moves" which enabled the U.S. soldiers to shoot civilians who had "suspicious behavior". He concluded that, after having "spoken to survivors of massacres by United States forces at Phi Phu, Trieu Ai, My Luoc and so many other hamlets, I can say with certainty that Westmoreland's assessment was false". He also accused Westmoreland of concealing evidence of atrocities from the American public when he was the Army Chief of Staff.
Historian Derek Frisby also criticized Westmoreland's view during an interview with "Deutsche Welle":
For the remainder of his life, Westmoreland maintained that the United States did not lose the war in Vietnam; he stated instead that "our country did not fulfill its commitment to South Vietnam. By virtue of Vietnam, the U.S. held the line for 10 years and stopped the dominoes from falling."
Personal life.
Westmoreland initially met his future wife, Katherine (Kitsy) Stevens Van Deusen, while stationed at Fort Sill; she was nine years old at the time and was the daughter of the post executive officer, Col. Edwin R. Van Deusen. Westmoreland met her again in North Carolina when she was nineteen and a student at UNC Greensboro. The couple married in May 1947 and later had three children: a daughter, Katherine Stevens; a son, James Ripley II, and another daughter, Margaret Childs.
Just hours after Westmoreland was sworn in as Army chief of staff on July 7, 1968, his brother-in-law, Lieutenant Colonel Frederick Van Deusen (commander of 2nd Battalion, 47th Infantry Regiment), was killed when his helicopter was shot down in the Mekong Delta region of Vietnam.
Westmoreland died on July 18, 2005, at the age of 91 at the Bishop Gadsden retirement home in Charleston, South Carolina. He had suffered from Alzheimer's disease during the final years of his life. He was buried on July 23, 2005, at the West Point Cemetery, United States Military Academy.
The General William C. Westmoreland Bridge in Charleston, South Carolina, is named in his honor.
In 1996, the National Society of the Sons of the American Revolution authorized the General William C. Westmoreland award. The award is given each year in recognition to an outstanding SAR veterans volunteer.
William Westmoreland was inducted as a Laureate of The Lincoln Academy of Illinois and awarded the Order of Lincoln (the State’s highest honor) by the Governor of Illinois in 1970 in the area of Government.
Dates of rank.
<br>
<br>
Retired from active service in July 1972.
Awards and decorations.
General Westmoreland's military awards:

</doc>
<doc id="80219" url="https://en.wikipedia.org/wiki?curid=80219" title="Dodona">
Dodona

Dodona (Doric Greek: Δωδώνᾱ, "Dōdṓnā", Ionic and Attic Greek: Δωδώνη, "Dōdṓnē") in Epirus in northwestern Greece was the oldest Hellenic oracle, possibly dating to the second millennium BCE according to Herodotus. The earliest accounts in Homer describe Dodona as an oracle of Zeus. Situated in a remote region away from the main Greek poleis, it was considered second only to the oracle of Delphi in prestige.
Aristotle considered the region around Dodona to have been part of Hellas and the region where the Hellenes originated. The oracle was first under the control of the Thesprotians before it passed into the hands of the Molossians. It remained an important religious sanctuary until the rise of Christianity during the Late Roman era.
Description.
During classical antiquity, according to various accounts, priestesses and priests in the sacred grove interpreted the rustling of the oak (or beech) leaves to determine the correct actions to be taken. According to a new interpretation, the oracular sound originated from bronze objects hanging from oak branches and sounded with the wind blowing, similar to a wind chime.
According to Nicholas Hammond, Dodona was an oracle devoted to a Mother Goddess (identified at other sites with Rhea or Gaia, but here called Dione) who was joined and partly supplanted in historical times by the Greek deity Zeus.
History.
Early history.
Although the earliest inscriptions at the site date to c. 550–500 BCE, archaeological excavations conducted for more than a century have recovered artifacts as early as the Mycenaean era, many now at the National Archaeological Museum of Athens, and some in the archaeological museum at nearby Ioannina.
Cult activity at Dodona was already established in some form during the Late Bronze Age (or Mycenaean period). During the post-Mycenaean period (or "Greek Dark Ages"), evidence of activity at Dodona is scanty, but there is a resumption of contact between Dodona and southern Greece during the Archaic period (8th century BCE) with the presence of bronze votive offerings (i.e. tripods) from southern Greek cities. Archaeologists also have found Illyrian dedications and objects that were received by the oracle during the 7th century BCE. Until 650 BCE, Dodona was a religious and oracular centre mainly for northern tribes: only after 650 BCE did it become important for the southern tribes.
Zeus was worshipped at Dodona as "Zeus Naios" or "Naos" (god of the spring below the oak in the "temenos" or sanctuary, cf. Naiads) and as "Zeus Bouleus" (Counsellor). According to Plutarch, the worship of Jupiter (Zeus) at Dodona was set up by Deucalion and Pyrrha, presumably after the Flood.
The earliest mention of Dodona is in Homer, and only Zeus is mentioned in this account. In the "Iliad" (circa 750 BCE), Achilles prays to "High Zeus, Lord of Dodona, Pelasgian, living afar off, brooding over wintry Dodona" (thus demonstrating that Zeus also could be invoked from a distance). No buildings are mentioned, and the priests (called "Selloi") slept on the ground with unwashed feet. No priestesses are mentioned in Homer.
The oracle also features in another passage involving Odysseus, giving a story of his visit to Dodona. Odysseus's words "bespeak a familiarity with Dodona, a realization of its importance, and an understanding that it was normal to consult Zeus there on a problem of personal conduct."
The details of this story are as follows. Odysseus says to the swineherd Eumaeus (possibly giving him a fictive account) that he (Odysseus) was seen among the Thesprotians, having gone to inquire of the oracle at Dodona whether he should return to Ithaca openly or in secret (as the disguised Odysseus is doing). Odysseus later repeats the same tale to Penelope, who may not yet have seen through his disguise.
According to some scholars, Dodona was originally an oracle of the Mother Goddess attended by priestesses. She was identified at other sites as Rhea or Gaia. The oracle also was shared by Dione (whose name simply means "deity"). By classical times, Dione was relegated to a minor role elsewhere in classical Greece, being made into an aspect of Zeus's more usual consort, Hera — but never at Dodona.
Many dedicatory inscriptions recovered from the site mention both "Dione" and "Zeus Naios".
According to some archaeologists, not until the 4th century BCE, was a small stone temple to Dione added to the site. By the time Euripides mentioned Dodona (fragmentary play "Melanippe") and Herodotus wrote about the oracle, the priestesses appeared at the site.
Classical Greece.
Though it never eclipsed the Oracle of Apollo at Delphi, Dodona gained a reputation far beyond Greece. In the "Argonautica" of Apollonius of Rhodes, a retelling of an older story of Jason and the Argonauts, Jason's ship, the "Argo", had the gift of prophecy, because it contained an oak timber spirited from Dodona.
In c. 290 BCE, King Pyrrhus made Dodona the religious capital of his domain and beautified it by implementing a series of construction projects (i.e. grandly rebuilt the Temple of Zeus, developed many other buildings, added a festival featuring athletic games, musical contests, and drama enacted in a theatre). A wall was built around the oracle itself and the holy tree, as well as temples to Dione and Heracles.
In 219 BCE, the Aetolians, under the leadership of General Dorimachus, invaded and burned the temple to the ground. During the late 3rd century BCE, King Philip V of Macedon (along with the Epirotes) reconstructed all the buildings at Dodona. In 167 BCE, Dodona was destroyed by the Romans (led by Aemilius Paulus), but was later rebuilt by Emperor Augustus in 31 BCE. By the time the traveller Pausanias visited Dodona in the 2nd century CE, the sacred grove had been reduced to a single oak. In 241 CE, a priest named Poplius Memmius Leon organized the Naia festival of Dodona. In 362 CE, Emperor Julian consulted the oracle prior to his military campaigns against the Persians.
Pilgrims still consulted the oracle until 391-392 CE when Emperor Theodosius closed all pagan temples, banned all pagan religious activities, and cut down the ancient oak tree at the sanctuary of Zeus. Although the surviving town was insignificant, the long-hallowed pagan site must have retained significance for Christians given that a Bishop Theodorus of Dodona attended the First Council of Ephesus in 431 CE.
Herodotus.
Herodotus ("Histories" 2:54–57) was told by priests at Egyptian Thebes in the 5th century BCE "that two priestesses had been carried away from Thebes by Phoenicians; one, they said they had heard was taken away and sold in Libya, the other in Hellas; these women, they said, were the first founders of places of divination in the aforesaid countries." The simplest analysis of the quote is: Egypt, for Greeks as well as for Egyptians, was a spring of human culture of all but immeasurable antiquity. This mythic element says that the oracles at the oasis of Siwa in Libya and of Dodona in Epirus were equally old, but similarly transmitted by Phoenician culture, and that the seeresses – Herodotus does not say "sibyls" – were women.
Herodotus follows with what he was told by the prophetesses, called "peleiades" ("doves") at Dodona:
In the simplest analysis, this was a confirmation of the oracle tradition in Egypt. The element of the dove may be an attempt to account for a folk etymology applied to the archaic name of the sacred women that no longer made sense and the eventual connection with Zeus, justified by a tale told by a priestess. Was the "pel-" element in their name connected with "black" or "muddy" root elements in names like "Peleus" or "Pelops"? Is that why the doves were black?
Herodotus adds:
Thesprotia, on the coast west of Dodona, would have been available to the seagoing Phoenicians, whom readers of Herodotus would not have expected to have penetrated as far inland as Dodona.
Strabo.
According to Strabo, the oracle was founded by the Pelasgi:
This oracle, according to Ephorus, was founded by the Pelasgi. And the Pelasgi are called the earliest of all peoples who have held dominion in Greece.
The site of the oracle was dominated by Mount Tomaros, the area being controlled by the Thesprotians and then the Molossians:
In ancient times, then, Dodona was under the rule of the Thesprotians; and so was Mount Tomaros, or Tmaros (for it is called both ways), at the base of which the temple is situated. And both the tragic poets and Pindaros have called Dodona 'Thesprotian Dodona.' But later on it came under the rule of the Molossoi.
According to Pindar, the prophecies were originally uttered by men:
At the outset, it is true, those who uttered the prophecies were men (this too perhaps the poet indicates, for he calls them “hypophetae” and the prophets might be ranked among these), but later on three old women were designated as prophets, after Dione also had been designated as temple-associate of Zeus.
Pindar also reports as uncertain the story that the predecessor of Dodona oracle was located in Thessaly:
...the temple was transferred from Thessaly, from the part of Pelasgia which is about Scotussa (and Scotussa does belong to the territory called Thessalia Pelasgiotis), and also that most of the women whose descendants are the prophetesses of today went along at the same time; and it is from this fact that Zeus was also called “Pelasgian.”
In a fragment of Pindar we find the following:
Among the Thesprotians and the Molossians old women are called "peliai" and old men "pelioi," as is also the case among the Macedonians; at any rate, those people call their dignitaries "peligones" (compare the "gerontes" among the Laconians and the Massaliotes). And this, it is said, is the origin of the myth about the pigeons in the Dodonaean oak-tree.
Other commentaries.
According to Sir Richard Claverhouse Jebb, the epithet "Neuos" of Zeus at Dodona primarily designated "the god of streams, and, generally, of water". Jebb also points out that Achelous, as a water deity, received special honours at Dodona. The area of the oracle was quite swampy, with lakes in the area and reference to the "holy spring" of Dodona may be a later addition.
Jebb mostly follows Strabo in his analysis. Accordingly, he notes that the Selloi, the prophets of Zeus, were also called "tomouroi", which name derived from Mount Tomares. "Tomouroi" was also a variant reading found in the "Odyssey".
According to Jebb, the Peleiades at Dodona were very early, and preceded the appointment of Phemonoe, the prophetess at Delphi. The introduction of female attendants probably took place in the fifth century. The timing of change is clearly prior to Herodotus (5th century BC), with his narrative about the doves and Egypt.
Aristotle (Meteorologica, 1.14) places 'Hellas' in the parts about Dodona and the Achelous and says it was inhabited by "the Selloi, who were formerly called Graikoi, but now Hellenes."
The alternative reading of "Selloi" is "Helloi". Aristotle clearly uses "Dodona" as the designation of the whole district in which the oracle was situated. Thus, according to some scholars, the origin of the words "Hellenes" and "Hellas" was from Dodona. Also, the word "Greece" may have been derived from this area.

</doc>
<doc id="80220" url="https://en.wikipedia.org/wiki?curid=80220" title="Peleiades">
Peleiades

Peleiades (Greek: , "doves") were the sacred women of Zeus and the Mother Goddess, Dione, at the Oracle at Dodona. Pindar made a reference to the Pleiades as the "peleiades" a flock of doves, but the connection seems witty and poetical, rather than mythic. The chariot of Aphrodite was drawn by a flock of doves, however. A mythic element of a black dove that initiated the oracle at Dodona, which Herodotus was told in the 5th century BC may be an attempt to account for a folk etymology applied to the archaic name of the sacred women that no longer made sense (an aitiological myth). Perhaps the "pel-" element in their name was originally connected with "black" or "muddy" root elements in names like Peleus or Pelops and peliganes (Epirotian, Macedonian senators), Attic "polios", Doric "peleios" grey, old, PIE *pel-, "gray". Peleiades are often confused with the nymphs Pleiades.

</doc>
<doc id="80222" url="https://en.wikipedia.org/wiki?curid=80222" title="Robert McNamara">
Robert McNamara

Robert Strange McNamara (June 9, 1916 – July 6, 2009) was an American business executive and the eighth Secretary of Defense, serving from 1961 to 1968 under Presidents John F. Kennedy and Lyndon B. Johnson, during which time he played a major role in escalating the United States involvement in the Vietnam War. Following that, he served as President of the World Bank from 1968 to 1981. McNamara was responsible for the institution of systems analysis in public policy, which developed into the discipline known today as policy analysis. McNamara consolidated intelligence and logistics functions of the Pentagon into two centralized agencies: the Defense Intelligence Agency and the Defense Supply Agency.
Prior to his public service, McNamara was one of the "Whiz Kids" who helped rebuild Ford Motor Company after World War II and briefly served as Ford's President before becoming Secretary of Defense. A group of advisors he brought to the Pentagon inherited the "Whiz Kids" moniker.
McNamara remains the longest serving Secretary of Defense, having remained in office over seven years.
Early life and career.
Robert McNamara was born in San Francisco, California. His father was Robert James McNamara, sales manager of a wholesale shoe company, and his mother was Clara Nell (Strange) McNamara. His father's family was Irish and in about 1850, following the Great Irish Famine, had emigrated to the U.S., first to Massachusetts and later to California. He graduated from Piedmont High School in Piedmont in 1933, where he was president of the Rigma Lions boys club and earned the rank of Eagle Scout. McNamara attended the University of California in Berkeley and graduated in 1937 with a Bachelor of Arts degree in economics with minors in mathematics and philosophy. He was a member of Phi Gamma Delta fraternity, was elected to Phi Beta Kappa his sophomore year, and earned a varsity letter in crew. McNamara was also a member of the UC Berkeley's Order of the Golden Bear which was a fellowship of students and leading faculty members formed to promote leadership within the student body. He then attended Harvard Business School and earned an MBA in 1939.
After business school, McNamara worked a year for the accounting firm Price Waterhouse in San Francisco, then returned to Harvard in August 1940 to teach accounting in the business school and became the highest paid and youngest assistant professor at that time. Following his involvement there in a program to teach analytical approaches used in business to officers of the United States Army Air Forces, he entered the USAAF as a captain in early 1943, serving most of World War II with its Office of Statistical Control. One major responsibility was the analysis of U.S. bombers' efficiency and effectiveness, especially the B-29 forces commanded by Major General Curtis LeMay in India, China, and the Mariana Islands. McNamara established a statistical control unit for XX Bomber Command and devised schedules for B-29s doubling as transports for carrying fuel and cargo over The Hump. He left active duty in 1946 with the rank of lieutenant colonel and with a Legion of Merit.
President of Ford Motor Company.
In 1946, Charles "Tex" Thornton, a colonel under whom McNamara had served, put together a group of officers from his AAF Statistical Control operation to go into business together. Thornton had seen an article in "Life" magazine portraying Ford as being in dire need of reform. Henry Ford II, himself a World War II veteran from the Navy, hired the entire group of 10, including McNamara.
The "Whiz Kids", as they came to be known, helped the money-losing company reform its chaotic administration through modern planning, organization and management control systems. Whiz Kids origins: Because of their youth, combined with asking lots of questions, Ford employees initially and disparagingly, referred to them as the "Quiz Kids". In a remarkable "turning of the tables", these Quiz Kids rebranded themselves as the "Whiz Kids" and backed-up their new moniker with performance driven results. Starting as manager of planning and financial analysis, he advanced rapidly through a series of top-level management positions.
McNamara was a force behind the wildly popular Ford Falcon sedan, introduced in the fall of 1959—a small, simple and inexpensive-to-produce counter to the large, expensive vehicles prominent in the late 1950s. McNamara placed a high emphasis on safety: the "Lifeguard" options package introduced the seat belt (a novelty at the time) and a dished steering wheel which helped to prevent the driver from being impaled on the steering column.
After the Lincoln line's very large 1958, 1959, and 1960 models proved unpopular, McNamara pushed for smaller versions, such as the 1961 Lincoln Continental — now an icon among 1960s automobiles.
On November 9, 1960, McNamara became the first president of Ford Motor Company from outside the Ford family. He received credit for the company's postwar success.
Secretary of Defense.
After his election in 1960, President-elect John F. Kennedy first offered the post of Secretary of Defense to former secretary Robert A. Lovett; Lovett declined but recommended McNamara. Kennedy then sent Sargent Shriver to approach him regarding either the Treasury or the Defense cabinet post less than five weeks after McNamara had become president at Ford. McNamara immediately rejected the Treasury position but eventually accepted Kennedy's invitation to serve as Secretary of Defense.
According to Special Counsel Ted Sorensen, Kennedy regarded McNamara as the "star of his team, calling upon him for advice on a wide range of issues beyond national security, including business and economic matters." McNamara became one of the few members of the Kennedy Administration to work and socialize with Kennedy, and he became so close to Attorney General Robert F. Kennedy that he served as a pallbearer at the younger Kennedy's funeral in 1968. McNamara's specialty was to statistically analyze the efficiency of fighting the protracted Vietnam War, including how to maximize the use of defoliants, bombs, and cannon.
Initially, the basic policies outlined by President Kennedy in a message to Congress on March 28, 1961, guided McNamara in the reorientation of the defense program. Kennedy rejected the concept of first-strike attack and emphasized the need for adequate strategic arms and defense to deter nuclear attack on the United States and its allies. U.S. arms, he maintained, must constantly be under civilian command and control, and the nation's defense posture had to be "designed to reduce the danger of irrational or unpremeditated general war". The primary mission of U.S. overseas forces, in cooperation with allies, was "to prevent the steady erosion of the Free World through limited wars". Kennedy and McNamara rejected massive retaliation for a posture of flexible response. The U.S. wanted choices in an emergency other than "inglorious retreat or unlimited retaliation", as the president put it. Out of a major review of the military challenges confronting the U.S. initiated by McNamara in 1961 came a decision to increase the nation's "limited warfare" capabilities. These moves were significant because McNamara was abandoning President Dwight D. Eisenhower's policy of massive retaliation in favor of a flexible response strategy that relied on increased U.S. capacity to conduct limited, non-nuclear warfare.
The Kennedy administration placed particular emphasis on improving ability to counter communist "wars of national liberation", in which the enemy avoided head-on military confrontation and resorted to political subversion and guerrilla tactics. As McNamara said in his 1962 annual report, "The military tactics are those of the sniper, the ambush, and the raid. The political tactics are terror, extortion, and assassination." In practical terms, this meant training and equipping U.S. military personnel, as well as such allies as South Vietnam, for counterinsurgency operations.
During the Cuban Missile Crisis in October 1962, McNamara served as a member of EXCOMM and played a large role in the Administration's handling and eventual defusing of the Cuban Missile Crisis. He was a strong proponent of the blockade option over a missile strike and helped persuade the Joint Chiefs of Staff to agree with the blockade option.
Increased attention to conventional strength complemented these special forces preparations. In this instance he called up reserves and also proceeded to expand the regular armed forces. Whereas active duty strength had declined from approximately 3,555,000 to 2,483,000 between 1953 (the end of the Korean War) and 1961, it increased to nearly 2,808,000 by June 30, 1962. Then the forces leveled off at around 2,700,000 until the Vietnam military buildup began in 1965, reaching a peak of nearly 3,550,000 by mid-1968, just after McNamara left office.
Other steps.
McNamara took other steps to increase U.S. deterrence posture and military capabilities. He raised the proportion of Strategic Air Command (SAC) strategic bombers on 15-minute ground alert from 25% to 50%, thus lessening their vulnerability to missile attack. In December 1961, he established the United States Strike Command (STRICOM). Authorized to draw forces when needed from the Strategic Army Corps (STRAC), the Tactical Air Command, and the airlift units of the Military Air Transport Service and the military services, Strike Command had the mission "to respond swiftly and with whatever force necessary to threats against the peace in any part of the world, reinforcing unified commands or... carrying out separate contingency operations." McNamara also increased long-range airlift and sealift capabilities and funds for space research and development. After reviewing the separate and often uncoordinated service efforts in intelligence and communications, McNamara in 1961 consolidated these functions in the Defense Intelligence Agency and the Defense Communications Agency (the latter originally established by Secretary Gates in 1960), having both report to the secretary of defense through the JCS. The end effect was to remove the Intelligence function from the control of the military and to put it under the control of the Secretary of Defense. In the same year, he set up the Defense Supply Agency to work toward unified supply procurement, distribution, and inventory management under the control of the Secretary of Defense rather than the uniformed military.
McNamara's institution of systems analysis as a basis for making key decisions on force requirements, weapon systems, and other matters occasioned much debate. Two of its main practitioners during the McNamara era, Alain C. Enthoven and K. Wayne Smith, described the concept as follows: "First, the word 'systems' indicates that every decision should be considered in as broad a context as necessary... The word 'analysis' emphasizes the need to reduce a complex problem to its component parts for better understanding. Systems analysis takes a complex problem and sorts out the tangle of significant factors so that each can be studied by the method most appropriate to it." Enthoven and Smith said they used mainly civilians as systems analysts because they could apply independent points of view to force planning. McNamara's tendency to take military advice into less account than had previous secretaries and to override military opinions contributed to his unpopularity with service leaders. It was also generally thought that Systems Analysis, rather than being objective, was tailored by the civilians to support decisions that McNamara had already made.
The most notable example of systems analysis was the Planning, Programming and Budgeting System (PPBS) instituted by United States Department of Defense Comptroller Charles J. Hitch. McNamara directed Hitch to analyze defense requirements systematically and produce a long-term, program-oriented Defense budget. PPBS evolved to become the heart of the McNamara management program. According to Enthoven and Smith, the basic ideas of PPBS were: "the attempt to put defense program issues into a broader context and to search for explicit measures of national need and adequacy"; "consideration of military needs and costs together"; "explicit consideration of alternatives at the top decision level"; "the active use of an analytical staff at the top policymaking levels"; "a plan combining both forces and costs which projected into the future the foreseeable implications of current decisions"; and "open and explicit analysis, that is, each analysis should be made available to all interested parties, so that they can examine the calculations, data, and assumptions and retrace the steps leading to the conclusions." In practice, the data produced by the analysis was so large and so complex that while it was available to all interested parties, none of them could challenge the conclusions.
Among the management tools developed to implement PPBS were the Five Year Defense Plan (FYDP), the Draft Presidential Memorandum (DPM), the Readiness, Information and Control Tables, and the Development Concept Paper (DCP). The annual FYDP was a series of tables projecting forces for eight years and costs and manpower for five years in mission-oriented, rather than individual service, programs. By 1968, the FYDP covered ten military areas: strategic forces, general purpose forces, intelligence and communications, airlift and sealift, guard and reserve forces, research and development, central supply and maintenance, training and medical services, administration and related activities, and support of other nations.
The DPM—intended for the White House and usually prepared by the systems analysis office—was a method to study and analyze major defense issues. Sixteen DPMs appeared between 1961 and 1968 on such topics as strategic offensive and defensive forces, NATO strategy and force structure, military assistance, and tactical air forces. OSD sent the DPMs to the services and the JCS for comment; in making decisions, McNamara included in the DPM a statement of alternative approaches, force levels, and other factors. The DPM in its final form became a decision document. The DPM was hated by the JCS and uniformed military in that it cut their ability to communicate directly to the White House. The DPMs were also disliked because the systems analysis process was so heavyweight that it was impossible for any service to effectively challenge its conclusions.
The Development Concept Paper examined performance, schedule, cost estimates, and technical risks to provide a basis for determining whether to begin or continue a research and development program. But in practice, what it proved to be was a cost burden that became a barrier to entry for companies attempting to deal with the military. It aided the trend toward a few large non-competitive defense contractors serving the military. Rather than serving any useful purpose, the overhead necessary to generate information that was often in practice ignored resulted in increased costs throughout the system.
The Readiness, Information, and Control Tables provided data on specific projects, more detailed than in the FYDP, such as the tables for the Southeast Asia Deployment Plan, which recorded by month and quarter the schedule for deployment, consumption rates, and future projections of U.S. forces in Southeast Asia.
ABM.
Toward the end of his term McNamara also opposed an anti-ballistic missile (ABM) system proposed for installation in the U.S. in defense against Soviet missiles, arguing the $40 billion "in itself is not the problem; the penetrability of the proposed shield is the problem." Under pressure to proceed with the ABM program after it became clear that the Soviets had begun a similar project, McNamara finally agreed to a "light" system which he believed could protect against the far smaller number of Chinese missiles. However, he never believed it was wise for the United States to move in that direction because of psychological risks of relying too much on nuclear weaponry and that there would be pressure from many directions to build a larger system than would be militarily effective.
He always believed that the best defense strategy for the U.S. was a parity of mutually assured destruction with the Soviet Union. An ABM system would be an ineffective weapon as compared to an increase in deployed nuclear missile capacity.
Cost reductions.
McNamara's staff stressed systems analysis as an aid in decision making on weapon development and many other budget issues. The secretary believed that the United States could afford any amount needed for national security, but that "this ability does not excuse us from applying strict standards of effectiveness and efficiency to the way we spend our defense dollars... You have to make a judgment on how much is enough." Acting on these principles, McNamara instituted a much-publicized cost reduction program, which, he reported, saved $14 billion in the five-year period beginning in 1961. Although he had to withstand a storm of criticism from senators and representatives from affected congressional districts, he closed many military bases and installations that he judged unnecessary to national security. He was equally determined about other cost-saving measures.
Due to the nuclear arms race, the Vietnam War buildup and other projects, total obligational authority (TOA) increased greatly during the McNamara years. Fiscal year TOA increased from $48.4 billion in 1962 to $49.5 billion in 1965 (before the major Vietnam increases) to $74.9 billion in 1968, McNamara's last year in office (though he left office in February). Not until FY 1984 did DoD's total obligational authority surpass that of FY 1968 in constant dollars.
Program consolidation.
One major hallmark of McNamara's cost reductions was the consolidation of programs from different services, most visibly in aircraft acquisition, believing that the redundancy created waste and unnecessary spending. McNamara directed the Air Force to adopt the Navy's F-4 Phantom and A-7 Corsair combat aircraft, a consolidation that was quite successful. Conversely, his actions in mandating a premature across-the-board adoption of the untested M16 rifle proved catastrophic when the weapons began to fail in combat. McNamara tried to extend his success by merging development programs as well, resulting in the TFX dual service F-111 project. It was to combine Navy requirements for an Fleet Air Defense (FAD) aircraft and Air Force requirements for a tactical bomber. His experience in the corporate world led him to believe that adopting a single type for different missions and service would save money. He insisted on the General Dynamics entry over the DOD's preference for Boeing because of commonality issues. Though heralded as a fighter that could do everything (fast supersonic dash, slow carrier and short airfield landings, tactical strike, and even close air support), in the end it involved too many compromises to succeed at any of them. The Navy version was drastically overweight and difficult to land, and eventually canceled after a Grumman study showed it was incapable of matching the abilities of the newly revealed Soviet MiG-23 and MiG-25 aircraft. The F-111 would eventually find its niche as a tactical bomber and electronic warfare aircraft with the Air Force.
However, many analysts believe that even though the TFX project itself was a failure, McNamara was ahead of his time as the trend in fighter design has continued toward consolidation — the F-16 Falcon and F/A-18 Hornet emerged as multi-role fighters, and most modern designs combine many of the roles the TFX would have had. In many ways, the Joint Strike Fighter is seen as a rebirth of the TFX project, in that it purports to satisfy the needs of three American Air arms (as well as several foreign customers), fulfilling the roles of strike fighter, carrier-launched fighter, V/STOL, and close air support (and drawing many criticisms similar to those leveled against the TFX).
Vietnam War.
During President John F. Kennedy's term, while McNamara was Secretary of Defense, America's troops in Vietnam increased from 900 to 16,000 advisers, who were not supposed to engage in combat but rather to train the Army of the Republic of Vietnam. The number of combat advisers in Vietnam when Kennedy died vary depending upon source. The first military adviser deaths in Vietnam occurred in 1957 or 1959 under the Eisenhower Administration, which had infiltrated Vietnam, through the efforts of Stanley Sheinbaum, with an unknown number of CIA operatives and other special forces in addition to almost 700 advisers.
The Truman and Eisenhower administrations had committed the United States to support the French and native anti-Communist forces in Vietnam in resisting efforts by the Communists in the North to unify the country, though neither administration established actual combat forces in the war. The U.S. role—initially limited to financial support, military advice and covert intelligence gathering—expanded after 1954 when the French withdrew. During the Kennedy administration, the U.S. military advisory group in South Vietnam steadily increased, with McNamara's concurrence, from 900 to 16,000. U.S. involvement escalated after the Gulf of Tonkin incidents in August 1964, involving two purported attacks on a U.S. Navy destroyer by North Vietnamese naval vessels.
But declassified records from the Lyndon Johnson Library indicated that McNamara misled Johnson on the attack on a U.S. Navy destroyer by withholding calls against executing airstrikes from US Pacific Commanders. Instead, McNamara issued the strike orders without informing Johnson of the hold calls, constituting a usurping of the president’s constitutional power of decision on the use of military force. McNamara was also instrumental in presenting the event to Congress and the public as justification for escalation of the war against the communists. In 1995, McNamara met with former North Vietnam Defense Minister Vo Nguyen Giap who told his American counterpart that the Aug. 4 attack never happened, a conclusion McNamara eventually came to accept.
President Johnson ordered retaliatory air strikes on North Vietnamese naval bases. Congress approved, with only Senators Wayne Morse (D-OR), and Ernest Gruening (D-AK), voting against, the Gulf of Tonkin Resolution, authorizing the president "to take all necessary measures to repel any armed attack against the forces of the U.S. and to prevent further aggression." Regardless of the particulars of the incident, the larger issue would turn out to be the sweeping powers granted by the resolution. It gave Johnson virtually unfettered authority to expand retaliation for a relatively minor naval incident into a major land war involving 500,000 American soldiers. "The fundamental issue of Tonkin Gulf involved not deception but, rather, misuse of power bestowed by the resolution," McNamara wrote later.
In 1965, in response to stepped up military activity by the Viet Cong in South Vietnam and their North Vietnamese allies, the U.S. began bombing North Vietnam, deployed large military forces and entered into combat in South Vietnam. McNamara's plan, supported by requests from top U.S. military commanders in Vietnam, led to the commitment of 485,000 troops by the end of 1967 and almost 535,000 by June 30, 1968. The casualty lists mounted as the number of troops and the intensity of fighting escalated. McNamara put in place a statistical strategy for victory in Vietnam. He concluded that there were a limited number of Viet Cong fighters in Vietnam and that a war of attrition would destroy them. He applied metrics (body counts) to determine how close to success his plan was.
Although he was a prime architect of the Vietnam War and repeatedly overruled the JCS on strategic matters, McNamara gradually became skeptical about whether the war could be won by deploying more troops to South Vietnam and intensifying the bombing of North Vietnam, a claim he would publish in a book years later. He also stated later that his support of the Vietnam War was given out of loyalty to administration policy. He traveled to Vietnam many times to study the situation firsthand and became increasingly reluctant to approve the large force increments requested by the military commanders.
McNamara said that the Domino Theory was the main reason for entering the Vietnam War. In the same interview he stated, "Kennedy hadn't said before he died whether, faced with the loss of Vietnam, he would withdraw; but I believe today that had he faced that choice, he would have withdrawn."
Social equity.
To commemorate President Harry S Truman's signing an order to end segregation in the military McNamara issued Directive 5120.36 on July 26, 1963. This directive, Equal Opportunity in the Armed Forces, dealt directly with the issue of racial and gender discrimination in areas surrounding military communities. The directive declared, "Every military commander has the responsibility to oppose discriminatory practices affecting his men and their dependents and to foster equal opportunity for them, not only in areas under his immediate control, but also in nearby communities where they may live or gather in off-duty hours." (para. II.C.) Under the directive, commanding officers were obligated to use the economic power of the military to influence local businesses in their treatment of minorities and women. With the approval of the Secretary of Defense, the commanding officer could declare areas off-limits to military personnel for discriminatory practices.
Departure.
McNamara wrote of his close personal friendship with Jackie Kennedy, and how she demanded that he stop the killing in Vietnam. As McNamara grew more and more controversial after 1966 and his differences with the President and the Joint Chiefs of Staff over Vietnam strategy became the subject of public speculation, frequent rumors surfaced that he would leave office. In an early November 1967 memorandum to Johnson, McNamara's recommendation to freeze troop levels, stop bombing North Vietnam and for the U.S. to hand over ground fighting to South Vietnam was rejected outright by the President. McNamara's recommendations amounted to his saying that the strategy of the United States in Vietnam which had been pursued to date had failed. McNamara later stated he "never heard back" from Johnson regarding the memo. Largely as a result, on November 29 of that year, McNamara announced his pending resignation and that he would become President of the World Bank. Other factors were the increasing intensity of the anti-war movement in the U.S., the approaching presidential campaign in which Johnson was expected to seek re-election, and McNamara's support—over the objections of the Joint Chiefs of Staff—of construction along the 17th parallel separating South and North Vietnam of a line of fortifications running from the coast of Vietnam into Laos. The President's announcement of McNamara's move to the World Bank stressed his stated interest in the job and that he deserved a change after seven years as Secretary of Defense, longer than any of his predecessors or successors.
Others give a different view of McNamara's departure from office. For example, Stanley Karnow in his book "Vietnam: A History" strongly suggests that McNamara was asked to leave by the President. McNamara himself expressed uncertainty about the question.
McNamara left office on February 29, 1968; for his efforts, the President awarded him both the Medal of Freedom and the Distinguished Service Medal.
Shortly after McNamara departed the Pentagon, he published "The Essence of Security", discussing various aspects of his tenure and position on basic national security issues. He did not speak out again on defense issues or Vietnam until after he left the World Bank.
World Bank President.
Robert McNamara served as head of the World Bank from April 1968 to June 1981, when he turned 65. In his 13 years at the Bank, he introduced key changes, most notably, shifting the Bank's focus toward targeted poverty reduction. He negotiated, with the conflicting countries represented on the Board, a growth in funds to channel credits for development, in the form of health, food, and education projects. He also instituted new methods of evaluating the effectiveness of funded projects. One notable project started during McNamara's tenure was the effort to prevent river blindness.
The World Bank currently has a scholarship program under his name.
As World Bank President, he declared at the 1968 Annual Meeting of the International Monetary Fund and the World Bank Group that countries permitting birth control practices would get preferential access to resources.
Post-World Bank activities and assessments.
In 1982, McNamara joined several other former national security officials in urging that the United States pledge not to use nuclear weapons first in Europe in the event of hostilities; subsequently he proposed the elimination of nuclear weapons as an element of NATO's defense posture.
In 1993, Washington journalist Deborah Shapley published a 615-page biography of Robert McNamara entitled "". The last pages of her book made clear that while Ms. Shapley deeply admired certain aspects of McNamara the man, and the public servant, she had seen first-hand his need to manipulate the truth, as well as to tell it. Shapley concluded her book with these words: "For better and worse McNamara shaped much in today's world – and imprisoned himself. A little-known nineteenth century writer, F.W. Boreham, offers a summation: `We make our decisions. And then our decisions turn around and make us.'"
McNamara's memoir, "In Retrospect", published in 1995, presented an account and analysis of the Vietnam War from his point of view. According to his lengthy "New York Times" obituary, "e concluded well before leaving the Pentagon that the war was futile, but he did not share that insight with the public until late in life. In 1995, he took a stand against his own conduct of the war, confessing in a memoir that it was 'wrong, terribly wrong.'" In return, he faced a "firestorm of scorn" at that time.
"The Fog of War: Eleven Lessons from the Life of Robert S. McNamara" is a 2003 Errol Morris documentary consisting mostly of interviews with Robert McNamara and archival footage. It went on to win the Academy Award for Documentary Feature. The particular structure of this personal account is accomplished with the characteristics of an intimate dialog. As McNamara explains, it is a process of examining the experiences of his long and controversial period as the United States Secretary of Defense, as well as other periods of his personal and public life. In this documentary he referred to the Vietnam War and he said, "None of our allies supported us. Not Japan, not Germany, not Britain or France. If we can't persuade nations with comparable values of the merit of our cause, we'd better reexamine our reasoning." (However, 60,000 Australians & 3,500 New Zealanders fought in the Vietnam War, where respectively 500 & 37 died, and 3,000 & 187 were wounded.)
The most striking part of the dialog is that he claims the Vietnam War was the result of the catastrophic failure of the American and Vietnamese leaderships to understand each other's intentions. The North Vietnamese were fighting an anti-colonial war of independence and the United States was fighting the Cold War. But the United States had no intention of colonizing Vietnam or even exerting the sort of control over it that the Soviet Union exerted over Eastern European countries. And Vietnam saw communist China largely as another threat to it, not an ally in a global war against capitalism. When McNamara visited Vietnam as part of the documentary, he asked his former counterpart about Chinese support for the north, and his counterpart asked if he had ever read a history textbook because China and Vietnam had been fighting each other for a thousand years.
His acknowledgement that the firebombing of Tokyo with General LeMay would have rightfully been considered a war crime had the US lost the war is also striking, especially given his own involvement in this action. Yet he stops short of expressing remorse given that he believed at the time that the action would save many American lives. The documentary contrasts the attitude of General Curtis LeMay, who believed that almost anything was justifiable in the name of military efficiency, with McNamara's more nuanced and indeed conflicted attitude.
The eleven lessons explored in the documentary are:
McNamara maintained his involvement in politics in his later years, delivering statements critical of the Bush administration's 2003 invasion of Iraq. On January 5, 2006, McNamara and most living former Secretaries of Defense and Secretaries of State met briefly at the White House with President Bush to discuss the war.
McNamara has been portrayed or fictionalized in several films and in at least one popular video game. Simon & Garfunkel's 1966 album, "Parsley, Sage, Rosemary and Thyme" contained a song entitled A Simple Desultory Philippic (or How I Was Robert McNamara'd into Submission).
Personal life.
McNamara married Margaret Craig, his teenage sweetheart, on August 13, 1940. She was an accomplished cook, and Robert's favorite dish was reputed to be her beef bourguignon. Margaret McNamara, a former teacher, used her position as a Cabinet spouse to launch a reading program for young children, Reading Is Fundamental, which became the largest literacy program in the country. She died of cancer in 1981.
The couple had two daughters and a son. The son Robert Craig McNamara, who as a student objected to the Vietnam War, is now a walnut and grape farmer in California. He is the owner of Sierra Orchards in Winters, California. Daughter Kathleen McNamara Spears is a forester with the World Bank. The second daughter is Margaret Elizabeth Pastor.
In the Errol Morris documentary, McNamara reports that both he and his wife were stricken with polio shortly after the end of World War II. Although McNamara had a relatively short stay in the hospital, his wife's case was more serious and it was concern over meeting her medical bills that led to his decision to not return to Harvard but to enter private industry as a consultant at Ford Motor Company.
When working at Ford Motor Company, McNamara resided in Ann Arbor, Michigan, rather than the usual auto executive domains of Grosse Pointe, Birmingham, and Bloomfield Hills. He and his wife sought to remain connected with a university town (the University of Michigan) after their hopes of returning to Harvard after the war were put on hold.
In 1961, he was named Alumnus of the Year by the University of California, Berkeley.
On September 29, 1972, a passenger on the ferry to Martha's Vineyard recognized McNamara on board and attempted to throw him into the ocean. McNamara declined to press charges. The man remained anonymous, but was interviewed years later by author Paul Hendrickson, who quoted the attacker as saying, "I just wanted to confront (McNamara) on Vietnam."
After his wife's death, McNamara dated Katharine Graham, with whom he had been friends since the early 1960s. Graham died in 2001.
In September 2004, McNamara wed Diana Masieri Byfield, an Italian-born widow who had lived in the United States for more than 40 years. It was her second marriage. She was married for more than three decades to Ernest Byfield, a former OSS officer and Chicago hotel heir whose mother, Gladys Tartiere, leased her , Glen Ora estate in Middleburg, Virginia to John F. Kennedy during his presidency.
McNamara was, at the end of his life, a life trustee on the Board of Trustees of the California Institute of Technology (Caltech), a trustee of the Economists for Peace and Security, a trustee of the American University of Nigeria, and an honorary trustee for the Brookings Institution.
McNamara died in his sleep, at his home in Washington, D.C., early in the morning, at 5:30 a.m. on July 6, 2009, at the age of 93. He is buried at the Arlington National Cemetery in Arlington, Virginia.

</doc>
<doc id="80223" url="https://en.wikipedia.org/wiki?curid=80223" title="Doris">
Doris

Doris may refer to:

</doc>
<doc id="80224" url="https://en.wikipedia.org/wiki?curid=80224" title="Clark Clifford">
Clark Clifford

Clark McAdams Clifford (December 25, 1906October 10, 1998) was an American lawyer who served as an important political advisor to Democratic Presidents Harry S. Truman, John F. Kennedy, Lyndon B. Johnson and Jimmy Carter. His official government positions were White House Counsel (1946–1950), Chairman of the President's Intelligence Advisory Board (1963–1968), and Secretary of Defense (1968–1969); Clifford was also influential in his role as an unofficial, informal presidential advisor in various issues. A successful Washington lawyer, he was known for his elite clientele, charming manners and impeccable suits.
In his later years, Clifford became involved in several controversies. He was a key figure in the Bank of Credit and Commerce International scandal, which led to a grand jury indictment.
Early life and career.
Clifford was born in Fort Scott, Kansas, the son of Frank Clifford and Georgia Clifford (née McAdams). He attended college and law school at Washington University in St. Louis, Missouri, and built a solid reputation practicing law in St. Louis between 1928 and 1943.
He served as an officer in the U.S. Navy from 1944 to 1946, reaching the rank of captain and serving as assistant naval aide and then naval aide to President Truman, for whom he became a trusted personal adviser and friend.
Presidential advisor.
Clifford went to Washington, D.C., first to serve as assistant to the President's Naval Adviser, after the naming of a personal friend from Missouri as the President's Naval Adviser. Following his discharge from the Navy, he remained at Truman's side as White House Counsel from 1946 to 1950, as Truman came rapidly to trust and rely upon Clifford.
Clifford was a key architect of Truman's campaign in 1948, when Truman pulled off a stunning upset victory over Republican nominee Thomas Dewey. Clifford encouraged Truman to embrace a left-wing populist image in hope of undermining the impact on the race of third-party Progressive candidate Henry A. Wallace, who had served as President Franklin D. Roosevelt's Vice-President from 1941 to 1945. Clifford also believed that a strong pro-civil rights stance, while sure to alienate traditional Southern Democrats, would not result in a serious challenge to the party's supremacy in that region. This prediction was foiled by Strom Thurmond's candidacy as a splinter States' Rights Democrat, but Clifford's strategy nonetheless helped win Truman election in his own right and establish the Democratic Party's position in the Civil Rights Movement.
In his role as presidential adviser, one of his most significant and controversial contributions was his successful advocacy, along with David Niles, of prompt 1948 recognition of the new "Jewish state" of Israel, over the strong objections of Secretary of State, General George Marshall.
Of similar importance, with the input of senior officials in the Departments of State, War, and Justice, the Joint Chiefs of Staff, and the Central Intelligence Group, and utilizing the expertise of George F. Kennan and Charles Bohlen, was his preparation, along with George Elsey, of the top secret Clifford-Elsey Report for President Truman in 1946. That report, solicited by the President, which detailed the numerous ways in which the Soviet Union had gone back on its various treaties and understandings with the Western powers, along with Kennan's X Article in "Foreign Affairs", was instrumental in turning U.S. relations toward the Soviet Union in the direction of a harder line.
After leaving the government in 1950, Clifford practiced law in Washington, D.C., but continued to advise Democratic Party leaders. One of his law clients was Kennedy, then a U.S. Senator, and Clifford tried to assuage Truman's suspicion of Kennedy and his father, Joseph P. Kennedy.
In 1960, Clifford was a member of President-elect Kennedy's Committee on the Defense Establishment, headed by Stuart Symington. In May 1961, Kennedy appointed Clifford to the President's Foreign Intelligence Advisory Board, which he chaired beginning in April 1963 and ending in January 1968.
After Johnson became president in November 1963 following Kennedy's assassination, Clifford served frequently as an unofficial White House Counsel and sometimes undertook short-term official duties, including a trip with General Maxwell Taylor in 1967 to Vietnam and other countries in Southeast Asia and the Pacific.
Secretary of Defense.
On January 19, 1968, Johnson announced his selection of Clifford to succeed Robert McNamara as the U.S. Secretary of Defense. Clifford estimated that, in the year just prior to his appointment, he had spent about half of his time advising the President and the other half working for his law firm.
Widely known and respected in Washington and knowledgeable on defense matters, Clifford was generally hailed as a worthy successor to McNamara. Many regarded the new secretary as more of a hawk on Vietnam than McNamara, and thought his selection might presage an escalation of the U.S. military effort there. Clifford attempted to allay such fears when, responding to a query about whether he was a hawk (favoring aggressive military action) or a dove (favoring a peaceful resolution to the Vietnam War), he remarked, "I am not conscious of falling under any of those ornithological divisions."
The new Secretary did not change the management system McNamara had installed at The Pentagon, and for the most part assigned internal administration to Deputy Secretary of Defense Paul H. Nitze. Clifford made no effort to depart from McNamara's policies and programs on such matters as nuclear strategy, NATO, and military assistance, but he favored the Sentinel anti-ballistic missile system, to which McNamara had given only lukewarm backing. Clifford wanted to deploy the system, and supported congressional appropriations for it. One important effect of Sentinel construction, he thought, would be to encourage the Soviet Union to enter arms control talks with the U.S. Indeed, before Clifford left office, the Johnson administration made arrangements for negotiations that eventually led to the Anti-Ballistic Missile Treaty of 1972.
Clifford continued McNamara's highly publicized Cost Reduction Program, announcing that over $1.2 billion had been saved in fiscal year (FY) 1968 as a result of the effort. Faced with a congressionally mandated reduction of expenditures in FY 1969, Clifford suspended the planned activation of an infantry division and deactivated 50 small ships, 9 naval air squadrons, and 23 Nike-Hercules missile launch sites.
By the time Clifford became secretary, Defense Department work on the fiscal year 1969 budget was complete. It amounted in total obligational authority to $77.7 billion, almost $3 billion more than in FY 1968. The final FY 1970 budget, which Clifford and his staff worked on before they left office after the election of Richard Nixon to the presidency, amounted to $75.5 billion TOA (Total Obligational Authority.
Vietnam.
Clifford took office committed to rethinking Johnson's Vietnam policies, and Vietnam policy consumed most of his time. He had argued against escalation in 1965 in private counsel with the president, but then provided public support for the president's position once the decision was made. At his confirmation hearing, he told the Armed Services Committee of the U.S. Senate that the limited objective of the U.S. was to guarantee to the people of South Vietnam the right of self-determination. He opposed ending the U.S. bombing of North Vietnam at the time, but acknowledged that the situation could change.
In fact, on March 31, 1968, just a month after Clifford arrived at The Pentagon, Johnson, in an effort to get peace talks started, ordered the cessation of bombing north of the 20th parallel, an area comprising almost 80 percent of North Vietnam's land area and 90 percent of its population. In the same address, Johnson announced that he would not be a candidate for reelection in 1968, surprising everyone, Clifford included. Soon the North Vietnamese agreed to negotiations, which began in Paris in mid-May 1968. Later, on October 31, 1968, to encourage the success of these talks, the President, with Clifford's strong support, ordered an end to all bombing in North Vietnam.
Clifford, like McNamara, had to deal with frequent requests for additional troops from military commanders in Vietnam. When he became secretary, the authorized force in Vietnam was 525,000. Soon after moving into his Pentagon office, Clifford persuaded Johnson to deny General William Westmoreland's request for an additional 206,000 American troops in Vietnam.
At the end of March 1968, however, the president agreed to send 24,500 more troops on an emergency basis, raising authorized strength to 549,500, a figure never reached. Even as he oversaw a continued buildup, Clifford preferred to emphasize the points Johnson had made in his March 31, 1968 address: that the South Vietnamese army could take over a greater share of the fighting, that the administration would place an absolute limit on the number of U.S. troops in Vietnam, and that it would take steps, including the bombing restrictions, to reduce the combat level.
Eventually Clifford moved very close, with Johnson's tacit support, to the views McNamara held on Vietnam just before he left office—no further increases in U.S. troop levels, support for the bombing halt, and gradual disengagement from the conflict. By this time Clifford clearly disagreed with Secretary of State Dean Rusk, who believed, according to "The Washington Post," "that the war was being won by the allies" and that it "would be won if America had the will to win it." He later recalled how he turned against the war: "I found out that we couldn’t win the war with the limitations that we had, which I thought were correct limitations, and I thought all we were going to do was just waste the lives of our men and our treasure out in the jungles of North and South Vietnam."
After he left office, Clifford, in the July 1969 issue of "Foreign Affairs," made his views very clear: "Nothing we might do could be so beneficial ... as to begin to withdraw our combat troops. Moreover ... we cannot realistically expect to achieve anything more through our military force, and the time has come to begin to disengage. That was my final conclusion as I left the Pentagon ..." Clifford received the Presidential Medal of Freedom, with Distinction, from Johnson on the President's last day in office, January 20, 1969.
Although the Johnson Administration ended under the cloud of the Vietnam War, Clifford concluded his short term as Secretary of Defense with his reputation actually enhanced. He got along well with the U.S. Congress, and this helped him to secure approval of at least some of his proposals. He settled into his duties quickly and efficiently, and capably managed the initial de-escalation of U.S. involvement in Vietnam; indeed, he apparently strongly influenced Johnson in favor of a de-escalation strategy. As he left office to return to his law practice in Washington, Clifford expressed the hope and expectation that international tensions would abate, citing the shift in the Vietnam confrontation from the battlefield to the conference table, and the evident willingness of the Soviet Union to discuss limitations on strategic nuclear weapons.
Special presidential emissary to India.
Clifford's legal practice and lobbying work made him wealthy, and he was considered one of Washington's "superlawyers" due to the reach of his influence and seemingly limitless connections. Clifford's office overlooked the White House, emphasizing his long experience in the capital. Clifford was renowned for his seemingly effortless charm, style, tact and discretion.
In 1980, President Carter appointed him as special presidential emissary to India.
Clifford made waves by threatening the newly established regime of Ayatollah Khomeini of Iran with war for its intransigence in negotiating the release of the hostages seized from the U.S. embassy in Tehran.
He also referred to President Ronald Reagan as an "amiable dunce" at a Washington dinner party.
Bank of Credit and Commerce International.
In 1991, Clifford's memoirs "Counsel to the President" (co-authored with Richard Holbrooke, later U.S. Ambassador to the United Nations) were published just as his name was implicated in the unfolding Bank of Credit and Commerce International (BCCI) scandal. The scandal focused on the criminal conduct of the international bank and its control of financial institutions nationwide. The bank was found by regulators in the U.S. and the United Kingdom to be involved in money laundering, bribery, support of terrorism, arms trafficking, the sale of nuclear technologies, the commission and facilitation of tax evasion, smuggling, illegal immigration, and the illicit purchases of banks and real estate. The bank was found to have at least $13 billion in unaccounted funds. 
From 1982 to 1991, Clifford served as chairman of First American Bankshares, which grew to become the largest bank in Washington, D.C. The bank was nominally owned by a group of Arab investors, but in order to assuage fears from the Federal Reserve, Clifford had assembled a board of distinguished American citizens to exercise day-to-day control. In 1991, Robert M. Morgenthau, the District Attorney for New York County (coterminous with the borough of Manhattan), disclosed that his office had found evidence that BCCI secretly owned First American. Morgenthau convened a grand jury to determine whether Clifford and his partner, Robert A. Altman, had deliberately misled federal regulators when the two men assured them that BCCI would have no outside control.
An audit by Price Waterhouse revealed that contrary to agreements between First American's nominal investors and the Federal Reserve, many of the investors had borrowed heavily from BCCI. Even more seriously, they had pledged their First American stock as collateral. When they missed interest payments, BCCI took control of the shares. It was later estimated that in this manner, BCCI had ended up with 60 percent or more of First American's stock. There had long been suspicions that First American's investors were actually nominees for BCCI. However, the audit was solid confirmation that BCCI secretly — and illegally — owned First American.
Clifford's predicament worsened when it was disclosed he had made about $6 million in profits from bank stock that he had bought with an unsecured loan from BCCI. The grand jury handed up indictments, and the U.S. Justice Department opened its own investigation. Clifford's assets in New York City, where he kept most of his investments, were frozen.
Clifford insisted that he had no knowledge of illegal activity at First American, and insisted that he himself had been deceived about the extent of BCCI's involvement.
A "Report to the Committee on Foreign Relations of the United States Senate," prepared by U.S. Senators John Kerry and Hank Brown, noted that a key strategy of "BCCI's successful secret acquisitions of U.S. banks in the face of regulatory suspicion was its aggressive use of a series of prominent Americans," Clifford among them. Clifford, who prided himself on decades of meticulously ethical conduct, summed his predicament up when he sadly told a reporter from "The New York Times", "I have a choice of either seeming stupid or venal."
Personal life.
On October 3, 1931, Clifford married Margery Pepperell "Marny" Kimball (April 20, 1908 – April 14, 2000). They had three daughters: Margery Clifford (nickname: Gery), Joyce Clifford Burland and Randall Clifford Wight.
Religious views.
Clifford was a Christian Zionist.
Death.
Not long after a final, frail appearance in the 1997 PBS television documentary "Truman", Clifford died from natural causes in 1998 at age 91. He was buried at Arlington National Cemetery, in Arlington, Virginia.

</doc>
<doc id="80225" url="https://en.wikipedia.org/wiki?curid=80225" title="Melvin Laird">
Melvin Laird

Melvin Robert "Bom" Laird (born September 1, 1922) is an American politician and writer. He was a U.S. congressman from Wisconsin before serving as Secretary of Defense from 1969 to 1973 under President Richard Nixon. Laird was instrumental in forming the administration's policy of withdrawing U.S. soldiers from the Vietnam War; he invented the expression "Vietnamization," referring to the process of transferring more responsibility for combat to the South Vietnamese forces.
Early life.
He was born in Omaha, Nebraska, grew up and attended high school in Marshfield, Wisconsin, although he attended Lake Forest Academy in Lake Forest, Illinois his junior year. He was nicknamed "Bambino" (shortened to "Bom" and pronounced like the word 'bomb') by his mother.
Laird was the grandson of William D. Connor, the Lieutenant Governor of Wisconsin from 1907 to 1909, and the great-grandson of Robert Connor, a member of the Wisconsin State Assembly. His niece is Jessica Laird Doyle, wife of former Wisconsin Governor Jim Doyle.
He graduated from Carleton College in Minnesota in May 1944, having enlisted in the United States Navy a year earlier. Following his commissioning as an ensign, he served on a destroyer, the USS "Maddox" (DD-731), in the Pacific. A recipient of the Purple Heart and several other decorations, Laird left the Navy in April 1946.
Legislative career.
Laird entered the Wisconsin State Senate at age 23, succeeding his deceased father Melvin R. Laird, Sr. He represented a legislative district encompassing Stevens Point, Wisconsin. He remained in the Senate until his election in November 1952 to the United States House of Representatives representing Wisconsin's 7th District in central Wisconsin, including the areas of Marshfield, Wausau, Wisconsin Rapids and Stevens Point. In the 1964 Republican presidential primaries, Laird was an "unannounced" supporter of Arizona Senator Barry Goldwater, and chaired the Platform Committee at that year's Republican convention, at which Goldwater was nominated.
Laird was re-elected eight consecutive times and he was chairman of the House Republican Conference when Nixon selected him for the cabinet. He was known for his work on both domestic and defense issues, including his service on the Defense subcommittee of the House Appropriations Committee. He left Congress reluctantly, making it clear when he became secretary on 22 January 1969 that he intended to serve no more than four years.
As a congressman Laird had supported a strong defense posture and had sometimes been critical of Secretary McNamara. In September 1966, characterizing himself as a member of the loyal opposition, he publicly charged the Johnson administration with deception about Vietnam war costs and for delaying decisions to escalate the ground war until after the 1966 congressional elections. Laird also criticized McNamara's management and decision-making practices.
Laird was reportedly the elder statesman chosen by the Republicans to convince Vice President Spiro Agnew to resign his position after Agnew's personal corruption became a public scandal. He also had a prominent role in the selection of Gerald Ford as Agnew's replacement as Vice President.
Secretary of Defense.
After he became Secretary of Defense, Laird and President Nixon appointed a Blue Ribbon Defense Panel that made more than 100 recommendations on DoD's organization and functions in a report on 1 July 1970. The department implemented a number of the panel's proposals while Laird served in the Pentagon.
Managerial style.
Laird did not depart abruptly from the McNamara-Clifford management system, but rather instituted gradual changes. He pursued what he called "participatory management," an approach calculated to gain the cooperation of the military leadership in reducing the Defense budget and the size of the military establishment. While retaining decisionmaking functions for himself and the deputy secretary of defense, Laird somewhat decentralized policymaking and operations. He accorded the service secretaries and the JCS a more influential role in the development of budgets and force levels. He revised the PPBS, including a return to the use of service budget ceilings and service programming of forces within these ceilings. The previously powerful systems analysis office could no longer initiate planning, only evaluate and review service proposals.
Laird noted this in his FY 1971 report, "Except for the major policy decisions, I am striving to decentralize decisionmaking as much as possible ... So, we are placing primary responsibility for detailed force planning on the Joint Chiefs and the Services, and we are delegating to the Military Departments more responsibility to manage development and procurement programs." The military leadership was enthusiastic about Laird's methods. As the Washington Post reported after his selection as secretary of defense, "Around the military-industrial complex these days they're singing 'Praise the Laird and pass the transformation.'"
Laird did not shrink from centralized management where he found it useful or warranted. His tenure saw the establishment of the Defense Investigative Service, the Defense Mapping Agency, the Office of Net Assessment, and the Defense Security Assistance Agency (to administer all DoD military assistance programs). In October 1972 Congress passed legislation creating a second deputy secretary of defense position, a proposal Laird strongly supported, even though he never filled the position. Laird paid special attention to two important interdepartmental bodies: the Washington Special Action Group (WSAG), composed of senior Defense, State, and CIA officials, which gathered information necessary for presidential decisions on the crisis use of U.S. military forces; and the Defense Program Review Committee (DPRC), which brought together representatives from many agencies, including DoD, State, the Council of Economic Advisers, and the Office of Management and Budget, to analyze defense budget issues as a basis for advising the president, placing, as Laird commented, "national security needs in proper relationship to non-defense requirements."
Pentagon budget.
Laird succeeded in improving DoD's standing with Congress. As a highly respected congressional veteran, Laird had a head start in his efforts to gain more legislative support for Defense programs. He maintained close contact with old congressional friends, and he spent many hours testifying before Senate and House committees. Recognizing the congressional determination, with wide public support, to cut defense costs (including winding down the Vietnam War), Laird worked hard to prune budgetary requests before they went to Congress, and acceded to additional cuts when they could be absorbed without serious harm to national security. One approach, which made it possible to proceed with such new strategic weapon systems as the B-1 bomber, the Trident nuclear submarine, and cruise missiles, was agreement to a substantial cut in conventional forces. As a result, total military personnel declined from some 3.5 million in FY 1969 to 2.3 million by the time Laird left office in January 1973. Those weapon platforms, as well as the F-15, F-16, A-10, and Los Angeles-class nuclear submarine were all programs started by the Laird Pentagon.
Other initiatives, including troop withdrawals from Vietnam, phasing out old weapon systems, base closures, and improved procurement practices, enabled the Pentagon to hold the line on spending, even at a time when high inflation affected both weapon and personnel costs. In Laird's years, total obligational authority by fiscal year was as follows: 1969, $77.7 billion; 1970, $75.5 billion; 1971, $72.8 billion; 1972, $76.4 billion; and 1973, $78.9 billion.
Vietnam War.
Vietnam preoccupied Laird as it had McNamara and Clifford. In 1968 Nixon campaigned on a platform critical of the Johnson administration's handling of the war and promised to achieve "peace with honor". Although not receptive to demands for immediate withdrawal, Laird acknowledged the necessity to disengage U.S. combat forces gradually. Thus he developed and strongly supported "Vietnamization", a program intended to expand, equip, and train South Vietnam's forces and assign to them an ever-increasing combat role, at the same time steadily reducing the number of U.S. combat troops. During 1969 the new administration cut authorized U.S. troop strength in Vietnam from 549,500 to 484,000, and by 1 May 1972 the number stood at 69,000. During this same period, from January 1969 to May 1972, U.S. combat deaths declined 95 percent from the 1968 peak, and war expenditures fell by about two-thirds. Laird publicized Vietnamization widely; in his final report as secretary of defense in early 1973, he stated: "Vietnamization ... today is virtually completed. As a consequence of the success of the military aspects of Vietnamization, the South Vietnamese people today, in my view, are fully capable of providing for their own in-country security against the North Vietnamese."
In this same report Laird noted that the war had commanded more of his attention than any other concern during his four-year term. Upon becoming secretary he set up a special advisory group of DoD officials, known as the Vietnam Task Force, and he met with them almost every morning he was in the Pentagon. He also visited Vietnam several times for on-the-scene evaluations. Although his program of Vietnamization could be termed a success, if one considers the progress of troop withdrawals, U.S. involvement in the conflict became perhaps even more disruptive at home during Nixon's presidency than during Johnson's. The U.S. incursion into Cambodia in May 1970 to eliminate North Vietnamese sanctuaries, the renewed bombing of North Vietnam and the mining of its harbors in the spring of 1972 in response to a North Vietnamese offensive, and another bombing campaign against the North in December 1972 brought widespread protest. Nixon's Vietnam policy, as well as that of previous administrations, suffered further criticism when, in June 1971, the Pentagon Papers, a highly classified narrative and documentary history of U.S. involvement in Vietnam from 1945 to 1967, prepared at Secretary McNamara's order, was leaked and published in part in several major newspapers.
Laird publicly supported Nixon's Vietnam course, although Laird privately opposed the deception used to mask the Cambodian invasion from the American populace. He counted on the success of Vietnamization, peace talks that had begun in 1968 in Paris, and the secret negotiations in Paris between Henry Kissinger, the president's assistant for national security affairs, and North Vietnamese representatives to end the conflict. On 27 January 1973, two days before Laird left office, the negotiators signed a Vietnam settlement in Paris. They agreed to an in-place cease-fire to begin on 28 January 1973, complete withdrawal of U.S. forces within 60 days, the concurrent phased release of U.S. prisoners of war in North Vietnam, and establishment of an international control commission to handle disagreements among the signatories. Although, as time was to demonstrate, South Vietnam was not really capable of defending its independence, Laird retired from office satisfied that he had accomplished his major objective, the disengagement of United States combat forces from Vietnam.
Cold War and nuclear war planning.
Vietnam preoccupied Laird, but not to the exclusion of other pressing matters. Although not intimately involved in the development of strategic nuclear policy as McNamara had been, Laird subscribed to the Nixon administration's program of "Strategic Sufficiency" - that the United States should have the capability to deter nuclear attacks against its home territory and that of its allies by convincing a potential aggressor that he would suffer an unacceptable level of retaliatory damage; it should also have enough nuclear forces to eliminate possible coercion of its allies. The policy, not much different from McNamara's except in name and phrasing, embraced the need both to avoid mass destruction of civilians and to seek mechanisms to prevent escalation of a nuclear conflict. The administration further refined its strategic ideas in July 1969 when the president issued a statement that came to be known as the "Nixon Doctrine", stressing "pursuit of peace through partnership with our allies." Instead of the previous administration's "2½ war" concept - readiness to fight simultaneous wars on two major fronts and one minor front - the Nixon Doctrine cut back to the "1½ war" level. Through military aid and credit-assisted sales of military equipment abroad, the United States would prepare its allies to take up a greater share of the defense burden, especially manpower needs, in case of war. U.S. military forces would be "smaller, more mobile, and more efficient general purpose forces that ... neither cast the United States in the role of world policeman nor force the nation into a new isolationism." Laird supported the strategic arms talks leading to the SALT I agreements with the Soviet Union in 1972: a five-year moratorium against expansion of strategic nuclear delivery systems, and an antiballistic missile treaty limiting each side to two sites (later cut to one) for deployed ABM systems. As Laird put it, "In terms of United States strategic objectives, SALT I improved our deterrent posture, braked the rapid buildup of Soviet strategic forces, and permitted us to continue those programs which are essential to maintaining the sufficiency of our long-term strategic nuclear deterrent."
Conscription suspended.
Other important Laird goals were ending conscription by 30 June 1973 and the creation of an All Volunteer Force (AVF). Strong opposition to selective service mounted during the Vietnam War and draft calls declined progressively during Laird's years at the Pentagon; from 300,000 in his first year, to 200,000 in the second, 100,000 in the third, and 50,000 in the fourth. On 27 January 1973, after the signing of the Vietnam agreement in Paris, Laird suspended the draft, five months ahead of schedule.
Later career.
Laird completed his term of office as secretary of defense on 29 January 1973. Because he had stated repeatedly that he would serve only four years (only Charles E. Wilson and Robert McNamara among his predecessors served longer), it came as no surprise when President Nixon on 28 November 1972 nominated Elliot L. Richardson to succeed him. In his final report in January 1973 Laird listed what he considered to be the major accomplishments of his tenure: Vietnamization; achieving the goal of strategic sufficiency; effective burden-sharing between the United States and its friends and allies; adequate security assistance; maintenance of U.S. technological superiority through development of systems such as the B-1, Trident, and cruise missiles; improved procurement; "People Programs" such as ending the draft and creating the AVF; improved National Guard and Reserve forces; enhanced operational readiness; and participatory management. One of Laird's most active initiatives was his persistent effort to secure the release of the American captives held by the enemy in Vietnam.
During his tenure as Defense Secretary, Laird did not share President Nixon's lingering timetable for withdrawal from Vietnam. He publicly contradicted the administrations policy, which upset the White House. Laird wished to return to the political arena, and was said to be planning a run for president in 1976. After Watergate, this proved implausible. There was also talk of a Senate run and perhaps a return to his old House seat in hopes of becoming Speaker.
In spite of Vietnam and the unfolding Watergate affair, which threatened to discredit the entire Nixon administration, Laird retired with his reputation intact. Although not a close confidant of the president and not the dominant presence that McNamara was, Laird had been an influential secretary. He achieved a smooth association with the military leadership by restoring some of the responsibilities they had lost during the 1960s. His excellent relations with Congress enabled him to gain approval for many of his programs and budget requests.
After a brief absence Laird returned to the Nixon administration in June 1973 as counselor to the president for domestic affairs, concerning himself mainly with legislative issues. In February 1974, as the Watergate crisis in the White House deepened, Laird resigned to become senior counselor for national and international affairs for "Reader's Digest". Following Richard Nixon's resignation as President, Laird was reported to be the first choice of successor Gerald Ford to be nominated Vice President, a position ultimately filled by Nelson Rockefeller.
In 1974, he received the Presidential Medal of Freedom. Since 1974 he has written widely, in "Reader's Digest" and other publications, on national and international topics.
On January 5, 2006, he participated in a meeting at the White House of former Secretaries of Defense and State to discuss United States foreign policy with Bush administration officials.
Journalist Dale Van Atta has written a biography of Laird entitled, "With Honor: Melvin Laird in War, Peace, and Politics," published by the University of Wisconsin Press, 2008.
Following the death of Clarence Clifton Young on April 3, 2016, Laird became the last surviving member of the 83rd Congress, as well as the last surviving member elected in either the 1952 or 1954 elections.
Role in health care research.
Laird played a key role in advancing medical research, although this part of his biography is often overshadowed by his political achievements.
“Laird’s position on the House Appropriations subcommittee handling health matters allowed him to play a key congressional role on many medical and health issues. He often teamed up with liberal Democrat John Fogarty of Rhode Island to pass key legislation on education or health matters. Their impact on the National Institutes of Health was pivotal in a vast expansion of health research programs and facilities. They also sponsored the buildup of the National Library of Medicine, the Center for Disease Control in Atlanta, the National Environmental Center in North Carolina, and the nation’s eight National Cancer Centers, later part of the National Institutes of Health. Laird received many awards for his work on health matters, including the Albert Lasker Medical Research Award (1964) and the American Public Health Association award for leadership.” This account of his role is noted in the Gerald R. Ford Presidential Library biography.
Between 1956 and 1967, Laird was appointed a member of the U.S. Delegation to the World Health Organization in Geneva, Switzerland, by three U.S. Presidents – Dwight Eisenhower, John Kennedy and Lyndon Johnson.
In fact, President Eisenhower so admired Laird's work in Congress for world health and national security that he described Congressman Laird as "one of the 10 men best qualified to become President of the United States."
Laird's interest in medical research is documented by his co-authoring legislation to finance the construction of the National Library of Medicine, and important centers for medical research on many university campuses (among them the McArdle Laboratory for Cancer Research and the University of Wisconsin Cancer Center in Madison) and the major institutes of the National Institutes of Health in Bethesda, MD. Laird, Congressman Fogarty and Senator Lister Hill (D-Alabama) also authorized legislation which funded the building of the Centers for Disease Control and Prevention (CDCP) in Atlanta, GA. BenchMarks Magazine, Fall, 1994 

</doc>
<doc id="80226" url="https://en.wikipedia.org/wiki?curid=80226" title="Lou Tellegen">
Lou Tellegen

Lou Tellegen (November 26, 1881 – October 29, 1934) was a Dutch-born silent film and stage actor, director and screenwriter.
Early life.
Born Isidore Louis Bernard Edmon van Dommelen, he was the illegitimate child of army lieutenant Isidore Louis Bernard Edmon Tellegen (1836–1902) and Anna Maria van Dommelen. 
He left Sint-Oedenrode to make his stage debut in Amsterdam in 1903, and over the next few years built a reputation to the point where he was invited to perform in Paris, eventually co-starring in several roles with Sarah Bernhardt, with whom he was involved romantically. In 1910, he made his motion picture debut alongside Bernhardt in "La dame aux camélias", a silent film made in France based on the play by Alexandre Dumas, fils.
Career.
In 1910, he and Bernhardt travelled to the United States, where "The New York Times" first published, and then retracted, the announcement of their impending marriage. (She was 37 years his senior.) Back in France, in 1912 they made their second film together, "Les Amours de la reine Élisabeth" ("Queen Elizabeth"), and the following year, "Adrienne Lecouvreur". The latter is considered a lost film.
In the summer of 1913, Tellegen went to London where he produced and starred in the Oscar Wilde play, "The Picture of Dorian Gray". Invited back to the United States, Tellegen worked in theatre and made his first American film in 1915, titled "The Explorer", followed by "The Unknown", both with Dorothy Davenport as his co-star. Considered one of the best-looking actors on screen, he followed up with three straight films starring opposite Geraldine Farrar. 
Tellegen's marriage to Farrar ended in divorce in 1923. Tellegen married a total of four times, the first to a sculptress in 1903 (this union produced a daughter), the second to Farrar in 1916. His third marriage was to actress Nina Romano (real name: Isabel Craven Dilworth). His fourth marriage was to silent film star Eve Casanova (real name Julia Horne). He became an American citizen in 1918.
Later career and death.
Tellegen appeared in numerous films before his face was damaged in a fire on Christmas Day 1929, when he fell asleep while smoking, preparing for an out-of-town tryout for a play. He had extensive plastic surgery in 1931.
One memorable role was as the villain in John Ford's Western "3 Bad Men" (1926), in which Tellegen wore a white hat instead of the stereotypical black hat. Fame fading, employment not forthcoming, and ridden with debt, he filed for bankruptcy. He was diagnosed with cancer, though this information was kept from him, and he became despondent. In 1931, he wrote his autobiography "Women Have Been Kind".
On October 29, 1934, while a guest in the Cudahy Mansion at 1844 North Vine Street in Hollywood (now the site of the Vine-Franklin underpass of the Hollywood Freeway), Tellegen locked himself in the bathroom, then shaved and powdered his face. Then while standing in front of a full-length mirror, he committed suicide by stabbing himself with a pair of sewing scissors seven times (supposedly while surrounded by newspaper clippings of his career), resulting in lurid press coverage.
When asked to comment on Tellegen's death, former wife Geraldine Farrar replied, "Why should that interest me?" Tellegen's remains were cremated and scattered at sea.

</doc>
<doc id="80227" url="https://en.wikipedia.org/wiki?curid=80227" title="Commando">
Commando

A commando is a soldier or operative of an elite light infantry or special operations force often specializing in amphibious landings, parachuting or abseiling. 
Originally "a commando" was a type of combat unit, as opposed to an individual in that unit. In other languages, "commando" and "kommando" denote a "command", including the sense of a military or an elite special operations unit.
In the militaries and governments of most countries, commandos are distinctive in that they specialize in assault on unconventional high-value targets. However, the term commando is sometimes used in relation to units carrying out the latter tasks (including some civilian police units).
In English, occasionally to distinguish between an individual commando and the unit Commando, the unit is capitalized.
Green Berets and training origins.
Since the 20th century and World War II, commandos have been set apart from other military units by virtue of their extreme training regimes; these are usually associated with the green beret which originated with British Commandos. The British Commandos were instrumental in founding many other international commando units during World War II. Some international commando units were formed from members who served as part of or alongside British Commandos, such as the Dutch Korps Commandotroepen (who still wear the recognition flash insignia of the British Fairbairn-Sykes Fighting Knife), Belgian 5th Special Air Service, or Greek Sacred Band (World War II). In 1944 the SAS Brigade was formed from the British 1st and 2nd SAS, the French 3rd and 4th SAS, and the Belgian 5th SAS. The French Army special force (1er RPIMa) still use the motto "Qui Ose Gagne", a translation of the SAS motto "Who Dares Wins."
In addition, many Commonwealth nations were part of the original British Commando units. They developed their own national traditions, including the Australian Special Air Service Regiment, the New Zealand Special Air Service, and the Southern Rhodesian Special Air Service, all of whom share the same insignia and motto as their British counterparts. During the Second World War, the British SAS quickly adopted sand-colored berets, since they were almost entirely based in the North African theatre; they used these rather than the green berets to distinguish themselves from other British Commando units. (See History of the Special Air Service. Other Commonwealth commando units were formed after the Second World War directly based on the British Commando units, such as the Australian 1st Commando Regiment (Australia), distinct from the Australian special operations 2nd Commando Regiment (Australia), who originated with the jungle-fighting 2nd Battalion, Royal Australian Regiment during the Second World War.
The US Rangers were founded by Major General Lucian Truscott of the US Army, a liaison officer with the British General Staff. In 1942, he submitted a proposal to General George Marshall that an American unit be set up "along the lines of the British Commandos". The original US Rangers trained at the British Commandos centre at Achnacarry Castle. The US Navy SEALs' original formation, the Observer Group, was also trained and influenced by British Commandos. The US Special Forces originated with the First Special Service Force, formed under British Combined Operations.
Malaysian green beret special forces PASKAL and Grup Gerak Khas (who still wear the Blue Lanyard of the Royal Marines) were originally trained by British Commandos. The Brazilian marine special operations COMANF also originated with Royal Marines mentoring. Other British units, such as the SAS, led to the development of many international special operations units that are now typically referred to as commandos, including the Pakistani Special Services Group, Indian MARCOS, and Jordanian special forces.
Etymology.
The word stems from the Afrikaans word "kommando", which translates roughly to "mobile infantry regiment". This term originally referred to mounted infantry regiments, who fought against the British Army in the first and second Boer Wars.
The Dutch word has had the meaning of "a military order or command" since at least 1652; it likely came into the language through the influence of the Portuguese word "comando" (meaning "command"). (In Dutch, "commando" can also mean a command given to a computer, e.g., "het mkdir-commando" "(= "create a directory")".) It is also possible the word was adopted into Afrikaans from interactions with Portuguese colonies. Less likely, it is a High German loan word, which was borrowed from Italian in the 17th century, from the sizable minority of German settlers in the initial European colonization of South Africa.
The officer commanding an Afrikaans "kommando" is called a "kommandant", which is a regimental commander equivalent to a lieutenant-colonel or a colonel.
The Oxford English Dictionary ties the English use of the word meaning " member of a body of picked men ..." directly into its Afrikaans' origins:
During World War II, newspaper reports of the deeds of "the commandos" led to readers thinking that the singular meant one man rather than one military unit, and this new usage became established.
History.
After the Dutch Cape Colony was established in 1652, the word was used to describe bands of militia. The first "Commando Law" was instated by the original Dutch East India Company chartered settlements and similar laws were maintained through the independent Boer Orange Free State and South African Republic. The law compelled Burghers to equip themselves with a horse and a firearm when required in defense. The implementation of these laws was called the "Commando System". A group of mounted militiamen were organized in a unit known as a "commando" and headed by a Commandant, who was normally elected from inside the unit. Men called up to serve were said to be "on commando". British experience with this system lead to the widespread adoption of the word "commandeer" into English in the 1880s.
During the "Great Trek", conflicts with Southern African peoples such as the Xhosa and the Zulu caused the Boers to retain the commando system despite being free of colonial laws. Also, the word became used to describe any armed raid. During this period, the Boers also developed guerrilla techniques for use against numerically superior but less mobile bands of natives such as the Zulu who fought in large complex formations.
In the First Boer War, Boer commandos were able to use superior marksmanship, fieldcraft, camouflage and mobility to expel an occupying British force (poorly trained in marksmanship, wearing red uniforms and unmounted) from the Transvaal. These tactics were continued throughout the Second Boer War. In the final phase of the war, 75,000 Boers carried out asymmetric warfare against the 450,000-strong British Imperial forces for two years after the British had captured the capital cities of the two Boer republics. During these conflicts the word entered English, retaining its general Afrikaans meaning of a "militia unit" or a "raid". Robert Baden-Powell recognised the importance of fieldcraft and was inspired to form the scouting movement.
In 1941, Lieutenant-Colonel D. W. Clarke of the British Imperial General Staff, suggested the name "Commando" for specialized raiding units of the British Army Special Service in evocation of the effectiveness and tactics of the Boer commandos. During World War II, American and British publications, confused over the use of the plural "commandos" for that type of British military units, gave rise to the modern common habit of using "a commando" to mean one member of such a unit, or one man engaged on a raiding-type operation.
World War I.
Italy.
The first country to establish commando troops was Italy, in the summer 1917, shortly before Germany.
Italy used specialist trench-raiding teams to break the stalemate of static fighting against Austria-Hungary, in the Alpine battles of World War I. These teams were called "Arditi" (meaning "daring, brave ones"); they were almost always men under 25 in top physical condition and, possibly at first, bachelors (due to fear of very high casualty rates). Actually the Arditi (who were led to the lines just a few hours before the assault, having been familiarised with the terrain via photo-reconnaissance and trained on trench systems re-created ad hoc for them) suffered fewer casualties than regular line infantry and were highly successful in their tasks. Many of them volunteered for extreme-right formations in the turbulent years after the war and (the Fascist Party took pride in this and adopted the style and the mannerism of Arditi), but some people of left-wing political persuasions created the "Arditi del Popolo" (People's Arditi) and for some years held the fascist raids in check, defending Socialist and Communist Party sections, buildings, rallies and meeting places.
During the Liberation of Rome in 1944, US troops broke into the Italian Ministry of Defence building in Rome and seized all World War I materials and documents pertaining to Arditi units in the archives.
Germany.
In World War I in 1918, raiding troops called "Sturmtruppen" or Storm Troopers carrying submachine guns, mostly the MP-18, were sent by the Germans to try to disrupt or even break into no man's land and into the trenches of British and French lines.
World War II.
Germany.
In December 1939, following the success of German infiltration and sabotage operations in the Polish campaign, the German Office for Foreign and Counter-Intelligence (OKW Amt Ausland/Abwehr) formed the Brandenburger Regiment (known officially as the 800th Special Purpose Training and Construction Company). The Brandenburgers conducted a mixture of covert and conventional operations but became increasingly involved in ordinary infantry actions and were eventually converted into a Panzer-Grenadier Division, suffering heavy losses in Russia. Otto Skorzeny (most famed for his rescue of Benito Mussolini) conducted many special operations for Adolf Hitler. Skorzeny commanded Sonderlehrgang z.b.V. Oranienburg, Sonderverband z.b.V. Friedenthal, and SS-Jäger-Bataillon 502, 500th SS Parachute Battalion, SS-Jagdverband Mitte and all other SS commando units.
A report written by Major-General Robert Laycock in 1947 said there was a German raid on a radar station on the Isle of Wight in 1941.
Japan.
In 1944–45, Japanese "Teishin Shudan" ("Raiding Group") and "Giretsu" ("heroic") detachments made airborne assaults on Allied airfields in the Philippines, Marianas and Okinawa. The attacking forces varied in size from a few paratroopers to operations involving several companies. Due to the balance of forces concerned, these raids achieved little in the way of damage or casualties, and resulted in the destruction of the Japanese units concerned. Considering that there were no plans to extract these forces, and the reluctance to surrender by Japanese personnel during that era, they are often seen in the same light as "kamikaze" pilots of 1944–45.
Nakano School trained intelligence and commando officers and organized commando teams for sabotage and guerrilla warfare.
The navy had commando units "S-toku" (Submarine special attack units, see Kure 101st JSNLF(in Japanese) ) for infiltrating enemy areas by submarine. It was called the Japanese Special Naval Landing Forces of Kure 101st, Sasebo 101st and 102nd.
Italy.
Italy's most renowned commando unit of World War II was "Decima Flottiglia MAS" ("10th Assault Vehicle Flotilla"), which, from mid-1940, sank or damaged a considerable tonnage of Allied ships in the Mediterranean.
After Italy surrendered in 1943, some of the "Decima Flottiglia MAS" were on the Allied side of the battle line and fought with the Allies, renaming themselves the "Mariassalto". The others fought on the German side and kept their original name but did not operate at sea after 1943, being mostly employed against Italian partisans; some of its men were involved in atrocities against civilians.
In post-war years the Italian marine commandos were re-organised as the "Comsubin" (an abbreviation of "Comando Subacqueo Incursori", or Underwater Raiders Command). They wear the green Commando beret.
United Kingdom.
In 1940, the British Army also formed "independent companies", later reformed as battalion sized "commandos", thereby reviving the word. The British intended that their commandos be small, highly mobile surprise raiding and reconnaissance forces. They intended them to carry all they needed and not remain in field operations for more than 36 hours. Army Commandos were all volunteers selected from existing soldiers still in Britain.
During the war the British Army Commandos spawned several other famous British units such as the Special Air Service, the Special Boat Service and the Parachute Regiment. The British Army Commandos themselves were never regimented and were disbanded at the end of the war.
The Special Operations Executive (SOE) also formed commando units from British and displaced European personnel (e.g., Cichociemni) to conduct raiding operations in occupied Europe. They also worked in small teams, such as the SAS, which was composed of ten or fewer commandos because that was better for special operations. One example is Norwegian Independent Company 1, which destroyed heavy water facilities in Norway in 1941.
The Royal Navy also controlled Royal Navy Beach Parties, based on teams formed to control the evacuation of Dunkirk in 1940. These were later known simply as RN Commandos, and they did not see action until they successfully fought for control of the landing beaches (as in the disastrous Dieppe Raid of 19 August 1942). The RN Commandos, including Commando "W" from the Royal Canadian Navy, saw action on D-Day.
In 1942, the Royal Navy's nine Royal Marines infantry battalions were reorganized as Commandos, numbered from 40 to 48, joining the British Army Commandos in combined Commando Brigades. After the war the Army Commandos were disbanded. The Royal Marines form an enduring Brigade-strength capability as 3 Commando Brigade with supporting Army units.
The Royal Air Force also formed 15 commando units in 1942, each of which was 150 strong. These units consisted of trained technicians, armourers and maintainers who had volunteered to undertake the commando course. These RAF commandos accompanied the Allied invasion forces in all theatres; their main role was to allow the forward operation of friendly fighters by servicing and arming them from captured air fields. However, due to the forward position of these airfields, the Royal Air Force Commandos were also trained to secure and make safe these airfields and to help defend them from enemy counterattack.
As of 1 September 1999 Great Britain's 16 Air Assault Brigade is a formation of the British Army based in Colchester in the county of Essex. It is the Army's rapid response airborne formation and is the only Operational Brigade in the British Army capable of delivering Air Manoeuvre, Air Assault and Airborne operations.
Australia.
The Australian Army formed commando units, known as Australian independent companies in the early stages of World War II. They first saw action in early 1942 during the Japanese assault on New Ireland, and in the Battle of Timor. Part of the 2/1st Independent Company was wiped out on New Ireland, but on Timor, the 2/2nd Independent Company formed the heart of an Allied force that engaged Japanese forces in a guerrilla campaign. The Japanese commander on the island drew parallels with the Boer War, and decided that it would require a 10:1 numerical advantage to defeat the Allies. The campaign occupied the attention of an entire Japanese division for almost a year. The independent companies were later renamed commando squadrons, and they saw widespread action in the South West Pacific Area, especially in New Guinea and Borneo. In 1943, all the commando squadrons except the 2/2nd and 2/8th were grouped into the 2/6th, 2/7th and 2/9th Cavalry Commando Regiments.
Later in the war the Royal Australian Navy also formed commando units along the lines of the Royal Naval Commandos to go ashore with the first waves of major amphibious assaults, to signpost the beaches and carry out other naval tasks. These were known as RAN Commandos. Four were formed—lettered A, B, C and D like their British counterparts—and they took part in the Borneo campaign.
Z Force, an Australian-British-New Zealand military intelligence commando unit, formed by the Australian Services Reconnaissance Department, also carried out many raiding and reconnaissance operations in the South West Pacific theatre, most notably Operation Jaywick, in which they destroyed tonnes of Japanese shipping at Singapore Harbour. An attempt to replicate this success, with Operation Rimau, resulted in the death of almost all those involved. However, Z Force and other SRD units continued operations until the war's end.
New Zealand.
New Zealand formed the Southern Independent Commando in Fiji 1942. Its primary function was to wage a guerrilla war on any Japanese forces should they attempt to capture the strategically important Fiji islands. 200 native Fijians were recruited and organised by 44 New Zealanders. Training focused intensely on jungle warfare, and many successful 'mock' raids were made on American garrisons who awoke to find dummy time bombs placed on their ammunition dumps, or chalk crosses drawn on the equipment of their guards.
When it became apparent that a Japanese invasion of Fiji was no longer likely, the commando was deployed to undertake scouting tasks for US forces around Guadalcanal and New Georgia. Recruiting was further expanded to include men from other pacific islands such as the Solomons and Tonga, and occasionally British or American personnel took part in training or accompanied the commandos on missions. After many successful operations and engagements, the harsh conditions of extended jungle living took their toll, and many men began to suffer from ill-health. As a result, the commando was reduced in strength until it was declared unfit for further service, and was disbanded in May 1944.
The commando's contribution to the Solomon Island campaign was significant, with senior American officers referring to the unit as "most capable", "invaluable" and "unquestionably ... of great aid in the campaign".
New Zealanders were also a notable component of the Long Range Desert Group, which undertook reconnaissance and occasional strike missions deep behind enemy lines during the North African Campaign.
Canada.
A joint Canadian-American Commando unit, the 1st Special Service Force, nicknamed the Devil's Brigade, was formed in 1942 under the command of Colonel Robert Frederick. The unit initially saw service in the Pacific, in August 1943 at Kiska in the Aleutians campaign. However most of its operations occurred during the Italian campaign and in southern France. Its most famous raid, which was documented in the film "Devil's Brigade", was the battle of Monte la Difensa. In 1945, the unit was disbanded; some of the Canadian members were sent to the 1st Canadian Parachute Battalion as replacements, and the American members were sent to either the 101st Airborne Division or the 82nd Airborne Division as replacements or the 474th Regimental Combat Team. Ironically they were sent to service in Norway in 1945, the country they were formed to raid.
Greece.
The Sacred band () was a Greek special forces unit formed in 1942 in the Middle East, composed entirely of Greek officers and officer cadets under the command of Col. Christodoulos Tsigantes. It fought alongside the SAS in the Libyan Desert and with the SBS in the Aegean, as well as with General Leclerc's "Free French Forces" in Tunisia. It was disbanded in August 1945.
United States.
During 1941, the United States Marine Corps formed commando battalions. The USMC commandos were known collectively as Marine Raiders. On orders from President Franklin D. Roosevelt through a proposal from OSS Director Colonel William J. Donovan and the former Commander of the United States Marine Detachment Major Evans F Carlson, directed the formation of what became the Marine Raiders. Initially this unit was to be called Marine Commandos and were to be the counterpart to the British Commandos. The name Marine Commandos met with much controversy within the Marine Corps leading Commandant Thomas J. Holcomb to state, "the term 'Marine' is sufficient to indicate a man ready for duty at any time, and the injection of a special name, such as "commando", would be undesirable and superfluous." President Roosevelt's son James Roosevelt served with The Marine Raiders. The Raiders initially saw action at the Battle of Tulagi and the Battle of Makin, as well as the Battle of Guadalcanal, the Battle of Empress Augusta Bay, and other parts of the Pacific Ocean Areas. In February 1944 the four Raider battalions were converted to regular Marine units. Additionally, as parachuting special forces units, Paramarines arguably also qualified as commandos- though they too were assimilated into regular Marine units in 1944.
In mid-1942, the United States Army formed its Army Rangers in Northern Ireland under William O. (Bill) Darby. The Rangers were designed along the similar lines to the British Commandos. The first sizable Ranger action took place in August 1942 at the Dieppe Raid, where 50 Rangers from the 1st Ranger Battalion were dispersed among Canadian regulars and British Commandos. The first full Ranger action took place in November 1942 during the invasion of Algiers in Northwest Africa in (Operation Torch), again by members of the 1st Ranger Battalion.
The 82nd Airborne Division and the 101st Airborne Division built their legacies during World War Two as light infantry divisions. The 101st Airborne Division is one of the U.S. Army's most decorated divisions and is famous for its defense of Bastogne, Belgium during the Siege of Bastogne during the Battle of the Bulge. The 101st Airborne Division was renowned for its role in Operation Overlord (the D-Day landings and airborne landings on June 6, 1944, in Normandy, France), Operation Market Garden, the liberation of the Netherlands. During the Vietnam War, the 101st Airborne Division fought in several major campaigns and battles including the fight for Hamburger Hill in May 1969.
The 173rd Airborne Brigade Combat Team has received 21 campaign streamers and several unit awards, including the Presidential Unit Citation for its actions during the Battle of Dak To during the Vietnam War.
After 1945.
After World War II there was much publicity about the deeds of "the commandos"; many civilians reading these accounts, guessing a meaning from the context, thought in error that the singular "a commando" meant one man, and that usage became general.
Australia.
In Australia, the Army's commando squadrons were disbanded at the end of the war. However, in 1954, two Citizens Military Force (reserve) units, 1 and 2 Commando Companies, were raised.
1st Commando Regiment (1 Cdo Regt), a regimental structure for the reserve commando companies—and 126 Signal Squadron (Special Forces)—was formed during the 1980s. It adopted the green berets worn by its World War II predecessors.
In 1997, the Australian government ordered the conversion of 4th Battalion, Royal Australian Regiment (4RAR) into a permanent, non-reserve commando battalion, with instructors from 1st Commando Regiment and Australian Special Air Service Regiment (SASR). 126 Signal Squadron was reassigned to 4RAR and 301 Signal Squadron re-raised to join 1 Cdo Regt. In 2009, 4RAR was renamed 2nd Commando Regiment (2 Cdo Regt).
1 Cdo and 2 Cdo utilise identical selection and training courses. One company of 2 Cdo is responsible for counter-terrorism operations and response in eastern Australia and is officially known as Tactical Assault Group-East (TAG-E). This company mirrors its sister unit (the original Tactical Assault Group) in the West (TAG-W), which is part of the SASR.
Commandos from 1CDO and 2CDO have been deployed on peacekeeping and combat missions in several countries, including East Timor, the Solomon Islands, Iraq and Afghanistan.
Belgium.
Commando units belonging to Belgium are the Para-Commando Regiments and Brigade Immediate Reaction Cell.
Canada.
Canadian commando forces were disbanded and recreated at various times in the post-war years, and in 1968 the Canadian Airborne Regiment was formed. It was divided into three Airborne Commandos each of company strength. This resulted in a ceiling of about 750 members in all ranks, organized into three smaller company-sized commandos. The three airborne commandos took shape around the three regimental affiliations: 1 Commando with the Royal 22e Régiment, 2 Commando with Princess Patricia's Canadian Light Infantry, and 3 Commando with The Royal Canadian Regiment. The Canadian Airborne Regiment was disbanded after the torture and murder of Shidane Arone, a Somalia civilian, in 1993, and other allegations of wrongdoing within the Regiment. Later, parliamentary investigations questioned why such an elite commando unit was sent on a peacekeeping mission. The Canadian Special Operations Regiment (CSOR) is known as a commando unit but is a special forces unit and Canadian Joint Task Force Two, or JTF2, is also sometimes referred to as a "commando" unit, but it is technically a specialist counter-terrorism unit.
Brazil.
Brazil created its special operations forces in the 1950s. There are commando units in the Brazilian Army and in the navy. In the Brazilian Army the main unit is the Special Operations Brigade, and their Navy counterparts are the COMANF, which is a part of the Brazilian Marine Corps.
Chile.
In Chile the Army Special Forces, Navy and Air Force commando units are characterized by their black berets and for their use of a special type of knife called a "Corvo". The Chilean commandos are also known for their military bearing and discipline, thorough preparation and for their rich historic traditions. The Army's motto is: "ever victorious, never defeated."
Congo.
The former Belgian Congo had one Commando company at independence in 1960 and this was soon expanded to a battalion, becoming known as the 1st Para-Commando Battalion. A 2nd Para-Commando Battalion was added a few years later. From 1963, the Congolese-manned 3rd and 4th Commando Battalions were formed but were little more than normal infantry units. In 1964, the 5th and 6th Commando Battalions were formed mainly with mercenaries, and the 7th to 15th Commando Battalions mainly with Congolese but with some white NCOs and officers. Again, there was no actual commando training and the units were more akin to motorized infantry, with some armour. The 5th to the 15th were all disbanded by 1967.
Finland.
The Finnish Defence Forces (FDF) do not train any commando units in the traditional sense, but the FDF and the Finnish Border Guard (under the Ministry of the Interior) have units which are trained specially, like commandos, with tactics to perform in the Arctic wilderness against enemy 
FDF trains only some tens of paratroopers in a year in the Utti Jaeger Regiment for Long Range Reconnaissance Patrol and special forces tactics. However, FDF and Finnish Frontier Guard have their own Sissi (Finnish light infantry) training regiments (thousands in reserve) in which some hundreds of highly motivated volunteers, per year, are trained to operate behind enemy lines with asymmetric tactics and with light and some times improvised weapons. The role of the troops is reconnaissance, ambushes, to hit supply, logistics and command and control. Also, any special gear (like bridge carriers) and weapons are preferable targets for these units.
France.
French Army (Armee de Terre):
French Navy (Marine Nationale):
French Air Force (Armee de L'Air): 
National Gendarmerie (Gendarmerie Nationale):
Directorate-General for External Security: Division Action:
Germany.
The German Army currently operates the Fernspähkompanie (Germany's elite long range reconnaissance company), and the Kommando Spezialkräfte (KSK).
The KSK is stationed in Calw, in the Black Forest area in southern Germany. It consists of about 1,100 soldiers, but only a nucleus of these are in fighting units. Exact numbers are not available, as this information is considered secret. The KSK is a part of the Special Operations Division (Div. Spezielle Operationen or DSO).
The fighting units are divided into four commando companies of about 100 men each and the "special commando company" with veteran members, taking supporting tasks. Each of the four commando companies has five specialised platoons:
There are four commando squads in every platoon. Each of these groups consists of about four equally skilled soldiers. One of each group is specially trained as weapons expert, medic, combat engineer or communications expert respectively. Additionally a group can contain other specialists, e.g. heavy weapons or language experts.
Another special unit, the Kampfschwimmer (comparable to the USN SEALs) are operated by the German Navy.
India.
The Para Commandos are a special forces unit of the Indian Army. Formed in 1952, the Para Commandos are the largest and most important part of the Special Forces of India. They are highly trained units of the Indian Army, meant to operate behind enemy lines.
The Special Frontier Force is a paramilitary special force of India created on 14 November 1962. Its main goal was to conduct covert operations behind Chinese lines in the event of another Indo-China war. SFF was raised with covert operations in mind, mainly along the Indo-China border, however SFF has been fielded by R&AW and the Indian government in various covert and overt operations.
The Garud Commando Force is the Special Forces unit of the Indian Air Force. The unit derives its name from the word for eagle in Sanskrit. Garud is tasked with acting as quick response teams during attacks on critical Air Force bases and installations; as well as conducting search and rescue of downed pilots, forward air control and carrying out strikes against enemy air defences and radar installations.
MARCOS (marine commandos) is a commando unit of the Indian Navy designed to carry out operation from the air, at sea and on land.
National Security Guards is a special force in India that has primarily been utilised for counter-terrorism activities. (NSG) personnel are popularly known as Black Cat Commandos. There are 2 main units of the NSG, The Special Action Group (SAG) and The Special Ranger Groups (SRG). The Special Action Group is the strike force in anti-terrorist and hostage rescue operations. The Special Rangers Group (SRG) is tasked with providing VVIP security for high-risk VVIPs in India.
Ghatak Force is a battalion-level special unit in the Indian Army, with one in each battalion. They are used as elite infantry to spearhead attacks, carry out reconnaissance and further the objectives of battalions on the battlefields.
The SOG (Special Operations Group (India)) is a special forces unit of the Jammu and Kashmir Police involved in counter terror activities in the state.
The Force One is an elite commando force, which is a specialised counter terrorism unit to guard the Mumbai metropolitan area, one of the largest metropolitan areas in the world, formed by the Government of Maharashtra on the lines of the National Security Guards (NSG).
Kerala Thunderbolts is an elite commando force, which specialises in counter terrorism and Anti-naxel activities, formed by the Government of Kerala on the lines of the National Security Guards.
Special Tactical Unit is an urban counter terrorist unit based in Odisha, India. They specialise in urban warfare scenarios including hostage situations.
Iran.
Revolutionary Guards.
In the Army of the Guardians of the Islamic Revolution/Islamic Revolutionary Guard Corps (IRGC), one of its five branches, the elite Quds Force specialises in extraterritorial operations.
In the Ground Forces, the Saberin Battalion is the most famous special unit. The Islamic Revolutionary Guards Corps Navy has its own Special Units of marines.
Army.
Ground Forces of Islamic Republic of Iran Army units whose members are trained at Lashkarak Takavar Training Centre:
Islamic Republic of Iran Navy green berets/marines () whose members are trained at Manjil Takavar Training Centre:
During the reign of the last Shah (king) of Iran, much of the naval training was created by members of the Soviet Union's Spetsnaz and the British Special Boat Service. Training is at least a 12-month process. After the recruit has demonstrated the minimum physical requirements, he is sent to a collection of schools.
Israel.
The primary commando units of the Israel Defense Forces include Shayetet 13, Sayeret Matkal and the Shaldag Unit.
Shayetet 13 is the elite naval commando unit of the Israeli Navy. S'13 specializes in sea-to-land incursions, counter-terrorism, sabotage, maritime intelligence gathering, maritime hostage rescue, and boarding.The unit is respected as among the best of the world's special forces.
Israel's premier commando unit of the Haganah, the forerunner of the modern IDF, was the Palmach. The first special forces unit created after Israel's independence was Unit 101.
Indonesia.
"Kopassus" (a portmanteau of ""Ko"mando "Pas"ukan Khu"sus"" or "Special Force Command") is an Indonesian Army special forces group that conducts special operations missions for the Indonesian government, such as direct action, unconventional warfare, sabotage, counter-insurgency, counter-terrorism, and intelligence gathering.
Kopassus was founded on April 16, 1952. On April 15, 1952, Colonel Alexander Evert Kawilarang laid the foundation for "Kesatuan Komando Tentara Territorium" III/Siliwangi (Kesko TT), the early name of Kopassus.
The impetus for building this special force was provided from frustration when fighting against the troops of the RMS ("Republik Maluku Selatan" or Republic of the South Moluccas). The Indonesians were amazed and hampered by the RMS's sniper ability and skills—which the Indonesian armed forces of the time did not possess. They were inspired to build a similar force for Indonesia. However, at that time, there were no Indonesian commanders with the necessary experience or special operations skills. However, Lieutenant Colonel Slamet Riyadi's dream was not realized due to his death in a battle against the troops of the separatist RMS.
Not long after, Colonel Kawilarang with the use of military intelligence, located and met Major Rokus Bernardus Visser—a former member of the Dutch Special Forces who had remained a peaceful and law-abiding citizen in newly independent Indonesia, settled in West Java, married an Indonesian woman, and adopted an Indonesian name, Mohamad Idjon Djanbi. He was the first recruit for the Indonesian special forces, as well as its first commander. 
At that time, Indonesia's special force name was Third Territorial Command: "Komando Teritorium Tiga (KTT)". "Kopassus" was the final result of five name changes: KTT, KKAD, RPKAD, and "Kopasandha". The first generation of Indonesian Forces was only around a hundred soldiers or one company, headquartered in Bandung.
As TNI members, the "Kopassus" are/were legally exempt from civil law jurisdiction and a military inquiry found them innocent of all charges. The principal members of the alleged "murder" were all of Group V (Jakarta) and not based in Jayapura nor West Papua, and the "supposed ring-leader Let-Col Hatono got three and a half years jail and two other officers were not even discharged. The ruling Jakarta perspective on the "murder" was affirmed by army Chief Ryamizard Ryacudu: "accepted the men had to face sentence because Indonesia is a State based on law. However he said the men are heroes to if they did kill a rebel leader. Defense lawyers who are appealing the verdicts, have also described the alleged "killers" as heroes"
Kopassus is alleged by external media and human rights-affiliated NGOs to have committed violations of human rights in East Timor, Aceh, Papua and the capital Jakarta. Notably in the Western press, published articles even in mainstream media may include epithets such as "the notorious Kopassus" . Four members of Kopassus were convicted of the strangulation killing of Theys Eluay, the former chairman of the Papuan Presidium Council. After admitting the killing after ambushing him and his driver, two received prison sentences of 3-1/2 years and two others received three years.
Kopassus also has been speculated by eyewitness accounts to have been involved in carrying out or supervising the May 1998 Jakarta riot, including the mass gang-rape of Chinese Indonesian women.
Pakistan.
The Special Service Group (SSG) is an independent commando division of the Pakistan Army. It is an elite special operations force. Official numbers are put at 2,100 men, in 3 Battalions; however the actual strength is classified. Based at Cherat and Attock, the SSG was created in 1956 with active support from U.S. Special Operations Forces. That year the 19th Battalion of the Baloch Regiment (19 Baloch) was selected for conversion to a Special Operations Force. Now the SSG has one of the best specialised and experienced Anti Terrorist units in the world, known as Al Zarrar
The SSG also has a unit in the Pakistan Navy known as the Special Service Group Navy (SSGN). The SSGN currently maintains its headquarters in Karachi and is headed by a Pakistan Navy Commander. In 2006, the SSGN created two new groups, the Pak Seals and VBSS. The Pak Seals will operate at sea, from the air and on land.
The SSG in 2001 created a special forces unit for the Pakistan Air Force called the Special Service Wing (SSW). This new component of the Special Forces of Pakistan is still being trained and built up.
Portugal.
The Portuguese Armed Forces, presently, include the following commando type forces: the "Comandos" Troops, the Parachute Troops, the Corpo de Fuzileiros.
The first modern commando type force created by the Portuguese Army was the "Sapadores de Assalto" (Assault Sappers), a small assault sub-unit organized inside the Army School of Engineers, by the then captain Kaulza de Arriaga, in 1947. However, the majority of the Army was opposed to the existence of special forces and the "Sapadores de Assalto" were soon extinct.
Later, Kaulza de Arriaga, would be appointed the first Secretary of the Air and - in this role - created the Portuguese Parachute Troops in 1956, with commando features, as part of the Portuguese Air Force and not of the Army.
In 1960, the Army created again a commando type unit, the "Caçadores Especiais" (Special Rifles). The "Caçadores Especiais" would fight in the beginning of the Portuguese Overseas War in Africa. However, the Army faction opposed to the existence of special forces prevailed again and the decision was taken to extinct the "Caçadores Especiais" and to extend the training given to those units to all the field units of the Army.
It was soon found impossible to train all units as "Caçadores Especiais". This originated the creation of the "Comandos". The first of these forces were created in Northern Angola in 1962, initially as shock sub-units of regular field battalions and later as independent units. The "Comandos" were designed to conduct special actions in the Portuguese territory or abroad, to fight as assault infantry / shock troops and to provide the high political and military commands with a force able to conduct irregular operations.
Beyond the above-mentioned, the Portuguese Armed and Security Forces organized and employed several other commando type forces in the Overseas Wars in Angola, Mozambique and Portuguese Guinea, including the "Fuzileiros Especiais" (Special Marines) of the Portuguese Navy, the "Flechas" (Arrows) of the International and State Defense Police and the "Grupos Especiais" (Special Groups) of the Government of Mozambique.
Rhodesia.
During the Rhodesian Bush War of 1965–1980, the Rhodesian military increased its usage of commando type of operations in fighting against insurgents until the formation of Zimbabwe. In the Rhodesian Light Infantry a Commando was also the name given to its company sized units.
Russia.
Russia has several units that can be listed under the commando distinction.
The 45th Detached Reconnaissance Brigade is a special reconnaissance and special operations military unit within the Russian Airborne Troops, and based near Moscow. Other Russian units include:
South Africa.
While the use of the word commando came to refer to various elite special operations forces units in other countries in the world, South Africa retained its original name as both a well regulated quick response militia as well as a special operations forces unit defined in the world-wide fashion. From the end of the 19th until the early 21st centuries, the Commando units in the form of its original structure were used in both urban and rural areas until the end of white rule in South Africa as part of a nationwide South African Commando System. Today, the old system has been completely purged by the democratic government which considered the old system as serving and protecting the interests of whites and white privilege. Many Commando veterans, however, argue that crime has risen dramatically as a result of this move.
When white rule was replaced with majority rule, the new democratic ANC led government demanded the disbandment of the commandos which they considered an obstacle to further democratic control as well as complaints of abuses. Thus, with the integration of white cities with black townships, the new ANC led urban governments immediately disbanded the urban militia commando units.
With the election of Thabo Mbeki, the process of de-arming white militias again commenced and it was announced in 2003, that the rural commandos would be disbanded. The last rural commandos were ordered disbanded by the central government over constitutional arguments.
The ANC government directed its attention toward the Reconnaissance Commandos which were the first mixed-race unit in the old SADF. During the period of rationalisation, reorganisation and integration, some Reconnaissance Regiments (Numbers 1, 2, 3, 5 and 6) were disbanded and the members absorbed into the remaining 4 Special Forces Regiment (SFR) at Langebaan and 5 SFR at Phalaborwa as part of the 
South African Special Forces Brigade.
Turkey.
According to 2008 formations there are 5 commando brigades in the Turkish Army. The most notable are the 1st Commando Brigade and the Hakkari Mountain and Commando Brigade. Turkish commandos typically wear blue berets.
The 1st Commando Brigade was involved in the Turkish invasion of Cyprus, and fought beside airborne commandos (Bolu) and the Naval Infantry Brigade (Izmir). In 1988, 7000 commandos received training from the United States.
The Hakkari Mountain and Commando Brigade was founded as a subunit of the 2nd Commando Brigade and is stationed in Hakkâri Province at south-easternmost Turkey. With the rise of the Kurdish insurgency, the existing formation has been enlarged from the size of a battalion to a brigade.
Ukraine.
The Ukrainian Airmobile Forces or VDV (from "Vysokomobil'ni desantni viyska Ukrayiny", Ukrainian: Високомобільні десантні війська України, ВДВ; High-mobile Airborne Forces of Ukraine) is a highly mobile component of the Ukrainian Ground Forces. The airmobile forces consist of formations, units and elements of the Army and the Army aviation, trained for combined activities behind the enemy lines. The airmobile forces are in constant combat readiness and are the high mobility branch of forces. The 79th Airmobile Brigade recently won fame in 2014. The Brigade took part in suppressing the 2014 insurgency in Donbass during the 2014 pro-Russian conflict in Ukraine. The brigade fought in the Second Battle of Donetsk Airport, where it and other Ukrainian military units became known as the "Cyborgs" due to their stubborn defense of the Donetsk Airport. Other Ukrainian units that partake in commando operations:
United Kingdom.
3 Commando Brigade, Royal Marines is under the command of the Royal Navy's Commander-in-Chief Fleet. All Royal Marines (other than the Royal Marines Band Service) are commando trained on entry to the Corps, with supporting units and individuals from the other services undertaking the All Arms Commando Course as required.
The Brigade is made up of 30 (IX) Commando, 40 Commando (home base: Taunton), 42 Commando (Bickleigh, South Hams, Plymouth) and 45 Commando (Arbroath, Scotland), the Commando Logistic Regiment, 539 Assault Squadron Royal Marines, 29 Commando Regiment Royal Artillery, 24 Commando Regiment Royal Engineers and 1 Rifles.
The Royal Marines are the largest force of its type in Europe and the second largest in NATO.
United States.
The United States continues to have no designated "commando" units; however, the closest equivalents remain the U.S. Army's 75th Ranger Regiment and United States Marine Corps Reconnaissance Battalions which specialize in many of the same tasks and missions.
During the Vietnam War the U.S. Army's 5th Special Forces Group (Airborne) instituted, "Special Operations Augmentation Recondo School," an acronym for Reconnaissance Commando. The school was at Nha Trang Air Base, north of the massive U.S. Navy and Air Force Base at Cam Ranh Bay. Recondo School trained small, heavily armed long-range reconnaissance teams the art of patrolling deep in enemy-held territory. All students were combat veterans and came from the ranks of the U.S. Army, U.S. Marine Corps Force Recon Battalions, and the Army of the Republic of South Korea. The Army of the Republic of Vietnam had their own school. Currently the training mission of LRRPs type units is by the U.S. Army Ranger Training Brigade, Reconnaissance and Surveillance Leaders Course, Fort Benning, Georgia. The U.S. Navy SEALs are also well known by the general public especially for their capture of Osama Bin Laden. That particular operation was conducted by the secretive SEAL Team Six.
Vietnam.
The North Vietnamese produced some of the most effective commando units of the post World War II era. Called đặc công, these units represented a force economy measure for the NVA (North Vietnamese Army) and the Viet Cong. With large scale conventional attacks increasingly untenable, small commando operations came into their own, particularly after the Tet Offensive, and at times inflicted severe damage to US and ARVN troops and bases.
Sappers were originally supporting adjuncts to regular formations prior to 1967, but in time, independent formations were created throughout the Vietnam arena. Sappers could operate in support of a larger regular infantry formation, or as the main spearhead themselves, with regulars as backup. In the spearhead mode, they represented their most potent threat. A typical raiding operation was divided into 4 elements: Assault, Fire-Support, Security and Reserves. Assault teams were generally broken down into three-five man cells. Fire-support was critical, as it forced defenders to keep their heads down, while infiltrating assault elements made their final penetrations. One of the most devastating attacks was against the US Firebase, FSB Mary Ann in 1971. See chart for detailed breakdown of a typical sapper raiding party.
While small in terms of total men deployed throughout the Vietnam theater, sapper attacks had a significant impact for the NLF/PAVN effort. As one US Army history puts it:

</doc>
<doc id="80230" url="https://en.wikipedia.org/wiki?curid=80230" title="Clothes hanger">
Clothes hanger

A clothes hanger, coat hanger, or coathanger, is a device in the shape of:
There are three basic types of clothes hangers. The first is the wire hanger, which has a simple loop of wire, most often steel, in a flattened triangle shape that continues into a hook at the top. The second is the wooden hanger, which consists of a flat piece of wood cut into a boomerang-like shape with the edges sanded down to prevent damage to the clothing, and a hook, usually of metal, protruding from the point. Some wooden hangers have a rounded bar from tip to tip, forming a flattened triangle. This bar is designed to hang the trousers belonging to the jacket. The third kind and most used in today's world are plastic coat hangers, which mostly mimic the shape of either a wire or wooden hanger. Plastic coat hangers are also produced in smaller sizes to accommodate the shapes of children's clothes. 
Some hangers have clips along the bottom for suspending skirts. Dedicated skirt and trousers hangers may not use the triangular shape at all, instead using just a rod with clips. Other hangers have little rings coming from the top two bars to hang straps from tank-tops on. Specialized pant hanger racks may accommodate many pairs of trousers. Foldable clothes hangers that are designed to be inserted through the collar area for ease of use and the reduction of stretching are an old, yet potentially useful variation on traditional clothes hangers. They have been patented over 200 times in the U.S. alone, as in U.S. Patent 0586456, awarded in 1897 to George E. Hideout.
History.
Some historians believe President Thomas Jefferson invented a forerunner of the wooden clothes hanger. However, today's most-used hanger, the shoulder-shaped wire hanger, was inspired by a coat hook that was invented in 1869 by O. A. North of New Britain, Connecticut. An employee of the Timberlake Wire and Novelty Company, Albert J. Parkhouse of Jackson, Michigan has also been credited with the invention., as has Christopher Cann in 1876 as an engineering student at Boston University.
In 1906 Meyer May, a men's clothier of Grand Rapids, Michigan, became the first retailer to display his wares on his wishbone-inspired hangers. Some of these original hangers can be seen at the Frank Lloyd Wright designed Meyer May House in Grand Rapids.
In 1932 Schuyler C. Hulett patented an improved design, which used cardboard tubes mounted on the upper and lower parts of the wire to prevent wrinkles, and in 1935 Elmer D. Rogers added a tube on the lower bar, which is still used.
Hangers can be made in wood, wire, plastic, rarely from rubber substance and other materials. Some are padded with fine materials, such as satin, for expensive clothes, lingerie and fancy dresses. The soft, plush padding is intended to protect garments from shoulder dents that wire hangers may make. A caped hanger is an inexpensive wire clothing hanger covered in paper. Caped hangers are used by dry cleaners to protect garments after cleaning. Used wire hangers may be recycled, or returned to the dry cleaner.
In popular culture.
A wire clothes hanger was also a featured prop in an iconic central scene in the 1981 movie "Mommie Dearest", in which Joan Crawford, played by Faye Dunaway with cold cream all over her face, enters the room of her daughter, Christina, at night while she sleeps, to admire the beautiful clothes hanging nicely in her closet. She then becomes enraged upon discovering that Christina has used a wire hanger fearing that her dresses are ruined, instead of the expensive padded hangers Joan provided and instructed her to use. Joan wakes her daughter in terror and gives her a thrashing. Joan's fierce cry of "No wire hangers, ever!" quickly worked its way into pop culture since wire hangers sometimes bring distortion in the clothes and tears holes through the fabric when not used properly. Wire clothes hangers play a prominent part in the 2008 movie "". During a key scene in this "Romantic thriller" directed by James Nguyen, four terrified characters defend themselves against bloodthirsty hawks and vultures by waving wire hangers over their heads in the parking lot of a San Francisco Bay Area Motel 6. 
Unfolded wire clothes hangers, because of their use in performing illegal or self-induced abortions (by inserting one in the uterus), have been used for pro-choice protests.
Unintended uses.
Wire is versatile, and wire clothes hangers are often used as cheap sources of semi-tough wire, more available than baling wire for all sorts of home projects. The use of wire clothes hangers for use as makeshift welding rod has been common for nearly 100 years. Similarly, many similar do-it-yourself and children's projects use wire hangers as holders of various types, from keeping a brake caliper from hanging by the brake line during auto repair work, to securing a gate on a bird cage. After sanding, wire hangers also find uses as conducting wire for uses as varied as hot wiring cars to games to testing hand steadiness. They are commonly used to gain forcible entry into older automobiles whose locks and entry systems are not protected from such methods. There is a long history of using wire coat hangers as replacement car radio antennas. Cloth hangers are also commonly used as an implement for roasting marshmallows or hot dogs at camp-outs.
"Collecticus" magazine reported in October 2007 that clothes hangers have now become collectible, especially those with a famous company or event advertised across the front. For example, a 1950 Butlins hanger sold for £10.10 in October 2006 within "Collecticus".
In 1995, while performing surgery in an airliner at 35,000 feet, orthopedic surgeon Angus Wallace and his fellow doctor Tom Wong used an unfolded coathanger, sterilised with brandy, as a trocar to stiffen a catheter for use as a chest tube to relieve a passenger's pneumothorax.

</doc>
<doc id="80247" url="https://en.wikipedia.org/wiki?curid=80247" title="Venn">
Venn

Venn may mean:

</doc>
<doc id="80248" url="https://en.wikipedia.org/wiki?curid=80248" title="Time immemorial">
Time immemorial

Time immemorial is a phrase meaning time extending beyond the reach of memory, record, or tradition, indefinitely ancient, "ancient beyond memory or record". The phrase is one of a few cases in the English language where the adjective is postpositive—some other phrases, such as the legal terms attorney general and court-martial, also follow that pattern, largely due to the influence of Norman French.
In law, it means that a property or benefit has been enjoyed for so long that its owner does not have to prove how they came to own it. In English law and its derivatives, "time immemorial" means the same as "time out of mind", "a time before legal history and beyond legal memory." In 1275, by the first Statute of Westminster, the time of memory was limited to the reign of Richard I (Richard the Lionheart), beginning 6 July 1189, the date of the King's accession. Since that date, proof of unbroken possession or use of any right made it unnecessary to establish the original grant under certain circumstances. In 1832, "time immemorial" was re-defined as "Time whereof the Memory of Man runneth not to the contrary."

</doc>
<doc id="80249" url="https://en.wikipedia.org/wiki?curid=80249" title="Charles Hapgood">
Charles Hapgood

Charles Hutchins Hapgood (May 17, 1904 – December 21, 1982) was an American college professor and author who became one of the best known advocates of the claim of a rapid and recent pole shift with catastrophic results.
Biography.
Hapgood received a master's degree from Harvard University in 1929 in medieval and modern History. His Ph.D. work on the French Revolution was interrupted by the Great Depression. He taught for a year in Vermont and directed a community center in Provincetown, also serving as the executive secretary of Franklin Roosevelt's Crafts Commission.
During World War II, Hapgood was employed by the Center of Information (which later became the Office of Strategic Services and then the Central Intelligence Agency) and the Red Cross, and also served as a liaison officer between the White House and the Office of the Secretary of the War. After the war, Hapgood taught at Keystone College (1945–1947), Springfield College (1947–1952), Keene State College (1956–1966), and New England College (1966–1967), lecturing in world and American history, anthropology, economics, and the history of science.
Hapgood married Tamsin Hughes in 1941 but divorced in 1955. He was struck by a car in Greenfield, Massachusetts, and died on December 21, 1982.
Polar shift.
While at Springfield College, a student's question about the Lost Continent of Mu prompted a class project to investigate the lost continent of Atlantis, leading Hapgood to investigate possible ways that massive earth changes could occur and exposing him to the literature of Hugh Auchincloss Brown.
In 1958, Hapgood published "The Earth's Shifting Crust" which denied the existence of continental drift and featured a foreword by Albert Einstein. In "Maps of the Ancient Sea Kings" (1966) and "The Path of the Pole" (1970), Hapgood proposed the hypothesis that the Earth's axis has shifted numerous times during geological history. In "Maps of the Ancient Sea Kings" he supported the suggestion made by Arlington Mallery that a part of the Piri Reis Map was a depiction of the area of Antarctica known as Queen Maud Land. He used this to propose that a 15 degree pole shift occurred around 9,600 BCE (approx. 11,600 years ago) and that a part of the Antarctic was ice-free at that time, and that an ice-age civilization could have mapped the coast. 
He concludes that "Antarctica was mapped when these parts were free of ice", taking that view that an Antarctic warm period coincided with the last ice age in the Northern hemisphere, and that the Piri Reis and other maps were based on "ancient" maps derived from ice-age originals. Later research concerning the paleoclimatology and ice sheets of Antarctica have completely discredited the interpretations by Hapgood that an Antarctic warm period coincided with the last glacial period in the Northern hemisphere and any part of it had been ice-free at and prior to 9,600 BCE (approx. 11,600 years ago).
Hapgood also examined a 1531 map by French mathematician and cartographer Oronce Finé (aka "Oronteus Finaeus"). In "Maps of the Ancient Sea Kings", he reproduces letters that he states he received from the chief of a U.S. Air Force cartography section stationed at Westover AFB in 1961. These letters say that at Hapgood's request, they had studied both Piri Reis and Oronce Finé maps during their off-duty hours, concluding that both were compiled from original source maps of Antarctica at a time when it was relatively free of ice, supporting Hapgood's findings. Hapgood concluded that advanced cartographic knowledge appears on the Piri Reis map and the Oronteus Finaeus map, and must be the result of some unknown ancient civilization that developed advanced scientific knowledge before other civilizations such as Greece.
According to historians Paul Hoye and Paul Lunde, while Hapgood's work garnered some enthusiasm and praise for its thoroughness, his revolutionary hypotheses largely met with skepticism and were ignored by most scholars. In the book "The Piri Reis Map of 1513" Gregory C. McIntosh examines Hapgood's claims for both maps and states that "they fall short of proving or even strongly suggesting that the Piri Reis map and the Fine map depict the actual outline of Antarctica."
Hapgood's unorthodox interpretations such as “Earth Crustal Displacement” were never accepted as valid competing scientific hypotheses, yet his ideas have found popularity in alternative circles. Librarians Rose and Rand Flem-Ath as well as author and former journalist Graham Hancock base portions of their works on Hapgood’s evidence for catastrophe at the end of the Last Glacial Maximum. Hapgood's ideas also figure prominently in the 2009 sci-fi/disaster movie "2012."
Acambaro figurines.
Hapgood and Erle Stanley Gardner thought the collection of clay artifacts known as the Acambaro figurines were created thousands of years ago. The date estimate as well as the notion the artifacts were made by some undiscovered culture was rejected by archeologists and paleontologists. The figurines, which most archaeologists dismiss as an elaborate hoax, depict oddities such as dinosaurs coexisting with men and horned humans. In the introduction to later editions of Hapgood's 1973 book, "Mystery in Acambaro", David Hatcher Childress wrote that Hapgood and Gardner thought the figurines were genuine and were evidence that orthodox understandings of dinosaur extinction were wrong.
Elwood Babbitt.
Hapgood spent ten years working with New England medium Elwood Babbitt (b. 1922), attempting to make contact with notable figures from the past. Babbitt, a retired carpenter and World War II veteran, had studied trance mediumship at Edgar Cayce's Association for Research and Enlightenment. Hapgood audiotaped and transcribed a number of Babbitt's "trance lectures" which purported to come from Jesus, Albert Einstein, Mark Twain, and the Hindu god Vishnu, using the material to publish his final three books:"Voices of Spirit, Through the Psychic Experience of Elwood Babbitt" (1975), "Talks with Christ and His Teachers Through the Psychic Gift of Elwood Babbitt" (1981), and "The God Within: a Testament of Vishnu, a Handbook for the Spiritual Renaissance" (1982).

</doc>
<doc id="80250" url="https://en.wikipedia.org/wiki?curid=80250" title="Endemic goitre">
Endemic goitre

Endemic goitre is a type of goitre that is associated with dietary iodine deficiency. 
Some inland areas where soil and water lacks in iodine compounds and consumption of marine foods is low are known for higher incidence of goitre. In such areas goitre is said to be "endemic".
This type of goitre is easily preventable. In most developed countries regulations have been put into force by health policy institutions requiring salt, flour or water to be fortified with iodine.
Treatment of endemic goitre is medical with iodine and thyroxine preparations. Surgery is only necessary in cases where complicated by significant compression of nearby structures.

</doc>
<doc id="80251" url="https://en.wikipedia.org/wiki?curid=80251" title="High Court of Chivalry">
High Court of Chivalry

Her Majesty's High Court of Chivalry of England and Wales is a civil court in England. It has had jurisdiction in cases of the misuse of heraldic arms since the fourteenth century. In Scotland, these types of cases are heard in the Court of the Lord Lyon, which is a standing civil and criminal court, with its own Procurator Fiscal (Public Prosecutor) under the Scottish legal system.
Composition.
The sole judge is now the hereditary Earl Marshal of England, the Duke of Norfolk, though he normally delegates his responsibility to a professional lawyer as his Surrogate. Before 1521, the Lord High Constable of England also presided, but that office was abolished as a permanent institution (it is "revived" only for a Coronation).
Meetings.
The court was last convened in 1954 for the case of "Manchester Corporation v Manchester Palace of Varieties Ltd"; prior to this, the Court had not sat for some centuries and before hearing the case, the Court first had to rule whether it still existed. The Palace theatre displayed the arms of the Manchester Corporation (now Manchester City Council) both inside and on its seal and this usage implied that it was linked with the city's council. The Corporation had requested that the theatre cease the usage and had met with refusal. The court ruled in favour of the Corporation.
More recently, in Oct 2012, Aberystwyth Town Council declared its intention to take legal action against a Facebook page displaying unauthorised use of its coat of arms: these were subsequently removed.
History.
Historically, the court was also known as "Curia Militaris", the Court of the Constable and the Marshal, or the Earl Marshal's Court.
Appeals from the High Court of Chivalry.
Since 1832, appeals from the High Court of Chivalry are to be heard by the Judicial Committee of the Privy Council. Before 1 February 1833, in common with the admiralty and ecclesiastical courts, appeal from the Court was to the Crown in Chancery, with appeals being heard by Commissioners appointed by letters patent under the Great Seal in each case. Sittings by these Commissioners became known as the "High Court of Delegates" by the time of the 1832 Act.

</doc>
<doc id="80252" url="https://en.wikipedia.org/wiki?curid=80252" title="Knossos">
Knossos

Knossos or Cnossos (; also Knossus or Cnossus ; , ), is the largest Bronze Age archaeological site on Crete and is considered Europe's oldest city.
The name Knossos survives from ancient Greek references to the major city of Crete. The identification of Knossos with the Bronze Age site is supported by tradition and by the Roman coins that were scattered over the fields surrounding the pre-excavation site, then a large mound named Kephala Hill, elevation from current sea level. Many of them were inscribed with Knosion or Knos on the obverse and an image of a Minotaur or Labyrinth on the reverse, both symbols deriving from the myth of King Minos, supposed to have reigned from Knossos. The coins came from the Roman settlement of "Colonia Julia Nobilis Cnossus", a Roman colony placed just to the north of, and politically including, Kephala. The Romans believed they had colonized Knossos. After excavation, the discovery of the Linear B tablets, and the decipherment of Linear B by Michael Ventris, the identification was confirmed by the reference to an administrative center, , "ko-no-so", Mycenaean Greek "Knosos" in Linear B, undoubtedly the palace complex. The palace was built over a Neolithic town. During the Bronze Age, the town surrounded the hill on which the palace was built.
The site was discovered in 1878 by Minos Kalokairinos (). The excavations in Knossos began in AD 1900 by the English archaeologist Sir Arthur Evans (1851–1941) and his team, and they continued for 35 years. The palace was excavated and partially restored under the direction of Arthur Evans in the earliest years of the 20th century. Its size far exceeded his original expectations, as did the discovery of two ancient scripts, which he termed Linear A and Linear B, to distinguish their writing from the pictographs also present. From the layering of the palace Evans developed de novo an archaeological concept of the civilization that used it, which he called Minoan, following the pre-existing custom of labelling all objects from the location Minoan.
The palace of Knossos was undoubtedly the ceremonial and political centre of the Minoan civilization and culture. It appears as a maze of workrooms, living spaces, and storerooms close to a central square. An approximate graphic view of some aspects of Cretan life in the Bronze Age is provided by restorations of the palace's indoor and outdoor murals, as it is also by the decorative motifs of the pottery and the insignia on the seals and sealings.
The palace was abandoned at some unknown time at the end of the Late Bronze Age, c. 1380–1100 BC. The occasion is not known for certain, but one of the many disasters that befell the palace is generally put forward. The abandoning population were probably Mycenaean Greeks, who had earlier occupied the city-state, and were using Linear B as its administrative script, as opposed to Linear A, the previous administrative script. The hill was never again a settlement or civic site, although squatters may have used it for a time.
However, fieldwork in 2015 revealed that during the early Iron Age, Knossos was rich in imports and was nearly three times larger than indicated by earlier excavations. Whilst archaeologists had previously believed that the city had declined in the wake of a socio-political collapse around 1200 BC, the work of the Knossos Urban Landscape Project found that the city had prospered instead.
Except for periods of abandonment, other cities were founded in the immediate vicinity, such as the Roman colony, and a Hellenistic Greek precedent. The population shifted to the new town of Chandax (modern Heraklion) during the 9th century AD. By the 13th century, it was called Makruteikhos 'Long Wall'; the bishops of Gortyn continued to call themselves Bishops of Knossos until the 19th century. Today, the name is used only for the archaeological site now situated in the expanding suburbs of Heraklion.
In the first palace period around 2000 BC the urban area reached a size of up to 18,000 people. In its peak the Palace and the surrounding city boasted a population of 100,000 people shortly after 1700 BC.
Discovery and modern history of the antiquities.
In addition to having a history of some thousands of years in the Neolithic, the Bronze Age, and the Classical period, the ruins in the age of archaeology (that is, since the 19th century) have undergone a history of their own, from excavation by renowned archaeologists, education and tourism, to occupation as a headquarters by governments warring over the control of the eastern Mediterranean in two world wars. This site history is to be distinguished from the ancient.
Legends of Knossos.
In Greek mythology, King Minos dwelt in a palace at Knossos. He had Daedalus construct a labyrinth;a very large maze (by some connected with the double-bladed axe, or "labrys") in which to retain his son, the Minotaur. Daedalus also built a dancing floor for Queen Ariadne (Homer, "Iliad" 18.590-2). The name "Knossos" was subsequently adopted by Arthur Evans because it seemed to fit the local archaeology. The identification has never been credibly questioned, mainly because of that archaeology.
Western civilization was thus predisposed by legend to associate whatever palace ruins should be found at Knossos with the legends of Minos and the labyrinth. The first name of the very first man to excavate at Knossos, Minos Kalokairinos, was taken from the legend. As far as is currently known, it was Stillman who, seeing the sign of the double axe on the massive walls partly uncovered by Kalokairinos, first associated the complex with the labyrinth of legend. Evans agreed with Stillman. The myth of the Minotaur tells that Theseus, a prince from Athens, whose father is an ancient Greek king named Aegean;reason for the name of the Greek sea(the Aegean Sea), sailed to Crete, where he was forced to fight a terrible creature called the Minotaur. The Minotaur was a half man, half bull, and was kept in the Labyrinth – a building like a maze – by the king Minos, the ruler of Crete. The king's daughter Ariadne fell in love with Theseus. Before he entered the Labyrinth to fight the Minotaur, Ariadne gave him a ball of thread which he unwound as he went into the Labyrinth so that he could find his way back by following it. Theseus killed the Minotaur, and then he and Ariadne fled from Crete, escaping her angry father.
As it turns out, there probably was an association of the word, whatever its etymology, with ancient Crete. The sign was used throughout the Mycenaean world as an apotropaic symbol: its presence on an object would prevent it from being "killed". Axes were scratched on many of the stones of the palace. It appears in pottery decoration and is a motif of the Shrine of the Double Axes at the palace, as well as of many shrines throughout Crete and the Aegean. And finally, it appears in Linear B on Knossos Tablet Gg702 as da-pu2-ri-to-jo po-ti-ni-ja, which probably represents the Mycenaean Greek "Daburinthoio potniai", "to the mistress of the Labyrinth," recording the distribution of one jar of honey. A credible theory uniting all the evidence has yet to be formulated.
Art and architecture of the palace complex.
The features of the palace depend on the time period. Currently visible is an accumulation of features over several centuries, the latest most dominant. The palace was thus never exactly as depicted today. In addition, it has been reconstituted in modern materials. The custom began in an effort to preserve the site from decay and torrential winter rain. After 1922, the chief proprietor, Arthur Evans, intended to recreate a facsimile based on archaeological evidence. The palace is not exactly as it ever was, perhaps in places not even close, and yet in general, judging from the work put in and the care taken, as well as parallels with other palaces, it probably is a good general facsimile. Opinions range, however, from most skeptical, viewing the palace as pure fantasy based on 1920s architecture and art deco, to most unquestioning, accepting the final judgements of Arthur Evans as most accurate. The mainstream of opinion falls between.
Site geography.
From an archaeological point of view, the terms, "Knossos," and "palace," are somewhat ambiguous. The palace was never just the residence of a monarch, although it contained rooms that might have been suitable for a royal family. Most of the structures, however, were designed to serve a civic, religious and economic center. The term palace complex is more accurate. In ancient times, Knossos was a town surrounding and including Kephala Hill. This hill was never an acropolis in the Greek sense. It had no steep heights, remained unfortified, and was not very high off the surrounding ground. These circumstances cannot necessarily be imputed to other Minoan palaces. Phaestos, contemporaneous with Knossos, was placed on a steep ridge, controlling access to the Mesara Plain from the sea, and was walled. To what degree Minoan civilization might be considered warlike remains debatable. It can, however, be said that Knossos bore no resemblance to a Mycenaean citadel, whether before or during Mycenaean Greek occupation.
The complex was constructed ultimately around a raised Central Court on the top of Kephala Hill. The previous structures were razed and the top was made level to make way for the court. The court is oblong, with the long axis, which points north-northeast, generally described as pointing "north." Plot plans typically show the court with the long axis horizontal, apparently east-west with the north on the right, or vertical with the north on the top. Either arrangement is confusing unless the compass points are carefully marked. About to the north of the palace complex is the sea at the Port of Heraklion. Directly to the south is Vlychia Stream, an east-west tributary of the north-south Kairatos River. Kephala Hill is an isolated hill at the confluence.
The Kairatos River reaches the sea between the port of Heraklion and Heraklion Airport to the east. In ancient times the flow continued without interruption. Today the stream loses itself in the sewers of Heraklion before emerging from under a highway on the shore east of the port. It flows down from higher ground at Arkhanes to the south, where part of it was diverted into the Knossos Aqueduct. The water at that point was clean enough for drinking. When it reached Knossos it became the main drain of the sewer system of a town of up to 100,000 people, according to Pendlebury's estimate. Today the population is mainly to the north, but the sewer function continues, in addition to which much of the river is siphoned off, and the water table is tapped, for irrigation. Looming over the right bank of the Vlychia, on the opposite shore from Knossos, is Gypsades Hill, where the Minoans quarried their gypsum. The limestone was quarried from the ridge on the east.
The archaeological site, Knossos, refers either to the palace complex itself or to that complex and several houses of similar antiquity nearby, which were inadvertently excavated along with the palace. To the south across the Vlychia is the Caravanserai. Further to the south are Minoan houses. The Minoan Road crossed the Vlychia on a Minoan Bridge, immediately entering the Stepped Portico, or covered stairway, to the palace complex. Near the northwest corner of the complex are the ruins of the House of the Frescoes. Across the Minoan Road entering from the northwest is the Arsenal. On the north side of the palace is the Customs House and the Northeast House. From there to the northeast is the modern village of Makrotoichos. Between it and the palace complex is the Royal Villa. On the west side is the Little Palace.
The Royal Road is the last vestige of a Minoan road that connected the port to the palace complex. Today a modern road built over or replacing the ancient, Leoforos Knosou, serves that function and continues south. The excavated ancient Royal Road is part of the complex. The junction of the ancient and the modern roads is partly over the Little Palace. Just to the northwest of there, off the modern road, is where Evans chose to have Villa Ariadne built as his home away from home and an administrative center. The villa is on a slope overlooking the ruins. At the edge of the property, on the road, is a pre-excavation house renovated many times as a residence for the official Keeper, called the Taverna. Immediately to the south of the villa, over parts of the Little Palace, is the modern Stratigraphical Museum, a square building. Excavation continues sporadically on its grounds. To the south of the museum is a modern settlement across from the entrance to the west court. Parking facilities are to the north, off Leoforos Knosou. A band of fields has been left on the northwest between the palace complex and the city streets of Heraklion. The east and west are protected by north-south mountain ridges, between which is the valley of the Kairatos.
General features.
The great palace was gradually built between 1700 and 1400 BC, with periodic rebuildings after destruction. Structures preceded it on Kephala hill. The features currently most visible date mainly to the last period of habitation, which Evans termed Late Minoan. The palace has an interesting layout – the original plan can no longer be seen due to the subsequent modifications. The 1,300 rooms are connected with corridors of varying sizes and direction, which differ from other contemporaneous palaces that connected the rooms via several main hallways. The of the palace included a theater, a main entrance on each of its four cardinal faces, and extensive storerooms (also called magazines). Within the storerooms were large clay containers (pithoi) that held oil, grains, dried fish, beans, and olives. Many of the items were processed at the palace, which had grain mills, oil presses, and wine presses. Beneath the pithoi were stone holes that were used to store more valuable objects, such as gold. The palace used advanced architectural techniques: for example, part of it was built up to five stories high.
Water management.
The palace had at least three separate water-management systems: one for supply, one for drainage of runoff, and one for drainage of waste water.
Aqueducts brought fresh water to Kephala hill from springs at Archanes, about 10 km away. Springs there are the source of the Kairatos river, in the valley in which Kephala is located. The aqueduct branched to the palace and to the town. Water was distributed at the palace by gravity feed through terracotta pipes to fountains and spigots. The pipes were tapered at one end to make a pressure fit, with rope for sealing. No hidden springs have been discovered as at Mycenae.
Sanitation drainage was through a closed system leading to a sewer apart from the hill. The queen's megaron contained an example of the first water-flushing system latrine adjoining the bathroom. This toilet was a seat over a drain that was flushed by pouring water from a jug. The bathtub located in the adjoining bathroom similarly had to be filled by someone heating, carrying, and pouring water, and must have been drained by overturning into a floor drain or by bailing. This toilet and bathtub were exceptional structures within the 1,300-room complex.
As the hill was periodically drenched by torrential rains, a runoff system was a necessity. It began with channels in the flat surfaces, which were zigzag and contained catchment basins to control the water velocity. Probably the upper system was open. Manholes provided access to parts that were covered.
Some links to photographs of parts of the water-collection-management system follow.
Ventilation.
Due to its placement on the hill, the palace received sea breezes during the summer. It had porticoes and air shafts.
Minoan columns.
The palace also includes the Minoan column, a structure notably different from other Greek columns. Unlike the stone columns that are characteristic of other Greek architecture, the Minoan column was constructed from the trunk of a cypress tree, common to the Mediterranean. While most Greek columns are smaller at the top and wider at the bottom to create the illusion of greater height (entasis), the Minoan columns are smaller at the bottom and wider at the top, a result of inverting the cypress trunk to prevent sprouting once in place. The columns at the Palace of Minos were painted red and mounted on stone bases with round, pillow-like capitals.
Pottery.
Pottery at Knossos is prolific, heavily decorated and uniquely styled by period. It is used as a layer diagnostic. Comparing it to similar pottery elsewhere in the eastern Mediterranean, Evans established a wider chronology, which, on that account, is difficult to question successfully. On the negative side, careful records of the locations of some objects were not always kept, due to the very size of the project and the difficulties under which the archaeologists and workmen had to labor.
Frescoes.
The palace at Knossos was a place of high color, as were Greek buildings in the classical period, and as are Greek buildings today. In the EM Period, the walls and pavements were coated with a pale red derived from red ochre. In addition to the background coloring, the walls displayed fresco panel murals, entirely of red. In the subsequent MM Period, with the development of the art, white and black were added, and then blue, green and yellow. The pigments were derived from natural materials, such as ground hematite. Outdoor panels were painted on fresh stucco with the motif in relief; indoor, on fresh, pure plaster, softer than the plaster with additives ordinarily used on walls.
The decorative motifs were generally bordered scenes: people, mythological creatures, real animals, rocks, vegetation, and marine life. The earliest imitated pottery motifs. Most have been reconstructed from various numbers of flakes fallen to the floor. Evans had various technicians and artists work on the project, some artists, some chemists and restorers. The symmetry and use of templates made possible a degree of reconstruction beyond what was warranted by only the flakes. For example, if evidence of the use of a certain template existed scantily in one place, the motif could be supplied from the template found somewhere else. Like the contemporary murals in the funerary art of the Egyptians, certain conventions were utilized that also assisted prediction. For example, male figures are shown with darker or redder skin than female figures.
Some archaeological authors have objected that Arthur and his restorers were not discovering the palace and civilization as it was, but were creating a modern artefact based on contemporary art and architecture.
Throne Room.
The centerpiece of the "Minoan" palace was the so-called Throne Room or Little Throne Room, dated to LM II. This chamber has an alabaster seat identified by Evans as a "throne" built into the north wall. On three sides of the room are gypsum benches. A sort of tub area is opposite the throne, behind the benches, termed a "lustral basin", which means that Evans and his team saw it as a place for ceremonial purification.
The room was accessed from an anteroom through two double doors. The anteroom was connected to the central court, which was four steps up through four doors. The anteroom had gypsum benches also, with carbonized remains between two of them thought to possibly be a wooden throne. Both rooms are located in the ceremonial complex on the west of the central court.
The throne is flanked by the Griffin Fresco, with two griffins couchant (lying down) facing the throne, one on either side. Griffins were important mythological creatures, also appearing on seal rings, which were used to stamp the identities of the bearers into pliable material, such as clay or wax.
The actual use of the room and the throne is unclear. The two main theories are as follows:
It is also speculated that the throne was made specifically for a female individual, since the indentation seems to be shaped for a woman's buttocks. Also, the extensive use of curved edges and the crescent moon carved at its base both symbolize femininity.
The lustral basin was originally thought to have had a ritual washing use, but the lack of drainage has more recently brought some scholars to doubt this theory. It is now speculated that the tank was used as an aquarium, or possibly a water reservoir.
Site history.
Arthur Evans developed his concept of Minoan civilization primarily from the excavations at Knossos. His periodization and general styles and other characteristics have wider application throughout the Aegean.
Neolithic.
Neolithic remains are prolific in Crete. They are found in caves, rock shelters, houses and settlements. Knossos has a thick Neolithic layer indicating the site was a sequence of settlements before the Palace Period. The earliest was placed on bedrock. A. Evans estimates its age by calculating a multiplier of 1800 years per 2.82 metres from the start of Early Minoan at 3400 BC to the end of Middle Minoan at 1600 BC. The 8 metres of the Neolithic is then equivalent 5100 years, except that Evans takes off 10% to allow for a possible increased deposition rate of mud materials. Adding the 4600 of the Neolithic to 3400 gives about 8000 BC for the start of the Neolithic at Knossos. The Proto-Neolithic is missing. From the pottery fragments Evans distinguishes Early, Middle and Late Neolithic.
Evans observes that about 8000 BC a Neolithic people arrived at the hill from elsewhere, probably from overseas by boat, and placed the first of a succession of wattle and daub villages. Large numbers of clay and stone incised spools and whorls attest to a home industry of cloth-making. There are fine ground axe and mace heads of colored stone: greenstone, serpentine, diorite and jadeite, as well as obsidian knives and arrowheads along with the cores from which they were flaked. Most significant among the other small items were a large number of animal and human figurines, including nude sitting or standing females with exaggerated breasts and buttocks. Evans attributes them to the worship of the Neolithic mother goddess and figurines in general to religion.
Evans did not have carbon dating at his command. He would perhaps have been the first to admit that his 8 meters and 10% were nearly completely judgement calls, and that slight variations in either direction would change the overall date significantly. Currently a number of radiocarbon dates have raised the estimate to 7000 – 6500 BC; furthermore, "Knossos Neolithic remains without parallels elsewhere on Crete." At some time in that range a people possessing sheep, pigs, cattle, and growing grains and pulses took up residence on the elevation. The Neolithic was not general over the Aegean until 6500 BC; however, the Neolithic of Cyprus dates to the 9th millennium. If the Knossians were from Cyprus, accessible from anywhere in the Middle East or to any possible maritime peoples from anywhere in the Mediterranean, their ultimate origin might very well never be discovered.
Considering that Evans was necessarily not very clear on the Neolithic, being primarily interested in the palace, John Davies Evans (no relation), whose specialty was the Neolithic of the Aegean, undertook further excavations in pits and trenches over the palace, elucidating the Neolithic. These findings are summarized by McEnroe. In the Aceramic Neolithic, 7,000–6,000 BC, a hamlet of 25–50 persons existed at the location of the Central Court. They lived in wattle and daub huts, kept animals, grew crops, and, in the event of tragedy, buried their children under the floor. In such circumstances as they are still seen today, a hamlet consisted of several families, necessarily interrelated, practicing some form of exogamy, living in close quarters, with little or no privacy and a high degree of intimacy, spending most of their time in the outdoors, sheltering only for the night or in inclement weather, and to a large degree nomadic or semi-nomadic. Sufficient numbers of tribesmen still live in this way to reconstruct a fairly clear picture of life from the remains.
In the Early Neolithic, 6,000–5,000 BC, a village of 200–600 persons occupied most of the area of the palace and the slopes to the north and west. They lived in one- or two-room square houses of mud-brick walls set on socles of stone, either field stone or recycled stone artifacts. The inner walls were lined with mud-plaster. The roofs were flat, composed of mud over branches. The residents dug hearths at various locations in the center of the main room. This village had an unusual feature: one house under the West Court contained eight rooms and covered . The walls were at right angles. The door was centered. Large stones were used for support under points of greater stress. The fact that distinct sleeping cubicles for individuals was not the custom suggests storage units of some sort.
The settlement of the Middle Neolithic, 5,000–4,000 BC, housed 500–1000 people in more substantial and presumably more family-private homes. Construction was the same, except the windows and doors were timbered, a fixed, raised hearth occupied the center of the main room, and pilasters and other raised features (cabinets, beds) occupied the perimeter. Under the palace was the Great House, a area stone house divided into 5 rooms with meter-thick walls suggesting a second story was present. The presence of the house, which is unlikely to have been a private residence like the others, suggests a communal or public use, although the socio-political alpha male may well have lived there; i.e., it may have been the predecessor of a palace. In the Late or Final Neolithic (two different but overlapping classification systems), 4,000–3,000 BC, population increased dramatically, suggesting an immigration (which was Arthur Evans's view also).
Minoan society evidenced at Knossos.
A long-standing debate between archaeologists concerns the main function of the palace, whether it acted as an administrative center, a religious center, or both, in a theocratic manner. Other important debates consider the role of Knossos in the administration of Bronze Age Crete, and whether Knossos acted as the primary center, or was on equal footing with the several other contemporaneous palaces that have been discovered on Crete. Many of these palaces were destroyed and abandoned in the early part of the 15th century BC, possibly by the Mycenaeans, although Knossos remained in use until it was destroyed by fire about one hundred years later. Knossos showed no signs of being a military site; for example, it had neither fortifications nor stores of weapons.

</doc>
<doc id="80253" url="https://en.wikipedia.org/wiki?curid=80253" title="Burmeister &amp; Wain">
Burmeister &amp; Wain

Burmeister & Wain was a large established Danish shipyard and leading diesel engine producer headquartered in Copenhagen, Denmark. Founded by two Danes and an Englishman, its earliest roots stretch back to 1846. Over its 150-year history, it grew successfully into a strong company through the end of the 1960s. In the 1970s, global competitive pressures, particularly from the far east, began to take their toll. In 1980, B&W became MAN B&W Diesel A/S, part of MAN B&W Diesel Group, a subsidiary of the German corporation MAN AG, with operations worldwide. The company still maintains operations at three main sites in Denmark for manufacturing, servicing, and licensing of its two-stroke engines and complete propulsion systems.
History.
Foundation.
Hans Heinrich Baumgarten (1806–1875) was from the town of Halstenbek near Pinneberg, in Schleswig-Holstein, an area of Germany that was then part of Denmark. He was apprenticed as a coffin maker by a farmer whose livestock he cared for. Later he was a carpenter before becoming a machine minder at the Danish newspaper Berlingske Tidende, whose printing office he later worked for in Berlin.
After trying to start a business with different partners, while in Berlin he was allowed an audience, on the subject of establishing a business in Copenhagen, with Crown Prince Christian of Denmark who was visiting. Shortly thereafter, in 1843 he was granted a Danish Royal Charter and what would later become Burmeister & Wain was launched with the opening of a mechanical workshop in Copenhagen.
Earliest years.
Carl Christian Burmeister (1821–1898) was born into poverty. The son of a cook and restaurant keeper, he studied at the Polytechnical Institute in Copenhagen from 1836–1846, now the Technical University of Denmark. He had been awarded a scholarship abroad after recommendation following an assistantship to Hans Christian Ørsted who was director there at the time. Burmeister joined the H.H. Baumgarten Company in 1846, which became a partnership with the opening of its engineering works, and was renamed B&B.
Soon came the establishment of the B&B foundry in 1847, the delivery of its first steam engine in 1848, the renting of the Jacob Holm Shipyard at the 'Englishman's Place' in 1851, and the delivery of their first ship S/S Hermod in 1854, before Baumgarten retired from regular duties in 1861. With Baumgarten as a co-owner, in 1865, William Wain (1819–1882) joined what then became B&W. In 1872 the company became A/S B&W ("Aktieselskabet Burmeister & Wain"), a limited liability corporation. That same year saw the founding of the Refshale Island shipyard. At this point, Baumgarten, as the first founder, became a director of the board of what he would see become Burmeister & Wain "Maskin- og Skibsbyggeri" (Engineering and Shipbuilding) in 1880.
Wain, from Bolton, England had apprenticed as an engineer in his youth and come up through the trades. He had worked for the Royal Danish Navy and the Royal Dutch dockyards. He came to have several designs to his credit within the company and his ingenuity was seen as "instrumental" in establishing its reputation.
Growth and development.
Production of stationary "paraffin" engines began in 1890. Then, in 1898, a year after introducing it to the world, B&W director Ivar Knudsen negotiated with Rudolf Diesel exclusive Danish manufacturing rights for the diesel engine. A test engine was built that same year. The 1903-1904 year saw delivery of their first diesel engine to the N. Larsen Carriage Factory. 1911-1912 saw the world's first ever ocean-going diesel-powered ship, M/S Selandia, start her maiden voyage from Copenhagen to Bangkok with two B&W four-stroke main engines (furnishing a total of 2,500 hp).
The larger Teglholmen iron foundry was established in the 1920-1921 year to provide capacity for growth in the coming years of business acquisition. 
William Elmgreen worked at Burmeister & Wain in Copenhagen as a 20 year old apprentice in 1922. His father Jens Peter Elmgreen had worked there in the 1890s. He later recalled that at that time some 12,000 workers were engaged to build ships, manufacture diesel engines and carry out ship repairs of all kinds. He was one of 2,500 men on Refshale Island, building and repairing ships. They had private lockers for their gear, their bikes were sheltered in enormous sheds, and had access to modern shower rooms – all regarded as modern conveniences in 1922. In the canteen - seating 2,500 - a hot lunch cost 0.75 Kr, and beer was also available in unlimited quantities. On one hot summer's day, seventy cases @ 50 bottles per case of beer were consumed in the canteen by the workers in their lunch hour and a half. Well-cooked food was picked up at the food bar, run by the Workers’ Cooperative, milk and soft drinks were also available. Tools were available at the tool sheds, workers signed for them and paid if they lost any. Each worker was allocated a number (his was 2274). He was engaged on a piece work basis, and worked in a propeller gang.
The first B&W two-stroke diesel engine set off to sea in 1930 and the world's largest diesel engine at the time was delivered in 1933 to H. C. Ørsted Power Station.
Steady progress and consolidation continued through the period of World War II and the subsequent period of reinvigorated prosperity. The first turbocharged two-stroke diesel engine was commissioned in 1952 with larger and more innovative designs to follow.
By this point, the company's engines and licensed designs were used worldwide throughout the industry. Meanwhile, post-war east Asian economies began to emerge as an industrial force.
Recent adjustment and recovery.
In 1971, the shipyard and the engineering works were split into two independent companies. A more challenging period ensued until the 1979-1980 year when B&W Diesel A/S was established, and its shares were sold to MAN, of Germany. Though engine production at Christianshavn was later discontinued in 1987, successful engine programs were rolled out. At Teglholmen in 1988 a spare parts and key components production factory was established as was an R&D Centre at the same site in 1992. Though all Copenhagen operations were consolidated at Teglholmen in 1994 and the last volume production unit at the B&W Shipyard was delivered in 1996. in 2000 MAN B&W Diesel two-stroke diesel engines had over 70% market share, with a substantial number of MC-line engines on order.
The electronically controlled line of ME diesel two-stroke engines was added in 2002 with a maximum cylinder bore of 108 cm. MAN B&W Diesel, Denmark, employed approximately 2,200 at the end of 2003 and had 100 million kW, or more than 8000 MC engines, in service or on order by 2004.
References.
"Lucky Bill" by William Elmgreen (1902-1990), autobiography.

</doc>
<doc id="80260" url="https://en.wikipedia.org/wiki?curid=80260" title="Sale, Victoria">
Sale, Victoria

Sale is a city situated in the Gippsland region of the Australian state of Victoria. It has a population (2011) of 13,186. Sale has seen much development and redevelopment in the past decade, one example being the multimillion-dollar redevelopment of the city's Port of Sale.
History.
Two famous Gippsland explorers, Paul Strzelecki and Angus McMillan, passed through the immediate area around 1840. The first white settler was Archibald McIntosh who arrived in 1844 and established his 'Flooding Creek' property on the flood plain country which was duly inundated soon after his arrival.
In the 1840s, drovers heading south to Port Albert crossed Flooding Creek and were confronted with the difficult marsh country around the Thomson and Latrobe rivers. A punt operated across the Latrobe River until a toll bridge was erected. A Post Office named Flooding Creek opened here on 30 September 1848 being renamed, somewhat belatedly, as Sale on 1 January 1854.
The first town plots went on sale in 1850. When the new settlement was gazetted in 1851 it was named 'Sale' — a tribute to General Sir Robert Sale, a British army officer who won fame in the first Afghan war before being killed in battle in India in 1845. An SBS TV documentary "Afghanistan: The Great Game" claims that it is actually named after his wife, Lady Florentia Sale (1790-1853), who wrote a famous journal of her experiences during the First Afghan War which became a best seller in the 1840s and was serialised in "The Times" (UK) and possibly in Australia. Certainly, her letters to her husband were enthusiastically published in Australian papers.
The town greatly benefitted from the 1851 gold rush at Omeo as it was situated on the Port Albert to Omeo route and was an important base for the goldfields, until the arrival of the railways. It was also an important service centre for East Gippsland and the Monaro Plains of New South Wales. A building boom took place c. 1855–65.
In 1863 the population of Sale reached 1800 and it became a borough. The courthouse opened the following year. Shops, hotels and offices spilled over into Raymond Street and the first Anglican Church was erected on the site now occupied by St Anne's and Gippsland Grammar School. The Gippsland Times newspaper was established in 1861 while the first Star Hotel and the Criterion Hotel were built in 1865.
St Paul's Cathedral is the cathedral church of the Anglican Diocese of Gippsland in Australia. The cathedral building, built in 1884, is a double-storey building with a rectangular footprint and is constructed of red brick and slate roofing.
In terms of access, the first reasonable road from Melbourne arrived in 1865 and Cobb and Co established a rough-and-ready 24-hour coach service linking Melbourne and Sale. The Latrobe Wharf was built in the 1870s and two hotels emerged to exploit the new centre of activity. It was located near the present swing bridge although little is left.
Anthony Trollope visited Sale in 1872. Writing of the experience in Australia and New Zealand (1873) he spoke of the town's 'innumerable hotels' and concluded from his impressions that the Aborigines had little chance of surviving as a race. The children's author Mary Grant Bruce was born in the town in 1878.
A two-storey post office, with clock tower, was built in 1884 (it was demolished in 1963). HM Prison Sale was completed in 1887 and it operated for 110 years until it was replaced by a private Fulham Correctional Centre. The building has since been demolished, with only part of the large brick fencing still remaining. The site remained empty until 2014 when construction of the new Sale Police Station commenced there. It opened in March 2015.
Other landmarks in the town include Our Lady of Sion Convent and the Criterion Hotel. The former was designed by architects Reed, Smart and Tappin and built 1892-1901. Assembly halls and dormitory rear wing were added in 1938; the residential wing was added in 1953. The building is listed on the Register of the National Estate. The Criterion Hotel was built in 1865. It originally had a two-storey timber verandah, but this was replaced by a cast iron verandah between 1880 and 1900. It is considered "one of the most impressive hostelries in Victoria" and is listed on the Register of the National Estate. The Criterion Hotel closed in 2006 and its rapidly deteriorating condition caused local concern that it would be demolished. However, the site was subsequently purchased by a Traralgon-based developer who had previous expertise in restoration of commercial buildings. The Criterion received a complete rebuild in 2010/11 with the external heritage facade and verandah fully restored. It re-opened as a hotel, function venue and restaurant early in 2013.
With the growth of shipping on the local waterways and the Gippsland Lakes (and the establishment of a railhead at Sale in 1879) schemes emerged to develop Sale as a port. The construction of the Sale Canal (complete with turning circle) duly commenced in the 1880s, thereby linking the town via the Thomson River and the Gippsland Lakes to the open sea. It was completed in 1890. Other elements were the Sale Swing Bridge, completed in 1883, a high wharf, and a launching ramp which still exists in the heart of the city. However, neither the bridge nor the canal created the desired surge of trade and the depression of the 1890s soon engulfed the town. Sale became a town in 1924 and a city in 1950.
In World War II, the West Sale RAAF base was the landing site of 2 Japanese Mitsubishi Zeros.
Climate.
Sale has a temperate climate made up of warm summers, mild autumns and springs and cool winters. Sale records 595.9 mm (23.4 in) of measurable precipitation per year, making it drier than the nearby state capital, Melbourne. The wettest month is November whilst the driest is July. At 54.8 days, it gets more clear days than Melbourne (48 days).
Oil and gas.
After oil was discovered offshore in 1965, the town experienced a boom period when it became the service and residential base of the Esso-BHP oil and gas exploration and development program. The unprocessed oil and gas is pumped through of undersea pipes to Longford, south of Sale. There the hydrocarbons are removed and used to produce LPG and ethane. The gas is piped to Melbourne and the oil to Westernport Bay and thence to Geelong and Altona from where it is shipped interstate and overseas.
An oil and gas display centre in Sale outlines the formation, exploration and drilling processes. Esso's Longford gas plant was the site of a major explosion on 25 September 1998 which killed two employees and crippled the state's gas supplies for a period of two weeks. Previously, Sale was significant as an office centre for the Esso corporation but these operations were relocated around 1990, leaving only a gas processing facility in nearby Longford.
Sports.
Australian rules football, basketball and cricket are the most popular sports in Sale. The Gippsland Regional Sports Complex hosts many other sports including basketball, Association rules football, volleyball, badminton, table tennis, indoor soccer, aerobics, group fitness and gym.
The city has two Australian rules football teams, Sale, competing in the Gippsland Football League and Sale City, who compete in the North Gippsland Football League.
It is home to the Sale Sonics, a representative basketball team that competes in the Country Basketball League and is renowned for developing many elite Australian rules football and National Basketball League sporting stars including Jason Gram, Scott Pendlebury, Dylan McLaren and Rhys Carter.
Sale United Football Club (formerly Sale City Soccer Club) represents the City in the Gippsland Soccer League (GSL). Sale United FC was formed as the Sale City Soccer Club in 1974. It has remained in the Gippsland competition each year since the Club's first season and has had a number of promotions and relegations during the term. Sale United is the only recognised soccer club in the Shire, but this was always the case. Representative clubs from Yarram, Bundalaguah, and the RAAF East Sale base also competed in the GSL.
The city is the home to two field hockey clubs in the East Gippsland Hockey Association. The Sale Hockey Club fields teams in juniors mixed under 13's, under 15's and under 18's along with two women's teams, the Sale Cygnets and the Sale Swans, along with one open team. The under 18's and open teams were champions in the 2008 season. The Wurruk Greyhounds are the Sale district's second hockey team, located in the satellite town Wurruk.
Sale has a horse racing club, the Sale Turf Club, which schedules around 21 race meetings a year including the Sale Cup meeting in October.
The Sale Greyhound Racing Club, operating since 1936, holds regular meetings.
Golfers play at the course of the Sale Golf Club on Longford-Rosedale Road in neighbouring Longford.
Sale is also home to a baseball club whose baseball diamonds are located at Stephenson Park.
There are both junior and senior teams competing in the Latrobe Valley Baseball Association.
Sale is also home to the Sale City Rollers who are the regions first amateur Co-ed flat track roller derby league and are located at the Henebery Pavilion at the Sale Showgrounds.
Shopping.
Sale's main shopping precincts are Gippsland Centre and adjacent Raymond St Mall.
Transport.
Sale is linked by rail to Melbourne and Bairnsdale by the Bairnsdale V/Line rail service that stops at the local railway station. Until 1983 the station was situated in the centre of town, on what is now the Gippsland Centre shopping centre.
The city is located at the junction of the Princes Highway and the northeastern end of the South Gippsland Highway.
Facilities.
Fulham Correctional Centre, a medium security prison, is in the locality of Fulham to the west of Sale.
Events and attractions.
The March Labour Day weekend witnesses the Marley Point Overnight Yacht Race which is the longest overnight inland yacht race in the world. It begins near Sale and concludes at Paynesville, some 60 km away.
A Sale attraction is Lake Guthridge, a low lying retention basin, which features a park for children, barbecues, and a walking trail around the lake and car parking facilities. Prior to refurbishment in the mid-1990s Lake Guthridge suffered a blue-green algae problem that resulted in widespread fish mortality until local joggers and nearby residents complained of the associated stench causing council to act. Lake Guthridge has never been used as a food source.
A significantly superior natural waterway of historical significance is the aforementioned Port of Sale (previously "Sale Canal"), the original inspiration for the early town's original name - "Flooding Creek". The Canal connects to other local rivers and lakes, leading eventually to Lakes Entrance, an ocean side tourist resort situated near a managed, naturally occurring channel connecting the Gippsland Lakes to Bass Strait. Once steam boats and ocean-going craft were able to journey from Lakes Entrance to Sale, arriving at the docks at Sale to ferry passengers and goods from Eastern Victoria, although its success in such a role was short lived.
In recent years, a grassroots effort helped to persuade the local council to invest in restoration of the foreshore and to protect against erosion. Prior to the rise of Common Carp as the predominant fish species due to nutrient overload from agricultural runoff, Sale Canal featured pristine waters and native fish stocks. The Sale Regatta is run yearly on a long straight section of the canal headed towards Longford. Visitors to Sale are usually unaware of the Canal, including its restoration, due to roadside views of it being blocked by the former Esso corporation headquarters, half of which is commercially let office space and the other half currently being re-developed into a multimillion-dollar Library and Art Gallery.
Sale is home to the Gippsland Art Gallery, a major Victorian public gallery. The gallery presents a diverse exhibition program of contemporary, modern and historical exhibitions, with a focus on the landscape of South Eastern Australia. The gallery holds a collection of nearly 1,000 artworks, with a small selection on permanent view.
A fishing contest is held at Lake Guthridge every Easter and the Sale Music Festival at Gippsland Grammar School in June. The Sale Art Exhibition is held over August and September, while the Sale show falls in October.
As a tribute to the late King George V, an elm-lined section of the Princes Highway is named "King George V Avenue".
On 30 May 2009, Sale hosted Triple J's One Night Stand at the Sale Football Ground. Sale also has a strong underground music scene; events are held every few months and attract scores of young people.
Every Saturday, Sunday, and Monday, the Gippsland Armed Forces Museum is open, featuring local military and significant history and artifacts. In recent times it has moved from its original location on Punt Lane to a bigger building at West Sale Airfield, after the original building was purchased for development works.
The museum pays homage to the 13th Australian Light Horse Regiment, among others.
Media.
Newspapers.
Sale's local newspaper is "The Gippsland Times", founded in 1861. Two issues are published each week; subscribers pay for only one issue per week. Its readership spans Wellington Shire, from north of Dargo to south of Port Albert, and to the west of Rosedale and east of Munro. The paper is part of the Fairfax Rural Media network of newspapers.
Television.
Commercial television networks Prime7, WIN and Southern Cross Ten all broadcast into Sale from the Latrobe Valley transmitter at Mt Tassie with all stations being based in Traralgon. All three channels have local commercials placed on their broadcasts and WIN TV also broadcasts a local news bulletin. Both national public broadcasters, ABC (ABC1) and SBS (SBS ONE) are broadcast into Sale as well.
New channels broadcast by all the networks in addition to the ones listed above are available on the digital service called Freeview (Australia) to viewers in Sale and the Gippsland \ Latrobe Valley region. These channels include ABC2, ABC3, ABC News 24, SBS Two, One HD, Eleven, 7Two, 7mate, GEM and GO!.
Radio.
Traralgon based Ace Radio commercial stations — TRFM and Gold 1242 both cover Sale. The Gold 1242 AM 1242 kHz transmitter is located in Myrtlebank between Maffra and Sale. Most ABC stations are rebroadcast locally as well as the local ABC Gippsland station that is based in Sale. Community Radio station Life FM is based in Sale.
On the 30 May 2009 the ABC's national network Triple J held their annual One Night Stand concert in Sale. 12,000 people attended the event at the Sale Football Ground. 
Sale Swing Bridge.
The Sale Swing Bridge is the only one left in the world that can swing around 360° and featured in the Australia film noir movie "The Tender Hook".

</doc>
<doc id="80268" url="https://en.wikipedia.org/wiki?curid=80268" title="Favorinus">
Favorinus

Favorinus of Arelate (c. 80 – c. 160 AD) was a Roman sophist and philosopher who flourished during the reign of Hadrian.
He was of Gaulish ancestry, born in Arelate (Arles). He is described as a eunuch (εὐνοῦχος) by birth. He received an exquisite education, first in Gallia Narbonensis and then in Rome, and at an early age began his lifelong travels through Greece, Italy and the East. His extensive knowledge, combined with great oratorical powers, raised him to eminence both in Athens and in Rome. With Plutarch, with Herodes Atticus, to whom he bequeathed his library at Rome, with Demetrius the Cynic, Cornelius Fronto, Aulus Gellius, and with Hadrian himself, he lived on intimate terms; his great rival, whom he violently attacked in his later years, was Polemon of Smyrna.
It was Favorinus who, on being silenced by Hadrian in an argument in which the sophist might easily have refuted his adversary, subsequently explained that it was foolish to criticize the logic of the master of thirty legions. When the servile Athenians, feigning to share the emperor's displeasure with the sophist, pulled down a statue which they had erected to him, Favorinus remarked that if only Socrates also had had a statue at Athens, he might have been spared the hemlock.
Hadrian banished Favorinus at some point in the 130s, to the island of Chios. Rehabilitated with the ascension of Antoninus Pius in 138, Favorinus returned to Rome, where he resumed his activities as an author and teacher of upper class pupils. His year of death is unknown, but he appears to have survived into his eighties, and died perhaps around 160.
Of the very numerous works of Favorinus, we possess only a few fragments, preserved by Aulus Gellius, Diogenes Laertius, Philostratus, and in the "Suda", "Pantodape Historia" (miscellaneous history) and "Apomnemoneumata" (memoirs, things remembered). As a philosopher, Favorinus belonged to the sceptical school; his most important work in this connection appears to have been the "Pyrrhonean Tropes" in ten books, in which he endeavours to show that the methods of Pyrrho were useful to those who intended to practise in the law courts.
Hofeneder (2006) suggests that Favorinus is identical with the "Celtic philosopher" explaining the image of Ogmios in Lucianus. (Eugenio Amato had suggested this identification before in "Luciano e l'anonimo filosofo celta di Hercules 4: proposta di identificazione", Symbolae Osloenses 79 (2004), 128–149).

</doc>
<doc id="80269" url="https://en.wikipedia.org/wiki?curid=80269" title="Roskilde">
Roskilde

Roskilde (), located west of Copenhagen on the Danish island of Zealand, is the main city in Roskilde Municipality. With a population of 50,046 (), the city is a business and educational centre for the region and the 10th largest city in Denmark. Roskilde is governed by the administrative council of Roskilde Municipality.
Roskilde has a long history, dating from the pre-Christian Viking Age. Its UNESCO-listed Gothic cathedral, now housing 39 tombs of the Danish monarchs, was completed in 1275, becoming a focus of religious influence until the Reformation.
With the development of the rail network in the 19th century, Roskilde became an important hub for traffic with Copenhagen, and by the end of the century, there were tobacco factories, iron foundries and machine shops. Among the largest private sector employers today are the IT firm BEC (Bankernes EDB Central) and GPI (Glim Plastic Industri), specializing in plastics. The Risø research facility is also becoming a major employer, extending interest in sustainable energy to the clean technology sphere. The local university, founded in 1972, the historic Cathedral School, and the Danish Meat Trade College, established in 1964, are educational institutions of note. Roskilde has a large local hospital which has been expanded and modernized since it was opened in 1855. It is now increasingly active in the research sphere. The Sankt Hans psychiatric hospital serves the Capital Region with specialized facilities for forensic psychiatry.
The cathedral and the Viking Ship Museum, which contains the well-preserved remains of five 11th-century ships, attract more than 100,000 visitors annually. In addition to its internationally recognized tourist attractions and its annual rock festival, Roskilde is popular with shoppers thanks to its two centrally located pedestrian streets complete with restaurants, cafés, and a variety of shops. The city is home to the FC Roskilde football club which play in the Danish 1st Division, the Roskilde Vikings RK rugby club, and the rowing club, Roskilde Roklub. In the 1970s, the city benefited from the opening of the university and from the completion of the Holbæk Motorway connecting it to Copenhagen. Roskilde has a the oldest operational railway station in Denmark, with connections across Zealand as well as with Falster, Lolland, and Jutland. The local airport opened in 1973, mainly serving light aircraft for business use and flight instruction.
Among the city's notable citizens are Absalon, the bishop who founded Copenhagen in the 12th century, L. A. Ring, the symbolist painter who gained fame in the 1880s, the writer Lise Nørgaard who wrote the popular Danish TV series "Matador" in 1978 and the rower Thomas Ebert who became an Olympic gold medallist in 2004.
History.
Roskilde, which developed as the hub of the Viking land and sea trade routes over a thousand years ago, is one of Denmark's oldest cities. From the 11th century until 1443, it was the capital of Denmark. By the Middle Ages, with the support of kings and bishops, it had become one of the most important centres in Scandinavia. The "Saxo Grammaticus" and other early sources associate the name Roskilde (meaning "Ro's spring") with the legendary King Roar who possibly lived there in the 6th century. 
According to Adam of Bremen and the "Saxo Grammaticus", Roskilde was founded in the 980s by Harald Bluetooth. On high ground above the harbour, he built a wooden church consecrated to the Holy Trinity as well as a royal residence nearby. Although no traces of these buildings have been discovered, in 1997 archaeologists found the remains of Viking ships in the Isefjord, the oldest of which is dated to 1030. At the time, there were also two churches in the area: St Jørgensbjerg, an early stone church, and a wooden church discovered under today's St Ib's Church. Harald was buried in the wooden church he had built on the site of today's Roskilde Cathedral.
In 1020, King Canute elevated Roskilde to a bishopric, giving it high national status. Absalon, the Danish bishop, had a brick church built on the site of Harald's church in 1170. Today's cathedral was completed in 1275 after five of Absalon's successors had contributed to its construction. As a result of Absalon's influence, many other churches were built in the vicinity, making Roskilde the most important town in Zealand. Coins were minted there from the 11th to the 14th century. In 1150, Sweyn Grathe built a moat around the city. The Roskilde bishops owned large areas of land in the region including, from 1186, Havn on the Øresund which later became Copenhagen. By the time of the Danish Reformation in 1536, there were 12 churches and five monasteries in the city.
It is not clear when Roskilde became a market town but it was certainly enjoying trading privileges under King Eric II who reigned from 1134 to 1137. These privileges were firmly established when the Roskilde City Council granted market town status to other towns on Zealand on 15 June 1268. By that time, it was probably the largest and most important town in Denmark. In 1370, the city owned 2,600 farms throughout Zealand.
The Reformation brought Roskilde's development to an abrupt stop. While the cathedral continued to be the preferred location for the entombment of the Danish monarchs, most of the other religious institutions disappeared. For the next three centuries, the city suffered a series of disasters including the effects of the Dano-Swedish War which terminated with the Treaty of Roskilde in 1658, the plague in 1710 and 1711, and a series of fires in 1730. Conditions improved in 1835 when the city became the Assembly of the Estates of the Realm ("Rådgivende Stænderforsamling") and in 1847 with the railway connecting Copenhagen and Roskilde.
With the development of the rail network, Roskilde became an important hub for traffic with Copenhagen. In the 1870s and 1880s, the harbour was extended attracting industrial firms to the area. By the end of the century, there were tobacco factories, iron foundries and machine shops. At the beginning of the 20th century, Roskilde first prospered as a satellite community for Copenhagen but then, as ships increased in size, suffered from the fact that the harbour was too small and Roskilde Fjord too shallow for navigation. Industries began to move out of the harbour area but were still the largest source of employment, thanks in part to the spirits factory ("De Danske Spritfabrikker") and the slaughterhouse ("Roskilde Andelssvineslagteri").
In the 1970s, the city benefited from the Holbæk Motorway which linked it to Copenhagen and the establishment of Roskilde University in 1972. Since the 1980s, the service sector has prospered, replacing manufacturing industry as the major employer (65% by 2002). With the increase in population, several new districts have grown up, including Himmelev and Kongebakken. Some of the surrounding villages such as Svogerslev, Vor Frue, Vindinge and Veddelev have developed as satellite communities.
Geography.
Roskilde is located in north-central Zealand at the south end of Roskilde Fjord which is itself the south branch of the Isefjord. By road, it is west of downtown Copenhagen, northwest of Køge and northeast of Ringsted. The city centre around the cathedral, south of the fjord, is about above sea level. On the slope down to the harbour, there are a number of springs, the most powerful of which is Maglekilde. The historic centre of the town covers the area around the main streets Skomagergade and Algade including the squares of Stændertorvet and Hestetorvet. Two parks, Byparken and Folkeparken which run down towards the fjord, are immediately north of the old town.
Neighbourhoods in the vicinity include Himmelev, Hyrdehøj, Musicon, Sankt Jørgensbjerg and Trekroner. Boserup Skov, a wood next to Roskidle Fjord northwest of the city centre, consists mainly of beech trees. In spring, its hilly slopes are covered with wild flowers, including white, blue and yellow anemones. Chaffinches, nightingales and other songbirds can be heard in the early summer. Also of note is the recently planted wooded area of Hyrdehøj Skov, to the south of the stadium and just north of Route 23 in the southern outskirts of Roskilde.
Demographics and administration.
<noinclude>
As early as 1070, Adam von Bremen referred to Roskilde as "Zealand's largest town". At the time of the Reformation in 1536, it had some 6,000 inhabitants but as a result of war, fire and disease, by 1753 its population had dropped to only 1,550. By the 1860s, it had grown to around 5,000 and by the 1900s to some 9,000. Thereafter it increased appreciably until 1970 when there were almost 45,000 inhabitants. The population dipped slightly to 40,000 in the 1980s, but thanks to improved connections with Copenhagen and the establishment of the university, it grew steadily to reach 47,117 by 2014 making Roskilde Denmark's tenth largest city.
In Roskilde Municipality as of 1 October 2014, 76,545 residents had Danish background, 6,287 were immigrants and 2,006 were second or third generation descendants of immigrants. The most common countries of birth of foreign-born residents of Roskilde Municipality are Turkey, Iraq, Poland and Afghanistan.
Roskilde is governed by the administrative council of Roskilde Municipality. Following the local elections of November 2013, Joy Mogensen (born 1980), a Social Democrat, was reappointed mayor (first elected mayor in 2011), gaining three additional seats on the council. The council now consists of 13 seats for the Social Democrats, one for the Social Liberal Party, one for the Conservative People's Party, one for the Socialist People's Party, three for the People's Party, nine for the Left Liberal Party and three for the Red–Green Alliance.
Economy.
In the 1890s, 37% of Roskilde's economy was in crafts and manufacturing industry with only 15% in administration and services. By 1984, industry had dropped to 16% while services had risen to 57%. In 2002, services had reached 62%, leaving industry at 15% and trade and transport at 22%.
Companies.
One of the largest employers in Roskilde is BEC (Bankernes EDB Central) who provide IT services to the financial sector. In July 2014, Novo A/S acquired Sonion, producing micro-acoustical components for hearing aids. Top-Toy A/S with up to 200 employees is a major Scandinavian toy importer and retailer based in Tune near Roskilde Airport. DLF-Trifolium A/S, a seed producer for the farming sector, has its headquarters in Roskilde with a workforce of over 50. Rambøll, the international Danish engineering consultancy, has recently concentrated its Zealand operations in Roskilde bringing 60 new jobs to the city.
Among the city's smaller companies are GPI (Glim Plastic Industri) established in 1987 producing plastic piping, Roskilde Galvanisering A/S, one of Denmark's leading galvanization companies, and Mathiesen A/S, a wholesaler of office equipment. Vestergaard Company A/S, an American firm which produces de-icing equipment and washing products for the aviation industry, has offices in Roskilde. The new city district of Musicon has already attracted 29 businesses in the area of culture and the creative arts, providing over 1,000 jobs.
Several food industries have their headquarters or production facilities in Roskilde, including: Chr. Hansen A/S, producing cultures for the dairy industry, DanÆg, eggs, the Scandinavian Pizza Company, and Stryhns, a cold cuts and meat paste producer with over 100 on the payroll.
Research parks.
There are a number of research institutes in the city including Risø, promoting sustainable energy, which is now part of Roskilde University. The research facilities are being extended over an additional to cover the clean technology area liable to provide up to 4,000 more jobs. The CAT ("Center for Avanceret Teknologi") research park is also part of the university working mainly in the areas of wind energy and biotechnology. In the public sector, the Accident Investigation Board Denmark has its headquarters in Roskilde.
Tourism.
An important component of the city's economy is tourism which currently accounts for DKK 1.2 billion (US$200 million) per annum. Provisional figures show an increase of 16.6% in overnight stays for 2014. The cathedral and the Viking Ship Museum attract more than 100,000 visitors per year although 20 years ago there were some 200,000 visits to the cathedral.
The city is also popular with shoppers, having received Denmark's Best Shopping City Award in 2012. In addition to a wide variety of shops and restaurants along its two downtown pedestrian streets, Algade and Skomagergade, Roskilde's shopping centre RO's Torv on Københavnsvej to the east of the city houses 70 stores under one roof.
One of the oldest restaurants in Roskilde is the "Raadhuskælderen", in a building dated to 1430, noted for its salmon steak with tartar sauce and grilled chicken and cream sauce dishes. Also of note is "La Brasserie" on Algade, the "Gimle Musikcafe" on Ringstedgade, which is an English-style pub-restaurant with live music, and "Restaurant Toppen" at the top of a water tower, built in 1961, with fine views of the town. The 76-room Hotel Prindsen has foundations which date to 1695. It has been a hotel for over 100 years and is decorated in the Nordic style with wooden floors and contains the large luxury Hans Christian Andersen suite. Scandic Hotel Roskilde is a 98-room chain-run hotel established in 1989, with a restaurant serving Danish and international cuisine. The thatched-roof Svogerslev Kro is an 18-room inn dated to 1727 in the Svogerslev area, about 2.5 miles to the west of Roskilde's centre.
Cityscape.
The old town of Roskilde is centred around the main square, Stændertorvet, just south of the cathedral. The original street plan is preserved in nearby Skomagergade, Algade and Hestetorvet although most of the buildings were rebuilt after serious fires in the 18th century. The area is flanked to the north by two large parks, Byparken and Folkeparken, which stretch down to Roskilde Fjord.
The old town is bordered to the south by the railway and main station, beyond which there are commercial buildings and apartment blocks. The residential areas of Himmelev and Veddelev to the east and north of the city have grown up around former villages. More recently, with the establishment of Roskilde University even further to the east beyond the ring road, the district of Trekroner is in full development, expected to attain some 3,500 houses in the coming years.
One of the most exclusive residential districts of the city, Sankt Jørgensbjerg, covers the hilly area to the northwest, bordered by the fjord. Initially a fishing village dating back to the Viking era, it became part of Roskilde in 1938.
Finally, Roskilde Municipality is developing the innovative Musicon quarter to the south of the city in an area of where a cement factory once stood. Located in the same district as the fairgrounds used for the Roskilde Festival, there are medium-term plans for establishing creative companies and housing for young people in the area. A large rock museum is to open in 2015.
Landmarks.
Roskilde Cathedral.
Located on the site of a 10th-century wooden church, the cathedral was built in the 12th and 13th centuries when the Romanesque style was influenced by Gothic trends from northern France. It was the first Gothic cathedral in Scandinavia to be built of brick, resulting in the spread of this style throughout northern Europe. With its 39 royal tombs, the cathedral is to this day the burial site for Danish monarchs. Since 1995, it has been listed as a UNESCO World Heritage Site, encouraging some 100,000 tourists to visit it each year. The cathedral houses a museum on its upper floor, tracing the building's history. A working church, it also hosts concerts throughout the year.
Roskilde Palace.
Adjacent to the cathedral is Roskilde Palace, built from 1733 to 1736 on the site of the former residence of the bishops of Roskilde. It was used by members of the royal family when they were in the city or attended funerals. Today it houses the Museum of Contemporary Art.
During the English siege of Copenhagen in 1807, the mansion served as headquarters of General Wellesley, the future Duke of Wellington. Built in the Baroque style with yellow-rendered masonry and red tile roofing, the four-winged complex consists of a two-storey main wing, two one-storey lateral wings and a curved gate wing opening onto the Stændertorvet. The four wings are connected by curving galleries. Facing the courtyard, the façade of the main wing has pilasters and a median risalit tipped by a triangular pediment decorated with the royal coat of arms.
Roskilde Convent.
Roskilde Convent is on the site of the former St Catherine's Priory from the mid-13th century which belonged to the Dominican friars until it was dissolved after the Danish Reformation. A private manor house ("Sortebrødregaard" or Blackfriars Manor) was built on the site in 1565 which in 1699 became a convent for women of high rank, the first of its kind in Lutheran Denmark. The building now houses a collection of 150 paintings from the 16th to 18th centuries as well as period furniture. The convent chapel has a carved altarpiece and pulpit.
Roskilde Museum.
Roskilde Museum is a local history museum, run by the municipalities of Roskilde, Frederikssund and Lejre. The main branch in Roskilde, on the corner of Sankt Olsgade and Sankt Olsstræde, is based in two listed buildings, "Sukkerhuset" (the Sugar House) and "Liebes Gård" (Liebe House), a former sugar refinery and merchant's house. The Sugar House was built by a consortium led by Johan Jørgen Holst as a facility for the processing of raw sugar from the Danish West Indies.
Jacob Borch constructed Liebe House in 1804 on the site next to the sugar factory. It replaced a modest house with timber framing and a straw roof dating from the 17th century. The building takes its name from the Liebe family who owned the property for two generations later in the century. On the occasion of his death in 1900, Liebe left the entire building complex to Roskilde Municipality. In 1908, the Sugar House came into use as a fire station. Roskilde Local History Museum was founded on 12 November 1929 on the ground floor of the Liebe House. When the fire station moved to new premises in 1989, Roskilde Museum took over the Sugar House. The museum has exhibits from prehistory, through the Viking Era and the Middle Ages to modern times. The Museum of Tools, housed in separate premises, contains a collection of tools used by craftsmen such as wheelrights, carpenters, shoemakers and wood carvers from around 1850 to 1950.
Viking Ship Museum.
A major attraction in the city is the Viking Ship Museum ("Vikingeskibsmuseet") located alongside Roskilde Fjord. The centrepieces of its collection are the well-preserved remains of five 11th-century Viking ships, excavated from the fjord some north of the city in the late 1960s. The ships were scuttled there in the 11th century to block a navigation channel, protecting the city, then the Danish capital, from seaborne assault. The five Viking ships represent several distinct classes, such as the Longship and Warship, and smaller fishing and ferry boats. The ships on display range from 10 feet (3 m) to 50 feet (15 m) in length. The museum also undertakes research in experimental archaeology centred on Viking shipbuilding and seaworthiness. The boatyard, which also forms part of the museum, safeguards the Viking boat-building tradition by building and exhibiting full-scale ships on site.
Ragnarock Museum.
On April 29, 2016, the Ragnarock museet for pop, rock & ungdomskultur in Roskilde has been inaugurated by Frederik, Crown Prince of Denmark. 
The new 3,100 square-meter museum, designed by the Danish architectural firm MVRDV and by the Dutch one COBE Architects, is aimed to present and disseminate rock music, from the 1950s to the present, and youth culture both intended as means of communication and socialization between people of different culture and social background.
Historic churches.
The Old Church of Our Lady ("Gammel Vor Frue Kirke") is an 11th-century stone church on the southern outskirts of the old town. It is the only surviving travertine basilica in Denmark with a high central nave opening onto two lower lateral aisles. Its carved altarpiece and pulpit from the 1620s are from Brix Michgell's Roskilde workshop. The church was attached to a convent for women of rank until the Reformation. It has been called the "Old" Church of Our Lady since 1907 when a new Church of Our Lady was built to the south of the city.
There are two other historic churches in central Roskilde. St Ib's is located below the cathedral plateau near the harbour. Built in travertine around 1100, the Romanesque building was once richly decorated in frescos, remains of which can be seen on the rear wall. It is no longer a functioning church. St Jørgensbjerg Church stands on a little hill to the northwest of the old town, overlooking the fjord. With a nave and chancel in travertine dating from c. 1080, it is Denmark's oldest preserved stone building. It features a carved pulput from 1616.
The Sankt Laurentii Church Tower is all that remains of the Romanesque Sankt Laurentii Church, built of travertine in the 13th century. It was torn down after the Reformation leaving only the tower which was built at the beginning of the 16th century and now forms part of the former town hall on Stændertorvet. It contains a museum where archaeological finds from 1998 can be seen.
Roskilde Jars.
The three huge Roskilde Jars ("Roskildekrukkerne") stand in a shallow water basin on the square outside the main railway station. They are in height and together weigh about 24 tons. 
The jars are the work of the Danish abstract sculptor Peter Brandes (born 1944). They were commissioned by Elsebeth Stryhn of Stryhns Leverpostej, a local meat paste company, and presented to the city in 1998 on the occasion of Roskilde's 1,000th anniversary.
Roskilde Festival.
Since it was first held in 1971, the Roskilde Festival, a rock music festival, has been held annually on the fairgrounds south of the city centre. It has grown to become one of the biggest music festivals in Scandinavia, with a turnout of around 80,000 every year. It features a diverse selection of music, including rock, metal, hip-hop, electronica, dance, and world music. All profits from the festival are donated to charities. The fairgrounds are also the site of regionally popular agricultural and animal exhibitions, and large flea markets.
Education and sport.
Roskilde University (Danish: "Roskilde Universitet, RUC") was founded in 1972. The university is on the eastern outskirts of Roskilde, in the Trekroner district (named after a signalman's cabin on the Roskilde-Copenhagen line). RUC hosts students from around the world. Roskilde University has on-campus dormitory style housing and apartments but many students commute from Copenhagen. In 2013, there were about 7,600 students, 630 teaching staff and 380 technical and administrative personnel. Designed by Preben Hansen (1908–1989), the university buildings were first brought into use in 1972.
Founded around 1020 to educate priests for the cathedral, Roskilde Cathedral School is possibly the oldest school in Denmark. Initially located close to the cathedral, it moved into larger premises in 1969 to accommodate an increasing number of pupils (currently over 1,300). The Danish Meat Trade College ("Slagteriskolen"), founded in 1964, is a non-profit institution offering vocational training courses in industrial slaughter, retail butchering, sausage making, nutrition and the meat service sector. Training is also offered to kitchen staff, waiters, cooks and bakers. The school employs about 150 teachers and supporting staff. Courses are also available for international students. There is a hostel with accommodation for some 200 students.
There are eleven public primary schools in the municipality split up between eleven school districts. Six gymnasiums (including Roskilde Cathedral School and Roskilde Gymnasium) offer Upper Secondary School Exit Examinations, Higher Preparatory Examinations, Higher Commercial Examination Programme and Higher Technical Examination Programme. There are many adult education, technical and trade schools in addition to the gymnasiums. Roskilde University Library (RUB) is a research library serving the students and staff at the university.
On the sports front, Roskilde is home to the FC Roskilde football club which play in the Danish 1st Division, the country's second highest league. Their home stadium is Roskilde Idrætspark with a capacity of 6,000. The city's rugby club, Roskilde Vikings RK, forms part of the Vor Frue Idrætsforening which also has facilities for badminton, soccer and gymnastics. Members of the rowing club, Roskilde Roklub, have distinguished themselves at the Olympic Games and other recent championships. The Roskilde Congress & Sports Centre provides facilities for sporting events accommodating up to 3,500 spectators. It is home to the Roskilde Handball Club.
Transport.
The principal road running through Roskilde is Danish national road 21, better known as Holbæk Motorway, which connects the city to the capital in the east. Roskilde has a four-platform railway station. Its seven tracks serve as a central hub connecting western and southern Zealand, the islands of Falster and Lolland, and Jutland to Copenhagen. Also within the municipality is the Trekroner station, serving Roskilde University and the developing residential areas to the east of Roskilde. Roskilde Station is the oldest railway station in Denmark still in operation and the first to be built of stone. The first train arrived from Copenhagen on 26 June 1847.
The main airport for Roskilde is Copenhagen Airport which can be reached in about 40 minutes by train. Since April 1973, there has also been the small local Roskilde Airport, serving light aircraft for training, taxi, and flight instruction. There are plans to expand it for use by larger aircraft, possibly including discount international flights. The plans were approved, but lack of commitment from any carriers has postponed progress. The airport currently handles up to 100,000 operations (flights) per year, most of which are light aircraft operations associated with school flights.
The airport is also home to a small Royal Danish Air Force detachment, maintaining a helicopter based search-and-rescue service covering Zealand and the Baltic Sea. Military passenger services have occasionally used the airport. However, there are now plans to close the military facilities in 2017 or 2018.
Healthcare.
The principal hospital in Roskilde is Roskilde Sygehus, founded in 1855. It currently has 437 beds for in-patients and several specialist wards, having been continuously modernized and expanded over the years. Recently physics facilities have been established in medical and hematological outpatient units, while in 2010 the cardiology laboratory was expanded for CAG/PCI. In addition, in 2011 a haematological and a urological ward were modernized and re-equipped. The hospital works in conjunction with Roskilde University in biomedical research, health services research, research assignments, direct research and pharmaceutical biology. It is also involved in a scientific co-operation with the Risø Research Centre.
Sankt Hans Hospital is a psychiatric hospital located in Roskilde but operated by the Capital Region of Denmark. With a history beginning in 1620, the hospital now has 180 beds and offers specialized treatment in the areas of forensic psychiatry and dual diagnosis.
Notable people.
Business
Culture
Politics
Science
Sports

</doc>
<doc id="80271" url="https://en.wikipedia.org/wiki?curid=80271" title="Philostratus">
Philostratus

Philostratus or Lucius Flavius Philostratus (; ; c. 170/172 – 247/250), called "the Athenian", was a Greek sophist of the Roman imperial period. His father was a minor sophist of the same name. He was born probably around 172, and is said by the "Suda" to have been living in the reign of emperor Philip the Arab (244–249). His death possibly occurred in Tyre c. 250 AD.
Name and identity.
Some ambiguity surrounds his name. The praenom "Flavius" is given in "The Lives of the Sophists" and Tzetzes. Eunapius and Synesius call him a Lemnian; Photius a Tyrian; his letters refer to him as an Athenian.
It is probable that he was born in Lemnos, studied and taught at Athens, and then settled in Rome (where he would naturally be called "Atheniensis") as a member of the learned circle with which empress Julia Domna surrounded herself.
Works attributed to Philostratus.
Historians agree that Philostratus authored at minimum five works: "Life of Apollonius of Tyana" (Τὰ ἐς τὸν Τυανέα Ἀπολλώνιον; ), "Lives of the Sophists" (Βίοι Σοφιστῶν), "Gymnasticus" (Γυμναστικός), "Heroicus" (Ἡρωικός) and "Epistolae" (Ἐπιστολαί). Another work, "Imagines" (Εἰκόνες), is usually assigned to his son-in-law Philostratus of Lemnos.
"Heroicus" ("On Heroes", 213–214 AD) is in the form of a dialogue between a Phoenician traveler and a vine-tender or groundskeeper (ἀμπελουργός "ampelourgos"), regarding Protesilaus (or "Protosilaos"), the first Achaean warrior to be killed at the siege of Troy, as described in "The Iliad." The dialogue extends into a discussion and critique of Homer's presentation of heroes and gods, based on the greater authority of the dead Protosileus, who lives after death and communicates with the "ampelourgos". Heroicus includes Achilles' "Ode to Echo".
"Life of Apollonius of Tyana", written between 217 and 238 AD, tells the story of Apollonius of Tyana (c. 40 – c. 120 AD), a Pythagorean philosopher and teacher. Philostratus wrote the book for Julia Domna, wife of Septimius Severus and mother of Caracalla. The book was completed after her death.
"Lives of the Sophists", written between 231 and 237 AD, is a semi-biographical history of the Greek sophists. The book is dedicated to a consul Antonius Gordianus, perhaps one of the two Gordians who were killed in 238. The work is divided into two parts: the first dealing with the ancient Sophists, e.g. Gorgias, the second with the later school, e.g. Herodes Atticus. The "Lives" are not in the true sense biographical, but rather picturesque impressions of leading representatives of an attitude of mind full of curiosity, alert and versatile, but lacking scientific method, preferring the external excellence of style and manner to the solid achievements of serious writing. The philosopher, as he says, investigates truth; the sophist embellishes it, and takes it for granted.
"Gymnasticus", written after 220 AD, contains accounts concerning the Olympic games and athletic contests in general.
"Epistolae", or "Love Letters", breathe the spirit of the New Comedy and the Alexandrine poets; portions of Letter 33 are almost literally translated in Ben Jonson's "Song to Celia", "Drink to Me Only with Thine Eyes." The letters are mainly of an erotic character. Their publication date is unknown.
Internal evidence confirms that the authors of "Life of Apollonius" and "Lives of the Sophists" are one and the same. The "Lives of the Sophists" was to have an enormous impact upon later writers, particularly Neoplatonists.

</doc>
<doc id="80273" url="https://en.wikipedia.org/wiki?curid=80273" title="Blekinge County">
Blekinge County

Blekinge County ("Blekinge län") is a county or "län" in the south of Sweden. It borders the Counties of Skåne, Kronoberg, Kalmar and the Baltic Sea. The capital is Karlskrona. It is the smallest of the present administrative counties of Sweden, covering only 0,7% of the total area
Province.
Blekinge, the historical province "Blekinge", has virtually the same boundaries as the current administrative entity, Blekinge County.
Administration.
Blekinge County was a part of Kalmar County between 1680 and 1683, due to the foundation of the naval base at Karlskrona.
The main aim of the County Administrative Board is to fulfil the goals set in national politics by the Riksdag and the Government, to coordinate the interests and promote the development of the county, to establish regional goals and safeguard the due process of law in the handling of each case. The County Administrative Board is a Government Agency headed by a Governor. See List of Blekinge Governors.
Heraldry.
The County of Blekinge inherited its coat of arms from the province of Blekinge. When it is shown with a royal crown it represents the County Administrative Board.
Politics.
Blekinge County Council, or "Landstinget Blekinge", is a municipal entity that is independent of, but coterminous with, the County Administrative Board. Its main responsibilities lie in health care and public transportation issues for the county.
After the Swedish general election in 2014, the Blekinge County council are represented by the following political parties:
Municipalities.
Population as of 2009-12-31
Blekinge county total 152 591, 1.6% of the nation.
Localities in order of size.
The five most populous localities of Blekinge County in 2010:

</doc>
<doc id="80292" url="https://en.wikipedia.org/wiki?curid=80292" title="Hierocles of Alexandria">
Hierocles of Alexandria

Hierocles of Alexandria () was a Greek Neoplatonist writer who was active around AD 430.
Life.
He studied under Plutarch (the Neoplatonist) at Athens in the early 5th century, and taught for some years in his native city. He seems to have been banished from Alexandria and to have taken up his abode in Constantinople, where he gave such offence that he was thrown into prison and flogged. The causes of this are not recorded.
Works.
The only complete work of his which has been preserved is the commentary on the "Chrysa Epe" ("Golden Verses") of Pythagoras. It enjoyed a great reputation in the Middle Ages and the Renaissance, and there are numerous translations in various European languages. Several other writings, especially one on providence and fate, a consolatory treatise dedicated to his patron Olympiodorus of Thebes, are quoted or referred to by Photius and Stobaeus. Hierocles argued against astrological fatalism on the basis that it is supported by an irrational necessity rather than a divine, rational Providence of God. For the same reason, he opposed theurgic and magic practices as they were attempts to supersede the divine providential order.
Although he never mentions Christianity in his surviving works, his writings have been taken as an attempt at reconciliation between Greek religion traditions and the Christian beliefs he may have encountered in Constantinople.
The collection of some 260 witticisms attributed to Hierocles and Philagrius has no connection with Hierocles of Alexandria, but is probably a compilation of later date, founded on two older collections. It is now agreed that the fragments of the Elements of Ethics preserved in Stobaeus are from a work by a Stoic named Hierocles, contemporary of Epictetus, who has been identified with the "Hierocles Stoicus vir sanctus et gravis" in Aulus Gellius (ix. 5. 8). This theory is confirmed by the discovery of a papyrus (ed. H. von Arnim in Berliner Kiassikertexte, Iv. 1906.)

</doc>
<doc id="80293" url="https://en.wikipedia.org/wiki?curid=80293" title="Botifarra">
Botifarra

Botifarra (; ; ) is a type of sausage and one of the most important dishes of the Catalan cuisine.
"Botifarra" is based on ancient recipes, either the Roman sausage "botulu" or the "lucanica", made of raw pork and spices, with variants today in Italy and in the Portuguese and Brazilian "linguiça".
In Colombia, "Butifarras Soledeñas" are a popular tradition in Soledad, Atlántico.
Varieties.
Some of the most representative types are:
Dishes with botifarra.
Usually white botifarra and black botifarra do not need to be cooked, but they are sometimes boiled as an ingredient "Escudella i carn d'olla", a traditional dish made by boiling vegetables and meat, as well as in the Catalan way of cooking fava beans.
Grilled botifarra served with white beans ( or "botifarra amb mongetes") is a typical Catalan dish.
In Latin America.
In South America a shorter, almost round version of the sausage is known as "butifarra". It is a speciality in Colombia in the town of Soledad and also in Barranquilla. Butifarra is a dish eaten with "bollo" of yuca and lime juice.
"Butifarra" is also very popular in Paraguay and in El Salvador. In Perú the word "butifarra" is used for a different preparation.

</doc>
<doc id="80301" url="https://en.wikipedia.org/wiki?curid=80301" title="J. C. Jacobsen">
J. C. Jacobsen

Jacob Christian Jacobsen (2 September 1811 – 30 April 1887), mostly known as J. C. Jacobsen, was a Danish industrialist and philanthropist best known for founding the brewery Carlsberg.
He had no formal academic or scientific training (although he had attended some lectures by Hans Christian Ørsted). In the 1840s he had come to realise that production of beer, which had until then been done in numerous small breweries, now had to be based on scientific methods and to be industrialised.
Starting in 1847, he established his brewery Carlsberg (named after his son, Carl Jacobsen), in Valby on the outskirts of Copenhagen, on a site where it has remained since. Being extremely scrupulous as for the securing of high quality beer, in 1875 he founded the Carlsberg Laboratory.
He took much interest in public affairs and supported the National Liberal Party – being gradually more of a conservative – both as a Member of Parliament for some periods between 1854 and 1871 and as a strong supporter of the case of defence. Besides he was a well-known patron of art. After the fire of Frederiksborg Palace in 1859 he paid its rebuilding.
1876 he also founded “Carlsberg-fondet” - the Carlsberg Foundation that became his heir because of family problems of the next years. A bitter conflict with his son Carl led to the latter's foundation of the Ny Carlsberg (New Carlsberg) Brewery 1882. A reconciliation was however obtained 1886. This conflict was the theme of a debated Danish TV drama series aired in 1997.
His son Carl Jacobsen created one of the largest private art collections of his time. It is now housed in the Ny Carlsberg Glyptotek, a museum founded by him in Copenhagen.

</doc>
<doc id="80308" url="https://en.wikipedia.org/wiki?curid=80308" title="Kickstart">
Kickstart

Kickstart can refer to:

</doc>
<doc id="80309" url="https://en.wikipedia.org/wiki?curid=80309" title="African diaspora">
African diaspora

The African diaspora refers to the communities throughout the world that have resulted by descent from the movement in historic times of peoples from Africa, predominantly to the Americas, Europe, Asia, and the Middle East, among other areas around the globe. The term has been historically applied in particular to the descendants of the West and Central Africans who were enslaved and shipped to the Americas in the Atlantic slave trade, with their largest populations in Brazil (see Afro-Brazilian), followed by the USA and others. Some scholars identify "four circulatory phases" of migration out of Africa.
The term has also less commonly been used to refer to recent emigration from Africa. The African Union defines the African diaspora as:
" of people of African origin living outside the continent, irrespective of their citizenship and nationality and who are willing to contribute to the development of the continent and the building of the African Union." Its constitutive act declares that it shall "invite and encourage the full participation of the African diaspora as an important part of our continent, in the building of the African Union."
The phrase "African diaspora" was coined during the 1990s, and gradually entered common usage during the 2000s. Use of the term "diaspora" is modelled after the concept of the Jewish diaspora.
History.
Dispersal through slavery.
Much of the African diaspora was dispersed throughout Asia, Europe, and the Americas during the Arab and the Atlantic slave trades. Beginning in the 8th century, Arabs took African slaves from the central and eastern portions of the continent (where they were known as the Zanj) and sold them into markets in the Middle East and eastern Asia. Beginning in the 15th century, Europeans captured or bought African slaves from West Africa and brought them to Europe and primarily, in much greater number, to the Americas. The Atlantic Slave Trade ended in the 19th century, and the Arab Slave Trade ended in the middle of the 20th century. The dispersal through slave trading represents the largest forced migrations in human history. The economic effect on the African continent was devastating, as generations of young people were taken from their communities and societies were disrupted. Some communities created by descendants of African slaves in Europe and Asia have survived to the modern day. In other cases, blacks intermarried with non-blacks, and their descendants blended into the local population.
In the Americas, the confluence of multiple ethnic groups from around the world created multi-ethnic societies. In Central and South America, most people are descended from European, indigenous American, and African ancestry. In Brazil, where in 1888 nearly half the population was descended from African slaves, the variation of physical characteristics extends across a broad range. In the United States, there was historically a greater European colonial population in relation to African slaves, especially in the Northern Tier. There was considerable racial intermarriage in colonial Virginia, and other forms of racial mixing during the slavery and post-Civil War years. Racist Jim Crow and anti-miscegenation laws passed after the Reconstruction era in the South in the late nineteenth century, plus waves of vastly increased immigration from Europe in the 19th and 20th centuries, maintained some distinction between racial groups. In the early 20th century, to institutionalize racial segregation, most southern states adopted the "one drop rule", which defined and recorded anyone with any discernible African ancestry as black, even of obvious majority white or Native American ancestry. One of the results of this implementation was the loss of records of Indian-identified groups, who were classified only as black because of being mixed race.
Dispersal through voluntary migration.
See Emigration from Africa for a general treatment of voluntary population movements since the late 20th century.
From the very onset of Spanish exploration and colonial activities in the Americas, Sub-Saharan Africans participated both as voluntary expeditionaries and as involuntary laborers. Juan Garrido was such an African conquistador. He crossed the Atlantic as a freedman in the 1510s and participated in the siege of Tenochtitlan. Africans had been present in Asia and Europe long before Columbus's travels. Beginning in the late 20th century, Africans began to emigrate to Europe and the Americas in increasing numbers, constituting new African diaspora communities not directly connected with the slave trade.
Concepts and definitions.
The African Union defined the African diaspora as " of people of African origin living outside the continent, irrespective of their citizenship and nationality and who are willing to contribute to the development of the continent and the building of the African Union." Its constitutive act declares that it shall "invite and encourage the full participation of the African diaspora as an important part of our continent, in the building of the African Union."
Between 1500 and 1900, approximately four million enslaved Africans were transported to island plantations in the Indian Ocean, about eight million were shipped to Mediterranean-area countries, and about eleven million survived the Middle Passage to the New World. Their descendants are now found around the globe, but because of intermarriage they are not necessarily readily identifiable.
Social and political.
A long line of scholars has challenged conventional views of the African diaspora as a mere dispersion of Black people. For them, it is a movement of liberation that opposes the implications of racialization. Their position assumes that Africans and their descendants abroad struggle to reclaim power over their lives through voluntary migration, cultural production and political conceptions and practices. It also implies the presence of cultures of resistance with similar objectives throughout the global diaspora. Thinkers like W.E.B. Dubois and more recently Robin Kelley, for example, have argued that Black politics of survival reveal more about the meaning of the African diaspora than labels of ethnicity and race, and degrees of skin hue. From this view, the daily struggle against what they call the "world-historical processes" of racial colonization, capitalism, and western domination defines Blacks links to Africa.
African diaspora and modernity.
In the last decades, studies on the African diaspora have shown an interest in the roles that Blacks played in bringing about modernity. This trend also opposes the traditional eurocentric perspective that has dominated history books showing Africans and its diasporans as primitive victims of slavery, and without historical agency. According to historian Patrick Manning, Blacks toiled at the center of forces that created the modern world. Recognizing their contributions offers a comprehensive appreciation of global history.
Black Diaspora.
The late cultural and political theorist Richard Iton suggested that diaspora be understood as a "culture of dislocation." For Iton, the traditional approach to the African diaspora focuses on the ruptures associated with the Atlantic slave trade and Middle Passage, notions of dispersal, and "the cycle of retaining, redeeming, refusing, and retrieving 'Africa.'" This conventional framework for analyzing the diaspora is dangerous, according to Iton, because it presumes that diaspora exists outside of Africa, thus simultaneously disowning and desiring Africa. Further, Iton suggests a new starting principle for the use of diaspora: "the impossibility of settlement that correlates throughout the modern period with the cluster of disturbances that trouble not only the physically dispersed but those moved without traveling." Iton adds that this impossibility of settlement—this "modern matrix of strange spaces—outside the state but within the empire,"—renders notions of black citizenship fanciful, and in fact, "undesirable." Iton argues that we must understand diaspora as "anaformative impulse... that which resists hierarchy, hegemony, and administration." Put another way, diaspora signals—and welcomes—the impossibility of citizenship, a state of statelessness thereby deconstructing colonial sites and narratives in an effort to "de-link geography and power," putting ""all" space into play" (emphasis added) For Iton, diaspora's potential is represented by a "rediscursive albeit agonistic field of play that might denaturalize the hegemonic representations of modernity as unencumbered and self-generating and bring into clear view its repressed, colonial subscript".
Populations and estimated distribution.
African diaspora populations include:
(*)Note that population statistics from different sources and countries use highly divergent methods of rating the "race", ethnicity, or national or genetic origin of individuals, from observing for color and racial characteristics, to asking the person to choose from a set of pre-defined choices, sometimes with an Other category, and sometimes with an open-ended option, and sometimes not, which different national populations tend to choose in divergent ways. Color and visual characteristics were considered an invalid way to determine the genetic "racial" branch in anthropology (the field of science that original conceived of "race", as a genetic branch of people who could have a relative success together compared with other branches, now considered invalid) as of 1910, thus not fully reflecting the percentage of the population who actually are of African heritage.
Largest 17 African diaspora populations.
Autosomal genetic studies and the African contribution to Brazil.
African ancestry has contributed to the formation of Brazil, along with European and Native American ancestries.
A 2015 autosomal genetic study, which also analysed data of 25 studies of 38 different Brazilian populations concluded that: European ancestry accounts for 62% of the heritage of the population, followed by the African (21%) and the Native American (17%). The European contribution is highest in Southern Brazil (77%), the African highest in Northeast Brazil (27%) and the Native American is the highest in Northern Brazil (32%).
An autosomal study from 2013, with nearly 1300 samples from all of the Brazilian regions, found a pedigree of European ancestry combined with African and Native American contributions. "Following an increasing North to South gradient, European ancestry was the most prevalent in all urban populations (with values up to 74%). The populations in the North consisted of a significant proportion of Native American ancestry that was about two times higher than the African contribution. Conversely, in the Northeast, Center-West and Southeast, African ancestry was the second most prevalent. At an intrapopulation level, all urban
populations were highly mixed, stemming from the large mixed ancestry population rather than a heterogenous distribution of groups of individuals with single ethnic ancestry. "
A 2011 autosomal DNA study, with nearly 1000 samples from all over the country ("whites", "pardos" and "blacks"), found out a major European contribution, followed by a high African contribution and an important Native American component. "In all regions studied, the European ancestry was predominant, with proportions ranging from 60.6% in the Northeast to 77.7% in the South". The 2011 autosomal study samples came from blood donors (the lowest classes constitute the great majority of blood donors in Brazil ), and also public health institutions personnel and health students. The study showed that Brazilians from different regions are more homogenous than previously thought by some based on the census alone. "Brazilian homogeneity is, therefore, a lot greater between Brazilian regions than within Brazilians region".
According to an autosomal DNA study from 2010, "a new portrayal of each ethnicity contribution to the DNA of Brazilians, obtained with samples from the five regions of the country, has indicated that, on average, European ancestors are responsible for nearly 80% of the genetic heritage of the population. The variation between the regions is small, with the possible exception of the South, where the European contribution reaches nearly 90%. The results, published by the scientific magazine "American Journal of Human Biology" by a team of the Catholic University of Brasília, show that, in Brazil, physical indicators such as skin colour, colour of the eyes and colour of the hair have little to do with the genetic ancestry of each person, which has been shown in previous studies (regardless of census classification). "Ancestry informative SNPs can be useful to estimate individual and population biogeographical ancestry. Brazilian population is characterized by a genetic background of three parental populations (European, African, and Brazilian Native Amerindians) with a wide degree and diverse patterns of admixture. In this work we analyzed the information content of 28 ancestry-informative SNPs into multiplexed panels using three parental population sources (African, Amerindian, and European) to infer the genetic admixture in an urban sample of the five Brazilian geopolitical regions. The SNPs assigned apart the parental populations from each other and thus can be applied for ancestry estimation in a three hybrid admixed population. Data was used to infer genetic ancestry in Brazilians with an admixture model. Pairwise estimates of F(st) among the five Brazilian geopolitical regions suggested little genetic differentiation only between the South and the remaining regions. Estimates of ancestry results are consistent with the heterogeneous genetic profile of Brazilian population, with a major contribution of European ancestry (0.771) followed by African (0.143) and Amerindian contributions (0.085). The described multiplexed SNP panels can be useful tool for bioanthropological studies but it can be mainly valuable to control for spurious results in genetic association studies in admixed populations". It is important to note that "the samples came from free of charge paternity test takers, thus as the researchers made it explicit: "the paternity tests were free of charge, the population samples involved people of variable socioeconomic strata, although "likely to be leaning slightly
towards the "pardo" group"".
An autosomal DNA study from 2009 found a similar profile "all the Brazilian samples (regions) lie more closely to the European group than to the African populations or to the Mestizos from Mexico".
According to another autosomal DNA study from 2008, by the University of Brasília (UnB), European ancestry dominates in the whole of Brazil (in all regions), accounting for 65,90% of heritage of the population, followed by the African contribution (24,80%) and the Native American (9,3%).
The Americas.
Caribbean.
The archipelagos and islands of the Caribbean were the first sites of African dispersal in the western Atlantic during the post-Columbian era. Specifically, in 1492, Pedro Alonso Niño, a black Spanish seafarer, piloted one of Columbus's ships. He returned in 1499, but did not settle. In the early 16th century, more Africans began to enter the population of the Spanish Caribbean colonies, sometimes as freedmen, but most often as enslaved servants and workers. Demand for African labour increased in the Caribbean because of the massive deaths among the Taino and other indigenous populations, resulting primarily from Eurasian infectious diseases to which they had no immunity, as well as conflict with the Spanish, and harsh working conditions. By the mid-16th century, slave trade from Africa to the Caribbean was so profitable that the Englishmen Francis Drake and John Hawkins engaged in piracy and violated Spanish colonial laws, in order to forcibly transport approximately 1500 enslaved people from Sierra Leone to Hispaniola (Haiti and Dominican Republic).
During the 17th and 18th centuries, European colonialism in the Caribbean became increasingly reliant on plantation slavery, so that, by the end of the 18th century, on many islands, enslaved Afro-Caribbeans far outnumbered their European masters. A total of 1,840,000 slaves arrived at other British colonies, chiefly the West Indies in the Caribbean.
Beginning in the late 18th century, harsh conditions, constant inter-imperial warfare, and growing human rights goals resulted in the Haitian Revolution in the French colony of Saint-Domingue, led by Toussaint L'Ouverture and Jean Jacques Dessalines. In 1804, Haiti, with what had been an overwhelmingly black slave population and leadership, became the second nation in the Americas to win independence from a European state and create a republic. Continuous waves of rebellion, such as the Baptist War led by Sam Sharpe in Jamaica, created the conditions for the incremental abolition of slavery in the region, with Great Britain abolishing it in 1838. Cuba (under the Spanish Crown) was the last island to emancipate its slaves.
During the 20th century, Afro-Caribbean people began to assert their cultural, economic and political rights on the world stage. The Jamaican Marcus Garvey formed the UNIA movement in the U.S., continuing with Aimé Césaire's négritude movement, which was intended to create a pan-African movement across national lines. From the 1960s, the former slave populations in the Caribbean began to win their independence from British colonial rule. They were pre-eminent in creating new cultural forms such as calypso, reggae music, and rastafarianism within the Caribbean. Beyond the region, a new Afro-Caribbean diaspora, including such figures as Stokely Carmichael and DJ Kool Herc in the United States, was influential in the creation of the black power and Hip Hop movements. Influential political theorists such as Walter Rodney, Frantz Fanon and Stuart Hall contributed to anti-colonial theory and movements in Africa, as well as cultural developments in Europe.
North America.
Several migration waves to the Americas, as well as relocations within the Americas, have brought people of African descent to North America. According to the Schomburg Center for Research in Black Culture, the first African populations came to North America in the 16th century via Mexico and the Caribbean to the Spanish colonies of Florida, Texas and other parts of the South. Out of the 12 million people from Africa who were shipped to the Americas during the transatlantic slave trade, 645,000 were shipped to the British colonies on the North American mainland and the United States. In 2000, African Americans comprised 12.1 percent of the total population in the United States, constituting the largest racial minority group. The African-American population is concentrated in the southern states and urban areas.
In the establishment of the African diaspora, the transatlantic slave trade is often considered the defining element, but people of African descent have engaged in eleven other migration movements involving North America since the 16th century, many being voluntary migrations, although undertaken in exploitative and hostile environments.
In the 1860s, people from sub-Saharan Africa, mainly from West Africa and the Cape Verde Islands, started to arrive in a voluntary immigration wave to seek employment as whalers in Massachusetts. This migration continued until restrictive laws were enacted in 1921 that in effect closed the door on non-Europeans. By that time, men of African ancestry were already a majority in New England’s whaling industry, with African Americans working as sailors, blacksmiths, shipbuilders, officers, and owners. The internationalism of whaling crews, including the character Daggoo, an African harpooneer, is recorded in the 1851 novel "Moby-Dick". They eventually took their trade to California.
Today 1.7 million people in the United States are descended from voluntary immigrants from sub-Saharan Africa, most of whom arrived in the late twentieth century. African immigrants represent 6 percent of all immigrants to the United States and almost 5 percent of the African-American community nationwide. About 57 percent immigrated between 1990 and 2000. Immigrants born in Africa constitute 1.6 percent of the black population. People of the African immigrant diaspora are the most educated population group in the United States — 50 percent have bachelor's or advanced degrees, compared to 23 percent of native-born Americans. The largest African immigrant communities in the United States are in New York, followed by California, Texas, and Maryland.
The states with the highest percentages of people of African descent are Mississippi (36.3%), and Louisiana (32.5%). While not a state, the population of the District of Columbia is more than 50% black. Recent African immigrants represent a minority of blacks nationwide. The U.S. Bureau of the Census categorizes the population by race based on self-identification. The census surveys have no provision for a "multiracial" or "biracial" self-identity, but since 2000, respondents may check off more than one box and claim multiple ethnicity that way.
Canada.
Much of the earliest black presence in Canada came from the newly independent United States (US) after the American Revolution; the British resettled African Americans (known as Black Loyalists) primarily in Nova Scotia. These were primarily former slaves who had escaped to British lines for promised freedom during the Revolution.
Later during the antebellum years, other individual African Americans escaped to Canada, mostly to locations in Southwestern Ontario, via the Underground Railroad, a system supported by both blacks and whites to assist fugitive slaves. After achieving independence, northern states in the US had begun to abolish slavery as early as 1793, but slavery was not abolished in the South until 1865, following the American Civil War.
Black immigration to Canada of the later nineteenth and twentieth centuries came primarily from the Caribbean, in such numbers that fully 70 per cent of all blacks now in Canada are of Caribbean origin. As a result of the prominence of Caribbean immigration, the term "African Canadian", while sometimes used to refer to the minority of Canadian blacks who have direct African or African-American heritage, is "not" normally used to denote black Canadians. Blacks of Caribbean origin are usually denoted as "West Indian Canadian", "Caribbean Canadian" or more rarely "Afro-Caribbean Canadian", but there remains no widely used alternative to "Black Canadian" which is considered inclusive of the African, Afro-Caribbean, and African-American black communities in Canada.
Central America and South America.
At an intermediate level, in South America and in the former plantations in and around the Indian Ocean, descendants of enslaved people are a bit harder to define because many people are mixed in demographic proportion to the original slave population. In places that imported relatively few slaves (like Chile), few if any are considered "black" today. In places that imported many enslaved people (like Brazil or Dominican Republic), the number is larger, though most identify themselves as being of mixed, rather than strictly African, ancestry. Behind America, Brazil has the largest population of Black diasporic people outside of Africa. However, in places like Brazil and the Dominican Republic, Blackness is performed in more taboo ways than it is in, say, the United States. The idea behind Trey Ellis Cultural Mulatto comes into play as there are blurred lines between what is considered as Black.
In Peru, the African population was very mixed with the other white, Indian and mestizo population; so someone is identified as "negro" if he or she has visible African features. Some mestizos and whites have a degree of African admixture.
In Colombia, the African slaves were first brought to work in the gold mines of the Department of Antioquia. After this was no longer a profitable business, these slaves slowly moved to the Pacific coast, where they have remained unmixed with the white or Indian population until today. The whole Department of Chocó remains a black area. Mixture with white population happened mainly in the Caribbean coast, which is a mestizo area until today. There was also a greater mixture in the south-western departments of Cauca and Valle del Cauca. In these mestizo areas the African culture has had a great influence.
Europe.
Some European countries make it illegal to conduct censuses on the basis of skin colour or race (e.g. France), but some others do query along racial lines (e.g. the UK). Of 42 countries surveyed by a European Commission against Racism and Intolerance study in 2007, it was found that 29 collected official statistics on country of birth, 37 on citizenship, 24 on religion, 26 on language, 6 on country of birth of parents, and 22 on nationality or ethnicity.
United Kingdom.
2 million (not including British Mixed) split evenly between Afro-Caribbeans and Africans.
France.
Estimates of 2 to 3 million of African descent, although one quarter of the Afro-French or French African population live in overseas territories. This number is difficult to estimate because the French census does not use race as a category for ideological reasons.
Italy.
There are an estimated 1 million to 1.5 million immigrants from Africa in Italy, with only a minority of Sub-Saharan Africans. Most of the latter come from West African countries such as Ghana, Nigeria, Senegal, and Ivory Coast.
Netherlands.
There are an estimated 500,000 black people in the Dutch Suriname and the Netherlands Antilles. They mainly live in the islands of Aruba, Bonaire, Curaçao and Saint Martin, the latter of which is also partly French-controlled. Many Afro-Dutch people reside in the Netherlands.
Germany.
As of 2005, there were approximately 500,000 Afro-Germans (not including those of mixed ethnicity). This number is difficult to estimate because the German census does not use race as a category.
Russia.
The first blacks in Russia were the result of the slave trade of the Ottoman Empire and their descendants still live on the coasts of the Black Sea. Czar Peter the Great was advised by his friend Lefort to bring in Africans to Russia for hard labor. Alexander Pushkin's great grandfather was the African princeling Abram Petrovich Gannibal, who became Peter's protégé, was educated as a military engineer in France, and eventually became general-en-chef, responsible for the building of sea forts and canals in Russia.
During the 1930s fifteen Black American families moved to the Soviet Union as agricultural experts. As African states became independent in the 1960s, the Soviet Union offered their citizens the chance to study in Russia; over 40 years, 400,000 African students came, and many settled there.
Note that there are also non-African people within the former Soviet Union who are colloquially referred to as "the blacks" ("chernye"). Gypsies, Georgians, and Chechens fall into this category.
Abkhazia.
Some blacks of unknown origin once inhabited southern Abkhazia; today, they are assimilated into the Abkhaz population.
Turkey.
Beginning several centuries ago, a number of sub-Saharan Africans, usually via Zanzibar and from places like Kenya, Tanzania and Sudan, were brought by Turkish slave traders during the Ottoman Empire to plantations around Dalaman, Menderes and Gediz valleys, Manavgat, and Çukurova. In modern times, Africans from all over the continent, including Libya, Cameroon, Algeria, Somalia, Niger, Nigeria, Kenya, Sudan and Ethiopia have immigrated to the large cities of Istanbul and Ankara in search of economic opportunities and prospects, in light of the more lax visa policy the country now has, the population of Africans in Turkey is in the tens of thousands.
Indian and Pacific Oceans.
There are a number of communities in South Asia that are descended from African slaves, traders or soldiers. These communities are the Siddi, Sheedi, Makrani and Sri Lanka Kaffirs. In some cases, they became very prominent, such as Jamal-ud-Din Yaqut, Hoshu Sheedi or the rulers of Janjira State. The Mauritian creole people are the descendants of African slaves similar to those in the Americas.
Some Pan-Africanists also consider other peoples as diasporic African peoples. These groups include, among others, Negritos, such as in the case of the peoples of the Malay Peninsula (Orang Asli); New Guinea (Papuans); Andamanese; certain peoples of the Indian subcontinent, and the aboriginal peoples of Melanesia and Micronesia. Most of these claims are rejected by mainstream ethnologists as pseudoscience and pseudoanthropology, as part of ideologically motivated Afrocentrist irredentism, touted primarily among some extremist elements in the United States who do not reflect on the mainstream African-American community. Mainstream anthropologists determine that the Andamanese and others are part of a network of Proto-Australoid and Paleo Mediterranean ethnic groups present in South Asia that trace their genetic ancestry to a migratory sequence that culminated in the Australian aboriginals rather than from African peoples directly.

</doc>
<doc id="80312" url="https://en.wikipedia.org/wiki?curid=80312" title="UAE (emulator)">
UAE (emulator)

UAE is a computer emulator which emulates the hardware of the Commodore Amiga range of computers. Released under the GNU General Public License, UAE is free software.
History.
UAE was released in 1995 and was originally called the "Unusable Amiga Emulator", due to its inability to boot. In its early stages, it was known as "Unix Amiga Emulator" and later with other names as well. Since none of the popular expansions fit any more, the abbreviation no longer stands for anything, and the software is simply known as UAE — this occasionally gets backronymed as Universal Amiga Emulator, Ultimate Amiga Emulator or Ubiquitous Amiga Emulator.
Features.
UAE is almost a full-featured Amiga emulator. It emulates most of its functions:
For software, UAE may use disk images made from original Amiga floppy disks. These images have the file extension of "ADF" (Amiga Disk File). Actual Amiga disks cannot be used, because of limitations in the floppy controllers used in other computers.
Images of Amiga formatted hard drives can also be made. UAE also supports mapping host operating system's directories to Amiga hard drives.
UAE does not include the original Amiga operating system ROM and files, which are required for running an Amiga system. These are included under license in packages like Amiga Forever. Original Kickstart 3.1 ROM images are also included with AmigaOS4 for PowerPC since version 4.1 Update 4. UAE also supports alternative system ROMs, such as those derived from the AROS project, however these do not provide the same degree of software compatibility as the original ROMs.
Portability.
UAE has been ported to many host operating systems, including Linux, Mac OS, FreeBSD, DOS, Microsoft Windows, RISC OS, BeOS, Palm OS, Android, the Xbox console, the PSP and GP2X handhelds, iOS, the Wii and Dreamcast consoles, and even to AmigaOS, MorphOS and AROS.
Emulation speed.
There have been many threads in the past on Usenet and other public forums where people argued about the possibility of writing an Amiga emulator. Some considered UAE to be attempting the impossible; to be demanding that a system read, process and output 100 MB/s of data when the fastest PC was a 66 MHz 486, while keeping various emulated chips (the Amiga chipset) all in sync and appearing as they were supposed to appear to software.
UAE was almost entirely unusable in its first releases, but slowly and step by step, it fleshed out its support of the Amiga chipset and by the end of 1997 was able to emulate an Amiga 500 at a quality and speed that were sufficient for productivity use and for many games.
Since then, UAE has been usable, thanks partly to the effort taken to develop it and partly to the big improvements in technology that brought computers many times faster than those UAE was initially running on. Many Amiga games and applications can run smoothly on a Pentium II-era system. The realization that a useful Amiga emulator could be written contributed to an increase in enthusiasm about emulation, which started or sped-up efforts to write emulators for other and often less popular computer and electronic game architectures.
A major improvement was made in 2000 by Bernd Meyer with the use of Just-in-time compilation, which significantly improved the emulation speed, to the extent that average PCs could now emulate some Amiga software faster than any real Amiga could run it. UAE can use as much of the host's power in native mode as possible, or balance it with other requirements of the host OS, or to accurately reflect the original speed, depending on a user's choice. UAE also provides an RTG-compatible "video card" for the Amiga side of the emulation which is tailored for display on the host hardware, so as not to be limited to the emulation of the original Amiga video hardware.
Project development.
There are five main forks of the original program:
The most active fork is WinUAE; current versions of this still contain bugs and compatibility issues. WinUAE has reasonable compatibility for most software but, just like a "real" Amiga, for some old games it requires careful configuration in order to match the originally-supported hardware. For example, 68000 code could cause an exception on an emulated 68040, just like it would on an Amiga 4000/040. Since 2007, WinUAE has been including a layer of code for use as a "plugin" in Amiga Forever.
Specific versions:

</doc>
<doc id="80313" url="https://en.wikipedia.org/wiki?curid=80313" title="Yokohama">
Yokohama

Yokohama's population of 3.7 million makes it Japan's largest incorporated city. Yokohama developed rapidly as Japan's prominent port city following the end of Japan's relative isolation in the mid-19th century, and is today one of its major ports along with Kobe, Osaka, Nagoya, Hakata, Tokyo, and Chiba.
History.
Opening of the Treaty Port (1859–1868).
Yokohama was a small fishing village up to the end of the feudal Edo period, when Japan held a policy of national seclusion, having little contact with foreigners. A major turning point in Japanese history happened in 1853–54, when Commodore Matthew Perry arrived just south of Yokohama with a fleet of American warships, demanding that Japan open several ports for commerce, and the Tokugawa shogunate agreed by signing the Treaty of Peace and Amity.
It was initially agreed that one of the ports to be opened to foreign ships would be the bustling town of Kanagawa-juku (in what is now Kanagawa Ward) on the Tōkaidō, a strategic highway that linked Edo to Kyoto and Osaka. However, the Tokugawa shogunate decided that Kanagawa-juku was too close to the Tōkaidō for comfort, and port facilities were instead built across the inlet in the sleepy fishing village of Yokohama. The Port of Yokohama was officially opened on June 2, 1859.
Yokohama quickly became the base of foreign trade in Japan. Foreigners initially occupied the low-lying district of the city called Kannai, residential districts later expanding as the settlement grew to incorporate much of the elevated Yamate district overlooking the city, commonly referred to by English speaking residents as "The Bluff".
Kannai, the foreign trade and commercial district (literally, "inside the barrier"), was surrounded by a moat, foreign residents enjoying extraterritorial status both within and outside the compound. Interactions with the local population, particularly young samurai, outside the settlement inevitably caused problems; the Namamugi Incident, one of the events that preceded the downfall of the shogunate, took place in what is now Tsurumi Ward in 1862, and prompted the brief Anglo-Japanese War of 1863.
To protect British commercial and diplomatic interests in Yokohama a military garrison was established in 1862. With the growth in trade increasing numbers of Chinese also came to settle in the city. Yokohama was the scene of many notable firsts for Japan including the growing acceptance of western fashion, photography by pioneers such as Felice Beato, Japan's first English language newspaper, the "Japan Herald" published in 1861 and in 1865 the first ice cream and beer to be produced in Japan. Recreational sports introduced to Japan by foreign residents in Yokohama included European style horse racing in 1862, cricket in 1863 and rugby union in 1866. A great fire destroyed much of the foreign settlement on November 26, 1866 and smallpox was a recurrent public health hazard, but the city continued to grow rapidly attracting both foreigners and local Japanese.
Meiji and Taisho Periods (1868–1923).
In 1887, a British merchant, Samuel Cocking, built the city's first power plant. At first for his own use, this coal-burning plant became the basis for the Yokohama Cooperative Electric Light Company. The city was officially incorporated on April 1, 1889. By the time the extraterritoriality of foreigner areas was abolished in 1899, Yokohama was the most international city in Japan, with foreigner areas stretching from Kannai to the Bluff area and the large Yokohama Chinatown.
The early 20th century was marked by rapid growth of industry. Entrepreneurs built factories along reclaimed land to the north of the city toward Kawasaki, which eventually grew to be the Keihin Industrial Area. The growth of Japanese industry brought affluence, and many wealthy trading families constructed sprawling residences there, while the rapid influx of population from Japan and Korea also led to the formation of Kojiki-Yato, then the largest slum in Japan.
Great Kanto Earthquake and the Second World War (1923–1945).
Much of Yokohama was destroyed on September 1, 1923 by the Great Kantō earthquake. The Yokohama police reported casualties at 30,771 dead and 47,908 injured, out of a pre-earthquake population of 434,170. Fuelled by rumours of rebellion and sabotage, vigilante mobs thereupon murdered many Koreans in the Kojiki-yato slum. Many people believed that Koreans used black magic to cause the earthquake. Martial law was in place until November 19. Rubble from the quake was used to reclaim land for parks, the most famous being the Yamashita Park on the waterfront which opened in 1930.
Yokohama was rebuilt, only to be destroyed again by thirty-odd U.S. air raids during World War II. An estimated seven or eight thousand people were killed in a single morning on May 29, 1945 in what is now known as the Great Yokohama Air Raid, when B-29s firebombed the city and in just one hour and nine minutes reduced 42% of it to rubble.
Post-war growth.
During the American occupation, Yokohama was a major transshipment base for American supplies and personnel, especially during the Korean War. After the occupation, most local U.S. naval activity moved from Yokohama to an American base in nearby Yokosuka.
The city was designated by government ordinance on September 1, 1956.
The city's tram and trolleybus system was abolished in 1972, the same year as the opening of the first line of Yokohama Municipal Subway.
Construction of Minato Mirai 21 ("Port Future 21"), a major urban development project on reclaimed land, started in 1983. Minato Mirai 21 hosted the Yokohama Exotic Showcase in 1989, which saw the first public operation of maglev trains in Japan and the opening of Cosmo Clock 21, then the tallest Ferris wheel in the world. The 860m-long Yokohama Bay Bridge opened in the same year.
In 1993, Minato Mirai saw the opening of the Yokohama Landmark Tower, the second tallest building in Japan.
The 2002 FIFA World Cup final was held in June at the International Stadium Yokohama.
In 2009, the city marked the 150th anniversary of the opening of the port and the 120th anniversary of the commencement of the City Administration. An early part in the commemoration project incorporated the Fourth Tokyo International Conference on African Development (TICAD IV) which was held in Yokohama in May 2008.
In November 2010, Yokohama hosted the Asia-Pacific Economic Cooperation (APEC) meeting.
Historical population.
Yokohama's foreign population of nearly 78,000 includes Chinese, Koreans, Filipinos, and Brazilians.
Climate.
Yokohama features a humid subtropical climate (Köppen: Cfa) with hot and humid summers and chilly winters. Winter temperatures rarely drop below freezing, while summer can get quite warm due to humidity effects. The coldest temperature was on 24 January 1927 when was reached, whilst the hottest day was 11 August 2013 at . The highest monthly rainfall has been in October 2004 with , closely followed by July 1941 with , whilst December and January have recorded no measurable precipitation three times each.
Politics and government.
The Yokohama Municipal Assembly consists of 92 members elected from 18 Wards total. The LDP has minority control with 30 seats with Democratic Party of Japan with a close 29. The mayor is Fumiko Hayashi, who succeeded Hiroshi Nakada in September 2009.
Wards.
Yokohama has 18 wards ("ku"):
Economy.
The city has a strong economic base, especially in the shipping, biotechnology, and semiconductor industries. Nissan moved its headquarters to Yokohama from Chūō, Tokyo in 2010.
Maritime Port.
Yokohama is the world's 31st largest seaport in terms of total cargo volume, at 121,326 freight tons , and is ranked 37th in terms of TEUs (Twenty-foot equivalent units).
In 2013 APM Terminals Yokohama facility was recognised as the most productive container terminal in the world averaging 163 crane moves per hour, per ship between the vessel's arrival and departure at the berth.
Transport.
Yokohama is serviced by the Tōkaidō Shinkansen, a high-speed rail line with a stop at Shin-Yokohama Station. Yokohama Station is also a major station, with two million passengers daily. The Yokohama Municipal Subway provides metro services.
Education.
Public elementary and middle schools are operated by the city of Yokohama. There are nine public high schools which are operated by the Yokohama City Board of Education, and a number of public high schools which are operated by the Kanagawa Prefectural Board of Education. Yokohama National University is a leading university in Yokohama which is also one of the highest ranking national universities in Japan.
Places of interest.
The historic downtown port district, location of the first foreign settlement, is known as Kannai. Next to the waterfront Yamashita Park is the museum ship, Hikawa Maru, and the Yokohama Marine Tower, the tallest inland lighthouse in the world. Further inland lies Yokohama Chinatown, the largest Chinatown in Japan and one of the largest in the world. Nearby is Yokohama Stadium, the Yokohama Silk Museum, and the Yokohama Doll Museum. The Isezakichō and Noge areas offer many colourful shops and bars that, with their restaurants and stores catering to residents from China, Thailand, South Korea, and other countries, have an increasingly international flavour.
The small but fashionable Motomachi shopping area leads up to Yamate, or "The Bluff" as it used to be known, a 19th/early 20th century Westerners' settlement overlooking the harbour, scattered with foreigners' mansions. A foreigners' cemetery and the Harbour View Park (, "Minato no mieru oka kōen") is in the area. Within the park are a rose garden and the Kanagawa Museum of Modern Literature.
There are various points of interest in the futuristic Minato Mirai 21 harbourside redevelopment. The highlights are the Landmark Tower which was the tallest building in Japan (until surpassed in 2014 by the Abeno Harukas building in Osaka), Queen's Square Yokohama (a shopping mall) and the Cosmo Clock 21, which was the tallest Ferris wheel in the world when it was built in 1989 and which also doubles as "the world's biggest clock".
The Shin-Yokohama district, where the Shinkansen station is located, is some distance away from the harbour area, and features the 17,000 capacity Yokohama Arena, the Shin-Yokohama Raumen Museum and Nissan Stadium, known as the International Stadium Yokohama when it was the setting for the final for the 2002 FIFA World Cup.
The city is home to the Central League baseball team, the Yokohama BayStars, and the soccer teams, Yokohama F. Marinos and Yokohama F.C.
Sankei-en is a traditional Japanese-style garden in Naka Ward. Designed by businessman Tomitaro Hara, it contains seventeen old buildings brought from all over Japan, ten of which have been declared Important National Cultural Properties.
Among the attractions are festivals and events.
International relations.
Yokohama has sister-city relationships with eleven cities worldwide.

</doc>
<doc id="80322" url="https://en.wikipedia.org/wiki?curid=80322" title="Lev Landau">
Lev Landau

Lev Davidovich Landau (; 1 April 1968) was a Soviet physicist who made fundamental contributions to many areas of theoretical physics. His accomplishments include the independent co-discovery of the density matrix method in quantum mechanics (alongside John von Neumann), the quantum mechanical theory of diamagnetism, the theory of superfluidity, the theory of second-order phase transitions, the Ginzburg–Landau theory of superconductivity, the theory of Fermi liquid, the explanation of Landau damping in plasma physics, the Landau pole in quantum electrodynamics, the two-component theory of neutrinos, and Landau's equations for "S" matrix singularities. He received the 1962 Nobel Prize in Physics for his development of a mathematical theory of superfluidity that accounts for the properties of liquid helium II at a temperature below ().
Life.
Early years.
Landau was born on 22 January 1908 to Jewish parents in Baku, Azerbaijan, in what was then the Russian Empire. Landau's father was an engineer with the local oil industry and his mother was a doctor. He learned to differentiate at age 12 and to integrate at age 13. Landau graduated in 1920 at age 13 from gymnasium. His parents considered him too young to attend university, so for a year he attended the Baku Economical Technical School (техникум). In 1922, at age 14, he matriculated at the Baku State University, studying in two departments simultaneously: the Departments of Physics and Mathematics, and the Department of Chemistry. Subsequently he ceased studying chemistry, but remained interested in the field throughout his life.
Leningrad and Europe.
In 1924, he moved to the main centre of Soviet physics at the time: the Physics Department of Leningrad State University. In Leningrad, he first made the acquaintance of genuine theoretical physics and dedicated himself fully to its study, graduating in 1927. Landau subsequently enrolled for post-graduate studies at the Leningrad Physico-Technical Institute where he eventually received a doctorate in Physical and Mathematical Sciences in 1934. Landau got his first chance to travel abroad during the period 1929–1931, on a Soviet government—People's Commissariat for Education—travelling fellowship supplemented by a Rockefeller Foundation fellowship.
After brief stays in Göttingen and Leipzig, he went to Copenhagen on April 8, 1930 to work at the Niels Bohr's Institute for Theoretical Physics. He stayed there till May 3 of the same year. After the visit, Landau always considered himself a pupil of Niels Bohr and Landau's approach to physics was greatly influenced by Bohr. After his stay in Copenhagen, he visited Cambridge (mid-1930), where he worked with P. A. M. Dirac, Copenhagen (September 20 to 22 November 22, 1930), and Zurich (December 1930 to January 1931), where he worked with Wolfgang Pauli. From Zurich Landau went back to Copenhagen for the third time and stayed there from February 25 till March 19, 1931 before returning to Leningrad the same year.
National Scientific Center Kharkiv Institute of Physics and Technology, Kharkiv.
Between 1932 and 1937 he headed the Department of Theoretical Physics at the National Scientific Center Kharkiv Institute of Physics and Technology and lectured at the University of Kharkiv and the Kharkiv Polytechnical Institute. Apart from his theoretical accomplishments, Landau was the principal founder of a great tradition of theoretical physics in Kharkiv, Soviet Union, sometimes referred to as the "Landau school". In Kharkiv, he and his friend and former student, Evgeny Lifshitz, began writing the "Course of Theoretical Physics", ten volumes that together span the whole of the subject and are still widely used as graduate-level physics texts. During the Great Purge, Landau was investigated within the UPTI Affair in Kharkiv, but he managed to leave for Moscow to take up a new post.
Landau developed a famous comprehensive exam called the "Theoretical Minimum" which students were expected to pass before admission to the school. The exam covered all aspects of theoretical physics, and between 1934 and 1961 only 43 candidates passed, but those who did later became quite notable theoretical physicists.
In 1932, he computed the Chandrashekhar limit, however, he did not apply it to white dwarf stars.
Institute for Physical Problems, Moscow.
Landau was the head of the Theoretical Division at the Institute for Physical Problems from 1937 until 1962. Landau was arrested on 27 April 1938, because he had compared the Stalinist dictatorship with that of Hitler, and was held in the NKVD's Lubyanka prison until his release on 29 April 1939, after the head of the institute Pyotr Kapitsa, an experimental low-temperature physicist, wrote a letter to Joseph Stalin, personally vouching for Landau's behavior, and threatening to quit the institute if Landau were not released. After his release Landau discovered how to explain Kapitsa's superfluidity using sound waves, or phonons, and a new excitation called a roton.
Landau led a team of mathematicians supporting Soviet atomic and hydrogen bomb development. Landau calculated the dynamics of the first Soviet thermonuclear bomb, including predicting the yield. For this work he received the Stalin Prize in 1949 and 1953, and was awarded the title "Hero of Socialist Labour" in 1954.
His students included Lev Pitaevskii, Alexei Abrikosov, Evgeny Lifshitz, Lev Gor'kov, Isaak Khalatnikov, Roald Sagdeev and Isaak Pomeranchuk.
Scientific achievements.
Physics Today writes: "A prominent Soviet physicist, Landau made fundamental contributions to many areas of theoretical physics.
His accomplishments include the independent co-discovery of the density matrix method in quantum mechanics (alongside John von Neumann), the quantum mechanical theory of diamagnetism, the theory of superfluidity, the theory of second-order phase transitions, the Ginzburg–Landau theory of superconductivity, the theory of Fermi liquid, the explanation of Landau damping in plasma physics, the Landau pole in quantum electrodynamics, the two-component theory of neutrinos, and Landau's equations for S matrix singularities.
He received the 1962 Nobel Prize in Physics for his development of a mathematical theory of superfluidity that accounts for the properties of liquid helium II at a temperature below 2.17 K (−270.98 °C)." 
Personal life and views.
In 1937 Landau married a girl from Kharkov, Kora T. Drobanzeva; their son Igor was born in 1946. Landau believed in "free love" rather than monogamy, and encouraged his wife and his students to practice "free love"; his wife was not enthusiastic. During his life, Landau was admitted involuntarily six times to the Kashchenko psychiatric hospital.
He was an atheist.
Last years.
On 7 January 1962, Landau's car collided with an oncoming truck. He was severely injured and spent two months in a coma. Although Landau recovered in many ways, his scientific creativity was destroyed, and he never returned fully to scientific work. His injuries prevented him from accepting the 1962 Nobel Prize for physics in person.
In 1965 former students and co-workers of Landau founded the Landau Institute for Theoretical Physics, located in the town of Chernogolovka near Moscow, and led for the following three decades by Isaak Markovich Khalatnikov.
In June 1965, Lev Landau and Yevsei Liberman published a letter in the "New York Times", stating that as Soviet Jews they opposed US intervention on behalf of the Student Struggle for Soviet Jewry.
Death.
Landau died on 1 April 1968, aged 60, from complications of the injuries sustained in the car accident he was involved in six years earlier. He was buried at the Novodevichy cemetery.
Legacy.
Two celestial objects are named in his honour:
Landau's List.
Landau kept a list of names of physicists which he ranked on a logarithmic scale of productivity ranging from 0 to 5. The highest ranking, 0, was assigned to Isaac Newton. Albert Einstein was ranked 0.5. A rank of 1 was awarded to the founding fathers of quantum mechanics, Niels Bohr, Werner Heisenberg, Paul Dirac and Erwin Schrödinger, and others. Landau ranked himself as a 2.5 but later promoted himself to a 2. David Mermin, writing about Landau, referred to the scale, and ranked himself in the fourth division, in the article "My Life with Landau: Homage of a 4.5 to a 2".
Works.
Other.
A complete list of Landau's works appeared in 1998 in the Russian journal "Physics-Uspekhi".

</doc>
<doc id="80327" url="https://en.wikipedia.org/wiki?curid=80327" title="New Keynesian economics">
New Keynesian economics

New Keynesian economics is a school of contemporary macroeconomics that strives to provide microeconomic foundations for Keynesian economics. It developed partly as a response to criticisms of Keynesian macroeconomics by adherents of New Classical macroeconomics.
Two main assumptions define the New Keynesian approach to macroeconomics. Like the New Classical approach, New Keynesian macroeconomic analysis usually assumes that households and firms have rational expectations. But the two schools differ in that New Keynesian analysis usually assumes a variety of market failures. In particular, New Keynesians assume that there is imperfect competition in price and wage setting to help explain why prices and wages can become "sticky", which means they do not adjust instantaneously to changes in economic conditions.
Wage and price stickiness, and the other market failures present in New Keynesian models, imply that the economy may fail to attain full employment. Therefore, New Keynesians argue that macroeconomic stabilization by the government (using fiscal policy) or by the central bank (using monetary policy) can lead to a more efficient macroeconomic outcome than a laissez faire policy would.
Development.
1970s.
The first wave of New Keynesian economics developed in the late 1970s. The first model of "Sticky information" was developed by Stanley Fischer in his 1977 article, "Long-Term Contracts, Rational Expectations, and the Optimal Money Supply Rule". He adopted a "staggered" or "overlapping" contract model. Suppose that there are two unions in the economy, who take turns to choose wages. When it is a union's turn, it chooses the wages it will set for the next two periods. This contrasts with John B. Taylor's model where the nominal wage is constant over the contract life, as was subsequently developed in his two articles, one in 1979 "Staggered wage setting in a macro model'. and one in 1980 "Aggregate Dynamics and Staggered Contracts". Both Taylor and Fischer contracts share the feature that only the unions setting the wage in the current period are using the latest information: wages in half of the economy still reflect old information. The Taylor model had sticky nominal wages in addition to the sticky information: nominal wages had to be constant over the length of the contract (two periods). These early new Keynesian theories were based on the basic idea that, given fixed nominal wages, a monetary authority (central bank) can control the employment rate. Since wages are fixed at a nominal rate, the monetary authority can control the real wage (wage values adjusted for inflation) by changing the money supply and thus impact the employment rate.
1980s.
Menu costs and Imperfect Competition.
In the 1980s the key concept of using menu costs in a framework of imperfect competition to explain price stickiness was developed. The concept of a lump-sum cost (menu cost) to changing the price was originally introduced by Sheshinski and Weiss (1977) in their paper looking at the effect of inflation on the frequency of price-changes. The idea of applying it as a general theory of Nominal Price Rigidity was simultaneously put forward by several economists in 1985–6. George Akerlof and Janet Yellen put forward the idea that due to bounded rationality firms will not want to change their price unless the benefit is more than a small amount. This bounded rationality leads to inertia in nominal prices and wages which can lead to output fluctuating at constant nominal prices and wages. Gregory Mankiw took the menu-cost idea and focused on the welfare effects of changes in output resulting from sticky prices. Michael Parkin also put forward the idea. Although the approach initially focused mainly on the rigidity of nominal prices, it was extended to wages and prices by Olivier Blanchard and Nobuhiro Kiyotaki in their influential article "Monopolistic Competition and the Effects of Aggregate Demand" . Huw Dixon and Claus Hansen showed that even if menu costs applied to a small sector of the economy, this would influence the rest of the economy and lead to prices in the rest of the economy becoming less responsive to changes in demand.
While some studies suggested that menu costs are too small to have much of an aggregate impact, Laurence Ball and David Romer showed in 1990 that real rigidities could interact with nominal rigidities to create significant disequilibrium. Real rigidities occur whenever a firm is slow to adjust its real prices in response to a changing economic environment. For example, a firm can face real rigidities if it has market power or if its costs for inputs and wages are locked-in by a contract. Ball and Romer argued that real rigidities in the labor market keep a firm's costs high, which makes firms hesitant to cut prices and lose revenue. The expense created by real rigidities combined with the menu cost of changing prices makes it less likely that firm will cut prices to a market clearing level.
Even if prices are perfectly flexible, imperfect competition can affect the influence of fiscal policy in terms of the multiplier. Huw Dixon and Gregory Mankiw developed independently simple general equilibrium models showing that the fiscal multiplier could be increasing with the degree of imperfect competition in the output market. The reason for this is that imperfect competition in the output market tends to reduce the real wage, leading to the household substituting away from consumption towards leisure. When government spending is increased, the corresponding increase in lump-sum taxation causes both leisure and consumption to decrease (assuming that they are both a normal good). The greater the degree of imperfect competition in the output market, the lower the real wage and hence the more the reduction falls on leisure (i.e. households work more) and less on consumption. Hence the fiscal multiplier is less than one, but increasing in the degree of imperfect competition in the output market.
The Calvo staggered contracts model.
In 1983 Guillermo Calvo wrote "Staggered Prices in a Utility-Maximizing Framework". The original article was written in a continuous time mathematical framework, but nowadays is mostly used in its discrete time version. The Calvo model has become the most common way to model nominal rigidity in new Keynesian models. There is a probability that the firm can reset its price in any one period h (the hazard rate), or equivalently the probability (1-h) that the price will remain unchanged in that period (the survival rate). The probability h is sometimes called the "Calvo probability" in this context. In the Calvo model the crucial feature is that the price-setter does not know how long the nominal price will remain in place, in contrast to the Taylor model where the length of contract is known ex ante.
Coordination failure.
Coordination failure was another important new Keynesian concept developed as another potential explanation for recessions and unemployment. In recessions a factory can go idle even though there are people willing to work in it, and people willing to buy its production if they had jobs. In such a scenario, economic downturns appear to be the result of coordination failure: The invisible hand fails to coordinate the usual, optimal, flow of production and consumption. Russell Cooper and Andrew John's 1988 paper "Coordinating Coordination Failures in Keynesian Models" expressed a general form of coordination as models with multiple equilibria where agents could coordinate to improve (or at least not harm) each of their respective situations. Cooper and John based their work on earlier models including Peter Diamond's 1982 coconut model, which demonstrated a case of coordination failure involving search and matching theory. In Diamond's model producers are more likely to produce if they see others producing. The increase in possible trading partners increases the likelihood of a given producer finding someone to trade with. As in other cases of coordination failure, Diamond's model has multiple equilibria, and the welfare of one agent is dependent on the decisions of others. Diamond's model is an example of a "thick-market externality" that causes markets to function better when more people and firms participate in them. Other potential sources of coordination failure include self-fulfilling prophecies. If a firm anticipates a fall in demand, they might cut back on hiring. A lack of job vacancies might worry workers who then cut back on their consumption. This fall in demand meets the firm's expectations, but it is entirely due to the firm's own actions.
Labor market failures: Efficiency wages.
New Keynesians offered explanations for the failure of the labor market to clear. In a Walrasian market, unemployed workers bid down wages until the demand for workers meets the supply. If markets are Walrasian, the ranks of the unemployed would be limited to workers transitioning between jobs and workers who choose not to work because wages are too low to attract them. They developed several theories explaining why markets might leave willing workers unemployed. The most important of these theories, new Keynesians was the efficiency wage theory used to explain long-term effects of previous unemployment, where short-term increases in unemployment become permanent and lead to higher levels of unemployment in the long-run.
In efficiency wage models, workers are paid at levels that maximize productivity instead of clearing the market. For example, in developing countries, firms might pay more than a market rate to ensure their workers can afford enough nutrition to be productive. Firms might also pay higher wages to increase loyalty and morale, possibly leading to better productivity. Firms can also pay higher than market wages to forestall shirking. Shirking models were particularly influential.Carl Shapiro and Joseph Stiglitz's 1984 paper "Equilibrium Unemployment as a Worker Discipline Device" created a model where employees tend to avoid work unless firms can monitor worker effort and threaten slacking employees with unemployment. If the economy is at full employment, a fired shirker simply moves to a new job. Individual firms pay their workers a premium over the market rate to ensure their workers would rather work and keep their current job instead of shirking and risk having to move to a new job. Since each firm pays more than market clearing wages, the aggregated labor market fails to clear. This creates a pool of unemployed laborers and adds to the expense of getting fired. Workers not only risk a lower wage, they risk being stuck in the pool of unemployed. Keeping wages above market clearing levels creates a serious disincentive to shirk that makes workers more efficient even though it leaves some willing workers unemployed.
1990s.
The new neoclassical synthesis.
In the early 1990s, economists began to combine the elements of new Keynesian economics developed in the 1980s and earlier with Real Business Cycle Theory. RBC models were dynamic but assumed perfect competition; new Keynesian models were primarily static but based on imperfect competition. The New neoclassical synthesis essentially combined the dynamic aspects of RBC with imperfect competition and nominal rigidities of new Keynesian models. Tack Yun was one of the first to do this, in a model which used the Calvo pricing model. Goodfriend and King proposed a list of four elements that are central to the new synthesis: intertemporal optimization, rational expectations, imperfect competition, and costly price adjustment (menu costs). Goodfriend and King also find that the consensus models produce certain policy implications: whilst monetary policy can affect real output in the short-run, but there is no long-run trade-off: money is not neutral in the short-run but it is in the long-run. Inflation has negative welfare effects. It is important for central banks to maintain credibility through rules based policy like inflation targeting.
Taylor Rule.
In 1993, John B Taylor formulated the idea of a Taylor rule, which is a monetary-policy rule that stipulates how much the central bank should change the nominal interest rate in response to changes in inflation, output, or other economic conditions. In particular, the rule stipulates that for each one-percent increase in inflation, the central bank should raise the nominal interest rate by more than one percentage point. This aspect of the rule is often called the Taylor principle.
According to Taylor's original version of the rule, the nominal interest rate should respond to
divergences of actual inflation rates from "target" inflation rates and of actual Gross Domestic Product (GDP) from "potential" GDP:
In this equation, formula_2 is the target short-term nominal interest rate (e.g. the federal funds rate in the US, the Bank of England base rate in the UK), formula_3 is the rate of inflation as measured by the GDP deflator, formula_4 is the desired rate of inflation, formula_5 is the assumed equilibrium real interest rate, formula_6 is the logarithm of real GDP, and formula_7 is the logarithm of potential output, as determined by a linear trend.
The New Keynesian Phillips curve.
The New Keynesian Phillips curve was originally derived by Roberts in 1995, and has since been used in most state-of-the-art New Keynesian DSGE models The new Keynesian Phillips curve says that this periods inflation depends on current output and the expectations of next periods inflation. The curve is derived from the dynamic Calvo model of pricing and in mathematical terms is:
The current period t expectations of next period's inflation are incorporated as formula_9, where formula_10 is the discount factor. The constant formula_11 captures the response of inflation to output, and is largely determined by the probability of changing price in any period, which is formula_12:
The less rigid nominal prices are (the higher is formula_12), the greater the effect of output on current inflation.
The Science of Monetary Policy.
The ideas of developed in the 1990s were put together to develop the new Keynesian Dynamic stochastic general equilibrium used to analyze monetary policy. This culminated in the three equation new Keynesian model found in the survey by Richard Clarida, Jordi Gali, and Mark Gertler in the Journal of Economic Literature. It combines the two equations of the new Keynesian Phillips curve and the Taylor rule with the "dynamic IS curve" derived from the optimal dynamic consumption equation (household's Euler equation).
These three equations formed a relatively simple model which could be used for the theoretical analysis of policy issues. However, the model was oversimplified in some respects (for example, there is no capital or investment). Also, it does not perform well empirically.
2000s.
In the new millennium there have been several advances in new Keynesian economics.
The introduction of imperfectly competitive labor markets.
Whilst the models of the 1990s focused on sticky prices in the output market, in 2000 Christopher Erceg, Dale Henderson and Andrew Levin adopted the Blanchard and Kiyotaki model of unionized labor markets by combining it with the Calvo pricing approach and introduced it into a new Keynesian DSGE model.
The development of complicated DSGE models..
In order to have models that worked well with the data and could be used for policy simulations, quite complicated new Keynesian models were developed with several features. Seminal papers were published by Frank Smets and Rafael Wouters and also Lawrence J. Christiano, Martin Eichenbaum and Charles Evans The common features of these models included:
Sticky information.
The idea of Sticky information found in Fischer's model was later developed by Gregory Mankiw and Ricardo Reis. This added a new feature to Fischer's model: there is a fixed probability that you can replan your wages or prices each period. Using quarterly data, they assumed a value of 25%: that is, each quarter 25% of randomly chosen firms/unions can plan a trajectory of current and future prices based on current information. Thus if we consider the current period: 25% of prices will be based on the latest information available; the rest on information that was available when they last were able to replan their price trajectory. Mankiw and Reis found that the model of sticky information provided a good way of explaining inflation persistence.
Sticky information models do not have nominal rigidity: firms or unions are free to choose different prices or wages for each period. It is the information that is sticky, not the prices. Thus when a firm gets lucky and can re-plan its current and future prices, it will choose a trajectory of what it believes will be the optimal prices now and in the future. In general, this will involve setting a different price every period covered by the plan. This is at odds with the empirical evidence on prices. There are now many studies of price rigidity in different countries: the US, the Eurozone, the UK and others. These studies all show that whilst there are some sectors where prices change frequently, there are also other sectors where prices remain fixed over time. The lack of sticky prices in the sticky information model is inconsistent with the behavior of prices in most of the economy. This has led to attempts to formulate a "dual Stickiness" model that combines sticky information with sticky prices.
Policy implications.
New Keynesian economists agree with New Classical economists that in the long run, the classical dichotomy holds: changes in the money supply are neutral. However, because prices are sticky in the New Keynesian model, an increase in the money supply (or equivalently, a decrease in the interest rate) does increase output and lower unemployment in the short run. Furthermore, some New Keynesian models confirm the non-neutrality of money under several conditions.
Nonetheless, New Keynesian economists do not advocate using expansive monetary policy for short run gains in output and employment, as it would raise inflationary expectations and thus store up problems for the future. Instead, they advocate using monetary policy for stabilization. That is, suddenly increasing the money supply just to produce a temporary economic boom is not recommended as eliminating the increased inflationary expectations will be impossible without producing a recession.
However, when the economy is hit by some unexpected external shock, it may be a good idea to offset the macroeconomic effects of the shock with monetary policy. This is especially true if the unexpected shock is one (like a fall in consumer confidence) which tends to lower both output and inflation; in that case, expanding the money supply (lowering interest rates) helps by increasing output while stabilizing inflation and inflationary expectations.
Studies of optimal monetary policy in New Keynesian DSGE models have focused on interest rate rules (especially 'Taylor rules'), specifying how the central bank should adjust the nominal interest rate in response to changes in inflation and output. (More precisely, optimal rules usually react to changes in the output gap, rather than changes in output "per se".) In some simple New Keynesian DSGE models, it turns out that stabilizing inflation suffices, because maintaining perfectly stable inflation also stabilizes output and employment to the maximum degree desirable. Blanchard and Galí have called this property the ‘divine coincidence’.
However, they also show that in models with more than one market imperfection (for example, frictions in adjusting the employment level, as well as sticky prices), there is no longer a 'divine coincidence', and instead there is a tradeoff between stabilizing inflation and stabilizing employment. Further, while some macroeconomists believe that New Keynesian models are on the verge of being useful for quarter-to-quarter quantitative policy advice, disagreement exists.
Recently, it was shown that the divine coincidence does not necessarily hold in the non-linear form of the standard New-Keynesian model. This property would only hold if the monetary authority is set to keep the inflation rate at exactly 0%. At any other desired target for the inflation rate, there is an endogenous trade-off, even under the absence real imperfections such as sticky wages, and the divine coincidence no longer holds.
Relation to other macroeconomic schools.
Over the years, a sequence of 'new' macroeconomic theories related to or opposed to Keynesianism have been influential. After World War II, Paul Samuelson used the term "neoclassical synthesis" to refer to the integration of Keynesian economics with neoclassical economics. The idea was that the government and the central bank would maintain rough full employment, so that neoclassical notions—centered on the axiom of the universality of scarcity—would apply. John Hicks' IS/LM model was central to the neoclassical synthesis.
Later work by economists such as James Tobin and Franco Modigliani involving more emphasis on the microfoundations of consumption and investment was sometimes called neo-Keynesianism. It is often contrasted with the post-Keynesianism of Paul Davidson, which emphasizes the role of fundamental uncertainty in economic life, especially concerning issues of private fixed investment.
New Keynesianism is a response to Robert Lucas and the new classical school. That school criticized the inconsistencies of Keynesianism in the light of the concept of "rational expectations". The new classicals combined a unique market-clearing equilibrium (at full employment) with rational expectations. The New Keynesians use "microfoundations" to demonstrate that price stickiness hinders markets from clearing. Thus, the rational expectations-based equilibrium need not be unique.
Whereas the neoclassical synthesis hoped that fiscal and monetary policy would maintain full employment, the new classicals assumed that price and wage adjustment would automatically attain this situation in the short run. The new Keynesians, on the other hand, see full employment as being automatically achieved only in the long run, since prices are "sticky" in the short run. Government and central-bank policies are needed because the "long run" may be very long.
Keynes' stress on the importance of centralized coordination of macroeconomic policies (e.g., monetary and fiscal stimulus) and of international economic institutions such as the World Bank and International Monetary Fund (IMF), and of the maintenance of a controlled trading system was emphasized during the 2008 global financial and economic crisis. This has been reflected in the work of IMF economists and of Donald Markwell.

</doc>
<doc id="80329" url="https://en.wikipedia.org/wiki?curid=80329" title="Sacrifice">
Sacrifice

Sacrifice is the offering of food, objects or the lives of animals to a higher purpose, in particular divine beings, as an act of propitiation or worship. While "sacrifice" often implies ritual killing, the term offering (Latin "oblatio") can be used for bloodless sacrifices of food or artifacts. For offerings of liquids (beverages) by pouring, the term libation is used.
Terminology.
The Latin term "sacrificium" (a sacrifice) derived from Latin "sacrificus" (performing priestly functions or sacrifices), which combined the concepts "sacra" (sacred things) and "facere" (to do or perform).
The Latin word "sacrificium" came to apply to the Christian eucharist in particular, sometimes named a "bloodless sacrifice" to distinguish it from blood sacrifices. In individual non-Christian ethnic religions, terms translated as "sacrifice" include the Indic "yajna", the Greek "thusia", the Germanic "blōtan", the Semitic "qorban"/"qurban", Slavic żertwa, etc.
The term usually implies "doing without something" or "giving something up" (see also self-sacrifice). But "sacrifice" is also used metaphorically to describe doing good for others or a short-term loss in return for a greater power gain, such as in a game of chess.
Animal sacrifice.
Animal sacrifice is the ritual killing of an animal as part of a religion. It is practiced by adherents of many religions as a means of appeasing a god or gods or changing the course of nature. It also served a social or economic function in those cultures where the edible portions of the animal were distributed among those attending the sacrifice for consumption. Animal sacrifice has turned up in almost all cultures, from the Hebrews to the Greeks and Romans (particularly the purifying ceremony Lustratio), Ancient Egyptians (for example in the cult of Apis) and from the Aztecs to the Yoruba.
It is against their religion for Egyptians to sacrifice animals, except for sheep, bulls, calves, male calves and geese. 
Animal sacrifice is still practiced today by the followers of Santería and other lineages of Orisa as a means of curing the sick and giving thanks to the Orisa (gods). However, in Santeria, such animal offerings constitute an extremely small portion of what are termed "ebos"—ritual activities that include offerings, prayer and deeds. Christians from some villages in Greece also sacrifice animals to Orthodox saints in a practice known as kourbània. The practice, while publicly condemned, is often tolerated.
Walter Burkert theory on origins of Greek sacrifice.
According to Walter Burkert, a scholar of sacrifice, Greek sacrifices derived from hunting practices. Hunters, feeling guilty for having killed another living being so they could eat and survive, tried to repudiate their responsibility in these rituals. The primary evidence used to suggest this theory is the Dipolieia, which is an Athenian festival, in limited circulation, during which an ox was sacrificed. The protagonist of the ritual was a plough ox, which it had, at one point, been a crime to kill in Athens. According to his theory, the killer of the ox eased his conscience by suggesting that everybody should participate in the killing of the sacrificial victim.
In the expansion of the Athenian state, numerous oxen were needed to feed the people at the banquets and were accompanied by state festivals. The hecatomb (“hundred oxen”) became the general designation for the great sacrifices offered by the state. These sacrificial processions of hundreds of oxen remove the original ties, which the farmers of an earlier and smaller Athens will have felt with their one ox.
Human sacrifice.
Human sacrifice was practiced by many ancient cultures. People would be ritually killed in a manner that was supposed to please or appease a god or spirit.
Some occasions for human sacrifice found in multiple cultures on multiple continents include:
Human sacrifices were practiced by various Pre-Columbian civilizations of Mesoamerica. The Aztec practiced human sacrifice on an unusually large scale; a sacrifice would be made every day to aid the sun in rising, the dedication of the great temple at Tenochtitlán was reportedly marked with the sacrificing of thousands, and there are multiple accounts of captured Conquistadores being sacrificed during the wars of the Spanish conquest of Mexico.
In Scandinavia, the old Scandinavian religion contained human sacrifice, and both the Norse sagas and German historians relate of this, see e.g. Temple at Uppsala and Blót.
There is evidence to suggest Pre-Hellenic Minoan cultures practiced human sacrifice. Sacrificed corpses were found at a number of sites in the citadel of Knossos in Crete. The north house at Knossos contained the bones of children who appeared to have been butchered. It is possible they may have been for human consumption as was the tradition with sacrificial offerings made in Pre-Hellenic Civilization. [http://projectsx.dartmouth.edu/history/bronze_age/lessons/les/15.html] The myth of Theseus and the Minotaur (set in the labyrinth at Knossos) provides evidence that human sacrifice was commonplace. In the myth, we are told that Athens sent seven young men and seven young women to Crete as human sacrifices to the Minotaur. This ties up well with the archaeological evidence that most sacrifices were of young adults or children.
The Phoenicians of Carthage were reputed to practise child sacrifice, and though the scale of sacrifices may have been exaggerated by ancient authors for political or religious reasons, there is archaeological evidence of large numbers of children's skeletons buried in association with sacrificial animals. Plutarch (ca. 46–120 AD) mentions the practice, as do Tertullian, Orosius, Diodorus Siculus and Philo. They describe children being roasted to death while still conscious on a heated bronze idol.
Human sacrifice still happens today as an underground practice in some traditional religions, for example in muti killings. Human sacrifice is no longer officially condoned in any country, and these cases are regarded as murder.
In the "Aeneid" by Virgil, the character Sinon claims (falsely) that he was going to be a human sacrifice to Poseidon to calm the seas.
Judaism.
Ritual sacrifice was practiced in Ancient Israel, with the opening chapters of the book Leviticus detailing parts of an overview referring to the exact methods of bringing sacrifices. In short, sacrifices were either whole or partial sacrifices, uninjured blood (animals) or bloodless offerings (grain and wine). Blood sacrifices were divided into burnt offerings (Hebrew: עלה קרבנות) in which the whole unmaimed animal was burnt, guilt offerings (in which part was burnt and part left for the priest) and peace offerings (in which similarly only part of the undamaged animal was burnt and the rest eaten in ritually pure conditions). The prophets point out that prayer and sacrifices are only a part of serving God and need to be accompanied by inner morality and goodness. Besides very rare examples of ritual sacrifice practiced to accompany the inner atonement for unintentional sins, there is no Jewish equivalent of the 
After the destruction of the Second Temple, ritual sacrifice ceased except among the Samaritans. Maimonides, a medieval Jewish rationalist, argued that God always held sacrifice inferior to prayer and philosophical meditation. However, God understood that the Israelites were used to the animal sacrifices that the surrounding pagan tribes used as the primary way to commune with their gods. As such, in Maimonides' view, it was only natural that Israelites would believe that sacrifice was a necessary part of the relationship between God and man. Maimonides concludes that God's decision to allow sacrifices was a concession to human psychological limitations. It would have been too much to have expected the Israelites to leap from pagan worship to prayer and meditation in one step. In the "Guide for the Perplexed", he writes:
In contrast, many others such as Nachmanides (in his Torah commentary on Leviticus 1:9) disagreed, contending that sacrifices are an ideal in Judaism, completely central.
The teachings of the Torah and Tanakh reveal the Israelites's familiarity with human sacrifices, as exemplified by the near-sacrifice of Isaac by his father Abraham (Genesis 22:1-24) and some believe, the actual sacrifice of Jephthah's daughter (Judges 11:31-40), while many believe that Jephthah's daughter was committed for life in service equivalent to a nunnery of the day, as indicated by her lament over her "weep for my virginity" and never having known a man (v37). The king of Moab gives his firstborn son and heir as a whole burnt offering ("olah", as used of the Temple sacrifice). It is apparently effective, as his enemy is promptly repelled by a 'great wrath' (). In the book of Micah, one asks, 'Shall I give my firstborn for my sin, the fruit of my body for the sin of my soul?' (), and receives a response, 'It hath been told thee, O man, what is good, and what the LORD doth require of thee: only to do justly, and to love mercy, and to walk humbly with thy God.' () Abhorrence of the practice of child sacrifice is emphasized by Jeremiah. See Jeremiah 7:30-32.
Christianity.
In Trinitarian Christianity, God became incarnate as Jesus, sacrificing his son to accomplish the reconciliation of God and humanity, which had separated itself from God through sin (see the concept of original sin). According to a view that has featured prominently in Western theology since early in the 2nd millennium, God's justice required an atonement for sin from humanity if human beings were to be restored to their place in creation and saved from damnation. However, God knew limited human beings could not make sufficient atonement, for humanity's offense to God was infinite, so God created a covenant with Abraham, which he fulfilled when he sent his only Son to become the sacrifice for the broken covenant. In Christian theology, this sacrifice replaced the insufficient animal sacrifice of the Old Covenant; Christ the "Lamb of God" replaced the lambs' sacrifice of the ancient "Korban Todah" (the Rite of Thanksgiving), chief of which is the Passover in the Mosaic law.
In the Roman Catholic Church, and the Eastern Orthodox Churches Eucharist or Mass, and the Divine Liturgy of the Eastern Catholic Churches and Eastern Orthodox Church, it is seen as a sacrifice. Among the Anglicans the words of the liturgy make explicit that the Eucharist is a sacrifice of praise and thanksgiving and is a material offering to God in union with Christ using such words, as "with these thy holy gifts which we now offer unto Thee," (1789 BCP) or "presenting to you from the gifts you have given us we offer you these gifts" (Prayer D BCP 1976) a clearly evidenced in the revised Books of Common Prayer in which the theology of Eucharist has been moved closer to the Catholic and Orthodox positions, a movement which began with the adoption of sacrificial language in the 1789 American Book of Common Prayer. It is however, not a separate or additional sacrifice to that Christ on the cross; it is rather exactly the same sacrifice, which transcends time and space ("the Lamb slain from the foundation of the world") (Rev. 13:8), renewed and made present, the only distinction being that it is offered in an unbloody manner. The sacrifice is made present without Christ dying or being crucified again; it is a re-presentation to God, of the "once and for all" sacrifice of Calvary by the now risen Christ, who continues to offer himself and what he has done on the cross as an oblation to the Father. The complete identification of the Mass with the sacrifice of the cross is found in Christ's words at the last supper over the bread and wine: "This is my body, which is given up for you," and "This is my blood of the new covenant, which is shed...unto the forgiveness of sins." The bread and wine, offered by Melchizedek in sacrifice in the old covenant (Genesis 14:18; Psalm 110:4), are transformed through the Mass into the body and blood of Christ (see transubstantiation; note: the Orthodox Church does not hold as dogma, as do Catholics, the doctrine of transubstantiation, preferring rather to not make an assertion regarding the "how" of the sacraments), and the offering becomes one with that of Christ on the cross. In the Mass as on the cross, Christ is both priest (offering the sacrifice) and victim (the sacrifice he offers is himself), though in the Mass in the former capacity he works through a solely human priest who is joined to him through the sacrament of Holy Orders and thus shares in Christ's priesthood as do all who are baptized into the death and resurrection of Jesus, the Christ. Through the Mass, the merits of the one sacrifice of the cross can be applied to the redemption of those present, to their specific intentions and prayers, and to the release of the souls from purgatory.
The concept of self-sacrifice and martyrs are central to Christianity. Often found in Roman Catholicism is the idea of joining one's own sufferings to the sacrifice of Christ on the cross. Thus one can offer up involuntary suffering, such as illness, or purposefully embrace suffering in acts of penance. Some Protestants criticize this as a denial of the all-sufficiency of Christ's sacrifice, but it finds support in St. Paul: "Now I rejoice in my sufferings for your sake, and in my flesh I complete what is lacking in Christ's afflictions for the sake of his body, that is, the church" (Col 1:24). Pope John Paul II explained in his Apostolic Letter "Salvifici Doloris" (11 February 1984):"In the Cross of Christ not only is the Redemption accomplished through suffering, but also human suffering itself has been redeemed...Every man has his own share in the Redemption. Each one is also called to share in that suffering through which the Redemption was accomplished...In bringing about the Redemption through suffering, Christ has also raised human suffering to the level of the Redemption. Thus each man, in his suffering, can also become a sharer in the redemptive suffering of Christ...The sufferings of Christ created the good of the world's redemption. This good in itself is inexhaustible and infinite. No man can add anything to it. But at the same time, in the mystery of the Church as his Body, Christ has in a sense opened his own redemptive suffering to all human suffering" ("Salvifici Doloris" 19; 24).Some Protestants reject the idea of the Eucharist as a sacrifice, inclining to see it as merely a holy meal (even if they believe in a form of the real presence of Christ in the bread and wine, as Lutherans do). The more recent the origin of a particular tradition, the less emphasis is placed on the sacrificial nature of the Eucharist. The Catholic/Orthodox response is that the sacrifice of the Mass in the New Covenant is that one sacrifice for sins on the cross which transcends time offered in an unbloody manner, as discussed above, and that Christ is the real priest at every Mass working through mere human beings to whom he has granted the grace of a share in his priesthood. As "priest" carries connotations of "one who offers sacrifice", Protestants usually do not use it for their clergy. Evangelical Protestantism emphasizes the importance of a decision to accept Christ's sacrifice on the Cross consciously and personally as atonement for one's individual sins if one is to be saved—this is known as "accepting Christ as one's personal Lord and Savior".
The Orthodox Church sees the celebration of the Eucharist as a continuation, rather than a reenactment, of the Last Supper, as Fr. John Matusiak (of the OCA) says: "The Liturgy is not so much a reenactment of the Mystical Supper or these events as it is a continuation of these events, which are beyond time and space. Unlike many of the Protestant bodies, the Orthodox also see the Eucharistic Liturgy as a bloodless sacrifice, during which the bread and wine we offer to God become the Body and Blood of Jesus Christ through the descent and operation of the Holy Spirit, Who effects the change." This view is witnessed to by the prayers of the Divine Liturgy of St. John Chrysostom, when the priest says: "Accept, O God, our supplications, make us to be worthy to offer unto thee supplications and prayers and bloodless sacrifices for all thy people," and "Remembering this saving commandment and all those things which came to pass for us: the cross, the grave, the resurrection on the third day, the ascension into heaven, the sitting down at the right hand, the second and glorious coming again, Thine own of Thine own we offer unto Thee on behalf of all and for all," and "… Thou didst become man and didst take the name of our High Priest, and deliver unto us the priestly rite of this liturgical and bloodless sacrifice…"
Islam.
An animal sacrifice in Arabic is called "ḏabiḥa" (ذَبِيْحَة) or "Qurban" (قُرْبَان) . The term may have roots from the Jewish term "Korban"; in some places such as in Pakistan, "qurbani" is always used for Islamic animal sacrifice. In the Islamic context, an animal sacrifice referred to as "ḏabiḥa" (ذَبِيْحَة) meaning "sacrifice as a ritual" is offered only in Eid ul-Adha. The sacrificial animal may be a sheep, a goat, a camel, or a cow. The animal must be healthy and conscious.
..."Therefore to the Lord turn in Prayer and Sacrifice. " (Surat Al-Kawthar) Quran, 108.2
Qurban is an Islamic prescription for the affluent to share their good fortune with the needy in the community.
On the occasion of Eid ul Adha (Festival of Sacrifice), affluent Muslims all over the world perform the Sunnah of Prophet Ibrahim (Abraham) by sacrificing a cow or sheep. The meat is then divided into three equal parts. One part is retained by the person who performs the sacrifice. The second is given to his relatives. The third part is distributed to the poor.
The Qur'an states that the sacrifice has nothing to do with the blood and gore (Qur'an 22:37: "It is not their meat nor their blood that reaches God. It is your piety that reaches Him..."). Rather, it is done to help the poor and in remembrance of Abraham's willingness to sacrifice his son Ishmael at God's command.
The Urdu and Persian word "Qurbani" comes from the Arabic word 'Qurban'. It suggests that associate act performed to hunt distance to Almighty God and to hunt His sensible pleasure. Originally, the word 'Qurban' enclosed all acts of charity as a result of the aim of charity is nothing however to hunt Allah's pleasure. But, in precise non secular nomenclature, the word was later confined to the sacrifice of associate animal slaughtered for the sake of God.
A similar symbology, which is a reflection of Abraham and Ismael's dilemma, is the stoning of the Jamaraat which takes place during the pilgrimage.
Hinduism.
The Sanskrit "yajna" (, modern Hindi pronunciation: "yagya") is often translated as "sacrifice" (also "offering, oblation", or more generically as "worship"). It is especially used to describe the offering of ghee (clarified butter), grains, spices, and wood into a fire along with the chanting of sacred mantras. The fire represents Agni, the divine messenger who carries offerings to the Devas. The offerings can represent devotion, aspiration, and seeds of past karma. In Vedic times, yajna commonly included the sacrifice of milk, ghee, curd, grains, and the "soma" plant—animal offerings were less common. In modern times, yajna is often performed at weddings and funerals, and in personal worship. Sacrifice in Hinduism can also refer to personal surrender through acts of inner and outer worship.

</doc>
<doc id="80330" url="https://en.wikipedia.org/wiki?curid=80330" title="United Kingdom general election, 1983">
United Kingdom general election, 1983

The 1983 United Kingdom general election was held on 9 June 1983. It gave the Conservative Party under Margaret Thatcher the most decisive election victory since that of Labour in 1945.
Thatcher's first four years as prime minister had not been an easy time. Unemployment increased during the first three years of her term and the economy went through a recession. However, the British victory in the Falklands War led to a recovery of her popularity; the economy had also returned to growth. By the time Thatcher called the election in May 1983, the Conservatives were most people's firm favourites to win the election. The Labour Party had been led by Michael Foot since the resignation of James Callaghan. They had fared well in opinion polls and local elections during this time, but issues developed which would lead directly to their defeat. Labour adopted a platform that was considered more left-wing than usual. Several moderate Labour MPs had left the party to form the Social Democrats. The Social Democrats then formed the SDP-Liberal Alliance with the existing Liberal Party.
The opposition vote split almost evenly between the SDP/Liberal Alliance and Labour. With its worst performance since 1918, the Labour vote fell by over 3 million from 1979 and this accounted for both a national swing of almost 4% towards the Conservatives and their larger parliamentary majority of 144, even though the Conservatives' total vote fell by almost 700,000. This was the most recent election where a party in government increased its number of seats until 2015.
The SDP/Liberal Alliance finished in third place but came within 700,000 votes to out-polling Labour. By gaining 25% of the popular vote, the Alliance won the largest such percentage for any third party since the 1923 general election. Despite this, they won only 23 seats, whereas Labour won 209. The Liberals argued that a proportional electoral system would have given them a more representative number of MPs. Changing the electoral system had been a long-running Liberal Party campaign plank and would later be adopted by the Liberal Democrats.
The election night was broadcast live on the BBC, and was presented by Peter Snow, David Dimbleby and Robin Day.
Background and campaign.
Michael Foot was elected leader of the Labour party in 1980, replacing James Callaghan. The election of Foot signalled that the core of the party was swinging to the left and the move exacerbated divisions within the party. In 1981 a group of senior figures including Roy Jenkins, David Owen, Bill Rodgers and Shirley Williams left Labour to found the Social Democratic Party (SDP). The SDP agreed to a pact with the Liberals for the 1983 elections and stood as The Alliance.
The campaign displayed the huge divisions between the two major parties. Thatcher had been extremely unpopular during her first two years in office until the swift and decisive victory in the Falklands War, coupled with an improving economy, considerably raised her standings in the polls. The Conservatives' key issues included employment, economic growth and defence. Labour's campaign manifesto involved leaving the European Economic Community, abolishing the House of Lords, abandoning the United Kingdom's nuclear deterrent by cancelling Trident and removing cruise missiles, a programme dubbed by Labour MP Gerald Kaufman "the longest suicide note in history". "Although, at barely 37 pages, it only seemed interminable", noted Roy Hattersley. Pro-Labour political journalist Michael White, writing in "The Guardian", commented, "There was something magnificently brave about Michael Foot's campaign but it was like the Battle of the Somme".
National election, 1979.
Following boundary changes in 1983, the BBC and ITN (Independent Television News) co-produced a calculation of how the 1979 general election would have gone if fought on the new 1983 boundaries. The following table shows the effects of the boundary changes on the House of Commons:
Timeline.
The Prime Minister Margaret Thatcher visited Buckingham Palace on the afternoon of 9 May and asked the Queen to dissolve Parliament on 13 May, announcing that the election would be held on 9 June. The key dates were as follows:
Results.
The election saw a landslide victory for the Conservatives, achieving their best results since 1959. Although there was a slight drop in their share of the vote, they made significant gains at the expense of Labour. The night was a disaster for the Labour party; their share of the vote fell by over 9%, which meant they were only 700,000 votes ahead of the newly formed 3rd party the SDP-Liberal Alliance. The massive increase of support for the Alliance at the expense of Labour meant that, in many seats, the collapse in the Labour vote allowed the Conservatives to win. Despite winning over 25% of the national vote, the Alliance got fewer than 4% of seats, 186 fewer than Labour. The most significant Labour loss of the night was Tony Benn, who was defeated in the revived Bristol East seat. SDP President Shirley Williams, then a prominent leader in the Social Democratic Party, lost her Crosby seat which she had won in a by-election in 1981. Bill Rodgers, another leading figure in the Alliance (like Williams, one of the "Gang of Four") also failed to win his old seat that he previously held as a Labour MP. 
" All parties with more than 500 votes shown."
"N.B. The SDP-Liberal Alliance vote is compared with the Liberal Party vote in the 1979 election."
"The Independent Unionist elected in the 1979 election defended and held his seat for the Ulster Popular Unionist Party. The United Ulster Unionist Party dissolved and its sole MP did not re-stand."
"The Independent Republican elected in the 1979 election died in 1981. In the ensuring by-election the seat was won by Bobby Sands, an Anti-H-Block/Armagh Political Prisoner who then died and was succeeded by an Anti-H-Block Proxy Political Prisoner candidate Owen Carron. He defended and lost his seat standing for Sinn Féin who contested seats in Northern Ireland for the first time since 1959."
"This election was fought under revised boundaries. The changes reflect those comparing to the notional results on the new boundaries. One significant change was the increase in the number of seats allocated to Northern Ireland from 12 to 17."
Target tables.
Labour targets.
In order to regain an overall majority, Labour needed to make at least 65 gains.

</doc>
