<doc id="45958" url="https://en.wikipedia.org/wiki?curid=45958" title="Mutual assured destruction">
Mutual assured destruction

Mutual assured destruction, or MAD, is a doctrine of military strategy and national security policy in which a full-scale use of nuclear weapons by two or more opposing sides would cause the complete annihilation of both the attacker and the defender (see pre-emptive nuclear strike and second strike). It is based on the theory of deterrence, which holds that the threat of using strong weapons against the enemy prevents the enemy's use of those same weapons. The strategy is a form of Nash equilibrium in which, once armed, neither side has any incentive to initiate a conflict or to disarm.
Theory.
The MAD doctrine assumes that each side has enough nuclear weaponry to destroy the other side and that either side, if attacked for any reason by the other, would retaliate without fail with equal or greater force. The expected result is an immediate, irreversible escalation of hostilities resulting in both combatants' mutual, total, and assured destruction. The doctrine requires that neither side construct shelters on a massive scale, such as there are in Switzerland. If one side constructed a similar system of shelters, it would violate the MAD doctrine and destabilize the situation, because it would not have to fear the consequences of a second strike. The same principle is invoked against missile defense.
The doctrine further assumes that neither side will dare to launch a first strike because the other side would launch on warning (also called fail-deadly) or with surviving forces (a second strike), resulting in unacceptable losses for both parties. The payoff of the MAD doctrine was and still is expected to be a tense but stable global peace.
The primary application of this doctrine started during the Cold War (1940s to 1991), in which MAD was seen as helping to prevent any direct full-scale conflicts between the United States and the Soviet Union while they engaged in smaller proxy wars around the world. It was also responsible for the arms race, as both nations struggled to keep nuclear parity, or at least retain second-strike capability. Although the Cold War ended in the early 1990s, the MAD doctrine continues to be applied.
Proponents of MAD as part of U.S. and USSR strategic doctrine believed that nuclear war could best be prevented if neither side could expect to survive a full-scale nuclear exchange as a functioning state. Since the credibility of the threat is critical to such assurance, each side had to invest substantial capital in their nuclear arsenals even if they were not intended for use. In addition, neither side could be expected or allowed to adequately defend itself against the other's nuclear missiles. This led both to the hardening and diversification of nuclear delivery systems (such as nuclear missile silos, ballistic missile submarines, and nuclear bombers kept at fail-safe points) and to the Anti-Ballistic Missile Treaty.
This MAD scenario is often referred to as nuclear deterrence. The term "deterrence" was first used in this context after World War II; prior to that time, its use was limited to legal terminology.
History.
Pre-1945.
One of the earliest references to the concept comes from the English author Wilkie Collins, writing at the time of the Franco-Prussian War in 1870: "I begin to believe in only one civilizing influence—the discovery one of these days of a destructive agent so terrible that War shall mean annihilation and men's fears will force them to keep the peace".
Richard Jordan Gatling patented his namesake rotary gun in 1862 with the partial intention of illustrating the futility of war.
After his 1867 invention of dynamite, Alfred Nobel stated that "The day when two army corps can annihilate each other in one second, all civilized nations, it is to be hoped, will recoil from war and discharge their troops."
Jan Gotlib Bloch in "The Future of War", published in 1898, argued that the state could not fight a war "under modern conditions with any prospect of being able to carry that war to a conclusion by defeating its adversary by force of arms on the battlefield. No decisive war is possible that will not entail even upon the victorious Power, the destruction of its resources and the breakup of society. War has therefore become impossible, except at the price of suicide." 
In 1937, Nikola Tesla published "The Art of Projecting Concentrated Non-dispersive Energy through the Natural Media", a treatise concerning charged particle beam weapons. Tesla described his device as a "superweapon that would put an end to all war."
In March 1940, the Frisch-Peierls memorandum anticipated deterrence as the principal means of combating an enemy with nuclear weapons.
Early Cold War.
In August 1945, the United States accepted the surrender of Japan after the nuclear attacks on Hiroshima and Nagasaki. Four years later, on August 29, 1949, the Soviet Union detonated its own nuclear device. At the time, both sides lacked the means to effectively use nuclear devices against each other. However, with the development of aircraft like the American Convair B-36 and the Soviet Tupolev Tu-95, both sides were gaining a greater ability to deliver nuclear weapons into the interior of the opposing country. The official nuclear policy of the United States became one of "massive retaliation", as coined by President Dwight D. Eisenhower's Secretary of State John Foster Dulles, which called for massive attack against the Soviet Union if they were to invade Europe, regardless of whether it was a conventional or a nuclear attack.
By the time of the 1962 Cuban Missile Crisis, both the United States and the Soviet Union had developed the capability of launching a nuclear-tipped missile from a submerged submarine, which completed the "third leg" of the "nuclear triad" weapons strategy necessary to fully implement the MAD doctrine. Having a three-branched nuclear capability eliminated the possibility that an enemy could destroy all of a nation's nuclear forces in a first-strike attack; this, in turn, ensured the credible threat of a devastating retaliatory strike against the aggressor, increasing a nation's nuclear deterrence.
Two doomsday devices.
The strategy of Mutually Assured Destruction and the acronym MAD are due to John von Neumann (1903–1957) and his taste for humorous acronyms, another example being his MANIAC computer. He was, among other things, an inventor of game theory, a cold war strategist, and chairman of the Intercontinental ballistic missile Committee until his death in 1957. See also John von Neumann.
The RAND corporation futurist and cold war strategist Herman Kahn (1922–1982) believed that although MAD was useful as a metaphor, when pushed to its logical conclusion it became absurd. In his 1960 book "On Thermonuclear War" he advocated a more reasoned approach to nuclear warfare and was misunderstood by some of his critics to be a nuclear war hawk in his writings. (He did however hold a profound belief in the possibility of success in the event of a nuclear war.) He invented the concept of the Doomsday Machine as an "idealized (almost caricaturized) device" to illustrate the danger of taking MAD to its extreme. He writes, "I used to be wary of discussing the concept for fear that some colonel would get out a General Operating Requirement or Development Planning Objective for the device".
The 1964 film "Dr. Strangelove" parodies some of Kahn's work, and the titular character makes parodic references to Kahn's research, as in this quote from the film (after the United States mistakenly launched a nuclear attack on the USSR): "Under the authority granted me as director of weapons research and development, I commissioned last year a study of this project a doomsday machine by the Bland Corporation. Based on the findings of the report, my conclusion was that this idea was not a practical deterrent, for reasons which, at this moment, must be all too obvious."
Sometime in the 1980s, a second, but real, doomsday device, called The Dead Hand, entered the picture in the Soviet Union. Unlike Kahn's device, it was not based on radioactive cobalt, but it was self-activated and could not be stopped.
Strategic Air Command.
Beginning in 1955, the United States Strategic Air Command (SAC) kept one-third of its bombers on alert, with crews ready to take off within fifteen minutes and fly to designated targets inside the Soviet Union and destroy them with nuclear bombs in the event of a Soviet first-strike attack on the United States. In 1961, President John F. Kennedy increased funding for this program and raised the commitment to 50 percent of SAC aircraft.
During periods of increased tension in the early 1960s, SAC kept part of its B-52 fleet airborne at all times, to allow an extremely fast retaliatory strike against the Soviet Union in the event of a surprise attack on the United States. This program continued until 1990 when the bomber wings were placed on quick reaction ground alert and were able to take off within a few minutes. SAC also maintained the National Emergency Airborne Command Post (NEACP, pronounced "kneecap"), also known as "Looking Glass," which consisted of several EC-135s, one of which was airborne at all times from 1961 through 1990. During the Cuban missile crisis the bombers were dispersed to several different airfields, and also were sometimes airborne. For example, some were sent to Wright Patterson, which normally didn't have B-52s.
During the height of the tensions between the US and the USSR in the 1960s, two popular films were made dealing with what could go terribly wrong with the policy of keeping nuclear-bomb carrying airplanes at the ready: "Dr. Strangelove" (1964) and "Fail Safe" (1964).
Retaliation capability (second strike).
The strategy of MAD was fully declared in the early 1960s, primarily by United States Secretary of Defense Robert McNamara. In McNamara's formulation there was the very real danger that a nation with nuclear weapons could attempt to eliminate another nation's retaliatory forces with a surprise, devastating first strike and theoretically "win" a nuclear war relatively unharmed. True second-strike capability could only be achieved when a nation had a "guaranteed" ability to fully retaliate after a first-strike attack.
The United States had achieved an early form of second-strike capability by fielding continual patrols of strategic nuclear bombers, with a large number of planes always in the air, on their way to or from fail-safe points close to the borders of the Soviet Union. This meant the United States could still retaliate, even after a devastating first-strike attack. The tactic was expensive and problematic because of the high cost of keeping enough planes in the air at all times and the possibility they would be shot down by Soviet anti-aircraft missiles before reaching their targets. In addition, as the idea of a missile gap existing between the US and the Soviet Union developed, there was increasing priority being given to ICBMs over bombers.
It was only with the advent of ballistic missile submarines, starting with the "George Washington" class in 1959, that a genuine survivable nuclear force became possible and a retaliatory second strike capability guaranteed.
The deployment of fleets of ballistic missile submarines established a guaranteed second-strike capability because of their stealth and by the number fielded by each Cold War adversary—it was highly unlikely that all of them could be targeted and preemptively destroyed (in contrast to, for example, a missile silo with a fixed location that could be targeted during a first strike). Given their long range, high survivability and ability to carry many medium- and long-range nuclear missiles, submarines were credible and effective means for full-scale retaliation even after a massive first strike.
This deterrence strategy and program has continued into the 21st century, with nuclear submarines carrying Trident II ballistic missiles as one leg of the U.S. strategic nuclear deterrent and as the sole deterrent of the United Kingdom. The USA's other such deterrent comprises the intercontinental ballistic missiles (ICBM)s on alert in the continental United States. Ballistic missile submarines are also operated by the navies of China, France, India and Russia.
The U.S. Department of Defense anticipates a continued need for a sea-based strategic nuclear force. The first of the current Ohio-class SSBNs are expected to be retired by 2029, meaning that a platform must already be seaworthy by that time. A replacement may cost over $4 billion per unit compared to the USS "Ohio"s $2 billion. The U.S. Navy is exploring two options. The first is a variant of the nuclear attack submarines. The second is a dedicated SSBN, either with a new hull or based on an overhaul of the current "Ohio".
ABMs threaten MAD.
In the 1960s both the Soviet Union (A-35 anti-ballistic missile system) and the United States (LIM-49 Nike Zeus) developed anti-ballistic missile systems. Had such systems been able to effectively defend against a retaliatory second strike, MAD would have been undermined, because a superpower could launch a first strike without fearing the consequences of a retaliatory second strike. See also Strategic Defense Initiative.
MIRVs.
MIRVs as counter against ABM.
The multiple independently targetable re-entry vehicle (MIRV) was another weapons system designed specifically to aid with the MAD nuclear deterrence doctrine. With a MIRV payload, one ICBM could hold many separate warheads. MIRVs were first created by the United States in order to counterbalance Soviet anti-ballistic missile systems around Moscow. Since each defensive missile could only be counted on to destroy one offensive missile, making each offensive missile have, for example, three warheads (as with early MIRV systems) meant that three times as many defensive missiles were needed for each offensive missile. This made defending against missile attacks more costly and difficult. One of the largest U.S. MIRVed missiles, the LGM-118A Peacekeeper, could hold up to 10 warheads, each with a yield of around —all together, an explosive payload equivalent to 230 Hiroshima-type bombs. The multiple warheads made defense untenable with the technology available, leaving only the threat of retaliatory attack as a viable defensive option. MIRVed land-based ICBMs tend to put a premium on striking first. The START II agreement was proposed to ban this type of weapon, but never entered into force.
In the event of a Soviet conventional attack on Western Europe, NATO planned to use tactical nuclear weapons. The Soviet Union countered this threat by issuing a statement that any use of nuclear weapons (tactical or otherwise) against Soviet forces would be grounds for a full-scale Soviet retaliatory strike (massive retaliation). Thus it was generally assumed that any combat in Europe would end with apocalyptic conclusions.
Land-based MIRVed ICBMs threaten MAD.
MIRVed land-based ICBMs are generally considered suitable for a first strike (inherently counterforce) or a counterforce second strike, due to:
Unlike a decapitation strike or a countervalue strike, a counterforce strike might result in a potentially more constrained retaliation. Though the Minuteman III of the mid-1960s was MIRVed with three warheads, heavily MIRVed vehicles threatened to upset the balance; these included the SS-18 Satan which was deployed in 1976, and was considered to threaten Minuteman III silos, which led some neoconservatives to conclude a Soviet first strike was being prepared for. This led to the development of the aforementioned Pershing II, the Trident I and Trident II, as well as the MX missile, and the B-1 Lancer.
MIRVed land-based ICBMs are considered destabilizing because they tend to put a premium on striking first. When a missile is MIRVed, it is able to carry many warheads (up to eight in existing U.S. missiles, limited by New START, though Trident II is capable of carrying up to 12) and deliver them to separate targets. If it is assumed that each side has 100 missiles, with five warheads each, and further that each side has a 95 percent chance of neutralizing the opponent's missiles in their silos by firing two warheads at each silo, then the attacking side can reduce the enemy ICBM force from 100 missiles to about five by firing 40 missiles with 200 warheads, and keeping the rest of 60 missiles in reserve. As such, this type of weapon was intended to be banned under the START II agreement; however, the START II agreement was never brought into force, and neither Russia nor the United States ratified the agreement.
Late Cold War.
The original U.S. MAD doctrine was modified on July 25, 1980, with U.S. President Jimmy Carter's adoption of "countervailing strategy" with Presidential Directive 59. According to its architect, Secretary of Defense Harold Brown, "countervailing strategy" stressed that the planned response to a Soviet attack was no longer to bomb Soviet population centers and cities primarily, but first to kill the Soviet leadership, then attack military targets, in the hope of a Soviet surrender before total destruction of the Soviet Union (and the United States). This modified version of MAD was seen as a winnable nuclear war, while still maintaining the possibility of assured destruction for at least one party. This policy was further developed by the Reagan administration with the announcement of the Strategic Defense Initiative (SDI, nicknamed "Star Wars"), the goal of which was to develop space-based technology to destroy Soviet missiles before they reached the United States.
SDI was criticized by both the Soviets and many of America's allies (including Prime Minister of the United Kingdom Margaret Thatcher) because, were it ever operational and effective, it would have undermined the "assured destruction" required for MAD. If the United States had a guarantee against Soviet nuclear attacks, its critics argued, it would have first-strike capability, which would have been a politically and militarily destabilizing position. Critics further argued that it could trigger a new arms race, this time to develop countermeasures for SDI. Despite its promise of nuclear safety, SDI was described by many of its critics (including Soviet nuclear physicist and later peace activist Andrei Sakharov) as being even more dangerous than MAD because of these political implications. Supporters also argued that SDI could trigger a new arms race, forcing the USSR to spend an increasing proportion of GDP on defense—something which has been claimed to have been an indirect cause of the eventual collapse of the Soviet Union.
Proponents of ballistic missile defense (BMD) argue that MAD is exceptionally dangerous in that it essentially offers a single course of action in the event of nuclear attack: full retaliatory response. The fact that nuclear proliferation has led to an increase in the number of nations in the "nuclear club", including nations of questionable stability (e.g. Pakistan and North Korea), and that a nuclear nation might be hijacked by a despot or other person or persons who might use nuclear weapons without a sane regard for the consequences, presents a strong case for proponents of BMD who seek a policy which both protects against attack, but also does not require an escalation into what might become global nuclear war. Russia continues to have a strong public distaste for Western BMD initiatives, presumably because proprietary operative BMD systems could exceed their technical and financial resources and therefore degrade their larger military standing and sense of security in a post-MAD environment. Russian refusal to accept invitations to participate in NATO BMD may be indicative of the lack of an alternative to MAD in current Russian war fighting strategy due to dilapidation of conventional forces after the breakup of the Soviet Union.
Post-Cold War.
After the fall of the Soviet Union, the Russian Federation emerged as a sovereign entity encompassing most of the territory of the former USSR. Relations between the United States and this new power have been less tense than they had been with its predecessor. Tensions also decreased between the United States and China.
The administration of U.S. President George W. Bush withdrew from the Anti-Ballistic Missile Treaty in June 2002, claiming that the limited national missile defense system which they proposed to build was designed only to prevent nuclear blackmail by a state with limited nuclear capability and was not planned to alter the nuclear posture between Russia and the United States.
While relations have improved and an intentional nuclear exchange is more unlikely, the decay in Russian nuclear capability in the post-Cold War era may have had an effect on the continued viability of the MAD doctrine. An article by Keir Lieber and Daryl Press stated that the United States could carry out a nuclear first strike on Russia and would "have a good chance of destroying every Russian bomber base, submarine, and ICBM." This was attributed to reductions in Russian nuclear stockpiles and the increasing inefficiency and age of that which remains. Lieber and Press argued that the MAD era is coming to an end and that the United States is on the cusp of global nuclear primacy.
However, in a follow-up article in the same publication, others criticized the analysis, including Peter Flory, the U.S. Assistant Secretary of Defense for International Security Policy, who began by writing "The essay by Keir Lieber and Daryl Press contains so many errors, on a topic of such gravity, that a Department of Defense response is required to correct the record." Regarding reductions in Russian stockpiles, another response stated that "a similarly one-sided examination of in U.S. forces would have painted a similarly dire portrait".
A situation in which the United States might actually be expected to carry out a "successful" attack is perceived as a disadvantage for both countries. The strategic balance between the United States and Russia is becoming less stable, and the objective, technical possibility of a first strike by the United States is increasing. At a time of crisis, this instability could lead to an accidental nuclear war. For example, if Russia feared a U.S. nuclear attack, Moscow might make rash moves (such as putting its forces on alert) that would provoke a U.S. preemptive strike.
An outline of current U.S. nuclear strategy toward both Russia and other nations was published as the document "Essentials of Post–Cold War Deterrence" in 1995.
Official policy.
Whether MAD was the officially accepted doctrine of the United States military during the Cold War is largely a matter of interpretation. The United States Air Force, for example, has retrospectively contended that it never advocated MAD as a sole strategy, and that this form of deterrence was seen as one of numerous options in U.S. nuclear policy. Former officers have emphasized that they never felt as limited by the logic of MAD (and were prepared to use nuclear weapons in smaller-scale situations than "assured destruction" allowed), and did not deliberately target civilian cities (though they acknowledge that the result of a "purely military" attack would certainly devastate the cities as well). However, according to a declassified 1959 Strategic Air Command study, U.S. nuclear weapons plans specifically targeted the populations of Beijing, Moscow, Leningrad, East Berlin, and Warsaw for systematic destruction. MAD was implied in several U.S. policies and used in the political rhetoric of leaders in both the United States and the USSR during many periods of the Cold War.
The doctrine of MAD was officially at odds with that of the USSR, which had, contrary to MAD, insisted survival was possible. The Soviets believed they could win not only a strategic nuclear war, which they planned to absorb with their extensive civil defense planning, but also the conventional war that they predicted would follow after their strategic nuclear arsenal had been depleted. Official Soviet policy, though, may have had internal critics towards the end of the Cold War, including some in the USSR's own leadership.
Criticism.
The doctrine of nuclear deterrence depends on several challengeable assumptions:

</doc>
<doc id="45959" url="https://en.wikipedia.org/wiki?curid=45959" title="Nuclear strategy">
Nuclear strategy

Nuclear strategy involves the development of doctrines and strategies for the production and use of nuclear weapons.
As a sub-branch of military strategy, nuclear strategy attempts to match nuclear weapons as means to political ends. In addition to the actual use of nuclear weapons whether in the battlefield or strategically, a large part of nuclear strategy involves their use as a bargaining tool.
Some of the issues considered within nuclear strategy include:
Many strategists argue that nuclear strategy differs from other forms of military strategy because the immense and terrifying power of the weapons makes their use in seeking victory in a traditional military sense impossible.
Perhaps counterintuitively, an important focus of nuclear strategy has been determining how to prevent and deter their use, a crucial part of mutual assured destruction.
In the context of nuclear proliferation and maintaining the balance of power, states also seek to prevent other states from acquiring nuclear weapons as part of nuclear strategy.
Nuclear deterrent composition.
The doctrine of mutual assured destruction (MAD) assumes that a nuclear deterrent force must be credible and survivable. That is, each deterrent force must survive a first strike with sufficient capability to effectively destroy the other country in a second strike. Therefore, a first strike would be suicidal for the launching country.
In the late 1940s and 1950s as the Cold War developed, the United States and Soviet Union pursued multiple delivery methods and platforms to deliver nuclear weapons. Three types of platforms proved most successful and are collectively called a "nuclear triad". These are air-delivered weapons (bombs or missiles), ballistic missile submarines (usually nuclear-powered and called SSBNs), and intercontinental ballistic missiles (ICBMs), usually deployed in land-based hardened missile silos or on vehicles.
Although not considered part of the deterrent forces, all of the nuclear powers deployed large numbers of tactical nuclear weapons in the Cold War. These could be delivered by virtually all platforms capable of delivering large conventional weapons.
During the 1970s there was growing concern that the combined conventional forces of the Soviet Union and the Warsaw Pact could overwhelm the forces of NATO. It seemed unthinkable to respond to a Soviet/Warsaw Pact incursion into Western Europe with strategic nuclear weapons, inviting a catastrophic exchange. Thus, technologies were developed to greatly reduce collateral damage while being effective against advancing conventional military forces. Some of these were low-yield neutron bombs, which were lethal to tank crews, especially with tanks massed in tight formation, while producing relatively little blast, thermal radiation, or radioactive fallout. Other technologies were so-called “suppressed radiation devices,” which produced mostly blast with little radioactivity, making them much like conventional explosives, but with much more energy.

</doc>
<doc id="45960" url="https://en.wikipedia.org/wiki?curid=45960" title="Cloaking device">
Cloaking device

A cloaking device is a theoretical or fictional stealth technology that can cause objects, such as spaceships or individuals, to be partially or wholly invisible to parts of the electromagnetic (EM) spectrum. However, over the entire spectrum, a cloaked object scatters more than an uncloaked object.
Fictional cloaking devices have been used as plot devices in various media for many years.
Developments in scientific research show that real-world cloaking devices can obscure objects from at least one wavelength of EM emissions. Scientists already use artificial materials called metamaterials to bend light around an object.
Conceptual origins.
"" screenwriter Paul Schneider, inspired in part by the 1958 film "Run Silent, Run Deep", imagined cloaking as a space-travel analog of a submarine submerging, and employed it in the 1966 "Star Trek" episode "Balance of Terror". Another "Star Trek" screenwriter, D.C. Fontana, coined the term "cloaking device" for the 1968 episode "The Enterprise Incident". A possible earlier example could be Wonder Woman's Invisible Jet, first appearing in "Sensation Comics" #1 (Jan. 1942). 
Writers and game designers have since incorporated cloaking devices into many other science-fiction narratives, including "Doctor Who", "Star Wars", and "Stargate".
Scientific experimentation.
An operational, non-fictional cloaking device might be an extension of the basic technologies used by stealth aircraft, such as radar-absorbing dark paint, optical camouflage, cooling the outer surface to minimize electromagnetic emissions (usually infrared), or other techniques to minimize other EM emissions, and to minimize particle emissions from the object. The use of certain devices to jam and confuse remote sensing devices would greatly aid in this process, but are more properly referred to as "active camouflage". Alternatively, metamaterials provide the theoretical possibility of making electromagnetic radiation pass freely around the 'cloaked' object.
Metamaterial research.
Optical metamaterials have featured in several recent proposals for invisibility schemes. "Metamaterials" refers to materials that owe their refractive properties to the way they are structured, rather than the substances that compose them. Using transformation optics it is possible to design the optical parameters of a "cloak" so that it guides light around some region, rendering it invisible over a certain band of 
wavelengths.
These spatially varying optical parameters do not correspond to any natural material, but may be implemented using metamaterials. There are several theories of cloaking, giving rise to different types of invisibility.
In 2014, scientists demonstrated good cloaking performance in murky water, demonstrating that an object shrouded in fog can disappear completely when appropriately coated with metamaterial. This is due to the random scattering of light, such as that which occurs in clouds, fog, milk, frosted glass, etc., combined with the properties of the metamaterial coating. When light is diffused, a thin coat of metamaterial around an object can make it essentially invisible under a range of lighting conditions.
Active camouflage.
"Active camouflage" (or "adaptive camouflage") is a group of camouflage technologies which would allow an object (usually military in nature) to blend into its surroundings by use of panels or coatings capable of changing color or luminosity. Active camouflage can be seen as having the potential to become the perfection of the art of camouflaging things from visual detection.
"Optical camouflage" is a kind of active camouflage in which one wears a fabric which has an image of the scene directly behind the wearer projected onto it, so that the wearer appears invisible. The drawback to this system is that, when the cloaked wearer moves, a visible distortion is often generated as the 'fabric' catches up with the object's motion. The concept exists for now only in theory and in proof-of-concept prototypes, although many experts consider it technically feasible.
It has been reported that the British Army has tested an invisible tank. Mercedes demonstrated an invisible car using LED and camera in 2012.
Plasma stealth.
Plasma at certain density ranges absorbs certain bandwidths of broadband waves, potentially rendering an object invisible. However, generating plasma in air is too expensive and a feasible alternative is generating plasma between thin membranes instead. The Defense Technical Information Center is also following up research on plasma reducing RCS technologies. A plasma cloaking device was patented in 1991.
Metascreen.
A prototype Metascreen is a claimed cloaking device, which is just few micrometers thick and to a limited extent can hide 3D objects from microwaves in their natural environment, in their natural positions, in all directions, and from all of the observer's positions. It was prepared at the University of Texas, Austin by Professor Andrea Alù.
The metascreen consisted of a 66 micrometre thick polycarbonate film supporting an arrangement of 20 micrometer thick copper strips that resembled a fishing net. In the experiment, when the metascreen was hit by 3.6 GHz microwaves, it re-radiated microwaves of the same frequency that were out of phase, thus cancelling out reflections from the object being hidden. The device only cancelled out the scattering of microwaves in the first order. The same researchers published a paper on "plasmonic cloaking" the previous year.
Howell/Choi cloaking device.
University of Rochester physics professor John Howell and graduate student Joseph Choi have announced a scalable cloaking device which uses common optical lenses to achieve visible light cloaking on the macroscopic scale, known as the "Rochester Cloak". The device consists of a series of four lenses which direct light rays around objects which would otherwise occlude the optical pathway.
Cloaking in Mechanics.
The concepts of cloaking are not limited to optics but can also be transferred to other fields of Physics. For example, it was possible to cloak acoustics for certain frequencies as well as touching in mechanics. This renders an object "invisible" to sound or even hides it from touching.

</doc>
<doc id="45963" url="https://en.wikipedia.org/wiki?curid=45963" title="Analytic language">
Analytic language

An analytic language is a language that conveys grammatical relationships without using inflectional morphemes. A grammatical construction can similarly be called analytic if it uses unbound morphemes, which are separate words, and/or word order. Analytic languages are in contrast to synthetic languages.
A related concept is the isolating language, which is about a low number of any type of morphemes per word, taking into account derivational morphemes as well. A purely isolating language would be analytic by necessity, lacking inflectional morphemes by definition. However, the reverse is not necessarily true: a language can have derivational morphemes while lacking inflectional morphemes. For example, Mandarin Chinese has many compound words, giving it a moderately high ratio of morphemes per word, yet, since it has almost no inflectional affixes at all to convey grammatical relationships, it is a very analytic language.
The term "analytic" is commonly used in a relative rather than an absolute sense. English has lost much of the inflectional morphology of Proto-Indo-European, Proto-Germanic and Old English over the centuries and has not gained any new inflectional morphemes in the meantime, making it more analytic than most Indo-European languages. For example, while Proto-Indo-European had inflections for eight cases in its nouns, standard English has lost all of them.
For comparison, nouns in Russian inflect for at least six cases, most of them descended from Proto-Indo-European cases, whose functions English translates using other strategies like prepositions, verbal voice, word order and possessive "’s" instead.
However, English is also not totally analytic in its nouns as it does use inflections for number, e.g. "one day, three days; one boy, four boys". Mandarin Chinese has, in contrast, no inflections in its nouns at all: compare yī tiān 'one day', sān tiān 'three days' (literally "three day"); yī ge nánhái 'one boy' (lit. "one of male child"), sì ge nánhái 'four boys' (lit. "four of male child"). Instead English is considered to be weakly inflected.

</doc>
<doc id="45964" url="https://en.wikipedia.org/wiki?curid=45964" title="Chuck Berry">
Chuck Berry

Charles Edward Anderson "Chuck" Berry (born October 18, 1926) is an American guitarist, singer and songwriter, and one of the pioneers of rock and roll music. With songs such as "Maybellene" (1955), "Roll Over Beethoven" (1956), "Rock and Roll Music" (1957) and "Johnny B. Goode" (1958), Berry refined and developed rhythm and blues into the major elements that made rock and roll distinctive, with lyrics focusing on teen life and consumerism and utilizing guitar solos and showmanship that would be a major influence on subsequent rock music.
Born into a middle-class African-American family in St. Louis, Missouri, Berry had an interest in music from an early age and gave his first public performance at Sumner High School. While still a high school student he was arrested, and served a prison sentence for armed robbery from 1944 to 1947. After his release, Berry settled into married life and worked at an automobile assembly plant. By early 1953, influenced by the guitar riffs and showmanship techniques of blues player T-Bone Walker, Berry began performing with the Johnnie Johnson Trio. His break came when he traveled to Chicago in May 1955, and met Muddy Waters, who suggested he contact Leonard Chess of Chess Records. With Chess he recorded "Maybellene"—Berry's adaptation of the country song "Ida Red"—which sold over a million copies, reaching number one on Billboard's Rhythm and Blues chart. By the end of the 1950s, Berry was an established star with several hit records and film appearances to his name as well as a lucrative touring career. He had also established his own St. Louis-based nightclub, called Berry's Club Bandstand. But in January 1962, Berry was sentenced to three years in prison for offenses under the Mann Act—he had transported a 14-year-old girl across state lines.
After his release in 1963, Berry had more hits in the mid 60's, including "No Particular Place to Go," "You Never Can Tell," and "Nadine." By the mid-1970s, he was more in demand as a nostalgic live performer, playing his past hits with local backup bands of variable quality. In 1979 he served 120 days in prison for tax evasion.
Berry was among the first musicians to be inducted into the Rock and Roll Hall of Fame on its opening in 1986, with the comment that he "laid the groundwork for not only a rock and roll sound but a rock and roll stance." Berry is included in several "Rolling Stone" "Greatest of All Time" lists, including being ranked fifth on their 2004 list of the 100 Greatest Artists of All Time. The Rock and Roll Hall of Fame's 500 Songs that Shaped Rock and Roll included three of Berry's songs: "Johnny B. Goode," "Maybellene," and "Rock and Roll Music." Berry's "Johnny B. Goode" is the only rock and roll song included on the Voyager Golden Record. He continues to play live, performing monthly at Blueberry Hill restaurant in St. Louis.
Biography and career.
Early life and apprenticeship with Johnnie Johnson (1926–54).
Born in St. Louis, Missouri, Berry was the fourth child in a family of six. He grew up in the north St. Louis neighborhood known as The Ville, an area where many middle class St. Louis people lived at the time. His father, Henry, was a contractor and deacon of a nearby Baptist church, his mother Martha a certified public school principal. His middle class upbringing allowed him to pursue his interest in music from an early age and he gave his first public performance in 1941 while still at Sumner High School. Just three years later, in 1944, while still at Sumner High School, he was arrested and convicted of armed robbery after robbing three shops in Kansas City and then stealing a car at gunpoint with some friends. Berry's own account in his autobiography is that his car broke down and he then flagged down a passing car and stole it at gunpoint with a non-functional pistol. Berry was sent to the Intermediate Reformatory for Young Men at Algoa, near Jefferson City, Missouri, where he formed a singing quartet and did some boxing. The singing group became competent enough that the authorities allowed it to perform outside the detention facility.
After his release from prison on his 21st birthday in 1947, Berry married Themetta "Toddy" Suggs on October 28, 1948, who gave birth to Darlin Ingrid Berry on October 3, 1950. Berry supported his family doing a number of jobs in St. Louis: working briefly as a factory worker at two automobile assembly plants, as well as being janitor for the apartment building where he and his wife lived. Afterwards he trained as a beautician at the Poro College of Cosmetology, founded by Annie Turnbo Malone. He was doing well enough by 1950 to buy a "small three room brick cottage with a bath" in Whittier Street, which is now listed as the Chuck Berry House on the National Register of Historic Places.
By the early 1950s, Berry was working with local bands in the clubs of St. Louis as an extra source of income. He had been playing the blues since his teens, and he borrowed both guitar riffs and showmanship techniques from blues player T-Bone Walker, as well as taking guitar lessons from his friend Ira Harris that laid the foundation for his guitar style.
By early 1953 Berry was performing with Johnnie Johnson's trio, starting a long-time collaboration with the pianist. Although the band played mostly blues and ballads, the most popular music among whites in the area was country. Berry wrote, "Curiosity provoked me to lay a lot of our country stuff on our predominantly black audience and some of our black audience began whispering 'who is that black hillbilly at the Cosmo?' After they laughed at me a few times they began requesting the hillbilly stuff and enjoyed dancing to it."
Berry's calculated showmanship, along with mixing country tunes with R&B tunes, and singing in the style of Nat King Cole to the music of Muddy Waters, brought in a wider audience, particularly affluent white people.
Signing with Chess: "Maybellene" to "Come On" (1955–62).
In May 1955, Berry traveled to Chicago where he met Muddy Waters, who suggested he contact Leonard Chess of Chess Records. Berry thought his blues material would be of most interest to Chess, but to his surprise it was an old country and western recording by Bob Wills, entitled "Ida Red" that got Chess's attention. Chess had seen the rhythm and blues market shrink and was looking to move beyond it, and he thought Berry might be the artist for that purpose. So on May 21, 1955 Berry recorded an adaptation of "Ida Red"—"Maybellene"—which featured Johnnie Johnson on piano, Jerome Green (from Bo Diddley's band) on the maracas, Jasper Thomas on the drums and Willie Dixon on the bass. "Maybellene" sold over a million copies, reaching number one on Billboard's Rhythm and Blues chart and number five on the September 10, 1955 Billboard Best Sellers in Stores chart.
At the end of June 1956, his song "Roll Over Beethoven" reached number 29 on the "Billboard Top 100" chart, and Berry toured as one of the "Top Acts of '56." He and Carl Perkins became friends. Perkins said that "I knew when I first heard Chuck that he'd been affected by country music. I respected his writing; his records were very, very great." As they toured, Perkins discovered that Berry not only liked country music, but knew about as many songs as he did. Jimmie Rodgers was one of his favorites. "Chuck knew every Blue Yodel and most of Bill Monroe's songs as well," Perkins remembered. "He told me about how he was raised very poor, very tough. He had a hard life. He was a good guy. I really liked him."
In late 1957, Berry took part in Alan Freed's "Biggest Show of Stars for 1957" United States tour with the Everly Brothers, Buddy Holly, and others. He also guest starred on ABC's "The Guy Mitchell Show", having sung his hit song "Rock 'n' Roll Music." The hits continued from 1957 to 1959, with Berry scoring over a dozen chart singles during this period, including the top 10 US hits "School Days," "Rock and Roll Music," "Sweet Little Sixteen," and "Johnny B. Goode". He appeared in two early rock and roll movies. The first was "Rock Rock Rock," (1956) in which he sings "You Can't Catch Me." He had a speaking role as himself in "Go, Johnny, Go!" (1959) along with Alan Freed, and performs his songs "Johnny B. Goode," "Memphis, Tennessee," and "Little Queenie." His performance of "Sweet Little Sixteen" at the Newport Jazz Festival in 1958 is captured in the motion picture "Jazz on a Summer's Day".
By the end of the 1950s, Berry was a high-profile established star with several hit records and film appearances to his name, as well as a lucrative touring career. He had opened a racially integrated St. Louis-based nightclub, called Berry's Club Bandstand, and was investing in real estate. But in December 1959, Berry was arrested under the Mann Act after questionable allegations that he had sexual intercourse with a 14-year-old Apache waitress, Janice Escalante, whom he had transported over state lines to work as a hat check girl at his club. After an initial two-week trial in March 1960, Berry was convicted, fined $5,000, and sentenced to five years in prison. Berry's appeal that the judge's comments and attitude were racist and prejudiced the jury against him was upheld, and a second trial was heard in May and June 1961, which resulted in Berry being given a three-year prison sentence. After another appeal failed, Berry served one and one half years in prison from February 1962 to October 1963. Berry had continued recording and performing during the trials, though his output had slowed down as his popularity declined; his final single released before being imprisoned was "Come On".
"Nadine" and move to Mercury (1963–69).
When Berry was released from prison in 1963, his return to recording and performing was made easier due to the British invasion acts of the 1960s—most notably the Beatles and the Rolling Stones—having kept up an interest in his music by releasing cover versions of his songs, along with other bands reworking them, such as the Beach Boys' 1963 hit "Surfin' U.S.A.", based on Berry's "Sweet Little Sixteen". In 1964–65 Berry released eight singles, including three, "No Particular Place to Go" (a humorous reworking of "School Days" concerning the introduction of car seat belts), "You Never Can Tell", and the rocking "Nadine", which achieved commercial success, reaching the top 20 of the Billboard 100. Between 1966 and 1969 Berry released five albums on the Mercury label, including his first live album "Live at Fillmore Auditorium" in which he was backed by the Steve Miller Band.
While this was not a successful period for studio work, Berry was still a top concert draw. In May 1964, he did a successful tour of the UK, but when he returned in January 1965 his behavior was erratic and moody, and his touring style of using unrehearsed local backing bands and a strict non-negotiable contract was earning him a reputation as a difficult yet unexciting performer. He also played at large events in North America, such as the Schaefer Music Festival in New York City's Central Park in July 1969, and the Toronto Rock and Roll Revival festival in October.
Back to Chess: "My Ding-a-Ling" to White House concert (1970–79).
Berry returned to Chess from 1970 to 1973. There were no hit singles from the 1970 album "Back Home", but in 1972 Chess released a live recording of "My Ding-a-Ling", a novelty song which he had recorded in a different version on his 1968 LP "From St. Louie to Frisco" as "My Tambourine". The track became his only number one single. A live recording of "Reelin' And Rockin'" was also issued as a follow-up single that same year and would prove to be Berry's final top-40 hit in both the US and the UK. Both singles were featured on the part-live/part-studio album "The London Chuck Berry Sessions" which was one of a series of London Sessions albums which included other Chess mainstay artists Muddy Waters and Howlin' Wolf. Berry's second tenure with Chess ended with the 1975 album "Chuck Berry", after which he did not make a studio record until 1979's "Rock It" for Atco Records, his last studio album to date.
In the 1970s Berry toured on the basis of his earlier successes. He was on the road for many years, carrying only his Gibson guitar, confident that he could hire a band that already knew his music no matter where he went. AllMusic has said that in this period his "live performances became increasingly erratic, ... working with terrible backup bands and turning in sloppy, out-of-tune performances" which "tarnished his reputation with younger fans and oldtimers" alike. Among the many bandleaders performing a backup role with Berry were Bruce Springsteen and Steve Miller when each was just starting his career. Springsteen related in the video "Hail! Hail! Rock 'n' Roll" that Berry did not even give the band a set list and just expected the musicians to follow his lead after each guitar intro. Berry neither spoke to nor thanked the band after the show. Nevertheless, Springsteen backed Berry again when he appeared at the concert for the Rock and Roll Hall of Fame in 1995. At the request of Jimmy Carter, Berry performed at the White House on June 1, 1979.
Berry's type of touring style, traveling the "oldies" circuit in the 1970s (where he was often paid in cash by local promoters) added ammunition to the Internal Revenue Service's accusations that Berry was a chronic income tax evader. Facing criminal sanction for the third time, Berry pleaded guilty to tax evasion and was sentenced to four months in prison and 1,000 hours of community service—doing benefit concerts—in 1979.
Still on the road (1980–present).
Berry continued to play 70 to 100 one-nighters per year in the 1980s, still traveling solo and requiring a local band to back him at each stop. In 1986, Taylor Hackford made a documentary film, "Hail! Hail! Rock 'n' Roll", of a celebration concert for Berry's sixtieth birthday, organized by Keith Richards. Eric Clapton, Etta James, Julian Lennon, Robert Cray and Linda Ronstadt, among others, appeared with Berry on stage and film. During the concert, Berry played a Gibson ES-355, the luxury version of the ES-335 that he favored on his 1970s tours. Richards played a black Fender Telecaster Custom, Cray a Fender Stratocaster and Clapton a Gibson ES 350T, the same guitar Berry used on his early recordings.
In the late 1980s, Berry bought a restaurant in Wentzville, Missouri, called The Southern Air, and in 1990 he was sued by several women who claimed that he had installed a video camera in the ladies' bathroom. Berry claimed that he had the camera installed to catch red-handed a worker who was suspected of stealing from the restaurant. Though his guilt was never proven in court, Berry opted for a class action settlement with 59 women. Berry's biographer, Bruce Pegg, estimated that it cost Berry over $1.2 million plus legal fees. It was during this time that he began using Wayne T. Schoeneberg as his legal counsel. Reportedly, a police raid on his house did find videotapes of women using the restroom, and one of the women was a minor. Also found in the raid were 62 grams of marijuana. Felony drug and child-abuse charges were filed. In order to avoid the child-abuse charges, Berry agreed to plead guilty to misdemeanor possession of marijuana. He was given a six-month suspended jail sentence, two years' unsupervised probation, and ordered to donate $5,000 to a local hospital.
In November 2000, Berry again faced legal charges when he was sued by his former pianist Johnnie Johnson, who claimed that he co-wrote over 50 songs, including "No Particular Place to Go", "Sweet Little Sixteen" and "Roll Over Beethoven", that credit Berry alone. The case was dismissed when the judge ruled that too much time had passed since the songs were written.
In 2008, Berry toured Europe, with stops in Sweden, Norway, Finland, the United Kingdom, the Netherlands, Ireland, Switzerland, Poland and Spain. In mid-2008, he played at Virgin Festival in Baltimore, Maryland. He presently lives in Ladue, Missouri, approximately 10 miles west of St. Louis. During a New Year's Day 2011 concert in Chicago, Berry, suffering from exhaustion, passed out and had to be helped off stage. He usually performs one Wednesday each month at Blueberry Hill, a restaurant and bar located in the Delmar Loop neighborhood in St. Louis.
Legacy.
A pioneer of rock music, Berry was a significant influence on the development of both the music and the attitude associated with the rock music lifestyle. With songs such as "Maybellene" (1955), "Roll Over Beethoven" (1956), "Rock and Roll Music" (1957) and "Johnny B. Goode" (1958), Berry refined and developed rhythm and blues into the major elements that made rock and roll distinctive, with lyrics successfully aimed to appeal to the early teenage market by using graphic and humorous descriptions of teen dances, fast cars, high-school life, and consumer culture, and utilizing guitar solos and showmanship that would be a major influence on subsequent rock music. His records are a rich storehouse of the essential lyrical, showmanship and musical components of rock and roll; and, in addition to the Beatles and the Rolling Stones, a large number of significant popular-music performers have recorded Berry's songs. Though not technically accomplished, his guitar style is distinctive—he incorporated electronic effects to mimic the sound of bottleneck blues guitarists, and drew on the influence of guitar players such as Charlie Christian and T-Bone Walker to produce a clear and exciting sound that many later guitar musicians would acknowledge as a major influence in their own style. Berry's showmanship has been influential on other rock guitar players, particularly his one-legged hop routine, and the "duck walk", which he first used as a child when he walked "stooping with full-bended knees, but with my back and head vertical" under a table to retrieve a ball and his family found it entertaining; he used it when "performing in New York for the first time and some journalist branded it the duck walk."
The rock critic Robert Christgau considers him "the greatest of the rock and rollers," while John Lennon said, "if you tried to give rock and roll another name, you might call it 'Chuck Berry'." Ted Nugent said "If you don't know every Chuck Berry lick, you can't play rock guitar."
Among the honors Berry has received have been the Grammy Lifetime Achievement Award in 1984, the Kennedy Center Honors in 2000, and being named seventh on "Time" magazine's 2009 list of the 10 best electric guitar players of all time. On May 14, 2002, Berry was honored as one of the first BMI Icons at the 50th annual BMI Pop Awards. He was presented the award along with BMI affiliates Bo Diddley and Little Richard. In August 2014, Berry was made a laureate of the Polar Music Prize.
Berry is included in several "Rolling Stone" "Greatest of All Time" lists. In September 2003, the magazine named him number 6 in their list of the "100 Greatest Guitarists of All Time". This was followed in November of the same year by his compilation album "The Great Twenty-Eight" being ranked 21st in the Rolling Stone's 500 Greatest Albums of All Time. The following year, in March 2004, Berry was ranked fifth out of "The Immortals – The 100 Greatest Artists of All Time". In December 2004, six of his songs were included in the "Rolling Stone's 500 Greatest Songs of All Time", namely "Johnny B. Goode" (#7), "Maybellene" (#18), "Roll Over Beethoven" (#97), "Rock and Roll Music" (#128), "Sweet Little Sixteen" (#272) and "Brown Eyed Handsome Man" (#374). In June 2008, his song "Johnny B. Goode" ranked first place in the "100 Greatest Guitar Songs of All Time".

</doc>
<doc id="45966" url="https://en.wikipedia.org/wiki?curid=45966" title="No first use">
No first use

No first use (NFU) refers to a pledge or a policy by a nuclear power not to use nuclear weapons as a means of warfare unless first attacked by an adversary using nuclear weapons. Earlier, the concept had also been applied to chemical and biological warfare.
China declared its NFU policy in 1964, and has since maintained this policy. India articulated its policy of no first use of nuclear weapons in 2003.
NATO has repeatedly rejected calls for adopting NFU policy, arguing that preemptive nuclear strike is a key option, in order to have a credible deterrent that could compensate for the overwhelming conventional weapon superiority enjoyed by the Soviet Army in the Eurasian land mass. In 1993, Russia dropped a pledge given by the former Soviet Union not to use nuclear weapons first. In 2000, a Russian military doctrine stated that Russia reserves the right to use nuclear weapons "in response to a large-scale conventional aggression". This is because the balance of forces was reversed, NATO now is enjoying a clear superiority in conventional weapons.
Countries pledging no-first-use.
China.
China became the first nation to propose and pledge NFU policy when it first gained nuclear capabilities in 1964, stating "not to be the first to use nuclear weapons at any time or under any circumstances". During the Cold War, China decided to keep the size of its nuclear arsenal small rather than compete in an international arms race with the United States and the Soviet Union. China has repeatedly re-affirmed its no-first-use policy in recent years, doing so in 2005, 2008, 2009 and again in 2011. China has also consistently called on the United States to adopt a no-first-use policy, to reach a NFU agreement bilaterally with China, and to conclude an NFU agreement among the five nuclear weapon states. The United States has repeatedly refused these calls.
India.
India has a declared nuclear no-first-use policy and is in the process of developing a nuclear doctrine based on "credible minimum deterrence." In August 1999, the Indian government released a draft of the doctrine which asserts that nuclear weapons are solely for deterrence and that India will pursue a policy of "retaliation only". The document also maintains that India "will not be the first to initiate a nuclear first strike, but will respond with punitive retaliation should deterrence fail" and that decisions to authorise the use of nuclear weapons would be made by the Prime Minister or his 'designated successor(s)'. According to the NRDC, despite the escalation of tensions between India and Pakistan in 2001–2002, India remained committed to its nuclear no-first-use policy.
A speech by India's then NSA Shivshankar Menon at National Defence College in New Delhi on October 21, 2010 changed the wording from ""no first use"" to ""no first use against non-nuclear weapon states"", although some argued that this was not a substantive change but "an innocent typographical or lexical error in the text of the speech." India’s current PM Modi has in the run up to the recent general elections reiterated commitment to no first use policy. In April 2013 Shyam Saran, convener of the National Security Advisory Board, affirmed that regardless of the size of a nuclear attack against India, be it a tactical nuclear weapon or a strategic nuclear weapon, India will retaliate massively. This was in response to reports that Pakistan had developed a tactical battlefield nuclear weapon, in an attempt to nullify an Indian "no first use" retaliatory doctrine.
Countries pledging to use nuclear weapons only defensively.
Pakistan, Russia, the United Kingdom, the United States, and France say they will use nuclear weapons against either nuclear or non-nuclear states only in the case of invasion or other attack against their territory or against one of their allies. Historically, NATO military strategy, taking into account the numerical superiority of Warsaw Pact conventional forces, assumed that the use of tactical nuclear weapons would have been required in defeating a Soviet invasion.
At a NATO summit in April 1999, Germany proposed that NATO adopt a no-first-use policy, but the proposal was rejected.
United Kingdom.
In March 2002, British defence secretary Geoff Hoon stated that the UK was prepared to use nuclear weapons against "rogue states" such as Iraq if they ever used "weapons of mass destruction" against British troops in the field. This policy was restated in February 2003.
United States.
The United States has refused to adopt a no-first-use policy, saying that it "reserves the right to use" nuclear weapons first in the case of conflict. The U.S. doctrine for the use of nuclear weapons was revised most recently in the Nuclear Posture Review, released April 6, 2010. The 2010 Nuclear Posture review reduces the role of U.S. nuclear weapons, stating that
"The fundamental role of U.S. nuclear weapons, which will continue as long as nuclear weapons exist, is to deter nuclear attack on the United States, our allies, and partners."
The U.S. doctrine also includes the following assurance to other states:
"The United States will not use or threaten to use nuclear weapons against non-nuclear weapons states that are party to the NPT and in compliance with their nuclear non-proliferation obligations."
For states eligible for this assurance, the United States would not use nuclear weapons in response to a chemical or biological attack, but states that those responsible for such an attack would be held accountable and would face the prospect of a devastating conventional military response. Even for states not eligible for this assurance, the United States would consider the use of nuclear weapons only in extreme circumstances to defend the vital interests of the United States or its allies and partners. The Nuclear Posture Review also notes:
"It is in the U.S. interest and that of all other nations that the nearly 65-year record of nuclear non-use be extended forever."
This supersedes the doctrine of the Bush Administration set forth in "Doctrine for Joint Nuclear Operations" and written under the direction of Air Force General Richard B. Myers, chairman of the Joint Chiefs of Staff. The new doctrine envisions commanders requesting presidential approval to use nuclear weapons to preempt an attack by a nation or a terrorist group using weapons of mass destruction. The draft also includes the option of using nuclear weapons to destroy known enemy stockpiles of nuclear, biological, or chemical weapons.
Pakistan.
Pakistan refuses to adopt a "no-first-use" doctrine, indicating that it would strike India with nuclear weapons even if India did not use such weapons first. Pakistan's asymmetric nuclear posture has significant influence on India's decision ability to retaliate, as shown in 2001 and 2008 crises, when non-state actors carried out deadly terrorist attacks on India, only to be met with a relatively subdued response from India. A military spokesperson stated that "Pakistan's threat of nuclear first-use deterred India from seriously considering conventional military strikes."
Pakistan's National Security Advisor Sartaj Aziz defended the policy of first use. Aziz stated that Pakistan's first use doctrine is entirely deterrent in nature. He explained that it was effective after the 2001 Indian Parliament attack and argued that if Pakistan had a no-first use policy, there would have been a major war between the two countries.
Israel.
Although Israel does not officially confirm or deny having nuclear weapons, the country is widely believed to be in possession of them. Its continued ambiguous stance puts it in a difficult position since to issue a statement pledging 'no first use' would confirm their possession of nuclear weapons.
Israel has said that it "would not be the first country in the Middle East to formally introduce nuclear weapons into the region."
If Israel's very existence is threatened, some speculate that Israel would use a "Samson Option," a "last resort" deterrence strategy of massive retaliation with nuclear weapons, should the State of Israel be substantially damaged and/or near destruction.

</doc>
<doc id="45967" url="https://en.wikipedia.org/wiki?curid=45967" title="Richard Burton">
Richard Burton

Richard Burton, CBE (; 10 November 19255 August 1984) was a Welsh stage and cinema actor noted for his mellifluous baritone voice and his acting talent.
Establishing himself as a formidable Shakespearean actor in the 1950s, with a memorable performance of Hamlet in 1964, Burton was called "the natural successor to Olivier" by critic and dramaturg Kenneth Tynan. An alcoholic, Burton's failure to live up to those expectations disappointed critics and colleagues and fueled his legend as a great thespian wastrel.
Burton was nominated seven times for an Academy Award without ever winning. He was a recipient of BAFTA, Golden Globe and Tony Awards for Best Actor. In the mid-1960s Burton ascended into the ranks of the top box office stars, and by the late 1960s was one of the highest-paid actors in the world, receiving fees of $1 million or more plus a share of the gross receipts.
Burton remains closely associated in the public consciousness with his second wife, actress Elizabeth Taylor. The couple's turbulent relationship was rarely out of the news.
Early life and education.
Childhood.
Richard Burton was born Richard Walter Jenkins, Jr. on 10 November 1925 in his house at 2 Dan-y-bont in Pontrhydyfen, a small village located in the county borough of Neath Port Talbot, Wales. He was the twelfth of thirteen children born to his father, Richard Walter Jenkins Sr. (1876-1957), and his mother, Edith Maude Jenkins (née Thomas; 1883-1927). Jenkins Sr., called Daddy Ni by the family, was a coal-miner while his mother worked as a bartender at a pub called the Miner's Arms, which was also the place where she met and married her husband. According to biographer Melvyn Bragg, Richard is quoted saying that Daddy Ni was "twelve-pints-a-day man" who sometimes went off on drinking and gambling sprees for weeks, and that "he looked very much like me". He remembered his mother to be "a very strong woman" and "a religious soul with fair hair and a beautiful face".
Richard was barely two years old when his mother died on 31 October, six days after the birth of the Jenkins family's thirteenth child, Graham Jenkins. The cause of Edith's death was because "of puerperal fever". which Richard termed "hygiene neglect". According to biographer Michael Munn, Edith "was fastidiously clean", but that her exposure to the dust from the coal mines resulted in her death. Following Edith's death, Richard's elder sister Cecilia, whom he affectionately addressed as "Cis", and her husband Elfed James, also a miner, took him under their care. Richard lived with Cis, Elfed and their two daughters, Marian and Rhianon, in their three bedroom terraced cottage on 73 Caradoc Street in Taibach, a suburban district in Port Talbot, which Bragg describes as "a tough steel town, English-speaking, grind and grime".
Richard remained forever grateful and loving to Cis throughout his life, later going on to say "When my mother died she, my sister, had become my mother, and more mother to me than any mother could ever have been ... I was immensely proud of her ... she felt all tragedies except her own". Daddy Ni would occasionally visit the homes of his grown daughters but was otherwise absent. Another important figure in Richard's early life was Ifor, his brother, 19 years his senior. A miner and rugby union player, Ifor "ruled the household with the proverbial firm hand". He was also responsible for nurturing in young Richard a passion for Rugby. Although Richard also played cricket, tennis and table tennis, biographer Bragg notes rugby union football to be his greatest interest. On rugby, Richard said he "would rather have played for Wales at Cardiff Arms Park than Hamlet at The Old Vic." The Welsh rugby union centre, Bleddyn Williams believed Richard "had distinct possibilities as a player".
From the age of five to eight, Richard had his education at the Eastern Primary School while he attended the Boys' segment of the same school from eight to twelve years old. He took a scholarship exam for admission into Port Talbot Secondary School in March 1937 and passed it. Biographer Hollis Alpert notes that both Daddy Ni and Ifor considered Richard's education to be "of paramount importance" and planned to send him to the University of Oxford. Richard became the first member of his family to go to secondary school. He displayed an excellent speaking and singing voice since childhood, even winning an eisteddfod prize as a boy soprano. During his tenure at Port Talbot Secondary School, Richard also showed immense interest in reading poetry as well as English and Welsh literature. He earned pocket money by running messages, hauling horse manure, and delivering newspapers.
The Philip Burton years.
Bolstered by his winning of the eisteddfod prize, Richard wanted to repeat the success. He chose to sing Sir Arthur Sullivan's "Orpheus with his Lute" (1866), which biographer Alpert thought "a difficult composition". He requested the help of his schoolmaster, Philip Burton, but his voice cracked during their practice sessions. This incident marked the beginning of his association with Philip. Philip later recalled, "His voice was tough to begin with but with constant practice it became memorably beautiful." Richard made his first foray into theatre with a minor role in his school's production of the Irish playwright George Bernard Shaw's "The Apple Cart". He decided to leave school by the end of 1941 and work at as a miner as Elfed wasn't fit for work due to illness. He worked for the local wartime Co-operative committee, handing out supplies in exchange for coupons. He also simultaneously considered other professions for his future, including boxing, religion and singing. It was also during this period that Richard took up smoking and drinking despite being underage.
When he joined the Port Talbot Squadron 499 of the Air Training Corps section of the Royal Air Force (RAF) as a cadet, he re-encountered Philip, who was the squadron commander. He also joined the Taibach Youth Center, a youth drama group founded by Meredith Jones and led by Leo Lloyd, a steel worker and avid amateur thespian, who taught him the fundamentals of acting. Richard played the role of an escaped convict in Lloyd's play, "The Bishop's Candlesticks", an adaptation of a section of Victor Hugo's "Les Misérables". The entire play did not have any dialogues, but Alpert noted that Richard "mimed his role". Philip gave him a part in a radio documentary/adaptation of his play for BBC Radio, "Youth at the Helm" (1942). Seeing the talent Richard possessed, both Jones and Philip re-admitted him to school on 5 October 1942. Philip called Richard "my son to all intents and purposes. I was committed to him." Philip tutored his charge intensely in school subjects, and also worked at developing the youth's acting voice, including outdoor voice drills which improved his projection. Richard called the experience "the most hardworking and painful period" in his life.
In autumn of 1943, Philip planned to adopt Richard, but was not able to do so as Richard was 20 days too young for the requirement of being 21 years older than Philip himself. As a result, Richard became Philip's legal ward and changed his surname to "Richard Burton", after Philip's own surname, by means of deed poll, which Richard's father accepted. It was also in 1943 that Richard qualified for admission into a University after excelling in the School Certificate Examination. Philip requested Richard to study at Exeter College, Oxford as a part of a six-month scholarship program offered by the RAF for qualified cadets prior to active service.
Career.
Early career and service in the RAF (1943–1947).
In 1943, Burton played Professor Henry Higgins in a school production of another Shaw play directed by Philip, "Pygmalion". The role won him favourable reviews and caught the attention of the dramatist, Emlyn Williams, who offered Burton a small role of the lead character's elder brother, Glan, in his play "The Druid's Rest". The play debuted at the Royal Court Theatre, Liverpool on 22 November 1943 and later premiered in St Martin's Theatre, London in January 1944. Burton thought the role was "a nothing part" and that he "hardly spoke at all". He was paid ten pounds a week for playing the role, which was "three times what the miners got." Alpert states that the play garnered mixed reviews from critic, but James Redfern of the "New Statesman" took notice of Burton's performance and wrote "In a wretched part, Richard Burton showed exceptional ability." Burton noted that single sentence from Redfern changed his life.
During his tenure at Exeter college, Burton featured as "the complicated sex-driven puritan" Angelo in the Oxford University Dramatic Society's 1944 production of William Shakespeare's "Measure for Measure". The play was directed by Burton's English literature professor, Nevill Coghill, and was performed at the college in the presence of an audience of West End theatre luminaries such as John Gielgud, Terence Rattigan and Binkie Beaumont. On Burton's performance, fellow actor and friend, Robert Hardy recalled, "There were moments when he totally commanded the audience by this stillness. And the voice which would sing like a violin and with a bass that could shake the floor." Gielgud appreciated Burton's performance and Beaumont, who knew about Burton's work in "The Druid's Rest", suggested that he "look him up" after completing his service in the RAF if he still wanted to pursue acting as a profession.
In late 1944, Burton successfully completed his six-month scholarship at Exeter college, Oxford, and went to the RAF classification examinations held in Torquay to train as a pilot. He was disqualified for pilot training due to his eyesight being below par, and was classified as a navigator trainee. He served the RAF as a navigator for three years, during which he performed an assignment as Aircraftman 1st Class in an RAF Hospital based in Wiltshire. Burton's habits of drinking and smoking increased during this period; he was involved in a brief casual affair with actress Eleanor Summerfield. Burton was cast in an uncredited and unnamed role of a bombing officer by BBC Third Programme in a 1946 radio adaptation of "In Parenthesis", an epic poem of the First World War by David Jones. Burton was discharged from the RAF on 16 December 1947.
Rise through the ranks and film debut (1948–1951).
In 1948, Burton moved to London to make contact with H. M. Tennent Ltd, where he again met Beaumont, who put Burton under a contract of £500 per year (£10 a week). Daphne Rye, the casting director for H. M. Tennent Ltd, offered Burton two rooms on the top floor of her house in Pelham Crescent, London as a place for him to stay. Rye cast Burton in a minor role as a young officer, Mr. Hicks, in "Castle Anna" (1948), a drama set in Ireland.
While touring with the cast and crew members of Wynyard Browne's "Dark Summer", Burton was called by Emlyn Williams for a screen test in his film, "The Last Days of Dolwyn" (1949). Burton performed the screen test for the role of Gareth, which Emlyn wrote especially for him, and was subsequently selected when Emlyn sent him a telegram which quoted a line from "The Corn Is Green" "You have won the scholarship". This led to Burton making his mainstream film debut. Filming took place during the summer and early autumn months of 1948. It was on the sets of this film where Burton was introduced by Emlyn to Sybil Williams, whom he married on 5 February 1949 at a register office in Kensington. "The Last Days of Dolwyn" opened to generally positive reviews from critics. Burton was praised for his "acting fire, manly bearing and good looks." Film critic Philip French of "The Guardian" called it an "impressive movie debut" from Burton.
Pleased with the feedback Burton received for his performance in "The Last Days of Dolwyn", the film's co-producer Alexander Korda offered him a contract at a stipend of £100 a week, which he signed. The contract enabled Korda to lend Burton to films produced by other companies. Throughout the late 40s and early 50s, Burton acted in small parts in various British films such as "Now Barabbas" (1949) with Richard Greene and Kathleen Harrison, "The Woman with No Name" (1950) opposite Phyllis Calvert, "Waterfront" (1950) with Kathleen Harrison again; he had a bigger part as Robert Hammond, a spy for a newspaper editor in "Green Grow the Rushes" (1951) alongside Honor Blackman. His performance in "Now Barabbas" received positive feedback from critics. C. A. Lejeune of "The Observer" believed Burton had "all the qualities of a leading man that the British film industry badly needs at this juncture: youth, good looks, a photogenic face, obviously alert intelligence and a trick of getting the maximum effort with the minimum of fuss." For "The Woman With No Name", a critic from "The New York Times" thought Burton "merely adequate" in his role of the Norwegian aviator, Nick Chamerd. Biographer Bragg states the reviews for Burton's performance in "Waterfront" were "not bad", and that "Green Grow the Rushes" was a box office bomb.
Rye recommended Richard to director Peter Glenville for the part of Hephaestion in Rattigan's play about Alexander the Great, "Adventure Story", in 1949. The play was directed by Glenville and starred the then up-and-coming actor Paul Scofield as the titular character. Glenville, however, rejected him as he felt that Burton was too short compared to Scolfield. Rye came to the rescue again by sending Burton to audition for a role in "The Lady's Not for Burning", a play by Christopher Fry and directed by Gielgud. The lead roles were played by Gielgud himself, and Pamela Brown, while Burton played a supporting role as Richard alongside the then-relatively unknown actress Claire Bloom. Gielgud was initially uncertain about selecting Burton and asked him to come back the following day to repeat his audition. Burton got the part the second time he auditioned for the role. He was paid £15 a week for the part, which was five more than what Beaumont was paying him. After getting the part, he pushed for a raise in his salary from £10 to £30 a week with Emlyn's assistance, in addition to the £100 Korda paid him; Beaumont accepted it after much persuasion. Bloom was impressed with Burton's natural way of acting, noting that "he just was" and went further by saying "He was recognisably a star, a fact he didn't question".
The play opened in the Globe Theatre in May 1949 and had a successful run in London for a year. Writer and journalist Samantha Ellis of "The Guardian", in her overview of the play, thought critics found Burton to be "most authentic" for his role. Gielgud took the play to Broadway in the United States, where it opened at the Royale Theatre on 8 November 1950. Theatre critic Brooks Atkinson appreciated the performances and praised the play's "hard glitter of wit and skepticism", while describing Fry as precocious with "a touch of genius". The play ran on Broadway until 17 March 1951, and received the New York Drama Critics' Circle award for the Best Foreign Play of 1951. Burton received the Theatre World Award for his performance, his first major award.
Burton went on to feature in two more plays by Fry "The Boy With A Cart" and "A Phoenix Too Frequent". The former opened at the Lyric Theatre, Hammersmith in February 1950 while the latter premiered at the Dolphin Theatre, Brighton the following month. Gielgud, who also directed "The Boy With A Cart", said about Richard's role as a boy named Cuthman who hears a mysterious call to build a church and travels with his mother in a cart for the right place to do so, that "It was one of the most beautiful performances" he had ever seen. During its month-long run, Anthony Quayle, who was on the lookout for a young actor to star as Prince Hal in his adaptations of "Henry IV, Part I" and "Henry IV, Part 2" as a part of the Shakespeare Memorial Theatre season for the Festival of Britain, came to see the play and as soon as he beheld Burton, he found his man and got his agreement to play the parts. Both plays opened in 1951 at the Shakespeare Memorial Theatre in Stratford-upon-Avon to mixed reviews, but Burton received acclaim and achieved stardom for his role as Prince Hal. Many critics dubbed him "the next Laurence Olivier". Theatre critic and dramaturge, Kenneth Tynan said of his performance, "His playing of Prince Hal turned interested speculation to awe almost as soon as he started to speak; in the first intermission local critics stood agape in the lobbies." He was also praised by Humphrey Bogart and his wife Lauren Bacall after both witnessed the play. Bacall later said of him: "He was just marvellous [...] Bogie loved him. We all did." Burton celebrated his success by buying his first car, a Standard Flying Fourteen and enjoyed a drink with Bogart at a pub called The Dirty Duck. Philip too was happy with the progress his ward made and that he felt "proud, humble, and awed by god's mysterious ways".
Burton went on to do "Henry V" as the titular character, and played Ferdinand in "The Tempest" as a part of the Shakespeare Memorial Theatre season as well. Both roles didn't go too well with critics, with a reviewer saying "he lacked inches" as Henry V. Olivier defended Burton by retaliating that he too received the same kind of review by the same critic for the same role. His last play in 1951 was as a musician named Orphée in Jean Anouilh's "Eurydice" opposite Dorothy McGuire and fellow Welsh actor Hugh Griffith. The play, retitled as "Legend of Lovers", opened in the Plymouth Theatre, New York City and ran only for a week, but critics were kind to Burton, with Bob Francis of "Billboard" magazine finding him "excellent as the self-tortured young accordionist".
Foray into Hollywood and success with The Old Vic (1952–1954).
Burton began 1952 by starring alongside Noel Willman in the title role of Emmanuel Roblès adventure "Montserrat", which opened on 8 April at the Lyric Hammersmith. The play only ran for six weeks but Burton once again won praises from critics. According to Bragg, some of the critics who watched the performance considered it to be Burton's "most convincing role" till then. Tynan lauded Burton's role of Captain Montserrat, noting that he played it "with a variousness which is amazing when you consider that it is really little more than a protracted exposition of smouldering dismay."
Burton successfully made the transition to Hollywood when, on the recommendation of film director George Cukor, he was given the lead role in the Gothic romance film, "My Cousin Rachel" (1952) opposite Olivia de Havilland. Darryl F. Zanuck, co-founder of 20th Century Fox, negotiated a deal with Korda to loan Burton to the company for three films as well as pay Burton a total of $150,000 ($50,000 per film). De Havilland did not get along well with Burton during filming, calling him "a coarse-grained man with a coarse-grained charm and a talent not completely developed, and a coarse-grained which makes him not like anyone else." One of Burton's friends opined it may have been due to Burton making remarks at her that she did not find to be in good taste. While shooting for the film, Burton was offered the role of Mark Antony in "Julius Caesar" (1953) by the production company, Metro Goldwyn Mayer (MGM), but Burton refused it to avoid schedule conflicts. The role subsequently went to Marlon Brando for which he earned a BAFTA Award for Best Foreign Actor and an Academy Award nomination for Best Actor. Based on the 1951 novel of the same name by Daphne du Maurier, "My Cousin Rachel" is about a man who suspects his rich cousin was murdered by his wife in order to inherit his wealth, but ends up falling in love with her, despite his suspicions. Upon release, the film was a decent grosser at the box office, and Burton's performance received mostly excellent reviews. Bosley Crowther, writing for "The New York Times", appreciated Burton's emotional performance, describing it as "most fetching"; he called him "the perfect hero of Miss du Maurier's tale." The "Los Angeles Daily News" reviewer stated "young Burton registers with an intense performance that stamps him as an actor of great potential." Conversely, a critic from the "Los Angeles Examiner" labelled Burton as "terribly, terribly tweedy". The film earned Burton the Golden Globe Award for New Star of the Year – Actor and his first Academy Award nomination in the Best Supporting Actor category.
The year 1953 marked an important turning point in Burton's career. He arrived in Hollywood at a time when the studio system was struggling. Television's rise was drawing viewers away and the studios looked to new stars and new film technologies to tempt viewers back to cinemas. He first appeared in the war film "The Desert Rats" with James Mason, playing an English captain in the North African campaign during World War II who takes charge of a hopelessly out-numbered Australian unit against the indomitable German field marshal, Erwin Rommel, who was portrayed by Mason. The film received generally good reviews from critics in London, although they complained the British contribution to the campaign had been minimised. The critic from "Variety" magazine thought Burton was "excellent" while "The New York Times" reviewer noted his "electric portrayal of the hero" made the film look "more than a plain, cavalier apology." Burton and Sybil became good friends with Mason and his wife Pamela Mason, and stayed at their residence until Burton returned home to England in June 1953 for playing Prince Hamlet as a part of The Old Vic 1953–54 season. This was to be the first time in his career he took up the role.
Burton's second and final film of the year was in the Biblical epic historical drama, "The Robe", notable for being the first ever motion picture to be made in CinemaScope. He replaced Tyrone Power, who was originally cast in the role of Marcellus Gallio, a noble but decadent Roman military tribune in command of the detachment of Roman soldiers that were involved in crucifying Jesus Christ. Haunted by nightmares of the crucifixion, he is eventually led to his own conversion. Marcellus' Greek slave Demetrius (played by Victor Mature) guides him as a spiritual teacher, and his wife Diana (played by Jean Simmons) follows his lead. The film marked a resurgence and set a trend for Biblical epics such as "Ben-Hur" (1959). Based on Lloyd C. Douglas' 1942 historical novel of the same name, "The Robe" was well received at the time of its release, but contemporary reviews have been less favourable. The magazine "Variety" termed the performances of the lead cast "effective" and complemented the fight sequences between Burton and Jeff Morrow. Crowther believed that Burton was "stalwart, spirited and stern" as Marcellus. Among those who gave negative reviews were Jonathan Rosenbaum of the "Chicago Reader" who called "The Robe" a "pious claptrap", and Dennis Schwartz of Ozus' World Movie Reviews who wrote, "Burton is served a death sentence to be in such a turgid film, one that ranges from being creaky to silly to just plain vulgar." The film was a commercial success, grossing $17 million against a $5 million budget, and Burton received his second Best Actor nomination at the 26th Academy Awards.
Bolstered by "The Robe"'s box office collections, Zanuck offered Burton a seven-year, seven-picture $1 million contract, but he politely turned it down as he was planning to head home to portray "Hamlet" in The Old Vic. Zanuck threatened to force Burton into cutting the deal, but the duo managed to come to a compromise when Burton agreed to a less binding contract, also for seven years and seven films at $1 million, that would begin only after he returned from his stint at The Old Vic 1953–54 season. The incident spread like wildfire and his decision to walk out on a million dollar contract for a stipend of £150 a week at The Old Vic was met with both appreciation and surprise. Bragg believed Burton defied the studio system with this act when it would have been tantamount to unemployment for him. Gossip columnist Hedda Hopper considered Burton's success in his first three films in Hollywood to be "the most exciting success story since Gregory Peck's contracts of ten years back".
At a party held in Simmons' residence in Bel Air, Los Angeles to celebrate the success of "The Robe", Burton met Elizabeth Taylor for the first time in his life. Taylor, who at the time was married to actor Michael Wilding and was pregnant with their first child, recalled her first impression of Burton being "rather full of himself. I seem to remember that he never stopped talking, and I had given him the cold fish eye." Hamlet was a challenge that both terrified and attracted him, as it was a role many of his peers in the British theatre had undertaken, including Gielgud and Olivier. He shared his anxiety with de Havilland whilst coming to terms with her. Bogart too, didn't make it easy for him when he retorted: "I never knew a man who played "Hamlet" who didn't die broke."
Notwithstanding, Burton began his thirty-nine week tenure at The Old Vic by rehearsing for "Hamlet" in July 1953, with Philip providing expert coaching on how to make Hamlet's character match Burton's dynamic acting style. Burton reunited with Bloom, who played Ophelia. "Hamlet" opened at the Assembly Hall in Edinburgh, Scotland on September 1953 as part of The Old Vic season during the Edinburgh Festival Fringe. The play and Burton's Hamlet were, on the whole, well received, with critics describing his interpretation of the character as "moody, virile and baleful" and that he had "dash, attack and verve". Burton's Hamlet was quite popular with the young audience, who came to watch the play in numbers as the were quite taken with the aggressiveness with which he portrayed the role. Burton also received appreciation from Winston Churchill. Gielgud was not too happy with Burton's Hamlet and asked him while both were backstage: "Shall I go ahead and wait until you're better?... ah, I mean ready?". Burton picked up the hint and infused some of Gielgud's traits to his own in later performances as Hamlet. A greater success followed in the form of the Roman General Gaius Marcius Coriolanus in "Coriolanus". Initially, Burton refused to play Coriolanus as he didn't like the character's initial disdain for the poor and the downtrodden. Michael Benthall, who was renowned for his association with Tyrone Guthrie in a previous production of "Hamlet" in 1944, sought Philip's help to entice Burton into accepting it. Philip convinced Burton by making him realise that it was Coriolanus' "lack of ambivalence" which made him an admirable character. Burton received even better reviews for Coriolanus than Hamlet. Hardy thought Burton's Hamlet was "too strong" but that "His Coriolanus is quite easily the best I've ever seen". Olivier too agreed it was the greatest Coriolanus he had ever seen till then.
The other roles he essayed for the season were Sir Toby Belch in "Twelfth Night", Caliban in "The Tempest" and Philip of Cognac in "King John". All five of Burton's plays were directed by Benthall; three of those plays featured Bloom. While Belch was considered "disappointing" due to Burton not putting on the proper make-up for the part, his reviews for Caliban and Philip of Cognac were positive. Alpert believed Burton's presence made the 1953–54 season of The Old Vic a commercial success. Burton was an ardent admirer of poet Dylan Thomas since his boyhood days. On the poet's death on 9 November 1953, he wrote an essay about him and took the time to do a 1954 BBC Radio play on one of his final works, "Under Milk Wood", where he voiced the First Voice in an all-Welsh cast. The entire cast of the radio play, including Burton, did their roles free of charge. Burton reprised his role in the play's 1972 film adaptation with Taylor. Burton was also involved in narrating Lindsay Anderson's short documentary film about The Royal School for the Deaf in Margate, "Thursday's Children" (1954).
Setback in film career and on-stage fame (1955–1959).
After The Old Vic season ended, Burton's contract with Fox required him to do three more films. The first was "Prince of Players" (1955). Burton was cast as the 19th-century Shakespearean actor Edwin Booth, the brother of John Wilkes Booth, the man who assassinated President Abraham Lincoln. Philip thought the script was "a disgrace" to Burton's name. The film's director Philip Dunne observed, "He hadn't mastered yet the tricks of the great movie stars, such as Gary Cooper, who knew them all. The personal magnetism Richard had on the sound stage didn't come through the camera." This was one aspect that troubled Richard throughout his career on celluloid. The film flopped at the box office and has since been described as "the first flop in CinemaScope". Crowther, however, lauded Burton's scenes where he performed Shakespeare plays such as Richard III.
Shortly after the release of "Prince of Players", Burton met director Robert Rossen, who was well-known at the time for his Academy Award winning film, "All the King's Men" (1949). Rossen planned to cast Burton in "Alexander the Great" (1956) as the eponymous character. Burton accepted Rossen's offer after the director reassured him he had been studying the Macedonian king for two years to make sure the film was historically accurate. Burton was loaned by Fox to the film's production company United Artists, which paid Burton a fee of $100,000. "Alexander the Great" was made mostly in Spain during February 1955 and July 1955 on a budget of $6 million. The film reunited Burton with Bloom and it was also the first film he made with her. Bloom played the role of Barsine, the daughter of Artabazos II of Phrygia, and one of Alexander's three wives. Fredric March, Danielle Darrieux, Stanley Baker, Michael Hordern and William Squire were respectively cast as Philip II of Macedon, Olympias, Attalus, Demosthenes and Aeschines.
After the completion of "Alexander the Great", Burton had high hopes for a favourable reception of the "intelligent epic", and went back to complete his next assignment for Fox, Jean Negulesco's "The Rains of Ranchipur" (1955). In this remake of Fox's own 1939 film "The Rains Came", Burton played a Hindu doctor, Rama Safti, who falls in love with Lady Edwina Esketh (Lana Turner), an invitee of the Maharani of the fictional town of Ranchipur. Burton faced the same troubles with playing character roles as before with Belch. "The Rains of Ranchipur" released on 16 December 1955, three moths before "Alexander the Great" rolled out in 28 March 1956. Contrary to Burton's expectations, both the films were critical and commercial failures, and he rued his decision to act in them. The "Time" magazine critic derided "The Rains of Ranchipur" and even went as far as to say Richard was hardly noticeable in the film. A. H. Weiler of "The New York Times", however, called Burton's rendering of Alexander "serious and impassioned".
Burton returned to The Old Vic to perform "Henry V" for a second time. The Benthall-directed production opened in December 1955 to glowing reviews and was a much-needed triumph for Burton. Tynan made it official by famously saying Burton was now "the next successor to Olivier". The reviewer from "The Times" began by pointing out the deficiencies in Burton's previous rendition of the character in 1951 before stating as quoted in Bragg's biography of Burton:
In January 1956, the free daily newspaper, "London Evening Standard" honoured Burton by presenting to him its Theatre Award for Best Actor for his portrayal of Henry V. His success in and as Henry V led him to be called the "Welsh Wizard". "Henry V" was followed by Benthall's adaptation of "Othello" in February 1956, where he alternated on successive openings between the roles of Othello and Iago with John Neville. As Othello, Burton received both praise for his dynamism and criticism with being less poetical with his dialogues, while he was acclaimed as Iago.
His stay at The Old Vic was cut short when he was approached by the Italian neorealist director Roberto Rossellini for Fox's "Sea Wife" (1957), a drama set in World War II about a nun and three men marooned on an island after the ship they travel on is torpedoed by a U-boat. Joan Collins, who played the nun, was his co-star. Burton's role was that of an RAF officer who develops romantic feelings for the nun. Rossellini was informed by Zanuck not to have any kissing scenes between Burton and Collins, which Rossellini found unnatural; this led to him walking out of the film and being replaced by Bob McNaught, one of the executive producers. According to Collins, Burton had a "take-the-money-and-run attitude" toward the film. "Sea Wife" was not a successful venture, with biographer Munn observing that his salary was the only positive feature that came from the film. Philip saw it and said he was "ashamed" that it added another insult to injury in Burton's career.
After "Sea Wife", Burton next appeared as the British Army Captain Jim Leith in Nicholas Ray's "Bitter Victory" (1957). Burton admired Ray's "Rebel Without A Cause" (1955) and was excited about working with him, but unfortunately, "Bitter Victory" tanked as well despite positive feedback. By mid-1957, Burton had no further offers in his kitty. He couldn't return to England due to his self-imposed exile from taxation, and his fortunes in film were dwindling. It was then that film producer and screenwriter Milton Sperling offered Burton to star alongside Helen Hayes and Susan Strasberg in Patricia Moyes' adaptation of Jean Anoulih's play, "Time Remembered" ("Léocadia" in the original French version). Sensing an opportunity for a career resurgence, Burton readily agreed to do the role of Prince Albert, who falls in love with a milliner named Amanda (Strasberg). It was on 10 September 1957, a day before he left for New York that Sybil gave birth to their first child, Kate Burton. "Time Remembered" was well received on its opening nights at Broadway's Morosco Theatre and also at the National Theatre in Washington, D.C.. The play went on to have a good run of 248 performances for six months. Burton received his first Tony Award for Best Actor in a Play nomination while Hayes won her second Tony Award for Best Actress in a Play for her role as Burton's mother, The Duchess of Pont-Au-Bronc.
In 1958, Burton appeared with Yvonne Furneaux in DuPont Show of the Month's 90-minute television adaptation of Emily Brontë's classic novel "Wuthering Heights" as Heathcliff. The film, directed by Daniel Petrie, aired on 9 May 1958 on CBS with Burton garnering plaudits from both the critics and Philip, who thought he was "magnificent" in it.
Burton next featured as Jimmy Porter, "an angry young man" role, in the film version of John Osborne's play "Look Back in Anger" (1959), a gritty drama about middle-class life in the British Midlands, directed by Tony Richardson, again with Claire Bloom as co-star. Biographer Bragg observed that "Look Back in Anger" "had defined a generation, provided a watershed in Britain's view of itself and brought into the public prints as a controversial, dangerous figure." Burton was able to identify himself with Porter, finding it "fascinating to find a man who came presumably from my sort of class, who actually could talk the way I would like to talk." The film and Burton's performance received mixed reviews upon release. Biographer Alpert noted that though reviews in England were favourable, those in the United States were more negative. Crowther wrote of Burton: "His tirades are eloquent but tiring, his breast beatings are dramatic but dull and his occasional lapses into sadness are pathetic but endurable." Both Geoff Andrew of "Time Out" magazine and Schwartz felt Burton was too old for the part, and the "Variety" reviewer thought "the role gives him little opportunity for variety." Contemporary reviews for the film have been better and it has a rating of 89% on the review aggregator website Rotten Tomatoes. "Look Back in Anger" is now considered one of the defining films of the British New Wave cinema, a movement from the late 1950s to the late 1960s in which working-class characters became the focus of the film and conflict of social classes a central theme. Jimmy Porter is also considered as one of Burton's best on-screen roles; he was nominated in the Best Actor categories at the BAFTA and Golden Globe Awards but lost to Peter Sellers for "I'm All Right Jack" (1959) and Anthony Franciosa for "Career" (1959) respectively. Though it didn't do well commercially, Burton was proud of the effort and wrote to Philip, "I promise you that there isn't a shred of self-pity in my performance. I am for the first time ever looking forward to seeing a film in which I play". While filming "Look Back in Anger", Burton did another play for BBC Radio, participating in two versions, one in Welsh and another in English, of Welsh poet Saunders Lewis' "Brad", which was about the 20 July plot. Burton voiced one of the conspirators, Caesar von Hofacker.
"Camelot", "Hamlet", Elizabeth Taylor and mainstream film acclaim (1960–1969).
In 1960, Burton appeared in two films for Warner Bros., neither of which were successful: "The Bramble Bush" which reunited him with his "Wuthering Heights" director Petrie, and Vincent Sherman's adaptation of Edna Ferber's "Ice Palace". Burton called the latter a "piece of shit". He received a fee of $125,000 for both films. While completing his parts for both pictures, Sybil gave birth to their second child, Jessica Burton. Burton's next appearance was as the stammering secularist, George Holyoake in BBC's documentary-style television adaptation of John Osborne's "A Subject of Scandal and Concern". According to Osborne's biographer Luc Gilleman, the film garnered little attention. Burton returned to the United States to complete filming on John Frankenheimer's television adaptation of Ernest Hemingway's "The Fifth Column". He also provided narration for 26 episodes of "The Valiant Years", a series by the American Broadcasting Company (ABC) based on Winston Churchill’s memoirs.
Burton made a triumphant return to the stage with Moss Hart's 1960 Broadway production of "Camelot" as King Arthur. The play, written by Alan Jay Lerner and Frederick Loewe, had Julie Andrews fresh from her triumph in "My Fair Lady" playing Guenevere, and Robert Goulet as Lancelot completing the love triangle. Roddy McDowall played the villainous Mordred. Hart first came up with the proposal to Burton after learning from Lerner about his ability to sing. Burton consulted Olivier on whether he should take the role, which came with a stipend of $4,000 a week. Olivier pointed out his salary was good and that he can carry on with accepting the offer. The production was troubled, with both Loewe and Hart falling ill and the pressure building up due to great expectations and huge advance sales. The show's running time was nearly five hours. Burton's intense preparation and competitive desire to succeed served him well. He immediately drafted Philip, who revised the musical's script and cut its running time to three hours while also incorporating three new songs. Burton was generous and supportive to everyone throughout the production and coached the understudies himself. According to Lerner, "he kept the boat from rocking, and "Camelot" might never have reached New York if it hadn't been for him." Burton's reviews were excellent, with the critic from "Time" magazine observing that Richard "gives Arthur the skilful and vastly appealing performance that might be expected from one of England's finest young actors." Broadway theatre reviewer Walter Kerr noted Richard's syllables, "sing, the account of his wrestling the stone from the sword becomes a bravura passage of house-hushing brilliance" and complemented his duets with Andrews, finding Burton's rendition to possess "a sly and fretful and mocking accent to take care of the without destroying the man."
The play on the whole, however, initially received mixed reviews on its opening at the Majestic Theatre in Broadway and made a slow start in raking the moolah. The advance sales managed to keep "Camelot" running for three months until a twenty-minute extract was broadcast on "The Ed Sullivan Show". The show helped "Camelot" achieve great success and an unprecedented three-year run overall from 1960 to 1963. The success of "Camelot" lead to Burton being coined the term "The King of Broadway", and he went on to receive the Tony Award for Best Actor in a Musical. The original soundtrack of the musical topped the "Billboard" charts throughout 1961 after its release in the end of 1960. John F. Kennedy, who was then the President of the United States, reportedly enjoyed the play and invited Burton for a visit to the White House. In 1962, Burton appeared as Officer David Campbell, an RAF fighter pilot in the large ensemble cast of "The Longest Day", which included McDowall, George Segal, Henry Fonda, John Wayne, Mel Ferrer, Robert Mitchum, Rod Steiger and Sean Connery. The same year he provided narration for the Jack Howells documentary "Dylan Thomas". The short won the Best Documentary Short Subject at the 35th Academy Awards ceremony.
After performing "Camelot" for six months, in July 1961, Burton was met by producer Walter Wanger to replace Stephen Boyd as Mark Antony in director Joseph L. Mankiewicz's magnum opus "Cleopatra". Burton was paid $250,000 for four months work in the film. The gigantic scale of the film's troubled production, Taylor's bouts of illness and fluctuating weight, the off-screen relationship between Burton and Taylor for which Burton gave the sardonic nickname "Le Scandale"—all generated enormous publicity, with "Life" proclaiming it the "Most Talked About Movie Ever Made". Fox's future appeared to hinge on what became the most expensive movie ever made until then, reaching almost $40 million. During filming, Burton met and fell in love with Elizabeth Taylor, who was then married to Eddie Fisher. According to Alpert, at their first meeting on the set while posing for their publicity photographs, Burton said, "Has anyone ever told you that you're a very pretty girl?" Taylor later recalled, "I said to myself, "Oy gevalt", here's the great lover, the great wit, the great intellectual of Wales, and he comes out with a line like that." Bragg contradicts Alpert by pointing out that Burton could not stand Taylor at first, calling her "Miss Tits" and opined to Mankiewicz, "I expect she shaves"; he saw her simply as another celebrity with no acting talent. All that changed when in their first scene together, Burton was shaky and forgot his lines, and she soothed and helped him; it was at this instance, according to Taylor, that she fell for him. Soon the affair began in earnest; both Fisher and Sybil were unable to bear it. While Fisher fled the sets for Gstaad, Sybil went first for Celigny and then headed off to London. Olivier, shocked by Burton's affair with Taylor, cabled him: "Make up your mind, dear heart. Do you want to be a great actor or a household word?". Burton replied "Both".
"Cleopatra" finally released on 11 June 1963 with a runtime of 243 minutes to polarising reviews. The "Time" magazine critic found the film, "raddled with flaws, style both in image and in action." and that Burton "staggers around looking ghastly and spouting irrelevance". In a contradictory review, Crowther termed the film "generally brilliant, moving, and satisfying" and thought Burton was "exciting as the arrogant Antony". Richard Brody of "The New Yorker" commented positively on the chemistry between Burton and Taylor, describing it as "entrancing in the movie’s drama as it was in life." "Cleopatra" grossed over $26 million, becoming one of the highest grossing films of 1963. It was not enough to prevent Fox from entering bankruptcy. The studio sued Burton and Taylor for allegedly damaging the film's prospects at the box office with their behaviour, but it proved unsuccessful. "Cleopatra" was nominated for nine Academy Awards, winning for Best Production Design, Best Costume Design and Best Visual Effects.
The film marked the beginning of a series of collaborations with Taylor, in addition to making Burton one of the Top 10 box office draws until 1967. Burton played Taylor's tycoon husband Paul Andros in Anthony Asquith's "The V.I.P.s" (1963), an ensemble cast film described by Alpert as a "kind of "Grand Hotel" story" that was set in the VIP lounge of London Heathrow Airport; it proved to be a box-office hit despite mixed reviews. It was after "The V.I.P.s" that Burton became considerably more selective about his roles crediting Taylor for it as he simply acted in films "to get rich" and that she "made me see what kind of rubbish I was doing." Burton and Taylor divorced their spouses in April 1963 after completing "The V.I.P.s"; Taylor subsequently took a two-year hiatus from films until her next venture with Burton, "The Sandpiper" (1965). The supercouple, now dubbed "Liz and Dick" by the press, continued starring together in films in the mid-1960s, earning a combined $88 million over the next decade and spending $65 million of them. Regarding their earnings, Burton, in a 1976 interview with Lester David and Jhan Robbins of "The Ledger", stated that "they say we generate more business activity than one of the smaller African nations" and that the couple "often outspent" the Greek business tycoon Aristotle Onassis.
In 1964, Burton portrayed Thomas Becket, the Archbishop of Canterbury who was martyred by Henry II of England, in Jean Anouilh's film adaptation of "Becket". Both Alpert and historian Alex von Tunzelmann noted Burton gave an effective, restrained performance, contrasting with co-actor and friend Peter O'Toole's manic portrayal of Henry. Burton requested the film's director, Peter Glenville, not to oust him out of the project like he had previously done so for "Adventure Story" before accepting the role of Becket. Writing for "The Christian Science Monitor", Peter Rainer labelled Burton as "extraordinary". Kenneth Turan of the "Los Angeles Times" appreciated Burton's on-screen chemistry with O'Toole and thought his portrayal of Becket served as "a reminder of how fine an actor Burton was". The film received twelve Oscar nominations, including Best Actor for both Burton and O'Toole; they lost to Harrison for "My Fair Lady" (1964). Burton and O'Toole also received nominations for Best Actor – Motion Picture Drama at the 22nd Golden Globe Awards, with O'Toole emerging victorious. Burton's triumph at the box office continued with his next appearance as the defrocked clergyman Dr. T. Lawrence Shannon in Tennessee Williams' "The Night of the Iguana" (1964) directed by John Huston; the film was also critically well received. Alpert believed Burton's success was due to how well he varied his acting with the three female characters, each of whom he tries to seduce differently: Ava Gardner (the randy hotel owner), Sue Lyon (the nubile American tourist), and Deborah Kerr (the poor, repressed artist). The success of "Becket" and "The Night of the Iguana" led "Time" magazine to term him "the new Mr. Box Office".
During the production of "Becket", Burton went to watch Gielgud perform in the 1963 stage adaptation of Thornton Wilder's 1948 novel, "The Ides of March". There he was confronted by Gielgud who asked what Burton planned to do as a part of the celebration of Shakespeare's quatercentenary. Burton told him he was approached by theatrical producer Alexander H. Cohen to do "Hamlet" in New York City. Burton had accepted Cohen's offer under the condition that Gielgud would direct it, which he convened to him. Gielgud agreed and soon production began in January 1964 after Burton had completed his work in "Becket" and "The Night of the Iguana". Taking into account Burton's dislike for wearing period clothing as well as fellow actor Harley Granville-Barker’s notion that the play was best approached as a “permanent rehearsal”, Gielgud decided for "Hamlet" to be performed in a 'rehearsal' version with an incomplete set and the actors can wear their own clothes. Unaccustomed to the freedom of wearing their own clothes to perform on stage, the cast members found it hard to select the appropriate clothes and wore different attire day by day. After the first performance in Toronto, Gielgud decreed that the actors must wear capes as he felt it "lacked colour". In addition to being the play's director, Gielgud appeared as the Ghost of Hamlet's father. According to Gielgud's biographer Jonathan Croall, Burton's basic reading of Hamlet was "a much more vigorous, extrovert" version of Gielgud's own performance in 1936. Burton varied his interpretations of the character in later performances; he even tried a homosexual Hamlet.
When the play debuted at the Lunt-Fontanne Theatre in New York City, Burton garnered good reviews for his portrayal of a "bold and virile" Hamlet. Howard Taubman of "The New York Times" called it "a performance of electrical power and sweeping virility." and that he had never known or seen "a Hamlet of such tempestuous manliness." A critic from "Time" magazine said that Burton "put his passion into Hamlet's language rather than the character. His acting is a technician's marvel. His voice has gem-cutting precision." Walter Kerr felt that though Burton carried "a certain lack of feeling" in his performance, he appreciated Burton's "reverberating" vocal projections. The opening night party was a lavish affair, attended by six hundred celebrities. The play ran for 137 performances, beating the previous record set by Gielgud himself in 1936. The most successful aspect of the production apart from Burton's performance was generally considered to be Hume Cronyn's performance as Polonius, winning Cronyn the only Tony Award he would ever receive in a competitive category. Burton himself was nominated for his second Tony Award for Best Actor in a Play but lost to Alec Guinness for his portrayal of the poet Dylan Thomas. The performance was immortalised in a film that was created by recording three live performances on camera from 30 June 1964 to 1 July 1964 using a process called Electronovision; it played in US theatres for a week in 1964. The play was also the subject of books written by cast members William Redfield and Richard L. Sterne.
Burton helped Taylor make her stage debut for "A Poetry Reading", a recitation of poems by the couple as well as anecdotes and quotes from the plays Burton had participated thus far. The idea was conceived by Burton as a benefit performance for his mentor Philip, whose conservatory, the American Musical and Dramatic Academy, had fallen short of funds. "A Poetry Reading" opened at the Lunt-Fontanne on 21 June 1964 to a packed house; the couple received a standing ovation at the end of their performance. Burton remarked on Taylor's performance, "I didn't know she was going to be this good."
After "Hamlet" came to a close in August 1964, Burton and Taylor continued making films together. The first film after their marriage was "The Sandpiper", was poorly received but still became a commercially successful venture. According to Bragg, the films they made during this period contained a lot of innuendos that referred directly to their private lives and the couple used this tactic as a means to profit from their collaborations. Following "The Sandpiper", Burton and Taylor enjoyed their greatest success in Mike Nichols's 1966 film version of the Edward Albee play "Who's Afraid of Virginia Woolf?", in which a bitter erudite couple spend the evening trading vicious barbs in front of their guests, Nick (George Segal) and Honey (Sandy Dennis). Burton was not the first choice for the role of Taylor's husband. Jack Lemmon was offered the role first, but when he backed out, Jack L. Warner, with Taylor's insistence, agreed on Burton and paid him his price. Albee preferred Bette Davis and James Mason, fearing that the Burtons' strong screen presence would dominate the film. Nichols, in his directorial debut, managed the Burtons brilliantly. The script, adapted from Albee's play by Hollywood veteran Ernest Lehman, broke new ground for its raw language and harsh depiction of marriage. Although all four actors received Oscar nominations for their roles in the film (the film received a total of thirteen), only Taylor and Dennis went on to win. So immersed had the Burtons become in the roles of George and Martha over the months of shooting that, after the wrap, Richard Burton said, "I feel rather lost." Later the couple would state that the film took its toll on their relationship, and that Taylor was "tired of playing Martha" in real life. Their lively version of Shakespeare's "The Taming of the Shrew" (1967), directed by Franco Zeffirelli, was a notable success. Later collaborations, however, "The Comedians" (1967), "Boom!" (1968), and the Burton-directed "Doctor Faustus" (1967) (which had its genesis from a theatre production he staged and starred in at the Oxford University Dramatic Society), were critical and commercial failures. Another box office failure was the 1969 film "Staircase", in which he and his "Cleopatra" co-star Rex Harrison appeared as a bickering homosexual couple. His fee for "Staircase", $1.25 million (equivalent to approximately $ in today's funds) plus a share of the gross, made him the highest-paid actor in the world.
He did enjoy a final commercial blockbuster with Clint Eastwood in the 1968 World War II picture "Where Eagles Dare", a major hit in 1969, for which he received a $1 million fee plus a share of the gross. His last film of the decade, "Anne of the Thousand Days" (1969), was a commercial and critical disappointment. In spite of those failures, it performed remarkably well at that year's Academy awards (receiving ten nominations, including one for Burton's performance as Henry VIII), which many thought to be largely the result of an expensive advertising campaign by Universal Studios.
Later career.
Because of Burton and Taylor's extravagant spending and his support of his family and others (42 people at one point), Burton agreed to work in mediocre films, which hurt his career. He recognised his financial need to do so, and that in the New Hollywood era of cinema, neither he nor Taylor would be paid as well as at the height of their stardom. Films he made during this period included "Bluebeard" (1972), "Hammersmith Is Out" (1972), "The Klansman" (1974), and "" (1977). He did enjoy one major critical success in the 1970s in the film version of his stage hit "Equus", winning the Golden Globe Award as well as an Academy Award nomination. Public sentiment towards his perennial frustration at not winning an Oscar made many pundits consider him the favourite to finally win the award, but on Oscar Night he lost to Richard Dreyfuss in "The Goodbye Girl".
In 1976 Burton received a Grammy in the category of Best Recording for Children for his narration of "The Little Prince" by Antoine de Saint-Exupéry. He also found success in 1978, when he narrated "Jeff Wayne's Musical Version of The War of the Worlds". His distinctive performance became a necessary part of the concept album – so much so that a hologram of Burton was used to narrate the live stage show (touring in 2006, 2007, 2009 and 2010) of the musical. In 2011, however, Liam Neeson was cast in the part for a "next generation" rerecording, and subsequently also replaced Burton as the hologram character in the stage show.
Burton had an international box-office hit with "The Wild Geese" (1978), an adventure tale about mercenaries in Africa. The film was a success in the UK and Europe but had only limited distribution in the U.S. owing to the collapse of the studio that funded it and the lack of an American star in the movie. He returned to films with "The Medusa Touch" (1978), "Circle of Two" (1980), and the title role in "Wagner" (1983), a role he said he was born to play, after his success in "Equus". His last film performance, as O'Brien in "Nineteen Eighty-Four", was critically acclaimed, though he was not the first choice for the part. According to the film's director, Michael Radford, Paul Scofield was originally contracted to play the part, but had to withdraw due to a broken leg, then Sean Connery, Marlon Brando and Rod Steiger were all approached before Burton was cast. He had "heard stories" about Burton's heavy drinking, which had concerned the producers.
At the time of his death, Burton was preparing to film "Wild Geese II", the sequel to "The Wild Geese", which was eventually released in 1985. Burton was to reprise the role of Colonel Faulkner, while his friend Sir Laurence Olivier was cast as Rudolf Hess. After his death, Burton was replaced by Edward Fox, and the character changed to Faulkner's younger brother.
Personal life and views.
Burton was married five times and he had four children. From 1949 until their divorce in 1963, he was married to Welsh actress/producer Sybil Williams, with whom he had two daughters, Katherine "Kate" Burton (born 10 September 1957) and Jessica Burton (born 1959). He was married twice, consecutively, to actress Elizabeth Taylor, from 15 March 1964 to 26 June 1974 and from 10 October 1975 to 29 July 1976. Their first wedding was at the Ritz-Carlton Hotel in Montreal. Ever optimistic, Taylor proclaimed, "I'm so happy you can't believe it. This marriage will last forever". Their second wedding occurred, 16 months after their divorce, in Chobe National Park in Botswana. In 1964, the couple adopted a daughter from Germany, Maria Burton (born 1 August 1961). Burton adopted Taylor's daughter by the late producer Mike Todd, Elizabeth Frances "Liza" Todd Burton (born 6 August 1957).
The relationship Burton and Taylor portrayed in the film "Who's Afraid of Virginia Woolf?" was popularly likened to their real-life marriage. Burton disagreed with others about Taylor's famed beauty, saying that calling her "the most beautiful woman in the world is absolute nonsense. She has wonderful eyes, but she has a double chin and an overdeveloped chest, and she's rather short in the leg." In August 1976, a month after his second divorce from Taylor, Burton married model Suzy Miller, the former wife of Formula 1 Champion James Hunt; the marriage ended in divorce in 1982. From 1983 until his death in 1984, Burton was married to make-up artist Sally Hay. In 1957 Burton had altogether earned £82,000 from "Prince of Players", "The Rains of Ranchipur" and "Alexander the Great", but only managed to keep £6,000 for personal expenses due to taxation regulations imposed by the then-ruling Conservative Party. As a result, he consulted with his lawyer, Aaron Frosch, who suggested he move to Switzerland where the tax payment was comparatively less. Burton acceded to Frosch's suggestion and moved with Sybil in January 1957 to Céligny, Switzerland where he purchased a villa. The Government didn't taking his leaving England too well, more so when Burton remarked "I believe that everyone should pay them —except actors." Burton lived in Céligny until his death. In 1968 Burton's elder brother, Ifor, slipped and fell, breaking his neck, after a lengthy drinking session with Burton in Céligny. The injury left him paralysed from the neck down. His younger brother Graham Jenkins opined it may have been guilt over this that caused Burton to start drinking very heavily, particularly after Ifor died in 1973.
In a February 1975 interview with his friend David Lewin he said he "tried" homosexuality. He also suggested that perhaps all actors were latent homosexuals, and "we cover it up with drink". In 2000, Ellis Amburn's biography of Elizabeth Taylor suggested that Burton had an affair with Laurence Olivier and tried to seduce Eddie Fisher, although this was strongly denied by Burton's younger brother Graham Jenkins.
Burton was a heavy smoker from the time he was just eight years old; and by his own admission in a December 1977 interview with Sir Ludovic Kennedy, Burton was smoking 60–100 cigarettes per day. According to his younger brother, as stated in Graham Jenkins's 1988 book "Richard Burton: My Brother", he smoked at least a hundred cigarettes a day. His father, also a heavy drinker, refused to acknowledge his son's talents, achievements and acclaim. In turn, Burton declined to attend the funeral, when his father died from a cerebral haemorrhage in January 1957 at age 81.
Burton admired and was inspired by the actor and dramatist Emlyn Williams. He employed his son, Brook Williams, as his personal assistant and adviser and he was given small roles in some of the films in which Burton starred.
Burton was banned permanently from BBC productions in November 1974 for writing two newspaper articles questioning the sanity of Winston Churchill and others in power during World War II – Burton reported hating them "virulently" for the alleged promise to wipe out all Japanese people on the planet. The publication of these articles coincided with what would have been Churchill's centenary, and came after Burton had played him in a favourable light in "A Walk with Destiny", with considerable help from the Churchill family. Politically Burton was a lifelong socialist, although he was never as heavily involved in politics as his close friend Stanley Baker. He admired Democratic Senator Robert F. Kennedy and once got into a sonnet-quoting contest with him. In 1973 Burton agreed to play Josip Broz Tito in a film biography, since he admired the Yugoslav leader. While filming in Yugoslavia he publicly proclaimed that he was a communist, saying he felt no contradiction between earning vast sums of money for films and holding left-wing views since "unlike capitalists, I don't exploit other people."
Burton courted further controversy in 1976 when he wrote an unsolicited article for "The Observer" about his friend and fellow Welsh thespian Stanley Baker, who had recently died from pneumonia at the age of 48; the article upset Baker's widow with its depiction of her late husband as an uncultured womaniser.
Melvyn Bragg, in the notes of his "Richard Burton: A Life", says that Burton told Laurence Olivier around 1970 of his own (unfulfilled) plans to make his own film of "Macbeth" with Elizabeth Taylor, knowing that this would hurt Olivier because he had failed to gain funding for his own cherished film version more than a decade earlier.
On his religious views, Burton was an atheist, stating, "I wish I could believe in a God of some kind but I simply cannot."
Health issues.
Burton was an alcoholic who reportedly nearly died in 1974 from an excess of drinking. According to biographer Robert Sellers, "At the height of his boozing in the mid-70s he was knocking back three to four bottles of hard liquor a day."
After drinking himself nearly to death during the shooting of "The Klansman" (1974), Burton was dried out at Saint John's Health Center in Santa Monica, California. Burton allegedly was so inebriated while making the picture that many of his scenes had to be filmed with him sitting or lying down due to his inability to stand. In some scenes, he appears to slur his words or speak incoherently. According to his own diaries, subsequently he used Antabuse to try to stop his excessive drinking, which he blamed for wrecking his marriage to Elizabeth Taylor. Burton himself said of the time leading up to his near loss of life, "I was fairly sloshed for five years. I was up there with John Barrymore and Robert Newton. The ghosts of them were looking over my shoulder."
Burton said that he turned to the bottle for solace "to burn up the flatness, the stale, empty, dull deadness that one feels when one goes offstage."
The 1988 biography of Burton by Melvyn Bragg provides a detailed description of the many health issues that plagued Burton throughout his life. In his youth, Burton was a star athlete and well known for his athletic abilities and strength.
By the age of 41 he had declined so far in health that his arms were by his own admission thin and weak. He suffered from bursitis, possibly aggravated by faulty treatment, arthritis, dermatitis, cirrhosis of the liver, and kidney disease, as well as developing, by his mid-forties, a pronounced limp. How much of this was due to his intake of alcohol is impossible to ascertain, according to Bragg, because of Burton's reluctance to be treated for alcohol addiction; however, in 1974, Burton spent six weeks in a clinic to recuperate from a period during which he had been drinking three bottles of vodka a day. He was also a chain smoker, with an intake of between three and five packs a day for most of his adult life. Health issues continued to plague him until his death of a stroke at the age of 58.
Death.
Burton died at age 58 from a brain haemorrhage on 5 August 1984 at his home in Céligny, Switzerland, and is buried there. Although his death was sudden, his health had been declining for several years, and he suffered from constant and severe neck pain. He had been warned that his liver was enlarged as early as March 1970, and had been diagnosed with cirrhosis of the liver and kidney disease in April 1981. Burton was buried in a red suit, a tribute to his Welsh roots, and with a copy of Dylan Thomas' poems. He and Taylor had discussed being buried together; his widow Sally purchased the plot next to Burton's and erected a large headstone across both, presumably to prevent Taylor from being buried there.
Honors.
For his contributions to cinema, Burton has a star on the Hollywood Walk of Fame at 6336 Hollywood Boulevard. For his contributions to theater, Burton was inducted into the Theater Hall of Fame.
Filmography, other works and awards.
Selected works, based on award nominations
External links.
!colspan="3" style="background:#C1D8FF;"| Husband of Elizabeth Taylor

</doc>
<doc id="45968" url="https://en.wikipedia.org/wiki?curid=45968" title="Tom Jones (singer)">
Tom Jones (singer)

Sir Thomas Jones Woodward OBE (born 7 June 1940) is a Welsh singer known by his stage name Tom Jones. He became one of the most popular vocalists to emerge from the mid-1960s. Since then, he has sung many forms of popular music – pop, rock, R&B, show tunes, country, dance, soul music and gospel – and sold over 100 million records.
Jones has had thirty-six Top 40 hits in the United Kingdom and nineteen in the United States; some of his notable songs include "It's Not Unusual", "What's New Pussycat", "Delilah", "Green, Green Grass of Home", "She's a Lady", "Kiss", and "Sex Bomb".
Jones was awarded an OBE in 1999 and received a knighthood from Queen Elizabeth II for "services to music" in 2006. He has received many other awards throughout his career, including the Grammy Award for Best New Artist in 1966, an MTV Video Music Award in 1989, and two Brit Awards, winning Best British Male in 2000 and Outstanding Contribution to Music in 2003. From 2012 to 2015 Jones was one of the four coaches on the BBC television talent show "The Voice UK".
Early life.
Jones was born Thomas John Woodward, at 57 Kingsland Terrace, Treforest, Pontypridd, in Glamorgan, South Wales. His parents were Thomas Woodward (died 5 October 1981), a coal miner, and Freda Jones (died 7 February 2003). Three of his grandparents were of English origin: his paternal grandfather, James Woodward, was an ironmonger's haulier from Gloucestershire, and his paternal grandmother was from Wiltshire. His maternal grandfather was Welsh, and his maternal grandmother, Ada Jones, was born in Pontypridd, to parents from Somerset and Wiltshire.
Jones attended Wood Road Infants School, Wood Road Junior School and Pontypridd Central Secondary Modern School. He began singing at an early age: He would regularly sing at family gatherings, weddings and in his school choir. Jones did not like school or sports, but gained confidence through his singing talent. At 12 he was diagnosed with tuberculosis. Many years later he said: "I spent two years in bed recovering. It was the worst time of my life." During convalescence he could do little else but listen to music and draw.
Jones's bluesy singing style developed out of the sound of American soul music. His early influences included blues and R&B singers Little Richard, Solomon Burke, Jackie Wilson and Brook Benton, as well as Elvis Presley, whom Jones idolised and with whom he would later become good friends.
In March 1957 Jones married his high school girlfriend, Linda Trenchard when they were expecting a child together, both aged 16. The couple's son, Mark, was born in the month following their wedding. To support his young family Jones took a job working in a glove factory and was later employed in construction.
Career.
Rise to fame.
Jones's voice has been described as a "full-throated, robust baritone". He became the frontman in 1963 for Tommy Scott and the Senators, a Welsh beat group. They soon gained a local following and reputation in South Wales. In 1964, the group recorded several solo tracks with producer Joe Meek, who took them to various labels, but they had little success. Later that year, Decca producer Peter Sullivan saw Tommy Scott and the Senators performing in a club and directed them to manager Phil Solomon, but the partnership was short-lived.
The group continued to play gigs at dance halls and working men's clubs in South Wales. One night at the Top Hat in Cwmtillery, Wales, Jones was spotted by Gordon Mills, a London-based manager who also originally hailed from South Wales. Mills became Jones's manager and took the young singer to London, and also renamed him Tom Jones, to exploit the popularity of the Academy Award winning 1963 film.
Eventually, Mills got Jones a recording contract with Decca. His first single, "Chills and Fever", was released in late 1964. It did not chart, but the follow-up, "It's Not Unusual", became an international hit after offshore pirate radio station Radio Caroline promoted it. The following year was the most prominent of Jones's career, making him one of the most popular vocalists of the British Invasion. In early 1965, "It's Not Unusual" reached No. 1 in the United Kingdom and the top ten in the United States. During 1965, Mills secured a number of film themes for Jones to record, including the themes for the film "What's New Pussycat?" (written by Burt Bacharach and Hal David) and for the James Bond film "Thunderball". Jones was also awarded the Grammy Award for Best New Artist for 1966. In Hollywood, Jones met Elvis Presley for the first time who he recalls singing his song as he walked towards him on set.
In 1966, Jones's popularity began to slip somewhat, causing Mills to reshape the singer's image into that of a crooner. Jones also began to sing material that appealed to a wider audience, such as the big country hit "Green, Green Grass of Home". The strategy worked, and Jones returned to the top of the charts in the UK and began hitting the Top 40 again in the US. For the remainder of the decade, he scored a string of hits on both sides of the Atlantic, including "I'll Never Fall in Love Again", "I'm Coming Home", and "Delilah" which all reached No. 2 in the UK chart.
Las Vegas.
In 1967, Jones performed in Las Vegas for the first time at the Flamingo. His performances and style of dress became part of his stage act, and increasingly featured his open, half-unbuttoned shirts and tight trousers. He soon chose to record less, instead concentrating on his lucrative club performances. His shows at Caesars Palace were a knicker-hurling frenzy of sexually charged adulation and good-time entertainment. Women started throwing hotel room keys onto the stage.
Jones and his idol Elvis Presley met in 1965 at the Paramount film stage, when Elvis was filming "Paradise, Hawaiian Style". They became good friends, spending more and more time together in Las Vegas and duetting until the early hours at Presley's private Las Vegas suite. The friendship endured until Presley's death in 1977. Jones's guitarist between 1969 and 1974 was Big Jim Sullivan, who also met and formed a friendship with Presley.
Jones played at least one week in Las Vegas every year until 2011.
Television and lawsuits.
Jones had an internationally successful television variety show titled "This Is Tom Jones" from 1969 to 1971. The ATV-produced show was worth a reported $9m to Jones over three years. It was broadcast by ITV in the UK and by ABC in America. As a result of the show, Jones was nominated in 1969 for a Golden Globe for "best actor". From 1980 to 1981, he had a second television variety show, "Tom Jones", that was produced in Vancouver, Canada, and lasted for 24 episodes.
In recent years, both television shows have been the subject of litigation with the original license holder C/F International. As of December 2004, C/F International was a secured judgment creditor of Classic World Productions and its principal, Darryl Payne, for approximately one million US dollars, and was the principal secured creditor at the time of the subsequent bankruptcy filing by the company. C/F International's action against Classic World Productions and owner Darryl Payne was based on unpaid royalties from "This Is Tom Jones" and related recordings. "This Is Tom Jones" is currently sold on DVD by Time Life rather than by Classic World Productions or C/F International.
C/F International's rights to later Tom Jones material were also disputed. In March 2007, Tom Jones and Tom Jones Enterprises sued C/F International to stop the company from licensing sound recordings made from the 1981 "Tom Jones" series. It was contended that any rights that C/F International had to license the "Tom Jones" show did not include the right to make and license separate recordings of the performances on the show, and that any rights that C/F International had in the "Tom Jones" show no longer existed because of numerous breaches of contract. Examples of contentious CDs are "Live on the Tom Jones Show", released in 2006, and "Greatest Hits Live", originally issued by C/F International in 1981 and later licensed to and issued by Prism Leisure Corporation as "30 Greatest Hits – Live in Concert".
Jones appeared on 31 December 1969, on the BBC's review of the 1960s music scene, "Pop Go The Sixties", performing "Delilah" (in a telerecording of an earlier appearance on "Top of the Pops").
In 1970, Jones teamed up with Raquel Welch and Producer/Choreographer David Winters of Winters-Rosen Productions for the television special "Raquel!". The multimillion-dollar television song and dance extravaganza was filmed around the world and included production numbers of classic songs from the era, lavish costumes, and guest performances from Jones, John Wayne, and Bob Hope.
Decline and resurgence.
In the 1970s, Jones toured with the female singing groups Quiet Elegance and the Blossoms as his backing groups. He had a number of hit singles, including "She's a Lady", "Till", and "The Young New Mexican Puppeteer", but in the mid-1970s his popularity declined. He did, however, have a big hit in 1976 with "Say You'll Stay Until Tomorrow", which went to No. 1 on the US country chart and No. 15 on the Billboard Hot 100.
In the early 1980s, Jones started to record country music. From 1980 to 1986, he had nine songs in the US country top 40, yet failed to crack the top 100 in the UK or the Billboard Hot 100. Jones's manager Gordon Mills died of cancer on 29 July 1986, and Jones's son Mark became his manager. In 1987, Tom Jones re-entered the singles chart with "A Boy From Nowhere", which went to No. 2 in the UK. The following year, he covered Prince's "Kiss" with Art of Noise. The song reached No. 5 in the UK and No. 31 in the US. The video for "Kiss" was much seen on MTV and VH1, and won the MTV Video Music Award for Breakthrough Video.
Jones received a star on the Hollywood Walk of Fame in 1989, located at 6608 Hollywood Boulevard, Los Angeles, California, in front of Frederick's of Hollywood. In 1992, he made his first appearance at the UK's Glastonbury Festival, and in 1993 he appeared as himself on episodes of "The Fresh Prince of Bel-Air" and "The Simpsons".
Jones signed with Interscope Records in 1993 and released the album "The Lead And How To Swing It". The first single, "If I Only Knew", went to No. 11 in the UK. Jones performed the song at the 1994 MTV Europe Music Awards, which he also served as host for. In 1997, Jones did the soundtrack for the comedy film "The Full Monty", recording "You Can Leave Your Hat On".
In 1999 Jones released the album "Reload", a collection of cover duets with artists such as the Cardigans, Natalie Imbruglia, Cerys Matthews, Van Morrison, Mousse T, Portishead, Stereophonics and Robbie Williams. The album went to No. 1 in the UK and sold over 4 million copies worldwide. Five singles from "Reload" hit the UK top 40. The single "Sex Bomb" was released in early 2000 and became the biggest single from the album, reaching No. 3 in the UK Singles Chart.
Into the 21st century.
United States President Bill Clinton invited Jones to perform on New Year's Eve at the 2000 millennium celebrations in Washington, D.C. Throughout 2000 Jones garnered a number of honours for his work including a BRIT Award for Best British Male. He was also hired as the new voice of Australia's National Rugby League, singing in an advertisement to market the 2000 season.
In 2002 Jones released the album "Mr. Jones", which was produced by Wyclef Jean. The album and the first single, "Tom Jones International", were top 40 hits in the UK.
Jones received the Brit Award for Outstanding Contribution to Music in 2003. The following year, he teamed up with pianist Jools Holland and released "Tom Jones & Jools Holland", a roots rock 'n' roll album. It peaked at No. 5 in the UK.
On 28 May 2005, in celebration of his approaching 65th birthday, Jones returned to his homeland to perform a concert in Ynysangharad Park, Pontypridd before a crowd of about 20,000. This was his first performance in Pontypridd since 1964. That same year the BBC reported that Jones was Wales's wealthiest entertainer, having amassed a fortune of £175 million. Jones collaborated with English-born Australian pop singer John Farnham in 2005 and released the live album "John Farnham & Tom Jones – Together in Concert". The following year Jones worked with Chicane and released the dance track "Stoned in Love", which went to No. 7 in the UK Singles Chart.
Jones, who was appointed an Officer of the Order of the British Empire (OBE) in 1999, was knighted by Elizabeth II in 2006 at Buckingham Palace for his services to music. "When you first come into show business and get a hit record, it is the start of something", Jones said. "As time goes by it just gets better. This is the best thing I have had. It's a wonderful feeling, a heady feeling."
2007–2009.
On 1 July 2007 Jones was among the invited artists who performed at Wembley Stadium at the Concert for Diana, joined on stage by guitarist Joe Perry of Aerosmith and British soul singer Joss Stone. In addition to performing some of his own songs the group covered Arctic Monkeys' "I Bet You Look Good on the Dancefloor". Jones, a boxing fan, has performed national anthems before a number of boxing matches. He sang "God Save the Queen", the United Kingdom's national anthem, before the Floyd Mayweather Jr.-Ricky Hatton fight in 2007; he sang "Hen Wlad Fy Nhadau", the Welsh national anthem, at the fight between fellow Welshman Joe Calzaghe and Bernard Hopkins in 2008; and he sang "God Save the Queen" before the Manny Pacquiao-Ricky Hatton fight in 2009.
In 2008 he released "24 Hours" on S-Curve Records, his first album of new material to be issued in the US for over 15 years. Jones, who was still performing over 200 dates a year as he approached his 70th birthday, set out on a world tour to promote the album. "The fire is still in me. Not to be an oldie, but a goodie. I want to be a contender", Jones said. In 2008 also Tom Jones was inducted into the Hit Parade Hall of Fame. On 16 November 2008 Jones was invited to perform on BBC's "Strictly Come Dancing". He performed the debut single from "24 Hours", "If He Should Ever Leave You", which was named the 9th best song of 2008 by Spinner. One of the songs from "24 Hours", "Give a Little Love", would later be featured in the first trailer for "Little Fockers".
In February 2009 he did an exclusive Take-Away Show with Vincent Moon, performing three songs live in front of a camera in a New York hotel room. In 2009 Jones was voted "Sexiest Man In The World" in the Hungarian magazine "Periodika".
In March 2009 Jones went to the top of the UK Music Charts for the third time in his career thanks to a cover of "Islands in the Stream", sung with Ruth Jones, Rob Brydon and Robin Gibb, who co-wrote the original with his brothers Barry and Maurice. The song, inspired by BBC's hit sitcom "Gavin and Stacey", was released in aid of Comic Relief and reached No. 1 in March 2009.
In 2009 he ditched his hair dye and declared he'd moved onto a new stage in his life: "Over Christmas, I always take a month off and let my hair go and don't even shave. Normally it comes out like salt and pepper, which I hated, but this year it grew out a silver colour, so I kept it, because it's more distinguished", he said.
2010–present.
Jones announced that his new album "Praise & Blame" would be released on 26 July 2010. The album, produced by Ethan Johns (who has previously worked with Kings of Leon, Rufus Wainwright and Laura Marling), would include covers of songs by Bob Dylan, John Lee Hooker and Billy Joe Shaver, and feature such guest musicians as Booker T.
On Jones's 70th birthday, 7 June 2010, the single "Burning Hell", a cover of the John Lee Hooker classic, from the forthcoming "Praise & Blame" album, was released. In July 2010 it was reported that David Sharpe, vice-president of Island Records (to whom Jones had moved, from EMI, for £1.5m in October 2009), had emailed colleagues demanding that they "pull back this project immediately or get my money back" and asking if the record had been "a sick joke". Jones later attacked Sharpe and revealed that he was furious about the leaked email. By 2010, Jones had sold over 100 million records.
In July 2010 Jones appeared on the penultimate episode of "Friday Night with Jonathan Ross" and performed "Burning Hell". In August 2010, "Praise & Blame" debuted at No. 2 on the UK album chart.
On 11 September 2010 Jones performed for an audience of 50,000 at the "Help for Heroes" charity concert at Twickenham Stadium performing "Strange Things Are Happening Every Day" and his classic hit "Green Green Grass of Home". On 22 September, Jones appeared on the "Late Show with David Letterman" at the Ed Sullivan Theater in New York.
In May 2011 Jones appeared as guest vocalist on the debut album "Let Them Talk" by Hugh Laurie. On 15 May 2011 he appeared alongside Laurie in the UK ITV series "Perspectives", singing music from the album in New Orleans. On 25 May 2011, he appeared on " American Idol " after a medley of his hits performed by the American Idol "Top 13".
Jones released a single on 19 March 2012, produced by former White Stripes frontman Jack White, called "Evil". The single was first made available through independent record stores in 7" vinyl on 5 March. An exclusive three-coloured vinyl was also sold at only one shop – Spillers Records in Cardiff. The shop, from which Jones bought records as a schoolboy in the 1950s and early 1960s, was founded in 1894 and is listed in "Guinness World Records" as the oldest record shop in the world.
In March 2012 Jones became a coach on the BBC talent show "The Voice UK". Jones was joined by will.i.am, Jessie J and Danny O'Donoghue. He mentored Leanne Mitchell to win the first series. Jones returned to coach in 2013, 2014 and 2015. In August 2015 it was announced that Jones's contract with the show would not be renewed and that he would be replaced by Boy George. Jones criticised BBC executives for "sub-standard behaviour", having not consulted with him and informing him only 24 hours before the official announcement.
In May 2012 Jones released the album "Spirit in the Room" on Island Records/Universal Music. The track listing included covers of songs by Paul McCartney, Paul Simon, Leonard Cohen and Richard and Linda Thompson, Blind Willie Johnson, Tom Waits and the Low Anthem.
On 4 June 2012, Jones performed at the Queen's Diamond Jubilee Concert in front of Buckingham Palace, singing "Delilah" and "Mama Told Me Not to Come".
On 18 August 2012, Jones performed a fifty-minute set at the V Festival’s Weston Park site in Staffordshire. On 9 September 2012, Jones headlined at BBC Radio 2's Live in Hyde Park festival.
In May 2014 Jones opened for Morrissey at a special show in the US. On 27 September 2014 Jones performed at the Australian Football League's pre game entertainment for the 2014 Grand Final along with Ed Sheeran.
In September 2015 Jones announced the long-awaited release of his album "Long Lost Suitcase", on 9 October, through Virgin/EMI. The album is the third in a trilogy of albums, following "Praise & Blame" (2010) and "Spirit In The Room" (2012). The album's track titles are interwoven into the chapters of his autobiography "Over the Top and Back" released at the same time. The producer is once again Ethan Johns and the diverse range of compositions includes songs from Gillian Welch, the Rolling Stones, Hank Williams and the Milk Carton Kids.
In November 2015 Jones appeared, alongside Rob Brydon in a special 90-minute show, from the SSE Arena, Wembley, for BBC's Children in Need.
In 2015 he appeared on BBC's "Jools' Annual Hootenanny", broadcast on New Year's Eve, on which he duetted with Paul Weller.
Personal life.
Jones remained married to Linda from 1957 until her death on 10 April 2016, despite his many well-publicised infidelities. The couple had one son, Mark Woodward (born 1957). At the height of his fame, Jones claims that he had sex with up to 250 groupies a year. His philandering once led Linda to physically assault him. After reading about one infidelity in a newspaper, she punched and kicked Jones, but he did not fight back; "I took it", he said. Jones has had affairs with well-known women, including Mary Wilson of the Supremes, TV host Charlotte Laws and former Miss World Marjorie Wallace. Cassandra Peterson, better known as Elvira, Mistress of the Dark, claims that she lost her virginity to Jones.
One affair resulted in the birth of a son. In October 1987, while on tour in the US, Jones had a brief relationship with model Katherine Berkery, who then discovered she was pregnant. After a legal battle that included DNA testing, a United States court ruled in 1989 that Jones was the boy's father. Jones denied the court's findings, until finally, in 2008, he admitted they were true. He has shown no interest in meeting his son, Jonathan Berkery.
Following the election of the Labour Party's Harold Wilson as Prime Minister in 1974, Jones became a tax exile. In June 1976 he purchased the red-brick mansion at 363 Copa De Oro Road in the East Gate Old Bel Air in Los Angeles from Dean Martin for $500,000.
He sold it to Nicolas Cage in 1998 for a reported $6.469 million. In 2009, after 35 years in the US, Jones revealed that he and his wife were planning to move back to the UK. "I've had a great time living in Los Angeles", Jones said, "but after all these years, we think now is the time to move home". On "The Chris Moyles Show" on 27 July 2009, he said he still lives in Los Angeles and will remain there for the foreseeable future, but he still frequently visits the UK.
In October 2015 his autobiography entitled "Over the Top and Back: The Autobiography" was published by Michael Joseph. Reviewing the book in "The Express", Clair Woodward said, "In the tradition of so many autobiographies these days, Tom Jones's doesn't tell you what you really want to hear. ... What you are left with is a riotously enjoyable story of Jones 'The Voice' which nicely doubles as the story of British pop and light entertainment from the Sixties onwards."
Melinda Rose, Lady Woodward (Linda) died on 10 April 2016, at the Cedars Sinai Hospital in Los Angeles, after a "short but fierce" battle with cancer. Jones had recently cancelled concerts due to a "serious illness" in his family.
Cultural influence.
Space and Cerys Matthews released "The Ballad of Tom Jones", a song about a fighting couple who are calmed down by listening to Jones's music on the radio. The song reached No. 4 in the UK in 1998.
A new musical, "Tom: A Story of Tom Jones", based on the singer's life and recordings, produced by Theatr na nÓg, opened at the Wales Millennium Centre in March 2016. Reviewing the show for "The Stage", Mark Shenton said, "... the show itself, written by Mike James and directed by Geinor Styles, is a more humdrum — while hummable — affair than its star and subject deserves. In the familiar jukebox musical style of shows like "Jersey Boys" and "", "A Story of Tom Jones" charts the behind-the-scenes rise to fame of a pop star, but without the craft or polish."
Compositions.
Jones wrote or co-wrote the following songs: "And I Tell the Sea", "Looking Out My Window", "Feel the Rain" from the 2002 "Mr. Jones" album, "Jezebel", "The Letter", "Younger Days", "Tom Jones International", "Holiday", "The Road", "24 Hours", "Seasons", "We Got Love", "Seen That Face", "Give a Little Love", "If He Should Ever Leave You", "Whatever it Takes", and "Traveling Shoes" from the 2012 album "Spirit in the Room".

</doc>
<doc id="45969" url="https://en.wikipedia.org/wiki?curid=45969" title="Joan Crawford">
Joan Crawford

Joan Crawford (born Lucille Fay LeSueur; March 23, 1904 – May 10, 1977) was an American film and television actress who started as a dancer and stage chorine. In 1999, the American Film Institute ranked Crawford tenth on their list of the greatest female stars of Classic Hollywood Cinema.
Beginning her career as a dancer in travelling theatrical companies before debuting as a chorus girl on Broadway, Crawford signed a motion picture contract with Metro-Goldwyn-Mayer in 1925. In the 1930s, Crawford's fame rivaled, and later outlasted, MGM colleagues Norma Shearer and Greta Garbo. Crawford often played hard-working young women who find romance and success. These stories were well received by Depression-era audiences and were popular with women. Crawford became one of Hollywood's most prominent movie stars and one of the highest paid women in the United States, but her films began losing money, and, by the end of the 1930s, she was labelled "Box Office Poison". But her career gradually improved in the early 1940s, and she made a major comeback in 1945 by starring in "Mildred Pierce", for which she won the Academy Award for Best Actress. She would go on to receive Best Actress nominations for "Possessed" (1947) and "Sudden Fear" (1952).
In 1955, she became involved with the Pepsi-Cola Company through her marriage to company Chairman Alfred Steele. After his death in 1959, Crawford was elected to fill his vacancy on the board of directors but was forcibly retired in 1973. She continued acting in film and television regularly through the 1960s, when her performances became fewer; after the release of the British horror film "Trog" in 1970, Crawford retired from the screen. Following a public appearance in 1974, after which unflattering photographs were published, Crawford withdrew from public life and became increasingly reclusive until her death in 1977.
Crawford married four times. Her first three marriages ended in divorce; the last ended with the death of husband Alfred Steele. She adopted five children, one of whom was reclaimed by his birth mother. Crawford's relationships with her two older children, Christina and Christopher, were acrimonious. Crawford disinherited the two, and, after Crawford's death, Christina wrote a "tell-all" memoir titled, "Mommie Dearest".
Early life.
Crawford was born Lucille Fay LeSueur in San Antonio, Texas, on March 23; the year is disputed, with 1904, 1905, and 1906 the most likely estimates, all cited in varying sources, the third child of Thomas E. LeSueur (died January 1, 1938), a laundry laborer, and Anna Bell Johnson (died August 15, 1958), neither of whose years of birth can be conclusively established. Anna Bell Johnson was of English, French Huguenot, Swedish, and Irish ancestry. Her elder siblings were Daisy LeSueur (ƒ 1902) and Hal LeSueur.
Thomas LeSueur abandoned the family a few months before Crawford's birth but reappeared in Abilene, Texas, in 1930 as a reportedly 62-year-old construction laborer. However, after his death on January 1, 1938, his age was given as 71. Crawford's mother subsequently married Henry J. Cassin (died October 25, 1922). This marriage is listed in census records as Crawford's mother's first marriage, calling into question whether Thomas LeSueur and Anna Bell Johnson were ever legally wed.
The family lived in Lawton, Oklahoma, where Cassin, a minor impresario, ran the Ramsey Opera House. Despite his own relatively minor status as an impresario, Cassin managed to get such diverse and noted performers as Anna Pavlova and Eva Tanguay during his career. Young Lucille was reportedly unaware that Cassin, whom she called "Daddy", was not her biological father until her brother Hal told her. Lucille preferred the nickname "Billie" as a child and she loved watching vaudeville acts perform on the stage of her stepfather's theatre. The instability of her family life affected her education and her schooling never formally progressed beyond elementary school.
Her ambition was to be a dancer. However, one day, in an attempt to escape piano lessons to play with friends, she leaped from the front porch of her home and cut her foot deeply on a broken milk bottle. She had three operations and was unable to attend elementary school for 18 months. She eventually fully recovered and returned to dancing.
Cassin was accused of embezzlement and although acquitted in court, was blacklisted in Lawton, and the family moved to Kansas City, Missouri, around 1916. Cassin was first listed in the City Directory in 1917, living at 403 East Ninth Street. A Catholic, Cassin placed Crawford at St. Agnes Academy in Kansas City. After her mother and stepfather broke up, she stayed on at St. Agnes as a work student, where she spent far more time working, primarily cooking and cleaning, than studying.
Later, she went to Rockingham Academy, also as a work student. While attending Rockingham she began dating and had her first serious relationship, with a trumpet player named Ray Sterling, who reportedly inspired her to begin challenging herself academically.
In 1922, she registered at Stephens College in Columbia, Missouri, giving her year of birth as 1906. She attended Stephens for only a few months before withdrawing after she realized she was not prepared for college.
Career.
Early career.
Under the name Lucille LeSueur, Crawford began dancing in the choruses of traveling revues and was spotted dancing in Detroit by producer Jacob J. Shubert. Shubert put her in the chorus line for his 1924 show, "Innocent Eyes", at the Winter Garden Theatre on Broadway in New York City. While appearing in "Innocent Eyes" Crawford met a saxophone player named James Welton. The two were allegedly married in 1924 and lived together for several months, although this supposed marriage was never mentioned in later life by Crawford.
Crawford wanted additional work and approached Loews Theaters publicist Nils Granlund. Granlund secured a position for her with producer Harry Richmond's act and arranged for her to do a screen test which he sent to producer Harry Rapf in Hollywood. (Stories have persisted that Crawford further supplemented her income by appearing in one or more stag, or soft-core pornographic, films, although this has been disputed.)
Rapf notified Granlund on December 24, 1924 that Metro-Goldwyn-Mayer (or MGM for short) had offered Crawford a contract at $75 a week. Granlund immediately wired LeSueur – who had returned to her mother's home in Kansas City – with the news; she borrowed $400 for travel expenses. She departed Kansas City on December 26 and arrived in Culver City, California on January 1, 1925.
Credited as Lucille LeSueur, her first film was "Lady of the Night" in 1925, as the body double for MGM's most-popular female star, Norma Shearer. She also appeared in "The Circle" and "Pretty Ladies" (both 1925), starring comedian ZaSu Pitts. This was soon followed by equally small and unbilled roles in two other 1925 successes, "The Only Thing" and "The Merry Widow".
MGM publicity head Pete Smith recognized her ability to become a major star, but felt her name sounded fake; he told studio head Louis B. Mayer that her last name—LeSueur—reminded him of a sewer. Smith organized a contest called "Name the Star" in "Movie Weekly" to allow readers to select her new stage name. The initial choice was "Joan Arden" but, after another actress was found to have prior claim to that name, the alternate surname "Crawford" became the choice. Crawford later said that she wanted her first name to be pronounced "Jo-Anne", and that she hated the name Crawford because it sounded like "craw fish", but also admitted she "liked the security" that went with the name.
Self-promotion and early successes.
Growing increasingly frustrated over the size and quality of the parts she was given, Crawford embarked on a campaign of self-promotion. As MGM screenwriter Frederica Sagor Maas recalled, "No one decided to make Joan Crawford a star. Joan Crawford became a star because Joan Crawford decided to become a star." She began attending dances in the afternoons and evenings at hotels around Hollywood, where she often won dance competitions with her performances of the Charleston and the Black Bottom.
Her strategy worked, and MGM cast her in the film where she first made an impression on audiences, Edmund Goulding's "Sally, Irene and Mary" (1925). From the beginning of her career, Crawford considered Norma Shearer—the studio's most-popular actress—her professional nemesis. Since Shearer was married to MGM Head of Production Irving Thalberg, she had the first choice of scripts and had more control than other stars in what films she would and would not make. Crawford was quoted to have said, "How can I compete with Norma? She sleeps with the boss!"
In 1926, Crawford was named one of the WAMPAS Baby Stars along with Mary Astor, Dolores del Río, Janet Gaynor, and Fay Wray among others. That same year, she starred in "Paris", co-starring Charles Ray. Within a few years, she became the romantic female lead to many of MGM's top male stars, including Ramón Novarro, John Gilbert, William Haines, and Tim McCoy.
Crawford appeared in "The Unknown" (1927), starring Lon Chaney, Sr. who played a carnival knife thrower with no arms. Crawford played his skimpily-clad young carnival assistant whom he hopes to marry. She stated that she learned more about acting from watching Chaney work than from anyone else in her career. "It was then," she said, "I became aware for the first time of the difference between standing in front of a camera, and acting." Also in 1927, she appeared alongside her close friend, William Haines, in "Spring Fever", which was the first of three movies the duo made together.
In 1928, Crawford starred opposite Ramón Novarro in "Across to Singapore", but it was her role as Diana Medford in "Our Dancing Daughters" (1928) that catapulted her to stardom. The role established her as a symbol of modern 1920s-style femininity which rivaled Clara Bow, the original It girl, then Hollywood's foremost flapper. A stream of hits followed "Our Dancing Daughters", including two more flapper-themed movies, in which Crawford embodied for her legion of fans (many of whom were women) an idealized vision of the free-spirited, all-American girl.
F. Scott Fitzgerald wrote of Crawford:
On June 3, 1929, Crawford married Douglas Fairbanks, Jr. at Saint Malachy's Roman Catholic Church (known as "The Actors' Chapel" due to its proximity to Broadway theatres) in Manhattan, although neither was Catholic. Fairbanks was the son of Douglas Fairbanks and the stepson of Mary Pickford, who were considered Hollywood royalty. Fairbanks Sr. and Pickford were opposed to the marriage and did not invite the couple to their home, Pickfair, for eight months after the marriage.
The relationship between Crawford and Fairbanks, Sr. eventually warmed; she called him "Uncle Doug" and he called her "Billie", her old childhood nickname. Following that first invitation, Crawford and Fairbanks, Jr. became more frequent guests, which was hard on Crawford. While the Fairbanks men played golf together, Crawford was left either with Pickford or alone.
To rid herself of her Southwestern accent, Crawford tirelessly practiced diction and elocution. She said:
Transition to sound and continued success.
After the release of "The Jazz Singer" in 1927—the first major Hollywood movie with synchronized sound—sound films, or talkies as they became nicknamed, were all the rage. The transition from silent to sound panicked many—if not all—involved with the film industry; many silent film stars found themselves unemployable because of their undesirable voices and hard-to-understand accents or simply because of their refusal to make the transition to talkies. Many studios and stars avoided making the transition as long as possible, especially MGM, which was the last studio to switch over to sound. "The Hollywood Revue of 1929" (1929) was one of the studio's first all-sound films, and their first attempt to showcase their stars' ability to make the transition from silent to sound. Crawford was among the dozen or more MGM stars included in the movie; she sang the song "Got a Feeling for You" during the film's first act.
Crawford made a successful transition to talkies. Her first starring role in an all-sound feature-length film was in "Untamed" in 1929, co-starring Robert Montgomery. Despite the success of the film at the box office, it received mixed reviews from critics, who noted that while Crawford seemed nervous at making the transition to sound, also noted that she had become one of the most popular actresses in the world.
"Montana Moon" (1930), an uneasy mix of Western clichés and music, teamed her with John Mack Brown and Ricardo Cortez. Although the film had problems with censors, it was a major success at the time of its release. "Our Blushing Brides" (1930), co-starring Robert Montgomery and Anita Page, was the final installment in the so-called "Our Dancing Daughters" franchise. It was a greater success–both critically and financially–than her previous talkies, and became one of her personal favorites.
Her next movie, "Paid" (1930), paired her with Robert Armstrong and was another success. During the early sound era, MGM began to place Crawford in more sophisticated roles, rather than continuing to promote her flapper-inspired persona of the silent era.
In 1931, MGM cast Crawford in five films. Three of them teamed her opposite the studio's biggest male star and King of Hollywood, Clark Gable. "Dance, Fools, Dance", released in February 1931, was the first pairing of Crawford and Gable. Their second movie together, "Laughing Sinners", released in May 1931, was directed by Harry Beaumont and also co-starred Neil Hamilton. "Possessed", their third film together, released in October, was directed by Clarence Brown.
These films were immensely popular with audiences, and were generally well received by critics, stapling Crawford's position as one of MGM's top female stars of the decade, along with Norma Shearer, Greta Garbo, and Jean Harlow. Her only other notable film of 1931, "This Modern Age", was released in August, and despite unfavorable reviews, was a moderate success.
MGM next cast her in the film "Grand Hotel", directed by Edmund Goulding. As the studio's first all-star production, Crawford co-starred opposite Greta Garbo, John and Lionel Barrymore, and Wallace Beery among others. Receiving third billing, she played the middle-class stenographer to Beery's controlling general director. Crawford later admitted to being nervous during the filming of the movie because she was working with "very big stars", and that she was disappointed that she had no scenes with the "divine Garbo". "Grand Hotel" was released in April 1932 to critical and commercial success. It was the highest-grossing movie of the year, and won the Academy Award for Best Picture.
Crawford achieved continued success in "Letty Lynton" (1932). Soon after this movie's release, a plagiarism suit forced MGM to withdraw it. For many years it was never shown on television nor made available on home video and is therefore considered the "lost" Crawford film. The gown with large ruffled sleeves, designed by Adrian, which Crawford wore in the movie, became a popular style that same year, and was even copied by Macy's.
On a loan out to United Artists, she played prostitute Sadie Thompson in "Rain" (1932), a film version of John Colton's 1923 play. Actress Jeanne Eagels played the role on stage and Gloria Swanson had originated the part on screen in the 1928 film version. Crawford's performance was panned and the film was not a success.
Despite the failure of "Rain", in 1932 the publishing of the first "Top Ten Money Making Stars Poll" placed Crawford third in popularity at the box office, behind only Marie Dressler and Janet Gaynor. She remained on the list for the next several years, last appearing on it in 1936.
In May 1933, Crawford divorced Fairbanks. Crawford cited "grievous mental cruelty", claiming Fairbanks had "a jealous and suspicious attitude" toward her friends and that they had "loud arguments about the most trivial subjects" lasting "far into the night".
Following her divorce, she was again teamed with Clark Gable, along with Franchot Tone and Fred Astaire, in the hit "Dancing Lady" (1933), in which she received top billing. She next played the title role in "Sadie McKee" (1934) opposite Tone and Gene Raymond. She was paired with Gable for the fifth time in "Chained" (1934) and for the sixth time in "Forsaking All Others" (1934). Crawford's films of this era were some of the most-popular and highest-grossing films of the mid-1930s.
In 1935, Crawford married Tone, a stage actor from New York who planned to use his film earnings to finance his theatre group. The couple built a small theatre at Crawford's Brentwood home and put on productions of classic plays for select groups of friends. Tone and Crawford had first appeared together in "Today We Live" (1933) but Crawford was hesitant about entering into another romance so soon after her split from Fairbanks.
Before and during their marriage, Crawford worked to promote Tone's Hollywood career, but Tone was ultimately not interested in being a movie star and Crawford eventually wearied of the effort. After Tone reportedly began drinking and becoming physically abusive, she filed for divorce, which was granted in 1939. Crawford and Tone much later rekindled their friendship and Tone even proposed in 1964 that they remarry. When he died in 1968, Crawford arranged for him to be cremated and his ashes scattered at Muskoka Lakes, Canada.
Crawford continued her reign as a popular movie actress well into the mid-1930s. "No More Ladies" (1935) co-starred Robert Montgomery and then-husband Franchot Tone, and was a success. Crawford had long pleaded with MGM's head Louis B. Mayer to cast her in more dramatic roles, and although he was reluctant, he cast her in the sophisticated comedy-drama "I Live My Life" (1935), directed by W.S. Van Dyke. It was well received by critics and made a larger profit than the studio had expected.
She next starred in "The Gorgeous Hussy" (1936), opposite Robert Taylor and Lionel Barrymore as well as Tone, a critical and box office success, become one of Crawford's biggest hits of the decade. "Love on the Run" (1936), a romantic comedy directed by W.S. Van Dyke, was her seventh film co-starring Clark Gable. It was, at the time of its release, called "a lot of happy nonsense" by critics, but a financial success nonetheless.
Box Office Poison.
Even though Crawford remained a respected MGM actress and her films still earned profits, her popularity declined in the late 1930s. In 1937, Crawford was proclaimed the first "Queen of the Movies" by "Life" magazine. She unexpectedly slipped from seventh to sixteenth place at the box office that year, and her public popularity also began to wane. Richard Boleslawski's comedy-drama "The Last of Mrs. Cheyney" (1937) teamed her opposite William Powell in their sole screen pairing. The film was also Crawford's last box-office success before the onset of her "Box-Office Poison" period.
She co-starred opposite Franchot Tone for the seventh and final time in "The Bride Wore Red" (1937). The film was generally unfavorably reviewed by the majority of critics, with one critic calling it the "same ole rags-to-riches story" Crawford had been making for years. It also ran a financial loss, becoming one of MGM's biggest failures of the year. "Mannequin" did, as the "New York Times" stated, "restore Crawford to her throne as queen of the working girls". Most other reviews were positive, and the film managed to generate a minor profit, but it did not resurrect Crawford's popularity.
On May 3, 1938, Crawford — along with Greta Garbo, Norma Shearer, Luise Rainer, and John Barrymore, Katharine Hepburn, Fred Astaire, Dolores del Río and others — was dubbed "Box Office Poison" in an open letter in the "Independent Film Journal". The list was submitted by Harry Brandt, president of the Independent Theatre Owners Association of America. Brandt stated that while these stars had "unquestioned" dramatic abilities, their high salaries did not reflect in their ticket sales, thus hurting the movie exhibitors involved. Her follow-up movie, "The Shining Hour" (1938), co-starring Margaret Sullavan and Melvyn Douglas, was well received by critics, but a box office flop.
She made a comeback in 1939 with her role as home-wrecker Crystal Allen in "The Women" opposite her professional nemesis, Norma Shearer. A year later, she played against type, playing the unglamorous role of Julie in "Strange Cargo" (1940), her eighth and final film with Clark Gable. She later starred as a facially disfigured blackmailer in "A Woman's Face" (1941), a remake of the Swedish film "En kvinnas ansikte" which had starred Ingrid Bergman in the lead role three years earlier. While the film was only a moderate box office success, her performance was hailed by many critics.
Crawford adopted her first child, a daughter, in 1940. Because she was single, California law prevented her from adopting within the state so she arranged the adoption through an agency in Las Vegas. The child was temporarily called Joan until Crawford changed her name to Christina. She married actor Phillip Terry on July 21, 1942 after a six-month courtship. Together the couple adopted a son whom they named Christopher, but his birth mother reclaimed the child. The couple adopted another boy, whom they named Phillip Terry, Jr. After the marriage ended in 1946, Crawford changed the child's name to Christopher Crawford.
After eighteen years, Crawford's contract with MGM was terminated by mutual consent on June 29, 1943. In lieu of the last film remaining under her contract, MGM bought her out for $100,000. During World War II she was a member of American Women's Voluntary Services.
Move to Warner Brothers.
For $500,000, Crawford signed with Warner Brothers for a three movie deal and was placed on the payroll on July 1, 1943. Her first film for the studio was "Hollywood Canteen" (1944), an all-star morale-booster film that teamed her with several other top movie stars at the time. Crawford said one of the main reasons she signed with Warner Brothers was because she wanted to play the character "Mattie" in a proposed 1944 film version of Edith Wharton's novel "Ethan Frome" (1911).
She wanted to play the title role in "Mildred Pierce" (1945), but Bette Davis was the studio's first choice. However, Davis turned the role down. Director Michael Curtiz did not want Crawford to play the part, and he instead lobbied for the casting of Barbara Stanwyck. Warners went against Curtiz, however, and cast Crawford in the film. Throughout the entire production of the movie, Curtiz criticized Crawford. He has been quoted as having told Jack Warner, "She comes over here with her high-hat airs and her goddamn shoulder pads... why should I waste my time directing a has-been?" Curtiz demanded Crawford prove her suitability by taking a screen test. After the test, Curtiz agreed to Crawford's casting. "Mildred Pierce" was a resounding critical and commercial success. It epitomized the lush visual style and the hard-boiled film noir sensibility that defined Warner Bros. movies of the late forties, earning Crawford the Academy Award for Best Actress in a Leading Role.
The success of "Mildred Pierce" revived Crawford's movie career. For several years, she starred in what were called "a series of first-rate melodramas". Her next film was "Humoresque" (1946), co-starring John Garfield, a romantic drama about a love affair between an older woman and a younger man. She starred alongside Van Heflin in "Possessed" (1947), for which she received a second Academy Award nomination, although she did not win. In "Daisy Kenyon" (1947), she appeared opposite Dana Andrews and Henry Fonda, and in "Flamingo Road" (1949) she played a carnival dancer opposite Zachary Scott and David Brian. She made a cameo appearance in "It's a Great Feeling" (1949), poking fun at her own screen image. In 1950, she starred in the film noir, "The Damned Don't Cry!", and starred in "Harriet Craig".
After the completion of "This Woman Is Dangerous" (1952), a film Crawford called her "worst", she asked to be released from her Warner Brothers contract. By this time she felt Warners was losing interest in her and she decided it was time to move on. Later that same year, she received her third and final Academy Award nomination for "Sudden Fear" for RKO Radio Pictures. In 1953, she appeared in her final film for MGM, "Torch Song". The movie received favorable reviews and moderate success at the box office.
Crawford adopted two more children in 1947, identical twins whom she named Cindy and Cathy.
Radio and television.
Crawford worked in the radio series "The Screen Guild Theater" on January 8, 1939; "Good News"; "Baby", broadcast March 2, 1940 on Arch Oboler's "Lights Out"; "The Word" on "Everyman's Theater" (1941); "Chained" on the "Lux Radio Theater" and Norman Corwin's "Document A/777" (1948). She appeared in episodes of anthology television series in the 1950s and, in 1959, made a pilot for her series, "The Joan Crawford Show".
Al Steele and Pepsi Cola Company.
Crawford married her fourth and final husband, Alfred Steele, at the Flamingo Hotel in Las Vegas on May 10, 1955. Crawford and Steele met at a party in 1950 when Steele was an executive at PepsiCo. They renewed their acquaintance at a New Year's Eve party in 1954. Steele by that time had become President of Pepsi Cola. Alfred Steele would later be named Chairman of the Board and Chief Executive Officer of Pepsi Cola. She traveled extensively on behalf of Pepsi following the marriage. She estimated that she traveled over 100,000 miles for the company.
Steele died of a heart attack in April 1959. Crawford was initially advised that her services were no longer required. After she told the story to Louella Parsons, Pepsi reversed its position and Crawford was elected to fill the vacant seat on the board of directors.
Crawford received the sixth annual "Pally Award", which was in the shape of a bronze Pepsi bottle. It was awarded to the employee making the most significant contribution to company sales. In 1973, Crawford was forced to retire from the company at the behest of company executive Don Kendall, whom Crawford had referred to for years as "Fang".
Later career.
After her Academy Award nominated performance in 1952's "Sudden Fear", Crawford continued to work steadily throughout the rest of the decade. In 1954, she starred in "Johnny Guitar", a camp western film, co-starring Sterling Hayden and Mercedes McCambridge. She also starred in "Female on the Beach" (1955) with Jeff Chandler, and in "Queen Bee" (1955) alongside John Ireland. The following year, she starred opposite a young Cliff Robertson in "Autumn Leaves" (1956) and filmed a leading role in "The Story of Esther Costello" (1957), co-starring Rossano Brazzi. Crawford, who had been left near-penniless following Alfred Steele's death accepted a small role in "The Best of Everything" (1959). Although she was not the star of the film, she received positive reviews. Crawford would later name the role as being one of her personal favorites. However, by the early 1960s, Crawford's status in motion pictures had declined considerably.
Crawford starred as Blanche Hudson, an old, wheelchair-bound former A-list movie star in conflict with her psychotic sister, in the highly successful psychological thriller "What Ever Happened to Baby Jane?" (1962). Despite the actresses' earlier tensions, Crawford reportedly suggested Bette Davis for the role of Jane. The two stars maintained publicly that there was no feud between them. The director, Robert Aldrich, explained that Davis and Crawford were each aware of how important the film was to their respective careers and commented, "It's proper to say that they really detested each other, but they behaved absolutely perfectly."
After filming was completed, their public comments against each other propelled their animosity into a lifelong feud. The film was a huge success, recouping its costs within 11 days of its nationwide release, and temporarily revived Crawford's career. Davis was nominated for an Academy Award for her performance as Jane Hudson. Crawford secretly contacted each of the other Oscar nominees in the category (Katharine Hepburn, Geraldine Page and Anne Bancroft, all East Coast-based actresses), to let them know that if they could not attend the ceremony, she would be happy to accept the Oscar on their behalf; all agreed. Both Davis and Crawford were backstage when the absent Anne Bancroft was announced as the winner, and Crawford accepted the award on her behalf. Davis claimed for the rest of her life that Crawford had campaigned against her, a charge Crawford denied.
That same year, Crawford starred as Lucy Harbin in William Castle's horror mystery "Strait-Jacket" (1964). Robert Aldrich cast Crawford and Davis in "Hush... Hush, Sweet Charlotte" (1964). After a purported campaign of harassment by Davis on location in Louisiana, Crawford returned to Hollywood and entered a hospital. After a prolonged absence, during which Crawford was accused of feigning illness, Aldrich was forced to replace her with Olivia de Havilland. Crawford claimed to be devastated, saying "I heard the news of my replacement over the radio, lying in my hospital bed ... I cried for 9 hours." Crawford nursed grudges against Davis and Aldrich for the rest of her life, saying of Aldrich, "He is a man who loves evil, horrendous, vile things", to which Aldrich replied, "If the shoe fits, wear it, and I am very fond of Miss Crawford."
In 1965 she played Amy Nelson in "I Saw What You Did" (1965), another William Castle vehicle. She starred as Monica Rivers in Herman Cohen's horror thriller film "Berserk!" (1967). After the film's release, Crawford guest-starred as herself on "The Lucy Show". The episode, "Lucy and the Lost Star", first aired on February 26, 1968. Crawford struggled during rehearsals and drank heavily on-set, leading series star Lucille Ball to suggest replacing her with Gloria Swanson. However, Crawford was letter-perfect the day of the show, which included dancing the Charleston, and received two standing ovations from the studio audience.
In October 1968, Crawford's 29-year-old daughter, Christina (who was then acting in New York on the CBS soap opera "The Secret Storm"), needed immediate medical attention for a ruptured ovarian tumor. Despite the fact that Christina's character was a 28-year-old and Crawford was 60, Crawford offered to play her role until Christina was well enough to return, to which producer Gloria Monty readily agreed. Although Crawford did well in rehearsal, she lost her composure while taping and the director and producer were left to struggle to piece together the necessary footage.
Crawford's appearance in the 1969 television film "Night Gallery" (which served as pilot to the series that followed), marked one of Steven Spielberg's earliest directing jobs. She made a cameo appearance as herself in the first episode of the situation comedy "The Tim Conway Show", which aired on January 30, 1970. She starred on the big screen one final time, playing Dr. Brockton in Herman Cohen's science fiction horror film "Trog" (1970), rounding out a career spanning 45 years and more than eighty motion pictures. Crawford made three more television appearances, as Stephanie White in a 1970 episode ("The Nightmare") of "The Virginian" and as Joan Fairchild (her final performance) in a 1972 episode ("Dear Joan: We're Going to Scare You to Death") of "The Sixth Sense".
Final years.
In 1970, Crawford was presented with the Cecil B. DeMille Award by John Wayne at the Golden Globes, which was telecast from the Coconut Grove at The Ambassador Hotel in Los Angeles. She also spoke at Stephens College, which she had attended for four months in 1922.
Crawford published her autobiography, "A Portrait of Joan", co-written with Jane Kesner Ardmore, in 1962 through Doubleday. Crawford's next book, "My Way of Life", was published in 1971 by Simon & Schuster. Those expecting a racy tell-all were disappointed, although Crawford's meticulous ways were revealed in her advice on grooming, wardrobe, exercise, and even food storage. Upon her death there was found in her apartment photographs of John F. Kennedy, for whom she had reportedly voted in the 1960 presidential election.
In September 1973, Crawford moved from apartment 22-G to a smaller apartment next door (22-H) at the Imperial House. Her last public appearance was September 23, 1974, at a party honoring her old friend Rosalind Russell at New York's Rainbow Room. Russell was suffering from breast cancer and arthritis at the time. When Crawford saw the unflattering photos that appeared in the papers the next day, she said, "If that's how I look, then they won't see me anymore." Crawford cancelled all public appearances, began declining interviews and left her apartment less and less. Dental-related issues, including surgery which left her needing round-the-clock nursing care, plagued her from 1972 until mid-1975. While on antibiotics for this problem in October 1974, her drinking caused her to pass out, slip and strike her face. The incident scared her enough to give up drinking, although she insisted it was because of her return to Christian Science. The incident is recorded in a series of letters sent to her insurance company held in the stack files on the 3rd floor of the New York Public Library for the Performing Arts; it is also documented by Carl Johnnes in his biography of the actress, "Joan Crawford: The Last Years".
Death and legacy.
On May 8, 1977, Crawford gave away her beloved Shih Tzu, "Princess Lotus Blossom," being too weak to care for it. She died two days later at her New York apartment from a heart attack, while also reportedly ill with cancer. A funeral was held at Campbell Funeral Home, New York, on May 13, 1977. In her will, which was signed October 28, 1976, Crawford bequeathed to her two youngest children, Cindy and Cathy, $77,500 each from her $2,000,000 estate. She explicitly disinherited the two eldest, Christina and Christopher, writing, "It is my intention to make no provision herein for my son, Christopher, or my daughter, Christina, for reasons which are well known to them." She also bequeathed nothing to her niece, Joan Lowe (1933-1999; born Joan Crawford LeSueur, the only child of her estranged brother, Hal). Crawford left money to her favorite charities: the U.S.O. of New York, the Motion Picture Home, the American Cancer Society, the Muscular Dystrophy Association, the American Heart Association, and the Wiltwyck School for Boys.
A memorial service was held for Crawford at All Souls' Unitarian Church on Lexington Avenue in New York on May 16, 1977, and was attended by, among others, her old Hollywood friend Myrna Loy. Another memorial service, organized by George Cukor, was held on June 24 in the Samuel Goldwyn Theater at the Academy of Motion Picture Arts and Sciences in Beverly Hills. Crawford was cremated and her ashes were placed in a crypt with her fourth and final husband, Alfred Steele, in Ferncliff Cemetery, Hartsdale, New York.
Joan Crawford's handprints and footprints are immortalized in the forecourt of Grauman's Chinese Theater on Hollywood Boulevard in Hollywood. She has a star on the Hollywood Walk of Fame at 1750 Vine Street. "Playboy" listed Crawford as #84 of the "100 Sexiest Women of the 20th century". Crawford was also voted the tenth greatest female star of the classic American cinema by the American Film Institute.
"Mommie Dearest".
In November 1978, Christina Crawford published "Mommie Dearest", which contained allegations that her late adoptive mother was emotionally and physically abusive to Christina and her brother Christopher. Many of Crawford's friends and co-workers, including Van Johnson, Ann Blyth, Marlene Dietrich, Myrna Loy, Katharine Hepburn, Cesar Romero, Gary Gray, Betty Barker (Joan's secretary for nearly fifty years), Douglas Fairbanks Jr. (Crawford's first husband), and Crawford's two other younger daughters — Cathy and Cindy — denounced the book, categorically denying any abuse. But others, including Betty Hutton, Helen Hayes, James MacArthur (Hayes' son), June Allyson, Liz Smith, Rex Reed, and Vincent Sherman stated they had witnessed some form of abusive behavior. Crawford's secretary, Jeri Binder Smith, confirmed Christina's account. "Mommie Dearest" became a bestseller and was made into the 1981 biography film "Mommie Dearest", starring Faye Dunaway as Crawford.

</doc>
<doc id="45971" url="https://en.wikipedia.org/wiki?curid=45971" title="Pentecost">
Pentecost

Pentecost (, "Pentēkostē "the fiftieth [day") is the Greek name for "Shavuot" (, lit. "Weeks"), the Feast of Weeks, a prominent feast in the calendar of ancient Israel celebrating the giving of the Law to Moses at Sinai. In Christianity, Pentecost is celebrated fifty days after Easter Sunday, inclusively (i.e., 49 days with the first day counted, seven weeks), hence its name. In Judaism, "Shavuot" is on the sixth day of the Hebrew month of Sivan (late May or early June). Pentecost falls on the tenth day after Ascension Thursday (which itself is 40 days after Easter).
The feast is also called "White Sunday", or "Whitsunday", especially in the United Kingdom, where traditionally the next day, Whit Monday, was also a public holiday. In Eastern Christianity, Pentecost can also refer to the entire fifty days between Easter and Pentecost, hence the book containing the liturgical texts for Paschaltide is called the Pentecostarion.
In the New Testament, Pentecost was the occasion of the descent of the Holy Spirit upon the Apostles and other followers of Jesus Christ, as described in the Acts of the Apostles . and therefore in the Christian liturgical year, it became a feast commemorating this occasion. For this reason, Pentecost is described by some Christians as the "Birthday of the Church". The Pentecostal movement of Christianity derives its name from this New Testament event, as the movement emphasizes direct personal experience with God, akin to the Descent of the Holy Spirit upon the Apostles.
Old Testament.
Pentecost is the old Greek and Latin name for the Jewish (Hebrew חג השבועות "Chag ha-Shavuot") Festival of Weeks, which can be found in the Hebrew Bible. Shavuot, called the Festival of Weeks (Hebrew: חג השבועות, Chag ha-Shavuot) in Exodus 34:22 and Deuteronomy 16:10, is also called the Festival of Reaping (Hebrew: חג הקציר, Chag ha-Katsir) in Exodus 23:16, and Day of the First Fruits (Hebrew יום הביכורים, Yom ha-Bikkurim) in Numbers 28:26.
Jews traditionally read the Book of Ruth at Pentecost, as the story links with the grain harvest theme of the festival.
Extra-Biblical and post-Biblical Jewish texts.
The Talmud refers to Shavuot as "Atzeret" (Hebrew: עצרת, literally, "refraining" or "holding back"), referring to the prohibition against work on this holiday and to the conclusion of the holiday and season of Passover. Since Shavuot occurs 49 days after the first day of Passover (i.e., the 50th day, including Passover itself), Hellenistic Jews gave it the name Pentecost (πεντηκοστή, "fiftieth day").
According to Jewish tradition, Pentecost commemorates God's giving of the Ten Commandments at Mount Sinai, 49 days after the Exodus. The Talmud derives this from a calculation based on Biblical texts.
There is a Jewish tradition that King David was born and died at Pentecost. In the Apostle Peter's first sermon, recorded in Acts 2:14-39, he linked the life, death and ascension of Jesus to King David's death, burial and hope of immortality.
New Testament.
The biblical narrative of Pentecost is given in the second chapter of the Book of Acts. Present were about one hundred and twenty followers of Christ (Acts 1:15), including the Twelve Apostles (i.e. the Eleven faithful disciples and Matthias who was Judas' replacement) (Acts 1:13, 26), his mother Mary, various other women disciples and his brothers (Acts 1:14).
Their reception of the Holy Spirit in the Upper Room is recounted in Acts 2:1–6:
And when the day of Pentecost was fully come, they were all with one accord in one place. And suddenly there came a sound from heaven as of a rushing mighty wind, and it filled all the house where they were sitting. And there appeared unto them cloven tongues like as of fire, and it sat upon each of them. And they were all filled with the Holy Spirit, and began to speak with other languages, as the Spirit gave them utterance. And there were dwelling at Jerusalem Jews, devout men, out of every nation under heaven. Now when this was noised abroad, the multitude came together, and were confounded, because that every man heard them speak in his own language.
While those on whom the Spirit had descended were speaking in many languages, the Apostle Peter stood up with the eleven and proclaimed to the crowd that this event was the fulfillment of the prophecy ("I will pour out my spirit"). In Acts 2:17, it reads: "'And in the last days,' God says, 'I will pour out my spirit upon every sort of flesh, and your sons and your daughters will prophesy and your young men will see visions and your old men will dream dreams." He also mentions (2:15) that it was the third hour of the day (about 9:00 AM). Acts 2:41 then reports: "Then they that gladly received his word were baptized: and the same day there were added unto them about three thousand souls."
Peter stated that this event was the beginning of a continual outpouring that would be available to all believers from that point on, Jews and Gentiles alike.
Location of the first Pentecost.
Traditional interpretation holds that the Descent of the Holy Spirit took place in the Upper Room, or Cenacle, while celebrating the day of Pentecost (Shavuot). The Upper Room was first mentioned in Luke 22:12–13 ( ""And he shall shew you a large upper room furnished: there make ready. And they went, and found as he had said unto them: and they made ready the passover"."). This Upper Room was to be the location of the Last Supper and the institution of Holy Communion. The next mention of an Upper Room is in Acts 1:13–14, the continuation of the Luke narrative, authored by the same biblical writer.
Here the disciples and women wait and they gave themselves up to constant prayer: ""And when they were come in, they went up into an upper room, where abode both Peter, and James, and John, and Andrew, Philip, and Thomas, Bartholomew, and Matthew, James the son of Alphaeus, and Simon Zelotes, and Judas the brother of James. These all continued with one accord in prayer and supplication, with the women, and Mary the mother of Jesus, and with his brethren.""
Then, in Acts 2:1–2, ""And when the day of Pentecost was fully come, they were all with one accord in one place. And suddenly there came a sound from heaven as of a rushing mighty wind, and it filled all the house where they were sitting."," "They" refers to the aforementioned disciples, and it includes the women. The "place" referring to the same Upper Room where these persons had """continued" with one accord in prayer and supplication". "
Date.
According to the current Jewish Calendar, the date of Pentecost is fifty days from Passover. In Jewish antiquity dates were disputed, as in the Dead Sea scrolls or in the Mishnah.
In Christian tradition Pentecost is part of the Moveable Cycle of the ecclesiastical year. According to Christian tradition, Pentecost is always seven weeks after Easter Sunday; that is to say, 50 days after Easter (inclusive of Easter Day). In other words, it falls on the eighth Sunday, counting Easter Day. The date of Easter may be calculated using a procedure known as Computus.
Since the date of Easter is calculated differently in the East and West (see Easter controversy), in most years the two traditions celebrate Pentecost on different days (though in some years the celebrations will coincide, as in 2010, 2011, and 2014). In the West, the earliest possible date is May 10 (as in 1818 and 2285), and the latest possible date June 13 (as in 1943 and 2038). In the East, this range of possible dates presently corresponds from May 23 to June 26 on the Gregorian calendar.
Liturgical celebration.
Eastern churches.
In the Eastern Orthodox Church, Pentecost is one of the Orthodox Great Feasts and is considered to be the highest ranking Great Feast of the Lord, second in rank only to Pascha. The service is celebrated with an All-night Vigil on the eve of the feast day, and the Divine Liturgy on the day of the feast itself. Orthodox churches are often decorated with greenery and flowers on this feast day, and the celebration is intentionally similar to the Jewish holiday of Shavuot, which celebrates the giving of the Mosaic Law.
The feast itself lasts three days. The first day is known as "Trinity Sunday"; the second day is known as "Spirit Monday" (or "Monday of the Holy Spirit"); and the third day, Tuesday, is called the "Third Day of the Trinity." The Afterfeast of Pentecost lasts for one week, during which fasting is not permitted, even on Wednesday and Friday. In the Orthodox Tradition, the liturgical color used at Pentecost is green, and the clergy and faithful carry flowers and green branches in their hands during the services.
An extraordinary service called the Kneeling Prayer, is observed on the night of Pentecost. This is a Vespers service to which are added three sets of long poetical prayers, the composition of Saint Basil the Great, during which everyone makes a full prostration, touching their foreheads to the floor (prostrations in church having been forbidden from the day of Pascha (Easter) up to this point). Uniquely, these prayers include a petition for all of those in hell, that they may be granted relief and even ultimate release from their confinement, if God deems this possible.
All of the remaining days of the ecclesiastical year, until the preparation for the next Great Lent are named for the day after Pentecost on which they occur (for example, the 13th Tuesday After Pentecost).
The Second Monday after Pentecost is the beginning of the Apostles' Fast (which continues until the Feast of Saints Peter and Paul on June 29). Theologically, Orthodox do not consider Pentecost to be the "birthday" of the Church; they see the Church as having existed before the creation of the world (cf. "The Shepherd of Hermas")
The Orthodox icon of the feast depicts the Twelve Apostles seated in a semicircle (sometimes the Theotokos (Virgin Mary) is shown sitting in the center of them). At the top of the icon, the Holy Spirit, in the form of tongues of fire, is descending upon them. At the bottom is an allegorical figure, called "Kosmos", which symbolizes the world. Although Kosmos is crowned with earthly glory he sits in the darkness caused by the ignorance of God. He is holding a towel on which have been placed 12 scrolls, representing the teaching of the Twelve Apostles.
In the ancient "Coptic Orthodox Church of Alexandria", Pentecost is one of the seven Major "Lord's Feasts". It is celebrated at the time of ninth hour (3:00pm) on the Sunday of Pentecost by a special three-segment prayer known as the "Office of Genuflection (Kneeling Prayer)". This feast is followed with the "Apostles Fast" which has a fixed end date on the fifth of the Coptic month of Epip currently falls on July 12, which is equivalent to June 29, due to the current 13-day Julian-Gregorian calendar offset. The fifth of Epip is the commemoration of the Martyrdom of St. Peter and Paul.
Western churches.
The liturgical celebrations of Pentecost in Western churches are as rich and varied as those in the East. The main sign of Pentecost in the West is the color red. It symbolizes joy and the fire of the Holy Spirit.
Priests or ministers, and choirs wear red vestments, and in modern times, the custom has extended to the lay people of the congregation wearing red clothing in celebration as well. Red banners are often hung from walls or ceilings to symbolize the blowing of the "mighty wind" and the free movement of the Spirit.
The celebrations may depict symbols of the Holy Spirit, such as the dove or flames, symbols of the church such as Noah's Ark and the Pomegranate, or especially within Protestant churches of Reformed and Evangelical traditions, words rather than images naming for example, the gifts and Fruits of the Spirit. Red flowers at the altar/preaching area, and red flowering plants such as geraniums around the church are also typical decorations for Pentecost masses/services. These symbolize the renewal of life, the coming of the warmth of summer, and the growth of the church at and from the first Pentecost. In the southern hemisphere, for example, in southern Australia, Pentecost comes in the mellow autumntide, after the often great heat of summer, and the red leaves of the poinsettia have often been used to decorate churches then.
These flowers often play an important role in the ancestral rites, and other rites, of the particular congregation. For example, in both Protestant and Catholic churches, the plants brought in to decorate for the holiday may be each "sponsored" by individuals in memory of a particular loved one, or in honor of a living person on a significant occasion, such as their Confirmation day.
In the German speaking lands, in Central Europe, and wherever the people of these nations have wandered, green branches are also traditionally used to decorate churches for Pentecost. Birch is the tree most typically associated with this practice in Europe, but other species are employed in different climates.
The singing of Pentecost hymns is also central to the celebration in the Western tradition. Hymns such as Martin Luther's "Komm, Heiliger Geist, Herre Gott" (Come, Holy Spirit, God and Lord), Charles Wesley's "Spirit of Faith Come Down" and "Come Holy Ghost Our Hearts Inspire" or Hildegard von Bingen's "O Holy Spirit Root of Life" are popular. Some traditional hymns of Pentecost make reference not only to themes relating to the Holy Spirit or the church, but to folk customs connected to the holiday as well, such as the decorating with green branches.
Consider "Oh that I had a Thousand Voices" (""O daß ich tausend Zungen hätte"") by German, Johann Mentzer Verse 2: ""Ye forest leaves so green and tender, that dance for joy in summer air"…" or "O Day Full of Grace" (""Den signede Dag"") by Dane, N. F. S. Grundtvig verse 3: ""Yea were every tree endowed with speech and every leaflet singing"…". In the Roman Catholic Church, Veni Sancte Spiritus is the sequence hymn for the Day of Pentecost. This has been translated into many languages and is sung in many denominations today. See also Veni Creator Spiritus.
Trumpeters or brass ensembles are often specially contracted to accompany singing and provide special music at Pentecost services, recalling the Sound of the mighty wind. While this practice is common among a wide spectrum of Western denominations (Eastern Churches do not employ instrumental accompaniment in their worship) it is particularly typical, and distinctive to the heritage of the Moravian Church.
Another custom is reading the appointed Scripture lessons in multiple foreign languages recounting the speaking in tongues recorded in .
In the Middle Ages, cathedrals and great churches throughout Western Europe were fitted with a peculiar architectural feature known as a Holy Ghost hole; a small circular opening in the roof that symbolized the entrance of Holy Spirit into the midst of the assembled worshippers. At Pentecost, these Holy Ghost holes would be decorated with flowers, and sometimes a dove figure lowered through into the church while the story of the Pentecost was read. Holy Ghost holes can still be seen today in European churches such as Canterbury Cathedral.
Similarly, a large two dimensional dove figure would be, and in some places still are, cut out of wood, painted and decorated with flowers, to be lowered over the people, particularly during the singing of the sequence hymn, or Veni Creator Spiritus. In other places, particularly Sicily and the Italian peninsula, rose petals were and are thrown from the galleries over the congregation calling to mind the tongues of fire. In modern times, this practice has been revived, and interestingly adapted as well, to include the strewing of origami doves from above, or suspending them – sometimes by the hundreds – from the ceiling.
In some cases, red fans, or red handkerchiefs are distributed to the assembled worshippers to be waved during the procession, etc. Other congregations have incorporated the use of red balloons, signifying the "Church's Birthday" into their festivities. These may be carried by worshippers, used to decorate the sanctuary, or released all at once.
Fasting, baptisms, and confirmations.
For some Protestants, the nine days between Ascension Day, and Pentecost are set aside as a time of fasting, and world-wide prayer in honor of the disciples' time of prayer and unity awaiting the Holy Spirit. Similarly among Roman Catholics, special Pentecost Novenas are held. The Pentecost Novena is considered the first Novena, all other Novenas offered in preparation of various festivals and Saints days deriving their practice from those original nine days of prayer observed by the disciples of Christ.
While the Eve of Pentecost was traditionally a day of fasting for Catholics, today's canon law no longer requires it. Both Catholics and Protestants may hold spiritual retreats, prayer vigils and litanies in the days leading up to Pentecost. In some cases vigils on the Eve of Pentecost may last all night. Pentecost is also one of the occasions specially appointed for the Lutheran Litany to be sung.
From the early days of Western Christianity, Pentecost became one of the days set aside to celebrate Baptism. In Northern Europe Pentecost was preferred even over Easter for this rite, as the temperatures in late spring might be supposed to be more conducive to outdoor immersion as was then the practice. It is proposed that the term Whit Sunday derives from the custom of the newly baptized wearing white clothing, and from the white vestments worn by the clergy in English liturgical uses. The holiday was also one of the three days each year (along with Christmas and Easter) Roman Catholics were required to confess and receive the sacrament of Holy Communion in order to remain in good church standing.
Holy Communion is likewise often a feature of the Protestant observance of Pentecost as well. It is one of the relatively few Sundays some Reformed denominations may offer the communion meal, and is one of the days of the year specially appointed among Moravians for the celebration of their Love Feasts. Ordinations are celebrated across a wide array of Western denominations at Pentecost, or near to it. In some denominations, for example the Lutheran Church, even if an ordination or consecration of a deaconess is not celebrated on Pentecost, the liturgical color will invariably be red, and the theme of the service will be the Holy Spirit.
Above all, Pentecost is a day for the Confirmation celebrations of young people. Flowers, the wearing of white robes, or white dresses recalling Baptism, rites such as the laying on of hands, and vibrant singing play prominent roles on these joyous occasions, the blossoming of Spring forming an equal analogy with the blossoming of youth.
The typical image of Pentecost in the West is that of the Virgin Mary seated centrally and prominently among the disciples, with flames resting on the crowns of their heads. Occasionally parting clouds suggesting the action of the "mighty wind", rays of light, and/or the Dove, are also depicted. Of course, the Western iconographic style is less static and stylized than that of the East, and other very different representations have been produced, and in some cases have achieved great fame, such as the Pentecosts by Titian, Giotto and el Greco.
Paul already in the 1st century notes the importance of this festival to the early Christian communities. (See: & ) Since the lifetime of some who may have been eyewitnesses, annual celebrations of the descent of the Holy Spirit have been observed. Before the Second Vatican Council Pentecost Monday as well was a Holy Day of Obligation during which the Catholic Church addressed the newly baptized and confirmed. Since that time however Pentecost Monday is no longer solemnized.
Nevertheless, Pentecost Monday remains an official church festival in many Protestant churches, such as the (Lutheran) Church of Sweden, the Evangelical Lutheran Church of Finland, and others. In the Byzantine Catholic Rite Pentecost Monday is no longer a Holy Day of Obligation, but rather a simple holy day. In the Extraordinary Form of the liturgy of the Roman Catholic Church, as at Easter, the liturgical rank of Monday and Tuesday of Pentecost week is a Double of the First Class and across many Western denominations, Pentecost is celebrated with an octave culminating on Trinity Sunday. However,in the modern Roman Rite (Ordinary Form), Pentecost ends after Evening Prayer on the feast day itself, with Ordinary Time resuming the next day.
Marking the festival's importance, in several denominations, such as the Lutheran, Episcopal and United Methodist churches (and formerly in the Roman Catholic Church), all the Sundays from the holiday itself until the next Advent in late November or December are designated the 2nd, 3rd, Nth, Sunday after Pentecost, etc. Throughout the year, in Roman Catholic piety, the Pentecost is the third of the Glorious Mysteries of the Holy Rosary, as well as being one of the Stations of the Resurrection, or Via Lucis.
In some Evangelical and Pentecostal churches, where there is less emphasis on the liturgical year, Pentecost may still be one of the greatest celebrations in the year, such as in Germany or Romania. In other cases, Pentecost may be ignored as a holy day in these churches. In many evangelical churches in the United States, the secular holiday, Mother's Day, may be more celebrated than the ancient and biblical feast of Pentecost. Some evangelicals and Pentecostals are observing the liturgical calendar and observe Pentecost as a day to teach the Gifts of the Holy Spirit.
Across denominational lines Pentecost has been an opportunity for Christians to honor the role of the Holy Spirit in their lives, and celebrate the birth of the church in an ecumenical context.
Classical compositions for Pentecost.
The Lutheran church of the Baroque observed three days of Pentecost. Some composers wrote sacred cantatas to be performed in the church services of these days. Johann Sebastian Bach composed several cantatas for days of Pentecost, including ""Erschallet, ihr Lieder, erklinget, ihr Saiten!" BWV 172" in 1714 and "Also hat Gott die Welt geliebt", BWV 68 in 1725. Gottfried Heinrich Stölzel wrote cantatas such as "Werdet voll Geistes" (Get full of spirit) in 1737. Mozart composed an antiphon "Veni Sancte Spiritus" in 1768.
Olivier Messiaen composed an organ mass "Messe de la Pentecôte" in 1949/50. In 1964 Fritz Werner wrote an oratorio for Pentecost "Veni, sancte spiritus" (Come, Holy Spirit) on the sequence "Veni sancte spiritus", and Jani Christou wrote "Tongues of Fire", a Pentecost oratorio. Richard Hillert wrote a "Motet for the Day of Pentecost" for choir, vibraphone, and prepared electronic tape in 1969. Violeta Dinescu composed "Pfingstoratorium", an oratorio for Pentecost for five soloists, mixed chorus and small orchestra in 1993.
Customs and traditions.
In Italy it was customary to scatter rose petals from the ceiling of the churches to recall the miracle of the fiery tongues; hence in Sicily and elsewhere in Italy Whitsunday is called "Pasqua rosatum". The Italian name "Pasqua rossa" comes from the red colours of the vestments used on Whitsunday.
In France it was customary to blow trumpets during Divine service, to recall the sound of the mighty wind which accompanied the Descent of the Holy Spirit.
In the north west of England, church and chapel parades called Whit Walks take place at Whitsun (sometimes on Whit Friday, the Friday after Whitsun). Typically, the parades contain brass bands and choirs; girls attending are dressed in white. Traditionally, Whit Fairs (sometimes called Whitsun Ales) took place. Other customs such as morris dancing and cheese rolling are also associated with Whitsun. "Whitsunday" has been the name of the day in the Church of England. (The Book of Common Prayer only once uses the word "Pentecost" for the festival. Though some think that name derives from white clothes worn by newly baptised in Eastertide, it may well be seen as derived from "wit", hence "wisdom", the reference being to Holy Wisdom (Sancta Sophia, Hagia Sophia), referred to in Proverbs and the Book of Wisdom, with which the Holy Spirit has often been identified.
In Finland there is a saying known virtually by everyone which translates as "if one has no sweetheart until Pentecost, he/she will not have it during the whole summer."
In Port Vila, the capital of Vanuatu, people originating from Pentecost Island usually celebrate their island's name-day with a special church service followed by cultural events such as dancing.
Public holiday.
Since Pentecost itself is on a Sunday, it is automatically a public holiday in Christian countries.
Pentecost Monday is a public holiday in many European countries including Austria, Belgium, Cyprus, Denmark, France, Germany, Greece, Hungary, Iceland, Luxembourg, the Netherlands, Norway, Portugal, Romania (since 2008), (most parts of) Switzerland, Ukraine and also in the African nations Senegal, Benin and Togo.
In Sweden it was also a public holiday, but Pentecost Monday (Annandag Pingst) was replaced by Swedish National Day on June 6, by a government decision on December 15, 2004. In Italy and Malta, it is no longer a public holiday. It was a public holiday in Ireland until 1973, when it was replaced by Early Summer Holiday on the first Monday in June. In the United Kingdom the day is known as Whit Monday, and was a bank holiday until 1967 when it was replaced by the Spring Bank Holiday on the last Monday in May. In France, following reactions to the implementation of the "Journée de solidarité envers les personnes âgées", Pentecost Monday has been reestablished as a holiday (but a "working holiday") on May 3, 2005.
Literary allusions.
According to legend, King Arthur always gathered all his knights at the round table for a feast and a quest on Pentecost:
"So ever the king had a custom that at the feast of Pentecost in especial, afore other feasts in the year, he would not go that day to meat until he had heard or seen of a great marvel."
German poet Johann Wolfgang von Goethe declared Pentecost "das liebliche Fest" – the lovely Feast, in a selection by the same name in his "Reineke Fuchs".
"Pfingsten, das liebliche Fest", speaks of Pentecost as a time of greening and blooming in fields, woods, hills, mountains, bushes and hedges, of birds singing new songs, meadows sprouting fragrant flowers, and of festive sunshine gleaming from the skies and coloring the earth – iconic lines idealizing the Pentecost holidays in the German-speaking lands.
Further, Goethe records an old peasant proverb relating to Pentecost in his "Sankt-Rochus-Fest zu Bingen"
– "Ripe strawberries at Pentecost mean a good wine crop."
Alexandre Dumas, père mentions of Pentecost in "Twenty Years After" (French: Vingt ans après), the sequel to "The Three Musketeers". A meal is planned for the holiday, to which La Ramée, second in command of the prison, is invited, and by which contrivance, the Duke is able to escape. He speaks sarcastically of the festival to his jailor, foreshadowing his escape : ""Now, what has Pentecost to do with me? Do you fear, say, that the Holy Ghost may come down in the form of fiery tongues and open the gates of my prison?""
William Shakespeare mentions Pentecost in a line from "Romeo and Juliet" Act 1, Scene V. At the ball at his home, Capulet speaks in refuting an overestimate of the time elapsed since he last danced: ""What, man? 'Tis not so much, 'tis not so much! 'Tis since the nuptial of Lucentio, Come Pentecost as quickly as it will, Some five-and-twenty years, and then we mask'd."" Note here the allusion to the tradition of mumming, Morris dancing and wedding celebrations at Pentecost.

</doc>
<doc id="45975" url="https://en.wikipedia.org/wiki?curid=45975" title="Whatì">
Whatì

Whatì (from the Dogrib language meaning "Marten Lakes"), officially the Tłı̨chǫ Community Government of Whatì is a First Nations community in the North Slave Region of the Northwest Territories, Canada. Whatì is located by Lac La Martre, about northwest of the territorial capital of Yellowknife.
History.
With rich and varied wildlife, the area has long been a favoured hunting ground of the Tłı̨chǫ (Dogrib Dene) Aboriginal people. The North West Company established a trading post there in 1793, and many natives began settling there permanently, while they continued to hunt and fish in the area. With the establishment of a trading post at Fort Rae on Great Slave Lake in the late 19th century, most regional trading was accomplished at the HBC and free traders posts there. A trading post at Lac La Martre was not again established until the 1920s. 
On 1 January 1996, the community officially changed its name from Lac La Martre to the Tłı̨chǫ name "Wha Ti", meaning "Marten Lake," the same meaning as the French and then on 4 August 2005 to the current spelling. Other traditional Tli Cho names for the settlement include Tsoti ('fouled water lake') and Mine Go Kola ('net fishing with houses').
Demographics.
At the 2011 census the population was 492, an increase of 7.0% over the 2006 census. In 2006 there were 435 Aboriginal people all of which were North American Indians. In 2012 the Government of the Northwest Territories reported that the population was 519 with an average yearly growth rate of 0.4% from 2001.
Economy.
While trapping, hunting, and fishing continue to be the main economic activities in this traditional community, efforts have been made to develop tourism as well. A fishing lodge was opened, and many tourists come to see the abundant wildlife, including black bears, barren-ground caribou, gray wolves, and eagles. The community takes special pride in the fact that no alcohol is allowed there.
Whatì is part of the Tlicho Government.

</doc>
<doc id="45976" url="https://en.wikipedia.org/wiki?curid=45976" title="Compromise of 1850">
Compromise of 1850

The Compromise of 1850 was a package of five separate bills passed by the United States Congress in September 1850, which defused a four-year political confrontation between slave and free states regarding the status of territories acquired during the Mexican–American War (1846–48). The compromise, drafted by Whig Senator Henry Clay of Kentucky and brokered by Clay and Democratic Senator Stephen Douglas of Illinois, reduced sectional conflict. Controversy arose over the Fugitive Slave provision. The Compromise was greeted with relief, although each side disliked specific provisions.
The Compromise became possible after the sudden death of President Zachary Taylor, who, although a slaveowner, had favored excluding slavery from the Southwest. Whig leader Henry Clay designed a compromise, which failed to pass in early 1850, due to opposition by both pro-slavery southern Democrats, led by John C. Calhoun, and anti-slavery northern Whigs. Upon Clay's instruction, Douglas then divided Clay's bill into several smaller pieces and narrowly won their passage over the opposition of those with stronger views on both sides.
Background.
Soon after the start of the Mexican War, when the extent of the contested territories was still unclear, the question of whether to allow slavery in those territories polarized the Northern and Southern United States in the most bitter sectional conflict up to this time. Since Texas was a slave state, not only the residents of that State, but the pro- and anti-slavery camps on a national scale had an interest in the size of the state of Texas. Texas claimed land north of the 36°30' demarcation line for slavery set by the 1820 Missouri Compromise.
The Texas Annexation resolution had required that if any new states were formed out of Texas' lands, those north of the Missouri Compromise line would become free states.
According to historian Mark Stegmaier, "The Fugitive Slave Act, the abolition of the slave trade in the District of Columbia, the admission of California as a free state, and even the application of the formula of popular sovereignty to the territories were all less important than the least remembered component of the Compromise of 1850--the statute by which Texas relinquished its claims to much of New Mexico in return for federal assumption of the debts."
Stegmaier also refers to "the principal Southern demand for a division of California at the line of 35° north latitude" and says that "Southern extremists made clear that a congressionally mandated division of California figured uppermost on their agenda."
During the deadlock of four years, the Second Party System broke up, Mormon pioneers settled Utah, the California Gold Rush settled northern California, and New Mexico under a federal military government turned back Texas' attempt to assert control over territory Texas claimed as far west as the Rio Grande. The eventual Compromise of 1850 preserved the Union, but only for another decade.
Various proposals.
Proposals during 1846–50 on the division of the Southwest included:
Final proposed compromise.
On January 29, 1850, Whig Senator Henry Clay gave a speech which called for compromise on the issues dividing the Union. However, Clay's specific proposals for achieving a compromise, including his idea for Texas' boundary, were not adopted in a single bill. Upon Clay's urging, Senator Stephen A. Douglas, Democrat of Illinois, divided Clay's bill into several smaller bills, and passed each separately. When he instructed Douglas, Clay was nearly dead and unable to guide the congressional debate any further. The Compromise came to coalesce around a plan dividing Texas at its present-day boundaries, creating territorial governments with "popular sovereignty" (without the Wilmot Proviso) for New Mexico and Utah, admitting California as a free state, abolishing the slave trade in the District of Columbia, and enacting a new fugitive slave law.
The Compromise of 1850 was formally proposed by Clay and guided to passage by Douglas over Northern Whig and Southern Democrat opposition. It was enacted September 1850:
Seward and Northern Whigs.
Most Northern Whigs, led by William Henry Seward who delivered his famous "Higher Law" speech during the controversy, opposed the Compromise as well because it would not have applied the Wilmot Proviso to the western territories and because of the newly strengthened fugitive slave act, which would have pressed ordinary citizens into duty on slave-hunting patrols. This provision was inserted by Democratic Virginia Senator James M. Mason to entice border-state Whigs, who faced the greatest danger of losing slaves as fugitives but who were lukewarm on general sectional issues related to the South into supporting Texas's land claims.
Zachary Taylor avoided the issue as the Whig candidate during the 1848 U.S. presidential election but then as President attempted to sidestep the entire controversy by pushing to admit California and New Mexico as free states immediately, avoiding the entire territorial process and thus the Wilmot Proviso question. Taylor's stand was unpopular among Southerners and surprised them because Taylor was a Southerner.
Northern Democrats and Southern Whigs supported the Compromise. Southern Whigs, many of whom were from the border states, supported the stronger fugitive slave law.
Debate and results.
On April 17, a "Committee of Thirteen" agreed on the border of Texas as part of Clay's plan. The dimensions were later changed. That same day, during debates on the measures in the Senate, Vice President Millard Fillmore and Senator Benton verbally sparred, with Fillmore charging that the Missourian was "out of order." During the heated debates, Compromise floor leader Henry S. Foote of Mississippi drew a pistol on Senator Benton.
In early June, nine slave holding Southern states sent delegates to the Nashville Convention to determine their course of action should the compromise take hold. While some delegates preached secession, eventually the moderates ruled, and they proposed a series of compromises, including extending the geographic dividing line designated by the Missouri Compromise of 1820 to the Pacific Coast.
The various bills were initially combined into one "omnibus" bill. Despite Clay's efforts, it failed in a crucial vote on July 31, opposed by southern Democrats and by northern, anti-slavery Whigs. He announced on the Senate floor the next day that he intended to persevere and pass each individual part of the bill. The 73-year-old Clay, however, was physically exhausted as the effects of the tuberculosis that would eventually kill him began to take its toll. Clay left the Senate to recuperate in Newport, Rhode Island, while Stephen A. Douglas wrote the separate bills and guided them through the Senate.
The situation had been changed by the sudden death of President Taylor and the accession of Vice President Millard Fillmore to the presidency, on July 9, 1850. President Fillmore, anxious to find a quick solution to the conflict in Texas over the border with New Mexico, which threatened to become armed conflict between Texas militia and Federal soldiers, reversed the administration's position late in July and threw its support to the compromise measures. The Northern Democrats held together and supported each of the bills and gained Whigs or Southern Democrats to pass each one. All passed and were signed by Fillmore between September 9 and September 20, 1850.
Clay was still given much of the credit for the Compromise's success. It quieted the controversy between Northerners and Southerners over the expansion of slavery and delayed secession and civil war for another decade. Senator Henry S. Foote of Mississippi, who had suggested the creation of the Committee of Thirteen, later said, "Had there been one such man in the Congress of the United States as Henry Clay in 1860–'61 there would, I feel sure, have been no civil war."
Implications.
The Compromise in general proved widely popular politically, as both parties committed themselves in their platforms to the finality of the Compromise on sectional issues. The strongest opposition in the South occurred in the states of South Carolina, Georgia, Alabama, and Mississippi, but unionists soon prevailed, spearheaded by Georgians Alexander Stephens, Robert Toombs, and Howell Cobb and the creation of the Georgia Platform. This peace was broken only by the divisive Kansas–Nebraska Act of 1854 introduced by Stephen Douglas, which had the effect of repealing the Missouri Compromise and led directly to the formation of the Republican Party, whose capture of the national government in 1860 led directly to the secession crisis of 1860–61.
Many historians argue that the Compromise played a major role in postponing the American Civil War for a decade, during which time the Northwest was growing more wealthy and more populous, and was being brought into closer relations with the Northeast. During that decade, the Whig Party had completely broken down, being replaced with the new Republican Party dominant in the North and the Democrats in the South. But others argue that the Compromise only made more obvious pre-existing sectional divisions and laid the groundwork for future conflict. In this view, the Fugitive Slave Law helped polarize North and South, as shown in the enormous reaction to Harriet Beecher Stowe's novel "Uncle Tom's Cabin". The passage of the Fugitive Slave Law aroused feelings of bitterness in the North. Furthermore, the Compromise of 1850 led to a breakdown in the spirit of compromise in the United States in the antebellum period, directly before the Civil War. The Compromise exemplifies this spirit, but the deaths of influential senators who worked on the compromise, primarily Henry Clay and Daniel Webster, contributed to this feeling of increasing disparity between the North and South.
The delay of hostilities for ten years allowed the free economy of the northern states to continue to industrialize. The southern states, to a large degree based on slave labor and cash crop production, lacked the ability to industrialize heavily. By 1860, the northern states had added many more miles of railroad, steel production, modern factories, and population to the advantages it possessed in 1850. The North was better able to supply, equip, and man its armed forces, an advantage that would prove decisive in the later stages of the war.
Issues.
Three major types of issues were addressed by the Compromise of 1850, to wit: a variety of boundary issues; status of territory issues; and the issue of slavery. While capable of analytical distinction, the boundary and territory issues were actually included in the overarching issue of slavery. Pro- and anti-slavery interests were each concerned with both the amount of land on which slavery was permitted and with the number of States which respectively would be in the slave or free camps. Since Texas was a slave state, not only the residents of that state, but the pro- and anti-slavery camps on a national scale had an interest in the size of the state of Texas.
The general solution that was adopted by the Compromise of 1850 was to transfer a considerable part of the territory claimed by the state of Texas to the federal government, to formally organize two new territories, the Territory of New Mexico and the Territory of Utah, which expressly would be allowed to locally determine whether they would become slave or free territories, to add another free state to the Union (California), adopt a severe measure to recover slaves who had escaped to a free state or free territory (the Fugitive Slave Law), and to abolish the slave trade in the District of Columbia.
Texas.
The independent Republic of Texas won the decisive Battle of San Jacinto (April 21, 1836) against Mexico and captured Mexican president Antonio Lopez de Santa Anna. He signed the Treaties of Velasco, which recognized the Rio Grande as the boundary of the Republic of Texas. The treaties were repudiated by the government of Mexico which insisted it was sovereign over Texas and promised to reclaim the lost territories. To the extent that there was a de facto recognition, Mexico treated the Nueces River as its northern boundary control. A huge, largely unsettled area lay between the two rivers. Neither Mexico nor the Republic of Texas had the military strength to effectively assert its territorial claim. On December 29, 1845, the Republic of Texas was annexed to the United States and became the 28th state. Texas was staunchly committed to slavery, with its constitution making illegal the unauthorized emancipation of slaves by their owners. With this annexation the United States inherited the territorial claims of the former Republic of Texas against Mexico. The territorial claim to the area between the Nueces River and the Rio Grande and Mexican resistance to it led to the Mexican–American War. On February 2, 1848, that war was concluded by the Treaty of Guadalupe Hidalgo. Among the provisos of the Treaty was the recognition by Mexico of the area between the Nueces River and the Rio Grande being a part of the United States.
The Republic of Texas had claimed ownership of the eastern half of present-day New Mexico, along with sections of Colorado, Kansas and Wyoming, but Texas had never effectively controlled the area, which was dominated by hostile Indian tribes (see Comancheria). However, the federal government now controlled the area after 1846. The Compromise of 1850 solved the problem by setting the present boundaries of Texas in return for $10 million in federal bonds paid to the state of Texas.
The state of Texas was heavily burdened with debt, which had been contracted during its struggles as the Republic of Texas. The federal government agreed to pay $10 million of bonds in trade for the transfer of a large portion of the claimed area of the state of Texas to the territory of the federal government and for the relinquishment of various claims which Texas had upon the federal government. (These bonds bore interest at the rate of 5%, which interest was collectible by Texas every six months, and the principal was redeemable at the end of fourteen years.)
The Constitution (Article IV, Section 3) does not permit Congress to unilaterally reduce the territory of any state, so the first part of the Compromise of 1850 had to take the form of an offer to the Texas State Legislature, rather than a unilateral enactment. The Texas State Legislature did ratify the bargain and in due course the transfer of a large swath of land from the state of Texas to the federal government was accomplished. Texas was allowed to keep the following portions of the erstwhile disputed land: that which is south of the 32nd parallel, and that which is south of the 36°30' parallel north and east of the 103rd meridian west. The rest of the land which had been disputed between Mexico and the Republic of Texas was transferred to federal government.
New Mexico and Utah Territories.
The first law of the Compromise of 1850 also organized the Territory of New Mexico. The second law, also enacted September 9, 1850, organized the Territory of Utah.
Some of the land had been claimed by the Republic of Texas. The Treaty of Guadalupe Hidalgo made no mention of the claims of the Republic of Texas; Mexico simply agreed to a Mexico-U.S. border south of both the "Mexican Cession" and the Republic of Texas claims. Before the Compromise of 1850, this disputed land had been claimed but never controlled by the state of Texas. Of importance in 1850 was land included in present-day eastern New Mexico.
From the Mexican Cession, the New Mexico Territory received most of the present-day state of Arizona, most of the western part of the present-day state of New Mexico, and the southern tip of present-day Nevada (south of the 37th parallel). From Texas, the territory received most of present-day eastern New Mexico, a portion of present-day Colorado (east of the crest of the Rocky Mountains, west of the 103rd meridian, and south of the 38th parallel).
From the Mexican Cession, the Utah Territory received present-day Utah, most of present-day Nevada (everything north of the 37th parallel), a major part of present-day Colorado (everything west of the crest of the Rocky Mountains), and a small part of present-day Wyoming. This included the newly founded colony at Salt Lake of Brigham Young. From Texas, the Utah Territory received most of present-day eastern New Mexico, and some of present-day Colorado that is east of the crest of the Rocky Mountains.
A key provision of each of the laws respectively organizing the Territory of New Mexico and the Territory of Utah was that slavery would be either permitted or prohibited as a local option (Popular Sovereignty). This was an important repudiation of the idea behind the Wilmot Proviso (which never passed Congress); it would have forbidden slavery in any territory acquired from Mexico.
California.
California also became part of the U.S. as a result of the Mexican Cession. After the Mexican War, California was essentially run by military governors. President James K. Polk tried to get Congress to officially establish a territorial government in California, but the increasing North vs. South debates prevented this. The South wanted to extend slave territory to Southern California and to the Pacific coast, while the North did not.
Starting in late 1848, Americans and foreigners of many different countries rushed into California for the California Gold Rush, exponentially increasing the population. In response to growing demand for a better more representative government, a Constitutional Convention was held in 1849. The delegates there unanimously outlawed slavery. They had no interest in extending the Missouri Compromise Line through California and splitting the state; the lightly populated southern half never had slavery and was heavily Hispanic.
The third statute of the Compromise of 1850 allowed California to be admitted to the Union, undivided, as a free state on September 9, 1850.
Fugitive Slave Law.
The fourth statute of the Compromise of 1850, enacted September 18, 1850, is informally known as the Fugitive Slave Law or the Fugitive Slave Act of 1850. (It bolstered the Fugitive Slave Act of 1793.) The new version of the Fugitive Slave Law required federal judicial officials in all states and federal territories, including in those states and territories in which slavery was prohibited, to actively assist with the return of escaped slaves to their masters in the states and territories permitting slavery. Any federal marshal or other official who did not arrest an alleged runaway slave was liable to a fine of $1,000. Law-enforcement officials everywhere in the United States had a duty to arrest anyone suspected of being a fugitive slave on no more evidence than a claimant's sworn testimony of ownership. The suspected slave could not ask for a jury trial or testify on his or her own behalf. In addition, any person aiding a runaway slave by providing food or shelter was to be subject to six months' imprisonment and a $1,000 fine. Officers capturing a fugitive slave were entitled to a fee for their work.
In addition to federal officials, the ordinary citizens of free states could be summoned to join a posse and be required to assist in the capture and/or custody and/or transportation of the alleged escaped slave. This particular law was so rigorously pro-slavery as to prohibit the admission of the testimony of a person accused of being an escaped slave into evidence at the judicial hearing to determine the status of the accused escaped slave. Thus, if a freedman were claimed to be an escaped slave under the Fugitive Slave Law he or she could not resist his or her return to slavery by truthfully telling his or her own actual history.
The Fugitive Slave Act was essential to meet Southern demands. In terms of public opinion in the North the critical provision was that ordinary citizens were required to aid slave catchers. Many northerners deeply resented this requirement that they personally aid and abet slavery. Resentment towards this act continued to heighten tensions between the North and South, as inflamed by abolitionists such as Harriet Beecher Stowe. Her book "Uncle Tom's Cabin" stressed the horrors of recapturing escaped slaves, and outraged Southerners.
Banning slave trade in the District of Columbia.
The fifth law, enacted on September 20, 1850, prohibited the slave trade (but not slavery itself) in the District of Columbia. Southerners in Congress were unanimous in opposing this provision, which was seen as a concession to the abolitionists, but were outvoted.

</doc>
<doc id="45978" url="https://en.wikipedia.org/wiki?curid=45978" title="Ergative">
Ergative

The term ergative is used in grammar in three different meanings:

</doc>
<doc id="45979" url="https://en.wikipedia.org/wiki?curid=45979" title="Victoria Beckham">
Victoria Beckham

Victoria Caroline Beckham ( Adams; born 17 April 1974) is an English businesswoman, fashion designer, model and singer. In the late 1990s, Beckham rose to fame with the all-female pop group Spice Girls and was dubbed Posh Spice by the July 1996 issue of the British music magazine "Top of the Pops". After the Spice Girls split, she was signed to Virgin Records and Telstar Records and had four UK Top 10 singles. Her first release, "Out of Your Mind", reached Number 2 in the UK Singles Chart.
Beckham has participated in five official documentaries and reality shows about her, including "Victoria's Secrets", "Being Victoria Beckham", "The Real Beckhams", "Victoria Beckham - A Mile In Their Shoes" and "". She has since made a cameo appearance in an episode of "Ugly Betty", and been a guest judge on "Project Runway", "Germany's Next Topmodel", and "American Idol". She is married to David Beckham and they have four children. As of September 2015, the couple's joint wealth is estimated at £508 million.
In the past decade, Beckham has become an internationally recognised style icon and fashion designer. Following high-profile collaborations with other brands, she launched an eponymous label in 2008 and a lower-priced (diffusion) label in 2011. The Victoria Beckham label was named designer brand of the year in the UK in 2011; in 2012 the brand was assessed as the star performer in the Beckham family's business interests. Writing in the "Daily Telegraph" in 2011, Belinda White noted that the transition from WAG to fashion designer had been more successful than most had predicted, saying: "She has gathered a significant celebrity following and won over the scathing fashion pack who now clamour for a ticket to her bi-annual show at New York Fashion Week."
Early life.
Beckham was born at the Princess Alexandra Hospital in Harlow, Essex and raised in Goffs Oak, Hertfordshire. She is the first of three children born to Jacqueline Doreen (née Cannon), a former insurance clerk and hairdresser, and Anthony William Adams, who worked as an electronics engineer. They founded an electronics wholesale business which allowed a comfortable upbringing for Victoria and her sister Louise and brother Christian Adams.
In 1980, she watched the musical film "Fame" and subsequently made the decision to pursue a musical career. Jacqueline and Anthony Adams enrolled her at Jason Theatre School. In 1991, Beckham entered Laine Theatre Arts in Epsom, Surrey and studied dance and modelling. Beckham attended St. Mary's High School in Cheshunt, where she was embarrassed by her family's wealth and often begged her father not to drop her off outside the school in their Rolls Royce. Eventually, she became a member of a band called Persuasion.
Fashion career.
Beckham made a guest appearance on the catwalk for Maria Grachvogel in 2000, marking her debut as a model at London Fashion Week. Beckham also acted as a British ambassador for Dolce and Gabbana and was briefly the face of Rocawear in 2003. Beckham designed a limited-edition fashion line for Rock & Republic called VB Rocks in 2004, consisting mainly of jeans for the high end of the market, retailing at approximately $300 in the US.
On 16 January 2006, Beckham walked the runway for Roberto Cavalli at Milan Fashion Week, and was for a period exclusively dressed by him for red-carpet and social events. For the March 2006 issue of "Harper's Bazaar", Beckham acted as fashion editor when she styled her close friend, Katie Holmes, for a fashion shoot. She has admitted to a personal love of sunglasses, saying "I'm quite obsessed with sunglasses. I collect vintage Guccis and Carreras – they can make virtually any outfit look cool." After Beckham's departure from Rock & Republic, in September 2006, she furthered her fashion ventures by launching her own denim label, dvb Style. Beckham then launched a new official website, dvbstyle.com to promote her fashion work.
On 14 June 2007, Beckham launched dvb Denim collection in New York at Saks Fifth Avenue, along with unveiling her eyewear range in the United States for the first time. In the same month, Beckham made her first appearance at London's annual Graduate Fashion Week as a judge alongside Glenda Bailey (editor-in-chief of "Harper's Bazaar") and Lanvin's Alber Elbaz, to choose the winner of the River Island Gold Award, worth £20,000. In August 2007, Intimately Beckham perfume was launched into US stores, one of more than 20 perfumes she and David Beckham have introduced over the years. In September 2007 her cosmetics line V-Sculpt was launched in Tokyo. In a 2007 appearance at an LA Galaxy press conference, Beckham is credited with having popularised Roland Mouret's 'moon dress' and his brand, and Beckham was also the face of Marc Jacobs for his Spring 2008 collection.
Beckham has graced countless fashion magazine covers during her career, including "I-D" in 2004 and "W" in 2007. Her first "Vogue" appearance was the April 2008 British edition. This was followed by "Vogue India", "Vogue Paris" as well as the German, Russian, Australian, Turkish, Taiwanese, Chinese and Spanish editions. Beckham has also graced various international editions of "Harper's Bazaar" and "Elle".
Launch of fashion label.
Beckham's eponymous label was launched in September 2008 in a low-key presentation. By 2011, it had grown into a fixture of New York Fashion Week and a lower-priced Victoria by Victoria Beckham label was introduced. In the first quarter of 2011-12, it was predicted to generate annual sales of more than £60 million. Known initially for its dresses, the range has expanded into separates and luxury handbags selling at up to £18,000. Alongside the main fashion line and diffusion range, the Victoria Beckham brand still includes separate denim, eyeware and fragrance lines. In November 2011, Victoria Beckham won Designer Brand of the Year at the British Fashion Awards.
In September 2012, Victoria Beckham was the most talked about designer on Twitter during New York Fashion Week, also acquiring 57,000 new followers during the shows according to research by The Whispr Group.
Writing in "The Independent" in February 2014, Alexander Fury described how Victoria Beckham had made the transition from novelty to respected designer, citing her recent guest editorship of French "Vogue" and forthcoming participation in a panel discussion with the dean of Parsons design school in New York. The article concluded that the brand's sales were down to the appeal of the designs themselves, not the celebrity association.
Music career.
1994–2000: Spice Girls.
Beckham auditioned for a March 1993 advertisement in "The Stage" which required girls who were "street smart, extrovert, ambitious and able to sing and dance". In 1994, Beckham joined the all-female group, the Spice Girls. In the recordings before her marriage, she is credited with her maiden name as Victoria Adams. The group's first single was called "Wannabe" (1996), and she worked alongside Geri Halliwell, Emma Bunton, Melanie Brown and Melanie Chisholm. It went to number one in the United Kingdom and United States, and another 29 countries. It was followed by nine further number one singles from their albums "Spice", "Spiceworld" and "Forever". Each member of the group received a nickname from the media. Beckham was named "Posh Spice". The group was one of the most successful pop acts of the 1990s, selling over fifty-five million records worldwide. After the release of their third album, "Forever", which charted at number two in the UK but was far less successful than their previous two albums, the Spice Girls stopped recording, concentrating on their solo careers in regards to their foreseeable future.
2000–2002: "Victoria Beckham".
On 14 August 2000, Beckham released her first solo single, "Out of Your Mind" in collaboration with Dane Bowers and Truesteppers. The week of release coincided with the release of "Groovejet (If This Ain't Love)" by Spiller featuring Sophie Ellis-Bextor, resulting in a chart battle dubbed 'Posh vs. Posher' by the tabloids. Before the single's release, on 8 July 2000, Beckham made her public solo debut at London's Hyde Park at a concert to raise money for the Prince's Trust charity. She sang "Out of Your Mind" to a 100,000-strong audience. Beckham then signed a recording contract with her group label Virgin Records. Her next single as a solo artist, "Not Such An Innocent Girl", was released on 17 September 2001. Again, she faced competition in another hugely hyped chart battle, this time with Kylie Minogue's single "Can't Get You Out of My Head". Despite a huge promotional campaign, Beckham was outsold eight to one, and her single debuted at number 6. Beckham's eponymous debut album, which was released on 1 October 2001, reached Number 10 in the UK album chart. The album cost a reputed £5 million to produce and it sold a modest 50,000 copies.
The second and final single to be released from the album was "A Mind of Its Own" on 11 February 2002. The single reached number 6 in the UK and sold 56,500 copies. Rumours soon spread that Beckham was to be dropped by her label for not charting in the Top Three. These were strongly refuted at the time. Beckham commented "You know what newspapers are like, they just like to put all the negative stuff in, but as far as I'm concerned and the record company is concerned it is all great." A third single, "I Wish", was promoted but never materialised. The single version was a remix featuring Robbie Craig, and was performed on TV on "Friday Night's All Wright". Following the announcement of Beckham's second pregnancy, the single was shelved. Beckham was reportedly dropped by Virgin Records along with fellow Spice Girls Emma Bunton and Melanie B,; but a statement from her publicist denied reports, stating: "No-one has been dropped. The Virgin deal has come to a natural end and both parties have decided not to continue."
2002–2004: Unreleased albums and end of solo career.
In 2002, Beckham signed a contract with Telstar Records and 19 Management worth £1.5 million. Beckham then began recording a pop-influenced album, "Open Your Eyes", which yielded the single "Let Your Head Go", but she allegedly chose not to release it after being disappointed with the results. Instead of pop, Beckham wanted a more urban sound and worked with urban producer Damon Dash to work on the R&B and hip hop influenced album "Come Together". When Dash was first asked why he recorded with Beckham, he stated: "Because I see how much she gets photographed over here." A Dash-produced track "It's That Simple" featuring M.O.P. premiered on radio stations in July 2003, generating mixed reviews. Beckham's first single with Telstar, "Let Your Head Go" / "This Groove", was released in the UK on 29 December 2003, following heavy promotion and many TV appearances across the Christmas period with the video being directed by Andy Hylton. The single charted at number three in the UK. This double A-side lifted "Let Your Head Go" from Beckham's earlier pop-inspired work with "This Groove" one of her hip hop and R&B songs and remains Beckham's last single release to date. Outside of the UK, Damon Dash had plans for Beckham in the US, including a potential release of "Let Your Head Go / This Groove" under the name of "Posh Spice Victoria Beckham". The release was proposed for sometime between March to May 2004, but never eventuated.
With the UK media describing her solo music career a failure, combined with a rumoured fall-out between Dash and Fuller, her hip hop album, "Come Together", was not released. Beckham's final attempt at a solo career came with the announcement of a new single "My Love Is for Real", in which she switched back from urban music to pop. She was dismissed from Telstar when the company became bankrupt, and gave up music to focus on her fashion career.
2007–2012: Return of the Spice Girls.
In 2007, the Spice Girls reformed and announced plans to embark upon a reunion tour, from which they were said to have earned £10 million each (approximately $20 million). Victoria had previously stated that she and her former Spice colleagues were enjoying their solo careers in various fields, saying "We're all still doing our own thing." Their "Greatest Hits" album was released in early November 2007 and the tour began on 2 December 2007. At its advent, Beckham said "I wanted my children to see that Mummy was a pop star. It was the last opportunity for them to stand in a crowd full of people screaming for the Spice Girls." When Beckham had her hair coloured brown for the tour, she stated that her sons immediately reacted by saying "Oh my goodness, it's Posh Spice. She's back." She was the only member of the group not to sing a solo song on the tour, instead posing in the style of a fashion show on a makeshift catwalk, whereas the others each performed a number from their solo careers.
Film-maker Bob Smeaton directed an official film of the tour titled "Spice Girls: Giving You Everything", which was first aired on Fox8 in Australia. It later aired in the UK on 31 December 2007 on BBC One. As well as their sell-out tour, the Spice Girls were contracted to appear in Tesco advertisements, for which they were paid £1 million each.
In October 2009, reports suggested that the Spice Girls were to star in a reality show in which they would cast female actors to play their roles in a musical. The following year, Judy Craymer teamed up with the Spice Girls and Simon Fuller to start developing a Spice Girls musical titled "Viva Forever". On 26 June 2012, all five Spice Girls were in attendance at a press conference in London to promote the launch of Viva Forever: The Musical. The musical is due to open at the West End's Piccadilly Theatre on 11 December 2012. On 12 August 2012, after much speculation, Beckham and the Spice Girls performed a medley of "Wannabe" and "Spice Up Your Life" at the 2012 Summer Olympics closing ceremony, reuniting solely for the event. Their performance was the most tweeted moment of Olympics closing ceremony with over 116,000 tweets on Twitter per minute.
Television.
Beckham has shot five official documentaries. The first, dated 11 January 2000, was called "Victoria's Secrets", a programme only shown in the UK on Channel 4. It involved Beckham being followed by cameras while also discussing and interviewing other British celebrities, such as Elton John.
The second, "Being Victoria Beckham", was broadcast in March 2002 and saw Beckham discussing her career as a solo artist with the release of her first album, and also showed her at various photo shoots and recording sessions. The documentary attracted a strong audience of 8.83 million, coming top in its timeslot. One critic described her as "so clearly level-headed, happy with her not inconsiderable lot and seemingly unfazed by the madly intrusive nature of her monumentally ridiculous fame". The third, "The Real Beckhams", aired on 24 December 2003 on ITV1 and focused on the Beckhams' move to Madrid from London after David Beckham was signed to Real Madrid. It also featured Victoria Beckham re-launching her solo career and showed her mocking the tabloid stories she reads in the paper every day. The special received an audience of 6.10 million viewers and was later released on DVD on 2 February 2004.
The fourth was titled "Full Length & Fabulous: The Beckhams' 2006 World Cup Party", and followed Victoria and David Beckham organising and making preparations to host a 2006 World Cup Party at a marquee in the grounds of their mansion in Hertfordshire, which aimed to raise money for their charity. Two tickets to attend the ball were auctioned on-line for charity, and sold for £103,000. The documentary aired on 28 May 2006 and showed the event itself, where the menu was designed especially by friend and chef Gordon Ramsay and the charity auction was hosted by Graham Norton. Ramsay catered for 600 guests, with the aid of 40 chefs and 100 waiting staff. The ITV documentary attracted an average of 7.56 million viewers.
To document Victoria Beckham's preparations for her family's move to the US, she signed a deal with NBC for six episodes of a half-hour unscripted reality TV series. Despite original plans for six episodes, the show was cut to a one-hour special only as there "just wasn't enough (material) for a series." The show, called "", aired on 16 July 2007 in the US and Canada. It was heavily scrutinised by the American media and critics, with "The New York Post" describing it as "an orgy of self-indulgence" and also describing Beckham as "vapid and condescending". The programme was the third-most-watched programme in its time-slot and received viewing figures of 4.9 million in the US, beaten by a repeat of "Wife Swap" and two sitcoms. The programme aired in Britain on 17 July 2007 on ITV with 3.84 million viewers tuning in. The programme was produced by Simon Fuller who managed her and the Spice Girls on their come-back tour.
In July 2007, it was announced that Beckham would shortly begin filming a cameo appearance as herself in an episode of the second season of ABC's TV series "Ugly Betty". The episode, "A Nice Day for a Posh Wedding", aired on 9 November 2007 in the United States and on 23 November in the United Kingdom. Despite her forays into television, Beckham has denied plans to embark upon a Hollywood movie career. In February 2008, it was revealed that Beckham would be the guest judge for the finale of fourth season of "Project Runway", which aired on 5 March 2008 in the US.
It was reported in October 2007 that Beckham had turned down the opportunity to appear in "". She stated in an interview: "was asked to be in the "Sex and the City" film, which I would have loved to have done, but because I am in full-on Spice Girls rehearsal mode, unfortunately, I can't do it."
Books.
On 13 September 2001, Beckham released her first book, "Learning to Fly". The title was taken from a line in a song from the musical "Fame", which Beckham had enjoyed as a child. The verse that inspired the title was: "I'm gonna live forever, I'm gonna learn how to fly". The autobiography documents her childhood, time during the Spice Girls, her marriage and family life, as well as her career at the time. She describes her eating disorder associated with the need to be slim. "Learning to Fly" became the third best-selling non-fiction title of 2001 and the total UK sales stand at more than 500,000 copies. When the book was first released, it went to Number 1 in the book charts after four weeks of release, relegating Robbie Williams' book to second place. A high-profile guest appearance on "Parkinson", watched by nine million people, helped to promote the book. "Hello!", "The Daily Mail" and "The Mail on Sunday" joined to buy the rights to preview and serialise the book before its publication. The figure paid was thought to be near £1 million.
Beckham was quoted by a Spanish journalist in 2005 as saying: "I've never read a book in my life". She later explained this was a mistranslation from the original Spanish in which the interview was printed, saying she actually stated that she never had time to finish reading a book because she was always too busy looking after her children.
Beckham's second book, a fashion advice guide titled "That Extra Half an Inch: Hair, Heels and Everything in Between", was published on 27 October 2006. "That Extra Half an Inch: Hair, Heels and Everything in Between" includes tips from Beckham on fashion, style and beauty, and also contains photography by Mario Testino, Annie Leibovitz and Steven Meisel. The book became another best-seller, and has sold 400,000 copies in Britain alone since it was published in hardcover. The rights have since been sold to the United States, the Netherlands, Japan, Portugal, Lithuania, Russia, and most recently China.
Power and influence.
In 2007, it was reported that Beckham was the 52nd richest woman in Britain and the 19th richest person in Britain with husband David, with an estimated joint wealth of £112 million ($225 million). According to "The Guardian", Beckham Ventures, a company linked to the Victoria Beckham fashion business, was the best performing brand in the family's three businesses in 2012, coming close to matching turnover in a sister company that promotes the David Beckham brand.
In 2010, Beckhams's charity work with Save the Children earned her a nomination for the Do Something With Style Award, an awards show, produced by VH1. She is a patron of the Elton John AIDS Foundation. Beckham promotes faux/synthetic furs. Her stand against the fur industry generated praise from animal rights organisations, including PETA. Beckham has stated that she is "supportive of its [PETA's] high-profile anti-fur campaigns," and pledged "never to work with fur in any of her own fashion collections". In February 2013, she was assessed as one of the 100 most powerful women in the UK in the fashion category by "Woman's Hour" on BBC Radio 4.
In 2014, Beckham joined the Ban Bossy campaign as a spokesperson advocating leadership roles for girls.
Personal life.
Beckham began a relationship with Corey Haim in 1995, which ended on mutual terms.
In 1997, she started dating footballer David Beckham after they met at a charity football match, prompting him to request a meeting with her. Of their initial meeting, she said, "I didn't really know who he was. I was never into football." The couple announced their engagement in 1998 and were dubbed "Posh and Becks" by the media.
Marriage.
On 4 July 1999 they were married by the Bishop of Cork, Paul Colton, at Luttrellstown Castle, Ireland. The wedding attracted much media coverage. Beckham's team-mate, Gary Neville, was the best man, and the couple's four-month-old son Brooklyn was the ring bearer. Most of the media were kept away from the ceremony as an exclusive deal with "OK!" magazine had been arranged, but photographs were released showing the Beckhams sitting on golden thrones. Victoria wore a diamond coronet created for her by jewellery designer Slim Barrett. A total of 437 staff were employed for the wedding reception, which was estimated to have cost £500,000 (US$823,650).
The couple bought what became their most famous home for £2.5 million in 1999; the property, which is set in of land, was given a £3 million renovation and was subsequently dubbed Beckingham Palace by the media.
Children.
Victoria and David Beckham have four children: sons Brooklyn Joseph Beckham (born 4 March 1999, Westminster, London), Romeo James Beckham (born 1 September 2002, Westminster, London), Cruz David Beckham (born 20 February 2005, Madrid, Spain); and daughter Harper Seven Beckham (born 10 July 2011, Los Angeles). Elton John and David Furnish are reportedly the godparents of Brooklyn and Romeo, and their godmother is Elizabeth Hurley.
Alleged kidnap and death threats.
In January 2000, a tip-off to Scotland Yard detectives exposed a plot to kidnap Victoria and Brooklyn Beckham and hold them at a house in Hampstead, London. The family was then moved to a secret location, but no arrests were made. Later in March 2000, she received a death threat prior to performing at the Brit Awards with the Spice Girls, and in the show's rehearsal, a red laser light appeared on her chest and she was rushed off stage. After a fire door was found to be lodged open, it was thought that there had been an assassin there, and Beckham later revealed that she was terrified by the experience. In November 2002, five people were arrested after another plot for her kidnap was infiltrated by a tabloid newspaper. All charges were dropped after a witness was deemed unreliable.

</doc>
<doc id="45985" url="https://en.wikipedia.org/wiki?curid=45985" title="George Michael">
George Michael

Georgios Kyriacos Panayiotou (born 25 June 1963), known professionally by his stage name George Michael, is an English singer, songwriter, and record producer. He rose to fame during the 1980s and 1990s with his style of post disco dance pop. He has also been characterised as a blue eyed soul singer, although his material draws more from middle of the road pop than soul music.
As one of the world's best selling music artists, Michael has sold more than 80 million records worldwide. His 1987 debut solo album, "Faith", has on its own sold more than 20 million copies worldwide. Michael has garnered seven number one singles in the UK and eight number one hits on the "Billboard" Hot 100 in the US. In 2008, "Billboard" magazine ranked Michael the 40th most successful artist on the "Billboard" Hot 100 Top All Time Artists list.
Michael has won numerous music awards throughout his 30-year career, including three Brit Awards—winning Best British Male twice, four MTV Video Music Awards, four Ivor Novello Awards, three American Music Awards, and two Grammy Awards from eight nominations.
In 2004, the Radio Academy named Michael the most played artist on British radio during the period 1984–2004. The documentary "A Different Story", released in 2005, covered his career and personal life. In 2006, George Michael announced his first tour in 15 years, the worldwide 25 Live tour, spanning three individual tours over the course of three years (2006, 2007 and 2008).
Early life.
Michael was born Georgios Kyriacos Panayiotou () in East Finchley, North London. His father, Kyriacos Panayiotou, a Cypriot restaurateur, moved to England in the 1950s and changed his name to Jack Panos. Michael's mother, Lesley Angold (née Harrison, 1937–1997), was an English dancer. Michael spent the majority of his childhood in Kingsbury, north-west London, in the home his parents bought soon after his birth, where he attended Kingsbury High School. While in his early teens, the family moved to Radlett, Hertfordshire. There Michael attended Bushey Meads School in the neighbouring town of Bushey, where he befriended his future Wham! partner Andrew Ridgeley. The two had the same career ambition of being musicians. Michael would busk on the London Underground, performing songs such as '"39" by Queen.
His involvement in the music business began with his working as a DJ, playing at clubs and local schools around Bushey, Stanmore and Watford. This was followed by the formation of a short-lived ska band called The Executive with Ridgeley, Ridgeley's brother Paul, Andrew Leaver, and David Mortimer (AKA David Austin).
Musical career.
1981–1986: Wham!
Michael first found success after forming the duo Wham! with Andrew Ridgeley in 1981. The band's first album "Fantastic" reached No. 1 in the UK in 1983 and produced a series of top 10 singles including "Young Guns", "Wham Rap!" and "Club Tropicana". Their second album, "Make It Big" reached No. 1 on the charts in the US. Singles from that album included "Wake Me Up Before You Go-Go" (No. 1 in the UK and US), "Freedom", "Everything She Wants", and "Careless Whisper" which reached No. 1 in nearly 25 countries, including the UK and US, and was Michael's first solo effort as a single.
Michael sang on the original Band Aid recording of "Do They Know It's Christmas?" (which became the UK Christmas number one) and donated the profits from "Last Christmas/Everything She Wants" to charity. In addition, he contributed background vocals to David Cassidy's 1985 hit "The Last Kiss", as well as Elton John's 1985 successes "Nikita" and "Wrap Her Up". Michael cited Cassidy as a major career influence and interviewed Cassidy for David Litchfield's Ritz Newspaper.
Wham!'s tour of China in April 1985, the first visit to China by a Western popular music act, generated worldwide media coverage, much of it centred on Michael. Before Wham!'s appearance in China, many kinds of music in the country were forbidden. The audience included members of the Chinese government, and Chinese television presenter, Kan Lijun, who was the on stage host, spoke of Wham!'s historic performance; "No-one had ever seen anything like that before. All the young people were amazed and everybody was tapping their feet. Of course the police weren't happy and they were scared there would be riots." The tour was documented by film director Lindsay Anderson and producer Martin Lewis in their film "Foreign Skies: Wham! In China".
With the success of Michael's solo singles, "Careless Whisper" (1984) and "A Different Corner" (1986), rumours of an impending break up of Wham! intensified. The duo officially separated during the summer of 1986, after releasing a farewell single, "The Edge of Heaven" and a singles compilation, "The Final", plus a sell-out concert at Wembley Stadium that included the world premiere of the China film. The Wham! partnership ended officially with the commercially successful single "The Edge of Heaven", which reached No. 1 on the UK chart in June 1986.
Solo career.
The beginning of his solo career, during early 1987, was a duet with Aretha Franklin. "I Knew You Were Waiting" was a one-off project that helped Michael achieve an ambition by singing with one of his favourite artists, and it scored number one on both the UK Singles Chart and the US "Billboard" Hot 100 upon its release.
For Michael, it became his third consecutive solo number one in the UK from three releases, after 1984's "Careless Whisper" (though the single was actually from the Wham! album "Make It Big") and 1986's "A Different Corner". The single was also the first Michael had recorded as a solo artist which he had not written himself. The co-writer, Simon Climie, was unknown at the time, although he would have success as a performer with the band Climie Fisher in 1988.
Michael and Aretha Franklin won a Grammy Award in 1988 for Best R&B Performance – Duo or Group with Vocal for the song.
1987–1989: "Faith".
During the autumn of 1987, Michael released his debut solo album, "Faith". In addition to playing a large number of instruments on the album, he wrote and produced every track on the recording, except for one, which he co-wrote.
The first single released from the album was "I Want Your Sex", during the summer of 1987. The song was banned by many radio stations in the UK and US, due to its sexually suggestive lyrics. MTV would broadcast the video, featuring celebrity make-up artist Kathy Jeung in a basque and suspenders, only during the late night hours. Michael argued that the act was beautiful if the sex was monogamous. Michael even recorded a brief prologue for the video in which he said: "This song is not about casual sex." One of the racier scenes involved Michael writing the words "explore monogamy" on his partner's back in lipstick. Some radio stations played a toned-down version of the song, "I Want Your Love," which was mainly the word "love" replacing "sex."
When "I Want Your Sex" reached the US charts, "American Top 40" host Casey Kasem refused to say the song's title, referring to it only as "the new single by George Michael." Despite censorship and radio play problems, "I Want Your Sex" reached No. 2 on the US "Billboard" Hot 100 and No. 3 in the UK.
The second single, "Faith", was released during October 1987, just a few weeks before the album. "Faith" would become one of his most popular songs. The song hit No. 1 on the "Billboard" Hot 100 in the US and maintained that position for four consecutive weeks. It also reached No. 2 in the UK Singles Chart. The famous video provided some definitive images of the 1980s music industry in the process—Michael in shades, leather jacket, cowboy boots, and Levi's jeans, playing a guitar near a classic-design jukebox.
On 30 October, "Faith" was released in the UK and in several markets worldwide. In the United States, the album had 51 non-consecutive weeks in the top 10 of "Billboard" 200, including 12 weeks at No. 1. "Faith" had many successes, with four singles ("Faith", "Father Figure", "One More Try", and "Monkey") reaching No. 1 in the US. "Faith" was certified Diamond by the RIAA for sales of 10 million copies in the US. To date, global sales of "Faith" are more than 25 million units. The album was highly acclaimed by music critics, with AllMusic journalist Steve Huey describing "Faith" as a "superbly crafted mainstream pop/rock masterpiece" and "one of the finest pop albums of the '80s". In a review by "Rolling Stone" magazine, journalist Mark Coleman commended most of the songs on the album, which he said "displays Michael's intuitive understanding of pop music and his increasingly intelligent use of his power to communicate to an ever-growing audience."
In 1988, Michael embarked on a world tour. The nightly set list included from the Wham! era "Everything She Wants" and "I'm Your Man", as well as covers of "Lady Marmalade" or "Play That Funky Music". In Los Angeles, Michael was joined on stage by Aretha Franklin for "I Knew You Were Waiting". It was the second highest grossing event of 1988, earning $17.7 million. In February 1989, "Faith" won the Grammy Award for Album of the Year at the 31st Grammy Awards. At the 1989 MTV Video Music Awards on 6 September in Los Angeles, Michael received the Video Vanguard Award.
According to Michael in his film, "A Different Story", success did not make him happy and he started to think there was something wrong in being an idol for millions of teenage girls. The whole "Faith" process (promotion, videos, tour, awards) left him exhausted, lonely and frustrated, and far from his friends and family. In 1990, he told his record company Sony that, for his second album, he did not want to do promotions like the one for "Faith".
1990–1992: "Listen Without Prejudice".
"Listen Without Prejudice Vol. 1" was released in September 1990. For this album, Michael tried to create a new reputation as a serious-minded artist; the title is an indication of his desire to be taken more seriously as a songwriter. Michael refused to make any kind of promotion for this album, including no music videos for the singles released. The first single, "Praying for Time", with lyrics concerning social ills and injustice, was released in August 1990 to critical acclaim. James Hunter of "Rolling Stone" magazine described the song as "a distraught look at the world's astounding woundedness. Michael offers the healing passage of time as the only balm for physical and emotional hunger, poverty, hypocrisy and hatred." The song was an instant success, reaching No. 1 on the US "Billboard" Hot 100 and No. 6 in the UK despite the absence of a video. A video was released shortly thereafter, consisting of the lyrics on a dark background. Michael did not appear in this video or any subsequent videos for the album.
The second single "Waiting for That Day" was an acoustic-heavy single, released as an immediate follow-up to "Praying For Time". It reached No. 23 in the UK and No. 27 in the US. in October 1990. The album was released in Europe on 3 September 1990 (and one week later in the United States). It reached No. 1 in the UK Albums Chart and peaked at No. 2 on the US "Billboard" 200. It spent a total of 88 weeks on the UK Albums Chart and was certified 4 times Platinum by the BPI. The album produced 5 UK singles, which were released quickly, within an at eight-month period: "Praying for Time", "Waiting for That Day", "Freedom! '90", "Heal the Pain", and "Cowboys and Angels" (the latter being his only single not to chart in the UK top 40).
"Freedom '90" was the second of only two of its singles to be supported by a music video (the other being the Michael-less "Praying for Time"). The song alludes to his struggles with his artistic identity, and prophesied his efforts shortly thereafter to end his recording contract with Sony Music. As if to prove the song's sentiment, Michael refused to appear in the video (directed by David Fincher), and instead recruited supermodels Naomi Campbell, Linda Evangelista, Christy Turlington, Tatjana Patitz, and Cindy Crawford to appear in and lip sync in his stead. It also featured the reduction of his sex symbol status. It had contrasting fortunes on each side of the Atlantic—a No. 8 success on the "Billboard" Hot 100 in the US, but only No. 28 on the UK Singles Chart.
"Mother's Pride" gained significant radio play in the US during the first Persian Gulf War during 1991, often with radio stations mixing in callers' tributes to soldiers with the music. It reached No. 46 on "Billboard" Hot 100 with only airplay. In the end, "Listen Without Prejudice Vol. 1" sold approximately 8 million copies.
At the 1991 Brit Awards, "Listen Without Prejudice Vol. 1" won the award for Best British Album. Later in 1991, Michael embarked on the "Cover to Cover tour" in Japan, England, the US, and Brazil, where he performed at "Rock in Rio". In the audience in Rio, he saw and later met Anselmo Feleppa, the man who would become his partner. The tour was not a proper promotion for "Listen Without Prejudice Vol. 1". Rather, it was more about Michael singing his favourite cover songs. Among his favourites was "Don't Let the Sun Go Down on Me", a 1974 song by Elton John; Michael and John had performed the song together at the Live Aid concert in 1985, and again for Michael's concert at London's Wembley Arena on 25 March 1991, where the duet was recorded. The single was released at the end of 1991 and reached No. 1 in both the UK and US.
In the meantime, the expected follow-up album, "Listen Without Prejudice Vol. 2", was scrapped due to Michael's lawsuit with Sony. Among Michael's complaints was that Sony had not completely supported the release of his second album, resulting in its poor performance in the US as compared to "Faith". Sony responded that Michael's refusal to appear in promotional videos had caused the bad response. Michael ended the idea for "Listen Without Prejudice Vol. 2" and donated three songs to the charity project "Red Hot + Dance", for the Red Hot Organization which raised money for AIDS awareness, while a fourth track "Crazyman Dance" was the B-side of 1992's "Too Funky". Michael donated the royalties from "Too Funky" to the same cause.
"Too Funky" was a commercial success, reaching No. 4 in the UK singles chart and No. 10 in the US "Billboard" Hot 100. It did not appear on any George Michael studio album, although later it was included on his solo collections "" in 1998 and "Twenty Five" in 2006. The video featured Michael (sporadically) as a director filming supermodels Linda Evangelista, Beverly Peele, Tyra Banks, Estelle Lefébure and Nadja Auermann at a fashion show.
1993: "Five Live".
George Michael performed at The Freddie Mercury Tribute Concert on 20 April 1992 at London's Wembley Stadium. The concert was a tribute to the life of the late Queen frontman, Freddie Mercury, with the proceeds going to AIDS research. In his last ever radio interview Mercury had praised Michael adding that he loved his track "Faith". Michael performed "'39", "These Are the Days of Our Lives" with Lisa Stansfield and "Somebody to Love". The performance of the latter was released on the "Five Live" EP.
"Five Live", released in 1993 for Parlophone in the UK and Hollywood Records in the US, features five—and in some countries, six—tracks performed by George Michael, Queen, and Lisa Stansfield."Somebody to Love" and "These Are the Days of Our Lives" were recorded at the Freddie Mercury Tribute Concert. "Killer", "Papa Was a Rollin' Stone", and "Calling You" were all live performances recorded during his "Cover to Cover Tour" from 1991. Michael's performance of "Somebody to Love" was hailed as "one of the best performances of the tribute concert". The idea of having George Michael take over as full-time lead singer of Queen was even given serious consideration.
All proceeds from the sale of the EP benefited the Mercury Phoenix Trust. Sales of the EP were very strong through Europe, where it debuted at number 1 in the UK and several European countries. Chart success in the United States was less spectacular, where it peaked at number 40 on the "Billboard" 200 ("Somebody to Love" reached No.30 on the US "Billboard" Hot 100).
1994–1997: "Older".
During November 1994, after a long period of seclusion, George Michael appeared at the first MTV Europe Music Awards show, where he gave a performance of a brand-new song, "Jesus to a Child". The song was a melancholy tribute to his lover, Anselmo Feleppa, who had died in March 1993.
The song was Michael's first self-penned success in his homeland in almost four years; it entered the UK singles chart at No. 1 and No. 7 on "Billboard" in the same month of release. It was also Michael's longest UK Top 40 single, at almost seven minutes long. The exact identity of the song's subject—and the nature of Michael's relationship with Feleppa—was shrouded in innuendo and speculation, as Michael had not confirmed he was homosexual and did not do so until 1998. The video for "Jesus to a Child" was a picture of images recalling loss, pain and suffering. Michael consistently dedicates the song to Feleppa before performing it live.
The second single, released in April 1996, was "Fastlove", an energetic tune about wanting gratification and fulfilment without commitment. The song was somewhat unusual for a popular song, in that it did not have a defined chorus and that the single version was nearly five minutes long. "Fastlove" was supported by a futuristic virtual reality-related video. It scored No. 1 in the UK singles chart, spending three weeks at the top spot. In the US, "Fastlove" peaked at No. 8, his most recent single to reach the top 10 on the US charts. Following "Fastlove", Michael finally released "Older", his first studio album in six years and only the third in his ten-year solo career. The album's US and Canada release was particularly notable as it was the first album released by David Geffen's (now-defunct) DreamWorks Records.
Older was particularly notable for the release of its six singles. Each of them reached the UK Top 3, a record for the most singles in the British Top 3 released from a single album. At the time of release of the album's fifth single, "Star People '97", chart specialist James Masterton noted George Michael's success on the singles charts, writing: "George Michael nonetheless makes an impressive Top 3 entry with this single. The Older album has now proved itself to be far and away his most commercially successful recording ever. Five singles now lifted and every single one has been a Top 3 hit. Compare this with the two Top 3 hits produced by "Faith" and "Listen Without Prejudice's" scant total of one Top Tenner and one single which missed the Top 40 altogether. This sustained single success has, of course, been achieved with a little help from marketing tricks such as remixes – or in this case a new recording of the album track which gives it a much-needed transformation into a deserved commercial smash."
In 1996, Michael was voted Best British Male, at the MTV Europe Music Awards and the Brit Awards; and at the British Academy's Ivor Novello Awards, he was awarded the prestigious title of 'Songwriter of The Year' for the third time. Michael performed a concert at Three Mills Studios, London, for "MTV Unplugged". It was his first long performance in years, and in the audience was Michael's mother. The next year, she died of cancer.
1998: "Ladies & Gentlemen: The Best of George Michael".
"Ladies & Gentlemen: The Best of George Michael" was Michael's first solo greatest hits collection released in 1998. The collection of 28 songs (29 songs are included on the European and Australian release) are separated into two halves, with each containing a particular theme and mood. The first CD, titled "For the Heart", predominantly contains Michael's successful ballads, while the second CD, "For the Feet", consists mainly of his popular dance tunes. It was released through Sony Music Entertainment as a condition of severing contractual ties with the label.
The album is notable for containing a large number of compilation tracks and duets that had not previously appeared on his albums, including his duet with Aretha Franklin, "I Knew You Were Waiting (For Me)"; "Desafinado", a duet in Portuguese with Brazilian legendary singer Astrud Gilberto; and the Elton John duet "Don't Let the Sun Go Down on Me".
"Ladies & Gentlemen" was an instant success, peaking at number one on the UK Albums Chart for 8 weeks. It has spent over 200 weeks in the UK Charts, and it is the 38th best-selling album of all time in the UK. It is certified 7 times platinum in the United Kingdom and Multi-Platinum in the United States, and it's George Michael's most commercially successful album in his homeland having sold more than 2.8 million copies. To date, the album has reached worldwide sales of approximately 15 million copies.
The first single of the album, "Outside" was a humorous song about his arrest for soliciting a policeman in a public restroom. "As", his duet with Mary J. Blige, was released as the second single in many territories around the world. Both singles reached the top 5 in the UK Singles Chart.
1999: "Songs from the Last Century".
"Songs from the Last Century" is a studio album of cover tracks. It was released in 1999 and was the final George Michael album to be released through Virgin Records. To date, the album has peaked the lowest of his solo effort. The album debuted at number 157 on the American "Billboard" 200 albums chart, which was also the album's peak position. It was also his lowest-charting album in the UK, becoming his only solo effort not to reach number 1. It peaked at number 2 in the UK Albums Chart. It consists of old standards, plus new interpretations of more recent popular songs such as "Roxanne", "The First Time Ever I Saw Your Face"; and the Frank Sinatra classic "Where or When". Each of the 11 tracks was co-produced by Phil Ramone and George Michael.
2000–2005: "Patience".
In 2000, Michael worked on the hit single "If I Told You That" with Whitney Houston, a song which was meant to feature Michael Jackson, initially. Michael co-produced on the single along with American producer Rodney Jerkins. It was also Michael's second consecutive duet.
Michael began working on what would be his fifth studio album, spending two years in the recording studio. His first single "Freeek!", taken from the new album, was successful in Europe going to number one in Italy, Portugal, Spain and Denmark in 2002 and reaching the top 10 in the UK and the top 5 in Australia. It made 22 charts around the world. However, his next single "Shoot the Dog" proved to be highly controversial when released in July 2002. It was highly critical of George W. Bush and Tony Blair in the leadup to the 2003 invasion of Iraq. It reached number one in Denmark and made the top 5 in most European charts. However, in Britain it peaked at only number 12 in the UK Singles Chart.
In February 2003 George Michael unexpectedly recorded another song in protest against the looming Iraq war, Don McLean's The Grave. The original was written by McLean in 1971 and was a protest against the Vietnam War. Michael performed the song on numerous top rated TV shows including "Top of the Pops" and "So Graham Norton". The video featured extensively on MTV. It was released as part of the War Child charity album "Hope". Michael also performed the song on long-running British chart show "Top of the Pops" on BBC Television on 7 March 2003, introduced by the writer and stand-up comedian (and fan of George Michael) Ben Elton. It was Michael's first appearance on the show since 1986, when he performed "The Edge of Heaven" as one half of Wham!. He ran into conflict with the show's producers for an anti-war, anti Blair T-shirt worn by some members of his band.
In response, McLean issued a statement, through his website, praising George Michael's recording: "I am proud of George Michael for standing up for life and sanity. I am delighted that he chose a song of mine to express these feelings. We must remember that the Wizard is really a cowardly old man hiding behind a curtain with a loud microphone. It takes courage and a song to pull the curtain open and expose him. Good Luck George."
On 17 November 2003, George Michael re-signed with Sony Music, the company he had left in 1995 after a legal battle. When Michael's fifth studio album, "Patience", was released in 2004, it was critically acclaimed and considered the album of George Michael's comeback to the spotlight in the new millennium. It went straight to number 1 on the UK Albums Chart, and became one of the fastest selling albums in the UK, selling over 200,000 copies in the first week alone. In Australia it reached number 2 on 22 March. It reached the Top 5 on most European charts, and peaked at number 12 in the United States, selling over 500,000 copies to earn a Gold certification from the RIAA. To date the album had sold around 7 million copies worldwide and spawned four (of six) new hit singles.
"Amazing", the third single from the album, became a number one hit in Europe. When Michael appeared on "The Oprah Winfrey Show" on 26 May 2004, to promote the album, he performed "Amazing", along with his classic songs "Father Figure" and "Faith". On the show Michael spoke of his arrest, revealing his homosexuality, and his resumption of public performances. He allowed Oprah's crew inside his home outside London. The fourth single taken off the album was "Flawless", which used the sample of The Ones' original dance hit "Flawless". It was a dance hit in Europe as well as North America, reaching no.1 on the "Billboard" Hot Dance Club Play and became Michael's last number one single on the United States Dance chart.
In November 2004, Sony released the fifth single – "Round Here". It was the least successful single taken from "Patience" when it stalled the UK charts at no. 32. In 2005, "John and Elvis Are Dead" was released as the sixth and final single from the album; it was released as a download single and was therefore unable to chart in the United Kingdom.
Michael told BBC Radio 1 on 10 March 2004 that future music that he puts out will be available for download, with fans encouraged to make a donation to charity.
2005–2010: "Twenty Five" and concert tours.
"Twenty Five" was George Michael's second greatest hits album, celebrating the 25th anniversary of his music career. Released in November 2006 by Sony BMG, it debuted at no.1 in the UK.
The album contains songs chiefly from George Michael's solo career but also from his earlier days in Wham! It comes in two formats: two CDs or a limited edition three-CD set. The 2-CD set contained 26 tracks, including four recorded with Wham! and three new songs: "An Easier Affair"; "This Is Not Real Love" (a duet with Mutya Buena, formerly of Sugababes, which peaked at No.15 in the UK Charts); and a new version of "Heal the Pain" recorded with Paul McCartney. The limited edition three-CD version contains an additional 14 lesser known tracks, including one from Wham! and another completely new song, "Understand".
"Twenty Five" was released in North America on 1 April 2008 as a 29-song, two-CD set featuring several new songs (including duets with Paul McCartney and Mary J. Blige and a song from the short-lived TV series Eli Stone) in addition to many of Michael's successful songs from both his solo and Wham! career. To commemorate the "Twenty Five" album, George Michael toured North America for the first time in 17 years, playing large venues in major cities including New York, Los Angeles, St. Paul/Minneapolis, Tampa/St. Pete, Chicago and Dallas. The DVD version of "Twenty Five" contains 40 videos on two discs, including seven with Wham!.
During the 2005 Live 8 concert at Hyde Park, London, Michael joined Paul McCartney on stage, harmonising on The Beatles classic "Drive My Car". Michael was one of several remixers commissioned in 1990 to work on dance mixes for Bananarama's "Tripping on Your Love". Bananarama covered "Careless Whisper" for their "Exotica" album in 2001, and the track was also released as a single in France.
In 2006, Michael started his first tour in 15 years, 25 Live. The tour began in Barcelona, Spain, on 23 September and finished in December at Wembley Arena in England. According to his website, the 80-show tour was seen by 1.3 million fans. On 12 May 2007 in Coimbra, Portugal, he began the European "25 Live Stadium Tour 2007", including London and Athens, and ending on 4 August 2007 in Belfast, Northern Ireland. There were 29 tour dates (as of 21 April 2007) across Europe. On 9 June 2007 Michael became the first artist to perform live at the newly renovated Wembley Stadium in London, where he was later fined £130,000 for over-running the programme for 13 minutes.
On 25 March 2008, a third part of the 25 Live Tour was announced for North America. This part included 21 dates in the United States and Canada. This was Michael's first tour of North America in 17 years. Following news of Michael's North American tour, "Twenty Five" was released in North America on 1 April 2008 as a 29-song, 2-CD set featuring several new songs (including duets with Paul McCartney and Mary J. Blige and a song from the short-lived TV series, "Eli Stone") in addition to many of Michael's successful songs from both his solo and Wham! career. In addition, a companion 2-disc DVD of 40 videos was also made available.
Michael made his American acting debut by playing a guardian angel to Jonny Lee Miller's character on "Eli Stone", a TV series that was broadcast in the United States. In addition to performing on the show as himself and as "visions", each episode of the show's first season was named after a song of his. Michael appeared on the 2008 finale show of "American Idol" on 21 May singing "Praying for Time". When asked what he thought Simon will say of his performance, he replied "I think he'll probably tell me I shouldn't have done a George Michael song. He's told plenty of people that in the past, so I think that'd be quite funny." On 1 December, Michael performed in Abu Dhabi in the United Arab Emirates, as part of the 37th National Day Celebrations.
On 25 December 2008, Michael released a new track "December Song" on his website for free. It was hoped that fans who download the song would donate money to charity. Though the song is not available any more on his website, it remains available on file sharing networks and on 29 October 2009 the BBC said that George Michael was to join the race for the UK Christmas number one as a remastered version of "December Song" would go on sale on 13 December. The popularity of the single was boosted by a promotional appearance that Michael made on "The X Factor", where he performed the song with David Austin playing piano.
At the end of 2009, Michael announced, after months of speculation, that he would be performing shows in the Australian cities of Melbourne, Perth and Sydney, his first concerts in Australia since 1988. On 20 February 2010, Michael performed his first show in Perth at the Burswood dome to an audience of 15,000.
On 5 March 2010, Michael confirmed that he would be a guest performer at the Sydney Gay and Lesbian Mardi Gras After Party, where he performed at 1 am, followed by Kelly Rowland at 3 am.
On 2 March 2011, Michael announced the release of his cover version of New Order's 1987 hit "True Faith" in aid of the charity Comic Relief. Michael released a cover of Stevie Wonder's 1972 song, "You and I" on 15 April 2011, as an MP3 gift to Prince William and Catherine Middleton on the occasion of their wedding on 29 April 2011.
Although the MP3 was released for free download, Michael appealed to those who do download the special track to make a contribution to "The Prince William & Miss Catherine Middleton Charitable Gift Fund".
2011–2014: "Symphonica" and concert tours.
On 11 May 2011, the Symphonica Tour was announced. Only European dates were released. The first show on the tour was performed at the Prague State Opera House on 22 August. In October 2011, Michael was announced as one of the final nominees for the Songwriter's Hall of Fame. In November, he had to cancel the remainder of the tour as he became severely ill with pneumonia in Vienna, Austria.
Michael told fans over Twitter in January 2012 that he did not think his vocal cords would be ready for performance "till the summer", and that the tour will probably take place in September of that year, and may include previously unheard songs. In February 2012, two months after leaving hospital, Michael made a surprise appearance at the 2012 Brit Awards at London's O2 Arena, where he received a standing ovation, and presented Adele the award for Best British Album.
On 19 June 2012, George Michael released a single "White Light" in order the celebrate the 30 years since the release of Wham Rap. The single also contains a cover version of "Song to the Siren", and two remixes.
Michael's album "Symphonica" was released on 17 March 2014, and became his 7th solo number one album in the UK, and 9th overall including his Wham! chart-toppers. The album was produced by Phil Ramone (his last production credit) and Michael.
Personal life.
Sexuality.
At the age of 19, Michael told Andrew Ridgeley and close friends that he was bisexual. Michael also told one of his two sisters, but he was advised by friends not to tell his parents about his sexuality. In a 1999 interview with "The Advocate", Michael told the Editor in Chief, Judy Wieder, that it was "falling in love with a man that ended his conflict over bisexuality." "I never had a moral problem with being gay," Michael told Wieder. "I thought I had fallen in love with a woman a couple of times. Then I fell in love with a man, and realized that none of those things had been love."
In 2007, Michael said he had hidden the fact he was gay because of worries over what effect it might have on his mother.
Speaking about his time with Wham! in the 1980s, Michael said: "I used to sleep with women quite a lot in the Wham! days but never felt it could develop into a relationship because I knew that, emotionally, I was a gay man. I didn't want to commit to them but I was attracted to them. Then I became ashamed that I might be using them." In 2009, Michael said: "My depression at the end of Wham! was because I was beginning to realise I was gay, not bisexual."
Relationships.
Michael established a relationship with Anselmo Feleppa, a Brazilian dress designer, whom he had met at the 1991 concert Rock in Rio. Six months into their relationship, Feleppa discovered that he had HIV. Michael later said: "It was terrifying news. I thought I could have the disease too. I couldn't go through it with my family because I didn't know how to share it with them – they didn't even know I was gay." In 1993, Feleppa died of an AIDS-related brain haemorrhage.
Michael's single "Jesus to a Child" is a tribute to Feleppa (he consistently dedicates it to him before performing it live), as is his 1996 album "Older". In 2008, speaking about the loss of his partner Feleppa, Michael said: "It was a terribly depressing time. It took about three years to grieve, then after that I lost my mother. I felt almost like I was cursed."
In 1996, Michael entered into a long-term relationship with Kenny Goss, a former flight attendant, cheerleader coach and sportswear executive from Dallas. They had homes in Dallas and an £8 million mansion in Highgate, North London. In late November 2005, it was reported that Michael and Goss would register their relationship as a civil partnership in the UK, but because of negative publicity and his upcoming tour, they postponed it to a later date.
On 22 August 2011, the opening night of his Symphonica world tour, Michael announced that he and Goss had split two years earlier. Goss was present at Michael's British sentencing for driving under the influence of marijuana on 14 September 2010.
Anonymous sex.
Questions of Michael's sexual orientation persisted in public until 7 April 1998, when he was arrested for "engaging in a lewd act" in a public restroom of the Will Rogers Memorial Park in Beverly Hills, California. In 2007, Michael said "that hiding his sexuality made him feel 'fraudulent', and his eventual outing, when he was arrested [...] in 1998, was a subconsciously deliberate act."
Michael was arrested by an undercover policeman named Marcelo Rodríguez, in a sting operation using so-called "pretty police." In an MTV interview, Michael stated: "I got followed into the restroom and then this cop—I didn't know it was a cop, obviously—he started playing this game, which I think is called, 'I'll show you mine, you show me yours, and then when you show me yours, I'm going to nick you!"
After pleading "no contest" to the charge, Michael was fined US$810 and sentenced to 80 hours of community service. Soon afterwards, Michael made a video for his single "Outside", which satirised the public toilet incident and featured men dressed as policemen kissing. Rodríguez claimed that this video "mocked" him, and that Michael had slandered him in interviews. In 1999, he brought a US$10 million court case in California against the singer. The court dismissed the case, but an appellate court reinstated the case on 3 December 2002. The court then ruled Rodríguez, as a public official, could not legally recover damages for emotional distress.
After the incident, Michael became explicit about his sexuality and his relationship with Kenny Goss which began in June 1996.
On 23 July 2006, Michael was again accused of engaging in anonymous public sex, this time at London's Hampstead Heath. The anonymous partner was stated (wrongly, as it turned out) to be 58-year-old Norman Kirtland, an unemployed van driver. Despite stating that he intended to sue both the "News of the World" tabloid who supposedly photographed the incident and Norman Kirtland for slander, Michael stated that he cruises for anonymous sex and that this was not an issue in his relationship with partner Kenny Goss.
Drugs.
On 26 February 2006, Michael was arrested for possession of Class C drugs, an incident that he described as "my own stupid fault, as usual." He was cautioned by the police and released.
Michael was arrested in Cricklewood, North-West London, after motorists reported a car obstructing the road at traffic lights. He pleaded guilty on 8 May 2007 to driving while unfit through drugs. He was banned from driving for two years, and sentenced to community service.
During September 2007, on "Desert Island Discs", he said that his cannabis use was a problem; he wished he could smoke less of it and was constantly trying to do so.
On 19 September 2008, Michael was arrested in a public toilet in the Hampstead Heath area of London for possession of Class A and C drugs. He was taken to the police station and cautioned for controlled substance possession.
On 5 December 2009, in an interview with "The Guardian", Michael explained he had cut back on cannabis and now smokes only 'seven or eight' spliffs per day instead of the 25 he used to smoke.
In the early hours of Sunday 4 July 2010 Michael was returning from the Gay Pride parade. The singer was spotted on CCTV driving into the front of a Snappy Snaps store in Hampstead, North London and was arrested on suspicion of being unfit to drive. On 12 August, London's Metropolitan Police said he was "charged with possession of cannabis and with driving while unfit through drink or drugs". It was reported that Michael had also been taking the prescription medication Amitriptyline.
On 24 August 2010, the singer pleaded guilty at Highbury Corner Magistrates' Court in London after admitting driving under the influence of drugs and on 14 September 2010 at the same court, was sentenced to eight weeks in prison, a fine, and a five-year ban from driving. Michael was released from Highpoint Prison in Suffolk on 11 October 2010, after serving four weeks.
Politics.
During the time of Margaret Thatcher as the Conservative Prime Minister of the United Kingdom throughout the 1980s, Michael voted Labour.
Michael wrote "Shoot the Dog", a song critical about the friendly relationship between the British and American governments, in particular Tony Blair and George W. Bush, with their involvement in the Iraq War. Michael voiced his concern about the lack of public consultation in the UK regarding the War on Terror: "On an issue as enormous as the possible bombing of Iraq, how can you represent us when you haven't asked us what we think?".
During 2000, Michael joined Melissa Etheridge, Garth Brooks, Queen Latifah, the Pet Shop Boys, and k.d. lang, to perform in Washington, D.C. as part of 'Equality Rocks' – a concert to benefit the Human Rights Campaign.
In 2007, the £1.45 million piano that John Lennon used to write "Imagine" was sent by Michael around the US on a "peace tour," having it on display at places where violence had taken place, such as Dallas' Dealey Plaza, where US President John. F. Kennedy was shot.
He devoted his 2007 concert in Sofia, Bulgaria, from his "Twenty Five Tour" to the Bulgarian nurses prosecuted in the HIV trial in Libya. On 17 June 2008, Michael said he was thrilled by California's legalisation of same-sex marriage, calling the move "way overdue."
Charity.
In November 1984, Michael joined other British and Irish pop stars of the era and formed Band Aid, singing on the charity song "Do They Know It's Christmas?" for famine relief in Ethiopia. This single became the UK Christmas number one in December 1984, holding Michael's own song, "Last Christmas" by Wham!, at No. 2. "Do They Know It's Christmas?" sold 3.75 million copies in the UK and became the biggest selling single in UK Chart history, a title it held until 1997 when it was overtaken by Elton John's "Candle in the Wind 1997", released in tribute to Princess Diana following her death (Michael would attend Diana's funeral with Elton John). Michael donated the royalties from "Last Christmas" to Band Aid and subsequently sang with Elton John at Live Aid (the Band Aid charity concert) in 1985.
In 1988, George Michael took part in the Nelson Mandela 70th Birthday Tribute at Wembley Stadium in London together with many other singers (such as Annie Lennox and Sting), performing "Sexual Healing".
In 2003 he paired up with Ronan Keating on "Who Wants to be a Millionaire?" and won £32,000, after having their original £64,000 winnings halved after missing the £125,000 question.
The proceeds from the single "Don't Let the Sun Go Down on Me" were divided among 10 different charities for children, AIDS and education. Michael is also a patron of the Elton John AIDS Foundation.
Michael is supporting a campaign to help raise US$32 million (GBP15 million) for terminally ill children.
In early 2011, Michael made You and I, a cover of a Stevie Wonder song, a free download on his website; he did so under the proviso that those that download it make a donation to a charity from those listed.
Assets.
Between the years 2006 and 2008, according to reports, Michael earned £48.5 million ($97 million) from the 25 Live tour alone. He reportedly earns millions more for private concerts that he periodically does, such as for billionaires Vladimir Potanin and Philip Green. According to the "Sunday Times" Rich List 2011 of the wealthiest British musicians, Michael is worth £90 million in currency alone. In July 2014, Michael was revealed to be a celebrity investor in a tax avoidance scheme called Liberty.
Memoirs.
In 1991 Michael released an autobiography titled "Bare" through Penguin Books, which he co-wrote with writer Tony Parsons. The over-200-page book covers various aspects of his life, including details of his relationship with a former girlfriend.
Health troubles.
On 26 October 2011, George Michael cancelled a performance at London's Royal Albert Hall due to a viral infection. On 21 November 2011, a hospital in Vienna admitted Michael after he had complained of chest pains while at a hotel just two hours before his performance at a venue there for his Symphonica Tour. The singer was later confirmed to have suffered from pneumonia and, until 1 December, was in an intensive care unit. While Michael appeared to be "in good spirits" and responded well to treatment following his admittance, on 25 November hospital officials said that his condition had "worsened overnight." This development led to cancellations and postponements of Michael's remaining 2011 performances, which had been scheduled mainly for the United Kingdom.
On 1 December 2011, doctors at the hospital in which George Michael had stayed announced that the singer was "steadily improving" and that he had moved out of the intensive care ward. On 21 December 2011, the hospital discharged Michael. On 23 December 2011, Michael made a public speech outside his house in Highgate, London, in which he stated that the staff at the Vienna General Hospital had saved his life and that he would perform a free concert specifically for those staff. While making the speech, he became emotional and breathless. During the speech, he also mentioned that he had undergone a tracheotomy. He also revealed that, after waking from the coma, he had a temporary West Country accent.
On May 2013, George Michael sustained a head injury when he fell from his moving car on the M1 motorway, near St Albans in Hertfordshire, and was airlifted to a hospital.

</doc>
<doc id="45990" url="https://en.wikipedia.org/wiki?curid=45990" title="Grandfather paradox">
Grandfather paradox

The grandfather paradox is a proposed paradox of time travel which results in an inconsistency through changing the past. The paradox was described as early as 1931, and even then it was described as "the age-old argument of preventing your birth by killing your grandparents". Early science fiction stories dealing with the paradox are the short story "Ancestral Voices" by Nathaniel Schachner, published in 1933, and the 1943 book by René Barjavel "Future Times Three". The paradox is described as follows: the time traveller goes back in time and kills his grandfather before his grandfather meets his grandmother. As a result, the time traveller is never born. But, if he was never born, then he is unable to travel through time and kill his grandfather, which means the traveller would be born after all, and so on.
Despite the name, the grandfather paradox does not exclusively regard the impossibility of one's own birth. Rather, it regards any action that eliminates the cause or means of traveling back in time. The paradox's namesake example is merely the most commonly thought of when one considers the whole range of possible actions. Another example would be using scientific knowledge to invent a time machine, then going back in time and (whether through murder or otherwise) impeding a scientist's work that would eventually lead to the invention of the time machine. An equivalent paradox is known (in philosophy) as autoinfanticide, going back in time and killing oneself as a baby.When the term was coined by Paul Horwich, he used the term autofanticide.</ref>
Assuming the causal link between the time traveller's present and future, the grandfather paradox that disrupts that link may be regarded as impossible (thus precluding the arbitrary alteration of one's fate). However, a number of hypotheses have been postulated to avoid the paradox, such as the idea that the past is unchangeable, so the grandfather must have already survived the attempted killing (as stated earlier); or the time traveller creates—or joins—an alternate timeline or parallel universe in which the traveller was never born.
A variant of the grandfather paradox is the Hitler paradox or Hitler's murder paradox, a fairly frequent trope in science fiction, in which the protagonist travels back in time to murder Adolf Hitler before he can instigate World War II. Rather than necessarily physically preventing time travel, the action removes any "reason" for the travel, along with any knowledge that the reason ever existed, thus removing any point in travelling in time in the first place. Additionally, the consequences of Hitler's existence are so monumental and all-encompassing that for anyone born after the war, it is likely that their birth was influenced in some way by its effects, and thus the grandfather paradox would directly apply in some way.
Scientific theories.
Novikov self-consistency principle.
The Novikov self-consistency principle expresses one view on how backwards time travel could be possible without a danger of paradoxes. According to this hypothesis, physics in or near closed timelike curves (time machines) can only be consistent with the universal laws of physics, and thus only self-consistent events can occur. Anything a time traveller does in the past must have been part of history all along, and the time traveller can never do anything to prevent the trip back in time from happening, since this would represent an inconsistency. Novikov et al used the example given by physicist Joseph Polchinski for the grandfather paradox, of a billiard ball heading towards a time machine; the ball's older self emerges from the time machine and strikes its younger self so its younger self never enters the time machine. Novikov et al showed how this system can be solved in a self-consistent way which avoids the grandfather paradox, though it creates a causal loop.
Seth Lloyd and other researchers at MIT have proposed an expanded version of the Novikov principle, according to which probability bends to prevent paradoxes from occurring. Outcomes would become stranger as one approaches a forbidden act, as the universe must favor improbable events to prevent impossible ones.
Parallel universes.
One variant of the grandfather paradox is that when the traveller kills the grandfather, the act took place in (or resulted in the creation of) a parallel universe where the traveller's counterpart never exists as a result. However, his prior existence in the original universe is unaltered. Succinctly, this explanation states that if time travel is possible, then multiple versions of the future exist in parallel universes. This theory would also apply if a person went back in time to shoot himself, because in the past he would be dead as in the future he would be alive and well.
Examples of parallel universes postulated in physics are:
Other considerations.
Consideration of the grandfather paradox has led some to the idea that time travel is by its very nature paradoxical and therefore logically impossible, on the same order as round squares. For example, the philosopher Bradley Dowden made this sort of argument in the textbook "Logical Reasoning", where he wrote:
Nobody has ever built a time machine that could take a person back to an earlier time. Nobody should be seriously trying to build one, either, because a good argument exists for why the machine can never be built. The argument goes like this: suppose you did have a time machine right now, and you could step into it and travel back to some earlier time. Your actions in that time might then prevent your grandparents from ever having met one another. This would make you not born, and thus not step into the time machine. So, the claim that there could be a time machine is self-contradictory.
But, some philosophers and scientists believe that time travel into the past need not be logically impossible provided that there is no possibility of changing the past, as suggested, for example, by the Novikov self-consistency principle. Bradley Dowden himself revised the view above after being convinced of this in an exchange with the philosopher Norman Swartz.
Consideration of the possibility of backwards time travel in a hypothetical universe described by a Gödel metric led famed logician Kurt Gödel to assert that time might itself be a sort of illusion. He seems to have been suggesting something along the lines of the block time view in which time does not really "flow" but is just another dimension like space, with all events at all times being fixed within this 4-dimensional "block".

</doc>
<doc id="45995" url="https://en.wikipedia.org/wiki?curid=45995" title="Building">
Building

A building or edifice is a structure with a roof and walls standing more or less permanently in one place, such as a house or factory. Buildings come in a variety of sizes, shapes and functions, and have been adapted throughout history for a wide number of factors, from building materials available, to weather conditions, to land prices, ground conditions, specific uses and aesthetic reasons. To better understand the term "building" compare the list of nonbuilding structures.
Buildings serve several needs of society – primarily as shelter from weather, security, living space, privacy, to store belongings, and to comfortably live and work. A building as a shelter represents a physical division of the human habitat (a place of comfort and safety) and the "outside" (a place that at times may be harsh and harmful).
Ever since the first cave paintings, buildings have also become objects or canvasess of artistic expression. In recent years, interest in sustainable planning and building practices has also become an intentional part of the design process of many new buildings.
Definitions.
The word "building" is both a noun and a verb: the structure itself and the act of making it. As a noun, a building is 'a structure that has a roof and walls and stands more or less permanently in one place'; "there was a three-storey building on the corner"; "it was an imposing edifice". In the broadest interpretation a fence or wall is a building However, the word "structure" is used more broadly than "building" including natural and man-made formations and does not necessarily have walls. Structure is more likely to be used for a fence. Sturgis' Dictionary included that "differs from Architecture [sic in excluding all idea of artistic treatment; and it differs from Construction in the idea of excluding scientific or highly skilful treatment." As a verb, building is the act of construction.
"Structural height" in technical usage is the height to the highest architectural detail on building from street-level. Depending on how they are classified, spires and masts may or may not be included in this height. Spires and masts used as antennas are not generally included. The definition of a "low-rise vs. a high-rise" building is a matter of debate, but generally three storeys or less is considered low-rise.
History.
A report by Shinichi Fujimura of a shelter built 500 000 years ago is doubtful since Fujimura was later found to have faked many of his findings. Supposed remains of huts found at the Terra Amata site in Nice purportedly dating from 200 000 to 400 000 years ago have also been called into question. (See Terra Amata.) There is clear evidence of home-building from around 18 000 BC. Buildings became common during the Neolithic (see Neolithic architecture).
Types.
Residential.
Single-family residential buildings are most often called houses or homes. Residential buildings containing more than one dwelling unit are called a duplex, apartment building to differentiate them from 'individual' houses. A condominium is an apartment that the occupant owns rather than rents. Houses may also be built in pairs (semi-detached), in terraces where all but two of the houses have others either side; apartments may be built round courtyards or as rectangular blocks surrounded by a piece of ground of varying sizes. Houses which were built as a single dwelling may later be divided into apartments or bedsitters; they may also be converted to another use e.g. an office or a shop.
Building types may range from huts to multi-million dollar high-rise apartment blocks able to house thousands of people. Increasing settlement density in buildings (and smaller distances between buildings) is usually a response to high ground prices resulting from many people wanting to live close to work or similar attractors. Other common building materials are brick, concrete or combinations of either of these with stone.
Residential buildings have different names for their use depending if they are seasonal include holiday cottage (vacation home) or timeshare; size such as a cottage or great house; value such as a shack or mansion; manner of construction such as a log home or mobile home; proximity to the ground such as earth sheltered house, stilt house, or tree house. Also if the residents are in need of special care such as a nursing home, orphanage or prison; or in group housing like barracks or dormitorys.
Historically many people lived in communal buildings called longhouses, smaller dwellings called pit-houses and houses combined with barns sometimes called housebarns.
Buildings are defined to be substantial, permanent structures so other dwelling forms such as houseboats, yurts, and motorhomes are dwellings but not buildings.
Multi-storey.
A Multi-storey is a building that has multiple floors above ground in the building.
Multi-storey buildings aim to increase the floor area of the building without increasing the area of the land the building is built on, hence saving land and, in most cases, money (depending on material used and land prices in the area). The building with the most stories is the Burj Khalifa, with 162.
Creation.
The practice of designing, constructing, and operating buildings is most usually a collective effort of different groups of professionals and trades. Depending on the size, complexity, and purpose of a particular building project, the project team may include:
Regardless of their size or intended use, all buildings in the US must comply with zoning ordinances, building codes and other regulations such as fire codes, life safety codes and related standards.
Vehicles—such as trailers, caravans, ships and passenger aircraft—are treated as "buildings" for life safety purposes.
Building services.
Physical plant.
Any building requires a certain amount of internal infrastructure to function, which includes such elements like heating / cooling, power and telecommunications, water and wastewater etc. Especially in commercial buildings (such as offices or factories), these can be extremely intricate systems taking up large amounts of space (sometimes located in separate areas or double floors / false ceilings) and constitute a big part of the regular maintenance required.
Conveying systems.
Systems for transport of people within buildings:
Systems for transport of people between interconnected buildings:
Building damage.
Buildings may be damaged during the construction of the building or during maintenance. There are several other reasons behind building damage like accidents such as storms, explosions and subsidence caused by mining or poor foundations. Buildings also may suffer from fire damage and flooding in special circumstances. They may also become dilapidated through lack of proper maintenance or alteration work improperly carried out.

</doc>
<doc id="45998" url="https://en.wikipedia.org/wiki?curid=45998" title="McDonnell Douglas F/A-18 Hornet">
McDonnell Douglas F/A-18 Hornet

The McDonnell Douglas F/A-18 Hornet is a twin-engine supersonic, all-weather carrier-capable multirole combat jet, designed as both a fighter and attack aircraft (hence the F/A designation). Designed by McDonnell Douglas (now Boeing) and Northrop, the F/A-18 was derived from the latter's YF-17 in the 1970s for use by the United States Navy and Marine Corps. The Hornet is also used by the air forces of several other nations and, since 1986, by the U.S. Navy's Flight Demonstration Squadron, the Blue Angels.
The F/A-18 has a top speed of Mach 1.8 (1,034 knots, 1,190 mph or 1,915 km/h at 40,000 ft or 12,190 m). It can carry a wide variety of bombs and missiles, including air-to-air and air-to-ground, supplemented by the 20 mm M61 Vulcan cannon. It is powered by two General Electric F404 turbofan engines, which give the aircraft a high thrust-to-weight ratio. The F/A-18 has excellent aerodynamic characteristics, primarily attributed to its leading edge extensions (LEX). The fighter's primary missions are fighter escort, fleet air defense, Suppression of Enemy Air Defenses (SEAD), air interdiction, close air support and aerial reconnaissance. Its versatility and reliability have proven it to be a valuable carrier asset, though it has been criticized for its lack of range and payload compared to its earlier contemporaries, such as the Grumman F-14 Tomcat in the fighter and strike fighter role, and the Grumman A-6 Intruder and LTV A-7 Corsair II in the attack role.
The Hornet saw its first combat action during the 1986 United States bombing of Libya and subsequently participated in the 1991 Gulf War and 2003 Iraq War. The F/A-18 Hornet provided the baseline design for the Boeing F/A-18E/F Super Hornet, a larger, evolutionary redesign of the F/A-18.
Development.
Origins.
The U.S. Navy started the Naval Fighter-Attack, Experimental (VFAX) program to procure a multirole aircraft to replace the Douglas A-4 Skyhawk, the A-7 Corsair II, and the remaining McDonnell Douglas F-4 Phantom IIs, and to complement the F-14 Tomcat. Vice Admiral Kent Lee, then head of Naval Air Systems Command (NAVAIR), was the lead advocate for the VFAX against strong opposition from many Navy officers, including Vice Admiral William D. Houser, deputy chief of naval operations for air warfare – the highest ranking naval aviator.
In August 1973, Congress mandated that the Navy pursue a lower-cost alternative to the F-14. Grumman proposed a stripped F-14 designated the F-14X, while McDonnell Douglas proposed a naval variant of the F-15, but both were nearly as expensive as the F-14. That summer, Secretary of Defense Schlesinger ordered the Navy to evaluate the competitors in the Air Force's Lightweight Fighter (LWF) program, the General Dynamics YF-16 and Northrop YF-17. The Air Force competition specified a day fighter with no strike capability. In May 1974, the House Armed Services Committee redirected $34 million from the VFAX to a new program, the Navy Air Combat Fighter (NACF), intended to make maximum use of the technology developed for the LWF program.
Redesigning the YF-17.
Though the YF-16 won the LWF competition, the Navy was skeptical that an aircraft with one engine and narrow landing gear could be easily or economically adapted to carrier service, and refused to adopt an F-16 derivative. On 2 May 1975 the Navy announced its selection of the YF-17. Since the LWF did not share the design requirements of the VFAX, the Navy asked McDonnell Douglas and Northrop to develop a new aircraft from the design and principles of the YF-17. On 1 March 1977 Secretary of the Navy W. Graham Claytor announced that the F-18 would be named "Hornet".
Northrop had partnered with McDonnell Douglas as a secondary contractor on NACF to capitalize on the latter's experience in building carrier aircraft, including the widely used F-4 Phantom II. On the F-18, the two companies agreed to evenly split component manufacturing, with McDonnell Douglas conducting final assembly. McDonnell Douglas would build the wings, stabilators, and forward fuselage; while Northrop would build the center and aft fuselage and vertical stabilizers. McDonnell Douglas was the prime contractor for the naval versions, and Northrop would be the prime contractor for the F-18L land-based version which Northrop hoped to sell on the export market.
The F-18, initially known as McDonnell Douglas Model 267, was drastically modified from the YF-17. For carrier operations, the airframe, undercarriage, and tailhook were strengthened, folding wings and catapult attachments were added, and the landing gear widened. To meet Navy range and reserves requirements, McDonnell increased fuel capacity by , by enlarging the dorsal spine and adding a 96-gallon fuel tank to each wing. A "snag" was added to the wing's leading edge and stabilators to prevent an Aeroelastic flutter discovered in the F-15 stabilator. The wings and stabilators were enlarged, the aft fuselage widened by , and the engines canted outward at the front. These changes added to the gross weight, bringing it to . The YF-17's control system was replaced with a fully digital fly-by-wire system with quadruple-redundancy, the first to be installed in a production fighter.
Originally, it was planned to acquire a total of 780 aircraft of three variants: the single seat F-18A fighter and A-18A attack aircraft, differing only in avionics; and the dual-seat TF-18A, which retained full mission capability of the F-18 with a reduced fuel load. Following improvements in avionics and multifunction displays, and a redesign of external stores stations, the A-18A and F-18A were able to be combined into one aircraft. Starting in 1980, the aircraft began to be referred to as the F/A-18A, and the designation was officially announced on 1 April 1984. The TF-18A was redesignated F/A-18B.
Northrop's F-18L.
Northrop developed the F-18L as a potential export aircraft. Since it was not strengthened for carrier service, it was expected to be lighter and better performing, and a strong competitor to the F-16 Fighting Falcon then being offered to American allies. The F-18L's normal gross weight was lighter than the F/A-18A by , via lighter landing gear, lack of wing folding mechanism, reduced part thickness in areas, and lower fuel-carrying capacity. Though the aircraft retained a lightened tailhook, the most obvious external difference was removed "snags" on the leading edge of the wings and stabilators. It still retained 71% commonality with the F/A-18 by parts weight, and 90% of the high-value systems, including the avionics, radar, and electronic countermeasure suite, though alternatives were offered. Unlike the F/A-18, the F-18L carried no fuel in its wings and lacked weapons stations on the intakes. It had three underwing pylons on each side instead.
The F/A-18L version followed to coincide with the US Navy's F/A-18A as a land-based export alternative. This was essentially an F/A-18A lightened by approximately ; weight was reduced by removing the folding wing and associated actuators, implementing a simpler landing gear (single wheel nose gear and cantilever oleo main gear), and change to a land-based tail-hook. The revised F/A-18L included wing fuel tanks and fuselage stations of the F/A-18A. Its weapons capacity would increase from ; largely due to the addition of a third underwing pylon and strengthened wingtips (11 stations in total vs 9 stations of the F/A-18A). Compared to the F-18L, the outboard weapons pylons are moved closer to the wingtip missile rails. Because of the strengthened non-folding wing, the wingtip missile rails were designed to carry either the AIM-7 Sparrow or Skyflash medium-range air-to-air missiles, in addition to the AIM-9 Sidewinder as found on the F/A-18A. The F/A-18L was strengthened for a 9 g design load factor compared to the F/A-18A's 7.5 g factor.
The partnership between McDonnell Douglas and Northrop soured over competition for foreign sales for the two models. Northrop felt that McDonnell Douglas would put the F/A-18 in direct competition with the F-18L. In October 1979, Northrop filed a series of lawsuits charging that McDonnell was using Northrop technology developed for the F-18L for foreign sales in violation of their agreement, and asked for a moratorium on foreign sales of the Hornet by McDonnell Douglas. The case was resolved in 1985 when McDonnell Douglas agreed to pay Northrop $50 million for complete rights to the design, with no admission of wrongdoing. By then Northrop had ceased work on the F-18L, and most export orders were captured by the F-16 or the F/A-18.
Into production.
During flight testing, the snag on the leading edge of the stabilators was filled in, and the gap between the Leading edge extensions (LEX) and the fuselage mostly filled in. The gaps, called the boundary layer air discharge (BLAD) slots, controlled the vortices generated by the LEX and presented clean air to the vertical stabilizers at high angles of attack, but they also generated a great deal of parasitic drag, worsening the problem of the F/A-18's inadequate range. McDonnell filled in 80% of the gap, leaving a small slot to bleed air from the engine intake. This may have contributed to early problems with fatigue cracks appearing on the vertical stabilizers due to extreme Structural loads, resulting in a short grounding in 1984 until the stabilizers were strengthened. Starting in May 1988, a small vertical fence was added to the top of each LEX to broaden the vortices and direct them away from the vertical stabilizers. This also provided a minor increase in controllability as a side effect. F/A-18s of early versions had a problem with insufficient rate of roll, exacerbated by the insufficient wing stiffness, especially with heavy underwing ordnance loads.
The first production F/A-18A flew on 12 April 1980. After a production run of 380 F/A-18As (including the nine assigned to flight systems development), manufacture shifted to the F/A-18C in September 1987.
Improvements and design changes.
In the 1990s, the U.S. Navy faced the need to replace its aging A-6 Intruders, and A-7 Corsair IIs with no replacement in development. To answer this deficiency, the Navy commissioned development of the F/A-18E/F Super Hornet. Despite its designation, it is not just an upgrade of the F/A-18 Hornet, but rather, a new, larger airframe using the design concepts of the Hornet.
Hornets and Super Hornets will serve complementary roles in the U.S. Navy carrier fleet until the Hornet A-D models are completely replaced by the F-35C Lightning II. The Marines have chosen to extend the use of certain of their F/A-18s up to 10000 flight hours, due to delays in the F-35B version.
Design.
The F/A-18 is a twin engine, mid wing, multi-mission tactical aircraft. It is highly maneuverable, owing to its good thrust to weight ratio, digital fly-by-wire control system, and leading edge extensions (LEX). The LEX allow the Hornet to remain controllable at high angles of attack. The trapezoidal wing has a 20-degree sweepback on the leading edge and a straight trailing edge. The wing has full-span leading edge flaps and the trailing edge has single-slotted flaps and ailerons over the entire span.
Canted vertical stabilizers are another distinguishing design element, one among several other such elements that enable the Hornet's excellent high angle of attack ability include oversized horizontal stabilators, oversized trailing edge flaps that operate as flaperons, large full-length leading edge slats, and flight control computer programming that multiplies the movement of each control surface at low speeds and moves the vertical rudders inboard instead of simply left and right. The Hornet's normally high angle of attack performance envelope was put to rigorous testing and enhanced in the NASA F-18 High Alpha Research Vehicle (HARV). NASA used the F-18 HARV to demonstrate flight handling characteristics at high angle-of-attack (alpha) of 65–70 degrees using thrust vectoring vanes. F/A-18 stabilators were also used as canards on NASA's F-15S/MTD.
The Hornet was among the first aircraft to heavily use multi-function displays, which at the switch of a button allow a pilot to perform either fighter or attack roles or both. This "force multiplier" ability gives the operational commander more flexibility to employ tactical aircraft in a fast-changing battle scenario. It was the first Navy aircraft to incorporate a digital multiplexing avionics bus, enabling easy upgrades.
The Hornet is also notable for having been designed to reduce maintenance, and as a result has required far less downtime than its heavier counterparts, the F-14 Tomcat and the A-6 Intruder. Its mean time between failures is three times greater than any other Navy strike aircraft, and requires half the maintenance time. Its General Electric F404 engines were also innovative in that they were designed with operability, reliability and maintainability first. The engine, while unexceptional in rated performance, demonstrates exceptional robustness under various conditions and is resistant to stall and flameout. The F404 engine connects to the airframe at only 10 points and can be replaced without special equipment; a four-person team can remove the engine within 20 minutes.
The engine air inlets of the Hornet, like that of the F-16, are of a simpler "fixed" design, while those of the F-4, F-14, and F-15 have variable geometry or variable intake ramp air inlets. This is a speed limiting factor in the Hornet design. Instead, the Hornet uses bleed air vents on the inboard surface of the engine air intake ducts to slow and reduce the amount of air reaching the engine. While not as effective as variable geometry, the bleed air technique functions well enough to achieve near Mach number 2 speeds, which is within the designed mission requirements.
A 1989 USMC study found that single-seat fighters were well suited to air-to-air combat missions while dual-seat fighters were favored for complex strike missions against heavy air and ground defenses in adverse weather—the question being not so much as to whether a second pair of eyes would be useful, but as to having the second crewman sit in the same fighter or in a second fighter. Single-seat fighters that lacked wingmen were shown to be especially vulnerable.
The F/A-18 provides automatic alerts via audio messages to the pilot.
Operational history.
United States.
Entry into service.
McDonnell Douglas rolled out the first F/A-18A on 13 September 1978, in blue-on-white colors marked with "Navy" on the left and "Marines" on the right. Its first flight was on 18 November. In a break with tradition, the Navy pioneered the "principal site concept" with the F/A-18, where almost all testing was done at Naval Air Station Patuxent River, instead of near the site of manufacture, and using Navy and Marine Corps test pilots instead of civilians early in development. In March 1979, Lt. Cdr. John Padgett became the first Navy pilot to fly the F/A-18.
Following trials and operational testing by VX-4 and VX-5, Hornets began to fill the Fleet Replacement Squadrons (FRS) VFA-125, VFA-106, and VMFAT-101, where pilots are introduced to the F/A-18. The Hornet entered operational service with Marine Corps squadron VMFA-314 at MCAS El Toro on 7 January 1984, and with Navy squadron VFA-25 in March 1984, replacing F-4s and A-7Es, respectively.
The initial fleet reports were complimentary, indicating that the Hornet was extraordinarily reliable, a major change from its predecessor, the F-4J. Other squadrons that switched to F/A-18 are VFA-146 "Blue diamonds", and VFA-147 "Argonauts". In January 1985, the VFA-131 "Wildcats" and the VFA-132 "Privateers" moved from Naval Air Station Lemoore, California to Naval Air Station Cecil Field, Florida, and became the Atlantic Fleet's first F/A-18 squadrons.
The US Navy's Blue Angels Flight Demonstration Squadron switched to the F/A-18 Hornet in 1986, when it replaced the A-4 Skyhawk. The Blue Angels perform in F/A-18A, B, C, and D models at air shows and other special events across the US and worldwide. Blue Angels pilots must have 1,400 hours and an aircraft carrier certification. The two-seat B and D models are typically used to give rides to VIPs, but can also fill in for other aircraft in the squadron in a normal show, if the need arises.
NASA operates several F/A-18 aircraft for research purposes and also as chase aircraft; these F/A-18s are based at the Armstrong Flight Research Center (formerly the Dryden Flight Research Center) in California. On 21 September 2012, two NASA F/A-18s escorted a NASA Boeing 747 Shuttle Carrier Aircraft (SCA) carrying the Space Shuttle Endeavour over portions of California to Los Angeles International Airport before being delivered to the California Science Center museum in Los Angeles.
Combat operations.
The F/A-18 first saw combat action in April 1986, when VFA-131, VFA-132, VMFA-314, and VMFA-323 Hornets from flew SEAD missions against Libyan air defenses during Operation Prairie Fire and an attack on Benghazi as part of Operation El Dorado Canyon.
During the Gulf War of 1991, the Navy deployed 106 F/A-18A/C Hornets and Marine Corps deployed 84 F/A-18A/C/D Hornets. F/A-18 pilots were credited with two kills during the Gulf War, both MiG-21s. On 17 January, the first day of the war, U.S. Navy pilots Lieutenant Commander Mark I. Fox and his wingman, Lieutenant Nick Mongilio were sent from in the Red Sea to bomb an airfield in southwestern Iraq. While en route, they were warned by an E-2C of approaching MiG-21 aircraft. The Hornets shot down the two MiGs with AIM-7 and AIM-9 missiles in a brief dogfight. The F/A-18s, each carrying four bombs, then resumed their bombing run before returning to "Saratoga".
The Hornet's survivability was demonstrated when a Hornet took hits in both engines and flew back to base. It was repaired and flying within a few days. F/A-18s flew 4,551 sorties with 10 Hornets damaged including two losses. The two losses were U.S. Navy F/A-18s and their pilots were lost. On 17 January 1991, Lieutenant Commander Scott Speicher of VFA-81 was shot down and killed in the crash of his aircraft. An unclassified summary of a 2001 CIA report suggests that Speicher's aircraft was shot down by a missile fired from an Iraqi Air Force aircraft, most likely a MiG-25. The other F/A-18, piloted by Lieutenant Robert Dwyer was lost over the North Persian Gulf after a successful mission to Iraq; he was officially listed as killed in action, body not recovered.
As the A-6 Intruder was retired in the 1990s, its role was filled by the F/A-18. The F/A-18 demonstrated its versatility and reliability during Operation Desert Storm, shooting down enemy fighters and subsequently bombing enemy targets with the same aircraft on the same mission. It broke records for tactical aircraft in availability, reliability, and maintainability.
Both U.S. Navy F/A-18A/C models and Marine F/A-18A/C/D models were used continuously in Operation Southern Watch and over Bosnia and Kosovo in the 1990s. U.S. Navy Hornets flew during Operation Enduring Freedom in 2001 from carriers operating in the North Arabian Sea. Both the F/A-18A/C and newer F/A-18E/F variants were used during Operation Iraqi Freedom in 2003, operating from aircraft carriers as well from an air base in Kuwait. Later in the conflict USMC A+, C, and primarily D models operated from bases within Iraq.
An F/A-18C was accidentally downed in a friendly fire incident by a Patriot missile when a pilot tried to evade two missiles fired at him and crashed. Two others collided over Iraq in May 2005. In January 2007, two Navy F/A-18E/F Super Hornets collided in midair and crashed in the Persian Gulf.
Non-U.S. service.
The F/A-18 has been purchased and is in operation with several foreign air services. Export Hornets are typically similar to U.S. models of a similar manufacture date. Since none of the customers operate aircraft carriers, all export models have been sold without the automatic carrier landing system, and Royal Australian Air Force further removed the catapult attachment on the nose gear. Except for Canada, all export customers purchased their Hornets through the U.S. Navy, via the U.S. Foreign Military Sales (FMS) Program, where the Navy acts as the purchasing manager but incurs no financial gain or loss. Canada is the largest Hornet operator outside of the U.S.
Australia.
The Royal Australian Air Force purchased 57 F/A-18A fighters and 18 F/A-18B two-seat trainers to replace its Dassault Mirage IIIOs. Numerous options were considered for the replacement, notably the F-15A Eagle, the F-16 Falcon, and the then new F/A-18 Hornet. The F-15 was discounted because the version offered had no ground-attack capability. The F-16 was considered unsuitable largely due to having only one engine. Australia selected the F/A-18 in October 1981. Original differences between the Australian and US Navy's standard F/A-18 were the removed nose wheel tie bar for catapult launch (later re-fitted with a dummy version to remove nose wheel shimmy), addition of a high frequency radio, an Australian fatigue data analysis system, an improved video and voice recorder, and the use of ILS/VOR (Instrument Landing System/Very High Frequency Omnidirectional Range) instead of the carrier landing system.
The first two aircraft were produced in the US, with the remainder assembled in Australia at Government Aircraft Factories. F/A-18 deliveries to the RAAF began on 29 October 1984, and continued until May 1990. In 2001, Australia deployed four aircraft to Diego Garcia, in an air defense role, during coalition operations against the Taliban in Afghanistan. In 2003, 75 Squadron deployed 14 F/A-18s to Qatar as part of Operation Falconer and these aircraft saw action during the invasion of Iraq. Australia had 71 Hornets in service in 2006, after four were lost to crashes.
The fleet was upgraded beginning in the late 1990s to extend their service lives to 2015. They were expected to be retired then and replaced by the F-35 Lightning II.
Several of the Australian Hornets have had refits applied to extend their service lives until the planned retirement date of 2020. In addition to the F/A-18A and F/A-18B Hornets, Australia has purchased 24 F/A-18F Super Hornets, with deliveries beginning in 2009.
In March 2015 six F/A-18As from No. 75 Squadron were deployed to the Middle East as part of Operation Okra, replacing a detachment of Super Hornets.
Canada.
Canada was the first export customer for the Hornet, replacing the CF-104 Starfighter (air reconnaissance and strike), the McDonnell CF-101 Voodoo (air interception) and the CF-116 Freedom Fighter (ground attack). The Canadian Forces Air Command ordered 98 A models (Canadian designation CF-188A/CF-18A) and 40 B models (designation CF-188B/CF-18B). The original CF-18 as delivered is largely identical to the F/A-18A and B models. 
In 1991, Canada committed 26 CF-18s to the Gulf War, based in Qatar. These aircraft primarily provided Combat Air Patrol duties, although, late in the air war, began to perform air strikes on Iraqi ground targets. On 30 January 1991, two CF-18s on CAP detected and attacked an Iraqi TNC-45 patrol boat. The vessel was repeatedly strafed and damaged by 20mm cannon fire, but an attempt to sink the ship with an air-to-air missile failed. The ship was subsequently sunk by American aircraft, but the Canadian CF-18s received partial credit for its destruction. In June 1999, 18 CF-18s were deployed to Aviano AB, Italy, where they participated in both the air-to-ground and air-to-air roles in the former Yugoslavia.
62 CF-18A and 18 CF-18B aircraft took part in the Incremental Modernization Project which was completed in two phases. The program was launched in 2001 and the last updated aircraft was delivered in March 2010. The aims were to improve air-to-air and air-to-ground combat abilities, upgrade sensors and the defensive suite, and replace the datalinks and communications systems on board the CF-18 from the F/A-18A and F/A-18B standard to the current F/A-18C and F/A-18D standard.
In July 2010 the Canadian government announced plans to replace the remaining CF-18 fleet with 65 F-35 Lightning IIs, with deliveries scheduled to start in 2016.
Finland.
The Finnish Air Force ("Suomen ilmavoimat") ordered 64 F-18C/Ds (57 C models, seven D models). All F-18D were built at St Louis, and then all F-18C were assembled in Finland. Delivery of the aircraft started in November 1995 until August 2000. The Hornet replaced the MiG-21bis and Saab 35 Draken in Finnish service. The Finnish Hornets were initially to be used only for air defense, hence the F-18 designation. The F-18C includes the ASPJ (Airborne-Self-Protection-Jammer) jamming pod ALQ-165. The US Navy later included the ALQ-165 on their F/A-18E/F Super Hornet procurement.
One fighter was destroyed in a mid-air collision in 2001. A damaged F-18C, nicknamed "Frankenhornet", was rebuilt into a F-18D using the forward section of a Canadian CF-18B that was purchased. The modified fighter crashed during a test flight in January 2010, due to a faulty tailplane servo cylinder.
Finland is upgrading its fleet of F-18s with new avionics, including helmet mounted sights (HMS), new cockpit displays, sensors and standard NATO data link. Several of the remaining Hornets are going to be fitted to carry air-to-ground ordnance such as the AGM-158 JASSM, in effect returning to the original F/A-18 multi-role configuration. The upgrade includes also the procurement and integration of new AIM-9X Sidewinder and AIM-120C-7 AMRAAM air-to-air missiles. This Mid-Life Upgrade (MLU) is estimated to cost between €1–1.6 billion and work is scheduled to be finished by 2016. After the upgrades the aircraft are to remain in active service until 2020–2025. In October 2014 the Finnish broadcaster Yle announced that consideration was being given to the replacement of the Hornet.
Over half of the fleet was upgraded by 1 June 2015. During that week the Finnish Air Force was to drop its first live bombs (JDAM) in 70 years, since World War II.
Kuwait.
The Kuwait Air Force ("Al Quwwat Aj Jawwaiya Al Kuwaitiya") ordered 32 F/A-18C and eight F/A-18D Hornets in 1988. Delivery started in October 1991 until August 1993. The F/A-18C/Ds replaced A-4KU Skyhawk. Kuwait Air Force Hornets have flown missions over Iraq during Operation Southern Watch in the 1990s. They have also participated in military exercises with the air forces of other Gulf nations. Kuwait had 39 F/A-18C/D Hornets in service in 2008.
Malaysia.
The Royal Malaysian Air Force ("Tentera Udara Diraja Malaysia") has eight F/A-18Ds. Delivery of the aircraft started in March 1997 until August 1997. The air force split their order between the F/A-18 and the Mikoyan MiG-29N.
Three Hornets were employed together with five UK-made BAE Hawk 208 in an airstrike on the Royal Security Forces of the Sultanate of Sulu and North Borneo terrorist hideout on 5 March 2013, occupying part of Borneo, just before the joint forces of Malaysian Army and Royal Malaysia Police operatives launched an assault in the Operation Daulat. Malaysian Hornets were deployed for close air support to the no-fly zone in eastern Sabah.
Spain.
The Spanish Air Force ("Ejército del Aire") ordered 60 EF-18A model and 12 EF-18B model Hornets (the "E" standing for "España", Spain), named respectively as C.15 and CE.15 by Spanish AF. Delivery of the Spanish version started on 22 November 1985 until July 1990. These fighters were upgraded to F-18A+/B+ standard, close to F/A-18C/D (plus version includes later mission and armament computers, databuses, data-storage set, new wiring, pylon modifications and software, new abilities as AN/AAS-38B NITE Hawk targeting FLIR pods).
In 1995 Spain obtained 24 ex-USN F/A-18A Hornets, with six more on option. These were delivered from December 1995 until December 1998. Before delivery, they were modified to EF-18A+ standard. This was the first sale of USN surplus Hornets.
Spanish Hornets operate as an all-weather interceptor 60% of the time and as an all-weather day/night attack aircraft for the remainder. In case of war, each of the front-line squadrons would take a primary role: 121 is tasked with tactical air support and maritime operations; 151 and 122 are assigned to all-weather interception and air combat roles; and 152 is assigned the SEAD mission. Air refueling is provided by KC-130Hs and Boeing 707TTs. Pilot conversion to EF-18 is centralized in 153 Squadron (Ala 15). Squadron 462's role is air defense of the Canary Islands, being responsible for fighter and attack missions from Gando AB.
Spanish Air Force EF-18 Hornets have flown Ground Attack, SEAD, combat air patrol (CAP) combat missions in Bosnia and Kosovo, under NATO command, in Aviano detachment (Italy). They shared the base with Canadian and USMC F/A-18s. Six Spanish Hornets had been lost in accidents by 2003.
Over Yugoslavia, eight EF-18s, based at Aviano AB, participated in bombing raids in Operation Allied Force in 1999. Over Bosnia, they also performed missions for air-to-air combat air patrol, close air support air-to-ground, photo reconnaissance, forward air controller-airborne, and tactical air controller-airborne. Over Libya, four Spanish Hornets participated in enforcing a no-fly zone.
Switzerland.
The Swiss Air Force purchased 26 C models and eight D models. Delivery of the aircraft started in January 1996 until December 1999. Three D models had been lost in crashes as of 2015. On 14 October 2015, a F/A-18D crashed in France during training with two Swiss Air Force F-5s in the Swiss/French training area EURAC25; the pilot ejected safely.
In late 2007, Switzerland requested to be included in F/A-18C/D Upgrade 25 Program, to extend the useful life of its F/A-18C/Ds. The program includes significant upgrades to the avionics and mission computer, 20 ATFLIR surveillance and targeting pods, and 44 sets of AN/ALR-67v3 ECM equipment. In October 2008, the Swiss Hornet fleet reached the 50,000 flight hour milestone.
Potential operators.
The F/A-18C and F/A-18D were considered by the French Navy ("Marine Nationale") during the 1980s for deployment on their aircraft carriers "Clemenceau" and "Foch" and again in the 1990s for the later nuclear-powered "Charles de Gaulle", in the event that the Dassault Rafale M was not brought into service when originally planned.
Austria, Chile, Czech Republic, Hungary, Philippines, Poland, and Singapore evaluated the Hornet but did not purchase it. Thailand ordered four C and four D model Hornets but the Asian financial crisis in the late 1990s resulted in the order being canceled. The Hornets were completed as F/A-18Ds for the U.S. Marine Corps.
The F/A-18A and F-18L land-based version competed for a fighter contract from Greece in the 1980s. The Greek government chose F-16 and Mirage 2000 instead.
Variants.
A/B.
The "F/A-18A" is the single-seat variant and the "F/A-18B" is the two-seat variant. The space for the two-seat cockpit is provided by a relocation of avionics equipment and a 6% reduction in internal fuel; two-seat Hornets are otherwise fully combat-capable. The B-model is used primarily for training.
In 1992, the original Hughes AN/APG-65 radar was replaced with the Hughes (now Raytheon) AN/APG-73, a faster and more capable radar. A-model Hornets that have been upgraded to the AN/APG-73 are designated "F/A-18A+".
C/D.
The "F/A-18C" is the single-seat variant and the "F/A-18D" is the two-seat variant. The D-model can be configured for training or as an all-weather strike craft. The "missionized" D model's rear seat is configured for a Marine Corps Naval Flight Officer who functions as a Weapons and Sensors Officer to assist in operating the weapons systems. The F/A-18D is primarily operated by the U.S. Marine Corps in the night attack and Forward Air Controller (Airborne) (FAC(A)) roles.
The F/A-18C and D models are the result of a block upgrade in 1987 incorporating upgraded radar, avionics, and the capacity to carry new missiles such as the AIM-120 AMRAAM air-to-air missile and AGM-65 Maverick and AGM-84 Harpoon air-to-surface missiles. Other upgrades include the Martin-Baker NACES (Navy Aircrew Common Ejection Seat), and a self-protection jammer. A synthetic aperture ground mapping radar enables the pilot to locate targets in poor visibility conditions. C and D models delivered since 1989 also have improved night attack abilities, consisting of the Hughes AN/AAR-50 thermal navigation pod, the Loral AN/AAS-38 NITE Hawk FLIR (forward looking infrared array) targeting pod, night vision goggles, and two full-color (formerly monochrome) multi-function display (MFDs) and a color moving map.
In addition, 60 D-model Hornets are configured as the night attack "F/A-18D (RC)" with ability for reconnaissance. These could be outfitted with the ATARS electro-optical sensor package that includes a sensor pod and equipment mounted in the place of the M61 cannon.
Beginning in 1992, the F404-GE-402 enhanced performance engine, providing approximately 10% more maximum static thrust became the standard Hornet engine. Since 1993, the AAS-38A NITE Hawk added a designator/ranger laser, allowing it to self-mark targets. The later AAS-38B added the ability to strike targets designated by lasers from other aircraft.
Production of the C- and D- models ended in 2000. The last F/A-18C was assembled in Finland and delivered to the Finnish Air Force in August 2000. The last F/A-18D was delivered to the U.S. Marine Corps in August 2000.
E/F Super Hornet.
The single-seat "F/A-18E" and two-seat "F/A-18F Super Hornets" carry over the name and design concept of the original F/A-18, but have been extensively redesigned. The Super Hornet has a new, 25% larger airframe, larger rectangular air intakes, more powerful GE F414 engines based on F/A-18's F404, and upgraded avionics suite. Like the Marine Corps' F/A-18D, the Navy's F/A-18F carries a Naval Flight Officer as a second crew member in a Weapons Systems Officer (WSO) role. The Super Hornet is also operated by Australia.
G Growler.
The EA-18G Growler is an electronic warfare version of the two-seat F/A-18F, which entered production in 2007. The Growler is replacing the Navy's EA-6B Prowler and carries a Naval Flight Officer as a second crewman in an Electronic Countermeasures Officer (ECMO) role.
Export variants.
"These designations are not part of 1962 United States Tri-Service aircraft designation system."
Notable appearances in media.
Hornets make frequent appearances in action movies and military novels. The Hornet was featured in the film "Independence Day" and "Behind Enemy Lines" as well as in 1998's "Godzilla". The Hornet has a major role in Jane's "US Navy Fighters" (1994), Jane's "Fighters Anthology" (1997) and "Jane's F/A-18 Simulator" computer simulators.

</doc>
<doc id="45999" url="https://en.wikipedia.org/wiki?curid=45999" title="Gecko (software)">
Gecko (software)

Gecko is a web browser engine used in many applications developed by Mozilla Foundation and the Mozilla Corporation (notably the Firefox web browser including its mobile version "other than iOS devices", and their e-mail client Thunderbird), as well as in many other open source software projects. Gecko is free and open-source software subject to the terms of the Mozilla Public License version 2.
It is designed to support open Internet standards, and is used by different applications to display web pages and, in some cases, an application's user interface itself (by rendering XUL). Gecko offers a rich programming API that makes it suitable for a wide variety of roles in Internet-enabled applications, such as web browsers, content presentation, and client/server.
Gecko is written in C++ and is cross-platform, and runs on various operating systems including BSDs, Linux, OS X, Solaris, OS/2, AIX, OpenVMS, and Microsoft Windows. Its development is now overseen by the Mozilla Foundation.
History.
Development of the layout engine now known as Gecko began at Netscape in 1997, following the company's purchase of DigitalStyle. The existing Netscape rendering engine, originally written for Netscape Navigator 1.0 and upgraded through the years, was slow, did not comply well with W3C standards, had limited support for dynamic HTML and lacked features such as incremental reflow (when the layout engine rearranges elements on the screen as new data is downloaded and added to the page). The new layout engine was developed in parallel with the old, with the intention being to integrate it into Netscape Communicator when it was mature and stable. At least one more major revision of Netscape was expected to be released with the old layout engine before the switch.
After the launch of the Mozilla project in early 1998, the new layout engine code was released under an open-source license. Originally unveiled as "Raptor", the name had to be changed to "NGLayout" (next generation layout) due to trademark problems. Netscape later rebranded NGLayout as "Gecko". While Mozilla Organization (the forerunner of the Mozilla Foundation) initially continued to use the NGLayout name (Gecko was a Netscape trademark), eventually the Gecko branding won out.
In October 1998, Netscape announced that its next browser would use Gecko (which was still called NGLayout at the time) rather than the old layout engine, requiring large parts of the application to be rewritten. While this decision was popular with web standards advocates, it was largely unpopular with Netscape developers, who were unhappy with the six months given for the rewrite. It also meant that most of the work done for Netscape Communicator 5.0 (including development on the Mariner improvements to the old layout engine) had to be abandoned. Netscape 6, the first Netscape release to incorporate Gecko, was released in November 2000 (the name Netscape 5 was never used).
As Gecko development continued, other applications and embedders began to make use of it. America Online, by this time Netscape's parent company, eventually adopted it for use in CompuServe 7.0 and AOL for Mac OS X (these products had previously embedded Internet Explorer). However, with the exception of a few betas, Gecko was never used in the main Microsoft Windows AOL client.
On July 15, 2003, AOL laid off the remaining Gecko developers and the Mozilla Foundation (formed on the same day) became the main steward of Gecko development. Today, Gecko is developed by employees of the Mozilla Corporation, employees of companies that contribute to the Mozilla project, and volunteers.
Standards support.
From the outset, Gecko was designed to support open Internet standards. Some of the standards Gecko supports include:
Gecko also partially supports SVG 1.1.
In order to support web pages designed for legacy versions of Netscape and Internet Explorer, Gecko supports DOCTYPE switching. Documents with a modern DOCTYPE are rendered in standards compliance mode, which follows the W3C standards strictly. Documents that have no DOCTYPE or an older DOCTYPE are rendered in quirks mode, which emulates some of the non-standard oddities of Netscape Communicator 4.x; however, some of the 4.x features (such as layers) are not supported.
Gecko also has limited support for some non-standard Internet Explorer features, such as the marquee element and the codice_1 property (though pages explicitly testing for codice_1 will be told it is not supported).
Usage.
Gecko is primarily used in web browsers, the earliest being Netscape 6 and Mozilla Suite (later renamed SeaMonkey). It is also used in other Mozilla web browser derivatives such as Firefox and Firefox for mobile and the implementation of the Internet Explorer-clone that is part of Wine. Mozilla also uses it in their Thunderbird email-client and their Firefox OS.
Other web browsers using Gecko include Airfox, Waterfox, K-Meleon, Lunascape, Pale Moon, Portable Firefox, Conkeror, Classilla, TenFourFox, HP Secure Web Browser, Oxygen and Sylera (for mobile).
Other products using Gecko include Conkeror, Oxygen, Nightingale, Instantbird and Google's picture-organization software Picasa (for Linux).
DevHelp, a GTK+/GNOME browser for API documentation, used Gecko for rendering documents.
Gecko is also used by Sugar for the OLPC XO-1 computer. Gecko is used as a complete implementation of the XUL (XML User Interface Language). Gecko currently defines the XUL specification.
Products that have historically used Gecko include Songbird, Epiphany (now known as Web and no longer using Gecko), Sunbird (calendar), and other web browsers including Swiftfox, Flock, Galeon, Camino, Minimo, Beonex Communicator, Kazehakase, and MicroB.
After Gecko 2.0, the version number was bumped to 5.0 to match Firefox 5, and from then on has been kept in sync with the major version number for both Firefox and Thunderbird, to reflect the fact that it is no longer a separate component.
Criticism.
In the past, Gecko had slower market share adoption due to the complexity of the Gecko code, which aimed to provide much more than just an HTML renderer for web browsers.
Mozilla's engineering efforts since then have addressed many of these historical weaknesses.
The Gecko engine also provides a versatile XML-based user interface rendering framework called XUL that was used extensively in mail, newsgroup, and other programs. Another reason for much of the complexity in Gecko is the use of XPCOM, a cross-platform component model. However, its use has been scaled back.
On Windows and similar platforms, Gecko depends on non-free compilers. Thus, FOSS distributions of Linux can not include the Gecko package used in the Windows compatibility layer Wine.

</doc>
<doc id="46000" url="https://en.wikipedia.org/wiki?curid=46000" title="Alexandru Ioan Cuza">
Alexandru Ioan Cuza

Alexandru Ioan Cuza (, or Alexandru Ioan I, also anglicised as Alexander John Cuza; 20 March 1820 – 15 May 1873) was Prince of Moldavia, Prince of Wallachia, and later Domnitor (ruler) of the Romanian Principalities. He was a prominent figure of the Revolution of 1848 in Moldavia. He initiated a series of reforms that contributed to the modernization of Romanian society and of state structures.
Early life.
Born in Bârlad, Cuza belonged to the traditional boyar class in Moldavia, being the son of Ispravnic Ioan Cuza (who was also a landowner in Fălciu County) and his wife Sultana (or Soltana), a member of the Cozadini family of Phanariote origins. Alexander received an urbane European education, becoming an officer in the Moldavian Army (rising to the rank of colonel). He married Elena Rosetti in 1844.
In 1848, known as the year of European revolutions, Moldavia and Wallachia fell into revolt. The Moldavian unrest was quickly suppressed, but in Wallachia the revolutionaries took power and governed during the summer ("see 1848 Wallachian revolution"). Young Cuza played a prominent enough part so as to establish his liberal credentials during the Moldavian episode and to be shipped to Vienna as a prisoner, where he made his escape with British support.
Returned during the reign of Prince Grigore Alexandru Ghica, he became Moldavia's minister of war in 1858 representing also Galați in the ad hoc Divan at Iași. Cuza was acting freely under the guarantees of the European Powers in the eve of the Crimean War for a recognition of the Prince of Moldavia. Cuza was a prominent speaker in the debates and strongly advocated the union of Moldavia and Walachia. In default of a foreign prince, he was nominated as a candidate in both principalities by the pro-unionist Partida Națională (profiting of an ambiguity in the text of the Treaty of Paris). Cuza was finally elected as Prince of Moldavia on 17 January 1859 (5 January Julian) and, after "street pressure" changed the vote in Bucharest, also Prince of Wallachia, on 5 February 1859 (24 January Julian). He received the firman from the Sultan on 2 December 1861 during a visit to Istanbul.
He was recipient of the Order of Medjidie, Order of Osmanieh, Order of Saints Maurice and Lazarus and Order of the Redeemer.
Although he and his wife Elena Rosetti had no children, she raised as her own children his two sons from his mistress Elena Maria Catargiu-Obrenović: Alexandru Al. Ioan Cuza (1864–1889), and Dimitrie Cuza (1865–1888 "suicide").
Reign.
Diplomatic efforts.
Thus Cuza achieved a de facto union of the two principalities. The Powers backtracked, Napoleon III of France remaining supportive, while the Austrian ministry withheld approval of such a union at the Congress of Paris (18 October 1858); partly as a consequence, Cuza's authority was not recognized by his nominal suzerain, Abdülaziz, the Sultan of the Ottoman Empire, until 23 December 1861, (and, even then, the union was only accepted for the duration of Cuza's rule).
The union was formally declared three years later, on 5 February 1862, (24 January Julian), the new country bearing the name of Romania, with Bucharest as its capital city.
Cuza invested his diplomatic actions in gaining further concessions from the Powers: the sultan's assent to a single unified parliament and cabinet for Cuza's lifetime, in recognition of the complexity of the task. Thus, he was regarded as the political embodiment of a unified Romania.
Reforms.
Assisted by his councilor Mihail Kogălniceanu, an intellectual leader of the 1848 revolution, Cuza initiated a series of reforms that contributed to the modernization of Romanian society and of state structures.
His first measure addressed a need for increasing the land resources and revenues available to the state, by "secularizing" (confiscating) monastic assets in 1863. Probably more than a quarter of Romania's farmland was controlled by untaxed Eastern Orthodox "Dedicated Monasteries", which supported Greek and other foreign monks in shrines such as Mount Athos and Jerusalem (a substantial drain on state revenues). Cuza got his parliament's backing to expropriate these lands. He offered compensation to the Greek Orthodox Church, but Sophronius III, the Patriarch of Constantinople, refused to negotiate; after several years, the Romanian government withdrew its offer and no compensation was ever paid. State revenues thereby increased without adding any domestic tax burden.
The land reform, liberating peasants from the last corvées, freeing their movements and redistributing some land (1864), was less successful. In attempting to create a solid support base among the peasants, Cuza soon found himself in conflict with the group of Conservatives. A liberal bill granting peasants title to the land they worked was defeated. Then the Conservatives responded with a bill that ended all peasant dues and responsibilities, but gave landlords title to all the land. Cuza vetoed it, then held a plebiscite to alter the Paris Convention (the virtual constitution), in the manner of Napoleon III.
His plan to establish universal manhood suffrage, together with the power of the Domnitor to rule by decree, passed by a vote of 682,621 to 1,307. He consequently governed the country under the provisions of "Statutul dezvoltător al Convenției de la Paris" ("Statute expanding the Paris Convention"), an organic law adopted on 15 July 1864. With his new plenary powers, Cuza then promulgated the Agrarian Law of 1863. Peasants received title to the land they worked, while landlords retained ownership of one third. Where there was not enough land available to create workable farms under this formula, state lands (from the confiscated monasteries) would be used to give the landowners compensation.
Despite the attempts by Lascăr Catargiu's cabinet to force a transition in which some corvées were to be maintained, Cuza's reform marked the disappearance of the boyar class as a privileged group, and led to a channeling of energies into capitalism and industrialization; at the same time, however, land distributed was still below necessities, and the problem became stringent over the following decades – as peasants reduced to destitution sold off their land or found that it was insufficient for the needs of their growing families.
Cuza's reforms also included the adoption of the Criminal Code and the Civil Code based on the Napoleonic code (1864), a Law on Education, establishing tuition-free, compulsory public education for primary schools (1864; the system, nonetheless, suffered from drastic shortages in allocated funds; illiteracy was eradicated about 100 years later, during the communist regime). He founded the University of Iași (1860) and the University of Bucharest (1864), and helped develop a modern, European-style Romanian Army, under a working relationship with France. He is the founder of the Romanian Naval Forces.
Downfall and exile.
Cuza failed in his effort to create an alliance of prosperous peasants and a strong liberal prince, ruling as a benevolent authoritarian in the style of Napoleon III. Having to rely on a decreasing group of hand-picked bureaucrats, Cuza began facing a mounting opposition after his land reform bill, with liberal landowners voicing concerns over his ability to represent their interests. Along with financial distress, there was an awkward scandal that revolved around his mistress, Maria Catargi-Obrenović, and popular discontent culminated in a coup d'état.
Cuza was forced to abdicate by the so-called "monstrous coalition" of Conservatives and Liberals. At four o'clock on the morning of 22 February 1866, a group of military conspirators broke into the palace, and compelled the prince to sign his abdication. On the following day they conducted him safely across the frontier.
His successor, Prince Karl of Hohenzollern-Sigmaringen, was proclaimed Domnitor as Carol I of Romania on 20 April 1866. The election of a foreign prince with ties to an important princely house, legitimizing Romanian independence (which Carol came to do after the Russo-Turkish War of 1877–1878), had been one of the liberal aims in the revolution of 1848.
Despite the participation of Ion Brătianu and other future leaders of the Liberal Party in the overthrow of Cuza, he remained a hero to the radical and republican wing, who, as Francophiles, had an additional reason to oppose a Prussian monarch; anti-Carol riots in Bucharest during the Franco-Prussian War ("see History of Bucharest") and the coup attempt known as the Republic of Ploiești in August 1870, the conflict was eventually resolved by the compromise between Brătianu and Carol, with the arrival of a prolonged and influential Liberal cabinet.
Cuza spent the remainder of his life in exile, chiefly in Paris, Vienna and Wiesbaden, accompanied by his wife, his mistress, and his two sons. He died in Heidelberg. His remains were buried in his residence in Ruginoasa, but were moved to the Trei Ierarhi Cathedral in Iași after World War II.

</doc>
<doc id="46001" url="https://en.wikipedia.org/wiki?curid=46001" title="Web browser engine">
Web browser engine

A web browser engine (sometimes called layout engine or rendering engine) is a program that renders marked up content (such as HTML, XML, image files, etc.) and formatting information (such as CSS, XSL, etc.).
A layout engine is typical component of web browsers, email clients, e-book readers, on-line help systems or other applications that require the displaying (and editing) of web content. Engines may wait for all data to be received before rendering a page, or may begin rendering before all data are received. This can result in pages changing as more data is received, such as images being filled in or a flash of unstyled content if rendering begins before formatting information is received.
Examples.
KDE's open-source KHTML engine is used in KDE's Konqueror web browser and was the basis for WebKit, the rendering engine in Apple's Safari and Google's Chrome web browsers, which is now the most widely used browser engine according to StatCounter. Current versions of Chromium/Chrome (except iOS version) and Opera are based on Blink, a fork of WebKit.
Gecko, the Mozilla project's open-source web browser engine, is used by a variety of products derived from the Mozilla code base, including the Firefox web browser, the Thunderbird e-mail client, and SeaMonkey internet suite.
Trident, the web browser engine from Internet Explorer, is used by many applications on the Microsoft Windows platform, such as netSmart, Outlook Express, some versions of Microsoft Outlook, and the mini-browsers in Winamp and RealPlayer.
Opera Software's proprietary Presto engine is licensed to a number of other software vendors, and was used in Opera's own web browser until it was switched to Blink in 2013.
MARTHA is a proprietary software engine developed with Java by RealObjects. The vendor prefix for MARTHA is codice_1
Technical operation.
The first web browsers were monolithic. They used various techniques inherited from text processing, such as regular expressions, to parse HTML into a visual representation. Later they adopted a more modular approach and were split into a host application and an engine.
This modular approach has the advantage that it then becomes easy to embed web-browser engines in a variety of applications. For example, the same engine used by a web browser can be used by an email client to display HTML email. On-line help systems integrated in applications have largely moved from using custom formats to using standard HTML displayed with a web-browser engine. The EPUB 3 e-book standard uses a layout engine to render XHTML and CSS.

</doc>
<doc id="46002" url="https://en.wikipedia.org/wiki?curid=46002" title="Pax Americana">
Pax Americana

Pax Americana (Latin for "American Peace", modeled after "Pax Britannica" and "Pax Romana") is a term applied to the concept of relative peace in the Western Hemisphere and later the world as a result of the preponderance of power enjoyed by the United States beginning around the middle of the 20th century and continuing to this day. Although the term finds its primary utility in the latter half of the 20th century, it has been used with different meanings and eras, such as the post-Civil War era in North America, and regionally in the Americas at the start of the 20th century.
"Pax Americana" is primarily used in its modern connotations to refer to the peace among great powers established after the end of World War II in 1945, also called the Long Peace. In this modern sense, it has come to indicate the military and economic position of the United States in relation to other nations. For example, the Marshall Plan, which spent $13 billion to rebuild the economy of Western Europe, has been seen as "the launching of the pax americana."
The Latin term derives from "Pax Romana" of the Roman Empire. The term is most notably associated with "Pax Britannica" under the British Empire, which served as the global hegemony and constabulary from the late 18th century until the early 20th century. 
Early period.
The first articulation of a "Pax Americana" occurred after the end of the American Civil War with reference to the peaceful nature of the North American geographical region, and was abeyant at the commencement of the First World War. Its emergence was concurrent with the development of the idea of American exceptionalism. This view holds that the U.S. occupies a special niche among developed nations in terms of its national credo, historical evolution, political and religious institutions, and unique origins. The concept originates from Alexis de Tocqueville, who asserted that the then-50-year-old United States held a special place among nations because it was a country of immigrants and the first modern democracy. From the establishment of the United States after the American Revolution until the Spanish–American War, the foreign policy of the United States had a regional, instead of global, focus. The Pax Americana, which the Union enforced upon the states of central North America, was a factor in the United States' national prosperity. The larger states were surrounded by smaller states, but these had no anxieties: no standing armies to require taxes and hinder labor; no wars or rumors of wars that would interrupt trade; there is not only peace, but security, for the Pax Americana of the Union covered all the states within the federal constitutional republic. According to the Oxford English Dictionary, the first time the phrase appeared in print was in the August 1894 issue of "Forum": "The true cause for exultation is the universal outburst of patriotism in support of the prompt and courageous action of President Cleveland in maintaining the supremacy of law throughout the length and breadth of the land, in establishing the "pax Americana"."
With the rise of the New Imperialism in the Western hemisphere at the end of the 19th century, debates arose between imperialist and isolationist factions in the U.S. Here, "Pax Americana" was used to connote the peace across the United States and, more widely, as a Pan-American peace under the aegis of the Monroe Doctrine. Those who favored traditional policies of avoiding foreign entanglements included labor leader Samuel Gompers and steel tycoon Andrew Carnegie. American politicians such as Henry Cabot Lodge, William McKinley, and Theodore Roosevelt advocated an aggressive foreign policy, but the administration of President Grover Cleveland was unwilling to pursue such actions. On January 16, 1893, U.S. diplomatic and military personnel conspired with a small group of individuals to overthrow the constitutional government of the Kingdom of Hawaii and establish a Provisional Government and then a republic. On February 15, they presented a treaty for annexation of the Hawaiian Islands to the U.S. Senate, but opposition to annexation stalled its passage. The United States finally opted to annex Hawaii by way of the Newlands Resolution in July 1898.
After its victory in the Spanish–American War of 1898 and the subsequent acquisition of Cuba, Puerto Rico, the Philippines, and Guam, the United States had gained a colonial empire. By ejecting Spain from the Americas, the United States shifted its position to an uncontested regional power, and extended its influence into Southeast Asia and Oceania. Although U.S. capital investments within the Philippines and Puerto Rico were relatively small, these colonies were strategic outposts for expanding trade with Latin America and Asia, particularly China. In the Caribbean area, the United States established a sphere of influence in line with the Monroe Doctrine, not explicitly defined as such, but recognized in effect by other governments and accepted by at least some of the republics in that area. The events around the start of the 20th century demonstrated that the United States undertook an obligation, usual in such cases, of imposing a "Pax Americana". As in similar instances elsewhere, this Pax Americana was not quite clearly marked in its geographical limit, nor was it guided by any theoretical consistency, but rather by the merits of the case and the test of immediate expediency in each instance. Thus, whereas the United States enforced a peace in much of the lands southward from the Nation and undertook measures to maintain internal tranquility in such areas, the United States on the other hand withdrew from interposition in Mexico.
European powers largely regarded these matters as the concern of the United States. Indeed, the nascent Pax Americana was, in essence, abetted by the policy of the United Kingdom, and the preponderance of global sea power which the British Empire enjoyed by virtue of the strength of the Royal Navy. Preserving the freedom of the seas and ensuring naval dominance had been the policy of the British since victory in the Napoleonic Wars. As it was not in the interests of the United Kingdom to permit any European power to interfere in Americas, the Monroe Doctrine was indirectly aided by the Royal Navy. British commercial interests in South America, which comprised a valuable component of the Informal Empire that accompanied Britain's imperial possessions, and the economic importance of the United States as a trading partner, ensured that intervention by Britain's rival European powers could not engage with the Americas.
The United States lost its Pacific and regionally bounded nature towards the end of the 19th century. The government adopted protectionism after the Spanish–American War and built up the navy, the "Great White Fleet", to expand the reach of U.S. power. When Theodore Roosevelt became President in 1901, he accelerated a foreign policy shift away from isolationism towards foreign intervention which had begun under his predecessor, William McKinley. The Philippine–American War arose from the ongoing Philippine Revolution against imperialism. Interventionism found its formal articulation in the 1904 Roosevelt Corollary to the Monroe Doctrine, proclaiming the right of the United States to intervene in the affairs of weak states in the Americas in order to stabilize them, a moment that underlined the emergent U.S. regional hegemony.
Interwar period.
The United States had been criticized for not taking up the hegemonic mantle following the disintegration of "Pax Britannica" before the First World War and during the interwar period due to the absence of established political structures, such as the World Bank or United Nations which would be created after World War II, and various internal policies, such as protectionism. Though, the United States participated in the Great War, according to Woodrow Wilson, to:
[...] to vindicate the principles of peace and justice in the life of the world as against selfish and autocratic power and to set up amongst the really free and self-governed peoples of the world such a concert of purpose and of action as will henceforth insure the observance of those principles.
[...] for democracy, for the right of those who submit to authority to have a voice in their own government, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.
The United States' entry into the Great War marked the abandonment of the traditional American policy of isolation and independence of world politics. Not at the close of the Civil War, not as the result of the Spanish War, but in the Interwar period did the United States become a part of the international system. With this global reorganization from the Great War, there were those in the American populace that advocated an activist role in international politics and international affairs by the United States. Activities that were initiated did not fall into political-military traps and, instead, focused on economic-ideological approaches that would increase the American Empire and general worldwide stability. Following the prior path, a precursor to the United Nations and a league to enforce peace, the League of Nations, was proposed by Woodrow Wilson. This was rejected by the American Government in favor of more economic-ideological approaches and the United States did not join the League. Additionally, there were even proposals of extending the Monroe Doctrine to Great Britain put forth to prevent a second conflagration on the European theater. Ultimately, the United States' proposals and actions did not stop the factors of European nationalism spawned by the previous war, the repercussions of Germany's defeat, and the failures of the Treaty of Versailles from plunging the globe into a Second World War.
Between World War I and World War II, America also sought to continue to preserve "Pax America" as a corollary to the Monroe Doctrine. Some sought the peaceful and orderly evolution of existing conditions in the western hemisphere and nothing by immediate changes. Before 1917, the position of the United States government and the feelings of the nation in respect to the "Great War" initially had properly been one of neutrality. Its interests remained untouched, and nothing occurred of a nature to affect those interests.
The average American's sympathies, on the other hand, if the feelings of the vast majority of the nation had been correctly interpreted, was with the Allied (Entente) Powers. The population of the United States was revolted at the ruthlessness of the Prussian doctrine of war, and German designs to shift the burden of aggression encountered skeptical derision. The American populace saw themselves safeguarding liberal peace in the Western World. To this end, the American writer Roland Hugins stated:
The truth is that the United States is the only high-minded Power left in the world. It is the only strong nation that has not entered on a career of imperial conquest, and does not want to enter on it. [...] There is in America little of that spirit of selfish aggression which lies at the heart of militarism. Here alone exists a broad basis for "a new passionate sense of brotherhood, and a new scale of human values." We have a deep abhorrence of war for war's sake; we are not enamored of glamour or glory. We have a strong faith in the principle of self-government. We do not care to dominate alien peoples, white or colored; we do not aspire to be the Romans of tomorrow or the "masters of the world." The idealism of Americans centers in the future of America, wherein we hope to work out those principles of liberty and democracy to which we are committed This political idealism, this strain of pacifism, this abstinence from aggression and desire to be left alone to work out our own destiny, has been manifest from the birth of the republic. We have not always followed our light, but we have never been utterly faithless to it.
It was observed during this time that the initial defeat of Germany opened a moral recasting of the world. The battles between Germans and Allies were seen as far less battles between different nations than they represent the contrast between Liberalism and reaction, between the aspirations of democracy and the Wilhelminism gospel of iron.
Modern period.
The modern "Pax Americana" era is cited by both supporters and critics of U.S. foreign policy after World War II. However, from 1946 to 1992 "Pax americana" is considered a partial international order, as it applied only to capitalist block countries, being preferable for some authors to speak about a "Pax americana et sovietica". Many commentators and critics focus on American policies from 1992 to the present, and as such, it carries different connotations depending on the context. For example, it appears three times in the 90 page document, "Rebuilding America's Defenses," by the Project for the New American Century, but is also used by critics to characterize American dominance and hyperpower as imperialist in function and basis. From about the mid-1940s until 1991, U.S. foreign policy was dominated by the Cold War, and characterized by its significant international military presence and greater diplomatic involvement. Seeking an alternative to the isolationist policies pursued after World War I, the United States defined a new policy called containment to oppose the spread of communism.
The modern "Pax Americana" may be seen as similar to the period of peace in Rome, "Pax Romana". In both situations, the period of peace was 'relative peace'. During both "Pax Romana" and "Pax Americana" wars continued to occur, but it was still a prosperous time for both Western and Roman civilizations. It is important to note that during these periods, and most other times of relative tranquility, the peace that is referred to does not mean complete peace. Rather, it simply means that the civilization prospered in their military, agriculture, trade, and manufacturing.
"Pax Britannica" heritage.
From the end of the Napoleonic Wars in 1815 until World War I in 1914, the United Kingdom played the role of offshore-balancer in Europe, where the balance of power was the main aim. It was also in this time that the British Empire became the largest empire of all time. The global superiority of British military and commerce was guaranteed by dominance of a Europe lacking in strong nation-states, and the presence of the Royal Navy on all of the world's oceans and seas. In 1905, the Royal Navy was superior to any two navies combined in the world. It provided services such as suppression of piracy and slavery. In this era of peace, though, there were several wars between the major powers: the Crimean War, the Franco-Austrian War, the Austro-Prussian War, the Franco-Prussian War, and the Russo-Japanese War, as well as numerous other wars.
During the British hegemony, America developed close ties with Britain, evolving into what has become known as a "special relationship" between the two. The many commonalities shared with the two nations (such as language and history) drew them together as allies. Under the managed transition of the British Empire to the Commonwealth of Nations, members of the British government, such as Harold Macmillan, liked to think of Britain's relationship with America as similar to that of a progenitor Greece to America's Rome. Throughout the years, both have been active in North American, Middle Eastern, and Asian countries.
Late 20th century.
After the Second World War, no armed conflict emerged among major Western nations themselves, and no nuclear weapons were used in open conflict. The United Nations was also soon developed after World War II to help keep peaceful relations between nations and establishing the veto power for the permanent members of the UN Security Council, which included the United States.
In the second half of the 20th century, the USSR and USA superpowers were engaged in the Cold War, which can be seen as a struggle between hegemonies for global dominance. After 1945, the United States enjoyed an advantageous position with respect to the rest of the industrialized world. In the Post–World War II economic expansion, the US was responsible for half of global industrial output, held 80 percent of the world's gold reserves, and was the world's sole nuclear power. The catastrophic destruction of life, infrastructure, and capital during the Second World War had exhausted the imperialism of the Old World, victor and vanquished alike. The largest economy in the world at the time, the United States recognized that it had come out of the war with its domestic infrastructure virtually unscathed and its military forces at unprecedented strength. Military officials recognized the fact that Pax Americana had been reliant on the effective United States air power, just as the instrument of Pax Britannica a century earlier was its sea power. In addition, a "unipolar moment" was seen to have occurred following the collapse of the Soviet Union.
The term "Pax Americana" was explicitly used by John F. Kennedy in the 1960s, who advocated against the idea, arguing that the Soviet bloc was composed of human beings with the same individual goals as Americans and that such a peace based on "American weapons of war" was undesirable:
"I have, therefore, chosen this time and place to discuss a topic on which ignorance too often abounds and the truth too rarely perceived. And that is the most important topic on earth: peace. What kind of peace do I mean and what kind of a peace do we seek? Not a "Pax Americana" enforced on the world by American weapons of war. Not the peace of the grave or the security of the slave. I am talking about genuine peace, the kind of peace that makes life on earth worth living, and the kind that enables men and nations to grow, and to hope, and build a better life for their children -- not merely peace for Americans but peace for all men and women, not merely peace in our time but peace in all time.
Beginning around the Vietnam War, the 'Pax Americana' term had started to be used by the critics of American Imperialism. Here in the late 20th century conflict between the Soviet Union and the United States, the charge of "Neocolonialism" was often aimed at Western involvement in the affairs of the Third World and other developing nations.
Contemporary power.
Currently, the "Pax Americana" is based on the military preponderance beyond challenge by any combination of powers and projection of power throughout the world's "commons"—neutral sea, air and space. This projection is coordinated by the Unified Command Plan which divides the world on regional branches controlled by a single command. Integrated with it are global network of military alliances (the Rio Pact, NATO, ANZUS and bilateral alliances with Japan and several other states) coordinated by Washington in a hub-and-spokes system and world-wide network of several hundreds of military bases and installations. Former Security Advisor, Zbignew Brzezinski, drew an expressive summary of the military foundation of "Pax Americana" shortly after the "unipolar moment":
Besides the military foundation, there are significant non-military international institutions backed by American financing and diplomacy (like the United Nations and WTO). The United States invested heavily in programs such as the Marshall Plan and in the reconstruction of Japan, economically cementing defense ties that owed increasingly to the establishment of the Iron Curtain/Eastern Bloc and the widening of the Cold War.
Being in the best position to take advantage of free trade, culturally indisposed to traditional empires, and alarmed by the rise of communism in China and the detonation of the first Soviet atom bomb, the historically non-interventionist U.S. also took a keen interest in developing multilateral institutions which would maintain a favorable world order among them. The International Monetary Fund and International Bank for Reconstruction and Development (World Bank), part of the Bretton Woods system of international financial management was developed and, until the early 1970s, the existence of a fixed exchange rate to the US dollar. The General Agreement on Tariffs and Trade (GATT) was developed and consists of a protocol for normalization and reduction of trade tariffs.
With the fall of the Iron Curtain, the demise of the notion of a "Pax Sovietica", and the end of the Cold War, the U.S. maintained significant contingents of armed forces in Europe and East Asia. The institutions behind the Pax Americana and the rise of the United States unipolar power have persisted into the early 21st century. The ability of the United States to act as "the world's policeman" has been constrained by its own citizens' historic aversion to foreign wars. Though there has been calls for the continuation of military leadership, as stated in "Rebuilding America's Defenses":
The American peace has proven itself peaceful, stable, and durable. It has, over the past decade, provided the geopolitical framework for widespread economic growth and the spread of American principles of liberty and democracy. Yet no moment in international politics can be frozen in time; even a global "Pax Americana" will not preserve itself. [... What is required is] a military that is strong and ready to meet both present and future challenges; a foreign policy that boldly and purposefully promotes American principles abroad; and national leadership that accepts the United States’ global responsibilities.
This is reflected in the research of American exceptionalism, which shows that "there is some indication for a leader of an "American peace" among the [U.S.] public, but very little evidence of unilateral attitudes". It should be noted that resentments have arisen at a country's' dependence on American military protection, due to disagreements with United States foreign policy or the presence of American military forces.
In the "post-communism" world of the 21st-century, the French Socialist politician and former Foreign Minister Hubert Védrine describes the USA as a hegemonic hyperpower, while the U.S. political scientists John Mearsheimer and Joseph Nye counter that the USA is not a “true” hegemony, because it does not have the resources to impose a proper, formal, global rule; despite its political and military strength, the USA is economically equal to Europe, thus, cannot rule the international stage. Several other countries are either emerging or re-emerging as powers, such as China, Russia, India, and the European Union.
Joseph Nye discredited the United States as not a "true" hegemony but his 2002 article he titled "The New Rome Meets the New Barbarians." In fact, there are striking parallels with the early "Pax Romana" (especially between 189 BC when the supremacy over the Mediterranean was won and the first annexation in 168 BC). Under that "Pax Romana" other states remained formally independent and very seldom were called "clients." The latter term became widely used only in the late medieval period. Usually, other states were called "friends and allies"—a popular expression under the "Pax Americana".
In 1992, a US strategic draft for the post-Cold War period was leaked to the press. The responsible for the confusion, former Assistant Secretary of State, Paul Wolfowitz, confessed seven years later: "In 1992 a draft memo prepared by my office at the Pentagon ... leaked to the press and sparked a major controversy." The draft's strategy aimed "to prevent any hostile power from dominating" a Eurasian region "whose resources would, under consolidated control, be sufficient to generate global power." He added: "Senator Joseph Biden ridiculed the proposed strategy as 'literally a "Pax Americana"... It won't work...' Just seven years later, many of these same critics seem quite comfortable with the idea of a "Pax Americana"."
American imperialism.
"American imperialism" is a term referring to outcomes or ideological elements of United States foreign policy. Since the start of the cold war, the United States has economically and/or diplomatically supported friendly foreign governments, including many that overtly violated the civil and human rights of their own citizens and residents. American imperialism concepts were initially a product of capitalism critiques and, later, of theorists opposed to what they take to be aggressive United States policies and doctrines. Although there are various views of the imperialist nature of the United States, which describe many of the same policies and institutions as evidence of imperialism, explanations for imperialism vary widely. In spite of such literature, the historians Archibald Paton Thorton and Stuart Creighton Miller argue against the very coherence of the concept. Miller argues that the overuse and abuse of the term "imperialism" makes it nearly meaningless as an analytical concept.
More specifically, critics of American influence contend that the Bush Doctrine of advancing democracy throughout all the world is all that is needed to justify the term "American Imperialism". On the other hand, advocates of American influence define imperialism as colonialism to some degree and claim protectionism, rather than imperialism, as the rationale for recent American international behavior. Such people emphasize that American history of returning governance back to indigenous people, supporting decolonization, and insisting on a rejection of previous isolationist policies, do not constitute the embrace of imperialism. The argument is made that unlike Britain in the previous century (during Pax Britannica) America does not directly rule subject peoples and practice closed trading policies.
Regardless, it is acknowledged that American isolationism subsided only after major shocks associated with the Spanish–American War and the two world wars. Critics such as Howard Zinn and Noam Chomsky argue that the United States has sought, or has found itself forced into, a quasi-imperialist role by its status as the world's sole superpower.
As to the "isolationist" history of the United States, it mainly applies to the global stage; the United States has not been isolationist with respect to the Western Hemisphere, which fell within its sphere of influence, and pursued military interventions within this region of the world. Though relative peace existed in the Western world, the United States and its allies have been involved in various regional wars, such as the Korean War, the Vietnam War, the Gulf War, the Yugoslav wars, the Afghanistan War and the Iraq War. The United States also maintained espionage and covert operations in various other areas, such as Latin America in the 1980s.

</doc>
<doc id="46003" url="https://en.wikipedia.org/wiki?curid=46003" title="Common Language Runtime">
Common Language Runtime

The Common Language Runtime (CLR), the virtual machine component of Microsoft's .NET framework, manages the execution of .NET programs. A process known as just-in-time compilation converts compiled code into machine instructions which the computer's CPU then executes. The CLR provides additional services including memory management, type safety, exception handling, garbage collection, security and thread management. All programs written for the .NET framework, regardless of programming language, are executed by the CLR. All versions of the .NET framework include CLR.
CLR implements the Virtual Execution System (VES) as defined in the Common Language Infrastructure (CLI) standard, initially developed by Microsoft itself. A public standard defines the Common Language Infrastructure specification.
Benefits.
The runtime provides the following benefits:

</doc>
<doc id="46004" url="https://en.wikipedia.org/wiki?curid=46004" title="Common Intermediate Language">
Common Intermediate Language

Common Intermediate Language (CIL, pronounced either "sil" or "kil"), formerly called Microsoft Intermediate Language or MSIL, is the lowest-level human-readable programming language defined by the Common Language Infrastructure (CLI) specification and is used by the .NET Framework and Mono. Languages which target a CLI-compatible runtime environment compile to CIL, which is assembled into an object code that has a bytecode-style format. CIL is an object-oriented assembly language, and is entirely stack-based. Its bytecode is translated into native code or — most commonly — executed by a virtual machine.
CIL was originally known as Microsoft Intermediate Language (MSIL) during the beta releases of the .NET languages. Due to standardization of C# and the Common Language Infrastructure, the bytecode is now officially known as CIL.
In an unrelated usage, CIL also refers to the C Intermediate Language, a simplified transformation of C used for further analysis.
General information.
During compilation of CLI programming languages, the source code is translated into CIL code rather than into platform- or processor-specific object code. CIL is a CPU- and platform-independent instruction set that can be executed in any environment supporting the Common Language Infrastructure, such as the .NET runtime on Windows, or the cross-platform Mono runtime. In theory, this eliminates the need to distribute different executable files for different platforms and CPU types. CIL code is verified for safety during runtime, providing better security and reliability than natively compiled executable files.
The execution process looks like this:
Instructions.
CIL bytecode has instructions for the following groups of tasks:
Computational model.
The Common Intermediate Language is object-oriented and stack-based. That means that data is pushed on a stack instead of pulled from registers as in most CPU architectures.
In x86 it might look like this:
The corresponding code in IL can be rendered as this:
Here are two locals that are pushed on the stack. When the add-instruction is called the operands get popped and the result is pushed. The remaining value is then popped and stored in the first local.
Object-oriented concepts.
This extends to object-oriented concepts as well. You may create objects, call methods and use other types of members such as fields.
CIL is designed to be object-oriented and every method needs (with some exceptions) to reside in a class. So does this static method:
This method does not require any instance of Foo to be declared because it is static. That means it belongs to the class and it may then be used like this in C#:
In CIL:
Instance classes.
An instance class contains at least one constructor and some instance members. This class has a set of methods representing actions of a Car-object.
Creating objects.
In C# class instances are created like this:
And these statements are roughly the same as these instructions:
Invoking instance methods.
Instance methods are invoked like the one that follows:
In CIL:
Metadata.
CLI records information about compiled classes as Metadata. Like the type library in the Component Object Model, this enables applications to support and discover the interfaces, classes, types, methods, and fields in the assembly. The process of reading such metadata is called "reflection".
Metadata can be data in the form of " attributes". Attributes can be custom made by extending from the codice_1 class. This is a very powerful feature. It allows the creator of the class the ability to adorn it with extra information that consumers of the class can use in various meaningful ways depending on the application domain.
Example.
Below is a basic Hello, World program written in CIL. It will display the string "Hello, world!".
The following code is more complex in number of opcodes.
"This code can also be compared with the corresponding code in the article about Java bytecode."
This is just a representation of how CIL looks like near VM-level. When compiled the methods are stored in tables and the instructions are stored as bytes inside the assembly, which is a Portable Executable (PE).
Generation.
A CIL assembly and instructions are generated by either a compiler or a utility called the "IL Assembler" (ILAsm) that is shipped with the execution environment.
Assembled CIL can also be disassembled into code again using the "IL Disassembler" (ILDASM). There are other tools such as .NET Reflector that can decompile CIL into a high-level language (e. g. C# or Visual Basic). This makes CIL a very easy target for reverse engineering. This trait is shared with Java bytecode. However, there are tools that can obfuscate the code, and do it so that the code cannot be easily readable but still be runnable.
Execution.
Just-in-time compilation.
Just-in-time compilation (JIT) involves turning the byte-code into code immediately executable by the CPU. The conversion is performed gradually during the program's execution. JIT compilation provides environment-specific optimization, runtime type safety, and assembly verification. To accomplish this, the JIT compiler examines the assembly metadata for any illegal accesses and handles violations appropriately.
Ahead-of-time compilation.
CLI-compatible execution environments also come with the option to do an Ahead-of-time compilation (AOT) of an assembly to make it execute faster by removing the JIT process at runtime.
In the .NET Framework there is a special tool called the Native Image Generator (NGEN) that performs the AOT. In Mono there is also an option to do an AOT.
Pointer instructions - C++/CLI.
A huge difference from Java's bytecode is that CIL comes with ldind, stind, ldloca, and many call instructions which are enough for data/function pointers manipulation needed to compile C/C++ code into CIL.
The corresponding code in IL can be rendered as this:

</doc>
<doc id="46006" url="https://en.wikipedia.org/wiki?curid=46006" title="Freedom of religion">
Freedom of religion

Freedom of religion or freedom of belief is a principle that supports the freedom of an individual or community, in public or private, to manifest religion or belief in teaching, practice, worship, and observance. It also includes the freedom to change one's religion or belief.
Freedom of religion is considered by many people and nations to be a fundamental human right. In a country with a state religion, freedom of religion is generally considered to mean that the government permits religious practices of other sects besides the state religion, and does not persecute believers in other faiths.
History.
Historically, "freedom of religion" has been used to refer to the tolerance of different theological systems of belief, while "freedom of worship" has been defined as freedom of individual action. Each of these have existed to varying degrees. While many countries have accepted some form of religious freedom, this has also often been limited in practice through punitive taxation, repressive social legislation, and political disenfranchisement. Compare examples of individual freedom in Italy or the Muslim tradition of dhimmis, literally "protected individuals" professing an officially tolerated non-Muslim religion.
In Antiquity, a syncretic point of view often allowed communities of traders to operate under their own customs. When street mobs of separate quarters clashed in a Hellenistic or Roman city, the issue was generally perceived to be an infringement of community rights.
Cyrus the Great established the Achaemenid Empire ca. 550 BC, and initiated a general policy of permitting religious freedom throughout the empire, documenting this on the Cyrus Cylinder.
Some of the historical exceptions have been in regions where one of the revealed religions has been in a position of power: Judaism, Zoroastrianism, Christianity and Islam. Others have been where the established order has felt threatened, as shown in the trial of Socrates in 399 BC or where the ruler has been deified, as in Rome, and refusal to offer token sacrifice was similar to refusing to take an oath of allegiance. This was the core for resentment and the persecution of early Christian communities.
Freedom of religious worship was established in the Buddhist Maurya Empire of ancient India by Ashoka the Great in the 3rd century BC, which was encapsulated in the Edicts of Ashoka.
Greek-Jewish clashes at Cyrene in 73 AD and 117 AD and in Alexandria in 115 AD provide examples of cosmopolitan cities as scenes of tumult.
Muslim world.
Following a period of fighting lasting around a hundred years before 620 AD which mainly involved Arab and Jewish inhabitants of Medina (then known as "Yathrib"), religious freedom for Muslims, Jews and pagans were declared by Muhammad in the Constitution of Medina. The Islamic Caliphate later guaranteed religious freedom under the conditions that non-Muslim communities accept "dhimmi" (second class) status and their adult males pay the punitive "jizya" tax instead of the "zakat" paid by Muslim citizens.
Religious pluralism existed in classical Islamic ethics and Sharia, as the religious laws and courts of other religions, including Christianity, Judaism and Hinduism, were usually accommodated within the Islamic legal framework, as seen in the early Caliphate, Al-Andalus, Indian subcontinent, and the Ottoman Millet system. In medieval Islamic societies, the "qadi" (Islamic judges) usually could not interfere in the matters of non-Muslims unless the parties voluntarily choose to be judged according to Islamic law, thus the "dhimmi" communities living in Islamic states usually had their own laws independent from the Sharia law, such as the Jews who would have their own "Halakha" courts.
Dhimmis were allowed to operate their own courts following their own legal systems in cases that did not involve other religious groups, or capital offences or threats to public order. Non-Muslims were allowed to engage in religious practices that was usually forbidden by Islamic law, such as the consumption of alcohol and pork, as well as religious practices which Muslims found repugnant, such as the Zoroastrian practice of incestuous "self-marriage" where a man could marry his mother, sister or daughter. According to the famous Islamic legal scholar Ibn Qayyim (1292–1350), non-Muslims had the right to engage in such religious practices even if it offended Muslims, under the conditions that such cases not be presented to Islamic Sharia courts and that these religious minorities believed that the practice in question is permissible according to their religion.
ISIS re-established the punitive "jizya" tax and forbade Christians in Syria from building places of worship, ringing bells, wearing crosses or criticizing Islam, or face beheading.
India.
Religious freedom and the right to worship freely were practices that had been appreciated and promoted by most ancient Indian dynasties. As a result, people fleeing religious persecution in other parts of the world including Christians, Jews, Bahá'í Faith and Zoroastrians fled to India as a place of refuge to enjoy religious freedom.
Ancient Jews fleeing from persecution in their homeland 2,500 years ago settled in India and never faced anti-Semitism. Freedom of religion edicts have been found written during Ashoka the Great's reign in the 3rd century BC. Freedom to practise, preach and propagate any religion is a constitutional right in Modern India. Most major religious festivals of the main communities are included in the list of national holidays.
Although India is an 80% Hindu country, three out of the twelve presidents of India have been Muslims.
Many scholars and intellectuals believe that India's predominant religion, Hinduism, has long been a most tolerant religion. Rajni Kothari, founder of the Centre for the Study of Developing Societies has written, " is a country built on the foundations of a civilisation that is fundamentally non-religious."
The Dalai Lama, the Tibetan leader in exile said that religious tolerance of 'Aryabhoomi,' a reference to India found in Mahabharata, has been in existence in this country from thousands of years. "Not only Hinduism, Jainism, Buddhism, Sikhism which are the native religions but also Christianity and Islam have flourished here. Religious tolerance is inherent in Indian tradition," the Dalai Lama said.
Freedom of religion in the Indian subcontinent is exemplified by the reign of King Piyadasi (304 BC to 232 BC) (Ashoka). One of King Ashoka's main concerns was to reform governmental institutes and exercise moral principles in his attempt to create a just and humane society. Later he promoted the principles of Buddhism, and the creation of a just, understanding and fair society was held as an important principle for many ancient rulers of this time in the East.
The importance of freedom of worship in India was encapsulated in an inscription of Ashoka:
The initial entry of Islam into South Asia came in the first century after the death of the Islamic Prophet Muhammad. When around 1210 AD the Islamic Sultanates invaded India from the north-west, gradually the principle of freedom of religion deteriorated in this part of the world. They were subsequently replaced by another Islamic invader in the form of Babur. The Mughal empire was founded by the Mongol leader Babur in 1526, when he defeated Ibrahim Lodi, the last of the Delhi Sultans at the First Battle of Panipat. The word "Mughal" is the Indo-Iranian version of Mongol.
On the main Asian continent, the Mongols were tolerant of religions. People could worship as they wished freely and openly, though the formation of 2 nations i.e. Pakistan and Bangladesh has been on basis of religious intolerance.
After arrival of Europeans, Christians in zeal to convert local as per belief in conversion as service of God, have also been seen to fall into frivolous methods since their arrival. Though by and large there are hardly any reports of law and order disturbance from mobs with Christian beliefs except perhaps in the north eastern region of India.
Freedom of religion in contemporary India is a fundamental right guaranteed under Article 25 of the nation's constitution. Accordingly, every citizen of India has a right to profess, practice and propagate their religions peacefully. Vishwa Hindu Parishad counters this argument by saying that evangelical Christians are forcefully (or through money) converting rural, illiterate populations and they are only trying to stop this.
In September 2010, Indian state Kerala's State Election Commissioner announced that "Religious heads cannot issue calls to vote for members of a particular community or to defeat the nonbelievers". The Catholic Church comprising Latin, Syro-Malabar and Syro-Malankara rites used to give clear directions to the faithful on exercising their franchise during elections through pastoral letters issued by bishops or council of bishops. The pastoral letter issued by Kerala Catholic Bishops' Council (KCBC) on the eve of the poll urged the faithful to shun atheists.
Even today, most Indians celebrate all religious festivals with equal enthusiasm and respect. Hindu festivals like Deepavali and Holi, Muslim festivals like Eid al-Fitr, Eid-Ul-Adha, Muharram, Christian festivals like Christmas and other festivals like Buddha Purnima, Mahavir Jayanti, Gur Purab etc. are celebrated and enjoyed by all Indians.
Europe.
Religious intolerance.
Most Roman Catholic kingdoms kept a tight rein on religious expression throughout the Middle Ages. Jews were alternately tolerated and persecuted, the most notable examples of the latter being the expulsion of all Jews from Spain in 1492. Some of those who remained and converted were tried as heretics in the Inquisition for allegedly practicing Judaism in secret. Despite the persecution of Jews, they were the most tolerated non-Catholic faith in Europe.
However, the latter was in part a reaction to the growing movement that became the Reformation. As early as 1380, John Wycliffe in England denied transubstantiation and began his translation of the Bible into English. He was condemned in a Papal Bull in 1410, and all his books were burned.
In 1414, Jan Hus, a Bohemian preacher of reformation, was given a safe conduct by the Holy Roman Emperor to attend the Council of Constance. Not entirely trusting in his safety, he made his will before he left. His forebodings proved accurate, and he was burned at the stake on 6 July 1415. The Council also decreed that Wycliffe's remains be disinterred and cast out. This decree was not carried out until 1429.
After the fall of the city of Granada, Spain, in 1492, the Muslim population was promised religious freedom by the Treaty of Granada, but that promise was short-lived. In 1501, Granada's Muslims were given an ultimatum to either convert to Christianity or to emigrate. The majority converted, but only superficially, continuing to dress and speak as they had before and to secretly practice Islam. The Moriscos (converts to Christianity) were ultimately expelled from Spain between 1609 (Castile) and 1614 (rest of Spain), by Philip III.
Martin Luther published his famous 95 Theses in Wittenberg on 31 October 1517. His major aim was theological, summed up in the three basic dogmas of Protestantism:
In consequence, Luther hoped to stop the sale of indulgences and to reform the Church from within. In 1521, he was given the chance to recant at the Diet of Worms before Charles V, Holy Roman Emperor, then only 19. After he refused to recant, he was declared heretic. Partly for his own protection, he was sequestered on the Wartburg in the possessions of Frederick III, Elector of Saxony, where he translated the New Testament into German. He was excommunicated by Papal Bull in 1521.
However, the movement continued to gain ground in his absence and spread to Switzerland. Huldrych Zwingli preached reform in Zürich from 1520 to 1523. He opposed the sale of indulgences, celibacy, pilgrimages, pictures, statues, relics, altars, and organs. This culminated in outright war between the Swiss cantons that accepted Protestantism and the Catholics. The Catholics were victorious, and Zwingli was killed in battle in 1531. The Catholic cantons were magnanimous in victory.
The defiance of Papal authority proved contagious, and in 1533, when Henry VIII of England was excommunicated for his divorce and remarriage to Anne Boleyn, he promptly established a state church with bishops appointed by the crown. This was not without internal opposition, and Thomas More, who had been his Lord Chancellor, was executed in 1535 for opposition to Henry.
In 1535, the Swiss canton of Geneva became Protestant. In 1536, the Bernese imposed the reformation on the canton of Vaud by conquest. They sacked the cathedral in Lausanne and destroyed all its art and statuary. John Calvin, who had been active in Geneva was expelled in 1538 in a power struggle, but he was invited back in 1540.
The same kind of seesaw back and forth between Protestantism and Catholicism was evident in England when Mary I of England returned that country briefly to the Catholic fold in 1553 and persecuted Protestants. However, her half-sister, Elizabeth I of England was to restore the Church of England in 1558, this time permanently, and began to persecute Catholics again. The King James Bible commissioned by King James I of England and published in 1611 proved a landmark for Protestant worship, with official Catholic forms of worship being banned.
In France, although peace was made between Protestants and Catholics at the Treaty of Saint Germain in 1570, persecution continued, most notably in the Massacre of Saint Bartholomew's Day on 24 August 1572, in which thousands of Protestants throughout France were killed. A few years before, at the "Michelade" of Nîmes in 1567, Protestants had massacred the local Catholic clergy.
Early steps and attempts in the way of tolerance.
The Norman Kingdom of Sicily under Roger II was characterized by its multi-ethnic nature and religious tolerance. Normans, Jews, Muslim Arabs, Byzantine Greeks, Lombards, and native Sicilians lived in harmony. Rather than exterminate the Muslims of Sicily, Roger II's grandson Emperor Frederick II of Hohenstaufen (1215—1250) allowed them to settle on the mainland and build mosques. Not least, he enlisted them in his – Christian – army and even into his personal bodyguards.
Bohemia (present-day Czech Republic) enjoyed religious freedom between 1436 and 1520, and became one of the most liberal countries of the Christian world during that period of time. The so-called Basel Compacts of 1436 declared the freedom of religion and peace between Catholics and Utraquists. In 1609 Emperor Rudolf II granted Bohemia greater religious liberty with his Letter of Majesty. The privileged position of the Catholic Church in the Czech kingdom was firmly established after the Battle of White Mountain in 1620. Gradually freedom of religion in Bohemian lands came to an end and Protestants fled or were expelled from the country. A devout Catholic, Emperor Ferdinand II forcibly converted Austrian and Bohemian Protestants.
In the meantime, in Germany Philip Melanchthon drafted the Augsburg Confession as a common confession for the Lutherans and the free territories. It was presented to Charles V in 1530.
In the Holy Roman Empire, Charles V agreed to tolerate Lutheranism in 1555 at the Peace of Augsburg. Each state was to take the religion of its prince, but within those states, there was not necessarily religious tolerance. Citizens of other faiths could relocate to a more hospitable environment.
In France, from the 1550s, many attempts to reconcile Catholics and Protestants and to establish tolerance failed because the State was too weak to enforce them. It took the victory of prince Henry IV of France, who had converted into Protestantism, and his accession to the throne, to impose religious tolerance formalized in the Edict of Nantes in 1598. It would remain in force for over 80 years until its revocation in 1685 by Louis XIV of France. Intolerance remained the norm until Louis XVI, who signed the Edict of Versailles (1787), then the constitutional text of 24 December 1789, granting civilian rights to Protestants. The French Revolution then abolished state religion and confiscated all Church property, turning intolerance against Catholics.
Early laws and legal guarantees for religious freedom.
In 1558, the Transylvanian Diet Diet of Torda declared free practice of both Catholicism and Lutherianism. Calvinism, however, was prohibited. Ten years later, in 1568, the Diet extended the freedom to all religions, declaring that "It is not allowed to anybody to intimidate anybody with captivity or expelling for his religion". However, it was more than a religious tolerance; it declared the equality of the religions. The emergence in social hierarchy wasn't depend on the religion of the person thus Transylvania had also Catholic and Protestant monarchs. The lack of state religion was unique for centuries in Europe. Therefore, the Edict of Torda is considered by mostly Hungarian historians as the first legal guarantee of religious freedom in Christian Europe.
In the Union of Utrecht (20 January 1579), personal freedom of religion was declared in the struggle between the Northern Netherlands and Spain. The Union of Utrecht was an important step in the establishment of the Dutch Republic (from 1581 to 1795). Under Calvinist leadership, the Netherlands became the most tolerant country in Europe. It granted asylum to persecuted religious minorities, such as the Huguenots, the Dissenters, and the Jews who had been expelled from Spain and Portugal. The establishment of a Jewish community in the Netherlands and New Amsterdam (present-day New York) during the Dutch Republic is an example of religious freedom. When New Amsterdam surrendered to the English in 1664, freedom of religion was guaranteed in the Articles of Capitulation. It benefitted also the Jews who had landed on Manhattan Island in 1654, fleeing Portuguese persecution in Brazil. During the 18th century, other Jewish communities were established at Newport, Rhode Island, Philadelphia, Charleston, Savannah, and Richmond.
Intolerance of dissident forms of Protestantism also continued, as evidenced by the exodus of the Pilgrims, who sought refuge, first in the Netherlands, and ultimately in America, founding Plymouth Colony in Massachusetts in 1620. William Penn, the founder of Philadelphia, was involved in a case which had a profound effect upon future American laws and those of England. In a classic case of jury nullification, the jury refused to convict William Penn of preaching a Quaker sermon, which was illegal. Even though the jury was imprisoned for their acquittal, they stood by their decision and helped establish the freedom of religion.
Poland.
Poland has a long tradition of religious freedom. The right to worship freely was a basic right given to all inhabitants of the Commonwealth throughout the 15th and early 16th century, however, complete freedom of religion was officially recognized in Poland in 1573 during the Warsaw Confederation. Poland kept religious freedom laws during an era when religious persecution was an everyday occurrence in the rest of Europe.
The General Charter of Jewish Liberties known as the Statute of Kalisz was issued by the Duke of Greater Poland Boleslaus the Pious on 8 September 1264 in Kalisz. The statute served as the basis for the legal position of Jews in Poland and led to creation of the Yiddish-speaking autonomous Jewish nation until 1795. The statute granted exclusive jurisdiction of Jewish courts over Jewish matters and established a separate tribunal for matters involving Christians and Jews. Additionally, it guaranteed personal liberties and safety for Jews including freedom of religion, travel, and trade. The statute was ratified by subsequent Polish Kings: Casimir III of Poland in 1334, Casimir IV of Poland in 1453 and Sigismund I of Poland in 1539. The Commonwealth set a precedent by allowing Jews to become ennobled.
United States.
Most of the early colonies were generally not tolerant of dissident forms of worship, with Maryland being one of the exceptions. For example, Roger Williams found it necessary to found a new colony in Rhode Island to escape persecution in the theocratically dominated colony of Massachusetts. The Puritans of the Massachusetts Bay Colony were the most active of the New England persecutors of Quakers, and the persecuting spirit was shared by Plymouth Colony and the colonies along the Connecticut river. In 1660, one of the most notable victims of the religious intolerance was English Quaker Mary Dyer, who was hanged in Boston, Massachusetts for repeatedly defying a Puritan law banning Quakers from the colony. As one of the four executed Quakers known as the Boston martyrs, the hanging of Dyer on the Boston gallows marked the beginning of the end of the Puritan theocracy and New England independence from English rule, and in 1661 King Charles II explicitly forbade Massachusetts from executing anyone for professing Quakerism.
Freedom of religion was first applied as a principle of government in the founding of the colony of Maryland, founded by the Catholic Lord Baltimore, in 1634. Fifteen years later (1649), the Maryland Toleration Act, drafted by Lord Baltimore, provided: "No person or persons...shall from henceforth be any waies troubled, molested or discountenanced for or in respect of his or her religion nor in the free exercise thereof." The Maryland Toleration Act was repealed during the Cromwellian Era with the assistance of Protestant assemblymen and a new law barring Catholics from openly practicing their religion was passed. In 1657, the Catholic Lord Baltimore regained control after making a deal with the colony's Protestants, and in 1658 the Act was again passed by the colonial assembly. This time, it would last more than thirty years, until 1692 when, after Maryland's Protestant Revolution of 1689, freedom of religion was again rescinded. In addition, in 1704, an Act was passed "to prevent the growth of Popery in this Province", preventing Catholics from holding political office. Full religious toleration would not be restored in Maryland until the American Revolution, when Maryland's Charles Carroll of Carrollton signed the American Declaration of Independence.
Rhode Island (1636), Connecticut (1636), New Jersey, and Pennsylvania (1682)—founded by Protestants Roger Williams, Thomas Hooker, and William Penn, respectively—combined the democratic form of government which had been developed by the Puritans and the Separatist Congregationalists in Massachusetts with religious freedom. These colonies became sanctuaries for persecuted religious minorities. Catholics and later on Jews also had full citizenship and free exercise of their religions. Williams, Hooker, Penn, and their friends were firmly convinced that freedom of conscience was the will of God. Williams gave the most profound argument: As faith is the free work of the Holy Spirit, it cannot be forced on a person. Therefore, strict separation of church and state has to be kept. Pennsylvania was the only colony that retained unlimited religious freedom until the foundation of the United States in 1776. It was the inseparable connection between democracy, religious freedom, and the other forms of freedom which became the political and legal basis of the new nation. In particular, Baptists and Presbyterians demanded the disestablishment of state churches - Anglican and Congregationalist - and the protection of religious freedom.
Reiterating Maryland's and the other colonies' earlier colonial legislation, the Virginia Statute for Religious Freedom, written in 1779 by Thomas Jefferson, proclaimed:
o man shall be compelled to frequent or support any religious worship, place, or ministry whatsoever, nor shall be enforced, restrained, molested, or burthened in his body or goods, nor shall otherwise suffer, on account of his religious opinions or belief; but that all men shall be free to profess, and by argument to maintain, their opinions in matters of religion, and that the same shall in no wise diminish, enlarge, or affect their civil capacities.
Those sentiments also found expression in the First Amendment of the national constitution, part of the United States' Bill of Rights: "Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof..."
The United States formally considers religious freedom in its foreign relations. The International Religious Freedom Act of 1998 established the United States Commission on International Religious Freedom which investigates the records of over 200 other nations with respect to religious freedom, and makes recommendations to submit nations with egregious records to ongoing scrutiny and possible economic sanctions. Many human rights organizations have urged the United States to be still more vigorous in imposing sanctions on countries that do not permit or tolerate religious freedom.
Canada.
Freedom of religion in Canada is a constitutionally protected right, allowing believers the freedom to assemble and worship without limitation or interference. Canadian law goes further, requiring that private citizens and companies provide reasonable accommodation to those, for example, with strong religious beliefs. The Canadian Human Rights Act allows an exception to reasonable accommodation with respect to religious dress, such as a Sikh turban, when there is a "bona fide" occupational requirement, such as a workplace requiring a hard hat.
International.
On 25 November 1981, the United Nations General Assembly passed the "Declaration on the Elimination of All Forms of Intolerance and of Discrimination Based on Religion or Belief". This declaration recognizes freedom of religion as a fundamental human right in accordance with several other instruments of international law.
However, the most substantial binding legal instruments that guarantee the right to freedom of religion that was passed by the international community is the Convention on the Rights of the Child which states in its Article 14 : ""States Parties shall respect the right of the child to freedom of thought, conscience and religion. - States Parties shall respect the rights and duties of the parents and, when applicable, legal guardians, to provide direction to the child in the exercise of his or her right in a manner consistent with the evolving capacities of the child. - Freedom to manifest one's religion or beliefs may be subject only to such limitations as are prescribed by law and are necessary to protect public safety, order, health or morals, or the fundamental rights and freedoms of others.""
Contemporary debates.
Theistic, non-theistic and atheistic beliefs.
In 1993, the UN's human rights committee declared that article 18 of the International Covenant on Civil and Political Rights "protects theistic, non-theistic and atheistic beliefs, as well as the right not to profess any religion or belief." The committee further stated that "the freedom to have or to adopt a religion or belief necessarily entails the freedom to choose a religion or belief, including the right to replace one's current religion or belief with another or to adopt atheistic views." Signatories to the convention are barred from "the use of threat of physical force or penal sanctions to compel believers or non-believers" to recant their beliefs or convert. Despite this, minority religions still are still persecuted in many parts of the world.
Within the United States, the Freedom From Religion Foundation argues that the United States Constitution not only prohibits the intrusion of religion into the processes of government, but also guarantees equal rights to citizens who choose not to follow any religion. Conservative sociopolitical commentator Bryan Fischer has responded: "The Constitution guarantees freedom of religion, not freedom from religion."
Liberal secular.
Adam Smith, in his book "The Wealth of Nations" (using an argument first put forward by his friend and contemporary David Hume), states that in the long run it is in the best interests of society as a whole and the civil magistrate (government) in particular to allow people to freely choose their own religion, as it helps prevent civil unrest and reduces intolerance. So long as there are enough different religions and/or religious sects operating freely in a society then they are all compelled to moderate their more controversial and violent teachings, so as to be more appealing to more people and so have an easier time attracting new converts. It is this free competition amongst religious sects for converts that ensures stability and tranquillity in the long run.
Smith also points out that laws that prevent religious freedom and seek to preserve the power and belief in a particular religion will, in the long run, only serve to weaken and corrupt that religion, as its leaders and preachers become complacent, disconnected and unpractised in their ability to seek and win over new converts:
Hinduism.
Hinduism is one of the more open-minded religions when it comes to religious freedom. It respects the right of everyone to reach God in their own way. Hindus believe in different ways to preach attainment of God and religion as a philosophy and hence respect all religions as equal. One of the famous Hindu sayings about religion is: "Truth is one; sages call it by different names."
Judaism.
Judaism includes multiple streams, such as Orthodox, Reform Judaism, Conservative Judaism, Reconstructionist Judaism, Jewish Renewal and Humanistic Judaism. Israel, viewed as the Jewish homeland, has been evaluated in research by the Pew organization as having "high" government restrictions on religion. The government recognizes only Orthodox Judaism in certain matters of personal status, and marriages can only be performed by religious authorities. The government provides the greatest funding to Orthodox Judaism, even though adherents represent a minority of citizens. Jewish women, including Anat Hoffman, have been arrested at the Western Wall for praying and singing while wearing religious garments the Orthodox feel should be reserved for men. Women of the Wall have organized to promote religious freedom at the Wall. In November 2014, a group of 60 non-Orthodox rabbinical students were told they would not be allowed to pray in the Knesset synagogue because it is reserved for Orthodox. Rabbi Joel Levy, director of the Conservative Yeshiva in Jerusalem, said that he had submitted the request on behalf of the students and saw their shock when the request was denied. He noted: "paradoxically, this decision served as an appropriate end to our conversation about religion and state in Israel." MK Dov Lipman expressed the concern that many Knesset workers are unfamiliar with non-Orthodox and American practices and would view "an egalitarian service in the synagogue as an affront."
Christianity.
Prior to this, Pope Pius IX had written a document called the "Syllabus of Errors. "The Syllabus was made up of phrases and paraphrases from earlier papal documents, along with index references to them, and presented as a list of "condemned propositions". It does not explain why each particular proposition is wrong, but it cites earlier documents to which the reader can refer for the Pope's reasons for saying each proposition is false. Among the statements included in the Syllabus are: "is an error to say that Every man is free to embrace and profess that religion which, guided by the light of reason, he shall consider true" (15); "is an error to say that In the present day it is no longer expedient that the Catholic religion should be held as the only religion of the State, to the exclusion of all other forms of worship" (77); "is an error to say that Hence it has been wisely decided by law, in some Catholic countries, that persons coming to reside therein shall enjoy the public exercise of their own peculiar worship" (78).
Some Orthodox Christians, especially those living in democratic countries, support religious freedom for all, as evidenced by the position of the Ecumenical Patriarchate. Many Protestant Christian churches, including some Baptists, Churches of Christ, Seventh-day Adventist Church and main line churches have a commitment to religious freedoms. The Church of Jesus Christ of Latter-day Saints also affirms religious freedom.
However others, such as African scholar Makau Mutua, have argued that Christian insistence on the propagation of their faith to native cultures as an element of religious freedom has resulted in a corresponding denial of religious freedom to native traditions and led to their destruction. As he states in the book produced by the Oslo Coalition on Freedom of Religion or Belief, "Imperial religions have necessarily violated individual conscience and the communal expressions of Africans and their communities by subverting African religions."
In their book "Breaking India", Rajiv Malhotra and Aravindan Neelakandan discussed the "US Church" funding activities in India, such as the popularly advertised campaigns to "save" poor children by feeding, clothing, and educating them, with the book arguing that the funds collected were being used not so much for the purposes indicated to sponsors, but for indoctrination and conversion activities. They suggest that India is the prime target of a huge enterprise—a "network" of organizations, individuals, and churches—that, they argue, seem intensely devoted to the task of creating a separatist identity, history, and even religion for the vulnerable sections of India. They suggest that this nexus of players includes not only church groups, government bodies, and related organizations, but also private think tanks and academics.
Joel Spring has written about the Christianization of the Roman Empire:
Christianity added new impetus to the expansion of empire. Increasing the arrogance of the imperial project, Christians insisted that the Gospels and the Church were the only valid sources of religious beliefs. Imperialists could claim that they were both civilizing the world and spreading the true religion. By the 5th century, Christianity was thought of as co-extensive with the "Imperium romanum". This meant that to be human, as opposed to being a natural slave, was to be "civilized" and Christian. Historian Anthony Pagden argues, "just as the "civitas"; had now become coterminous with Christianity, so to be human—to be, that is, one who was 'civil', and who was able to interpret correctly the law of nature—one had now also to be Christian." After the fifteenth century, most Western colonialists rationalized the spread of empire with the belief that they were saving a barbaric and pagan world by spreading Christian civilization.
Islam.
Conversion to Islam is simple (cf. shahada), but Muslims are forbidden to convert from Islam to another religion. Certain Muslim-majority countries are known for their restrictions on religious freedom, highly favoring Muslim citizens over non-Muslim citizens. Other countries having the same restrictive laws tend to be more liberal when imposing them. Even other Muslim-majority countries are secular and thus do not regulate religious belief.
Some Islamic theologians quote the Qur'an ( and , i.e., Sura Al-Kafirun) to show scriptural support for religious freedom.
, referring to the war against Pagans during the Battle of Badr in Medina, indicates that Muslims are only allowed to fight against those who intend to harm them (right of self-defense) and that if their enemies surrender, they must also stop because God does not like those who transgress limits.
In Bukhari:V9 N316, Jabir ibn 'Abdullah narrated that a Bedouin accepted Islam and then when he got a fever he demanded that Muhammad to cancel his pledge (allow him to renounce Islam). Muhammad refused to do so. The Bedouin man repeated his demand once, but Muhammad once again refused. Then, he (the Bedouin) left Medina. Muhammad said, "Madinah is like a pair of bellows (furnace): it expels its impurities and brightens and clear its good." In this narration, there was no evidence demonstrating that Muhammad ordered the execution of the Bedouin for wanting to renounce Islam.
In addition, , which is believed to be God's final revelation to Muhammad, states that Muslims are to fear God and not those who reject Islam, and states that one is accountable only for one's own actions. Therefore, it postulates that in Islam, in the matters of practising a religion, it does not relate to a worldly punishment, but rather these actions are accountable to God in the afterlife. Thus, this supports the argument against the execution of apostates in Islam.
However, on the other hand, some Muslims support the practice of executing apostates who leave Islam, as in Bukhari:V4 B52 N260; "The Prophet said, 'If a Muslim discards his religion, kill him.
In Iran, the constitution recognizes four religions whose status is formally protected: Zoroastrianism, Judaism, Christianity, and Islam.
The constitution, however, also set the groundwork for the institutionalized persecution of Bahá'ís,
who have been subjected to arrests, beatings, executions, confiscation and destruction of property, and the denial of civil rights and liberties, and the denial of access to higher education. There is no freedom of conscience in Iran, as converting from Islam to any other religion is forbidden.
In Egypt, a 16 December 2006 judgment of the Supreme Administrative Council created a clear demarcation between recognized religions – Islam, Christianity and Judaism – and all other religious beliefs; no other religious affiliation is officially admissible. The ruling leaves members of other religious communities, including Bahá'ís, without the ability to obtain the necessary government documents to have rights in their country, essentially denying them of all rights of citizenship. They cannot obtain ID cards, birth certificates, death certificates, marriage or divorce certificates, and passports; they also cannot be employed, educated, treated in public hospitals or vote, among other things. See Egyptian identification card controversy.
Changing religion.
Among the most contentious areas of religious freedom is the right of an individual to change or abandon his or her own religion (apostasy), and the right to evangelize individuals seeking to convince others to make such a change.
Other debates have centered around restricting certain kinds of missionary activity by religions. Many Islamic states, and others such as China, severely restrict missionary activities of other religions. Greece, among European countries, has generally looked unfavorably on missionary activities of denominations others than the majority church and proselytizing is constitutionally prohibited.
A different kind of critique of the freedom to propagate religion has come from non-Abrahamic traditions such as the African and Indian. African scholar Makau Mutua criticizes religious evangelism on the ground of cultural annihilation by what he calls "proselytizing universalist faiths" (Chapter 28: Proselytism and Cultural Integrity, page 652):
Some Indian scholars have similarly argued that the right to propagate religion is not culturally or religiously neutral.
In Sri Lanka, there have been debates regarding a bill on religious freedom that seeks to protect indigenous religious traditions from certain kinds of missionary activities. Debates have also occurred in various states of India regarding similar laws, particularly those that restrict conversions using force, fraud or allurement.
In 2008, Christian Solidarity Worldwide, a Christian human rights non-governmental organisation which specializes in religious freedom, launched an in-depth report on the human rights abuses faced by individuals who leave Islam for another religion. The report is the product of a year long research project in six different countries. It calls on Muslim nations, the international community, the UN and the international media to resolutely address the serious violations of human rights suffered by apostates.
Apostasy in Islam.
In Islam, apostasy is called ""ridda"" ("turning back") and is considered to be a profound insult to God. A person born of Muslim parents that rejects Islam is called a ""murtad fitri"" (natural apostate), and a person that converted to Islam and later rejects the religion is called a ""murtad milli"" (apostate from the community).
In Islamic law (Sharia), the consensus view is that a male apostate must be put to death unless he suffers from a mental disorder or converted under duress, for example, due to an imminent danger of being killed. A female apostate must be either executed, according to Shafi'i, Maliki, and Hanbali schools of Sunni Islamic jurisprudence (fiqh), or imprisoned until she reverts to Islam as advocated by the Sunni Hanafi school and by Shi'a scholars.
Ideally, the one performing the execution of an apostate must be an imam. At the same time, all schools of Islamic jurisprudence agree that any Muslim can kill an apostate without punishment.
However, while almost all scholars agree about the punishment, many disagree on the allowable time to retract the apostasy. Many scholars push this as far as allowing the apostate till he/she dies. Thus, practically making the death penalty just a theoretical statement/exercise. S. A. Rahman, a former Chief Justice of Pakistan, argues that there is no indication of the death penalty for apostasy in the Qur'an.
Secular law.
Religious practice may also conflict with secular law, creating debates on religious freedom. For instance, even though polygamy is permitted in Islam, it is prohibited in secular law in many countries. This raises the question of whether prohibiting the practice infringes on the beliefs of certain Muslims. The US and India, both constitutionally secular nations, have taken two different views of this. In India, polygamy is permitted, but only for Muslims, under Muslim Personal Law. In the US, polygamy is prohibited for all. This was a major source of conflict between the early LDS Church and the United States until the Church amended its position on practicing polygamy.
Similar issues have also arisen in the context of the religious use of psychedelic substances by Native American tribes in the United States as well as other Native practices.
In 1955, Chief Justice of California Roger J. Traynor neatly summarized the American position on how freedom of religion cannot imply freedom from law: "Although freedom of conscience and the freedom to believe are absolute, the freedom to act is not." But with respect to the religious use of animals within secular law and those acts, the US Supreme Court decision in the case of the "Church of Lukumi Babalu Aye v. City of Hialeah" in 1993 upheld the right of Santeria adherents to practice ritual animal sacrifice, with Justice Anthony Kennedy stating in the decision: "religious beliefs need not be acceptable, logical, consistent or comprehensible to others in order to merit First Amendment protection" (quoted by Justice Kennedy from the opinion by Justice Burger in "Thomas v. Review Board of the Indiana Employment Security Division" ).
In 2015, Kim Davis, a Kentucky county clerk, refused to abide by the Supreme Court decision in "Obergefell v. Hodges" legalizing same-sex marriage in the United States. When she refused to issue marriage licenses, she became embroiled in the "Miller v. Davis" lawsuit. Her actions caused attorney and author Roberta Kaplan to state that "Kim Davis is the clearest example of someone who wants to use a religious liberty argument to discriminate."
Children's rights.
The law in Germany provides the term of "religious majority" ("Religiöse Mündigkeit") with a minimum age for minors to follow their own religious beliefs even if their parents don't share those or don't approve. Children 14 and older have the unrestricted right to enter or exit any religious community. Children 12 and older cannot be compelled to change to a different belief. Children 10 and older have to be heard before their parents change their religious upbringing to a different belief. There are similar laws in Austria and in Switzerland.
International Religious Freedom Day.
27 October is International Religious Freedom Day, in commemoration of the execution of the Boston martyrs, a group of Quakers executed by the Puritans on Boston Common for their religious beliefs under the legislature of the Massachusetts Bay Colony between 1659–1661. The US proclaimed 16 January Religious Freedom Day.
Modern concerns.
In its 2011 annual report, the "United States Commission on International Religious Freedom" designated fourteen nations as "countries of particular concern". The commission chairman commented that these are nations whose conduct marks them as the world's worst religious freedom violators and human rights abusers. The fourteen nations designated were Burma, China, Egypt, Eritrea, Iran, Iraq, Nigeria, North Korea, Pakistan, Saudi Arabia, Sudan, Turkmenistan, Uzbekistan, and Vietnam. Other nations on the commission's watchlist include Afghanistan, Belarus, Cuba, India, Indonesia, Laos, Russia, Somalia, Tajikistan, Turkey, and Venezuela.^ 
^ </ref>
There are concerns about the restrictions on public religious dress in some European countries (including the Hijab, Kippah, and Christian cross). Article 18 of the UN International Covenant on Civil and Political Rights limits restrictions on freedom to manifest one's religion or beliefs to those necessary to protect public safety, order, health, or morals or the fundamental rights and freedoms of others. Freedom of religion as a legal concept is related to, but not identical with, religious toleration, separation of church and state, or secular state ("laïcité").
Social hostilities and government restrictions.
The Pew Research Center has performed studies on international religious freedom between 2009 and 2015, compiling global data from 16 governmental and non-governmental organizations–including the United Nations, the United States State Department, and Human Rights Watch–and representing over 99.5 percent of the world's population. In 2009, nearly 70 percent of the world's population lived in countries classified as having heavy restrictions on freedom of religion. This concerns restrictions on religion originating from government prohibitions on free speech and religious expression as well as social hostilities undertaken by private individuals, organisations and social groups. Social hostilities were classified by the level of communal violence and religion-related terrorism.
While most countries provided for the protection of religious freedom in their constitutions or laws, only a quarter of those countries were found to fully respect these legal rights in practice. In 75 countries governments limit the efforts of religious groups to proselytise and in 178 countries religious groups must register with the government. In 2013, Pew classified 30% of countries as having restrictions that tend to target religious minorities, and 61% of countries have social hostilities that tend to target religious minorities.
The countries in North and South America reportedly had some of the lowest levels of "government" and "social" restrictions on religion, while The Middle East and North Africa were the regions with the highest. Saudi Arabia, Pakistan and Iran were the countries that top the list of countries with the "overall" highest levels of restriction on religion. Topping the Pew government restrictions index were Saudi Arabia, Iran, Uzbekistan, China, Egypt, Burma, Maldives, Eritrea, Malaysia and Brunei.
Of the world's 25 most populous countries, Iran, Egypt, Indonesia and Pakistan had the most restrictions, while Brazil, Japan, Italy, South Africa, the UK, and the US had some of the lowest levels, as measured by Pew.
Vietnam and China were classified as having high "government" restrictions on religion but were in the moderate or low range when it came to "social" hostilities. Nigeria, Bangladesh and India were high in "social" hostilities but moderate in terms of "government" actions.
Restrictions on religion across the world increased between mid-2009 and mid-2010, according to a 2012 study by the Pew Research Center. Restrictions in each of the five major regions of the world increased—including in the Americas and sub-Saharan Africa, the two regions where overall restrictions previously had been declining. In 2010, Egypt, Nigeria, the Palestinian territories, Russia, and Yemen were added to the "very high" category of social hostilities. The five highest social hostility scores were for Pakistan, India, Sri Lanka, Iraq, and Bangladesh. In 2015, Pew published that social hostilities declined in 2013, but the harassment of Jews increased.

</doc>
<doc id="46007" url="https://en.wikipedia.org/wiki?curid=46007" title="Moldavia">
Moldavia

Moldavia ( ) is a historical region, and former principality in Eastern Europe, corresponding to the territory between the Eastern Carpathians and the Dniester river. An initially independent and later autonomous state, it existed from the 14th century to 1859, when it united with Wallachia as the basis of the modern Romanian state; at various times, the state included the regions of Bessarabia (with the Budjak) and all of Bukovina. The western half of Moldavia is now part of Romania, the eastern side belongs to the Republic of Moldova, while the northern and southeastern parts are territories of Ukraine.
Name and etymology.
The original and short-lived reference to the region was "Bogdania", after Bogdan I, the founding figure of the principality. The names "Moldavia" and "Moldova" are derived from the name of the Moldova River; however, the etymology is not known and there are several variants:
In several early references, "Moldavia" is rendered under the composite form "Moldo-Wallachia" (in the same way Wallachia may appear as "Hungro-Wallachia"). Ottoman Turkish references to Moldavia included "Boğdan Iflak" (meaning "Bogdan's Wallachia") and "Boğdan" (and occasionally "Kara-Boğdan" - "Black Bogdania"). See also names in other languages.
The name of the region in other languages include , , , , , .
History.
Early Middle Ages.
The inhabitants of Moldova were Christians. Archaeological works revealed the remains of a Christian necropolis at Mihălășeni, Botoșani county, from the Vth century.The place of worship, and the tombs had Christian characteristics. The place of worship had a rectangular form with sides of 8 and 7 meters. Similar necropolis and place of worship were found at Nicolina, in Iași
The Bolohoveni, a Vlach population, is mentioned by the Hypatian Chronicle in the 13th century. The chronicle shows that this land is bordered on the principalities of Halych, Volhynia and Kiev. Archaeological research also identified the location of 13th-century fortified settlements in this region. Alexandru V. Boldur identified Voscodavie, Voscodavti, Voloscovti, Volcovti, Volosovca and their other towns and villages between the middle course of the rivers Nistru/Dniester and Nipru/Dnieper. The Bolohoveni disappeared from chronicles after their defeat in 1257 by Daniil Romanovich's troops.
In the early 13th century, the "Brodniks", a possible Slavic–Vlach vassal state of Halych, were present, alongside the Vlachs, in much of the region's territory (towards 1216, the Brodniks are mentioned as in service of Suzdal).
On the border between Halych and the Brodniks, in the 11th century, a Viking by the name of "Rodfos" was killed in the area by Vlachs who supposedly betrayed him.[http://www.vikingart.com/VArt/PS_Sjonhem.htm] In 1164, the future Byzantine Emperor Andronikos I Komnenos, was taken prisoner by Vlach shepherds around the same region.
High Middle Ages.
Later in the 14th century, King Charles I of Hungary attempted to expand his realm and the influence of the Catholic Church eastwards after the fall of Cuman rule, and ordered a campaign under the command of Phynta de Mende (1324). In 1342 and 1345, the Hungarians were victorious in a battle against Tatar-Mongols; the conflict was resolved by the death of Jani Beg, in 1357. The Polish chronicler Jan Długosz mentioned Moldavians (under the name "Wallachians") as having joined a military expedition in 1342, under King Władysław I, against the Margraviate of Brandenburg.
In 1353, Dragoș, mentioned as a Vlach "Knyaz" in Maramureș, was sent by Louis I to establish a line of defense against the Golden Horde forces of Mongols on the Siret River. This expedition resulted in a polity vassal to Hungary, centered around Baia ("Târgul Moldovei" or "Moldvabánya").
Bogdan of Cuhea, another Vlach voivode from Maramureş who had fallen out with the Hungarian king, crossed the Carpathians in 1359, took control of Moldavia, and succeeded in removing Moldavia from Hungarian control. His realm extended north to the Cheremosh River, while the southern part of Moldavia was still occupied by the Tatar Mongols.
After first residing in Baia, Bogdan moved Moldavia's seat to Siret (it was to remain there until Petru Muşat moved it to Suceava; it was finally moved to Iași under Alexandru Lăpușneanu - in 1565). The area around Suceava, roughly correspondent to future Bukovina, formed one of the two administrative divisions of the new realm, under the name "Ţara de Sus" (the "Upper Land"), whereas the rest, on both sides of the Prut river, formed "Ţara de Jos" (the "Lower Land").
Disfavored by the brief union of Angevin Poland and Hungary (the latter was still the country's overlord), Bogdan's successor Lațcu accepted conversion to Roman Catholicism around 1370, but his gesture was to remain without consequences. Despite remaining officially Eastern Orthodox and culturally connected with the Byzantine Empire after 1382, princes of the House of Bogdan-Mușat entered a conflict with the Constantinople Patriarchy over control of appointments to the newly founded Moldavian Metropolitan seat; Patriarch Antony IV even cast an anathema over Moldavia after Roman I expelled his appointee back to Byzantium. The crisis was finally settled in favor of the Moldavian princes under Alexander I. Nevertheless, religious policy remained complex: while conversions to faiths other than Orthodox were discouraged (and forbidden for princes), Moldavia included sizable Roman Catholic communities (Germans and Magyars), as well as non-Chalcedonic Armenians; after 1460, the country welcomed Hussite refugees (founders of Ciuburciu and, probably, Huși).
The principality of Moldavia covered the entire geographic region of Moldavia. In various periods, various other territories were politically connected with the Moldavian principality. This is the case of the province of Pokuttya, the fiefdoms of Cetatea de Baltă and Ciceu (both in Transylvania) or, at a later date, the territories between the Dniester and the Bug rivers.
Petru I profited from the end of the Hungarian-Polish union and moved the country closer to the Jagiellon realm, becoming a vassal of Władysław II on September 26, 1387. This gesture was to have unexpected consequences: Petru supplied the Polish ruler with funds needed in the war against the Teutonic Knights, and was granted control over Pokuttya until the debt was to be repaid; as this is not recorded to have been carried out, the region became disputed by the two states, until it was lost by Moldavia in the Battle of Obertyn (1531). Prince Petru also expanded his rule southwards to the Danube Delta and established a frontier with Wallachia; his brother Roman I conquered the Hungarian-ruled Cetatea Albă in 1392, giving Moldavia an outlet to the Black Sea, before being toppled from the throne for supporting Fyodor Koriatovych in his conflict with Vytautas the Great of Lithuania. Under Stephen I, growing Polish influence was challenged by Sigismund of Hungary, whose expedition was defeated at Ghindăoani in 1385; however, Stephen disappeared in mysterious circumstances, and the throne was soon occupied by Iuga Ologul (Vytautas' favorite).
Although Alexander I was brought to the throne in 1400 by the Hungarians (with assistance from Mircea I of Wallachia), he shifted his allegiances towards Poland (notably engaging Moldavian forces on the Polish side in the Battle of Grunwald and the Siege of Marienburg), and placed his own choice of rulers in Wallachia. His reign was one of the most successful in Moldavia's history, but also saw the very first confrontation with the Ottoman Turks at Cetatea Albă in 1420, and later even a conflict with the Poles. A deep crisis was to follow Alexandru's long reign, with his successors battling each other in a succession of wars that divided the country until the murder of Bogdan II and the ascension of Peter III Aaron in 1451. Nevertheless, Moldavia was subject to further Hungarian interventions after that moment, as Matthias Corvinus deposed Aron and backed Alexăndrel to the throne in Suceava. Petru Aron's rule also signified the beginning of Moldavia's Ottoman Empire allegiance, as the ruler agreed to pay tribute to Sultan Mehmed II.
Late Middle Ages.
Under Stephen the Great, who took the throne and subsequently came to an agreement with Kazimierz IV of Poland in 1457, the state reached its most glorious period. Stephen blocked Hungarian interventions in the Battle of Baia, invaded Wallachia in 1471, and dealt with Ottoman reprisals in a major victory (the 1475 Battle of Vaslui); after feeling threatened by Polish ambitions, he also attacked Galicia and resisted Polish reprisals in the Battle of the Cosmin Forest (1497). However, he had to surrender Chilia (Kiliya) and Cetatea Albă (Bilhorod-Dnistrovskyi), the two main fortresses in the Budjak, to the Ottomans in 1484, and in 1498 he had to accept Ottoman suzerainty, when he was forced to agree to continue paying tribute to Sultan Bayezid II. Following the taking of Hotin (Khotyn) and Pokuttya, Stephen's rule also brought a brief extension of Moldavian rule into Transylvania: Cetatea de Baltă and Ciceu became his fiefs in 1489.
Early Modern Era and Renaissance.
Under Bogdan III the One-Eyed, Ottoman overlordship was confirmed in the shape that would rapidly evolve into control over Moldavia's affairs. Peter IV Rareș, who reigned in the 1530s and 1540s, clashed with the Habsburg Monarchy over his ambitions in Transylvania (losing possessions in the region to George Martinuzzi), was defeated in Pokuttya by Poland, and failed in his attempt to extricate Moldavia from Ottoman rule – the country lost Bender to the Ottomans, who included it in their Silistra Eyalet.
A period of profound crisis followed. Moldavia stopped issuing its own coinage circa 1520, under Prince Ştefăniţă, when it was confronted with rapid depletion of funds and rising demands from the Porte. Such problems became endemic when the country, brought into the Great Turkish War, suffered the impact of the stagnation of the Ottoman Empire; at one point, during the 1650s and 1660s, princes began relying on counterfeit coinage (usually copies of Swedish riksdalers, as was that issued by Eustratie Dabija). The economic decline was accompanied by a failure to maintain state structures: the feudal-based Moldavian military forces were no longer convoked, and the few troops maintained by the rulers remained professional mercenaries such as the "seimeni".
However, Moldavia and the similarly affected Wallachia remained both important sources of income for the Ottoman Empire and relatively prosperous agricultural economies (especially as suppliers of grain and cattle – the latter was especially relevant in Moldavia, which remained an under-populated country of pastures). In time, much of the resources were tied to the Ottoman economy, either through monopolies on trade which were only lifted in 1829, after the Treaty of Adrianople (which did not affect all domains directly), or through the raise in direct taxes - the one demanded by the Ottomans from the princes, as well as the ones demanded by the princes from the country's population. Taxes were directly proportional with Ottoman requests, but also with the growing importance of Ottoman appointment and sanctioning of princes in front of election by the boyars and the boyar Council – "Sfatul boieresc" (drawing in a competition among pretenders, which also implied the intervention of creditors as suppliers of bribes). The fiscal system soon included taxes such as the "văcărit" (a tax on head of cattle), first introduced by Iancu Sasul in the 1580s.
The economic opportunities offered brought about a significant influx of Greek and Levantine financiers and officials, who entered a stiff competition with the high boyars over appointments to the Court. As the manor system suffered the blows of economic crises, and in the absence of salarisation (which implied that persons in office could decide their own income), obtaining princely appointment became the major focus of a boyar's career. Such changes also implied the decline of free peasantry and the rise of serfdom, as well as the rapid fall in the importance of low boyars (a traditional institution, the latter soon became marginal, and, in more successful instances, added to the population of towns); however, they also implied a rapid transition towards a monetary economy, based on exchanges in foreign currency. Serfdom was doubled by the much less numerous slave population ("robi"), composed of migrant Roma and captured Nogais.
The conflict between princes and boyars was to become exceptionally violent – the latter group, who frequently appealed to the Ottoman court in order to have princes comply with its demands, was persecuted by rulers such as Alexandru Lăpușneanu and John III. Ioan Vodă's revolt against the Ottomans ended in his execution (1574). The country descended into political chaos, with frequent Ottoman and Tatar incursions and pillages. The claims of Muşatins to the crown and the traditional system of succession were ended by scores of illegitimate reigns; one of the usurpers, Ioan Iacob Heraclid, was a Protestant Greek who encouraged the Renaissance and attempted to introduce Lutheranism to Moldavia.
In 1595, the rise of the Movileşti boyars to the throne with Ieremia Movilă coincided with the start of frequent anti-Ottoman and anti-Habsburg military expeditions of the Polish–Lithuanian Commonwealth into Moldavian territory (see "Moldavian Magnate Wars"), and rivalries between pretenders to the Moldavian throne encouraged by the three competing powers.
The Wallachian prince Michael the Brave, after previously taking over Transylvania, also deposed Prince Ieremia Movilă, in 1600, and managed to become the first Prince to rule over Moldavia, Wallachia, and Transylvania; the episode ended in Polish conquests of lands down to Bucharest, soon ended by the outbreak of the Polish–Swedish War and the reestablishment of Ottoman rule. Polish incursions were dealt a blow by the Ottomans during the 1620 Battle of Cecora, which also saw an end to the reign of Gaspar Graziani.
The following period of relative peace saw the more prosperous and prestigious rule of Vasile Lupu, who took the throne as a boyar appointee in 1637, and began battling his rival Gheorghe Ştefan, as well as the Wallachian prince Matei Basarab – however, his invasion of Wallachia with the backing of Cossack Hetman Bohdan Khmelnytsky ended in disaster at the Battle of Finta (1653). A few years later, Moldavia was occupied for two short intervals by the anti-Ottoman Wallachian prince Constantin Șerban, who clashed with the first ruler of the Ghica family, George Ghica. In the early 1680s, Moldavian troops under George Ducas intervened in right-bank Ukraine and assisted Mehmed IV in the Battle of Vienna, only to suffer the effects of the Great Turkish War.
Phanariots (1711–1822).
During the late 17th century, Moldavia became the target of the Russian Empire's southwards expansion, inaugurated by Peter the Great during the Russo-Turkish War of 1710-1711; Prince Dimitrie Cantemir's siding with Peter and open anti-Ottoman rebellion, ended in defeat at Stănileşti, provoked Sultan Ahmed III's reaction, and the official discarding of recognition of local choices for princes, imposing instead a system which relied solely on Ottoman approval – the Phanariote epoch, inaugurated by the reign of Nicholas Mavrocordatos.
Short and frequently ended through violence, Phanariote rules were usually marked by political corruption, intrigue, and high taxation, as well as by sporadic incursions of Habsburg and Russian armies deep into Moldavian territory; nonetheless, they also saw attempts at legislative and administrative modernization inspired by The Enlightenment (such as Constantine Mavrocordatos' decision to salarize public offices, to the outrage of boyars, and the abolition of serfdom in 1749, as well as Scarlat Callimachi's "Code"), and signified a decrease in Ottoman demands after the threat of Russian annexation became real and the prospects of a better life led to waves of peasant emigration to neighboring lands. The effects of Ottoman control were also made less notable after the 1774 Treaty of Küçük Kaynarca allowed Russia to intervene in favour of Ottoman subjects of the Eastern Orthodox faith - leading to campaigns of petitioning by the Moldavian boyars against princely policies.
In 1712, Hotin was taken over by the Ottomans, and became part of a defensive system that Moldavian princes were required to maintain, as well as an area for Islamic colonization (the Laz community). 
Fragmentation.
In 1775, Moldavia lost to the Habsburg Empire its northwestern part, which became known as Bukovina. For Moldavia, it meant both an important territorial loss and a major blow to the cattle trade (as the region stood on the trade route to Central Europe).
The 1792 Treaty of Jassy forced the Ottoman Empire to cede all of its holdings in what is now Transnistria to Russian Empire, which made Russian presence much more notable, given that the Empire acquired a common border with Moldavia. The first effect of this was the cession of the eastern half of Moldavia (renamed as Bessarabia) to the Russian Empire, in 1812.
Organic Statute, 1848 revolution.
Phanariote rules were officially ended after the 1821 occupation of the country by Alexander Ypsilantis's Filiki Eteria during the Greek War of Independence; the subsequent Ottoman retaliation brought the rule of Ioan Sturdza, considered as the first one of a new system – especially since, in 1826, the Ottomans and Russia agreed to allow for the election by locals of rulers over the two Danubian Principalities, and convened on their mandating for seven-year terms. In practice, a new fundament to reigns in Moldavia was created by the Russo-Turkish War (1828–1829), and a period of Russian domination over the two countries which ended only in 1856: begun as a military occupation under the command of Pavel Kiselyov, Russian domination gave Wallachia and Moldavia, which were not removed from nominal Ottoman control, the modernizing "Organic Statute" (the first document resembling a constitution, as well as the first one to regard both principalities). After 1829, the country also became an important destination for immigration of Ashkenazi Jews from the Kingdom of Galicia and Lodomeria and areas of Russia ("see History of the Jews in Romania and Sudiţi").
The first Moldavian rule established under the Statute, that of Mihail Sturdza, was nonetheless ambivalent: eager to reduce abuse of office, Sturdza introduced reforms (the abolition of slavery, secularization, economic rebuilding), but he was widely seen as enforcing his own power over that of the newly instituted consultative Assembly. A supporter of the union of his country with Wallachia and of Romanian Romantic nationalism, he obtained the establishment of a customs union between the two countries (1847) and showed support for radical projects favored by low boyars; nevertheless, he clamped down with noted violence the Moldavian revolutionary attempt in the last days of March 1848. Grigore Alexandru Ghica allowed the exiled revolutionaries to return to Moldavia c. 1853, which led to the creation of the National Party (), a trans-boundary group of radical union supporters which campaigned for a single state under a foreign dynasty.
Slavery.
Slavery () was part of the social order from before the founding of the Principality of Moldavia, until it was abolished in stages during the 1840s and 1850s. Most of the slaves were of Roma (Gypsy) ethnicity. There were also slaves of Tatar ethnicity, probably prisoners captured from the wars with the Nogai and Crimean Tatars. The institution of slavery was first attested in a 1470 Moldavian document, through which Prince Stephen the Great frees Oană, a Tatar slave who had fled to Jagiellon Poland.
The exact origins of slavery are not known, as it was a common practice in medieval Europe. As in the Byzantine Empire, the Roma were held as slaves of the state, of the boyars or of the monasteries. Historian Nicolae Iorga associated the Roma people's arrival with the 1241 Mongol invasion of Europe and considered their slavery as a vestige of that era; he believed that the Romanians took the Roma as slaves from the Mongols and preserved their status to control their labor. Other historians consider that the Roma were enslaved while captured during the battles with the Tatars. The practice of enslaving prisoners may also have been taken from the Mongols. The ethnic identity of the "Tatar slaves" is unknown, they could have been captured Tatars of the Golden Horde, Cumans, or the slaves of Tatars and Cumans. While it is possible that some Romani people were slaves or auxiliary troops of the Mongols or Tatars, most of them came from south of the Danube, demonstrating that slavery a widespread practice. The Tatar slaves, smaller in numbers, were eventually merged into the Roma population.
Traditionally, Roma slaves were divided into three categories. The smallest was owned by the "hospodars", and went by the Romanian-language name of "ţigani domneşti" ("Gypsies belonging to the lord"). The two other categories comprised "ţigani mănăstireşti" ("Gypsies belonging to the monasteries"), who were the property of Romanian Orthodox and Greek Orthodox monasteries, and "ţigani boiereşti" ("Gypsies belonging to the boyars"), who were enslaved by the category of landowners.
The abolition of slavery was carried out following a campaign by young revolutionaries who embraced the liberal ideas of the Enlightenment. In 1844, Moldavian Prince Mihail Sturdza proposed a law on the freeing of slaves owned by the church and state. By the 1850s, the movement gained support from almost the whole of Romanian society. In December 1855, following a proposal by Prince Grigore Alexandru Ghica, a bill drafted by Mihail Kogălniceanu and Petre Mavrogheni was adopted by the Divan; the law emancipated all slaves to the status of taxpayers (citizens).
Support for the abolitionists was reflected in Romanian literature of the mid-19h century. The issue of the Roma slavery became a theme in the literary works of various liberal and Romantic intellectuals, many of whom were active in the abolitionist camp. The Romanian abolitionist movement was also influenced by the much larger movement against Black slavery in the United States through press reports and through a translation of Harriet Beecher Stowe's "Uncle Tom's Cabin". Translated by Theodor Codrescu and first published in Iași in 1853, under the name "Coliba lui Moşu Toma sau Viaţa negrilor în sudul Statelor Unite din America" (which translates back as "Uncle Toma's Cabin or the Life of Blacks in the Southern United States of America"), it was the first American novel to be published in Romanian. The foreword included a study on slavery by Mihail Kogălniceanu.
Union with Wallachia.
Russian domination ended abruptly after the Crimean War, when the Treaty of Paris passed the two principalities under the tutelage of Great European Powers (together with Russia and the Ottoman overlord, power-sharing included the United Kingdom of Great Britain and Ireland, the Austrian Empire, the French Empire, the Kingdom of Piedmont-Sardinia, and Prussia). Due to Austrian and Ottoman opposition and British reserves, the union program as demanded by radical campaigners was debated intensely. In September 1857, given that "Caimacam" Nicolae Vogoride had perpetrated fraud in elections in Moldavia in July, the Powers allowed the two states to convene ad-hoc divans, which were to decide a new constitutional framework; the result showed overwhelming support for the union, as the creation of a liberal and neutral state. After further meetings among leaders of tutor states, an agreement was reached (the "Paris Convention"), whereby a limited union was to be enforced – separate governments and thrones, with only two bodies (a Court of Cassation and a Central Commission residing in Focșani); it also stipulated that an end to all privilege was to be passed into law, and awarded back to Moldavia the areas around Bolhrad, Cahul, and Izmail.
However, the Convention failed to note whether the two thrones could not be occupied by the same person, allowing "Partida Naţională" to introduce the candidacy of Alexandru Ioan Cuza in both countries. On January 17 (January 5, 1859 Old Style), in Iași, he was elected prince of Moldavia by the respective electoral body. After street pressure over the much more conservative body in Bucharest, Cuza was elected in Wallachia as well (February 5/January 24). Exactly three years later, after diplomatic missions that helped remove opposition to the action, the formal union created the United Principalities (the basis of modern Romania) and instituted Cuza as "Domnitor" (all legal matters were clarified after the replacement of the prince with Carol of Hohenzollern-Sigmaringen in April 1866, and the creation of an independent Kingdom of Romania in 1881) - this officially ending the existence of the Principality of Moldavia.
Military forces.
Under the reign of Stephen the Great, all farmers and villagers had to bear arms. Stephen justified this by saying that "every man has a duty to defend his fatherland"; according to Polish chronicler Jan Długosz, if someone was found without carrying a weapon, he was sentenced to death. Stephen reformed the army by promoting men from the landed free peasantry "răzeşi" (i.e. something akin to freeholding yeomen) to infantry ("voinici") and light cavalry ("hânsari") — to make himself less dependent on the boyars — and introduced his army to guns. In times of crises, The Small Host ("Oastea Mică") — which consisted of around 10,000 to 12,000 men — stood ready to engage the enemy, while the Large Host ("Oastea Mare") — which could reach up to 40,000 — had all the free peasantry older than 14, and strong enough to carry a sword or use the bow, recruited. This seldom happened, for such a levée en masse was devastating for both economy and population growth. In the Battle of Vaslui, Stephen had to summon the Large Host and also recruited mercenary troops.
In the Middle Ages and early Renaissance, the Moldavians relied on light cavalry ("călărași") which used hit-and-run tactics similar to those of the Tatars; this gave them great mobility and also flexibility, in case they found it more suitable to dismount their horses and fight in hand-to-hand combat, as it happened in 1422, when 400 horse archers were sent to aid Jagiellon Poland, Moldavia’s overlord against the Teutonic Knights. When making eye-contact with the enemy, the horse archers would withdraw to a nearby forest and camouflage themselves with leaves and branches; according to Jan Długosz, when the enemy entered the wood, they were "showered with arrows" and defeated. The heavy cavalry consisted of the nobility, namely, the boyars and their guards, the "viteji" (lit. "brave ones", small nobility) and the "curteni" — the Court Cavalry (all nominally part of the "Small Host"). In times of war, boyars were compelled by the feudal system of allegiance to supply the prince with troops in accordance with the extent of their manorial domain.
Other troops consisted of professional foot soldiers ("lefegii") which fulfilled the heavy infantry role, and the "plăieşi", free peasants whose role was that of border guards: they guarded the mountain passes and were prepared to ambush the enemy and to fight delaying actions.
In the absence of the prince, command was assigned to the "Mare Spătar" (Grand Sword-Bearer - a military office) or to the "Mare Vornic" (approx. Governor of the Country; a civilian office second only to the "Voievod", which was filled by the prince himself). Supplying the troops was by tradition-later-made-into-law the duty of the inhabitants of those lands on which the soldiers were present at a given time.
The Moldavians' (as well as Wallachians') favourite military doctrine in (defensive) wars was a scorched earth policy combined with harassment of the advancing enemy using hit-and-run tactics and disruption of communication and supply lines, followed by a large scale ambush: a weakened enemy would be lured in a place where it would find itself in a position hard or impossible to defend. A general attack would follow, often with devastating results. The shattered remains of what was once the enemy army would be pursued closely and harassed all the way to the border and sometimes beyond. A typical example of successful employments of this scenario is the Battle of Vaslui.
Towards the end of the 15th century, especially after the success of guns and cannons, mercenaries became a dominant force in the country’s military. With the economic demands created by the stagnation of the Ottoman Empire, the force diminished and included only mercenaries such as the "seimeni".
The 1829 Treaty of Adrianople allowed Moldavia to again maintain its own troops, no longer acting as an auxiliary under strict Ottoman supervision, and assigned red over blue pennants ("see Flag and coat of arms of Moldavia"). Their renewed existence under Mihail Sturdza was a major symbol and rally point for the nationalist cause, aiding in bringing about the 1848 Moldavian revolution.
Fleet.
An early mention of a Moldavian naval fleet is found in connection with the rule of Aron Tiranul, who used it to help Wallachian ruler Michael the Brave establish his control over the Chilia branch of the Danube and Dobruja.
The Treaty of Adrianople provided for a Moldavian self-defense naval force, to be composed of caicque vessels. Schooners armed with cannons were first built in the 1840s. Along with patrolling the Danube, these made their way on its tributaries, the Siret and the Prut River.
Geography.
Geographically, Moldavia is limited by the Carpathian Mountains to the West, the Cheremosh River to the North, the Dniester River to the East and the Danube and Black Sea to the South. The Prut River flows approximately through its middle from north to south.
Of late 15th century Moldavia, with an area of approximately , the biggest part and the core of the former principality is located in Romania (47.5%), followed by the Republic of Moldova (30.5%) and Ukraine (22%). This represents 88% of the Republic of Moldova's surface, 19.5% of Romania's surface, and 3.5% of Ukraine's surface.
The region is mostly hilly, with a range of mountains in the west, and plain areas in the southeast. Moldavia's highest altitude is Ineu peak (2,279m), which is also the westernmost point of the region.
Population.
Historical population.
Contemporary historians estimate the populatian of the Moldavian Principality in the 15th century, at between 250,000 - 600,000 people, but an extensive catagraphy was first conducted in 1769-1774. In 1848, the northwestern part, annexed in 1775 by the Habsburg Empire, Bukovina, had a population of 377,571; in 1856, the eastern half of Moldavia, Bessarabia, annexed in 1812 by the Russian Empire, had a population of 990,274, while the population of Moldavia proper (the western half), in 1859, was 1,463,927.
Cities.
The largest cities (as per last censuses) in the Moldavia region are:
Education.
In 1562, the so-called Schola Latina (a Latin Academic College) was founded in Cotnari, near Iași, a school which marked the beginnings of the organized humanistic education institutions in Moldavia.
The first institute of higher learning that functioned on the territory of Romania was Academia Vasiliană (1640), founded by Prince Vasile Lupu as a "Higher School for Latin and Slavonic Languages", followed by the Princely Academy, in 1707. The first high education structure in Romanian language was established in the autumn of 1813, when Gheorghe Asachi laid the foundations of a class of engineers, its activities taking place within the Greek Princely Academy.
After 1813, other moments marked the development of higher education in Romanian language, regarding both humanities and the technical science. Academia Mihăileană, founded in 1835 by Prince Mihail Sturdza, is considered the first Romanian superior institute. In 1860, three faculties part of the Academia Mihăileană formed the nucleus for the newly established University of Iași, the first Romanian modern university.

</doc>
