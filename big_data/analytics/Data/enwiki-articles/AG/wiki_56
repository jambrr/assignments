<doc id="44093" url="https://en.wikipedia.org/wiki?curid=44093" title="Electroconvulsive therapy">
Electroconvulsive therapy

Electroconvulsive therapy (ECT), formerly known as electroshock therapy and often referred to as shock treatment, is a psychiatric treatment in which seizures are electrically induced in patients to provide relief from psychiatric illnesses. The ECT procedure was first conducted in 1938 and is the only currently used form of shock therapy in psychiatry. ECT is often used with informed consent as a last line of intervention for major depressive disorder, mania and catatonia. ECT machines have been placed in the Class III category (high risk) by the FDA since 1976.
A round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Follow-up treatment is still poorly studied, but about half of people who respond relapse within 12 months. Aside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia. Immediately following treatment, the most common adverse effects are confusion and memory loss. ECT is considered one of the least harmful treatment options available for severely depressed pregnant women.
A usual course of ECT involves multiple administrations, typically given two or three times per week until the patient is no longer suffering symptoms. ECT is administered under anesthetic with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. Placement can be bilateral, in which the electric current is passed across the whole brain, or unilateral, in which the current is passed across one hemisphere of the brain. Bilateral placement seems to have greater efficacy than unilateral, but also carries greater risk of memory loss. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT. 
ECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.
Medical use.
ECT is used with informed consent in treatment-resistant major depressive disorder, treatment-resistant catatonia, or prolonged or severe mania, and in conditions where "there is a need for rapid, definitive response because of the severity of a psychiatric or medical condition (e.g., when illness is characterized by stupor, marked psychomotor retardation, depressive delusions or hallucinations, or life–threatening physical exhaustion associated with mania)."
Major depressive disorder.
For major depressive disorder, ECT is generally used only when other treatments have failed, or in emergencies, such as imminent suicide. ECT has also been used in selected cases of depression occurring in the setting of multiple sclerosis, Parkinson's disease, Huntington's chorea, developmental delay, brain arteriovenous malformations and hydrocephalus.
Efficacy.
A meta-analysis on the effectiveness of ECT in unipolar and bipolar depression was conducted in 2012. Results indicated that although patients with unipolar depression and bipolar depression responded to other medical treatments very differently, both groups responded equally well to ECT. Overall remission rate for patients given a round of ECT treatment was 51.5% for those with unipolar depression and 50.9% for those with bipolar depression. The severity of each patient’s depression was assessed at the same baseline in each group.
There is little agreement on the most appropriate followup to ECT for people with major depressive disorder. When ECT is followed by treatment with antidepressants, about 50% of people relapsed by 12 months following successful initial treatment with ECT, with about 37% relapsing within the first 6 months. About twice as many relapsed with no antidepressants. Most of the evidence for continuation therapy is with tricyclics; evidence for relapse prevention with newer antidepressants is lacking.
In 2008, a meta-analytic review paper found in terms of efficacy, "a significant superiority of ECT in all comparisons: ECT versus simulated ECT, ECT versus placebo, ECT versus antidepressants in general, ECT versus TCAs and ECT versus MAOIs."
In 2003, The UK ECT Review group published a systematic review and meta-analysis comparing ECT to placebo and antidepressant drugs. This meta-analysis demonstrated a large effect size (high efficacy relative to the mean in terms of the standard deviation) for ECT versus placebo, and versus antidepressant drugs.
Compared with transcranial magnetic stimulation for people with treatment-resistant major depressive disorder, ECT relieves depression about twice as well, reducing the score on the Hamilton Rating Scale for Depression by about 15 points, while TMS reduced it by 9 points.
Catatonia.
ECT is generally a second-line treatment for people with catatonia who do not respond to other treatments, but is a first-line treatment for severe or life-threatening catatonia. There is a lack of clinical evidence for its efficacy but "the excellent efficacy of ECT in catatonia is generally acknowledged". For people with autism spectrum disorders who have catatonia, there is little published evidence about the efficacy of ECT; as of 2014 there were twelve case reports, and while ECT had "life saving" efficacy in some, results were mixed and temporary, and maintenance ECT was necessary to sustain any benefit.
Mania.
ECT is used to treat people who have severe or prolonged mania; NICE recommends it only in life-threatening situations or when other treatments have failed. and as a second-line treatment for bipolar mania.
Schizophrenia.
ECT is rarely used in treatment-resistant schizophrenia, but is sometimes recommended for schizophrenia when short term global improvement is desired, or the subject shows little response to antipsychotics alone. It is useful in the case of severe exacerbations of catatonic schizophrenia, whether excited or stuporous.
Adverse effects.
Aside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia; the U.S. Surgeon General's report says that there are "no absolute health contraindications" to its use. Immediately following treatment, the most common adverse effects are confusion and memory loss. It must be used very cautiously in people with epilepsy or other neurological disorders because by its nature it provokes small tonic-clonic seizures, and so would likely not be given to a person whose epilepsy is not well controlled. Some patients experience muscle soreness after ECT. This is due to the muscle relaxants given during the procedure and rarely due to muscle activity. ECT, especially if combined with deep sleep therapy, may lead to brain damage if administered in such a way as to lead to hypoxia or anoxia in the patient.
The death rate due to ECT is around 4 per 100,000 procedures. There is evidence and rationale to support giving low doses of benzodiazepines or else low doses of general anesthetics which induce sedation but not anesthesia to patients to reduce adverse effects of ECT.
While there are no absolute contraindications for ECT, there is increased risk for patients who have unstable or severe cardiovascular conditions or aneurysms; who have recently had a stroke; who have increased intracranial pressure (for instance, due to a solid brain tumor), or who have severe pulmonary conditions, or who are generally at high risk for receiving anesthesia.
In adolescents, ECT is highly efficient for several psychiatric disorders, with few and relatively benign adverse effects.
Effects on memory.
Retrograde amnesia occurs to some extent in almost all ECT recipients. The American Psychiatric Association report (2001) acknowledges: “In some patients the recovery from retrograde amnesia will be incomplete, and evidence has shown that ECT can result in persistent or permanent memory loss”. It is the purported effects of ECT on long-term memory that give rise to much of the concern surrounding its use.
However, the methods used to measure memory loss are generally poor, and their application to people with depression, who have cognitive deficits including problems with memory, have been problematic.
The acute effects of ECT can include amnesia, both retrograde (for events occurring before the treatment) and anterograde (for events occurring after the treatment). Memory loss and confusion are more pronounced with bilateral electrode placement rather than unilateral, and with outdated sine-wave rather than brief-pulse currents. The use of either constant or pulsing electrical impulses also varied the memory loss results in patients. Patients who received pulsing electrical impulses as opposed to a steady flow seemed to incur less memory loss. The vast majority of modern treatment uses brief pulse currents.
Retrograde amnesia is most marked for events occurring in the weeks or months before treatment, with one study showing that although some people lose memories from years prior to treatment, recovery of such memories was "virtually complete" by seven months post-treatment, with the only enduring loss being memories in the weeks and months prior to the treatment. Anterograde memory loss is usually limited to the time of treatment itself or shortly afterwards. In the weeks and months following ECT these memory problems gradually improve, but some people have persistent losses, especially with bilateral ECT. One published review summarizing the results of questionnaires about subjective memory loss found that between 29% and 55% of respondents believed they experienced long-lasting or permanent memory changes. In 2000, American psychiatrist Sarah Lisanby and colleagues found that bilateral ECT left patients with more persistently impaired memory of public events as compared to RUL ECT.
Effects on brain structure.
Considerable controversy exists over the effects of ECT on brain tissue, although a number of mental health associations — including the American Psychiatric Association — have concluded that there is no evidence that ECT causes structural brain damage. A 1999 report by the U.S. Surgeon General states, "The fears that ECT causes gross structural brain pathology have not been supported by decades of methodologically sound research in both humans and animals".
Many expert proponents of ECT maintain that the procedure is safe and does not cause brain damage. Dr. Charles Kellner, a prominent ECT researcher and former chief editor of the "Journal of ECT", stated in a 2007 interview that, "There are a number of well-designed studies that show ECT does not cause brain damage and numerous reports of patients who have received a large number of treatments over their lifetime and have suffered no significant problems due to ECT." Dr. Kellner cites a study purporting to show an absence of cognitive impairment in eight subjects after more than 100 lifetime ECT treatments. Dr. Kellner stated "Rather than cause brain damage, there is evidence that ECT may reverse some of the damaging effects of serious psychiatric illness."
Effects in pregnancy.
If steps are taken to decrease potential risks, ECT is generally accepted to be relatively safe during all trimesters of pregnancy, particularly when compared to pharmacological treatments. Suggested preparation for ECT during pregnancy includes a pelvic examination, discontinuation of nonessential anticholinergic medication, uterine tocodynamometry, intravenous hydration, and administration of a nonparticulate antacid. During ECT, elevation of the pregnant woman's right hip, external fetal cardiac monitoring, intubation, and avoidance of excessive hyperventilation are recommended.
Technique.
ECT requires the informed consent of the patient.
Whether psychiatric medications are terminated prior to treatment or maintained, varies. However, drugs that are known to cause toxicity in combination with ECT, such as lithium, are discontinued, and benzodiazepines, which increase seizure thresholds, are either discontinued, a benzodiazepine antagonist is administered at each ECT session, or the ECT treatment is adjusted accordingly.
The placement of electrodes, as well as the dose and duration of the stimulation is determined on a per-patient basis.
In unilateral ECT, both electrodes are placed on the same side of the patient's head. Unilateral ECT may be used first to minimize side effects (memory loss). When electrodes are placed on both sides of the head, this is known as bilateral ECT. In bifrontal ECT, an uncommon variation, the electrode position is somewhere between bilateral and unilateral. Unilateral is thought to cause fewer cognitive effects than bilateral but is considered less effective if the dose administered is close to the seizure threshold. In the USA most patients receive bilateral ECT. In the UK almost all patients receive bilateral ECT.
The electrodes deliver an electrical stimulus. The stimulus levels recommended for ECT are in excess of an individual's seizure threshold: about one and a half times seizure threshold for bilateral ECT and up to 12 times for unilateral ECT. Below these levels treatment may not be effective in spite of a seizure, while doses massively above threshold level, especially with bilateral ECT, expose patients to the risk of more severe cognitive impairment without additional therapeutic gains. Seizure threshold is determined by trial and error ("dose titration"). Some psychiatrists use dose titration, some still use "fixed dose" (that is, all patients are given the same dose) and others compromise by roughly estimating a patient's threshold according to age and sex. Older men tend to have higher thresholds than younger women, but it is not a hard and fast rule, and other factors, for example drugs, affect seizure threshold.
Immediately prior to treatment, a patient is given a short-acting anesthetic such as methohexital, etomidate, or thiopental, a muscle relaxant such as suxamethonium (succinylcholine), and occasionally atropine to inhibit salivation. In a minority of countries such as Japan, India, and Nigeria, ECT may be used without anesthesia. The Union Health Ministry of India recommended a ban on ECT without anesthesia in India's Mental Health Care Bill of 2010 and the Mental Health Care Bill of 2013. Some psychiatrists in India argued against the ban on unmodified ECT due to a lack of trained anesthesiologists available to administer ECT with anesthesia. The practice was abolished in Turkey's largest psychiatric hospital in 2008.
The patient's EEG, ECG, and blood oxygen levels are monitored during treatment.
ECT is usually administered three times a week, on alternate days, over a course of two to four weeks.
Devices.
Most modern ECT devices deliver a brief-pulse current, which is thought to cause fewer cognitive effects than the sine-wave currents which were originally used in ECT. A small minority of psychiatrists in the USA still use sine-wave stimuli. Sine-wave is no longer used in the UK or Ireland.
Typically, the electrical stimulus used in ECT is about 800 milliamps and has up to several hundred watts, and the current flows for between one and 6 seconds.
In the USA, ECT devices are manufactured by two companies, Somatics, which is owned by psychiatrists Richard Abrams and Conrad Swartz, and Mecta. In the UK, the market for ECT devices was long monopolized by Ectron Ltd, which was set up by psychiatrist Robert Russell.
Mechanism of action.
Despite decades of research, the exact mechanism of action of ECT remains elusive. Neuroimaging studies in people who have had ECT, investigating differences between responders and nonresponders, and people who relapse, find that responders have anticonvulsant effects mostly in the frontal lobes, which corresponds to immediate responses, and neurotrophic effects primarily in the medial temporal lobe. The anticonvulsant effects are decreased blood flow and decreased metabolism, while the neurotrophic effects are opposite - increased perfusion and metabolism, as well as increased volume of the hippocampus.
Usage.
As of 2001, it was estimated that about one million people received ECT annually.
There is wide variation in ECT use between different countries, different hospitals, and different psychiatrists. International practice varies considerably from widespread use of the therapy in many western countries to a small minority of countries that do not use ECT at all, such as Slovenia.
About 70 percent of ECT patients are women. This may be due to the fact that women are more likely to be diagnosed with depression. Older and more affluent patients are also more likely to receive ECT. The use of ECT is not as common in ethnic minorities.
Sarah Hall reports, "ECT has been dogged by conflict between psychiatrists who swear by it, and some patients and families of patients who say that their lives have been ruined by it. It is controversial in some European countries such as the Netherlands and Italy, where its use is severely restricted".
United States.
ECT became popular in the United States in the 1940s. At this time psychiatric hospitals were overrun with patients whom doctors were desperate to treat and cure. The practices of ECT and lobotomies became popular because they held some promise of addressing the overpopulation problem. Whereas lobotomies would reduce a patient to a more manageable submissive state ECT helped to improve mood in those with severe depression. In the United States, a survey of psychiatric practice in the late 1980s found that an estimated 100,000 people received ECT annually, with wide variation between metropolitan statistical areas.
Accurate statistics about the frequency, context and circumstances of ECT in the United States are difficult to obtain because only a few states have reporting laws that require the treating facility to supply state authorities with this information. In 13 of the 50 states, the practice of ECT is regulated by law.
One state which does report such data is Texas, where in the mid-1990s ECT was used in about one third of psychiatric facilities and given to about 1,650 people annually.
Usage of ECT has since declined slightly; in 2000–01 ECT was given to about 1500 people aged from 16 to 97 (in Texas it is illegal to give ECT to anyone under sixteen). ECT is more commonly used in private psychiatric hospitals than in public hospitals, and minority patients are underrepresented in the ECT statistics.
In the United States, ECT is usually given three times a week; in the UK, it is usually given twice a week. Occasionally it is given on a daily basis. A course usually consists of 6–12 treatments, but may be more or fewer. Following a course of ECT some patients may be given continuation or maintenance ECT with further treatments at weekly, fortnightly or monthly intervals. A few psychiatrists in the USA use multiple-monitored ECT (MMECT) where patients receive more than one treatment per anesthetic. Electroconvulsive therapy is not a required subject in US medical schools and not a required skill in psychiatric residency training. Privileging for ECT practice at institutions is a local option: no national certification standards are established, and no ECT-specific continuing training experiences are required of ECT practitioners.
United Kingdom.
In the United Kingdom in 1980, an estimated 50,000 people received ECT annually, with use declining steadily since then to about 12,000 per annum in 2002. It is still used in nearly all psychiatric hospitals, with a survey of ECT use from 2002 finding that 71 percent of patients were women and 46 percent were over 65 years of age. Eighty-one percent had a diagnosis of mood disorder; schizophrenia was the next most common diagnosis. Sixteen percent were treated without their consent. In 2003, the National Institute for Health and Care Excellence, a government body which was set up to standardize treatment throughout the National Health Service in England and Wales, issued guidance on the use of ECT. Its use was recommended "only to achieve rapid and short-term improvement of severe symptoms after an adequate trial of treatment options has proven ineffective and/or when the condition is considered to be potentially life-threatening in individuals with severe depressive illness, catatonia or a prolonged manic episode".
The guidance received a mixed reception. It was welcomed by an editorial in the British Medical Journal but the Royal College of Psychiatrists launched an unsuccessful appeal. The NICE guidance, as the British Medical Journal editorial points out, is only a policy statement and psychiatrists may deviate from it if they see fit. Adherence to standards has not been universal in the past. A survey of ECT use in 1980 found that more than half of ECT clinics failed to meet minimum standards set by the Royal College of Psychiatrists, with a later survey in 1998 finding that minimum standards were largely adhered to, but that two-thirds of clinics still fell short of current guidelines, particularly in the training and supervision of junior doctors involved in the procedure. A voluntary accreditation scheme, ECTAS, was set up in 2004 by the Royal College, but as of 2006 only a minority of ECT clinics in England, Wales, Northern Ireland and the Republic of Ireland have signed up.
The Mental Health Act 2007 allows people to be treated against their will. This law has extra protections for electro convulsive therapy. A patient capable of making the decision can decline the treatment, and in that case treatment cannot be given unless it's an emergency situation and it will save that patient's life or is immediately necessary to prevent deterioration of the patient's condition. A patient may not be capable of making the decision (they "lack capacity"), and in that situation ECT can be given if it's appropriate and also if there are no advance directives that prevent the use of ECT.
China.
ECT was introduced in China in the early 1950s and while it was originally practiced without anesthesia, as of 2012 almost all procedures were conducted with it. As of 2012, there are approximately 400 ECT machines in China, and 150,000 ECT treatments are performed each year. Chinese national practice guidelines recommend ECT for the treatment of schizophrenia, depressive disorders, and bipolar disorder and in the Chinese literature, ECT is an effective treatment for schizophrenia and mood disorders.
History.
As early as the 16th century, agents to induce seizures were used to treat psychiatric conditions. In 1785, the therapeutic use of seizure induction was documented in the "London Medical Journal". As to its earliest antecedents one doctor claims 1744 as the dawn of electricity's therapeutic use, as documented in the first issue of "Electricity and Medicine". Treatment and cure of hysterical blindness was documented eleven years later. Benjamin Franklin wrote that an electrostatic machine cured "a woman of hysterical fits." G.B.C. Duchenne, the mid-19th century "Father of Electrotherapy," said its use was integral to a neurological practice.
In the second half of the 19th century, such efforts were frequent enough in British asylums as to make it notable.
Convulsive therapy was introduced in 1934 by Hungarian neuropsychiatrist Ladislas J. Meduna who, believing mistakenly that schizophrenia and epilepsy were antagonistic disorders, induced seizures first with camphor and then metrazol (cardiazol). Ladislas Meduna is thought to be the father of convulsive therapy. In 1937, the first international meeting on convulsive therapy was held in Switzerland by the Swiss psychiatrist Muller. The proceedings were published in the "American Journal of Psychiatry" and, within three years, cardiazol convulsive therapy was being used worldwide. Italian Professor of neuropsychiatry Ugo Cerletti, who had been using electric shocks to produce seizures in animal experiments, and his colleague Lucio Bini developed the idea of using electricity as a substitute for metrazol in convulsive therapy and, in 1938, experimented for the first time on a person. It was believed early on that inducing convulsions aided in helping those with severe schizophrenia but later found to be most useful with affective disorders such as depression. Cerletti had noted a shock to the head produced convulsions in dogs. The idea to use electroshock on humans came to Cerletti when he saw how pigs were given an electric shock before being butchered to put them in an anesthetized state. Cerletti and Bini practiced until they felt they had the right parameters needed to have a successful human trial. Once they started trials on patients they found that after 10-20 treatments the results were significant. Patients had much improved. A positive side effect to the treatment was retrograde amnesia. It was because of this side effect that patients could not remember the treatments and had no ill feelings toward it.
ECT soon replaced metrazol therapy all over the world because it was cheaper, less frightening and more convenient. Cerletti and Bini were nominated for a Nobel Prize but did not receive one. By 1940, the procedure was introduced to both England and the US. In Germany and Austria it was promoted by Friedrich Meggendorfer. Through the 1940s and 1950s, the use of ECT became widespread.
In the early 1940s, in an attempt to reduce the memory disturbance and confusion associated with treatment, two modifications were introduced: the use of unilateral electrode placement and the replacement of sinusoidal current with brief pulse. It took many years for brief-pulse equipment to be widely adopted. In the 1940s and early 1950s ECT was usually given in "unmodified" form, without muscle relaxants, and the seizure resulted in a full-scale convulsion. A rare but serious complication of unmodified ECT was fracture or dislocation of the long bones. In the 1940s psychiatrists began to experiment with curare, the muscle-paralysing South American poison, in order to modify the convulsions. The introduction of suxamethonium (succinylcholine), a safer synthetic alternative to curare, in 1951 led to the more widespread use of "modified" ECT. A short-acting anesthetic was usually given in addition to the muscle relaxant in order to spare patients the terrifying feeling of suffocation that can be experienced with muscle relaxants.
The steady growth of antidepressant use along with negative depictions of ECT in the mass media led to a marked decline in the use of ECT during the 1950s to the 1970s. The Surgeon General stated there were problems with electroshock therapy in the initial years before anesthesia was routinely given, and that "these now-antiquated practices contributed to the negative portrayal of ECT in the popular media." The New York Times described the public's negative perception of ECT as being caused mainly by one movie. "For Big Nurse in "One Flew Over the Cuckoo's Nest," it was a tool of terror, and, in the public mind, "shock therapy" has retained the tarnished image given it by Ken Kesey's novel: dangerous, inhumane and overused".
In 1976, Dr. Blatchley demonstrated the effectiveness of his constant current, brief pulse device ECT. This device eventually largely replaced earlier devices because of the reduction in cognitive side effects, although as of 2012 some ECT clinics still were using sine-wave devices. The 1970s saw the publication of the first American Psychiatric Association (APA) task force report on electroconvulsive therapy (to be followed by further reports in 1990 and 2001). The report endorsed the use of ECT in the treatment of depression. The decade also saw criticism of ECT. Specifically critics pointed to shortcomings such as noted side effects, the procedure being used as a form of abuse, and uneven application of ECT. The use of ECT declined until the 1980s, "when use began to increase amid growing awareness of its benefits and cost-effectiveness for treating severe depression". In 1985 the National Institute of Mental Health and National Institutes of Health convened a consensus development conference on ECT and concluded that, while ECT was the most controversial treatment in psychiatry and had significant side-effects, it had been shown to be effective for a narrow range of severe psychiatric disorders.
Because of the backlash noted previously, national institutions reviewed past practices and set new standards. In 1978, The American Psychiatric Association released its first task force report in which new standards for consent were introduced and the use of unilateral electrode placement was recommended. The 1985 NIMH Consensus Conference confirmed the therapeutic role of ECT in certain circumstances. The American Psychiatric Association released its second task force report in 1990 where specific details on the delivery, education, and training of ECT were documented. Finally in 2001 the American Psychiatric Association released its latest task force report. This report emphasizes the importance of informed consent, and the expanded role that the procedure has in modern medicine.
Society and culture.
Surveys of public opinion, the testimony of former patients, legal restrictions on its use and disputes as to the efficacy, ethics and adverse effects of ECT within the psychiatric and wider medical community indicate that the use of ECT remains controversial. This is reflected in the recent vote by the United States Food and Drug Administration's (FDA's) Neurological Devices Advisory Panel to recommend that FDA maintain ECT devices in the Class III device category for high risk devices except for patients suffering from catatonia. This may result in the manufacturers of such devices having to do controlled trials on their safety and efficacy for the first time. In justifying their position, panelists referred to the memory loss associated with ECT and the lack of long-term data.
Legal status.
Informed consent.
The World Health Organization (2005) advises that ECT should be used only with the informed consent of the patient (or their guardian if their incapacity to consent has been established).
In the US, this doctrine places a legal obligation on a doctor to make a patient aware of: the reason for treatment, the risks and benefits of a proposed treatment, the risks and benefits of alternative treatment, and the risks and benefits of receiving no treatment. The patient is then given the opportunity to accept or reject the treatment. The form states how many treatments are recommended and also makes the patient aware that consent may be revoked and treatment discontinued at any time during a course of ECT. The Surgeon General's Report on Mental Health states that patients should be warned that the benefits of ECT are short-lived without active continuation treatment in the form of drugs or further ECT, and that there may be some risk of permanent, severe memory loss after ECT. The report advises psychiatrists to involve patients in discussion, possibly with the aid of leaflets or videos, both before and during a course of ECT.
To demonstrate what he believes should be required to fully satisfy the legal obligation for informed consent, one psychiatrist, working for an anti-psychiatry organisation, has formulated his own consent form using the consent form developed and enacted by the Texas Legislature as a model.
According to the Surgeon General, involuntary treatment is uncommon in the United States and is typically used only in cases of great extremity, and only when all other treatment options have been exhausted. The use of ECT is believed to be a potentially life-saving treatment.
In one of the few jurisdictions where recent statistics on ECT usage are available, a national audit of ECT by the Scottish ECT Accreditation Network indicated that 77% of patients who received the treatment in 2008 were capable of giving informed consent.
In the UK, in order for consent to be valid it requires an explanation in "broad terms" of the nature of the procedure and its likely effects. One review from 2005 found that only about half of patients felt they were given sufficient information about ECT and its adverse effects and another survey found that about fifty percent of psychiatrists and nurses agreed with them.
A 2005 study published in the "British Journal of Psychiatry" described patients' perspectives on the adequacy of informed consent before ECT. The study found that, "About half (45–55%) of patients reported they were given an adequate explanation of ECT, implying a similar percentage felt they were not." The authors also stated:
Involuntary ECT.
Procedures for involuntary ECT vary from country to country depending on local mental health laws.
United States.
In the United States, ECT devices came into existence prior to medical devices being regulated by the Food and Drug Administration; when the law came into effect the FDA was obligated to retrospectively review already existing devices and classify them, and determine whether clinical trials were needed to prove efficacy and safety. While the FDA has classified the devices used to administer ECT as , as of 2011 the FDA had not yet determined whether the devices should be withdrawn from the market until clinical trials prove their safety and efficacy. The FDA considers ECT machinery to be experimental devices.
In most states in the USA, a judicial order following a formal hearing is needed before a patient can be forced to undergo involuntary ECT. However, ECT can also be involuntarily administered in situations with less immediate danger. Suicidal intent is a common justification for its involuntary use, especially when other treatments are ineffective.
United Kingdom.
Until 2009 in England and Wales, the Mental Health Act 1983 allowed the use of ECT on detained patients whether or not they had capacity to consent to it. However, following amendments which took effect in 2009, ECT may not generally be given to a patient who has capacity and refuses it, irrespective of his or her detention under the Act. In fact, even if a patient is deemed to lack capacity, if they made a valid advance decision refusing ECT then they should not be given it; and even if they do not have an advance decision, the psychiatrist must obtain an independent second opinion (which is also the case if the patient is under age of consent). However, there is an exception regardless of consent and capacity; under Section 62 of the Act, if the treating psychiatrist says the need for treatment is urgent they may start a course of ECT without authorization. From 2003 to 2005, about 2,000 people a year in England and Wales were treated without their consent under the Mental Health Act. Concerns have been raised by the official regulator that psychiatrists are too readily assuming that patients have the capacity to consent to their treatments, and that there is a worrying lack of independent advocacy. In Scotland the Mental Health (Care and Treatment) (Scotland) Act 2003 also gives patients with capacity the right to refuse ECT.
Public perception.
A questionnaire survey of 379 members of the general public in Australia indicated that more than 60% of respondents had some knowledge about the main aspects of ECT. Participants were generally opposed to the use of ECT on depressed individuals with psychosocial issues, on children, and on involuntary patients. Public perceptions of ECT were found to be mainly negative.
Famous cases.
Ernest Hemingway, American author, committed suicide shortly after ECT at the Mayo Clinic in 1961. He is reported to have said to his biographer, "Well, what is the sense of ruining my head and erasing my memory, which is my capital, and putting me out of business? It was a brilliant cure but we lost the patient..." American surgeon and award-winning author Sherwin B. Nuland is another notable person who has undergone ECT. In his 40s, this successful surgeon's depression became so severe that he had to be institutionalized. After exhausting all treatment options, a young resident assigned to his case suggested ECT, which ended up being successful.
Fictional examples.
Electroconvulsive therapy has been depicted in fiction, including fictional works partly based on true experiences. These include Sylvia Plath's autobiographical novel, "The Bell Jar", and Ken Kesey's novel "One Flew Over the Cuckoo's Nest"; Kesey's novel is a direct product of his time working the graveyard shift as an orderly at a mental health facility in Menlo Park, California.
In the 2000 film "Requiem for a Dream", Sarah Goldfarb receives "unmodified" Electroconvulsive Therapy after experiencing severe amphetamine psychosis following prolonged stimulant abuse. In the 2014 TV series "Constantine", the protagonist John Constantine is institutionalized and specifically requests Electroconvulsive therapy as an attempt to alleviate or resolve his mental problems.
Gender.
Throughout the history of ECT, women have received it two to three times as often as men, and continue to do so irrespective of diagnosis. A 1974 study of ECT in Massachusetts reported that women made up 69 per cent of those given ECT. The Ministry of Health in Canada reported that from 1999 until 2000 in Ontario, women were 71 per cent of those given ECT in provincial psychiatric institutions, and 75 per cent of the total ECT given was given to women.

</doc>
<doc id="44095" url="https://en.wikipedia.org/wiki?curid=44095" title="Sui generis">
Sui generis

Sui generis (; ) is a Latin phrase, meaning "of its (his, her, or their) own kind; in a class by itself; unique".
The term is widely used to refer to more esoteric entities in a number of disciplines, including
Philosophy.
The expression is often used in analytic philosophy to indicate an idea, an entity, or a reality which cannot be reduced to a lower concept or included in a higher concept.
Biology.
In the taxonomical structure "genus → species", a species is described as "sui generis" if its genus was created to classify it (i.e., its uniqueness at the time of classification merited the creation of a new genus, the sole member of which was initially the "sui generis" species). A species that is the sole "extant" member of its genus (e.g. the "Homo" genus) is not necessarily "sui generis": extinction may have eliminated other species of that genus.
Law.
In law, it is a term of art used to identify a legal classification that exists independently of other categorizations because of its singularity or due to the specific creation of an entitlement or obligation. For example, a court's contempt powers arise" sui generis" and not from statute or rule. The New York Court of Appeals has used the term in describing cooperative apartment corporations, mostly because this form of housing is considered real property for some purposes and personal property for other purposes.
When citing cases and other authorities, lawyers and judges may refer to "a "sui generis" case", or "a "sui generis" authority", meaning it is a special one confined to "its own" facts, and therefore may not be of broader application.
Statutory.
In statutory interpretation, it refers to the problem of giving meaning to groups of words where one of the words is ambiguous or inherently unclear.
For example, in Road Traffic law, a statute may require consideration of large vehicles separately from other vehicles. The word ""large"" is ambiguous per se, but may be considered to be ""heavy"". Thus the relevant legislation will (in Australian law) contain a section "Terms used" or "Definitions" which will itemise all words considered ambiguous, and confer very specific interpretations consistent with natural language. So in this list we find the entry ""heavy vehicle means a vehicle with a GVM of more than 4.5 t;"" and referring upwards we find ""GVM (which stands for “gross vehicle mass”), in relation to a vehicle, means the maximum loaded mass of the vehicle —"" with further expansions to cover various contingencies. Thus the term ""large"" is made equivalent to ""heavy"" and is (for this purpose) clearly defined, "sui generis".
Town planning.
In British town planning law, such as the Town and Country Planning (Use Classes) Order 1987, many common types of land use are classified in "use classes". Change of use of land "within" a use class does not require planning permission; however, changing "between" use classes might require planning permission, but not if the use class is "sui generis".
Examples of "sui generis" transference include embassies, theatres, amusement arcades, laundrettes, taxi or vehicle hire businesses, petrol filling stations, scrapyards, nightclubs, motor car showrooms, retail warehouses, clubs and hostels.
The grant of private hire vehicle (taxicab) operators licences by local authorities frequently has a condition attached that the appropriate "sui generis" change of use planning permission is granted to those premises to ensure those businesses cannot trade lawfully without the appropriate planning consents. 
Even qualified and experienced town planners misconceive that changing use from an existing use class to one which is "sui generis" always requires planning permission; it does not because the property is not transferred "between" two existing use classes. Permission is only required if the "sui generis" use is materially different from the existing one, such as from a petrol station where petrol tanks might have leaked. As in other applications of the phrase "sui generis", the decisions will be a unique matter of fact, degree, and professional opinion.
Aboriginal law and education.
The motto "Sui Generis" has been adopted by the Akitsiraq Law School because it is a "sui generis" (aboriginal) title in all of Canadian aboriginal law institutes by dint of its title being Inuktitut, the Aboriginal language of the Inuit in the far north of Canada. More importantly, in aboriginal professional legal education, the work of Aboriginal people to define and create contemporary aboriginal education is a "thing of its own kind" having "sui generis" admissions and "sui generis" curriculum.
Intellectual property law.
Generally speaking, protection for intellectual property extends to intellectual creations in order to incentivize innovation, and depends upon the nature of the work and its "characteristics". The main types of intellectual property law are: copyright, which protects creative works; patent, which protects invention; trade secret, which protects information not generally known or readily ascertainable that is valuable to the secret holder; and trademark, which protects branding and other exclusive properties of products and services. Any matter that meets such criteria is protected.
However, "sui generis" statutes exist in many countries that extend intellectual property protection to matter that does not meet characteristic definitions: integrated circuit layouts, ship hull designs, fashion designs in France, databases, or plant varieties require "sui generis" statutes because of their unique characteristics. The United States, Japan, and many EU countries protect the topography of semiconductor chips and integrated circuits under "sui generis" laws, which borrow some aspects from patent or copyright law. In the U.S. this "sui generis" law is known as the Semiconductor Chip Protection Act of 1984.
Politics and society.
In political philosophy, the unparalleled development of the European Union as compared to other international organizations has led to its designation as a "sui generis" geopolitical entity. The legal nature of the EU is widely debated because its mixture of intergovernmental and supranational elements causes it to share characteristics with both confederal and federal entities. It is generally considered more than a confederation but less than a federation, thus being appropriately classified as an instance of neither political form.
Compared to other international organizations, the EU is often considered "sui generis" because its legal system comprehensively rejects any use of retaliatory sanctions by one member state against another.
A similar case which has led to the use of the label "sui generis" is the unique relationship between France and New Caledonia because the legal status of New Caledonia can aptly be said to lie "somewhere between an overseas collectivity and a sovereign nation"; although other examples of such a status for other disputed or dependent territories may exist, this arrangement is certainly unique within the French Republic.
In local government, a "sui generis" entity is one which does not fit with the general scheme of local governance of a country. For example in England, the City of London and the Isles of Scilly are the two "sui generis" localities, as their forms of local government are both (for historical or geographical reasons) very different from those of elsewhere in the country. Therefore "The City of London" and "the Isles of Scilly" are said to be "sui generis authorities, pre-dating recent reforms of local government." The Joint Council of Municipalities of Croatia is a "sui generis" council of municipalities because it was formed after international agreement and therefore has no similar example in the rest of the country.
The legal status of the Holy See has been described as a "sui generis" entity possessing an international personality.
In a press conference during which reporters were trying to analyse his political personality, Huey Long stated : " . . . say that I am "sui generus", and let it go at that. "
Sociology.
In sociology, the "sui generis" is what has been externalized, then internalized in the overall public and becomes a part of society that simply exists in its construct. It is not something that is not thought to have been created because it is imbedded in everyone's way of thinking and being. Like the idea of love, or going to school, or clothing belonging to a specific gender. These examples are "sui generis" for they simply exist in society and in all of us without thought of where they come from or how they were created.
Creative arts.
A book, movie, television series, or other artistic creation is said to be "sui generis" when it does not fit into standard genre boundaries. Movie critic Richard Schickel identifies Joe Versus the Volcano as a "sui generis" movie. Joss Whedon's work may be considered "sui generis", to the point where his name has become adjectival in describing his work. The video game "Killer7" has been referred to as a game without genre, due to its combination of on-rails movement, first-person aiming and puzzle solving.

</doc>
<doc id="44096" url="https://en.wikipedia.org/wiki?curid=44096" title="Hans von Bodeck">
Hans von Bodeck

Hans von Bodeck (1582–1658) was a German diplomat and chancellor of the Hohenzollern Prince-electors of Brandenburg-Prussia.
Bodeck came from a prominent patrician family of Elbląg (Elbing) in Poland. His grandfather was the burgomaster, while his father was a city councilman. His ancestor Johann III von Bodeck (1542–1595) received imperial status from Emperor Rudolf II and was allowed to improve the family's coat of arms. The family also held offices in Danzig (Gdańsk).
In order to find a trading partner Bodeck was sent on a diplomatic mission from Elbing throughout Europe. During that time he wrote "liber amicorum", which is now studied by musicologists. During his diplomatic tour Bodeck visited the Netherlands, France, Switzerland, and England, where he attended the Universities of Oxford and Cambridge. He attended the funeral ceremony for Queen Elizabeth I of England and the coronation of the new English king, James I. The council of Elbing had sent two delegates with dual missions: firstly, to pay its respects to the new king and secondly to oppose the transfer of English trade from Elbing to nearby Danzig.
In 1604 Bodeck left for London and met John Dowland, Philip Rosseter, and Thomas Campion. All three composers of lute songs lived in the same district of London. Bodeck befriended them, and Campion wrote a song dedicated to Bodeck. Many people from England and Scotland came to live in Elbling.
Later that year Bodeck left for Paris and met Count Christopher von Dohna, a nobleman of Prussia, who lived 15 km from Elbing. Bodeck then became the chancellor to Elector Joachim Frederick of Brandenburg. He died in 1658.
A collection of pieces for lute was purchased by Dohna and kept at the Elbing library. In 1929 Hans Bauer wrote a full description of the register of Bodeck. During the capture of Elbing by the Soviet Red Army in 1945 during World War II and the subsequent expulsion of the city's German populace, the library was destroyed. Many Prussian documents and original manuscripts have since been discovered in Kraków, leading music researchers to hope that some of Bodeck's works might resurface.

</doc>
<doc id="44099" url="https://en.wikipedia.org/wiki?curid=44099" title="HMS Antelope">
HMS Antelope

Twelve ships of the Royal Navy have been named HMS "Antelope", after the Antelope:

</doc>
<doc id="44101" url="https://en.wikipedia.org/wiki?curid=44101" title="Satellite state">
Satellite state

The term satellite state designates a country that is formally independent in the world, but under heavy political, economic and military influence or control from another country. The term was coined by analogy to planetary objects orbiting a larger object, such as smaller moons revolving around larger planets, and is used mainly to refer to Central and Eastern European countries of the Warsaw Pact during the Cold War or to Mongolia between 1924 and 1990, for example. As used for Central and Eastern European countries it implies that the countries in question were "satellites" under the hegemony of the Soviet Union. In some contexts it also refers to other countries in the Soviet sphere of influence during the Cold War—such as North Korea (especially in the years surrounding the Korean War of 1950–1953) and Cuba (particularly after it joined the Comecon in 1972). In Western usage, the term has seldom been applied to states other than those in the Soviet orbit. In Soviet usage, the term applied to the states in the orbit of Nazi Germany and Fascist Italy.
The Oxford English Dictionary traces the use of the phrase "satellite state" in English back at least as far as 1916.
In times of war or political tension, satellite states sometimes serve as buffers between an enemy country and the nation exerting control over the satellites. "Satellite state" is one of several contentious terms used to describe the (alleged) subordination of one state to another. Other such terms include puppet state and neo-colony. In general, the term "satellite state" implies deep ideological and military allegiance to the hegemonic power, whereas "puppet state" implies political and military dependence, and "neo-colony" implies (often abject) economic dependence. Depending on which aspect of dependence is being emphasised, a state may fall into more than one category.
World War II.
During World War II, Kingdoms of Romania, Hungary, and Italy were often considered to be satellite states of Nazi Germany.
Soviet satellite states.
Post World War I.
When the Mongolian Revolution of 1921 broke out, Mongolian revolutionaries expelled Russian White Guards (during the Russian Civil War of 1917–1923 following the Communist October Revolution of 1917) from Mongolia, which became independent when the Qing dynasty collapsed in 1911, with the assistance of the Soviet Red Army. The revolution also officially ended Manchurian sovereignty over Mongolia, which had existed since 1691. Although the theocratic Bogd Khaanate of Mongolia still nominally continued, with successive series of violent struggles, Soviet influence got ever stronger, and after the death of the Bogd Khaan ("Great Khan", or "Emperor"), the Mongolian People's Republic was proclaimed on November 26, 1924. A nominally independent and sovereign country, it has been described as being a satellite state of the Soviet Union in the years from 1924 until 1990.
During the Russian Civil War, the Soviet Red Army troops took Tuva in January 1920, which was also part of the Qing Empire of China and a protectorate of Imperial Russia. The Tuvan People's Republic, was proclaimed independent in 1921 and was a satellite state of Soviet Union until its annexation in 1944 by the Soviet Union.
Another early Soviet satellite state in Asia was the short-lived Far East Republic in Siberia.
Post World War II.
At the end of World War II, most eastern and central European countries were occupied by the Soviet Union, and along with the USSR made up what is sometimes called the Soviet Empire. The Soviets remained in these countries after the war's end. Through a series of coalition governments including Communist parties, and then a forced liquidation of coalition members unliked by the Soviets, Stalinist systems were established in each country. Stalinists gained control of existing governments, police, press and radio outlets in these countries. Soviet satellite states in Europe included:
The Federal People's Republic of Yugoslavia is sometimes referred to as a Soviet satellite, though it broke from the Soviet Union in the 1948 Tito-Stalin split, with the Cominform offices being moved from Belgrade to Bucharest, and subsequently initiated formation of the Non-Aligned Movement. The People's Republic of Albania, under the leadership of Stalinist Enver Hoxha, broke ties with the Soviet Union in 1960 following the Soviet de-Stalinization process. These countries were, at least between 1945 and 1948, all members of the Eastern Bloc.
The Democratic Republic of Afghanistan can also be considered a Soviet satellite; from 1978 until 1991 the central government in Kabul was aligned with the Communist bloc, and was directly supported by Soviet military power between 1979 and 1989. The short-lived East Turkestan Republic (1944–1950) was a Soviet satellite until it was absorbed into the People's Republic of China along with the rest of Xinjiang.
Post-Cold War use of the term.
Commentators have sometimes expressed concern that United States military and diplomatic interventions in the Middle East and elsewhere might lead, or perhaps has already led, to the existence of American satellite states. William Pfaff has warned that a permanent American presence in Iraq would "turn Iraq into an American satellite state." The term has also been used in the past to describe the relationship between Lebanon and Syria, as Syria has been accused of intervening in Lebanese political affairs. In addition, Swaziland and Lesotho have both been described as satellite states of South Africa.

</doc>
<doc id="44103" url="https://en.wikipedia.org/wiki?curid=44103" title="Tribute in Light">
Tribute in Light

The Tribute in Light is an art installation of 88 searchlights placed next to the site of the World Trade Center to create two vertical columns of light in remembrance of the September 11 attacks. It is produced annually by the Municipal Art Society of New York. 
The two beams cost approximately $1,626 (assuming $0.11 kWh) to run for 24 hours. There are 88 xenon spotlights (44 for each tower) which each consume 7,000 watts.
Overview.
The Tribute in Light initially ran as a temporary installation from March 11 to April 14, 2002, and was launched again in 2003 to mark the second anniversary of the attack. , it has been repeated every year on September 11. It had been announced that 2008 would be its final year, but the tribute was continued in 2009. 
On December 17, 2009, it was confirmed that the tribute would continue through to the tenth anniversary of the attacks in 2011, but continued again in 2012. As of July 23, 2012, plans are underway for the National September 11 Memorial & Museum to assume the lease for the MTA property used during this tribute, and to begin transitioning operation of the tribute from the Municipal Art Society to the memorial foundation.
Development.
The idea of two vertical beams of light was first suggested by Ezra Orion, an Israeli sculptor, in 1997. Orion proposed an art installation in which 120 Xenon searchlights were to be placed on the tops of the Twin Towers for the 1998 4th of July celebration. On September 25th, 1997, Orion met with Richard Heart, the vice president of Xenon, and the Municipal art advisor, at the top of the south tower. Although the response to Orion’s suggestion was enthusiastic, it was deemed too expensive… 
Those working on the project came up with the concept in the week following the attack. On September 13, 2001, the idea was presented to executives of Consolidated Edison, the electric utility company serving New York City, by John Englehart, then president of the brand innovation firm Arnell Group Architects John Bennett and Gustavo Bonevardi of PROUN Space Studio distributed their "Project for the Immediate Reconstruction of Manhattan's Skyline". Artists Julian LaVerdiere and Paul Myoda, who before September 11 were working on the 91st floor of the World Trade Center north tower on a proposed light sculpture on the giant radio antenna with Creative Time, conceived of a project called "Phantom Towers". They were commissioned by "The New York Times Magazine" to create an image of the project for its September 23 cover.
Richard Nash Gould, a New York architect, presented the concept to the Municipal Art Society. On September 19, Municipal Art Society chairman Philip K. Howard wrote to Mayor Rudy Giuliani, asking him "to consider placing two large searchlights near the disaster site, projecting their light straight up into the sky."
After some consideration, it was decided to contact lighting experts in the field of high intensity light displays. A Las Vegas-based company, Light America, was chosen because of their vast knowledge of high intensity light displays. Gary Evans, the VP of Light America and Michael Burns the designer of the Tribute in Light, said that the company did testing of the lighting fixtures in the Las Vegas Valley before bringing the fixtures to the World Trade Center Site.
The project was originally going to be named "Towers of Light", but the victims' families felt that the name emphasized the buildings destroyed instead of the people killed.
On clear nights, the lights could be seen from over away, visible in all of New York City and most of suburban Northern New Jersey and Long Island, Fairfield County, Connecticut, Westchester County, Orange County, New York and Rockland County, New York. The beams were clearly visible from the terrace at Century Country Club in Purchase, New York, from at least as far west as western Morris County, in Flanders, New Jersey, at least as far as the barrier beach of Fire Island in Suffolk County, New York on Long Island, and as far south near Trenton, New Jersey in nearby Hamilton.
A permanent fixture of the Tribute in Light was to be installed on the roof of One World Trade Center, but never was due to the Durst Organization who redesigned the spire, which did not include the permanent fixture of Tribute in Light.
Since 2008, the generators that power Tribute in Light have been fueled with biodiesel made from used cooking oil collected from local restaurants provided by Tri-State Biodiesel. 
The lights have caused confusion for thousands of migrating birds, trapping them in the beams, and requiring that the lights be switched off for 20-minute periods to allow the birds to escape. To ensure the lights do not affect migrating birds, the Municipal Art Society works with the New York City Audubon on the illumination.
Media appearances.
The "Tribute in Light" has been featured in Boyz II Men's music video for "Color of Love". It also made a notable appearance during the opening credits of Spike Lee's 2002 film "25th Hour". In the Spider-Man 2 Video Game for Xbox, PlayStation 2 and GameCube, it appeared as a virtual memorial.

</doc>
<doc id="44104" url="https://en.wikipedia.org/wiki?curid=44104" title="Sigismund von Herberstein">
Sigismund von Herberstein

Siegmund (Sigismund) Freiherr von Herberstein, (or Baron Sigismund von Herberstein), (23 August 1486 – 28 March 1566) was a Carniolan diplomat, writer, historian and member of the Holy Roman Empire Imperial Council. He was most noted for his extensive writing on the geography, history and customs of Russia and contributed greatly to early Western European knowledge of that area.
Early life.
Herberstein was born in 1486 in Vipava (German "Wippach") in the Duchy of Carniola, now in Slovenia, then part of the Habsburg Monarchy's state of Inner Austria. His parents were Leonhard von Herberstein and Barbara von Lueg, members of the prominent German-speaking family which had already resided in Herberstein Castle for nearly 200 years. Little is known of his early life apart from the fact that he became familiar with the Slovene language spoken in the region. This knowledge became significant later in his life.
In 1499 he entered the University of Vienna to study philosophy and law. In 1506 he entered the army as an officer and served in a number of campaigns. In 1508 he was knighted by the Holy Roman Emperor, Maximilian I, in person. In 1515 he entered the Imperial council, or Parliament, and began a long and illustrious diplomatic career.
Diplomatic career.
Between 1515 and 1553, Herberstein carried out approximately 69 missions abroad, travelling throughout much of Europe, including Turkey. He was feted by the ruling Habsburgs and rewarded with titles and estates. He was twice sent to Russia as ambassador of the Holy Roman Emperor, in 1517 to attempt to arrange a truce between Russia and Lithuania, and in 1526 to renew a treaty between the two signed in 1522. These extended visits (nine months in his 1517 visit) provided him with the opportunity to study a hitherto largely unknown Russian society.
Writing on Russia.
Herberstein's knowledge of Slovene, acquired in his youth, allowed him to communicate freely with Russians, as Slovene and Russian both belong to the Slavic languages. He used this ability to question a variety of people in Russia on a wide range of topics. This gave him an insight into Russia and Russians unavailable to the few previous visitors to Russia. 
He probably wrote his first account of life in Russia between 1517 and 1527, but no copy of this survives. In 1526 he was asked to produce a formal report on his experiences in Russia, but this remained relatively unnoticed in the archives until he was able to find time to revise and expand it, which he possibly started in the 1530s.
The evidence suggests that Herberstein was an energetic and capable ethnographer. He investigated in depth both by questioning locals and by critically examining the scarce existing literature on Russia. The result was his major work, a book written in Latin titled "Rerum Moscoviticarum Commentarii" (literally "Notes on Muscovite Affairs"), published in 1549. This became the main early source of knowledge in Western Europe on Russia.
He was the first to record the spelling of "tsar" as "czar" (both spellings are meant to express the same pronunciation). Later, English and French began to move from the 'cz' spelling to the 'ts' spelling in the 19th century.

</doc>
<doc id="44106" url="https://en.wikipedia.org/wiki?curid=44106" title="Marwan al-Shehhi">
Marwan al-Shehhi

Marwan Yousef Mohamed Rashid Lekrab al-Shehhi (, , also transliterated as Alshehhi; 9 May 1978 – 11 September 2001) was the hijacker-pilot of United Airlines Flight 175, crashing the plane into the South Tower of the World Trade Center as part of the September 11 attacks.
Al-Shehhi was a student from the United Arab Emirates who moved to Germany in 1996 and soon became close friends with Mohamed Atta, Ziad Jarrah and Ramzi bin al-Shibh, forming the Hamburg cell. Together, after pledging their lives to martyrdom, they became the leaders of the September 11 attacks. In late 1999, al-Shehhi, Atta, Jarrah, and bin al-Shibh traveled to terrorist training camps in Afghanistan and met with Osama bin Laden who recruited the four Hamburg cell members for the attacks in the United States. He arrived in the United States in May 2000, one month before Atta. They both trained in Florida at Huffman Aviation, receiving their commercial pilot licenses in December 2000 from the FAA. 
Al-Shehhi spent 2001 making preparations for the attack itself, such as meeting with crucial September 11 planners abroad, assisting with the arrival of hijackers aboard the other flights, and travelling on surveillance flights determining details on how the hijacking would take place. On 9 September 2001, he flew from Florida to Boston, where he stayed at the Milner Hotel up until 11 September. Upon boarding United 175, al-Shehhi and 4 other hijackers waited 30 minutes into the flight to make their attack, which then allowed al-Shehhi to take over control as pilot, and at 9:03 a.m., 17 minutes after Mohamed Atta crashed American 11 into the North Tower, 23-year-old al-Shehhi crashed the Boeing 767 into the South Tower of the World Trade Center. He was the youngest hijacker-pilot in the attacks. The impact of the Boeing 767 operating as United 175 into the South Tower was seen live on television around the world as it happened.
Early life.
Al-Shehhi was born in Ras al-Khaimah, on 9 May 1978, in the United Arab Emirates, to a Muslim cleric who died in 1997. He was described as a quiet and devout Muslim. After graduating from high school in 1995, al-Shehhi enlisted in the Emirati military and received a half a year of basic training before he was admitted into a military scholarship program that allowed him to continue his education in Germany. Upon arriving in Germany in April 1996, al-Shehhi moved into an apartment, which he shared three other scholarship students for two months before boarding with a local German family. Several months later, he moved into his own apartment. Those who knew him described al-Shehhi as a very religious and friendly individual who wore western clothes and sometimes rented cars for trips to Berlin, France, and the Netherlands. 
While in Germany, al-Shehhi enrolled in the University of Bonn after completing a German course. He left Germany in June 1997 to attend to problems at home although the university forbade him. In early 1998, al-Shehhi transferred to the Technical University of Hamburg. A poor student, Marwan was directed by the Scholarship program administrators to repeat a semester of his studies back in Bonn beginning in August 1998. Al-Shehhi did not enroll back at Bonn until January 1999 and continued to struggle with his studies. By July 1999, Marwan returned to Hamburg to study shipbuilding.
Radicalization.
After moving to Hamburg in 1998, al-Shehhi helped form the Hamburg cell with Mohamed Atta and Ramzi bin al-Shibh. There, his views became more and more radical. They met three or four times a week to discuss anti-American feelings and plot possible attacks. When someone asked why he and Atta never laughed, al-Shehhi retorted, "How can you laugh when people are dying in Palestine?"
In October 1999 Marwan al-Shehhi was filmed at Said Bahaji's wedding in Germany with other 9/11 hijackers including Ziad Jarrah.
In late 1999, al-Shehhi, Atta, Ziad Jarrah, Said Bahaji, and Ramzi bin al-Shibh decided to travel to Chechnya to fight against the Russians, but were convinced by Khalid al-Masri and Mohamedou Ould Slahi at the last minute to change their plans. They instead traveled to Afghanistan to meet with Osama bin Laden and train for terrorist attacks. Immediately afterwards, Atta, al-Shehhi, and Jarrah reported their passports stolen, possibly to erase travel visas to Afghanistan. After their training, the hijackers began to attempt to hide their radicalism. al-Shehhi shaved his beard and seemed to his old friends like he had become less religious. After the attacks, a librarian in Hamburg reported that al-Shehhi boasted to her "There will be thousands of dead. You will think of me ... You will see, in America something is going to happen. There will be many people killed."
Al-Shehhi returned to Germany in March 2000, and began to learn to fly airplanes. Ammar al-Baluchi, one of the most important 9/11 financial organizers, bought a Boeing 747 flight simulator program using al-Shehhi's credit card. Eventually they decided that German flight schools would not work for them, and they decided to train in the United States. 
In the United States.
Flight education and preparation.
Al-Shehhi was the first of the Hamburg group to leave for the United States. He arrived in Newark, New Jersey on 29 May 2000. Atta joined him the next month, and the two began to search for flight schools. Al-Shehhi posed as a body guard of Atta, who was also posing as a "Saudi Arabian royal family member" while the two of them took flying lessons in Venice, Florida. They logged hundreds of hours on a Boeing 727 flight simulator. They received their licenses by December 2000. Their expenses were paid for by Ali Abdul Aziz Ali. On either 26 or 27 December, Atta and Marwan abandoned a Piper Cherokee that had stalled on the runway of Miami International Airport. On 29 December, Atta and Marwan went to the Opa-Locka Airport and practiced on a Boeing 727 simulator. Al-Shehhi began to take "surveillance flights" in the summer of 2001, watching the operations of flight crews and making final preparations. 
Travels in early 2001.
Ziad Jarrah, Atta, and al-Shehhi, having progressed in their training, all took foreign trips during the holiday period of 2000-2001. When Atta returned to Florida, al-Shehhi left for Morocco, traveling to Casablanca in mid-January 2001. al-Shehhi's family, concerned about not having heard from him, reported him missing to the UAE government. The UAE embassy in turn contacted the Hamburg police and a UAE representative tried to find him in Germany, visiting mosques and al-Shehhi's last address in Hamburg. After learning that his family was looking for him, al-Shehhi telephoned them on 20 January and said he was living and studying in Hamburg. The UAE government then told the Hamburg police they could call off the search.
Atta and al-Shehhi both encountered some difficulty reentering the United States, on 10 January and 19 January, respectively. As neither had presented a student visa, both of them had to persuade INS inspectors that they should be admitted so that they could continue their flight training. Neither operative had any problem clearing customs. After returning to Florida from their trips, Atta and al-Shehhi visited Georgia, staying briefly in Norcross and Decatur, and renting a single-engine plane to fly with an instructor in Lawrenceville. By 19 February, Atta and al-Shehhi were in Virginia. They had rented a mailbox in Virginia Beach, cashed a check, and then promptly returned to Georgia, staying in Stone Mountain. In mid-March, Ziad Jarrah was in Georgia as well, staying in Decatur. At the end of the month, Jarrah left the United States again and visited Sengün in Germany for two weeks. In early April, Atta and al-Shehhi returned to Virginia Beach and closed the mailbox they had opened in February.
Atta and al-Shehhi returned to Virginia Beach from their travels in Georgia, making their way to a large Dar Al-Hijrah mosque, sometime in early April. They were joined there by 9/11 hijackers Nawaf al-Hazmi and Hani Hanjour who had moved out of San Diego and Arizona after living in or visiting Abdussattar Shaikh's house, where Khalid al-Mihdhar also stayed. This mosque had recently in January 2001 hired the same imam Anwar al-Awlaki with whom Hazmi had spent time at the Rabat mosque in San Diego. He remembered Hazmi from San Diego but denied having contact with Hazmi or Hanjour in Virginia. Atta and al-Shehhi returned to Florida and moved into an apartment in Coral Springs. Atta stayed in Florida, awaiting the arrival of the first muscle hijackers. Al-Shehhi, on the other hand, bought a ticket to Cairo and flew there from Miami on 18 April. Al-Shehhi met with Atta's father, who stated in a post-9/11 interview that al-Shehhi wanted to pick up Atta's international driver's license and some money.
Al-Shehhi returned to Miami on 2 May. That day, Atta and Jarrah were together, about 30 miles to the north, visiting a Department of Motor Vehicles office in Lauderdale Lakes, Florida, to get Florida driver's licenses. In mid-July 2001, some of the hijackers and members of the Hamburg cell gathered near Salou, Spain, for a period of a few days up to a couple of weeks. Since hotel records are sparse during some of that time, it is thought that they may have spent considerable time in and around safe houses related to the al-Qaeda leader in Spain, Imad Yarkas. After 9/11, Spanish investigators followed the trails backwards, and the events they uncovered were chronicled in the Spanish nationwide newspaper "El País". Witnesses told Spanish investigators they saw a man who resembled al-Shehhi on 17 July 2001 at the Universal Studios PortAventura theme park next to Salou, Spain. The visitor, who was accompanied by two men, inquired about rides at the customer service counter. Witnesses indicated these companions resembled Ziad Jarrah, the later pilot on United Airlines Flight 93, and Said Bahaji, a then 26-year-old German-Moroccan member of the al-Qaeda cell in Hamburg. Back in Germany, it had been Bahaji's 1999 wedding during which al-Shehhi was filmed. Other witnesses elsewhere had pointed out Bahaji from photos, as one of the men they saw in Spain. But Bahaji bore a resemblance in appearance to Atta, who was traced to the same areas in Spain via hotel and travel records.
August 2001.
On 23 August, Israeli Mossad reportedly gave al-Shehhi's name to the CIA as part of a list of 19 names they said were planning an attack in the near future. Only four of the names are known for certain, including al-Shehhi; Nawaf al-Hazmi, Mohamed Atta, and Khalid al-Mihdhar.
On 26 August, Marwan signed into the Panther Motel in Deerfield Beach, Florida, paying US$500, saying he wanted to stay until 2 September, and listing a Mailboxes Etc. as his permanent address. His register entry indicated that he was driving a blue Chevrolet Malibu, assumed to be the one rented by Atta two weeks prior, and manager Richard Surma said that he bent rules to allow Marwan to have another man as an overnight guest. On 28 August, Marwan went to the Miami International Airport, accompanied by an unknown man, where he purchased his ticket for Flight 175. On 9 September, the motel manager, cleaning the room that al-Shehhi had vacated, found a bag containing a German/English dictionary, a protractor, flight manuals and local airport listings. Another employee later reported finding a box cutter. 
According to librarian Kathleen Hensmen, Wail al-Shehri and Waleed al-Shehri used Internet access at Delray Beach Public Library in August 2001, where they may have been looking at information on crop dusting. They reportedly left the library with a third middle-eastern man, thought to be Marwan al-Shehhi, whom Hensmen claimed asked her for the name of a local restaurant. Staff at Shuckum's Oyster Pub and Seafood Grill in Hollywood, Florida claimed they recognized both Atta and Marwan as two of the people who had been at the restaurant on either 7 or 8 September. While there are varying stories about Atta's activities, all sources indicate that al-Shehhi drank rum and coke while talking to the others. On 9 September, they flew to Boston. The next day, al-Shehhi and three of the other hijackers, Fayez Banihammad, Mohand al-Shehri, and Satam al-Suqami, shared a room at the Milner Hotel in Boston. 
Attacks.
According to the 9/11 Commission Report, al-Shehhi made a 3-minute call to Mohamed Atta (6:52-6:55 a.m.) on 11 September from within Logan International Airport as both American 11 and United 175 were to fly from Boston Logan to LAX. 
al-Shehhi boarded United 175 at 7:27 a.m. Around 30 minutes into the flight, between 8:42 and 8:46 a.m., the plane was hijacked. During the flight, the plane narrowly avoided a mid-air collision with another aircraft, Delta Airlines Flight 2315. Several calls were made from the plane to relatives, the passengers learning of the fate of American 11.
The plane was flown into the South Tower of the World Trade Center at 9:03:02 a.m. The plane crashed with a speed of approximately 590 mph (950 km/h). The plane was carrying about 10,000 gallons (37,850 litres) of jet fuel. It was seen live on television around the world as it crashed into the South Tower, being filmed from multiple vantage points. al-Shehhi flew the plane faster and lower into the tower than Atta did, into the eastern half of the South Tower's southern facade close to the southeast corner, leading to the South Tower collapsing before the North Tower; which was the first to be hit.

</doc>
<doc id="44108" url="https://en.wikipedia.org/wiki?curid=44108" title="Minuet">
Minuet

A minuet (; also spelled "menuet"), is a social dance of French origin for two people, usually in time. The word was adapted from Italian "minuetto" and French "menuet", possibly from the French "menu" meaning slender, small, referring to the very small steps, or from the early 17th-century popular group dances called "branle à mener" or "amener".
The term also describes the musical style that accompanies the dance, which subsequently developed more fully, often with a longer musical form called the minuet and trio, and was much used as a movement in the early classical symphony.
Dance.
The name may refer to the short steps, "pas menus", taken in the dance, or else be derived from the "branle à mener" or "amener", popular group dances in early 17th-century France . The minuet was traditionally said to have descended from the "bransle de Poitou", though there is no evidence making a clear connection between these two dances. The earliest treatise to mention the possible connection of the name to the expression "pas menus" is Gottfried Taubert's "Rechtschaffener Tantzmeister", published in Leipzig in 1717, but this source does not describe the steps as being particularly small or dainty . At the period when it was most fashionable it was controlled, ceremonious and graceful.
Music.
Rhythm and form.
The name is also given to a musical composition written in the same time and rhythm, though when not accompanying an actual dance the pace was quicker. Stylistically refined minuets, apart from the social dance context, were introduced—to opera at first—by Jean-Baptiste Lully, who included no fewer than 92 of them in his theatrical works and in the late 17th century the minuet was adopted into the suite, such as some of the suites of Johann Sebastian Bach and George Frideric Händel. Among Italian composers the minuet was often considerably quicker and livelier and was sometimes written in or time. Because the tempo of a minuet was not standard, the tempo direction "tempo di minuetto" was ambiguous unless qualified by another direction, as it sometimes was .
Initially, before its adoption in contexts other than social dance, the minuet was usually in binary form, with two repeated sections of usually eight bars each. But the second section eventually expanded, resulting in a kind of ternary form. The second (or middle) minuet provided form of contrast by means of different key and orchestration. On a larger scale, two such minuets might be further combined, so that the first minuet was followed by a second one and then by a repetition of the first. The whole form might in any case be repeated as long as the dance lasted.
Minuet and trio.
Around Lully's time it became a common practice to score this middle section for a trio (such as two oboes and a bassoon, as is common in Lully). As a result, this middle section came to be called the minuet's "trio", even when no trace of such an orchestration remains. The overall structure is called rounded binary or minuet form :
After these developments by Lully, composers occasionally inserted a modified repetition of the first (A) section or a section that contrasted with both the A section and what was thereby rendered the third or C section, yielding the form A–A′–B–A or A–B–C–A, respectively; an example of the latter is the third movement of Mozart's Serenade No. 13 in G major, K. 525, popularly known under the title "Eine kleine Nachtmusik".
A livelier form of the minuet simultaneously developed into the scherzo (which was generally also coupled with a trio). This term came into existence approximately from Beethoven onwards, but the form itself can be traced back to Haydn.
The minuet and trio eventually became the standard third movement in the four-movement classical symphony, Johann Stamitz being the first to employ it thus with regularity.
An example of the true form of the minuet is to be found in "Don Giovanni".
A famous example of a more recent instrumental work in minuet form is Ignacy Jan Paderewski's Minuet in G.

</doc>
<doc id="44112" url="https://en.wikipedia.org/wiki?curid=44112" title="John Dalton">
John Dalton

John Dalton FRS (6 September 1766 – 27 July 1844) was an English chemist, physicist, and meteorologist. He is best known for his pioneering work in the development of modern atomic theory; and his research into colour blindness, sometimes referred to as Daltonism, in his honour.
Early life.
John Dalton was born into a Quaker family at the settlement of Eaglesfield, near the town of Cockermouth, in the county of Cumberland, England in 1766. His father was a weaver. He received his early education from his father and from Quaker John Fletcher, who ran a private school at Pardshaw Hall. With his family too poor to support him for long, he began to earn his living at the age of ten in the service of a wealthy local Quaker, Elihu Robinson. It is said he began teaching at a local school at age 12, and was proficient in Latin at age 14.
Early careers.
He joined his older brother Jonathan at age 15 in running a Quaker school at Stramongate in Kendal, about forty five miles from his home. Around age 23 Dalton may have considered studying law or medicine, but his relatives did not encourage him, perhaps because being a Dissenter (a Christian opposed to a state religion and mandatory membership in the Church of England), he was barred from attending English universities. He acquired much scientific knowledge from informal instruction by John Gough, a blind philosopher who was gifted in the sciences and arts. At age 27 he was appointed teacher of mathematics and natural philosophy at the "New College" in Manchester, a dissenting academy. He remained there until age 34, when the college's worsening financial situation led him to resign his post and begin a new career as a private tutor for mathematics and natural philosophy.
Scientific contributions.
Meteorology.
Dalton's early life was highly influenced by a prominent Eaglesfield Quaker named Elihu Robinson, a competent meteorologist and instrument maker, who got him interested in problems of mathematics and meteorology. During his years in Kendal, Dalton contributed solutions of problems and questions on various subjects to "The Ladies' Diary" and the "Gentleman's Diary". In 1787 at age 21 he began to keep a meteorological diary in which, during the succeeding 57 years, he entered more than 200,000 observations. He also rediscovered George Hadley's theory of atmospheric circulation (now known as the Hadley cell) around this time. Dalton's first publication was "Meteorological Observations and Essays" at age 27 in 1793, which contained the seeds of several of his later discoveries. However, in spite of the originality of his treatment, little attention was paid to them by other scholars. A second work by Dalton, "Elements of English Grammar", was published at age 35 in 1801.
Colour blindness.
In 1794 at age 28, shortly after his arrival in Manchester, Dalton was elected a member of the Manchester Literary and Philosophical Society, the "Lit & Phil", and a few weeks later he communicated his first paper on "Extraordinary facts relating to the vision of colours", in which he postulated that shortage in colour perception was caused by discoloration of the liquid medium of the eyeball. In fact, a shortage of colour perception in some people had not even been formally described or officially noticed until Dalton wrote about his own. Since both he and his brother were colour blind, he recognized that this condition must be hereditary.
Although Dalton's theory lost credence in his own lifetime, the thorough and methodical nature of his research into his own visual problem was so broadly recognized that Daltonism became a common term for colour blindness. Examination of his preserved eyeball in 1995 demonstrated that Dalton actually had a less common kind of colour blindness, deuteroanopia, in which medium wavelength sensitive cones are missing (rather than functioning with a mutated form of their pigment, as in the most common type of colour blindness, deuteroanomaly). Besides the blue and purple of the optical spectrum he was able to recognize only one colour, yellow, or, as he says in his paper,
Measuring mountains in the Lake District.
Dalton regularly holidayed in the Lake District where his study of meteorology involved a lot of mountain climbing: until the advent of aeroplanes and weather balloons, the only way to make measurements of temperature and humidity at altitude was to climb a mountain. The altitude achieved was estimated using a barometer. This meant that, until the Ordnance Survey started publishing their maps for the Lake District in the 1860s, Dalton was one of the few sources of such information. Dalton was often accompanied by Jonathan Otley, who was one of the few other authorities on the heights of the Lake District mountains. He became both an assistant and a friend.
Gas laws.
In 1800, at age 34 Dalton became a secretary of the Manchester Literary and Philosophical Society, and in the following year he orally presented an important series of papers, entitled "Experimental Essays" on the constitution of mixed gases; on the pressure of steam and other vapours at different temperatures, both in a vacuum and in air; on evaporation; and on the thermal expansion of gases. These four essays were published in the "Memoirs" of the Lit & Phil in 1802.
The second of these essays opens with the striking remark,
After describing experiments to ascertain the pressure of steam at various points between 0 and 100 °C (32 and 212 °F), Dalton concluded from observations on the vapour pressure of six different liquids, that the variation of vapour pressure for all liquids is equivalent, for the same variation of temperature, reckoning from vapour of any given pressure.
In the fourth essay he remarks,
He thus enunciated Gay-Lussac's law or J.A.C. Charles's law, published in 1802 at age 36 by Joseph Louis Gay-Lussac. In the two or three years following the reading of these essays, Dalton published several papers on similar topics, that on the absorption of gases by water and other liquids (1803), containing his law of partial pressures now known as Dalton's law.
Atomic theory.
The most important of all Dalton's investigations are those concerned with the atomic theory in chemistry. While his name is inseparably associated with this theory, the origin of Dalton's atomic theory is not fully understood. It has been proposed that this theory was suggested to him either by researches on ethylene ("olefiant gas") and methane ("carburetted hydrogen") or by analysis of nitrous oxide ("protoxide of azote") and nitrogen dioxide ("deutoxide of azote"), both views resting on the authority of Thomas Thomson. However, a study of Dalton's own laboratory notebooks, discovered in the rooms of the Lit & Phil, concluded that so far from Dalton being led by his search for an explanation of the law of multiple proportions to the idea that chemical combination consists in the interaction of atoms of definite and characteristic weight, the idea of atoms arose in his mind as a purely physical concept, forced upon him by study of the physical properties of the atmosphere and other gases. The first published indications of this idea are to be found at the end of his paper on the absorption of gases already mentioned, which was read on 21 October 1803, though not published until 1805. Here he says:
The main points of Dalton's atomic theory were:
Dalton proposed an additional "rule of greatest simplicity" that created controversy, since it could not be independently confirmed.
For elements that combined in multiple ratios, their combinations were assumed to be the simplest ones possible. Two combinations resulted in a binary and a ternary compound. This was merely an assumption, derived from faith in the simplicity of nature. No evidence was then available to scientists to deduce how many atoms of each element combine to form compound molecules. But this or some other such rule was absolutely necessary to any incipient theory, since one needed an assumed molecular formula in order to calculate relative atomic weights. In any case, Dalton's "rule of greatest simplicity" caused him to assume that the formula for water was OH and ammonia was NH, quite different from our modern understanding (H2O, NH3).
Despite the uncertainty at the heart of Dalton's atomic theory, the principles of the theory survived. To be sure, the conviction that atoms cannot be subdivided, created, or destroyed into smaller particles when they are combined, separated, or rearranged in chemical reactions is inconsistent with the existence of nuclear fusion and nuclear fission, but such processes are nuclear reactions and not chemical reactions. In addition, the idea that all atoms of a given element are identical in their physical and chemical properties is not precisely true, as we now know that different isotopes of an element have slightly varying weights. However, Dalton had created a theory of immense power and importance. Indeed, Dalton's innovation was fully as important for the future of the science as Antoine Laurent Lavoisier's oxygen-based chemistry had been.
Atomic weights.
Dalton proceeded to print his first published table of relative atomic weights. Six elements appear in this table, namely hydrogen, oxygen, nitrogen, carbon, sulfur, and phosphorus, with the atom of hydrogen conventionally assumed to weigh 1. Dalton provided no indication in this first paper how he had arrived at these numbers. However, in his laboratory notebook under the date 6 September 1803 there appears a list in which he sets out the relative weights of the atoms of a number of elements, derived from analysis of water, ammonia, carbon dioxide, etc. by chemists of the time.
It appears, then, that confronted with the problem of calculating the relative diameter of the atoms of which, he was convinced, all gases were made, he used the results of chemical analysis. Assisted by the assumption that combination always takes place in the simplest possible way, he thus arrived at the idea that chemical combination takes place between particles of different weights, and it was this which differentiated his theory from the historic speculations of the Greeks, such as Democritus and Lucretius.
The extension of this idea to substances in general necessarily led him to the law of multiple proportions, and the comparison with experiment brilliantly confirmed his deduction. It may be noted that in a paper on the proportion of the gases or elastic fluids constituting the atmosphere, read by him in November 1802, the law of multiple proportions appears to be anticipated in the words: "The elements of oxygen may combine with a certain portion of nitrous gas or with twice that portion, but with no intermediate quantity", but there is reason to suspect that this sentence may have been added some time after the reading of the paper, which was not published until 1805.
Compounds were listed as binary, ternary, quaternary, etc. (molecules composed of two, three, four, etc. atoms) in the "New System of Chemical Philosophy" depending on the number of atoms a compound had in its simplest, empirical form.
He hypothesized the structure of compounds can be represented in whole number ratios. So, one atom of element X combining with one atom of element Y is a binary compound. Furthermore, one atom of element X combining with two elements of Y or vice versa, is a ternary compound. Many of the first compounds listed in the "New System of Chemical Philosophy" correspond to modern views, although many others do not.
Dalton used his own symbols to visually represent the atomic structure of compounds. These were depicted in the"New System of Chemical Philosophy", where Dalton listed twenty elements and seventeen simple molecules.
Other investigations.
Dalton published papers on such diverse topics as rain and dew and the origin of springs (hydrosphere); on heat, the color of the sky, steam, and the reflection and refraction of light; and on the grammatical subjects of the auxiliary verbs and participles of the English language.
Experimental approach.
As an investigator, Dalton was often content with rough and inaccurate instruments, even though better ones were obtainable. Sir Humphry Davy described him as "a very coarse experimenter", who almost always found the results he required, trusting to his head rather than his hands. On the other hand, historians who have replicated some of his crucial experiments have confirmed Dalton's skill and precision.
In the preface to the second part of Volume I of his "New System", he says he had so often been misled by taking for granted the results of others that he determined to write "as little as possible but what I can attest by my own experience", but this independence he carried so far that it sometimes resembled lack of receptivity. Thus he distrusted, and probably never fully accepted, Gay-Lussac's conclusions as to the combining volumes of gases.
He held unconventional views on chlorine. Even after its elementary character had been settled by Davy, he persisted in using the atomic weights he himself had adopted, even when they had been superseded by the more accurate determinations of other chemists.
He always objected to the chemical notation devised by Jöns Jakob Berzelius, although most thought that it was much simpler and more convenient than his own cumbersome system of circular symbols.
Other publications.
For "Rees's Cyclopædia" Dalton contributed articles on Chemistry and Meteorology, but the topics are not known.
He contributed 117 "Memoirs of the Literary and Philosophical Society of Manchester", from 1817 until his death in 1840, while president of that organization. Of these the earlier are the most important. In one of them, read in 1814, he explains the principles of volumetric analysis, in which he was one of the earliest workers. In 1840 a paper on the phosphates and arsenates, often regarded as a weaker work, was refused by the Royal Society, and he was so incensed that he published it himself. He took the same course soon afterwards with four other papers, two of which ("On the quantity of acids, bases and salts in different varieties of salts" and "On a new and easy method of analysing sugar") contain his discovery, regarded by him as second in importance only to the atomic theory, that certain anhydrates, when dissolved in water, cause no increase in its volume, his inference being that the salt enters into the pores of the water.
Public life.
Before he had propounded the atomic theory, he had already attained a considerable scientific reputation. In 1803, he was chosen to give a course of lectures on natural philosophy at the Royal Institution in London, and he delivered another course of lectures there in 1809–1810. However, some witnesses reported that he was deficient in the qualities that make an attractive lecturer, being harsh and indistinct in voice, ineffective in the treatment of his subject, and singularly wanting in the language and power of illustration.
In 1810, Sir Humphry Davy asked him to offer himself as a candidate for the fellowship of the Royal Society, but Dalton declined, possibly for financial reasons. However, in 1822 he was proposed without his knowledge, and on election paid the usual fee. Six years previously he had been made a corresponding member of the French Académie des Sciences, and in 1830 he was elected as one of its eight foreign associates in place of Davy. In 1833, at age 67 Earl Grey's government conferred on him a pension of £150, raised in 1836 to £300. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1834 at age 68.
A young James Prescott Joule, who later studied and published (1843) on the nature of heat and its relationship to mechanical work, was a famous pupil of Dalton in his last years.
Personal life.
Dalton never married and had only a few close friends. All in all as a Quaker he lived a modest and unassuming personal life.
For the twenty-six years prior to Dalton's death, he lived in a room in the home of the Rev. (and Mrs.) W. Johns, a published botanist, in George Street, Manchester. Dalton and Johns died in the same year - 1844.
Dalton's daily round of laboratory work and tutoring in Manchester was broken only by annual excursions to the Lake District and occasional visits to London. In 1822 he paid a short visit to Paris, where he met many distinguished resident men of science. He attended several of the earlier meetings of the British Association at York, Oxford, Dublin and Bristol.
Disability and death.
Dalton suffered a minor stroke in 1837, and a second one in 1838 left him with a speech impairment, though he remained able to perform experiments. In May 1844 he had yet another stroke; on 26 July 1844 he recorded with trembling hand his last meteorological observation. On 27 July 1844, in Manchester, Dalton fell from his bed and was found lifeless by his attendant.
Dalton was accorded a civic funeral with full honours. His body was laid in state in Manchester Town Hall for four days and more than 40,000 people filed past his coffin. The funeral procession included representatives of the city’s major civic, commercial, and scientific bodies. He was buried in Manchester in Ardwick cemetery. The cemetery is now a playing field, but pictures of the original grave may be found in published materials.

</doc>
<doc id="44114" url="https://en.wikipedia.org/wiki?curid=44114" title="Symphony">
Symphony

A symphony is an extended musical composition in Western classical music, most often written by composers for orchestra. Although the term has had many meanings from its origins in the ancient Greek era, by the late 18th century the word had taken on the meaning common today: a work usually consisting of multiple distinct sections or movements, often four, with the first movement in sonata form. Symphonies are scored for string (violin, viola, cello and double bass), brass, woodwind, and percussion instruments which altogether number about 30–100 musicians. Symphonies are notated in a musical score, which contains all the instrument parts. Orchestral musicians play from parts which contain just the notated music for their instrument. A small number of symphonies also contain vocal parts (e.g., Beethoven's Ninth Symphony).
Origins.
The word "symphony" is derived from Greek ("symphonia"), meaning "agreement or concord of sound", "concert of vocal or instrumental music", from ("symphōnos"), "harmonious". The word referred to an astonishing variety of different things, before ultimately settling on its current meaning designating a musical form.
In late Greek and medieval theory, the word was used for consonance, as opposed to διαφωνία ("diaphōnia"), which was the word for dissonance. In the Middle Ages and later, the Latin form "symphonia" was used to describe various instruments, especially those capable of producing more than one sound simultaneously. Isidore of Seville was the first to use the word symphonia as the name of a two-headed drum, and from c. 1155 to 1377 the French form "symphonie" was the name of the "organistrum" or hurdy-gurdy. In late medieval England, "symphony" was used in both of these senses, whereas by the 16th century it was equated with the dulcimer. In German, "Symphonie" was a generic term for spinets and virginals from the late 16th century to the 18th century.
In the sense of "sounding together," the word begins to appear in the titles of some works by 16th- and 17th-century composers including Giovanni Gabrieli's "Sacrae symphoniae", and "Symphoniae sacrae, liber secundus", published in 1597 and 1615, respectively; Adriano Banchieri's "Eclesiastiche sinfonie, dette canzoni in aria francese, per sonare, et cantare", op. 16, published in 1607; Lodovico Grossi da Viadana's "Sinfonie musicali", op. 18, published in 1610; and Heinrich Schütz's "Symphoniae sacrae", op. 6, and "Symphoniarum sacrarum secunda pars", op. 10, published in 1629 and 1647, respectively. Except for Viadana's collection, which contained purely instrumental and secular music, these were all collections of sacred vocal works, some with instrumental accompaniment.
In the 17th century, for most of the Baroque period, the terms "symphony" and "sinfonia" were used for a range of different compositions, including instrumental pieces used in operas, sonatas and concertos—usually part of a larger work. The "opera sinfonia", or "Italian overture" had, by the 18th century, a standard structure of three contrasting movements: fast, slow, fast and dance-like. It is this form that is often considered as the direct forerunner of the orchestral symphony. The terms "overture", "symphony" and "sinfonia" were widely regarded as interchangeable for much of the 18th century.
In the 17th century, pieces scored for large instrumental ensemble did not precisely designate which instruments were to play which parts, as is the practice from the 19th century to the current period. When composers from the 17th century wrote pieces, they expected that these works would be performed by whatever group of musicians were available. To give one example, whereas the bassline in a 19th-century work is scored for cellos, double basses and other specific instruments, in a 17th-century work, a basso continuo part for a sinfonia would not specify which instruments would play the part. A performance of the piece might be done with a basso continuo group as small as a single cello and harpsichord. However, if a bigger budget was available for a performance and a larger sound was required, a basso continue group might include multiple chord-playing instruments (harpsichord, lute, etc.) and a range of bass instruments, including cello, double bass, bass viol or even a serpent, an early bass woodwind instrument.
18th century.
During the 18th century, "the symphony was cultivated with extraordinary intensity". It played a role in many areas of public life, including church services, but a particularly strong area of support for symphonic performances was the aristocracy. In Vienna, perhaps the most important location in Europe for the composition of symphonies, "literally hundreds of noble families supported musical establishments, generally dividing their time between Vienna and their ancestral estate in the Empire". Since the normal size of the orchestra at the time was quite small, many of these courtly establishments were capable of performing symphonies. The young Joseph Haydn, taking up his first job as a music director in 1757 for the Morzin family, found that when the Morzin household was in Vienna, his own orchestra was only part of a lively and competitive musical scene, with multiple aristocrats sponsoring concerts with their own ensembles (Carpani 1823, 66, cited in Gotwals 1968).
LaRue, Bonds, Walsh, and Wilson trace the gradual expansion of the symphonic orchestra through the 18th century. At first, symphonies were string symphonies, written in just four parts: first violin, second violin, viola, and bass (the bass line was taken by cello(s), double bass(es) playing the part an octave below, and perhaps also a bassoon). Occasionally the early symphonists even dispensed with the viola part, thus creating three-part symphonies. A basso continuo part including a bassoon together with a harpsichord or other chording instrument was also possible.
The first additions to this simple ensemble were a pair of horns, occasionally a pair of oboes, and then both horns and oboes together. Over the century, other instruments were added to the classical orchestra: flutes (sometimes replacing the oboes), separate parts for bassoons, clarinets, and trumpets and timpani. Works varied in their scoring concerning which of these additional instruments were to appear. The full-scale classical orchestra, deployed at the end of the century for the largest-scale symphonies, has the standard string ensemble mentioned above, pairs of winds (flutes, oboes, clarinets, bassoons), a pair of horns, and timpani. A keyboard continuo instrument (harpsichord or piano) remained an option.
The "Italian" style of symphony, often used as overture and entr'acte in opera houses, became a standard three-movement form: a fast movement, a slow movement, and another fast movement. Over the course of the 18th century it became the custom to write four-movement symphonies, along the lines described in the next paragraph. The three-movement symphony died out slowly; about half of Haydn's first thirty symphonies are in three movements; An outstanding late example of the three-movement Classical symphony is Mozart's "Prague" Symphony, from 1787.
The four-movement form that emerged from this evolution was as follows:
Variations on this layout, like changing the order of the middle movements or adding a slow introduction to the first movement, were common. Haydn, Mozart and their contemporaries restricted their use of the four-movement form to orchestral or multi-instrument chamber music such as quartets, though since Beethoven solo sonatas are as often written in four as in three movements.
The composition of early symphonies was centred on Milan, Vienna, and Mannheim. The Milanese school centred around Giovanni Battista Sammartini and included Antonio Brioschi, Ferdinando Galimberti and Giovanni Battista Lampugnani. Early exponents of the form in Vienna included Georg Christoph Wagenseil, Wenzel Raimund Birck and Georg Matthias Monn, while later significant Viennese composers of symphonies included Johann Baptist Wanhal, Karl Ditters von Dittersdorf and Leopold Hoffmann. The Mannheim school included Johann Stamitz.
The most important symphonists of the latter part of the 18th century are Haydn, who wrote at least 107 symphonies over the course of 36 years, and Mozart, with at least 47 symphonies in 24 years.
19th century.
At the beginning of the 19th century, Beethoven elevated the symphony from an everyday genre produced in large quantities to a supreme form in which composers strove to reach the highest potential of music in just a few works. Beethoven began with two works directly emulating his models Mozart and Haydn, then seven more symphonies, starting with the Third Symphony ("Eroica") that expanded the scope and ambition of the genre. His Symphony No. 5 is perhaps the most famous symphony ever written; its transition from the emotionally stormy C minor opening movement to a triumphant major-key finale provided a model adopted by later symphonists such as Brahms and Mahler. His Symphony No. 6 is a programmatic work, featuring instrumental imitations of bird calls and a storm; and, unconventionally, a fifth movement (symphonies usually had at most four movements). His Symphony No. 9 includes parts for vocal soloists and choir in the last movement, making it a choral symphony.
Of the symphonies of Franz Schubert, two are core repertory items and are frequently performed. Of the Eighth Symphony (1822), Schubert completed only the first two movements; this highly Romantic work is usually called by its nickname "The Unfinished." His last completed symphony, the Ninth (1826) is a massive work in the Classical idiom.
Of the early Romantics, Felix Mendelssohn (five symphonies) and Robert Schumann (four) continued to write symphonies in the classical mold, though using their own musical language. In contrast, Hector Berlioz favored programmatic works, including his "dramatic symphony" "Roméo et Juliette" and the highly original "Symphonie fantastique". The latter is also a programme work and has both a march and a waltz and five movements instead of the customary four. His fourth and last symphony, the "Grande symphonie funèbre et triomphale" (originally titled "Symphonie militaire") was composed in 1840 for a 200-piece marching military band, to be performed out of doors, and is an early example of a band symphony. Berlioz later added optional string parts and a choral finale. In 1851, Richard Wagner declared that all of these post-Beethoven symphonies were no more than an epilogue, offering nothing substantially new. Indeed, after Schumann's last symphony, the "Rhenish" composed in 1850, for two decades the Lisztian symphonic poem appeared to have displaced the symphony as the leading form of large-scale instrumental music. If the symphony had been eclipsed, it was not long before it re-emerged in a "second age" in the 1870s and 1880s, with the symphonies of Anton Bruckner, Johannes Brahms, Pyotr Ilyich Tchaikovsky, Camille Saint-Saëns, Alexander Borodin, Antonín Dvořák, and César Franck—works which continued to dominate the concert repertory for at least a century.
Over the course of the 19th century, composers continued to add to the size of the symphonic orchestra. Around the beginning of the century, a full-scale orchestra would consist of the string section plus pairs of flutes, oboes, clarinets, bassoons, horns, trumpets, and lastly a set of timpani. This is, for instance, the scoring used in Beethoven's symphonies numbered 1, 2, 4, 7, and 8. Trombones, which had previously been confined to church and theater music, came to be added to the symphonic orchestra, notably in Beethoven's 5th, 6th, and 9th symphonies. The combination of bass drum, triangle, and cymbals (sometimes also: piccolo), which 18th century composers employed as a coloristic effect in so-called "Turkish music", came to be increasingly used during the second half of the 19th century without any such connotations of genre. By the time of Mahler (see below), it was possible for a composer to write a symphony scored for "a veritable compendium of orchestral instruments". In addition to increasing in variety of instruments, 19th century symphonies were gradually augmented with more string players and more wind parts, so that that the orchestra grew substantially in sheer numbers, as concert halls likewise grew.
20th century.
At the beginning of the 20th century, Gustav Mahler wrote long, large-scale symphonies. His Eighth Symphony, for example, was composed in 1906 and is nicknamed the "Symphony of a Thousand" because of the large number of voices required to perform the choral sections. Additionally, his Third Symphony is one of the longest regularly performed symphonies at around 100 minutes in length for most performances. The 20th century also saw further diversification in the style and content of works that composers labeled "symphonies" (Anon. 2008). Some composers, including Dmitri Shostakovich, Sergei Rachmaninoff, and Carl Nielsen, continued to write in the traditional four-movement form, while other composers took different approaches: Jean Sibelius' "Symphony No. 7", his last, is in one movement, whereas Alan Hovhaness's Symphony No. 9, "Saint Vartan"—originally op. 80, changed to op. 180—composed in 1949–50, is in twenty-four.
A concern with unification of the traditional four-movement symphony into a single, subsuming formal conception had emerged in the late 19th century. This has been called a "two-dimensional symphonic form", and finds its key turning point in Arnold Schoenberg's Chamber Symphony No. 1, Op. 9 (1909), which was followed in the 1920s by other notable single-movement German symphonies, including Kurt Weill’s First Symphony (1921), Max Butting’s Chamber Symphony, Op. 25 (1923), and Paul Dessau's 1926 Symphony.
There remained, however, certain tendencies. Designating a work a "symphony" still implied a degree of sophistication and seriousness of purpose. The word "sinfonietta" came into use to designate a work that is shorter, of more modest aims, or "lighter" than a symphony, such as Sergei Prokofiev's Sinfonietta for orchestra (Kennedy 2006a).
In the first half of the century, Edward Elgar, Gustav Mahler, Jean Sibelius, Carl Nielsen, Igor Stravinsky, Bohuslav Martinů, Roger Sessions, and Dmitri Shostakovich composed symphonies "extraordinary in scope, richness, originality, and urgency of expression" (Steinberg 1995, 404). One measure of the significance of a symphony is the degree to which it reflects conceptions of temporal form particular to the age in which it was created. Five composers from across the span of the 20th century who fulfill this measure are Sibelius, Stravinsky, Luciano Berio (in his Sinfonia, 1968–69), Elliott Carter (in his "Symphony of Three Orchestras", 1976), and Pelle Gudmundsen-Holmgreen (in "Symphony/Antiphony", 1980).
Beginning in the 20th century, more symphonies have been written for concert band than in past centuries. Although examples exist from as early as 1932, the first such symphony of importance since Hector Berlioz wrote the "Grande symphonie funèbre et triomphale" in 1840 is Nikolai Miaskovsky’s Symphony No. 19, Op. 46, composed in 1939 (Battisti 2002, 42). Some further examples are Paul Hindemith's Symphony in B-flat for Band, composed in 1951; Morton Gould's Symphony No. 4 "West Point", composed in 1952; Vincent Persichetti's Symphony No. 6, Op. 69, composed in 1956; Vittorio Giannini's Symphony No.3, composed in 1959; Alan Hovhaness's Symphonies No. 4, op. 165, No. 7, "Nanga Parvat", op. 175, No. 14, "Ararat", op. 194, and No. 23, "Ani", op. 249, composed in 1958, 1959, 1961, and 1972 respectively; Alfred Reed's 2nd, 3rd, 4th, and 5th symphonies, composed in 1979, 1988, 1992, and 1994 respectively; and Johan de Meij's Symphony No. 1 "The Lord of the Rings", composed in 1988, and his Symphony No. 2 "The Big Apple", composed in 1993.
Other modern usages of "symphony".
The word "symphony" is also used to refer to the orchestra, the large ensemble that often performs these works. The word "symphony" appears in the name of many orchestras, for example, the Boston Symphony Orchestra, the St. Louis Symphony, the Houston Symphony, or Miami's New World Symphony. For some orchestras, "(city name) Symphony" provides a shorter version of the full name; for instance, the OED gives "Vancouver Symphony" as a possible abbreviated form of Vancouver Symphony Orchestra. As well, in common usage, a person may say they are going out to hear a symphony perform, a reference to the orchestra and not the works on the program.

</doc>
<doc id="44116" url="https://en.wikipedia.org/wiki?curid=44116" title="Concerto">
Concerto

A concerto (from the , plural "concerti" or, often, the anglicised form "concertos") is a musical composition, whose characteristics have changed over time. In the 17th century, "sacred works for voices and orchestra were typically called concertos." J. S. Bach "was thus reflecting a long-standing tradition when he used the title `concerto' for many of the works that we know as cantatas.". But in recent centuries, up to the present, a concerto is a piece usually composed in three parts or movements, in which (usually) one solo instrument (for instance, a piano, violin, cello or flute) is accompanied by an orchestra or concert band.
The etymology is uncertain, but the word seems to have originated from the conjunction of the two Latin words "conserere" (meaning to tie, to join, to weave) and "certamen" (competition, fight): the idea is that the two parts in a concerto, the soloist and the orchestra or concert band, alternate episodes of opposition, cooperation, and independence in the creation of the music flow.
The concerto, as understood in this modern way, arose in the Baroque period side by side with the concerto grosso, which contrasted a small group of instruments called a concertino with the rest of the orchestra, called the ripieno. The popularity of the concerto grosso form declined after the Baroque period, and the genre was not revived until the 20th century. The solo concerto, however, has remained a vital musical force from its inception to this day.
Early Baroque concerto.
The term "concerto" was initially used to denote works involving voices and instruments in which the instruments had independent parts—as opposed to the Renaissance common practice in which the instruments that accompanied voices only doubled the voice parts. Examples of this earlier form of concerto include Giovanni Gabrieli's "In Ecclesiis" or Heinrich Schütz's "Saul, Saul, was verfolgst du mich."
Late Baroque concerto.
The concerto began to take its modern shape in the late Baroque period, beginning with the Concerto grosso form popularized by Arcangelo Corelli. Corelli's concertino group was two violins and a cello. In J. S. Bach's Fifth Brandenburg Concerto, for example, the concertino is a flute, a violin, and a harpsichord; the harpsichord sometimes plays with the ripieno.
Later the concerto approached its modern form in which the concertino usually reduces to a single solo instrument playing with/"against" an orchestra. The main composers of concerti of the baroque were Tommaso Albinoni, Antonio Vivaldi, Georg Philipp Telemann, Johann Sebastian Bach, George Frideric Handel, Pietro Locatelli, Giuseppe Tartini, Francesco Geminiani and Johann Joachim Quantz.
The concerto was intended as a composition typical of the Italian style of the time, and all the composers were studying how to compose in the Italian fashion (all'italiana).
The baroque concerto was mainly for a string instrument (violin, viola, cello, seldom viola d'amore or harp) or a wind instrument (oboe, trumpet, flute, or horn).
During the baroque period, before the invention of the piano, keyboard concertos were comparatively rare, with the exception of the organ and some harpsichord concertos by Johann Sebastian Bach. As the harpsichord evolved into the fortepiano, and in the end to the modern piano, the increased volume and the richer sound of the new instrument allowed the keyboard instrument to better compete with a full orchestra.
Cello concertos have been written since the Baroque era if not earlier. Among the works from that period, those by Antonio Vivaldi and Giuseppe Tartini are still part of the standard repertoire today.
Classical concerto.
The concerti of the sons of Johann Sebastian Bach, such as CPE Bach, are perhaps the best links between those of the Baroque period and those of the Classical era.
It is conventional to state that the first movements of concerti from the Classical period onwards follow the structure of sonata form. Final movements are often in rondo form, as in J.S. Bach's E Major Violin Concerto.
Violin concertos.
Mozart wrote five violin concertos, all in 1775. They show a number of influences, notably Italian and Austrian. Several passages have leanings towards folk music, as manifested in Austrian serenades.
Mozart also wrote the highly regarded Sinfonia Concertante for violin, viola, and orchestra.
Beethoven wrote only one violin concerto, under-appreciated until revealed as a masterpiece in a performance by violin virtuoso Joseph Joachim.
Cello concertos.
Haydn wrote at least two cello concertos (for cello, oboes, horns, and strings) which are the most important works in that genre of the classical era. However, C.P.E. Bach’s three cello concertos and Boccherini's are also noteworthy.
Keyboard concertos.
C.P.E. Bach’s keyboard concertos contain some brilliant soloistic writing. Some of them have movements that run into one another without a break, and there are frequent cross-movement thematic references.
Mozart, as a boy, made arrangements for keyboard and orchestra of four sonatas by now little-known composers. Then he arranged three sonata movements by Johann Christian Bach. By the time he was twenty, Mozart was able to write concerto ritornelli that gave the orchestra admirable opportunity for asserting its character in an exposition with some five or six sharply contrasted themes, before the soloist enters to elaborate on the material. Of his 27 piano concertos, those with numbers five on up are highly appreciated.
Haydn wrote a dozen keyboard concertos, although a couple of them are considered spurious.
Concertos for other instruments.
C.P.E. Bach wrote four flute concertos and two oboe concertos.
Bohemian composer Francesco Antonio Rosetti composed several solo and double horn concertos. He was a significant contributor to the genre of horn concertos in the 18th century. Most of his outstanding horn concertos were composed between 1782 and 1789 for the Bohemian duo Franz Zwierzina and Joseph Nage while at the Bavarian court of Oettingen-Wallerstein. One of his best known works in this genre is his Horn Concerto in E flat major C49/K III:36. It consists of three movements: 1. Allegro moderato 2. Romance 3. Rondo
Many common features of the Galant style are present in Rosetti’s music and composing style. In his E flat horn concerto, we hear periodic and short phrases, Galant harmonic rhythm and melodic line reduction. Rosetti’s influence on the 18th century composers, musicians and music was considerable. At the Bavarian court of Oettingen-Wallerstein, his music was often performed by the Wallerstein ensembles. In Paris, his compositions were performed by the best ensembles of the city, including the orchestra of the Concert Spirituel. His publishers were Le Menu et Boyer and Sieber. According to H. C. Robbins Landon (Mozart scholar), Rosetti’s horn concertos might have been a model for Mozart’s horn concertos.
Mozart wrote one concerto each for flute, oboe (later rearranged for flute and known as Flute Concerto No. 2), clarinet, and bassoon, four for horn, a Concerto for Flute, Harp, and Orchestra, and "Exsultate, jubilate", a "de facto" concerto for soprano voice. They all exploit and explore the characteristics of the solo instrument(s).
Haydn wrote an important trumpet concerto and a "Sinfonia Concertante" for violin, cello, oboe and bassoon as well as two horn concertos.
Romantic concerto.
Violin concertos.
In the 19th century the concerto as a vehicle for virtuosic display flourished as never before. It was the age in which the artist was seen as hero, to be worshipped with rapture. Early Romantic traits can be found in the violin concertos of Viotti, but it is Spohr’s twelve violin concertos, written between 1802 and 1827, that truly embrace the Romantic spirit with their melodic as well as their dramatic qualities.
Beethoven’s Violin Concerto is unique in its scale and melodic qualities. Recitative elements are often incorporated, showing the influence of Italian opera on purely instrumental forms.
Mendelssohn opens his violin concerto (1844) with the singing qualities of the violin solo. Even later passage work is dramatic and recitative-like, rather than merely virtuosic. The wind instruments state the lyrical second subject over a low pedal G on the violin – certainly an innovation. The cadenza, placed at the end of the development and acting as a link to the recapitulation, is fully written out and integrated into the structure.
The great violin virtuoso Niccolò Paganini was a legendary figure who, as a composer, exploited the technical potential of his instrument to its very limits. Each one exploits rhapsodic ideas but is unique in its own form. The Belgian violinist Henri Vieuxtemps, himself a major virtuoso, contributed several works to this form.
Édouard Lalo's "Symphonie espagnole" (1875) displays virtuoso writing with a Spanish flavor.
Max Bruch wrote three violin concertos, but it is the first, in G minor, that has remained a firm favorite in the repertoire. The opening movement relates so closely to the two remaining movements that it functions like an operatic prelude.
Tchaikovsky’s violin concerto (1878) is a powerful work which succeeds in being lyrical as well as superbly virtuosic.
In the same year Brahms wrote his violin concerto for the virtuoso Joseph Joachim. This work makes new demands on the player, so much so that when it was first written it was referred to as a "concerto against the violin". The first movement brings the concerto into the realm of symphonic development. The second movement is traditionally lyrical, and the finale is based on a lively Hungarian theme.
Cello concertos.
Since the Romantic era, the cello has received as much attention as the piano and violin as a concerto instrument, and many great Romantic and even more 20th-century composers left examples.
Antonín Dvořák’s cello concerto ranks among the supreme examples from the Romantic era while Robert Schumann's focuses on the lyrical qualities of the instrument. The instrument was also popular with composers of the Franco-Belgian tradition: Saint-Saëns and Vieuxtemps wrote two cello concertos each and Lalo and Jongen one. Elgar's popular concerto, while written in the early 20th century, belongs to the late romantic period stylistically.
Beethoven contributed to the repertoire with a "Triple Concerto" for piano, violin, cello and orchestra while later in the century, Brahms wrote a "Double Concerto" for violin, cello and orchestra.
Tchaikovsky’s contribution to the genre is a series of Variations on a Rococo Theme. He also left very fragmentary sketches of a projected Cello Concerto. Cellist Yuriy Leonovich and Tchaikovsky researcher Brett Langston published their completion of the piece in 2006.
Carl Reinecke, David Popper and Julius Klengel also wrote cello concertos that were popular in their time and are still played occasionally nowadays.
Today's 'core' repertoire which is performed the most of any cello concertos are by Elgar, Dvořák, Saint-Saëns, Haydn, Shostakovich and Schumann, but there are many more concertos which are performed nearly as often (see below: cello concertos in the 20th century).
Piano concertos.
Beethoven’s five piano concertos increase the technical demands made on the soloist. The last two are particularly remarkable, integrating the concerto into a large symphonic structure with movements that frequently run into one another. His Piano Concerto No. 4 starts, against tradition, with a statement by the piano, after which the orchestra enters in a foreign key, to present what would normally have been the opening tutti. The work has an essentially lyrical character. The slow movement is a dramatic dialogue between the soloist and the orchestra. His Piano Concerto No. 5 has the basic rhythm of a Viennese military march. There is no lyrical second subject, but in its place a continuous development of the opening material.
The piano concertos of Cramer, Field, Düssek, Woelfl, and Hummel provide a link from the Classical concerto to the Romantic concerto.
Chopin wrote two piano concertos in which the orchestra is very much relegated to an accompanying role. Schumann, despite being a pianist-composer, wrote a piano concerto in which virtuosity is never allowed to eclipse the essential lyrical quality of the work. The gentle, expressive melody heard at the beginning on woodwind and horns (after the piano’s heralding introductory chords) bears the material for most of the argument in the first movement. In fact, argument in the traditional developmental sense is replaced by a kind of variation technique in which soloist and orchestra interweave their ideas.
Liszt's mastery of piano technique matched that of Paganini for the violin. His concertos No. 1 and No. 2 left a deep impression on the style of piano concerto writing, influencing Rubinstein, and especially Tchaikovsky, whose first piano concerto's rich chordal opening is justly famous. Grieg’s concerto likewise begins in a striking manner after which it continues in a lyrical vein.
Brahms's First Piano Concerto in D minor (pub 1861) was the result of an immense amount of work on a mass of material originally intended for a symphony. His Second Piano Concerto in B major (1881) has four movements and is written on a larger scale than any earlier concerto. Like his violin concerto, it is symphonic in proportions.
Fewer piano concertos were written in the late Romantic Period. But Sergei Rachmaninoff wrote 4 piano concertos between 1891 and 1926. His 2nd and 3rd, being the most popular of the 4, went on to become among the most famous in piano repertoire.
Other romantic piano concertos, like those by Kalkbrenner, Henri Herz, Moscheles and Thalberg were also very popular in the Romantic era, but not today.
Small-scale works.
Besides the usual three-movement works with the title "concerto", many 19th-century composers wrote shorter pieces for solo instrument and orchestra, often bearing descriptive titles. From around 1800 such pieces were often called "Konzertstück" or "Phantasie" by German composers.
Liszt wrote the "Totentanz" for piano and orchestra, a paraphrase of the "Dies Irae". Max Bruch wrote a popular "Scottish Fantasy" for violin and orchestra, César Franck wrote "Les Djinns" and "Variations symphoniques", and Gabriel Fauré wrote a "Ballade" for piano and orchestra. Rachmaninoff's Rhapsody on a Theme of Paganini is widely considered to be structured similarly to a piano concerto.
Tchaikovsky's Variations on a Rococo Theme for cello and orchestra have an important place in the instrument's repertoire.
20th century.
Many of the concertos written in the early 20th century belong more to the late Romantic school than to any modernistic movement. Masterpieces were written by Edward Elgar (a violin concerto and a cello concerto), Sergei Rachmaninoff and Nikolai Medtner (four and three piano concertos, respectively), Jean Sibelius (a violin concerto), Frederick Delius (a violin concerto, a cello concerto, a piano concerto and a double concerto for violin and cello), Karol Szymanowski (two violin concertos and a "Symphonie Concertante" for piano), and Richard Strauss (two horn concertos, a violin concerto, "Don Quixote" —a tone poem which features the cello as a soloist— and among later works, an oboe concerto).
However, in the first decades of the 20th century, several composers such as Debussy, Schoenberg, Berg, Hindemith, Stravinsky, Prokofiev and Bartók started experimenting with ideas that were to have far-reaching consequences for the way music is written and, in some cases, performed. Some of these innovations include a more frequent use of modality, the exploration of non-western scales, the development of atonality, the wider acceptance of dissonances, the invention of the twelve-tone technique of composition and the use of polyrhythms and complex time signatures.
These changes also affected the concerto as a musical form. Beside more or less radical effects on musical language, they led to a redefinition of the concept of virtuosity in order to include new and extended instrumental techniques as well as a focus on aspects of sound that had been neglected or even ignored before such as pitch, timbre and dynamics. In some cases, they also brought about a new approach to the role of the soloist and its relation to the orchestra.
Violin concertos.
Two great innovators of early 20th-century music, Schoenberg and Stravinsky, both wrote violin concertos. The material in Schoenberg’s concerto, like that in Berg’s, is linked by the twelve-tone serial method. Bartók, another major 20th-century composer, wrote two important concertos for violin. Russian composers Prokofiev and Shostakovich both wrote two concertos while Khachaturian wrote a concerto and a Concerto-Rhapsody for the instrument. Hindemith’s concertos hark back to the forms of the 19th century, even if the harmonic language which he used was different.
Three violin concertos from David Diamond show the form in neoclassical style.
More recently, Dutilleux's "L'Arbre des Songes" has proved an important addition to the repertoire and a fine example of the composer's atonal yet melodic style.
Other composers of major violin concertos include Jean Sibelius, Ralph Vaughan Williams, Samuel Barber, Walton, Benjamin Britten, Frank Martin, Carl Nielsen, Paul Hindemith, Alfred Schnittke, György Ligeti, Philip Glass, Dmitri Shostakovich, Sergei Prokofiev, Aram Khachaturian, Béla Bartók and John Adams.
Cello concertos.
In the 20th century, particularly after the Second World War, the cello enjoyed an unprecedented popularity. As a result, its concertante repertoire caught up with those of the piano and the violin both in terms of quantity and quality.
An important factor in this phenomenon was the rise of virtuoso cellist Mstislav Rostropovich. His outstanding technique and passionate playing prompted dozens of composers to write pieces for him, first in his native Soviet Union and then abroad. His creations include such masterpieces as Sergei Prokofiev's Symphony-Concerto, Dmitri Shostakovich's two cello concertos, Benjamin Britten's Cello-Symphony (which emphasizes, as its title suggests, the equal importance of soloist and orchestra), Henri Dutilleux' "Tout un monde lointain...", Witold Lutosławski's cello concerto, Dmitry Kabalevsky's two cello concertos, Aram Khachaturian's "Concerto-Rhapsody", Arvo Pärt's "Pro et Contra", Alfred Schnittke, André Jolivet and Krzysztof Penderecki second cello concertos, Sofia Gubaidulina's "Canticles of the Sun", Luciano Berio's "Ritorno degli Snovidenia", Leonard Bernstein's "Three Meditations", James MacMillan's cello concerto and Olivier Messiaen's "Concert à quatre" (a quadruple concerto for cello, piano, oboe, flute and orchestra).
In addition, several important composers who were not directly influenced by Rostropovich wrote cello concertos: György Ligeti, Alexander Glazunov, Paul Hindemith, Toru Takemitsu, Darius Milhaud, Arthur Honegger, Nikolai Myaskovsky, Samuel Barber, Joaquín Rodrigo, Elliott Carter, Erich Wolfgang Korngold, William Walton, Heitor Villa-Lobos, Hans Werner Henze, Bernd Alois Zimmermann and Einojuhani Rautavaara for instance.
Piano concertos.
Igor Stravinsky wrote three works for solo piano and orchestra: Concerto for Piano and Wind Instruments, Capriccio for Piano and Orchestra, and Movements for Piano and Orchestra. Sergei Prokofiev, another Russian composer, wrote no less than five piano concertos which he himself performed. Dmitri Shostakovich composed two. Fellow soviet composer Aram Khachaturian contributed to the repertoire with a piano concerto and a Concerto-Rhapsody.
Arnold Schoenberg’s "Piano Concerto" is a well-known example of a dodecaphonic piano concerto.
Béla Bartók also wrote three piano concertos. Like their violin counterparts, they show the various stages in his musical development. Bartok's also rearranged his chamber piece, Sonata for Two Pianos and Percussion, into a "Concerto for Two Pianos and Percussion", adding orchestral accompaniment.
Ralph Vaughan Williams wrote a concerto for piano (in fact a reworking of a concerto for two pianos - both versions have been recorded) while Benjamin Britten's concerto for piano (1938) is a prominent work from his early period.
György Ligeti's concerto (1988) has a synthetic quality: it mixes complex rhythms, the composer's Hungarian roots and his experiments with micropolyphony from the 1960s and 70's. Witold Lutoslawski's piano concerto, completed in the same year, alternates between playfulness and mystery. It also displays a partial return to melody after the composer's aleatoric period.
Russian composer Rodion Shchedrin has written six piano concertos. Finnish composer Einojuhani Rautavaara wrote three piano concertos, the third one dedicated to Vladimir Ashkenazy, who played and conducted the world première.
Concertos for other instruments.
The 20th century also witnessed a growth of the concertante repertoire of instruments, some of which had seldom or never been used in this capacity. As a result, almost all classical instruments now have a concertante repertoire. Examples include:
Among the works of the prolific composer Alan Hovhaness may be noted "Prayer of St. Gregory" for trumpet and strings.
Today the concerto tradition has been continued by composers such as Maxwell Davies, whose series of Strathclyde Concertos exploit some of the instruments less familiar as soloists.
Concertos for orchestra or concert band.
In the 20th and 21st centuries, several composers wrote concertos for orchestra or concert band. In these works, different sections and/or instruments of the orchestra or concert band are treated at one point or another as soloists with emphasis on solo sections and/or instruments changing during the piece. Some examples include those written by:
Orchestra:
Dutilleux has also described his "Métaboles" as a concerto for orchestra, while Britten's well-known pedagogical work "The Young Person's Guide to the Orchestra" is essentially a concerto for orchestra in all but name.
Concert band:
Concertos for two or more instruments.
Many composers also wrote concertos for two or more soloists.
In the Baroque era:
In the Classical era:
In the Romantic era:
In the 20th century:
In the 21st century:

</doc>
<doc id="44118" url="https://en.wikipedia.org/wiki?curid=44118" title="Sonata">
Sonata

Sonata (; Italian: , pl. "sonate"; from Latin and Italian: "sonare", "to sound"), in music, literally means a piece "played" as opposed to a cantata (Latin and Italian "cantare", "to sing"), a piece "sung". The term evolved through the history of music, designating a variety of forms until the Classical era, when it took on increasing importance, and is vague. By the early 19th century it came to represent a principle of composing large-scale works. It was applied to most instrumental genres and regarded—alongside the fugue—as one of two fundamental methods of organizing, interpreting and analyzing concert music. Though the musical style of sonatas has changed since the Classical era, most 20th- and 21st-century sonatas still maintain the same structure.
The term sonatina, pl. "sonatine", the diminutive form of sonata, is often used for a short or technically easy sonata.
Instrumentation.
In the Baroque period, a sonata was for one or more instruments almost always with continuo. After the Baroque period most works designated as sonatas specifically are performed by a solo instrument, most often a keyboard instrument, or by a solo instrument accompanied by a keyboard instrument.
Sonatas for a solo instrument other than keyboard have been composed, as have sonatas for other combinations of instruments.
Brief history of the usage of sonata.
The Baroque sonata.
In the works of Arcangelo Corelli and his contemporaries, two broad classes of sonata were established, and were first described by Sébastien de Brossard in his "Dictionaire de musique" (third edition, Amsterdam, ca. 1710): the sonata da chiesa (that is, suitable for use in church), which was the type "rightly known as "Sonatas"", and the sonata da camera (proper for use at court), which consists of a prelude followed by a succession of dances, all in the same key. Although the four, five, or six movements of the sonata da chiesa are also most often in one key, one or two of the internal movements are sometimes in a contrasting tonality .
The sonata da chiesa, generally for one or more violins and bass, consisted normally of a slow introduction, a loosely fugued allegro, a slow movement, and a lively finale in some binary form suggesting affinity with the dance-tunes of the suite. This scheme, however, was not very clearly defined, until the works of Arcangelo Corelli when it became the essential sonata and persisted as a tradition of Italian violin music.
The sonata da camera consisted almost entirely of idealized dance-tunes. On the other hand, the features of "sonata da chiesa" and "sonata da camera" then tended to be freely intermixed. Although nearly half of Bach's 1,100 surviving compositions, arrangements, and transcriptions are instrumental works, only about 4% are sonatas .
The term "sonata" is also applied to the series of over 500 works for harpsichord solo, or sometimes for other keyboard instruments, by Domenico Scarlatti, originally published under the name "Essercizi per il gravicembalo" (Exercises for the Harpsichord). Most of these pieces are in one binary-form movement only, with two parts that are in the same tempo and use the same thematic material, though occasionally there will be changes in tempo within the sections. They are frequently virtuosic, and use more distant harmonic transitions and modulations than were common for other works of the time. They were admired for their great variety and invention.
Both the solo and trio sonatas of Vivaldi show parallels with the concerti he was writing at the same time. He composed over 70 sonatas, the great majority of which are of the solo type; most of the rest are trio sonatas, and a very small number are of the multivoice type .
The sonatas of Domenico Paradies are mild and elongated works with a graceful and melodious little second movement included.
The sonata in the Classical period.
The practice of the Classical period would become decisive for the sonata; the term moved from being one of many terms indicating genres or forms, to designating the fundamental form of organization for large-scale works. This evolution stretched over fifty years. The term came to apply both to the structure of individual movements (see Sonata form and History of sonata form) and to the layout of the movements in a multi-movement work. In the transition to the Classical period there were several names given to multimovement works, including divertimento, serenade, and partita, many of which are now regarded effectively as sonatas. The usage of "sonata" as the standard term for such works began somewhere in the 1770s. Haydn labels his first piano sonata as such in 1771, after which the term "divertimento" is used sparingly in his output. The term "sonata" was increasingly applied to either a work for keyboard alone (see piano sonata), or for keyboard and one other instrument, often the violin or cello. It was less and less frequently applied to works with more than two instrumentalists; for example piano trios were not often labelled "sonata for piano, violin, and cello."
Initially the most common layout of movements was:
However, two-movement layouts also occur, a practice Haydn uses as late as the 1790s. There was also in the early Classical period the possibility of using four movements, with a dance movement inserted before the slow movement, as in Haydn's Piano sonatas No. 6 and No. 8. Mozart's sonatas were also primarily in three movements. Of the works that Haydn labelled "piano sonata", "divertimento", or "partita" in Hob XIV, seven are in two movements, thirty-five are in three, and three are in four; and there are several in three or four movements whose authenticity is listed as "doubtful." Composers such as Boccherini would publish sonatas for piano and obbligato instrument with an optional third movement—–in Boccherini's case, 28 cello sonatas.
But increasingly instrumental works were laid out in four, not three movements, a practice seen first in string quartets and symphonies, and reaching the sonata proper in the early sonatas of Beethoven. However, two- and three-movement sonatas continued to be written throughout the Classical period: Beethoven's opus 102 pair has a two-movement C major sonata and a three-movement D major sonata. Nevertheless, works with fewer or more than four movements were increasingly felt to be exceptions; they were labelled as having movements "omitted," or had "extra" movements.
Thus, the four-movement layout was by this point standard for the string quartet, and overwhelmingly the most common for the symphony. The usual order of the four movements was:
When movements appeared out of this order they would be described as "reversed", such as the scherzo coming before the slow movement in Beethoven's 9th Symphony. This usage would be noted by critics in the early 19th century, and it was codified into teaching soon thereafter.
It is difficult to overstate the importance of Beethoven's output of sonatas: 32 piano sonatas, plus sonatas for cello and piano or violin and piano, forming a large body of music that would over time increasingly be thought essential for any serious instrumentalist to master.
The sonata in the Romantic period.
In the early 19th century the current usage of the term "sonata" was established, both as regards form "per se", and in the sense that a fully elaborated sonata serves as a norm for concert music in general, which other forms are seen in relation to. From this point forward, the word "sonata" in music theory labels as much the abstract musical form as particular works. Hence there are references to a symphony as a "sonata for orchestra". This is referred to by William Newman as the "sonata idea".
Among works expressly labeled "sonata" for the piano, there are the three of Frédéric Chopin, those of Felix Mendelssohn, the three of Robert Schumann, Franz Liszt's Sonata in B Minor, and later the sonatas of Johannes Brahms and Sergei Rachmaninoff.
In the early 19th century the sonata form was defined, from a combination of previous practice and the works of important Classical composers, particularly Haydn, Mozart, Beethoven, but composers such as Clementi also. It is during this period that the differences between the three- and the four-movement layouts became a subject of commentary, with emphasis on the concerto being laid out in three movements, and the symphony in four.
Ernest Newman wrote in the essay "Brahms and the Serpent":
The sonata after the Romantic period.
The role of the sonata as an extremely important form of extended musical argument would inspire composers such as Hindemith, Prokofiev, Shostakovich to compose in sonata form, and works with traditional sonata structures continue to be composed and performed.
The sonata in scholarship and musicology.
The sonata idea or principle.
Research into the practice and meaning of sonata form, style, and structure has been the motivation for important theoretical works by Heinrich Schenker, Arnold Schoenberg, and Charles Rosen among others; and the pedagogy of music continued to rest on an understanding and application of the rules of sonata form as almost two centuries of development in practice and theory had codified it.
The development of the classical style and its norms of composition formed the basis for much of the music theory of the 19th and 20th centuries. As an overarching formal principle, sonata was accorded the same central status as Baroque fugue; generations of composers, instrumentalists, and audiences were guided by this understanding of sonata as an enduring and dominant principle in Western music. The sonata idea begins before the term had taken on its present importance, along with the evolution of the Classical period's changing norms. The reasons for these changes, and how they relate to the evolving sense of a new formal order in music, is a matter to which research is devoted. Some common factors which were pointed to include: the shift of focus from vocal music to instrumental music; changes in performance practice, including the loss of the continuo .
Crucial to most interpretations of the sonata form is the idea of a tonal center; and, as the "Grove Concise Dictionary of Music" puts it: "The main form of the group embodying the 'sonata principle', the most important principle of musical structure from the Classical period to the 20th century: that material first stated in a complementary key be restated in the home key" (, ).
The sonata idea has been thoroughly explored by William Newman in his monumental three-volume work "Sonata in the Classic Era (A History of the Sonata Idea)", begun in the 1950s and published in what has become the standard edition of all three volumes in 1972.
20th-century theory.
Heinrich Schenker argued that there was an "Urlinie" or basic tonal melody, and a basic bass figuration. He held that when these two were present, there was basic structure, and that the sonata represented this basic structure in a whole work with a process known as "interruption" .
As a practical matter, Schenker applied his ideas to the editing of the piano sonatas of Beethoven, using original manuscripts and his own theories to "correct" the available sources. The basic procedure was the use of tonal theory to infer meaning from available sources as part of the critical process, even to the extent of completing works left unfinished by their composers. While many of these changes were and are controversial, that procedure has a central role today in music theory, and is an essential part of the theory of sonata structure as taught in most music schools.

</doc>
<doc id="44120" url="https://en.wikipedia.org/wiki?curid=44120" title="Jelly Roll Morton">
Jelly Roll Morton

Ferdinand Joseph LaMothe (October 20, 1890 – July 10, 1941), known professionally as Jelly Roll Morton, was an American ragtime and early jazz pianist, bandleader and composer who started his career in New Orleans, Louisiana.
Widely recognized as a pivotal figure in early jazz, Morton is perhaps most notable as jazz's first arranger, proving that a genre rooted in improvisation could retain its essential spirit and characteristics when notated. His composition "Jelly Roll Blues" was the first published jazz composition, in 1915. Morton is also notable for writing such standards as "King Porter Stomp", "Wolverine Blues", "Black Bottom Stomp", and "I Thought I Heard Buddy Bolden Say", the last a tribute to New Orleans musicians from the turn of the 20th century.
Notorious for his arrogance and self-promotion as often as recognized in his day for his musical talents, Morton claimed to have invented jazz outright in 1902—much to the derision of later musicians and critics. The jazz historian, musician, and composer Gunther Schuller says of Morton's "hyperbolic assertions" that there is "no proof to the contrary" and that Morton's "considerable accomplishments in themselves provide reasonable substantiation". However, the scholar Katy Martin has argued that Morton's bragging was exaggerated by Alan Lomax in the book "Mister Jelly Roll", and this portrayal has influenced public opinion and scholarship on Morton since.
Biography.
Early life and education.
Morton was born into a creole of color family in the Faubourg Marigny neighborhood of downtown New Orleans, Louisiana. Sources differ as to his birth date: a baptismal certificate issued in 1894 lists his date of birth as October 20, 1890; Morton and his half-sisters claimed he was born on September 20, 1885. His World War I draft registration card showed September 13, 1884, but his California death certificate listed his birth as September 20, 1889. He was born to F. P. Lamothe and Louise Monette (written as Lemott and Monett on his baptismal certificate). Eulaley Haco (Eulalie Hécaud) was the godparent. Hécaud helped choose his christening name of Ferdinand. His parents lived in a common-law marriage and were not legally married. No birth certificate has been found to date.
Ferdinand started playing music as a child, showing early talent. After his parents separated, his mother married a man named Mouton. Ferdinand took his stepfather's name and anglicized it as "Morton."
Musical career.
At the age of fourteen, Morton began working as a piano player in a brothel (or, as it was referred to then, a sporting house). In that atmosphere, he often sang smutty lyrics; he took the nickname "Jelly Roll", which was African American slang for female genitalia. While working there, he was living with his religious, church-going great-grandmother; he had her convinced that he worked as a night watchman in a barrel factory.
After Morton's grandmother found out that he was playing jazz in a local brothel, she kicked him out of her house. He said:
When my grandmother found out that I was playing jazz in one of the sporting houses in the District, she told me that I had disgraced the family and forbade me to live at the house... She told me that devil music would surely bring about my downfall, but I just couldn't put it behind me. Cornetist Rex Stewart recalled that Morton had chosen "the nom de plume 'Morton' to protect his family from disgrace if he was identified as a whorehouse 'professor'."
Tony Jackson, also a pianist at brothels and an accomplished guitar player, was a major influence on Morton's music. Jelly Roll said that Jackson was the only pianist better than he was.
Touring.
Around 1904, Morton also started touring in the American South, working with minstrel shows, gambling and composing. His works "Jelly Roll Blues", "New Orleans Blues", "Frog-I-More Rag", "Animule Dance", and "King Porter Stomp" were composed during this period. He got to Chicago in 1910 and New York City in 1911, where future stride greats James P. Johnson and Willie "The Lion" Smith caught his act, years before the blues were widely played in the North.
In 1912–1914, Morton toured with his girlfriend Rosa Brown as a vaudeville act before settling in Chicago for three years. By 1914, he had started writing down his compositions. In 1915, his "Jelly Roll Blues" was arguably the first jazz composition ever published, recording as sheet music the New Orleans traditions that had been jealously guarded by the musicians. In 1917, he followed bandleader William Manuel Johnson and Johnson's sister Anita Gonzalez to California, where Morton's tango, "The Crave", made a sensation in Hollywood.
Vancouver.
Morton was invited to play a new Vancouver, British Columbia, nightclub called The Patricia, on East Hastings Street. The jazz historian Mark Miller described his arrival as "an extended period of itinerancy as a pianist, vaudeville performer, gambler, hustler, and, as legend would have it, pimp".
Chicago.
Morton returned to Chicago in 1923 to claim authorship of his recently published rag, "The Wolverines", which had become a hit as "Wolverine Blues" in the Windy City. He released the first of his commercial recordings, first as piano rolls, then on record, both as a piano soloist and with various jazz bands.
In 1926, Morton succeeded in getting a contract to record for the largest and most prestigious company in the United States, the Victor Talking Machine Company. This gave him a chance to bring a well-rehearsed band to play his arrangements in Victor's Chicago recording studios. These recordings by "Jelly Roll Morton & His Red Hot Peppers" are regarded as classics of 1920s jazz. The Red Hot Peppers featured such other New Orleans jazz luminaries as Kid Ory, Omer Simeon, George Mitchell, Johnny St. Cyr, Barney Bigard, Johnny Dodds, Baby Dodds, and Andrew Hilaire. Jelly Roll Morton & His Red Hot Peppers were one of the first acts booked on tours by MCA.
Marriage and family.
In November 1928, Morton married the showgirl Mabel Bertrand in Gary, Indiana.
New York City.
They moved that year to New York City, where Morton continued to record for Victor. His piano solos and trio recordings are well regarded, but his band recordings suffer in comparison with the Chicago sides, where Morton could draw on many great New Orleans musicians for sidemen. Although he recorded with the noted musicians clarinetists Omer Simeon, George Baquet, Albert Nicholas, Wilton Crawley, Barney Bigard, Russell Procope, Lorenzo Tio and Artie Shaw, trumpeters Bubber Miley, Johnny Dunn and Henry "Red" Allen, saxophonists Sidney Bechet, Paul Barnes and Bud Freeman, bassist Pops Foster, and drummers Paul Barbarin, Cozy Cole and Zutty Singleton, Morton generally had trouble finding musicians who wanted to play his style of jazz. His New York sessions failed to produce a hit.
With the Great Depression and the near collapse of the record industry, RCA Victor did not renew Morton's recording contract for 1931. Morton continued playing in New York, but struggled financially. He briefly had a radio show in 1934, then took on touring in the band of a traveling burlesque act for some steady income. In 1935, Morton's 30-year-old composition King Porter Stomp, as arranged by Fletcher Henderson, became Benny Goodman's first hit and a swing standard, but Morton received no royalties from its recordings.
Washington, D.C..
In 1935, Morton moved to Washington, D.C., to become the manager/piano player of a bar called, at various times, the "Music Box", "Blue Moon Inn", and "Jungle Inn" in the African-American neighborhood of Shaw. (The building that hosted the nightclub stands at 1211 U Street NW.) Morton was also the master of ceremonies, bouncer, and bartender of the club. He lived in Washington for a few years; the club owner allowed all her friends free admission and drinks, which prevented Morton from making the business a success.
In 1938, Morton was stabbed by a friend of the owner and suffered wounds to the head and chest. After this incident, his wife Mabel demanded that they leave Washington.
During Morton's brief residency at the Music Box, the folklorist Alan Lomax heard the pianist playing in the bar. In May 1938, Lomax invited Morton to record music and interviews for the Library of Congress. The sessions, originally intended as a short interview with musical examples for use by music researchers in the Library of Congress, soon expanded to record more than eight hours of Morton talking and playing piano. Lomax also conducted longer interviews during which he took notes but did not record. Despite the low fidelity of these non-commercial recordings, their musical and historical importance have attracted numerous jazz fans, and they have helped to ensure Morton's place in jazz history.
Lomax was very interested in Morton's Storyville days in New Orleans and the ribald songs of the time. Although reluctant to recount and record these, Morton eventually obliged Lomax. Because of the suggestive nature of the songs, some of the Library of Congress recordings were not released until 2005.
In his interviews, Morton claimed to have been born in 1885. He was aware that if he had been born in 1890, he would have been slightly too young to make a good case as the inventor of jazz. He said in the interview that Buddy Bolden played ragtime but not jazz; this is not accepted by the consensus of Bolden's other New Orleans contemporaries. The contradictions may stem from different definitions for the terms "ragtime" and "jazz". These interviews, released in different forms over the years, were released on an eight-CD boxed set in 2005, "The Complete Library of Congress Recordings". This collection won two Grammy Awards. The same year, Morton was honored with the Grammy Lifetime Achievement Award.
Later years.
When Morton was stabbed and wounded, a nearby whites-only hospital refused to treat him, as the city had racially segregated facilities. He was transported to a black hospital farther away. When he was in the hospital, the doctors left ice on his wounds for several hours before attending to his eventually fatal injury. His recovery from his wounds was incomplete, and thereafter he was often ill and easily became short of breath. Morton made a new series of commercial recordings in New York, several recounting tunes from his early years that he discussed in his Library of Congress interviews.
Worsening asthma sent him to a New York hospital for three months at one point. He continued to suffer from respiratory problems when visiting Los Angeles with a series of manuscripts of new tunes and arrangements, planning to form a new band and restart his career. Morton died on July 10, 1941, after an eleven-day stay in Los Angeles County General Hospital.
According to the jazz historian David Gelly in 2000, Morton's arrogance and "bumptious" persona alienated so many musicians over the years that no colleagues or admirers attended his funeral. But, a contemporary news account of the funeral in the August 1, 1941, issue of "Downbeat" says that fellow musicians Kid Ory, Mutt Carey, Fred Washington and Ed Garland were among his pall bearers. The story notes the absence of Duke Ellington and Jimmie Lunceford, both of whom were appearing in Los Angeles at the time. (The article is reproduced in Alan Lomax's biography of Morton, "Mister Jelly Roll", University of California Press, 1950.)
Piano style.
Morton's piano style was formed from early secondary ragtime and "shout", which also evolved separately into the New York school of stride piano. Morton's playing was also close to barrelhouse, which produced boogie woogie.
Morton often played the melody of a tune with his right thumb, while sounding a harmony above these notes with other fingers of the right hand. This added a rustic or "out-of-tune" sound (due to the playing of a diminished 5th above the melody). This may still be recognized as belonging to New Orleans. Morton also walked in major and minor sixths in the bass, instead of tenths or octaves. He played basic swing rhythms in both the left and right hand.
Compositions.
Some of Morton's songs (listed alphabetically):
Several of Morton's compositions were musical tributes to himself, including "Winin' Boy", "The Jelly Roll Blues", subtitled "The Original Jelly-Roll"; and "Mr. Jelly Lord". In the Big Band era, his "King Porter Stomp", which Morton had written decades earlier, was a big hit for Fletcher Henderson and Benny Goodman; it became a standard covered by most other swing bands of that time. Morton claimed to have written some tunes that were copyrighted by others, including "Alabama Bound" and "Tiger Rag". "Sweet Peter," which Morton recorded in 1926, appears to be the source for the melody of the hit song "All Of Me," ostensibly written by Gerald Marks and Seymour Simons in 1931.
His musical influence continues in the work of Dick Hyman and Reginald Robinson.

</doc>
<doc id="44122" url="https://en.wikipedia.org/wiki?curid=44122" title="American Beauty (1999 film)">
American Beauty (1999 film)

American Beauty is a 1999 American drama film directed by Sam Mendes and written by Alan Ball. Kevin Spacey stars as Lester Burnham, a 42-year-old advertising executive who has a midlife crisis when he becomes infatuated with his teenage daughter's best friend, Angela (Mena Suvari). Annette Bening co-stars as Lester's materialistic wife, Carolyn, and Thora Birch plays their insecure daughter, Jane. Wes Bentley, Chris Cooper and Allison Janney also feature. The film is described by academics as a satire of American middle class notions of beauty and personal satisfaction; analysis has focused on the film's explorations of romantic, and paternal love, sexuality, beauty, materialism, self-liberation and redemption.
Ball began writing "American Beauty" as a play in the early 1990s, partly inspired by the media circus around the Amy Fisher trial in 1992. He shelved the play after realizing the story would not work on stage. After several years as a television screenwriter, Ball revived the idea in 1997 when attempting to break into the film industry. The modified script had a cynical outlook that was influenced by Ball's frustrating tenures writing for several sitcoms. Producers Dan Jinks and Bruce Cohen took "American Beauty" to DreamWorks; the then-fledgling film studio bought Ball's script for $250,000, outbidding several other production bodies. DreamWorks financed the $15 million production and served as its North American distributor. "American Beauty" marked acclaimed theater director Mendes' film debut; courted after his successful productions of the musicals "Oliver!" and "Cabaret", Mendes was nevertheless only given the job after twenty others were considered and several "A-list" directors turned down the opportunity.
Spacey was Mendes' first choice for the role of Lester, even though DreamWorks had urged the director to consider better-known actors; similarly, the studio suggested several actors for the role of Carolyn until Mendes offered the part to Bening without DreamWorks' knowledge. Principal photography took place between December 1998 and February 1999 on soundstages at the Warner Bros. backlot in Burbank, California and on location in Los Angeles. Mendes' dominant style was deliberate and composed; he made extensive use of static shots and slow pans and zooms to generate tension. Cinematographer Conrad Hall complemented Mendes' style with peaceful shot compositions to contrast with the turbulent on-screen events. During editing, Mendes made several changes that gave the film a less cynical tone than the script.
Released in North America on September 17, 1999, "American Beauty" was positively received by critics and audiences; it was the best-reviewed American film of the year and grossed over $356 million worldwide. Reviewers praised most aspects of the production, with particular emphasis on Mendes, Spacey and Ball; criticism focused on the familiarity of the characters and setting. DreamWorks launched a major campaign to increase the film's chances of Academy Award success; at the 72nd Academy Awards the following year, the film won Best Picture, Best Director, Best Actor (for Spacey), Best Original Screenplay and Best Cinematography. It was nominated for and won many other awards and honors, mainly for the direction, writing and acting.
Plot.
Lester Burnham is a middle-aged magazine writer and advertising executive who despises his job. His wife, Carolyn, is an ambitious real estate broker; their sixteen-year-old daughter, Jane, abhors her parents and has low self-esteem. The Burnhams' new neighbors are retired United States Marine Corps Colonel Frank Fitts and his introverted wife, Barbara. Their teenage son, Ricky, obsessively films his surroundings with a camcorder, collecting hundreds of recordings on video tapes in his bedroom. His job as a part-time bar caterer serves as a front for his secret marijuana dealing. Having been previously forced into a military academy and a psychiatric hospital, Ricky is subjected by Col. Fitts to a strict disciplinarian lifestyle. Jim Olmeyer and Jim Berkley, a gay couple who live nearby, welcome the family to the neighborhood; Col. Fitts later reveals his homophobia when angrily discussing the incident with Ricky.
Lester becomes fixated with Jane's vain cheerleader friend, Angela Hayes, after seeing her perform a half-time dance routine at a high school basketball game. He starts having sexual fantasies about Angela, during which red rose petals are a recurring motif. Carolyn begins an affair with her business rival, Buddy Kane. When Lester's boss and efficiency expert Brad tells him that he is to be laid off, Lester instead blackmails him for $60,000 and quits his job. Lester continues his liberation by taking employment serving fast food, trading in his Toyota Camry for his dream car, a 1970 Pontiac Firebird, and starts working out after he overhears Angela tell Jane that she would find him sexually attractive if he improved his physique. He begins smoking marijuana supplied by Ricky, and flirts with Angela whenever she visits Jane. The girls' friendship wanes after Jane becomes involved with Ricky; they bond over what Ricky considers the most beautiful imagery he has filmed: a plastic bag being blown in the wind.
Lester discovers Carolyn's infidelity, but reacts indifferently. Buddy ends the affair, fearing an expensive divorce. Col. Fitts becomes suspicious of Lester and Ricky's friendship when he finds his son's footage of Lester lifting weights while nude, which Ricky captured by chance, leading him to believe that Ricky is gay. After spying on Ricky and Lester through Lester's garage window, the colonel mistakenly concludes the pair are sexually involved. He later confronts and beats Ricky for the affair and accuses him of being gay. Ricky falsely admits the charges and goads his father into kicking him out of their home. Carolyn is sitting in her car in the rain, she takes a gun out of the glove box while a voice on the radio talks about not being a victim. Ricky goes to Jane's bedroom, finding her arguing with Angela about Angela's flirtation with Lester. Ricky convinces Jane to flee with him to New York City and assures Angela that she is ugly, boring and ordinary.
Col. Fitts confronts Lester and attempts to kiss him; Lester rebuffs the colonel, who tearfully flees. Carolyn puts the gun in her handbag shouting "I refuse to be a victim!" Lester finds a distraught Angela sitting alone in the dark; she asks him to tell her she is beautiful. He does, and he begins to seduce her.
Carolyn drives through the rain, rehearsing a confession to Lester. As Lester strokes Angela she admits that she is a virgin, and Lester changes his mind. He instead comforts her and the pair bond over their shared frustrations. Angela goes to the bathroom and Lester smiles at a family photograph in his kitchen. An unseen figure raises a gun to the back of his head, a gunshot sounds and blood sprays on the wall. Ricky and Jane find Lester's body, while Carolyn breaks down crying in the closet. A bloodied Col. Fitts returns home, where a gun is shown to be missing from his collection. Lester's closing narration describes meaningful experiences during his life; he says that, despite his death, he is happy because there is so much beauty in the world.
Themes and analysis.
Multiple interpretations.
Scholars and academics have offered many possible readings of "American Beauty"; film critics are similarly divided, not so much about the quality of the film as their interpretations of it. Described by many as about "the meaning of life" or "the hollow existence of the American suburbs", the film has defied categorization by even the filmmakers. Mendes is indecisive, saying the script seemed to be about something different each time he read it: "a mystery story, a kaleidoscopic journey through American suburbia, a series of love stories; [...] it was about imprisonment, [...] loneliness beauty. It was funny; it was angry, sad." The literary critic and author Wayne C. Booth concludes that the film resists any one interpretation: "["American Beauty" cannot be adequately summarized as 'here is a satire on what's wrong with American life'; that plays down the celebration of beauty. It is more tempting to summarize it as 'a portrait of the beauty underlying American miseries and misdeeds'; but that plays down the scenes of cruelty and horror, and Ball's disgust with our mores. It cannot be summarized with either Lester's or Ricky's philosophical statements about what life is or how one should live." He argues that the problem of interpreting the film is tied with that of finding its center—a controlling voice who " all of the choices". He contends that in "American Beauty"s case it is neither Mendes nor Ball. Mendes considers the voice to be Ball's, but even while the writer was "strongly influential" on set, he often had to accept deviations from his vision, particularly ones that transformed the cynical tone of his script into something more optimistic. With "innumerable voices intruding on the original author's," Booth says, those who interpret "American Beauty" "have forgotten to probe for the elusive center". According to Booth, the film's true controller is the creative energy "that hundreds of people put into its production, agreeing and disagreeing, inserting and cutting".
Imprisonment and redemption.
Mendes called "American Beauty" a rite of passage film about imprisonment and escape from imprisonment. The monotony of Lester's existence is established through his gray, nondescript workplace and characterless clothing. In these scenes, he is often framed as if trapped, "reiterating rituals that hardly please him". He masturbates in the confines of his shower; the shower stall evokes a jail cell and the shot is the first of many where Lester is confined behind bars or within frames, such as when he is reflected behind columns of numbers on a computer monitor, "confined nearly crossed out". The academic and author Jody W. Pennington argues that Lester's journey is the story's center. His sexual reawakening through meeting Angela is the first of several turning points as he begins to "[throw off the responsibilities of the comfortable life he has come to despise". After Lester shares a joint with Ricky, his spirit is released and he begins to rebel against Carolyn. Changed by Ricky's "attractive, profound confidence", Lester is convinced that Angela is attainable and sees that he must question his "banal, numbingly materialist suburban existence"; he takes a job at a fast-food outlet, which allows him to regress to a point when he could "see his whole life ahead of him".
When Lester is caught masturbating by Carolyn, his angry retort about their lack of intimacy is the first time he says aloud what he thinks about her. By confronting the issue and Carolyn's "superficial investments in others", Lester is trying to "regain a voice in a home that respects the voices of mother and daughter". His final turning point comes when he and Angela almost have sex; after she confesses her virginity, he no longer thinks of her as a sex object, but as a daughter. He holds her close and "wraps her up". Mendes called it "the most satisfying end to [Lester's] journey there could possibly have been". With these final scenes, Mendes intended to show Lester at the conclusion of a "mythical quest". After Lester gets a beer from the refrigerator, the camera pushes toward him, then stops facing a hallway down which he walks "to meet his fate". Having begun to act his age again, Lester achieves closure. As he smiles at a family photo, the camera pans slowly from Lester to the kitchen wall, onto which blood spatters as a gunshot rings out; the slow pan reflects the peace of Lester's death. His body is discovered by Jane and Ricky. Mendes said that Ricky's staring into Lester's dead eyes is "the culmination of the theme" of the film: that beauty is found where it is least expected.
Conformity and beauty.
Like other American films of 1999—such as "Fight Club", "Bringing Out the Dead" and "Magnolia"—"American Beauty" instructs its audience to "more meaningful lives". The film argues the case against conformity, but does not deny that people need and want it; even the gay characters just want to fit in. Jim and Jim, the Burnhams' other neighbors, are a satire of "gay bourgeois coupledom", who "in the numbing sameness" that the film criticizes in heterosexual couples. The feminist academic and author Sally R. Munt argues that "American Beauty" uses its "art house" trappings to direct its message of non-conformity primarily to the middle classes, and that this approach is a "cliché of bourgeois preoccupation; [... the underlying premise being that the luxury of finding an individual 'self' through denial and renunciation is always open to those wealthy enough to choose, and sly enough to present themselves sympathetically as a rebel."
Professor Roy M. Anker argues that the film's thematic center is its direction to the audience to "look closer". The opening combines an unfamiliar viewpoint of the Burnhams' neighborhood with Lester's narrated admission that he will soon die, forcing audiences to consider their own mortality and the beauty around them. It also sets a series of mysteries; Anker asks, "from what place exactly, and from what state of being, is he telling this story? If he's already dead, why bother with whatever it is he wishes to tell about his last year of being alive? There is also the question of how Lester has died—or will die." Anker believes the preceding scene—Jane's discussion with Ricky about the possibility of his killing her father—adds further mystery. Professor Ann C. Hall disagrees; she says by presenting an early resolution to the mystery, the film allows the audience to put it aside "to view the film and its philosophical issues". Through this examination of Lester's life, rebirth and death, "American Beauty" satirizes American middle class notions of meaning, beauty and satisfaction. Even Lester's transformation only comes about because of the possibility of sex with Angela; he therefore remains a "willing devotee of the popular media's exaltation of pubescent male sexuality as a sensible route to personal wholeness". Carolyn is similarly driven by conventional views of happiness; from her belief in "house beautiful" domestic bliss to her car and gardening outfit, Carolyn's domain is a "fetching American millennial vision of Pleasantville, or Eden". The Burnhams are unaware that they are "materialists philosophically, and devout consumers ethically" who expect the "rudiments of American beauty" to give them happiness. Anker argues that "they are helpless in the face of the prettified economic and sexual stereotypes [...] that they and their culture have designated for their salvation."
The film presents Ricky as its "visionary, [...] spiritual and mystical center". He sees beauty in the minutiae of everyday life, videoing as much as he can for fear of missing it. He shows Jane what he considers the most beautiful thing he has filmed: a plastic bag, tossing in the wind in front of a wall. He says capturing the moment was when he realized that there was "an entire life behind things"; he feels that "sometimes there's so much beauty in the world I feel like I can't take it... and my heart is going to cave in." Anker argues that Ricky, in looking past the "cultural dross", has " the radiant splendor of the created world" to see God. As the film progresses, the Burnhams move closer to Ricky's view of the world. Lester only forswears personal satisfaction at the film's end. On the cusp of having sex with Angela, he returns to himself after she admits her virginity. Suddenly confronted with a child, he begins to treat her as a daughter; in doing so Lester sees himself, Angela and his family "for the poor and fragile but wondrous creatures they are". He looks at a picture of his family in happier times, and dies having had an epiphany that infuses him with "wonder, joy, and soul-shaking gratitude"—he has finally seen the world as it is.
According to Patti Bellantoni, colors are used symbolically throughout the film, none more so than red, which is an important thematic signature that drives the story and "Lester's arc". First seen in drab colors that reflect his passivity, Lester surrounds himself with red as he regains his individuality. The American Beauty rose is repeatedly used as symbol; when Lester fantasizes about Angela, she is usually naked and surrounded by rose petals. In these scenes, the rose symbolizes Lester's desire for her. When associated with Carolyn, the rose represents a "façade for suburban success". Roses are included in almost every shot inside the Burnhams' home, where they signify "a mask covering a bleak, unbeautiful reality". Carolyn feels that "as long as there can be roses, all is well". She cuts the roses and puts them in vases, where they adorn her "meretricious vision of what makes for beauty" and begin to die. The roses in the vase in the Angela–Lester seduction scene symbolize Lester's previous life and Carolyn; the camera pushes in as Lester and Angela get closer, finally taking the roses—and thus Carolyn—out of the shot. Lester's epiphany at the end of the film is expressed via rain and the use of red, building to a crescendo that is a deliberate contrast to the release Lester feels. The constant use of red "lulls [the audience subliminally" into becoming used to it; consequently, it leaves the audience unprepared when Lester is shot and his blood spatters on the wall.
Sexuality and repression.
Pennington argues that "American Beauty" defines its characters through their sexuality. Lester's attempts to relive his youth are a direct result of his lust for Angela, and the state of his relationship with Carolyn is in part shown through their lack of sexual contact. Also sexually frustrated, Carolyn has an affair that takes her from "cold perfectionist" to a more carefree soul who " happily along with" the music in her car. Jane and Angela constantly reference sex, through Angela's descriptions of her supposed sexual encounters and the way the girls address each other. Their nude scenes are used to communicate their vulnerability. By the end of the film, Angela's hold on Jane has weakened until the only power she has over her friend is Lester's attraction to her. Col. Fitts reacts with disgust to meeting Jim and Jim; he asks, "How come these faggots always have to rub it in your face? How can they be so shameless?" To which Ricky replies, "That's the thing, Dad—they don't feel like it's anything to be ashamed of." Pennington argues that Col. Fitts' reaction is not homophobic, but an "anguished self-interrogation".
With other turn-of-the-millennium films such as "Fight Club", "In the Company of Men" (1997), "American Psycho" (2000) and "Boys Don't Cry" (1999), "American Beauty" "raises the broader, widely explored issue of masculinity in crisis". Professor Vincent Hausmann charges that in their reinforcement of masculinity "against threats posed by war, by consumerism, and by feminist and queer challenges", these films present a need to "focus on, and even to privilege" aspects of maleness "deemed 'deviant. Lester's transformation conveys "that he, and not the woman, has borne the brunt of of being" and he will not stand for being emasculated. Lester's attempts to "strengthen traditional masculinity" conflict with his responsibilities as a father. Although the film portrays the way Lester returns to that role positively, he does not become "the hypermasculine figure implicitly celebrated in films like "Fight Club"". Hausmann concludes that Lester's behavior toward Angela is "a misguided but nearly necessary step toward his becoming a father again".
Hausmann says the film "explicitly affirms the importance of upholding the prohibition against incest"; a recurring theme of Ball's work is his comparison of the taboos against incest and homosexuality. Instead of making an overt distinction, "American Beauty" looks at how their repression can lead to violence. Col. Fitts is so ashamed of his homosexuality that it drives him to murder Lester. Ball said, "The movie is in part about how homophobia is based in fear and repression and about what can do." The film implies two unfulfilled incestuous desires: Lester's pursuit of Angela is a manifestation of his lust for his own daughter, while Col. Fitts' repression is exhibited through the almost sexualized discipline with which he controls Ricky. Consequently, Ricky realizes that he can only hurt his father by falsely telling him he is homosexual, while Angela's vulnerability and submission to Lester reminds him of his responsibilities and the limits of his fantasy. Col. Fitts represents Ball's father, whose repressed homosexual desires led to his own unhappiness. Ball rewrote Col. Fitts to delay revealing him as homosexual, which Munt reads as a possible "deferment of Ball's own patriarchal-incest fantasies".
Temporality and music.
"American Beauty" follows a traditional narrative structure, only deviating with the displaced opening scene of Jane and Ricky from the middle of the story. Although the plot spans one year, the film is narrated by Lester at the moment of his death. Jacqueline Furby says that the plot "occupies [...] no time all time", citing Lester's claim that life did not flash before his eyes, but that it "stretches on forever like an ocean of time". Furby argues that a "rhythm of repetition" forms the core of the film's structure. For example, two scenes see the Burnhams sitting down to an evening meal, shot from the same angle. Each image is broadly similar, with minor differences in object placement and body language that reflect the changed dynamic brought on by Lester's new-found assertiveness. Another example is the pair of scenes in which Jane and Ricky film each other. Ricky films Jane from his bedroom window as she removes her bra, and the image is reversed later for a similarly "voyeuristic and exhibitionist" scene in which Jane films Ricky at a vulnerable moment.
Lester's fantasies are emphasized by slow motion and repetitive motion shots; Mendes uses double-and-triple cut backs in several sequences, and the score alters to make the audience aware that it is entering a fantasy. One example is the gymnasium scene—Lester's first encounter with Angela. While the cheerleaders perform their half-time routine to "On Broadway", Lester becomes increasingly fixated on Angela. Time slows to represent his "voyeuristic hypnosis" and Lester begins to fantasize that Angela's performance is for him alone. "On Broadway"—which provides a conventional underscore to the onscreen action—is replaced by discordant, percussive music that lacks melody or progression. This nondiegetic score is important to creating the narrative stasis in the sequence; it conveys a moment for Lester that is stretched to an indeterminate length. The effect is one that Stan Link likens to "vertical time", described by the composer and music theorist Jonathan Kramer as music that imparts "a single present stretched out into an enormous duration, a potentially infinite 'now' that nonetheless feels like an instant". The music is used like a visual cue, so that Lester and the score are staring at Angela. The sequence ends with the sudden reintroduction of "On Broadway" and teleological time.
According to Drew Miller of "Stylus", the soundtrack "unconscious voice" to the characters' psyches and complements the subtext. The most obvious use of pop music "accompanies and gives context to" Lester's attempts to recapture his youth; reminiscent of how the counterculture of the 1960s combated American repression through music and drugs, Lester begins to smoke cannabis and listen to rock music. Mendes' song choices "progress through the history of American popular music". Miller argues that although some may be over familiar, there is a parodic element at work, "making good on [the film's encouragement that viewers look closer". Toward the end of the film, Thomas Newman's score features more prominently, creating "a disturbing tempo" that matches the tension of the visuals. The exception is "Don't Let It Bring You Down", which plays during Angela's seduction of Lester. At first appropriate, its tone clashes as the seduction stops. The lyrics, which speak of "castles burning", can be seen as a metaphor for Lester's view of Angela—"the rosy, fantasy-driven exterior of the 'American Beauty—as it burns away to reveal "the timid, small-breasted girl who, like his wife, has willfully developed a false public self".
Production.
Development.
In 1997, Alan Ball resolved to move into the film industry after several frustrating years writing for the television sitcoms "Grace Under Fire" and "Cybill". He joined the United Talent Agency (UTA), where his representative, Andrew Cannava, suggested he write a spec script to "reintroduce to the town as a screenwriter". Ball pitched three ideas to Cannava: two conventional romantic comedies and "American Beauty", which he had originally conceived as a play in the early 1990s. Despite the story's lack of an easily marketable concept, Cannava selected "American Beauty" because he felt it was the one Ball had the most passion for. While developing the script, Ball created another television sitcom, "Oh, Grow Up". He channeled his anger and frustration at having to accede to network demands on that show—and during his tenures on "Grace Under Fire" and "Cybill"—into writing "American Beauty".
Ball did not expect to sell the script, believing it would act as more of a calling card, but "American Beauty" drew interest from several production bodies. Cannava passed the script to several producers, including Dan Jinks and Bruce Cohen, who took it to DreamWorks. With the help of executives Glenn Williamson and Bob Cooper, and Steven Spielberg in his capacity as studio partner, Ball was convinced to develop the project at DreamWorks; he received assurances from the studio—known at the time for its more conventional fare—that it would not "iron the out". In an unusual move, DreamWorks decided not to option the script; instead, in April 1998, the studio bought it outright for $250,000, outbidding Fox Searchlight Pictures, October Films, Metro-Goldwyn-Mayer and Lakeshore Entertainment. DreamWorks planned to make the film for $6–8 million.
Jinks and Cohen involved Ball throughout the film's development, including casting and director selection. The producers met with about twenty interested directors, several of whom were considered "A-list" at the time. Ball was not keen on the more well-known directors because he believed their involvement would increase the budget and lead DreamWorks to become "nervous about the content". Nevertheless, the studio offered the film to Mike Nichols and Robert Zemeckis; neither accepted. In the same year, Mendes (then a theater director) revived the musical "Cabaret" in New York with fellow director Rob Marshall. Beth Swofford of the Creative Artists Agency arranged meetings for Mendes with studio figures in Los Angeles to see if film direction was a possibility. Mendes came across "American Beauty" in a pile of eight scripts at Swofford's house, and knew immediately that it was the one he wanted to make; early in his career, he had been inspired by how the film "Paris, Texas" (1984) presented contemporary America as a mythic landscape and he saw the same theme in "American Beauty", as well as parallels with his own childhood. Mendes later met with Spielberg; impressed by Mendes' productions of "Oliver!" and "Cabaret", Spielberg encouraged him to consider "American Beauty".
Mendes found that he still had to convince DreamWorks' production executives to let him direct. He had already discussed the film with Jinks and Cohen, and felt they supported him. Ball was also keen; having seen "Cabaret", he was impressed with Mendes' "keen visual sense" and thought he did not make obvious choices. Ball felt that Mendes liked to look under the story's surface, a talent he felt would be a good fit with the themes of "American Beauty". Mendes' background also reassured him, because of the prominent role the playwright usually has in a theater production. Over two meetings—the first with Cooper, Walter Parkes and Laurie MacDonald, the second with Cooper alone—Mendes pitched himself to the studio. The studio soon approached Mendes with a deal to direct for the minimum salary allowed under Directors Guild of America rules—$150,000. Mendes accepted, and later recalled that after taxes and his agent's commission, he only earned $38,000. In June 1998, DreamWorks confirmed that it had contracted Mendes to direct the film.
Writing.
Ball was partly inspired by two encounters he had in the early 1990s. In about 1991–92, Ball saw a plastic bag blowing in the wind outside the World Trade Center. He watched the bag for ten minutes, saying later that it provoked an "unexpected emotional response". In 1992, Ball became preoccupied with the media circus around the Amy Fisher trial. Discovering a comic book telling of the scandal, he was struck by how quickly it had become commercialized. He said he "felt like there was a real story underneath was more fascinating and way more tragic" than the story presented to the public, and attempted to turn the idea into a play. Ball produced around 40 pages, but stopped when he realized it would work better as a film. He felt that because of the visual themes, and because each character's story was.. "intensely personal", it could not be done on a stage. All the main characters appeared in this version, but Carolyn did not feature strongly; Jim and Jim instead had much larger roles.
Ball based Lester's story on aspects of his own life. Lester's re-examination of his life parallels feelings Ball had in his mid-30s; like Lester, Ball put aside his passions to work in jobs he hated for people he did not respect. Scenes in Ricky's household reflect Ball's own childhood experiences. Ball suspected his father was homosexual and used the idea to create Col. Fitts, a man who "gave up his chance to be himself". Ball said the script's mix of comedy and drama was not intentional, but that it came unconsciously from his own outlook on life. He said the juxtaposition produced a starker contrast, giving each trait more impact than if they appeared alone.
In the script that was sent to prospective actors and directors, Lester and Angela had sex; by the time of shooting, Ball had rewritten the scene to the final version. Ball initially rebuffed counsel from others that he change the script, feeling they were being puritanical; the final impetus to alter the scene came from DreamWorks' then-president Walter Parkes. He convinced Ball by indicating that in Greek mythology, the hero "has a moment of epiphany before [...] tragedy occurs". Ball later said his anger when writing the first draft had blinded him to the idea that Lester needed to refuse sex with Angela to complete his emotional journey—to achieve redemption. Jinks and Cohen asked Ball not to alter the scene straight away, as they felt it would be inappropriate to make changes to the script before a director had been hired. Early drafts also included a flashback to Col. Fitts' service in the Marines, a sequence that unequivocally established his homosexual leanings. In love with another Marine, Col. Fitts sees the man die and comes to believe that he is being punished for the "sin" of being gay. Ball removed the sequence because it did not fit the structure of the rest of the film—Col. Fitts was the only character to have a flashback—and because it removed the element of surprise from Col. Fitts' later pass at Lester. Ball said he had to write it for his own benefit to know what happened to Col. Fitts, even though all that remained in later drafts was subtext.
Ball remained involved throughout production; he had signed a television show development deal, so had to get permission from his producers to take a year off to be close to "American Beauty". Ball was on-set for rewrites and to help interpret his script for all but two days of filming. His original bookend scenes—in which Ricky and Jane are prosecuted for Lester's murder after being framed by Col. Fitts—were excised in post-production; the writer later felt the scenes were unnecessary, saying they were a reflection of his "anger and cynicism" at the time of writing (see "Editing"). Ball and Mendes revised the script twice before it was sent to the actors, and twice more before the first read-through.
The shooting script features a scene in Angela's car in which Ricky and Jane talk about death and beauty; the scene differed from earlier versions, which set it as a "big scene on a freeway" in which the three witness a car crash and see a dead body. The change was a practical decision, as the production was behind schedule and they needed to cut costs. The schedule called for two days to be spent filming the crash, but only half a day was available. Ball agreed, but only if the scene could retain a line of Ricky's where he reflects on having once seen a dead homeless woman: "When you see something like that, it's like God is looking right at you, just for a second. And if you're careful, you can look right back." Jane asks: "And what do you see?" Ricky: "Beauty." Ball said, "They wanted to cut that scene. They said it's not important. I said, 'You're out of your fucking mind. It's one of the most important scenes in the movie!' [...] If any one line is the heart and soul of this movie, that is the line." Another scene was rewritten to accommodate the loss of the freeway sequence; set in a schoolyard, it presents a "turning point" for Jane in that she chooses to walk home with Ricky instead of going with Angela. By the end of filming, the script had been through ten drafts.
Casting.
Mendes had Spacey and Bening in mind for the leads from the beginning, but DreamWorks executives were unenthusiastic. The studio suggested several alternatives, including Bruce Willis, Kevin Costner or John Travolta to play Lester, and Helen Hunt or Holly Hunter to play Carolyn. Mendes did not want a big star "weighing the film down"; he felt Spacey was the right choice based on his performances in the 1995 films "The Usual Suspects" and "Seven", and 1992's "Glengarry Glen Ross". Spacey was surprised; he said, "I usually play characters who are very quick, very manipulative and smart. [...] I usually wade in dark, sort of treacherous waters. This is a man living one step at a time, playing by his instincts. This is actually much closer to me, to what I am, than those other parts." Mendes offered Bening the role of Carolyn without the studio's consent; although executives were upset at Mendes, by September 1998, DreamWorks had entered negotiations with Spacey and Bening.
Spacey loosely based Lester's early "schlubby" deportment on Walter Matthau. During the film, Lester's physique improves from flabby to toned; Spacey worked out during filming to improve his body, but because Mendes shot the scenes out of chronological order, Spacey varied postures to portray the stages. Before filming, Mendes and Spacey analyzed Jack Lemmon's performance in "The Apartment" (1960), because Mendes wanted Spacey to emulate "the way moved, the way he looked, the way he was in that office and the way he was an ordinary man and yet a special man". Spacey's voiceover is a throwback to "Sunset Boulevard" (1950), which is also narrated in retrospect by a dead character. Mendes felt it evoked Lester's—and the film's—loneliness. Bening recalled women from her youth to inform her performance: "I used to babysit constantly. You'd go to church and see how people present themselves on the outside, and then be inside their house and see the difference." Bening and a hair stylist collaborated to create a "PTA president coif" hairstyle, and Mendes and production designer Naomi Shohan researched mail order catalogs to better establish Carolyn's environment of a "spotless suburban manor". To help Bening get into Carolyn's mindset, Mendes gave her music that he believed Carolyn would like. He lent Bening the Bobby Darin version of the song "Don't Rain on My Parade", which she enjoyed and persuaded the director to include it for a scene in which Carolyn sings in her car.
For the roles of Jane, Ricky and Angela, DreamWorks gave Mendes "carte blanche". By November 1998, Thora Birch, Wes Bentley, and Mena Suvari had been cast in the parts—in Birch's case, despite the fact she was underage for her nude scene. As Birch was 16 at the time she made the film, and thus classified as a minor in the United States, her parents had to approve her brief topless scene in the movie. They and child labor representatives were on the set for the shooting of the scene. Bentley overcame competition from top actors under the age of 25 to be cast. The 2009 documentary "My Big Break" followed Bentley, and several other young actors, before and after he landed the part. To prepare, Mendes provided Bentley with a video camera, telling the actor to film what Ricky would. Peter Gallagher and Alison Janney were cast (as Buddy Kane and Barbara Fitts) after filming began in December 1998. Mendes gave Janney a book of paintings by Edvard Munch. He told her, "Your character is in there somewhere." Mendes cut much of Barbara's dialogue, including conversations between her and Colonel Fitts, as he felt that what needed to be said about the pair—their humanity and vulnerability—was conveyed successfully through their shared moments of silence. Chris Cooper plays Colonel Fitts, Scott Bakula plays Jim Olmeyer, and Sam Robards plays Jim Berkley. Jim and Jim were deliberately depicted as the most normal, happy—and boring—couple in the film. Ball's inspiration for the characters came from a thought he had after seeing a "bland, boring, heterosexual couple" who wore matching clothes: "I can't wait for the time when a gay couple can be just as boring." Ball also included aspects of a gay couple he knew who had the same forename.
Mendes insisted on two weeks of cast rehearsals, although the sessions were not as formal as he was used to in the theater, and the actors could not be present at every one. Several improvisations and suggestions by the actors were incorporated into the script. An early scene showing the Burnhams leaving home for work was inserted later on to show the low point that Carolyn and Lester's relationship had reached. Spacey and Bening worked to create a sense of the love that Lester and Carolyn once had for one another; for example, the scene in which Lester almost seduces Carolyn after the pair argue over Lester's buying a car was originally "strictly contentious".
Filming.
Principal photography lasted about 50 days from December 14, 1998, to February 1999. "American Beauty" was filmed on soundstages at the Warner Bros. backlot in Burbank, California, and at Hancock Park and Brentwood in Los Angeles. The aerial shots at the beginning and end of the film were captured in Sacramento, California, and many of the school scenes were shot at South High School in Torrance, California; several extras in the gym crowd were South High students. The film is set in an upper middle class neighborhood in an unidentified American town. Production designer Naomi Shohan likened the locale to Evanston, Illinois, but said, "it's not about a place, it's about an archetype. [...] The milieu was pretty much Anywhere, USA—upwardly mobile suburbia." The intent was for the setting to reflect the characters, who are also archetypes. Shohan said, "All of them are very strained, and their lives are constructs." The Burnhams' household was designed as the reverse of the Fitts'—the former a pristine ideal, but graceless and lacking in "inner balance", leading to Carolyn's desire to at least give it the appearance of a "perfect all-American household"; the Fitts' home is depicted in "exaggerated darkness symmetry".
The production selected two adjacent properties on the Warner backlot's "Blondie Street" for the Burnhams' and Fitts' homes. The crew rebuilt the houses to incorporate false rooms that established lines of sight—between Ricky and Jane's bedroom windows, and between Ricky's bedroom and Lester's garage. The garage windows were designed specifically to obtain the crucial shot toward the end of the film in which Col. Fitts—watching from Ricky's bedroom—mistakenly assumes that Lester is paying Ricky for sex. Mendes made sure to establish the line of sight early on in the film to make the audience feel a sense of familiarity with the shot. The house interiors were filmed on the backlot, on location, and on soundstages when overhead shots were needed. The inside of the Burnhams' home was shot at a house close to Interstate 405 and Sunset Boulevard in Los Angeles; the inside of the Fitts' home was shot in the city's Hancock Park neighborhood. Ricky's bedroom was designed to be cell-like to suggest his "monkish" personality, while at the same time blending with the high-tech equipment to reflect his voyeuristic side. The production deliberately minimized the use of red, as it was an important thematic signature elsewhere. The Burnhams' home uses cool blues, while the Fitts' is kept in a "depressed military palette".
Mendes' dominating visual style was deliberate and composed, with a minimalist design that provided "a sparse, almost surreal feeling—a bright, crisp, hard edged, near Magritte-like take on American suburbia"; Mendes constantly directed his set dressers to empty the frame. He made Lester's fantasy scenes "more fluid and graceful", and Mendes made minimal use of steadicams, feeling that stable shots generated more tension. For example, when Mendes used a slow push in to the Burnhams' dinner table, he held the shot because his training as a theater director taught him the importance of putting distance between the characters. He wanted to keep the tension in the scene, so he only cut away when Jane left the table. Mendes did use a hand-held camera for the scene in which Col. Fitts beats Ricky. Mendes said the camera provided the scene with a "kinetic [...] off balance energy". He also went hand-held for the excerpts of Ricky's camcorder footage. It took Mendes a long time to get the quality of Ricky's footage to the level he wanted. For the plastic bag footage, Mendes used wind machines to move the bag in the air. The scene took four takes; two by the second unit did not satisfy Mendes, so he shot the scene himself. He felt his first take lacked grace, but for the last attempt he changed the location to the front of a brick wall and added leaves on the ground. Mendes was satisfied by the way the wall gave definition to the outline of the bag.
Mendes avoided using close-ups, as he believed the technique was overused; he also cited Spielberg's advice that he should imagine an audience silhouetted at the bottom of the camera monitor, to keep in mind that he was shooting for display on a screen. Spielberg—who visited the set a few times—also advised Mendes not to worry about costs if he had a "great idea" toward the end of a long working day. Mendes said, "That happened three or four times, and they are all in the movie." Despite Spielberg's support, DreamWorks and Mendes fought constantly over the schedule and budget—although the studio interfered little with the film's content. Spacey, Bening and Hall worked for significantly less than their usual rates. "American Beauty" cost DreamWorks $15 million to produce, slightly above their projected sum. Mendes was so dissatisfied with his first three days' filming that he obtained permission from DreamWorks to reshoot the scenes. He said, "I started with a wrong scene, actually, a comedy scene. And the actors played it way too big: [...] it was badly shot, my fault, badly composed, my fault, bad costumes, my fault [...]; and everybody was doing what I was asking. It was all my fault." Aware that he was a novice, Mendes drew on the experience of Hall: "I made a very conscious decision early on, if I didn't understand something technically, to say, without embarrassment, 'I don't understand what you're talking about, please explain it.
Mendes encouraged some improvisation; for example, when Lester masturbates in bed beside Carolyn, the director asked Spacey to improvise several euphemisms for the act in each take. Mendes said, "I wanted that not just because it was funny [...] but because I didn't want it to seem rehearsed. I wanted it to seem like he was blurting it out of his mouth without thinking. is so in control—I wanted him to break through." Spacey obliged, eventually coming up with 35 phrases, but Bening could not always keep a straight face, which meant the scene had to be shot ten times. The production used small amounts of computer-generated imagery. Most of the rose petals in Lester's fantasies were added in post-production, although some were real and had the wires holding them digitally removed. When Lester fantasizes about Angela in a rose petal bath, the steam was real, save for in the overhead shot. To position the camera, a hole had to be cut in the ceiling, through which the steam escaped; it was instead added digitally.
Editing.
"American Beauty" was edited by Christopher Greenbury and Tariq Anwar; Greenbury began in the position, but had to leave halfway through post-production because of a scheduling conflict with "Me, Myself and Irene" (2000) (which Chris Cooper also starred in). Mendes and an assistant edited the film for ten days between the appointments. Mendes realized during editing that the film was different from the one he had envisioned. He believed he had been making a "much more whimsical, [...] kaleidoscopic" film than what came together in the edit suite. Instead, Mendes was drawn to the emotion and darkness; he began to use the score and shots he had intended to discard to craft the film along these lines. In total, he cut about 30 minutes from his original edit. The opening included a dream in which Lester imagines himself flying above the town. Mendes spent two days filming Spacey against bluescreen, but removed the sequence as he believed it to be too whimsical—"like a Coen brothers movie"—and therefore inappropriate for the tone he was trying to set. The opening in the final cut reused a scene from the middle of the film where Jane tells Ricky to kill her father. This scene was to be the revelation to the audience that the pair were not responsible for Lester's death, as the way it was scored and acted made it clear that Jane's request was not serious. However, in the portion he used in the opening—and when the full scene plays out later—Mendes used the score and a reaction shot of Ricky to leave a lingering ambiguity as to his guilt. The subsequent shot—an aerial view of the neighborhood—was originally intended as the plate shot for the bluescreen effects in the dream sequence.
Mendes spent more time re-cutting the first ten minutes than the rest of the film taken together. He trialled several versions of the opening; the first edit included bookend scenes in which Jane and Ricky are convicted of Lester's murder, but Mendes excised these in the last week of editing because he felt they made the film lose its mystery, and because they did not fit with the theme of redemption that had emerged during production. Mendes believed the trial drew focus away from the characters and turned the film "into an episode of "NYPD Blue"". Instead, he wanted the ending to be "a poetic mixture of dream and memory and narrative resolution". When Ball first saw a completed edit, it was a version with truncated versions of these scenes. He felt that they were so short that they "didn't really register". He and Mendes argued, but Ball was more accepting after Mendes cut the sequences completely; Ball felt that without the scenes the film was more optimistic and had evolved into something that "for all its darkness had a really romantic heart".
Cinematography.
Conrad Hall was not the first choice for director of photography; Mendes believed he was "too old and too experienced" to want the job, and he had been told that Hall was difficult to work with. Instead, Mendes asked Fred Elmes, who turned the job down because he did not like the script. Hall was recommended to Mendes by Tom Cruise, because of Hall's work on "Without Limits" (1998), which Cruise had executive produced. Mendes was directing Cruise's then-wife Nicole Kidman in the play "The Blue Room" during pre-production on "American Beauty", and had already storyboarded the whole film. Hall was involved for one month during pre-production; his ideas for lighting the film began with his first reading of the script, and further passes allowed him to refine his approach before meeting Mendes. Hall was initially concerned that audiences would not like the characters; he only felt able to identify with them during cast rehearsals, which gave him fresh ideas on his approach to the visuals.
Hall's approach was to create peaceful compositions that evoked classicism, to contrast with the turbulent on-screen events and allow audiences to take in the action. Hall and Mendes would first discuss the intended mood of a scene, but he was allowed to light the shot in any way he felt necessary. In most cases, Hall first lit the scene's subject by "painting in" the blacks and whites, before adding fill light, which he reflected from beadboard or white card on the ceiling. This approach gave Hall more control over the shadows while keeping the fill light unobtrusive and the dark areas free of spill. Hall shot "American Beauty" in a 2.39:1 aspect ratio in the Super 35 format, using Kodak Vision 500T 5279 35 mm film stock. He used Super 35 partly because its larger scope allowed him to capture elements such as the corners of the petal-filled pool in its overhead shot, creating a frame around Angela within. He shot the whole film at the same T-stop (T1.9); given his preference for shooting that wide, Hall favored high-speed stocks to allow for more subtle lighting effects. He used Panavision Platinum cameras with the company's Primo series of prime and zoom lenses. Hall employed Kodak Vision 200T 5274 and EXR 5248 stock for scenes with daylight effects. He had difficulty adjusting to Kodak's newly introduced Vision release print stock, which, combined with his contrast-heavy lighting style, created a look with too much contrast. Hall contacted Kodak, who sent him a batch of 5279 that was 5% lower in contrast. Hall used a 1/8 inch Tiffen Black ProMist filter for almost every scene, which he said in retrospect may not have been the best choice, as the optical steps required to blow Super 35 up for its anamorphic release print led to a slight amount of degradation; therefore, the diffusion from the filter was not required. When he saw the film in a theater, Hall felt that the image was slightly unclear and that had he not used the filter, the diffusion from the Super 35–anamorphic conversion would have generated an image closer to what he originally intended.
A shot where Lester and Ricky share a cannabis joint behind a building came from a misunderstanding between Hall and Mendes. Mendes asked Hall to prepare the shot in his absence; Hall assumed the characters would look for privacy, so he placed them in a narrow passage between a truck and the building, intending to light from the top of the truck. When Mendes returned, he explained that the characters did not care if they were seen. He removed the truck and Hall had to rethink the lighting; he lit it from the left, with a large light crossing the actors, and with a soft light behind the camera. Hall felt the consequent wide shot "worked perfectly for the tone of the scene". Hall made sure to keep rain, or the suggestion of it, in every shot near the end of the film. In one shot during Lester's encounter with Angela at the Burnhams' home, Hall created rain effects on the foreground cross lights; in another, he partly lit the pair through French windows to which he had added material to make the rain run slower, intensifying the light (although the strength of the outside light was unrealistic for a night scene, Hall felt it justified because of the strong contrasts it produced). For the close-ups when Lester and Angela move to the couch, Hall tried to keep rain in the frame, lighting through the window onto the ceiling behind Lester. He also used rain boxes to produce rain patterns where he wanted without lighting the entire room.
Music.
Thomas Newman's score was recorded in Santa Monica, California. He mainly used percussion instruments to create the mood and rhythm, the inspiration for which was provided by Mendes. Newman "favored pulse, rhythm and color over melody", making for a more minimalist score than he had previously created. He built each cue around "small, endlessly repeating phrases"—often, the only variety through a "thinning of the texture for eight bars". The percussion instruments included tablas, bongos, cymbals, piano, xylophones and marimbas; also featured were guitars, flute, and world music instruments. Newman also used electronic music and on "quirkier" tracks employed more unorthodox methods, such as tapping metal mixing bowls with a finger and using a detuned mandolin. Newman believed the score helped move the film along without disturbing the "moral ambiguity" of the script: "It was a real delicate balancing act in terms of what music worked to preserve ."
The soundtrack features songs by Newman, Bobby Darin, The Who, Free, Eels, The Guess Who, Bill Withers, Betty Carter, Peggy Lee, The Folk Implosion, Gomez, and Bob Dylan, as well as two cover versions—The Beatles' "Because" performed by Elliott Smith, and Neil Young's "Don't Let It Bring You Down" performed by Annie Lennox. Produced by the film's music supervisor Chris Douridas, an abridged soundtrack album was released on October 5, 1999 and went on to be nominated for a Grammy Award for Best Soundtrack Album. An album featuring 19 tracks from Newman's score was released on January 11, 2000, and won the Grammy Award for Best Score Soundtrack Album. "Filmmaker" considered the score to be one of Newman's best, saying it " the film's transcendentalist aspirations". In 2006, the magazine chose the score as one of twenty essential soundtracks it believed spoke to the "complex and innovative relationships between music and screen storytelling".
Release.
Publicity.
DreamWorks contracted Amazon.com to create the official website, marking the first time that Amazon had created a special section devoted to a feature film. The website included an overview, a photo gallery, cast and crew filmographies, and exclusive interviews with Spacey and Bening. The film's tagline—"look closer"—originally came from a cutting pasted on Lester's workplace cubicle by the set dresser. DreamWorks ran parallel marketing campaigns and trailers—one aimed at adults, the other at teenagers. Both trailers ended with the poster image of a girl holding a rose. Reviewing the posters of several 1999 films, David Hochman of "Entertainment Weekly" rated "American Beauty"s highly, saying it evoked the tagline; he said, "You return to the poster again and again, thinking, this time you're gonna find something." DreamWorks did not want to test screen the film; according to Mendes, the studio was pleased with it, but he insisted on one where he could question the audience afterward. The studio reluctantly agreed and showed the film to a young audience in San Jose, California. Mendes claimed the screening went very well.
Theatrical run.
The film had its world premiere on September 8, 1999, at Grauman's Egyptian Theatre in Los Angeles. Three days later, the film appeared at the Toronto International Film Festival. With the filmmakers and cast in attendance, it screened at several American universities, including the University of California at Berkeley, New York University, the University of California at Los Angeles, the University of Texas at Austin, and Northwestern University.
On September 15, 1999, "American Beauty" opened to the public in limited release at three theaters in Los Angeles and three in New York. More theaters were added during the limited run, and on October 1, the film officially entered wide release by screening in 706 theaters across North America. The film grossed $8,188,587 over the weekend, ranking third at the box office. Audiences polled by the market research firm CinemaScore gave "American Beauty" a "B+" grade on average. The theater count hit a high of 1,528 at the end of the month, before a gradual decline. Following "American Beauty"s wins at the 57th Golden Globe Awards, DreamWorks re-expanded the theater presence from a low of 7 in mid-February, to a high of 1,990 in March. The film ended its North American theatrical run on June 4, 2000, having grossed $130.1 million.
"American Beauty" had its European premiere at the London Film Festival on November 18, 1999; in January 2000, it began to screen in various territories outside North America. It debuted in Israel to "potent" returns, and limited releases in Germany, Italy, Austria, Switzerland, the Netherlands and Finland followed on January 21. After January 28 opening weekends in Australia, the United Kingdom, Spain and Norway, "American Beauty" had earned $7 million in 12 countries for a total of $12.1 million outside North America. On February 4, "American Beauty" debuted in France and Belgium. Expanding to 303 theaters in the United Kingdom, the film ranked first at the box office with $1.7 million. On the weekend of February 18—following "American Beauty"s eight nominations for the 72nd Academy Awards—the film grossed $11.7 million from 21 territories, for a total of $65.4 million outside North America. The film had "dazzling" debuts in Hungary, Denmark, the Czech Republic, Slovakia and New Zealand.
As of February 18, the most successful territories were the United Kingdom ($15.2 million), Italy ($10.8 million), Germany ($10.5 million), Australia ($6 million) and France ($5.3 million). The Academy Award nominations meant strong performances continued across the board; the following weekend, "American Beauty" grossed $10.9 million in 27 countries, with strong debuts in Brazil, Mexico and South Korea. Other high spots included robust returns in Argentina, Greece and Turkey. On the weekend of March 3, 2000, "American Beauty" debuted strongly in Hong Kong, Taiwan and in Singapore, markets traditionally "not receptive to this kind of upscale fare". The impressive South Korean performance continued, with a return of $1.2 million after nine days. In total, "American Beauty" grossed $130.1 million in North America and $226.2 million internationally, for $356.3 million worldwide.
Home media.
"American Beauty" was released on VHS on May 9, 2000 and on DVD with the DTS format on October 24, 2000. Before the North American rental release on May 9, Blockbuster Video wanted to purchase hundreds of thousands of extra copies for its "guaranteed title" range, whereby anyone who wanted to rent the film would be guaranteed a copy. Blockbuster and DreamWorks could not agree on a profit sharing deal, so Blockbuster ordered two thirds the number of copies it originally intended. DreamWorks made around one million copies available for rental; Blockbuster's share would usually have been about 400,000 of these. Some Blockbuster stores only displayed 60 copies, and others did not display the film at all, forcing customers to ask for it. The strategy required staff to read a statement to customers explaining the situation; Blockbuster claimed it was only " customer demand" due to the reduced availability. Blockbuster's strategy leaked before May 9, leading to a 30% order increase from other retailers. In its first week of rental release, "American Beauty" made $6.8 million. This return was lower than would have been expected had DreamWorks and Blockbuster reached an agreement. In the same year, "The Sixth Sense" made $22 million, while "Fight Club" made $8.1 million, even though the latter's North American theatrical performance was just 29% that of "American Beauty". Blockbuster's strategy also affected rental fees; "American Beauty" averaged $3.12, compared with $3.40 for films that Blockbuster fully promoted. Only 53% of the film's rentals were from large outlets in the first week, compared with the usual 65%.
The DVD release included a behind-the-scenes featurette, film audio commentary from Mendes and Ball and a storyboard presentation with discussion from Mendes and Hall. In the film commentary, Mendes refers to deleted scenes he intended to include in the release. However, these scenes are not on the DVD as he changed his mind after recording the commentary; Mendes felt that to show scenes he previously chose not to use would detract from the film's integrity.
On September 21, 2010, Paramount Home Entertainment released "American Beauty" on Blu-ray, as part of Paramount's "Sapphire Series". All the extras from the DVD release were present, with the theatrical trailers upgraded to HD.
Critical reception.
"American Beauty" was widely considered the best film of 1999 by the American press. It received overwhelming praise, chiefly for Spacey, Mendes and Ball. "Variety" reported that "no other 1999 movie has benefited from such universal raves." It was the best-received title at the Toronto International Film Festival (TIFF), where it won the People's Choice Award after a ballot of the festival's audiences. TIFF's director, Piers Handling, said, ""American Beauty" was the buzz of the festival, the film most talked about."
Writing in "Variety", Todd McCarthy said the cast ensemble "could not be better"; he praised Spacey's "handling of innuendo, subtle sarcasm and blunt talk" and the way he imbued Lester with "genuine feeling". Janet Maslin in "The New York Times" said Spacey was at his "wittiest and most agile" to date, and Roger Ebert of the "Chicago Sun-Times" singled Spacey out for successfully portraying a man who "does reckless and foolish things who doesn't deceive himself". Kevin Jackson of "Sight & Sound" said Spacey impressed in ways distinct from his previous performances, the most satisfying aspect being his portrayal of "both sap and hero". Writing in "Film Quarterly", Gary Hentzi praised the actors, but said that characters such as Carolyn and Col. Fitts were stereotypes. Hentzi accused Mendes and Ball of identifying too readily with Jane and Ricky, saying the latter was their "fantasy figure"—a teenaged boy who's an absurdly wealthy artist able to "finance own projects". Hentzi said Angela was the most believable teenager, in particular with her "painfully familiar" attempts to "live up to an unworthy image of herself". Maslin agreed that some characters were unoriginal, but said their detailed characterizations made them memorable. Kenneth Turan of the "Los Angeles Times" said the actors coped "faultlessly" with what were difficult roles; he called Spacey's performance "the energy that drives the film", saying the actor commanded audience involvement despite Lester not always being sympathetic. "Against considerable odds, we do like [these characters," Turan concluded.
Maslin felt that Mendes directed with "terrific visual flair", saying his minimalist style balanced "the mordant and bright" and that he evoked the "delicate, eroticized power-playing vignettes" of his theater work. Jackson said Mendes' theatrical roots rarely showed, and that the "most remarkable" aspect was that Spacey's performance did not overshadow the film. He said that Mendes worked the script's intricacies smoothly, to the ensemble's strengths, and staged the tonal shifts skillfully. McCarthy believed "American Beauty" a "stunning card of introduction" for film débutantes Mendes and Ball. He said Mendes' "sure hand" was "as precise and controlled" as his theater work. McCarthy cited Hall's involvement as fortunate for Mendes, as the cinematographer was "unsurpassed" at conveying the themes of a work. Turan agreed that Mendes' choice of collaborators was "shrewd", naming Hall and Newman in particular. Turan suggested that "American Beauty" may have benefited from Mendes' inexperience, as his "anything's possible daring" made him attempt beats that more seasoned directors might have avoided. Turan felt that Mendes' accomplishment was to "capture and enhance duality" of Ball's script—the simultaneously "caricatured [... and painfully real" characters. Hentzi, while critical of many of Mendes and Ball's choices, admitted the film showed off their "considerable talents".
Turan cited Ball's lack of constraint when writing the film as the reason for its uniqueness, in particular the script's subtle changes in tone. McCarthy said the script was "as fresh and distinctive" as any of its American film contemporaries, and praised how it analyzed the characters while not compromising narrative pace. He called Ball's dialogue "tart" and said the characters—Carolyn excepted—were "deeply drawn". One other flaw, McCarthy said, was the revelation of Col. Fitts' homosexuality, which he said evoked "hoary Freudianism". Jackson said the film transcended its clichéd setup to become a "wonderfully resourceful and sombre comedy". He said that even when the film played for sitcom laughs, it did so with "unexpected nuance". Hentzi criticized how the film made a mystery of Lester's murder, believing it manipulative and simply a way of generating suspense. McCarthy cited the production and costume design as plusses, and said the soundtrack was good at creating "ironic counterpoint" to the story. Hentzi concluded that "American Beauty" was "vital but uneven"; he felt the film's examination of "the ways which teenagers and adults imagine each other's lives" was its best point, and that although Lester and Angela's dynamic was familiar, its romantic irony stood beside "the most enduring literary treatments" of the theme, such as "Lolita". Nevertheless, Hentzi believed that the film's themes of materialism and conformity in American suburbia were "hackneyed". McCarthy conceded that the setting was familiar, but said it merely provided the film with a "starting point" from which to tell its "subtle and acutely judged tale". Maslin agreed; she said that while it "takes aim at targets that are none too fresh", and that the theme of nonconformity did not surprise, the film had its own "corrosive novelty". Ebert awarded "American Beauty" four stars out of four, and Turan said it was layered, subversive, complex and surprising, concluding it was "a hell of a picture".
A few months after the film's release, reports of a backlash appeared in the American press, and the years since have seen its critical regard wane. In 2005, "Premiere" named "American Beauty" as one of 20 "most overrated movies of all time"; Mendes accepted the inevitability of the critical reappraisal, saying, "I thought some of it was entirely justified—it was a little overpraised at the time."
Currently, the film holds an 88% score on Rotten Tomatoes based on 180 reviews, with an average rating of 8.2/10; the critical consensus reads, "Flawlessly cast and brimming with dark, acid wit, "American Beauty" is a smart, provocative high point of late '90s mainstream Hollywood film." Metacritic gives the film a score of 86, based on 33 reviews, indicating "universal acclaim."
Accolades.
"American Beauty" was not considered an immediate favorite to dominate the American awards season. Several other contenders opened at the end of 1999, and US critics spread their honors among them when compiling their end-of-year lists. The Chicago Film Critics Association and the Broadcast Film Critics Association named the film the best of 1999, but while the New York Film Critics Circle, the National Society of Film Critics and the Los Angeles Film Critics Association recognized "American Beauty", they gave their top awards to other films. By the end of the year, reports of a critical backlash suggested "American Beauty" was the underdog in the race for Best Picture; however, at the Golden Globe Awards in January 2000, "American Beauty" won Best Film, Best Director and Best Screenplay.
As the nominations for the 72nd Academy Awards approached, a frontrunner had not emerged. DreamWorks had launched a major campaign for "American Beauty" five weeks before ballots were due to be sent to the 5,600 Academy Award voters. Its campaign combined traditional advertising and publicity with more focused strategies. Although direct mail campaigning was prohibited, DreamWorks reached voters by promoting the film in "casual, comfortable settings" in voters' communities. The studio's candidate for Best Picture the previous year, "Saving Private Ryan", lost to "Shakespeare in Love", so the studio took a new approach by hiring outsiders to provide input for the campaign. It hired three veteran consultants, who told the studio to "think small". Nancy Willen encouraged DreamWorks to produce a special about the making of "American Beauty", to set up displays of the film in the communities' bookstores, and to arrange a question-and-answer session with Mendes for the British Academy of Film and Television Arts. Dale Olson advised the studio to advertise in free publications that circulated in Beverly Hills—home to many voters—in addition to major newspapers. Olson arranged to screen "American Beauty" to about 1,000 members of the Actors Fund of America, as many participating actors were also voters. Bruce Feldman took Ball to the Santa Barbara International Film Festival, where Ball attended a private dinner in honor of Anthony Hopkins, meeting several voters who were in attendance.
In February 2000, "American Beauty" was nominated for eight Academy Awards; its closest rivals, "The Cider House Rules" and "The Insider", received seven nominations each. In March 2000, the major industry labor organizations all awarded their top honors to "American Beauty"; perceptions had shifted—the film was now the favorite to dominate the Academy Awards. "American Beauty"s closest rival for Best Picture was still "The Cider House Rules", from Miramax. Both studios mounted aggressive campaigns; DreamWorks bought 38% more advertising space in "Variety" than Miramax. On March 26, 2000, "American Beauty" won five Academy Awards: Best Picture, Best Director, Best Actor (Spacey), Best Original Screenplay and Best Cinematography. At the 53rd British Academy Film Awards, "American Beauty" won six of the fourteen awards for which it was nominated: Best Film, Best Actor, Best Actress (Bening), Best Cinematography, Best Film Music and Best Editing. In 2000, the Publicists Guild of America recognized DreamWorks for the best film publicity campaign. In September 2008, "Empire" named "American Beauty" the 96th "Greatest Movie of All Time" after a poll of 10,000 readers, 150 filmmakers and 50 film critics, the 4th highest ranked movie from 1999 (behind "Fight Club", "The Matrix", and "Magnolia"). In 2013, the Writers Guild of America ranked the screenplay #38 on its list of 101 Greatest Screenplays.
The film was nominated for AFI's 100 Years...100 Movies (10th Anniversary Edition) in 2007.

</doc>
<doc id="44125" url="https://en.wikipedia.org/wiki?curid=44125" title="Gyroscope">
Gyroscope

A gyroscope (from Greek γῦρος "gûros", "circle" and σκοπέω "skopéō", "to look") is a spinning wheel or disc in which the axis of rotation is free to assume any orientation by itself. When rotating, the orientation of this axis is unaffected by tilting or rotation of the mounting, according to the conservation of angular momentum. Because of this, gyroscopes are useful for measuring or maintaining orientation.
Gyroscopes based on other operating principles also exist, such as the electronic, microchip-packaged MEMS gyroscopes found in consumer electronics devices, solid-state ring lasers, fibre optic gyroscopes, and the extremely sensitive quantum gyroscope.
Applications of gyroscopes include inertial navigation systems where magnetic compasses would not work (as in the Hubble telescope) or would not be precise enough (as in intercontinental ballistic missiles), or for the stabilization of flying vehicles like radio-controlled helicopters or unmanned aerial vehicles, and recreational boats and commercial ships. Due to their precision, gyroscopes are also used in gyrotheodolites to maintain direction in tunnel mining. Gyroscopes can be used to construct gyrocompasses, which complement or replace magnetic compasses (in ships, aircraft and spacecraft, vehicles in general), to assist in stability (Hubble Space Telescope, bicycles, motorcycles, and ships) or be used as part of an inertial guidance system.
Description and diagram.
Within mechanical systems or devices, a conventional "gyroscope" is a mechanism comprising a rotor journaled to spin about one axis, the journals of the rotor being mounted in an inner gimbal or ring; the inner gimbal is journaled for oscillation in an outer gimbal for a total of two gimbals.
The outer gimbal or ring, which is the gyroscope frame, is mounted so as to pivot about an axis in its own plane determined by the support. This outer gimbal possesses one degree of rotational freedom and its axis possesses none. The next inner gimbal is mounted in the gyroscope frame (outer gimbal) so as to pivot about an axis in its own plane that is always perpendicular to the pivotal axis of the gyroscope frame (outer gimbal). This inner gimbal has two degrees of rotational freedom.
The axle of the spinning wheel defines the spin axis. The rotor is journaled to spin about an axis, which is always perpendicular to the axis of the inner gimbal. So the rotor possesses three degrees of rotational freedom and its axis possesses two.
The wheel responds to a force applied about the input axis by a reaction force about the output axis.
The behaviour of a gyroscope can be most easily appreciated by consideration of the front wheel of a bicycle. If the wheel is leaned away from the vertical so that the top of the wheel moves to the left, the forward rim of the wheel also turns to the left. In other words, rotation on one axis of the turning wheel produces rotation of the third axis.
A gyroscope flywheel will roll or resist about the output axis depending upon whether the output gimbals are of a free- or fixed- configuration. Examples of some free-output-gimbal devices would be the attitude reference gyroscopes used to sense or measure the pitch, roll and yaw attitude angles in a spacecraft or aircraft.
The centre of gravity of the rotor can be in a fixed position. The rotor simultaneously spins about one axis and is capable of oscillating about the two other axes, and, thus, except for its inherent resistance due to rotor spin, it is free to turn in any direction about the fixed point. Some gyroscopes have mechanical equivalents substituted for one or more of the elements. For example, the spinning rotor may be suspended in a fluid, instead of being pivotally mounted in gimbals. A control moment gyroscope (CMG) is an example of a fixed-output-gimbal device that is used on spacecraft to hold or maintain a desired attitude angle or pointing direction using the gyroscopic resistance force.
In some special cases, the outer gimbal (or its equivalent) may be omitted so that the rotor has only two degrees of freedom. In other cases, the centre of gravity of the rotor may be offset from the axis of oscillation, and, thus, the centre of gravity of the rotor and the centre of suspension of the rotor may not coincide.
History.
Essentially, a gyroscope is a top combined with a pair of gimbals. Tops were invented in many different civilizations, including classical Greece, Rome, and China. Most of these were not utilized as instruments.
The first known apparatus similar to a gyroscope (the "Whirling Speculum" or "Serson's Speculum") was invented by John Serson in 1743. It was used as a level, to locate the horizon in foggy or misty conditions.
The first instrument used more like an actual gyroscope was made by German Johann Bohnenberger, who first wrote about it in 1817. At first he called it the "Machine". Bohnenberger's machine was based on a rotating massive sphere. In 1832, American Walter R. Johnson developed a similar device that was based on a rotating disc. The French mathematician Pierre-Simon Laplace, working at the École Polytechnique in Paris, recommended the machine for use as a teaching aid, and thus it came to the attention of Léon Foucault. In 1852, Foucault used it in an experiment involving the rotation of the Earth. It was Foucault who gave the device its modern name, in an experiment to see (Greek "skopeein", to see) the Earth's rotation (Greek "gyros", circle or rotation), which was visible in the 8 to 10 minutes before friction slowed the spinning rotor.
In the 1860s, the advent of electric motors made it possible for a gyroscope to spin indefinitely; this led to the first prototype heading indicators, and a rather more complicated device, the gyrocompass. The first functional gyrocompass was patented in 1904 by German inventor Hermann Anschütz-Kaempfe. The American Elmer Sperry followed with his own design later that year, and other nations soon realized the military importance of the invention—in an age in which naval prowess was the most significant measure of military power—and created their own gyroscope industries. The Sperry Gyroscope Company quickly expanded to provide aircraft and naval stabilizers as well, and other gyroscope developers followed suit.
In 1917, the Chandler Company of Indianapolis, created the "Chandler gyroscope", a toy gyroscope with a pull string and pedestal. Chandler continued to produce the toy until the company was purchased by TEDCO inc. in 1982. The chandler toy is still produced by TEDCO today.
In the first several decades of the 20th century, other inventors attempted (unsuccessfully) to use gyroscopes as the basis for early black box navigational systems by creating a stable platform from which accurate acceleration measurements could be performed (in order to bypass the need for star sightings to calculate position). Similar principles were later employed in the development of inertial navigation systems for ballistic missiles.
During World War II, the gyroscope became the prime component for aircraft and anti-aircraft gun sights. After the war, the race to miniaturize gyroscopes for guided missiles and weapons navigation systems resulted in the development and manufacturing of so-called midget gyroscopes that weighed less than and had a diameter of approximately . Some of these miniaturized gyroscopes could reach a speed of 24,000 revolutions per minute in less than 10 seconds.
Three-axis MEMS-based gyroscopes are also being used in portable electronic devices such as tablets, smartphones, and smartwatches. This adds to the 3-axis acceleration sensing ability available on previous generations of devices. Together these sensors provide 6 component motion sensing; acceleration for X,Y, and Z movement, and gyroscopes for measuring the extent and rate of rotation in space (roll, pitch and yaw). Some devices (e.g. the iPhone) additionally incorporate a magnetometer to provide absolute angular measurements relative to the Earth's magnetic field. Newer MEMS-based inertial measurement units incorporate up to all nine axes of sensing in a single integrated circuit package, providing inexpensive and widely available motion sensing.
Variations.
Gyrostat.
A gyrostat is a variant of the gyroscope. It consists of a massive flywheel concealed in a solid casing. Its behaviour on a table, or with various modes of suspension or support, serves to illustrate the curious reversal of the ordinary laws of static equilibrium due to the gyrostatic behaviour of the interior invisible flywheel when rotated rapidly. The first gyrostat was designed by Lord Kelvin to illustrate the more complicated state of motion of a spinning body when free to wander about on a horizontal plane, like a top spun on the pavement, or a hoop or bicycle on the road. Kelvin also made use of gyrostats to develop mechanical theories of the elasticity of matter and of the ether; these theories are of purely historical interest today.
In modern times, the gyrostat concept is used in the design of attitude control systems for orbiting spacecraft and satellites. For instance, the Mir space station had three pairs of internally mounted flywheels known as "gyrodynes" or "control moment gyros".
In physics, there are several systems whose dynamical equations resemble the equations of motion of a gyrostat. Examples include a solid body with a cavity filled with an inviscid, incompressible, homogeneous liquid, the static equilibrium configuration of a stressed elastic rod in elastica theory, the polarization dynamics of a light pulse propagating through a nonlinear medium, the Lorenz system in chaos theory, and the motion of an ion in a Penning trap mass spectrometer.
MEMS.
A MEMS gyroscope takes the idea of the Foucault pendulum and uses a vibrating element, known as a MEMS (microelectromechanical system). The MEMS-based gyro was initially made practical and producible by Systron Donner Inertial (SDI). Today, SDI is a large manufacturer of MEMS gyroscopes.
FOG.
A fiber optic gyroscope (FOG) is a gyroscope that uses the interference of light to detect mechanical rotation. The sensor is a coil of fiber optic cable which can be over 5 km of optical fiber. The development of low-loss single-mode optical fiber in the early 1970s for the telecommunications industry enabled the development of Sagnac effect fiber optic gyroscopes. The Sagnac effect is the same principle used in FOG's as in RLG's
HRG.
The hemispherical resonator gyroscope (HRG), also called wine-glass gyroscope or mushroom gyro, makes using a thin solid-state hemispherical shell, anchored by a thick stem. This shell is driven to a flexural resonance by electrostatic forces generated by electrodes which are deposited directly onto separate fused-quartz structures that surround the shell. Gyroscopic effect is obtained from the inertial property of the flexural standing waves.
VSG or CVG.
A vibrating structure gyroscope (VSG), also called a Coriolis vibratory gyroscope (CVG), uses a resonator made of different metallic alloys. It takes a position between the low-accuracy, low-cost MEMS gyroscope and the higher-accuracy and higher-cost FOG. Accuracy parameters are increased by using low-intrinsic damping materials, resonator vacuumization, and digital electronics to reduce temperature dependent drift and instability of control signals.
High quality wine-glass resonators are used for precise sensors like HRG or CRG.
DTG.
A dynamically tuned gyroscope (DTG) is a rotor suspended by a universal joint with flexure pivots. The flexure spring stiffness is independent of spin rate. However, the dynamic inertia (from the gyroscopic reaction effect) from the gimbal provides negative spring stiffness proportional to the square of the spin speed (Howe and Savet, 1964; Lawrence, 1998). Therefore, at a particular speed, called the tuning speed, the two moments cancel each other, freeing the rotor from torque, a necessary condition for an ideal gyroscope.
RLG.
A ring laser gyroscope relies on the Sagnac effect to measure rotation by measuring the shifting interference pattern of a split beam of light as it moves around the ring in opposite directions.
London moment.
A London moment gyroscope relies on the quantum-mechanical phenomenon, whereby a spinning superconductor generates a magnetic field whose axis lines up exactly with the spin axis of the gyroscopic rotor. A magnetometer determines the orientation of the generated field, which is interpolated to determine the axis of rotation. Gyroscopes of this type can be extremely accurate and stable. For example, those used in the Gravity Probe B experiment measured changes in gyroscope spin axis orientation to better than 0.5 milliarcseconds (1.4 degrees) over a one-year period. This is equivalent to an angular separation the width of a human hair viewed from away.
The GP-B gyro consists of a nearly-perfect spherical rotating mass made of fused quartz, which provides a dielectric support for a thin layer of niobium superconducting material. To eliminate friction found in conventional bearings, the rotor assembly is centered by the electric field from six electrodes. After the initial spin-up by a jet of helium which brings the rotor to 4,000 RPM, the polished gyroscope housing is evacuated to an ultra-high vacuum to further reduce drag on the rotor. Provided the suspension electronics remain powered, the extreme rotational symmetry, lack of friction, and low drag will allow the angular momentum of the rotor to keep it spinning for about 15,000 years.
A sensitive DC SQUID is able to discriminate changes as small as one quantum, or about 2 Wb, is used to monitor the gyroscope. A precession, or tilt, in the orientation of the rotor causes the London moment magnetic field to shift relative to the housing. The moving field passes through a superconducting pickup loop fixed to the housing, inducing a small electric current. The current produces a voltage across a shunt resistance, which is resolved to spherical coordinates by a microprocessor. The system is designed to minimize Lorentz torque on the rotor.
Modern uses.
In addition to being used in compasses, aircraft, computer pointing devices, etc., gyroscopes have been introduced into consumer electronics. Since the gyroscope allows the calculation of orientation and rotation, designers have incorporated them into modern technology. The integration of the gyroscope has allowed for more accurate recognition of movement within a 3D space than the previous lone accelerometer within a number of smartphones. Gyroscopes in consumer electronics are frequently combined with accelerometers (acceleration sensors) for more robust direction- and motion-sensing. Examples of such applications include smartphones such as the Samsung Galaxy Note 4, HTC Titan, Nexus 5, iPhone 5s, Nokia 808 PureView and Sony Xperia, game console peripherals such as the PlayStation 3 controller and the Wii Remote, and virtual reality sets such as the Oculus Rift.
Nintendo has integrated a gyroscope into the Wii console's Wii Remote controller by an additional piece of hardware called "Wii MotionPlus". It is also included in the 3DS and the Wii U GamePad, which detects movement when turning.
Cruise ships use gyroscopes to level motion-sensitive devices such as self-leveling pool tables.
An electric powered flywheel gyroscope inserted in a bicycle wheel is being sold as a training wheel alternative.

</doc>
<doc id="44126" url="https://en.wikipedia.org/wiki?curid=44126" title="Hitch">
Hitch

Hitch may refer to:

</doc>
<doc id="44127" url="https://en.wikipedia.org/wiki?curid=44127" title="Military incompetence">
Military incompetence

Military incompetence refers to incompetencies and failures of military organisations, whether through incompetent individuals or through a flawed institutional culture.
The effects of isolated cases of "personal" incompetence can be disproportionately significant in military organisations. Strict hierarchies of command provide the opportunity for a single decision to direct the work of thousands, whilst an institutional culture devoted to following orders without debate can help ensure that a bad or miscommunicated decision is implemented without being challenged or corrected.
However, the most common cases of "military incompetence" can be attributable to a flawed organisational culture. Perhaps the most marked of these is a conservative and traditionalist attitude, where innovative ideas or new technology are discarded or left untested. A tendency to believe that a problem can be solved by applying an earlier (failed) solution "better", be that with more men, more firepower, or simply more "élan", is common. A strict hierarchical system often discourages the devolution of power to junior commanders, and can encourage micromanagement by senior officers.
The nature of warfare provides several factors which exacerbate these effects; the fog of war means that information about the enemy forces is often limited or inaccurate, making it easy for the intelligence process to interpret the information to agree with existing assumptions, or to fit it to their own preconceptions and expectations. Communications tend to deteriorate in battlefield situations, with the flow of information between commanders and combat units being disrupted, making it difficult to react to changes in the situation as they develop.
After operations have ceased, military organisations often fail to learn effectively from experience. In victory, whatever methods have been usedno matter how inefficientappear to have been vindicated (see victory disease), whilst in defeat there is a tendency to select scapegoats and to avoid looking in detail at the broader reasons for failure.

</doc>
<doc id="44128" url="https://en.wikipedia.org/wiki?curid=44128" title="Lashing (ropework)">
Lashing (ropework)

A lashing is an arrangement of rope wire or webbing with linking device used to secure and fasten two or more items together in a somewhat rigid manner. Lashings are most commonly applied to timber poles, and are commonly associated with cargo, containerisation, the Scouting movement, and sailors.
This word usage derives from using whipcord to tie things together.
It has been imagined that the first lashing made by humans was wrapping a few strips of bark around a stone to hold it to a tree branch to make an ax to hunt and build with. In modern times, the same methods are used, but strips of bark and vines have been replaced with natural and synthetic fiber ropes. Scouts and campers use lashings to build camp gadgets and improve their campsites for comfort and convenience. Lashings are also used in pioneering, the art of creating structures such as bridges and towers, using ropes and wooden spars.
There are still areas in the world where lashing spars (or poles) is the basic means of building.
Types.
Square lashing.
Square lashing is a type of lashing used to bind spars together. There are different types, but all consist of a series of wraps around the spars, and fraps around the wraps between the spars.
Diagonal lashing.
Diagonal lashing is a type of lashing used to bind spars or poles together, to prevent racking. It gets its name from the fact that the wrapping turns cross the poles diagonally and is used to spring poles together where they do not touch as in the X-brace of a trestle.
Shear lashing.
Shear lashing (two-spar shear lashing) also spelled "sheer lashing" is used for lashing together two parallel spars which will be opened out of the parallel to form sheer legs as in the formation of an A-frame. The clove hitch is tied around one leg only and frapping turns are taken between the poles.
Round lashing.
The round lashing is most frequently used to join two poles together to extend their length. In the simple version, a clove hitch is tied around both poles and there are no frapping turns.
Tripod lashing.
The tripod lashing (also known as gyn lashing, figure of eight lashing, and three-spar shear lashing) is used to join three spars together to form a tripod.

</doc>
<doc id="44130" url="https://en.wikipedia.org/wiki?curid=44130" title="Plait">
Plait

A plait may refer to:
Plait may also refer to:

</doc>
<doc id="44132" url="https://en.wikipedia.org/wiki?curid=44132" title="Ramallah">
Ramallah

Ramallah (, pronounced "Rāmallāh" ) is a Palestinian city in the central West Bank located north of Jerusalem at an average elevation of 880 meters above sea level, adjacent to al-Bireh. It currently serves as the "de facto" administrative capital of the Palestinian National Authority (PNA). Ramallah was historically an Arab Christian town. Today Muslims form the majority of the population of nearly 27,092 in 2007, with Christians making up a significant minority.
Etymology.
"Ramallah" is composed of "Ram," an Aramaic word that means "high place or mountain," and "Allah," the Arabic word for God, meaning "the Hill of God".
History.
Ancient rock-cut tombs have been found near Ramallah. Potsherds from the Crusader/Ayyubid and early Ottoman period have also been found there.
Ramallah has been identified with the Crusader place called "Ramalie". Remains of a building with an arched doorway from the Crusader era, called "al-Burj," have been identified, but the original use of the building is undetermined.
Ottoman era.
Ramallah was incorporated into the Ottoman Empire in 1517 with all of Palestine. In 1596 it was listed in the tax registers as being in the "nahiya" of Quds of the "Liwa of Quds." It had a population of 71 Christian households and 9 Muslim households. It paid taxes on wheat, barley, olives, vines or fruit trees, and goats or beehives.
Modern Ramallah was founded in the mid-1500s by the Haddadins (also: Haddad"ee"n), a clan of brothers descended from Ghassanid Christians. The Haddadins (ancestors of the present-day Jadallah family, among others), and their leader Rashid El-Haddadin, arrived from east of the Jordan River from the areas of Karak and Shoubak. The Haddadin migration is attributed to fighting and unrest among clans in that area.
Rashid and his brothers were blacksmiths. The Haddadin name comes from the old (Aramaicܚܕܕ or ܚܕܐܕ ) word Haddad, which translates to blacksmith.
Haddadin was attracted to the mountainous site of Ramallah because it was similar to the other mountainous areas he came from. In addition, the heavily forested area could supply him with plenty of fuel for his forges.
In 1838 American biblical scholar Edward Robinson visited the area, noting that the inhabitants were Christian "of the Greek rite". There were 200 taxable men, which gives an estimated total population of 800-900 people. The village "belonged" to the Haram al-Sharif, Jerusalem, to which it paid an annual tax of 350 Mids of grain.
In 1883, the Palestine Exploration Fund's "Survey of Western Palestine" described Ramallah as 
"A large Christian village, of well-built stone houses, standing on a high ridge, with a view on the west extending to the sea. It stands amongst gardens and olive-yards, and has three springs to the south and one on the west; on the north there are three more, within a mile from the village. On the east there is a well. There are rock-cut tombs to the north-east with well-cut entrances, but completely blocked with rubbish. In the village is a Greek church, and on the east a Latin convent and a Protestant schoolhouse, all modern buildings. The village lands are Wakuf, or ecclesiastical property, belonging to the Haram of Jerusalem. About a quarter of the inhabitants are Roman Catholics, the rest Orthodox Greeks."
In the 21st century, a large community of people with direct descent from the Haddadins who founded Ramallah live in the United States. The town is now predominately Muslim, but still contains a Christian minority. The change in demographics is due mostly to new migration of Muslims to the area, and emigration of Christians from the area.
Christian presence.
Ramallah grew dramatically throughout the 17th and 18th centuries as an agricultural village; thus, attracting more (predominantly Christian) inhabitants from all around the region. In 1700, Yacoub Elias was the first Ramallah native to be ordained by the Eastern Greek Melkite Orthodox Church of Jerusalem, the Christian denomination that prevailed in the Holy Land at the time. In the early 19th century, the first Greek Melkite Jerusalemite Orthodox Christian church was built. Later in the 1850s, "The Church of Transfiguration", was built to replace it; it is the sole Orthodox Church in Ramallah today. During that same decade, the Latin (Roman Catholic) Church established its presence in Ramallah, constituting the second largest Christian denomination in the city. The Roman Catholic Church established the St. Joseph's Girl's School run by St. Joseph sisters, as well as the co-educational Al-Ahliyyah College high school runs by Rosary sisters. With the influx of Muslim and Christian refugees and internal migration, new mosques and churches were built.
In the 19th century, the Religious Society of Friends (Quakers) established a presence in Ramallah and built the Ramallah Friends Schools, one for girls and later a boys school, to alleviate the dearth of education for women and girls. Eli and Sybil Jones opened “The Girls Training Home of Ramallah” in 1869. A medical clinic was established in 1883, with Dr. George Hassenauer serving as the first doctor in Ramallah. In 1889, the girls academy became the Friends Girls School (FGS). As the FGS was also a boarding school, it attracted a number of girls from surrounding communities, including Jerusalem, Lydda, Jaffa, and Beirut. The Friends Boys School (FBS) was founded in 1901 and opened in 1918. The Quakers opened a Friends Meeting House for worship in the city center in 1910. According to the schools' official website, most high school students choose to take the International Baccalaureate exams (IBE) instead of the traditional "Tawjihi" university exams.
The activity of foreign churches in Palestine in the late 19th century increased awareness of prosperity in the West. In Ramallah and Bethlehem, a few miles south, local residents began to seek economic opportunity overseas. In 1901, merchants from Ramallah emigrated to the United States and established import-export businesses, selling handmade rugs and other exotic wares across the Atlantic. Increased trade dramatically improved living standards for Ramallah's inhabitants. American cars, mechanized farming equipment, radios, and later televisions became attainable luxuries for upper-class families. As residents of Jaffa and Lydda moved to Ramallah, the balance of Muslims and Christians began to change.
Ramallah was declared a modern city in 1908. It had an elected municipality as well as partnership projects with the adjacent town of al-Bireh. The Friends Boys School became a temporary hospital during World War I. 
British Mandate.
The British Army occupied Ramallah in December 1917 during the war years. Following the First World War, it was designated as a mandate territory and under British rule until 1948. The economy improved in the 1920s, and the landed aristocracy and merchants of the Palestinian upper class built stately multi-storied villas, many of which still stand. The Jerusalem Electric Company brought electricity to Ramallah in 1936, and most homes were wired shortly thereafter. The same year the British inaugurated the "Palestine Broadcasting Service" in Ramallah. The British Broadcasting Corporation trained the local staff to deliver daily broadcasts in Arabic, Hebrew, and English. The station was later renamed "Kol Yerushalayim" (The Voice of Jerusalem).
During the 1936–39 Arab revolt in Palestine, Ramallah was a center of activities against the British. Nancy Parker McDowell describes vividly how the British attacked Ramallah using the Air Force. Many residents were killed and wounded. The wounded had to be transferred to Jerusalem since no significant medical facilities existed in Ramallah.
Jordanian era.
Following the creation of the State of Israel and the ensuing war, Jordan seized the part of Palestine they named the West Bank. This included Ramallah. The West Bank was relatively peaceful during the years of Jordanian rule between 1948 and 1967, with its residents enjoying freedom of movement between the West Bank, Jordan, Lebanon, and Syria. Jordan annexed the West Bank, applying its national law to the conquered territory. However, many Palestinians were jailed for being members of "illegal political parties", which included the Palestine Communist Party and other socialist and pro-independence groups. By 1953, Ramallah's population had doubled, but the economy and infrastructure could not accommodate the influx of poor villagers. Natives of Ramallah began to emigrate, primarily to the United States. By 1956, about one fourth of Ramallah's 6,000 natives had left, with Arabs from the surrounding towns and villages (particularly Hebron) buying the homes and land the émigrés left behind. 
Israeli occupation.
During the Six-Day War in 1967, Israel captured Ramallah from Jordan, imposing a military closure and conducting a census a few weeks later. Every person registered in the census was given an Israeli identity card which allowed the bearer to continue to reside there. Those who were abroad during the census lost their residency rights. For residents of Ramallah, the situation had now been reversed. For the first time in 19 years, residents could freely visit Israel and the Gaza Strip and engage in commerce there.
Unlike the Jordanians, Israel did not offer citizenship to the residents. Ramallah residents were issued permits to work in Israel, but did not gain the rights associated with Israeli citizenship. The city remained under Israeli military rule for more than four decades.
The Israeli Civil Administration (CA), established in 1981, was in charge of civilian and day-to-day services such as issuing permission to travel, build, export or import, and host relatives from abroad. The CA reprinted Jordanian textbooks for distribution in schools but did not update them. The CA was in charge of tax collection and land expropriation, which sometimes included Israeli theft of olive groves that Arab villagers had tended for generations.
According to the Israeli Human Rights activists, the development of Jewish settlements in the Ramallah area, such as Beit El and Psagot, prevented the expansion of the city and cut it off from the surrounding Arab villages. As resistance increased, Ramallah residents who were members of the Palestine Liberation Organization were jailed or deported to neighboring countries. In December 1987, the popular uprising known as the Intifada erupted.
First Intifada.
Ramallah residents were among the early joiners of the First Intifada. The Intifada Unified Leadership, an umbrella organization of various Palestinian factions, distributed weekly bulletins on the streets of Ramallah with a schedule of the daily protests, strikes and action against Israeli patrols in the city. At the demonstrations, tyres were burned in the street, and the crowds threw stones and Molotov cocktails. The IDF responded with tear gas and rubber bullets. Schools in Ramallah were forcibly shut down, and opened gradually for a few hours a day. The Israelis conducted house arrests, imposing curfews that restricted travel and exports in what Palestinians regarded as collective punishment. In response to the closure of schools, residents organized home schooling sessions to help students make up missed material; this became one of the few symbols of civil disobedience. The Intifada leadership organized "tree plantings" and resorted to the tactics used in pre-1948 Palestine, such as ordering general strikes in which no commercial businesses were allowed to open and no cars were allowed on the streets.
In 1991, the Palestinian delegation to the Madrid International Peace Conference included many notables from Ramallah. As the Intifada wound down and the peace process moved forward, normal life in Ramallah resumed. On September 13, 1993 Israeli Prime Minister Yitzhak Rabin and Palestinian Leader Yasser Arafat shook hands at a meeting at the White House. Schoolchildren in Ramallah handed out olive branches to Israeli soldiers patrolling the streets. In December 1995, in keeping with the Oslo Accords, the Israeli army abandoned the Mukataa and withdrew to the city outskirts. The newly established Palestinian Authority assumed civilian and security responsibility for the city, which was designated "Area A" under the accords.
Palestinian Authority rule.
1990s.
The years between 1993 and 2000 (known locally as the "Oslo Years") brought relative prosperity to Ramallah. Many expatriates returned to establish businesses there, and the atmosphere was one of optimism. In 2000, unemployment began to rise and the economy of Ramallah declined. The Israel Defense Forces remained in control of the territories and its government did not restore the freedom of movement enjoyed by Ramallah residents prior to the first Intifada. Travel to Jerusalem required special permits. The number and size of Israeli settlements around Ramallah increased dramatically. A network of bypass roads for use of Israeli citizens only was built around Ramallah, and Israel confiscated land for settlements.
Many official documents previously handled by the Israeli Civil Administration were now handled by the Palestinian Authority but still required Israeli approval. A Palestinian passport issued to Ramallah residents was not valid unless the serial number was registered with the Israeli authorities, who controlled border crossings. The failure of the Camp David summit in July 2000 led to the outbreak of the Second Intifada (al-Aqsa Intifada) in September 2000.
Second Intifada.
Young Ramallah residents demonstrated daily against the Israeli army, with marches to the Israeli checkpoints at the outskirts of the city. Over time, the marches were replaced by sporadic use of live ammunition against Israeli soldiers; and various attacks targeting Jewish settlers, particularly on the Israeli-only bypass roads. Army checkpoints were established to restrict movement in and out of Ramallah.
On October 12, 2000, two Israeli army reservists, Vadim Norzhich and Yosef Avrahami were lynched in Ramallah. They had taken a wrong turn, and were set upon by a mob, enraged in particular by the Muhammad al-Durrah incident in Gaza. A frenzied crowd killed the two IDF reservists, mutilated their bodies, and dragged them through the streets. Later that afternoon, the Israeli army carried out an air strike on Ramallah, demolishing the police station. Israel later succeeded in capturing and prosecuting some of those involved in the deaths of the reservists.
In 2002, Ramallah was reoccupied by Israel in an IDF operation codenamed Operation Defensive Shield. They imposed curfews, electricity cuts, school closures and disruptions of commercial life. Many Ramallah institutions, including government ministries, were vandalized, and equipment was destroyed or stolen. The IDF took over local Ramallah television stations, and social and economic conditions deteriorated. Many expatriates left, as did many other Palestinians who complained that the living conditions had become intolerable. Construction of the Israeli West Bank barrier has added to Ramallah's isolation.
Yasser Arafat established his West Bank headquarters, the Mukataa, in Ramallah. Although considered an interim solution, Ramallah became the "de facto" capital of the Palestinian Authority, now officially known as the State of Palestine. It hosts almost all governmental headquarters. In December 2001, Arafat held meetings at the Mukataa, but lived with his wife and daughter in Gaza City. After suicide bombings in Haifa, Arafat was confined to the Ramallah compound. In 2002, the compound was partly demolished by the Israeli Defense Forces and Arafat's building was cut off from the rest of the compound.
On November 11, 2004 Arafat died at the Percy training hospital of the Armies near Paris. He was buried in the courtyard of the Mukataa on November 12, 2004. The site still serves as the Ramallah headquarters of the Palestinian Authority, as well the official West Bank office of Mahmoud Abbas. Throughout 2005, while the Disengagement Plan was underway, some US government officials suggested to the Palestinian leadership to move the provisional capital back to Gaza, where it had been when the Palestinian Aurhority was first established in 1994. President Abbas, however, refrained from doing so, arguing that at this point, it was important to keep the administrative center in the West Bank in order to remind the international community that the West Bank was still awaiting territorial solution.
Economic rehabilitation.
In December 2005, local elections were held in Ramallah in which candidates from three different factions competed for the 15-seat municipal council for a four-year term. The council elected Janet Mikhail as mayor, the first woman to hold the post.
Munir Hamdan, a member of Fatah and a Ramallah businessman, discussed the concentration of government offices with a journalist. He said, “The president and prime minister have their offices here. So do the parliament and all the government ministries,” representing a "collusion" between the Palestinian Authority and Israel to turn Ramallah into the political as well as the financial capital of the Palestinians. He is particularly worried by the construction of a large new governmental complex by the PA. Hatem Abdel Kader, a Jerusalem resident, Fatah legislator and former Minister for Jerusalem Affairs, complained that “If they are building a new government compound here, that means they have no plans to be based in Jerusalem... Unfortunately, the Palestinian government of Salam Fayyad has abandoned Jerusalem in favor of Ramallah.”
Many foreign nations have located their diplomatic missions to the Palestinian Authority in Ramallah, including, , Argentina, Australia, Austria, Korea, South Africa, Norway, Sri Lanka, Switzerland, China, Poland, Portugal, The Netherlands, Russia, Jordan, Brazil, Finland, Denmark, Ireland, Germany, India, Japan, the Czech Republic, Canada and Mexico.
In November 2011, king Abdullah II of Jordan visited Ramallah for the first time since 2000.
Geography and climate.
This area enjoys a Mediterranean climate of a dry summer and mild, rainy winter with occasional snowfall. The recorded average of Ramallah's rainfall is about and minimum rainfall is and maximum rainfall is .
The Köppen climate classification places Ramallah in the Csa category. Climates of this class generally occur on the western sides of continents between the latitudes of 30° and 45°. These climates are in the polar front region in winter, and thus have moderate temperatures and changeable, rainy weather. Summers are hot and dry, due to the domination of the subtropical high pressure systems, except in the immediate coastal areas, where summers are milder due to the nearby presence of cold ocean currents that may bring fog but prevent rain.
Economy.
Ramallah has been described as the seat of power of the Palestinian Authority and serves as the headquarters for most international NGOs and embassies. Hundreds of millions of dollars in aid flowing into the city have boosted Ramallah’s economy greatly since the end of the Second Intifada.
The Ramallah construction boom is one of the most obvious signs of West Bank economic growth, estimated at an annual rate of 8 percent. This has been attributed to relative stability and Western donor support to the Palestinian Authority. Ramallah's buoyant economy continues to draw Palestinians from other West Bank towns where jobs are fewer. The built-up area has grown fivefold since 2002.
By 2010, Ramallah had become the leading center of economic and political activity in the territories under the control of the Palestinian Authority. During a building boom in the early years of the 21st century, apartment buildings and "five-star" hotels were erected, particularly in the Al-Masyoun neighborhood. In 2010, "more than one hundred" Palestinian businesses were reported to have moved to Ramallah from East Jerusalem, because “Here they pay less taxes and have more customers." One local boasted to a journalist that “Ramallah is becoming the de facto capital of Palestine.” This boast was seconded by the "New York Times" which, in 2010, called Ramallah the "de facto capital of the West Bank. According to Sani Meo, the publisher of "This Week in Palestine," "Capital or no capital, Ramallah has done well and Palestine is proud of its achievements.” Some Palestinians allege that Ramallah's prosperity is part of an Israeli "conspiracy" to make Ramallah the capital of a Palestinian state, instead of Jerusalem.
ASAL technologies, an information technology company in Ramallah, has 120 employees and is looking forward to "exponential growth." 
Demographics.
In the 1922 census of Palestine conducted by the British Mandate authorities, Ramallah had a population of 3,104; 2,972 Christians, 125 Muslims, and 10 Jews.
This had increased at the time of the 1931 census to 4,286, 3766 Christians, 519 Muslim and 1 Jew, in a total of 1014 houses.
In Sami Hadawi's 1945 survey, the population stood at 5,080, with Christians forming the majority of the population. However, the demographic makeup of the town changed drastically between 1948 and 1967, when considerable emigration of Christians took place. Slightly more than half of the city's 12,134 inhabitants were Christian by 1967, the other half Muslim.
Ramallah's population drastically decreased in the late 20th century from 24,722 inhabitants in 1987 to 17,851 in 1997. In the Palestinian Central Bureau of Statistics (PCBS) census in 1997, Palestinian refugees accounted for 60.3% of the population, which was 17,851. There were 8,622 males and 9,229 females. People younger than 20 years of age made up 45.9% of the population, while those aged between 20 and 64 were 45.4%, and residents aged over 64 constituted 4.7%.
Only in 2005 did the population reach more than 24,000. In a PCBS projection in 2006, Ramallah had a population of 25,467 inhabitants. In the 2007 PCBS census, there were 27,460 people living in the city. Sources vary about the current Christian population in the city, ranging around 25%.
Infrastructure.
Health.
In the aftermath of the 1936–39 Arab revolt, the Ramallah Hospital Foundation was established and registered as a tax exempt organization in New York in 1944. It bought large pieces of land in the south-eastern fringes of the city dedicated for the future hospital. In 1963 a hospital was opened. The present Ramallah Government Hospital and the Palestine Medical Centered are located on the land purchased by the Foundation. In January 1987 the first open-heart surgery was performed at the Hospital under the direction of Dr. Shehadeh (Shawki) Harb, a Palestinian surgeon trained in the United States.
Religious institutions.
The Jamal Abdel Nasser Mosque is one of the city's largest. The Orthodox Church of Ramallah, an Orthodox Christian convent, Melkite Catholic Church, Evangelical Lutheran Church, Arab Episcopal (Anglican) Church, Ramallah Local Church (Evangelical\Born Again) and Ramallah Baptist Church all operate schools in the city. A large new church has been built on top of one of the highest hills of Ramallah, belonging to the Coptic Orthodox Church. A small group of Jehovah Witnesses are present in the area as well and others.
During the annual "Saturday of Light" religious festival (which occurs on the Saturday between Good Friday and Easter Sunday to commemorate the light that tradition holds shone from the tomb of Jesus), the scouts hold a parade through the city streets to receive the flame from Jerusalem. (The flame is ignited in Jerusalem's Church of the Holy Sepulchre and is passed on through candles and lanterns to regional churches.) A variety of mosques and churches of different denominations dot the landscape.
Culture.
Ramallah is generally considered the most affluent and cultural, as well as the most liberal, of all Palestinian cities, and is home to a number of popular Palestinian activists, poets, artists, and musicians. It boasts a lively nightlife, with many restaurants including the Stars and Bucks Cafe, a branch of the Tche Tche Cafe and the Orjuwan Lounge, described in 2010 as two among the "dozens of fancy restaurants, bars and discotheques that have cropped up in Ramallah in the last three years."
One hallmark of Ramallah is Rukab's Ice Cream, which is based on the resin of chewing gum and thus has a distinctive taste. Another is the First Ramallah Group, a boy- and girl-scout club that also holds a number of traditional dance (Dabka) performances and is also home to men's and women's basketball teams that compete regionally. International music and dance troupes occasionally make a stop in Ramallah, and renowned Argentine pianist Daniel Barenboim performs there often. The Khalil Sakakini Cultural Center, founded in 1996, is a popular venue for such events. The Al-Kasaba Theatre is a venue for plays and movies. In 2004, the state-of-the art Ramallah Cultural Palace opened in the city. The only cultural center of its kind in the Palestinian-governed areas, it houses a 736-seat auditorium, as well as conference rooms, exhibit halls, and movie-screening rooms. It was a joint venture of the Palestinian Authority, the United Nations Development Programme (UNDP), and the Japanese government. Ramallah hosted its first annual international film festival in 2004.
Ramallah folklore.
Ramallah, like most Palestinian areas, has a rich folklore of song and dance. Songs accompanied people in every occasion whether it was the harvest season, roofing a house, traveling, coming back from travel, engagement, wedding, or even death. Most of the songs were sung by the women with the exception of Zaffeh and Mal'ab which are sung by the men at wedding celebrations. Palestinian educator Bahia Khalil's book "Ramallah Folklore Songs and Traditions" documents to a great extend this oral tradition inherited from one generation to another. The second edition of the book was published in 2002 by the American Federation of Ramallah, Palestine, an organization for Palestinian-Americans from the Ramallah region living in the United States.
Foreign travelers to Palestine in late 19th and early 20th centuries often commented on the rich variety of costumes among the Palestinian people, and particularly among the fellaheen or village women. Until the 1940s, a woman's economic status, whether married or single, and the town or area they were from could be deciphered by most Palestinian women by the type of cloth, colors, cut, and embroidery motifs, or lack thereof, used for the robe-like dress or "thoub" in Arabic
Palestinian costume.
Though experts in the field trace the origins of Palestinian costumes to ancient times, there are no surviving clothing artifacts from this early period against which the modern items might be definitively compared. Influences from the various empires to have ruled Palestine, such as Ancient Egypt, Ancient Rome, Byzantine empire, and Ayyubids, among others, have been documented by scholars largely based on the depictions in art and descriptions in literature of costumes produced during these times.
Hanan Munayyer, collector and researcher of Palestinian clothing, sees examples of proto-Palestinian attire in artifacts from the Canaanite period (1500 BCE) such as Egyptian paintings depicting Canaanites in A-shaped garments. Munayyer says that from 1200 BC to 1940 AD, all Palestinian dresses were cut from natural fabrics in a similar A-line shape with triangular sleeves. This shape is known to archaeologists as the "Syrian tunic" and appears in artifacts such as an ivory engraving from Megiddo dating to 1200 BC.
Until the 1940s, traditional Palestinian costumes reflected a woman's economic and marital status and her town or district of origin, with knowledgeable observers discerning this information from the fabric, colours, cut, and embroidery motifs (or lack thereof) used in the apparel.
Due to the difficulty of travel in the 19th century, villages in Palestine remained isolated. As a result, clothing and accessories became a statement of region. In Ramallah, the back panels of dresses often incorporated a palm tree motif embroidered in cross-stitch. Ramallah women were famous for their distinctive dress of white linen fabric embroidered with red silk thread. The headdress or "smadeh" worn in Ramallah was common throughout northern Palestine: a small roundish cap, padded and stiffened, with gold and silver coins set in a fringe with a long veil pinned to the back, sometimes of silk and sometimes embroidered.
Twin towns – sister cities.
Ramallah is twinned with:

</doc>
<doc id="44133" url="https://en.wikipedia.org/wiki?curid=44133" title="Overture">
Overture

Overture (French "ouverture", "opening"; German "Ouvertüre", "Vorspiel", i.e., "prelude", lit. "play before") in music is the term originally applied to the instrumental introduction to an opera. During the early Romantic era, composers such as Beethoven and Mendelssohn began to use the term to refer to independent, self-existing instrumental, programmatic works that presaged genres such as the symphonic poem. These were "at first undoubtedly intended to be played at the head of a programme".
History.
17th century.
The idea of an instrumental opening to opera existed during the 17th century. Peri's "Euridice" opens with a brief instrumental ritornello, and Monteverdi's "L'Orfeo" (1607) opens with a toccata, in this case a fanfare for muted trumpets. More important, however, was the prologue, which comprised sung dialogue between allegorical characters which introduced the overarching themes of the stories depicted.
French overture.
As a musical form, however, the French overture first appears in the court ballet and operatic overtures of Jean-Baptiste Lully, which he elaborated from a similar, two-section form called "Ouverture", found in the French ballets de cour as early as 1640. This French overture consists of a slow introduction in a marked "dotted rhythm" (i.e., exaggerated iambic, if the first chord is disregarded), followed by a lively movement in fugato style. The overture was frequently followed by a series of dance tunes before the curtain rose, and would often return following the Prologue to introduce the action proper. This ouverture style was also used in English opera, most notably in Henry Purcell's "Dido and Æneas". Its distinctive rhythmic profile and function thus led to the French overture style as found in the works of late Baroque composers such as Johann Sebastian Bach. The style is most often used in preludes to suites, and can be found in non-staged vocal works such as cantatas, for example in the opening chorus of Bach's cantata "Nun komm, der Heiden Heiland, BWV 61". Handel also uses the French overture form in some of his Italian operas such as Giulio Cesare.
Italian overture.
In Italy, a distinct form called "overture" arose in the 1680s, and became established particularly through the operas of Alessandro Scarlatti, and spread throughout Europe, supplanting the French form as the standard operatic overture by the mid-18th century. Its usual form is in three generally homophonic movements: fast–slow–fast. The opening movement was normally in duple metre and in a major key; the slow movement in earlier examples was usually quite short, and could be in a contrasting key; the concluding movement was dance-like, most often with rhythms of the gigue or minuet, and returned to the key of the opening section. As the form evolved, the first movement often incorporated fanfare-like elements and took on the pattern of so-called "sonatina form" (sonata form without a development section), and the slow section became more extended and lyrical. Italian overtures were often detached from their operas and played as independent concert pieces. In this context, they became important in the early history of the symphony.
18th Century.
Prior to the 18th century, the symphony and the overture were almost interchangeable, with overtures being extracted from operas to serve as stand alone instrumental works, and symphonies were tagged to the front of operas as overtures. With the reform of "opera seria," the overture began to distinguish itself from the symphony, and composers began to link the content of overtures to their operas dramatically and emotionally. Elements from the opera are foreshadowed in the overture, following the reform ideology that the music and every other element on stages serves to enhance the plot. One such overture was that of "La Magnifique" by André-Ernest-Modeste Grétry, in which several of the arias are quoted.
19th-century opera.
In 19th-century opera the overture, "Vorspiel", "Einleitung," Introduction, or whatever else it may be called, is generally nothing more definite than that portion of the music which takes place before the curtain rises. Richard Wagner's "Vorspiel" to "Lohengrin" is a short self-contained movement founded on the music of the Grail.
In Italian opera after about 1800, the "overture" became known as the "sinfonia". Fisher also notes the term "Sinfonia avanti l'opera" (literally, the "symphony before the opera") was "an early term for a sinfonia used to begin an opera, that is, as an overture as opposed to one serving to begin a later section of the work".
Concert overture.
Early 19th century.
Although by the end of the eighteenth century opera overtures were already beginning to be performed as separate items in the concert hall, the "concert overture", intended specifically as an individual concert piece without reference to stage performance and generally based on some literary theme, began to appear early in the Romantic era. Carl Maria von Weber wrote two concert overtures, "Der Beherrscher der Geister" ('The Ruler of the Spirits', 1811, a revision of the overture to his unfinished opera "Rübezahl" of 1805), and "Jubel-Ouvertüre" ('Jubilee Overture', 1818, incorporating "God Save the King" at its climax). However, the overture "A Midsummer Night's Dream" (1826) by Felix Mendelssohn is generally regarded as the first concert overture (Temperley 2001). Mendelssohn's other contributions to this genre include his "Calm Sea and Prosperous Voyage" overture (1828), his overture "The Hebrides" (1830; also known as "Fingal's Cave") and the overtures "Die schöne Melusine" ("The Fair Melusine", 1834) and "Ruy Blas" (1839). Other notable early concert overtures were written by Hector Berlioz (e.g., "Les Francs juges" (1826), and "Le corsaire" (1828)).
Later 19th century.
In the 1850s the concert overture began to be supplanted by the symphonic poem, a form devised by Franz Liszt in several works that began as dramatic overtures. The distinction between the two genres was the freedom to mould the musical form according to external programmatic requirements (Temperley 2001). The symphonic poem became the preferred form for the more "progressive" composers, such as César Franck, Richard Strauss, Alexander Scriabin, and Arnold Schoenberg, while more conservative composers like Anton Rubinstein, Tchaikovsky, Johannes Brahms, Robert Schumann and Arthur Sullivan remained faithful to the overture.
In the age when the symphonic poem had already become popular, Brahms wrote his "Academic Festival Overture", Op. 80, as well as his "Tragic Overture", Op. 81. An example clearly influenced by the symphonic poem is Tchaikovsky's "1812 Overture". His equally well-known "Romeo and Juliet" is also labelled a 'fantasy-overture'.
20th century.
In European music after 1900, an example of an overture displaying a connection with the traditional form is Dmitri Shostakovich's "Festive Overture", Op. 96 (1954), which is in two linked sections, "Allegretto" and "Presto" (Temperely 2001). Malcolm Arnold's "A Grand, Grand Overture", Op. 57 (1956), is a 20th-century parody of the late 19th century concert overture, scored for an enormous orchestra with organ, additional brass instruments, and obbligato parts for four rifles, three Hoover vacuum cleaners (two uprights in B, one horizontal with detachable sucker in C), and an electric floor polisher in E; it is dedicated "to President Hoover".
Film.
In motion pictures, an overture is a piece of music setting the mood for the film before the opening credits start. For a comprehensive list, see the list of films with overtures.
List of some common overtures.
Some well-known or commonly played Overtures:

</doc>
<doc id="44136" url="https://en.wikipedia.org/wiki?curid=44136" title="John Huston">
John Huston

John Marcellus Huston (August 5, 1906 – August 28, 1987) was an American film director, screenwriter and actor. He wrote the screenplays for most of the 37 feature films he directed, many of which are today considered classics: "The Maltese Falcon" (1941), "The Treasure of the Sierra Madre" (1948), "Key Largo" (1948), "The Asphalt Jungle" (1950), "The African Queen" (1951), "Moulin Rouge" (1952), "The Misfits" (1961), and "The Man Who Would Be King" (1975). During his 46-year career, Huston received 15 Oscar nominations, won twice, and directed both his father, Walter Huston, and daughter, Anjelica Huston, to Oscar wins in different films.
Huston was known to direct with the vision of an artist, having studied and worked as a fine art painter in Paris in his early years. He continued to explore the visual aspects of his films throughout his career: sketching each scene on paper beforehand, then carefully framing his characters during the shooting. While most directors rely on post-production editing to shape their final work, Huston instead created his films while they were being shot, making them both more economical and cerebral, with little editing needed.
Most of Huston's films were adaptations of important novels, often depicting a "heroic quest," as in "Moby Dick", or "The Red Badge of Courage". In many films, different groups of people, while struggling toward a common goal, would become doomed, forming "destructive alliances," giving the films a dramatic and visual tension. Many of his films involved themes such as religion, meaning, truth, freedom, psychology, colonialism and war.
Before becoming a Hollywood filmmaker, he had been an amateur boxer, reporter, short-story writer, portrait artist in Paris, a cavalry rider in Mexico, and a documentary filmmaker during World War II. Huston has been referred to as "a titan", "a rebel", and a "renaissance man" in the Hollywood film industry. Author Ian Freer describes him as "cinema's Ernest Hemingway"—a filmmaker who was "never afraid to tackle tough issues head on."
Early life.
John Huston was born on August 5, 1906, in Nevada, Missouri. He was the only child of Rhea (née Gore) and Canadian-born Walter Huston, originally Walter Houghston. His father was an actor, initially in vaudeville, and later in films. His mother initially worked as a sports editor for various publications but gave it up after Huston was born. Similarly, his father gave up his stage acting career for steady employment as a civil engineer, although he returned to stage acting within a few years. He would later become highly successful on both Broadway and then in motion pictures. He had Scottish, Scots-Irish, English and Welsh ancestry.
Huston's parents divorced in 1913, when he was 6, and as a result much of his childhood was spent living in boarding schools. During summer vacations, he traveled with each of his parents separately — with his father on vaudeville tours, and with his mother to racetracks or other sports events. The young Huston benefited greatly from seeing his father act on stage, as he was later drawn to the world of acting. Some critics, such as Lawrence Grobel, surmise that his relationship with his mother may have been the cause of his five marriages, and why few of his relationships lasted. Grobel wrote, "When I interviewed some of the women who had loved him, they inevitably referred to his mother as the key to unlocking Huston's psyche." According to actress Olivia de Havilland, "she mother was the central character. I always felt that John was ridden by witches. He seemed pursued by something destructive. If it wasn't his mother, it was his idea of his mother."
As a child he was often ill and was treated for an enlarged heart and kidney ailments. He recovered after an extended bedridden stay in Arizona, and moved with his mother to Los Angeles, where he went to Lincoln Heights High School. He dropped out of high school after two years to become a professional boxer, and by age 15 was already a top-ranking amateur lightweight boxer in California. He ended his brief boxing career after suffering a broken nose.
He also "plunged" himself into a multitude of interests, including abstract painting, ballet, English and French literature, opera, and horseback riding. Living in Los Angeles he became "infatuated" with the new film industry and motion pictures, but as a spectator only. To Huston, "Charlie Chaplin was a god."
He moved back to New York to live with his father, who was then acting in off-Broadway productions, and John had a few small roles. He remembers, while watching his father rehearse, being fascinated with the mechanics of acting:
After a short period acting on stage, and having undergone surgery, he traveled on his own to Mexico. During his two years there, among his other adventures, he got a position riding as an honorary member of the Mexican cavalry. He returned to Los Angeles and married a girlfriend from high school, Dorothy Harvey. Their marriage only lasted a year.
Early career as writer.
During his stay in Mexico, he wrote a play called "Frankie and Johnny", based on the ballad of the same title. After selling it easily, he decided that writing would be a viable career, and he focused on it. His self-esteem was enhanced when H. L. Mencken, editor of the popular magazine, "American Mercury," bought two of his stories, "Fool" and "Figures of Fighting Men." During subsequent years his stories and feature articles were published in "Esquire," "Theatre Arts," and "The New York Times." He also worked for a period on the "New York Graphic." In 1931, when he was 25, he moved back to Los Angeles with his hopes aimed at writing for the blossoming film industry, where the silent film industry had given way to "talkies", and writers were in demand. In addition, his father had earlier moved there where he was already successful in a number of films.
He received a script editing contract with Samuel Goldwyn Productions, but after six months of receiving no assignments, quit to work for Universal Studios, where his father was by then a star. At Universal, he got a job in the script department, and began by writing dialogue for a number of films in 1932, including "Murders in the Rue Morgue", "A House Divided", and "Law and Order". The last two also starred his father, Walter Huston. In addition, "House Divided" was directed by William Wyler, who gave Huston his first real "inside view" of the filmmaking process during all stages of production. Wyler and Huston would also later become close friends and collaborators on a number of leading films.
Huston gained a reputation as a "lusty, hard-drinking libertine" during his first years as a writer in Hollywood. Huston describes those years as a "series of misadventures and disappointments", however. His brief career as a Hollywood writer ended suddenly after a car he was driving struck and killed a young female pedestrian. He was absolved of blame by a coroner's jury, but the incident left him "traumatized" nonetheless, and he moved to London and Paris, living as a "drifter."
By 1937, after five years, the 31-year-old Huston returned to Hollywood intent on being a "serious writer." He also married Lesley Black. His first job was as scriptwriter with Warner Brothers Studio, with his personal longterm goal of directing his own scripts. For the next four years, he co-wrote scripts for major films such as "Jezebel, " "The Amazing Dr. Clitterhouse", "Juarez", "Dr. Ehrlich's Magic Bullet" and "Sergeant York" (1941). He was nominated for an Academy Award for his writing both "Ehrlich" and "Sergeant York." Huston writes that "Sergeant York", which was directed by Howard Hawks, has "gone down as one of Howard's best pictures, and Gary Cooper had a triumph playing the young mountaineer."
Huston was becoming a recognized and respected screenwriter. He was able to persuade Warners to give him a chance to direct, under the condition that his next script also became a hit. Huston writes:
They indulged me rather. They liked my work as a writer and they wanted to keep me on. If I wanted to direct, why, they'd give me a shot at it, and if it didn't come off all that well, they wouldn't be too disappointed as it was to be a very small picture.
The next script he was given to work on was "High Sierra" (1941), to be directed by Raoul Walsh. The film became the hit Huston wanted. It also made Humphrey Bogart a star with his first major role, as a gunman on the run. Warners kept their end of the bargain, and gave Huston his choice of subject.
Screenwriter and director.
"The Maltese Falcon" (1941).
For his first directing assignment, Huston chose Dashiell Hammett's detective thriller, "The Maltese Falcon", a film which had already failed at the box office in two earlier versions by Warners. However, studio head Jack L. Warner approved of Huston's treatment of Hammett's 1930 novel, as he stood by his word to let Huston choose his first subject.
Huston kept the screenplay close to the novel, keeping much of Hammett's dialogue, and directing it in an uncluttered style, much like the book's narrative. He also did the unusual preparation for this, his first directing job, by sketching out each shot beforehand, including camera positions, lighting, and compositional scale, for such things as closeups.
He especially benefited by selecting a superior cast, giving Humphrey Bogart the lead role. Bogart was happy to take the role, as he liked working with Huston. In addition, the supporting cast included other noted actors: Mary Astor, Peter Lorre, Sydney Greenstreet (his first film role), and his own father, Walter Huston. The film, however, was given only a small B-movie budget, and received minimal publicity by Warners, as they had low expectations. The entire film was made in eight weeks for only $300,000.
Upon receiving immediate enthusiastic response by the public and critics, Warners was surprised. Critics hailed the film as a "classic", and up until the present day it is claimed by many to be the "best detective melodrama ever made." "Herald Tribune" critic Howard Barnes called it a "triumph." Huston again received an Academy Award nomination for the screenplay. After this film, Huston would from then on direct all of his screenplays, except for one, "Three Strangers" (1946).
In 1942, he directed two more hits, "In This Our Life" (1942), starring Bette Davis, and "Across the Pacific", another thriller starring Humphrey Bogart.
Army years during World War II.
In 1942 he served in the United States Army during World War II to make films for the Army Signal Corps. While in uniform with the rank of captain, he directed and produced three films that some critics rank as "among the finest made about World War II: "Report from the Aleutians" (1943), about soldiers preparing for combat; "The Battle of San Pietro" (1945), the story (censored by the Army) of a failure by America's intelligence agencies which resulted in many deaths, and "Let There Be Light" (1946), about psychologically damaged veterans, also censored for 35 years, until 1981. He rose to the rank of major and received the Legion of Merit award for "courageous work under battle conditions." Nonetheless, all of his films made for the Army were "controversial", and either not released, censored, or banned outright, as they were considered "demoralizing" to soldiers and the public. Years later, after moving to Ireland, his daughter, actress Anjelica Huston, recalled that the "main movies we watched were the war documentaries."
Huston did an uncredited rewrite of Anthony Veiller's screenplay for "The Stranger" (1946), a film he was to have directed. When Huston became unavailable Orson Welles was offered the opportunity to direct. He had been cast in the role of a high-ranking Nazi fugitive who manages to settle in New England under an assumed name.
"The Treasure of the Sierra Madre" (1948).
His next picture, which he wrote, directed, and briefly appeared in as an American, asked to "help out a fellow American, down on his luck", was "The Treasure of the Sierra Madre" (1948). It would become one of the films which established his reputation as a leading filmmaker. The film, also starring Humphrey Bogart, was the story of three drifters who band together to prospect for gold. Huston also gave a supporting role to his father, Walter Huston.
Warners studio was initially uncertain what to make of the film. They had allowed Huston to film on location in Mexico, which was a "radical move" for a studio at the time. They also knew that Huston was gaining a reputation as "one of the wild men of Hollywood." In any case, studio boss Jack L. Warner initially "detested it." But whatever doubts Warners had were soon removed, as the film achieved widespread public and critical acclaim. Hollywood writer James Agee called it "one of the most beautiful and visually alive movies I have ever seen." "Time" magazine described it as "one of the best things Hollywood has done since it learned to talk." Huston won Oscars for Best Director and Best Adapted Screenplay; his father won for Best Supporting Actor. It also won other awards in the U.S. and overseas. "Film Comment" magazine devoted four pages to the film in its May–June 1980 edition, with author Richard T. Jameson offering his impressions:
This film has impressed itself on the heart and mind and soul of anyone who has seen it, to the extent that filmmakers of great originality and distinctiveness like Robert Altman and Sam Peckinpah can be said to have remade it again and again ... without compromising its uniqueness.
Also in 1948 he directed his next film, "Key Largo", again with Humphrey Bogart starring. It was the story about a disillusioned returning veteran clashing with gangsters on a remote Florida key. It co-starred Lauren Bacall, Claire Trevor, and Edward G. Robinson. The film was an adaptation of the stage play by Maxwell Anderson, and the film itself seemed overly stage-bound for many viewers. However, the "outstanding performances" by all the actors saved the film, and Claire Trevor won an Oscar for best supporting actress. Huston was annoyed that the studio cut several scenes from the final release without his agreement. That, along with some earlier disputes, angered Huston enough that he left the studio when his contract expired.
"The Asphalt Jungle" (1950).
In 1950 he wrote and directed "The Asphalt Jungle", a film which broke new ground by depicting criminals as somewhat sympathetic characters, simply doing their professional work, "an occupation like any other", or what Huston calls "a left-handed form of human endeavor." Huston achieved that effect by giving "deep attention" to the plot, involving a large jewelry theft, by examining the minute, step by step details and difficulties each of the characters had of carrying it out. In doing so, some critics felt that Huston had achieved an almost "documentary" style.
Film critic Andrew Sarris considered it to be "Huston's best film", and the film that made Marilyn Monroe a recognized actress. Sarris also notes the similar themes in many of Huston's films, as exemplified by this one: "His protagonists almost invariably fail at what they set out to do." This theme was also similar to the story in "Treasure of the Sierra Madre", where greed became the cause of the group's undoing.
It starred Sterling Hayden and Huston's personal friend, Sam Jaffe. It also became the first serious role for Marilyn Monroe, according to Huston: "it was, of course, where Marilyn Monroe got her start." The film succeeded at the box office and Huston was again nominated for an Oscar for best screenplay and best director, along with winning the Screen Directors Guild Award. It would subsequently become a model for many similar movies by other filmmakers.
"The Red Badge of Courage" (1951).
After completing "The Asphalt Jungle", Huston's next film, "The Red Badge of Courage" (1951), was of a completely different subject: war and its effect on soldiers. While in the army during World War II, he became interested in Stephen Crane's classic American Civil War novel of the same title. For the starring role, Huston chose World War II hero Audie Murphy to play the young Union soldier who deserts his company out of fear, but later returns to fight alongside them. MGM, however, saw the message of the movie as too antiwar. Without Huston's input, they cut down the running time of the film from eighty-eight minutes to sixty-nine, added narration, and deleted what Huston felt was a crucial scene.
The movie did poorly at the box office. Huston suggests that it was possibly because it "brought war very close to home." Huston recalls that at the preview showing, before the film was halfway through, "damn near a third of the audience got up and walked out of the theater." Despite the "butchering" and weak public response, film historian Michael Barson describes the movie as "a minor masterpiece."
"The African Queen" (1951).
Before the "Asphalt Jungle" opened in theaters, Huston was already in Africa shooting "The African Queen" (1951), a story based on C. S. Forester's popular novel. It starred Humphrey Bogart and Katharine Hepburn in a combination of romance, comedy and adventure. Barson calls it "one of the most popular Hollywood movies of all time." The film's producer, Sam Spiegel, urged Huston to change the ending to allow the protagonists to survive, instead of dying. Huston agreed, and the ending was rewritten. It became Huston's most successful film financially, and "it remains one of his finest works." Huston was nominated for two Academy Awards—best director and best screenplay. Bogart, however, won an Oscar for best actor, his first time winning.
HUAC period.
In 1952 Huston moved to Ireland as a result of his "disgust" at the "witch-hunt" and the "moral rot" he felt was created by House Committee on Un-American Activities (HUAC), which had affected many of his friends in the movie industry. Huston had, with friends including director William Wyler and screenwriter Philip Dunne, established the "Committee for the First Amendment", as a response to the ongoing government investigations into communists within the film industry. The HUAC was calling numerous filmmakers, screenwriters, and actors to testify about any past affiliations. He tries to describe in general the types of people who were alleged communists:
"Moby Dick" (1956).
Huston took producing, writing, and directing credits for his next two films: "Moulin Rouge" (1953); and "Beat the Devil" (1953). "Moby Dick" (1956), however, was written by Ray Bradbury, although Huston had his name added to the screenplay credit after the completion of the project. Although Huston had personally hired Bradbury to adapt Herman Melville's novel into a screenplay, Bradbury and Huston did not get along during pre-production, and Bradbury later dramatized their relationship in the short story "Banshee"; Peter O'Toole would later play the role based on John Huston when "Banshee" was adapted into an episode of Ray Bradbury Theater.
Huston had been planning to film Herman Melville's "Moby Dick" for the previous ten years, and originally saw it as an excellent part for his father, Walter Huston. However, his father died in 1950, and he chose Gregory Peck to play the starring role of Captain Ahab. The movie was filmed over a three-year period on location in Ireland, where Huston was then living. The fishing village of New Bedford, Massachusetts was recreated along the waterfront; the sailing ship in the film was fully constructed to be seaworthy; and three 100-foot whales were built out of steel, wood, and plastic. However, the film failed at the box office, with some critics, like David Robinson, suggesting that the movie lacked the "mysticism of the book" and thereby "loses its significance."
"The Misfits" (1961).
Of his next five films, only "The Misfits" (1961), found critical approval. However, critics have noted the "retrospective atmosphere of doom" which now hangs over the film. Clark Gable, the star, died of a heart attack a few days after the filming was completed; Marilyn Monroe never did another film and died a year later; and costars Montgomery Clift and Thelma Ritter also died over the next few years. During the filming itself, Monroe was often on drugs of various kinds, which led to her arriving late on the set and often forgetting her lines. Monroe's problems also led to the breakup of her marriage to the film's scriptwriter, Arthur Miller, "virtually on set." Huston later commented about this period in her career: "Marilyn was on her way out. Not only of the picture, but of life."
"Freud: the Secret Passion" (1962).
He followed "The Misfits" with "", a film quite different from most of his others. Besides directing, he also narrates portions of the story. Film historian Stuart M. Kaminsky notes that Huston presents Sigmund Freud, played by Montgomery Clift, "as a kind of savior and messiah", with an "almost Biblical detachment." As the film begins, Huston describes Freud as a "kind of hero or God on a quest for mankind":
This is the story of Freud's descent into a region as black as hell, man's unconscious, and how he let in the light.
Huston explains how he became interested in psychotherapy, the subject of the film:
I first got into that through an experience in a hospital during the war, where I made a documentary about patients suffering from battle neuroses. I was in the army and made the picture "Let There Be Light". That experience started my interest in psychotherapy, and to this day Freud looms as the single huge figure in that field.
"The Night of the Iguana" (1964).
For his next film, Huston once again traveled down to Puerto Vallarta, Mexico, after meeting an architect by the name of Guillermo Wulff who owned property and businesses in the town. The filming would take place in a beach cove called Mismaloya, about thirty minutes south of town. Huston adapted the stage play by Tennessee Williams. The film stars Richard Burton and Ava Gardner, and was nominated for several Academy Awards. Production attracted intense worldwide media attention, due to Burton bringing his celebrity mistress Elizabeth Taylor (who was married to singer Eddie Fisher at the time) to Puerto Vallarta, Mexico. Huston liked the town where filming took place so much that he bought a house near there. As did Richard Burton and Elizabeth Taylor. Guillermo Wulff and Huston became friends and always spent time together while Huston was in town, more frequently at Wulff's El Dorado Restaurant on Los Muertos Beach. The owners of Taylor's original home have since completely remodeled the property; Casa Kimberly is a luxury boutique hotel with high-end restaurant.
"The Bible: In the Beginning" (1966).
Producer Dino De Laurentis traveled to Ireland to ask Huston to direct "". Although De Laurentis had ambitions for a broader story, he realized that the subject could not be adequately covered and limited the story to the first half of the Book of Genesis. Huston enjoyed directing the film, as it gave him a chance to indulge his love of animals. Besides directing he also played the role of Noah and the voice of God. The film did poorly at the box office, however, and at a cost of 18 million dollars, it was the most expensive movie in his career. Huston likes describing details about the filming:
Every morning before beginning work, I visited the animals. One of the elephants, Candy, loved to be scratched on the belly behind her foreleg. I'd scratch her and she would lean farther and farther toward me until there was some danger of her toppling over on me. One time I started to walk away from her, and she reached out and took my wrist with her trunk and pulled me back to her side. It was a command: "Don't stop!" I used it in the picture. Noah scratches the elephant's belly and walks away, and the elephant pulls him back to her time after time.
"Fat City" (1972).
After several films that were not well received, Huston returned to critical acclaim with "Fat City". Based on Leonard Gardner's 1969 novel of the same name, it was about an aging, washed-up alcoholic boxer in Stockton, California trying to get his name back on the map, while having a new relationship with a world weary alcoholic, and an amateur boxer trying to find success in boxing. The film was nominated for several awards upon its release. It starred Stacy Keach, a young Jeff Bridges, and Susan Tyrrell, in which she was nominated for an Academy Award for Best Supporting Actress. Roger Ebert stated "Fat City" as one of Huston's best films, giving it four out of four stars, his highest rating.
"The Man Who Would Be King" (1975).
Perhaps Huston's most highly regarded film of the 1970s, "The Man Who Would Be King" was both a critical and commercial success. Huston had been planning to make this film since the 50's, originally with his friends Humphrey Bogart and Clark Gable. Eventually the lead roles went to Sean Connery and Michael Caine. The movie was filmed on location in North Africa. The film was praised for its use of old fashioned escapism and entertainment. Steven Spielberg has cited the film as one of his inspirations for his film "Raiders of the Lost Ark".
"Wise Blood" (1979).
After filming "The Man Who Would Be King", Huston took his longest break between directing films. He returned with an offbeat and somewhat controversial film based on the novel "Wise Blood". Here, Huston showed his skills as a storyteller, and boldness when it came to difficult subjects such as religion.
"Under the Volcano" (1984).
Huston's last film set in Mexico stars Albert Finney as an alcoholic ambassador during the beginnings of World War II. The film gained a strong critical reception, most notably for Finney's portrayal of a desperate and depressed alcoholic. The film was also a success on the independent circuit.
"The Dead" (1987).
John Huston's final film is an adaptation of the classic short story by James Joyce. This may have been one of Huston's most personal films, due to his citizenship in Ireland and his passion for classic literature. Huston directed most of the film from a wheelchair, as he needed an oxygen tank to breathe during the last few months of his life. The film was nominated for two Academy Awards, and was praised by critics. Roger Ebert eventually placed it in his Great Movies list; a section of movies he claims to be some of the best ever made. Huston died nearly four months before the film's release date.
As an actor.
Toward the end of his career he also began to act in various films. In 1963, director Otto Preminger asked if he would portray a Boston prelate in "The Cardinal", and, writes author Philip Kemp, he "virtually stole the picture." He was nominated for an Academy Award for Best Supporting Actor for his role. He had a little participation (as did many others) in 1967's "Casino Royale" as actor and director. He acted in Roman Polanski's "Chinatown" (1974) as the film's master villain, and as Teddy Roosevelt's secretary of state John Hay in "The Wind and the Lion". Huston enjoyed acting and denied that he took it all that seriously. "It's a cinch," he once said, "and they pay you damn near as much as you make directing."
Huston said he did not regard himself very highly as an actor, saying he was only proud of his performance in "Chinatown", although he had also greatly enjoyed acting in "Winter Kills". He also played the Lawgiver in "Battle for the Planet of the Apes".
Huston is also famous to a generation of fans of J. R. R. Tolkien's Middle-earth stories as the voice of the wizard Gandalf in the Rankin/Bass animated adaptations of "The Hobbit" (1977) and "The Return of the King" (1980).
Movie themes.
Huston's films were insightful about human nature and human predicaments. They also sometimes included scenes or brief dialogue passages that were remarkably prescient concerning environmental issues that came to public awareness in the future, in the period starting about 1970; examples include "The Misfits" and "The Night of the Iguana" (1964). Huston spent long evenings carousing in the Nevada casinos after filming, surrounded by reporters and beautiful women, gambling, drinking, and smoking cigars.
According to Kaminsky, Huston's stories were often about "failed quests" by a group of different people. The group would persist in the face of poor odds, doomed at the outset by the circumstances created by an impossible situation. However, some members of the doomed group usually survive, those who are "cool" and "intelligent", or someone who "will sacrifice everything for self-understanding and independence". Those types of characters are exemplified by Bogart in "The Maltese Falcon", and Montgomery Clift in "Freud."
Another type of quest often seen in Huston's films involve a pair of potential lovers trying to face a hostile world. Flint adds, however, that he "bucked Hollywood's penchant for happy endings", and many of his stories ended with "love unsatisfied".
Film historian James Goodwin adds that in virtually all of his films, there is some type of "heroic quest — even if it involves questionable motives or destructive alliances". In addition, the quest "is preferable to the spiritless, amoral routines of life". As a result, his best films, according to Flint, "have lean, fast-paced scripts and vibrant plots and characterizations, and many of them deal ironically with vanity, avarice and unfulfilled quests".
However, in the opinion of critics Tony Tracy and Roddy Flynn, "... what fundamentally fascinated Huston was not movies "per se" — that is, form — but the human condition ... and literature offered a road map for exploring that condition." In many of his films, therefore, he tried to express his interest by developing themes involving some of the "grand narratives" of the twentieth century, such as "faith, meaning, truth, freedom, psychology, colonialism, war and capitalism".
To Jameson, all of Huston's films are adaptations, and he believes that through his films there was a "cohesive world-view, not only thematically but also stylistically; there is the Huston look". The "Huston look" was also noted by screenwriter James Agee, who adds that this "look proceeds from Huston's sense of what is natural to the eye and his delicate, simple feeling for space relationships." In any case, notes Flint, Huston took "uncommon care to preserve the writer's styles and values ... and sought repeatedly to transpose the interior essence of literature to film with dramatic and visual tension", as he did in "Red Badge of Courage," "Moby Dick," and "Under the Volcano."
Religion is also a theme that runs through many of Huston's films. In "The Night of the Iguana," Kaminsky notes how Richard Burton, while preaching a sermon to his congregation, seems "lost, confused, his speech is gibberish", and leads his congregation to turn away from him. In other films, adds Kaminsky, religion is seen as "part of the fantasy world", that the actors must overcome to survive physically or emotionally. "These religious zealots counsel a move away from the pleasure of the world and human love, a world that Huston believes in," concludes Kaminsky. Such religious themes were also seen in "The Bible," and "Wise Blood," for example.
To Barson, however, Huston was among the "least consistent" filmmakers, although he concludes that he was one of the "most interesting directors of the past sixty years". Throughout his long career, many of his films did poorly and were criticized as a result. To a writer in 1972 he commented, "Criticism isn't a new experience for me. Pictures that are now thought of as, forgive the term, classics, weren't all that well thought of at the time they came out." After an interview a few years before he died, the reporter writes that "Huston said he missed the major studio era when people savored making movies, not just money."
According to Roger Ebert, on his review of "Fat City", "His fascination with underdogs and losers. The characters in Huston movies hardly ever set out to achieve what they're aiming for. Sam Spade, in "The Maltese Falcon", Huston's first film, ends up minus one partner and one woman he thought he could trust. Everyone is a loser in "The Treasure of the Sierra Madre", and the gold blows back into the dust and is lost in it. Ahab, in "Moby Dick". Marlon Brando's career Army officer in "Reflections in a Golden Eye", even Bogart and Hepburn in "The African Queen" – they all fall short of their plans. "The African Queen" does have a happy ending, but it feels tacked-on and ridiculous, and the Queen destroys itself in destroying the German steamer. So this "City" is a theme we find in Huston's work, but rarely does he fit it to characters and a time and place so well as in "Fat City". Maybe that's because Huston knows the territory: he was a professional boxer himself for a while, and not a very good one."
Directing techniques.
George Stevens, Jr. notes that while many directors rely on post-production editing to shape their final work, Huston instead created his films while they were being shot: "I don't even know the editor of my films most of the time," Huston said. Actor Michael Caine also observed the same technique: "Most directors don't know what they want so they shoot everything they can think of — they use the camera like a machine gun. John uses it like a sniper."
Film writer Peter Flint also agrees and points out other benefits to that style: "He shot economically, eschewing the many protective shots favored by timid directors, and edited cerebrally so that financial backers would have trouble trying to cut scenes." Huston shot most of his films on location, working "intensely" six days a week, and "on Sundays, played equally intense poker with the cast and crew."
When asked how he envisions his films while directing and what his goals are, Huston replied:
To me the ideal film — which I've never succeeded in making — would be as though the reel were behind one's eyes and you were projecting it yourself, seeing what you wish to see. This has a great deal in common with thought processes ... That's why I think the camera is an eye as well as a mind. Everything we do with the camera has physiological and mental significance.
According to Kaminsky, much of Huston's vision probably came from his early experience as a painter on the streets of Paris. While there, he studied art and worked at it for a year and a half. Huston continued painting as a hobby for most of his life. Kaminsky also notes that most of Huston's films "reflected this prime interest in the image, the moving portrait and the use of color." Huston explored the use of "stylistic framing", especially well-planned close-ups, in much of his directing. In his first film, "The Maltese Falcon", for instance, Huston sketched out all of his scenes beforehand, "like canvases of paintings". His daughter, Anjelica Huston adds that even for his subsequent films, he sketched storyboards "constantly". She agrees that for her father, "it was a form of study, and my father was a painter, a very good one." She also notes that "there was an extremely developed sensory quality about my father, he didn't miss a trick."
Awards and honors.
Huston received 15 Oscar nominations in the course of his career, and is the oldest person ever to be nominated for the Best Director Oscar when, at 79 years old, he was nominated for "Prizzi's Honor" (1985). He won two Oscars, for directing and writing the screenplay for "The Treasure of the Sierra Madre". Huston also won a Golden Globe for that film and received multiple lifetime achievement awards (including one from American Film Institute in 1982).
He also has the unique distinction of directing both his father Walter and his daughter Anjelica in Oscar-winning performances (in "The Treasure of the Sierra Madre" and "Prizzi's Honor", respectively), making the Hustons the first family to have three generations of Academy Award winners.
In addition, he also directed 13 other actors in Oscar-nominated performances: Sydney Greenstreet, Claire Trevor, Sam Jaffe, Humphrey Bogart, Katharine Hepburn, José Ferrer, Colette Marchand, Deborah Kerr, Grayson Hall, Susan Tyrrell, Albert Finney, Jack Nicholson and William Hickey.
In 1960, Huston was honored with a star on the Hollywood Walk of Fame for his contribution to motion pictures.
In 1965, Huston received the Laurel Award for Screenwriting Achievement from the Writers Guild of America.
In 1981 his film "Escape to Victory" was nominated for the Golden Prize at the 12th Moscow International Film Festival.
A statue of Huston, sitting in his director's chair, stands in Plaza John Huston in Puerto Vallarta, Mexico.
Personal life.
To producer George Stevens, Jr., Huston symbolized "intellect, charm and physical grace" within the film industry. He adds, "He was the most charismatic of the directors I knew, speaking with a soothing, melodic voice that was often mimicked, but was unique to him."
Huston loved the outdoors, especially sports such as hunting while living in Ireland. He claimed that he had no orthodox religion. Among his life's adventures before becoming a Hollywood filmmaker, he had been an amateur boxer, reporter, short-story writer, portrait artist in Paris, a cavalry rider in Mexico, and a documentary filmmaker during World War II. Besides sports and adventure, he enjoyed hard liquor and relationships with women of all types — one of the reasons he was married five times. Stevens describes him as someone who "lived life to its fullest". Barson even suggests that Huston's "flamboyant life" as a rebel would possibly make for "an even more engaging tale than most of his movies".
His daughter, Anjelica Huston notes that he did not like Hollywood, and "especially despised Beverly Hills ... he thought it was just fake from the ground up. He didn't like any of that; he was not intrigued or attracted by it." She notes that in contrast, "he liked to be in the wild places; he liked animals as much as he liked people."
He was married five times:
Four of his marriages ended in divorce. His fourth wife, Enrica Soma, died in a car accident in 1969, while they were married. In addition to his children with Soma, he fathered a son, actor Danny Huston, with author Zoe Sallis.
Among his friends were Orson Welles and Ernest Hemingway. Humphrey Bogart was one of his best friends and Huston delivered the eulogy at his funeral.
Huston visited Ireland in 1951 and stayed at Luggala, County Wicklow, the home of Garech Browne, a member of the Guinness family. He visited Ireland several times afterwards and on one of these visits he purchased and restored a Georgian home, St Clerans, of Craughwell, County Galway. Between 1960 and 1971 he served as Master of Fox Hounds (MFH) of the County Galway Hunt – the famous "Galway Blazers" – whose kennels are at Craughwell. He renounced his U.S. citizenship and became an Irish citizen in 1964. His daughter Anjelica attended school in Ireland at Kylemore Abbey for a number of years. A film school is now dedicated to him on the NUIG campus.
Huston was an accomplished painter who wrote in his autobiography, "Nothing has played a more important role in my life". As a young man he studied at the Smith School of Art in Los Angeles but dropped out within a few months. He later studied at the Art Students League of New York. He painted throughout his life and had studios in each of his homes. He had owned a wide collection of art, including a notable collection of Pre-Columbian art.
A heavy smoker, he was diagnosed with emphysema in 1978. By the last year of his life he could not breathe for more than twenty minutes without needing oxygen. He died on August 28, 1987, in his rented home in Middletown, Rhode Island, from pneumonia as a complication of lung disease. Huston is interred in the Hollywood Forever Cemetery in Hollywood with his mother.

</doc>
<doc id="44138" url="https://en.wikipedia.org/wiki?curid=44138" title="Cantata">
Cantata

A cantata (literally "sung", past participle feminine singular of the Italian verb "cantare", "to sing") is a vocal composition with an instrumental accompaniment, typically in several movements, often involving a choir.
The meaning of the term changed over time, from the simple single voice madrigal of the early 17th century, to the multi-voice "cantata da camera" and the "cantata da chiesa" of the later part of that century, from the more substantial dramatic forms of the 18th century to the usually sacred-texted 19th-century cantata, which was effectively a type of short oratorio. Cantatas for use in the liturgy of church services are called church cantata or sacred cantata, other cantatas can be indicated as secular cantata. Several cantatas were, and still are, written for special occasions, such as Christmas cantatas. Johann Sebastian Bach composed cycles of church cantatas for the occasions of the liturgical year.
Historical context.
The term originated in the early 17th century simultaneously with opera and oratorio. Prior to that all "cultured" music was vocal. With the rise of instrumental music the term appeared, while the instrumental art became sufficiently developed to be embodied in sonatas. From the beginning of the 17th century until late in the 18th, the cantata for one or two solo voices with accompaniment of basso continuo (and perhaps a few solo instruments) was a principal form of Italian vocal chamber music.
A cantata consisted first of a declamatory narrative or scene in recitative, held together by a primitive aria repeated at intervals. Fine examples may be found in the church music of Giacomo Carissimi; and the English vocal solos of Henry Purcell (such as "Mad Tom" and "Mad Bess") show the utmost that can be made of this archaic form. With the rise of the da capo aria, the cantata became a group of two or three arias joined by recitative. George Frideric Handel's numerous Italian duets and trios are examples on a rather large scale. His Latin motet "Silete Venti", for soprano solo, shows the use of this form in church music.
Differences from other musical forms.
The Italian solo cantata tended, when on a large scale, to become indistinguishable from a scene in an opera, in the same way the church cantata, solo or choral, is indistinguishable from a small oratorio or portion of an oratorio. This is equally evident whether we examine the unparalleled church cantatas of Bach, of which nearly 200 are extant (see List of Bach cantatas), or the "Chandos Anthems" of Handel. In Johann Sebastian Bach's case many of the larger cantatas are actually called oratorios; and the "Christmas Oratorio" is a collection of six church cantatas actually intended for performance on six different days, though together forming as complete an artistic whole as any classical oratorio.
Baroque.
Cantatas were in great demand for the services of the Lutheran church. Sacred cantatas for the liturgy or other occasions were not only composed by Bach but also by Dieterich Buxtehude, Christoph Graupner, Gottfried Heinrich Stölzel and Georg Philipp Telemann, to name a few. Many secular cantatas were composed for events in the nobility. They were so similar in form to the sacred ones that many of them were parodied (in parts or completely) to sacred cantatas, for example in Bach's "Christmas Oratorio".
Classical and romantic period.
The term cantata came to be applied almost exclusively to choral works, as distinguished from solo vocal music. In early 19th-century cantatas the chorus is the vehicle for music more lyric and songlike than in oratorio, not excluding the possibility of a brilliant climax in a fugue as in Ludwig van Beethoven's "Glorreiche Augenblick", Carl Maria von Weber's "Jubel-Kantate", and Felix Mendelssohn's "Die erste Walpurgisnacht". Anton Bruckner composed several Name-day cantatas, a Festive Cantata and two secular cantatas ("Germanenzug" and "Helgoland"). Bruckners's Psalm 146 is also in cantata form. Mendelssohn's Symphony Cantata, the "Lobgesang", is a hybrid work, partly in the oratorio style. It is preceded by three symphonic movements, a device avowedly suggested by Beethoven's ninth symphony; but the analogy is not accurate, as Beethoven's work is a symphony of which the fourth movement is a choral finale of essentially single design, whereas Mendelssohn's "Symphony Cantata" is a cantata with three symphonic preludes. Robert Schumann wrote the cantata "Paradise and the Peri". The full lyric possibilities of a string of choral songs were realized by Johannes Brahms in his "Rinaldo", that—like the "Walpurgisnacht"—was set to a text by Goethe. Other cantatas, Beethoven's "Meeresstille", works of Brahms and many notable small English choral works, such as cantatas of John Henry Maunder and John Stanley, find various ways to set poetry to choral music. The competition for the French Prix de Rome prescribed that each candidate submit a cantata. Hector Berlioz failed in three attempts before finally winning in 1830 with "Sardanapale". While almost all of the Prix de Rome cantatas have long since been forgotten (along with their composers, for the most part), Debussy's prize-winning "L'enfant prodigue" (1884, following his unsuccessful "Le gladiateur" of 1883) is still performed occasionally today. Late in the century, Gustav Mahler wrote his early "Das klagende Lied" on his own words, between 1878 and 1880, and Samuel Coleridge-Taylor created a successful trilogy of cantatas "The Song of Hiawatha" between 1898 and 1900.
Twentieth century and beyond.
Cantatas, both of the chamber variety and on a grand scale, were composed after 1900 as well. In the early part of the century, secular cantatas once again became prominent, while the 19th-century tradition of sacred cantatas also continued. Ralph Vaughan Williams composed both kinds: "festival" cantatas such as "Toward the Unknown Region" (1907), "Five Mystical Songs" (1911), and "Five Tudor Portraits" (1936), and sacred cantatas including "Sancta civitas" (1926), "Benedicite" (1930), "Dona nobis pacem" (1936), and "Hodie" (1954). Joseph Ryelandt also composed secular and sacred cantatas, such as "Le chant de la pauvreté" Op. 92 in 1928 and "Veni creator" Op. 123 in 1938. Béla Bartók composed the secular "Cantata Profana", subtitled "The Nine Splendid Stags" and based on a Romanian folk tale, in 1930. Although it began as a song cycle (as reflected also by its title), Arnold Schoenberg's "Gurre-Lieder" (1900–1903/1910–11) evolved into one of the century's largest secular cantatas. Paul Hindemith composed three works he designated as cantatas: "Die Serenaden", Op. 35, for soprano, oboe, viola, and cello (1924), "Mahnung an die Jugend, sich der Musik zu befleissigen" (from the "Plöner Musiktage", 1932), and "Ite angeli veloces" for alto and tenor, mixed chorus, and orchestra, with audience participation (1953–55). Of Anton Webern's last three compositions, two are secular cantatas: Cantata No. 1, Op. 29 (1938–39), and Cantata No. 2, Op. 31 (1941–43), both setting texts by Hildegard Jone. Webern had begun sketching a Third Cantata by the time he was killed in 1945. Ernst Krenek also composed two examples: a "scenic cantata", "Die Zwingburg", Op. 14 (1922), and a "Cantata for Wartime", Op. 95, for women's voices and orchestra (1943). Sergei Prokofiev composed "Semero ikh" (1917–18; rev. 1933), and in 1939 premiered a cantata drawn from the film music for "Alexander Nevsky". .
Patriotic cantatas celebrating anniversaries of events in the Revolution or extolling state leaders were frequently commissioned in the Soviet Union between 1930 and the middle of the century, though these occasional works were seldom among their composers' best. Examples include Dmitri Shostakovich's "Poem of the Motherland", Op. 47 (1947) and "The Sun Shines over Our Motherland", Op. 90 (1952), and three works by Prokofiev, "Zdravitsa!" to Stalin (1939), along with two festival cantatas, the "Cantata for the Twentieth Anniversary of the October Revolution", Op. 74, and "Flourish, Mighty Homeland", Op. 114, for the thirtieth anniversary of the same event. Dmitry Kabalevsky also composed four such cantatas, "The Great Homeland", Op. 35 (1941–42), "The Song of Morning, Spring and Peace", Op. 57 (1957–58), "Leninists", Op. 63 (1959), and "About Our Native Land", Op. 82 (1965).
In 1940, the Brazilian composer Heitor Villa-Lobos created a secular cantata titled "Mandu çarará", based on an Indian legend collected by Barbosa Rodrigues. Igor Stravinsky composed a work titled simply "Cantata" in 1951–52, which used stanzas from the 15th-century "Lyke-wake Dirge" as a narrative frame for other anonymous English lyrics, and later designated "A Sermon, a Narrative and a Prayer" (1961) as "a cantata for alto and tenor soli, speaker, chorus, and orchestra". Luigi Nono wrote "Il canto sospeso" in 1955–56. Hans Werner Henze composed a "Cantata della fiaba estrema" and "Novae de infinito laudes" (both in 1963), as well as a number of other works that might be regarded as cantatas, such as "Kammermusik" (1958, rev. 1963), "Muzen Siziliens" (1966), and "El Cimarrón" (1969–70). "Momente" (1962–64/1969), one of the most important works of Karlheinz Stockhausen, is often described as a cantata. Benjamin Britten composed at least six works he designated as cantatas: "The Company of Heaven" (1937), "Rejoice in the Lamb", Op. 30 (1943), "Saint Nicolas", Op. 42 (1949), the "Cantata academica", Op. 62 (1959), the "Cantata Misericordium", Op. 69 (1963), and "Phaedra", Op. 93 (1975). Alberto Ginastera also composed three works in this form: the "Cantata para América Mágica", Op. 27 (1960), "Bomarzo", Op. 32 (1964), and "Milena", Op. 37 (1971), and Gottfried von Einem composed in 1973 "An die Nachgeborenen" based on diverse texts, the title taken from a poem of Bertolt Brecht. Mikis Theodorakis composed the cantatas "According to the Sadducees" and "Canto Olympico". Herbert Blendinger's "Media in vita" was premiered in 1980, his "Mich ruft zuweilen eine Stille" (Sometimes a silence calls me) in (1992), and "Allein den Betern kann es noch gelingen" (It can only be achieved by those who pray) in 1995. Iván Erőd wrote in 1988/89) "Vox Lucis" (Voice of the Light), Op. 56. Ivan Moody wrote in 1995 "Revelation". Cantatas were also composed by Mark Alburger, Erik Bergman, Carlos Chávez, Osvald Chlubna, Peter Maxwell Davies, Norman Dello Joio, Lukas Foss, Roy Harris, Arthur Honegger, Alan Hovhaness, Dmitry Kabalevsky, Libby Larsen, Peter Mennin, Dimitri Nicolau, Krzysztof Penderecki, Daniel Pinkham, Earl Robinson, Ned Rorem, William Schuman ("A Free Song"), Roger Sessions, Siegfried Strohbach, Michael Tippett, and Kurt Weill.

</doc>
<doc id="44142" url="https://en.wikipedia.org/wiki?curid=44142" title="Metric system">
Metric system

The metric system is an internationally agreed decimal system of measurement. It was originally based on the and the introduced by the First French Republic in 1799, but over the years the definitions of the metre and the kilogram have been refined, and the metric system has been extended to incorporate many more units. Although a number of variants of the metric system emerged in the late nineteenth and early twentieth centuries, the term is now often used as a synonym for "SI" or the "International System of Units"—the official system of measurement in almost every country in the world.
The metric system has been officially sanctioned for use in the United States since 1866, but the US remains the only industrialised country that has not adopted the metric system as its official system of measurement. Many sources also cite Liberia and Myanmar as the only other countries not to have done so. Although the United Kingdom uses the metric system for most administrative and trade purposes, Imperial units are permitted or obligatory for some purposes, such as road signs.
Although the originators intended to devise a system that was equally accessible to all, it proved necessary to use prototype units in the custody of national or local authorities as standards. Control of the prototype units of measure was maintained by the French government until 1875, when it was passed to an inter-governmental organisation—the General Conference on Weights and Measures (CGPM).
From its beginning, the main features of the metric system were the standard set of inter-related base units and a standard set of prefixes in powers of ten. These base units are used to derive larger and smaller units that could replace a huge number of other units of measure in existence. Although the system was first developed for commercial use, the development of coherent units of measure made it particularly suitable for science and engineering.
The uncoordinated use of the metric system by different scientific and engineering disciplines, particularly in the late 19th century, resulted in different choices of base units, even though all were based on the same definitions of the metre and the kilogram. During the 20th century, efforts were made to rationalise these units, and in 1960 the CGPM published the International System of Units, which has since then been the internationally recognised standard metric system.
Features.
Although the metric system has changed and developed since its inception, its basic concepts have hardly changed. Designed for transnational use, it consisted of a basic set of units of measurement, now known as base units. Derived units were built up from the base units using logical rather than empirical relationships while multiples and submultiples of both base and derived units were decimal-based and identified by a standard set of prefixes.
Universality.
At the outbreak of the French Revolution in 1789, most countries and even some cities had their own system of measurement. Although different countries might have used units of measure with the same name, such as the foot, or local language equivalents such as "pied", "Fuß" and "voet", there was no consistency in the magnitude of those units, nor in the relationships with their multiples and submultiples, much like the modern-day differences between the US and the UK pints and gallons.
The metric system was designed to be universal—in the words of the French philosopher Marquis de Condorcet it was to be "for all people for all time". It was designed for ordinary people, for engineers who worked in human-related measurements and for astronomers and physicists who worked with numbers both small and large, hence the huge range of the prefixes that have been defined in SI.
When the French Government first investigated the idea of overhauling their system of measurement, the concept of universality was put into practice in 1789: Maurice de Talleyrand, acting on Condorcet's advice, invited John Riggs Miller, a British parliamentarian and Thomas Jefferson, the American Secretary of State to George Washington, to work with the French in producing an international standard by promoting legislation in their respective legislative bodies. However, these early overtures failed and the custody of the metric system remained in the hands of the French government until 1875.
In languages where the distinction is made, unit names are common nouns (i.e. not proper nouns). They use the character set and follow the grammatical rules of the language concerned, for example "", """", but each unit has a symbol that is independent of language, for example "km" for "kilometre", "V" for "volts" etc.
Decimal multiples.
In the metric system, multiples and submultiples of units follow a decimal pattern, a concept identified as a possibility in 1586 by Simon Stevin, the Flemish mathematician who had introduced decimal fractions into Europe. This is done at the cost of losing the simplicity associated with many traditional systems of units where division by 3 does not result in awkward fractions; for example one third of a foot is four inches, a simplicity that in 1790 was debated, but rejected by the originators of the metric system. In 1854, in the introduction to the proceedings of the Decimal Association, the mathematician Augustus de Morgan summarised the advantages of a decimal-based system over a non-decimal system thus: "In the "simple" rules of arithmetic, we practice a pure decimal system, nowhere interrupted by the entrance of any other system: "from column to column we never carry anything but tens"".
A common set of decimal-based prefixes that have the effect of multiplication or division by an integer power of ten can be applied to units which are themselves too large or too small for practical use. The concept of using consistent classical (Latin or Greek) names for the prefixes was first proposed in a report by the ] Commission on Weights and Measures in May 1793. The prefix "kilo", for example, is used to multiply the unit by 1000, and the prefix "milli" is to indicate a one-thousandth part of the unit. Thus the "kilogram" and "kilometre" are a thousand grams and metres respectively, and a "milligram" and "millimetre" are one thousandth of a gram and metre respectively. These relations can be written symbolically as:
In the early days, multipliers that were positive powers of ten were given Greek-derived prefixes such as "kilo-" and "mega-", and those that were negative powers of ten were given Latin-derived prefixes such as "centi-" and "milli-". However, 1935 extensions to the prefix system did not follow this convention: the prefixes "nano-" and "micro-", for example have Greek roots. During the 19th century the prefix "myria-", derived from the Greek word μύριοι ("mýrioi"), was used as a multiplier for .
When applying prefixes to derived units of area and volume that are expressed in terms of units of length squared or cubed, the square and cube operators are applied to the unit of length including the prefix, as illustrated below.
Prefixes are not usually used to indicate multiples of a second greater than 1; the non-SI units of minute, hour and day are used instead. On the other hand, prefixes are used for multiples of the non-SI unit of volume, the litre (l, L) such as millilitres (ml).
Realisability and replicable prototypes.
The base units used in the metric system must be realisable, ideally with reference to natural phenomena rather than unique artefacts. Each of the base units in SI is accompanied by a "mise en pratique" realisation published by the BIPM that describes in detail at least one way in which the base unit can be measured. Where possible, definitions of the base units were developed so that any laboratory equipped with proper instruments would be able to realise a standard without reliance on an artefact held by another country. In practice, such realisation is done under the auspices of a mutual acceptance arrangement (MAA).
Metre and kilogram.
In the original version of the metric system the base units could be derived from a specified length (the metre) and the weight of a specified volume ( of a cubic metre) of pure water. Initially the "de facto" French Government of the day, the "Assemblée nationale constituante", considered defining the metre as the length of a pendulum that has a period of one second at 45°N and an altitude equal to sea level. The altitude and latitude were specified to accommodate variations in gravity; the specified latitude was a compromise between the latitude of , and the median parallel of the United States (38°N) to accommodate variations. However the mathematician Borda persuaded the assembly that a survey having its ends at sea level and based on a meridian that spanned at least 10% of the earth's quadrant would be more appropriate for such a basis.
The available technology of the 1790s made it impracticable to use these definitions as the basis of the kilogram and the metre, so prototypes that represented these quantities insofar as was practicable were manufactured. On 22 June 1799 these prototypes were adopted as the definitive reference pieces, deposited in the "Archives nationales" and became known as the and the . Copies were made and distributed around France. These artefacts were replaced in 1889 by the new prototypes manufactured under international supervision. Insofar as was possible, the new prototypes were exact copies of the original prototypes, but used a later technology to ensure better stability. One of each of the kilogram and metre prototypes were chosen by lot to serve as the definitive international reference piece with the remainder being distributed to signatories of the Metre Convention.
In 1889 there was no generally accepted theory regarding the nature of light but by 1960 the wavelength of specific light spectra could give a more accurate and reproducible value than a prototype metre. In that year the prototype metre was replaced by a formal definition which defines the metre in terms of the wavelength of specified light spectra. By 1983 it was accepted that the speed of light in vacuum was constant and that this constant provided a more reproducible procedure for measuring length. Therefore, the metre was redefined in terms of the speed of light. These definitions give a much better reproducibility and also allow anyone, anywhere with a suitably equipped laboratory, to make a standard metre.
Other base units.
None of the other base units rely on a prototype – all are based on phenomena that are directly observable and had been in use for many years before formally becoming part of the metric system.
The second first became a "de facto" base unit within the metric system when, in 1832, Carl Friedrich Gauss used it, the centimetre and the gram to derive the units associated with values of absolute measurements of the Earth's magnetic field. The second, if based on the Earth's rotation, is not a constant as the Earth's rotation is slowing down—in 2008 the solar day was 0.002 s longer than in 1820. This had been known for many years; consequently in 1952 the International Astronomical Union (IAU) defined the second in terms of the Earth's rotation in the year 1900. Measurements of time were made using extrapolation from readings based on astronomy. With the launch of SI in 1960, the 11th CGPM adopted the IAU definition. In the years that followed, atomic clocks became significantly more reliable and precise; and in 1968 the 13th CGPM redefined the second in terms of a specific frequency from the emission spectrum of the caesium 133 atom, a component of atomic clocks. This provided the means to measure the time associated with astronomical phenomena rather than using astronomical phenomena as the basis from which time measurements were made.
The CGS absolute unit of electric current, the abampere, had been defined in terms of the force between two parallel current-carrying wires in 1881. In the 1940s, the International Electrotechnical Commission adopted an MKS variant of this definition for the ampere which was adopted in 1948 by the CGPM.
Temperature has always been based on observable phenomena—in 1744 the degree Centigrade was based on the freezing and boiling points of water. In 1948 the CGPM adopted the Centigrade scale, renamed it the "Celsius" temperature scale name and defined it in terms of the triple point of water.
When the mole and the candela were accepted by the CGPM in 1971 and 1975 respectively, both had been defined by third parties by reference to phenomena rather than artefacts.
Coherence.
Each variant of the metric system has a degree of coherence—the various derived units are directly related to the base units without the need for intermediate conversion factors. For example, in a coherent system the units of force, energy and power are chosen so that the equations
hold without the introduction of unit conversion factors. Once a set of coherent units have been defined, other relationships in physics that use those units will automatically be true. Therefore, Einstein's mass-energy equation, "E" = "mc"2, does not require extraneous constants when expressed in coherent units.
The CGS system had two units of energy, the erg that was related to mechanics and the calorie that was related to thermal energy; so only one of them (the erg) could bear a coherent relationship to the base units. Coherence was a design aim of SI resulting in only one unit of energy being defined – the joule.
In SI, which is a coherent system, the unit of power is the "watt" which is defined as " joule per second". In the US customary system of measurement, which is non-coherent, the unit of power is the "horsepower" which is defined as "550 foot-pounds per second" (the pound in this context being the pound-force). Similarly, neither the US gallon nor the imperial gallon is cubic foot or cubic yard— the US gallon is 231 cubic inches and the imperial gallon is 277.42 cubic inches.
The concept of coherence was only introduced into the metric system in the third quarter of the 19th century; in its original form the metric system was non-coherent—in particular the litre was 0.001 m3 and the are (from which the hectare derives) was 100 m2. However the units of mass and length were related to each other through the physical properties of water, the gram having been designed as being the mass of one cubic centimetre of water at its freezing point.
History.
In 1586 the Flemish mathematician Simon Stevin published a small pamphlet called "De Thiende" ("the tenth"). Decimal fractions had been employed for the extraction of square roots some five centuries before his time, but nobody used decimal numbers in daily life. Stevin declared that using decimals was so important that the universal introduction of decimal weights, measures and coinage was only a matter of time.
One of the earliest proposals for a decimal system in which length, area, volume and mass were linked to each other was made by John Wilkins, first secretary of the Royal Society of London in his 1668 essay ""An Essay towards a Real Character and a Philosophical Language"". His proposal used a pendulum that had a beat of one second as the basis of the unit of length. Two years later, in 1670, Gabriel Mouton, a French abbot and scientist, proposed a decimal system of length based on the circumference of the Earth. His suggestion was that a unit, the milliare, be defined as a minute of arc along a meridian. He then suggested a system of sub-units, dividing successively by factors of ten into the centuria, decuria, virga, virgula, decima, centesima, and millesima. His ideas attracted interest at the time, and were supported by both Jean Picard and Christiaan Huygens in 1673, and also studied at the Royal Society in London. In the same year, Gottfried Leibniz independently made proposals similar to those of Mouton.
In pre-revolutionary Europe, each state had its own system of units of measure. Some countries, such as Spain and Russia, saw the advantages of harmonising their units of measure with those of their trading partners. However, vested interests who profited from variations in units of measure opposed this. This was particularly prevalent in France where the huge inconsistency in the size of units of measure was one of the causes that, in 1789, led to the outbreak of the French Revolution. During the early years of the revolution, savants including the Marquis de Condorcet, Pierre-Simon Laplace, Adrien-Marie Legendre, Antoine Lavoisier and Jean-Charles de Borda set up a Commission of Weights and Measures. The commission was of the opinion that the country should adopt a completely new system of measure based on the principles of logic and natural phenomena. Logic dictated that such a system should be based on the radix used for counting. Their report of March 1791 to the "Assemblée nationale constituante" considered but rejected the view of Laplace that a duodecimal system of counting should replace the existing decimal system; the view such a system was bound to fail prevailed. The commission's final recommendation was that the assembly should promote a decimal-based system of measurement. The leaders of the assembly accepted the views of the commission.
Initially France attempted to work with other countries towards the adoption of a common set of units of measure. Among the supporters of such an international system of units was Thomas Jefferson who, in 1790, presented a document "Plan for Establishing Uniformity in the Coinage, Weights, and Measures of the United States" to Congress in which he advocated a decimal system that used traditional names for units (such as ten inches per foot). The report was considered but not adopted by Congress.
Original metric system.
The French law of 18 Germinal, Year III (7 April 1795) defined five units of measure:
This system continued the tradition of having separate base units for geometrically related dimensions, e.g., "mètre" for lengths, "are" (100 m2) for areas, "stère" (1 m3) for dry capacities, and "litre" (1 dm3) for liquid capacities. The "hectare", equal to a hundred "ares", the area of a square 100 metres on a side (about 2.47 acres), is still in use. The early metric system included only a few prefixes from "milli" (one thousandth) to "myria" (ten thousand).
Originally the "kilogramme", defined as being one "pinte" (later renamed the "litre") of water at the melting point of ice, was called the "grave"; the "gramme" being an alternative name for a thousandth of a "grave". However, the word "grave", being a synonym for the title "count", had aristocratic connotations and was renamed the "kilogramme". The name "mètre" was suggested by Auguste-Savinien Leblond in May 1790.
France officially adopted the metric system on 10 December 1799. Although it was decreed that its use was to be mandatory in Paris that year and across the provinces the following year, the decree was not universally observed across France.
International adoption.
Areas annexed by France during the Napoleonic era were the first to inherit the metric system. In 1812 Napoleon introduced a system known as "mesures usuelles" which used the names of pre-metric units of measure, but defined them in terms of metric units – for example, the "livre metrique" (metric pound) was 500 g and the "toise metrique" (metric fathom) was 2 metres. After the Congress of Vienna in 1815, France lost the territories that she had annexed; some, such as the Papal States reverted to their pre-revolutionary units of measure, others such as Baden adopted a modified version of the "mesures usuelles", but France kept her system of measurement intact.
In 1817 the Netherlands reintroduced the metric system, but used pre-revolutionary names—for example 1 centimetre became the "duim" (thumb), the "ons" (ounce) became 100 g and so on. Certain German states adopted similar systems and in 1852 the German Zollverein (customs union) adopted the zollpfund (customs pound) of 500 g for intrastate commerce. In 1872 the newly formed German Empire adopted the metric system as its official system of weights and measures and the newly formed Kingdom of Italy likewise, following the lead given by Piedmont, adopted the metric system in 1861.
The "Exposition Universelle (1867)" (Paris Exhibition) devoted a stand to the metric system and by 1875 two thirds of the European population and close to half the world's population had adopted the metric system. By 1872 the only principal European countries not to have adopted the metric system were Russia and the United Kingdom.
By 1920 countries comprising 22% of the world's population, mainly English-speaking, used the imperial system; 25% used mainly the metric system and the remaining 53% used neither.
In 1927 several million people in the United States sent over 100,000 petitions backed by the Metric Association and The General Federation of Women's Clubs urging Congress to adopt the metric system. The petition was opposed by the manufacturing industry, citing the cost of the conversion.
International standards.
In 1861 a committee of the British Association for Advancement of Science (BAAS) including William Thomson (later Lord Kelvin), James Clerk Maxwell and James Prescott Joule introduced the concept of a coherent system of units based on the metre, gram and second which, in 1873, was extended to include electrical units.
On 20 May 1875 an international treaty known as the "Convention du Mètre" (Metre Convention) was signed by 17 states. This treaty established the following organisations to conduct international activities relating to a uniform system for measurements:
In 1881 first International Electrical Congress adopted the BAAS recommendations on electrical units, followed by a series of congresses in which further units of measure were defined and the International Electrotechnical Commission (IEC) was set up with the specific task of overseeing electrical units of measure. This was followed by the International Congress of Radiology (ISR) who, at their inaugural meeting in 1926, initiated the definition of radiological-related units of measure.
In 1921 the Metre Convention was extended to cover all units of measure, not just length and mass and in 1933 the 8th CGPM resolved to work with other international bodies to agree standards for electrical units that could be related back to the international prototypes. Since 1954 the CIPM committee that oversees the definition of units of measurement, the Consultative Committee for Units, has representatives from many international organisations including the ISR, IEC and ISO under the chairmanship of the CIPM.
Variants.
A number of variants of the metric system evolved, all using the "Mètre des Archives" and "Kilogramme des Archives" (or their descendants) as their base units, but differing in the definitions of the various derived units.
Centimetre-gram-second systems.
The centimetre gram second system of units (CGS) was the first coherent metric system, having been developed in the 1860s and promoted by Maxwell and Thomson. In 1874, this system was formally promoted by the British Association for the Advancement of Science (BAAS). The system's characteristics are that density is expressed in , force expressed in dynes and mechanical energy in ergs. Thermal energy was defined in calories, one calorie being the energy required to raise the temperature of one gram of water from 15.5 °C to 16.5 °C. The meeting also proposed two sets of units for electrical and magnetic properties – the electrostatic set of units and the electromagnetic set of units.
Metre-kilogram-second systems.
The CGS units of electricity were cumbersome to work with. This was remedied at the 1893 International Electrical Congress held in Chicago by defining the "international" ampere and ohm using definitions based on the metre, kilogram and second. In 1901, Giovanni Giorgi showed that by adding an electrical unit as a fourth base unit, the various anomalies in electromagnetic systems could be resolved. The metre-kilogram-second-coulomb (MKSC) and metre-kilogram-second-ampere (MKSA) systems are examples of such systems.
The International System of Units ("Système international d'unités" or SI) is the current international standard metric system and is also the system most widely used around the world. It is an extension of Giorgi's MKSA system—its base units are the metre, kilogram, second, ampere, kelvin, candela and mole.
Metre-tonne-second systems.
The metre-tonne-second system of units (MTS) was based on the metre, tonne and second – the unit of force was the sthène and the unit of pressure was the pièze. It was invented in France for industrial use and from 1933 to 1955 was used both in France and in the Soviet Union.
Gravitational systems.
Gravitational metric systems use the kilogram-force (kilopond) as a base unit of force, with mass measured in a unit known as the hyl, "Technische Mass Einheit" (TME), mug or metric slug. Although the CGPM passed a resolution in 1901 defining the standard value of acceleration due to gravity to be 980.665 cm/s2, gravitational units are not part of the International System of Units (SI).
International System of Units.
The 9th CGPM met in 1948, three years after the end of the Second World War and fifteen years after the 8th CGPM. In response to formal requests made by the International Union of Pure and Applied Physics and by the French Government to establish a practical system of units of measure, the CGPM requested the CIPM to prepare recommendations for such a system, suitable for adoption by all countries adhering to the Metre Convention. The recommendation also catalogued symbols for the most important MKS and CGS units of measure and for the first time the CGPM made recommendations concerning derived units. At the same time the CGPM formally adopted a recommendation for the writing and printing of unit symbols and of numbers.
The CIPM's draft proposal, which was an extensive revision and simplification of the metric unit definitions, symbols and terminology based on the MKS system of units, was put to the 10th CGPM in 1954. In accordance with Giorgi's proposals of 1901, the CIPM also recommended that the ampere be the base unit from which electromechanical units would be derived. The definitions for the ohm and volt that had previously been in use were discarded and these units became derived units based on the metre, ampere, second and kilogram. After negotiations with the International Commission on Illumination (CIE) and IUPAP, two further base units, the degree kelvin and the candela were also proposed as base units. The full system and name "Système International d'Unités" were adopted at the 11th CGPM in October 1960. During the years that followed the definitions of the base units and particularly the methods of applying these definitions have been refined.
The formal definition of International System of Units (SI) along with the associated resolutions passed by the CGPM and the CIPM are published by the BIPM in brochure form at regular intervals. The eighth edition of the brochure "Le Système International d'Unités—The International System of Units" was published in 2006 and is available on the internet.
In October 2011, at the 24th CGPM proposals were made to change the definitions of four of the base units. These changes should not affect the average person.
Relating SI to the real world.
Although SI, as published by the CGPM, should, in theory, meet all the requirements of commerce, science and technology, certain units of measure have acquired such a position within the world community that it is likely they will be used for many years to come. In order that such units are used consistently around the world, the CGPM catalogued such units in Tables 6 to 9 of the SI brochure. These categories are:
Usage around the world.
The usage of the metric system varies around the world. According to the US Central Intelligence Agency's "Factbook" (2007), the International System of Units has been adopted as the official system of weights and measures by all nations in the world except for Myanmar (Burma), Liberia and the United States, while the NIST has identified the United States as the only industrialised country where the metric system is not the predominant system of units. However, reports published since 2007 hold this is no longer true of Myanmar or Liberia. An Agence France-Presse report from 2010 stated that Sierra Leone had passed a law to replace the imperial system with the metric system thereby aligning its system of measurement with that used by its Mano River Union (MRU) neighbours Guinea and Liberia. Reports from Myanmar suggest that the country is also planning to adopt the metric system.
In the United States metric units, authorised by Congress in 1866, are widely used in science, medicine, military, and partially in industry, but customary units predominate in household use. At retail stores the litre is a commonly used unit for volume, especially on bottles of beverages, and milligrams are used to denominate the amounts of medications, rather than grains. On the other hand, non-metric units are used in certain regulated environments such as nautical miles and knots in international aviation. Resistance to metrication, particularly in the UK and the US, has been connected to the perceived cost involved, a sense of patriotism and lack of desire to conform internationally.
In the countries of the Commonwealth of Nations the metric system has replaced the imperial system by varying degrees: Australia, New Zealand and Commonwealth countries in Africa are almost totally metric, India is mostly metric while Canada is partly metric. In the United Kingdom the metric system, the use of which was first permitted for trade in 1864, is used in much government business, in most industries including building, health and engineering and for pricing by measure or weight in most trading situations, both wholesale and retail. However the imperial system is widely used by the British public, such as feet and inches as a measurement of height, weight in stone and pounds, and is legally mandated in various cases, such as road-sign distances "must" be in yards and miles. In 2007, the European Commission announced that it was to abandon the requirement for metric-only labelling on packaged goods in the UK, and to allow dual metric–imperial marking to continue indefinitely.
Some other jurisdictions, such as Hong Kong, have laws mandating or permitting other systems of measurement in parallel with the metric system in some or all contexts.
Variations in spelling.
The SI symbols for the metric units are intended to be identical, regardless of the language used but unit names are ordinary nouns and use the character set and follow the grammatical rules of the language concerned. For example, the SI unit symbol for kilometre is "km" everywhere in the world, even though the local language word for the unit name may vary. Language variants for the kilometre unit name include: ' (Italian), ' (German), ' (Dutch), ' (French), ' (Greek), ' (Portuguese), ' (Spanish) and ' (Russian).
Variations are also found with the spelling of unit names in countries using the same language, including differences in American English and British spelling. For example, "meter" and "liter" are used in the United States whereas "metre" and "litre" are used in other English-speaking countries. In addition, the official US spelling for the rarely used SI prefix for ten is "deka". In American English the term "metric ton" is the normal usage whereas in other varieties of English "tonne" is common. "Gram" is also sometimes spelled "gramme" in English-speaking countries other than the United States, though this older usage is declining.
Conversion and calculation incidents.
The dual usage of or confusion between metric and non-metric units has resulted in a number of serious incidents. These include:
Conversion between SI and legacy units.
During its evolution, the metric system has adopted many units of measure. The introduction of SI rationalised both the way in which units of measure were defined and also the list of units in use. These are now catalogued in the official SI Brochure. The table below lists the units of measure in this catalogue and shows the conversion factors connecting them with the equivalent units that were in use on the eve of the adoption of SI.
The SI Brochure also catalogues certain non-SI units that are widely used with the SI in matters of everyday life or units that are exactly defined values in terms of SI units and are used in particular circumstances to satisfy the needs of commercial, legal, or specialised scientific interests. These units include:
Future developments.
After the metre was redefined in 1960, the kilogram was the only SI base unit that relied on a specific artefact. After the 1996–1998 recalibrations a clear divergence between the international and various national prototype kilograms was observed.
At the 23rd CGPM (2007), the CIPM was mandated to investigate the use of natural constants as the basis for all units of measure rather than the artefacts that were then in use. At a meeting of the CCU held in Reading, United Kingdom in September 2010, a resolution and draft changes to the SI brochure that were to be presented to the next meeting of the CIPM in October 2010 were agreed to in principle. The CCU proposed to
The CIPM meeting of October 2010 found that "the conditions set by the General Conference at its 23rd meeting have not yet been fully met. For this reason the CIPM does not propose a revision of the SI at the present time". The CIPM did however sponsor a resolution at the 24th CGPM in which the changes were agreed in principle and which were expected to be finalised at the 25th CGPM in 2014.

</doc>
<doc id="44145" url="https://en.wikipedia.org/wiki?curid=44145" title="Interquartile mean">
Interquartile mean

The interquartile mean (IQM) (or midmean) is a statistical measure of central tendency based on the truncated mean of the interquartile range. The IQM is very similar to the scoring method used in sports that are evaluated by a panel of judges: "discard the lowest and the highest scores; calculate the mean value of the remaining scores".
Calculation.
In calculation of the IQM, only the data in the second and third quartiles is used (as in the interquartile range), and the lowest 25% and the highest 25% of the scores are discarded. These points are called the first and third quartiles, hence the name of the IQM. (Note that the "second" quartile is also called the median).
assuming the values have been ordered.
Examples.
Dataset size divisible by four.
The method is best explained with an example. Consider the following dataset:
First sort the list from lowest-to-highest:
There are 12 observations (datapoints) in the dataset, thus we have 4 quartiles of 3 numbers. Discard the lowest and the highest 3 values:
We now have 6 of the 12 observations remaining; next, we calculate the arithmetic mean of these numbers:
For comparison, the arithmetic mean of the original dataset is
due to the strong influence of the outlier, 38.
Dataset size not divisible by four.
The above example consisted of 12 observations in the dataset, which made the determination of the quartiles very easy. Of course, not all datasets have a number of observations that is divisible by 4. We can adjust the method of calculating the IQM to accommodate this. So ideally we want to have the IQM equal to the mean for symmetric distributions, e.g.:
has a mean value "x"mean = 3, and since it is a symmetric distribution, "x"IQM = 3 would be desired.
We can solve this by using a weighted average of the quartiles and the interquartile dataset:
Consider the following dataset of 9 observations:
There are 9/4 = 2.25 observations in each quartile, and 4.5 observations in the interquartile range. Truncate the fractional quartile size, and remove this number from the 1st and 4th quartiles (2.25 observations in each quartile, thus the lowest 2 and the highest 2 are removed).
Thus, there are 3 "full" observations in the interquartile range, and 2 fractional observations. Since we have a total of 4.5 observations in the interquartile range, the two fractional observations each count for 0.75 (and thus 3×1 + 2×0.75 = 4.5 observations).
The IQM is now calculated as follows:
In the above example, the mean has a value xmean = 9. The same as the IQM, as was expected. The method of calculating the IQM for any number of observations is analogous; the fractional contributions to the IQM can be either 0, 0.25, 0.50, or 0.75.
Comparison with mean and median.
The Interquartile Mean shares some properties from both the mean as well as the median:

</doc>
<doc id="44146" url="https://en.wikipedia.org/wiki?curid=44146" title="1100s BC (decade)">
1100s BC (decade)


</doc>
<doc id="44147" url="https://en.wikipedia.org/wiki?curid=44147" title="1110s BC">
1110s BC


</doc>
<doc id="44149" url="https://en.wikipedia.org/wiki?curid=44149" title="1560s BC">
1560s BC


</doc>
<doc id="44150" url="https://en.wikipedia.org/wiki?curid=44150" title="1710s BC">
1710s BC


</doc>
<doc id="44151" url="https://en.wikipedia.org/wiki?curid=44151" title="1550s BC">
1550s BC


</doc>
<doc id="44152" url="https://en.wikipedia.org/wiki?curid=44152" title="1720s BC">
1720s BC


</doc>
<doc id="44153" url="https://en.wikipedia.org/wiki?curid=44153" title="Kill Doctor Lucky">
Kill Doctor Lucky

Kill Doctor Lucky is a humorous board game designed by James Ernest and released in 1996 by Cheapass Games. In 1998, "Kill Doctor Lucky" won the Origins Award for "Best Abstract Board Game of 1997".
"Kill Doctor Lucky" is, in concept, a sort of inversion and perhaps a parody of "Cluedo" ("Clue" in North America). Both games are set in a sprawling mansion full of colorfully named rooms, feature a variety of dangerous weapons, and deal with the murder of the mansion's owner. "Cluedo" begins after the murder has been committed, and players compete to solve it; "Kill Doctor Lucky" ends with the murder, and players compete to commit it.
In October 2015 a "Deluxe 19.5th Anniversary Edition" with new art and updated game mechanics was launched on Kickstarter.
Gameplay.
The gameboard is a floor plan of Doctor Lucky's mansion, and it is accompanied by a deck of cards representing the objects and opportunities that can be found there. Players take turns moving through the rooms of the mansion and accumulating cards, while Doctor Lucky moves through the mansion following a predetermined path. A player may attempt to kill Doctor Lucky by playing a weapon card (such as a runcible spoon, a monkey hand, a letter opener, a trowel, a chainsaw or pinking shears) while the player's token is in the same room as Doctor Lucky and out of sight of all other players. Each weapon card has a certain point value, and certain weapons are worth more points when used in certain rooms (for example, the trowel is worth extra points when used in the wine cellar, an allusion to Poe's "The Cask of Amontillado").
At this point, the player making the murder attempt succeeds, and thereby wins the game, unless the opponents play Failure cards of combined value equal to the value of the weapon used. The situation is complicated by the requirement that players play Failure cards in clockwise order, with each player having only one opportunity to play cards. Since it is to any player's advantage to eliminate failure cards from his opponents' hands, a large part of the strategy of the game consists in bluffing: when one player attacks Doctor Lucky, it is in your interest to persuade your other opponents that you have no failure cards in your hand, to attempt to force them to save the game by spending the required cards.
When played, failure cards are set aside and not returned to the deck. Thus, as the game goes on, fewer and fewer failure cards are in play. This not only builds tension but also forces the game to end in a reasonable amount of time, because once all the failure cards are gone, the next murder attempt cannot fail.
The new Titanic Games version of "Kill Doctor Lucky" makes two changes to the original rules. First, a minor change was made to game play that now allows everyone to take at least one turn before the Doctor Lucky pawn determines turn order. In the original, it was possible for players to position themselves in such a way as to keep some players from ever getting a turn. This is no longer possible.
The second change was the addition of a new game piece called the "spite token" (a variant in the prior edition). Spite tokens are awarded when a murder attempt fails and adds a bonus point to all future murder attempts. A player also has the option to spend a spite token as a failure point to aid in thwarting an opponent's murder attempt. When spite tokens are spent in this manner they are given to the player they're spent against. This speeds the game up and adds a great deal of strategy to the late game when all of the failure cards have been removed from the deck.

</doc>
<doc id="44154" url="https://en.wikipedia.org/wiki?curid=44154" title="Catherine de' Medici">
Catherine de' Medici

Catherine de' Medici (Italian: "Caterina de' Medici" ; French "Catherine de Médicis" , 13 April 1519 – 5 January 1589), daughter of Lorenzo II de' Medici and of Madeleine de La Tour d'Auvergne, was an Italian noblewoman who was Queen of France from 1547 until 1559, as the wife of King Henry II. As the mother of three sons who became kings of France during her lifetime, she had extensive, if at times varying, influence in the political life of France. For a time she ruled France as its regent.
In 1533, at the age of fourteen, Caterina married Henry, second son of King Francis I and Queen Claude of France. Under the gallicised version of her name, Catherine de Médicis, she was Queen consort of France as the wife of King Henry II of France from 1547 to 1559. Throughout his reign, Henry excluded Catherine from participating in state affairs and instead showered favours on his chief mistress, Diane de Poitiers, who wielded much influence over him. Henry's death thrust Catherine into the political arena as mother of the frail fifteen-year-old King Francis II. When he died in 1560, she became regent on behalf of her ten-year-old son King Charles IX and was granted sweeping powers. After Charles died in 1574, Catherine played a key role in the reign of her third son, Henry III. He dispensed with her advice only in the last months of her life.
Catherine's three sons reigned in an age of almost constant civil and religious war in France. The problems facing the monarchy were complex and daunting but Catherine was able to keep the monarchy and the state institutions functioning even at a minimum level
. At first, Catherine compromised and made concessions to the rebelling Protestants, or Huguenots, as they became known. She failed, however, to grasp the theological issues that drove their movement. Later she resorted, in frustration and anger, to hard-line policies against them. In return, she came to be blamed for the excessive persecutions carried out under her sons' rule, in particular for the St. Bartholomew's Day massacre of 1572, in which thousands of Huguenots were killed in Paris and throughout France.
Some historians have excused Catherine from blame for the worst decisions of the crown, though evidence for her ruthlessness can be found in her letters. In practice, her authority was always limited by the effects of the civil wars. Her policies, therefore, may be seen as desperate measures to keep the Valois monarchy on the throne at all costs, and her patronage of the arts as an attempt to glorify a monarchy whose prestige was in steep decline. Without Catherine, it is unlikely that her sons would have remained in power. The years in which they reigned have been called "the age of Catherine de' Medici". According to one of her biographers Mark Strage, Catherine was the most powerful woman in sixteenth-century Europe.
Birth and upbringing.
Catherine was born in Florence, Republic of Florence, as Caterina Maria Romula di Lorenzo de' Medici.
The Medici family were at the time the "de facto" rulers of Florence. Originally bankers, they came to great wealth and power by bankrolling the monarchies of Europe. Catherine's father, Lorenzo II de' Medici, was made Duke of Urbino by his uncle Pope Leo X, and the title reverted to Francesco Maria I della Rovere after Lorenzo's death. Thus, even though her father was a duke, Catherine was of relatively low birth. However her mother, Madeleine de la Tour d'Auvergne, the Countess of Boulogne, was from one of the most prominent and ancient French noble families; this prestigious maternal heritage was of benefit to her future marriage to a "fils de France".
According to a contemporary chronicler, when Catherine de' Medici was born, her parents, were "as pleased as if it had been a boy". Madeleine died on 28 April of puerperal fever or plague, and Lorenzo died on 4 May. The young couple were married the year before at Amboise as part of the alliance between King Francis I of France and Pope Leo against the Holy Roman Emperor Maximilian I. King Francis wanted Catherine to be raised at the French court, but Pope Leo had other plans for her. He intended to marry her to his brother's illegitimate son, Ippolito de' Medici, and set them up to rule Florence.
Catherine was first cared for by her paternal grandmother, Alfonsina Orsini (wife of Piero de' Medici). After Alfonsina's death in 1520, Catherine joined her cousins and was raised by her aunt, Clarice Strozzi. The death of Pope Leo in 1521 interrupted Medici power briefly, until Cardinal Giulio de' Medici was elected Pope Clement VII in 1523. Clement housed Catherine in the Palazzo Medici Riccardi in Florence, where she lived in state. The Florentine people called her "duchessina" ("the little duchess"), in deference to her unrecognised claim to the Duchy of Urbino.
In 1527, the Medici were overthrown in Florence by a faction opposed to the regime of Clement's representative, Cardinal Silvio Passerini, and Catherine was taken hostage and placed in a series of convents. The final one, the "Santissima Annuziata delle Murate" was her home for three years. Mark Strage described these years as "the happiest of her entire life". Clement had no choice but to crown Charles Holy Roman Emperor in return for his help in retaking the city. In October 1529, Charles's troops laid siege to Florence. As the siege dragged on, voices called for Catherine to be killed and exposed naked and chained to the city walls. Some even suggested that she be handed over to the troops to be used for their sexual gratification. The city finally surrendered on 12 August 1530. Clement summoned Catherine from her beloved convent to join him in Rome where he greeted her with open arms and tears in his eyes. Then he set about the business of finding her a husband.
Marriage.
On her visit to Rome, the Venetian envoy described Catherine as "small of stature, and thin, and without delicate features, but having the protruding eyes peculiar to the Medici family". Suitors, however, lined up for her hand, including James V of Scotland who sent the Duke of Albany to Clement to conclude a marriage in April and November 1530. When Francis I of France proposed his second son, Henry, Duke of Orléans, in early 1533, Clement jumped at the offer. Henry was a prize catch for Catherine, who despite her wealth, was from commoner origins.
The wedding, a grand affair marked by extravagant display and gift-giving, took place in the Église Saint-Ferréol les Augustins in Marseille on 28 October 1533. Prince Henry danced and jousted for Catherine. The fourteen-year-old couple left their wedding ball at midnight to perform their nuptial duties. Henry arrived in the bedroom with King Francis, who is said to have stayed until the marriage was consummated. He noted that "each had shown valour in the joust". Clement visited the newlyweds in bed the next morning and added his blessings to the night's proceedings.
Catherine saw little of her husband in their first year of marriage, but the ladies of the court treated her well, impressed with her intelligence and keenness to please. The death of Pope Clement VII on 25 September 1534, however, undermined Catherine's standing in the French court. The next pope, Paul III, broke the alliance with France and refused to pay her huge dowry. King Francis lamented, "The girl has come to me stark naked."
Prince Henry showed no interest in Catherine as a wife; instead, he openly took mistresses. For the first ten years of the marriage, Catherine failed to produce any children. In 1537, Philippa Duci, one of Henry's mistresses, gave birth to a daughter, whom he publicly acknowledged. This proved that Henry was fertile and added to the pressure on Catherine to produce a child.
Dauphine.
In 1536, Henry's older brother, Francis, caught a chill after a game of tennis, contracted a fever and died, leaving Henry the heir. As Dauphine, Catherine was now expected to provide a future heir to the throne. According to the court chronicler Brantôme, "many people advised the king and the Dauphin to repudiate her, since it was necessary to continue the line of France". Divorce was discussed. In desperation, Catherine tried every known trick for getting pregnant, such as placing cow dung and ground stags' antlers on her "source of life", and drinking mule's urine. On 19 January 1544, she at last gave birth to a son, named after King Francis.
After becoming pregnant once, Catherine had no trouble doing so again. She may have owed her change of luck to the physician Jean Fernel, who had noticed slight abnormalities in the couple's sexual organs and advised them how to solve the problem. Catherine quickly conceived again and on 2 April 1545 she bore a daughter, Elisabeth. She went on to bear Henry a further eight children, six of whom survived infancy, including the future Charles IX (born 27 June 1550); the future Henry III (born 19 September 1551); and Francis, Duke of Anjou (born 18 March 1555). The long-term future of the Valois dynasty, which had ruled France since the 14th century, seemed assured.
Catherine's new-found ability to bear children, however, failed to improve her marriage. In 1538, at the age of nineteen, Henry had taken as his mistress the thirty-eight-year-old Diane de Poitiers, whom he adored for the rest of his life. Even so, he respected Catherine's status as his consort. When King Francis I died in 1559 Catherine became queen consort of France. She was crowned in the basilica of Saint-Denis on 10 June 1559.
Queen of France.
Henry allowed Catherine almost no political influence as queen. Although she sometimes acted as regent during his absences from France, her powers were strictly nominal. Henry gave the Château of Chenonceau, which Catherine had wanted for herself, to Diane de Poitiers, who took her place at the centre of power, dispensing patronage and accepting favours.
The imperial ambassador reported that in the presence of guests, Henry would sit on Diane's lap and play the guitar, chat about politics, or fondle her breasts. Diane never regarded Catherine as a threat. She even encouraged the king to sleep with Catherine and sire more children. In 1556, Catherine nearly died giving birth to twin daughters. Surgeons saved her life by breaking the legs of one of the two babies, who died in her womb. The surviving daughter died seven weeks later. Catherine had no more children.
Henry's reign also saw the rise of the Guise brothers, Charles, who became a cardinal, and Henry's boyhood friend Francis, who became Duke of Guise. Their sister Mary of Guise had married James V of Scotland in 1538 and was the mother of Mary, Queen of Scots. At the age of five and a half, Mary was brought to the French court, where she was promised to the Dauphin, Francis. Catherine brought her up with her own children at the French court, while Mary of Guise governed Scotland as her daughter's regent.
On 3–4 April 1559, Henry signed the Peace of Cateau-Cambrésis with the Holy Roman Empire and England, ending a long period of Italian wars. The treaty was sealed by the betrothal of Catherine's thirteen-year-old daughter Elisabeth to Philip II of Spain. Their proxy wedding in Paris on 22 June 1559 was celebrated with festivities, balls, masques, and five days of jousting.
King Henry took part in the jousting, sporting Diane's black-and-white colours. He defeated the dukes of Guise and Nemours, but the young Gabriel, comte de Montgomery, knocked him half out of the saddle. Henry insisted on riding against Montgomery again, and this time, Montgomery's lance shattered into the king's face. Henry reeled out of the clash, his face pouring blood, with splinters "of a good bigness" sticking out of his eye and head. Catherine, Diane, and Prince Francis all fainted. Henry was carried to the Château de Tournelles, where five splinters of wood were extracted from his head, one of which had pierced his eye and brain. Catherine stayed by his bedside, but Diane kept away, "for fear", in the words of a chronicler, "of being expelled by the Queen". For the next ten days, Henry's state fluctuated. At times he even felt well enough to dictate letters and listen to music. Slowly, however, he lost his sight, speech, and reason, and on 10 July 1559 he died. From that day, Catherine took a broken lance as her emblem, inscribed with the words ""lacrymae hinc, hinc dolor"" ("from this come my tears and my pain"), and wore black mourning in memory of Henry.
Queen mother.
Reign of Francis II.
Francis II became king at the age of fifteen. In what has been called a "coup d'état", the Cardinal of Lorraine and the Duke of Guise—whose niece, Mary, Queen of Scots, had married Francis the year before—seized power the day after Henry II's death and quickly moved themselves into the Louvre Palace with the young couple. The English ambassador reported a few days later that "the house of Guise ruleth and doth all about the French king". For the moment, Catherine worked with the Guises out of necessity. She was not strictly entitled to a role in Francis's government, because he was deemed old enough to rule for himself. Nevertheless, all his official acts began with the words: "This being the good pleasure of the Queen, my lady-mother, and I also approving of every opinion that she holdeth, am content and command that ..." Catherine did not hesitate to exploit her new authority. One of her first acts was to force Diane de Poitiers to hand over the crown jewels and return the Château de Chenonceau to the crown. She later did her best to efface or outdo Diane's building work there.
The Guise brothers set about persecuting the Protestants with zeal. Catherine adopted a moderate stance and spoke up against the Guise persecutions, though she had no particular sympathy for the Huguenots, whose beliefs she never shared. The Protestants looked for leadership first to Antoine de Bourbon, King of Navarre, the First Prince of the Blood, and then, with more success, to his brother, Louis de Bourbon, Prince of Condé, who backed a plot to overthrow the Guises by force. When the Guises heard of the plot, they moved the court to the fortified Château of Amboise. The Duke of Guise launched an attack into the woods around the château. His troops surprised the rebels and killed many of them on the spot, including the commander, La Renaudie. Others they drowned in the river or strung up around the battlements while Catherine and the court watched.
In June 1560, Michel de l'Hôpital was appointed Chancellor of France. He sought the support of France's constitutional bodies and worked closely with Catherine to defend the law in the face of the growing anarchy. Neither saw the need to punish Protestants who worshipped in private and did not take up arms. On 20 August 1560, Catherine and the chancellor advocated this policy to an assembly of notables at Fontainebleau. Historians regard the occasion as an early example of Catherine's statesmanship. Meanwhile, Condé raised an army and in autumn 1560 began attacking towns in the south. Catherine ordered him to court and had him imprisoned as soon as he arrived. He was tried in November, found guilty of offences against the crown, and sentenced to death. His life was saved by the illness and death of the king, as a result of an infection or an abscess in his ear.
When Catherine had realized Francis was going to die, she made a pact with Antoine de Bourbon by which he would renounce his right to the regency of the future king, Charles IX, in return for the release of his brother Condé. As a result, when Francis died on 5 December 1560, the Privy Council appointed Catherine as governor of France ("gouvernante de France"), with sweeping powers. She wrote to her daughter Elisabeth: "My principal aim is to have the honour of God before my eyes in all things and to preserve my authority, not for myself, but for the conservation of this kingdom and for the good of all your brothers".
Reign of Charles IX.
At first Catherine kept the nine-year-old king, who cried at his coronation, close to her, and slept in his chamber. She presided over his council, decided policy, and controlled state business and patronage. However, she was never in a position to control the country as a whole, which was on the brink of civil war. In many parts of France the rule of nobles held sway rather than that of the crown. The challenges Catherine faced were complex and in some ways difficult for her to comprehend as a foreigner.
She summoned church leaders from both sides to attempt to solve their doctrinal differences. Despite her optimism, the resulting Colloquy of Poissy ended in failure on 13 October 1561, dissolving itself without her permission. Catherine failed because she saw the religious divide only in political terms. In the words of historian R. J. Knecht, "she underestimated the strength of religious conviction, imagining that all would be well if only she could get the party leaders to agree". In January 1562, Catherine issued the tolerant Edict of Saint-Germain in a further attempt to build bridges with the Protestants. On 1 March 1562, however, in an incident known as the Massacre of Vassy, the Duke of Guise and his men attacked worshipping Huguenots in a barn at Vassy (Wassy), killing 74 and wounding 104. Guise, who called the massacre "a regrettable accident", was cheered as a hero in the streets of Paris while the Huguenots called for revenge. The massacre lit the fuse that sparked the French Wars of Religion. For the next thirty years, France found itself in a state of either civil war or armed truce.
Within a month Louis de Bourbon, Prince of Condé, and Admiral Gaspard de Coligny had raised an army of 1,800. They formed an alliance with England and seized town after town in France. Catherine met Coligny, but he refused to back down. She therefore told him: "Since you rely on your forces, we will show you ours". The royal army struck back quickly and laid siege to Huguenot-held Rouen. Catherine visited the deathbed of Antoine de Bourbon, King of Navarre, after he was fatally wounded by an arquebus shot. Catherine insisted on visiting the field herself and when warned of the dangers laughed, "My courage is as great as yours". The Catholics took Rouen, but their triumph was short lived. On 18 February 1563, a spy called Poltrot de Méré fired an arquebus into the back of the Duke of Guise, at the siege of Orléans. The murder triggered an aristocratic blood feud that complicated the French civil wars for years to come. Catherine, however, was delighted with the death of her ally. "If Monsieur de Guise had perished sooner", she told the Venetian ambassador, "peace would have been achieved more quickly". On 19 March 1563, the Edict of Amboise, also known as the Edict of Pacification, ended the war. Catherine now rallied both Huguenot and Catholic forces to retake Le Havre from the English.
Huguenots.
On 17 August 1563, Charles IX was declared of age at the Parlement of Rouen, but he was never able to rule on his own and showed little interest in government. Catherine decided to launch a drive to enforce the Edict of Amboise and revive loyalty to the crown. To this end, she set out with Charles and the court on a progress around France that lasted from January 1564 until May 1565. Catherine held talks with the Protestant Queen Jeanne III of Navarre at Mâcon and Nérac. She also met her daughter Elisabeth at Bayonne near the Spanish border, amidst lavish court festivities. Philip II excused himself from the occasion. He sent the Duke of Alba to tell Catherine to scrap the Edict of Amboise and to find punitive solutions to the problem of heresy.
In 1566, through the ambassador to the Ottoman Empire, Guillaume de Grandchamp de Grantrie, and because of a long-standing Franco-Ottoman alliance, Charles IX of France and Catherine de Medicis proposed to the Ottoman Court a plan to resettle French Huguenots and French and German Lutherans in Ottoman-controlled Moldavia, in order to create a military colony and a buffer against the Habsburg. This plan also had the added advantage of removing the Huguenots from France, but it failed to interest the Ottomans.
On 27 September 1567, in a swoop known as the Surprise of Meaux, Huguenot forces attempted to ambush the king, triggering renewed civil war. Taken unawares, the court fled to Paris in disarray. The war was ended by the Peace of Longjumeau of 22–23 March 1568, but civil unrest and bloodshed continued. The Surprise of Meaux marked a turning point in Catherine's policy towards the Huguenots. From that moment, she abandoned compromise for a policy of repression. She told the Venetian ambassador in June 1568 that all one could expect from Huguenots was deceit, and she praised the Duke of Alba's reign of terror in the Netherlands, where Calvinists and rebels were put to death in the thousands.
The Huguenots retreated to the fortified stronghold of La Rochelle on the west coast, where Jeanne d'Albret and her fifteen-year-old son, Henry of Bourbon, joined them. "We have come to the determination to die, all of us", Jeanne wrote to Catherine, "rather than abandon our God, and our religion". Catherine called Jeanne, whose decision to rebel posed a dynastic threat to the Valois, "the most shameless woman in the world". Nevertheless, the Peace of Saint-Germain-en-Laye, signed on 8 August 1570 because the royal army ran out of cash, conceded wider toleration to the Huguenots than ever before.
Catherine looked to further Valois interests by grand dynastic marriages. In 1570, Charles IX married Elisabeth of Austria, daughter of Maximilian II, Holy Roman Emperor. Catherine was also eager for a match between one of her two youngest sons and Elizabeth I of England. After Catherine's daughter Elisabeth died in childbirth in 1568, she had touted her youngest daughter Margaret as a bride for Philip II of Spain. Now she sought a marriage between Margaret and Henry III of Navarre, with the aim of uniting Valois and Bourbon interests. Margaret, however, was secretly involved with Henry of Guise, the son of the late Duke of Guise. When Catherine found this out, she had her daughter brought from her bed. Catherine and the king then beat her, ripping her nightclothes and pulling out handfuls of her hair.
Catherine pressed Jeanne d'Albret to attend court. Writing that she wanted to see Jeanne's children, she promised not to harm them. Jeanne replied: "Pardon me if, reading that, I want to laugh, because you want to relieve me of a fear that I've never had. I've never thought that, as they say, you eat little children". When Jeanne did come to court, Catherine pressured her hard, playing on Jeanne's hopes for her beloved son. Jeanne finally agreed to the marriage between her son and Margaret, so long as Henry could remain a Huguenot. When Jeanne arrived in Paris to buy clothes for the wedding, she was taken ill and died, aged forty-four. Huguenot writers later accused Catherine of murdering her with poisoned gloves. The wedding took place on 18 August 1572 at Notre-Dame, Paris.
St. Bartholomew's Day massacre.
Three days later, Admiral Coligny was walking back to his rooms from the Louvre when a shot rang out from a house and wounded him in the hand and arm. A smoking arquebus was discovered in a window, but the culprit had made his escape from the rear of the building on a waiting horse. Coligny was carried to his lodgings at the Hôtel de Béthisy, where the surgeon Ambroise Paré removed a bullet from his elbow and amputated a damaged finger with a pair of scissors. Catherine, who was said to have received the news without emotion, made a tearful visit to Coligny and promised to punish his attacker. Many historians have blamed Catherine for the attack on Coligny. Others point to the Guise family or a Spanish-papal plot to end Coligny's influence on the king.• Frieda, 292. The Duke of Anjou was later reported as saying that he and Catherine had planned the assassination with Anne d'Este, who longed to avenge her husband, Francis, Duke of Guise.• For an overview of historians' various interpretations, see Holt, 83–4.</ref> Whatever the truth, the bloodbath that followed was soon beyond the control of Catherine or any other leader.
The St. Bartholomew's Day massacre, which began two days later, has stained Catherine's reputation ever since. There is no reason to believe she was not party to the decision when on 23 August Charles IX ordered, "Then kill them all! Kill them all!"• Marshal Tavannes recalled that Catherine had summoned a war council in the Tuileries Gardens (so as not to be overheard) to plan the next move: "Because the attempt on the Admiral would cause a war, she, and the rest of us, agreed that it would be advisable to bring battle in Paris". It is almost certain, however, that when Charles gave the order "Kill them all!", he meant those drawn up on a list by Catherine, and not, as has often been claimed, all Huguenots. Frieda, 306–8.</ref> The thinking was clear. Catherine and her advisers expected a Huguenot uprising to avenge the attack on Coligny. They chose therefore to strike first and wipe out the Huguenot leaders while they were still in Paris after the wedding.
The slaughter in Paris lasted for almost a week. It spread to many parts of France, where it persisted into the autumn. In the words of historian Jules Michelet, "St Bartholomew was not a day, but a season". On 29 September, when Navarre knelt before the altar as a Roman Catholic, having converted to avoid being killed, Catherine turned to the ambassadors and laughed. From this time dates the legend of the wicked Italian queen. Huguenot writers branded Catherine a scheming Italian, who had acted on Machiavelli's principles to kill all enemies in one blow.
Reign of Henry III.
Two years later, Catherine faced a new crisis with the death of Charles IX at the age of twenty-three. His dying words were "oh, my mother ...". The day before he died, he named Catherine regent, since his brother and heir, Henry the Duke of Anjou, was in the Polish-Lithuanian Commonwealth, where he had been elected king the year before. However, three months after his coronation at Wawel Cathedral, Henry abandoned that throne and returned to France in order to become king of France. Catherine wrote to Henry of Charles IX's death: "I am grief-stricken to have witnessed such a scene and the love which he showed me at the end ... My only consolation is to see you here soon, as your kingdom requires, and in good health, for if I were to lose you, I would have myself buried alive with you."
Henry was Catherine's favourite son. Unlike his brothers, he came to the throne as a grown man. He was also healthier, though he suffered from weak lungs and constant fatigue. His interest in the tasks of government, however, proved fitful. He depended on Catherine and her team of secretaries until the last few weeks of her life. He often hid from state affairs, immersing himself in acts of piety, such as pilgrimages and flagellation. He was, however, also famous for his circle of favorites, called Les Mignons (from "mignon", French for "the darlings" or "the dainty ones"). It was a term used by polemicists in the toxic atmosphere of the French Wars of Religion and taken up by the people of Paris, to designate the favourites of Henry III of France, from his return from Poland to reign in France in 1574, to his assassination in 1589, a disastrous end to which the perception of effeminate weakness contributed. The mignons were frivolous and fashionable young men, to whom public malignity attributed heterodox sexuality, rumors that some historians have found to be a factor in the disintegration of the late Valois monarchy.
According to the contemporary chronicler Pierre de l'Estoile, they made themselves "exceedingly odious, as much by their foolish and haughty demeanour, as by their effeminate and immodest dress, but above all by the immense gifts the king made to them." The Joyeuse wedding in 1581 occasioned one of the most extravagant display of the reign.
Henry married Louise de Lorraine-Vaudémont in February 1575, two days after his coronation. His choice thwarted Catherine's plans for a political marriage to a foreign princess. Rumours of Henry's inability to produce children were by that time in wide circulation. The papal nuncio Salviati observed, "it is only with difficulty that we can imagine there will be offspring ... physicians and those who know him well say that he has an extremely weak constitution and will not live long." As time passed and the likelihood of children from the marriage receded, Catherine's youngest son, Francis, Duke of Alençon, known as "Monsieur", played upon his role as heir to the throne, repeatedly exploiting the anarchy of the civil wars, which were by now as much about noble power struggles as religion. Catherine did all in her power to bring Francis back into the fold. On one occasion, in March 1578, she lectured him for six hours about his dangerously subversive behaviour.
In 1576, in a move that endangered Henry's throne, Francis allied with the Protestant princes against the crown. On 6 May 1576, Catherine gave in to almost all Huguenot demands in the Edict of Beaulieu. The treaty became known as the "Peace of Monsieur" because it was thought that Francis had forced it on the crown. Francis died of consumption in June 1584, after a disastrous intervention in the Low Countries during which his army had been massacred. Catherine wrote, the next day: "I am so wretched to live long enough to see so many people die before me, although I realize that God's will must be obeyed, that He owns everything, and that he lends us only for as long as He likes the children whom He gives us." The death of her youngest son was a calamity for Catherine's dynastic dreams. Under Salic law, by which only males could ascend the throne, the Huguenot Henry of Navarre now became heir presumptive to the French crown.
Catherine had at least taken the precaution of marrying Margaret, her youngest daughter, to Navarre. Margaret, however, became almost as much of a thorn in Catherine's side as Francis, and in 1582, she returned to the French court without her husband. Catherine was heard yelling at her for taking lovers. Catherine sent Pomponne de Bellièvre to Navarre to arrange Margaret's return. In 1585, Margaret fled Navarre again. She retreated to her property at Agen and begged her mother for money. Catherine sent her only enough "to put food on her table". Moving on to the fortress of Carlat, Margaret took a lover called d'Aubiac. Catherine asked Henry to act before Margaret brought shame on them again. In October 1586, therefore, he had Margaret locked up in the Château d'Usson. D'Aubiac was executed, though not, despite Catherine's wish, in front of Margaret. Catherine cut Margaret out of her will and never saw her again.
Catherine was unable to control Henry in the way she had Francis and Charles. Her role in his government became that of chief executive and roving diplomat. She travelled widely across the kingdom, enforcing his authority and trying to head off war. In 1578, she took on the task of pacifying the south. At the age of fifty-nine, she embarked on an eighteen-month journey around the south of France to meet Huguenot leaders face to face. Her efforts won Catherine new respect from the French people. On her return to Paris in 1579, she was greeted outside the city by the Parlement and crowds. The Venetian ambassador, Gerolamo Lipomanno, wrote: "She is an indefatigable princess, born to tame and govern a people as unruly as the French: they now recognize her merits, her concern for unity and are sorry not to have appreciated her sooner." She was under no illusions, however. On 25 November 1579, she wrote to the king, "You are on the eve of a general revolt. Anyone who tells you differently is a liar."
Catholic League.
Many leading Roman Catholics were appalled by Catherine's attempts to appease the Huguenots. After the Edict of Beaulieu, they had started forming local leagues to protect their religion. The death of the heir to the throne in 1584 prompted the Duke of Guise to assume the leadership of the Catholic League. He planned to block Henry of Navarre's succession and place Henry's Catholic uncle Cardinal Charles de Bourbon on the throne instead. In this cause, he recruited the great Catholic princes, nobles and prelates, signed the treaty of Joinville with Spain, and prepared to make war on the "heretics". By 1585, Henry III had no choice but to go to war against the League. As Catherine put it, "peace is carried on a stick" ("bâton porte paix"). "Take care", she wrote to the king, "especially about your person. There is so much treachery about that I die of fear."
Henry was unable to fight the Catholics and the Protestants at once, both of whom had stronger armies than his own. In the Treaty of Nemours, signed on 7 July 1585, he was forced to give in to all the League's demands, even that he pay its troops. He went into hiding to fast and pray, surrounded by a bodyguard known as "the Forty-five", and left Catherine to sort out the mess. The monarchy had lost control of the country, and was in no position to assist England in the face of the coming Spanish attack. The Spanish ambassador told Philip II that the abscess was about to burst.
By 1587, the Catholic backlash against the Protestants had become a campaign across Europe. Elizabeth I of England's execution of Mary, Queen of Scots, on 8 February 1587 outraged the Catholic world. Philip II of Spain prepared for an invasion of England. The League took control of much of northern France to secure French ports for his armada.
Last months and death.
Henry hired Swiss troops to help him defend himself in Paris. The Parisians, however, claimed the right to defend the city themselves. On 12 May 1588, they set up barricades in the streets and refused to take orders from anyone except the Duke of Guise. When Catherine tried to go to Mass, she found her way barred, though she was allowed through the barricades. The chronicler L'Estoile reported that she cried all through her lunch that day. She wrote to Bellièvre, "Never have I seen myself in such trouble or with so little light by which to escape." As usual, Catherine advised the king, who had fled the city in the nick of time, to compromise and live to fight another day. On 15 June 1588, Henry duly signed the Act of Union, which gave in to all the League's latest demands.
On 8 September 1588 at Blois, where the court had assembled for a meeting of the Estates, Henry dismissed all his ministers without warning. Catherine, in bed with a lung infection, had been kept in the dark. The king's actions effectively ended her days of power.
At the meeting of the Estates, Henry thanked Catherine for all she had done. He called her not only the mother of the king but the mother of the state. Henry did not tell Catherine of his plan for a solution to his problems. On 23 December 1588, he asked the Duke of Guise to call on him at the Château de Blois. As Guise entered the king's chamber, the Forty-five plunged their blades into his body, and he died at the foot of the king's bed. At the same moment, eight members of the Guise family were rounded up, including the Duke of Guise's brother, Louis II, Cardinal of Guise, whom Henry's men hacked to death the next day in the palace dungeons. Immediately after the murder of Guise, Henry entered Catherine's bedroom on the floor below and announced, "Please forgive me. Monsieur de Guise is dead. He will not be spoken of again. I have had him killed. I have done to him what he was going to do to me." Catherine's immediate reaction is not known; but on Christmas Day, she told a friar, "Oh, wretched man! What has he done? ... Pray for him ... I see him rushing towards his ruin." She visited her old friend Cardinal de Bourbon on 1 January 1589 to tell him she was sure he would soon be freed. He shouted at her, "Your words, Madam, have led us all to this butchery." She left in tears.
On 5 January 1589, Catherine died at the age of sixty-nine, probably from pleurisy. L'Estoile wrote: "those close to her believed that her life had been shortened by displeasure over her son's deed." He added that she had no sooner died than she was treated with as much consideration as a dead goat. Because Paris was held by enemies of the crown, Catherine had to be buried provisionally at Blois. Eight months later, Jacques Clément stabbed Henry III to death. At the time, Henry was besieging Paris with the King of Navarre, who would succeed him as Henry IV of France. Henry III's assassination ended nearly three centuries of Valois rule and brought the Bourbon dynasty into power. Years later, Diane, daughter of Henry II and Philippa Duci, had Catherine's remains reinterred in the Saint-Denis basilica in Paris. In 1793, a revolutionary mob tossed her bones into a mass grave with those of the other kings and queens.
Henry IV was later reported to have said of Catherine:
Patron of the arts.
Catherine believed in the humanist ideal of the learned Renaissance prince whose authority depended on letters as well as arms. She was inspired by the example of her father-in-law, King Francis I of France, who had hosted the leading artists of Europe at his court, and by her Medici ancestors. In an age of civil war and declining respect for the monarchy, she sought to bolster royal prestige through lavish cultural display. Once in control of the royal purse, she launched a programme of artistic patronage that lasted for three decades. During this time, she presided over a distinctive late French Renaissance culture in all branches of the arts.
An inventory drawn up at the Hôtel de la Reine after Catherine's death shows her to have been a keen collector. Listed works of art included tapestries, hand-drawn maps, sculptures, rich fabrics, ebony furniture inlaid with ivory, sets of china, and Limoges pottery. There were also hundreds of portraits, for which a vogue had developed during Catherine's lifetime. Many portraits in her collection were by Jean Clouet (1480–1541) and his son François Clouet (c. 1510 – 1572). François Clouet drew and painted portraits of all Catherine's family and of many members of the court. After Catherine's death, a decline in the quality of French portraiture set in. By 1610, the school patronised by the late Valois court and brought to its pinnacle by François Clouet had all but died out.
Beyond portraiture, little is known about the painting at Catherine de' Medici's court. In the last two decades of her life, only two painters stand out as recognisable personalities: Jean Cousin the Younger (c. 1522 – c. 1594), few of whose works survive, and Antoine Caron (c. 1521 – 1599), who became Catherine's official painter after working at Fontainebleau under Primaticcio. Caron's vivid Mannerism, with its love of ceremonial and its preoccupation with massacres, reflects the neurotic atmosphere of the French court during the Wars of Religion.
Many of Caron's paintings, such as those of the "Triumphs of the Seasons'," are of allegorical subjects that echo the festivities for which Catherine's court was famous. His designs for the Valois Tapestries celebrate the "fêtes," picnics, and mock battles of the "magnificent" entertainments hosted by Catherine. They depict events held at Fontainebleau in 1564; at Bayonne in 1565 for the summit meeting with the Spanish court; and at the Tuileries in 1573 for the visit of the Polish ambassadors who presented the Polish crown to Catherine's son Henry of Anjou. Biographer Leonie Frieda suggests that "Catherine, more than anyone, inaugurated the fantastic entertainments for which later French monarchs also became renowned".
The musical shows in particular allowed Catherine to express her creative gifts. They were usually dedicated to the ideal of peace in the realm and based on mythological themes. To create the necessary dramas, music, and scenic effects for these events, Catherine employed the leading artists and architects of the day. Historian Frances Yates has called her "a great creative artist in festivals." Catherine gradually introduced changes to the traditional entertainments: for example, she increased the prominence of dance in the shows that climaxed each series of entertainments. A distinctive new art form, the "ballet de cour," emerged from these creative advances. Owing to its synthesis of dance, music, verse, and setting, the production of the "Ballet Comique de la Reine" in 1581 is regarded by scholars as the first authentic ballet.
Catherine de' Medici's great love among the arts was architecture. "As the daughter of the Medici," suggests French art historian Jean-Pierre Babelon, "she was driven by a passion to build and a desire to leave great achievements behind her when she died." After Henry II's death, Catherine set out to immortalise her husband's memory and to enhance the grandeur of the Valois monarchy through a series of costly building projects. These included work on châteaux at Montceaux-en-Brie, Saint-Maur-des-Fossés, and Chenonceau. Catherine built two new palaces in Paris: the Tuileries and the Hôtel de la Reine. She was closely involved in the planning and supervising of all her architectural schemes.
Catherine had emblems of her love and grief carved into the stonework of her buildings. Poets lauded her as the new Artemisia, after Artemisia II of Caria, who built the Mausoleum at Halicarnassus as a tomb for her dead husband. As the centrepiece of an ambitious new chapel, she commissioned a magnificent tomb for Henry at the basilica of Saint Denis. It was designed by Francesco Primaticcio (1504–1570), with sculpture by Germain Pilon (1528–1590). Art historian Henri Zerner has called this monument "the last and most brilliant of the royal tombs of the Renaissance." Catherine also commissioned Germain Pilon to carve the marble sculpture that contains Henry II's heart. A poem by Ronsard, engraved on its base, tells the reader not to wonder that so small a vase can hold so large a heart, since Henry's real heart resides in Catherine's breast.
Although Catherine spent ruinous sums on the arts, most of her patronage left no permanent legacy. The end of the Valois dynasty so soon after her death brought a change in priorities.
Culinary Legend.
The legend that Catherine de’ Medici introduced a long list of foods, techniques and utensils from Italy to France for the first time is amongst the most enduring and widespread in food history, cited first among such unverified claims by The Oxford Companion to Food. Items whose introduction to France have been attributed to Catherine include the dinner fork, parsley, the artichoke, lettuce, broccoli, the garden pea, pasta, Parmesan, as well as the turkey and tomato of the New World. She has also received credit for introducing sauces and a variety of dishes such as duck à l’orange and deviled eggs.
Barbara Ketcham Wheaton and Stephen Mennell provided the definitive arguments against these claims. They point out that Catherine’s father-in-law, François I of France, and the flower of the French aristocracy had dined at some of Italy’s most élite tables during the king’s Italian campaigns (and that an earlier generation had done so during Charles VIII of France’s invasion of 1494); that a vast Italian entourage had visited France for the wedding of Catherine de’ Medici’s father to her French-born mother; and that she had little influence at court until her husband’s death because he was so besotted by his mistress, Diane de Poitiers. In fact, a large population of Italians — bankers, silk-weavers, philosophers, musicians, and artists, including Leonardo da Vinci— had emigrated to France to promote the burgeoning Renaissance. Nevertheless, popular culture frequently attributes Italian culinary influence and forks in France to Catherine.
The earliest known reference to Catherine as the popularizer of Italian culinary innovation is the entry for "cuisine" in Diderot and d’Alembert’s "Encyclopédie" published in 1754, which describes haute cuisine as decadent and effeminate and explains that fussy sauces and fancy fricassees arrived in France via "that crowd of corrupt Italians who served at the court of Catherine de’ Medici."
Links to the occult.
Catherine de Medici has been labelled a "sinister Queen… noted for her interest in the occult arts". To some, Catherine and Henry's inability to produce an heir for the first ten years of their marriage gave rise to suspicion of witchcraft. Labouvie suggested that women's power was believed to be the ability to create and sustain life, whilst witches were believed to have the opposite power; that of attacking health, life and fertility. An infertile woman, and in particular an infertile Queen, was therefore regarded as 'unnatural' and a small step from supernatural. Elizabeth I was treated with similar suspicion - she too entertained questionable characters (such as her advisor, John Dee), and produced no official heir. Essentially, however, there exists no concrete proof that either woman took part in the Occult, and it is now believed that Catherine's trouble in providing an heir was in fact due to Henry II's penile deformity.
Suspicion was fuelled to some degree by her entertainment of questionable characters at court - for example, the reputed seer Nostradamus, who was rumoured to have created a talisman for Catherine, made from a mixture of metals, goat blood and human blood. Catherine also gave patronage to the Ruggeri brothers, who were renowned astrologers, but were also known for their involvement in necromancy and the black arts. Cosimo Ruggeri, in particular, was believed to be Catherine's own "trusted necromancer, and specialist in the dark arts", although there is not a great deal of surviving documentation to tell of his life. Though some suggest that they were simply magicians, for many living in Italy at the time, the distinction between 'magician' and 'witch' was unclear. Entertaining individuals that appeared to subvert the natural religious order during the most intense period of witch hunting and a time of great religious conflict was therefore an easy way to arouse suspicion.
Catherine herself had been educated in astrology and astronomy. Though these were largely considered respectable subjects, Catherine's biographer Leonie Frieda believes that it was her fascination with these subjects that has earned her the reputation history and her peers accorded her. Indeed, it has been suggested that Catherine educated her son, Henry III, in the dark arts, and that "the two devoted themselves to sorceries that were scandals of the age". As a result, some (more extreme) authors believe Catherine to be the creator of the Black Mass, a Satanic inversion of the traditional Catholic Mass, although there is little to prove this aside from Jean Bodin's account in his book "De la démonomanie des sorciers". Nevertheless, Catherine was never formally accused or prosecuted despite the fact that her reign experienced the greatest number of prosecutions for Witchcraft in Italy. This lends some weight to the suggestion that people were labelled 'witches' simply because they did not act the way a woman should (humble and grateful), or simply to suit personal agendas. This may be particularly true for Catherine as an Italian woman ruling in France; several historians argue that she was disliked by her French subjects, who labelled her "the Italian woman". In any event, the rumours have made a mark on Catherine's reputation over time, and there are now many dramaticised works about her involvement in the Occult.
Issue.
Catherine de' Medici married Henry, Duke of Orléans, the future Henry II of France, in Marseille on 28 October 1533. She gave birth to ten children, seven of whom survived to adulthood. Her three oldest sons became king of France; two of her daughters married kings; and one married a duke. Catherine outlived all her children except Henry III, who died seven months after her, and Margaret, who inherited her robust health.

</doc>
<doc id="44156" url="https://en.wikipedia.org/wiki?curid=44156" title="Clue">
Clue

Clue may refer to:
In arts and entertainment:
In science and technology:
Other uses:

</doc>
<doc id="44158" url="https://en.wikipedia.org/wiki?curid=44158" title="Conservative force">
Conservative force

A conservative force is a force with the property that the work done in moving a particle between two points is independent of the taken path. Equivalently, if a particle travels in a closed loop, the net work done (the sum of the force acting along the path multiplied by the distance travelled) by a conservative force is zero.
A conservative force is dependent only on the position of the object. If a force is conservative, it is possible to assign a numerical value for the potential at any point. When an object moves from one location to another, the force changes the potential energy of the object by an amount that does not depend on the path taken. If the force is not conservative, then defining a scalar potential is not possible, because taking different paths would lead to conflicting potential differences between the start and end points.
Gravity is an example of a conservative force, while friction is an example of a non-conservative force.
Informal definition.
Informally, a conservative force can be thought of as a force that "conserves" mechanical energy. Suppose a particle starts at point A, and there is a force "F" acting on it. Then the particle is moved around by other forces, and eventually ends up at A again. Though the particle may still be moving, at that instant when it passes point A again, it has traveled a closed path. If the net work done by "F" at this point is 0, then "F" passes the closed path test. Any force that passes the closed path test for all possible closed paths is classified as a conservative force.
The gravitational force, spring force, magnetic force (according to some definitions, see below) and electric force (at least in a time-independent magnetic field, see Faraday's law of induction for details) are examples of conservative forces, while friction and air drag are classical examples of non-conservative forces.
For non-conservative forces, the mechanical energy that is lost (not conserved) has to go somewhere else, by conservation of energy. Usually the energy is turned into heat, for example the heat generated by friction. In addition to heat, friction also often produces some sound energy. The water drag on a moving boat converts the boat's mechanical energy into not only heat and sound energy, but also wave energy at the edges of its wake. These and other energy losses are irreversible because of the second law of thermodynamics.
Path independence.
A direct consequence of the closed path test is that the work done by a conservative force on a particle moving between any two points does not depend on the path taken by the particle. 
This is illustrated in the figure to the right: The work done by the gravitational force on an object depends only on its change in height because the gravitational force is conservative. The work done by a conservative force is equal to the negative of change in potential energy during that process. For a proof, imagine two paths 1 and 2, both going from point A to point B. The variation of energy for the particle, taking path 1 from A to B and then path 2 backwards from B to A, is 0; thus, the work is the same in path 1 and 2, i.e., the work is independent of the path followed, as long as it goes from A to B.
For example, if a child slides down a frictionless slide, the work done by the gravitational force on the child from the top of the slide to the bottom will be the same no matter what the shape of the slide; it can be straight or it can be a spiral. The amount of work done only depends on the vertical displacement of the child.
Mathematical description.
A force field "F", defined everywhere in space (or within a simply-connected volume of space), is called a "conservative force" or "conservative vector field" if it meets any of these three "equivalent" conditions:
The term "conservative force" comes from the fact that when a conservative force exists, it conserves mechanical energy. The most familiar conservative forces are gravity, the electric force (in a time-independent magnetic field, see Faraday's law), and spring force.
Many forces (particularly those that depend on velocity) are not force "fields". In these cases, the above three conditions are not mathematically equivalent. For example, the magnetic force satisfies condition 2 (since the work done by a magnetic field on a charged particle is always zero), but does not satisfy condition 3, and condition 1 is not even defined (the force is not a vector field, so one cannot evaluate its curl). Accordingly, some authors classify the magnetic force as conservative, while others do not. The magnetic force is an unusual case; most velocity-dependent forces, such as friction, do not satisfy any of the three conditions, and therefore are unambiguously nonconservative.
Nonconservative forces.
Nonconservative forces can arise in classical physics due to neglected degrees of freedom or from time-dependent potentials. For instance, friction may be treated without resorting to the use of nonconservative forces by considering the motion of individual molecules; however that means every molecule's motion must be considered rather than handling it through statistical methods. For macroscopic systems the nonconservative approximation is far easier to deal with than millions of degrees of freedom. Examples of nonconservative forces are friction and non-elastic material stress.
However, general relativity is non-conservative, as seen in the anomalous precession of Mercury's orbit. However, general relativity can be shown to conserve a stress-energy-momentum pseudotensor.

</doc>
<doc id="44159" url="https://en.wikipedia.org/wiki?curid=44159" title="Coda">
Coda

Coda can denote any concluding event, summation, or section.
Coda may also refer to:

</doc>
<doc id="44160" url="https://en.wikipedia.org/wiki?curid=44160" title="Sauk people">
Sauk people

The Sac or Sauk are a group of Native Americans of the Eastern Woodlands culture group. Their autonym is oθaakiiwaki, and their exonym is Ozaagii(-wag) in Ojibwe. The latter name was transliterated into French and English by colonists of those cultures.
Today they have three federally recognized tribes, together with the Meskwaki (Fox), located in Iowa, Oklahoma and Kansas.
History.
The Sauk, an Algonquian languages people, are believed to have developed as a people along the St. Lawrence River. They were driven by pressure from other tribes, especially the powerful Iroquois League or "Haudenosaunee", to migrate to Michigan, where they settled around Saginaw Bay. Due to the yellow-clay soils found around Saginaw Bay, they called themselves the autonym of "Oθaakiiwaki" (often interpreted to mean "yellow-earth".)
The neighboring Ojibwe and Ottawa peoples referred to them by the exonym "Ozaagii", meaning "those at the outlet". French colonists transliterated that as "Sac" and the English as "Sauk". Anishinaabe expansion and the Huron attempt to gain regional stability drove the Sac out of their territory. The Huron were armed with guns supplied by their French trading partners. The Sac moved south to territory in parts of what are now northern Illinois and Wisconsin.
A closely allied tribe, the "Meskwaki" (Fox), were noted for resisting French encroachment, having fought two wars against them in the early 18th century. After a devastating battle of September 9, 1730, in Illinois, in which hundreds of warriors were killed and many women and children taken captive by French allies, Fox refugees took shelter with the Sac, making them subject to French attack. The Sac continued moving west to Iowa and Kansas. Two important leaders arose among the Sac: Keokuk and Black Hawk. At first Keokuk accepted the loss of land as inevitable in the face of the vast numbers of white soldiers and settlers coming west. He tried to preserve tribal land and his people, and to keep the peace.
Having failed to receive expected supplies from the Americans on credit, Black Hawk wanted to fight, saying his people were "forced into war by being deceived." Led by Black Hawk in 1832, the mainly Sac band resisted the continued loss of lands (in western Illinois, this time.) Their warfare with United States forces resulted in defeat at the hands of General Edmund P. Gaines in the Black Hawk War.
About this time, one group of Sac moved into Missouri, and later to Kansas and Nebraska. In 1869 the larger group of Sac moved into reservations in Oklahoma, where they merged with the Meskwaki as the federally recognized Sac and Fox Nation. (The United States had been making treaties with them together since their residency in the Midwest.) A smaller number returned to the Midwest from Oklahoma (or resisted leaving.) They joined the Mesquakie at the Mesqwaki Settlement, Iowa.
Clan system.
Originally, the Sauk had a patrilineal clan system, in which descent and inheritance was traced through the father. Clans which continue are: Fish, Ocean/Sea, Thunder, Bear, Fox, Potato, Deer, Beaver, Snow, and Wolf. The tribe was governed by a council of sacred clan chiefs, a war chief, the head of families, and the warriors. Chiefs were recognized in three categories: civil, war, and ceremonial. Only the civil chiefs were hereditary. The other two chiefs were recognized by bands after they demonstrated their ability or spiritual power.
This traditional manner of selecting historic clan chiefs and governance was replaced in the 19th century by the United States appointing leaders through their agents at the Sac and Fox Agency, or reservation in Indian Territory (now Oklahoma). In the 20th century, the tribe adopted a constitutional government patterned after the United States form. They elect their chiefs.
Federally recognized tribes.
Today the federally recognized Sac and Fox tribes are:
Language.
Sauk is one of the many Algonquian languages. It is very closely related to the varieties spoken by the Meskwaki and the Kickapoo tribes; linguist often describe these three as dialects of the same language. Each of the dialects contains archaisms and innovations that distinguish them from each other. Sauk and Meskwaki appear to be the most closely related of the three, reflecting the peoples' long relationship. Sauk is considered to be mutually intelligible, to a point, with Fox.
In their own language, the Sauk at one time called themselves "asakiwaki" [a-‘sak-i-wa-ki], "people of the outlet."
The Sauk people have a syllabic orthography for their language. They published a Primer Book in 1977, based on a "traditional" syllabary that existed in 1906. It is intended to help modern-day Sauk to learn to write and speak their ancestral tongue. A newer orthography was proposed around 1994 to aid in language revival. The former syllabary was aimed at remaining native speakers of Sauk; the more recent orthography was developed for native English speakers, as many Sauk grow up with English as their first language (Müller 1994).
Sauk has so few speakers that it is considered an endangered language, as are numerous others native to North America.
In 2012, Shawnee High School in Shawnee, Oklahoma began to offer a Sauk language course.
Phonology.
Sauk does not have many phonemes in comparison to many other languages: four vowels, two semivowels, and eight consonants.
Consonants.
The representation of was omitted in the 1977 syllabary. It was added back in later editions because it is an important distinctive sound in the Sauk language.
All three stops have at least two allophones each, one voiceless and one voiced:
Semivowels.
Müller (1994) symbolizes as /y/, following Americanist practice.
Vowels.
Vowel length is important in the Sauk language. Müller presents four vowels, each with two allophones:
Pitch and tone.
Pitch and tone are also important when speaking Sauk.
Syllables.
Both the Sauk and Fox languages are known for "swallowing" syllables in word-final position, which can make identification of individual sounds more difficult for the language learner.
Morphology.
Sauk is a polysynthetic language. Because this can easily pose great difficulties to learners with little to no experience with highly synthetic languages, the Sauk orthography has words written by identifying each syllable.
Orthography.
Two samples of written Sauk language, as they appear in Müller (1994):
"Ho! Ne nu ta ma"!
'Hi! I speak Sauk!'
"Ni swi me cli ke a ki a la se te ke wa ki a la te ki ki"
"e ka ta wi ke mi yak i e we li ke mi ya ki ne ko ti"
"me cle ke a e cla gwe ne mo tti wi ne li wi tti cle we na"
"li ta ske wa ne li se ke"
"Two turtles were sunning on a bank when a thunderstorm approached. When it began to rain, one turtle said to the other, 'I don’t want to get wet,' and jumped into the lake."
Geographical names.
Lake Osakis in west-central Minnesota, the Sauk River, which flows from Lake Osakis, and the towns of Osakis, Sauk Centre, and Sauk Rapids all were named for association historically with a small party of Sac who made camp on the shores of Lake Osakis. They had been banished from their tribe for murder. According to Anishinaabe oral tradition, these five Sac were killed by local Dakota in the late 18th century.
Place names with "Sauk" references include: 

</doc>
<doc id="44165" url="https://en.wikipedia.org/wiki?curid=44165" title="Cluedo">
Cluedo

Cluedo () — known as Clue in North America — is a murder mystery game for three to six players, devised by Anthony E. Pratt from Birmingham, England, and currently published by the American game and toy company Hasbro. The object of the game is to determine who murdered the game's victim ("Dr. Black" in the UK version and "Mr. Boddy" in North American versions), where the crime took place, and which weapon was used. Each player assumes the role of one of the six suspects, and attempts to deduce the correct answer by strategically moving around a game board representing the rooms of a mansion and collecting clues about the circumstances of the murder from the other players.
Numerous games, books, and a film have been released as part of the "Cluedo" franchise. Several spinoffs have been released featuring various extra characters, weapons and rooms, or different game play. The original game is marketed as the "Classic Detective Game", while the various spinoffs are all distinguished by different slogans.
In 2008, "" was created (with changes to board, gameplay and characters) as a modern spinoff, but was criticized in the media and by fans of the original game. "Cluedo: The Classic Mystery Game" was then introduced in 2012, returning to Pratt's classic formula but also adding several variations.
History.
In 1944, Anthony E. Pratt, an English musician, applied for a patent of his invention of a murder/mystery-themed game, originally named "Murder!" The game was originally invented as a new game to play in bomb shelters. Shortly thereafter, Pratt and his wife, Elva Pratt (1913-1990), who had helped in designing the game, presented it to Waddingtons' executive, Norman Watson, who immediately purchased it and provided its trademark name of "Cluedo" (a play on "clue" and "Ludo"; "ludo" is Latin for "I play"). Though the patent was granted in 1947, due to post-war shortages, the game was not officially launched until 1949, when the game was simultaneously licensed to Parker Brothers in the United States for publication, where it was renamed "Clue" along with other minor changes.
There were several differences between the original game concept and that initially published in 1949, In particular, Pratt's original design calls for ten characters, one of whom was to be designated the victim by random drawing prior to the start of the game. These ten included the eliminated Mr. Brown, Mr. Gold, Miss Grey, and Mrs. Silver. The characters of Nurse White and Colonel Yellow were renamed Mrs. White and Colonel Mustard for the actual release. The game allowed for play of up to eight remaining characters, providing for nine suspects in total. Originally there were eleven rooms, including the eliminated "gun room" and cellar. In addition there were nine weapons including the unused bomb, syringe, shillelagh (walking stick/cudgel), fireplace poker, axe, and poison. Some of these unused weapons and characters appeared later in spin-off versions of the game.
Some gameplay aspects were different as well. Notably, the remaining playing cards were distributed into the rooms to be retrieved, rather than dealt directly to the players. Players also had to land on another player in order to make suggestions about that player's character through the use of special counter-tokens, and once exhausted, a player could no longer make suggestions. There were other minor differences, all of which were later updated by the game's initial release and remain essentially unchanged in the standard Classic Detective Game editions of the game.
Equipment.
The game consists of a board which shows the rooms, corridors and secret passages of an English country house called "Tudor Mansion", although previously named variously as "Tudor Close" or "Tudor Hall", and in some editions "Boddy Manor" or "Boddy Mansion". More recent editions have restored the name Tudor Mansion to the mansion, and say the mansion is in Hampshire, England in the year 1926. The game box also includes several coloured playing pieces to represent characters, miniature murder weapon props, one or two six-sided dice, three sets of cards, each set describing the aforementioned rooms, characters and weapons, "Solution Cards" envelope to contain one card from each set of cards, and a "Detective's Notes" pad on which are printed lists of rooms, weapons and characters, so players can keep detailed notes during the game.
Suspects.
Depending on edition, the playing pieces are typically made of coloured plastic, shaped like chess pawns, or character figurines. Occasionally they are made from wood or pewter. The standard edition of Cluedo comes with six basic tokens representing these original characters:
Weapons.
The playing tokens are typically made out of unfinished pewter, with the exception of the rope, which may be made of plastic, metal, or string depending on edition. Special editions have included gold plated, brass finished and sterling silver versions, which have appeared in a variety of designs.
Rooms.
There are nine rooms in the mansion where the murder can take place, laid out in circular fashion on the game board, separated by pathways overlaid by playing spaces. Each of the four corner rooms contains a secret passage that leads to the room on the opposite diagonal corner of the map. The centre room (often referred to as the Cellar, or Stairs) is inaccessible to the players, but contains the solution envelope, and is not otherwise used during game play. Coloured "start" spaces encircle the outer perimeter which correspond to each player's suspect token. Each character starts at the corresponding coloured space.
† ‡ "denote secret passages to opposite corner"
Rules.
At the beginning of play, three cards — one suspect, one weapon, and one room card — are chosen at random and put into a special envelope, so that no one can see them. These cards represent the facts of the case. The remainder of the cards are distributed among the players.
Players are instructed to assume the token/suspect nearest them. In older versions, play begins with Miss Scarlett and proceeds clockwise. In modern versions, all players roll the dice and the highest total starts the game and then proceeds clockwise. Players roll the dice (some versions contain one and others two) and move along the board's corridor spaces, or into the rooms accordingly.
The aim is to deduce the details of the murder; that is, the cards in the envelope. There are six characters, six murder weapons and nine rooms, leaving the players with 324 possibilities. While determining the details of the murder, players announce suggestions to the other players, for example:
The player's token must be in the room they suggest (in this example, it must be in the Hall); suggestions may not be made in the corridors. The token of the player suggested as the murderer as well as the weapon suggested are moved into the room, if not already present.
The player to the left of the suggesting player must then disprove the suggestion, if they can, by showing the suggesting player one (and only one) of the cards containing one of the suggestion components (either the suspect, the weapon, or the room), as this proves that the card cannot be in the envelope. This is done in secret so that the other players cannot see which card is being used to disprove the suggestion. If a player has more than one such card, they may select which one to show. If the first player to the left of the suggesting player does not have any of the three cards needed to disprove the suggestion, the next player clockwise must disprove the suggestion, if possible, and so on clockwise until either the suggesting player is shown a card that disproves their suggestion, or each player advises that they cannot disprove the suggestion. The suggesting player's turn then ends. The suggesting player does not advise the other players whether they hold any of the three cards.
Once a player has sufficiently narrowed the solution, that player can make an accusation. According to the rules, "When you think you have worked out which three cards are in the envelope, you may, on your turn, make an Accusation and name any three elements you want." Players may name any room (unlike a Suggestion, where a player's character pawn must be in the room that the player suggests).
The accusing player checks the validity of the accusation by checking the cards, keeping them concealed from other players. If they've made an incorrect accusation, they play no further part in the game except to reveal cards secretly to one of the remaining players when required to do so to disprove suggestions. Also, according to the rules, "If, after making a false Accusation, your character pawn is blocking a door, must move it into that room so that other players may enter." If the player made a correct accusation, the solution cards are shown to the other players and the game ends.
A player can use the piece representing the murderer. This does not affect the game play; the object of the game is still to be the first to make the correct accusation.
All editions of the current version of the game are advertised as a three to six player game only. Traditionally, the UK version was advertised for two to six players. The problem with two-player games under these rules is that each player has half of the remaining cards, and thus anything shared easily gives the game away. A player could potentially win after making a single suggestion in which the opponent does not have any of the cards for.
Strategy.
Though gameplay is relatively straightforward as described above, various strategies allow players to maximize their opportunities to make suggestions and therefore gain the advantage of accumulating information faster. As alluded to above, blocking the entrance to a room is one way to prevent an opponent from entering a desired room and making a suggestion.
Choice of playing piece.
The first opportunity is in choosing the initial playing piece. Mrs. Peacock has an immediate advantage of being one space closer to the first room than any of the other players. Professor Plum can move to the study, and then take the secret passage to the Kitchen, the hardest room to get to. Traditionally, Miss Scarlet had the advantage of moving first. This has been eliminated with the implementation of the high roll rule.
Navigating the board.
The next opportunity is choice of initial rooms to enter. Again Mrs. Peacock has an advantage in that she is closest to the Conservatory, a corner room with a secret passage, enabling a player on their turn to move immediately to another room and make a suggestion without rolling the dice. Miss Scarlet has a similar advantage with the Lounge. Making as many suggestions as possible gives a player an advantage to gain information. Therefore, moving into a new room as frequently as possible is one way to meet this goal. Players should make good use of the secret passages. Following the shortest path between rooms then is a good choice, even if a player already holds the card representing that room in their hand. As mentioned earlier, blocking passage of another player prevents them from attaining rooms from which to make suggestions. Various single space tracks on the board can therefore become traps, which are best avoided by a player when planning a path from room to room.
Making suggestions.
Each player begins the game with three to six cards in his hand. Keeping track of which cards are shown to each player is important in deducing the solution. Detective Notes are supplied with the game to help make this task easier. The pads can keep not only a history of which cards are in a player's hand, but also which cards have been shown by another player. It can also be useful in deducing which cards the other players have shown one another. A player makes a suggestion to learn which cards may be eliminated from suspicion. However, in some cases it may be advantageous for a player to include one of their own cards in a suggestion. This technique can be used for both forcing a player to reveal a different card as well as misleading other players into believing a specific card is suspect. Therefore, moving into a room already held in the player's hand may work to their advantage. Suggestions may also be used to thwart a player's opponent. Since every suggestion results in a suspect token being re-located to the suggested room, a suggestion may be used to prevent another player from achieving their intended destination, preventing them from suggesting a particular room, especially if that player appears to be getting close to a solution.
Notetaking.
One reason the game is enjoyed by many ages and skill levels is that the complexity of note-taking can increase as a player becomes more skillful. An amateur may simply mark off the cards he has been shown; more advanced players will keep track of who has and who does "not" have a particular card, possibly with the aid of an additional grid. Expert players may keep track of each suggestion made, knowing that the player who answers it must have at least one of the cards named; which one can be deduced by later events. One can also keep track of which cards a given player has seen, in order to minimize information revealed to that player and/or to read into that player's suggestions.
Editions.
Parker Brothers and Waddingtons each produced their own unique editions between 1949 and 1992. Hasbro purchased both companies in the early 1990s and continued to produce unique editions for each market until 2002/2003 when the current edition of Clue/Cluedo was first released. At this time, Hasbro produced a unified product across markets. The game was then localized with regional differences in spelling and naming conventions.
During Cluedo's long history, eight unique Clue editions were published in North America (1949, '56/60, '60/63, '72, '86, '92, '96, and 2002), including miniaturized "travel" editions. However, only three distinct editions of Cluedo were released in the UK – the longest of which lasted 47 years from its introduction in 1949 until its first successor in 1996. The eighth North America and fourth UK editions constitute the current shared game design. International versions occasionally developed their own unique designs for specific editions. However, most drew on the designs and art from either the US or UK editions, and in some cases mixing elements from both, while localizing others – specifically suspect portraits.
While the suspects' appearance and interior design of Dr. Black's/Mr. Boddy's mansion changed with each edition, the weapons underwent relatively minor changes, with the only major redesign occurring in the fourth 1972 US edition, which was adopted by the second 1996 UK edition and remains the standard configuration across all Classic Detective Game versions since. The artwork for the previous US editions tended to reflect the current popular style at the time they were released. The earlier UK editions were more artistically stylized themes. From 1972 on, the US editions presented lush box cover art depicting the six suspects in various candid poses within a room of the mansion. The UK would finally adopt this style only in its third release in 2000, prior to which Cluedo boxes depicted basic representations of the contents. Such lavish box art illustrations have become a hallmark of the game, since copied for the numerous licensed variants which pay homage to Clue.
Marketing.
Cluedo was originally marketed as "The Great New Detective Game" upon its launch in 1949 in North America, and quickly made a deal to license "The Great New Sherlock Holmes Game" from the Sir Arthur Conan Doyle estate. Advertising at the time suggested players would take on the guise of "Sherlock Holmes following the path of the criminal", however no depictions of Holmes appears in the advertising or on the box. By 1950 the game was simply marketed as "The Great Detective Game" until the 1960s, at which time it became: "Parker Brothers Detective Game". But the association with Sherlock Holmes was far from over. With the launch of the US 1972 edition, a television commercial showed Holmes and Watson engaged in a particularly competitive game. Adjusting with the times, in 1979 US TV commercials a detective resembling a bumbling Inspector Clouseau from the popular Pink Panther film franchise, looks for clues. In 1986, the marketing slogan added "Classic Detective Game" which persists through the last 2002/2003 edition.
In the UK, Cluedo did not start using "The Great Detective Game" marketing slogan until the mid-1950s, which it continued using until the 2000 edition when it adopted the "Classic Detective Game" slogan. However, in the mid-1950s Waddingtons also adopted a Sherlock Holmes-type detective to adorn their box covers for a brief time, though unlike the US editions, there was no acknowledgement that the character was actually the famous detective. In the 1980s, as in the US, Sherlock Holmes also appeared in TV advertising of the time, along with other classic detectives such as Sam Spade.
Spinoffs.
Waddingtons, Parker Brothers and Hasbro have created many spin-off versions of the game. Spin-off games consist of alternative rule variations of the original Classic Detective Game, which are not to be confused with themed "variants" which use the same rules and game configuration. In 1985, the brand expanded to include a feature film, television series, a musical, and numerous books.
Games.
In addition to revising the rules of gameplay, many of the games also introduced new characters, rooms and locations, weapons and/or alternative objectives.
Computer and video games.
Various versions of the game were developed for Commodore 64, MSX, Atari ST, PC, Game Boy Advance, ZX Spectrum, Nintendo DS, Super Nintendo Entertainment System, CD-i, Sega Mega Drive/Genesis, PC, Mac, Xbox 360 and Apple iPhone / iPod Touch.
"Clue: Murder at Boddy Mansion" was released in 1998 for Microsoft Windows.
In 1999 "" was released, which was not based directly upon the board game, but instead uses the familiar characters in a new mystery.
An arcade version of the game was released on an itbox terminal which involves answering questions with a chance to win money. It is available in many pubs throughout the UK.
In 1994–1996, there were six mysteries: "The Hooded Madonna," "Happy Ever After", "Deadly Patent", "Blackmail", "The Road to Damascus", and "Not in my Backyard", with actors.
"Clue Classic" was released on June 3, 2008 developed by Games Cafe for Hasbro. It is a single player interactive game based on the latest 2002/2003 Classic Detective Game artwork featuring the original six characters, weapons and nine original rooms.
In May 2009 Electronic Arts released a version of Clue for the Apple iPhone and iPod Touch on the Apple iTunes Music Store, entitled . This version is an entirely new game, based on the most recent spin-off game of . Additionally, EA's games site Pogo has a hidden-object game called "" (or "Clue" depending on market), where each game is a 60-minute "episode" (the object being to complete the game overall within this time limit). "Episodes" are usually grouped into "series" of two or more.
On the iWin website, there is a Hidden Object Game called "Clue: Accusations & Alibis."
Film.
A comedic film "Clue," based on the American version of the game, was released in 1985. In this version, the person murdered was Mr. Boddy. The film, which featured different endings released to different theatres, failed at the box office, but has subsequently attracted a cult following. All three endings released to theatres are available on the VHS and DVD versions of the film, to watch one after the other (VHS), or to select playing one or all three endings (DVD/Blu-ray).
In 2008, Universal Pictures reported that Hasbro, the makers of "Cluedo", had licensed several of its board games to the film company for feature film adaptations; among these was "Clue". Gore Verbinski was announced as director.
Television.
Game shows.
There have been several television game shows based upon this game. To date, there have been four seasons of the British version of "Cluedo" (and a Christmas version that in fact shows some similarity to the North American movie), and there have been other versions in Germany, France, Italy, Australia, Portugal and Scandinavia. The format for each puts two teams (each usually containing one celebrity and one person with law enforcement/research experience) against six in-character actors as the famed colour-coded suspects. There is a new murder victim every episode, who usually has it coming to them for one reason or another. Each episode uses different weapons. In the Christmas episode in the UK the six original weapons were used.
TV series.
On August 6, 2010, The Hub announced that an original five-part miniseries based on "Clue" was in pre-production. The miniseries premiered on November 14, 2011 and featured a youthful, ensemble cast loosely based on the characters of the board game, working together to unravel a mystery. The short mini-series draws similarities to the original board game and mostly to the 2012 spin-off Clue: The Classic Mystery Game which both featured the characters belonging or having ties to secret societies/houses and fitting closely with the character descriptions.
Documentary.
The "Clue" title and theme were used in the 1986 US documentary "Clue: Movies, Murders, and Mystery" which took a look at mystery-related pieces of media including "Murder on the Orient Express;" "Murder, She Wrote;" "Sherlock Holmes" and other television series and movies, as well as a look at the board game itself. The one-hour special was hosted by Martin Mull, who had starred in the feature film adaptation the previous year; clips from the movie are seen intertwined with the footage.
Musical.
A comedic musical of "Clue," based on the American version of the game, ran Off Broadway in 1997, closing in 1999. At the start of each performance, three audience members each select one card from over-sized versions of the traditional game decks and place them in an envelope. The chosen cards determine the ending of the show, with 216 possible conclusions.
Play.
Penned by Robert Duncan with the cooperation of Waddingtons, the first official theatrical adaptation of Cluedo was presented by the amateur theatre group: The Thame Players in Oxfordshire in July 1985. The play was subsequently picked up by Hiss & Boo productions and began a successful tour of the UK. A second tour was undertaken in 1990. Like the musical, the play involved the audience's random selection of three solution cards which were revealed towards the end of the play, whereupon the actors would then conclude the play by performing one of the 216 endings possible. Presently the play is not available for performance due to a restriction by Hasbro, since Hasbro has been planning to make a new movie. It is unclear whether the restriction applies to the musical as well.
Books.
A series of 18 humorous children's books/teen books were published in the United States by Scholastic Press between 1992 and 1997 based on the "Clue" concept and created by A.E. Parker. The books featured the US "Clue" characters in short, comedic vignettes and asked the reader to follow along and solve a crime at the end of each. The answers are printed "Upside down" with an explanation on the following page following each chapter to see if the reader was able to guess correctly or not. The crime would usually be the murder of another guest besides Mr. Boddy, a robbery of some sort, or a simple contest, in which case they must figure out who won. The tenth and final vignette would always be the murder of Mr. Boddy. Somehow, Mr. Boddy would always manage to cheat death, such as fainting before the shot was fired or being shot with trick bullets. However, at the end of the 18th book, Mrs. Peacock kills Mr. Boddy out of starvation and Mr. Boddy "stays" dead. The books feature mysterious-sounding titles such as "Midnight phone calls" "Footprints in the fog" or "The secret, secret passage".
These books are now out of print but can still be bought from various online retailers in both new and used conditions.
In 2003, Canadian mystery writer Vicki Cameron wrote a new set of mini-mysteries, called the Clue Mysteries books. The series is geared toward a more adult audience while still retaining some comic absurdity as did the 1990s series. Only two were published. Both books feature more complex storylines and vocabulary, as well as fifteen mysteries apiece. The first book contains the more modern looking clue game cover by Drew Struzan.
Another book called "CLUE Code-Breaking Puzzles" was released in December 2008 written by Helene Hovanec. The book contains a whopping 60 mysteries.
A similar series of books featuring the "Clue Jr." characters was also published. The first book, unlike the others, features thirteen mysteries, not ten, and is titled simply enough "Who Killed Mr Boddy?". The name of the book is usually the name of the tenth mystery in which Boddy is killed.
The books notably depart from the film. Mr Boddy is a trillionaire, and the guests are his friends. But since Boddy has his will made out to his friends, they each try to kill him at one point with the intent on cashing in on his will. The guests are all given some sort of defining characteristic for comic effect, as well as to help the reader discern the culprit. Colonel Mustard constantly challenges other guests to duels, Professor Plum often forgets things, even what he is doing or his own name, and Mr. Green is notoriously greedy. Mrs. Peacock is highly proper and will not stand for any lack of manners, the maid Mrs. White hates her employer and all the guests, and Miss Scarlet is beautiful and seductive. The traits all help the reader identify the guests. For example, if a mystery thief suddenly forgets what he is doing, and another guest scolds him for his bad manners, the reader can safely assume the two guests are Plum and Peacock. Mr. Boddy himself is ludicrously naive, to the point where he accepts any attempt to kill him as an accident or a misunderstanding (such as a dropped wrench flying all the way across the Mansion and hitting him in the head), and invites the guests back to the mansion. This explains why he never seeks any legal action against his "friends," and invited them back despite repeated attempts to kill him. However, after a few books, he wises up enough to be suspicious of them, but continues to invite them over against better judgement.
The "Clue Jr." series originally had all six characters, but suddenly, some of the characters were taken out, leaving only four. The mysteries usually only included cases similar to the theft of a toy, but sometimes the cases were more serious. They are usually solved when the culprit traps himself in his own lies.
Jigsaw puzzles.
A series of jigsaw puzzles (500 piece Clue/750 piece Cluedo/200 Jr. ed.), based on the game was introduced in 1991. The jigsaw puzzles presented detailed stories with a biography for each of the standard suspects. The object was to assemble the jigsaw puzzles and then deduce the solutions presented in the mystery stories from the clues provided within the completed pictures.
Variants.
The following games are licensed thematic variations of the game, which follow the basic rules and configuration of the original Classic Detective Game or its spinoffs.
Cluedo: Discover the Secrets.
On August 8, 2008, Hasbro redesigned and updated the board, characters, weapons, and rooms. Changes to the rules of game play were made, some to accommodate the new features.
The suspects have new given names and backgrounds, as well as differing abilities that may be used during the game. The revolver is now a pistol, the lead pipe has been removed, and a bat, axe, and trophy have been added. The nine rooms have changed to (in clockwise order): Hall, Guest House, Dining Room, Kitchen, Patio, Spa, Theatre, Living Room, and Observatory.
There is also a second deck of cards—the Intrigue cards. In this deck, there are two types of cards, Keepers and Clocks. Keepers are special abilities; for example, "You can see the card". There are eight clocks—the first seven drawn do nothing—whoever draws the eighth is killed by the murderer and out of the game.
The player must move to the indoor swimming pool in the centre of the board to make an accusation. This adds some challenge versus the ability to make accusations from anywhere in the original game.
The most significant change to game play is that once the suspect cards have been taken, the remaining cards are dealt so that all players have an even number of cards (rather than dealt out so that "one player may have a slight advantage"). This means that depending on the number of players a number of cards are left over. These cards are placed face down in the middle and are not seen unless a player takes a turn in the pool room to look at them.
The changes to the game have been criticized in the media for unnecessarily altering classic cultural icons. The game has also been criticized by lovers of the original game.
As of December 2012, Hasbro no longer sells the game via its website.
Worldwide differences.
Besides some rule differences listed above, some versions label differently the names of characters, weapons, rooms and in some instances the actual game itself.
In Canada and the U.S., the game is known as "Clue." It was retitled because the traditional British board game Ludo, on which the name is based, was less well known there than its American variant "Parcheesi."
The North American versions of "Clue" also replace the character "Reverend Green" from the original "Cluedo" with "Mr. Green." This is the only region to continue to make such a change. Minor changes include "Miss Scarlett" with her name being spelt with one 't', the spanner being called a wrench, and the dagger renamed a knife. And until 2003, the lead piping was known as the lead pipe only in the North American edition.
In some international versions of the game (mostly the Spanish-language ones) the colours of some pieces are different, so as to correspond with the changes to each suspect's unique foreign name variations. In some cases, rooms and weapons are changed in addition to other regional variances.
In South America it is licensed and sold under several different names. In particular, it is notably marketed as "Detetive" in Brazil.
In Norway it was first released as "Scotland Yard" by Damm. It was later re-released as "Cluedo", but the rules are the same.
Merchandising.
The Clue and Cluedo brands are well-merchandised through umbrellas, books, toys, clothing and other miscellaneous items.

</doc>
<doc id="44168" url="https://en.wikipedia.org/wiki?curid=44168" title="Brahms (disambiguation)">
Brahms (disambiguation)

Johannes Brahms (1833–1897) was a German composer and pianist.
Brahms may also refer to:

</doc>
<doc id="44169" url="https://en.wikipedia.org/wiki?curid=44169" title="Purcell (disambiguation)">
Purcell (disambiguation)

Henry Purcell (1659–1695) was an English composer.
Purcell may also refer to:

</doc>
<doc id="44173" url="https://en.wikipedia.org/wiki?curid=44173" title="Wagner (disambiguation)">
Wagner (disambiguation)

Wagner may refer to:

</doc>
<doc id="44175" url="https://en.wikipedia.org/wiki?curid=44175" title="House of Medici">
House of Medici

The House of Medici ( ; ) was an Italian banking family, political dynasty and later royal house that first began to gather prominence under Cosimo de' Medici in the Republic of Florence during the first half of the 15th century. The family originated in the Mugello region of the Tuscan countryside, gradually rising until they were able to fund the Medici Bank. The bank was the largest in Europe during the 15th century, seeing the Medici gain political power in Florence — though officially they remained citizens rather than monarchs.
The Medici produced three Popes of the Catholic Church—Pope Leo X (1513–1521), Pope Clement VII (1523–1534), and Pope Leo XI (1605); two regent queens of France—Catherine de' Medici (1547–1559) and Marie de' Medici (1600–1610); and, in 1531, the family became hereditary Dukes of Florence. In 1569, the duchy was elevated to a grand duchy after territorial expansion. They ruled the Grand Duchy of Tuscany from its inception until 1737, with the death of Gian Gastone de' Medici. The grand duchy witnessed degrees of economic growth under the earlier grand dukes, but by the time of Cosimo III de' Medici, Tuscany was fiscally bankrupt.
Their wealth and influence initially derived from the textile trade guided by the guild of the "Arte della Lana". Like other signore families, they dominated their city's government, they were able to bring Florence under their family's power, and they created an environment where art and humanism could flourish. They along with other families of Italy, such as the Visconti and Sforza of Milan, the Este of Ferrara, and the Gonzaga of Mantua, fostered and inspired the birth of the Italian Renaissance.
The Medici Bank was one of the most prosperous and most respected institutions in Europe. There are some estimates that the Medici family were the wealthiest family in Europe for a time. From this base, they acquired political power initially in Florence and later in wider Italy and Europe. A notable contribution to the profession of accounting was the improvement of the general ledger system through the development of the double-entry bookkeeping system for tracking credits and debits. The Medici family were among the earliest businesses to use the system.
History.
Origins.
The Medici family came from the agricultural Mugello region, north of Florence, being mentioned for the first time in a document of 1230. The origin of the name is uncertain. "Medici" is the plural of "medico", also written "del medico" or "delmedigo", meaning, "medical doctor". It has been suggested that the name derived from one "Medico di Potrone", a castellan of Potrone in the late 11th century, who presumably was the family's ancestor.
The dynasty began with the founding of the Medici Bank.
Rise to power.
Until the late 14th century, prior to the Medici, Florence's leading family were the House of Albizzi. In 1293 the Ordinances of Justice were enacted which effectively became the constitution of the republic of Florence throughout the Italian Renaissance. The city's numerous luxurious palazzi were becoming surrounded by townhouses, built by the ever prospering merchant class. In 1298, one of the leading banking families of Europe, the Bonsignoris, were bankrupted and so the city of Siena lost her status as the banking center of Europe to Florence.
The main challengers of the Albizzi family were the Medicis, first under Giovanni de' Medici, later under his son Cosimo di Giovanni de' Medici and grandson, Lorenzo de' Medici. The Medici controlled the Medici bank—then Europe's largest bank—and an array of other enterprises in Florence and elsewhere. In 1433, the Albizzi managed to have Cosimo exiled. The next year, however, saw a pro-Medici Signoria elected and Cosimo returned. The Medici became the town's leading family, a position they would hold for the next three centuries. Florence remained a republic until 1537, traditionally marking the end of the High Renaissance in Florence, but the instruments of republican government were firmly under the control of the Medici and their allies, save during the intervals after 1494 and 1527. Cosimo and Lorenzo rarely held official posts, but were the unquestioned leaders.
The Medici family was connected to most other elite families of the time through marriages of convenience, partnerships, or employment, as a result of which the Medici family had a central position in the social network: several families had systematic access to the rest of the elite families only through the Medici, perhaps similar to banking relationships. Some examples of these families include the Bardi, Salviati, Cavalcanti, and the Tornabuoni. This has been suggested as a reason for the rise of the Medici family.
Members of the family rose to some prominence in the early 14th century in the wool trade, especially with France and Spain. Despite the presence of some Medici in the city's government institutions, they were still far less notable than other outstanding families such as the Albizzi or the Strozzi. One Salvestro de' Medici was speaker of the woolmakers' guild during the Ciompi revolt, and one Antonio was exiled from Florence in 1396. The involvement in another plot in 1400 caused all branches of the family to be banned from Florentine politics for twenty years, with the exception of two: from one of the latter, that of Averardo de' Medici (1320-1363), originated the Medici dynasty.
15th century.
Averardo's son, Giovanni di Bicci de' Medici (c. 1360–1429), increased the wealth of the family through his creation of the Medici Bank, and became one of the richest men in the city of Florence. Although he never held any political charge, he gained strong popular support for the family through his support for the introduction of a proportional taxing system. Giovanni's son Cosimo the Elder, "Pater Patriae", took over in 1434 as gran maestro, and the Medici became unofficial heads of state of the Florentine republic.
Cosimo, Piero, and Lorenzo, three successive generations of the Medici, ruled over Florence through the greater part of the 15th century, without altogether abolishing representative government, yet while clearly dominating it. These three members of the Medici family had great skills in the management of so "restive and independent a city" as Florence, but when Lorenzo died in 1492, his son Piero proved quite incapable, and within two years he and his supporters were forced into exile a republican government replac[ing him.
Piero de' Medici (1416–1469), Cosimo's son, stayed in power for only five years (1464–1469). He was called "Piero the Gouty" because of the gout that afflicted his foot, and it eventually led to his death. Unlike his father, Piero had little interest in the arts. Due to his illness, he mostly stayed at home bedridden, and therefore did little to further the Medici control of Florence while in power. As such, Medici rule stagnated until the next generation, when Piero's son Lorenzo took over. Piero's illegitimate son, Lenihanio, fled from Italy and lived in the Alps for 15 years.
Lorenzo de' Medici (1449–1492), called "the Magnificent", was more capable of leading and ruling a city; however, he neglected the family banking business, leading to its ultimate ruin. To ensure the continuance of his family's success, Lorenzo planned his children's future careers for them. He groomed the headstrong Piero II to follow as his successor in civil leadership; Giovanni (future Pope Leo X) was placed in the church at an early age; and his daughter Maddalena was provided with a sumptuous dowry to make a politically advantageous marriage to a son of Pope Innocent VIII.
There was a conspiracy in 1478 to depose the family by killing Lorenzo with his younger brother Giuliano during Easter services, the assassination attempt ending with the death of Giuliano and an injured Lorenzo. The conspiracy involved the Pazzi and Salviati families, who were both rival banking families seeking to end the Medici influence, the priest presiding over the church services, the Archbishop of Pisa and even Sixtus IV to a degree. The conspirators approached Sixtus IV in the hopes of gaining his approval, as he and the Medici had a long rivalry themselves, but the pope gave no official sanction to the plan. Despite his refusal of official approval, the pope nonetheless allowed the plot to proceed without interfering, and, after the failed assassination of Lorenzo, also gave dispensation for crimes done in the service of the church. After this, Lorenzo adopted his brother's illegitimate son, Giulio de' Medici (1478–1535), the future Clement VII. Unfortunately, all Lorenzo's careful planning fell apart to some degree under the incompetent Piero II, who took over as the head of Florence after his father Lorenzo's death. Piero was responsible for the expulsion of the Medici from 1494-1512.
The Medici additionally benefited from the discovery of vast deposits of alum in Tolfa. Alum is essential as a mordant in the dyeing of certain cloths and was used extensively in Florence, where the main industry was textile manufacturing. However, the Turks were the only exporters of alum, so Europe was forced to buy from them until the discovery of alum in the Italian town of Tolfa. Pius II then granted the Medici family the monopoly on the mining there, making them the primary producers of Alum in Europe.
16th century.
This exile lasted only until 1512, however, and the "senior" branch of the family — those descended from Cosimo the Elder — were able to rule on and off until the assassination of Alessandro de' Medici, first Duke of Florence, in 1537. This century-long rule was only interrupted on two occasions (between 1494–1512 and 1527–1530), when popular revolts sent the Medici into exile. Power then passed to the "junior" Medici branch — those descended from Lorenzo the Elder, younger son of Giovanni di Bicci, starting with his great-great-grandson Cosimo I the Great. The Medici's rise to power was chronicled in detail by Benedetto Dei. Cosimo and his father started the Medici foundations in banking, manufacturing - including a form of franchises - wealth, art, cultural patronage, and in the Papacy that ensured their success for generations. At least half, probably more, of Florence's people were employed by them and their foundational branches in business.
However, the Medici remained masters of Italy through their two famous 16th century popes, Leo X and Clement VII, who were "de facto" rulers of both Rome and Florence. They were both patrons of the arts, but in the religious field they proved unable to stem the advance of Martin Luther's ideas. Clement VII was the pope during the sack of Rome by Charles V, and later was forced to crown him. Clement frequently changed his alliances between the Empire and France, which eventually led him to marry off his first cousin, twice removed, Catherine de' Medici, to the son of Francis I of France, the future Henry II. This led to the Medici blood being transferred, through Catherine's daughters, to the royal family of Spain through Elisabeth of Valois, and the House of Lorraine through Claude of Valois.
The most outstanding figure of the 16th century Medici was Cosimo I, who, coming from relatively modest beginnings in the Mugello, rose to supremacy in the whole of Tuscany, conquering the Florentines' most hated rival Siena and founding the Grand Duchy of Tuscany. Cosimo purchased a portion of the island of Elba from the Republic of Genoa and based the Tuscan navy there. He died in 1574, succeeded by his eldest surviving son Francesco, whose inability to produce male heirs led to the succession of his younger brother, Ferdinando, upon his death in 1587. Francesco married Johanna of Austria, and with his consort produced Eleonora de' Medici, Duchess of Mantua, and Marie de' Medici, Queen of France and of Navarre. Through Marie, all succeeding French monarchs (bar the Napoleons) are descended from Francesco.
Ferdinando eagerly assumed the government of Tuscany. He commanded the draining of the Tuscan marshlands, built a road network in Southern Tuscany and cultivated trade in Leghorn. To augment the Tuscan silk industry, he oversaw the planting of Mulberry trees along the major roads (silk worms feed on Mulberry leaves). He shifted Tuscany away from Habsburg hegemony by marrying the first non-Habsburg candidate since Alessandro, Christina of Lorraine, a granddaughter of Catherine de' Medici. The Spanish reaction was to construct a citadel on their portion of the island of Elba. To strengthen the new Franco-Tuscan alliance, he married his niece, Marie, to Henry IV of France. Henry explicitly stated that he would defend Tuscany from Spanish aggression, but later reneged, after which Ferdinando was forced to marry his heir, Cosimo, to Maria Maddalena of Austria to assuage Spain (where Maria Maddalena's sister was the incumbent Queen consort). Ferdinando sponsored a Tuscan expedition to the New World with the intention of establishing a Tuscan colony. Despite all of these incentives to economic growth and prosperity, the population of Florence at the dawn of the 17th century was a mere 75,000, far smaller than the other capitals of Italy: Rome, Milan, Venice, Palermo and Naples. Francesco and Ferdinando, due to lax distinction between Medici and Tuscan state property, are thought to have been wealthier than their ancestor, Cosimo de' Medici, the founder of the dynasty. The Grand Duke alone had the prerogative to exploit the state's mineral and salt resources, and the fortunes of the Medici were directly tied to the Tuscan economy.
17th century.
Ferdinando, although no longer a cardinal, exercised much influence at successive conclaves. In 1605, Ferdinando succeeded in getting his candidate, Alessandro de' Medici, elected Pope Leo XI. He died the same month, but his successor, Pope Paul V, was also pro-Medici. Ferdinando's pro-Papal foreign policy, however, had drawbacks. Tuscany was overrun with religious orders, not all of whom were obliged to pay taxes. Ferdinando died in 1609, leaving an affluent realm; his inaction in international affairs, however, would have long-reaching consequences down the line.
In France, Marie de' Medici was acting as regent for her son, Louis XIII. Louis repudiated her pro-Habsburg policy in 1617. She lived the rest of her life deprived of any political influence.
Ferdinando's successor, Cosimo II, reigned for less than 12 years. He married Maria Maddalena of Austria, with whom he had his eight children, including Margherita de' Medici, Ferdinando II de' Medici, and an Anna de' Medici.
He is most remembered as the patron of astronomer Galileo Galilei, whose 1610 treatise, Sidereus Nuncius, was dedicated to him. Cosimo died of consumption (tuberculosis) in 1621.
Cosimo's elder son, Ferdinando, was not yet of legal maturity to succeed him, thus Maria Maddalena and his grandmother, Christina of Lorraine, acted as regents. Their collective regency is known as the "Turtici". Maria Maddelana's temperament was analogous to Christina's, and together they aligned Tuscany with the Papacy, re-doubled the Tuscan clergy, and allowed the heresy trial of Galileo Galilei to occur. Upon the death of the last Duke of Urbino (Francesco Maria II), instead of claiming the duchy for Ferdinando, who was married to the Duke of Urbino's granddaughter and heiress, Vittoria della Rovere, they permitted it to be annexed by Pope Urban VIII. In 1626, they banned any Tuscan subject from being educated outside the Grand Duchy, a law later overturned but resurrected by Maria Maddalena's grandson, Cosimo III. Harold Acton, an Anglo-Italian historian, ascribes the decline of Tuscany to the "Turtici" regency.
Grand Duke Ferdinado was obsessed with new technology, and had a variety of hygrometers, barometers, thermometers, and telescopes installed in the Palazzo Pitti. In 1657, Leopoldo de' Medici, the Grand Duke’s youngest brother, established the Accademia del Cimento, organized to attract scientists to Florence from all over Tuscany for mutual study.
Tuscany participated in the Wars of Castro (the last time Medicean Tuscany proper was involved in a conflict) and inflicted a defeat on the forces of Pope Urban VIII in 1643. The war effort was costly and the treasury so empty because of it that when the Castro mercenaries were paid for, the state could no longer afford to pay interest on government bonds, with the result that the interest rate was lowered by 0.75%. At that time, the economy was so decrepit that barter trade became prevalent in rural market places.
Ferdinando died on 23 May 1670 afflicted by apoplexy and dropsy. He was interred in the Basilica of San Lorenzo, the Medici's necropolis. At the time of his death, the population of the grand duchy was 730,594; the streets were lined with grass and the buildings on the verge of collapse in Pisa.
Ferdinando's marriage to Vittoria della Rovere produced two children: Cosimo III de' Medici, Grand Duke of Tuscany and Francesco Maria de' Medici, Duke of Rovere and Montefeltro. Upon Vittoria's death in 1694, her allodial possessions, the Duchies of Rovere and Montefeltro, passed to her younger son.
18th century: the fall of the dynasty.
Cosimo traditionally has been accused of destroying Florentine liberties; but these ancient liberties, more of an illusion than a reality, had already ceased to exist in the Florence of the Albizzi. He made no changes in the law’s actual administration, but in the spirit of the law he changed everything, consolidating power among himself and his most loyal associates in return dictatorial powers were now granted for a fixed term that was always renewed. He married Marguerite Louise d'Orléans, a granddaughter of Henry IV of France and Marie de' Medici. An exceedingly discontented pairing, this union produced three children, notably Anna Maria Luisa de' Medici, Electress Palatine and the last Medicean Grand Duke of Tuscany, Gian Gastone de' Medici.
Johann Wilhelm, Elector Palatine, Anna Maria Luisa's spouse, successfully requisitioned the dignity "Royal Highness" for the Grand Duke and his family in 1691, despite the fact that they had no claim to any kingdom. Cosimo frequently paid the Holy Roman Emperor, his nominal feudal overlord, exorbitant dues; and he sent munitions to the Emperor during the Battle of Vienna.
The Medici lacked male heirs, and in 1705, the grand ducal treasury was virtually bankrupt. The population of Florence declined by 50%; the population of the grand duchy as a whole declined by an estimated 40%. Cosimo desperately tried to reach a settlement with the European powers, but Tuscany’s legal status was very complicated: the area of the grand duchy formerly comprising the Republic of Siena was technically a Spanish fief, while the territory of the old Republic of Florence was thought to be under imperial suzerainty. Upon the death of his first son, Cosimo contemplated restoring the Florentine republic, either upon Anna Maria Luisa's death, or on his own, if he predeceased her. The restoration of the republic would entail resigning Siena to the Holy Roman Empire, but, regardless, it was vehemently endorsed by his government. Europe largely ignored Cosimo’s plan, only Great Britain and the Dutch Republic gave any credence to it, and the plan ultimately died with Cosimo III in 1723.
On 4 April 1718, Great Britain, France and the Dutch Republic (and later Austria) selected Don Carlos of Spain, the elder child of Elisabeth Farnese and Philip V of Spain, as the Tuscan heir. By 1722, the Electress was not even acknowledged as heiress, and Cosimo was reduced to spectator at the conferences for Tuscany's future. On 25 October 1723, six days before his death, Grand Duke Cosimo disseminated a final proclamation commanding that Tuscany stay independent: Anna Maria Luisa would succeed uninhibited to Tuscany after Gian Gastone, and the Grand Duke reserved the right to choose his successor. However, these portions of his proclamation were completely ignored and he died a few days later.
Gian Gastone despised the Electress for engineering his catastrophic marriage to Anna Maria Franziska of Saxe-Lauenburg; while she abhorred her brother's liberal policies, he repealed all of his father's anti-Semitic statutes. Gian Gastone revelled in upsetting her. On 25 October 1731, a Spanish detachment occupied Florence on behalf of Don Carlos, who disembarked in Tuscany in December of the same year.
The "Ruspanti", Gian Gastone's decrepit entourage, loathed the Electress, and she them. Duchess Violante, Gian Gastone's sister-in-law, tried to withdraw the Grand Duke from the "Ruspanti" sphere of influence by organising banquets. His conduct at the banquets was less than regal, he often vomited repeatedly into his napkin, belched, and regaled those present with socially inappropriate jokes. Following a sprained ankle in 1731, he remained confined to his bed for the rest of his life. The bed, oft smelling of faeces, was occasionally cleaned by Violante.
In 1736, following the War of the Polish Succession, Don Carlos was disbarred from Tuscany, and Francis III of Lorraine was made heir in his stead. In January 1737, the Spanish troops withdrew from Tuscany, and were replaced by Austrians.
Gian Gastone died on 9 July 1737, surrounded by prelates and his sister. Anna Maria Luisa was offered a nominal regency by the Prince de Craon until the new Grand Duke could peregrinate to Tuscany, but declined. Upon her brother's death, she received all the House of Medici's allodial possessions.
Anna Maria Luisa signed the "Patto di Famiglia" on 31 October 1737. In collaboration with the Holy Roman Emperor and Grand Duke Francis of Lorraine, she willed all the personal property of the Medici to the Tuscan state, provided that nothing was ever removed from Florence.
The "Lorrainers", as the occupying forces were called, were popularly loathed, but the Regent, the Prince de Craon, allowed the Electress to live unperturbed in the Pitti. She occupied herself with financing, and with overseeing the construction of the Basilica of San Lorenzo, started in 1604 by Ferdinando I de' Medici, Grand Duke of Tuscany, costing the state 1,000 crowns per week.
She donated much of her fortune to charity: £4,000 a month. On 19 February 1743, the Dowager Electress Palatine Anna Maria Luisa de' Medici died, and the Grand Ducal line of the House of Medici died with her. The Florentines grieved her, and she was interred in the crypt that she helped to complete, San Lorenzo.
The extinction of the main Medici dynasty and the accession in 1737 of Francis Stephen, Duke of Lorraine and husband of Maria Theresa of Austria, led to Tuscany's temporary inclusion in the territories of the Austrian crown. The line of the principi di Ottajano, an extant branch of the House of Medici who were eligible to inherit the grand duchy of Tuscany when the last male of the senior branch died in 1737, could have carried on as Medici sovereigns but for the intervention of Europe's major powers, which allocated the sovereignty of Florence elsewhere.
As a consequence, the Duchy expired and the territory became a secundogeniture of the Habsburg-Lorraine dynasty. The first Grand Duke of the new dynasty, Francis I, was a great-great-great-grandson of Francesco I de' Medici, thus continuing the Medicean Dynasty on the throne of Tuscany through the female line. The Habsburgs were deposed for the Bourbon-Parma in 1801 (themselves deposed in 1807), and restored at the Congress of Vienna. Tuscany became a province of the United Kingdom of Italy in 1861. However, several extant branches of the House of Medici currently continue to exist including the Princes of Ottajano, the Medici Tornaquinci, and the Verona Medici Counts of Caprara and Gavardo.
Legacy.
The biggest accomplishments of the Medici were in the sponsorship of art and architecture, mainly early and High Renaissance art and architecture. The Medici were responsible for the majority of Florentine art during their reign. Their money was significant because during this period, artists generally only made their works when they received commissions in advance. Giovanni di Bicci de' Medici, the first patron of the arts in the family, aided Masaccio and commissioned Brunelleschi for the reconstruction of the Basilica of San Lorenzo, Florence in 1419. Cosimo the Elder's notable artistic associates were Donatello and Fra Angelico. The most significant addition to the list over the years was Michelangelo Buonarroti (1475–1564), who produced work for a number of Medici, beginning with Lorenzo the Magnificent, who was said to be extremely fond of the young Michelangelo, inviting him to study the family collection of antique sculpture. Lorenzo also served as patron to Leonardo da Vinci (1452–1519) for seven years. Indeed, Lorenzo was an artist in his own right, and author of poetry and song; his support of the arts and letters is seen as a high point in Medici patronage.
After Lorenzo's death the puritanical Dominican friar, Girolamo Savonarola rose to prominence, warning Florentines against excessive luxury. Under Savonarola's fanatical leadership, many great works were "voluntarily" destroyed in the Bonfire of the Vanities (February 7, 1497). The following year, on May 23, 1498, Savonarola and two young supporters were burned at the stake in the Piazza della Signoria, the same location as his bonfire. In addition to commissions for art and architecture, the Medici were prolific collectors and today their acquisitions form the core of the Uffizi museum in Florence. In architecture, the Medici are responsible for some notable features of Florence; including the Uffizi Gallery, the Boboli Gardens, the Belvedere,the Medici Chapel and the Palazzo Medici.
Later, in Rome, the Medici Popes continued in the family tradition of patronizing artists in Rome. Pope Leo X would chiefly commission works from Raphael. Pope Clement VII commissioned Michelangelo to paint the altar wall of the Sistine Chapel just before the pontiff's death in 1534. Eleanor of Toledo, princess of Spain and wife of Cosimo I the Great, purchased the Pitti Palace from Buonaccorso Pitti in 1550. Cosimo in turn patronized Vasari who erected the Uffizi Gallery in 1560 and founded the Accademia delle Arti del Disegno – ("Academy of the Arts of Drawing") in 1563. Marie de' Medici, widow of Henry IV of France and mother of Louis XIII, is the subject of a commissioned cycle of paintings known as the Marie de' Medici cycle, painted for the Luxembourg Palace by court painter Peter Paul Rubens in 1622-23.
Although none of the Medici themselves were scientists, the family is well known to have been the patrons of the famous Galileo Galilei, who tutored multiple generations of Medici children, and was an important figurehead for his patron's quest for power. Galileo's patronage was eventually abandoned by Ferdinando II, when the Inquisition accused Galileo of heresy. However, the Medici family did afford the scientist a safe haven for many years. Galileo named the four largest moons of Jupiter after four Medici children he tutored, although the names Galileo used are not the names currently used.

</doc>
<doc id="44178" url="https://en.wikipedia.org/wiki?curid=44178" title="Hanlon's razor">
Hanlon's razor

Hanlon's razor is an aphorism expressed in various ways including "never assume bad intentions when assuming stupidity is enough", "never assume malice when stupidity will suffice", and "never attribute to malice that which is adequately explained by stupidity". It recommends a way of eliminating unlikely explanations for a phenomenon (a philosophical razor).
As an eponymous law, it may have been named after Robert J. Hanlon. There are also earlier sayings that convey the same idea dating back at least as far as Goethe in 1774.
Origins and etymology.
Inspired by Occam's razor, the aphorism was popularized in this form and under this name by the "Jargon File", a glossary of computer programmer slang. In 1990, it appeared in the Jargon File described as a "'murphyism' parallel to Occam's Razor".
Later that same year, the "Jargon File" editors noted lack of knowledge about the term's derivation and the existence of a similar epigram by William James. In 1996, the "Jargon File" entry on Hanlon's Razor noted the existence of a similar quotation in Robert A. Heinlein's short story "Logic of Empire" (1941), with speculation that Hanlon's Razor might be a corruption of "Heinlein's Razor". (Heinlein termed it the "devil theory" of sociology, and wrote, "You have attributed conditions to villainy that simply result from stupidity".)
In 2001, Quentin Stafford-Fraser published two blog entries citing e-mails from one Joseph E. Bigler about how the quotation originally came from Robert J. Hanlon of Scranton, Pennsylvania, as a submission for a book compilation of various jokes related to Murphy's law published in Arthur Bloch's "Murphy's Law Book Two: More Reasons Why Things Go Wrong!" (1980). Subsequently, in 2002, the "Jargon File" entry noted the same, though not definitively.
Similar quotations.
Another similar quotation appears in Goethe's "The Sorrows of Young Werther" (1774):
Similarly, Jane West's "The Loyalists" (1812) includes:
A common (and more laconic) British English variation, coined by Bernard Ingham, is the saying "cock-up before conspiracy", deriving from this 1985 quotation:
Another similar instance from politics is the attribution by First Minister of Scotland, Henry McLeish, of financial irregularities that led to his resignation in 2001, to "a muddle not a fiddle".
"Heinlein's Razor" has since been defined as variations on "Never attribute to malice that which can be adequately explained by stupidity, but don't rule out malice." This quotation is falsely attributed to Albert Einstein in Peter W. Singer's book "Wired for War" (2009).

</doc>
