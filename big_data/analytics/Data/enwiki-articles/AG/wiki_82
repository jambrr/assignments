<doc id="46112" url="https://en.wikipedia.org/wiki?curid=46112" title="Violence">
Violence

[[File:Violence world map - DALY - WHO2004.svg|thumb|upright=1.2|Estimates of disability-adjusted life years from physical violence, per 100,000 inhabitants in 2004.
Violence is defined by the World Health Organization as "the intentional use of physical force or power, threatened or actual, against oneself, another person, or against a group or community, which either results in or has a high likelihood of resulting in injury, death, psychological harm, maldevelopment, or deprivation", although the group acknowledges that the inclusion of "the use of power" in its definition expands on the conventional meaning of the word. This definition involves intentionality with the committing of the act itself, irrespective of the outcome it produces. However, generally, anything that is excited in an injurious or damaging way may be described as violent even if not meant to be violence (by a person and against a person).
The most prevalent cause of death in interpersonal violence is assault with a firearm (180,000), followed by a sharp object (114,000). Other means contribute to another 110,000 deaths.
Violence in many forms is preventable. There is a strong relationship between levels of violence and modifiable factors such as concentrated poverty, income and gender inequality, the harmful use of alcohol, and the absence of safe, stable, and nurturing relationships between children and parents. Strategies addressing the underlying causes of violence can be effective in preventing violence.
Globally, violence resulted in the death of 1.28 million people in 2013 up from 1.13 million in 1990. 842,000 were due to suicide, 405,000 were due to homicide, and 31,000 were due to war. In Africa, out of every 100,000 people, each year an estimated 60.9 die a violent death. Corlin, past president of the American Medical Association said: "The United States leads the world—in the rate at which its children die from firearms." He concluded: "Gun violence is a threat to the public health of our country." For each single death due to violence, there are dozens of hospitalizations, hundreds of emergency department visits, and thousands of doctors' appointments. Furthermore, violence often has lifelong consequences for physical and mental health and social functioning and can slow economic and social development.
Types.
Violence can be divided into three broad categories:
Violent acts can be:
This initial categorization differentiates between violence a person inflicts upon himself or herself, violence inflicted by another individual or by a small group of individuals, and violence inflicted by larger groups such as states, organized political groups, militia groups and terrorist organizations. These three broad categories are each divided further to reflect more specific types of violence.
Violence is primarily classified as either instrumental or reactive / hostile.
Self-directed violence.
Self-directed violence is subdivided into suicidal behaviour and self-abuse. The former includes suicidal thoughts, attempted suicides – also called "para suicide" or "deliberate self-injury" in some countries – and completed suicides. Self-abuse, in contrast, includes acts such as self-mutilation.
Collective violence.
Collective violence is subdivided into structural violence and economic violence. Unlike the other two broad categories, the subcategories of collective violence suggest possible motives for violence committed by larger groups of individuals or by states. Collective violence that is committed to advance a particular social agenda includes, for example, crimes of hate committed by organized groups, terrorist acts and mob violence. Political violence includes war and related violent conflicts, state violence and similar acts carried out by larger groups. Economic violence includes attacks by larger groups motivated by economic gain – such as attacks carried out with the purpose of disrupting economic activity, denying access to essential services, or creating economic division and fragmentation. Clearly, acts committed by larger groups can have multiple motives.
This typology, while imperfect and far from being universally accepted, does provide a useful framework for understanding the complex patterns of violence taking place around the world, as well as violence in the everyday lives of individuals, families and communities. It also overcomes many of the limitations of other typologies by capturing the nature of violent acts, the relevance of the setting, the relationship between the perpetrator and the victim, and – in the case of collective violence – possible motivations for the violence. However, in both research and practice, the dividing lines between the different types of violence are not always so clear.
Warfare.
War is a state of prolonged violent large-scale conflict involving two or more groups of people, usually under the auspices of government. It is the most extreme form of collective violence.
War is fought as a means of resolving territorial and other conflicts, as war of aggression to conquer territory or loot resources, in national self-defence or liberation, or to suppress attempts of part of the nation to secede from it. We know also ideological, religious and revolutionary wars.
Since the Industrial Revolution, the lethality of modern warfare has grown. World War I casualties were over 40 million and World War II casualties were over 70 million.
Non-physical.
Violence includes those acts that result from a power relationship, including threats and intimidation, neglect or acts of omission. Such non-physical violence has a broad range of outcomes – including psychological harm, deprivation and maldevelopment. Violence may not necessarily result in injury or death, but nonetheless poses a substantial burden on individuals, families, communities and health care systems worldwide. Many forms of violence against women, children and the elderly, for instance, can result in physical, psychological and social problems that do not necessarily lead to injury, disability or death. These consequences can be immediate, as well as latent, and can last for years after the initial abuse. Defining outcomes solely in terms of injury or death thus limits the understanding of the full impact of violence.
Interpersonal violence.
Interpersonal violence is divided into two subcategories: Family and intimate partner violence – that is, violence largely between family members and intimate partners, usually, though not exclusively, taking place in the home. Community violence – violence between individuals who are unrelated, and who may or may not know each other, generally taking place outside the home. The former group includes forms of violence such as child abuse, intimate partner violence and abuse of the elderly. The latter includes youth violence, random acts of violence, rape or sexual assault by strangers, and violence in institutional settings such as schools, workplaces, prisons and nursing homes. When interpersonal violence occurs in families, its psychological consequences can affect parents, children, and their relationship in the short- and long-terms.
Child maltreatment.
Child maltreatment is the abuse and neglect that occurs to children under 18 years of age. It includes all types of physical and/or emotional ill-treatment, sexual abuse, neglect, negligence and commercial or other child exploitation, which results in actual or potential harm to the child’s health, survival, development or dignity in the context of a relationship of responsibility, trust or power. Exposure to intimate partner violence is also sometimes included as a form of child maltreatment.
Child maltreatment is a global problem with serious lifelong consequences, which is, however, complex and difficult to study.
There are no reliable global estimates for the prevalence of child maltreatment. Data for many countries, especially low- and middle-income countries, are lacking. Current estimates vary widely depending on the country and the method of research used. Approximately 20% of women and 5–10% of men report being sexually abused as children, while 25–50% of all children report being physically abused.
Consequences of child maltreatment include impaired lifelong physical and mental health, and social and occupational functioning (e.g. school, job, and relationship difficulties). These can ultimately slow a country's economic and social development. Preventing child maltreatment before it starts is possible and requires a multisectoral approach. Effective prevention programmes support parents and teach positive parenting skills. Ongoing care of children and families can reduce the risk of maltreatment reoccurring and can minimize its consequences.
Youth violence.
Following the World Health Organization, youth are defined as people between the ages of 10 and 29 years. Youth violence refers to violence occurring between youths, and includes acts that range from bullying and physical fighting, through more severe sexual and physical assault to homicide.
Worldwide some 250,000 homicides occur among youth 10–29 years of age each year, which is 41% of the total number of homicides globally each year ("Global Burden of Disease", World Health Organization, 2008). For each young person killed, 20-40 more sustain injuries requiring hospital treatment. Youth violence has a serious, often lifelong, impact on a person's psychological and social functioning. Youth violence greatly increases the costs of health, welfare and criminal justice services; reduces productivity; decreases the value of property; and generally undermines the fabric of society.
Prevention programmes shown to be effective or to have promise in reducing youth violence include life skills and social development programmes designed to help children and adolescents manage anger, resolve conflict, and develop the necessary social skills to solve problems; schools-based anti-bullying prevention programmes; and programmes to reduce access to alcohol, illegal drugs and guns. Also, given significant neighbourhood effects on youth violence, interventions involving relocating families to less poor environments have shown promising results. Similarly, urban renewal projects such as business improvement districts have shown a reduction in youth violence.
Intimate partner violence.
Intimate partner violence refers to behaviour in an intimate relationship that causes physical, sexual or psychological harm, including physical aggression, sexual coercion, psychological abuse and controlling behaviours.
Population-level surveys based on reports from victims provide the most accurate estimates of the prevalence of intimate partner violence and sexual violence in non-conflict settings. A study conducted by WHO in 10 mainly developing countries found that, among women aged 15 to 49 years, between 15% (Japan) and 70% (Ethiopia and Peru) of women reported physical and/or sexual violence by an intimate partner.
Intimate partner and sexual violence have serious short- and long-term physical, mental, sexual and reproductive health problems for victims and for their children, and lead to high social and economic costs. These include both fatal and non-fatal injuries, depression and post-traumatic stress disorder, unintended pregnancies, sexually transmitted infections, including HIV.
Factors associated with the perpetration and experiencing of intimate partner violence are low levels of education, history of violence as a perpetrator, a victim or a witness of parental violence, harmful use of alcohol, attitudes that are accepting of violence as well as marital discord and dissatisfaction. Factors associated only with perpetration of intimate partner violence are having multiple partners, and antisocial personality disorder.
A recent theory named "The Criminal Spin" suggests a mutual flywheel effect between partners that is manifested by an escalation in the violence. A violent spin may occur in any other forms of violence, but in Intimate partner violence the added value is the mutual spin, based on the unique situation and characteristics of intimate relationship.
The primary prevention strategy with the best evidence for effectiveness for intimate partner violence is school-based programming for adolescents to prevent violence within dating relationships. Evidence is emerging for the effectiveness of several other primary prevention strategies – those that: combine microfinance with gender equality training; promote communication and relationship skills within communities; reduce access to, and the harmful use of alcohol; and change cultural gender norms.
Sexual violence.
Sexual violence is any sexual act, attempt to obtain a sexual act, unwanted sexual comments or advances, or acts to traffic, or otherwise directed against a person’s sexuality using coercion, by any person regardless of their relationship to the victim, in any setting. It includes rape, defined as the physically forced or otherwise coerced penetration of the vulva or anus with a penis, other body part or object.
Population-level surveys based on reports from victims estimate that between 0.3–11.5% of women reported experiencing sexual violence. Sexual violence has serious short- and long-term consequences on physical, mental, sexual and reproductive health for victims and for their children as described in the section on intimate partner violence. If perpetrated during childhood, sexual violence can lead to increased smoking, drug and alcohol misuse, and risky sexual behaviours in later life. It is also associated with perpetration of violence and being a victim of violence.
Many of the risk factors for sexual violence are the same as for domestic violence. Risk factors specific to sexual violence perpetration include beliefs in family honour and sexual purity, ideologies of male sexual entitlement and weak legal sanctions for sexual violence.
Few intervention to prevent sexual violence have been demonstrated to be effective. School-based programmes to prevent child sexual abuse by teaching children to recognize and avoid potentially sexually abusive situations are run in many parts of the world and appear promising, but require further research. To achieve lasting change, it is important to enact legislation and develop policies that protect women; address discrimination against women and promote gender equality; and help to move the culture away from violence.
Elder maltreatment.
Elder maltreatment is a single or repeated act, or lack of appropriate action, occurring within any relationship where there is an expectation of trust which causes harm or distress to an older person. This type of violence constitutes a violation of human rights and includes physical, sexual, psychological, emotional; financial and material abuse; abandonment; neglect; and serious loss of dignity and respect.
While there is little information regarding the extent of maltreatment in elderly populations, especially in developing countries, it is estimated that 4–6% of elderly people in high-income countries have experienced some form of maltreatment at home However, older people are often afraid to report cases of maltreatment to family, friends, or to the authorities. Data on the extent of the problem in institutions such as hospitals, nursing homes and other long-term care facilities are scarce. Elder maltreatment can lead to serious physical injuries and long-term psychological consequences. Elder maltreatment is predicted to increase as many countries are experiencing rapidly ageing populations.
Many strategies have been implemented to prevent elder maltreatment and to take action against it and mitigate its consequences including public and professional awareness campaigns, screening (of potential victims and abusers), caregiver support interventions (e.g. stress management, respite care), adult protective services and self-help groups. Their effectiveness has, however, not so far been well-established.
Targeted violence.
Several rare but painful episodes of assassination, attempted assassination and school shootings at elementary, middle, high schools as well as colleges and universities in the United States led to a considerable body of research on ascertainable behaviours of persons who have planned or carried out such attacks. These studies (1995-2002) investigated what the authors called "targeted violence," described the "path to violence" of those who planned or carried out attacks, and laid out suggestions for law enforcement and educators. A major point from these research studies is that targeted violence does not just "come out of the blue".
Every day violence.
As an anthropological concept, this kind of violence may refers to the incorporation of different forms of violence (mainly political violence) into daily practices.
Factors.
Violence cannot be attributed to a single factor. Its causes are complex and occur at different levels. To represent this complexity, the ecological, or social ecological model is often used. The following four-level version of the ecological model is often used in the study of violence:
The first level identifies biological and personal factors that influence how individuals behave and increase their likelihood of becoming a victim or perpetrator of violence: demographic characteristics (age, education, income), genetics, brain lesions, personality disorders, substance abuse, and a history of experiencing, witnessing, or engaging in violent behaviour.
The second level focuses on close relationships, such as those with family and friends. In youth violence, for example, having friends who engage in or encourage violence can increase a young person’s risk of being a victim or perpetrator of violence. For intimate partner violence, a consistent marker at this level of the model is marital conflict or discord in the relationship. In elder abuse, important factors are stress due to the nature of the past relationship between the abused person and the care giver.
The third level explores the community context—i.e., schools, workplaces, and neighbourhoods. Risk at this level may be affected by factors such as the existence of a local drug trade, the absence of social networks, and concentrated poverty. All these factors have been shown to be important in several types of violence.
Finally, the fourth level looks at the broad societal factors that help to create a climate in which violence is encouraged or inhibited: the responsiveness of the criminal justice system, social and cultural norms regarding gender roles or parent-child relationships, income inequality, the strength of the social welfare system, the social acceptability of violence, the availability of weapons, the exposure to violence in mass media, and political instability.
Child-rearing.
Cross-cultural studies have shown that greater prevalence of corporal punishment of children tends to predict higher levels of violence in societies. For instance, a 2005 analysis of 186 pre-industrial societies found that corporal punishment was more prevalent in societies which also had higher rates of homicide, assault, and war. In the United States, domestic corporal punishment has been linked to later violent acts against family members and spouses. While studies showing associations between physical punishment of children and later aggression cannot prove that physical punishment causes an increase in aggression, a number of longitudinal studies suggest that the experience of physical punishment has a direct causal effect on later aggressive behaviors. The American family violence researcher Murray A. Straus believes that disciplinary spanking forms "the most prevalent and important form of violence in American families", whose effects contribute to several major societal problems, including later domestic violence and crime.
Psychology.
The causes of violent behaviour in humans are often a topic of research in psychology. Neurobiologist Jan Volavka emphasizes that, for those purposes, "violent behavior is defined as intentional physically aggressive behavior against another person."
Based on the idea of human nature, scientists do agree violence is inherent in humans. Among prehistoric humans, there is archaeological evidence for both contentions of violence and peacefulness as primary characteristics.
Since violence is a matter of perception as well as a measurable phenomenon, psychologists have found variability in whether people perceive certain physical acts as "violent". For example, in a state where execution is a legalized punishment we do not typically perceive the executioner as "violent", though we may talk, in a more metaphorical way, of the state acting violently. Likewise, understandings of violence are linked to a perceived aggressor-victim relationship: hence psychologists have shown that people may not recognise defensive use of force as violent, even in cases where the amount of force used is significantly greater than in the original aggression.
The "violent male ape" image is often brought up in discussions of human violence. Dale Peterson and Richard Wranghamin "Demonic Males: Apes and the Origins of Human Violence" write that violence is inherent in humans, though not inevitable.
However, William L. Ury, editor of a book called "Must We Fight? From the Battlefield to the Schoolyard—A New Perspective on Violent Conflict and Its Prevention" criticizes the "killer ape" myth in his book which brings together discussions from two Harvard Law School symposiums. The conclusion is that "we also have lots of natural mechanisms for cooperation, to keep conflict in check, to channel aggression, and to overcome conflict. These are just as natural to us as the aggressive tendencies."
James Gilligan writes violence is often pursued as an antidote to shame or humiliation. The use of violence often is a source of pride and a defence of honor, especially among males who often believe violence defines manhood.
In an article entitled "The History of Violence" in "The New Republic", Steven Pinker offers evidence that, on average, the amount and cruelty of violence to humans and animals has decreased over the last few centuries.
Pinker's observation of the decline in interpersonal violence echoes the work of Norbert Elias, who attributes the decline to a "civilizing process", in which the state's monopolization of violence, the maintenance of socioeconomic interdependencies or "figurations", and the maintenance of behavioural codes in culture all contribute to the development of individual sensibilities, which increase the repugnance of individuals towards violent acts.
Some scholars disagree with the argument that all violence is decreasing arguing that not all types of violent behaviour are lower now than in the past. They suggest that research typically focuses on lethal violence, often looks at homicide rates of death due to warfare, but ignore the less obvious forms of violence. However, non-lethal violence, such as assaults or bullying appear to be declining as well.
This concept that violence can be normalized, is known as socially sanctioned or structural violence, and is a topic of increasing interest to researchers trying to understand violent behavior. It has been discussed at length by researchers in sociology, medical anthropology, psychology, philosophy, and bioarchaeology.
Evolutionary psychology offers several explanations for human violence in various contexts, such as sexual jealousy in humans, child abuse, and homicide. Goetz (2010) argues that humans are similar to most mammal species and use violence in specific situations. He writes that "Buss and Shackelford (1997a) proposed seven adaptive problems our ancestors recurrently faced that might have been solved by aggression: co-opting the resources of others, defending against attack, inflicting costs on same-sex rivals, negotiating status and hierarchies, deterring rivals from future aggression, deterring mate from infidelity, and reducing resources expended on genetically unrelated children."
Goetz writes that most homicides seem to start from relatively trivial disputes between unrelated men who then escalate to violence and death. He argues that such conflicts occur when there is a status dispute between men of relatively similar status. If there is a great initial status difference, then the lower status individual usually offers no challenge and if challenged the higher status individual usually ignores the lower status individual. At the same an environment of great inequalities between people may cause those at the bottom to use more violence in attempts to gain status.
Media.
Research into the media and violence examines whether links between consuming media violence and subsequent aggressive and violent behaviour exists. Although some scholars had claimed media violence may increase aggression, this view is coming increasingly in doubt both in the scholarly community and was rejected by the US Supreme Court in the Brown v EMA case, as well as in a review of video game violence by the Australian Government (2010) which concluded evidence for harmful effects were inconclusive at best and the rhetoric of some scholars was not matched by good data.
Prevention.
The threat and enforcement of physical punishment has been a tried and tested method of preventing some violence since civilisation began. It is used in various degrees in most countries.
Interpersonal violence.
A review of scientific literature by the World Health Organization on the effectiveness of strategies to prevent interpersonal violence identified the seven strategies below as being supported by either strong or emerging evidence for effectiveness. These strategies target risk factors at all four levels of the ecological model.
Child–caregiver relationships.
Among the most effective such programmes to prevent child maltreatment and reduce childhood aggression are the Nurse Family Partnership home-visiting programme and the Triple P (Parenting Program). There is also emerging evidence that these programmes reduce convictions and violent acts in adolescence and early adulthood, and probably help decrease intimate partner violence and self-directed violence in later life.
Life skills in youth.
Evidence shows that the life skills acquired in social development programmes can reduce involvement in violence, improve social skills, boost educational achievement and improve job prospects. Life skills refer to social, emotional, and behavioural competencies which help children and adolescents effectively deal with the challenges of everyday life.
Gender equality.
Evaluation studies are beginning to support community interventions that aim to prevent violence against women by promoting gender equality. For instance, evidence suggests that programmes that combine microfinance with gender equity training can reduce intimate partner violence. School-based programmes such as Safe Dates programme in the United States of America and the Youth Relationship Project in Canada have been found to be effective for reducing dating violence.
Cultural norms.
Rules or expectations of behaviour – norms – within a cultural or social group can encourage violence. Interventions that challenge cultural and social norms supportive of violence can prevent acts of violence and have been widely used, but the evidence base for their effectiveness is currently weak. The effectiveness of interventions addressing dating violence and sexual abuse among teenagers and young adults by challenging social and cultural norms related to gender is supported by some evidence.
Support programmes.
Interventions to identify victims of interpersonal violence and provide effective care and support are critical for protecting health and breaking cycles of violence from one generation to the next. Examples for which evidence of effectiveness is emerging includes: screening tools to identify victims of intimate partner violence and refer them to appropriate services; psychosocial interventions – such as trauma-focused cognitive behavioural therapy – to reduce mental health problems associated with violence, including post-traumatic stress disorder; and protection orders, which prohibit a perpetrator from contacting the victim, to reduce repeat victimization among victims of intimate partner violence.
Collective violence.
Not surprisingly, scientific evidence about the effectiveness of interventions to prevent collective violence is lacking. However, policies that facilitate reductions in poverty, that make decision-making more accountable, that reduce inequalities between groups, as well as policies that reduce access to biological, chemical, nuclear and other weapons have been recommended. When planning responses to violent conflicts, recommended approaches include assessing at an early stage who is most vulnerable and what their needs are, co-ordination of activities between various players and working towards global, national and local capabilities so as to deliver effective health services during the various stages of an emergency.
Criminal justice.
One of the main functions of law is to regulate violence. Sociologist Max Weber stated that the state claims the monopoly of the legitimate use of force practised within the confines of a specific territory. Law enforcement is the main means of regulating nonmilitary violence in society. Governments regulate the use of violence through legal systems governing individuals and political authorities, including the police and military. Civil societies authorize some amount of violence, exercised through the police power, to maintain the status quo and enforce laws.
However, German political theorist Hannah Arendt noted: "Violence can be justifiable, but it never will be legitimate ... Its justification loses in plausibility the farther its intended end recedes into the future. No one questions the use of violence in self-defence, because the danger is not only clear but also present, and the end justifying the means is immediate". Arendt made a clear distinction between violence and power. Most political theorists regarded violence as an extreme manifestation of power whereas Arendt regarded the two concepts as opposites.
In the 20th century in acts of democide governments may have killed more than 260 million of their own people through police brutality, execution, massacre, slave labour camps, and sometimes through intentional famine.
Violent acts that are not carried out by the military or police and that are not in self-defense are usually classified as crimes, although not all crimes are violent crimes. Damage to property is classified as violent crime in some jurisdictions but not in all. The Federal Bureau of Investigation (FBI) classifies violence resulting in homicide into criminal homicide and justifiable homicide (e.g. self-defense).
The criminal justice approach sees its main task as enforcing laws that proscribe violence and ensuring that "justice is done". The notions of individual blame, responsibility, guilt, and culpability are central to criminal justice's approach to violence and one of the criminal justice system's main tasks is to "do justice", i.e. to ensure that offenders are properly identified, that the degree of their guilt is as accurately ascertained as possible, and that they are punished appropriately. To prevent and respond to violence, the criminal justice approach relies primarily on deterrence, incarceration and the punishment and rehabilitation of perpetrators.
The criminal justice approach, beyond justice and punishment, has traditionally emphasized indicated interventions, aimed at those who have already been involved in violence, either as victims or as perpetrators. One of the main reasons offenders are arrested, prosecuted, and convicted is to prevent further crimes – through deterrence (threatening potential offenders with criminal sanctions if they commit crimes), incapacitation (physically preventing offenders from committing further crimes by locking them up) and through rehabilitation (using time spent under state supervision to develop skills or change one's psychological make-up to reduce the likelihood of future offences).
In recent decades in many countries in the world, the criminal justice system has taken an increasing interest in preventing violence before it occurs. For instance, much of community and problem-oriented policing aims to reduce crime and violence by altering the conditions that foster it - and not to increase the number of arrests. Indeed, some police leaders have gone so far as to say the police should primarily be a crime prevention agency. Juvenile justice systems – an important component of criminal justice systems – are largely based on the belief in rehabilitation and prevention. In the US, the criminal justice system has, for instance, funded school- and community-based initiatives to reduce children's access to guns and teach conflict resolution. In 1974, the US Department of Justice assumed primary responsibility for delinquency prevention programmes and created the Office of Juvenile Justice and Delinquency Prevention, which has supported the "Blueprints for violence prevention" programme at the University of Colorado Boulder.
Public health.
The public health approach is a science-driven, population-based, interdisciplinary, intersectoral approach based on the ecological model which emphasizes primary prevention. Rather than focusing on individuals, the public health approach aims to provide the maximum benefit for the largest number of people, and to extend better care and safety to entire populations. The public health approach is interdisciplinary, drawing upon knowledge from many disciplines including medicine, epidemiology, sociology, psychology, criminology, education and economics. Because all forms of violence are multi-faceted problems, the public health approach emphasizes a multi-sectoral response. It has been proved time and again that cooperative efforts from such diverse sectors as health, education, social welfare, and criminal justice are often necessary to solve what are usually assumed to be purely "criminal" or "medical" problems. The public health approach considers that violence, rather than being the result of any single factor, is the outcome of multiple risk factors and causes, interacting at four levels of a nested hierarchy (individual, close relationship/family, community and wider society) of the Social ecological model.
From a public health perspective, prevention strategies can be classified into three types:
A public health approach emphasizes the primary prevention of violence, i.e. stopping them from occurring in the first place. Until recently, this approach has been relatively neglected in the field, with the majority of resources directed towards secondary or tertiary prevention. Perhaps the most critical element of a public health approach to prevention is the ability to identify underlying causes rather than focusing upon more visible "symptoms". This allows for the development and testing of effective approaches to address the underlying causes and so improve health.
The public health approach is an evidence-based and systematic process involving the following four steps:
In many countries, violence prevention is still a new or emerging field in public health. The public health community has started only recently to realize the contributions it can make to reducing violence and mitigating its consequences. In 1949, Gordon called for injury prevention efforts to be based on the understanding of causes, in a similar way to prevention efforts for communicable and other diseases. In 1962, Gomez, referring to the WHO definition of health, stated that it is obvious that violence does not contribute to "extending life" or to a "complete state of well-being". He defined violence as an issue that public health experts needed to address and stated that it should not be the primary domain of lawyers, military personnel, or politicians.
However, it is only in the last 30 years that public health has begun to address violence, and only in the last fifteen has it done so at the global level. This is a much shorter period of time than public health has been tackling other health problems of comparable magnitude and with similarly severe lifelong consequences.
The global public health response to interpersonal violence began in earnest in the mid-1990s. In 1996, the World Health Assembly adopted Resolution WHA49.25 which declared violence "a leading worldwide public health problem" and requested that the World Health Organization (WHO) initiate public health activities to (1) document and characterize the burden of violence, (2) assess the effectiveness of programmes, with particular attention to women and children and community-based initiatives, and (3) promote activities to tackle the problem at the international and national levels. The World Health Organization's initial response to this resolution was to create the Department of Violence and Injury Prevention and Disability and to publish the World report on violence and health (2002).
The case for the public health sector addressing interpersonal violence rests on four main arguments. First, the significant amount of time health care professionals dedicate to caring for victims and perpetrators of violence has made them familiar with the problem and has led many, particularly in emergency departments, to mobilize to address it. The information, resources, and infrastructures the health care sector has at its disposal are an important asset for research and prevention work. Second, the magnitude of the problem and its potentially severe lifelong consequences and high costs to individuals and wider society call for population-level interventions typical of the public health approach. Third, the criminal justice approach, the other main approach to addressing violence (link to entry above), has traditionally been more geared towards violence that occurs between male youths and adults in the street and other public places – which makes up the bulk of homicides in most countries – than towards violence occurring in private settings such as child maltreatment, intimate partner violence and elder abuse – which makes up the largest share of non-fatal violence. Fourth, evidence is beginning to accumulate that a science-based public health approach is effective at preventing interpersonal violence.
Human rights.
The human rights approach is based on the obligations of states to respect, protect and fulfill human rights and therefore to prevent, eradicate and punish violence. It recognizes violence as a violation of many human rights: the rights to life, liberty, autonomy and security of the person; the rights to equality and non-discrimination; the rights to be free from torture and cruel, inhuman and degrading treatment or punishment; the right to privacy; and the right to the highest attainable standard of health. These human rights are enshrined in international and regional treaties and national constitutions and laws, which stipulate the obligations of states, and include mechanisms to hold states accountable. The Convention on the Elimination of All Forms of Discrimination Against Women, for example, requires that countries party to the Convention take all appropriate steps to end violence against women. The Convention on the Rights of the Child in its Article 19 states that States Parties shall take all appropriate legislative, administrative, social and educational measures to protect the child from all forms of physical or mental violence, injury or abuse, neglect or negligent treatment, maltreatment or exploitation, including sexual abuse, while in the care of parent(s), legal guardian(s) or any other person who has the care of the child.
Geographical context.
Violence, as defined in the dictionary of human geography, "appears whenever power is in jeopardy" and "in and of itself stands emptied of strength and purpose: it is part of a larger matrix of socio-political power struggles". Violence can be broadly divided into three broad categories – direct violence, structural violence and cultural violence. Thus defined and delineated, it is of note, as Hyndman says, that "geography came late to theorizing violence" in comparison to other social sciences. Social and human geography, rooted in the humanist, Marxist, and feminist subfields that emerged following the early positivist approaches and subsequent behavioral turn, have long been concerned with social and spatial justice.
Along with critical geographers and political geographers, it is these groupings of geographers that most often interact with violence. Keeping this idea of social/spatial justice via geography in mind, it is worthwhile to look at geographical approaches to violence in the context of politics.
Derek Gregory and Alan Pred assembled the influential edited collection "Violent Geographies: Fear, Terror, and Political Violence", which demonstrates how place, space, and landscape are foremost factors in the real and imagined practices of organized violence both historically and in the present. Evidently, political violence often gives a part for the state to play. When "modern states not only claim a monopoly of the legitimate means of violence; they also routinely use the threat of violence to enforce the rule of law", the law not only becomes a form of violence but is violence. Philosopher Giorgio Agamben's concepts of state of exception and "homo sacer" are useful to consider within a geography of violence. The state, in the grip of a perceived, potential crisis (whether legitimate or not) takes preventative legal measures, such as a suspension of rights (it is in this climate, as Agamben demonstrates, that the formation of the Social Democratic and Nazi government's lager or concentration camp can occur). However, when this "in limbo" reality is designed to be in place "until further notice…the state of exception thus ceases to be referred to as an external and provisional state of factual danger and comes to be confused with juridical rule itself". For Agamben, the physical space of the camp "is a piece of land placed outside the normal juridical order, but it is nevertheless not simply an external space". At the scale of the body, in the state of exception, a person is so removed from their rights by "juridical procedures and deployments of power" that "no act committed against them could appear any longer as a crime"; in other words, people become only "homo sacer". Guantanamo Bay could also be said to represent the physicality of the state of exception in space, and can just as easily draw man as homo sacer.
In the 1970s, genocides in Cambodia under the Khmer Rouge and Pol Pot resulted in the deaths of over two million Cambodians (which was 25% of the Cambodian population), forming one of the many contemporary examples of state-sponsored violence. About fourteen thousand of these murders occurred at Choeung Ek, which is the best-known of the extermination camps referred to as the Killing Fields. The killings were arbitrary; for example, a person could be killed for wearing glasses, since that was seen as associating them with intellectuals and therefore as making them part of the enemy. People were murdered with impunity because it was no crime; Cambodians were made "homo sacer" in a condition of bare life. The Killing Fields—manifestations of Agamben's concept of camps beyond the normal rule of law—featured the state of exception. As part of Pol Pot's "ideological intent…to create a purely agrarian society or cooperative", he "dismantled the country's existing economic infrastructure and depopulated every urban area". Forced movement, such as this forced movement applied by Pol Pot, is a clear display of structural violence. When "symbols of Cambodian society were equally disrupted, social institutions of every kind…were purged or torn down", cultural violence (defined as when "any aspect of culture such as language, religion, ideology, art, or cosmology is used to legitimize direct or structural violence") is added to the structural violence of forced movement and to the direct violence, such as murder, at the Killing Fields. Vietnam eventually intervened and the genocide officially ended. However, ten million landmines left by opposing guerillas in the 1970s continue to create a violent landscape in Cambodia.
Human geography, though coming late to the theorizing table, has tackled violence through many lenses, including anarchist geography, feminist geography, Marxist geography, political geography, and critical geography. However, Adriana Cavarero notes that, "as violence spreads and assumes unheard-of forms, it becomes difficult to name in contemporary language". Cavarero proposes that, in facing such a truth, it is prudent to reconsider violence as "horrorism"; that is, "as though ideally all the…victims, instead of their killers, ought to determine the name". With geography often adding the forgotten spatial aspect to theories of social science, rather than creating them solely within the discipline, it seems that the self-reflexive contemporary geography of today may have an extremely important place in this current (re)imaging of violence, exemplified by Cavarero.
Epidemiology.
As of 2010, all forms of violence resulted in about 1.34 million deaths up from about 1 million in 1990. Suicide accounts for about 883,000, interpersonal violence for 456,000 and collective violence for 18,000. Deaths due to collective violence have decreased from 64,000 in 1990.
By way of comparison, the 1.5 millions deaths a year due to violence is greater than the number of deaths due to tuberculosis (1.34 million), road traffic injuries (1.21 million), and malaria (830'000), but slightly less than the number of people who die from HIV/AIDS (1.77 million).
For every death due to violence, there are numerous nonfatal injuries. In 2008, over 16 million cases of non-fatal violence-related injuries were severe enough to require medical attention. Beyond deaths and injuries, forms of violence such as child maltreatment, intimate partner violence, and elder maltreatment have been found to be highly prevalent.
Self-directed violence.
In the last 45 years, suicide rates have increased by 60% worldwide. Suicide is among the three leading causes of death among those aged 15–44 years in some countries, and the second leading cause of death in the 10–24 years age group. These figures do not include suicide attempts which are up to 20 times more frequent than completed suicide. Suicide was the 16th leading cause of death worldwide in 2004 and is projected to increase to the 12th in 2030. Although suicide rates have traditionally been highest among the male elderly, rates among young people have been increasing to such an extent that they are now the group at highest risk in a third of countries, in both developed and developing countries.
Interpersonal violence.
Rates and patterns of violent death vary by country and region. In recent years, homicide rates have been highest in developing countries in Sub-Saharan Africa and Latin America and the Caribbean and lowest in East Asia, the western Pacific, and some countries in northern Africa. Studies show a strong, inverse relationship between homicide rates and both economic development and economic equality. Poorer countries, especially those with large gaps between the rich and the poor, tend to have higher rates of homicide than wealthier countries. Homicide rates differ markedly by age and sex. Gender differences are least marked for children. For the 15 to 29 age group, male rates were nearly six times those for female rates; for the remaining age groups, male rates were from two to four times those for females.
Studies in a number of countries show that, for every homicide among young people age 10 to 24, 20 to 40 other young people receive hospital treatment for a violent injury.
Forms of violence such as child maltreatment and intimate partner violence are highly prevalent. Approximately 20% of women and 5–10% of men report being sexually abused as children, while 25–50% of all children report being physically abused. A WHO multi-country study found that between 15–71% of women reported experiencing physical and/or sexual violence by an intimate partner at some point in their lives.
Collective violence.
Wars grab headlines, but the individual risk of dying violently in an armed conflict is today relatively low—much lower than the risk of violent death in many countries that are not suffering from an armed conflict. For example, between 1976 and 2008, African Americans were victims of 329,825 homicides. Although there is a widespread perception that war is the most dangerous form of armed violence in the world, the average person living in a conflict-affected country had a risk of dying violently in the conflict of about 2.0 per 100,000 population between 2004 and 2007. This can be compared to the average world homicide rate of 7.6 per 100,000 people. This illustration highlights the value of accounting for all forms of armed violence rather than an exclusive focus on conflict related violence. Certainly, there are huge variations in the risk of dying from armed conflict at the national and subnational level, and the risk of dying violently in a conflict in specific countries remains extremely high. In Iraq, for example, the direct conflict death rate for 2004–07 was 65 per 100,000 people per year and, in Somalia, 24 per 100,000 people. This rate even reached peaks of 91 per 100,000 in Iraq in 2006 and 74 per 100,000 in Somalia in 2007.
History.
Organized, large-scale, militaristic, or regular human-on-human violence was absent for the vast majority of the human timeline, and is first documented to have started only relatively recently in the Holocene, an epoch that began about 11,700 years ago, probably with the advent of higher population densities due to sedentism. Social anthropologist Douglas P. Fry writes that scholars are divided on the origins of this greater degree of violence—in other words, war-like behavior: 
Jared Diamond in his books "Guns, Germs and Steel" and "The Third Chimpanzee" posits that the rise of large-scale warfare is the result of advances in technology and city-states. For instance, the rise of agriculture provided a significant increase in the number of individuals that a region could sustain over hunter-gatherer societies, allowing for development of specialized classes such as soldiers, or weapons manufacturers.
In academia, the idea of the peaceful pre-history and non-violent tribal societies gained popularity with the post-colonial perspective. The trend, starting in archaeology and spreading to anthropology reached its height in the late half of the 20th century. However, some newer research in archaeology and bioarchaeology may provide evidence that violence within and among groups is not a recent phenomenon. According to the book "The Bioarchaeology of Violence" violence is a behavior that is found throughout human history.
Lawrence H. Keeley at the University of Illinois writes in "War Before Civilization" that 87% of tribal societies were at war more than once per year, and that 65% of them were fighting continuously. He writes that the attrition rate of numerous close-quarter clashes, which characterize endemic warfare, produces casualty rates of up to 60%, compared to 1% of the combatants as is typical in modern warfare. "Primitive Warfare" of these small groups or tribes was driven by the basic need for sustenance and violent competition.
Fry explores Keeley's argument in depth and counters that such sources erroneously focus on the ethnography of hunters and gatherers in the present, whose culture and values have been infiltrated externally by modern civilization, rather than the actual archaeological record spanning some two million years of human existence. Fry determines that all present ethnographically studied tribal societies, "by the very fact of having been described and published by anthropologists, have been irrevocably impacted by history and modern colonial nation states" and that "many have been affected by state societies for at least 5000 years."
"The Better Angels of Our Nature".
Steven Pinker's 2011 book, "The Better Angels of Our Nature", roused both acclaim and controversy by asserting that modern society is less violent than in periods of the past, whether on the short scale of decades or long scale of centuries or millennia.
Steven Pinker argues that by every possible measure, every type of violence has drastically decreased since ancient and medieval times. A few centuries ago, for example, genocide was a standard practice in all kinds of warfare and was so common that historians did not even bother to mention it. According to Pinker, rape, murder, warfare and animal cruelty have all seen drastic declines in the 20th century. However, Pinker's analyses have met with much criticism; for example, Pinker himself, on his FAQ page, states that he does not include catastrophic ecological violence (including violence against wild or domesticated non-human animals or plants, or against ecosystems) or the violence of economic inequality and of coercive working conditions in his definition; he controversially regards these forms of violence as "metaphorical". Some critics have therefore argued that Pinker suffers from "a reductive vision of what it means to be violent."
Society and culture.
Beyond deaths and injuries, highly prevalent forms of violence (such as child maltreatment and intimate partner violence) have serious lifelong non-injury health consequences. Victims may engage in high-risk behaviours such as alcohol and substance misuse, smoking, and unsafe sex, which in turn can contribute to cardiovascular disorders, cancers, depression, diabetes and HIV/AIDS, resulting in premature death Violence may beget violence. The balances of prevention, mitigation, mediation and exacerbation are complex, and vary with the underpinnings of violence.
Economic effects.
In countries with high levels of violence, economic growth can be slowed down, personal and collective security eroded, and social development impeded. Families edging out of poverty and investing in schooling their sons and daughters can be ruined through the violent death or severe disability of the main breadwinner. Communities can be caught in poverty traps where pervasive violence and deprivation form a vicious circle that stifles economic growth. For societies, meeting the direct costs of health, criminal justice, and social welfare responses to violence diverts many billions of dollars from more constructive societal spending. The much larger indirect costs of violence due to lost productivity and lost investment in education work together to slow economic development, increase socioeconomic inequality, and erode human and social capital.
Additionally, communities with high level of violence do not provide the level of stability and predictability vital for a prospering business economy. Individuals will be less likely to invest money and effort towards growth in such unstable and violent conditions.
Religion.
Religious and political ideologies have been the cause of interpersonal violence throughout history. Ideologues often falsely accuse others of violence, such as the ancient blood libel against Jews, the medieval accusations of casting witchcraft spells against women, and modern accusations of satanic ritual abuse against day care center owners and others.
Both supporters and opponents of the 21st century War on Terrorism regard it largely as an ideological and religious war.
Vittorio Bufacchi describes two different modern concepts of violence, one the "minimalist conception" of violence as an intentional act of excessive or destructive force, the other the "comprehensive conception" which includes violations of rights, including a long list of human needs.
Anti-capitalists assert that capitalism is violent. They believe private property, trade, interest and profit survive only because police violence defends them and that capitalist economies need war to expand. They may use the term "structural violence" to describe the systematic ways in which a given social structure or institution kills people slowly by preventing them from meeting their basic needs, for example the deaths caused by diseases because of lack of medicine.
Frantz Fanon critiqued the violence of colonialism and wrote about the counter violence of the "colonized victims."
Throughout history, most religions and individuals like Mahatma Gandhi have preached that humans are capable of eliminating individual violence and organizing societies through purely nonviolent means. Gandhi himself once wrote: "A society organized and run on the basis of complete non-violence would be the purest anarchy." Modern political ideologies which espouse similar views include pacifist varieties of voluntarism, mutualism, anarchism and libertarianism.
Terence Fretheim writing about the Old Testament:
For many people, ... only physical violence truly qualifies as violence. But, certainly, violence is more than killing people, unless one includes all those words and actions that kill people slowly. The effect of limitation to a “killing fields” perspective is the widespread neglect of many other forms of violence. We must insist that violence also refers to that which is psychologically destructive, that which demeans, damages, or depersonalizes others. In view of these considerations, violence may be defined as follows: any action, verbal or nonverbal, oral or written, physical or psychical, active or passive, public or private, individual or institutional/societal, human or divine, in whatever degree of intensity, that abuses, violates, injures, or kills. Some of the most pervasive and most dangerous forms of violence are those that are often hidden from view (against women and children, especially); just beneath the surface in many of our homes, churches, and communities is abuse enough to freeze the
blood. Moreover, many forms of systemic violence often slip past our attention because they are so much a part of the infrastructure of life (e.g., racism, sexism, ageism).

</doc>
<doc id="46117" url="https://en.wikipedia.org/wiki?curid=46117" title="Eratosthenes">
Eratosthenes

Eratosthenes of Cyrene (; , ;  – ) was a Greek mathematician, geographer, poet, astronomer, and music theorist. He was a man of learning, becoming the chief librarian at the Library of Alexandria. He invented the discipline of geography, including the terminology used today.
He is best known for being the first person to calculate the circumference of the Earth, which he did by applying a measuring system using stadia, which was a standard unit of measure during that time period. His calculation was remarkably accurate. He was also the first to calculate the tilt of the Earth's axis (again with remarkable accuracy). Additionally, he may have accurately calculated the distance from the Earth to the Sun and invented the leap day. He created the first map of the world incorporating parallels and meridians, based on the available geographical knowledge of the era.
Eratosthenes was the founder of scientific chronology; he endeavored to revise the dates of the chief literary and political events from the conquest of Troy. In number theory, he introduced the sieve of Eratosthenes, an efficient method of identifying prime numbers.
He was a figure of influence who declined to specialize in only one field. According to an entry in the Suda (a 10th-century reference), his critics scorned him, calling him "Beta", from the second letter of the Greek alphabet, because he always came in second in all his endeavors. Nonetheless, his devotees nicknamed him "Pentathlos", after the Olympians who were well rounded competitors, for he had proven himself to be knowledgeable in every area of learning. Eratosthenes yearned to understand the complexities of the entire world.
Life.
The son of Aglaos, Eratosthenes was born in 276 BC, in Cyrene. Now part of modern-day Libya, Cyrene had been founded by the Greeks centuries earlier, and became the capital of Pentapolis (North Africa), a country of five cities: Cyrene, Arsinde, Berenice, Ptolemias, and Apollonia, Cyrenaica. Alexander the Great conquered Cyrene in 332 BC, and following his death in 323 BC its rule was given to one of his generals, Ptolemy I Soter, the founder of the Ptolemaic Kingdom. Under Ptolemaic rule the economy prospered, based largely on the export of horses and silphium, a plant used for rich seasoning and medicine. Cyrene became a place of cultivation, where knowledge blossomed. Like any young Greek, Eratosthenes would have studied in the local gymnasium, where he would have learned physical skills and social discourse as well as reading, writing, arithmetic, poetry, and music.
Eratosthenes went to Athens to further his studies. There he was taught Stoicism by its founder, Zeno of Citium, in philosophical lectures on living a virtuous life. He then studied under Ariston of Chios, who led a more cynical school of philosophy. He also studied under the head of the Platonic Academy, who was Arcesilaus of Pitane. His interest in Plato led him to write his very first work at a scholarly level, "Platonikos", inquiring into the mathematical foundation of Plato's philosophies. Eratosthenes was a man of many perspectives and investigated the art of poetry under Callimachus. He had talent as a most imaginative poet. He wrote poems: one in hexameters called "Hermes" illustrating the god's life history; and another, in elegiacs, called "Erigone", describing the suicide of the Athenian maiden Erigone (daughter of Icarius). He wrote "Chronographies", a text that scientifically depicted dates of importance, beginning with the Trojan War. This work was highly esteemed for its accuracy: George Syncellus was later able to preserve from "Chronographies" a list of 38 kings of the Egyptian Thebes. Eratosthenes also wrote "Olympic Victors", a chronology of the winners of the Olympic Games. It is not known when he wrote his works, but they highlighted his abilities.
These works and his great poetic abilities led the pharaoh Ptolemy III Euergetes to seek to place him as a librarian at the Library of Alexandria in the year 245 BC. Eratosthenes, then thirty years old, accepted Ptolemy's invitation and traveled to Alexandria, where he lived for the rest of his life. Within about five years he became Chief Librarian, a position that the poet Apollonius Rhodius had previously held. As head of the library Eratosthenes tutored the children of Ptolemy, including Ptolemy IV Philopator who became the fourth Ptolemaic pharaoh. He expanded the library's holdings: in Alexandria all books had to be surrendered for duplication. It was said that these were copied so accurately that it was impossible to tell if the library had returned the original or the copy.
He sought to maintain the reputation of the Library of Alexandria against competition from the Pergamum. Eratosthenes created a whole section devoted to the examination of Homer, and acquired original works of great tragic dramas of Aeschylus, Sophocles and Euripides.
Eratosthenes made several important contributions to mathematics and science, and was a friend of Archimedes. Around 255 BC, he invented the armillary sphere. In "On the Circular Motions of the Celestial Bodies", Cleomedes credited him with having calculated the Earth's circumference around 240 BC, using knowledge of the angle of elevation of the Sun at noon on the summer solstice in Alexandria and on Elephantine Island near Syene (modern Aswan, Egypt).
Eratosthenes believed there was good and bad in every nation and criticized Aristotle for arguing that humanity was divided into Greeks and barbarians, and that the Greeks should keep themselves racially pure. As he aged he contracted ophthalmia, becoming blind around 195 BC. Losing the ability to read and to observe nature plagued and depressed him, leading him to voluntarily starve himself to death. He died in 194 BC at the age of 82 in his beloved Alexandria.
Measurement of the Earth's circumference.
Eratosthenes calculated the circumference of the Earth without leaving Egypt. He knew that at local noon on the summer solstice in Syene (modern Aswan, Egypt), the Sun was directly overhead. He knew this because the shadow of someone looking down a deep well at that time in Syene blocked the reflection of the Sun on the water. He measured the Sun's angle of elevation at noon on the same day in Alexandria. The method of measurement was to make a scale drawing of that triangle which included a right angle between a vertical rod and its shadow. This turned out to be 1/50th of a circle. Taking the Earth as spherical, and knowing both the distance and direction of Syene, he concluded that the Earth's circumference was fifty times that distance.
His knowledge of the size of Egypt was founded on the work of many generations of surveying trips. Pharaonic bookkeepers gave a distance between Syene and Alexandria of 5,000 stadia (a figure that was checked yearly). Some say that the distance was corroborated by inquiring about the time that it took to travel from Syene to Alexandria by camel. Carl Sagan says that Eratosthenes paid a man to walk and measure the distance. Some claim Eratosthenes used the Olympic stade of 176.4 m, which would imply a circumference of 44,100 km, an error of 10%, but the 184.8 m Italian stade became (300 years later) the most commonly accepted value for the length of the stade, which implies a circumference of 46,100 km, an error of 15%. It was unlikely, even accounting for his extremely primitive measuring tools, that Eratosthenes could have calculated an accurate measurement for the circumference of the Earth for three important assumptions he made (none of which are perfectly accurate):
Eratosthenes later rounded the result to a final value of 700 stadia per degree, which implies a circumference of 252,000 stadia, likely for reasons of calculation simplicity as the larger number is evenly divisible by 60. Repeating Eratosthenes' calculation with more accurate data, the result is 40,074 km, which is 66 km different (0.16 %) from the currently accepted polar circumference of the Earth.
Seventeen hundred years after Eratosthenes' death, while Christopher Columbus studied what Eratosthenes had written about the size of the Earth, he chose to believe, based on a map by Toscanelli, that the Earth's circumference was one-third smaller. Had Columbus set sail knowing that Eratosthenes' larger circumference value was more accurate, he would have known that the place that he made landfall was not Asia, but rather a New World.
"Father of geography".
Eratosthenes continued from his knowledge about the Earth, his discoveries of its size and shape, and began to sketch it. In the Library of Alexandria he had access to various travel books, which contained various items of information and representations of the world that needed to be pieced together in some organized format. In his three-volume work "Geography" (), he described and mapped his entire known world, even dividing the Earth into five climate zones: two freezing zones around the pole, two temperate zones, and a zone encompassing the equator and the tropics. He had invented geography. He created terminology that is still used today. He placed grids of overlapping lines over the surface of the Earth. He used parallels and meridians to link together every place in the world. It was now possible to estimate one's distance from remote locations with this network over the surface of the Earth. In the "Geography" the names of over 400 cities and their locations were shown: this had never been achieved before. Unfortunately, his "Geography" has been lost to history, but fragments of the work can be pieced together from other great historians like Pliny, Polybius, Strabo, and Marcianus.
Other achievements.
Eratosthenes was described by the Suda Lexicon as a Πένταθλος (Pentathlos) which can be translated as "All-Rounder", for he was skilled in a variety of things: He was a true polymath. He was nicknamed Beta because he was great at many things and tried to get his hands on every bit of information but never achieved the highest rank in anything; Strabo accounts Eratosthenes as a mathematician among geographers and a geographer among mathematicians.
Prime numbers.
Eratosthenes proposed a simple algorithm for finding prime numbers. This algorithm is known in mathematics as the Sieve of Eratosthenes.
In mathematics, the sieve of Eratosthenes (Greek: κόσκινον Ἐρατοσθένους), one of a number of prime number sieves, is a simple, ancient algorithm for finding all prime numbers up to any given limit. It does so by iteratively marking as composite, "i.e.", not prime, the multiples of each prime, starting with the multiples of 2. The multiples of a given prime are generated starting from that prime, as a sequence of numbers with the same difference, equal to that prime, between consecutive numbers. This is the sieve's key distinction from using trial division to sequentially test each candidate number for divisibility by each prime.
Works.
Eratosthenes was one of the most pre-eminent scholarly figures of his time, and produced works covering a vast area of knowledge before and during his time at the Library. He wrote on many topics — geography, mathematics, philosophy, chronology, literary criticism, grammar, poetry, and even old comedies. Unfortunately, there are only fragments left of his works after the Destruction of the Library of Alexandria.

</doc>
<doc id="46118" url="https://en.wikipedia.org/wiki?curid=46118" title="Iona Nikitchenko">
Iona Nikitchenko

Major-General Iona Timofeevich Nikitchenko (Russian: Иона Тимофеевич Никитченко) (June 28, 1895, Don Voisko Oblast, Russian Empire – April 22, 1967, Moscow, Russian SFSR) was a judge of the Supreme Court of the Soviet Union.
Iona was born to a peasant family in khutor Tuzlukov (now Rostov Oblast). He studied at his local Agricultural Institute and from 1916 was a Bolshevik. His court experience started in May 1920 when he was appointed as the chairman-deputy of the Military Court of Semirechye Army Group during the Civil War. During the Civil War he participated on the frontlines in the Middle Asia. In 1924 was appointed as the member of the Military Court Collegiate of the Moscow Military District.
Nikitchenko presided over some of the most notorious of Joseph Stalin's show trials during the Great Purges of 1936 to 1938, where he among other things sentenced Kamenev and Zinoviev.
Nuremberg trials.
Nikitchenko was one of the three main drafters of the London Charter. He was also the Soviet Union's judge at the Nuremberg trials, and was President for the session at Berlin. Nikitchenko's prejudices were evident from the outset. Before the Tribunal convened, Nikitchenko explained the Soviet perspective of the trials:"We are dealing here with the chief war criminals who have already been convicted and whose conviction has been already announced by both the Moscow and Crimea declarations by the heads of the [Allied governments... The whole idea is to secure quick and just punishment for the crime."
His statements in this respect call to mind the statements of US Supreme Court Chief Justice Harlan Fiske Stone who wrote "Chief US prosecutor Jackson is away conducting his high-grade lynching party in Nuremberg, I don't mind what he does to the Nazis, but I hate to see the pretense that he is running a court and proceeding according to common law. This is a little too sanctimonious a fraud to meet my old-fashioned ideas." Nikitchenko was thus far from alone in viewing the Nuremberg trials as a farcical cloaking in law of the process of putting to death a large number of notorious villains.
Nikitchenko dissented against the acquittals of Hjalmar Schacht, Franz von Papen and Hans Fritzsche, and argued for a death sentence for Rudolf Hess. Nikitchenko said, in the lead-up to the trials, "If... the judge is supposed to be impartial, it would only lead to unnecessary delays." Hess, formerly Hitler's deputy fuhrer, the man charged by Hitler with implementing Nazi Germany's Nuremberg Laws, the man who signed the decree establishing the notorious German occupation government of Poland, and since May 1941 in a British prison, was sentenced to life in prison by the tribunal. In this respect, he was by far the most senior surviving Nazi official to escape a death sentence. Nikitchenko also found the majority judgments incorrect with regard to the Reich Cabinet, the German General Staff and the Oberkommando der Wehrmacht. Having never before written a dissenting opinion - these being unheard of in Soviet jurisprudence - and being unsure of the form of such an opinion, Nikitchenko was assisted in writing his dissents by his fellow judge Norman Birkett.
Nikitchenko feared a compromise on too lenient a level. At the point of final deliberation he reexamined Hess' case and voted for a life sentence so that the opportunity for Hess to get away with a lesser degree of punishment did not occur.

</doc>
<doc id="46120" url="https://en.wikipedia.org/wiki?curid=46120" title="Range encoding">
Range encoding

Range encoding is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976. Given a stream of symbols and their probabilities, a range coder produces a space efficient stream of bits to represent these symbols and, given the stream and the probabilities, a range decoder reverses the process.
Range coding is very similar to arithmetic encoding, except that encoding is done with digits in any base, instead of with bits, and so it is faster when using larger bases (e.g. a byte) at small cost in compression efficiency. After the expiration of the first (1978) arithmetic coding patent, range encoding appeared to clearly be free of patent encumbrances. This particularly drove interest in the technique in the open source community. Since that time, patents on various well-known arithmetic coding techniques have also expired.
How range encoding works.
Range encoding conceptually encodes all the symbols of the message into one number, unlike Huffman coding which assigns each symbol a bit-pattern and concatenates all the bit-patterns together. Thus range encoding can achieve greater compression ratios than the one-bit-per-symbol lower bound on Huffman encoding and it does not suffer the inefficiencies that Huffman does when dealing with probabilities that are not exact powers of two.
The central concept behind range encoding is this: given a large-enough range of integers, and a probability estimation for the symbols, the initial range can easily be divided into sub-ranges whose sizes are proportional to the probability of the symbol they represent. Each symbol of the message can then be encoded in turn, by reducing the current range down to just that sub-range which corresponds to the next symbol to be encoded. The decoder must have the same probability estimation the encoder used, which can either be sent in advance, derived from already transferred data or be part of the compressor and decompressor.
When all symbols have been encoded, merely identifying the sub-range is enough to communicate the entire message (presuming of course that the decoder is somehow notified when it has extracted the entire message). A single integer is actually sufficient to identify the sub-range, and it may not even be necessary to transmit the entire integer; if there is a sequence of digits such that every integer beginning with that prefix falls within the sub-range, then the prefix alone is all that's needed to identify the sub-range and thus transmit the message.
Example.
Suppose we want to encode the message "AABA<EOM>", where <EOM> is the end-of-message symbol. For this example it is assumed that the decoder knows that we intend to encode exactly five symbols in the base 10 number system (allowing for 105 different combinations of symbols with the range [0, 100000)) using the probability distribution {A: .60; B: .20; <EOM>: .20}. The encoder breaks down the range [0, 100000) into three subranges:
Since our first symbol is an A, it reduces our initial range down to [0, 60000). The second symbol choice leaves us with three sub-ranges of this range, we show them following the already-encoded 'A':
With two symbols encoded, our range is now [0, 36000) and our third symbol leads to the following choices:
This time it is the second of our three choices that represent the message we want to encode, and our range becomes [21600, 28800). It may look harder to determine our sub-ranges in this case, but it is actually not: we can merely subtract the lower bound from the upper bound to determine that there are 7200 numbers in our range; that the first 4320 of them represent 0.60 of the total, the next 1440 represent the next 0.20, and the remaining 1440 represent the remaining 0.20 of the total. Adding back the lower bound gives us our ranges:
Finally, with our range narrowed down to [21600, 25920), we have just one more symbol to encode. Using the same technique as before for dividing up the range between the lower and upper bound, we find the three sub-ranges are:
And since <EOM> is our final symbol, our final range is [25056, 25920). Because all five-digit integers starting with "251" fall within our final range, it is one of the three-digit prefixes we could transmit that would unambiguously convey our original message. (The fact that there are actually eight such prefixes in all implies we still have inefficiencies. They have been introduced by our use of base 10 rather than base 2.)
The central problem may appear to be selecting an initial range large enough that no matter how many symbols we have to encode, we will always have a current range large enough to divide into non-zero sub-ranges. In practice, however, this is not a problem, because instead of starting with a very large range and gradually narrowing it down, the encoder works with a smaller range of numbers at any given time. After some number of digits have been encoded, the leftmost digits will not change. In the example after encoding just three symbols, we already knew that our final result would start with "2". More digits are shifted in on the right as digits on the left are sent off. This is illustrated in the following code:
To finish off we may need to emit a few extra digits. The top digit of codice_1 is probably too small so we need to increment it, but we have to make sure we don't increment it past codice_2. So first we need to make sure codice_3 is large enough.
One problem that can occur with the codice_4 function above is that codice_3 might become very small but codice_1 and codice_2 still have differing first digits. This could result in the interval having insufficient precision to distinguish between all of the symbols in the alphabet. When this happens we need to fudge a little, output the first couple of digits even though we might be off by one, and re-adjust the range to give us as much room as possible. The decoder will be following the same steps so it will know when it needs to do this to keep in sync.
Base 10 was used in this example, but a real implementation would just use binary, with the full range of the native integer data type. Instead of codice_8 and codice_9 you would likely use hexadecimal constants such as codice_10 and codice_11. Instead of emitting a digit at a time you would emit a byte at a time and use a byte-shift operation instead of multiplying by 10.
Decoding uses exactly the same algorithm with the addition of keeping track of the current codice_12 value consisting of the digits read from the compressor. Instead of emitting the top digit of codice_1 you just throw it away, but you also shift out the top digit of codice_12 and shift in a new digit read from the compressor. Use codice_15 below instead of codice_16.
In order to determine which probability intervals to apply, the decoder needs to look at the current value of codice_12 within the interval [low, low+range) and decide which symbol this represents.
For the AABA<EOM> example above, this would return a value in the range 0 to 9. Values 0 through 5 would represent A, 6 and 7 would represent B, and 8 and 9 would represent <EOM>.
Relationship with arithmetic coding.
Arithmetic coding is the same as range encoding, but with the integers taken as being the numerators of fractions. These fractions have an implicit, common denominator, such that all the fractions fall in the range [0,1). Accordingly, the resulting arithmetic code is interpreted as beginning with an implicit "0.". As these are just different interpretations of the same coding methods, and as the resulting arithmetic and range codes are identical, each arithmetic coder is its corresponding range encoder, and vice versa. In other words, arithmetic coding and range encoding are just two, slightly different ways of understanding the same thing.
In practice, though, so-called range "encoders" tend to be implemented pretty much as described in Martin's paper, while arithmetic coders more generally tend not to be called range encoders. An often noted feature of such range encoders is the tendency to perform renormalization a byte at a time, rather than one bit at a time (as is usually the case). In other words, range encoders tend to use bytes as encoding digits, rather than bits. While this does reduce the amount of compression that can be achieved by a very small amount, it is faster than when performing renormalization for each bit.

</doc>
<doc id="46122" url="https://en.wikipedia.org/wiki?curid=46122" title="Karl Brandt">
Karl Brandt

Karl Brandt (January 8, 1904 – June 2, 1948) was a German physician and "Schutzstaffel" (SS) officer in Nazi Germany. Trained in surgery, Brandt joined the Nazi Party in 1932 and became Adolf Hitler's escort physician in August 1934. A member of Hitler's inner circle at the Berghof, he was selected by Philipp Bouhler, the head of Hitler's Chancellery, to administer the "Aktion T4" euthanasia program. Brandt was later appointed the Reich Commissioner of Sanitation and Health ("Bevollmächtiger für das Sanitäts und Gesundheitswesen"). Accused of involvement in human experimentation and other war crimes, Brandt was indicted in late 1946 and faced trial before a U.S. military tribunal along with 22 others in "United States of America v. Karl Brandt, et al". He was convicted, sentenced to death, and later hanged on June 2, 1948.
Early life.
Brandt was born in Mulhouse in the then German Alsace-Lorraine territory (now in Haut-Rhin, France) into the family of a Prussian Army officer. He became a medical doctor and surgeon in 1928, specializing in head and spinal injuries. He joined the Nazi Party in January 1932, and first met Hitler in the summer of 1932. He became a member of the SA in 1933 and a member of the SS on July 29, 1934; appointed the officer rank of "Untersturmführer". From the Summer of 1934 forward, he was Hitler's "Escort Physician". Karl Brandt married Anni Rehborn (born 1907), a champion swimmer, on March 17, 1934. They had one son, Karl Adolf Brandt (born October 4, 1935).
Career in Nazi Germany.
In the context of the 1933 Nazi law "Gesetz zur Verhütung erbkranken Nachwuchses" (Law for the Prevention of Hereditarily Diseased Offspring), he was one of the medical scientists who performed abortions in great numbers on women deemed genetically disordered, mentally or physically handicapped or racially deficient, or whose unborn fetuses were expected to develop such genetic "defects". These abortions had been legalized, as long as no healthy Aryan fetuses were aborted.
On September 1, 1939, Brandt was appointed by Hitler co-head of the T-4 Euthanasia Program, with Philipp Bouhler. Additional power was afforded Brandt when on July 28, 1942, he was appointed Commissioner of Sanitation and Health ("Bevollmächtiger für das Sanitäts und Gesundheitswesen") by Hitler and was thereafter only bound by the Führer's instructions alone. He received regular promotions in the SS; by April 1944, Brandt was a SS-"Gruppenführer" in the "Allgemeine-SS" and a SS-"Brigadeführer" in the Waffen-SS. On April 16, 1945, he was arrested by the Gestapo for moving his family out of Berlin so they could surrender to American forces. He was condemned to death by a military court and then sent to Kiel. Brandt was released from arrest by order of Karl Dönitz on May 2, 1945. He was later placed under arrest by the British on May 23, 1945.
Brandt's medical ethics.
Brandt's medical ethics, particularly regarding euthanasia, were influenced by Alfred Hoche, whose courses he attended. Like many other German doctors of the period, Brandt came to believe that the health of society as a whole should take precedence over that of its individual members. Because society was viewed as an organism that had to be cured, its weakest, most invalid and incurable members were only parts that should be removed. Such hapless creatures should therefore be granted a "merciful death" ("Gnadentod"). In addition to these considerations, Brandt's explanation at his trial for his criminal actions – particularly ordering experimentation on human beings – was that "... Any personal code of ethics must give way to the total character of the war". Historian Horst Freyhofer asserts that, in the absence of at least Brandt's "tacit" approval, it is highly unlikely that the grotesque and cruel medical experiments for which the Nazi doctors are infamous, could have been performed. Brandt and Hitler discussed multiple killing techniques during the initial planning of the euthanasia program, during which Hitler asked Brandt, “which is the most humane way;” Brandt suggested the use of carbon monoxide gas, whereupon Hitler gave his approval and instructed Brandt to reach out to other physicians and begin to coordinate the mass killings.
Life in the inner circle.
Karl Brandt and his wife Anni were members of Hitler's inner circle at Berchtesgaden where Hitler maintained his private residence known as the Berghof. This very exclusive group functioned as Hitler's de facto family circle. It included Eva Braun, Albert Speer, his wife Margarete, Dr. Theodor Morell, Martin Bormann, Hitler's photographer Heinrich Hoffmann, Hitler's adjutants and his secretaries. Brandt and Hitler’s chief architect Albert Speer were good friends as the two shared technocratic dispositions about their work. Brandt looked at killing "useless eaters" and the handicapped as a means to an end, namely since it was in the interest of public health. Similarly, Speer viewed the use of concentration camp labor for his defense and building projects in much the same way. As members of this inner circle, the Brandts had a residence near the Berghof and spent extensive time there when Hitler was present. In his memoirs, Speer described the numbing lifestyle of Hitler's inner circle, forced to stay up most of the night listening to the insomniac Nazi leader's repetitive monologues or to an unvarying selection of music. Despite Brandt's closeness to Hitler, the dictator was furious when he learned shortly before the end of the war that the doctor had sent Anni and their son toward the American lines in hopes of evading capture by the Russians. Only the intervention of Heinrich Himmler, Albert Speer, and the direct order of Admiral Doenitz after Brandt had been captured by the Gestapo and sent to Kiel in the war's closing days, saved him from execution.
Trial and execution.
Brandt was tried along with twenty-two others at the Palace of Justice in Nuremberg, Germany. The trial was officially titled "United States of America v. Karl Brandt et al.", but is more commonly referred to as the "Doctors' Trial"; it began on December 9, 1946. He was charged with four counts: 
After a defense led by Robert Servatius, on August 19, 1947, Brandt was found guilty on counts 2-4 of the indictment. With six others, he was sentenced to death by hanging, and all were executed at Landsberg Prison on June 2, 1948. Nine other defendants received prison terms of between fifteen years and life, while a further seven were found not guilty.
While on the gallows, Brandt remarked: "It is no shame to stand upon the scaffold. This is nothing but political revenge. I have served my Fatherland as others before me ...” His speech was cut short when a black hood was placed over his head.

</doc>
<doc id="46124" url="https://en.wikipedia.org/wiki?curid=46124" title="ACIS">
ACIS

The 3D ACIS Modeler (ACIS) is a geometric modeling kernel developed by Spatial Corporation (formerly Spatial Technology), part of Dassault Systemes. ACIS is used by many software developers in industries such as computer-aided design (CAD), computer-aided manufacturing (CAM), computer-aided engineering (CAE), architecture, engineering and construction (AEC), coordinate-measuring machine (CMM), 3D animation, and shipbuilding. ACIS provides software developers and manufacturers the underlying 3D modeling functionality.
ACIS features an open, object-oriented C++ architecture that enables robust, 3D modelling capabilities. ACIS is used to construct applications with hybrid modeling features, since it integrates wireframe model, surface, and solid modeling functionality with both manifold and non-manifold topology, and a rich set of geometric operations.
History.
As a geometric kernel, ACIS is a second generation system, coming after the first generation Romulus
There are several versions about what the word ACIS actually stands for, or whether it is an acronym at all. The most popular version is that ACIS stands for "Alan, Charles, Ian's System" (Alan Grayer, Charles Lang and Ian Braid as part of Three-Space Ltd.), or "Alan, Charles, Ian and Spatial" (as the system was later on sold to Spatial Technology, now Spatial Corp). However, when asked, the creators of ACIS would simply suggest that its name was derived from Greek mythology (See also Acis).
In 1985 Charles Lang and Ian Braid (creators of Romulus and Romulus-D) formed Three-Space Ltd. (Cambridge, England) which had been retained by Dick Sowar's Spatial Technology (which had been founded by Sowar in 1986) to develop the ACIS solid modeling kernel for Spatial Technology's Strata CAM software. The first version of ACIS was released in 1989 and was quickly licensed by HP for integration into its ME CAD software.
In late 2000, around the time when Spatial was acquired by Dassault Systemes, the ACIS file format changed slightly and was no longer openly published.
Architecture.
A software component is a functionally specialized unit of software—a collection of software items (functions, classes, etc.) grouped together to serve some distinct purpose. It serves as a constituent part of a whole software system or product. A product is one or more software components that are assembled together and sold as a package. Components can be arranged in different combinations to form different products.
The ACIS product line is designed using software component technology, which allows an application to use only the components it requires. In some cases, more than one component is available (either from Spatial or third party vendors) for a given purpose, so application developers can use the component that best meets their needs. For example, several rendering components are available from Spatial, and developers use the one that works best for their platform or application.
Functionality.
ACIS Modeler.
ACIS core functionality can be subclassified into three categories, namely:
File format.
ACIS saves modeling information to external files which have an open format allowing external applications, even those not based on ACIS, access to the ACIS geometric model. The basic information needed to understand the ACIS file format (focusing on the reading, or restore, operation), includes the structure of the save file format, how data is encapsulated, the types of data written, and subtypes and references.
Save File Types.
ACIS supports two kinds of save files, Standard ACIS Text (SAT), and Standard ACIS Binary (SAB). The two formats store identical information, so the term SAT file is generally used to refer to either when no distinction is needed. 
In the narrow sense, SAT files are ASCII text files that may be viewed with a simple text editor. A SAT file contains carriage returns, white space and other formatting that makes it readable to the human eye. A SAT file has a .sat file extension. 
SAB files cannot be viewed with a simple text editor and are meant for compactness and not for human readability. A SAB file has a .sab file extension. A SAB file uses delimiters between elements and binary tags, without additional formatting.
Structure of the Save File.
A save file contains:
Beginning with ACIS Release 6.3, it is required that the product ID and units be populated for the file header before you can save a SAT file.
Version Numbers and ACIS Releases.
ACIS is currently being developed by Spatial. They maintain the concept of a current version (release) number in ACIS, as well as a save version number. The save version allows one to create a SAT save file that can be read by a previous version of ACIS.
Beginning with ACIS Release 4.0, the SAT save file format does not change with minor releases, only with major releases. This allows applications that are based upon the same major version of ACIS to exchange data without being concerned about the save version. To provide this interoperability in a simple implementation, ACIS save files have contained a symbol that accurately identified the major version number, but not the minor version. This meant that applications created using the same major version of ACIS would produce compatible save files, regardless of their minor versions. This was accomplished by simply not incrementing the internal minor version number between major versions.
Beginning with Release 7.0, ACIS started again providing accurate major, minor, and point version numbers. Beginning with Release 2016 1.0 in September, 2015, Spatial updated to Semantic Versioning, and now describes versions by the model year and major, minor and point releases within that model year.
To summarize how release numbers and SAT changes are related:
Adoption.
In 2013 the following software uses ACIS as its geometric kernel/engine: AutoCAD,
SpaceClaim

</doc>
<doc id="46126" url="https://en.wikipedia.org/wiki?curid=46126" title="Sulfur mustard">
Sulfur mustard

Sulfur mustard, commonly known as mustard gas, is a cytotoxic and vesicant chemical warfare agent with the ability to form large blisters on the exposed skin and in the lungs. Related chemical compounds with similar chemical structure and similar properties form a class of compounds known collectively as sulfur mustards or mustard agents. Pure sulfur mustards are colorless, viscous liquids at room temperature. When used in impure form, such as warfare agents, they are usually yellow-brown in color and have an odor resembling mustard plants, garlic, or horseradish, hence the name. Sulfur mustard was originally assigned the name LOST, after the scientists Wilhelm Lommel and Wilhelm Steinkopf, who developed a method for the large-scale production for the Imperial German Army in 1916.
Mustard agents are regulated under the 1993 Chemical Weapons Convention (C.W.C.). Three classes of chemicals are monitored under this Convention, with sulfur and nitrogen mustard grouped in Schedule 1, as substances with no use other than in chemical warfare. Mustard agents could be deployed on the battlefield by means of artillery shells, aerial bombs, rockets, or by spraying from warplanes.
Synthesis.
Sulfur mustard is the organic compound with formula (ClCH2CH2)2S. In the Depretz method, sulfur mustard is synthesized by treating sulfur dichloride with ethylene:
In the Levinstein process, disulfur dichloride is used instead:
In the Meyer method, thiodiglycol is produced from chloroethanol and potassium sulfide and chlorinated with phosphorus trichloride:
In the Meyer-Clarke method, concentrated hydrochloric acid (HCl) instead of PCl3 is used as the chlorinating agent:
Thionyl chloride and phosgene, the latter of which (CG) is also a choking agent, have also been used as chlorinating agents.
Sulfur mustard is a viscous liquid at normal temperatures. The pure compound has a melting point of and decomposes before boiling at .
Mechanism of cellular toxicity.
The compound readily eliminates a chloride ion by intramolecular nucleophilic substitution to form a cyclic sulfonium ion. This very reactive intermediate tends to cause permanent alkylation of the guanine nucleotide in DNA strands, which prevents cellular division and generally leads directly to programmed cell death, or, if cell death is not immediate, the damaged DNA may lead to the development of cancer. Oxidative stress would be another pathology involved in sulfur mustard toxicity. Sulfur mustard is not very soluble in water but is very soluble in fat, contributing to its rapid absorption into the skin.
In the wider sense, compounds with the structural element BCH2CH2X, where X is any leaving group, and B is a Lewis base are known as "mustards". Such compounds can form cyclic "onium" ions (sulfonium, ammoniums, etc.) that are good alkylating agents. Examples are bis(2-chloroethyl)ether, the (2-haloethyl)amines (nitrogen mustards), and sulfur sesquimustard, which has two α-chloroethyl thioether groups (ClH2CCH2S−) connected by an ethylene (−CH2CH2−) group. These compounds have a similar ability to alkylate DNA, but their physical properties, e.g. melting points, may vary.
Physiological effects.
Mustard agent has extremely powerful vesicant effects on its victims. In addition, it is strongly mutagenic and carcinogenic, due to its alkylating properties. It is also lipophilic. Because people exposed to mustard agent rarely suffer immediate symptoms, and mustard-contaminated areas may appear completely normal, victims can unknowingly receive high dosages. Within 24 hours of exposure to mustard agent, victims experience intense itching and skin irritation, which gradually turns into large blisters filled with yellow fluid wherever the mustard agent contacted the skin. These are chemical burns and are very debilitating. Mustard agent vapor easily penetrates clothing fabrics such as wool or cotton, so it is not only the exposed skin of victims that gets burned. If the victim's eyes were exposed then they become sore, starting with conjunctivitis, after which the eyelids swell, resulting in temporary blindness. In rare cases of extreme ocular exposure to sulfur mustard vapors, corneal ulceration, anterior chamber scarring, and neovascularization have occurred. In these severe and infrequent cases, corneal transplantation has been used as a treatment option. Miosis may also occur, which is probably the result from the cholinomimetic activity of mustard. At very high concentrations, if inhaled, mustard agent causes bleeding and blistering within the respiratory system, damaging mucous membranes and causing pulmonary edema. Depending on the level of contamination, mustard agent burns can vary between first and second degree burns, though they can also be every bit as severe, disfiguring and dangerous as third degree burns. Severe mustard agent burns (i.e. where more than 50% of the victim's skin has been burned) are often fatal, with death occurring after some days or even weeks have passed. Mild or moderate exposure to mustard agent is unlikely to kill, though victims require lengthy periods of medical treatment and convalescence before recovery is complete.
The mutagenic and carcinogenic effects of mustard agent mean that victims who recover from mustard agent burns have an increased risk of developing cancer in later life. In a study of patients 25 years after wartime exposure to chemical weaponry, c-DNA microarray profiling indicated that a total of specific 122 genes were significantly mutated in the lungs and airways of sulfur mustard victims. Those genes all correspond to functions commonly affected by sulfur mustard exposure, including apoptosis, inflammation, and stress responses.
The vesicant property of mustard agent can be neutralized by oxidation or chlorination, using household bleach (sodium hypochlorite), or by nucleophilic attack using e.g. decontamination solution "DS2" (2% NaOH, 70% diethylenetriamine, 28% ethylene glycol monomethyl ether). After initial decontamination of the victim's wounds is complete, medical treatment is similar to that required by any conventional burn. The amount of pain and discomfort suffered by the victim is comparable as well. Mustard agent burns heal slowly, and, as with other types of burn, there is a risk of sepsis caused by pathogens such as "Staphylococcus aureus" and "Pseudomonas aeruginosa". The mechanisms behind sulfur mustard’s effect on endothelial cells are still being studied, but recent studies have shown that high levels of exposure can induce high rates of both necrosis and apoptosis. In vitro tests have shown that at low concentrations of sulfur mustard, where apoptosis is the predominant result of exposure, pretreatment with 50 mM N-acetyl-L-cystein (NAC) was able to decrease the rate of apoptosis. NAC protects actin filaments from reorganization by sulfur mustard, demonstrating that actin filaments play a large role in the severe burns observed in victims.
A British nurse treating soldiers with mustard agent burns during World War I commented:
Formulations.
In its history, various types and mixtures of sulfur mustard have been employed. These include:
Sulfur mustard agents (class).
The complete list of effective sulfur mustard agents commonly stockpiled is as follows:
History.
Development.
Mustard agent was possibly developed as early as 1822 by César-Mansuète Despretz (1798–1863). Despretz described the reaction of sulfur dichloride and ethylene but never made mention of any irritating properties of the reaction product, which makes the claim doubtful. In 1854, another French chemist, Alfred Riche (1829–1908), repeated this procedure but he did not describe any adverse physiological properties. In 1860, the British scientist Frederick Guthrie synthesized and characterized the mustard agent compound, and he also noted its irritating properties, especially in tasting. In 1860, chemist Albert Niemann, known as a pioneer in cocaine chemistry, repeated the reaction, and recorded blister-forming properties. In 1886, Viktor Meyer published a paper describing a synthesis that produced good yields. He combined 2-chloroethanol with aqueous potassium sulfide, and then treated the resulting thiodiglycol with phosphorus trichloride. The purity of this compound was much higher, and the adverse health effects on exposure much more severe. These symptoms presented themselves in his assistant, and in order to rule out the possibility that his assistant was suffering from a mental illness (psychosomatic symptoms), Meyer had this compound tested on laboratory rabbits, most of which died. In 1913, the English chemist Hans Thacher Clarke (known for the Eschweiler-Clarke reaction) replaced the phosphorus trichloride with hydrochloric acid in Meyer's formulation while working with Emil Fischer in Berlin. Clarke was hospitalized for two months for burns after one of his flasks broke. According to Meyer, Fischer's report on this accident to the German Chemical Society sent the German Empire on the road to chemical weapons.
Mustard agent can have the effect of turning a patient's skin different colors, including reds, oranges, pinks, and in unusual cases, blues. The German Empire during World War I relied on the Meyer-Clarke method with the 2-chloroethanol chemical structure already available from the German chemical dye industry of that time.
Use.
Mustard agent was first used effectively in World War I by the German army against British and Canadian soldiers near Ypres, Belgium, in 1917 and later also against the French Second Army. The name Yperite comes from its usage by the German army near the town of Ypres. The Allies did not use mustard agent until November 1917 at Cambrai, France, after the armies had captured a stockpile of German mustard-gas shells. It took the British more than a year to develop their own mustard agent weapon, with production of the chemicals centred on Avonmouth Docks. (The only option available to the British was the Despretz–Niemann–Guthrie process). This was used first in September 1918 during the breaking of the Hindenburg Line.
Mustard agent was dispersed as an aerosol in a mixture with other chemicals, giving it a yellow-brown color and a distinctive odor. Mustard agent has also been dispersed in such munitions as aerial bombs, land mines, mortar rounds, artillery shells, and rockets. Exposure to mustard agent was lethal in about one percent of cases. Its effectiveness was as an incapacitating agent. The early countermeasures against mustard agent were relatively ineffective, since a soldier wearing a gas mask was not protected against absorbing it through his skin and being blistered.
Mustard agent is a persistent weapon that remains on the ground for days and weeks, and it continues to cause ill effects. If mustard agent contaminates a soldier's clothing and equipment, then the other soldiers that he comes into contact with are also poisoned. Towards the end of World War I, mustard agent was used in high concentrations as an area-denial weapon that forced troops to abandon heavily-contaminated areas.
Since World War I, mustard agent has been used in several wars or other conflicts, usually against people who cannot retaliate in kind:
In 1943, during the Second World War, an American shipment of mustard agent exploded aboard a supply ship that was bombed during an air raid in the harbor of Bari, Italy. Eighty-three of the 628 hospitalized victims who had been exposed to the mustard agent died. The deaths and incident were partially classified for many years.
From 1943 to 1944, mustard agent experiments were performed on Australian service volunteers in tropical Queensland, Australia, by British Army and American experimenters, resulting in some severe injuries. One test site, the Brook Islands National Park, was chosen to simulate Pacific islands held by the Imperial Japanese Army.
After WWII, stockpiled mustard agent was dumped by the British in the sea near Port Elizabeth, South Africa, resulting in burn cases among trawler crews.
The use of poison gases, including mustard agent, during warfare is known as chemical warfare, and this kind of warfare was prohibited by the Geneva Protocol of 1925, and also by the later Chemical Weapons Convention of 1993. The latter agreement also prohibits the development, production, stockpiling, and sale of such weapons.
In September 2015 a US official stated that the rebel militant group ISIS was manufacturing and using sulfur mustard in Syria and Iraq, which was allegedly confirmed by their the group's head of chemical weapons development, Sleiman Daoud al-Afari, who has since been captured.
Development of the first chemotherapy drug.
As early as 1919 it was known that mustard agent was a suppressor of hematopoiesis. In addition, autopsies performed on 75 soldiers who had died of mustard agent during World War I were done by researchers from the University of Pennsylvania who reported decreased counts of white blood cells. This led the American Office of Scientific Research and Development (OSRD) to finance the biology and chemistry departments at Yale University to conduct research on the use of chemical warfare during World War II. As a part of this effort, the group investigated nitrogen mustard as a therapy for Hodgkin's lymphoma and other types of lymphoma and leukemia, and this compound was tried out on its first human patient in December 1942. The results of this study were not published until 1946, when they were declassified. In a parallel track, after the air raid on Bari in December 1943, the doctors of the U.S. Army noted that white blood cell counts were reduced in their patients. Some years after World War II was over, the incident in Bari and the work of the Yale University group with nitrogen mustard converged, and this prompted a search for other similar chemical compounds. Due to its use in previous studies, the nitrogen mustard called "HN2" became the first cancer chemotherapy drug, mustine, to be used.
Disposal.
Most of the sulfur mustard agent found in Nazi Germany after World War II was dumped into the Baltic Sea. Between 1966 and 2002, fishermen have found about 700 chemical weapons in the region of Bornholm, most of which contain sulfur mustard. One of the more frequently-dumped weapons was the "Sprühbüchse 37" (SprüBü37, Spray Can 37, 1937 being the year of its fielding with the German Army). These weapons contain sulfur mustard mixed with a thickener, which gives it a tar-like viscosity. When the content of the SprüBü37 comes in contact with water, only the sulfur mustard in the outer layers of the lumps of viscous mustard hydrolyzes, leaving behind amber-colored residues that still contain most of the active sulfur mustard. On mechanically breaking these lumps, e.g., with the drag board of a fishing net or by the human hand, the enclosed sulfur mustard is still as active as it had been at the time the weapon was dumped. These lumps, when washed ashore, can be mistaken for amber, which can lead to severe health problems. Artillery shells containing sulfur mustard and other toxic ammunition from World War I (as well as conventional explosives) can still be found in France and Belgium. These were formerly disposed of by explosion undersea, but since the current environmental regulations prohibit this, the French government is building an automated factory to dispose of the accumulation of chemical shells.
In 1972, the U.S. Congress banned the practice of disposing of chemical weapons into the ocean by the United States. 29000 tons of nerve and mustard agents had already been dumped into the ocean off the United States by the U.S. Army. According to a report created in 1998 by William Brankowitz, a deputy project manager in the U.S. Army Chemical Materials Agency, the army created at least 26 chemical weapons dumping sites in the ocean offshore from at least 11 states on both the East Coast and the West Coast (in Operation CHASE, Operation Geranium, etc.). In addition, due to poor recordkeeping, about one-half of the sites have only their rough locations known.
A significant portion of the stockpile of mustard agent in the United States was stored at the Edgewood Area of Aberdeen Proving Ground in Maryland. Approximately 1,621 tons of mustard agent were stored in one-ton containers on the base under heavy guard. A chemical neutralization plant was built on the proving ground and neutralized the last of this stockpile in February 2005. This stockpile had priority because of the potential for quick reduction of risk to the community. The nearest schools were fitted with overpressurization machinery to protect the students and faculty in the event of a catastrophic explosion and fire at the site. These projects, as well as planning, equipment, and training assistance, were provided to the surrounding community as a part of the Chemical Stockpile Emergency Preparedness Program (CSEPP), a joint program of the Army and the Federal Emergency Management Agency (FEMA). Unexploded shells containing mustard agent and other chemical agents are still present in several test ranges in proximity to schools in the Edgewood area, but the smaller amounts of poison gas (four to 14 pounds) present considerably lower risks. These remnants are being detected and excavated systematically for disposal. The U.S. Army Chemical Materials Agency oversaw disposal of several other chemical weapons stockpiles located across the United States in compliance with international chemical weapons treaties. These include the complete incineration of the chemical weapons stockpiled in Alabama, Arkansas, Indiana, and Oregon. Earlier, this agency had also completed destruction of the chemical weapons stockpile located on Johnston Atoll located south of Hawaii in the Pacific Ocean. The largest mustard agent stockpile, of about 6,196 tons, was stored at the Deseret Chemical Depot in northern Utah. The incineration of this stockpile began in 2006. In May 2011, the last one-ton tank of mustard agent was incinerated at the Deseret Chemical Depot, and the last mustard agent artillery shells at Deseret were incinerated in January 2012.
In June 1997, India declared its stock of chemical weapons (1,044 tonnes of sulphur mustard). By the end of 2006, India had destroyed more than 75 percent of its chemical weapons/material stockpile and was granted extension for destroying (the remaining stocks by April 2009) and was expected to achieve 100 percent destruction within that time frame. India informed the United Nations in May 2009 that it had destroyed its stockpile of chemical weapons in compliance with the international Chemical Weapons Convention. With this India has become third country after South Korea and Albania to do so. This was cross-checked by inspectors of the United Nations.
The storage and incineration of mustard agent and other poison gases was carried out by the U.S. Army Chemical Materials Agency. Disposal projects at the two remaining American chemical weapons sites, will be carried out at their sites near Richmond, Kentucky, and Pueblo, Colorado.
In 2002, an archaeologist at the Presidio Trust archaeology lab in San Francisco was exposed to mustard agent, which had been dug up at the Presidio of San Francisco, a former military base.
In 2008, many empty mustard agent aerial bombs were found in an excavation at the Marrangaroo Army Base just west of Sydney, Australia. In 2009, a mining survey near Chinchilla, Queensland, uncovered 144 105-millimeter howitzer shells, some containing "Mustard H", that had been buried by the U.S. Army during World War II.
In 2010, a clamming boat pulled up some old artillery shells of World War I from the Atlantic Ocean south of Long Island, New York. Multiple fishermen suffered from skin blistering and respiratory irritation severe enough to require their hospitalization.
A large British stockpile of old mustard agent that had been made and stored at M. S. Factory, Valley near Rhydymwyn in Flintshire, Wales, since World War I was destroyed in 1958.
In 2014, a collection of 200 bombs were found on the boundary between the Flemish villages of Passendale and Moorslede. The majority of the bombs were filled with mustard agent. The bombs are a leftover from the German army and were meant to be used in the Battle of Passchendale in World War I. It was the largest collection of chemical weapons ever found in Belgium.
New detection techniques are being developed in order to detect the presence of sulfur mustard and its metabolites. The technology is portable and detects small quantities of the hazardous waste and its oxidized products, which are notorious for harming unsuspecting civilians. The immunochromatographic assay would eliminate the need for expensive, time-consuming lab tests and enable easy-to-read tests to protect civilians from sulfur-mustard dumping sites.
Detection in biological fluids.
Urinary concentrations of the thiodiglycol hydrolysis products of sulfur mustard have been used to confirm a diagnosis of chemical poisoning in hospitalized victims. The presence in urine of 1,1'-sulfonylbismethylthioethane (SBMTE), a conjugation product with glutathione, is considered a more specific marker, since this metabolite is not found in specimens from unexposed persons. Intact sulfur mustard was detected in postmortem fluids and tissues of a man who died one week post-exposure.

</doc>
<doc id="46127" url="https://en.wikipedia.org/wiki?curid=46127" title="Robert Tarjan">
Robert Tarjan

Robert Endre Tarjan (born April 30, 1948) is an American computer scientist and mathematician. He is the discoverer of several graph algorithms, including Tarjan's off-line lowest common ancestors algorithm, and co-inventor of both splay trees and Fibonacci heaps. Tarjan is currently the James S. McDonnell Distinguished University Professor of Computer Science at Princeton University, and the Chief Scientist at Intertrust Technologies.
Early life and education.
He was born in Pomona, California. His father was a child psychiatrist specializing in mental retardation, and ran a state hospital. As a child, Tarjan read a lot of science fiction, and wanted to be an astronomer. He became interested in mathematics after reading Martin Gardner's mathematical games column in Scientific American. He became seriously interested in math in the eighth grade, thanks to a "very stimulating" teacher.
While he was in high school, Tarjan got a job, where he worked IBM card punch collators. He first worked with real computers while studying astronomy at the Summer Science Program in 1964.
Tarjan obtained a Bachelor's degree in mathematics from the California Institute of Technology in 1969. At Stanford University, he received his master's degree in computer science in 1971 and a Ph.D. in computer science (with a minor in mathematics) in 1972. At Stanford, he was supervised by Robert Floyd and Donald Knuth, both highly prominent computer scientists, and his Ph.D. dissertation was "An Efficient Planarity Algorithm". Tarjan selected computer science as his area of interest because he believed that CS was a way of doing mathematics that could have a practical impact.
Computer science career.
Tarjan has been teaching at Princeton University since 1985. He has also held academic positions at Cornell University (1972–73), University of California, Berkeley (1973–1975), Stanford University (1974–1980), and New York University (1981–1985). He has also been a fellow of the NEC Research Institute (1989–1997). In April 2013 he joined Microsoft Research Silicon Valley in addition to the position at Princeton. In October 2014 he rejoined Intertrust Technologies as chief scientist.
Tarjan has worked at AT&T Bell Labs (1980–1989), Intertrust Technologies (1997–2001, 2014–present), Compaq (2002) and Hewlett Packard (2006–2013).
Algorithms and data structures.
Tarjan is known for his pioneering work on graph theory algorithms and data structures. Some of his well-known algorithms include Tarjan's off-line least common ancestors algorithm, and Tarjan's strongly connected components algorithm, and he was one of five co-authors of the median of medians linear time selection algorithm. The Hopcroft-Tarjan planarity testing algorithm was the first linear-time algorithm for planarity-testing.
Tarjan has also developed important data structures such as the Fibonacci heap (a heap data structure consisting of a forest of trees), and the splay tree (a self-adjusting binary search tree; co-invented by Tarjan and Daniel Sleator). Another significant contribution was the analysis of the disjoint-set data structure; he was the first to prove the optimal runtime involving the inverse Ackermann function.
Awards.
Tarjan received the Turing Award jointly with John Hopcroft in 1986. The citation for the award states that it was:
Tarjan was also elected an ACM Fellow in 1994. The citation for this award states:
Some of the other awards for Tarjan include:
Patents.
Tarjan holds at least 18 U.S. patents. These include:

</doc>
<doc id="46128" url="https://en.wikipedia.org/wiki?curid=46128" title="Invasion of Normandy">
Invasion of Normandy

The Western Allies of World War II launched the largest amphibious invasion in history when they assaulted Normandy, located on the northern coast of France, on 6 June 1944. The invaders were able to establish a beachhead as part of Operation Overlord after a successful "D-Day," the first day of the invasion.
Allied land forces came from Canada, Britain, the United States and Free French forces. In the weeks following the invasion, Polish forces and contingents from Belgium, Czechoslovakia, Greece and the Netherlands participated in the ground campaign; most also provided air and naval support alongside elements of the Royal Australian Air Force, the Royal New Zealand Air Force, and the Royal Norwegian Navy.
The Normandy invasion began with overnight parachute and glider landings, massive air attacks and naval bombardments. In the early morning, amphibious landings on five beaches codenamed Sword, Juno, Gold, Omaha and Utah began and during the evening the remaining elements of the parachute divisions landed. Land forces used on D-Day sailed from bases along the south coast of England, the most important of these being Portsmouth.
Planning of the invasion.
Allied forces rehearsed their D-Day roles for months before the invasion. On 28 April 1944, in south Devon on the English coast, 638 U.S. soldiers and sailors were killed when German torpedo boats surprised one of these landing exercises, Exercise Tiger.
In the months leading up to the invasion, the Allied forces conducted a deception operation, Operation Fortitude, aimed at misleading the Germans with respect to the date and place of the invasion.
There were several leaks prior to or on D-Day. Through the Cicero affair, the Germans obtained documents containing references to Overlord, but these documents lacked all detail. Double Cross agents, such as the Spaniard Joan Pujol (code named Garbo), played an important role in convincing the German High Command that Normandy was at best a diversionary attack. U.S. Major General Henry Miller, chief supply officer of the US 9th Air Force, during a party at Claridge's Hotel in London complained to guests of the supply problems he was having but that after the invasion, which he told them would be before 15 June, supply would be easier. After being told, Eisenhower reduced Miller to lieutenant colonel Press, June 10, 1944 and sent him back to the U.S. where he retired. Another such leak was General Charles de Gaulle's radio message after D-Day. He, unlike all the other leaders, stated that this invasion was the real invasion. This had the potential to ruin the Allied deceptions Fortitude North and Fortitude South. In contrast, Gen. Eisenhower referred to the landings as the initial invasion.
Only ten days each month were suitable for launching the operation: a day near the full moon was needed both for illumination during the hours of darkness and for the , the former to illuminate navigational landmarks for the crews of aircraft, gliders and landing craft, and the latter to expose defensive obstacles placed by the German forces in the surf on the seaward approaches to the beaches. A full moon occurred on 6 June. Allied Expeditionary Force Supreme Commander Dwight D. Eisenhower had tentatively selected 5 June as the date for the assault. The weather was fine during most of May, but deteriorated in early June. On 4 June, conditions were clearly unsuitable for a landing; wind and high seas would make it impossible to launch landing craft from larger ships at sea, low clouds would prevent aircraft finding their targets. The Allied troop convoys already at sea were forced to take shelter in bays and inlets on the south coast of Britain for the night.
It seemed possible that everything would have to be cancelled and the troops returned to their embarkation camps (which would be almost impossible, as the enormous movement of follow-up formations into them was already proceeding). The next full moon period would be nearly a month away. At a vital meeting on 5 June, Eisenhower's chief meteorologist (Group Captain J.M. Stagg) forecast a brief improvement for 6 June. Commander of all land forces for the invasion General Bernard Montgomery and Eisenhower's Chief of Staff General Walter Bedell Smith wished to proceed with the invasion. Commander of the Allied Air Forces Air Chief Marshal Leigh Mallory was doubtful, but Allied Naval Commander-in-Chief Admiral Bertram Ramsay believed that conditions would be marginally favorable. On the strength of Stagg's forecast, Eisenhower ordered the invasion to proceed. As a result, prevailing overcast skies limited Allied air support, and no serious damage would be done to the beach defences on Omaha and Juno.
The Germans meanwhile took comfort from the existing poor conditions, which were worse over Northern France than over the English Channel itself, and believed no invasion would be possible for several days. Some troops stood down and many senior officers were away for the weekend. Field Marshal Erwin Rommel took a few days' leave to celebrate his wife's birthday, while dozens of division, regimental and battalion commanders were away from their posts conducting war games just prior to the invasion.
Codenames.
The Allies assigned codenames to the various operations involved in the invasion. "Overlord" was the name assigned to the establishment of a large-scale lodgement on the northern portion of the Continent. The first phase, the establishment of a secure foothold, was codenamed "Neptune". According to the D-day museum:
Officers with knowledge of D-Day were not to be sent where there was the slightest danger of being captured. These officers were given the codename of "Bigot", derived from the words "To Gib" (To Gibraltar) that was stamped on the papers of officers who took part in the North African invasion in 1942. On the night of 27 April, during Exercise Tiger, a pre-invasion exercise off the coast of Slapton Sands beach, several American LSTs were attacked by German E boats and among the 638 Americans killed in the attack and a further 308 killed by friendly fire, ten "Bigots" were listed as missing. As the invasion would be cancelled if any were captured or unaccounted for, their fate was given the highest priority and eventually all ten bodies were recovered.
Allied order of battle.
D-Day.
The following major units were landed on D-Day (6 June 1944). A more detailed order of battle for D-Day itself can be found at Normandy landings.
The total number of troops landed on D-Day was around 130,000–156,000 roughly half American and the other from the Commonwealth Realms.
Subsequent days.
The total troops, vehicles and supplies landed over the period of the invasion were:
Naval participants.
The invasion fleet was drawn from eight different navies, comprising 6,939 vessels: 1,213 warships, 4,126 transport vessels (landing ships and landing craft), and 736 ancillary craft and 864 merchant vessels.
The overall commander of the Allied Naval Expeditionary Force, providing close protection and bombardment at the beaches, was Admiral Sir Bertram Ramsay. The Allied Naval Expeditionary Force was divided into two Naval Task Forces: Western (Rear-Admiral Alan G Kirk) and Eastern (Rear-Admiral Sir Philip Vian).
The warships provided cover for the transports against the enemy—whether in the form of surface warships, submarines, or as an aerial attack—and gave support to the landings through shore bombardment. These ships included the Allied Task Force "O".
German order of battle.
The number of military forces at the disposal of Nazi Germany reached its peak during 1944. Tanks on the east front peaked at 5,202 in November 1944, while total aircraft in the Luftwaffe inventory peaked at 5,041 in December 1944. By D-Day 157 German divisions were stationed in the Soviet Union, 6 in Finland, 12 in Norway, 6 in Denmark, 9 in Germany, 21 in the Balkans, 26 in Italy and 59 in France, Belgium and the Netherlands. However, these statistics are somewhat misleading since a significant number of the divisions in the east were depleted; German records indicate that the average personnel complement was at about 50% in the spring of 1944.
A more detailed order of battle for D-Day itself can be found at Normandy landings.
Atlantic Wall.
Standing in the way of the Allies was the English Channel, a crossing which had frustrated the ambitions of the Spanish Armada and Napoleon Bonaparte's Navy. Compounding the invasion efforts was the extensive Atlantic Wall, ordered by Hitler in his Directive 51. Believing that any forthcoming landings would be timed for high tide (this caused the landings to be timed for low tide), Hitler had the entire wall fortified with tank top turrets and extensive barbed wire, and laid a million mines to deter landing craft. The sector that was attacked was guarded by four divisions.
Divisional areas.
The following units were deployed in a static defensive mode in the areas of the actual landings:
Adjacent divisional areas.
Other divisions occupied the areas around the landing zones, including:
Armoured reserves.
Rommel's defensive measures were also frustrated by a dispute over armoured doctrine. In addition to his two army groups, von Rundstedt also commanded the headquarters of "Panzer Group West" under General Leo Geyr von Schweppenburg (usually referred to as "von Geyr"). This formation was nominally an administrative HQ for von Rundstedt's armoured and mobile formations, but it was later to be brought into the line in Normandy and renamed Fifth Panzer Army. Von Geyr and Rommel disagreed over the deployment and use of the vital Panzer divisions.
Rommel recognised that the Allies would possess air superiority and would be able to harass his movements from the air. He therefore proposed that the armoured formations be deployed close to the invasion beaches. In his words, it was better to have one Panzer division facing the invaders on the first day, than three Panzer divisions three days later when the Allies would already have established a firm beachhead. Von Geyr argued for the standard doctrine that the Panzer formations should be concentrated in a central position around Paris and Rouen, and deployed "en masse" against the main Allied beachhead when this had been identified.
The argument was eventually brought before Hitler for arbitration. He characteristically imposed an unworkable compromise solution. Only three Panzer divisions were given to Rommel, too few to cover all the threatened sectors. The remainder, nominally under Von Geyr's control, were actually designated as being in "OKW Reserve". Only three of these were deployed close enough to intervene immediately against any invasion of Northern France; the other four were dispersed in southern France and the Netherlands. Hitler reserved to himself the authority to move the divisions in OKW Reserve, or commit them to action. On 6 June many Panzer division commanders were unable to move because Hitler had not given the necessary authorisation, and his staff refused to wake him upon news of the invasion.
Army Group B reserve.
The other two armoured divisions over which Rommel had operational control, the 2nd Panzer Division and 116th Panzer Division, were deployed near the Pas de Calais in accordance with German views about the likely Allied landing sites. Neither was moved from the Pas de Calais for at least fourteen days after the invasion.
OKW reserve.
The other mechanized divisions capable of intervening in Normandy were retained under the direct control of the German Armed Forces HQ (OKW) and were initially denied to Rommel:
Four divisions were deployed to Normandy within seven days of the invasion:
Three other divisions (the 2nd SS Panzer Division Das Reich, which had been refitting at Montauban in Southern France, and the 9th SS Panzer Division Hohenstaufen and 10th SS Panzer Division Frundsberg which had been in transit from the Eastern Front on 6 June), were committed to battle in Normandy around twenty-one days after the first landings.
One more armoured division (the 9th Panzer Division) saw action only after the American breakout from the beachhead. Two other armoured divisions which had been in the west on 6 June (the 11th Panzer Division and 19th Panzer Division) did not see action in Normandy.
Allied establishment in France.
The Allied invasion plans had called for the capture of Saint-Lô, Caen, and Bayeux on the first day, with all the beaches linked except Utah, and Sword (the last linked with paratroopers) and a front line 10 to 16 kilometres (6–10 mi) from the beaches. However, practically none of these objectives had been achieved. It took two months for British and Canadian troops to capture Caen, as they faced 7 heavy Panzer divisions, while their American allies, although advancing more rapidly, faced only 2 of these divisions. Overall the casualties had not been as heavy as some had feared (around 10,000 compared to the 20,000 Churchill had estimated) and the bridgeheads had withstood the expected counterattacks.
Once the beachhead was established, two artificial Mulberry harbours were towed across the English Channel in segments and made operational around D+3 (9 June). One was constructed at Arromanches by British forces, the other at Omaha Beach by American forces. By 19 June, when severe storms interrupted the landing of supplies for several days and destroyed the Omaha harbour, the British had landed 314,547 men, 54,000 vehicles, and 102,000 tons of supplies, while the Americans put ashore 314,504 men, 41,000 vehicles, and 116,000 tons of supplies. Around 9,000 tons of materiel were landed daily at the Arromanches harbour until the end of August 1944, by which time the port of Cherbourg had been secured by the Allies and had begun to return to service.
In addition, with the installation of PLUTO in August 1944 the Allies had fuel piped over directly from England without having to rely on vulnerable tankers.
Assessment of the battle.
The Normandy landings were the first successful opposed landings across the English Channel in over eight centuries. They were costly in terms of men, but the defeat inflicted on the Germans was one of the largest of the war. Strategically, the campaign led to the loss of the German position in most of France and the secure establishment of a new major front. In larger context the Normandy landings helped the Soviets on the Eastern Front, who were facing the bulk of the German forces and, to a certain extent, contributed to the shortening of the conflict there.
Although there was a shortage of artillery ammunition, at no time were the Allies critically short of any necessity. This was a remarkable achievement considering they did not hold a port until Cherbourg fell. By the time of the breakout the Allies also enjoyed a considerable superiority in numbers of troops (approximately 7:2) and armoured vehicles (approximately 4:1) which helped overcome the natural advantages the terrain gave to the German defenders.
Allied intelligence and counterintelligence efforts were successful beyond expectations. The Operation Fortitude deception before the invasion kept German attention focused on the Pas de Calais, and indeed high-quality German forces were kept in this area, away from Normandy, until July. Prior to the invasion, few German reconnaissance flights took place over Britain, and those that did saw only the dummy staging areas. Ultra decrypts of German communications had been helpful as well, exposing German dispositions and revealing their plans such as the Mortain counterattack.
Allied air operations also contributed significantly to the invasion, via close tactical support, interdiction of German lines of communication (preventing timely movement of supplies and reinforcements—particularly the critical Panzer units), and rendering the Luftwaffe ineffective in Normandy. Although the impact upon armoured vehicles was less than expected, air activity intimidated these units and cut their supplies.
Despite initial heavy losses in the assault phase, Allied morale remained high. Casualty rates among all the armies were tremendous, and the Commonwealth forces had to use a recently created category—Double Intense—to be able to describe them.
German leadership.
German commanders at all levels failed to react to the assault phase in a timely manner. Communications problems exacerbated the difficulties caused by Allied air and naval firepower. Local commanders also seemed incapable of the task of fighting an aggressive defense on the beach, as Rommel had envisioned.
The German High Command remained fixated on the Calais area, and von Rundstedt was not permitted to commit the armoured reserve. When it was finally released late in the day, any chance of success was much more difficult. Overall, despite considerable Allied material superiority, the Germans kept the Allies bottled up in a small beachhead for nearly two months, aided immeasurably by terrain factors.
Although there were several known disputes among the Allied commanders, their tactics and strategy were essentially determined by agreement between the main commanders. By contrast, the German leaders were bullied and their decisions interfered with by Hitler, controlling the battle from a distance with little knowledge of local conditions. Field Marshals von Rundstedt and Rommel repeatedly asked Hitler for more discretion but were refused. Von Rundstedt was removed from his command on 29 June after he bluntly told the Chief of Staff at Hitler's Armed Forces HQ (Field Marshal Keitel) to "Make peace, you idiots!" Rommel was severely injured by Allied aircraft on 17 July.
The German commanders also suffered in the quality of the available troops. Sixty thousand of the 850,000 in Rundstedt's command were raised from the many prisoners of war captured on the Eastern Front. These "Ost" units had volunteered to fight against Stalin, but when instead unwisely used to defend France against the Western Allies, ended up being unreliable. Many surrendered or deserted at the first available opportunity.
War memorials and tourism.
The beaches at Normandy are still referred to on maps and signposts by their invasion codenames. There are several vast cemeteries in the area. The American cemetery, in Colleville-sur-Mer, contains row upon row of identical white crosses and Stars of David, immaculately kept, commemorating the American dead. Commonwealth graves, maintained in many locations by the Commonwealth War Graves Commission, uses white headstones engraved with the person's religious or medal (Victoria Cross or George Cross only) symbol and their unit insignia. The Bayeux War Cemetery, with 4,648 burials, is the largest British cemetery of the war. The largest cemetery in Normandy is the La Cambe German war cemetery, with 21,222 burials, which features granite stones almost flush with the ground and groups of low-set crosses. There is also a Polish cemetery.
At the Bayeux Memorial, a monument erected by Britain has a Latin inscription on the memorial reads ""Nos a gulielmo victi victoris patriam liberavimus"" – freely translated, this reads "We, once conquered by William, have now set free the Conqueror's native land".
Streets near the beaches are still named after the units that fought there, and occasional markers commemorate notable incidents. At significant points, such as Pointe du Hoc and Pegasus Bridge, there are plaques, memorials or small museums. The Mulberry harbour still sits in the sea at Arromanches. In Sainte-Mère-Église, a dummy paratrooper hangs from the church spire. On Juno Beach, the Canadian government has built the Juno Beach Information Centre, commemorating one of the most significant events in Canadian military history.
In England the most significant memorial is the D-Day Museum in Southsea, Hampshire. The Museum was opened in 1984 to commemorate the 40th anniversary of D-Day. Its centrepiece is the Overlord embroidery commissioned by Lord Dulverton of Batsford (1915–92) as a tribute to the sacrifice and heroism of those men and women who took part in Operation Overlord.
On 5 June 1994 a drumhead service was held on Southsea Common adjacent the D-Day Museum. This service was attended by US President Bill Clinton, Queen Elizabeth II and over 100,000 members of the public.
Dramatisations.
The battle of Normandy has been the topic of many films, television shows, songs, computer games and books. Many dramatisations focus on the initial landings, and these are covered at Normandy Landings. Some examples that cover the wider battle include:

</doc>
<doc id="46129" url="https://en.wikipedia.org/wiki?curid=46129" title="ITV Digital">
ITV Digital

ITV Digital was a British digital terrestrial television broadcaster which launched a pay-TV service on the world's first digital terrestrial television network. Its main shareholders were Carlton Communications and Granada plc, two franchises of the ITV network. Starting as ONdigital in 1998, the service was re-branded as ITV Digital in July 2001. Low audience figures and an ultimately unaffordable multimillion-pound deal with the Football League led to the broadcaster suffering massive losses; these forced it to enter administration in March 2002. The service ceased permanently in June 2002, with the terrestrial multiplexes subsequently taken over by Crown Castle and the BBC to create Freeview in October 2002.
History.
Digital terrestrial television (DTT) began in the United Kingdom in 1998. Six multiplexes were set up, with three of them allocated to the existing analogue broadcasters. The other three multiplexes were auctioned off. A consortium of Carlton Television, Granada Television and British Sky Broadcasting won the auction as British Digital Broadcasting (BDB). The brand ONdigital was adopted for launch. BSkyB was forced by the Independent Television Commission (ITC) to withdraw from the consortium on competition grounds; this effectively placed Sky in direct competition with the newly launched service, although BSkyB was still required to provide key channels such as Sky Movies and Sky Sports to ONdigital. With Sky originally part of the consortium, ONdigital would have paid discounted rates to carry Sky's television channels. Instead, with its positioning as a competitor, Sky charged the full market rates for the channels, at an extra cost of around £60million a year to ONdigital. In all ONdigital was given one year from the award of the licence to launch the first DTT service. In addition to launching audio and video services, they also led the specification of an industry-wide advanced interactive engine (based on MHEG-5). This was an open standard that was then used by all broadcasters on DTT.
The new digital broadcaster was launched on 15 November 1998, with a lineup of 18 channels, including many developed in-house by Carlton and Granada. On 7 March 2000, Onmail was launched, followed closely on 18 September 2000, by ONdigital text service ONnet, and in the same year a deal with multiplex operator SDN led to the launch of pay-per-view service ONrequest.
From the launch date, however, the service was quickly losing money. Aggressive marketing by BSkyB for its own digital service, Sky Digital, made the ONdigital offer look unattractive. The new digital satellite service provided a dish, Digibox, installation and around 200 channels for £159, a lower price than ONdigital at £199. ONdigital's subscription pricing had been set to compare with the older Sky analogue service of 20 channels.
ONdigital's growth slowed throughout 2000 and by the start of 2001, the number of subscribers did not increase - meanwhile, its competitor Sky Digital was growing. The ONdigital management team hoped to obtain the upper hand by a series of 'free set top box' promotions (initially at retailers such as Currys and Dixons) when ONdigital receiving equipment was purchased at the same time as a television set or similarly priced piece of equipment. These offers eventually became permanent, with the set-top box 'loaned' to the customer at no charge for as long as they continued to subscribe to ONdigital. The offer was matched by Sky. ONdigital's churn rate, a measure of the number of subscribers leaving the service, reached 28% during 2001.
Additional problems for ONdigital were caused by the choice of 64QAM broadcast mode, coupled with far weaker than expected broadcast power, (meaning that the signal was weak in many areas), a complex pricing structure (comprising many menu options), a poor quality subscriber management system (badly adapted from Canal+), a paper magazine TV guide whereas BSkyB had provided an electronic programme guide (EPG), insufficient technical customer services, and much signal piracy. While there was a limited return path provided via an in-built 2400 baud modem, there was no requirement (as with BSkyB) to connect the set-top box's modem to a phone line.
Later problems occurred when ONdigital began to sell 'ONprepaid', a set-top box bundle sold in high street stores and supermarkets at a price that included - in theory - the set-top box on loan and the first year's subscription package. Thousands of these packages were also sold at well below retail price on auction sites such as the then-popular QXL. As the call to activate the viewing card did not require any bank details, many ONdigital boxes which were technically on loan were at unverifiable addresses. This was later changed so a customer could not walk away with a box without ONdigital verifying their address. Many customers did not activate the viewing card at all, although where the viewer's address was known, ONdigital would write informing them that they must activate before a certain deadline.
Additionally, the OnDigital pay-per-view channels had been encrypted using a system - SECA MediaGuard - which had subsequently been cracked. ITV Digital did not update this system, therefore it was very easy for people to produce and sell counterfeit subscription cards which would give access to all the channels.
In 2002, Canal+ accused News Corp of extracting the UserROM code from the MediaGuard cards and leaking it onto the internet.
Canal+ brought a lawsuit against News Corporation alleging that it, with the help of NDS, had been working on breaking the MediaGuard smartcards used by Canal+, ITV Digital and other non-Murdoch-owned TV companies throughout Europe. The action was later partially dropped after News Corporation agreed to buy Canal Plus's struggling Italian operation Telepiu. 
Other legal action by Echostar/NagraStar was being pursued as late as August 2005 accusing NDS of the same wrongdoing. In 2008, NDS was found to have broken piracy laws by hacking EchoStar Communications’ smart card system, however only $1,500 in statutory damages was awarded.
Rebranding.
On 11 July 2001 Carlton and Granada rebranded ONdigital as ITV Digital. They also purchased the TV rights to the Football League and launched the ITV Sport Channel. A re-branding campaign was launched to support the new naming, with customers even being sent ITV Digital stickers to place over the existing ONdigital logos on their remote controls and set top boxes. The software running on the receivers was not changed though, and always displayed 'ON' on nearly every screen. A plan to change the onscreen software was planned along with a change to a stronger encryption system in Autumn 2002, however this never arose due to liquidation. The rebrand was not without controversy as SMG plc (owner of Scottish Television and Grampian Television), UTV and Channel Television all pointed out that the ITV brand did not belong solely to Carlton and Granada. SMG and UTV initially refused to carry the advertising campaign for ITV Digital and did not allow the ITV Sports Channel space on their multiplex, meaning that it was not available at launch in most of Scotland and Northern Ireland. The case was resolved in Scotland, and the Channel Islands and later still in Northern Ireland, allowing the ITV Sport Channel to launch in the non-Carlton and Granada regions (although it was never made available in the Channel Islands, as the islands did not have DTT or cable and it never appeared on Sky Digital).
Monkey.
ITV Digital also ran an advertising campaign involving the comedian Johnny Vegas as Al and a knitted monkey simply called Monkey, voiced by Ben Miller. A knitted replica of Monkey could be obtained by signing up to ITV Digital. Because the monkey could not be obtained without signing up to the service, a popular market for second-hand monkeys developed. At one time, original ITV Digital Monkeys were fetching several hundred pounds on eBay, and even knitting patterns delivered by email were sold for several pounds. The campaign was created by the advertising agency Mother. In early 2007, Monkey and Al reappeared in an advert for PG Tips tea, which included a reference to ITV Digital's downfall.
Administration and Freeview.
ITV Digital was placed into administration on 27 March 2002, after the Football League refused to accept a £130m pay cut in its £315m deal with the ITV Sport Channel. Most subscription channels ceased broadcasting on ITV Digital on 1 May 2002. The collapse on 30 June 2002 caused financial difficulties for lower-division football clubs who had budgeted for large incomes from the television contract. The Football League sued ITV Digital's parent companies, Carlton and Granada, claiming that the firms had breached their contract in failing to deliver the guaranteed income. And so, by the end of June 2002, the service ceased. The League lost the case, with the judge ruling that it had "failed to extract sufficient written guarantees". The League then filed a negligence claim against its lawyers for failing to press for a written guarantee at the time of the deal with ITV Digital. This time it was awarded a paltry £4 in damages of the £150m it was seeking.
A consortium made up of the BBC, BSkyB and Crown Castle International was granted ITV Digital's old broadcasting licence, and launched the Freeview service on 30 October 2002, offering 30 free-to-air TV channels and 20 free-to-air radio channels including several interactive channels such as BBCi (later rebranded as the BBC Red Button) and the now-defunct Teletext, but no subscription or premium services. Those followed on 31 March 2004 when Top Up TV began broadcasting 11 pay TV channels in timeshared broadcast slots.
During 2002, ITV Digital's liquidators started to ask customers to return their set top boxes or pay a £39.99 fee. Had this been successful it could have threatened to undermine the fledgling Freeview service, since at the time most digital terrestrial receivers were former ONdigital and ITV Digital units. Carlton and Granada stepped in and paid £2.8m to have the boxes stay with their customers, because at the time the ITV companies received a discount on their broadcasting licence payments based on the number of homes they had converted to digital television.
Following the administration in 2002, the three multiplexes that were run by ITV Digital remained blank until a week or so before Freeview's launch.
ITV Digital was based in the now-demolished Marco Polo House in Battersea, south London which was previously the headquarters of British Satellite Broadcasting, home to shopping TV channel QVC, and which had once housed The Observer newspaper. ITV Digital had call centres located in Pembroke Dock, Wales and in Plymouth, England, with other call centres outsourced to BT in Cork, Republic of Ireland and Belfast, Northern Ireland.
Set top boxes.
This is a list of ex-ITV and ONdigital set-top boxes. All boxes used similar software, in that a unified interface and design was used between all models. Top Up TV provided a small update in 2004 which upgraded minor technicalities with encryption services.
All these set top boxes (and some ONdigital branded IDTVs) become obsolete after the digital switchover (DSO), as post-DSO broadcasts utilise a newer 8k modulation scheme with which this earlier equipment is not compatible.
iDTVs.
ONdigital and ITVdigital could also be received with an Integrated Digital Television (iDTV) receiver. They used a conditional-access module (CAM) with a smart card, plugged into a DVB Common Interface slot in the back of the set.
Purchasers of iDTVs were given a substantially discounted price on using the ONdigital service, as there was no cost for a set-top box.
Some of the original iDTVs needed firmware upgrades to work with the CAM. For example, Sony sent technicians out to homes to make the necessary updates free of charge.
Carlton/Granada digital television channels.
Carlton and Granada (later ITV Digital Channels Ltd) created a selection of channels which formed some of the core content of channels available via the service, which were:

</doc>
<doc id="46132" url="https://en.wikipedia.org/wiki?curid=46132" title="Rennes">
Rennes

Rennes (; , Gallo: "Resnn", , ) is a city in the east of Brittany in northwestern France at the confluence of the Ille and the Vilaine. Rennes is the capital of the region of Brittany, as well as the Ille-et-Vilaine department.
Rennes's history goes back more than 2,000 years, at a time when it was a small Gallic village named Condate. Together with Vannes and Nantes, it was one of the major cities of the historic province of Brittany and the ancient Duchy of Brittany. After the French Revolution, Rennes remained for most of its history a parliamentary, administrative and garrison city of the Kingdom of France.
Since the 1950s, Rennes has grown in importance through rural flight and its modern industrial development, partly automotive. The city developed extensive building plans to accommodate upwards of 200,000 inhabitants. During the 1980s, Rennes became one of the main centres in telecommunication and high technology industry. It is now a significant digital innovation centre in France.
In 2015, the city is the tenth largest in France, with a metropolitan area of about 700,000 inhabitants. With more than 63,000 students in 2013, is also the eighth-largest university campus of France. The inhabitants of Rennes are called Rennais, Rennaise in French. In 2012, "l'Express" named Rennes as "the most liveable city in France".
History.
Overall significance.
Rennes is the administrative capital of the French department of Ille-et-Vilaine. Before the French Revolution, prior to the integration of the Duchy of Brittany into the Kingdom of France, Rennes was the capital of the duchy, with the other historical capitals of Brittany's Ducal period being Nantes and Vannes. It has a long history due to its location at the confluence of two rivers and its proximity to the bordering regions from which arose various challenges to the borders of Brittany.
Earliest history.
By the 2nd century BC the Gallic tribe known as the Redones had occupied a territory in eastern Brittany roughly equivalent to the modern department of Ille-et-Vilaine and had established their chief township at the confluence of the Ille and Vilaine rivers, the site of the modern city of Rennes. Although the tribe's name - from the Celtic root "red" cognate with "ride" suggesting the Redones were known for their horsemanship - would eventually default to their chief township ultimately yielding the name of the modern city of Rennes, the chief township of the Redones was contemporaneously referred to as "Condate" a Celtic term for confluence which was utilised to designate numerous towns in ancient Gaul.
Early in the 1st century BC, the Redones adopted the Greek and Roman practice of issuing coinage, adapting the widely imitated gold staters of Philip II of Macedon, in the characteristic Celtic coin metal alloy called billion. Without inscriptions, as the Celtic practice was, the Redones coinage features a charioteer whose pony has a human head. Large hoards of their coins were unearthed in the "treasure of Amanlis" found in June 1835 and that of Saint-Jacques-de-la-Lande, discovered in February 1941. The museum at Rennes contains a large representative collection.
In 57 BC the Redones joined the Gaulish coalition against Rome which was suppressed by Crassus. In 56 BC Roman emissaries were held hostage by the Redones causing Julius Caesar to intervene in Armorica suppressing the rebels, and the following year to cross the Channel to discourage further support of the Redones by the Britons. In 52 BC, the Redones responded to the call of Vercingetorix to furnish a large contingent of warriors.
Roman era.
It was subsequent to its Roman occupation that the chief township of the Redones became known as Condate Riedonum - alternately Civitas Riedonum - the second element, referring to the Redones tribe who had founded it, ultimately yielding the name of the modern city of Rennes. The oldest known Rennais is Titus Flavius Postuminus, known to us from his steles found in Rennes in 1969. As indicated by his name, he would have been born under the Flavian dynasty, under the reign of Titus, i.e. between 79 and 81 AD. One of the steles tells us, in Latin, that he took charge over all the public affairs in the Civitas Riedonum. He was twice duumvir and flamen for life for Mars Mullo.
During the Roman era, the strategic position of the town contributed to its importance. To the west the principal Roman route, via Osismii, stretched from Condate Riedonum to Vorgium (modern Carhaix).
In the year 275, the threat of barbarians led to the erection of a robust brick wall around Rennes. Threatened by the danger of the peasant marauders designated as "bagaudae" in the final days of the Roman Empire in the 5th century, the Armorican peninsula, including Brittany and therefore Rennes, constituted the last stronghold of the western Roman Empire with the Armorican Romans invincible against Clovis I, who occupied most of Alamans, then the Visigoths.
The Holy See of Rennes had been established by 453, with a church having occupied the site of the current Rennes Cathedral since the start of the 6th century.
One of the earliest bishops of Rennes: Melaine - who would become the city's patron saint - played an important role in the peace treaty between the Franks and the Armoricans in the year 497. He famously declared """" ("Peace must be made between Christians").
Middle Ages.
From the 5th century, Bretons occupied the western part of the Armorican peninsula, which was resultantly known as Brittany (i.e. Little Britain), while the Franks took the rest of Armorica. To contain the expansion and avoid Breton incursions, the Carolingians instituted a Breton March or frontier province, composed of the counties of Rennes, Nantes and Vannes. These marches were entirely absorbed by the Kingdom of Brittany in the 9th century, with Rennes becoming fully Breton in 851. Throughout Brittany's existence as an independent state - first as a kingdom and then as a duchy - Rennes generally was considered to be one of three cities acting as the territory's capital, the others being Nantes and Vannes, with Rennes Cathedral being the coronation site for the dukes of Brittany.
During the Breton War of Succession (1356–57) Rennes was laid siege to by Henry of Grosmont (duke of Lancaster), cousin of the English king, but Bertrand du Guesclin penetrated the city and commandeered the resistance with ultimate victory. After nearly a year, Lancaster abandoned the English siege in 1357.
In 1491, the French army of Charles VIII, led by General Louis II de la Trémoille, unsuccessfully attacked Rennes. Brittany having already capitulated elsewhere, Rennes alone resisted. The defenders of Rennes were determined to resist to the death, but the Duchess Anne of Brittany chose instead to negotiate. The resulting treaty of Rennes of 15 November 1491 dictated her marriage to Charles VIII and brought Brittany into the French kingdom. Anne zealously guarded Brittany's autonomy and the treaty promised that justice would continue to be dispensed according to practices, usages and customs maintained and observed heretofore. Furthermore, he promised the continuation of the Parlement of Brittany which met in February–April 1493, September 1494 and September 1495.
In 1720, a major fire destroyed all timber framing houses in the northern part of the city. The rebuilding was made of stone, on a grid plan.
Modern era.
In 1857, Rennes railway station was built, which gradually led to the southward sprawl of the town. In 1899, Alfred Dreyfus' second trial in Rennes caused a national sensation.
With several faculties of the University of Brittany having transferred from Nantes to Rennes beginning with the law school in 1730, the full-fledged University of Rennes began operation in 1885 (although it was not so named until 1896 rather being referred to as a "Conseil des facultés").
During the Second World War, Rennes suffered heavy damage from just three German aircraft which hit an ammunition train parked alongside French and British troop trains and near a refugee train on the yard: 1,000 died. The next day, 18 June 1940, German troops entered the city. Later, Rennes endured heavy bombing by the US and Royal Air Forces in March and May 1943, and again in June 1944, causing hundreds of deaths. Rennes contained a German transit POW camp and a POW hospital which contained many of the paratroopers captured on D-Day. Patton's army freed the capital of Brittany on 4 August, as retreating German troops blew up the bridges behind them, adding further damage. About 50,000 German prisoners were kept in four camps, in a city of only about 100,000 inhabitants at the time.
From 1954 onward, the city developed extensive building plans to accommodate upwards of 220,000 inhabitants, helping it become the second fastest-growing city in France, after Toulouse (1999 census).
Administration.
Rennes is divided into 11 cantons:
Since the 2008 cantonal elections, all eleven cantons are held by Socialists or their allies. The right held Rennes-Nord-Ouest until 2008.
Rennes is divided into 12 quarters:
Mayors.
The current mayor of Rennes is Nathalie Appéré. A member of the Socialist Party, she replaced retiring Socialist incumbent Daniel Delaveau, in office from 2008 to 2014.
Among previous well-known mayors are:
The "" ("city hall") is right in the centre of Rennes.
National representation.
The French Prison Service operates the "Centre pénitentiaire de Rennes", the largest women's prison in France.
Geography.
The ancient centre of the town is built on a hill, with the north side being more elevated than the south side. It is at the confluence of two rivers: the Ille and the Vilaine.
Rennes is located on the European atlantic arc, 50 km from the English Channel (near Saint-Malo, Dinard and Mont Saint-Michel).
Rennes has the distinction of having a significant Green Belt around its ring road. This Green Belt is a protected area between the city proper (rather dense) and the rest of its urban area (rather rural).
Climate.
Rennes features an oceanic climate with mild winters and warm summers. Precipitation in Rennes is considerably less abundant than in the western parts of Brittany, reaching only half of the levels of, e.g., the city of Quimper, which makes rainfall in Rennes comparable to the levels of larger parts of western Germany. Sunshine hours range between 1,700 and 1,850 annually, which is about the amount of sunshine received by the city of Lausanne.
Population.
In 2013, the inner population of the city was of 211,373 inhabitants, the Rennes intercommunal structure connecting Rennes with 42 nearby suburbs (named Rennes Métropole) counted 426,502 inhabitants and the metropolitan area counted 700,675 inhabitants.
Rennes has the second fastest-growing metropolitan area in France after Toulouse and before Montpellier, Bordeaux and Nantes.
The inhabitants of Rennes are called "Rennais" in French.
Sights.
Rennes is classified as a city of art and history.
Historic centre.
The historic centre is located on the former plan of the ramparts. There is a difference between the northern city centre and the southern city centre due to the 1720 fire, which destroyed most of the timber framed houses in the northern part of the city. The rebuilding was done in stone, on a grid plan. The southern part, the poorest at this time, was not rebuilt.
Due to the presence of the "parlement de Bretagne", many "hôtels particuliers" were built in the northern part, the richest in the 18th century. Most of the monuments historiques can be found there.
Colourful traditional half-timbered houses are situated primarily along the roads of Saint-Sauveur, Saint-Georges, de Saint-Malo, Saint-Guillaume, des Dames, du Chapitre, Vasselot, Saint-Michel, de la Psallette and around the plazas of Champ-Jacquet, des Lices, Saint-Anne and Rallier-du-Baty.
The Parlement de Bretagne and city hall area.
The "Parlement de Bretagne" (Administrative and judicial centre of Brittany, ) is the most famous 17th century building in Rennes. It was rebuilt after a terrible fire in 1994 that may have been caused by a flare fired by a protester during a demonstration. It houses the Rennes Court of Appeal. The plaza around is built on the classical architecture.
On the west, the Place de la Mairie (City Hall Plaza, Plasenn Ti Kêr) :
On the east, at the end of the "Rue Saint-Georges" with traditional half-timbered houses : 
On the south-east :
The Place des Lices and cathedral area.
The Place des Lices is lined by hôtels particuliers with the place Railler-du-Baty, is the location of the weekly big market, the marché des Lices.
Near the Rennes Cathedral (cathédrale Saint-Pierre de Rennes) is the Rue du Chapitre :
On this era are the former St. Yves chapel, now the tourism office and a museum about the historical development of Rennes and the Basilica Saint-Sauveur
Remains of the ramparts.
Built from the 3rd to the 12th centuries, the ramparts were largely destroyed between the beginning of the 16th century and the 1860s.
Place Saint-Anne area.
Place Saint-Anne (Plasenn Santez-Anna)
South-western, "La Rue Saint-Michel" nicknamed "Rue de La Soif" ("Road of Thirst") because there are bars all along this street.
South-eastern, the Champ-Jacquet square, with Renaissance buildings and a statue of mayor Jean Leperdit ripping up a conscription list.
East : Thabor park area.
Area of Saint-Melaine square
Jardin botanique du Thabor (formal French garden, orangerie, rose garden, aviary) a botanical garden on 10 hectares of land, built between 1860 and 1867.
17th century promenade "la Motte à Madame", and a monumental stairway overlooking the Rue de Paris entrance to the Thabor.
South city centre.
The south city centre is a mix of old buildings and 19th and 20th centuries constructions.
South of the Vilaine.
The Fine Arts Museum is situated on Quai Émile Zola, by the Vilaine River.
Les Champs Libres is a building on Esplanade Charles de Gaulle, and was designed by the architect Christian de Portzamparc. It houses the Brittany Museum (Musée de Bretagne), the regional library Bibliothèque de Rennes Métropole with six floors, and the Espace des Sciences science centre with a planetarium.
At Place Honoré Commeurec is Les Halles Centrales, a covered market from 1922, with one part converted into contemporary art gallery.
The Mercure Hotel is located in a restored building on Rue du Pré-Botté, which was the prior location of Ouest-Éclair, and then of Ouest-France, a premier daily regional newspaper.
There are large mills at Rue Duhamel, constructed on each side of the south branch of the Vilaine in 1895 and 1902.
Other sights.
To the northwest of Rennes, near Rue de Saint-Malo are the locks of the Canal d'Ille-et-Rance of 1843.
There are two halls of the printer, Oberthür, built by Marthenot between 1870 and 1895 on Rue de Paris in the eastern part of the city. Oberthür Park is the second biggest garden in the city.
The 17th century manor of Haute-Chalais, a granite château, is situated to the south of the city in Blosne Quarter (Bréquigny).
Parks and gardens.
Parc du Thabor contains a compact but significant botanical garden, the Jardin botanique du Thabor. The University of Rennes 1, with a campus in the city's eastern section, also contains a botanical garden and collections (the Jardin botanique de l'Université de Rennes).
Economy.
Local economy include car manufacturing, telecommunications, digital sector and agrofood.
PSA Peugeot Citroën, currently the largest private employer in the metropolitan area of Rennes, opened a manufacturing plant at La Janais in Chartres-de-Bretagne in 1961. The ITC firm Orange R&D (ex-France Telecom) is the second largest local employer with 3,800 people. Technicolor, one of the biggest firms in TV and cinema broadcasting in the world employs over 500 people.
In a few years, Rennes became one of the main centres in high technology industry and digital. The city hosts one of the first Technopoles established in France : Rennes Atalante witch employs over 20,000 people.
Rennes is the 2nd concentration of digital and ITC firms in France after Paris (with well-known companies and startups like Atos, SFR, Neosoft, Orange S.A., France Telecom, Envivio, Thomson Video Networks, Golaem, Technicolor R&D, Regionsjob, Capgemini, OVH, Dassault Systèmes, Delta Dore, Canon, Artefacto, Enensys Technologies, Astellia, Mitsubishi Electric R&D Europe, Digitaleo, Alcatel-Lucent, Kelbillet, Texas Instruments, NXP, Sopra Group, Niji, Thales, Nemeus or Logica). Rennes was one of the first French cities to receive the French Tech label in November 2014.
Moreover, Rennes hosts the 3rd public research potential in digital and ITC sectors in France, after Paris and Grenoble, with 3,000 people working in 10 laboratories, like well-known IRISA, IETR, IRMAR, DGA-MI (cyberdefense), SATIE, etc.
It is also the 3rd innovation potential in agrofood French industry with lots of firms in this field (Lactalis, Triballat Sojasun, Coralis, Panavi, Bridor, Claude Léger, Loïc Raison, Groupe Roullier, Sanders, etc.), an agro campus (Agrocampus Ouest) and a big international and professional expo, the Space (every year in September).
Other large firms located in Rennes include the restaurant conglomerate Groupe Le Duff (owners of Brioche Dorée, Bruegger's, La Madeleine, Mimi's Cafe, Timothy's World Coffee), the first French newspaper Ouest France (800,000 daily copies) and Samsic Service (cleanliness, industrial safety, job search, etc.).
Culture.
Rennes is known to be one of the most festive cities of France. It invests heavily in arts and culture and a number of its festivals (such as the music festival "Les Transmusicales", "Les Tombées de la Nuit", "Mythos", "The Stunfest" (a retro gaming festival) and "Travelling (a cinematic festival)") are well known throughout France. During the 80's, Rennes was often cited as the French town of rock ans new wave music.
Concerts hall.
Rennes is well equipped in musical facilities :
Museums and exhibitions places.
There are also five museums in Rennes:
In addition to this list, there is art facilities, such as "40mcube" exhibition space or the centre for contemporary art "La Criée".
There is also miscellaneous cultural places: the dance dedicated place the "Triange", two "Art et Essai" - art house cinemas - cinemas called "l'Arvor" and "Cine TNB". Remark that the surrounding citys house many other cultural places.
Media.
Rennes was one of the first towns in France to have its own local television channel 'TV Rennes', created in 1987.
Rennes has also local radio stations (Hit West, Radio Campus, Canal B, Radio Caroline, Radio Rennes, Radio Laser) and local newspapers or magazines (Ouest-France, Le Mensuel de Rennes, Place Publique, 20 Minutes Rennes).
Local culture.
Breton language.
In Brittany, two regional languages are spoken: Breton and Gallo. In and around Rennes, Gallo was traditionally spoken as a local language, but Breton has always been spoken by regional migrants coming from the western part of the region.
Nowadays, the Breton language is taught in one Diwan school, some bilingual public and Catholic schools, in evening courses, and in university.
The municipality launched a linguistic plan through Ya d'ar brezhoneg on 24 January 2008.
In 2008, 2.87% of primary school children were enrolled in bilingual primary schools, and the number of pupils enrolled in these schools is steadily growing.
Local food.
Specialties from Rennes include:
Many other Breton specialties (seafood, milk, vegetables, cheese, meat) are seen at the Marché des Lices, a weekly market held every Saturday morning (one of the most important markets in France).
Education.
The Rennes agglomeration has a large student population (around 63,000).
The city has two main universities; "Université de Rennes 1", which offers courses in science, technology, medicine, philosophy, law, management and economics and "Université Rennes 2", which has courses in the arts, literature, languages, communication, human and social sciences and sport. The official website of Université Rennes 2 identifies that facility as "the largest research and higher learning institution in Arts, Literature, Languages, Social Sciences and Humanities in the West of France."
There are a few "École Supérieures" in Rennes, like the "École Normale Supérieure de Cachan" (which has a branch on the Ker Lann campus, just outside Rennes), the "Institut d'études politiques de Rennes" or the ESC Rennes School of Business.
There is also branches of "École Supérieure d'Électricité" – Supélec and Telecom Bretagne in the east of the city (Cesson-Sévigné), a campus of the "École pour l'informatique et les nouvelles technologies" and the "grande école" Institut National des Sciences Appliquées, which is next to the "École Nationale Supérieure de Chimie de Rennes".
The computer science and applied mathematics research institute, IRISA, is located on the campus of the Université des Sciences, nearby Cesson-Sévigné. The "Délégation Générale pour l'Armement" (defence procurement agency) operates the CELAR research centre, dedicated to electronics and computing, in Bruz, a neighbouring town.
The city is also home to an American study abroad program for high school students, School Year Abroad, in which students are immersed in French culture through five classes in the language and a nine-month home stay.
The "École Compleméntaire Japonaise de Rennes" (レンヌ補習授業校 "Rennu Hoshū Jugyō Kō"), a part-time Japanese supplementary school, is held in the "Collège Anne de Bretagne" in Rennes.
Transport.
Rennes has well-developed national road, rail and air links.
Public transport.
Local transport is based primarily on an extensive bus network (65 lines) and a metro line that was inaugurated in March 2002 and cost €500 million to build. The driverless Rennes Metro (VAL) is in length and has 15 stations, including one designed by architect Norman Foster (La Poterie station). A second metro line is being planned, it should be operational by 2019, and the construction began in 2014.
Cycling.
Rennes provides other modes of local transport : a bike sharing system with 900 bicycles (named Vélostar). Rennes created the first system of modern French bike sharing (1998).
Roads.
The city is an important hub of Brittany's motorway network and is surrounded by a ring road : the Rocade (national road 136). The construction of the bypass was started in 1968 and completed in 1999. It is 31 km (18.5 mi) long, it has 2 lanes each way (sometimes 3 lanes) and toll free. Many other expressways are connected to the Rennes ring road for local and regional service. By road, Saint-Malo can be reached in 45 minutes, Nantes in 1 hour, Brest in 2 hours and 30 minutes, Paris in 4 hours, Bordeaux in 5 hours and Bruxelles in 6 hours and 30 minutes.
Railway.
Rennes has a major French railway station, the Gare de Rennes, opened in 1857. It is now two hours by TGV high speed train from Paris (this will be reduced to one hour and 30 minutes from 2017, after extension of the High Speed Rail Line). Train service is available to other big cities in France such as Lyon, Marseille, Lille and Strasbourg.
Rennes is also an important railway station for regional transport in Brittany. The TER Bretagne provide links to Saint-Malo, Nantes, Redon, Vitré, Saint-Brieuc, Vannes, Laval, Brest and many other regional cities. It is served by Gare station on the VAL Rennes Metro.
Airport.
Rennes is served by Rennes Brittany Airport (Saint-Jacques), located from the centre to the south-west in the commune Saint-Jacques-de-la-Lande.
It notably operates regular or seasonal flights to Paris-Charles de Gaulle, Lyon, Marseille, Nice, Toulouse, Barcelona, Palma de Mallorca, Rome-Fiumicino, Southampton, Dublin, Manchester, Amsterdam Schiphol (begins 2016), Madrid Barajas (begins 2016), Birmingham (begins 2016), London-City (begins 2016) and daily flights to London Southend Airport with Flybe.
International relations.
Twin towns – sister cities.
Rennes is twinned with:
"(These twinned towns are inscribed on the bridge over the central canal of Rennes)"
Within France
Pacts of cooperation
Sponsorship
In Rennes is also the only Institut Franco-Américain in France.

</doc>
<doc id="46133" url="https://en.wikipedia.org/wiki?curid=46133" title="Cardiomyopathy">
Cardiomyopathy

Cardiomyopathy (literally "heart muscle disease") is the measurable deterioration for any reason of the ability of the myocardium (the heart muscle) to contract, usually leading to heart failure. Common symptoms include dyspnea (breathlessness) and peripheral edema (swelling of the legs). Those with cardiomyopathy are often at risk of dangerous forms of irregular heart rate and sudden cardiac death.
The most common form of cardiomyopathy is dilated cardiomyopathy. Although the term "cardiomyopathy" could theoretically apply to almost any disease affecting the heart, it is usually reserved for "severe myocardial disease leading to heart failure." Cardiomyopathy and myocarditis resulted in 443,000 deaths in 2013, up from 294,000 in 1990.
Differential diagnosis.
Cardiomyopathies are either confined to the heart or are part of a generalized disorder, both often leading to death or progressive heart failure. Other diseases that cause heart muscle dysfunction are excluded, such as coronary artery disease, hypertension, or abnormalities of the heart valves.
Earlier, simpler, categories such as intrinsic, (defined as weakness of the heart muscle without an identifiable external cause), and extrinsic, (where the primary pathology arose outside the myocardium itself), became more difficult to sustain. 
For example, as more external causes were recognized, the intrinsic category became smaller. Alcoholism, for example, has been identified as a cause of dilated cardiomyopathy, as has drug toxicity, and certain infections (including Hepatitis C). On the other hand, molecular biology and genetics have given rise to the recognition of various genetic causes, increasing the intrinsic category. For example, mutations in the cardiac desmosomal genes as well as in the DES gene may cause arrhythmogenic right ventricular cardiomyopathy (ARVC).
At the same time, a more clinical categorization of cardiomyopathy as 'hypertrophied', 'dilated', or 'restrictive', became difficult to maintain when it became apparent that some of the conditions could fulfill more than one of those three categories at any particular stage of their development. The current American Heart Association definition divides cardiomyopathies into primary, which affect the heart alone, and secondary, which are the result of illness affecting other parts of the body. These categories are further broken down into subgroups which incorporate new genetic and molecular biology knowledge.
Types.
Cardiomyopathies can be classified using different criteria:
Mechanism.
Symptoms may include shortness of breath after physical exertion, fatigue, and swelling of the feet, legs, or abdomen. Additionally, arrhythmias and chest pain may be present.
The pathophysiology of cardiomyopathies is better understood at the cellular level with advances in molecular techniques. Mutant proteins can disturb cardiac function in the contractile apparatus (or mechanosensitive complexes). Cardiomyocyte alterations and their persistent responses at the cellular level cause changes that are correlated with sudden cardiac death and other cardiac problems.
Diagnosis.
Among the diagnostic procedures done to determine a cardiomyopathy are:
Treatment.
Treatment may include suggestion of lifestyle changes to better manage the condition. Treatment depends on the type of cardiomyopathy and condition of disease, but may include medication (conservative treatment) or iatrogenic/implanted pacemakers for slow heart rates, defibrillators for those prone to fatal heart rhythms, ventricular assist devices (VADs) for severe heart failure, or ablation for recurring dysrhythmias that cannot be eliminated by medication or mechanical cardioversion. The goal of treatment is often symptom relief, and some patients may eventually require a heart transplant.

</doc>
<doc id="46134" url="https://en.wikipedia.org/wiki?curid=46134" title="Robert Bylot">
Robert Bylot

Robert Bylot was a 17th-century explorer who made four voyages to the Arctic. He was uneducated and from a working-class background, but was able to rise to rank of Master in the British Royal Navy.
"1610 with Hudson:" Bylot was first mate on Henry Hudson's ship "Discovery", during Hudson's 1610-1611 expedition into what is now known as Hudson Bay. In the spring of 1611, Hudson wanted to continue the expedition, but the crew wanted to return home. There was discontent between the Captain (Hudson) and members of the crew, Bylot was stripped of his rank. Later there was a mutiny in which Hudson, his son and several sailors were set adrift in an open boat. It was due to Bylot's navigational skills that the ship was able to return from the Arctic safely. Upon return to England, Bylot was tried as a mutineer but was pardoned.
"1612 with Button:" Bylot returned to Hudson Bay in 1612 with Sir Thomas Button. They wintered over at the mouth of the Nelson River, and in the spring of 1613 continued north. They were able to reach latitude 65°, then returned to England.
"1615:" In 1615, the Muscovy Company hired Bylot to find the Northwest Passage as captain of the "Discovery". He sailed west from Hudson Strait and was blocked by ice at Frozen Strait.
"1616 with Baffin:" The following year (1616), the Muscovy Company again hired Bylot to continue to search for the Northwest Passage. This time he was accompanied by pilot William Baffin. The Bylot-Baffin voyage resulted in several notable achievements. First was the circumnavigation and mapping of what is now called Baffin Bay. Second was the discovery of Smith Sound, by which the North Pole would eventually be reached. Third was the discovery of Lancaster Sound, through which the Northwest Passage would eventually be found three centuries later. Fourth, and perhaps most significantly, they were able to reach 77° 45' North latitude, a record which held for 236 years.
Bylot and Baffin's work in Baffin Bay was doubted by cartographers back in England. As late as 1812, charts of the area only showed a dotted bulge with the words: "Baffin's Bay according to the relation of W. Baffin in 1616, but not now believed". When the bay was "rediscovered" by Sir John Ross in 1818, the records of the Bylot-Baffin voyage proved extremely accurate. In England, almost total credit for the discovery was given to Baffin, and Bylot was virtually ignored. Historian Farley Mowat has speculated two possible reasons for this: Bylot's lack of education and lower position relative to Baffin in English society, and his involvement in the mutiny during Hudson's expedition.
Bylot Island, one of the more dramatic of the Arctic Islands, was named after him.

</doc>
<doc id="46135" url="https://en.wikipedia.org/wiki?curid=46135" title="George Lakoff">
George Lakoff

George P. Lakoff (, born May 24, 1941) is an American cognitive linguist, best known for his thesis that lives of individuals are significantly influenced by the central metaphors they use to explain complex phenomena.
The metaphor thesis, introduced in his 1980 book "Metaphors We Live By" has found applications in a number of academic disciplines and its application to politics, literature, philosophy and mathematics has led him into territory normally considered basic to political science. In the 1996 book "Moral Politics", Lakoff described conservative voters as being influenced by the "strict father model" as a central metaphor for such a complex phenomenon as the state and liberal/progressive voters as being influenced by the "nurturant parent model" as the folk psychological metaphor for this complex phenomenon. According to him, an individual's experience and attitude towards sociopolitical issues is influenced by being framed in linguistic constructions. In "Metaphor and War: The Metaphor System Used to Justify War in the Gulf", he argues that the American involvement in the Gulf war was obscured or "spun" by the metaphors which were used by the first Bush administration to justify it. Between 2003 and 2008, Lakoff was involved with a progressive think tank, the now defunct Rockridge Institute. He is a member of the scientific committee of the Fundación IDEAS (IDEAS Foundation), Spain's Socialist Party's think tank.
The more general theory that elaborated his thesis is known as embodied mind. He is a professor of linguistics at the University of California, Berkeley, where he has taught since 1972.
Work.
Reappraisal of metaphor.
Although some of Lakoff's research involves questions traditionally pursued by linguists, such as the conditions under which a certain linguistic construction is grammatically viable, he is most famous for his reappraisal of the role that metaphors play in socio-political lives of humans.
Metaphor has been seen within the Western scientific tradition as purely a linguistic construction. The essential thrust of Lakoff's work has been the argument that metaphors are primarily a conceptual construction, and indeed are central to the development of thought.
He suggested that: 
Non-metaphorical thought is for Lakoff only possible when we talk about purely physical reality. For Lakoff the greater the level of abstraction the more layers of metaphor are required to express it. People do not notice these metaphors for various reasons. One reason is that some metaphors become 'dead' and we no longer recognize their origin. Another reason is that we just don't "see" what is "going on".
For instance, in intellectual debate the underlying metaphor is usually that argument is war (later revised as "argument is struggle"):
For Lakoff, the development of thought has been the process of developing better metaphors. The application of one domain of knowledge to another domain of knowledge offers new perceptions and understandings.
Linguistics wars.
Lakoff began his career as a student and later a teacher of the theory of transformational grammar developed by Massachusetts Institute of Technology professor Noam Chomsky. In the late 1960s, however, he joined with others to promote generative semantics as an alternative to Chomsky's generative syntax. In an interview he stated:
Lakoff's claim that Chomsky asserts independence between syntax and semantics has been rejected by Chomsky, who has given examples from within his work where he talks about the relationship between his semantics and syntax. Chomsky goes further and claims that Lakoff has "virtually no comprehension of the work he is discussing" (the work in question being Chomsky's). His differences with Chomsky contributed to fierce, acrimonious debates among linguists that have come to be known as the "linguistics wars".
Embodied mind.
When Lakoff claims the mind is "embodied", he is arguing that almost all of human cognition, up through the most abstract reasoning, depends on and makes use of such concrete and "low-level" facilities as the sensorimotor system and the emotions. Therefore, embodiment is a rejection not only of dualism vis-a-vis mind and matter, but also of claims that human reason can be basically understood without reference to the underlying "implementation details".
Lakoff offers three complementary but distinct sorts of arguments in favor of embodiment. First, using evidence from neuroscience and neural network simulations, he argues that certain concepts, such as color and spatial relation concepts (e.g. "red" or "over"; see also "qualia"), can be almost entirely understood through the examination of how processes of perception or motor control work.
Second, based on cognitive linguistics' analysis of figurative language, he argues that the reasoning we use for such abstract topics as warfare, economics, or morality is somehow rooted in the reasoning we use for such mundane topics as spatial relationships. (See conceptual metaphor.)
Finally, based on research in cognitive psychology and some investigations in the philosophy of language, he argues that very few of the categories used by humans are actually of the black-and-white type amenable to analysis in terms of necessary and sufficient conditions. On the contrary, most categories are supposed to be much more complicated and messy, just like our bodies.
"We are neural beings," Lakoff states, "Our brains take their input from the rest of our bodies. What our bodies are like and how they function in the world thus structures the very concepts we can use to think. We cannot think just anything — only what our embodied brains permit."
Lakoff believes consciousness to be neurally embodied, however he explicitly states that the mechanism is not just neural computation alone. Using the concept of disembodiment, Lakoff supports the physicalist approach to the afterlife. If the soul can not have any of the properties of the body, then Lakoff claims it can not feel, perceive, think, be conscious, or have a personality. If this is true, then Lakoff asks what would be the point of the afterlife? 
Many scientists share the belief that there are problems with falsifiability and foundation ontologies purporting to describe "what exists", to a sufficient degree of rigor to establish a reasonable method of empirical validation. But Lakoff takes this further to explain why hypotheses built with complex metaphors cannot be directly falsified. Instead, they can only be rejected based on interpretations of empirical observations guided by other complex metaphors. This is what he means when he says that falsifiability itself can never be established by any reasonable method that would not rely ultimately on a shared human bias. The bias he's referring to is the set of conceptual metaphors governing how people interpret observations.
Lakoff is, with coauthors Mark Johnson and Rafael E. Núñez, one of the primary proponents of the embodied mind thesis. Lakoff discussed these themes in his 2001 Gifford Lectures at the University of Glasgow, published as "The Nature and Limits of Human Understanding". Others who have written about the embodied mind include philosopher Andy Clark (See his Being There), philosopher and neurobiologists Humberto Maturana and Francisco Varela and his student Evan Thompson (See Varela, Thompson & Rosch's "The Embodied Mind"), roboticists such as Rodney Brooks, Rolf Pfeifer and Tom Ziemke, the physicist David Bohm (see his "Thought As A System"), Ray Gibbs (see his "Embodiment and Cognitive Science"), John Grinder and Richard Bandler in their neuro-linguistic programming, and Julian Jaynes. The work of these writers can be traced back to earlier philosophical writings, most notably in the phenomenological tradition, such as Maurice Merleau-Ponty and Heidegger. The basic thesis of "embodied mind" is also traceable to the American contextualist or pragmatist tradition, notably John Dewey in such works as "Art As Experience."
Mathematics.
According to Lakoff, even mathematics is subjective to the human species and its cultures: thus "any question of math's being inherent in physical reality is moot, since there is no way to know whether or not it is." By this, he is saying that there is nothing outside of the thought structures we derive from our embodied minds that we can use to "prove" that mathematics is somehow beyond biology. Lakoff and Rafael E. Núñez (2000) argue at length that mathematical and philosophical ideas are best understood in light of the embodied mind. The philosophy of mathematics ought therefore to look to the current scientific understanding of the human body as a foundation ontology, and abandon self-referential attempts to ground the operational components of mathematics in anything other than "meat".
Mathematical reviewers have generally been critical of Lakoff and Núñez, pointing to mathematical errors . Lakoff claims that these errors have been corrected in subsequent printings . Although their book attempts a refutation of some of the most widely accepted viewpoints in philosophy of mathematics and advice for how the field might proceed, they have yet to elicit much of a reaction from philosophers of mathematics themselves. The small community specializing in the psychology of mathematical learning, to which Núñez belongs, is paying attention.
Lakoff has also claimed that we should remain agnostic about whether math is somehow wrapped up with the very nature of the universe. Early in 2001 Lakoff told the American Association for the Advancement of Science (AAAS): "Mathematics may or may not be out there in the world, but there's no way that we scientifically could possibly tell." This is because the structures of scientific knowledge are not "out there" but rather in our brains, based on the details of our anatomy. Therefore, we cannot "tell" that mathematics is "out there" without relying on conceptual metaphors rooted in our biology. This claim bothers those who believe that there really is a way we could "tell". The falsifiability of this claim is perhaps the central problem in the cognitive science of mathematics, a field that attempts to establish a foundation ontology based on the human cognitive and scientific process.
Political significance and involvement.
Lakoff has publicly expressed both ideas about the conceptual structures that he views as central to understanding the political process, and some of his particular political views. He almost always discusses the latter in terms of the former.
"Moral Politics" (1996, revisited in 2002) gives book-length consideration to the conceptual metaphors that Lakoff sees as present in the minds of American "liberals" and "conservatives". The book is a blend of cognitive science and political analysis. Lakoff makes an attempt to keep his personal views confined to the last third of the book, where he explicitly argues for the superiority of the liberal vision.
Lakoff argues that the differences in opinions between liberals and conservatives follow from the fact that they subscribe with different strength to two different central metaphors about the relationship of the state to its citizens. Both, he claims, see governance through metaphors of the family. Conservatives would subscribe more strongly and more often to a model that he calls the "strict father model" and has a family structured around a strong, dominant "father" (government), and assumes that the "children" (citizens) need to be disciplined to be made into responsible "adults" (morality, self-financing). Once the "children" are "adults", though, the "father" should not interfere with their lives: the government should stay out of the business of those in society who have proved their responsibility. In contrast, Lakoff argues that liberals place more support in a model of the family, which he calls the "nurturant parent model", based on "nurturant values", where both "mothers" and "fathers" work to keep the essentially good "children" away from "corrupting influences" (pollution, social injustice, poverty, etc.). Lakoff says that most people have a blend of both metaphors applied at different times, and that political speech works primarily by invoking these metaphors and urging the subscription of one over the other.
Lakoff further argues that one of the reasons liberals have had difficulty since the 1980s is that they have not been as aware of their own guiding metaphors, and have too often accepted conservative terminology framed in a way to promote the strict father metaphor. Lakoff insists that liberals must cease using terms like "partial birth abortion" and "tax relief" because they are manufactured specifically to allow the possibilities of only certain types of opinions. "Tax relief" for example, implies explicitly that taxes are an affliction, something someone would want "relief" from. To use the terms of another metaphoric worldview, Lakoff insists, is to unconsciously support it. Liberals must support linguistic think tanks in the same way that conservatives do if they are going to succeed in appealing to those in the country who share their metaphors.
Between 2003 and 2008, Lakoff was involved with a progressive think tank, the Rockridge Institute, an involvement that follows in part from his recommendations in "Moral Politics". Among his activities with the Institute, which concentrates in part on helping liberal candidates and politicians with re-framing political metaphors, Lakoff has given numerous public lectures and written accounts of his message from "Moral Politics." In 2008, Lakoff joined Fenton Communications, the nation's largest public interest communications firm, as a Senior Consultant.
One of his political works, "Don't Think of an Elephant! Know Your Values and Frame the Debate", self-labeled as "the Essential Guide for Progressives", was published in September 2004 and features a foreword by former Democratic presidential candidate Howard Dean.
Disagreement with Steven Pinker.
In 2006 Steven Pinker wrote an unfavorable review of Lakoff's book "Whose Freedom? The Battle over America's Most Important Idea". Pinker's review was published in "The New Republic". Pinker argued that Lakoff's propositions are unsupported and his prescriptions are a recipe for electoral failure. He wrote that Lakoff was condescending and deplored Lakoff's "shameless caricaturing of beliefs" and his "faith in the power of euphemism". Pinker portrayed Lakoff's arguments as "cognitive relativism, in which mathematics, science, and philosophy are beauty contests between rival frames rather than attempts to characterize the nature of reality". Lakoff wrote a rebuttal to the review stating that his position on many matters is the exact reverse of what Pinker attributes to him. Lakoff explicitly rejected, for example, the cognitive relativism and faith in euphemism described above, arguing in favor of a deeper understanding of rationality that discards the modal logic conceptualization of rationality in favor of the better supported framing conceptualization.

</doc>
<doc id="46136" url="https://en.wikipedia.org/wiki?curid=46136" title="The Football Association">
The Football Association

The Football Association, also known simply as The FA, is the governing body of association football in England, and the Crown dependencies of Jersey, Guernsey and the Isle of Man. Formed in 1863, it is the oldest football association in the world and is responsible for overseeing all aspects of the amateur and professional game in its territory.
The FA sanctions all competitive football matches within its remit at national level, and indirectly at local level through the County Football Associations. It runs numerous competitions, the most famous of which is the FA Cup. It is also responsible for appointing the management of the men's, women's and youth national football teams.
The FA is a member of both UEFA and FIFA and holds a permanent seat on the International Football Association Board (IFAB) which is responsible for the laws of the game. As the first football association, it does not use the national name "English" in its title. The FA is based at Wembley Stadium, London. The FA is a member of the British Olympic Association, meaning that the FA has control over the men's and women's Great Britain Olympic football team.
All of England's professional football teams are members of the Football Association. Although it does not run the day-to-day operations of the Premier League, it has veto power over the appointment of the League Chairman and Chief Executive and over any changes to league rules. The Football League, made up of the three fully professional divisions below the Premier League, is self-governing.
History.
For centuries before the first meeting of the Football Association in The Freemasons' Tavern on Great Queen Street, London on 26 October 1863, there were no universally accepted rules for playing football. In each public school the game was formalised according to local conditions; but when the schoolboys reached university, chaos ensued when the players used different rules, so members of the University of Cambridge devised and published a set of Cambridge Rules in 1848 which was widely adopted. Another set of rules, the Sheffield Rules, was used by a number of clubs in the North of England from the 1850s.
Eleven London football clubs and schools representatives met on 26 October 1863 to agree on common rules. The founding clubs present at the first meeting were Barnes, Civil Service, Crusaders, Forest of Leytonstone (later to become Wanderers), N.N. (No Names) Club (Kilburn), the original Crystal Palace, Blackheath, Kensington School, Perceval House (Blackheath), Surbiton and Blackheath Proprietary School; Charterhouse sent their captain, B.F. Hartshorne, but declined the offer to join. Many of these clubs are now defunct or play rugby union. Civil Service FC, who now plays in the Southern Amateur League, is the only one of the original eleven football clubs still in existence.
Central to the creation of the Football Association and modern football was Ebenezer Cobb Morley. He was a founding member of the Football Association in 1863. In 1862, as captain of Barnes, he wrote to "Bell's Life" newspaper proposing a governing body for the sport that led to the first meeting at The Freemasons' Tavern that created the FA. He was the FA's first secretary (1863–66) and its second president (1867–74) and drafted the Laws of the Game generally called the "London Rules" at his home in Barnes, London. As a player, he played in the first ever match in 1863.
The first version of the rules for the modern game was drawn up over a series of six meetings held in The Freemasons' Tavern from October till December. At the final meeting, F. M. Campbell, the first FA treasurer and the Blackheath representative, withdrew his club from the FA over the removal of two draft rules at the previous meeting, the first which allowed for the running with the ball in hand and the second, obstructing such a run by hacking (kicking an opponent in the shins), tripping and holding. Other English rugby clubs followed this lead and did not join the FA but instead in 1871 formed the Rugby Football Union. The term "soccer" dates back to this split to refer to football played under the "association" rules.
An inaugural game using the new FA rules was initially scheduled for Battersea Park on 2 January 1864, but enthusiastic members of the FA could not wait for the new year and an experimental game was played at Mortlake on 19 December 1863 between Morley's Barnes team and their neighbours Richmond (who were not members of the FA), ending in a goalless draw. The Richmond side were obviously unimpressed by the new rules in practice because they subsequently helped form the Rugby Football Union in 1871. The Battersea Park game was postponed for a week, and the first exhibition game using FA rules was played there on Saturday 9 January 1864. The members of the opposing teams for this game were chosen by the President of the FA (A. Pember) and the Secretary (E. C. Morley) and included many well-known footballers of the day.
After the first match according to the new FA rules a toast was given "Success to football, irrespective of class or creed".
Charles Alcock (of Harrow School) of the Wanderers was elected to the committee of the FA in 1866, becoming its first full-time secretary and treasurer in 1870. He masterminded the creation of the Football Association Cup—the longest-running association football competition in the world—in 1871. Fifteen participating clubs subscribed to purchase a trophy. The very first Cup Final was held at The Oval on 16 March 1872, fought between the Wanderers and the Royal Engineers (RE), watched by 2,000 spectators.
This competition was initially contested by mostly amateur teams but by the end of the 19th century it was dominated by professional teams that were mostly members of the Football League that had been founded in 1888 and expanded during the 1890s.
After many years of wrangling between the London Association and the Sheffield Football Association, the FA Cup brought the acceptance that one undisputed set of laws was required. The two associations had played 16 inter-association matches under differing rules; the Sheffield Rules, the London Rules and Mixed Rules. In April 1877, those laws were set with a number of Sheffield Rules being incorporated.
In 1992, the Football Association took control of the newly created Premier League which consisted of 22 clubs who had broken away from the First Division of the Football League. The Premier League reduced to 20 clubs in 1995 and is one of the richest football leagues in the world.
The Football Association celebrated their 150th year by changing their logo. The new logo has retained the current logo's three lions but it would be in golden colour and also have "The FA" written above and also have "1863 150 years 2013" written below. It also has some writings of the laws of the game penned at the first meeting held at The Freemasons' Tavern.
Crown dependencies.
The Football Associations within the Crown dependencies Jersey (Jersey Football Association), Guernsey (Guernsey Football Association) and the Isle of Man (Isle of Man Football Association) are affiliated to the Football Association despite having a separate identity from that of the United Kingdom and by extension England. They are considered County Football Associations by the Football Association. Matt Le Tissier and Graeme Le Saux have represented The Football Associations' full national representative team and were born in Guernsey and Jersey respectively.
The Guernsey Football Association, Isle of Man Football Association and Jersey Football Association have been affiliated with the Football Association since 1903, 1908 and 1905 respectively.
The British Overseas Territory of Gibraltar's Gibraltar Football Association were affiliated the Football Association from 1911 until they opted to become a fully recognised member of UEFA, a feat achieved after a 14-year legal battle. Joseph Nunez, the Gibraltar FA President claimed they were "unilaterally thrown out" of the FA following an intervention from Geoff Thompson.
A loophole was closed in May 2008 by FIFA which allowed players born in the Channel Islands to choose which nation belonging to the United Kingdom to present at international level. During the 1990s, Trevor Wood (Jersey) and Chris Tardif (Guernsey) represented Northern Ireland.
Relationship with FIFA.
The Football Association first joined FIFA in 1905. The "British Associations" (England, Ireland, Scotland and Wales) opted to leave FIFA after World War I after FIFA chose not to exclude those who were part of the Central Powers from the organisation. The British Associations' stance had changed by 1922 and in 1924 they had rejoined FIFA.
The British Olympic Association had fought against 'broken time' - monetary compensation for athletes' earnings when competing in the Olympic games. At the 1925 Olympic Congress in Prague, the British had made an amendment that concluded governing federations should define amateur status for their sports but only in accordance with the definition of amateurism accepted by the Olympic Congress. In 1928, Switzerland proposed to FIFA that in certain circumstances, 'broken time' payments should be allowed and FIFA accepted. The FA resigned from FIFA in protest against the proposal. As a result of The FA's resignation, England did not participate in the 1930, 1934 or 1938 FIFA World Cup.
At the 1930 Olympic Congress in Berlin, Belgian delegates proposed that for each sport the definition of amateur status be left to its international federation. The BOA argued for a common definition of amateurism and argued that 'broken time' payments were against the Olympic ideal.
The FA rejoined FIFA in 1946 and participated in their first World Cup in 1950. One of the first actions of the Football Association was to request the expulsion of the German and Japanese national football associations for their countries' role in World War II. Germany and Japan were prevented from qualifying for the 1950 FIFA World Cup as a consequence. They were re-acquainted with FIFA in 1950 following a second request from Switzerland who had a previous request rejected in 1948.
Finances.
The FA's main commercial asset is its ownership of the rights to England internationals and the FA Cup. Turnover for the year ending 31 December 2008 was £261.8 million. on which it made an operating profit of £16.6 million and loss before tax of £15.3 million. The loss was attributable to £39.6 million of interest payable and similar charges, principally relating to the cost of constructing the new Wembley Stadium, opened in 2006, which the FA owns via its subsidiary Wembley National Stadium Limited. For the 4 seasons from 2008 to 2012, the FA has secured £425 million from ITV and Setanta for England and FA Cup games domestic television rights, a 42% increase over the previous contract, and £145 million for overseas television rights, up 272% on the £39 million received for the previous four-year period. However, during 2008–09 Setanta UK went into administration, which weakened the FA's cashflow position.
The FA's income does not include the turnover of English football clubs, which are independent businesses. As well as running its own operations the FA chooses five charities each year to which it gives considerable financial support.
During the last three years, The FA received £350,000 in fines from players over comments made on Twitter, the most recent fine being a £25,000 to Rio Ferdinand. The highest fine given during the last three years was a £90,000 fine to Ashley Cole in 2012 after calling The FA "a bunch of twats." The FA has been more and more strict on comments made by players on Twitter, as The FA has disciplined 121 players overall in the last three years.
Competitions.
The FA also runs several competitions:
Principals.
The FA has a figurehead President, since 1939, who is always a member of the British Royal Family. The Chairman of the FA has overall responsibility for policy. Traditionally this person rose through the ranks of the FA's committee structure (e.g. by holding posts such the chairmanship of a county football association). In 2008 the politician David Triesman was appointed as the FA's first "independent chairman", that is the first from outside the football hierarchy. The day to day head of the FA was known as the Secretary until 1989, when the job title was changed to Chief Executive.
Board of directors.
None of the FA board of directors has ever played football professionally.
Taken from thefa.com website on 2014-08-06
Chief Executive: Martin Glenn
Roger Burden (Gloucestershire FA)†
"Key:"
† = National Game Representative
‡ = Premier League Representative

</doc>
<doc id="46137" url="https://en.wikipedia.org/wiki?curid=46137" title="Rafael E. Núñez">
Rafael E. Núñez

Rafael E. Núñez is a professor of cognitive science at the University of California, San Diego and a proponent of embodied cognition. He co-authored "Where Mathematics Comes From" with George Lakoff.

</doc>
<doc id="46138" url="https://en.wikipedia.org/wiki?curid=46138" title="Sicherheitsdienst">
Sicherheitsdienst

Sicherheitsdienst (), full title Sicherheitsdienst des Reichsführers-SS (), or SD, was the intelligence agency of the SS and the Nazi Party in Nazi Germany. The organization was the first Nazi Party intelligence organization to be established and was considered a sister organization with the Gestapo, which the SS had infiltrated heavily after 1934. Between 1933 and 1939, the SD was administered as an independent SS office, after which it was transferred to the authority of the Reich Main Security Office ("Reichssicherheitshauptamt"; RSHA), as one of its seven departments/offices. Its first director, Reinhard Heydrich, intended for the SD to bring every single individual within the Third Reich's reach under "continuous supervision."
Following Germany's defeat in World War II, the SD was declared a criminal organisation at the Nuremberg Trials, along with the rest of Heydrich's RSHA (including the Gestapo) both individually and as branches of the SS in the collective. Heydrich's successor, Ernst Kaltenbrunner, was sentenced to death for war crimes at the Nuremberg Tribunals and hanged in 1946.
History.
The SD was one of the oldest security organizations of the SS and was first formed in 1931 as the "Ic-Dienst", operating out of a single apartment and reporting directly to Heinrich Himmler. Himmler appointed a former naval officer, Reinhard Heydrich, to organise the small agency. The office was renamed "Sicherheitsdienst" (SD) in the summer of 1932. The SD became more powerful after the Nazis took control of Germany and the SS started infiltrating all leading positions of the security apparatus of the Reich. Even before Hitler came to power, the SD was a veritable "watchdog" over the SS and members of the Nazi Party and played a critical role in consolidating political police powers into the hands of Himmler and Heydrich.
Growth of SD and SS power.
Once Hitler was appointed Chancellor by German President, Paul von Hindenburg, he quickly made efforts to manipulate the aging president. On 28 February 1933, Hitler convinced Hindenburg to declare a state of emergency which suspended all civil liberties throughout Germany, due at least in part to the Reichstag fire the night before, assuring Hindenburg throughout that he was attempting to stabilize the tumultuous political scene in Germany by taking a "defensive measure against Communist acts of violence endangering the state." Wasting no time, Himmler set the SD in motion as they began creating an extensive card index of the Nazi regime's political opponents, arresting labor organizers, socialists, Jewish leaders, journalists, and communists in the process, sending them to their new prison facility near Munich, Dachau. Himmler's SS and SD made their presence felt at once by helping rid the regime of its known political enemies and its perceived ones, as well. As far as Heydrich and Himmler were concerned, the SD left their mission somewhat vaguely defined so as to "remain an instrument for all eventualities." One of those eventualities would soon arise.
For a while, the SS was in ‘competition’ with the "Sturmabteilung" (SA) for influence within the Third Reich. Himmler distrusted the SA and came to deplore the ‘rabble-rousing’ brownshirts (despite once having been a member) and what they considered to be the indecent sexual deviants amid its leadership. At least one pretext to secure additional influence for Himmler's SS and Heydrich's SD in "protecting" Hitler and securing his absolute trust in their intelligence collection abilities involved thwarting a plot from Ernst Roehm's SA using subversive means.
On 20 April 1934 Hermann Göring handed over control of the Gestapo to Himmler. Heydrich, named chief of the Gestapo by Himmler on 22 April 1934, also continued as head of the SD. These events further extended Himmler’s control of the security mechanism of the Reich, which by proxy also strengthened the surveillance power of Heydrich’s SD, as both entities methodically infiltrated every police agency in Germany. Thereafter, the SD was made the sole "Party information service" on 9 June 1934.
Under pressure from the "Reichswehr" (German armed forces) leadership, whose members viewed the enormous armed forces of the SA as an existential threat and with the collusion of Göring, Joseph Goebbels, the Gestapo and SD, Hitler was led to believe that Roehm’s SA posed a serious conspiratorial threat requiring a drastic and immediate solution. For its part, the SD provided fictitious information that there was an assassination plot on Hitler’s life and that an SA putsch to assume power was imminent since they were allegedly amassing weapons. Additionally, reports were coming in to the SD and Gestapo that the vulgarity of the SA's behavior was damaging the party and was even making antisemitism less palatable. In what became known as the Night of the Long Knives, the SS took one of its most decisive steps in eliminating its competition for command of security within the Third Reich and established itself firmly in the Nazi hierarchy, making the SS and its intelligence organ, the SD, responsible only to the Führer. Moreover, the brutal crushing of the SA and its leadership sent a clear message to everyone that opposition to Hitler’s regime could be deadly. In many ways, it struck fear across the Nazi leadership and a tangible concern about the reach and influence of Himmler’s intelligence collection and policing powers since not only had the SA’s chief been murdered, but numerous party functionaries and “opponents” had been eliminated in the action based on an extensive list which Hitler only saw after the event.
The SD and Austria.
During the autumn of 1937, Hitler secured Mussolini’s support to annex Austria (Mussolini was originally apprehensive of the Nazi takeover of Austria) and informed his generals of his intentions to invade both Austria and Czechoslovakia. Getting Mussolini to approve political intrigue against Austria was a major accomplishment as the Italian leader had expressed great concern previously in the wake of an Austrian SS unit’s attempt to stage a coup not more than three weeks after the Röhm affair; an episode that embarrassed the SS, enraged Hitler, and which ended in the assassination of Austrian Chancellor Engelbert Dollfuss. Nonetheless, to facilitate the incorporation of Austria into the greater Reich, the SD and Gestapo went to work arresting people right away using lists compiled by Heydrich. Heydrich’s SD and Austrian SS members received financing from Berlin to harass Austrian Chancellor von Schuschnigg’s government all throughout 1937. One section of the SD that was nothing more than a front for subversive activities against Austria, ironically promoted “German-Austrian peace.”
Throughout the events leading to the "Anschluß" and even after the Nazis marched into Austria, Heydrich - convinced that only his SD could pull off a peaceful union between the two German-speaking nations - organized demonstrations, conducted clandestine operations, ordered terror attacks, distributed propaganda materials, encouraged the intimidation of opponents, and had his SS and SD personnel round-up prominent anti-Nazis, most of whom ended up in Mauthausen concentration camp. Through the coordinated efforts of the SiPo and Heydrich's SD during the first days of the "Anschluß", all forms of possible political, military and economic resistance within Austria were effectively eliminated. Once the "Anschluß" was official, the Austrian police was immediately subordinated to Heydrich’s SD, SS and the Gestapo. Machinations by the SD, the Gestapo, and the SS helped to bring Austria fully into Hitler's grasp and on 13 March 1938, he signed into law the union with Austria as tears streamed down his face.
“Case Green” and the Sudetenland.
Concomitant to their machinations against Austria, the SD was also afoot in subversive activities throughout Czechoslovakia. Focusing on the Sudetenland with its 3 million ethnic Germans and the disharmony there which the Czech government could not seem to remedy, Hitler set Heydrich’s SD in motion there in what later came to be known as "Case Green". This SD intelligence operation was akin to their earlier efforts in Austria; however, unlike Austria, the Czechs fielded their own Secret Service against which, Heydrich had to contend. Once "Case Green" (which included military invasion to smash Czechoslovakia) began (as early as 1937), Heydrich’s SD spies began covertly gathering (even going so far as having SD agents use their spouses and children in the cover scheme) every conceivable type of intelligence data possible using a myriad of cameras and photographic equipment, focusing their efforts on important strategic locations like government buildings, police stations, postal services, public utilities, logistical routes, and above all, airfields. The SD activities in this regard can only be described as military espionage.
Hitler worked out a sophisticated plan to acquire the Sudetenland, which included manipulating Slovak nationalists to vie for independence and the suppression of this movement by the Czech government. Under directions from Heydrich, SD operative Alfred Naujocks was once again activated to engage in sabotage activities designed to incite a response from the Slovakians and the Czechs, a mission that ultimately failed. In June 1938, a directive from the head SD office indicated that Hitler issued an order at Jueterbog to his generals to prepare for the invasion of Czechoslovakia.
To hasten a presumed heavy response from the French, British, and Czechs, Hitler then upped the stakes and claimed that the Czechs were slaughtering Sudeten Germans, demanding the unconditional and prompt cession of the Sudetenland to Germany in order to secure the safety of endangered ethnic Germans. It was around this time that early plots from select members of the German General Staff to rid themselves of Hitler arose. How much the SD knew about schemes to subvert Hitler remains unknown. 
Eventually a diplomatic showdown pitting Hitler against the governments of Czechoslovakia, Great Britain, and France, whose tepid reaction to Austria precipitated this crisis to some degree, ensued. The Sudetenland Crisis came to an end when Neville Chamberlain and Hitler signed the Munich Agreement on 29 September 1938, effectively ceding the Sudetenland to Nazi Germany. Involvement in international affairs by the SD certainly did not end there and they remained active in foreign operations to such a degree that the head of the Foreign Ministry office, Joachim von Ribbentrop, complained of their meddling, since Hitler would apparently make decisions based on SD reports without consulting him. Following the Sudetenland Crisis, the SD then took part in operations against Poland.
Intrigue against Poland.
Aside from their participation in diminishing the power of the SA and their scheme to kill Ernst Roehm, the SD took part in international intrigue, first by activities in Austria, again in Czechoslovakia, and then by helping provoke the 'reactive' war against Poland. Code-named "Operation Himmler" and part of Hitler's plan to justify an attack upon Poland, the SD's clandestine activity for this mission included faking a Polish attack against 'innocent Germans' at a German radio station in Gleiwitz. Using concentration camp inmates condemned to die, the SD fitted them with Polish Army uniforms Heinz Jost had acquired from Admiral Canaris' "Abwehr". Leading this mission and personally selected by Heydrich was SS veteran Alfred Naujocks, who later reported during a War Criminal proceeding that he brought a Polish-speaking German along so he could broadcast a message in Polish from the German radio station 'under siege' that it was time for an all out confrontation between Germans and Poles. To add documented proof of this attack, the SD operatives placed the fictitious Polish troops (killed by lethal injection, then shot for appearance) around the 'attacked' radio station with the intention of taking members of the press to the site of the incident. Immediately in the wake of the staged incidents on 1 September 1939, Hitler proclaimed from the Reichstag in a famous radio address that German soldiers had been 'returning' fire since 0545 in the morning, setting the Second World War in Europe into motion.
Tasks and general structure.
The SD was tasked with the detection of actual or potential enemies of the Nazi leadership and the neutralization of this opposition as the action against the SA demonstrated. To fulfill this task, the SD created an organization of agents and informants throughout the Reich and later throughout the occupied territories, all part of the development of an extensive SS state and a totalitarian regime without parallel. The organization consisted of a few hundred full-time agents and several thousand informants. Historian George C. Browder writes that SD regiments were comparable to SS regiments, in that:
The SD was mainly the information-gathering agency, and the Gestapo, and to a degree the "Kriminalpolizei" (Kripo), was the executive agency of the political police system. Both the SD and the "Geheime Staatspolizei" (Gestapo) were departments under Heydrich's control which answered to Himmler as both Chief of the German Police and "Reichsfuhrer-SS", but the Kripo kept a level of independence since its structure was longer-established.
Part and parcel to intelligence operations, the SD carefully tracked foreign opinion and criticism of Nazi policies, censoring when necessary and likewise publishing hostile political cartoons in the SS weekly magazine, "Das Schwarze Korps". An additional task assigned to the SD and the Gestapo was keeping tabs on the morale of the German population at large which meant they were charged to "carefully supervise the political health of the German ethnic body" and once any symptoms of "disease and germs" appeared, it was their job to "remove them by every appropriate means." Regular reports - ranging from opinion polls, press dispatches, and information bulletins were established. These were monitored and reviewed by SS-"Gruppenführer" and head of the Inland-SD, Otto Ohlendorf (responsible for intelligence and security within Germany) and the former Heidelberg professor and SD member Reinhard Höhn, all designed to control and assess the "life domain" or "Lebensgebiet" of the German population. Gathered information was then distributed by the SD through secret internal political reports entitled "Meldungen aus dem Reich" (reports from the Reich) to the upper echelons of the Nazi Party, enabling Hitler's regime to evaluate the general morale and attitude of the German people so it could be timely manipulated by the Nazi propaganda machine. When the Nuremberg Laws were passed in 1935, the SD reported that the measures against the Jews were well received by the German populace.
In 1936, the police were divided into the "Ordnungspolizei" (Orpo or Order Police) and the "Sicherheitspolizei" (SiPo or Security Police). The "Ordnungspolizei" consisted mainly of the "Schutzpolizei" (Urban police), the "Gendarmerie" (Rural police) and the "Gemeindepolizei" (Municipal police). The "Sicherheitspolizei" was composed of the Kripo and the Gestapo. Heydrich became Chief of the SiPo (Security Police) and continued as Chief of the SD. Continuing escalation of antisemitic policies in the spring of 1937 from the SD organization concerned with Jewish affairs, staffed by members like Adolf Eichmann, Herbert Hagen, and Theodor Dannecker, led to an advocation for the complete removal ("Entfernung") of all Jews from Germany with little concern for where they were headed. 
Due to the fact that the Gestapo and SD had parallel duties, Heydrich tried to reduce any confusion or related territorial disputes through a decree on 1 July 1937, clearly defining the SD's area of responsibility as those dealing with "learning ("Wissenschaft"), art, party and state, constitution and administration, foreign lands, Freemasonry and associations" whereas the "Gestapo's jurisdiction was Marxism, treason, and emigrants." Additionally, the SD was responsible for matters related to "churches and sects, pacifism, the Jews, right-wing movements", as well as "the economy, and the Press", but the SD was instructed to "avoid all matters which touched the 'state police executive powers' ["staatspolizeiliche Vollzugsmaßnahmen"] since these belonged to the Gestapo, as did all individual cases."
In 1938, the SD was made the intelligence organization for the State as well as for the Party, supporting the "Gestapo" and working with the General and Interior Administration. As such, the SD came into immediate, fierce competition with the German "Abwehr" (military intelligence), headed by Admiral Wilhelm Canaris. The competition stemmed from Heydrich and Himmler's intention to absorb the "Abwehr" and Admiral Canaris' view of the SD as an amateur upstart. Canaris refused to give up the autonomy that his military intelligence organ was granted. Additional problems also existed, like the racial exemption for members of the "Abwehr" from the Nazi Aryan screening process, and then there was competition for resources which occurred throughout the Third Reich's existence.
On 27 September 1939, the "Sicherheitspolizei" became a part of the RSHA under Heydrich. The operational sections of the SD became (department) "Amt" III and for foreign intelligence, "Amt" VI; the Gestapo became "Amt" IV and the Kripo became "Amt" V. Otto Ohlendorf was named the Chief of "Amt" III, the SD-Inland (within Germany); Heinrich Müller was named the Chief of "Amt" IV, the Gestapo; Arthur Nebe was named the Chief of "Amt" V, the Kripo; and Walter Schellenberg became Chief of "Amt" VI, the SD-Ausland (outside Germany). In 1944, the sections of the "Abwehr" were incorporated into "Amt" VI.
SD relationship to the "Einsatzgruppen".
The SD was the overarching agency under which the "Einsatzgruppen der Sicherheitspolizei und des SD", also known as the "Einsatzgruppen", was subordinated; this was one of the principal reasons for the later war-crimes indictment against the organization by the Allies. The "Einsatzgruppen’s" part in the Holocaust has been well documented. Its mobile killing units were active in the implementation of the Final Solution in the territories overrun by the Nazi war machine. This SD subsidiary worked closely with the Wehrmacht in persecuting Jews, communists, partisans, and other groups, as well. Starting with the invasion of Poland throughout the campaign in the East, the "Einsatzgruppen" ruthlessly killed anyone suspected of being an opponent of the regime, either real or imagined. The men of the "Einsatzgruppen" were recruited from the SD, Gestapo, Kripo, Orpo, and Waffen-SS.
On 31 July 1941 Hermann Göring gave written authorisation to SD Chief Heydrich to ensure the cooperation of administrative leaders of various government departments in the implementation of a "Endlösung der Judenfrage" (Final Solution to the Jewish question) in territories under German control. An SD headquarter's memorandum indicated that the SD was tasked to accompany military invasions so as to assist in control and pacification efforts. The memo explicitly stated:
Correspondingly, SD affiliated units, including the "Einsatzgruppen" followed German troops into Austria, the Sudetenland, Bohemia, Moravia, Poland, Lithuania, as well as Russia. Since their task included cooperating with military leadership and vice versa, suppression of opposition in the occupied territories was a joint venture, so any attempt to feign ignorance on the part of the military leadership loses credibility in light of the orders passed up and down their respective commands. There were territorial disputes and disagreement about how some of these policies were to be implemented.
On 20 January 1942, Heydrich chaired a meeting, now called the Wannsee Conference, to discuss the implementation of the plan. Facilities such as Chelmno, Majdanek, Sobibor, Treblinka, and Auschwitz have their origins in the planning actions undertaken by Heydrich. Heydrich remained chief of the Security Police (SiPo) and the SD (through the RSHA) until his assassination in 1942, after which Ernst Kaltenbrunner was named chief by Himmler on 30 January 1943, and remained there until the end of the war. The SD was declared a criminal organization after the war and its members were tried as war criminals at Nuremberg. Whatever their original purpose, the SD and SS were ultimately created to identify and eradicate internal enemies of the State, as well as to pacify, subjugate, and exploit conquered territories and peoples. 
Organization.
By 1933, the organization was known as the SS "SD-Amt" and, in 1934, became the official security organization of the entire Nazi Party. Consisting at first of paid agents and a few hundred unpaid informants scattered across Germany, the SD was quickly professionalized under Heydrich, who commissioned National Socialist academics and lawyers to ensure that the SS and the SD in particular, operated "within the framework of National Socialist ideology." Heydrich was given the power to select men for the SD from among any of the SS component commands since Himmler considered the organization of the SD so important. In 1939, the SD was divided into two offices, the "Inland-SD" and "Ausland-SD", and placed under the authority of the RSHA.
By 1941, the SD had been organized into the following internal sections:
Inland-SD.
The "Inland-SD" (Office II) was originally headed by SS-Colonel Hermann Behrends until September 1939 and it was within this organization that Adolf Eichmann began working out the details for the Final Solution of the Jewish problem. The "Inland SD" was responsible for intelligence and security within Germany and was divided into the following sub-offices:
After 27 September 1939, (Office II) became officially "Amt" III (department III), the SD-Inland of the RSHA. Otto Ohlendorf was named the Chief of "Amt" III.
Ausland-SD.
The "Ausland-SD" (Office III) was the civilian foreign intelligence agency of the Third Reich and was "nominally commanded by Heydrich, but his chief of staff was SS-Colonel Heinz Jost." Jost ran the department until March 1942. Jost was fired from his position as Chief of "Ausland-SD" which, as of September 1939, had officially become known as "Amt" VI (department VI) of the RSHA. Jost's place was taken by "Brigadeführer" Walter Schellenberg, a deputy of Heydrich. After the July 20 Plot in 1944, the "Ausland-SD" took over the functions of the "Abwehr" (military intelligence). The "Ausland-SD" was divided into the following sections:
Membership.
Given the nature of the intelligence operations assigned to the SD, there were clear delineations between what constituted a full member ("Mitglieder") of the SD and those who were considered "associates" ("Mitarbeiter") with a further subset for clerical support personnel (typists, file clerks, etc.) who were connoted as V-persons ("Vertrauensleute"). All SD personnel, whether simply associates or full members were required to swear an oath of secrecy, had to meet all the requirements for SS membership, were assigned SD code numbers ("Chiffre Nummer") and if they were "above the level of V-person" they had to carry "an SD identification card." The vast majority of early SD members were relatively young, but the officers were typically older by comparison; nevertheless, the average age of an SD member was approximately 2 years older than the average Nazi Party member. Much like the Nazi revolution in general, membership in the SS and the SD appealed more to the impressionable youth. Most SD members were Protestant by faith, had served in the military, and generally had a significant amount of education, representing "an educated elite" in the general sense - with about 14 percent of them earning doctorate degrees. Heydrich viewed the SD as spiritual-elite leaders within the SS and the "cream of the cream of the NSDAP."
According to historian George C. Browder, "SD men represented no pathological or psychically susceptible group. Few were wild or extreme Nazi fanatics. In those respects they were 'ordinary men'. Yet in most other respects, they were an extraordinary mix of men, drawn together by a unique mix of missions." Along with members of the Gestapo, SD personnel were "regarded with a mixture of fear and foreboding," and people wanted as little to do with them as possible. Belonging to the security apparatus of the Third Reich obviously had its advantages but it was also fraught with occupationally related social disadvantages as well, and if post-war descriptions of the SD by historians are any indication, membership therein implied being a part of a "ubiquitous secret society" which was "sinister" and a "messenger of terror" not just for the German population, but within the "ranks of the Nazi Party itself."
Security forces.
The SD and the SiPo were the main sources of officers for the security forces in occupied territories. SD-SiPo led battalions were typically placed under the command of the SS and Police Leaders, reporting directly to the RSHA in Berlin. The SD also maintained a presence at all concentration camps and supplied personnel, on an as-needed basis, to such special action troops as the "Einsatzgruppen". In fact, all members of the "Einsatzgruppen" wore the SD sleeve diamond on their uniforms. The SD-SiPo was also the primary agency, in conjunction with the "Ordnungspolizei", assigned to maintain order and security in the Jewish ghettos established by the Germans on the territory of occupied Eastern Europe. On 7 December 1941, the same day that the American naval station at Pearl Harbor was bombed by the Japanese, the first extermination camp was opened at Chelmno near Lodz by the SD and SiPo commander in occupied Poznań (Posen), then SS-"Standartenführer" Ernst Damzog. Damzog had personally selected the staff for the killing centre and later supervised the daily operation of the camp which was under the command of SS-"Hauptsturmführer "Herbert Lange. Over a span of approximately 15 months, 150,000 people were killed there.
Local offices.
The SD also maintained local offices in Germany's cities and larger towns. The small offices were known as "SD-Unterabschnitte", and the larger offices were referred to as "SD-Abschnitte". All SD offices answered to a local commander known as the "Inspektor des Sicherheitspolizei und SD" who, in turn, was under the dual command of the RSHA and local SS and Police Leaders.
Infiltration.
According to the book "Piercing the Reich", the SD was infiltrated in 1944 by a Russian who was working for the Americans. The agent's parents had fled the Russian Revolution, and he had been raised in Berlin, and then moved to Paris. He was recruited by Albert Jolis of the Office of Strategic Services (OSS) Seventh Army detachment. The mission was codenamed RUPPERT.
Early plots against the Führer.
How extensive the SD’s knowledge was about the early plots to kill Hitler by key members of the military remains a contested subject and a veritable unknown. According to British historian John Wheeler-Bennett, “in view of the wholesale destruction of Gestapo archives it is improbable that this knowledge will ever be forthcoming. That the authorities were aware of serious 'defeatism' is certain, but it is doubtful whether they suspected anyone of outright treason.”

</doc>
<doc id="46143" url="https://en.wikipedia.org/wiki?curid=46143" title="Planner (programming language)">
Planner (programming language)

Planner (often seen in publications as "PLANNER" although it is not an acronym) is a programming language designed by Carl Hewitt at MIT, and first published in 1969. First, subsets such as Micro-Planner and Pico-Planner were implemented, and then essentially the whole language was implemented as "Popler" by Julian Davies at the University of Edinburgh in the POP-2 programming language. Derivations such as QA4, Conniver, QLISP and Ether (see Scientific Community Metaphor) were important tools in Artificial Intelligence research in the 1970s, which influenced commercial developments such as KEE and ART.
Procedural approach versus logical approach.
The two major paradigms for constructing semantic software systems were procedural and logical. The procedural paradigm was epitomized by 
Lisp "et al." 1962 which featured recursive procedures that operated on list structures.
The logical paradigm was epitomized by uniform proof procedure resolution theorem provers 1965. According to the logical paradigm it was “cheating” to incorporate procedural knowledge 1969.
Procedural embedding of knowledge.
Planner was invented for the purposes of the procedural embedding of knowledge 1971 and was a rejection of the resolution uniform proof procedure paradigm 1965, which
Planner was a kind of hybrid between the procedural and logical paradigms because it combined programmability with logical reasoning. Planner featured a procedural interpretation of logical sentences where an implication of the form (P implies Q) can be procedurally interpreted in the following ways using pattern-directed invocation:
In this respect, the development of Planner was influenced by natural deductive logical systems (especially the one by Frederic Fitch ).
Micro-planner implementation.
A subset called Micro-Planner was implemented by Gerry Sussman, Eugene Charniak and Terry Winograd Charniak, and Winograd 1971 and was used in Winograd's natural-language understanding program SHRDLU, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning, and some other projects. This generated a great deal of excitement in the field of AI. It also generated controversy because it proposed an alternative to the logic approach that had been one of the mainstay paradigms for AI.
At SRI International, Jeff Rulifson, Jan Derksen, and Richard Waldinger developed QA4 which built on the constructs in Planner and introduced a context mechanism to provide modularity for expressions in the database. Earl Sacerdoti and Rene Reboh developed QLISP, an extension of QA4 embedded in INTERLISP, providing Planner-like reasoning embedded in a procedural language and developed in its rich programming environment. QLISP was used by Richard Waldinger and Karl Levitt for program verification, by Earl Sacerdoti for planning and execution monitoring, by Jean-Claude Latombe for computer-aided design, by Richard Fikes for deductive retrieval, and by Steven Coles for an early expert system that guided use of an econometric model.
Computers were expensive. They had only a single slow processor and their memories were very small by comparison with today. So Planner adopted some efficiency expedients including the following:
The genesis of Prolog.
Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists. At the University of Edinburgh, Bruce Anderson implemented a subset of Micro-Planner called PICO-PLANNER (Anderson 1972) and Julian Davies (1973) implemented essentially all of Planner.
According to Donald MacKenzie, Pat Hayes recalled the impact of a visit from Papert to Edinburgh, which had become the "heart of artificial intelligence's Logicland," according to Papert's MIT colleague, Carl Hewitt. Papert eloquently voiced his critique of the resolution approach dominant at Edinburgh "...and at least one person upped sticks and left because of Papert." 2001 pg 82.
The above developments generated tension among the Logicists at Edinburgh. These tensions were exacerbated when the UK Science Research Council commissioned Sir James Lighthill to write a report on the AI research situation in the UK. The resulting report [Lighthill 1973; McCarthy 1973] was highly critical although SHRDLU was favorably mentioned.
Pat Hayes visited Stanford where he learned about Planner. When he returned to Edinburgh, he tried to influence his friend Bob Kowalski to take Planner into account in their joint work on automated theorem proving. "Resolution theorem-proving was demoted from a hot topic to a relic of the misguided past. Bob Kowalski doggedly stuck to his faith in the potential of resolution theorem proving. He carefully studied Planner.” according to Bruynooghe, Pereira, Siekmann, and van Emden Kowalski [1988 states "I can recall trying to convince Hewitt that Planner was similar to SL-resolution." But Planner was invented for the purposes of the procedural embedding of knowledge and was a rejection of the resolution uniform proof procedure paradigm. Colmerauer and Roussel recalled their reaction to learning about Planner in the following way:
"While attending an IJCAI convention in September ‘71 with Jean Trudel, we met Robert Kowalski again and heard a lecture by Terry Winograd on natural language processing. The fact that he did not use a unified formalism left us puzzled. It was at this time that we learned of the existence of Carl Hewitt’s programming language, Planner 1969. The lack of formalization of this language, our ignorance of Lisp and, above all, the fact that we were absolutely devoted to logic meant that this work had little influence on our later research." and Roussel 1996
In the fall of 1972, Philippe Roussel implemented a language called Prolog (an abbreviation for PROgrammation en LOGique - French for "programming in logic"). Prolog programs are generically of the following form (which is a special case of the backward-chaining in Planner):
Prolog duplicated the following aspects of Micro-Planner:
Prolog also duplicated the following capabilities of Micro-Planner which were pragmatically useful for the computers of the era because they saved space and time:
Use of the Unique Name Assumption and Negation as Failure became more questionable when attention turned to Open Systems and de Jong 1983, Hewitt 1985, Hewitt and Inman 1991.
The following capabilities of Micro-Planner were omitted from Prolog:
Prolog did not include negation in part because it raises implementation issues. Consider for example if negation were included in the following Prolog program:
The above program would be unable to prove "not" P even though it follows by the rules of mathematical logic. This is an illustration of the fact that Prolog (like Planner) is intended to be a programming language and so does not (by itself) prove many of the logical consequences that follow from a declarative reading of its programs.
The work on Prolog was valuable in that it was much simpler than Planner. However, as the need arose for greater expressive power in the language, Prolog began to include many of the capabilities of Planner that were left out of the original version of Prolog.

</doc>
<doc id="46145" url="https://en.wikipedia.org/wiki?curid=46145" title="Solaris (operating system)">
Solaris (operating system)

Solaris is a Unix operating system originally developed by Sun Microsystems. It superseded their earlier SunOS in 1993. Oracle Solaris, so named as of 2010, has been owned by Oracle Corporation since the Sun acquisition by Oracle in January 2010.
Solaris is known for its scalability, especially on SPARC systems, and for originating many innovative features such as DTrace, ZFS and Time Slider. Solaris supports SPARC-based and x86-based workstations and servers from Oracle and other vendors, with efforts underway to port to additional platforms. Solaris is registered as compliant with the Single Unix Specification.
Historically, Solaris was developed as proprietary software. In June 2005, Sun Microsystems released most of the codebase under the CDDL license, and founded the OpenSolaris open source project. With OpenSolaris, Sun wanted to build a developer and user community around the software. After the acquisition of Sun Microsystems in January 2010, Oracle decided to discontinue the OpenSolaris distribution and the development model.
In August 2010, Oracle discontinued providing public updates to the source code of the Solaris kernel, effectively turning Solaris 11 back into a closed source proprietary operating system. Following that, in 2011 the Solaris 11 kernel source code leaked to BitTorrent. However, through the Oracle Technology Network (OTN), industry partners can still gain access to the in-development Solaris source code. Source code for the open source components of Solaris 11 is available for download from Oracle.
History.
In 1987, AT&T Corporation and Sun announced that they were collaborating on a project to merge the most popular Unix variants on the market at that time: BSD, System V, and Xenix. This became Unix System V Release 4 (SVR4).
On September 4, 1991, Sun announced that it would replace its existing BSD-derived Unix, SunOS 4, with one based on SVR4. This was identified internally as SunOS 5, but a new marketing name was introduced at the same time: Solaris 2. Although SunOS 4.1."x" micro releases were retroactively named Solaris 1 by Sun, the Solaris name is used almost exclusively to refer to the SVR4-derived SunOS 5.0 and later.
The justification for this new "overbrand" was that it encompassed not only SunOS, but also the OpenWindows graphical user interface and Open Network Computing (ONC) functionality. The SunOS minor version is included in the Solaris release number. For example, Solaris 2.4 incorporated SunOS 5.4. After Solaris 2.6, Sun dropped the "2." from the number, so Solaris 7 incorporates SunOS 5.7, and the latest release SunOS 5.11 forms the core of "Solaris 11.3".
Solaris originated on the SPARC. The first x86 port, of version 2.1, was originally intended by Sun as a desktop operating system for large businesses that would also use Solaris on their high-end server machines. It included the Wabi emulator to support Microsoft Windows applications. For smaller clients, Sun simultaneously maintained the Interactive Unix system that it had acquired from Interactive Systems Corporation.
Supported architectures.
Solaris uses a common code base for the platforms it supports: SPARC and i86pc (which includes both x86 and x86-64).
Solaris has a reputation for being well-suited to symmetric multiprocessing, supporting a large number of CPUs. It has historically been tightly integrated with Sun's SPARC hardware (including support for 64-bit SPARC applications since Solaris 7), with which it is marketed as a combined package. This has led to more reliable systems, but at a cost premium compared to commodity PC hardware. However, it has supported x86 systems since Solaris 2.1 and 64-bit x86 applications since Solaris 10, allowing Sun to capitalize on the availability of commodity 64-bit CPUs based on the x86-64 architecture. Sun has heavily marketed Solaris for use with both its own "x64" workstations and servers based on AMD Opteron and Intel Xeon processors, as well as x86 systems manufactured by companies such as Dell, Hewlett-Packard, and IBM. As of 2009, the following vendors support Solaris for their x86 server systems:
As of July 2010, Dell and HP certify and resell Oracle Solaris, Oracle Enterprise Linux and Oracle VM on their respective x86 platforms,
and IBM stopped direct support for Solaris on x64 kit.
Other platforms.
Solaris 2.5.1 included support for the PowerPC platform (PowerPC Reference Platform), but the port was canceled before the Solaris 2.6 release. In January 2006, a community of developers at Blastwave began work on a PowerPC port which they named "Polaris". In October 2006, an OpenSolaris community project based on the Blastwave efforts and Sun Labs' "Project Pulsar", which re-integrated the relevant parts from Solaris 2.5.1 into OpenSolaris, announced its first official source code release.
A port of Solaris to the Intel Itanium architecture was announced in 1997 but never brought to market.
On November 28, 2007, IBM, Sun, and Sine Nomine Associates demonstrated a preview of OpenSolaris for System z running on an IBM System z mainframe under z/VM, called "Sirius" (in analogy to the Polaris project, and also due to the primary developer's Australian nationality: HMS "Sirius" of 1786 was a ship of the First Fleet to Australia). On October 17, 2008, a prototype release of Sirius was made available and on November 19 the same year, IBM authorized the use of Sirius on System z Integrated Facility for Linux (IFL) processors.
Solaris also supports the Linux platform application binary interface (ABI), allowing Solaris to run native Linux binaries on x86 systems. This feature is called "Solaris Containers for Linux Applications" (SCLA), based on the branded zones functionality introduced in Solaris 10 8/07.
Installation and usage options.
Solaris can be installed from various pre-packaged software groups, ranging from a minimalistic "Reduced Network Support" to a complete "Entire Plus OEM". Installation of Solaris is not necessary for an individual to use the system. Additional software, like Apache, MySQL, etc. can be installed as well in a packaged form from "sunfreeware" and OpenCSW. Solaris can be installed from physical media or a network for use on a desktop or server, or be without installing on a desktop or server.
Desktop environments.
Early releases of Solaris used OpenWindows as the standard desktop environment. In Solaris 2.0 to 2.2, OpenWindows supported both NeWS and X applications, and provided backward compatibility for SunView applications from Sun's older desktop environment. NeWS allowed applications to be built in an object-oriented way using PostScript, a common printing language released in 1982. The X Window System originated from MIT's Project Athena in 1984 and allowed for the display of an application to be disconnected from the machine where the application was running, separated by a network connection. Sun’s original bundled SunView application suite was ported to X.
Sun later dropped support for legacy SunView applications and NeWS with OpenWindows 3.3, which shipped with Solaris 2.3, and switched to X11R5 with Display Postscript support. The graphical look and feel remained based upon OPEN LOOK. OpenWindows 3.6.2 was the last release under Solaris 8. The OPEN LOOK Window Manager (olwm) with other OPEN LOOK specific applications were dropped in Solaris 9, but support libraries were still bundled, providing long term binary backwards compatibility with existing applications. The OPEN LOOK Virtual Window Manager (olvwm) can still be downloaded for Solaris from sunfreeware and works on releases as recent as Solaris 10.
Sun and other Unix vendors created an industry alliance to standardize Unix desktops. As a member of the Common Open Software Environment (COSE) initiative, Sun helped co-develop the Common Desktop Environment (CDE). This was an initiative to create a standard Unix desktop environment. Each vendor contributed different components: Hewlett-Packard contributed the window manager, IBM provided the file manager, and Sun provided the e-mail and calendar facilities as well as drag-and-drop support (ToolTalk). This new desktop environment was based upon the Motif look and feel and the old OPEN LOOK desktop environment was considered legacy. CDE unified Unix desktops across multiple open system vendors. CDE was available as an unbundled add-on for Solaris 2.4 and 2.5, and was included in Solaris 2.6 through 10. In 2001, Sun issued a preview release of the open-source desktop environment GNOME 1.4, based on the GTK+ toolkit, for Solaris 8. Solaris 9 8/03 introduced GNOME 2.0 as an alternative to CDE. Solaris 10 includes Sun's Java Desktop System (JDS), which is based on GNOME and comes with a large set of applications, including StarOffice, Sun's office suite. Sun describes JDS as a "major component" of Solaris 10. The Java Desktop System is not included in Solaris 11 which instead ships with a stock version of GNOME. Likewise, CDE applications are no longer included in Solaris 11, but many libraries remain for binary backwards compatibility.
The open source desktop environments KDE and Xfce, along with numerous other window managers, also compile and run on recent versions of Solaris.
Sun was investing in a new desktop environment called Project Looking Glass since 2003. The project has been inactive since late 2006.
License.
Traditional operating system license (1982 to 2004).
For versions up to 2005 (Solaris 9), Solaris was licensed under a license that permitted a customer to buy licenses in bulk, and install the software on any machine up to a maximum number. The key license grant was:
In addition, the license provided a "License to Develop" granting rights to create derivative works, restricted copying to only a single archival copy, disclaimer of warranties, and the like. The license varied only little through 2004.
Open source (2005 until March 2010).
From 2005–10, Sun began to release the source code for development builds of Solaris under the Common Development and Distribution License (CDDL) via the OpenSolaris project. This code was based on the work being done for the post-Solaris 10 release (code-named "Nevada"; eventually released as Oracle Solaris 11). As the project progressed, it grew to encompass most of the necessary code to compile an entire release, with a few exceptions.
Post-Oracle closed source (Solaris 10 after March 2010, and Solaris 11 (2011 and later)).
When Sun was acquired by Oracle in 2010, the OpenSolaris project was discontinued after the board became unhappy with Oracle's stance on the project. In March 2010, the previously freely available Solaris 10 was placed under a restrictive license that limited the use, modification and redistribution of the operating system. The license allowed the user to download the operating system free of charge, through the Oracle Technology Network, and use it for a 90-day trial period. After that trial period had expired the user would then have to purchase a support contract from Oracle to continue using the operating system.
With the release of Solaris 11 in 2011, the license terms changed again. The new license allows Solaris 10 and Solaris 11 to be downloaded free of charge from the Oracle Technology Network and used without a support contract indefinitely however the license only expressly permits the user to use Solaris as a development platform and expressly forbids commercial and "production" use. Educational use is permitted in some circumstances. From the OTN license:
When Solaris is used without a support contract it can be upgraded to each new "point release" however a support contract is required for access to patches and updates that are released monthly.
Version history.
Notable features of Solaris include DTrace, Doors, Service Management Facility, Solaris Containers, Solaris Multiplexed I/O, Solaris Volume Manager, ZFS, and Solaris Trusted Extensions.
Updates to Solaris versions are periodically issued. In the past, these were named after the month and year of their release, such as "Solaris 10 1/13"; as of Solaris 11, sequential update numbers are appended to the release name with a period, such as "Oracle Solaris 11.3".
In ascending order, the following versions of Solaris have been released:
A more comprehensive summary of some Solaris versions is also available. Solaris releases are also described in the Solaris 2 FAQ.
Development release.
The underlying Solaris codebase has been under continuous development since work began in the late 1980s on what was eventually released as Solaris 2.0. Each version such as Solaris 10 is based on a snapshot of this development codebase, taken near the time of its release, which is then maintained as a derived project. Updates to that project are built and delivered several times a year until the next official release comes out.
The Solaris version under development by Sun since the release of Solaris 10 in 2005, was codenamed "Nevada", and is derived from what is now the OpenSolaris codebase.
In 2003, an addition to the Solaris development process was initiated. Under the program name "Software Express for Solaris" (or just "Solaris Express"), a binary release based on the current development basis was made available for download on a monthly basis, allowing anyone to try out new features and test the quality and stability of the OS as it progressed to the release of the next official Solaris version. A later change to this program introduced a quarterly release model with support available, renamed "Solaris Express Developer Edition" (SXDE).
In 2007, Sun announced "Project Indiana" with several goals, including providing an open source binary distribution of the OpenSolaris project, replacing SXDE. The first release of this distribution was "OpenSolaris 2008.05".
The "Solaris Express Community Edition" (SXCE) was intended specifically for OpenSolaris developers. It was updated every two weeks until it was discontinued in January 2010, with a recommendation that users migrate to the OpenSolaris distribution. Although the download license seen when downloading the image files indicates its use is limited to personal, educational and evaluation purposes, the license acceptance form displayed when the user actually installs from these images lists additional uses including commercial and production environments.
SXCE releases terminated with build 130 and OpenSolaris releases terminated with build 134 a few weeks later. The next release of OpenSolaris based on build 134 was due in March 2010, but it was never fully released, though the packages were made available on the package repository. Instead, Oracle renamed the binary distribution Solaris 11 Express, changed the license terms and released build 151a as 2010.11 in November 2010.

</doc>
<doc id="46149" url="https://en.wikipedia.org/wiki?curid=46149" title="GLONASS">
GLONASS

GLONASS (, ; ; transliteration ""), or "GLObal NAvigation Satellite System", is a space-based satellite navigation system operating in the radionavigation-satellite service and used by the Russian Aerospace Defence Forces. It provides an alternative to GPS and is the second alternative navigational system in operation with global coverage and of comparable precision.
Manufacturers of GPS devices say that adding GLONASS made more satellites available to them, meaning positions can be fixed more quickly and accurately, especially in built-up areas where the view to some GPS satellites is obscured by buildings. Smartphones generally tend to use the same chipsets and since the versions used since 2015 receive GLONASS signals, smartphones using such chips receive GLONASS positioning information along with GPS. Since 2012, GLONASS was the second most used positioning system in mobile phones after GPS. The system has the advantage that smartphone users receive a more accurate reception of up to 2 meters.
Development of GLONASS began in the Soviet Union in 1976. Beginning on 12 October 1982, numerous rocket launches added satellites to the system until the constellation was completed in 1995. After a decline in capacity during the late 1990s, in 2001, under Vladimir Putin's presidency, the restoration of the system was made a top government priority and funding was substantially increased. GLONASS is the most expensive program of the Russian Federal Space Agency, consuming a third of its budget in 2010.
By 2010, GLONASS had achieved 100% coverage of Russia's territory and in October 2011, the full orbital constellation of 24 satellites was restored, enabling full global coverage. The GLONASS satellites' designs have undergone several upgrades, with the latest version being GLONASS-K.
History.
Inception and design.
The first satellite-based radio navigation system developed in the Soviet Union was Tsiklon, which had the purpose of providing ballistic missile submarines a method for accurate positioning. 31 Tsiklon satellites were launched between 1967 and 1978. The main problem with the system was that, although highly accurate for stationary or slow-moving ships, it required several hours of observation by the receiving station to fix a position, making it unusable for many navigation purposes and for the guidance of the new generation of ballistic missiles. In 1968–1969, a new navigation system, which would support not only the navy, but also the air, land and space forces, was conceived. Formal requirements were completed in 1970; in 1976, the government made a decision to launch development of the "Unified Space Navigation System GLONASS".
The task of designing GLONASS was given to a group of young specialists at NPO PM in the city of Krasnoyarsk-26 (today called Zheleznogorsk). Under the leadership of Vladimir Cheremisin, they developed different proposals, from which the institute's director Grigory Chernyavsky selected the final one. The work was completed in the late 1970s; the system consists of 24 satellites operating at an altitude of in medium circular orbit. It would be able to promptly fix the receiving station's position based on signals from four satellites, and also reveal the object's speed and direction. The satellites would be launched three at a time on the heavy-lift Proton rocket. Due to the large number of satellites needed for the program, NPO PM delegated the manufacturing of the satellites to PO Polyot in Omsk, which had better production capabilities.
Originally, GLONASS was designed to have an accuracy of , but in reality it had an accuracy of in the civilian signal and in the military signal. The first generation GLONASS satellites were tall, had a width of , measured across their solar panels, and a mass of .
Achieving full orbital constellation.
In the early 1980s, NPO PM received the first prototype satellites from PO Polyot for ground tests. Many of the produced parts were of low quality and NPO PM engineers had to perform substantial redesigning, leading to a delay. On 12 October 1982, three satellites, designated Kosmos-1413, Kosmos-1414, and Kosmos-1415 were launched aboard a Proton rocket. As only one GLONASS satellite was ready in time for the launch instead of the expected three, it was decided to launch it along with two mock-ups. The USA media reported the event as a launch of one satellite and "two secret objects." For a long time, the USA could not find out the nature of those "objects". The Telegraph Agency of the Soviet Union (TASS) covered the launch, describing GLONASS as a system "created to determine positioning of civil aviation aircraft, navy transport and fishing-boats of the Soviet Union".
From 1982 to April 1991, the Soviet Union successfully launched a total of 43 GLONASS-related satellites plus five test satellites. When the Soviet Union disintegrated in 1991, twelve GLONASS satellites in two planes were operational; enough to allow limited use of the system (to cover the entire territory of the Union, 18 satellites would have been necessary.) The Russian Federation took over control of the constellation and continued its development. In 1993, the system, now consisting of 12 satellites, was formally declared operational and in December 1995 it was brought to a fully operational constellation of 24 satellites. This brought the precision of GLONASS on a par with the USA GPS system, which had achieved full operation а year earlier.
Economic crisis.
Since the first generation satellites operated for three years each, to keep the system at full capacity, two launches per year would have been necessary to maintain the full network of 24 satellites. However, in the financially difficult period of 1989–1999, the space program's funding was cut by 80% and Russia consequently found itself unable to afford this launch rate. After the full complement was achieved in December 1995, there were no further launches until December 1999. As a result, the constellation reached its lowest point of just six operational satellites in 2001. As a prelude to demilitarisation, responsibility of the program was transferred from the Ministry of Defence to Russia's civilian space agency Roscosmos.
Renewed efforts and modernization.
In the 2000s, under Vladimir Putin's presidency, the Russian economy recovered and state finances improved considerably. Putin himself took special interest in GLONASS and the system's restoration was made one of the government's top priorities. For this purpose, on August 2001, the Federal Targeted Program "Global Navigation System" 2002–2011 (Government Decision No. 587) was launched. The program was given a budget of $420 million and aimed at restoring the full constellation by 2009.
On 10 December 2003, the second generation satellite design, GLONASS-M, was launched for the first time. It had a slightly larger mass than the baseline GLONASS, standing at , but it had seven years lifetime, four years longer than the lifetime of the original GLONASS satellite, decreasing the required replacement rate. The new satellite also had better accuracy and ability to broadcast two extra civilian signals.
In 2006, Defence Minister Sergey Ivanov ordered one of the signals (with an accuracy of ) to be made available to civilian users. Putin, however, was not satisfied with this, and demanded that the whole system should be made fully available to everyone. Consequently, on 18 May 2007, all restrictions were lifted. The accurate, formerly military-only signal with a precision of , has since then been freely available to civilian users.
During the middle of the first decade of the 21st century, the Russian economy boomed, resulting in substantial increases in the country's space budget. In 2007, the financing of the GLONASS program was increased considerably; its budget was more than doubled. While in 2006 the GLONASS had received $181 million from the federal budget, in 2007 the amount was increased to $380 million.
In the end, 140.1 billion rubles ($4.7 billion) were spent on the program 2001–2011, making it Roscosmos' largest project and consuming a third of its 2010 budget of 84.5 billion rubles.
For the period of 2012 to 2020 320 billion rubles ($10 billion) were allocated to support the system.
Restoring full capacity.
In June 2008, the system consisted of 16 satellites, 12 of which were fully operational at the time. At this point, Roscosmos aimed at having a full constellation of 24 satellites in orbit by 2010, one year later than previously planned.
In September 2008, Prime Minister Vladimir Putin signed a decree allocating additional 67 billion rubles ($2.6 billion) to GLONASS from the federal budget.
Promoting commercial use.
Although the GLONASS constellation has reached global coverage, its commercialisation, especially development of the user segment, has been lacking compared to the American GPS. For example, the first commercial Russian-made GLONASS navigation device for cars, Glospace SGK-70, was introduced in 2007, but it was much bigger and costlier than similar GPS receivers. In late 2010, there were only a handful of GLONASS receivers on the market, and few of them were meant for ordinary consumers. To improve the situation, the Russian government has been actively promoting GLONASS for civilian use.
To improve development of the user segment, on 11 August 2010, Sergei Ivanov announced a plan to introduce a 25% import duty on all GPS-capable devices, including mobile phones, unless they are compatible with GLONASS. The government also planned to force all car manufacturers in Russia to support GLONASS starting from 2011. This would affect all car makers, including foreign brands like Ford and Toyota, which have car assembly facilities in Russia.
GPS and phone baseband chips from major vendors Qualcomm, Exynos and Broadcom all support GLONASS in combination with GPS.
In April 2011, Sweden's Swepos—a national network of satellite reference stations that provides real-time positioning data with meter accuracy—became the first known foreign company to use GLONASS.
Smartphones and Tablets also saw implementation of GLONASS support in 2011 with devices released that year from Xiaomi Tech Company (Xiaomi Phone 2), Sony Ericsson, Samsung (Galaxy Note Galaxy Note II, Galaxy SII, the Google Nexus 10 in late 2012), Asus, Apple (iPhone 4S and iPad Mini in late 2012) and HTC adding support for the system allowing increased accuracy and lock on speed in difficult conditions. For a more complete list of smartphones see List of smartphones using GLONASS Navigation and for a more complete list of tablets see the text GLONASS in the GPS column in the Comparison of tablet computers.
Finishing the constellation.
Russia's aim of finishing the constellation in 2010 suffered a setback when a December 2010 launch of three GLONASS-M satellites failed. The Proton-M rocket itself performed flawlessly, but the upper stage Blok DM3 (a new version that was to make its maiden flight) was loaded with too much fuel due to a sensor failure. As a result, the upper stage and the three satellites crashed into the Pacific Ocean. Kommersant estimated that the launch failure cost up to $160 million. Russian President Dmitry Medvedev ordered a full audit of the entire program and an investigation into the failure.
Following the mishap, Roscosmos activated two reserve satellites and decided to make the first improved GLONASS-K satellite, to be launched in February 2011, part of the operational constellation instead of mainly for testing as was originally planned. This would bring the total number of satellites to 23, obtaining almost complete worldwide coverage. The GLONASS-K2 was originally scheduled to be launched by 2013, however by 2012 was not expected to be launched until 2015.
In 2010, President Dmitry Medvedev ordered the government to prepare a new federal targeted program for GLONASS, covering the years 2012–2020. The original 2001 program is scheduled to end in 2011. On 22 June 2011, Roscosmos revealed that the agency was looking for a funding of 402 billion rubles ($14.35 billion) for the program. The funds would be spent on maintaining the satellite constellation, on developing and maintaining navigational maps as well as on sponsoring supplemental technologies to make GLONASS more attractive to users.
On 2 October 2011 the 24th satellite of the system, a GLONASS-M, was successfully launched from Plesetsk Cosmodrome and is now in service. This made the GLONASS constellation fully restored, for the first time since 1996.
On 5 November 2011 the Proton-M booster successfully put three GLONASS-M units in final orbit.
On Monday 28 November 2011, a Soyuz rocket, launched from the Plesetsk Cosmodrome Space Centre, placed a single GLONASS-M satellite into orbit into Plane 3.
On 26 April 2013 a single GLONASS-M satellite was delivered to the orbit by Soyuz rocket from Plesetsk Cosmodrome, restoring the constellation to 24 operational satellites, the minimum to provide global coverage.
On 2 July 2013 a Proton-M rocket, carrying 3 GLONASS-M satellites, crashed during takeoff from Baikonur Cosmodrome. It veered off the course just after leaving the pad and plunged into the ground nose first. The rocket employed a DM-03 booster, for the first time since the December 2010 launch, when the vehicle had also failed, resulting in a loss of another 3 satellites.
However, as of 2014, while the system was completed from technical point of view, the operational side was still not closed by the Ministry of Defense and its formal status was still "in development".
On 7 December 2015, the system was officially completed.
System description.
GLONASS is a global satellite navigation system, providing real time position and velocity determination for military and civilian users. The satellites are located in middle circular orbit at altitude with a 64.8 degree inclination and a period of 11 hours and 15 minutes. GLONASS' orbit makes it especially suited for usage in high latitudes (north or south), where getting a GPS signal can be problematic. The constellation operates in three orbital planes, with eight evenly spaced satellites on each. A fully operational constellation with global coverage consists of 24 satellites, while 18 satellites are necessary for covering the territory of Russia. To get a position fix the receiver must be in the range of at least four satellites.
Signal.
FDMA.
GLONASS satellites transmit two types of signal: open standard-precision signal L1OF/L2OF, and obfuscated high-precision signal L1SF/L2SF.
The signals use similar DSSS encoding and binary phase-shift keying (BPSK) modulation as in GPS signals. All GLONASS satellites transmit the same code as their standard-precision signal; however each transmits on a different frequency using a 15-channel frequency division multiple access (FDMA) technique spanning either side from 1602.0 MHz, known as the L1 band. The center frequency is 1602 MHz + "n" × 0.5625 MHz, where "n" is a satellite's frequency channel number ("n"=−7,−6,−5...0...,6, previously "n"=0...,13). Signals are transmitted in a 38° cone, using right-hand circular polarization, at an EIRP between 25 and 27 dBW (316 to 500 watts). Note that the 24-satellite constellation is accommodated with only 15 channels by using identical frequency channels to support antipodal (opposite side of planet in orbit) satellite pairs, as these satellites are never both in view of an earth-based user at the same time.
The L2 band signals use the same FDMA as the L1 band signals, but transmit straddling 1246 MHz with the center frequency 1246 MHz + "n"×0.4375 MHz, where "n" spans the same range as for L1. In the original GLONASS design, only obfuscated high-precision signal was broadcast in the L2 band, but starting with GLONASS-M, an additional civil reference signal L2OF is broadcast with an identical standard-precision code to the L1OF signal.
The open standard-precision signal is generated with modulo-2 addition (XOR) of 511 kbit/s pseudo-random ranging code, 50 bit/s navigation message, and an auxiliary 100 Hz meander sequence (Manchester code), all generated using a single time/frequency oscillator. The pseudo-random code is generated with a 9-stage shift register operating with a period of 1 ms.
The navigational message is modulated at 50 bits per second. The superframe of the open signal is 7500 bits long and consists of 5 frames of 30 seconds, taking 150 seconds (2.5 minutes) to transmit the continuous message. Each frame is 1500 bits long and consists of 15 strings of 100 bits (2 seconds for each string), with 85 bits (1.7 seconds) for data and check-sum bits, and 15 bits (0.3 seconds) for time mark. Strings 1-4 provide immediate data for the transmitting satellite, and are repeated every frame; the data include ephemeris, clock and frequency offsets, and satellite status. Strings 5-15 provide non-immediate data (i.e. almanac) for each satellite in the constellation, with frames I-IV each describing five satellites, and frame V describing remaining four satellites.
The ephemerides are updated every 30 minutes using data from the Ground Control segment; they use Earth Centred Earth Fixed (ECEF) Cartesian coordinates in position and velocity, and include lunisolar acceleration parameters. The almanac uses modified Keplerian parameters and is updated daily.
The more accurate high-precision signal is available for authorized users, such as the Russian Military, yet unlike the US P(Y) code, which is modulated by an encrypting W code, the GLONASS restricted-use codes are broadcast in the clear using only "security through obscurity". The details of the high-precision signal have not been disclosed. The modulation (and therefore the tracking strategy) of the data bits on the L2SF code has recently changed from unmodulated to 250 bit/s burst at random intervals. The L1SF code is modulated by the navigation data at 50 bit/s without a Manchester meander code.
The high-precision signal is broadcast in phase quadrature with the standard-precision signal, effectively sharing the same carrier wave, but with a ten-times-higher bandwidth than the open signal. The message format of the high-precision signal remains unpublished, although attempts at reverse-engineering indicate that the superframe is composed of 72 frames, each containing 5 strings of 100 bits and taking 10 seconds to transmit, with total length of 36 000 bits or 720 seconds (12 minutes) for the whole navigational message. The additional data are seemingly allocated to critical Luni-Solar acceleration parameters and clock correction terms.
Accuracy.
At peak efficiency, the standard-precision signal offers horizontal positioning accuracy within 5–10 meters, vertical positioning within , a velocity vector measuring within , and timing within 200 ns, all based on measurements from four first-generation satellites simultaneously; newer satellites such as GLONASS-M improve on this.
GLONASS uses a coordinate datum named "PZ-90" (Earth Parameters 1990 – Parametry Zemli 1990), in which the precise location of the North Pole is given as an average of its position from 1990 to 1995. This is in contrast to the GPS's coordinate datum, WGS 84, which uses the location of the North Pole in 1984. As of 17 September 2007 the PZ-90 datum has been updated to version PZ-90.02 which differ from WGS 84 by less than in any given direction. Since 31 December 2013, version PZ-90.11 is being broadcast, which is aligned to the International Terrestrial Reference System at epoch 2011.0 at the centimeter level.
CDMA.
Since 2008, new CDMA signals are being researched for use with GLONASS.
According to preliminary statements from GLONASS developers, there will be three open and two restricted CDMA signals. The open signal L3OC is centered at 1202.025 MHz and uses BPSK(10) modulation for both data and pilot channels; the ranging code transmits at 10.23 million chips per second, modulated onto the carrier frequency using QPSK with in-phase data and quadrature pilot. The data is error-coded with 5-bit Barker code and the pilot with 10-bit Neuman-Hoffman code.
Open L1OC and restricted L1SC signals are centered at 1600.995 MHz, and open L2OC and restricted L2SC signals are centered at 1248.06 MHz, overlapping with GLONASS FDMA signals. Open signals L1OC and L2OC use time-division multiplexing to transmit pilot and data signals, with BPSK(1) modulation for data and BOC(1,1) modulation for pilot; wide-band restricted signals L1SC and L2SC use BOC (5, 2.5) modulation for both data and pilot, transmitted in quadrature phase to the open signals; this places peak signal strength away from the center frequency of narrow-band open signals.
Binary phase-shift keying (BPSK) is used by standard GPS and GLONASS signals, however both BPSK and quadrature phase-shift keying (QPSK) can be considered as variations of quadrature amplitude modulation (QAM), specifically QAM-2 and QAM-4. Binary offset carrier (BOC) is the modulation used by Galileo, modernized GPS, and COMPASS.
The navigational message of the L3OC signal is transmitted at 100 bit/s. The navigational frame is 15 seconds (1500 bits) long and includes 5 strings of symbols each taking 3 seconds (300 bits); a frame contains ephemerides for the current satellite and part of the almanac for three satellites. The superframe consists of 8 navigational frames, so it takes 120 seconds (2 minutes) to transmit 12000 bits of almanac for all current 24 satellites. In the future, the superframe will be expanded to 10 frames or 15000 bits (150 seconds or 2.5 minutes) of data to cover full 30 satellites. The system time marker is transmitted with each string; UTC leap second correction is achieved by shortening or lengthening (zero-padding) the final string of the day by one second (100 bits), with shortened strings being discarded by the receiver. The strings have a version tag to facilitate forward compatibility: future upgrades to the message format will not break older equipment, which will continue to work by ignoring new data (as long as the constellation still transmits old string types), but up-to-date equipment will be able to use additional information from newer satellites.
Glonass-K1 test satellite launched in 2011 introduced L3OC signal. They will be used as fleet replacement from 2018 until the Glonass-K2 are validated. The final Glonass-M satellites launched in 2014–2017 will also include L3OC signal.
Glonass-K2 satellites, to be launched in 2018, will feature a full suite of modernized CDMA signals in the existing L1 and L2 bands, which includes L1SC, L1OC, and L2SC, as well as the L3OC signal. Glonass-K2 should gradually replace existing satellites starting from 2017, when Glonass-M launches will cease.
Glonass-KM satellites will be launched by 2025. Additional open signals are being studied for these satellites, based on the same frequencies and formats as GPS signals L5 and L1C and corresponding Galileo/COMPASS signals E1, E5a and E5b. These signals include:
Such an arrangement will allow easier and cheaper implementation of multi-standard GNSS receivers.
With the introduction of CDMA signals, the constellation will be expanded to 30 active satellites by 2025; this may require eventual deprecation of FDMA signals. The new satellites will be deployed into three additional planes, bringing the total to six planes from the current three—aided by System for Differential Correction and Monitoring (SDCM), which is a GNSS augmentation system based on a network of ground-based control stations and communication satellites Luch 5A and Luch 5B. Additional satellites may use Molniya orbit, Tundra orbit, geosynchronous orbit, or inclined orbit to offer increased regional availability, similar to Japanese QZSS system.
Satellites.
The main contractor of the GLONASS program is Joint Stock Company Reshetnev Information Satellite Systems (ISS Reshetnev, formerly called NPO-PM). The company, located in Zheleznogorsk, is the designer of all GLONASS satellites, in cooperation with the Institute for Space Device Engineering (:ru:РНИИ КП) and the Russian Institute of Radio Navigation and Time. Serial production of the satellites is accomplished by the company PC Polyot in Omsk.
Over the three decades of development, the satellite designs have gone through numerous improvements, and can be divided into three generations: the original GLONASS (since 1982), GLONASS-M (since 2003) and GLONASS-K (since 2011). Each GLONASS satellite has a GRAU designation 11F654, and each of them also has the military "Cosmos-NNNN" designation.
First generation.
The true first generation of GLONASS (also called Uragan) satellites were all three-axis stabilized vehicles, generally weighing and were equipped with a modest propulsion system to permit relocation within the constellation. Over time they were upgraded to Block IIa, IIb, and IIv vehicles, with each block containing evolutionary improvements.
Six Block IIa satellites were launched in 1985–1986 with improved time and frequency standards over the prototypes, and increased frequency stability. These spacecraft also demonstrated a 16-month average operational lifetime. Block IIb spacecraft, with a two-year design lifetimes, appeared in 1987, of which a total of 12 were launched, but half were lost in launch vehicle accidents. The six spacecraft that made it to orbit worked well, operating for an average of nearly 22 months.
Block IIv was the most prolific of the first generation. Used exclusively from 1988 to 2000, and continued to be included in launches through 2005, a total of 25 satellites were launched. The design life was three years, however numerous spacecraft exceeded this, with one late model lasting 68 months.
Block II satellites were typically launched three at a time from the Baikonur Cosmodrome using Proton-K Blok-DM-2 or Proton-K Briz-M boosters. The only exception was when, on two launches, an Etalon geodetic reflector satellite was substituted for a GLONASS satellite.
Second generation.
The second generation of satellites, known as Glonass-M, were developed beginning in 1990 and first launched in 2003. These satellites possess a substantially increased lifetime of seven years and weigh slightly more at . They are approximately in diameter and high, with a solar array span of for an electrical power generation capability of 1600 watts at launch. The aft payload structure houses 12 primary antennas for L-band transmissions. Laser corner-cube reflectors are also carried to aid in precise orbit determination and geodetic research. On-board cesium clocks provide the local clock source. Glonass-M consisting 31 satellites ranging from satellite index 21 - 92 and with 4 spare active satellites.
A total of 41 second generation satellites were launched through the end of 2013. As with the previous generation, the second generation spacecraft were launched in triplets using Proton-K Blok-DM-2 or Proton-K Briz-M boosters. Some where launched alone with Soyuz-2-1b/Fregat
On July 30, 2015, ISS Reshetnev announced that it had completed the last GLONASS-M (N° 61) spacecraft and it was putting it in storage waiting for launch, along an additional eight already built satellites.
Third generation.
GLONASS-K is a substantial improvement of the previous generation: it is the first unpressurised GLONASS satellite with a much reduced mass ( versus of GLONASS-M). It has an operational lifetime of 10 years, compared to the 7-year lifetime of the second generation GLONASS-M. It will transmit more navigation signals to improve the system's accuracy—including new CDMA signals in the L3 and L5 bands, which will use modulation similar to modernized GPS, Galileo, and Compass. Glonass-K consist of 26 satellites having satellite index 65-98 and widely used in Russian Military space. The new satellite's advanced equipment—made solely from Russian components—will allow the doubling of GLONASS' accuracy. As with the previous satellites, these are 3-axis stabilized, nadir pointing with dual solar arrays. The first GLONASS-K satellite was successfully launched on 26 February 2011.
Due to their weight reduction, GLONASS-K spacecraft can be launched in pairs from the Plesetsk Cosmodrome launch site using the substantially lower cost Soyuz-2.1b boosters or in six-at-once from the Baikonur Cosmodrome using Proton-K Briz-M launch vehicles.
Ground control.
The ground control segment of GLONASS is almost entirely located within former Soviet Union territory, except for a station in Brasilia, Brazil. The Ground Control Center and Time Standards is located in Moscow and the telemetry and tracking stations are in Saint Petersburg, Ternopil, Eniseisk and Komsomolsk-na-Amure.
Receivers.
Septentrio, Topcon, C-Nav, JAVAD, Magellan Navigation, Novatel, Leica Geosystems, Hemisphere GNSS and Trimble Inc produce GNSS receivers making use of GLONASS. NPO Progress describes a receiver called "GALS-A1", which combines GPS and GLONASS reception. SkyWave Mobile Communications manufactures an Inmarsat-based satellite communications terminal that uses both GLONASS and GPS. , some of the latest receivers in the Garmin eTrex line also support GLONASS (along with GPS). Garmin also produce a standalone Bluetooth receiver, the GLOTM for Aviation, which combines GPS, WAAS and GLONASS. Various smartphones from 2011 onwards have integrated GLONASS capability, including devices from Xiaomi Tech Company (Xiaomi Phone 2), Sony Ericsson, ZTE, Huawei, Samsung (Galaxy Note, Galaxy Note II, Galaxy S3, Galaxy S4), Apple (iPhone 4S, iPhone 5, iPhone 5C, iPhone 5S, iPhone 6 and iPhone 6 Plus, iPhone 6s, iPhone 6s Plus, and iPhone SE), iPad Mini (LTE models only), iPad Mini 2 (LTE models only), iPad Mini 3 (LTE models only), iPad Mini 4 (LTE models only) iPad (3rd generation and 4th Generation, 4G and LTE models only iPad Air (LTE models only) and iPad Air 2 (LTE models only) and Apple's flagship iPad Pro 12.9" and 9.7", HTC, LG, Motorola and Nokia.
Status.
Availability.
, the GLONASS constellation status is:
The system requires 18 satellites for continuous navigation services covering the entire territory of the Russian Federation, and 24 satellites to provide services worldwide. The GLONASS system covers 100% of worldwide territory.
On 2 April 2014 the system experienced a technical failure that resulted in practical unavailability of the navigation signal for around 12 hours.
On 14–15 April 2014 nine GLONASS satellites experienced a technical failure due to software problems.
On 19 February 2016 three GLONASS satellites experienced a technical failure: the batteries of GLONASS-738 exploded, the batteries of GLONASS-737 were depleted, and GLONASS-736 experienced a stationkeeping failure due to human error during maneuvering. GLONASS-737 and GLONASS-736 are expected to be operational again after maintenance, and one new satellite (GLONASS-751) to replace GLONASS-738 is expected to complete commissioning in early March. The full capacity of the satellite group is expected to be restored in the middle of March.
Accuracy.
According to Russian System of Differentional Correction and Monitoring's data, , precisions of GLONASS navigation definitions (for p=0.95) for latitude and longitude were with mean number of navigation space vehicles (NSV) equals 7—8 (depending on station). In comparison, the same time precisions of GPS navigation definitions were with mean number of NSV equals 6—11 (depending on station). Civilian GLONASS used alone is therefore very slightly less accurate than GPS. On high latitudes (north or south), GLONASS' accuracy is better than that of GPS due to the orbital position of the satellites.
Some modern receivers are able to use both GLONASS and GPS satellites together, providing greatly improved coverage in urban canyons and giving a very fast time to fix due to over 50 satellites being available. In indoor, urban canyon or mountainous areas, accuracy can be greatly improved over using GPS alone. For using both navigation systems simultaneously, precisions of GLONASS/GPS navigation definitions were with mean number of NSV equals 14—19 (depends on station).
In May 2009, Anatoly Perminov, then director of the Russian Federal Space Agency, stated that actions were undertaken to expand GLONASS's constellation and to improve the ground segment to increase the navigation definition of GLONASS to an accuracy of by 2011. In particular, the latest satellite design, GLONASS-K has the ability to double the system's accuracy once introduced. The system's ground segment is also to undergo improvements. As of early 2012, sixteen positioning ground stations are under construction in Russia and in the Antarctic at the Bellingshausen and Novolazarevskaya bases. New stations will be built around the southern hemisphere from Brazil to Indonesia. Together, these improvements are expected to bring GLONASS' accuracy to 0.6 m or better by 2020.

</doc>
<doc id="46150" url="https://en.wikipedia.org/wiki?curid=46150" title="Lua (programming language)">
Lua (programming language)

Lua ( , from meaning "moon"; explicitly not "LUA" because it is not an acronym) is a lightweight multi-paradigm programming language designed primarily for embedded systems and clients. Lua is cross-platform since it is written in ANSI C, and has a relatively simple C API.
Lua was originally designed in 1993 as a language for extending software applications to meet the increasing demand for customization at the time. It provided the basic facilities of most procedural programming languages, but more complicated or domain-specific features were not included; rather, it included mechanisms for extending the language, allowing programmers to implement such features. As Lua was intended to be a general embeddable extension language, the designers of Lua focused on improving its speed, portability, extensibility, and ease-of-use in development.
History.
Lua was created in 1993 by Roberto Ierusalimschy, Luiz Henrique de Figueiredo, and Waldemar Celes, members of the Computer Graphics Technology Group (Tecgraf) at the Pontifical Catholic University of Rio de Janeiro, in Brazil.
From 1977 until 1992, Brazil had a policy of strong trade barriers (called a market reserve) for computer hardware and software. In that atmosphere, Tecgraf's clients could not afford, either politically or financially, to buy customized software from abroad. Those reasons led Tecgraf to implement the basic tools it needed from scratch.
Lua's historical "father and mother" were the data-description/configuration languages "SOL" (Simple Object Language) and "DEL" (data-entry language). They had been independently developed at Tecgraf in 1992–1993 to add some flexibility into two different projects (both were interactive graphical programs for engineering applications at Petrobras company). There was a lack of any flow-control structures in SOL and DEL, and Petrobras felt a growing need to add full programming power to them.
As the language's authors wrote, in "The Evolution of Lua":
Lua 1.0 was designed in such a way that its object constructors, being then slightly different from the current light and flexible style, incorporated the data-description syntax of SOL (hence the name Lua – "sol" is Portuguese for sun; "lua" is moon). Lua syntax for control structures was mostly borrowed from Modula (if, while, repeat/until), but also had taken influence from CLU (multiple assignments and multiple returns from function calls, as a simpler alternative to reference parameters or explicit pointers), C++ ("neat idea of allowing a local variable to be declared only where we need it"), SNOBOL and AWK (associative arrays). In an article published in "Dr. Dobb's Journal", Lua's creators also state that LISP and Scheme with their single, ubiquitous data structure mechanism (the list) were a major influence on their decision to develop the table as the primary data structure of Lua.
Lua semantics have been increasingly influenced by Scheme over time, especially with the introduction of anonymous functions and full lexical scoping.
Versions of Lua prior to version 5.0 were released under a license similar to the BSD license. From version 5.0 onwards, Lua has been licensed under the MIT License. Both are permissive free software licences and are almost identical.
Features.
Lua is commonly described as a "multi-paradigm" language, providing a small set of general features that can be extended to fit different problem types, rather than providing a more complex and rigid specification to match a single paradigm. Lua, for instance, does not contain explicit support for inheritance, but allows it to be implemented with metatables. Similarly, Lua allows programmers to implement namespaces, classes, and other related features using its single table implementation; first-class functions allow the employment of many techniques from functional programming; and full lexical scoping allows fine-grained information hiding to enforce the principle of least privilege.
In general, Lua strives to provide flexible meta-features that can be extended as needed, rather than supply a feature-set specific to one programming paradigm. As a result, the base language is light – the full reference interpreter is only about 180 kB compiled – and easily adaptable to a broad range of applications.
Lua is a dynamically typed language intended for use as an extension or scripting language, and is compact enough to fit on a variety of host platforms. It supports only a small number of atomic data structures such as boolean values, numbers (double-precision floating point by default), and strings. Typical data structures such as arrays, sets, lists, and records can be represented using Lua's single native data structure, the table, which is essentially a heterogeneous associative array.
Lua implements a small set of advanced features such as first-class functions, garbage collection, closures, proper tail calls, coercion (automatic conversion between string and number values at run time), coroutines (cooperative multitasking) and dynamic module loading.
By including only a minimum set of data types, Lua attempts to strike a balance between power and size.
Example code.
The classic hello world program can be written as follows:
<syntaxhighlight lang="lua">
print("Hello World!")
</syntaxhighlight>
It can also be written as
<syntaxhighlight lang="lua">
io.write('Hello World!\n')
</syntaxhighlight>
or, the example given on the Lua website
<syntaxhighlight lang="lua">
io.write("Hello world, from ", _VERSION, "!\n")
</syntaxhighlight>
Comments use the following syntax, similar to that of Ada, Eiffel, Haskell, SQL and VHDL:
<syntaxhighlight lang="lua">
-- A comment in Lua starts with a double-hyphen and runs to the end of the line.
-- Multi-line strings & comments
--[=[ Comments like this can have other --comments nested. ]=]
</syntaxhighlight>
The factorial function is implemented as a function in this example:
<syntaxhighlight lang="lua">
function factorial(n)
end
</syntaxhighlight>
Loops.
Lua has four types of loops: the while loop, the repeat loop (similar to a do while loop), the numeric for loop, and the generic for loop.
<syntaxhighlight lang="lua">
--condition = true
while condition do
end
repeat
until condition
for i = first,last,delta do --delta may be negative, allowing the for loop to count down or up
end
</syntaxhighlight>
The generic for loop:
<syntaxhighlight lang="lua">
for key, value in pairs(_G) do
end
</syntaxhighlight>
would iterate over the table _G using the standard iterator function pairs, until it returns nil.
Functions.
Lua's treatment of functions as first-class values is shown in the following example, where the print function's behavior is modified:
<syntaxhighlight lang="lua">
do
end
</syntaxhighlight>
Any future calls to print will now be routed through the new function, and because of Lua's lexical scoping, the old print function will only be accessible by the new, modified print.
Lua also supports closures, as demonstrated below:
<syntaxhighlight lang="lua">
function addto(x)
end
fourplus = addto(4)
print(fourplus(3)) -- Prints 7
--This can also be achieved by calling the function in the following way:
print(addto(4)(3))
-- This is because we are calling the returned function from `addto(4)' with the argument `3' directly.
</syntaxhighlight>
A new closure for the variable x is created every time addto is called, so that each new anonymous function returned will always access its own x parameter. The closure is managed by Lua's garbage collector, just like any other object.
Tables.
Tables are the most important data structures (and, by design, the only built-in composite data type) in Lua, and are the foundation of all user-created types. They are conceptually similar to associative arrays in PHP, dictionaries in Python and hashes in Ruby or Perl.
A table is a collection of key and data pairs, where the data is referenced by key; in other words, it's a hashed heterogeneous associative array. A key (index) can be any value but nil and NaN. A numeric key of 1 is considered distinct from a string key of "1".
Tables are created using the codice_1 constructor syntax:
<syntaxhighlight lang="lua">
a_table = {} -- Creates a new, empty table
</syntaxhighlight>
Tables are always passed by reference (See Call by sharing):
<syntaxhighlight lang="lua">
a_table = {x = 10} -- Creates a new table, with one entry mapping "x" to the number 10.
print(a_table["x"]) -- Prints the value associated with the string key, in this case 10.
b_table = a_table
b_table["x"] = 20 -- The value in the table has been changed to 20.
print(b_table["x"]) -- Prints 20.
print(a_table["x"]) -- Also prints 20, because a_table and b_table both refer to the same table.
</syntaxhighlight>
As record.
A table is often used as structure (or record) by using strings as keys. Because such use is very common, Lua features a special syntax for accessing such fields.
Example:
<syntaxhighlight lang="lua">
point = { x = 10, y = 20 } -- Create new table
print(point["x"]) -- Prints 10
print(point.x) -- Has exactly the same meaning as line above. The easier-to-read
</syntaxhighlight>
Quoting the Lua 5.1 Reference Manual:
"The syntax var.Name is just syntactic sugar for var['Name'];"
As namespace.
By using a table to store related functions, it can act as a namespace.
<syntaxhighlight lang="lua">
Point.new = function(x, y)
end
Point.set_x = function(point, x)
end
</syntaxhighlight>
As array.
By using a numerical key, the table resembles an array data type. Lua arrays are 1-based: the first index is 1 rather than 0 as it is for many other programming languages (though an explicit index of 0 is allowed).
A simple array of strings:
<syntaxhighlight lang="lua">
array = { "a", "b", "c", "d" } -- Indices are assigned automatically.
print(array) -- Prints "b". Automatic indexing in Lua starts at 1.
print(#array) -- Prints 4. # is the length operator for tables and strings.
array = "z" -- Zero is a legal index.
print(#array) -- Still prints 4, as Lua arrays are 1-based.
</syntaxhighlight>
The length of a table t is defined to be any integer index n such that tis not nil and t[n+1 is nil; moreover, if t is nil, n can be zero. For a regular array, with non-nil values from 1 to a given n, its length is exactly that n, the index of its last value. If the array has "holes" (that is, nil values between other non-nil values), then #t can be any of the indices that directly precedes a nil value (that is, it may consider any such nil value as the end of the array).
A two dimensional table:
<syntaxhighlight lang="lua">
ExampleTable =
print(ExampleTable) -- Prints "3"
print(ExampleTable) -- Prints "8"
</syntaxhighlight>
An array of objects:
<syntaxhighlight lang="lua">
function Point(x, y) -- "Point" object constructor
end
array = { Point(10, 20), Point(30, 40), Point(50, 60) } -- Creates array of points
print(array.y) -- Prints 40
</syntaxhighlight>
Using a hash map to emulate an array normally is slower than using an actual array; however, Lua tables are optimized for use as arrays to help avoid this issue.
Metatables.
Extensible semantics is a key feature of Lua, and the metatable concept allows Lua's tables to be customized in powerful ways. The following example demonstrates an "infinite" table. For any formula_1, fibs will give the formula_1th Fibonacci number using dynamic programming and memoization.
<syntaxhighlight lang="lua">
fibs = { 1, 1 } -- Initial values for fibsand fibs[2.
setmetatable(fibs, {
})
</syntaxhighlight>
Object-oriented programming.
Although Lua does not have a built-in concept of classes, they can be implemented using two language features: first-class functions and tables. By placing functions and related data into a table, an object is formed. Inheritance (both single and multiple) can be implemented via the metatable mechanism, telling the object to look up nonexistent methods and fields in parent object(s).
There is no such concept as "class" with these techniques; rather, prototypes are used, as in the programming languages Self or JavaScript. New objects are created either with a factory method (that constructs new objects from scratch), or by cloning an existing object.
Lua provides some syntactic sugar to facilitate object orientation. To declare member functions inside a prototype table, one can use function table:func(args), which is equivalent to function table.func(self, args). Calling class methods also makes use of the colon: object:func(args) is equivalent to object.func(object, args).
Creating a basic vector object:
<syntaxhighlight lang="lua">
Vector.__index = Vector
function Vector:new(x, y, z) -- The constructor
end
function Vector:magnitude() -- Another method
end
local vec = Vector:new(0, 1, 0) -- Create a vector
print(vec:magnitude()) -- Call a method (output: 1)
print(vec.x) -- Access a member variable (output: 0)
</syntaxhighlight>
Internals.
Lua programs are not interpreted directly from the textual Lua file, but are compiled into bytecode, which is then run on the Lua virtual machine. The compilation process is typically invisible to the user and is performed during run-time, but it can be done offline in order to increase loading performance or reduce the memory footprint of the host environment by leaving out the compiler. Lua bytecode can also be produced and executed from within Lua, using the dump function from the string library and the load/loadstring/loadfile functions. The Lua compiler for version 5.3.1 was built from approximately 23,000 lines of code.
Like most CPUs, and unlike most virtual machines (which are stack-based), the Lua VM is register-based, and therefore more closely resembles an actual hardware design. The register architecture both avoids excessive copying of values and reduces the total number of instructions per function. The virtual machine of Lua 5 is one of the first register-based pure VMs to have a wide use. Perl's
Parrot and Android's Dalvik are two other well-known register-based VMs.
This example is the bytecode listing of the factorial function defined above (as shown by the luac 5.1 compiler):
C API.
Lua is intended to be embedded into other applications, and provides a C API for this purpose. The API is divided into two parts: the Lua core and the Lua auxiliary library.
The Lua API's design eliminates the need for manual reference management in C code, unlike Python's API. The API, like the language, is minimalistic. Advanced functionality is provided by the auxiliary library, which consists largely of preprocessor macros which assist with complex table operations.
Stack.
The Lua C API is stack based. Lua provides functions to push and pop most simple C data types (integers, floats, etc.) to and from the stack, as well as functions for manipulating tables through the stack. The Lua stack is somewhat different from a traditional stack; the stack can be indexed directly, for example. Negative indices indicate offsets from the top of the stack. For example, −1 is the top (most recently pushed value), while positive indices indicate offsets from the bottom (oldest value).
Marshalling data between C and Lua functions is also done using the stack. To call a Lua function, arguments are pushed onto the stack, and then the lua_call is used to call the actual function. When writing a C function to be directly called from Lua, the arguments are read from the stack.
Example.
Here is an example of calling a Lua function from C:
<syntaxhighlight lang="c">
int main(void)
</syntaxhighlight>
Running this example gives:
Special tables.
The C API also provides some special tables, located at various "pseudo-indices" in the Lua stack. At LUA_GLOBALSINDEX prior to Lua 5.2 is the globals table, _G from within Lua, which is the main namespace. There is also a registry located at LUA_REGISTRYINDEX where C programs can store Lua values for later retrieval.
Extension and binding.
It is possible to write extension modules using the Lua API. Extension modules are shared objects which can be used to extend the functionality of the interpreter by providing native facilities to Lua scripts. From the Lua side, such a module appears as a namespace table holding its functions and variables. Lua scripts may load extension modules using require, just like modules written in Lua itself.
A growing collection of modules known as "rocks" are available through a package management system called "LuaRocks", in the spirit of CPAN, RubyGems and Python Eggs.
Other modules can be found through the "Lua Addons" directory of the lua-users.org wiki.
Prewritten Lua bindings exist for most popular programming languages, including other scripting languages. For C++, there are a number of template-based approaches and some automatic binding generators.
Applications.
Video games.
In video game development, Lua is widely used as a scripting language by game programmers, perhaps due to its perceived easiness to embed, fast execution, and short learning curve.
In 2003, a poll conducted by GameDev.net showed Lua as the most popular scripting language for game programming. On 12 January 2012, Lua was announced as a winner of the Front Line Award 2011 from the magazine "Game Developer" in the category Programming Tools.
Other.
Other applications using Lua include:

</doc>
<doc id="46151" url="https://en.wikipedia.org/wiki?curid=46151" title="1480s BC">
1480s BC


</doc>
<doc id="46157" url="https://en.wikipedia.org/wiki?curid=46157" title="Garrett County, Maryland">
Garrett County, Maryland

Garrett County (gərɛt) is the westernmost county of the U.S. state of Maryland. As of the 2010 census, the population was 30,097, making it the third-least populous county in Maryland. Its county seat is Oakland. The county was named for John Work Garrett (1820–1884), president of the Baltimore and Ohio Railroad. Created from Allegany County, Maryland in 1872, it was the last Maryland county to be formed.
Garrett County has long been part of the media market of Pittsburgh, Pennsylvania. It is considered to be a part of Western Maryland.
The Commonwealth of Pennsylvania is to the north. The Maryland–Pennsylvania boundary was surveyed and marked between April 1765 and October 1767 by astronomer Charles Mason and surveyor Jeremiah Dixon. This boundary is commonly known as the Mason–Dixon line. The eastern border with Allegany County was defined by the Bauer Report, submitted to Governor Lloyd Lowndes, Jr. on November 9, 1898. The Potomac River and State of West Virginia lie to the south and west.
Garrett County lies in the Allegheny Mountains, which here form the western flank of the Appalachian Mountain Range. Hoye-Crest, a summit along Backbone Mountain, is the highest point in Maryland.
The Eastern Continental Divide runs along portions of Backbone Mountain. The western part of the county, drained by the Youghiogheny River, is the only part of Maryland within the Mississippi River drainage basin. All other parts of the county are in the Chesapeake Bay basin.
Garrett County contains over of parks, lakes, and publicly accessible forestland. Popular activities in the county include camping, hiking, backpacking, rock climbing, alpine and cross county skiing, snowmobiling, hunting, ice fishing, fly fishing, whitewater canoeing, kayaking, rafting, boating, swimming, sailing, horseback riding, and water skiing.
The National Register of Historic Places listings in Garrett County, Maryland has 20 National Register of Historic Places properties and districts, including Casselman Bridge, National Road a National Historic Landmark. Garrett County is part of Maryland's 6th congressional district.
History.
In the early 20th century, the railroad and tourism started to decline. Coal mining and timber production continued at a much slower pace. Today, tourism has made a dramatic rebound in the county with logging and farming making up the greatest part of the economic base. Due to a cold climate and lack of any large city, Garrett County has remained a sparsely populated rural area.
Law and government.
Government.
The County is governed by an elected Board of County Commissioners (the "Board"), whose three members serve four-year terms and must live in the District they represent. The Board is the traditional form of county government in Maryland and may exercise only such powers as are conferred by the General Assembly of Maryland.
The County is administered under a line organizational method, with the County Administrator responsible for the general administration of County Government. The administration of the County is centralized with the County Administrator responsible for overseeing the financial planning, annual budget process, personnel management, and direction and management of operations within the organization.
The county is part of Maryland's 6th congressional district and is the most Republican in the state. The Republican candidate for President has won in each of the last thirteen elections. In 2008, John McCain carried Garrett County by a 40.2% margin over Barack Obama, with Obama carrying Maryland by a 25.5% margin over McCain.
County seal.
On December 15, 1977, the seal of Garrett County went into effect by virtue of Resolution #7. The seal is elliptical, with the name "Garrett County" inscribed above the upper fourth of the ellipse, and "Maryland 1872" inscribed below the lower fourth of the ellipse. The date “1872" depicts the year of the formation of Garrett County. The seal illustrates a large snowflake to depict winter; water to represent sailing; and oaks and conifer to represent the county’s mountains. The colors are peacock blue for the sky and water. The blue and white background is divided by kelly green.
County flag.
The official flag for Garrett County is elliptical. The flag illustrates a large snowflake to depict winter; water to represent sailing; and oaks and conifer to represent the county’s mountains. The colors are peacock blue for the sky and water. The blue and white background is divided by kelly green.
Law enforcement.
The county is policed by the Garrett County Sheriff's Office and the Maryland State Police.
The state parks are police by the Department of Natural Resources Police.
Geography.
According to the U.S. Census Bureau, the county has a total area of , of which is land and (1.3%) is water. It is the second-largest county in Maryland by land area.
Garrett County is Maryland's westernmost county, bordered to the north by the Mason–Dixon line with Pennsylvania, to the south by the Potomac River and West Virginia, to the west by a land border with West Virginia, and to the east by a land border with Allegany County, Maryland. The county's northwesternmost point is approximately southeast of Pittsburgh, Pennsylvania, and its southeasternmost point is approximately northwest of Baltimore, Maryland.
Garrett County is located entirely within the highland zone of the Appalachian Mountains known variously as the Allegheny Mountains, the Allegheny Plateau, and the Appalachian Plateau. The county's highest elevations are located along four flat-topped ridges and range to a height of at Hoye-Crest along Backbone Mountain, the highest point in the state of Maryland. As is typical in the Allegheny region, broad flats generally lie below the ridge crests at elevations of approximately . River valleys are generally narrow and deep, with ravines typically 1,000 to below surrounding peaks.
The county contains over of parks, lakes, and publicly accessible forestland. It is drained by two river systems, the Potomac and the Youghiogheny. The Savage River, a tributary of the Potomac, drains about a third of the county. The Casselman River, a tributary of the Youghiogheny, flows north from the county’s central section into Pennsylvania. The Youghiogheny itself drains the westernmost area of the county and flows north into Pennsylvania, where it empties into the Monongahela River at McKeesport, just south of Pittsburgh.
Geologic points of interest.
The Glades.
The Glades' is of great scientific interest because it is an ombrotrophic system (fed solely by rainwater) with peat layers up to thick, and is one of the oldest examples of mountain peatland in the Appalachians.
On the western edge of the Savage River State Forest along Maryland Route 495 lies Bittinger, Maryland. Named after Henry Bittinger who first settled in the area, other German settlers moved in and took up the fertile farm land. On the eastern edge of Bittinger is one of the largest glades area of Garrett County. Geographically, this is an area which seems to have been affected by the last great ice sheet of North America. Two miles southeast of Bittinger, there is a large deposit of peat moss.
Loess Dunes.
In the Casselman River valley, south of Grantsville, Maryland and beside Maryland Route 495, one can see remains of geological evidence about the last great ice sheet over North America. A series of low mounds can be seen in the fields on the west side of Maryland Route 495 that are "loess" (wind-blown) material. Apparently, these are the only ones still visible in the northern part of Garrett County.
The mounds were formed when a glacier lake existed in the Casselman valley, and the ice around the edges of the frozen lake melted. Wind blew fine grains of earth into the water around the edges where it sank to the bottom, and the mounds were the result of the deposit of this wind-blown material.
Forests, rivers, caves.
See these articles for information on the forests, rivers and caves of Garrett County:
Parks and recreation.
State parks.
There are six state parks in Garrett County. All offer picnic and fishing areas; all but Casselman River State Park have hiking paths. Mountain bike paths, swimming areas, and boat launches and rentals are available at Deep Creek, Herrington Manor, and New Germany state parks. Rental cabins are available at Herrington Manor and New Germany state parks. Big Run, Deep Creek, Herrington Manor and New Germany state parks all offer canoeing, while campsites may be found at Big Run, Deep Creek, New Germany, and Swallow Falls state parks.
County parks.
Garrett County owns four park sites and fifteen recreation facilities. The parks are maintained in cooperation with local associations and civic groups. The recreation areas are attached to public schools and colleges and maintained by the Garrett County Board of Education.
Municipal parks.
The municipal parks of Garrett County provide sport facilities, hiking, bike and walk paths, playgrounds, picnic areas, boat ramps, and fishing.
Demographics.
2000 census.
As of the census of 2000, there were 29,846 people, 11,476 households, and 8,354 families residing in the county. The population density was 18/km² (46/sq mi). There were 16,761 housing units at an average density of 10/km² (26/sq mi). The racial makeup of the county was 98.83% White, 0.43% Black or African American, 0.07% Native American, 0.19% Asian, 0.02% Pacific Islander, 0.09% from other races, and 0.37% from two or more races. 0.44% of the population were Hispanic or Latino of any race. 36.1% were of German, 22.9% American, 9.6% English and 8.8% Irish ancestry.
There were 11,476 households out of which 32.60% had children under the age of 18 living with them, 60.70% were married couples living together, 8.40% had a female householder with no husband present, and 27.20% were non-families. 23.50% of all households were made up of individuals and 10.60% had someone living alone who was 65 years of age or older. The average household size was 2.55 and the average family size was 3.00.
In the county the population was spread out with 25.10% under the age of 18, 7.80% from 18 to 24, 27.60% from 25 to 44, 24.60% from 45 to 64, and 14.90% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 97.20 males. For every 100 females age 18 and over, there were 93.80 males.
The median income for a household in the county was $32,238, and the median income for a family was $37,811. Males had a median income of $29,469 versus $20,673 for females. The per capita income for the county was $16,219. 13.30% of the population and 9.80% of families were below the poverty line. Out of the total people living in poverty, 16.60% are under the age of 18 and 13.90% are 65 or older.
2010 census.
As of the 2010 United States Census, there were 30,097 people, 12,057 households, and 8,437 families residing in the county. The population density was . There were 18,854 housing units at an average density of . The racial makeup of the county was 97.8% white, 1.0% black or African American, 0.3% Asian, 0.1% American Indian, 0.1% from other races, and 0.7% from two or more races. Those of Hispanic or Latino origin made up 0.7% of the population. In terms of ancestry, 35.4% were German, 13.6% were American, 11.3% were Irish, and 11.3% were English.
Of the 12,057 households, 30.0% had children under the age of 18 living with them, 56.4% were married couples living together, 9.3% had a female householder with no husband present, 30.0% were non-families, and 25.5% of all households were made up of individuals. The average household size was 2.45 and the average family size was 2.92. The median age was 42.7 years.
The median income for a household in the county was $45,760 and the median income for a family was $56,545. Males had a median income of $40,035 versus $27,325 for females. The per capita income for the county was $23,888. About 8.9% of families and 12.5% of the population were below the poverty line, including 19.2% of those under age 18 and 12.1% of those age 65 or over.
Economy.
Garrett County produces natural gas, the only county in the state to do so. Much of the economic activity in the area centers around the outdoors. In the winter, the Wisp ski resort in Oakland and New Germany State Park's cross county skiing trail are frequent destinations, and Deep Creek Lake sees much activity in the summer. The state parks in the county are frequented year-round.
Transportation.
Airport.
Garrett County Airport (2G4) is a general aviation airport surrounded by the mountains of Western Maryland. The airport enhances the region's tourist industry and provides emergency air service evacuation and landing facilities for general aviation.
Media.
Garrett County is part of the Pittsburgh DMA, a regional media market centered in neighboring Pennsylvania.
Events.
Annual events include the Autumn Glory Festival, the Scottish Highland Festival, and the Garrett County Fair.
Communities.
Census-designated places.
The United States Census Bureau recognizes seven census-designated places (CDPs) in Garrett County.
Unincorporated communities.
The following communities are classified as populated places or locales by the Geographic Names Information System.

</doc>
<doc id="46159" url="https://en.wikipedia.org/wiki?curid=46159" title="Omaha, Nebraska">
Omaha, Nebraska

Omaha ( ) is the largest city in the state of Nebraska and the county seat of Douglas County. Omaha is located in the Midwestern United States on the Missouri River, about north of the mouth of the Platte River. Omaha is the anchor of the Omaha-Council Bluffs metropolitan area, which includes Council Bluffs, Iowa, across the Missouri River from Omaha. According to the 2010 census, Omaha's population was 408,958, making it the nation's 41st-largest city. According to the 2014 Population Estimates, Omaha's population was 446,599. Including its suburbs, Omaha formed the 60th-largest metropolitan area in the United States in 2013, with an estimated population of 895,151 residing in eight counties. The Omaha-Council Bluffs-Fremont, Nebraska-IA Combined Statistical Area is 931,667, according to the U.S. Census Bureau's 2013 estimate. There are nearly 1.3 million residents within the Greater Omaha area, comprising a 50-mile (80 km) radius of Downtown Omaha, the city's center.
Omaha's pioneer period began in 1854, when the city was founded by speculators from neighboring Council Bluffs, Iowa. The city was founded along the Missouri River, and a crossing called Lone Tree Ferry earned the city its nickname, the "Gateway to the West". Omaha introduced this new West to the world in 1898, when it played host to the World's Fair, dubbed the Trans-Mississippi Exposition. During the 19th century, Omaha's central location in the United States spurred the city to become an important national transportation hub. Throughout the rest of the 19th century, the transportation and jobbing sectors were important in the city, along with its railroads and breweries. In the 20th century, the Omaha Stockyards, once the world's largest, and its meatpacking plants gained international prominence.
Today, Omaha is the home to the headquarters of five Fortune 500 companies: mega-conglomerate Berkshire Hathaway; packaged-food giant ConAgra Foods; one of the world's largest construction companies, Kiewit Corporation; insurance and financial firm Mutual of Omaha; and the United States' largest railroad operator, Union Pacific Corporation. Berkshire Hathaway is headed by local investor Warren Buffett, one of the richest people in the world, according to a decade's worth of "Forbes Magazine" rankings, some of which have ranked him as high as No. 1. Omaha is also the home to five Fortune 1000 headquarters: Green Plains Renewable Energy, TD Ameritrade, Valmont Industries, Werner Enterprises, and West Corporation. Also headquartered in Omaha are First National Bank of Omaha, the largest privately held bank in the United States; three of the nation's largest 10 architecture/engineering firms: DLR Group, HDR, Inc., and Leo A Daly; the Gallup Organization, of Gallup Poll fame; and its riverfront Gallup University. Enron began in Omaha as Northern Natural Gas in 1930, before taking over a smaller Houston company in 1985 to form InterNorth, which Kenneth Lay moved permanently to Houston, in 1987.
The modern economy of Omaha is diverse and built on skilled knowledge jobs. In 2009, "Forbes" identified Omaha as the nation's number one "Best Bang-For-The Buck City" and ranked it number one on "America's Fastest-Recovering Cities" list. Tourism in Omaha benefits the city's economy greatly, with the annual College World Series providing important revenue and the city's Henry Doorly Zoo serving as the top attraction in Nebraska. Also, Omaha hosted the U.S. Olympic swim trials in 2008, 2012, and will host the event again in 2016.
Notable modern Omaha inventions include: the bobby pin and the "pink hair curler", at Omaha's Tip Top; Butter Brickle Ice Cream and the Reuben sandwich, conceived by a chef at the then-Blackstone Hotel on 33rd and Farnam Streets; cake mix, developed by Duncan Hines, then a division of Omaha's Nebraska Consolidated Mills, the forerunner to today's ConAgra Foods; center-pivot irrigation by the Omaha company now known as Valmont Corporation; Raisin Bran, developed by Omaha's Skinner Macaroni Co.; the ski lift, in 1936, by Omaha's Union Pacific Corp; the "Top 40" radio format, pioneered by Todd Storz, scion of Omaha's Storz Brewing Co., and head of Storz Broadcasting, which was the first in the U.S. to use the "Top 40" format at Omaha's KOWH Radio; and the TV dinner, developed by Omaha's Carl Swanson Co.
A character in a Rudyard Kipling essay claimed "dice were invented in Omaha, and the man who invented 'em, he made a colossal fortune."
History.
Various Native American tribes had lived in the land that became Omaha, including since the 17th century, the Omaha and Ponca, Dhegian-Siouan-language people who had originated in the lower Ohio River valley and migrated west by the early 17th century; Pawnee, Otoe, Missouri, and Ioway. The word "Omaha" (actually "Umoⁿhoⁿ" or "Umaⁿhaⁿ") means "Dwellers on the bluff".
In 1804 the Lewis and Clark Expedition passed by the riverbanks where the city of Omaha would be built. Between July 30 and August 3, 1804, members of the expedition, including Meriwether Lewis and William Clark, met with Oto and Missouria tribal leaders at the Council Bluff at a point about 20 miles (30 km) north of present-day Omaha. Immediately south of that area, Americans built several fur trading outposts in succeeding years, including Fort Lisa in 1812; Fort Atkinson in 1819; Cabanné's Trading Post, built in 1822, and Fontenelle's Post in 1823, in what became Bellevue. There was fierce competition among fur traders until John Jacob Astor created the monopoly of the American Fur Company. The Mormons built a town called Cutler's Park in the area in 1846. While it was temporary, the settlement provided the basis for further development in the future.
Through 26 separate treaties with the United States federal government, Native American tribes in Nebraska gradually ceded the lands currently comprising the state. The treaty and cession involving the Omaha area occurred in 1854 when the Omaha Tribe ceded most of east-central Nebraska. Logan Fontenelle, an interpreter for the Omaha and signatory to the 1854 treaty, played an essential role in those proceedings.
Pioneer Omaha.
Before it was legal to claim land in Indian Country, William D. Brown was operating the Lone Tree Ferry to bring settlers from Council Bluffs, Iowa to the area that became Omaha. Brown is generally credited as having the first vision for a city where Omaha now sits. The passage of the Kansas–Nebraska Act in 1854 was presaged by the staking out of claims around the area to become Omaha by residents from neighboring Council Bluffs. On July 4, 1854, the city was informally established at a picnic on Capital Hill, current site of Omaha Central High School. Soon after, the Omaha Claim Club was formed to provide vigilante justice for claim jumpers and others who infringed on the land of many of the city's founding fathers. Some of this land, which now wraps around Downtown Omaha, was later used to entice Nebraska Territorial legislators to an area called Scriptown. The Territorial capitol was located in Omaha, but when Nebraska became a state in 1867, the capital was relocated to Lincoln, south-west of Omaha. The U.S. Supreme Court later ruled against numerous landowners whose violent actions were condemned in "Baker v. Morton".
Many of Omaha's founding figures stayed at the Douglas House or the Cozzens House Hotel. Dodge Street was important early in the city's early commercial history; North 24th Street and South 24th Street developed independently as business districts, as well. Early pioneers were buried in Prospect Hill Cemetery and Cedar Hill Cemetery. Cedar Hill closed in the 1860s and its graves were moved to Prospect Hill, where pioneers were later joined by soldiers from Fort Omaha, African Americans and early European immigrants. There are several other historical cemeteries in Omaha, historical Jewish synagogues and historical Christian churches dating from the pioneer era, as well. The city's pioneering history is celebrated at two sculpture parks, Pioneer Courage and Spirit of Nebraska's Wilderness and The Transcontinental Railroad.
19th century.
The economy of Omaha boomed and busted through its early years. Omaha was a stopping point for settlers and prospectors heading west, either overland or via the Missouri River. The steamboat "Bertrand" sank north of Omaha on its way to the goldfields in 1865. Its massive collection of artifacts is on display at the nearby Desoto National Wildlife Refuge. The jobbing and wholesaling district brought new jobs, followed by the railroads and the stockyards. Groundbreaking for the First Transcontinental Railroad in 1863, provided an essential developmental boom for the city. The Union Pacific Railroad was authorized by the U.S. Congress to begin building westward railways in 1862; in January 1866 it commenced construction out of Omaha.
Equally as important, the Union Stockyards were founded in 1883. Within twenty years of the founding of the Union Stockyards in South Omaha, four of the five major meatpacking companies in the United States were located in Omaha. By the 1950s, half the city's workforce was employed in meatpacking and processing. Meatpacking, jobbing and railroads were responsible for most of the growth in the city from the late 19th century through the early decades of the 20th century.
Immigrants soon created ethnic enclaves throughout the city, including Irish in Sheelytown in South Omaha; Germans in the Near North Side, joined by the European Jews and black migrants from the South; Little Italy and Little Bohemia in South Omaha. Beginning in the late 19th century, Omaha's upper class lived in posh enclaves throughout the city, including the south and north Gold Coast neighborhoods, Bemis Park, Kountze Place, Field Club and throughout Midtown Omaha. They traveled the city's sprawling park system on boulevards designed by renowned landscape architect Horace Cleveland. The Omaha Horse Railway first carried passengers throughout the city, as did the later Omaha Cable Tramway Company and several similar companies. In 1888, the Omaha and Council Bluffs Railway and Bridge Company built the Douglas Street Bridge, the first pedestrian and wagon bridge between Omaha and Council Bluffs. Gambling, drinking and prostitution were widespread in the 19th century, first rampant in the city's Burnt District and later in the Sporting District. Controlled by Omaha's political boss Tom Dennison by 1890, criminal elements enjoyed support from Omaha's "perpetual" mayor, "Cowboy Jim" Dahlman, nicknamed for his eight terms as mayor. Calamities such as the Great Flood of 1881 did not slow down the city's violence. In 1882, the Camp Dump Strike pitted state militia against unionized strikers, drawing national attention to Omaha's labor troubles. The Governor of Nebraska had to call in U.S. Army troops from nearby Fort Omaha to protect strikebreakers for the Burlington Railroad, bringing along Gatling guns and a cannon for defense. When the event ended, one man was dead and several were wounded. In 1891, a mob hanged Joe Coe, an African-American porter after he was accused of raping a white girl. There were several other riots and civil unrest events in Omaha during this period as well.
In 1898, Omaha's leaders, under the guidance of Gurdon Wattles, held the Trans-Mississippi and International Exposition, touted as a celebration of agricultural and industrial growth throughout the Midwest. The Indian Congress, which drew more than 500 American Indians from across the country, was held simultaneously. More than 2 million visitors attended these events, located at Kountze Park and the Omaha Driving Park in the Kountze Place neighborhood.
20th century.
With dramatically increasing population in the 20th century, there was major civil unrest in Omaha, resulting from competition and fierce labor struggles. In 1900, Omaha was the center of a national uproar over the kidnapping of Edward Cudahy, Jr., the son of a local meatpacking magnate.
The city's labor and management clashed in bitter strikes, racial tension escalated as blacks were hired as strikebreakers, and ethnic strife broke out. A major riot by ethnic whites in South Omaha destroyed the city's Greek Town in 1909, completely driving out the Greek population.
The civil rights movement in Omaha has roots that extend back to 1912, when the first chapter of the National Association for the Advancement of Colored People west of the Mississippi River was founded in the city.
The Omaha Easter Sunday Tornado of 1913 destroyed much of the city's African-American community, in addition to much of Midtown Omaha.
Six years later, in 1919, the city was caught up in the Red Summer riots when thousands of ethnic whites marched from South Omaha to the courthouse to lynch a black worker, Willy Brown, a suspect in an alleged rape of a white woman. The mob burned the Douglas County Courthouse to get the prisoner, causing more than $1,000,000 damage. They hung and shot Will Brown, then burned his body. Troops were called in from Fort Omaha to quell the riot, prevent more crowds gathering in South Omaha, and to protect the black community in North Omaha.
The culture of North Omaha thrived throughout the 1920s through 1950s, with several creative figures, including Tillie Olsen, Wallace Thurman, Lloyd Hunter, and Anna Mae Winburn emerging from the vibrant Near North Side.
Musicians created their own world in Omaha, and also joined national bands and groups that toured and appeared in the city.
After the tumultuous Great Depression of the 1930s, Omaha rebounded with the development of Offutt Air Force Base just south of the city. The Glenn L. Martin Company operated a factory there in the 1940s that produced 521 B-29 "Superfortresses", including the "Enola Gay" and "Bockscar" used in the atomic bombing of Japan in World War II.
The construction of Interstates 80, 480 and 680, along with the North Omaha Freeway, spurred development. There was also controversy, particularly in North Omaha, where several neighborhoods were bisected by new routes. Creighton University hosted the DePorres Club, an early civil rights group whose sit-in strategies for integration of public facilities predated the national movement, starting in 1947.
Following the development of the Glenn L. Martin Company bomber manufacturing plant in Bellevue at the beginning of World War II, the relocation of the Strategic Air Command to the Omaha suburb in 1948 provided a major economic boost to the area.
From the 1950s through the 1960s, more than 40 insurance companies were headquartered in Omaha, including Woodmen of the World and Mutual of Omaha. By the late 1960s, the city rivaled, but never surpassed, the United States insurance centers of Hartford, Connecticut, New York City and Boston, Massachusetts.
After surpassing Chicago in meat processing by the late 1950s, Omaha suffered the loss of 10,000 jobs as both the railroad and meatpacking industries restructured. The city struggled for decades to shift its economy as workers suffered. Poverty became more entrenched among families who remained in North Omaha.
In the 1960s, three major race riots along North 24th Street destroyed the Near North Side's economic base, with recovery slow for decades. In 1969, Woodmen Tower was completed and became Omaha's tallest building and first major skyscraper at , a sign of renewal.
Since the 1970s, Omaha has continued expanding and growing, mostly to available land to the west. West Omaha has become home to the majority of the city's population. North and South Omaha's populations continue to be centers of new immigrants, with economic and racial diversity. In 1975 a major tornado, along with a major blizzard, caused more than $100 million in damages in 1975 dollars.
Downtown Omaha has since been rejuvenated in numerous ways, starting with the development of Gene Leahy Mall and W. Dale Clark Library in the late 1970s. In the 1980s, Omaha's fruit warehouses were converted into a shopping area called the Old Market.
The demolition of Jobber's Canyon in 1989 led to the creation of the ConAgra Foods campus. Several nearby buildings, including the Nash Block, have been converted into condominiums. The stockyards were taken down; the only surviving building is the Livestock Exchange Building, which was converted to multi-use and listed on the National Register of Historic Places.
A historic preservation movement in Omaha has led to a number of historic structures and districts being designated Omaha Landmarks or listed on the National Register of Historic Places. Much of the push toward preservation came after Omaha gained the notorious designation of having, in 1989, demolished the largest-ever National Register historic district in the United States, a record that still stands as of 2013. The Jobbers Canyon Historic District, along the Missouri River, was felled for a new headquarters campus for ConAgra Foods, a company which threatened to relocate if Omaha did not allow them to raze the city's historic district. The Jobber's Canyon warehouses had before then been allowed to deteriorate and were the scene of several fires set by the homeless population that had come to live in the abandoned buildings. At the time, there were no plans in place for revitalizing the buildings.
In the 1980s and 1990s, Omaha also saw major company headquarters leave the city, including Enron, founded in the city in 1930 and taken to Houston in 1987 by the now-notorious Kenneth Lay. First Data Corporation, a large credit-card processor, also was founded in Omaha in 1969; as of 2009, its headquarters are in Atlanta.
Inacom, founded in Omaha in 1991, was a technology company that customized computer systems for large businesses, and was on the Fortune 500 list from 1997 until 2000, when it filed for bankruptcy. Northwestern Bell, the Bell System affiliate for Northwestern states, had its headquarters in Omaha from its founding in 1896 until it moved to Denver in 1991 as US West. Level 3 Communications, a large Tier 1 network provider, was founded in Omaha in 1985 as Kiewit Diversified Group, a division of Kiewit Corporation, a Fortune 500 construction and mining company still headquartered in Omaha; Level 3 moved to Denver in 1998. World Com was founded by a merger with Omaha's MFS Communications, started as Metropolitan Fiber Systems in 1993. MFS, backed by Kiewit Corporation CEO Walter Scott and Warren Buffett, purchased UUNET, one of the largest Internet backbones in the world, for $2 billion in 1996. The now-infamous Bernie Ebbers purchased the much larger MFS for $14.3 billion in 1997 under his World Com. He moved headquarters of the merged company from Omaha to Mississippi.
21st century.
Around the start of the 21st century, several new downtown skyscrapers and cultural institutions were built. One First National Center was completed in 2002, surpassing the Woodmen Tower as the tallest building in Omaha as well as in the state at . The creation of the city's new North Downtown included the construction of the CenturyLink Center and the Slowdown/Film Streams development at North 14th and Webster Streets. Construction of the new TD Ameritrade Park began in 2009 and was completed in 2011, also in the North Downtown area, near the CenturyLink Center.
New construction has occurred throughout the city since the start of the 21st century. Important retail and office developments have occurred in West Omaha such as the Village Pointe shopping center and several business parks including First National Business Park and parks for Bank of the West and C&A Industries, Inc and Morgan Stanley Smith Barney and several others. Downtown and Midtown Omaha have both seen the development of a significant number of condominiums in recent years. In Midtown Omaha significant mixed-use projects are underway. The site of the former Ak-Sar-Ben arena has been redeveloped into a mixed use development Aksarben Village. In January 2009 Blue Cross Blue Shield of Nebraska announced plans to build a new 10 story, $98 million headquarters, in the Aksarben Village, completed in Spring 2011. Gordmans is also currently building their new corporate headquarters in Aksarben. The other major mixed-use development is Midtown Crossing at Turner Park. Developed by Mutual of Omaha, the development includes several condominium towers and retail businesses built around Omaha's Turner Park.
The Holland Performing Arts Center opened in 2005 near the Gene Leahy Mall and the Union Pacific Center opened in 2004.
There have also been several developments along the Missouri River waterfront in downtown. The Bob Kerrey Pedestrian Bridge was opened to foot and bicycle traffic on September 28, 2008. Started in 2003, RiverFront Place Condos first phase was completed in 2006 and is fully occupied and the second phase was opened in 2011. The development along Omaha's riverfront is attributed with prompting the City of Council Bluffs to move their own riverfront development time line forward.
In the summers of 2008 and 2012, the United States Olympic Team swimming trials were held in Omaha, at the Qwest/Century Link Center. The event was a highlight in the city's sports community, as well as a showcase for redevelopment in the downtown area.
Geography.
Omaha is located at . According to the United States Census Bureau, the city has a total area of , of which is land and is water. Situated in the Midwestern United States on the bank of the Missouri River in eastern Nebraska, much of Omaha is built in the Missouri River Valley. Other significant bodies of water in the Omaha-Council Bluffs metropolitan area include Lake Manawa, Papillion Creek, Carter Lake, Platte River and the Glenn Cunningham Lake. The city's land has been altered considerably with substantial land grading throughout Downtown Omaha and scattered across the city. East Omaha sits on a flood plain west of the Missouri River. The area is the location of Carter Lake, an oxbow lake. The lake was once the site of East Omaha Island and Florence Lake, which dried up in the 1920s.
The Omaha-Council Bluffs metropolitan area consists of eight counties; five in Nebraska and three in Iowa. The metropolitan area now includes Harrison, Pottawattamie, and Mills Counties in Iowa and Washington, Douglas, Sarpy, Cass, and Saunders Counties in Nebraska. This area was formerly referred to only as the Omaha Metropolitan Statistical Area and consisted of only five counties: Pottawattamie in Iowa, and Washington, Douglas, Cass, and Sarpy in Nebraska. The Omaha-Council Bluffs combined statistical area comprises the Omaha-Council Bluffs metropolitan statistical area and the Fremont Micropolitan statistical area; the CSA has a population of 858,720 (2005 Census Bureau estimate). Omaha ranks as the 42nd-largest city in the United States, and is the core city of its 60th-largest metropolitan area. There are currently no consolidated city-counties in the area; the City of Omaha studied the possibility extensively through 2003 and concluded, "The City of Omaha and Douglas County should merge into a municipal county, work to commence immediately, and that functional consolidations begin immediately in as many departments as possible, including but not limited to parks, fleet management, facilities management, local planning, purchasing and personnel."
Geographically, Omaha is considered as being located in the "Heartland" of the United States. Important environmental impacts on the natural habitat in the area include the spread of invasive plant species, restoring prairies and bur oak savanna habitats, and managing the whitetail deer population.
Omaha is home to several hospitals, located mostly along Dodge St (US6). Being the county seat, it is also the location of the county courthouse.
Neighborhoods.
Omaha is generally divided into six geographic areas: Downtown, Midtown, North Omaha, South Omaha, West Omaha, and East Omaha. West Omaha includes the Miracle Hills, Boys Town, Regency, and Gateway areas. There is also a small community in East Omaha. The city has a wide range of historical and new neighborhoods and suburbs that reflect its socioeconomic diversity. Early neighborhood development happened in ethnic enclaves, including Little Italy, Little Bohemia, Little Mexico and Greek Town. According to U.S. Census data, five European ethnic enclaves existed in Omaha in 1880, expanding to nine in 1900.
Around the start of the 20th century. the City of Omaha annexed several surrounding communities, including Florence, Dundee and Benson. At the same time, the city annexed all of South Omaha, including the Dahlman and Burlington Road neighborhoods. From its first annexation in 1857 (of East Omaha) to its recent and controversial annexation of Elkhorn, Omaha has continually had an eye towards growth.
Starting in the 1950s, development of highways and new housing led to movement of middle class to suburbs in West Omaha. Some of the movement was designated as white flight from racial unrest in the 1960s. Newer and poorer migrants lived in older housing close to downtown; those residents who were more established moved west into newer housing. Some suburbs are gated communities or have become edge cities. Recently, Omahans have made strides to revitalize the downtown and Midtown areas with the redevelopment of the Old Market, Turner Park, Gifford Park, and the designation of the Omaha Rail and Commerce Historic District.
Landmark preservation.
Omaha is home to dozens of nationally, regionally and locally significant landmarks. The city has more than a dozen historic districts, including Fort Omaha Historic District, Gold Coast Historic District, Omaha Quartermaster Depot Historic District, Field Club Historic District, Bemis Park Historic District, and the South Omaha Main Street Historic District. Omaha is notorious for its 1989 demolition of 24 buildings in the Jobbers Canyon Historic District, which represents to date the largest loss of buildings on the National Register. The only original building surviving of that complex is the Nash Block.
Omaha has almost one hundred individual properties listed on the National Register of Historic Places, including the Bank of Florence, Holy Family Church, the Christian Specht Building and the Joslyn Castle. There are also three properties designated as National Historic Landmarks.
Locally designated landmarks, including residential, commercial, religious, educational, agricultural and socially significant locations across the city, honor Omaha's cultural legacy and important history. The City of Omaha Landmarks Heritage Preservation Commission is the government body that works with the mayor of Omaha and the Omaha City Council to protect historic places. Important history organizations in the community include the Douglas County Historical Society.
Climate.
Omaha, due to its latitude of 41.26˚ N and location far from moderating bodies of water or mountain ranges, displays a humid continental climate (Köppen "Dfa"), with hot, humid summers and cold, relatively dry winters. July averages , with moderate, but sometimes-high humidity and relatively frequent thunderstorms, usually rather violent and capable of spawning severe weather or tornadoes; temperatures reach on 29 days and on 1.7 days annually. The January daily average is , with lows reaching on 11 days annually. The lowest temperature recorded in the city was on January 5, 1884, and the highest on July 25, 1936. Average yearly precipitation is , falling mostly in the warmer months. What precipitation that does fall in winter usually takes the form of snow, with average seasonal snowfall being .
Based on 30-year averages obtained from NOAA's National Climatic Data Center for the months of December, January and February, Weather Channel ranked Omaha the 5th coldest major U.S. city as of 2014.
Demographics.
2010 census.
As of the census of 2010, there were 408,958 people, 162,627 households, and 96,477 families residing in the city. The population density was . There were 177,518 housing units at an average density of . The racial makeup of the city was 73.1% White, 13.7% African American, 0.8% Native American, 2.4% Asian, 0.1% Pacific Islander, 6.9% from other races, and 3.0% from two or more races. Hispanic or Latino of any race were 13.1% of the population. Non-Hispanic Whites were 68.0% of the population.
There were 162,627 households of which 31.3% had children under the age of 18 living with them, 40.6% were married couples living together, 13.7% had a female householder with no husband present, 4.9% had a male householder with no wife present, and 40.7% were non-families. 32.3% of all households were made up of individuals and 9.3% had someone living alone who was 65 years of age or older. The average household size was 2.45 and the average family size was 3.14.
The median age in the city was 33.5 years. 25.1% of residents were under the age of 18; 11.4% were between the ages of 18 and 24; 27.9% were from 25 to 44; 24.4% were from 45 to 64; and 11.4% were 65 years of age or older. The gender makeup of the city was 49.2% male and 50.8% female.
2000 census.
As of the census of 2000, there were 390,007 people, 156,738 households, and 94,983 families residing within city limits. The population density was 3,370.7 people per square mile (1,301.5/km2). There were 165,731 housing units at an average density of 1,432.4 per square mile (553.1/km2). The racial makeup of the city was 78.4% White, 13.3% African American, 0.7% Native American, 1.7% Asian, 0.1% Pacific Islander, 3.9% from other races, and 1.9% from two or more races. 7.5% of the population were Hispanic or Latino of any race.
The median income for a household in the city was US$40,006, and the median income for a family was $50,821. Males had a median income of $34,301 versus $26,652 for females. The per capita income for the city was $21,756. 11.3% of the population and 7.8% of families lived below the poverty line. Out of the total population, 15.6% of those under the age of 18 and 7.4% of those 65 and older were living below the poverty line.
People.
Native Americans were the first residents of the Omaha area. The city of Omaha was established by European Americans from neighboring Council Bluffs who arrived from the Northeast United States a few years earlier. While much of the early population was of Yankee stock, over the next 100 years numerous ethnic groups moved to the city. In 1910, the Census Bureau reported Omaha's population as 96.4% White and 3.6% Black. Irish immigrants in Omaha originally moved to an area in present-day North Omaha called "Gophertown", as they lived in dirt dugouts. That population was followed by Polish immigrants in the Sheelytown neighborhood, and many immigrants were recruited for jobs in South Omaha's stockyards and meatpacking industry. The German community in Omaha was largely responsible for founding its once-thriving beer industry, including the Metz, Krug, Falstaff and the Storz breweries.
Since its founding, ethnic groups in the city have clustered in enclaves in north, south and downtown Omaha. In its early days, the sometimes lawless nature of a new frontier city included crime, such as illicit gambling and riots.
In the early 20th century, Jewish immigrants set up numerous businesses along the North 24th Street commercial area. It suffered with the loss of industrial jobs in the 1960s and later, the shifting of population west of the city. The commercial area is now the center of the African American community, concentrated in North Omaha. The African-American community has maintained its social and religious base, while it is currently experiencing an economic revitalization.
The Little Italy neighborhood grew south of downtown, as many Italian immigrants came to the city to work in the Union Pacific shops. Scandinavians first came to Omaha as Mormon settlers in the Florence neighborhood. Czechs had a strong political and cultural voice in Omaha, and were involved in a variety of trades and businesses, including banks, wholesale houses, and funeral homes. The Notre Dame Academy and Convent and Czechoslovak Museum are legacies of their residence. Today the legacy of the city's early European immigrant populations is evident in many social and cultural institutions in Downtown and South Omaha.
Mexicans originally immigrated to Omaha to work in the rail yards. Today they compose the majority of South Omaha's Hispanic population and many have taken jobs in meat processing. Other significant early ethnic populations in Omaha included Danes, Poles, and Swedes.
A growing number of African immigrants have made their homes in Omaha in the last twenty years. There are approximately 8,500 Sudanese living in Omaha, comprising the largest population of Sudanese refugees in the United States. Most have immigrated since 1995 because of warfare in their nation. Ten different tribes are represented, including the Nuer, Dinka, Equatorians, Maubans and Nubians. Most Sudanese people in Omaha speak the Nuer language. Other Africans have immigrated to Omaha as well, with one-third from Nigeria, and significant populations from Kenya, Togo, Cameroon and Ghana.
With the expansion of railroad and industrial jobs in meatpacking, Omaha attracted many new immigrants and migrants. As the major city in Nebraska, it has historically been more racially and ethnically diverse than the rest of the state. At times rapid population change, overcrowded housing and job competition have aroused racial and ethnic tensions. Around the start of the 20th century, violence towards new immigrants in Omaha often erupted out of suspicions and fears.
The Greek Town Riot in 1909 flared after increased Greek immigration, Greeks' working as strikebreakers, and the killing of an Irish policeman provoked violence among earlier immigrants such as ethnic Irish. That mob violence forced the Greek immigrant population to flee from the city. By 1910, 53.7% of Omaha's residents and 64.2% of South Omaha's residents were foreign born or had at least one parent born outside of America. Six years after the Greek Town Riot, in 1915, a Mexican immigrant named Juan Gonzalez was killed by a mob near Scribner, a town in the Greater Omaha metropolitan area. The event occurred after an Omaha Police Department officer was investigating a criminal operation selling goods stolen from the nearby railroad yards. Racial profiling targeted Gonzalez as the culprit. After escaping the city, he was trapped along the Elkhorn River, where the mob, including several policemen from Omaha, shot him more than twenty times. Afterward it was discovered that Gonzalez was unarmed, and that he had a reliable alibi for the time of the murder. Nobody was ever indicted for his lynching. In the fall of 1919, following Red Summer, postwar social and economic tensions, the earlier hiring of blacks as strikebreakers, and job uncertainty contributed to a mob from South Omaha lynching Willy Brown and the ensuing Omaha Race Riot. Trying to defend Brown, the city's mayor, Edward Parsons Smith, was lynched also, surviving only after a quick rescue.
Similar to other industrial cities in the U.S., Omaha suffered severe job losses in the 1950s, more than 10,000 in total, as both the railroad and meatpacking industries restructured. Stockyards and packing plants were located closer to ranches, and union achievements were lost as wages declined in surviving jobs. Many workers left the area if they could get to other jobs. Poverty deepened in areas of the city whose residents had depended on those jobs, specifically North and South Omaha. At the same time, with reduced revenues, the city had less financial ability to respond to longstanding problems. Despair after the assassination of Dr. Martin Luther King, Jr. in April 1968 contributed to riots in North Omaha, including one at the Logan Fontenelle Housing Project. For some, the Civil Rights Movement in Omaha, Nebraska evolved towards black nationalism, as the Black Panther Party was involved in tensions in the late 1960s. Organizations such as the Black Association for Nationalism Through Unity became popular among the city's African-American youth. This tension culminated in the "cause célèbre" trial of the Rice/Poindexter Case, in which an Omaha Police Department officer was killed by a bomb while answering an emergency call. 
Whites in Omaha have followed the white flight pattern, suburbanizing to West Omaha over time. In the late 1990s and early 2000s, gang violence and incidents between the Omaha Police and black residents undermined relations between groups in North and South Omaha. More recent Hispanic immigrants, concentrated in South Omaha, have struggled to earn living wages in meatpacking, adapt to a new society, and deal with discrimination.
Economy.
According to "USA Today", Omaha ranks eighth among the nation's 50 largest cities in both per-capita billionaires and Fortune 500 companies. With diversification in several industries, including banking, insurance, telecommunications, architecture/construction, and transportation, Omaha's economy has grown dramatically since the early 1990s. In 2001 "Newsweek" identified Omaha as one of the Top 10 high-tech havens in the nation. Six national fiber optic networks converge in Omaha.
Omaha's most prominent businessman is Warren Buffett, nicknamed the "Oracle of Omaha", who is regularly ranked one of the richest people in the world. Five Omaha-based companies: Berkshire Hathaway, ConAgra Foods, Union Pacific Railroad, Mutual of Omaha, and Kiewit Corporation, are among the "Fortune" 500.
Omaha is the headquarters of several other major corporations, including the Gallup Organization, TD Ameritrade, infoGROUP, Werner Enterprises, First National Bank, Gavilon and First Comp Insurance. Many large technology firms have major operations or operational headquarters in Omaha, including Bank of the West, First Data, PayPal and LinkedIn. The city is also home to three of the 30 largest architecture firms in the United States, including HDR, Inc., DLR Group, Inc., and Leo A Daly. Omaha has the fifth highest percentage of low-income African Americans in the country. In 2013, "Forbes"' named Omaha among its list of the Best Places for Business and Careers.
Top employers.
According to the Greater Omaha Economic Development Partnership, the largest regional employers are:
Tourism.
Tourist attractions in Omaha include history, sports, outdoors and cultural experiences. Its principal tourist attractions are the Henry Doorly Zoo and the College World Series. The Old Market in Downtown Omaha is another major attraction and is important to the city's retail economy. The city has been a tourist destination for many years. Famous early visitors included British author Rudyard Kipling and General George Crook. In 1883 Omaha hosted the first official performance of the Buffalo Bill's Wild West Show for eight thousand attendees. In 1898 the city hosted more than 1,000,000 visitors from across the United States at the Trans-Mississippi and International Exposition, a world's fair that lasted for more than half the year.
Research on leisure and hospitality situates Omaha in the same tier for tourists as the neighboring cities of Des Moines, Iowa, Topeka, Kansas, Kansas City, Missouri, Oklahoma City, Oklahoma, Denver, Colorado, and Sioux Falls, South Dakota. A recent study found that investment of $1 million in cultural tourism generated approximately $83,000 in state and local taxes, and provided support for hundreds of jobs for the metropolitan area, which in turn led to additional tax revenue for government.
Culture.
The city's historical and cultural attractions have been lauded by numerous national newspapers, including the "Boston Globe" and The "New York Times". Omaha is home to the Omaha Community Playhouse, the largest community theater in the United States. The Omaha Symphony Orchestra and its modern Holland Performing Arts Center, the Opera Omaha at the Orpheum theater, the Blue Barn Theatre, and The Rose Theater form the backbone of Omaha's performing arts community. Opened in 1931, the Joslyn Art Museum has significant art collections. Since its inception in 1976, Omaha Children's Museum has been a place where children can challenge themselves, discover how the world works and learn through play. The Bemis Center for Contemporary Arts, one of the nation's premier urban artist colonies, was founded in Omaha in 1981, and the Durham Museum is accredited with the Smithsonian Institution for traveling exhibits. The city is also home to the largest singly funded mural in the nation, "Fertile Ground", by Meg Saligman. The annual Omaha Blues, Jazz, & Gospel Festival celebrates local music along with the Omaha Black Music Hall of Fame.
In 1955 Omaha's Union Stockyards overtook Chicago's stockyards as the United States' meat packing center. This legacy is reflected in the cuisine of Omaha, with renowned steakhouses such as Gorat's and the recently closed Mister C's, as well as the retail chain Omaha Steaks.
Henry Doorly Zoo.
The Henry Doorly Zoo is widely considered one of the premier zoos in the world. The zoo is home to the world's largest nocturnal exhibit and indoor swamp; the world's largest indoor rainforest, the world's largest indoor desert, and the largest geodesic dome in the world (13 stories tall). The Zoo is Nebraska's number one paid attendance attraction and has welcomed more than 25 million visitors over the past 40 years.
Old Market.
The Old Market is a major historic district in Downtown Omaha listed on the National Register of Historical Places. Today, its warehouses and other buildings house shops, restaurants, bars, coffee shops, and art galleries. Downtown is also the location of the Omaha Rail and Commerce Historic District, which has several art galleries and restaurants as well. The Omaha Botanical Gardens features with a variety of landscaping, and the new Kenefick Park recognizes Union Pacific Railroad's long history in Omaha. North Omaha has several historical cultural attractions including the Dreamland Historical Project, Love's Jazz and Art Center, and the John Beasley Theater. The annual River City Roundup is celebrated at Fort Omaha, and the neighborhood of Florence celebrates its history during "Florence Days". Native Omaha Days is a biennial event celebrating Near North Side heritage.
Religious institutions reflect the city's heritage. The city's Christian community has several historical churches dating from the founding of the city. There are also all sizes of congregations, including small, medium and megachurches. Omaha hosts the only Church of Jesus Christ of Latter-day Saints temple in Nebraska, along with a significant Jewish community. There are 152 parishes in the Roman Catholic Archdiocese of Omaha, and several Orthodox Christian congregations throughout the city.
Music.
Omaha's rich history in rhythm and blues, and jazz gave rise to a number of influential bands, including Anna Mae Winburn's Cotton Club Boys and Lloyd Hunter's Seranaders. Rock and roll pioneer Wynonie Harris; jazz great Preston Love; drummer Buddy Miles; and Luigi Waites are among the city's homegrown talent. Doug Ingle from the late 1960s band Iron Butterfly was born in Omaha as was indie-folk singer/songwriter Elliott Smith, though both were raised elsewhere.
Today, the diverse culture of Omaha includes a variety of performance venues, museums, and musical heritage, including the historically significant jazz scene in North Omaha and the modern and influential "Omaha Sound".
Contemporary music groups either located in or originally from Omaha include Mannheim Steamroller, Bright Eyes, The Faint, Cursive, Azure Ray, Tilly and the Wall and 311. During the late 1990s, Omaha became nationally known as the birthplace of Saddle Creek Records, and the subsequent "Omaha Sound" was born from their bands' collective style.
Omaha also has a fledgling hip hop scene. Long-time bastion Houston Alexander, a one-time graffiti artist and professional Mixed Martial Arts competitor, is currently a local hip-hop radio show host. Cerone Thompson, known as "Scrybe", has had a number one single on college radio stations across the United States. He has also had several number one hits on the local hip hop station respectively titled, "Lose Control" and "Do What U Do". More recently, in 2009 Eric Scheid, also known as "Titus", released a single called "What Do You Believe" featuring Bizzy Bone from the nationally known hip hop group Bone Thugs-n-Harmony. The single was produced by Omaha producer J Keez. The record was released by Smashmode Publishing and Timeless Keys Music Publishing which are two Omaha-based music publishing companies. South Omaha's OTR Familia, consisting of MOC and Xpreshin aka XP, have worked with Fat Joes Terror Squad on several songs and have participated in summer concerts with Pitbull, Nicky Jam, and Aventura.
A long heritage of ethnic and cultural bands have come from Omaha. The Omaha Black Music Hall of Fame celebrates the city's long history of African-American music and the Strathdon Caledonia Pipe Band carries on a Scottish legacy. Internationally renowned composer Antonín Dvořák wrote his Ninth ("New World") Symphony in 1893 based on his impressions of the region after visiting Omaha's robust Czech community. In the period surrounding World War I Valentin J. Peter encouraged Germans in Omaha to celebrate their rich musical heritage, too. Frederick Metz, Gottlieb Storz and Frederick Krug were influential brewers whose beer gardens kept many German bands active.
Popular culture.
In 1939, the world premiere of the film "Union Pacific" was held in Omaha, Nebraska and the accompanying three-day celebration drew 250,000 people. A special train from Hollywood carried director Cecil B. DeMille and stars Barbara Stanwyck and Joel McCrea. Omaha's Boys Town was made famous by the Spencer Tracy and Mickey Rooney movie "Boys Town". Omaha has been featured in recent years by a handful of relatively big budget motion pictures. The city's most extensive exposure can be accredited to Omaha native Alexander Payne, the Oscar-nominated director who shot parts of "About Schmidt", "Citizen Ruth" and "Election" in the city and suburbs of Papillion and La Vista.
Built in 1962, Omaha's Cinerama was called Indian Hills Theater. Its demolition in 2001 by the Nebraska Methodist Health System was unpopular, with objections from local historical and cultural groups and luminaries from around the world. The Dundee Theatre is the lone surviving single-screen movie theater in Omaha and still shows films. A recent development to the Omaha film scene was the addition of Film Streams's Ruth Sokolof Theater in North Downtown. The two-screen theater is part of the Slowdown facility. It features new American independents, foreign films, documentaries, classics, themed series, and director retrospectives. There are many new theaters opening in Omaha. In addition to the five Douglas Theatres venues in Omaha, two more are opening, including Midtown Crossing Theatres, located on 32nd and Farnam Streets by the Mutual of Omaha Building. Westroads Mall has opened a new multiplex movie theater with 14 screens, operated by Rave Motion Pictures.
Songs about Omaha include "Omaha" by Moby Grape, "Omaha", by the indie rock band Tapes 'n Tapes, "Omaha" by Counting Crows, "Omaha Celebration" by Pat Metheny, "Omaha" sung by Waylon Jennings, "Greater Omaha" by Desaparecidos, "Omaha Stylee" by 311 and "(Ready Or Not) Omaha Nebraska" by Bowling for Soup.
Popular young adult novel "Eleanor & Park" by Rainbow Rowell (St. Martin's Press, 2013) takes place in Omaha.
The 1935 winner of the Triple Crown of Thoroughbred Racing was named Omaha, and after traveling the world the horse eventually retired to a farm south of the city. The horse made promotional appearances at Ak-Sar-Ben during the 1950s and following his death in 1959 was buried at the racetrack's Circle of Champions.
Sports and recreation.
Sports have been important in Omaha for more than a century, and the city currently plays host to three minor-league professional sports teams. It is perhaps more known as the home of the College World Series, to which it has played host since 1950. The Kings, an NBA franchise, called Omaha and Kansas City home from 1972 to 1978. The Kansas City-Omaha Kings split their time between the two cities, playing at Kansas City's Municipal Auditorium and the Omaha Civic Auditorium, before decamping solely to Kansas City until 1985, when the team moved to its current home of Sacramento.
The Omaha Sports Commission is a quasi-governmental nonprofit organization that coordinates much of the professional and amateur athletic activity in the city, including the 2008 and 2012 US Olympic Swimming Team Trials and the building of a new stadium in North Downtown. The University of Nebraska and the Commission co-hosted the 2008 National Collegiate Athletic Association (NCAA) Division One Women's Volleyball Championship in December of that year. Another quasi-governmental board, the Metropolitan Entertainment and Convention Authority (MECA), was created by city voters in 2000, and is responsible for maintaining the CenturyLink Center Omaha.
Omaha's Johnny Rosenblatt Stadium was home to the Omaha Storm Chasers (at the time known as the Omaha Royals) minor-league baseball team (the AAA affiliate of the Kansas City Royals). From 1950 to 2010, it hosted the annual NCAA College World Series, or CWS, men's baseball tournament in mid-June.
After Rosenblatt Stadium closed, its tenants moved to new venues. On April 16, 2011, the Omaha Storm Chasers moved to Werner Park. The CWS moved to the downtown TD Ameritrade Park in 2011.
Omaha is also home to the Omaha Diamond Spirit, a collegiate summer baseball team that plays in the MINK league.
Omaha was home to a new expansion team in the United Football League that play from 2010 to 2011.
The Omaha Beef indoor football team played at the Omaha Civic Auditorium until 2012 when they moved to the new Ralston Arena.
The Creighton University Bluejays compete in a number of NCAA Division I sports as members of the Big East Conference. Baseball is played at TD Ameritrade Park Omaha, soccer is played at Morrison Stadium, and basketball is played at the 18,000 seat CenturyLink Center. The Jays annually rank in the top 15 in attendance each year, averaging more than 16,000 people per game. The Omaha Mavericks, representing the University of Nebraska Omaha (UNO), also play in NCAA Division I, mostly as members of The Summit League. The UNO men's ice hockey team plays in the National Collegiate Hockey Conference.
Ice hockey is a popular spectator sport in Omaha and there are two Omaha-area teams. The Omaha Lancers, a United States Hockey League team play at the Civic Auditorium. The Omaha Mavericks play in the on-campus Baxter Arena.
Omaha has a thriving running community and many miles of paved running and biking trails throughout the city and surrounding communities. The Omaha Marathon involves a half-marathon and a race that take place annually in September. Omaha also has a history of curling, including multiple junior national champions.
The city's historic boulevards were originally designed by Horace Cleveland in 1889 to work with the parks to create a seamless flow of trees, grass and flowers throughout the city. Florence Boulevard and Fontenelle Boulevard are among the remnants of this system. Omaha boasts more than of trails for pedestrians, bicyclists and hikers. They include the American Discovery Trail, which traverses the entire United States, and the Lewis and Clark National Historic Trail passes through Omaha as it travels westward from Illinois to Oregon. Trails throughout the area are included in comprehensive plans for the city of Omaha, the Omaha metropolitan area, Douglas County, and long-distance coordinated plans between the municipalities of southeast Nebraska.
Government and politics.
Omaha has a strong mayor form of government, along with a city council that is elected from seven districts across the city. The current mayor is Jean Stothert, who was elected in May 2013. The longest serving mayor in Omaha's history was "Cowboy" Jim Dahlman, who served 20 years over eight terms. He was regarded as the "wettest mayor in America" because of the flourishing number of bars in Omaha during his tenure. Dahlman was a close associate of political boss Tom Dennison. During Dahlman's tenure, the city switched from its original strong-mayor form of government to a city commission government. In 1956, the city switched back.
The city clerk is Buster Brown. The City of Omaha administers twelve departments, including finance, police, human rights, libraries and planning. The Omaha City Council is the legislative branch and is made up seven members elected from districts across the city. The council enacts local ordinances and approves the city budget. Government priorities and activities are established in a budget ordinance approved annually. The council takes official action through the passage of ordinances and resolutions. Nebraska's constitution grants the option of home rule to cities with more than 5,000 residents, meaning they may operate under their own charters. Omaha is one of only three cities in Nebraska to use this option, out of 17 eligible. The City of Omaha is currently considering consolidating with Douglas County government.
Although registered Republicans outnumbered Democrats in the 2nd congressional district, which includes Omaha, Democratic presidential candidate Barack Obama opened three campaign offices in the city with 15 staff members to cover the state in fall 2008. Mike Fahey, the former Democratic mayor of Omaha, said he would do whatever it took to deliver the district's electoral vote to Obama; and the Obama campaign considered the district "in play". Former Nebraska U.S. Senator Bob Kerrey and former Senator Ben Nelson campaigned in the city for Obama, and in November 2008 Obama won the district's electoral vote. This was an exceptional win, because with Nebraska's split electoral vote system Obama became the first Democratic presidential candidate to win an electoral vote in Nebraska since 1964.
In 2011, Nebraska lawmakers moved Offutt Air Force Base and the town of Bellevue — an area with a large minority population — out of the Omaha-based 2nd District and shifted in the Republican-heavy Omaha suburbs in Sarpy County. The move is expected to dilute the city's urban Democratic vote.
Crime.
Omaha's rate of violent crimes per 100,000 residents has been lower than the average rates of three dozen United States cities of similar size. Unlike Omaha, those cities have experienced an increase in violent crime overall since 2003. Rates for property crime have decreased for both Omaha and its peer cities during the same time period. In 2006, Omaha was ranked for homicides as 46th out of the 72 cities in the United States of more than 250,000 in population.
As a major industrial city into the mid-20th century, Omaha shared in social tensions of larger cities that accompanied rapid growth and many new immigrants and migrants. By the 1950s, Omaha was a center for illegal gambling, while experiencing dramatic job losses and unemployment because of dramatic restructuring of the railroads and the meatpacking industry, as well as other sectors. Persistent poverty resulting from racial discrimination and job losses generated different crimes in the late 20th century, with drug trade and drug abuse becoming associated with violent crime rates, which climbed after 1986 as Los Angeles gangs made affiliates in the city. Gambling in Omaha has been significant throughout the city's history. From its founding in the 1850s through the 1930s, the city was known as a "wide-open" town, meaning that gambling of all sorts was accepted either openly or in closed quarters. By the mid-20th century, Omaha reportedly had more illicit gambling per capita than any other city in the nation. From the 1930s through the 1970s the city's gambling was controlled by an Italian criminal element. Today, gambling in Omaha is limited to keno, lotteries, and parimutuel betting, leaving Omahans to drive across the Missouri River to Council Bluffs, Iowa, where casinos are legal and there are numerous businesses operating currently. Recently a controversial proposal by the Ponca tribe of Nebraska was approved by the National Indian Gaming Commission. It will allow the tribe to build a casino in Carter Lake, Iowa, which sits geographically on the west side of the Missouri River, adjacent to Omaha, where casinos are illegal.
Education.
Education in Omaha is provided by many private and public institutions. Omaha Public Schools is the largest public school district in Nebraska, with more than 47,750 students in more than 75 schools. After a contentious period of uncertainty, in 2007 the Nebraska Legislature approved a plan to create a learning community for Omaha-area school districts with a central administrative board. The Roman Catholic Archdiocese of Omaha maintains numerous private Catholic schools with 21,500 students in 32 elementary schools and nine high schools. St. Cecilia Grade School at 3869 Webster St. in Midtown Omaha and St. Stephen the Martyr School at 168th and Q street in western Omaha earned national distinction when they received the U.S. Department of Education Blue Ribbon School award. Omaha is also home to Brownell-Talbot School, the only preschool through grade 12, independent college preparatory school in the state of Nebraska.
There are eleven colleges and universities among Omaha's higher education institutions, including the University of Nebraska Omaha. The University of Nebraska Medical Center is located in midtown Omaha and is home to the Eppley Cancer Center, one of 66 designated Cancer Centers by the National Cancer Institute in the United States. The University of Nebraska College of Medicine, also located on the UNMC campus, is ranked 7th in the country by US News and World Report for primary care medical education. Omaha's Creighton University is ranked the top non-doctoral regional university in the Midwestern United States by "U.S. News and World Report". Creighton maintains a campus just outside Downtown Omaha in the new North Downtown district, and the Jesuit institution has an enrollment of around 6,700 in its undergraduate, graduate, medical, and law schools. There are more than 10 other colleges and universities in Omaha in the Omaha metro area.
Media.
The city is the focus of the Omaha designated market area, and is the 76th largest in the United States.
"Omaha Magazine" (a weekly)
The major daily newspaper in Nebraska is the "Omaha World-Herald", which is the largest employee-owned newspaper in the United States. Weeklies in the city include the Midlands Business Journal (weekly business publication); "American Classifieds" (Formerly "Thrifty Nickel"), a weekly classified newspaper; "The Reader" , as well as "The Omaha Star". Founded in 1938 in North Omaha, the "Star" is Nebraska's only African-American newspaper. 
Omaha's four television news stations were found not to represent the city's racial composition in a 2007 study. Cox Communications provides cable television services throughout the metropolitan area.
Infrastructure.
In 2008 "Kiplinger's Personal Finance" magazine ranked Omaha the No. 3 best city in the United States to "live, work and play". Omaha's growth has required the constant development of new urban infrastructure that influence, allow and encourage the constant expansion of the city.
Retail natural gas and water public utilities in Omaha are provided by the Metropolitan Utilities District. Nebraska is the only public power state in the nation. All electric utilities are non-profit and customer-owned. Electricity in the city is provided by the Omaha Public Power District. Public housing is governed by the Omaha Housing Authority, and public transportation is provided by Metro Area Transit. CenturyLink and Cox provide local telephone and internet services. The City of Omaha maintains two modern sewage treatment plants.
Portions of the Enron corporation began as Northern Natural Gas Company in Omaha. Northern currently provides three natural gas lines to Omaha. Enron formerly owned UtiliCorp United, Inc., which became Aquila, Inc.. Peoples Natural Gas, a division of Aquila, Inc., currently serves several surrounding communities around the Omaha metropolitan area, including Plattsmouth.
There are several hospitals in Omaha. Research hospitals include the Boys Town National Research Hospital, the University of Nebraska Medical Center and the Creighton University Medical Center. The Boys Town facility is well known for world-class researchers in hearing-related research and high quality treatment. The University of Nebraska Medical Center hosts the Eppley Institute for Research in Cancer and Allied Diseases, a world-renowned cancer treatment facility named in honor of Omahan Eugene Eppley.
Transportation.
Omaha's central role in the history of transportation across America earned it the nickname "Gate City of the West." Despite President Lincoln's decree that Council Bluffs, Iowa, be the starting point for the Union Pacific Railroad, construction began from Omaha on the eastern portion of the first transcontinental railroad. By the middle of the 20th century, Omaha was served by almost every major railroad. Today, the Omaha Rail and Commerce Historic District celebrates this connection, along with the listing of the Burlington Train Station and the Union Station on the National Register of Historic Places. First housed in the former Herndon House, the Union Pacific Railroad's corporate headquarters have been in Omaha since the company began. Their new headquarters, the Union Pacific Center, was opened in Downtown Omaha in 2004. Amtrak, the national passenger rail system, provides service through Omaha. The Greyhound lines terminal is at 1601 Jackson St in downtown Omaha. Megabus has a stop at Crossroads Mall – N 72nd St between Dodge St and Cass St, and provides service to Des Moines, Iowa City, and Chicago. Metro Transit, previously known as Metro Area Transit, is the local bus.
Omaha's position as a transportation center was finalized with the 1872 opening of the Union Pacific Missouri River Bridge linking the transcontinental railroad to the railroads terminating in Council Bluffs. In 1888, the first road bridge, the Douglas Street Bridge, opened. In the 1890s, the Illinois Central drawbridge opened as the largest bridge of its type in the world. Omaha's Missouri River road bridges are now entering their second generation, including the Works Progress Administration-financed South Omaha Bridge, now called Veteran's Memorial Bridge, which was added to the National Register of Historic Places. In 2006, Omaha and Council Bluffs announced joint plans to build the Missouri River Pedestrian Bridge, which opened in 2008.
Today, the primary mode of transportation in Omaha is by automobile, with I-80, I-480, I-680, I-29, and U.S. Route 75 (JFK Freeway and North Freeway) providing freeway service across the metropolitan area. The expressway along West Dodge Road (U.S. Route 6 and Nebraska Link 28B) and U.S. Route 275 has been upgraded to freeway standards from I-680 to Fremont. City owned Metro Transit formerly as MAT Metro Area Transit provides public bus service to hundreds of locations throughout the Metro.
A 2011 study by Walk Score ranked Omaha 21st most walkable of fifty largest U.S. cities. There is an extensive trail system throughout the city for walkers, runners, bicyclists, and other pedestrian modes of transportation.
Omaha is laid out on a grid plan, with 12 blocks to the mile with a north-to-south house numbering system. Omaha is the location of a historic boulevard system designed by H.W.S. Cleveland who sought to combine the beauty of parks with the pleasure of driving cars. The historic Florence and Fontenelle Boulevards, as well as the modern Sorenson Parkway, are important elements in this system.
Eppley Airfield, Omaha's airport, serves the region with over 4.2 million passengers in 2006. United Airlines, Southwest Airlines, Delta Air Lines, American Airlines, Alaska Airlines, Allegiant Air and Frontier Airlines serve the airport with direct and connecting service. Eppley is situated in East Omaha, with many users driving through Carter Lake, Iowa and getting a view of Carter Lake before getting there. General aviation airports serving the area are the Millard Municipal Airport, North Omaha Airport and the Council Bluffs Airport. Offutt Air Force Base continues to serve as a military airbase; it is located at the southern edge of Bellevue, which in turn lies immediately south of Omaha.
Sister cities.
Omaha has six sister cities:

</doc>
<doc id="46160" url="https://en.wikipedia.org/wiki?curid=46160" title="Accuracy in Media">
Accuracy in Media

Accuracy In Media (AIM) is an American non-profit news media watchdog founded in 1969 by economist Reed Irvine. AIM describes itself as "a non-profit, grassroots citizens watchdog of the news media that critiques botched and bungled news stories and sets the record straight on important issues that have received slanted coverage." It has been described as having a politically conservative stance.
History.
At its inception, Accuracy In Media was run primarily by Reed Irvine and then-executive secretary Abraham Kalish. The two sent letters to the editors of many newspapers and magazines they identified as skewed, calling out slanted news stories. If the newspaper rejected the letter, AIM bought space and printed the letter in that newspaper. Beginning in 1975, Accuracy In Media began purchasing stock in major media companies, allowing Irvine to attend annual shareholder meetings. He used these opportunities to express AIM's concerns to the various companies' owners. Reed's son, Don, chairs the organization. Don Irvine referred to his father as a "die-hard anti-communist."
In 1972, Accuracy In Media began publishing the" AIM Report", a twice-monthly newsletter originally edited by Reed Irvine. Cliff Kincaid and Roger Aronoff, AIM Senior Editor and AIM Executive Secretary and Media Analyst, respectively, continue to handle the publication, as well as daily online updates. The" AIM Report" often calls on its subscribers to contact newsmakers, reporters and news corporations to end perceived liberal media bias. 
AIM's work.
Human rights.
In 1982, "New York Times" reporter Raymond Bonner broke the story of the El Mozote massacre. This report was strongly criticized by AIM and the Reagan White House, and Bonner was pressured into business reporting, later deciding to resign. Although the report was embarrassing to the Reagan administration, who was heavily aiding the right-wing junta at the time, skeletons unearthed a decade later confirmed the original story's veracity. AIM was critical of journalist Helen Marmor, who in 1983 produced a documentary for NBC concerning the Russian Orthodox Church. AIM contended that "it ignored the repressive religious policies of the Soviet state".
Vincent Foster conspiracy theory.
AIM received a substantial amount of funding from Richard Mellon Scaife who paid Christopher W. Ruddy to investigate allegations that President Bill Clinton was connected to the suicide of Vincent Foster. AIM contended that "Foster was murdered", which is contrary to three independent reports including one by Kenneth Starr. AIM faulted the media for not picking up on the conspiracy. The organization even went to court for documents and recordings linked to the case.
AIM credited much of its reporting on the Foster case to Ruddy. Yet, his work was called a "hoax" and "discredited" by conservatives such as Ann Coulter, it was also disputed by the "American Spectator", which caused Scaife to end his funding of the Arkansas Project with the publisher. As CNN explained on February 28, 1997, "The report refutes claims by conservative political organizations that Foster was the victim of a murder plot and coverup", but "despite those findings, right-wing political groups have continued to allege that there was more to the death and that the president and First Lady tried to cover it up".
Ruddy operates a conservative news website, NewsMax, that, as of 2004, continued to assert there was a conspiracy and faulted the media.
United Nations.
AIM has been critical of the United Nations and its coverage by the media. In February 2005, AIM alleged that United Nations correspondents, including Ian Williams, a correspondent for "The Nation" had accepted money from the UN while covering it for their publications. AIM also asserted that the United Nations Correspondents Association may have violated immigration laws by employing the wife of Williams. Williams and The Nation denied wrongdoing. The charges were reiterated by "FrontPage Magazine" and the allegation concerning Williams receiving UN cash was picked up by Brit Hume and the Fox News Channel.
Cliff Kincaid and Fox News Channel.
In November 2005, AIM columnist Cliff Kincaid criticized Fox News for broadcasting a program "The Heat is On", which reported that global warming represents a serious problem (the program was broadcast with a disclaimer). Kincaid argued the piece was one-sided and stated that this "scandal" amounted to a "hostile takeover of Fox News".
On October 20, 2006, Accuracy in Media released a list of 27 questions to pose at the Fox News Executive meeting that was attended by AIM editor Cliff Kincaid. Of these 27 questions, 8 dwell on Rupert Murdoch's relationship with the Clintons and how that may have affected Fox News coverage. Moreover, AIM wrote "News Corporation hired the Glover Park Group, a public relations firm run by friends of Bill and Hillary Clinton, to block changes in the TV ratings system", and asks, "Was this part of News Corporation's move to the left?"
In May 2007, Accuracy in Media raised questions about a conflict of interest in Fox News' co-sponsorship of the May 15 Republican Presidential Candidates debate, pointing out that News Corporation, the parent company of Fox News, is a client of presidential candidate Rudy Giuliani.
Funding.
A minimum of eight separate oil companies are known to have been contributors in the early 80s. Only three donors of the remainder are given by name: the Allied Educational Foundation (founded and chaired by George Barasch), Shelby Cullom Davis, and billionaire Richard Mellon Scaife. Scaife gave $2 million to Accuracy in Media between 1977 and 1997.

</doc>
<doc id="46165" url="https://en.wikipedia.org/wiki?curid=46165" title="Charlton Heston">
Charlton Heston

Charlton Heston (born Charlton John Carter; October 4, 1923 – April 5, 2008) was an American actor and political activist.
As a Hollywood star, he appeared in 100 films over the course of 60 years. He played Moses in the epic film, "The Ten Commandments" (1956), for which he received his first Golden Globe Award nomination. He also starred in "Touch of Evil" (1958) with Orson Welles, "Ben-Hur", for which he won the Academy Award for Best Actor (1959), "El Cid" (1961), and "Planet of the Apes" (1968). He also starred in the films "The Greatest Show on Earth" (1952), "Secret of the Incas" (1954), "The Big Country" (1958), and "The Agony and the Ecstasy" (1965).
A supporter of Democratic politicians and civil rights in the 1960s, Heston later became a Republican, founding a conservative political action committee and supporting Ronald Reagan. Heston's most famous role in politics came as the five-term president of the National Rifle Association, from 1998 to 2003. After being diagnosed with Alzheimer's disease in 2003, he retired from both acting and the NRA presidency. Heston died on April 5, 2008, aged 84, from pneumonia.
Early years.
Charlton Heston was born Charlton John Carter on October 4, 1923, to Lilla (née Baines; 1899–1994) and Russell Whitford Carter (1897–1966), a sawmill operator. Many sources indicate he was born in Evanston, Illinois. Heston's autobiography; however, and some other sources, place his birth in No Man's Land, Illinois, which usually refers to a then-unincorporated area now part of Wilmette, a wealthy Chicago suburb.
Heston said in a 1995 interview that he was not very good at remembering addresses or his early childhood. Heston was partially of Scottish descent, including from the Clan Fraser, but the majority of his ancestry was English. His earliest immigrant ancestors arrived in America from England in the 1600s. 
In his autobiography, Heston refers to his father participating in his family's construction business. When Heston was an infant, his father's work moved the family to St. Helen, Michigan. It was a rural, heavily forested part of the state, and Heston lived an isolated yet idyllic existence, spending much time hunting and fishing in the backwoods of the area.
When Heston was 10 years old, his parents divorced. Shortly thereafter, his mother married Chester Heston. The new family moved back to Wilmette. Heston (his new surname) attended New Trier High School. He recalled living there:
The 1930 United States Census record shows his name as being Charlton John Carter despite later accounts by sources saying it was John Charles Carter. Charlton was his maternal grandmother Marian's maiden surname which his mother also used as her last name as a young woman instead of her true maiden surname of Baines. After his parent's divorce in 1933, he was recorded with his stepfather's surname (Heston), and this was the name he used for his first film, an adaptation of Ibsen's "Peer Gynt" (1941).
Career.
Heston frequently recounted that while growing up in northern Michigan in a sparsely populated area, he often wandered in the forest, "acting" out characters from books he had read. Later, in high school, he enrolled in New Trier's drama program, playing in the amateur silent 16 mm film adaptation of "Peer Gynt", from the Ibsen play, by future film activist David Bradley released in 1941.
From the Winnetka Community Theatre (or the Winnetka Dramatist's Guild, as it was then known) in which he was active, he earned a drama scholarship to Northwestern University; among his acting teachers was Alvina Krause. Several years later, Heston teamed up with Bradley to produce the first sound version of William Shakespeare's "Julius Caesar", in which Heston played Mark Antony.
World War II service.
In 1944, Heston enlisted in the United States Army Air Forces. He served for two years as a radio operator and aerial gunner aboard a B-25 Mitchell stationed in the Alaskan Aleutian Islands with the 77th Bombardment Squadron of the Eleventh Air Force. He reached the rank of staff sergeant.
Heston married Northwestern University student Lydia Marie Clarke, who was six months his senior. That same year, he joined the military. After his rise to fame, Heston narrated for highly classified military and Department of Energy instructional films, particularly relating to nuclear weapons, and "for six years Heston the nation's highest security clearance" or Q clearance." The Q clearance is similar to a DoD or DIA clearance of top secret.
Theater and television.
After the war, Heston and Clarke lived in Hell's Kitchen, New York City, where they worked as artists' models. Seeking a way to make it in theater, Heston and his wife Lydia decided to manage a playhouse in Asheville, North Carolina, in 1947, making $100 a week. In 1948, they returned to New York, where Heston was offered a supporting role in a Broadway revival of Shakespeare's "Antony and Cleopatra", starring Katharine Cornell. In television, Heston played a number of roles in CBS's "Studio One", one of the most popular anthology dramas of the 1950s.
Film producer Hal B. Wallis of "Casablanca" spotted Heston in a 1950 television production of "Wuthering Heights" and offered him a contract. When his wife reminded Heston they had decided to pursue theater and television, he replied, "Well, maybe just for one film to see what it's like."
Heston turned down the lead opposite Marilyn Monroe in "Let's Make Love" to appear in Benn W. Levy's play "The Tumbler", directed by Laurence Olivier. Called a "harrowingly pretentious verse drama" by "Time", the production went through a troubled out-of-town tryout period in Boston and closed after five performances on Broadway in February 1960. Heston, a great admirer of Olivier the actor, took on the play to work with him as a director. After the play flopped, Heston told columnist Joe Hyams, "I feel I am the only one who came out with a profit... I got out of it precisely what I went in for – a chance to work with Olivier. I learned from him in six weeks things I never would have learned otherwise. I think I've ended up a better actor."
Heston enjoyed acting on stage, believing it revivified him as an actor. He never returned to Broadway, but acted in regional theaters. His most frequent stage roles included the title role in "Macbeth", and Mark Antony in both "Julius Caesar" and "Antony and Cleopatra". He played Sir Thomas More in "A Man for All Seasons" in several regional productions in the 1970s and 1980s, eventually playing it in London's West End. The play was a success and the West End production was taken to Aberdeen, Scotland, for a week, where it was staged at His Majesty's Theatre. 
Hollywood.
Heston's first professional movie appearance was the leading role in "Dark City", a 1950 film noir. His breakthrough came when Cecil B. DeMille cast him as a circus manager in "The Greatest Show on Earth", which was named by the Motion Picture Academy as the best picture of 1952. In 1953, Heston was Billy Wilder's first choice to play Sefton in "Stalag 17". However, the role was given to William Holden, who won an Oscar for it. In 1954, he played the lead in "Secret of the Incas", which was shot on location at the archeological site Macchu Picchu and had numerous similarities to "Raiders of the Lost Ark". Filmed a quarter-century before the latter film, ""Incas"" included a tomb scene with the revelatory shaft of light pointing out a clue on a map and featured Heston's roguish antiquities thief's costume and light beard; "Raiders"' costume designer Deborah Nadoolman Landis noted that it was "almost a shot for shot similar" to the film on which she worked. Heston became an icon for playing Moses in the hugely successful film "The Ten Commandments" (1956), selected by director Cecil B. DeMille, who reportedly thought Heston bore an uncanny resemblance to Michelangelo's statue of Moses.
In 1955, Heston appeared with Jane Wyman in "Lucy Gallant". In 1958, he portrayed a Mexican police officer, Ramon Miguel Vargas, in Orson Welles's widely acclaimed film noir "Touch of Evil". He also played a rare supporting role in William Wyler's "The Big Country" opposite Gregory Peck and Burl Ives.
After Marlon Brando, Burt Lancaster, and Rock Hudson turned down the title role in "Ben-Hur" (1959), Heston accepted the role, winning the Academy Award for Best Actor, one of the unprecedented 11 Oscars the film earned. After Moses and "Ben-Hur", Heston became more identified with Biblical epics than any other actor. He voiced Ben-Hur in an animated television production of the Lew Wallace in 2003.
Heston played leading roles in a number of fictional and historical epics: "El Cid" (1961), "55 Days at Peking" (1963), as Michelangelo in "The Agony and the Ecstasy" (1965), and "Khartoum" (1966). Heston also played the title role in the Western movie "Will Penny" (1968).
From 1965–71, Heston served as president of the Screen Actors Guild. The Guild had been created in 1933 for the benefit of actors, who had different interests from the producers and directors who controlled the Academy of Motion Pictures Arts and Sciences. He was more conservative than most actors, and publicly clashed with outspoken liberal actors such as Ed Asner.
In 1968, Heston starred in "Planet of the Apes" and in 1970, he had a smaller supporting role in the sequel, "Beneath the Planet of the Apes". In 1970, he portrayed Mark Antony again in another film version of Shakespeare's " Julius Caesar". His co-stars included Jason Robards as Brutus, Richard Chamberlain as Octavius, Robert Vaughn as Casca, and English actors Richard Johnson as Cassius, John Gielgud as Caesar, and Diana Rigg as Portia.
In 1971, he starred in the postapocalpytic science-fiction film "The Omega Man", which has received mixed critical reviews. In 1972, Heston made his directorial debut and starred as Mark Antony in an adaptation of the William Shakespeare play he had performed earlier in his theater career, "Antony and Cleopatra". Hildegarde Neil was Cleopatra and English actor Eric Porter was Ahenobarbus. After receiving scathing reviews, the film was never released to theaters, and is rarely seen on television. It was finally released on DVD in March 2011. He subsequently starred in more successful films such as "Soylent Green" (1973) and "Earthquake" (1974).
Beginning with playing Cardinal Richelieu in 1973's "The Three Musketeers", Heston was seen in an increasing number of supporting roles, cameos, and live theater. From 1985-87, he starred in his only prime-time stint on a television series in the soap, "The Colbys". With his son Fraser, he produced and starred in several TV movies, including remakes of "Treasure Island" and "A Man For All Seasons". In 1992, Heston appeared on the A&E cable network in a short series of videos, "Charlton Heston Presents the Bible", reading passages from the King James version.
Never taking himself too seriously, he also made a few appearances as "Chuck" in Dame Edna Everage's shows, both on stage and on television. Heston appeared in 1993 in a cameo role in "Wayne's World 2", in a scene where Wayne Campbell (Mike Myers) requests casting a better actor for a small role. After the scene is reshot with Heston, Campbell weeps in awe. That same year, Heston hosted "Saturday Night Live". He had cameos in the films "Hamlet", "Tombstone", and "True Lies".
He starred in many theatre productions at the Los Angeles Music Center, where he appeared in "Detective Story" and "The Caine Mutiny Court Martial," and as Sherlock Holmes in "The Crucifer of Blood", opposite Richard Johnson as Dr. Watson. In 2001, he made a cameo appearance as an elderly, dying chimpanzee in Tim Burton's remake of "Planet of the Apes". His last film role was as Josef Mengele in "My Father, Rua Alguem 5555", which had limited release (mainly to festivals) in 2003.
Heston's distinctive voice landed him roles as a film narrator, including "Armageddon" and Disney's "Hercules". He played the title role in "Mister Roberts" three times and cited it as one of his favorite roles. In the early 1990s, he tried unsuccessfully to revive and direct the show with Tom Selleck in the title role. In 1998, Heston had a cameo role playing himself in the American television series "Friends", in the episode "The One with Joey's Dirty Day".
Political activism.
Heston's political activism had four stages. In the first stage, 1955–61, he endorsed Democratic candidates for President, and signed on to petitions and liberal political causes. From 1961-72, the second stage, he continued to endorse Democratic candidates for President. From 1965-71, he served as the elected president of the Screen Actors Guild, and clashed with his liberal rival Ed Asner. Moving beyond Hollywood, he became nationally visible in 1963 in support of the Civil Rights Act of 1964. In 1968, he used his "cowboy" persona to publicize gun control measures.
The third stage began in 1972. Like many neoconservatives of the same era who moved from liberal Democrat to conservative Republican, he rejected the liberalism of George McGovern and supported Richard Nixon in 1972 for President. In the 1980s, he gave strong support to Ronald Reagan during his conservative presidency. In 1995, Heston entered his fourth stage by establishing his own political action fund-raising committee, and jumped into the internal politics of the National Rifle Association. He gave numerous culture wars speeches and interviews upholding the conservative position, blaming media and academia for imposing affirmative action, which he saw as unfair reverse discrimination.
Heston campaigned for Presidential candidate Adlai Stevenson in 1956, although he was unable to campaign for John F. Kennedy in 1960 due to filming on "El Cid" in Spain. Reportedly, when in 1961 a segregated Oklahoma movie theater was showing his movie "El Cid" for the first time, he joined a picket line outside. Heston made no reference to this in his autobiography, but describes traveling to Oklahoma City to picket segregated restaurants, to the chagrin of the producers of "El Cid", Allied Artists. During the March on Washington for Jobs and Freedom held in Washington, DC, in 1963, he accompanied Martin Luther King, Jr. In later speeches, he said he helped the civil rights cause "long before Hollywood found it fashionable."
In the 1964 election, he endorsed Lyndon Baines Johnson, who had masterminded the passage of the Civil Rights Act of 1964 through Congress over the vociferous opposition of Southern Democrats. That year, Heston publicly opposed California Proposition 14 that rolled back the state's fair housing law, the Rumford Fair Housing Act.
In his 1995 autobiography, "In the Arena", written after he became a conservative Republican, Heston wrote that while driving back from the set of "The War Lord", he saw a "Barry Goldwater for President" billboard with his campaign slogan "In Your Heart You Know He's Right" and thought to himself, "Son of a bitch, he is right." Heston later said that his "support" for Goldwater was the event that helped turn him against gun control laws. However, following the assassination of Senator Robert F. Kennedy in 1968, Heston, Gregory Peck, Kirk Douglas, and James Stewart issued a statement in support of President Johnson's Gun Control Act of 1968. The Johnson White House had solicited Heston's support. He endorsed Hubert Humphrey in the 1968 Presidential election.
Heston opposed the Vietnam War during its course (though he changed his opinion in the years following the war) and in 1969 was approached by the Democratic Party to run for the U.S. Senate against incumbent George Murphy. He agonized over the decision but ultimately determined he could never give up acting. He is reported to have voted for Richard Nixon in 1972, though Nixon is not mentioned in his autobiography.
By the 1980s, Heston supported gun rights and changed his political affiliation from Democratic to Republican. When asked why he changed political alliances, Heston replied "I didn't change. The Democratic Party changed." In 1987, he first registered as a Republican. He campaigned for Republicans and Republican Presidents Ronald Reagan, George H.W. Bush, and George W. Bush.
Heston resigned in protest from Actors Equity, saying the union's refusal to allow a white actor to play a Eurasian role in "Miss Saigon" was "obscenely racist".
Heston charged that CNN's telecasts from Baghdad were "sowing doubts" about the allied effort in the 1990–91 Gulf War."
At a Time Warner stockholders' meeting, Heston castigated the company for releasing an Ice-T album which included a song "Cop Killer" about killing police officers. While filming "The Savage", Heston was initiated by blood into the Miniconjou Lakota Nation, saying that he had no natural American Indian heritage, but elected to be "Native American" to salvage the term from exclusively referring to American Indians.
In 1993, Heston teamed up with John Anthony West and Robert M. Schoch in an Emmy Award-winning NBC special, "The Mystery of the Sphinx". The documentary proposed a much earlier date for the construction of the Great Sphinx than originally suggested. Heston, when hosting the documentary, suggested that the main type of weathering evident on the Great Sphinx and surrounding enclosure walls could only have been caused by prolonged and extensive rainfall, and the whole structure was carved out of limestone bedrock by an ancient advanced culture (such as the Heavy Neolithic Qaraoun culture).
In a 1997 speech called "Fighting the Culture War in America", Heston rhetorically deplored a culture war he said was being conducted by a generation of media people, educators, entertainers, and politicians against:...the God fearing, law-abiding, Caucasian, middle-class Protestant – or even worse, evangelical Christian, Midwestern or Southern – or even worse, rural, apparently straight – or even worse, admitted heterosexuals, gun-owning – or even worse, NRA-card-carrying, average working stiff – or even worse, male working stiff – because, not only don’t you count, you are a down-right obstacle to social progress. Your voice deserves a lower decibel level, your opinion is less enlightened, your media access is insignificant; and frankly, mister, you need to wake up, wise up, and learn a little something from your new America; and until you do, would you mind shutting up?
He went on to say:The Constitution was handed down to guide us by a bunch of wise old dead white guys who invented our country! Now some flinch when I say that. Why! It's true-they were white guys! So were most of the guys that died in Lincoln's name opposing slavery in the 1860s. So why should I be ashamed of white guys? Why is "Hispanic Pride" or "Black Pride" a good thing, while "White Pride" conjures shaven heads and white hoods? Why was the Million Man March on Washington celebrated by many as progress, while the Promise Keepers March on Washington was greeted with suspicion and ridicule? I'll tell you why: Cultural warfare!
In an address to students at Harvard Law School entitled "Winning the Cultural War", Heston said, "If Americans believed in political correctness, we'd still be King George's boys – subjects bound to the British crown."
He said to the students:You are the best and the brightest. You, here in this fertile cradle of American academia, here in the castle of learning on the Charles River. You are the cream. But I submit that you and your counterparts across the land are the most socially conformed and politically silenced generation since Concord Bridge. And as long as you validate that and abide it, you are, by your grandfathers' standards, cowards.
During a speech at Brandeis University, he stated, "Political correctness is tyranny with manners". In a speech to the National Press Club in 1997, Heston said, "Now, I doubt any of you would prefer a rolled up newspaper as a weapon against a dictator or a criminal intruder."
Heston was the president (a largely ceremonial position) and spokesman of the NRA from 1998 until he resigned in 2003. At the 2000 NRA convention, he raised a rifle over his head and declared that a potential Al Gore administration would take away his Second Amendment rights "from my cold, dead hands". In announcing his resignation in 2003, he again raised a rifle over his head, repeating the five famous words of his 2000 speech. Heston became an honorary life member.
In the 2002 film "Bowling for Columbine", Michael Moore interviewed Heston at Heston's home, asking him about an April 1999 meeting the NRA held in Denver, Colorado, shortly after the Columbine high school massacre. Moore criticized Heston for the perceived thoughtlessness in the timing and location of the meeting. When Moore asked Heston for his thoughts on why gun-related homicide is so much higher in the United States than in other countries, Heston said it was because, "we have probably more mixed ethnicity". Heston subsequently, on-camera, excused himself and walked away. Heston also said just minutes later that he needed to think more on the ethnicity statement. Moore was later criticized for having conducted the interview in what some viewed as an ambush. The interview was conducted early in 2001, before Heston publicly announced his Alzheimer's diagnosis, but the film was released afterward, causing some to say that Moore should have cut the interview from the final film.
In April 2003, he sent a message of support to the American forces in the Iraq war, attacking opponents of the war as "pretend patriots". Heston opposed abortion and introduced Bernard Nathanson's 1987 pro-life documentary, "Eclipse of Reason", which focuses on late-term abortions. Heston served on the advisory board of Accuracy in Media, a conservative media watchdog group founded by Reed Irvine.
Illness and death.
In 1996, Heston had a hip replacement. He was diagnosed with prostate cancer in 1998. Following a course of radiation treatment, the cancer went into remission. In 2000, he publicly disclosed that he had been treated for alcoholism at a Utah clinic in May–June of that year.
On August 9, 2002, he publicly announced (via a taped message) that he had been diagnosed with symptoms consistent with Alzheimer's disease. In July 2003, in his final public appearance, Heston received the Presidential Medal of Freedom at the White House from President George W. Bush. In March 2005, various newspapers reported that family and friends were shocked by the progression of his illness, and that he was sometimes unable to get out of bed.
Heston died on the morning of April 5, 2008, at his home in Beverly Hills, California, with Lydia, his wife of 64 years, by his side. He was also survived by their son, Fraser Clarke Heston, and adopted daughter, Holly Ann Heston. The cause of death was not disclosed by the family. A month later, media outlets reported his death was due to pneumonia. Heston's family released a statement:
Early tributes came in from leading figures; President George W. Bush called Heston "a man of character and integrity, with a big heart ... e served his country during World War II, marched in the civil rights movement, led a labor union and vigorously defended Americans’ Second Amendment rights." Former First Lady Nancy Reagan said that she was "heartbroken" over Heston's death and released a statement, reading, "I will never forget Chuck as a hero on the big screen in the roles he played, but more importantly I considered him a hero in life for the many times that he stepped up to support Ronnie in whatever he was doing."
Heston's funeral was held a week later on April 12, 2008, in a ceremony which was attended by 250 people including Nancy Reagan and Hollywood stars such as California Governor Arnold Schwarzenegger, Olivia de Havilland, Keith Carradine, Pat Boone, Tom Selleck, Oliver Stone (who had cast Heston in his 1999 movie "Any Given Sunday"), Rob Reiner, and Christian Bale.
The funeral was held at Episcopal Parish of St. Matthew's Church in Pacific Palisades, the church where Heston regularly worshipped and attended Sunday services since the early 1980s. He was cremated and his ashes were given to his family.
Legacy.
Richard Corliss wrote in "Time" magazine, "From start to finish, Heston was a grand, ornery anachronism, the sinewy symbol of a time when Hollywood took itself seriously, when heroes came from history books, not comic books. Epics like "Ben-Hur" or "El Cid" simply couldn't be made today, in part because popular culture has changed as much as political fashion. But mainly because there's no one remotely like Charlton Heston to infuse the form with his stature, fire and guts."
In his obituary for the actor, film critic Roger Ebert noted, "Heston made at least three movies that almost everybody eventually sees: "Ben-Hur", "The Ten Commandments" and "Planet of the Apes"."
Heston's cinematic legacy was the subject of "Cinematic Atlas: The Triumphs of Charlton Heston", an 11-film retrospective by the Film Society of the Lincoln Center that was shown at the Walter Reade Theater from August 29 to September 4, 2008.
On April 17, 2010, Heston was inducted into the National Cowboy and Western Heritage Museum's Hall of Great Western Performers.
In his childhood hometown of St. Helen, Michigan, a charter school, Charlton Heston Academy, opened on September 4, 2012. It is housed in the former St. Helen Elementary School. Enrollment on the first day was 220 students in grades kindergarten through eighth.
Charlton Heston was commemorated on a United States postage stamp issued on April 11, 2014.
Charlton Heston was inducted as a Laureate of The Lincoln Academy of Illinois and awarded the Order of Lincoln (the State’s highest honor) by the Governor of Illinois in 1977 in the area of Performing Arts.
Bibliography.
by Heston:

</doc>
<doc id="46169" url="https://en.wikipedia.org/wiki?curid=46169" title="Lucca">
Lucca

Lucca () is a city and "comune" in Tuscany, Central Italy, on the Serchio, in a fertile plain near the Tyrrhenian Sea. It is the capital of the Province of Lucca. One thing for which it is famous is its intact Renaissance-era city walls.
History.
Ancient and medieval city.
Lucca was founded by the Etruscans (there are traces of a pre-existing Ligurian settlement) and became a Roman colony in 180 BC. The rectangular grid of its historical centre preserves the Roman street plan, and the Piazza San Michele occupies the site of the ancient forum. Traces of the amphitheatre can still be seen in the Piazza dell'Anfiteatro.
At the Lucca Conference, in 56 BC, Julius Caesar, Pompey, and Crassus reaffirmed their political alliance known as the First Triumvirate.
Frediano, an Irish monk, was bishop of Lucca in the early 6th century. At one point, Lucca was plundered by Odoacer, the first Germanic King of Italy. Lucca was an important city and fortress even in the 6th century, when Narses besieged it for several months in 553. Under the Lombards, it was the seat of a duke who minted his own coins. The Holy Face of Lucca (or Volto Santo), a major relic supposedly carved by Nicodemus, arrived in 742. During the 8th - 10th centuries Lucca was a center of Jewish life, the Jewish community being led by the Kalonymos family (which at some point during this time migrated to Germany to become a major component of proto-Ashkenazic Jewry). Lucca became prosperous through the silk trade that began in the 11th century, and came to rival the silks of Byzantium. During the 10–11th centuries Lucca was the capital of the feudal margraviate of Tuscany, more or less independent but owing nominal allegiance to the Holy Roman Emperor.
First republic.
After the death of Matilda of Tuscany, the city began to constitute itself an independent commune, with a charter in 1160. For almost 500 years, Lucca remained an independent republic. There were many minor provinces in the region between southern Liguria and northern Tuscany dominated by the Malaspina; Tuscany in this time was a part of feudal Europe. Dante’s "Divine Comedy" includes many references to the great feudal families who had huge jurisdictions with administrative and judicial rights. Dante spent some of his exile in Lucca.
In 1273 and again in 1277, Lucca was ruled by a Guelph "capitano del popolo" (captain of the people) named Luchetto Gattilusio. In 1314, internal discord allowed Uguccione della Faggiuola of Pisa to make himself lord of Lucca. The Lucchesi expelled him two years later, and handed over the city to another "condottiero", Castruccio Castracani, under whose rule it became a leading state in central Italy. Lucca rivalled Florence until Castracani's death in 1328. On 22 and 23 September 1325, in the battle of Altopascio, Castracani defeated Florence's Guelphs. For this he was nominated by Louis IV the Bavarian to become duke of Lucca. Castracani's tomb is in the church of San Francesco. His biography is Machiavelli's third famous book on political rule.
In 1408, Lucca hosted the convocation intended to end the schism in the papacy. Occupied by the troops of Louis of Bavaria, the city was sold to a rich Genoese, Gherardino Spinola, then seized by John, king of Bohemia. Pawned to the Rossi of Parma, by them it was ceded to Mastino II della Scala of Verona, sold to the Florentines, surrendered to the Pisans, and then nominally liberated by the emperor Charles IV and governed by his vicar. Lucca managed, at first as a democracy, and after 1628 as an oligarchy, to maintain its independence alongside of Venice and Genoa, and painted the word "Libertas" on its banner until the French Revolution in 1789.
After Napoleonic conquest.
Lucca had been the second largest Italian city state (after Venice) with a republican constitution ("comune") to remain independent over the centuries.
In 1805, Lucca was conquered by Napoleon, who installed his sister Elisa Bonaparte Baciocchi as "Queen of Etruria".
From 1815 to 1847 it was a Bourbon-Parma duchy. The only reigning dukes of Lucca were Maria Luisa of Spain, who was succeeded by her son Charles II, Duke of Parma in 1824. Meanwhile, the Duchy of Parma had been assigned for life to Marie Louise, Duchess of Parma, the second wife of Napoleon. In accordance with the Treaty of Vienna (1815), upon the death of Marie Louise, Duchess of Parma in 1847, Parma reverted to Charles II, Duke of Parma, while Lucca lost independence and was annexed to the Grand Duchy of Tuscany. As part of Tuscany, it became part of the Kingdom of Sardinia in 1860 and finally part of the Italian State in 1861.
Main sights.
Walls, streets, and squares.
The walls encircling the old town remain intact, even as the city expanded and modernized, unusual for cities in the region. Once the walls lost their military importance, they became a pedestrian promenade, the Passeggiata delle Mura Urbane, a street atop the walls linking the bastions. It passes through the Bastions of Santa Croce, San Frediano, San Martino, San Pietro/Battisti, San Salvatore, La Libertà/Cairoli, San Regolo, San Colombano, Santa Maria, San Paolino/Catalani, and San Donato; and over the gates (Porte): San Donato, Santa Maria, San Jocopo, Elisa, San Pietro, and Sant'Anna. Each of the four principal sides is lined with a different tree species.
The walled city is encircled by Piazzale Boccherini, Viale Lazzaro Papi, Viale Carlo Del Prete, Piazzale Martiri della Libertà, Via Batoni, Viale Agostino Marti, Viale G. Marconi ("vide" Guglielmo Marconi), Piazza Don A. Mei, Viale Pacini, Viale Giusti, Piazza Curtatone, Piazzale Ricasoli, Viale Ricasoli, Piazza Risorgimento ("vide" Risorgimento) and Viale Giosuè Carducci.
The town includes a number of public squares, most notably the Piazza dell'Anfiteatro, site of ancient Roman amphitheater; but also Piazzale Verdi; Piazza Napoleone'; and Piazza San Michele.
Churches.
There are many medieval, a few as old as the 8th century, basilica-form churches with richly arcaded façades and campaniles.
Culture.
Lucca is the birthplace of composers Giacomo Puccini ("La Bohème" and "Madama Butterfly)", Nicalao Dorati, Francesco Geminiani, Gioseffo Guami, Luigi Boccherini, and Alfredo Catalani. It is also the birthplace of Bruno Menconi and artist Benedetto Brandimarte.
Events.
Lucca annually hosts the Lucca Summer Festival. The 2006 edition saw Eric Clapton, Placebo, Massive Attack, Roger Waters, Tracy Chapman and Santana play live in the "Piazza Napoleone".
Lucca hosts the annual Lucca Comics and Games festival, Europe's largest festival for comics and related subjects.
Other events include:
Film and television.
Mauro Bolognini's 1958 film "Giovani mariti" with Sylva Koscina is set and was filmed in Lucca.
International relations.
Lucca is twinned with:

</doc>
<doc id="46172" url="https://en.wikipedia.org/wiki?curid=46172" title="Siderno">
Siderno

Siderno () is a town and "comune" located in Calabria, Italy about 3 kilometres from Locri.
Siderno Marina is the newer town located on the Ionian coast. It is popular with both Italian and foreign tourists and has a bathing beach.
Siderno Superiore is the old town, higher up on the flank of the coastal mountain range. It has historic palaces, old buildings and very narrow streets. It has now become a ghost town because most of the old population has moved to the more modern Siderno which is the new city and offers more job opportunities and services.
History.
The early history of the town is unknown. The old town in the hilly inland was probably founded in the 10th century by some people from Locri, who had fled to the area to defend themselves from Saracen incursions; in the following century it became a hamlet of the county of Grotteria and was home to various feudal lords. Siderno Marina was built along the coast after the 1783 earthquake.
Emigration.
Large-scale emigration abroad as well as to Northern Italy, which began to diminish only in the 1970s, has had a lasting effect on the demographic situation in the region. Emigrants from Siderno emigrated to the United States, Canada and Australia since the end of the 19th century to find employment.
Many moving to Canada settled in Schreiber, Ontario, because of the construction of the Canadian Pacific Railway and many played a major part in its completion. One of them was Cosimo Figliomeni. His good fortune and letters home lured many of his villagers to jobs in Schreiber. Half of Schreiber’s 2,000 residents trace their roots to the Italian city of Siderno.
Economy.
Siderno, also known as the "pearl" of the "Jasmine Riviera" (Italian: "Riviera dei Gelsomini")), is one of the most well-equipped tourist resorts on the Ionian coast of the province of Reggio Calabria, with wide, sandy beaches, clear sea and a magnificently-coloured seabed.
The Siderno area is famous for the production of bergamot orange, a citrus fruit that is used as an essence and fundamental ingredient in cosmetics, for its wound healing properties in the pharmaceutical industry, and for flavouring in the food industry.
Crime.
The town is home to the 'Ndrangheta, a Mafia-type criminal organization based in Calabria. Several powerful criminal clans originate from the town. Siderno was the fiefdom of Antonio Macrì, the undisputed local boss until his demise in January 1975. Several of the criminal clans are sometimes involved in bloody feuds. The town is home to one of the 'Ndrangheta's biggest and most important clans, the Commisso 'ndrina, heavily involved in the global cocaine business and money laundering.
Several clans moved to Canada, in particular the Greater Toronto Area, home to what Canadian law enforcement call the Siderno Group, which has been here since at least the 1950s. "The criminal minds of Siderno are in Canada", according to the Siderno police force. One of them, Antonio Commisso, was arrested in June 2005.
Frazioni.
Donisi (), Vennerello, Mirto (), Campo, Lucis, Zammariti, Pellegrina, Arona, San Filippo, Leone, Grappidaro, Gonia (), Pergola, Lamia.

</doc>
<doc id="46173" url="https://en.wikipedia.org/wiki?curid=46173" title="Fish and chips">
Fish and chips

Fish and chips is a hot dish of English origin and an early example of culinary fusion, consisting of fried battered fish and hot chips. It is a common take-away food.
History.
Fish and chips became a stock meal among the working classes in England as a consequence of the rapid development of trawl fishing in the North Sea, and the development of railways which connected the ports to major industrial cities during the second half of the 19th century, so that fresh fish could be rapidly transported to the heavily populated areas. Fried fish was first brought to England by Spanish Jews, and is considered the model for the fish element of the dish. Originally, Spanish Jews settling in England in the 17th century would have prepared fried fish in a manner similar to Pescado frito, which is coated in a flour. Battered fish is first coated in flour then dipped into a batter consisting of flour mixed with liquid, usually water but sometimes beer. Some newer modifications to the recipe may have cornflour added, and instead of beer sometimes soda water is added. In 1860, the first fish and chip shop was opened in London by Joseph Malin.
Deep-fried chips (slices or pieces of potato) as a dish may have first appeared in England in about the same period: the "Oxford English Dictionary" notes as its earliest usage of "chips" in this sense the mention in Dickens' "A Tale of Two Cities" (published in 1859): "Husky chips of potatoes, fried with some reluctant drops of oil".
The modern fish-and-chip shop ("chippy" or "chipper" in modern English slang) originated in the United Kingdom, although outlets selling fried food occurred commonly throughout Europe. Early fish-and-chip shops had only very basic facilities. Usually these consisted principally of a large cauldron of cooking fat, heated by a coal fire. The fish-and-chip shop later evolved into a fairly standard format, with the food served, in paper wrappings, to queuing customers, over a counter behind which the fryers were located. During World War II fish and chips remained one of the few foods in the United Kingdom not subject to rationing.
British fish and chips were originally served in a wrapping of old newspapers, but this practice largely ceased as a result of European Union directives, with plain paper, cardboard or plastic being used instead.
In the United Kingdom the Fish Labelling Regulations 2003 and in Ireland the European Communities (Labelling of Fishery and Aquaculture Products) Regulations 2003 respectively enact directive 2065/2001/EC, and generally mean that "fish" must be sold with the particular commercial name or species named; so, for example, "cod and chips" now appears on menus rather than the more vague "fish and chips". In the United Kingdom the Food Standards Agency guidance excludes caterers from this; but several local Trading Standards authorities and others do say it cannot be sold merely as "fish and chips".
United Kingdom.
The dish became popular in wider circles in London and South East England in the middle of the 19th century: Charles Dickens mentions a "fried fish warehouse" in "Oliver Twist", first published in 1838, while in the north of England a trade in deep-fried chipped potatoes developed. The first chip shop stood on the present site of Oldham's Tommyfield Market. It remains unclear exactly when and where these two trades combined to become the fish-and-chip shop industry we know. A Jewish immigrant, Joseph Malin, opened the first recorded combined fish-and-chip shop in London in 1860 or in 1865; a Mr Lees pioneered the concept in the North of England, in Mossley, in 1863.
The concept of a fish restaurant, as opposed to take-away, was introduced by Samuel Isaacs (born 1856 in Whitechapel, London; died 1939 in Brighton, Sussex) who ran a thriving wholesale and retail fish business throughout London and the South of England in the latter part of the 19th century. Isaacs' first restaurant opened in London in 1896 serving fish and chips, bread and butter, and tea for nine pence, and its popularity ensured a rapid expansion of the chain.
The restaurants were carpeted, had waited service, tablecloths, flowers, china and cutlery, and made the trappings of upmarket dining affordable to the working classes for the first time. They were located in Tottenham Court Road, St Pancras, The Strand, Hoxton, Shoreditch, Brixton and other London districts, as well as Clacton, Brighton, Ramsgate, Margate and other seaside resorts in southern England. Menus were expanded in the early 20th century to include meat dishes and other variations as their popularity grew to a total of thirty restaurants. Sam Isaacs' trademark was the phrase "This is the Plaice", combined with a picture of the punned-upon fish in question. A glimpse of the old Brighton restaurant at No.1 Marine Parade can be seen in the background of Norman Wisdom's 1955 film "One Good Turn" just as Norman/Pitkin runs onto the seafront; this is now the site of a Harry Ramsden's fish and chips restaurant. A blue plaque at Oldham's Tommyfield Market marks the first chips fried in England in 1860, and the origin of the fish and chip shop and fast food industries in England.
Dundee City Council claims that "… in the 1870s, that glory of English gastronomy—the chip—was first sold by Belgian immigrant Edward De Gernier in the city's Greenmarket."
In Edinburgh, a combination of Gold Star brown sauce and water or malt vinegar, known as "sauce", or more specifically as "chippy sauce", has great popularity.
Ireland.
In Ireland, the first fish and chips were sold by an Italian immigrant, Giuseppe Cervi, who mistakenly stepped off an America-bound ship at Cobh (then called Queenstown) in County Cork in the 1880s and walked all the way to Dublin. He started by selling fish and chips outside Dublin pubs from a handcart. He then found a permanent spot in Great Brunswick Street (now Pearse Street). His wife Palma would ask customers "Uno di questa, uno di quella?" This phrase (meaning "one of this, one of the other") entered the vernacular in Dublin as "one and one", which is still a way of referring to fish and chips in the city.
India.
In India, the dish is usually based on Pomfret fish, and uses more chili paste and pepper than would be used in the UK. The dish is more of a niche market delicacy in India than a mass market dish.
United States.
In the United States, the dish is most commonly sold as "fish and chips", except in Upstate New York and Wisconsin and other parts of the Northeast and Upper Midwest, where this dish would be called a fish fry. Despite the name "fish and chips", and the US meaning of "chips", the dish is served with French fries. In the southeastern United States, a common form of cuisine is fried catfish with French fries, accompanied by coleslaw, pickles, raw onion slices and lemon slices.
Denmark.
Typical Danish fish and chips are plaice fillets, breaded and fried, and served alongside a remoulade, a slice of lemon, and chips ("pommes frites") on the side. It is normally served in restaurants, not as fast food. Other light-coloured fish may be used, such as other flatfish, cod or saithe.
Composition.
Cooking.
Traditional frying uses beef dripping or lard; however, vegetable oils, such as peanut oil (used because of its relatively high smoke point) predominate. A minority of vendors in the north of England and Scotland and the majority of vendors in Northern Ireland still use dripping or lard, as it imparts a different flavour to the dish, but this makes the fried chips unsuitable for vegetarians and for adherents of certain faiths. Lard is used in some living industrial history museums, such as the Black Country Living Museum.
Thickness.
English chips are usually thicker than American-style French fries sold by major multinational fast food chains, resulting in a lower fat content per portion. In their homes or in some restaurants, people in or from the United States may eat a thick type of chip, more similar to the English variant, sometimes referred to as steak fries.
Batter.
In Britain and Ireland, fish and chip shops traditionally use a simple water and flour batter, adding a little sodium bicarbonate (baking soda) and a little vinegar to create lightness, as they create bubbles in the batter. Other recipes may use beer or milk batter, where these liquids are often substitutes for water. The carbon dioxide in the beer lends a lighter texture to the batter. Beer also results in an orange-brown colour. A simple beer batter might consist of a 2:3 ratio of flour to beer by volume. The type of beer makes the batter taste different: some prefer lager whereas others use stout or bitter.
Choice of fish.
In Britain and Ireland, cod and haddock appear most commonly as the fish used for fish and chips, but vendors also sell many other kinds of fish, especially other white fish, such as pollock or coley, plaice, skate, and ray (particularly popular in Ireland); and huss or rock salmon (a term covering several species of dogfish and similar fish). In Northern Ireland, cod, plaice or whiting appear most commonly in 'fish suppers'—'supper' being Scottish and Northern Irish chip-shop slang for a food item accompanied by chips. Suppliers in Devon and Cornwall often offer pollock and coley as cheap alternatives to haddock, due to their regular availability in a common catch.
In Australia, reef cod and rock cod (a different variety from that used in the United Kingdom), barramundi (an expensive option) or flake (a type of shark meat), or snapper—both cheaper options—are commonly used. From the early 21st century, farmed basa imported from Vietnam and hoki have become common in Australian fish and chip shops. Other types of fish are also used based on regional availability.
In New Zealand, snapper or gurnard was originally the preferred species for battered fillets in the North Island. As catches of this fish declined, it was replaced by hoki, shark (particularly rig) – marketed as lemon fish – and tarakihi. Bluefin gurnard and blue cod predominate in South Island fish and chips.
In the United States, the type of fish used depends on availability in a given region. Some common types are cod, halibut, flounder, tilapia or, in New England, Atlantic cod or haddock. Salmon is growing common on the West Coast, while freshwater catfish is most frequently used in the Southeast. In Canada, pollock, haddock, and halibut are popular choices, alongside cod.
Accompaniments.
In chip shops in the United Kingdom and Ireland, salt and vinegar are traditionally sprinkled over fish and chips at the time it is served. Suppliers use malt vinegar, onion vinegar (used for pickling onions), or the cheaper non-brewed condiment. In England a portion of mushy peas is a popular side dish, as are a range of pickles that typically include gherkins, onions and eggs. In table-service restaurants and pubs, the dish is usually served with a slice of lemon for squeezing over the fish and without any sauces or condiments, with salt, vinegar and sauces available at the customer's leisure.
In Ireland, Wales and England, most takeaways serve warm side portions of sauces such as curry sauce, gravy or mushy peas. The sauces are usually poured over the chips. In some areas, this dish without fish is referred to as 'wet chips'. In the Midlands especially, chips with mushy peas or baked beans is known as a "pea mix" or a "bean mix". Other fried products include 'scraps' (also known as 'bits' in Southern England and "scrumps" in South Wales), originally a by-product of fish frying. Still popular in Northern England, they were given as treats to the children of customers. Portions prepared and sold today consist of loose blobs of batter, deep fried to a crunchy golden crisp in the cooking-fat. The very popular potato scallop or potato cake consists of slices of potato dipped in fish batter and deep fried until golden brown. These are often accompanied for dipping by the warm sauces listed above.
Vendors.
In the United Kingdom, Ireland, Australia, Canada, New Zealand and South Africa, fish and chips are usually sold by independent restaurants and take-aways known as fish and chip shops. Outlets range from small affairs to chain restaurants. Locally owned seafood restaurants are also popular in many places, as are mobile "chip vans". In Canada, the outlets may be referred to as "chip wagons". In the United Kingdom some shops have amusing names, such as "A Salt and Battery", "The Codfather","The Frying Scotsman", "Oh My Cod", and "Frying Nemo" In New Zealand and Australia, fish-and-chip vendors are a popular business and source of income among the Asian community, particularly Chinese migrants.
In Ireland, the majority of traditional vendors are migrants or the descendants of migrants from southern Italy. A trade organisation exists to represent this tradition.
Fish and chips is a popular lunch meal eaten by families travelling to seaside resorts for day trips who do not bring their own picnic meals.
Fish-and-chip outlets sell roughly 25% of all the white fish consumed in the United Kingdom, and 10% of all potatoes.
The numerous competitions and awards for "best fish-and-chip shop" testify to the recognised status of this type of outlet in popular culture.
Fish-and-chip shops traditionally wrapped their product in newspaper, or with an inner layer of white paper (for hygiene) and an outer layer of newspaper or blank newsprint (for insulation and to absorb grease), though the use of newspaper for wrapping has almost ceased on grounds of hygiene. , establishments usually use food-quality wrapping paper, occasionally printed on the outside to imitate newspaper.
The British National Federation of Fish Friers was founded in 1913. It promotes fish and chips and offers training courses.
A previous world record for the "largest serving of fish and chips" was held by Gadaleto's Seafood Market in New Paltz, New York. This 2004 record was broken by Yorkshire pub "Wensleydale Heifer" in July 2011. An attempt to break this record was made by Doncaster fish and chip shop Scawsby Fisheries in August 2012, which served of battered cod alongside of chips.
Cultural impact.
The long-standing Roman Catholic tradition of not eating meat on Fridays, especially during Lent, and of substituting fish for meat on that day continues to influence habits even in predominantly Protestant, Anglican, semi-secular and secular societies. Friday night remains a traditional occasion for eating fish-and-chips; and many cafeterias and similar establishments, while varying their menus on other days of the week, habitually offer fish and chips every Friday.
In Australia and New Zealand, the words "fish and chips" are often used to highlight the difference in each country's short-i vowel sound . Australian English has a higher forward sound , close to the "y" in "happy" and "city", while New Zealand English has a lower backward sound , a slightly higher version of the "a" in "about" and "comma". Thus, New Zealanders hear Australians say "feesh and cheeps," while Australians hear New Zealanders say "fush and chups."
Environment.
In the UK, waste oil from fish and chip shops has become a useful source of biodiesel. German biodiesel company Petrotec have outlined plans to produce biodiesel in the UK from waste oil from the British fish-and-chip industry.

</doc>
<doc id="46174" url="https://en.wikipedia.org/wiki?curid=46174" title="National Institutes of Health">
National Institutes of Health

The National Institutes of Health (NIH) is a biomedical research facility primarily located in Bethesda, Maryland. An agency of the United States Department of Health and Human Services, it is the primary agency of the United States government responsible for biomedical and health-related research. The NIH both conducts its own scientific research through its Intramural Research Program (IRP) and provides major biomedical research funding to non-NIH research facilities through its Extramural Research Program.
With 1,200 principal investigators and more than 4,000 postdoctoral fellows in basic, translational, and clinical research, the IRP is the largest biomedical research institution in the world, while, as of 2003, the extramural arm provided 28% of biomedical research funding spent annually in the U.S., or about US$26.4 billion.
The NIH comprises 27 separate institutes and centers that conduct research in different disciplines of biomedical science. The IRP is responsible for many scientific accomplishments, including the discovery of fluoride to prevent tooth decay, the use of lithium to manage bipolar disorder, and the creation of vaccines against hepatitis, "Haemophilus influenzae" (HIB), and human papillomavirus (HPV).
History.
NIH's roots extend back to a Marine Hospital Service in the late 1790s that provided medical relief to sick and disabled men in the U.S. Navy. By 1870, a network of marine hospitals had developed and was placed under the charge of a medical officer within the Bureau of the Treasury Department. In the late 1870s, Congress allocated funds to investigate the causes of epidemics like cholera and yellow fever, and it created the National Board of Health, making medical research an official government initiative.
In 1887, a laboratory for the study of bacteria, the Hygienic Laboratory, was established at the Marine Hospital in New York. In the early 1900s, Congress began appropriating funds for the Marine Hospital Service. By 1922, this organization changed its name to Public Health Services and established a Special Cancer Investigations laboratory at Harvard Medical School. This marked the beginning of a partnership with universities. In 1930, the Hygienic Laboratory was re-designated as the National Institute of Health by the Ransdell Act and was given $750,000 to construct two NIH buildings. Over the next few decades, Congress would increase its funding tremendously to the NIH, and various institutes and centers within the NIH were created for specific research programs. In 1944, the Public Health Service Act was approved, and National Cancer Institute became a division of NIH. In 1948, the name changed from National Institute of Health to National Institutes of Health.
In 1967, the Division of Regional Medical Programs was created to administer grants for research for heart disease, cancer, and strokes. That same year, the NIH director lobbied the White House for increased federal funding in order to increase research and the speed with which health benefits could be brought to the people. An advisory committee was formed to oversee further development of the NIH and its research programs. By 1971, cancer research was in full force and President Nixon signed the National Cancer Act, initiating a National Cancer Program, President's Cancer Panel, National Cancer Advisory Board, and 15 new research, training, and demonstration centers.
The funding of NIH has often been a source of contention in Congress, serving as a proxy for the political currents of the time. This contention was seen most dramatically during the 1980s, when President Reagan repeatedly tried to cut funding for research, only to see Congress partly restore funding. The political contention over NIH funding slowed the nation's response to the AIDS epidemic; while AIDS was reported in newspaper articles from 1981, no funding was provided for research on the disease. In 1984, National Cancer Institute scientists found implications that "variants of a human cancer virus called HTLV-III are the primary cause of acquired immunodeficiency syndrome (AIDS)," a new epidemic that gripped the nation. But it was not until July 1987, as NIH celebrated its 100th anniversary, that President Reagan announced a committee to research the HIV epidemic. 
By the 1990s, the focus of the NIH committee had shifted to DNA research, and the Human Genome Project was launched. In 2009, President Obama reinstated federally funded stem-cell research, revoking the ban imposed by President Bush in 2001.
From logistical restructuring, to funding increases, to research prioritization, to government expansion and political influence, the history of the National Institutes of Health is extensive and full of change. The NIH has grown to encompass nearly 1 percent of the federal government's operating budget. The NIH now controls more than 50 percent of all funding for health research, and 85 percent of all funding for health studies in universities.
Locations and campuses.
Intramural research is primarily conducted at the main campus in Bethesda, Maryland, and the surrounding communities. The National Institute on Aging and the National Institute on Drug Abuse are located in Baltimore, Maryland, and the National Institute of Environmental Health Sciences is located in the Research Triangle region of North Carolina. The National Institute of Allergy and Infectious Diseases maintains its Rocky Mountain Labs in Hamilton, Montana, with an emphasis on BSL3 and BSL4 laboratory work.
Research.
NIH devotes 10% of its funding to research within its own facilities (intramural research). The institution gives 80% of its funding in research grants to extramural (outside) researchers. Of this extramural funding, a certain percentage (2.8% in 2014) must be granted to small businesses under the SBIR/STTR program. The extramural funding consists of about 50,000 grants to more than 325,000 researchers at more than 3000 institutions. , NIH spent (not including temporary funding from the American Recovery and Reinvestment Act of 2009) on clinical research, on genetics-related research, on prevention research, on cancer, and on biotechnology.
Public Access Policy.
In 2008, a Congressional mandate called for investigators funded by the NIH to submit an electronic version of their final manuscripts to the National Library of Medicine's research repository, PubMed Central (PMC), no later than 12 months after the official date of publication. The NIH Public Access Policy was the first public access mandate for a U.S. public funding agency.
NIH Interagency Pain Research Coordinating Committee.
February 13, 2012 the National Institutes of Health (NIH) announced a new group of individuals assigned to research pain. This committee is composed of researchers from different organizations and will focus to "coordinate pain research activities across the federal government with the goals of stimulating pain research collaboration… and providing an important avenue for public involvement" ("Members of new," 2012). With a committee such as this research will not be conducted by each individual organization or person but instead a collaborating group which will increase the information available. With this hopefully more pain management will be available including techniques for arthritis sufferers.
NIH Toolbox.
In September 2006, a contract for the NIH Toolbox for the Assessment of Neurological and Behavioral Function (www.nihtoolbox.org) was initiated by the NIH Blueprint for Neuroscience Research (www.neuroscienceblueprint.nih.gov) to develop a set of state-of-the-art measurement tools to enhance collection of data in large cohort studies and to advance the biomedical research enterprise. The NIH Toolbox was officially rolled out to the research community on September 10–11, 2012 at a public conference "Unveiling the NIH Toolbox" held in Bethesda, Maryland and Washington, D.C. Scientists from more than 100 institutions nationwide contributed to the development of the NIH Toolbox. The construction of NIH Toolbox assessments is based, where possible, on Item Response Theory and adapted for testing by computer.
Economic impact.
In 2000, a report from a Joint Economic Committee of Congress outlined the benefits of NIH research. It noted that some econometric studies had given its research, which was funded at $16 billion a year in 2000, a rate of return of 25 to 40 percent per year. It also found that of the 21 drugs with the highest therapeutic impact on society introduced between 1965 and 1992, public funding was "instrumental" for 15.
Funding.
To allocate funds, the NIH must first obtain its budget from Congress. This process begins with institute and center (IC) leaders collaborating with scientists to determine the most important and promising research areas within their fields. IC leaders discuss research areas with NIH management who then develops a budget request for continuing projects, new research proposals, and new initiatives from the Director. NIH submits its budget request to the Department of Health and Human Services (HHS), and the HHS considers this request as a portion of its budget. Many adjustments and appeals occur between NIH and HHS before the agency submits NIH's budget request to the Office of Management and Budget (OMB). 
OMB determines what amounts and research areas are approved for incorporation into the President's final budget. The President then sends NIH's budget request to Congress in February for the next fiscal year's allocations. The House and Senate Appropriations Subcommittees deliberate and by fall, Congress usually appropriates funding. This process takes approximately 18 months before the NIH can allocate any actual funds.
NIH employs five broad decision criteria in its funding policy. First, ensure the highest quality of scientific research by employing an arduous peer review process. Second, seize opportunities that have the greatest potential to yield new knowledge and that will lead to better prevention and treatment of disease. Third, maintain a diverse research portfolio in order to capitalize on major discoveries in a variety of fields such as cell biology, genetics, physics, engineering, and computer science. Fourth, address public health needs according to the disease burden (e.g., prevalence and mortality). And fifth, construct and support the scientific infrastructure (e.g., well-equipped laboratories and safe research facilities) necessary to conduct research.
In 2007 the director of the agency stated "responsibilities for identifying ... FCOIs (financial conflict of interest) must remain with grantee institutions" but institutions that administer grants have no interest to identify grantee's conflicts of interest.
The NIH issued dozens of waivers for NIH's advisory committee members up to 2012. Such waivers exempt a conflicted government employee from ethics laws. Since 2005 the U.S. Office of Government Ethics had documented only three times where the NIH consulted with the office as required by law, and none of the waivers in question had to do with a member of an advisory committee.
Advisory committee members advise the Institute on policy and procedures affecting the external research programs and provide a second level of review for all grant and cooperative agreement applications considered by the Institute for funding.
Recent changes.
The NIH funding policy has changed in several significant ways over time. First, the amount of money given to the NIH has increased in hard dollars, although in relation to inflation and the increased expense of doing science, the funding levels are currently down. Most scientists know that in the history of the NIH, it is more difficult now to get R01 grant funding than ever before, let alone have them renewed. The scientific community concerns the low funding to be a crisis in America, and wonder how China can busily recruit our scientists who cannot stay funded given the lowered NIH funding levels without American realizing the great cost to this nation of not funding research. R01 Grants scored even in the top 20% are not being funded nowadays—and that 20% is after fifty percent of the grants are first triaged. So only five percent of grants are getting funded. And grants cannot be submitted more than two times.
However, in hard dollars, the funding appears to have gone up. For example, in 1999, Congress increased the NIH's budget by $2.3 billion. (to $17.2 billion in 2000) 
In 2009 Congress again increased the NIH budget to $31 billion in 2010. Second, with the creation of the various ICs, the responsibility to allocate funding to researchers has shifted from the OD and Advisory Committee to the individual ICs. Additionally, Congress increasingly sets apart funding for particular causes. In the 1970s, Congress began to earmark funds specifically for cancer research and in the 1980s there was a significant amount allocated for AIDS/HIV research. Congress has continued to play an active role in allotting funds for specified research. These are some of the most significant changes in NIH funding policy over the last century.
A few of the key issues in evaluating NIH funding policy were previously mentioned in the paper as the five criteria the NIH has established. Three of the criteria are particularly relevant. First, is the NIH ensuring the highest quality of research by fairly implementing their peer review process and allocating extramural research funds? Second, is the NIH maximizing opportunities to produce research that yields new knowledge that will lead to better disease prevention and treatment? Next, are public health needs being addressed according to the public disease burden; in other words, are the most important needs of society being met rather than those of special interest groups? These are the most important issues in evaluating NIH funding policy.
When a government shutdown occurs, the NIH continues to treat people who are already enrolled in clinical trials, but does not start any new clinical trials and does not admit new patients who are not already enrolled in a clinical trial, except for the most critically ill, as determined by the NIH Director.
In 2014, it was announced that the NIH is directing scientists to perform their experiments with both female and male animals, or cells derived from females as well as males if they are studying cell cultures, and that the NIH would take the balance of each study design into consideration when awarding grants. However, the announcement also stated that this rule would probably not apply when studying sex-specific diseases (for example, ovarian or testicular cancer).
Grant allocation bias controversy.
In 2011, a paper published in "Science" found that black researchers were 10% less likely to win NIH R01 grants (the oldest and most widely used) than white researchers, after controlling for "educational background, country of origin, training, previous research awards, publication record, and employer characteristics." It also found that black researchers are significantly less likely to resubmit an unapproved grant than white researchers. The study lead and economist Donna Grant said that grant reviewers do not have access to the applicant race, but may infer it from biographies or names. She also speculated that the decreased re-submission rate may be due to lack of mentoring. The study, which was commissioned by the NIH, included in its analysis 83,000 grant applications, made between 2000 and 2006. Dr. Otis W. Brawley, chief medical officer at the American Cancer Society and a black man, commented on the cause of the disparity as one unrelated to racism per se, but rather to the reviewers' unconscious tendency to more likely give the benefit of the doubt to someone they are familiar with, in a scientific world where black researchers tend to keep a lower profile than other groups. The study did not reveal similar difficulties for members of other races and ethnic groups (e.g., Hispanics). Taxpayer dollars funding NIH are from the taxpayers, making them the primary beneficiaries of advances in research. Thus, the general public is a key stakeholder in the decisions resulting from the NIH funding policy. Congress theoretically represents the public interest as the NIH Advisory Committee allocates to the NIH, and the funds to the Director. However, many in the general public do not feel their interests are being accurately represented. As a result, individuals have formed patient advocacy groups to represent their own interests. Patient advocacy groups tend to focus on specific aspects of health care or diseases. Advocates get involved in many different areas such as organizing awareness campaigns, promoting patients' rights, and enhancing health policy initiatives. Most importantly, patient advocacy groups are often involved with advisory panels to ensure that current projects and those projects being considered for funding will directly impact patients' lives, improve delivery of care, and provide support for tertiary care. Advocacy groups strive to promote a health care system that is beneficial for all parties involved. Through congressional representation, NIH Advisory Committee efforts, and patient advocacy groups, the public is able to influence funding allocation as well as the policy itself.
Extramural researchers and scientists.
Other important stakeholders of the NIH funding policy are the researchers and scientists themselves. Extramural researchers differ from intramural researchers in that they are not employed by the NIH but must apply for funding. Throughout the history of the NIH, the amount of funding received has increased, but the proportion to each IC remains relatively constant. The individual ICs then decide who will receive the grant money and how much will be allotted. Research funding is important to extramural researchers for multiple reasons. Without the help of an NIH grant (or a similar type of funding), researchers and scientists are unable to pursue their own research interests but are obliged to follow the agenda of the company or university for which they work. This could potentially hinder discoveries in novel research areas.
In 2000, Brian Jacobs and Lars Lefgren researched extensively the impact of NIH grants on basic research and development, and the careers of grant recipients. 
For the period of 1980–2000, they reviewed all postdoctoral research grants and standard research grants for those who received funding and those who did not. Jacobs and Lefgren found that scientists who received postdoctoral research grants were 20 percent more likely to be published within the first five years after receiving the grant. They also found that scientists who received grants were 11 percent more likely to have one publication and 23 percent more likely to have five publications. Due to the 'publish or perish' standard that many researchers face, NIH funding can have a great impact on researchers' careers.
Receiving a standard research grant also has a significant impact on researchers. Young scientists who receive a first-time grant (R01) usually produce more than one additional publication in the five-year period after they receive the grant. Those who receive an NIH grant will typically receive $252,000 more in NIH funding in the following six to ten years, and a statistically significant relationship exists between scientists receiving NIH grants and their research productivity throughout their careers.
Policy changes on who receives funding also significantly affect researchers. For example, the NIH has recently attempted to approve more first-time NIH R01 applicants, or the research grant applications of young scientists. To encourage the participation of young scientists who potentially think outside the box, the application process has been shortened and made easier. In addition, first-time applicants are being offered more funding for their research grants than those who have received grants in the past. Although this change provides greater opportunities for young scientists, it also places older, more experienced scientists at a funding disadvantage.
Commercial partnerships.
In 2011 and 2012, the Department of Health and Human Services Office of Inspector General published a series of audit reports revealing that throughout the fiscal years 2000–2010, institutes under the aegis of the NIH, did not comply with the time and amount requirements specified in appropriations statutes, in awarding federal contracts to commercial partners, committing the federal government to tens of millions of dollars of expenditure ahead of appropriation of funds from Congress.
</ref>
Institutes and centers.
The NIH is composed of 27 separate institutes and centers (ICs) that conduct and coordinate research across different disciplines of biomedical science. These are:
In addition, the National Center for Research Resources operated from April 13, 1962 to December 23, 2011.

</doc>
<doc id="46177" url="https://en.wikipedia.org/wiki?curid=46177" title="Epidemic typhus">
Epidemic typhus

Epidemic typhus (also called "camp fever", "jail fever", "hospital fever", "ship fever", "famine fever", "putrid fever", "petechial fever", "Epidemic louse-borne typhus," and "louse-borne typhus") is a form of typhus so named because the disease often causes epidemics following wars and natural disasters. The causative organism is "Rickettsia prowazekii", transmitted by the human body louse ("Pediculus humanus humanus"). Feeding on a human who carries the bacterium infects the louse. "R. prowazekii" grows in the louse's gut and is excreted in its feces. The disease is then transmitted to an uninfected human who scratches the louse bite (which itches) and rubs the feces into the wound. The incubation period is one to two weeks. "R. prowazekii" can remain viable and virulent in the dried louse feces for many days. Typhus will eventually kill the louse, though the disease will remain viable for many weeks in the dead louse.
Signs and symptoms.
Symptoms include severe headache, a sustained high fever, cough, rash, severe muscle pain, chills, falling blood pressure, stupor, sensitivity to light, delirium and death. A rash begins on the chest about five days after the fever appears, and spreads to the trunk and extremities. A symptom common to all forms of typhus is a fever which may reach 39 °C (102 °F).
Brill-Zinsser disease, first described by Nathan Brill in 1913 at Mount Sinai Hospital in New York City, is a mild form of epidemic typhus which recurs in someone after a long period of latency (similar to the relationship between chickenpox and shingles). This recurrence often occurs in times of relative immunosuppression, which is often in the context of malnutrition and other illnesses. In combination with poor sanitation and hygiene which leads to a greater density of lice, this reactivation is why typhus forms epidemics in times of social chaos and upheaval.
Transmission.
Epidemic typhus occurs most frequently during times of war and deprivation. For example, typhus killed hundreds of thousands of prisoners in Nazi concentration camps during World War II. The deteriorating quality of hygiene in camps such as Theresienstadt and Bergen-Belsen created conditions where diseases such as typhus flourished. Situations in the twenty-first century with potential for a typhus epidemic would include refugee camps during a major famine or natural disaster. In the periods between outbreaks, when human to human transmission occurs less often, the flying squirrel serves as a zoonotic reservoir for the "Rickettsia prowazekii" bacterium.
Henrique da Rocha Lima in 1916 then proved that the bacterium "Rickettsia prowazekii" was the agent responsible for typhus; he named it after H. T. Ricketts and Stanislaus von Prowazek, two zoologists who had died from typhus while investigating epidemics. Once these crucial facts were recognized, Rudolf Weigl in 1930 was able to fashion a practical and effective vaccine production method by grinding up the insides of infected lice that had been drinking blood. It was, however, very dangerous to produce, and carried a high likelihood of infection to those who were working on it.
A safer mass-production-ready method using egg yolks was developed by Herald R. Cox in 1938. This vaccine was widely available and used extensively by 1943.
Treatment.
The infection is treated with antibiotics. Intravenous fluids and oxygen may be needed to stabilize the patient. The mortality rate is 10% to 60%, but is vastly lower (close to zero) if intracellular antibiotics such as tetracycline are used before 8 days. Chloramphenicol is also used. Infection can also be prevented by vaccination.
History.
The first description of typhus was probably given in 1083 at La Cava abbey near Salerno, Italy. In 1546, Girolamo Fracastoro, a Florentine physician, described typhus in his famous treatise on viruses and contagion, "De Contagione et Contagiosis Morbis".
Before a vaccine was developed during World War II, typhus was a devastating disease for humans and has been responsible for a number of epidemics throughout history. These epidemics tend to follow wars, famine, and other conditions that result in mass casualties.
During the second year of the Peloponnesian War (430 BC), the city-state of Athens in ancient Greece was hit by a devastating epidemic, known as the Plague of Athens, which killed, among others, Pericles and his two elder sons. The plague returned twice more, in 429 BC and in the winter of 427/6 BC. Epidemic typhus is a strong candidate for the cause of this disease outbreak, supported by both medical and scholarly opinions.
Typhus also arrived in Europe with soldiers who had been fighting on Cyprus. The first reliable description of the disease appears during the Spanish siege of Moorish Granada in 1489. These accounts include descriptions of fever and red spots over arms, back and chest, progressing to delirium, gangrenous sores, and the stench of rotting flesh. During the siege, the Spaniards lost 3,000 men to enemy action but an additional 17,000 died of typhus.
Typhus was also common in prisons (and in crowded conditions where lice spread easily), where it was known as "Gaol fever" or "Jail fever". Gaol fever often occurs when prisoners are frequently huddled together in dark, filthy rooms. Imprisonment until the next term of court was often equivalent to a death sentence. It was so infectious that prisoners brought before the court sometimes infected the court itself. Following the Assize held at Oxford in 1577, later deemed the Black Assize, over 300 died from epidemic typhus, including Sir Robert Bell, Lord Chief Baron of the Exchequer. The outbreak that followed, between 1577 to 1579, killed about 10% of the English population. During the Lent Assize Court held at Taunton (1730) typhus caused the death of the Lord Chief Baron, as well as the High Sheriff, the sergeant, and hundreds of others. During a time when there were 241 capital offences, more prisoners died from 'gaol fever' than were put to death by all the public executioners in the realm. In 1759 an English authority estimated that each year a quarter of the prisoners had died from gaol fever. In London, typhus frequently broke out among the ill-kept prisoners of Newgate Gaol and then moved into the general city population.
Epidemics occurred throughout Europe and occurred during the English Civil War, the Thirty Years' War and the Napoleonic Wars. During Napoleon's retreat from Moscow in 1812, more French soldiers died of typhus than were killed by the Russians. A major epidemic occurred in Ireland between 1816–19, and again in the late 1830s, and yet another major typhus epidemic occurred during the Great Irish Famine between 1846 and 1849. The Irish typhus spread to England, where it was sometimes called "Irish fever" and was noted for its virulence. It killed people of all social classes, since lice were endemic and inescapable, but it hit particularly hard in the lower or "unwashed" social strata. In Canada, the typhus epidemic of 1847 killed more than 20,000 people died from 1847 to 1848, mainly Irish immigrants in fever sheds and other forms of quarantine, who had contracted the disease aboard coffin ships.
In America, a typhus epidemic killed the son of Franklin Pierce in Concord, New Hampshire in 1843 and struck in Philadelphia in 1837. Several epidemics occurred in Baltimore, Memphis and Washington DC between 1865 and 1873. Typhus fever was also a significant killer during the US Civil War, although typhoid fever was the more prevalent cause of US Civil War "camp fever." Typhoid is a completely different disease from typhus.
During World War I typhus caused three million deaths in Russia and more in Poland and Romania. Delousing stations were established for troops on the Western front but the disease ravaged the armies of the Eastern front, with over 150,000 dying in Serbia alone. Fatalities were generally between 10 to 40 percent of those infected, and the disease was a major cause of death for those nursing the sick. Between 1918 and 1922 typhus caused at least 3 million deaths out of 20–30 million cases. In Russia after World War I, during a civil war between the White and Red armies, typhus killed three million, largely civilians. 
During World War II typhus struck the German Army as it invaded Russia in 1941. In 1942 and 1943 typhus hit French North Africa, Egypt and Iran particularly hard. Typhus epidemics killed inmates in the Nazi Germany concentration camps; infamous pictures of typhus victims' mass graves can be seen in footage shot at Bergen-Belsen concentration camp. Thousands of prisoners held in appalling conditions in Nazi concentration camps such Theresienstadt and Bergen-Belsen also died of typhus during World War II, including Anne Frank at the age of 15 and her sister Margot. Even larger epidemics in the post-war chaos of Europe were only averted by the widespread use of the newly discovered DDT to kill the lice on millions of refugees and displaced persons.
Following the development of a vaccine during World War II, epidemics have usually occurred in Eastern Europe, the Middle East and parts of Africa, particularly Ethiopia, where its eradication was the focus of major research efforts by Naval Medical Research Unit Five.
Society and culture.
Biological weapon.
Typhus was one of more than a dozen agents that the United States researched as potential biological weapons before President Richard Nixon suspended all non-defensive aspects of the U.S. biological weapons program in 1969.

</doc>
<doc id="46178" url="https://en.wikipedia.org/wiki?curid=46178" title="SQUID">
SQUID

A SQUID (for superconducting quantum interference device) is a very sensitive magnetometer used to measure extremely subtle magnetic fields, based on superconducting loops containing Josephson junctions.
SQUIDs are sensitive enough to measure fields as low as 5 aT (5×10−18 T) within a few days of averaged measurements. Their noise levels are as low as 3 fT·Hz-½. For comparison, a typical refrigerator magnet produces 0.01 tesla (10−2 T), and some processes in animals produce very small magnetic fields between 10−9 T and 10−6 T. Recently invented SERF atomic magnetometers are potentially more sensitive and do not require cryogenic refrigeration but are orders of magnitude larger in size (~1 cm3) and must be operated in a near-zero magnetic field.
History and design.
There are two main types of SQUID: direct current (DC) and radio frequency (RF). RF SQUIDs can work with only one Josephson junction (superconducting tunnel junction), which might make them cheaper to produce, but are less sensitive.
DC SQUID.
The DC SQUID was invented in 1964 by Robert Jaklevic, John J. Lambe, James Mercereau, and Arnold Silver of Ford Research Labs after Brian David Josephson postulated the Josephson effect in 1962, and the first Josephson junction was made by John Rowell and Philip Anderson at Bell Labs in 1963. It has two Josephson junctions in parallel in a superconducting loop. It is based on the DC Josephson effect. In the absence of any external magnetic field, the input current formula_1 splits into the two branches equally. If a small external magnetic field is applied to the superconducting loop, a screening current, formula_2, begins circulating in the loop that generates a magnetic field canceling the applied external flux. The induced current is in the same direction as formula_1 in one of the branches of the superconducting loop, and is opposite to formula_1 in the other branch; the total current becomes formula_5 in one branch and formula_6 in the other. As soon as the current in either branch exceeds the critical current, formula_7, of the Josephson junction, a voltage appears across the junction.
Now suppose the external flux is further increased until it exceeds formula_8, half the magnetic flux quantum. Since the flux enclosed by the superconducting loop must be an integer number of flux quanta, instead of screening the flux the SQUID now energetically prefers to increase it to formula_9. The screening current now flows in the opposite direction. Thus the screening current changes direction every time the flux increases by half integer multiples of formula_9. Thus the critical current oscillates as a function of the applied flux. If the input current is more than formula_7, then the SQUID always operates in the resistive mode. The voltage in this case is thus a function of the applied magnetic field and the period equal to formula_9. Since the current-voltage characteristics of the DC SQUID is hysteretic, a shunt resistance, formula_13 is connected across the junction to eliminate the hysteresis (in the case of copper oxide based high-temperature superconductors the junction's own intrinsic resistance is usually sufficient). The screening current is the applied flux divided by the self-inductance of the ring. Thus formula_14 can be estimated as the function of formula_15 (flux to voltage converter) as follows:
The discussion in this Section assumed perfect flux quantization in the loop. However, this is only true for big loops with a large self-inductance. According to the relations, given above, this implies also small current and voltage variations. In practice the self-inductance "L" of the loop is not so large. The general case can be evaluated by introducing a parameter
with "i"c the critical current of the SQUID. Usually "λ" is of order one.
RF SQUID.
The RF SQUID was invented in 1965 by Robert Jaklevic, John J. Lambe, Arnold Silver, and James Edward Zimmerman at Ford. It is based on the AC Josephson effect and uses only one Josephson junction. It is less sensitive compared to DC SQUID but is cheaper and easier to manufacture in smaller quantities. Most fundamental measurements in biomagnetism, even of extremely small signals, have been made using RF SQUIDS.
The RF SQUID is inductively coupled to a resonant tank circuit. Depending on the external magnetic field, as the SQUID operates in the resistive mode, the effective inductance of the tank circuit changes, thus changing the resonant frequency of the tank circuit. These frequency measurements can be easily taken, and thus the losses which appear as the voltage across the load resistor in the circuit are a periodic function of the applied magnetic flux with a period of "Φ"0. For a precise mathematical description refer to the original paper by Erné et al.
Materials used.
The traditional superconducting materials for SQUIDs are pure niobium or a lead alloy with 10% gold or indium, as pure lead is unstable when its temperature is repeatedly changed. To maintain superconductivity, the entire device needs to operate within a few degrees of absolute zero, cooled with liquid helium.
In 2006, proof of concept has be shown for CNT-SQUID sensors build with Aluminum (for the loop) and single walled carbon nanotube (CNT). The sensors is few 100 nm size and operates at 1K or below . Such sensors allows to count spins.
"High-temperature" SQUID sensors are more recent; they are made of high-temperature superconductors, particularly YBCO, and are cooled by liquid nitrogen which is cheaper and more easily handled than liquid helium. They are less sensitive than conventional "low temperature" SQUIDs but good enough for many applications.
Uses.
The extreme sensitivity of SQUIDs makes them ideal for studies in biology. Magnetoencephalography (MEG), for example, uses measurements from an array of SQUIDs to make inferences about neural activity inside brains. Because SQUIDs can operate at acquisition rates much higher than the highest temporal frequency of interest in the signals emitted by the brain (kHz), MEG achieves good temporal resolution. Another area where SQUIDs are used is magnetogastrography, which is concerned with recording the weak magnetic fields of the stomach. A novel application of SQUIDs is the magnetic marker monitoring method, which is used to trace the path of orally applied drugs. In the clinical environment SQUIDs are used in cardiology for magnetic field imaging (MFI), which detects the magnetic field of the heart for diagnosis and risk stratification.
Probably the most common commercial use of SQUIDs is in magnetic property measurement systems (MPMS). These are turn-key systems, made by several manufacturers, that measure the magnetic properties of a material sample. This is typically done over a temperature range from that of 300 mK to roughly 400 K. With the decreasing size of SQUID sensors since the last decade, such sensor can equip the tip of an AFM probe. Such device allows simultaneous measurement of roughness of the surface of a sample and the local magnetic flux.
For example, SQUIDs are being used as detectors to perform magnetic resonance imaging (MRI). While high-field MRI uses precession fields of one to several teslas, SQUID-detected MRI uses measurement fields that lie in the microtesla range. In a conventional MRI system, the signal scales as the square of the measurement frequency (and hence precession field): one power of frequency comes from the thermal polarization of the spins at ambient temperature, while the second power of field comes from the fact that the induced voltage in the pickup coil is proportional to the frequency of the precessing magnetization. In the case of untuned SQUID detection of prepolarized spins, however, the NMR signal strength is independent of precession field, allowing MRI signal detection in extremely weak fields, of order the Earth's field. SQUID-detected MRI has advantages over high-field MRI systems, such as the low cost required to build such a system, and its compactness. The principle has been demonstrated by imaging human extremities, and its future application may include tumor screening.
Another application is the scanning SQUID microscope, which uses a SQUID immersed in liquid helium as the probe. The use of SQUIDs in oil prospecting, mineral exploration, earthquake prediction and geothermal energy surveying is becoming more widespread as superconductor technology develops; they are also used as precision movement sensors in a variety of scientific applications, such as the detection of gravitational waves.
A SQUID is the sensor in each of the four gyroscopes employed on Gravity Probe B in order to test the limits of the theory of general relativity.
A modified RF SQUID was used to observe the dynamical Casimir effect for the first time.
Proposed uses.
It has also been suggested that they might be implemented in a quantum computer.
A potential military application exists for use in anti-submarine warfare as a magnetic anomaly detector (MAD) fitted to maritime patrol aircraft.

</doc>
<doc id="46182" url="https://en.wikipedia.org/wiki?curid=46182" title="White noise">
White noise

In signal processing, white noise is a random signal with a constant power spectral density. The term is used, with this or similar meanings, in many scientific and technical disciplines, including physics, acoustic engineering, telecommunications, statistical forecasting, and many more. White noise refers to a statistical model for signals and signal sources, rather than to any specific signal.
In discrete time, white noise is a discrete signal whose samples are regarded as a sequence of serially uncorrelated random variables with zero mean and finite variance; a single realization of white noise is a random shock. Depending on the context, one may also require that the samples be independent and have the same probability distribution (in other words i.i.d is a simplest representative of the white noise). In particular, if each sample has a normal distribution with zero mean, the signal is said to be Gaussian white noise.
The samples of a white noise signal may be sequential in time, or arranged along one or more spatial dimensions. In digital image processing, the pixels of a "white noise image" are typically arranged in a rectangular grid, and are assumed to be independent random variables with uniform probability distribution over some interval. The concept can be defined also for signals spread over more complicated domains, such as a sphere or a torus.
An infinite-bandwidth white noise signal is a purely theoretical construction. The bandwidth of white noise is limited in practice by the mechanism of noise generation, by the transmission medium and by finite observation capabilities. Thus, a random signal is considered "white noise" if it is observed to have a flat spectrum over the range of frequencies that is relevant to the context. For an audio signal, for example, the relevant range is the band of audible sound frequencies, between 20 to 20,000 Hz. Such a signal is heard as a hissing sound, resembling the /sh/ sound in "ash". In music and acoustics, the term "white noise" may be used for any signal that has a similar hissing sound.
White noise draws its name from white light, although light that appears white generally does not have a flat spectral power density over the visible band.
The term white noise is sometimes used in the context of phylogenetically based statistical methods to refer to a lack of phylogenetic pattern in comparative data. It is sometimes used in non technical contexts, in the metaphoric sense of "random talk without meaningful contents".
Statistical properties.
Being uncorrelated in time does not restrict the values a signal can take. Any distribution of values is possible (although it must have zero DC component). Even a binary signal which can only take on the values 1 or -1 will be white if the sequence is statistically uncorrelated. Noise having a continuous distribution, such as a normal distribution, can of course be white.
It is often incorrectly assumed that Gaussian noise (i.e., noise with a Gaussian amplitude distribution — see normal distribution) necessarily refers to white noise, yet neither property implies the other. Gaussianity refers to the probability distribution with respect to the value, in this context the probability of the signal falling within any particular range of amplitudes, while the term 'white' refers to the way the signal power is distributed (i.e., independently) over time or among frequencies.
We can therefore find Gaussian white noise, but also Poisson, Cauchy, etc. white noises. Thus, the two words "Gaussian" and "white" are often both specified in mathematical models of systems. Gaussian white noise is a good approximation of many real-world situations and generates mathematically tractable models. These models are used so frequently that the term additive white Gaussian noise has a standard abbreviation: AWGN.
White noise is the generalized mean-square derivative of the Wiener process or Brownian motion.
A generalization to random elements on infinite dimensional spaces, such as random fields, is the white noise measure.
Practical applications.
Music.
White noise is commonly used in the production of electronic music, usually either directly or as an input for a filter to create other types of noise signal. It is used extensively in audio synthesis, typically to recreate percussive instruments such as cymbals or snare drums which have high noise content in their frequency domain.
Electronics engineering.
White noise is also used to obtain the impulse response of an electrical circuit, in particular of amplifiers and other audio equipment. It is not used for testing loudspeakers as its spectrum contains too great an amount of high frequency content. Pink noise, which differs from white noise in that it has equal energy in each octave, is used for testing transducers such as loudspeakers and microphones.
Acoustics.
To set up the equalization for a concert or other performance in a venue, a short burst of white or pink noise is sent through the PA system and monitored from various points in the venue so that the engineer can tell if the acoustics of the building naturally boost or cut any frequencies. The engineer can then adjust the overall equalization to ensure a balanced mix.
Computing.
White noise is used as the basis of some random number generators. For example, Random.org uses a system of atmospheric antennae to generate random digit patterns from white noise.
Tinnitus treatment.
White noise is a common synthetic noise source used for sound masking by a tinnitus masker. White noise machines and other white noise sources are sold as privacy enhancers and sleep aids and to mask tinnitus. Alternatively, the use of an FM radio tuned to unused frequencies ("static") is a simpler and more cost-effective source of white noise. However, white noise generated from a common commercial radio receiver tuned to an unused frequency is extremely vulnerable to being contaminated with spurious signals, such as adjacent radio stations, harmonics from non-adjacent radio stations, electrical equipment in the vicinity of the receiving antenna causing interference, or even atmospheric events such as solar flares and especially lightning.
Work environment.
The effects of white noise upon cognitive function are mixed. Recently, a small study found that white noise background stimulation improves cognitive functioning among secondary students with attention deficit hyperactivity disorder (ADHD), while decreasing performance of non-ADHD students. Other work indicates it is effective in improving the mood and performance of workers by masking background office noise, but decreases cognitive performance in complex card sorting tasks.
Mathematical definitions.
White noise vector.
A random vector (that is, a partially indeterminate process that produces vectors of real numbers) is said to be a white noise vector or white random vector if its components each have a probability distribution with zero mean and finite variance, and are statistically independent: that is, their joint probability distribution must be the product of the distributions of the individual components.
A necessary (but, in general, not sufficient) condition for statistical independence of two variables is that they be statistically uncorrelated; that is, their covariance is zero. Therefore, the covariance matrix "R" of the components of a white noise vector "w" with "n" elements must be an "n" by "n" diagonal matrix, where each diagonal element "R""ii" is the variance of component "w""i"; and the correlation matrix must be the "n" by "n" identity matrix.
In particular, if in addition to being independent every variable in "w" also has a normal distribution with zero mean and the same variance formula_1, "w" is said to be a Gaussian white noise vector. In that case, the joint distribution of "w" is a multivariate normal distribution; the independence between the variables then implies that the distribution has spherical symmetry in "n"-dimensional space. Therefore, any orthogonal transformation of the vector will result in a Gaussian white random vector. In particular, under most types of discrete Fourier transform, such as FFT and Hartley, the transform "W" of "w" will be a Gaussian white noise vector, too; that is, the "n" Fourier coefficients of "w" will be independent Gaussian variables with zero mean and the same variance formula_1.
The power spectrum "P" of a random vector "w" can be defined as the expected value of the squared modulus of each coefficient of its Fourier transform "W", that is, "P""i" = E(|"W""i"|2). Under that definition, a Gaussian white noise vector will have a perfectly flat power spectrum, with "P""i" = formula_1 for all "i".
If "w" is a white random vector, but not a Gaussian one, its Fourier coefficients "W""i" will not be completely independent of each other; although for large "n" and common probability distributions the dependencies are very subtle, and their pairwise correlations can be assumed to be zero.
Often the weaker condition "statistically uncorrelated" is used in the definition of white noise, instead of "statistically independent". However some of the commonly expected properties of white noise (such as flat power spectrum) may not hold for this weaker version. Under this assumption, the stricter version can be referred to explicitly as independent white noise vector. Other authors use strongly white and weakly white instead.
An example of a random vector that is "Gaussian white noise" in the weak but not in the strong sense is "x"=["x"1,"x"2] where "x"1 is a normal random variable with zero mean, and "x"2 is equal to +"x"1 or to −"x"1, with equal probability. These two variables are uncorrelated and individually normally distributed, but they are not jointly normally distributed and are not independent. If "x" is rotated by 45 degrees, its two components will still be uncorrelated, but their distribution will no longer be normal.
In some situations one may relax the definition by allowing each component of a white random vector "w" to have non-zero expected value formula_4. In image processing especially, where samples are typically restricted to positive values, one often takes formula_4 to be one half of the maximum sample value. In that case, the Fourier coefficient "W"0 corresponding to the zero-frequency component (essentially, the average of the "w"_i) will also have a non-zero expected value formula_6; and the power spectrum "P" will be flat only over the non-zero frequencies.
Continuous-time white noise.
In order to define the notion of "white noise" in the theory of continuous-time signals, one must replace the concept of a "random vector" by a continuous-time random signal; that is, a random process that generates a function formula_7 of a real-valued parameter formula_8.
Such a process is said to be white noise in the strongest sense if the value formula_9 for any time formula_8 is a random variable that is statistically independent of its entire history before formula_8. A weaker definition requires independence only between the values formula_12 and formula_13 at every pair of distinct times formula_14 and formula_15. An even weaker definition requires only that such pairs formula_12 and formula_13 be uncorrelated. As in the discrete case, some authors adopt the weaker definition for "white noise", and use the qualifier independent to refer to either of the stronger definitions. Others use weakly white and strongly white to distinguish between them.
However, a precise definition of these concepts is not trivial, because some quantities that are finite sums in the finite discrete case must be replaced by integrals that may not converge. Indeed, the set of all possible instances of a signal formula_7 is no longer a finite-dimensional space formula_19, but an infinite-dimensional function space. Moreover, by any definition a white noise signal formula_7 would have to be essentially discontinuous at every point; therefore even the simplest operations on formula_7, like integration over a finite interval, require advanced mathematical machinery.
Some authors require each value formula_9 to be a real-valued random variable with some finite variance formula_1. Then the covariance formula_24 between the values at two times formula_14 and formula_15 is well-defined: it is zero if the times are distinct, and formula_1 if they are equal. However, by this definition, the integral
over any interval with positive width formula_29 would be zero. This property would render the concept inadequate as a model of physical "white noise" signals.
Therefore, most authors define the signal formula_7 indirectly by specifying non-zero values for the integrals of formula_9 and formula_32 over any interval formula_33, as a function of its width formula_29. In this approach, however, the value of formula_9 at an isolated time cannot be defined as a real-valued random variable. Also the covariance formula_24 becomes infinite when formula_37; and the autocorrelation function formula_38 must be defined as formula_39, where formula_40 is some real constant and formula_41 is Dirac's "function".
In this approach, one usually specifies that the integral formula_42 of formula_9 over an interval formula_44 is a real random variable with normal distribution, zero mean, and variance formula_45; and also that the covariance formula_46 of the integrals formula_42, formula_48 is formula_49, where formula_29 is the width of the intersection formula_51 of the two intervals formula_52. This model is called a Gaussian white noise signal (or process).
Mathematical applications.
Time series analysis and regression.
In statistics and econometrics one often assumes that an observed series of data values is the sum of a series of values generated by a deterministic linear process, depending on certain independent (explanatory) variables, and on a series of random noise values. Then regression analysis is used to infer the parameters of the model process from the observed data, e.g. by ordinary least squares, and to test the null hypothesis that each of the parameters is zero against the alternative hypothesis that it is non-zero. Hypothesis testing typically assumes that the noise values are mutually uncorrelated with zero mean and the same Gaussian probability distribution — in other words, that the noise is white. If there is non-zero correlation between the noise values underlying different observations then the estimated model parameters are still unbiased, but estimates of their uncertainties (such as confidence intervals) will be biased (not accurate on average). This is also true if the noise is heteroskedastic — that is, if it has different variances for different data points.
Alternatively, in the subset of regression analysis known as time series analysis there are often no explanatory variables other than the past values of the variable being modeled (the dependent variable). In this case the noise process is often modeled as a moving average process, in which the current value of the dependent variable depends on current and past values of a sequential white noise process.
Random vector transformations.
These two ideas are crucial in applications such as channel estimation and channel equalization in communications and audio. These concepts are also used in data compression.
In particular, by a suitable linear transformation (a coloring transformation), a white random vector can be used to produce a "non-white" random vector (that is, a list of random variables) whose elements have a prescribed covariance matrix. Conversely, a random vector with known covariance matrix can be transformed into a white random vector by a suitable whitening transformation.
Generation.
White noise may be generated digitally with a digital signal processor, microprocessor, or microcontroller. Generating white noise typically entails feeding an appropriate stream of random numbers to a digital-to-analog converter. The quality of the white noise will depend on the quality of the algorithm used.

</doc>
