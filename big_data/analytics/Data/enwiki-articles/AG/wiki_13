<doc id="40132" url="https://en.wikipedia.org/wiki?curid=40132" title="The Muppet Show">
The Muppet Show

The Muppet Show is a family-oriented comedy-variety television series that was produced by puppeteer Jim Henson and features The Muppets. After two pilot episodes produced in 1974 and 1975 failed to get the attention of network executives in the United States, Lew Grade approached Henson to produce the programme in the United Kingdom for ATV, the (then) ITV franchise in the English Midlands. The show lasted for five series consisting of 120 episodes which were first broadcast in Britain between 5 September 1976 and 15 March 1981 on ATV and syndicated the remaining ITV franchises around the United Kingdom. The programmes were recorded at ATV's Elstree Studios in Borehamwood, England.
The series shows a vaudeville or music hall-style song-and-dance variety show, as well as glimpses behind the scenes of such a show. Kermit the Frog stars as a showrunner who tries to keep control of the antics of the other Muppet characters (and his temper), as well as keep the guest stars happy. The show was known for outrageous physical slapstick, sometimes absurdist comedy, and humorous parodies. Each episode also featured a human guest star. As the show's popularity rose, many celebrities were eager to perform with the Muppets on television and in film.
Many of the puppeteers also worked on "Sesame Street". Muppet performers over the course of the show include Jim Henson, Frank Oz, Jerry Nelson, Richard Hunt, Dave Goelz, Steve Whitmire, Fran Brill, Eren Ozker, Louise Gold, Kathryn Mullen, Karen Prell, Brian Muehl, Bob Payne, and John Lovelady. Jerry Juhl and Jack Burns were two of the show writers. The music was performed by Jack Parnell and his orchestra.
History.
Since 1969, "Sesame Street" had given Jim Henson's Muppet creations exposure; however, Henson began to perceive that he was pigeonholed as a children's entertainer. He sought to create a programme that could be enjoyed by young and old. Two specials ("The Muppets Valentine Show" and "") were produced and aired on ABC that are considered pilots for "The Muppet Show". Neither led to the sale of a prime-time network series. However, the prime-time access rule had just been enacted, which took the 7:30 to 8Â pm ET slot from the networks and turned it over to their affiliates. CBS suggested it would be interested in Henson's proposal as a syndicated series it could purchase for its owned-and-operated stations, to run one night a week in that time slot.
Lew Grade, head of the British commercial station ATV and accustomed to the idea of puppet television considering he underwrote the various 1960s Supermarionation series produced by Gerry Anderson such as "Thunderbirds", offered a deal to Henson that would see his show produced at the ATV studios in Elstree, England. ATV, as part of the ITV network, would broadcast the show to other ITV stations in the United Kingdom, and its distribution arm, ITC Entertainment, would sell the show in the United States and around the world. Henson put aside his misgivings about syndication and accepted.
Opening sequence.
"The Muppet Show Theme" (written by Henson and Sam Pottle in 1976) is the show's theme song. It is the opening and closing theme for every episode of "The Muppet Show", and was performed by The Muppets in a scene of "The Muppets".
Each episode ended with an extended instrumental performance of "The Muppet Show Theme" by the Muppet orchestra before Statler and Waldorf gave the last laugh of the night. Some last laugh sequences featured other Muppets on the balcony. For example, in one episode, the Muppets of "Sesame Street" appeared behind the duo who told them: "How should we know how to get to Sesame Street? We don't even know how to get out of this stupid theater box!"
Every series, the TV version of the song was presented with re-worked lyrics. While the opening sequence evolved visually over the course of the show's five series, the musical composition remained sequentially the same. Throughout the years, the song has become a staple of the franchise.
Setting.
Muppet Theater.
The Muppet Theater is the setting for "The Muppet Show", a grand old vaudeville house that has seen better days. In episode 106, Kermit identifies the name of the theatre as The Benny Vandergast Memorial Theater, although by the time of "It's a Very Merry Muppet Christmas Movie", it is simply called "The Muppet Theater." It is then that the theatre becomes registered as a historical landmark.
According to "The Phantom of the Muppet Theater",
Illustrator Manhar Chauhan
Published 1991
Publisher Smithmark Publishers Inc. / Muppet Press
ISBN 0-8317-6151-2</ref> the theatre was built by a stage actor named John Stone in 1802. At some point a production of "Hamlet" ran in the theatre, with Stone playing the title role. An alternate exterior is also shown in the book.
Locations seen in the Muppet Theater include backstage right (which includes Kermit's desk), the dressing rooms, the attic (featured in four compilation videos released in 1985), the canteen, the prop room, the stage, Statler and Waldorf's Box, the auditorium, reception, the recording studio, the stage door lobby, and the back alley. A replica of the theatre serves as the setting for the Muppet*Vision 3D attraction at Disney's Hollywood Studios and Disney California Adventure.
Scooter's uncle J.P. Grosse owns the theatre, and rents it to the Muppets, as Scooter is only too happy to remind Kermit. In a deleted scene from "It's a Very Merry Muppet Christmas Movie", Kermit reveals that J.P. has died and left the theatre to the Muppets in his will. This would have taken place sometime after 1996, as J.P. can be seen (and referred to as such by the head of the KMUP network) in episode 107 of "Muppets Tonight", the 1990s reworking of "The Muppet Show". The Muppet Theater is shown to be in New York City as Rachel Bitterman plots to tear down the Muppet Theater and build a club. She is thwarted when Pepe the King Prawn manages to get the Muppet Theater to be made into a national landmark.
In the film "The Muppets", a version of the Muppet Theater is seen in Los Angeles and is located next to Muppet Studios. It is the main storyline of the movie that the Muppets reunite to raise money to buy back the Muppet Theater deed from an oil magnate named Tex Richman.
Characters and performers.
Many of the characters who appeared on "The Muppet Show" have appeared in previous and subsequent Muppets productions.
Guest stars.
No guest star ever appeared twice on "The Muppet Show", although John Denver appeared both on the show and in two specials ("" and "John Denver & the Muppets: Rocky Mountain Holiday"), while Dudley Moore reappeared in the special, "The Muppets Go to the Movies". Additionally, several guest stars from the series had cameos in one of the first three Muppet theatrical films. Originally, the producers had to call on their personal contacts to appeal to them to appear, especially considering that doing so meant an overseas trip to Britain to do so. However, the situation changed when the renowned ballet dancer, Rudolph Nureyev, offered to appear; his performance on this unusual TV program produced so much favourable publicity that the series became one of the most sought after for various celebrities to appear in.
Many episodes featured actors, such as Dom DeLuise; some featured veteran performers like Ethel Merman and Rita Moreno; some featured well-known pop singers, including Elton John, Diana Ross, and Leo Sayer. Sayer's show used his hit "The Show Must Go On": he changed the lyrics in the second verse slightly, from "I wish I could tear down the walls of this theatre" to "I wish I could tear down the walls of this Muppet theatre". The last episode, in 1981, featured then-James Bond actor Roger Moore. Mark Hamill was in one episode as both himself and Luke Skywalker, his role in the science fiction film "Star Wars".
One episode featured staff writer, Chris Langham, (who wrote some episodes of this show starting in series Three) guest starring due to Richard Pryor being unable to make the taping of the episode at the last minute.
An early tradition was to present the guest star with a Muppet likeness of themselves as a parting gift at the end of the show, but this only lasted for the first two episodes produced, featuring Connie Stevens and Juliet Prowse. The high cost and effort of creating these unique Muppets, scheduling conflicts, and potential legal issues contributed to the decline of this practice, although Muppet caricatures and parodies would continue to appear.
Episodes.
The first episode opens on a character called Wally, and develops as he types the script on his typewriter. In the second pilot, a new character called Nigel acts as the backstage boss. Statler and Waldorf grumble from a living room while watching the show on television (This setting for Statler and Waldorf would be revisited in the first series of "Muppets Tonight"). In both pilot episodes Kermit the Frog only plays a supporting role.
Kermit the Frog becomes the host for the show from the start of the first series, while former host Nigel gets a part as the orchestra leader. Statler and Waldorf now watch the show from a balcony. Other characters from the pilots, including Dr. Teeth and the Electric Mayhem, Sam the Eagle, The Swedish Chef, George the Janitor, Mildred Huxtetter, Crazy Harry, Brewster, Nigel the Conductor, and Droop continue to make appearances. Characters from previous Jim Henson productions also make appearances, including Rowlf the Dog, Sweetums and Robin the Frog (from "The Frog Prince"), Miss Piggy, Gonzo the Great, and Thog (from "The Great Santa Claus Switch"). New characters include Fozzie Bear, The Muppet Newsman, Scooter, Dr. Bunsen Honeydew, wardrobe lady Hilda, Uncle Deadly, Marvin Suggs and his Muppaphones, Trumpet Girl, and the singing duet of Wayne and Wanda. Recurring sketches include "Veterinarian's Hospital", "At the Dance", "Talking Houses", "Pressing Questions (Panel Discussions)", "Fozzie's Monologue", "Chatting with Guest Star", "Muppet Labs" and "Gonzo's Act".
Several changes were made for the second series. Each week, Scooter would now greet the guest star in his or her dressing room before the opening theme song by announcing the time until curtain call. The opening theme sequence was replaced with one involving the cast in arches. Sketches such as "At the Dance", "Talk Spot", "Panel Discussions", "Talking Houses", and "Fozzie's Monologue" either made fewer appearances or were dropped altogether. Several characters were rebuilt, with noticeable changes in Miss Piggy, Fozzie Bear, and Gonzo the Great. Characters like George the Janitor, Hilda, Mildred, and Wayne and Wanda were dropped from the series. Robin is identified as Kermit's nephew. New sketches include "Pigs in Space" and "An Editorial by Sam the Eagle". New characters include Bunsen Honeydew's assistant Beaker, Link Hogthrob, Dr. Julius Strangepork, Doglion, and Annie Sue. Muppet performers Eren Ozker and John Lovelady departed from "The Muppet Show" after the first series. In early episodes of the second series, female puppeteers were auditioned to replace Ozker. Louise Gold was eventually hired as Ozker's replacement. Jack Burns quit his role as writer after the first series.
All of the characters and sketches from the previous series remained. New characters included dimwitted stagehand Beauregard, boomerang fish-thrower Lew Zealand, cafeteria lady Gladys, Bobby Benson and His Baby Band, and sports commenter Louis Kazagger. New segments included "Muppet Sports" and "Bear on Patrol". Two new puppeteers, Steve Whitmire and Kathryn Mullen joined the troupe of Muppeteers during this series.
Most of the characters and sketches from the previous series remained. Canteen worker Gladys however, was replaced by a new character, Winny. Rizzo the Rat also made his earliest appearances.
The cold open featuring Scooter visiting the guest star's dressing room was replaced by a new opening in which Pops, the doorman, would greet each guest as they entered the theatre. New characters included Pops, Lips, and Gaffer the Cat.
Recurring sketches.
Repeats.
In the UK the series was repeated on the BBC although only shown 45 episodes from 8 February 1986 to 7 October 1987. A number of Sky channels have also repeated the series, including Nickelodeon and the Disney Channel UK from 2005 to 2007.
Reruns of "The Muppet Show" in the USA aired in syndication for many years and eventually turned up on TNT from the channel's sign-on in 1988 to 1992. From 1994 to 1996, reruns aired on Nickelodeon. In 1999, the reruns moved to Odyssey Network (which was co-owned by Henson's company), featuring new introductions by Brian Henson, until Odyssey shut down Henson's half of the channel in 2001; the show has not been seen on American television since.
Outside the US, "The Muppet Show", the MuppeTelevision segments of "The Jim Henson Hour" and "Muppets Tonight" were all put into an umbrella syndication package.
Awards and nominations.
"The Muppet Show" program was nominated for nine BAFTA Awards during its run, winning three. It was nominated for twenty-one Primetime Emmy Awards, winning four, including the 1978 award for Outstanding Comedy-Variety or Music Series. It was presented with a Peabody Award in 1978. Also in 1978, the show received the Television Award of Merit by the Mary Washington Colonial Chapter of the National Society of the Daughters of the American Revolution.
Home video.
Compilation releases.
In 1985, Playhouse Video released a collection of video compilations under the Jim Henson's Muppet Video banner. Ten videos were released, featuring original linking material in addition to clips from the show.
Videos included:
In 1993, Jim Henson Video released two compilations under the "It's the Muppets" banner, "Meet the Muppets" and "More Muppets, Please!" Later, three volumes of "The Very Best of The Muppet Show" were released on VHS and DVD in the UK (volume 3 was a release of full episodes as opposed to compilations). Unlike the Playhouse Video releases, "It's the Muppets" and "The Very Best of The Muppet Show" did not include any original footage or guest star clips, but all compilation collections did include material cut from the original US broadcasts.
Series releases.
In 1994, Jim Henson Video released "The Muppet Show: Monster Laughs with Vincent Price", featuring the episodes with Vincent Price and Alice Cooper. Both episodes were edited. In addition to replacing the first series opening and the ending logos with Zoot, the Vincent Price episode was edited to remove the songs "I'm Looking Through You" and "You've Got a Friend" (the latter of which would be cut again when released on the first series DVD) as well as a sketch with the talking houses, while the Alice Cooper episode removed Robin's performance of "Somewhere Over the Rainbow".
Time-Life began marketing 'best of' volumes of "The Muppet Show" for mail-order in 2001, with six initial volumes with three episodes on each VHS and DVD. Unique to each episode was an introduction by Jim Henson's son, Brian. Nine more volumes were added for 2002, the Muppets' 25th anniversary. The collection was available for retail in 2002 via Sony Pictures Home Entertainment by which time Time-Life had released its tenth volume.
Buena Vista Home Entertainment released the first series on DVD in Region 1 on 9 August 2005. The rights to the episodes and characters used in "The Muppet Show", and subsequent film outings, were bought in February 2004 by the Walt Disney Company.
Several songs were cut from the series 1 DVD release due to music licensing issues. There have also been some cuts in the intro sequence, and backstage scenes leading up to these songs. However, episodes that used Disney music remained unaltered (for example, episode 14 of series 1 used "Never Smile at a Crocodile" from "Peter Pan").
The only uncut release of Season 1 on DVD so far is the German DVD release by Disney's Buena Vista Home Entertainment division from 2010 (which also contains English audio). However, the intro and end credit sequences on this release are in German.
Spin-offs.
The cast of "The Muppet Show" appeared on the Kenny Everett show at lunchtime on Capital Radio in 1976.
"The Muppet Show" characters went on to star in "The Muppet Movie", which was the first film to feature puppets interacting with humans in real-world locations, and later films such as "The Great Muppet Caper", "The Muppets Take Manhattan", "The Muppet Christmas Carol", "Muppet Treasure Island", "Muppets from Space", "It's a Very Merry Muppet Christmas Movie", "The Muppets' Wizard of Oz", "The Muppets", and "Muppets Most Wanted" the last two of which relied heavily on the "The Muppet Show" as a plot basis.
"The Jim Henson Hour" featured many of the same characters, plus new and boldly different content. "The Muppet Show" format was later revived as "Muppets Tonight" in 1996. The first 10 episodes aired on ABC, while the rest aired on The Disney Channel. Today, all three incarnations are syndicated together as a single package.
The Muppets appeared as toddlers in the long-running animated series "Muppet Babies" (the Muppet babies characters were a spin-off from a daydream sequence in "The Muppets Take Manhattan"). Animated versions of the Muppets were also featured on the short-lived series "Little Muppet Monsters".
On 9 December 2001, the MuppetFest celebration including "The Muppet Show Live" was staged at the Hollywood Palace in Hollywood. The special guest stars included Jon Voight, Brooke Shields, Joe Pasquale and Paul Williams. Lionel Richie was scheduled to appear in the show singing "Say You, Say Me" immediately after "Bein' Green," but Richie was unable to attend the show because of illness.
In 2005, the Muppets launched an award-winning web-series titled "". The biweekly web-series created new episodes for 15 months on movies.com and starred Statler and Waldorf, along with many other popular Muppet characters from their theatre box from "The Muppet Show". Each episode featured the duo as they discuss upcoming films, watch movie trailers, and share the week's "balconism".
The Muppets were brought back in 2008 for two half-hour television specials on the Disney Channel called "".
There was also a comic book adaption to "The Muppet Show" that was published in 2009 and was written and drawn by Roger Langridge.
For the "Muppets.com" channel on Disney Xtreme Digital, over 100 new, web-exclusive sketches have been produced as of January 2009, including a muppet performed version of Queen's Bohemian Rhapsody.
In 2006, the first French private TV network TF1, with Walt Disney Television, produced a French version of the show called "Muppets TV" with original Muppets and French guest stars. Low ratings cancelled the program after only a few months.
In the 2011 Children in Need special, Kermit the Frog and Miss Piggy make a brief appearance for the original song "Mah NÃ  Mah NÃ " with various guests and presenters.
On 3 April 2015, ABC confirmed it was developing a "Muppet Show" revival, "The Muppets". On 22 April, "Entertainment Weekly" reported the revival will be a mockumentary-style series that goes deeper into the Muppets' personal lives, and promises a "more adult" show than previous incarnations of the franchise.

</doc>
<doc id="40133" url="https://en.wikipedia.org/wiki?curid=40133" title="Bacillus cereus">
Bacillus cereus

Bacillus cereus is a Gram-positive, rod-shaped, aerobic, motile, beta hemolytic bacterium commonly found in soil and food. Some strains are harmful to humans and cause foodborne illness, while other strains can be beneficial as probiotics for animals. It is the cause of "fried rice syndrome", as the bacteria are classically contracted from fried rice dishes that have been sitting at room temperature for hours (such as at a buffet). "B. cereus" bacteria are facultative anaerobes, and like other members of the genus "Bacillus", can produce protective endospores. Its virulence factors include cereolysin and phospholipase C.
It was from this species that two new enzymes, named AlkC and AlkD, which are involved in DNA repair, were discovered in 2006.
History.
Colonies of "Bacillus cereus" were originally isolated from an agar plate left exposed to the air in a cow shed. 
Ecology.
"B. cereus" competes with other microorganisms such as "Salmonella" and "Campylobacter" in the gut, so its presence reduces the numbers of those microorganisms. In food animals such as chickens, rabbits and pigs, some harmless strains of "B. cereus" are used as a probiotic feed additive to reduce "Salmonella" in the intestines and cecum. This improves the animals' growth as well as food safety for humans who eat their meat.
Some strains of "B. cereus" produce cereins, bacteriocins active against different "B. cereus" strains or other Gram-positive bacteria.
Reproduction.
At , a population of "B. cereus" can double in as little as 20 minutes or as long as 3 hours, depending on the food product.
Pathogenesis.
"B. cereus" is responsible for a minority of foodborne illnesses (2â5%), causing severe nausea, vomiting, and diarrhea. "Bacillus" foodborne illnesses occur due to survival of the bacterial endospores when food is improperly cooked. Cooking temperatures less than or equal to 100Â Â°C (212Â Â°F) allow some "B. cereus" spores to survive. This problem is compounded when food is then improperly refrigerated, allowing the endospores to germinate. Cooked foods not meant for either immediate consumption or rapid cooling and refrigeration should be kept at temperatures below 10Â Â°C or above 50Â Â°C (50Â Â°F and 122Â Â°F). Germination and growth generally occur between 10Â Â°C and 50Â Â°C, though some strains are psychrotrophic. Bacterial growth results in production of enterotoxins, one of which is highly resistant to heat and acids (pH levels between 2 and 11); ingestion leads to two types of illness, diarrheal and emetic (vomiting) syndrome.
The diarrhetic syndromes observed in patients are thought to stem from the three toxins: hemolysin BL (Hbl), nonhemolytic enterotoxin (Nhe) and cytotoxin K (CytK). The "nhe"/"hbl"/"cytK" genes are located on the chromosome of the bacteria. Transcription of these genes is controlled by "PlcR". These genes occur in the taxonomically related "B. thuringiensis" and "B. anthracis", as well. These enterotoxins are all produced in the small intestine of the host, thus thwarting digestion by host endogenous enzymes. The Hbl and Nhe toxins are pore-forming toxins closely related to ClyA of "E. coli". The proteins exhibit a conformation known as "beta-barrel" that can insert into cellular membranes due to a hydrophobic exterior, thus creating pores with hydrophilic interiors. The effect is loss of cellular membrane potential and eventually cell death. CytK is a pore-forming protein more related to other hemolysins.
The timing of the toxin production was previously thought to be possibly responsible for the two different courses of disease, but in fact the emetic syndrome is caused by a toxin, cereulide, found only in emetic strains and is not part of the "standard toolbox" of "B. cereus". Cereulide is a cyclic polypeptide containing three repeats of four amino acids: D-oxy-LeuâD-AlaâL-oxy-ValâL-Val (similar to valinomycin produced by "Streptomyces griseus") produced by nonribosomal peptide synthesis. Cereulide is believed to bind to 5-hydroxytryptamine 3 (5-HT3) serotonin receptors, activating them and leading to increased afferent vagus nerve stimulation. It was shown independently by two research groups to be encoded on multiple plasmids: pCERE01 or pBCE4810. Plasmid pBCE4810 shares homology with the "Bacillus anthracis" virulence plasmid pXO1, which encodes the anthrax toxin. Periodontal isolates of "B. cereus" also possess distinct pXO1-like plasmids. Like most of cyclic peptides containing nonproteogenic amino acids, cereulid is resistant to heat, proteolysis, and acid conditions.
"B. cereus" is also known to cause difficult-to-eradicate chronic skin infections, though less aggressive than necrotizing fasciitis. "B. cereus" can also cause keratitis.
Diagnosis.
In case of foodborne illness, the diagnosis of "B. cereus" can be confirmed by the isolation of more than 105 "B. cereus" organisms per gram from epidemiologically implicated food, but such testing is often not done because the illness is relatively harmless and usually self-limiting.
Prognosis.
Most emetic patients recover within six to 24 hours, but in some cases, the toxin can be fatal. In 2014, 23 neonates receiving total parenteral nutrition contaminated with "B. cereus" developed septicaemia, with three of the infants later dying as a result of infection. 

</doc>
<doc id="40135" url="https://en.wikipedia.org/wiki?curid=40135" title="Lumen gentium">
Lumen gentium

Lumen gentium, the Dogmatic Constitution on the Church, is one of the principal documents of the Second Vatican Council. This dogmatic constitution was promulgated by Pope Paul VI on 21 November 1964, following approval by the assembled bishops by a vote of 2,151 to 5. As is customary with significant Roman Catholic Church documents, it is known by its first words, "Lumen gentium", Latin for "Light of the Nations".
Contents.
"The numbers given correspond to section numbers within the text."
Some Highlights.
Ecclesiology (Chapter I).
In its first chapter titled ""The Mystery of the Church,"" the decree states that âall the just, from Adam and âfrom Abel, the just one, to the last of the elect,â will be gathered together with the Father in the universal Church, â¦ a people made one with the unity of the Father, the Son and the Holy Spirit."(2) âChrist made His brothers, called together from all nations, mystically the components of His own Body.â(7) It goes on to describe "the sole Church of Christ which in the Creed is professed as one, holy, catholic and apostolic, which our Saviour, after His Resurrection, commissioned Peter to shepherd, and him and the other apostles to extend and direct with authority, which He erected for all ages as 'the pillar and mainstay of the truth.' This Church, constituted and organized as a society in the present world, subsists in the Catholic Church, which is governed by the successor of Peter and by the bishops in communion with him, although many elements of sanctification and of truth are found outside its visible confines." (8) Only those who "knowing that the Catholic Church was made necessary by Christ, would refuse to enter or to remain in it, could not be saved."(14)
People of God (Chapter II).
One of the key portions of "Lumen gentium" is its second chapter, with its declaration that the Church is "the People of God":
In the second chapter, the Council teaches that God wills to save people not just as individuals but as a people. For this reason God chose the Israelite people to be his own people and established a covenant with it, as a preparation and figure of the covenant ratified in Christ that constitutes the new People of God, which would be one, not according to the flesh, but in the Spirit and which is called the Church of Christ.(9)
All human beings are called to belong to the Church. Not all are fully incorporated into the Church, but "the Church recognizes that in many ways she is linked with those who, being baptized, are honored with the name of Christian, though they do not profess the faith in its entirety or do not preserve unity of communion with the successor of Peter."(15) In addition, the Church declares the possibility of Salvation for non-Christians and even non-theists:
Collegiality (Chapter III).
The third chapter of the document, which spoke of the bishops as a "college"(22) that, within the Church, succeeds to the place of the "college" or "stable group" of the apostles(19) and is "the subject of supreme and full power over the universal Church, provided we understand this body together with its head, the Roman Pontiff."(22)
Conservative bishops in the Council were fearful that the idea of the College of Bishops would be interpreted as a new conciliarism, a fifteenth-century idea that an ecumenical council was the supreme authority under Christ in the Catholic Church. Of the members of the Council, 322, a minority, but a substantial minority, voted against any mention whatever in the document of a "college" of bishops), and were now proposing 47 amendments to chapter III. Accordingly, a "Preliminary Note of Explanation" (in Latin, Nota explicativa praevia", often referred to as "the Nota praevia") intended to reconcile them with the text was added on 16 November 1964. The Note reaffirmed that the college of bishops exercises its authority only with the assent of the pope, thus safeguarding the primacy and pastoral independence of the pope.
The Note achieved its purpose: on the following day, 17 November, the No votes against chapter III dropped to 46, a number that may have included some who opposed it because they felt the Preliminary Note of Explanation had weakened the concept of collegiality. In the final vote on 18 November only 5 of the over 2200 participants voted against the dogmatic constitution as a whole.
The Note is introduced by the following words: "A preliminary note of explanation is being given to the Council Fathers from higher authority, regarding the Modi bearing on Chapter III of the Schema de Ecclesia; the doctrine set forth in Chapter III ought to be explained and understood in accordance with the meaning and intent of this explanatory note." "Higher authority" refers to the Pope, Paul VI, and "the Schema de Ecclesia" to the draft text for the dogmatic constitution "Lumen gentium". By "the Modi" is meant the proposals for amendments of that draft text which some of the Council participants had presented.
The Note was thus added by papal authority, consistently with the idea that the consent of the Pope, as head of the College of Bishops was necessary, and that he had the "right to make his consent dependent on an interpretation determined in advance".
The Preliminary Note of Explanation did not in fact alter the value of the statement on collegiality in the text of "Lumen gentium": it "strengthened the adherence to the doctrine of the First Vatican Council on the primacy, but it did not subsequently strike out anything from the direct divine origin of the episcopal office and its function, and the responsibility of the College of Bishops for the Universal Church."
Part 4 of the Note reads:
Priesthood of the faithful (Chapter IV).
Though they differ from one another in essence and not only in degree, the common priesthood of the faithful and the ministerial or hierarchical priesthood are nonetheless interrelated: each of them in its own special way is a participation in the one priesthood of Christ. The ministerial priest, by the sacred power he enjoys, teaches and rules the priestly people; acting in the person of Christ, he makes present the eucharistic sacrifice, and offers it to God in the name of all the people. But the faithful, in virtue of their royal priesthood, join in the offering of the Eucharist. They likewise exercise that priesthood in receiving the sacraments, in prayer and thanksgiving, in the witness of a holy life, and by self-denial and active charity.(10)
Universal call to holiness (Chapter V).
This theme was built on in the fifth chapter, which is on "the universal call to holiness":
Mariology (chapter VIII).
The chapter on Mary was the subject of debate. Original plans had called for a separate document about the role of Mary, keeping the document on the Church "ecumenical," in the sense of "non-offensive" to Protestant Christians, who viewed special veneration of Mary with suspicion. However, the Council Fathers insisted, with the support of the Pope, that, as Mary's place is within the Church, treatment of her should appear within the Constitution on the Church.
Vatican Council II was sensitive to the views of other Christians, as the council, at the request of Pope John XXIII, hoped to promote Christian unity, but knew there are different concepts about Mary among other Christians, especially Protestants. The council spoke of Mary as "Mediatrix," as strengthening â not lessening â confidence in Christ as the one essential Mediator. The council, in speaking of Mary, used a biblical approach, with strong emphasis on her pilgrimage of faith. They also drew heavily from the Fathers of the Church, which Christians of all denominations respect.
Pope Paul VI, in a speech to the council fathers, spoke as follows: "This year, the homage of our Council appears much more precious and significant. By the promulgation of today's constitution, which has as its crown and summit a whole chapter dedicated to our Lady, we can rightly affirm that the present session ends as an incomparable hymn of praise in honor of Mary." "It is the first time, in fact, and saying it fills our souls with profound emotion, that an Ecumenical Council has presented such a vast synthesis of the Catholic doctrine regarding the place which the Blessed Mary occupies in the mystery of Christ and of the Church."
Some bishops had advocated a dogma of Mary Mediatrix, Advocate and Co-Redemptrix. However, the Constitution did not mention the controversial notion of Marian co-redemption and instead only included a specific section on the Blessed Virgin Mary. In part, this was due to the rise of Ecumenism and the need to maintain positive relations with Protestants. Also the council did not consider Mary as separate from its treatment of the Church, but discussed the mystery of Mary in the larger mystery of Christ and his Church.
Issues surrounding the document.
Contributors.
Marie Rosaire Gagnebet O.P. (1904-1983) professor of theology at the Pontifical University of St. Thomas Aquinas, "Angelicum" from 1938-1976 and peritus during Vatican II, was influential in the redaction of the "Lumen gentium".
Conservative reaction.
Certain Traditionalist Catholic groups, particularly Sedevacantists, consider "Lumen gentium" to be the demarcation of when the Roman Church fell into heresy, pointing to the use of "subsistit in" rather than "est" as an abdication of the Church's historic (and to them compulsory) identification of itself "alone" as God's church. In an interview with "Frankfurter Allgemeine Zeitung", Cardinal Joseph Ratzinger responded to this criticism as follows:
The concept expressed by 'is' (to be) is far broader than that expressed by 'to subsist'. 'To subsist' is a very precise way of being, that is, to be as a subject, which exists in itself. Thus the Council Fathers meant to say that the being of the Church as such is a broader entity than the Roman Catholic Church, but within the latter it acquires, in an incomparable way, the character of a true and proper subject.

</doc>
<doc id="40137" url="https://en.wikipedia.org/wiki?curid=40137" title="Dei verbum">
Dei verbum

Dei verbum (the incipit of the Second Vatican Council's Dogmatic Constitution on Divine Revelation) was promulgated by Pope Paul VI on November 18, 1965, following approval by the assembled bishops by a vote of 2,344 to 6. It is one of the principal documents of the Second Vatican Council, indeed their very foundation in the view of one of the leading Council Fathers, Bishop Christopher Butler. The phrase "Dei verbum" is Latin for "Word of God" and is taken from the first line of the document, as is customary for titles of major Catholic documents.
Contents of "Dei verbum".
"The numbers given correspond to the chapter numbers and, those in parentheses, to the section numbers within the text."
The full text in English is available through the Holy See's website from which the excerpts below have been taken. The footnotes have been inserted into the text at the appropriate places in small print and indented for the convenience of the present reader.
Another widely used translation is Austin Flannery OP (ed.), "Vatican Council II" (2 volumes).
Concerning sacred Tradition and sacred Scripture.
In Chapter II under the heading "Handing On Divine Revelation" the Constitution states among other points:
Hence there exists a close connection and communication between sacred Tradition and sacred Scripture. For both of them, flowing from the same divine wellspring, in a certain way merge into a unity and tend toward the same end. For Sacred Scripture is the word of God inasmuch as it is consigned to writing under the inspiration of the divine Spirit, while sacred tradition takes the word of God entrusted by Christ the Lord and the Holy Spirit to the Apostles, and hands it on to their successors in its full purity, so that led by the light of the Spirit of truth, they may in proclaiming it preserve this word of God faithfully, explain it, and make it more widely known. Consequently it is not from Sacred Scripture alone that the Church draws her certainty about everything which has been revealed. Therefore both sacred tradition and Sacred Scripture are to be accepted and venerated with the same sense of loyalty and reverence. 
The Word of God is transmitted both through the canonical texts of Sacred Scripture, and through Sacred Tradition, which includes various forms such as liturgy, prayers, and the teachings of the Apostles and their successors. The Church looks to Tradition as a protection against errors that could arise from private interpretation. 
Concerning the inspiration and interpretation of sacred Scripture.
In Chapter III under the heading "Sacred Scripture, Its Inspiration and Divine Interpretation" the Constitution states:
Concerning the New Testament, in particular the Gospel accounts.
In Chapter V under the heading "The New Testament" the Constitution states among other points:
"For the Latin text of sections 18 and 19 and the relevant sections of "Sancta Mater Ecclesia" see Bernard Orchard OSB, "Dei verbum and the Synoptic Gospels", Appendix (1990)."[http://www.catholic.com/thisrock/1996/9605scrp.asp]
Sacred Scripture in the Life of the Church.
"Easy access to Sacred Scripture should be provided for all the Christian faithful." To this end the Church sees to it that suitable and correct translations are made into different languages, especially from the original texts of the sacred books. Frequent reading of the divine Scriptures is encouraged for all the Christian faithful, and prayer should accompany the reading of Sacred Scripture, "so that God and man may talk together". Some are ordained to preach the Word, while others reveal Christ in the way they live and interact in the world. 
Scholarly opinion.
The schema, or draft document, prepared for the first council session (OctoberâDecember 1962) reflected the conservative theology of the Holy Office under Cardinal Ottaviani. Pope John intervened directly to promote instead the preparation of a new draft which was assigned to a mixed commission of conservatives and progressives, and it was this on which the final document was based.
Joseph Ratzinger, later elected pope, identified three overall motifs in "Dei verbum": (1) the new view of the phenomenon of tradition; (2) the theological problem of the application of critical historical methods to the interpretation of Scripture; and (3) the biblical movement that had been growing from the turn of the twentieth century.
Regarding article 1 of the preface of "Dei verbum", Joseph Ratzinger writes, "The brief form of the Preface and the barely concealed illogicalities that it contains betray clearly the confusion from which it has emerged."
Biblical infallibility and inerrancy.
The Catechism states that "the books of Scripture firmly, faithfully, and without error teach that truth which God, for the sake of our salvation, wished to see confided to the Sacred Scriptures."
Nevertheless, the Catechism clearly states that "the Christian faith is not a 'religion of the book.' Christianity is the religion of the 'Word' of God, a word which is 'not a written and mute word, but the Word is incarnate and living'. If the Scriptures are not to remain a dead letter, Christ, the eternal Word of the living God, must, through the Holy Spirit, 'open minds to understand the Scriptures.'"
The Catechism goes on to state that "In Sacred Scripture, God speaks to man in a human way. To interpret Scripture correctly, the reader must be attentive to what the human authors truly wanted to affirm, and to what God wanted to reveal to us by their words." 
"But since Sacred Scripture is inspired, there is another and no less important principle of correct interpretation, without which Scripture would remain a dead letter. 'Sacred Scripture must be read and interpreted in the light of the same Spirit by whom it was written.'"
There was a controversy during the Council on whether the Roman Catholic Church taught biblical infallibility or biblical inerrancy. Some have interpreted "Dei verbum" as teaching the infallibility position, while others note that the conciliar document often quotes previous documents such as "Providentissimus Deus" and "Divino afflante Spiritu" that clearly teach inerrancy.
"Dei verbum" has sometimes been compared to the Chicago Statement on Biblical Inerrancy, which expounds similar teachings, characteristic of many evangelical Protestants.

</doc>
<doc id="40138" url="https://en.wikipedia.org/wiki?curid=40138" title="Bacterial growth">
Bacterial growth

Bacterial growth is the asexual reproduction, or cell division, of a bacterium into two daughter cells, in a process called binary fission. Providing no mutational event occurs the resulting daughter cells are genetically identical to the original cell. Hence, "local doubling" of the bacterial population occurs. Both daughter cells from the division do not necessarily survive. However, if the number surviving exceeds unity on average, the bacterial population undergoes exponential growth. The measurement of an exponential bacterial growth curve in batch culture was traditionally a part of the training of all microbiologists; the basic means requires bacterial enumeration (cell counting) by direct and individual (microscopic, flow cytometry), direct and bulk (biomass), indirect and individual (colony counting), or indirect and bulk (most probable number, turbidity, nutrient uptake) methods. Models reconcile theory with the measurements.
Phases.
In autecological studies, the growth of bacteria (or other microorganisms, as protozoa, microalgae or yeasts) in batch culture can be modeled with four different phases: lag phase (A), log phase or exponential phase (B), stationary phase (C), and death phase (D).
This basic batch culture growth model draws out and emphasizes aspects of bacterial growth which may differ from the growth of macrofauna. It emphasizes clonality, asexual binary division, the short development time relative to replication itself, the seemingly low death rate, the need to move from a dormant state to a reproductive state or to condition the media, and finally, the tendency of lab adapted strains to exhaust their nutrients. In reality, even in batch culture, the four phases are not well defined. The cells do not reproduce in synchrony without explicit and continual prompting (as in experiments with stalked bacteria ) and their exponential phase growth is often not ever a constant rate, but instead a slowly decaying rate, a constant stochastic response to pressures both to reproduce and to go dormant in the face of declining nutrient concentrations and increasing waste concentrations.
Batch culture is the most common laboratory growth method in which bacterial growth is studied, but it is only one of many. It is ideally spatially unstructured and temporally structured. The bacterial culture is incubated in a closed vessel with a single batch of medium. In some experimental regimes, some of the bacterial culture is periodically removed and added to fresh sterile medium. In the extreme case, this leads to the continual renewal of the nutrients. This is a chemostat, also known as continuous culture. It is ideally spatially unstructured and temporally unstructured, in a steady state defined by the rates of nutrient supply and bacterial growth. In comparison to batch culture, bacteria are maintained in exponential growth phase, and the growth rate of the bacteria is known. Related devices include turbidostats and auxostats.
Bacterial growth can be suppressed with bacteriostats, without necessarily killing the bacteria. In a synecological, true-to-nature situation in which more than one bacterial species is present, the growth of microbes is more dynamic and continual.
Liquid is not the only laboratory environment for bacterial growth. Spatially structured environments such as biofilms or agar surfaces present additional complex growth models.
External links.
"This article includes material from an article posted on 26 April 2003 on Nupedia; written by Nagina Parmar; reviewed and approved by the Biology group; editor, Gaytha Langlois; lead reviewer, Gaytha Langlois ; lead copyeditors, Ruth Ifcher. and Jan Hogle."

</doc>
<doc id="40139" url="https://en.wikipedia.org/wiki?curid=40139" title="Bdellovibrio">
Bdellovibrio

Bdellovibrio is a genus of Gram-negative, obligate aerobic bacteria. One of the more notable characteristics of this genus is that members parasitize other Gram-negative bacteria by entering into their periplasmic space and feeding on the biopolymers, e.g. proteins and nucleic acids, of their hosts. After entering the periplasmic space of its host the "Bdellovibrio" bacterium forms a structure called a bdelloplast, which modifies both predator's and prey's cells. The predator cell can remain dormant at this stage, without affecting the viability of the host. In most cases, though, "Bdellovibrio" devours its prey and moves on. Because of this, "Bdellovibrio" can be considered bacterial predators, in addition to parasites.
"Bdellovibrio bacteriovorus" was first described by Stolp and Petzold in 1962. Two other species, "Bdellovibrio starrii" and "Bdellovibrio stolpii", have been moved to a separate genus "Bacteriovorax".
Appearance.
Under the microscope, a "Bdellovibrio" appears as a comma-shaped motile rod that is about 0.3â0.5 by 0.5â1.4 Âµm in size with a barely discernible flagellum. Colonies of "Bdellovibrio" show up as a growing clear plaque in an "E. coli" lawn. 
Another notable feature of "Bdellovibrio" is the sheath that covers its flagellum. This is a rare characteristic among bacteria. Flagellar motility stops after"Bdellovibrio" penetrates its prey. In some cases the flagella is shed; in others it protrudes from the outer membrane of the prey cell.
Culture conditions.
"Bdellovibrio" species are found in river water or soil and live an intraperiplasmic existence. "Bdellovibrio" is grown in the laboratory with nutrient broth diluted 1:500 (also known as NB/500) and mixed with hot soft agar. Cultures are grown with a population of "E. coli" at 30 Â°C for one week. "Bdellovibrio" may also be cultured using YPSC(yeast extract, peptone, sodium acetate, calcium chloride) overlays or prey lysates.
Life cycle and parasitism.
"Bdellovibrio" cells can swim as fast as 160Â Âµm/s, or over 100 times their length per second. It swims using a single sheathed polar flagellum with a characteristic dampened filament waveform. "Bdellovibrio" attacks other gram-negative bacteria by attaching itself to the prey cell's outer membrane and peptidoglycan layer, after which it creates a small hole in the outer membrane. The "Bdellovibrio" cell then enters the host periplasmic space. It remains reversibly attached to it for a short "recognition" period. After the recognition period, it becomes irreversibly attached via the pole opposite the flagellum. Once inside the periplasm, the "Bdellovibrio" cell seals the membrane hole and converts the host cell to a spheroblast. A mixture of hydrolytic enzymes is applied in a locally targeted manner that prevents excessive damage to the prey and counters diffusion. This two-cell complex is now called a bdelloplast. The "Bdellovibrio" cell uses hydrolytic enzymes to break down the host cell molecules, which it uses to elongate and form a filament. When the host cell nutrients are exhausted, the filament septates to form progeny "Bdellovibrios". The progeny become motile before they lyse the host cell and are released into the environment. The entire life cycle takes from one to three hours, and produces an average of 3â6 progeny cells from a single "E. coli", or up to 90 from larger prey such as filamentous "E. coli".
Targets of "Bdellovibrio" species, including "Vibrio vulnificus", may undergo coinfection by "Bdellovibrio" and bacteriophage.
Genomics.
The genome of "Bdellovibrio bacteriovorus" HD100 was sequenced in 2006. The HD100 genome is nucleotides long, larger than expected given its small size.

</doc>
<doc id="40142" url="https://en.wikipedia.org/wiki?curid=40142" title="Botulism">
Botulism

Botulism (Latin, "botulus", a sausage) is a rare and potentially fatal illness caused by a toxin produced by the bacterium "Clostridium botulinum". --> The disease begins with weakness, trouble seeing, feeling tired, and trouble speaking. --> This may then be followed by weakness of the arms, chest muscles, and legs. --> The disease does not usually affect consciousness or cause a fever.
Botulism can occur in a few different ways. The bacterial spores that cause it are common in both soil and water. --> They produce the botulinum toxin when exposed to low oxygen levels and certain temperatures. --> Foodborne botulism happens when food containing the toxin is eaten. --> Infant botulism happens when the bacteria develops in the intestines and releases the toxin. --> This typically only occurs in children less than six months old, as protective mechanisms develop after that time. --> Wound botulism is found most often among those who inject street drugs. --> In this situation spores enter a wound and, in the absence of oxygen, release the toxin. --> It is not passed directly between people. --> The diagnosis is confirmed by finding the toxin or bacteria in the person in question.
Prevention is primarily by proper food preparation. --> The toxin, though not the organism, is destroyed by heating it to more than for longer than 5Â minutes. --> Honey can contain the organism, and for this reason honey should not be fed to children under 12 months. --> Treatment is with an antitoxin. --> In those who lose their ability to breathe on their own, mechanical ventilation, potentially for months, may be required. --> Antibiotics may be used for wound botulism. --> Death occurs in 5 to 10% of people. --> Botulism can affect many other animals.
Signs and symptoms.
The muscle weakness of botulism characteristically starts in the muscles supplied by the cranial nerves. A group of twelve nerves controls eye movements, the facial muscles and the muscles controlling chewing and swallowing. Double vision, drooping of both eyelids, loss of facial expression and swallowing problems may therefore occur. In addition to affecting the voluntary muscles, it can also cause disruptions in the autonomic nervous system. This is experienced as a dry mouth and throat (due to decreased production of saliva), postural hypotension (decreased blood pressure on standing, with resultant lightheadedness and risk of blackouts), and eventually constipation (due to decreased peristalsis). Some of the toxins (B and E) also precipitate nausea, vomiting, and difficulty with talking. The weakness then spreads to the arms (starting in the shoulders and proceeding to the forearms) and legs (again from the thighs down to the feet).
Severe botulism leads to reduced movement of the muscles of respiration, and hence problems with gas exchange. This may be experienced as dyspnea (difficulty breathing), but when severe can lead to respiratory failure, due to the buildup of unexhaled carbon dioxide and its resultant depressant effect on the brain. This may lead to coma and eventually death if untreated.
Clinicians frequently think of the symptoms of botulism in terms of a classic triad: bulbar palsy and descending paralysis, lack of fever, and clear senses and mental status ("clear sensorium").
Infant botulism.
Infant botulism (also referred to as floppy baby syndrome) was first recognized in 1976, and is the most common form of botulism in the United States. There were 17 diagnosed cases of infant botulism in the United States in 2013. Infants are susceptible to infant botulism in the first year of life, with more than 90% of cases occurring in infants younger than six months. Infant botulism results from the ingestion of the "C. botulinum" spores, and subsequent colonization of the small intestine. The infant gut may be colonized when the composition of the intestinal microflora (normal flora) is insufficient to competitively inhibit the growth of "C. botulinum" and levels of bile acids (which normally inhibit clostridial growth) are lower than later in life.
The growth of the spores releases botulinum toxin, which is then absorbed into the bloodstream and taken throughout the body, causing paralysis by blocking the release of acetylcholine at the neuromuscular junction. Typical symptoms of infant botulism include constipation, lethargy, weakness, difficulty feeding and an altered cry, often progressing to a complete descending flaccid paralysis. Although constipation is usually the first symptom of infant botulism, it is commonly overlooked.
Honey is a known dietary reservoir of "C. botulinum" spores and has been linked to infant botulism. For this reason honey is not recommended for infants less than one year of age. Most cases of infant botulism, however, are thought to be caused by acquiring the spores from the natural environment. "Clostridium botulinum" is a ubiquitous soil-dwelling bacterium. Many infant botulism patients have been demonstrated to live near a construction site or an area of soil disturbance.
Infant botulism has been reported in 49 of 50 US states, and cases have been recognized in 26 countries on five continents.
Complications.
Infant botulism has no long-term side effects, but can be complicated by hospital-acquired infections. The case fatality rate is less than 1% for hospitalized infants with botulism.
Botulism can result in death due to respiratory failure. However, in the past 50 years, the proportion of patients with botulism who die has fallen from about 50% to 7% due to improved supportive care. A patient with severe botulism may require mechanical ventilation (breathing support through a ventilator) as well as intensive medical and nursing care, sometimes for several months. The respiratory failure and paralysis that occur with severe botulism may require a person to be on a breathing machine (ventilator) for weeks or months. The person may require rehabilitation therapy after leaving the hospital.
Cause.
"Clostridium botulinum" is an anaerobic, Gram positive, spore-forming rod. Botulinum toxin is one of the most powerful known toxins: about one microgram is lethal to humans when inhaled. It acts by blocking nerve function (neuromuscular blockade) through inhibition of the excitatory neurotransmitter acetylcholine's release from the presynaptic membrane of neuromuscular junctions in the somatic nervous system. This causes paralysis. Advanced botulism can cause respiratory failure by paralysing the muscles of the chest; this can progress to respiratory arrest.
In all cases, illness is caused by the botulinum toxin produced by the bacterium "C. botulinum" in anaerobic conditions and not by the bacterium itself. The pattern of damage occurs because the toxin affects nerves that fire (depolarise) at a higher frequency first.
Mechanisms of entry into the human body for botulinum toxin are described below.
Colonization of the gut.
The most common form in Western countries is infant botulism. This occurs in infants who are colonized with the bacterium in the small intestine during the early stages of their lives. The bacterium then produces the toxin, which is absorbed into the bloodstream. The consumption of honey during the first year of life has been identified as a risk factor for infant botulism; it is a factor in a fifth of all cases. The adult form of infant botulism is termed "adult intestinal toxemia", and is exceedingly rare.
Food.
Toxin that is produced by the bacterium within containers of food that have been improperly preserved is the most common cause of food-borne botulism. Fish that has been pickled without the salinity or acidity of brine that contains acetic acid and high sodium levels, as well as smoked fish stored at too high a temperature, presents a risk, as does improperly canned food.
Foodborne botulism results from contaminated food in which "C. botulinum" spores have been allowed to germinate in low-oxygen conditions. This typically occurs in home-canned food substances and fermented uncooked dishes. Given that multiple people often consume food from the same source, it is common for more than a single person to be affected simultaneously. Symptoms usually appear 12â36 hours after eating, but can also appear within 2 hours to 10 days.
Wound.
Wound botulism results from the contamination of a wound with the bacteria, which then secrete the toxin into the bloodstream. This has become more common in intravenous drug users since the 1990s, especially people using black tar heroin and those injecting heroin into the skin rather than the veins. Wound botulism accounts for 29% of cases. 
Inhalation.
Isolated cases of botulism have been described after inhalation by laboratory workers.
Injection.
Botulism has occurred after cosmetic use of inappropriate strengths of Botox.
Mechanism.
The toxin is the protein botulinum toxin produced under anaerobic conditions (where there is no oxygen) by the bacterium "Clostridium botulinum".
"Clostridium botulinum" is a large anaerobic Gram-positive bacillus that forms subterminal endospores.
There are eight serological varieties of the bacterium denoted by the letters A to H. The toxin from all of these acts in the same way and produces similar symptoms: the motor nerve endings are prevented from releasing acetylcholine, causing flaccid paralysis and symptoms of blurred vision, ptosis, nausea, vomiting, diarrhea and/or constipation, cramps, and respiratory difficulty.
Botulinum toxin is broken into 8 neurotoxins (labeled as types A, B, C C2, D, E, F, and G), which are antigenically and serologically distinct but structurally similar. Human botulism is caused mainly by types A, B, E, and (rarely) F. Types C and D cause toxicity only in other animals.
In October 2013, scientists released news of the discovery of type H, the first new botulism neurotoxin found in forty years. However, further information about type H has not been disclosed because of its potential for abuse as a lethal bioweapon and lack of a known antitoxin.
Some types produce a characteristic putrefactive smell and digest meat (types A and some of B and F); these are said to be proteolytic; type E and some types of B, C, D and F are nonproteolytic and can go undetected because there is no strong odor associated with them.
When the bacteria are under stress, they develop spores, which are inert. Their natural habitats are in the soil, in the silt that comprises the bottom sediment of streams, lakes and coastal waters and ocean, while some types are natural inhabitants of the intestinal tracts of mammals (e.g., horses, cattle, humans), and are present in their excreta. The spores can survive in their inert form for many years.
Toxin is produced by the bacteria when environmental conditions are favourable for the spores to replicate and grow, but the gene that encodes for the toxin protein is actually carried by a virus or phage that infects the bacteria. Unfortunately, little is known about the natural factors that control phage infection and replication within the bacteria.
The spores require warm temperatures, a protein source, an anaerobic environment, and moisture in order to become active and produce toxin. In the wild, decomposing vegetation and invertebrates combined with warm temperatures can provide ideal conditions for the botulism bacteria to activate and produce toxin that may affect feeding birds and other animals. Spores are not killed by boiling, but botulism is uncommon because special, rarely obtained conditions are necessary for botulinum toxin production from C. botulinum spores, including an anaerobic, low-salt, low-acid, low-sugar environment at ambient temperatures.
Botulinum inhibits the release within the nervous system of acetylcholine, the chemical that produces a bridge across synapses, where nerve cell axons and dendrites connect with each other. All forms of botulism lead to paralysis that typically starts with the muscles of the face and then spreads towards the limbs. In severe forms, botulism leads to paralysis of the breathing muscles and causes respiratory failure. In light of this life-threatening complication, all suspected cases of botulism are treated as medical emergencies, and public health officials are usually involved to identify the source and take steps to prevent further cases from occurring.
Diagnosis.
For infant botulism, diagnosis should be made on clinical grounds. Confirmation of the diagnosis is made by testing of a stool or enema specimen with the mouse bioassay.
Physicians may consider diagnosing botulism if the patient's history and physical examination suggest botulism. However, these clues are often not enough to allow a diagnosis. Other diseases such as Guillain-BarrÃ© syndrome, stroke, and myasthenia gravis can appear similar to botulism, and special tests may be needed to exclude these other conditions. These tests may include a brain scan, cerebrospinal fluid examination, nerve conduction test (electromyography, or EMG), and an edrophonium chloride (Tensilon) test for myasthenia gravis. A definite diagnosis can be made if botulinum toxin is identified in the food, stomach or intestinal contents, vomit or feces. The toxin is occasionally found in the blood in peracute cases. Botulinum toxin can be detected by a variety of techniques, including enzyme-linked immunosorbent assays (ELISAs), electrochemiluminescent (ECL) tests and mouse inoculation or feeding trials. The toxins can be typed with neutralization tests in mice. In toxicoinfectious botulism, the organism can be cultured from tissues. On egg yolk medium, toxin-producing colonies usually display surface iridescence that extends beyond the colony.
Prevention.
Although the botulinum toxin is destroyed by thorough cooking over the course of a few minutes, the spore itself is not killed by the temperatures reached with normal sea-level-pressure boiling, leaving it free to grow and again produce the toxin when conditions are right.
A recommended prevention measure for infant botulism is to avoid giving honey to infants less than 12 months of age, as botulinum spores are often present. In older children and adults the normal intestinal bacteria suppress development of "C. botulinum".
While commercially canned goods are required to undergo a "botulinum cook" in a pressure cooker at for 3 minutes, and so rarely cause botulism, there have been notable exceptions such as the 1978 Alaskan salmon outbreak and the 2007 Castleberry's Food Company outbreak. Foodborne botulism is the rarest form though, accounting for only around 15% of cases (US) and has more frequently been from home-canned foods with low acid content, such as carrot juice, asparagus, green beans, beets, and corn. However, outbreaks of botulism have resulted from more unusual sources. In July 2002, fourteen Alaskans ate "muktuk" (whale meat) from a beached whale, and eight of them developed symptoms of botulism, two of them requiring mechanical ventilation.
Other, but much rarer sources of infection (about every decade in the US) include garlic or herbs stored covered in oil without acidification, chili peppers, improperly handled baked potatoes wrapped in aluminum foil, tomatoes, and home-canned or fermented fish.
When canning or preserving food at home, attention should be paid to hygiene, pressure, temperature, refrigeration and storage. When making home preserves, only acidic fruit such as apples, pears, stone fruits and berries should be bottled. Tropical fruit and tomatoes are low in acidity and must have some acidity added before they are bottled.
Oils infused with fresh garlic or herbs should be acidified and refrigerated. Potatoes which have been baked while wrapped in aluminum foil should be kept hot until served or refrigerated. Because the botulism toxin is destroyed by high temperatures, home-canned foods are best boiled for 10 minutes before eating. Metal cans containing food in which bacteria, possibly botulinum, are growing may bulge outwards due to gas production from bacterial growth; such cans should be discarded.
Any container of food which has been heat-treated and then assumed to be airtight which shows signs of not being so, e.g., metal cans with pinprick holes from rust or mechanical damage, should also be discarded. Contamination of a canned food solely with "C. botulinum" may not cause any visual defects (e.g. bulging). Only sufficient thermal processing during production should be used as a food safety control.
Vaccine.
There is a vaccine but its usefulness is unclear as it is associated with significant adverse effects. As of 2013 there are efforts ongoing to develop a better vaccine.
Treatment.
Botulism is generally treated with botulism antitoxin and supportive care.
Supportive care for botulism includes monitoring of respiratory function. Respiratory failure due to paralysis may require mechanical ventilation for 2 to 8 weeks, plus intensive medical and nursing care. After this time, paralysis generally improves as new neuromuscular connections are formed.
In some cases, physicians may try to remove contaminated food still in the digestive tract by inducing vomiting and/or using enemas. Wounds should be treated, usually surgically, to remove the source of the toxin-producing bacteria.
Antitoxin.
In adults, botulism can be treated by passive immunization with a horse-derived antitoxin, which blocks the action of the toxin circulating in the blood. A trivalent antitoxin containing antibodies raised against botulinum toxin types A, B, and E is used most commonly, however a heptavalent botulism antitoxin has also been developed and was approved by the U.S. FDA in 2013. In infants, horse-derived antitoxin is sometimes avoided for fear of infants developing serum sickness or lasting hypersensitivity to horse-derived proteins. To avoid this, a human-derived antitoxin has been developed and approved by the U.S. FDA in 2003 for the treatment of infant botulism. This human-derived antitoxin has been shown to be both safe and effective for the treatment of infant botulism. However, the danger of equine-derived antitoxin to infants has not been clearly established, and one study showed the equine-derived antitoxin to be both safe and effective for the treatment of infant botulism.
Trivalent (A,B,E) botulinum antitoxin is derived from equine sources utilizing whole antibodies (Fab and Fc portions). In the United States, this antitoxin is available from the local health department via the CDC. The second antitoxin, heptavalent (A,B,C,D,E,F,G) botulinum antitoxin, is derived from "despeciated" equine IgG antibodies which have had the Fc portion cleaved off leaving the F(ab')2 portions. This less immunogenic antitoxin is effective against all known strains of botulism where not contraindicated.
Prognosis.
The paralysis caused by botulism can persist for 2 to 8 weeks, during which supportive care and ventilation may be necessary to keep the patient alive. Botulism is fatal in 5 to 10% of people who are affected. However, if left untreated, botulism is fatal in 40 to 50% of cases.
The mortality rate for wound botulism is about 10%. 
Infant botulism has no long-term side effects but can be complicated by nosocomial adverse events. The case fatality rate is less than 1% for hospitalized infants with botulism. In part because the vast majority of infants with botulism are hospitalized, the overall infant botulism mortality rate is about 1.3%.
Epidemiology.
Globally, botulism is fairly rare. In the United States, for example, an average of 145 cases are reported each year. Of these, roughly 65% are infant botulism, 20% are wound botulism, and 15% are foodborne. Infant botulism is predominantly sporadic and not associated with epidemics, but great geographic variability exists. From 1974 to 1996, for example, 47.2% of all infant botulism cases reported in the U.S. occurred in California.
Between 1990 and 2000, the Centers for Disease Control and Prevention reported 263 individual foodborne cases from 160 botulism events in the United States with a case-fatality rate of 4%. Thirty-nine percent (103 cases and 58 events) occurred in Alaska, all of which were attributable to traditional Alaska aboriginal foods. In the lower 49 states, home-canned food was implicated in 70 (91%) events with canned asparagus being the most numerous cause. Two restaurant-associated outbreaks affected 25 persons. The median number of cases per year was 23 (range 17â43), the median number of events per year was 14 (range 9â24). The highest incidence rates occurred in Alaska, Idaho, Washington, and Oregon. All other states had an incidence rate of 1 case per ten million people or less.
The number of cases of food borne and infant botulism has changed little in recent years, but wound botulism has increased because of the use of black tar heroin, especially in California.
United States.
All data regarding botulism antitoxin releases and laboratory confirmation of cases in the US are recorded annually by the Centers for Disease Control and Prevention and published on their website.
United Kingdom.
The largest recorded outbreak of foodborne botulism in the United Kingdom occurred in June 1989. A total of 27 patients were affected; one patient died. Twenty-five of the patients had eaten one brand of hazelnut yogurt in the week before the onset of symptoms. This yogurt contained hazelnut conserve sweetened with aspartame rather than sugar. Control measures included the cessation of all yogurt production by the implicated producer, the withdrawal of the firm's yogurts from sale, the recall of cans of the hazelnut conserve, and advice to the general public to avoid the consumption of all hazelnut yogurts.
Other species.
Botulism can occur in many vertebrates and invertebrates. Botulism has been reported in rats, mice, chicken, frogs, toads, goldfish, aplysia, squid, crayfish, drosophila, leeches, etc.
Death from botulism is common in waterfowl; an estimated 10,000 to 100,000 birds die of botulism annually. In some large outbreaks, a million or more birds may die. Ducks appear to be affected most often. Botulism also affects commercially raised poultry. In chickens, the mortality rate varies from a few birds to 40% of the flock.
Botulism seems to be relatively uncommon in domestic mammals; however, in some parts of the world, epidemics with up to 65% mortality are seen in cattle. The prognosis is poor in large animals that are recumbent.
In cattle, the symptoms may include drooling, restlessness, uncoordination, urine retention, dysphagia, and sternal recumbency. Laterally recumbent animals are usually very close to death. In sheep, the symptoms may include drooling, a serous nasal discharge, stiffness, and incoordination. Abdominal respiration may be observed and the tail may switch on the side. As the disease progresses, the limbs may become paralyzed and death may occur.
Phosphorus-deficient cattle, especially in southern Africa, are inclined to ingest bones and carrion containing clostridial toxins and consequently suffer "lame sickness" or "lamsiekte".
A recent study has demonstrated an effective vaccine against cattle botulism associated with Clostridium botulinum serotypes C and D.
The clinical signs in horses are similar to cattle. The muscle paralysis is progressive; it usually begins at the hindquarters and gradually moves to the front limbs, neck, and head. Death generally occurs 24 to 72 hours after initial symptoms and results from respiratory paralysis. Some foals are found dead without other clinical signs.
Domestic dogs may develop systemic toxemia after consuming C. botulinum type C exotoxin or spores within bird carcasses or other infected meat but are generally resistant to the more severe effects of Clostridium botulinum type C.
Symptoms include flaccid muscle paralysis; dogs with breathing difficulties will require more intensive care monitoring. Muscle paralysis can lead to death due to cardiac and respiratory arrest.
Pigs are relatively resistant to botulism. Reported symptoms include anorexia, refusal to drink, vomiting, pupillary dilation, and muscle paralysis.
In poultry and wild birds, flaccid paralysis is usually seen in the legs, wings, neck and eyelids. Broiler chickens with the toxicoinfectious form may also have diarrhea with excess urates.

</doc>
<doc id="40145" url="https://en.wikipedia.org/wiki?curid=40145" title="Witenagemot">
Witenagemot

The WitenaÄ¡emot (Old English witena Ä¡emÅt modern English "meeting of wise men"), also known as the Witan (more properly the title of its members) was a political institution in Anglo-Saxon England which operated from before the 7th century until the 11th century. The witenagemots did not represent the political will of all England: before the unification of England in the 10th century, separate witenagemots were convened by the Kings of Essex, Kent, Mercia, Northumbria, Sussex and Wessex. The Witenagemot was an assembly of the ruling class whose primary function was to advise the king and whose membership was composed of the most important noblemen in England, both ecclesiastic and secular. The institution is thought to represent an aristocratic development of the ancient Germanic general assemblies, or folkmoots. In England, by the 7th century, these ancient folkmoots had developed into convocations of the land's most powerful and important people, including ealdormen, thegns, and senior clergy, to discuss matters of both national and local importance.
Terminology.
The terms 'Witan' and 'Witenagemot' are increasingly avoided by modern historians, although few would go as far as Geoffrey Hindley, who described 'witenagemot' as an "essentially Victorian" coinage. "The Blackwell Encyclopaedia of Anglo-Saxon England" prefers 'King's Council', but adds that it was known in Old English as the 'witan'. John Maddicott regarded the word witan with suspicion, even though it is used in sources such as the "Anglo-Saxon Chronicle":
For these reasons, in his study of the origins of the English parliament, he generally preferred the more neutral word 'assembly'. He described 'witena gemot' as a rare eleventh century usage, with only nine pre-Conquest examples, mainly in the crisis of 1051-52. Patrick Wormald was also sceptical, describing 'witena-gemot' as "a word always rare and unattested before 1035".
Constitution and limitations.
Despite historians' best efforts to find in it some permanence of character, the exact nature of the witenagemot remains "essentially vague, fluctuating, and incoherent." Nevertheless, there is much direct evidence of the witan's various activities. Knowledge about who made up the witan and who was present at their meetings is provided mainly by lists of witnesses to charters, or grants of land, which were concocted at the witenagemots. Reference to the witan's "acta" or official decisions are also preserved in law codes.
The first recorded act of a witenagemot was the law code issued by King Ãthelberht of Kent ca. 600, the earliest document which survives in sustained Old English prose; however, the witan was certainly in existence long before this time. Altogether, about 2000 charters and 40 law codes survive which attest to the workings of the various meetings of the witan, of which there are around 300 recorded.
These documents clearly indicate that the witan was composed of the nation's highest echelon of both ecclesiastical and secular officers. Present on the ecclesiastical side were archbishops, bishops, and abbots, and occasionally also abbesses and priests; on the secular side ealdormen (or "eorls" in the latter centuries) and thegns. Members of the royal family were also present, and the king presided over the entire body.
In his investigation into Anglo-Saxon institutions, H. M. Chadwick wrote: I have not thought it necessary to discuss at length the nature of the powers possessed by the council the witenagemot, for .. there can be little hope of arriving at any definite conclusions on this subject. Indeed it seems at least doubtful whether the functions of the council were ever properly defined.
Similarly, in his study of the witenagemots, Felix Liebermann stated that "its functions and power differ .. considerably at various times." Still, he was able to give a relatively detailed description of its constitution:From the time of Ine the Witan was composed of the aristocratic "Ã©lite" created by monarchy. The king, generally indeed advised by the existing nobility, conferred prelatures and ealdormanries, with both of which a seat in the national assembly the witenagemot was legally or practically connected. Members of the royal family, ladies not excepted, were present at many gemots. The king alone raised a man to the position of a gesith, a thane, a provincial or local reeve, a court officer or a royal chaplain, one of which titles seems to have been the indispensable qualification for a vote. .. as no periodicity of the assembly was fixed, the king determined when and where it was to meet, for the most part choosing places under his immediate control; he presided, spoke first, put his questions, proposed his bills, and finally dismissed the witan.
The witan was noted by contemporary sources as having the singular power to "ceosan to cyninge", 'to choose the king' from amongst the (extended) royal family. Nevertheless, at least until the 11th century, royal succession generally followed the "ordinary system of primogeniture." Chadwick interpreted these facts as proof that the so-called election of the king by the witan merely amounted to formal recognition of the deceased king's natural successor. But Liebermann was generally less willing than Chadwick to see the witan's significance as buried under the weight of the royal prerogative:The influence of the king, or at least of kingship, on the constitution of the assembly seems, therefore, to have been immense. But on the other hand he (the king) was elected by the witan .. He could not depose the prelates or ealdormen, who held their office for life, nor indeed the hereditary thanes. .. At any rate, the king had to get on with the highest statesmen appointed by his predecessor, though possibly disliked by him, until death made a post vacant that he could fill with a relation or a favourite, not, however, without having a certain regard to the wishes of the aristocracy.
Liebermann's more subtle position seems to be vindicated by testimony from abbot Ãlfric of Eynsham, the leading homilist of the late 10th century, who wrote:No man can make himself king, but the people has the choice to choose as king whom they please; but after he is consecrated as king, he then has dominion over the people, and they cannot shake his yoke off their necks.
In addition to having a role in the 'election' of English Kings, it is often held that the witenagemots had the power to depose an unpopular king. However, there are only two occasions when this probably happened, in 757 and 774 with the depositions of kings Sigeberht of Wessex and Alhred of Northumbria respectively.
The witan's powers are illustrated by the following event. In the year 1013 King Ãthelred II fled the country from Sweyn Forkbeard, who then had the witan proclaim him king. Within a few weeks, however, Sweyn died and Ãthelred was called back to England by the witan. According to the "Anglo-Saxon Chronicle", the witan would only receive him back under the condition that he promise to rule better than he had. Ãthelred did so, and was reinstated as King of England. His nickname of the 'UnrÃ¦d' or 'Unready' means ill-advised, indicating that contemporaries regarded those who sat in the witan as in part responsible for the failure of his reign.
Though in general the witan were recognized as the king's closest advisors and policy-makers, various witan also operated in other capacities; there are mentions of "Ã¾eodwitan", 'people's witan', "Angolcynnes witan", 'England's witan', and an Anglo-Saxon Archbishop of York, Wulfstan II, wrote that "it is incumbent on bishops, that venerable witan always travel with them, and dwell with them, at least of the priesthood; and that they may consult with them .. and who may be their counsellors at every time." 
Even when summoned explicitly by kings, the witenagemots did not represent the political will of all England: before the unification of England in the 10th century, separate witenagemots were convened by the Kings of Essex, Kent, Mercia, Northumbria, Sussex and Wessex. Indeed, even after Wessex became the dominant power in England, supplanting the other kingdoms, local witans continued to meet until as late as 1067. In his work on Alfred the Great, historian David Sturdy argues that the witan did not embody modern notions of a 'national institution' or a 'democratic' body:Victorian notions of a national 'witan' are crazy dreams without foundation, myths of a 'democratic parliament' that never was.
Function and legacy.
Witans would advise on the administration and organization of the kingdom, dealing with issues such as taxation, jurisprudence and both internal and external security. The witenagemot was in many ways different from the future Parliament, it had substantially different powers and some major limitations, such as a lack of a fixed procedure, schedule, or meeting place. The witan could seek to prevent autocracy and carry on government during interregnums, but ultimately the witenagemot answered to the king. It only assembled when he summoned it, and its assembling without his approval could be considered treason. The witenagemot was more an advisory council. In some cases, weak kings (such as Ethelred the Unready) were dependent on the witenagemot, while others used it as simply a group of advisers.
Though no set date was ever in use, witenagemots met at least once a year, and commonly more often. There was no single seat of a witenagemot, it being held where the king was, who typically had no single fixed court either. Witenagemots are known to have met in at least 116 locations, including Amesbury, Calne, Cheddar, Gloucester, London and Winchester. The meeting places were often on royal estates, but some witenagemots were convened in the open at prominent rocks, hills, meadows and famous trees.
This arrangement ended when the Normans invaded in 1066, replacing the witenagemot with the "curia regis", or king's court. However, in a sign of the witenagemot's enduring legacy, the "curia regis" continued to be dubbed a "witan" by chroniclers until as late as the 12th century.
Origin.
It is generally accepted that the English witenagemot had its origins in ancient Germanic assemblies summoned to witness royal grants of land. Yet whatever their status in the 5th and 4th centuries, the nature of these assemblies in England was irrevocably changed when Christianity was introduced, circa 600. Hereafter, church and state were "inseparably intertwined," and this was reflected in the strong ecclesiastical element in the witan's membership and concerns; records of decisions made by witan encompass ecclesiastical and secular jurisdictions alike.

</doc>
<doc id="40147" url="https://en.wikipedia.org/wiki?curid=40147" title="Divorce">
Divorce

Divorce (or dissolution of marriage) is the termination of a marriage or marital union, the canceling and/or reorganizing of the legal duties and responsibilities of marriage, thus dissolving the bonds of matrimony between a married couple under the rule of law of the particular country and/or state. Divorce laws vary considerably around the world, but in most countries divorce requires the sanction of a court or other authority in a legal process, which may involve issues of alimony (spousal support), child custody, child visitation / access, parenting time, child support, distribution of property, and division of debt. In most countries, monogamy is required by law, so divorce allows each former partner to marry another person; where polygyny is legal but polyandry is not, divorce allows the woman to marry a new husband.
Divorce should not be confused with annulment, which declares the marriage null and void; with legal separation or "de jure" separation (a legal process by which a married couple may formalize a "de facto" separation while remaining legally married) or with "de facto separation" (a process where the spouses informally stop cohabiting). Reasons for divorce vary, from sexual incompatibility or lack of independence for one or both spouses to a personality clash.
The only countries that do not allow divorce are the Philippines and the Vatican City, an ecclesiastical state, which has no procedure for divorce. Countries that have relatively recently legalized divorce are Italy (1970), Portugal (1975), Brazil (1977), Spain (1981), Argentina (1987), Paraguay (1991), Colombia (1991*), Andorra (1995), Ireland (1996), Chile (2004) and Malta (2011).
Overview.
Grounds for divorce vary widely from country to country. Marriage may be seen as a contract, a status, or a combination of these. Where it is seen as a contract, the refusal or inability of one spouse to perform the obligations stipulated in the contract may constitute a ground for divorce for the other spouse. In contrast, in some countries (such as Sweden, Finland, Australia, New Zealand), divorce is purely no fault. Many jurisdictions offer both the option of a "no fault" divorce as well as an "at fault" divorce. This is the case, for example, in many US states (see Grounds for divorce (United States)).
Though divorce laws vary between jurisdictions, there are two basic approaches to divorce: fault based and no-fault based. However, even in some jurisdictions that do not require a party to claim fault of their partner, a court may still take into account the behavior of the parties when dividing property, debts, evaluating custody, shared care arrangements and support. In some jurisdictions one spouse may be forced to pay the attorney's fees of another spouse.
Laws vary as to the waiting period before a divorce is effective. Also, residency requirements vary. However, issues of division of property are typically determined by the law of the jurisdiction in which the property is located.
In Europe, divorce laws differ from country to country, reflecting differing legal and cultural traditions. In some countries, particularly (but not only) in some former communist countries, divorce can be obtained only on one single general ground of "irretrievable breakdown of the marriage" (or a similar formulation). Yet, what constitutes such a "breakdown" of the marriage is interpreted very differently from jurisdiction to jurisdiction, ranging from very liberal interpretations (e.g. Netherlands) to quite restrictive ones (e.g., in Poland, there must be an "irretrievable and complete disintegration of matrimonial life," but there are many restrictions to granting a divorce). Separation constitutes a ground of divorce in some European countries (in Germany, e.g., a divorce is granted on the basis of a 1-year separation if both spouses consent, or 3-year separation if only one spouse consents). Note that "separation" does not necessarily mean separate residences - in some jurisdictions, living in the same household but leading a separate life (e.g., eating, sleeping, socializing, etc. separately) is sufficient to constitute "de facto" separation; this is explicitly stated, e.g., in the family laws of Latvia.
Divorce laws are not static; they often change reflecting evolving social norms of societies. In the 21st century, many European countries have made changes to their divorce laws, in particular by reducing the length of the necessary periods of separation, e.g., Scotland in 2006 (1 or 2 years from the previous 2 or 5 years); France in 2005 (2 years from the previous 6 years), Switzerland in 2005 (2 years from the previous 4 years), Greece in 2008 (2 years from the previous 4 years). Some countries have completely overhauled their divorce laws, such as Spain in 2005, and Portugal in 2008. A new divorce law also came into force in September 2007 in Belgium, creating a new system that is primarily no-fault. Bulgaria also modified its divorce regulations in 2009. In Italy, however, the divorce laws still remain traditionally based, with divorce's being a relatively complicated and lengthy process.
Austria is another European country where the divorce law remains conservative.
The liberalization of divorce laws is not without opposition, particularly in the United States. Indeed, in the US, certain conservative and religious organizations are lobbying for laws which restrict divorce. In 2011, in the US, the Coalition for Divorce Reform was established, describing itself as an organization "dedicated to supporting efforts to reduce unnecessary divorce and promote healthy marriages."
Law.
Types of divorce.
In some jurisdictions, the courts will seldom apply principles of fault, but might willingly hold a party liable for a breach of a fiduciary duty to his or her spouse (for example, see Family Code Sections 720 and 1100 of the California Family Code). Grounds for divorce differs from state to state in the U.S. Some states have no-fault divorce; some states require a declaration of fault on the part of one partner or both; some states allow either method.
In most jurisdictions, a divorce must be certified (or ordered by a Judge) by a court of law to come into effect. The terms of the divorce are usually determined by the courts, though they may take into account prenuptial agreements or post-nuptial agreements, or simply ratify terms that the spouses may have agreed to privately (this is not true in the United States, where agreements related to the marriage typically have to be rendered in writing to be enforceable). In absence of agreement, a contested divorce may be stressful to the spouses.
In some other countries, when the spouses agree to divorce and to the terms of the divorce, it can be certified by a non-judiciary administrative entity. The effect of a divorce is that both parties are free to marry again.
Contested divorce.
Contested divorces mean that one of several issues are required to be heard by a judge at trial levelâthis is more expensive, and the parties will have to pay for a lawyer's time and preparation. In such a divorce the spouses are not able to agree on issues for instance child custody and division of marital assets. In such situations, the litigation process takes longer to conclude. The judge controls the outcome of the case. Less adversarial approaches to divorce settlements have recently emerged, such as mediation and collaborative divorce settlement, which negotiate mutually acceptable resolution to conflicts. This principle in the United States is called 'Alternative Dispute Resolution' and has gained popularity.
At-fault divorce.
Before the late 1960s, nearly all countries that permitted divorce required proof by one party that the other party had committed an act incompatible to the marriage. This was termed "grounds" for divorce (popularly called "fault") and was the only way to terminate a marriage. Most jurisdictions around the world still require such proof of fault. In the United States, no-fault divorce is available in all 50 states, as is the case with Australia, New Zealand, Canada and other Western countries.
Fault-based divorces can be contested; evaluation of offenses may involve allegations of collusion of the parties (working together to get the divorce), or condonation (approving the offense), connivance (tricking someone into committing an offense), or provocation by the other party. Contested fault divorces can be expensive, and not usually practical as eventually most divorces are granted. Comparative rectitude is a doctrine used to determine which spouse is more at fault when both spouses are guilty of breaches.
The grounds for a divorce which a party could raise and need to prove included 'desertion,' 'abandonment,' 'cruelty,' or 'adultery.' The requirement of proving a ground was revised (and withdrawn) by the terms of 'no-fault' statutes, which became popular in many Western countries in the late 1960s and early 1970s. In 'no-fault' jurisdictions divorce can be obtained either on a simple allegation of 'irreconcilable differences,' 'irretrievable break-down', or 'incompatibility' with respect to the marriage relationship, or on the ground of separation.
Summary divorce.
A summary (or simple) divorce, available in some jurisdictions, is used when spouses meet certain eligibility requirements and/or can agree on key issues beforehand.
Key factors:
No-fault divorce.
Some Western jurisdictions have a no-fault divorce system, which requires no allegation or proof of fault of either party. The barest of assertions suffice. For example, in countries that require "irretrievable breakdown", the mere assertion that the marriage has broken down will satisfy the judicial officer. In other jurisdictions requiring irreconcilable differences, the mere allegation that the marriage has been irreparable by these differences is enough for granting a divorce. Courts will not inquire into facts. A "yes" is enough, even if the other party vehemently says "no".
The application can be made by either party or by both parties jointly.
In jurisdictions adopting the 'no-fault' principle regarding whether to "grant" a divorce, some courts may still take into account the fault of the parties when determining some aspects of the "content" of the divorce decree, "e.g.", its terms for the division of property and debts and the existence and, if applicable, the amount of spousal support. Provisions related to child custody are determined using a different fundamental standard, that of the child's or children's best interests; while some behaviors that may constitute marital fault ("e.g.", violence, cruelty, endangerment, neglect, or substance abuse) may also qualify as factors to be considered when determining child custody, they do so for the independent reason that they provide evidence as to what arrangement is in the child's or children's best interests going forward.
Uncontested divorce.
It is estimated that upwards of 95% of divorces in the U.S. are "uncontested", because the two parties are able to come to an agreement (either with or without lawyers/mediators/collaborative counsel) about the property, children, and support issues. When the parties can agree and present the court with a fair and equitable agreement, approval of the divorce is almost guaranteed. If the two parties cannot come to an agreement, they may ask the court to decide how to split property and deal with the custody of their children. Though this may be necessary, the courts would prefer parties come to an agreement prior to entering court.
Where the issues are not complex and the parties are cooperative, a settlement often can be directly negotiated between them. In the majority of cases, forms are acquired from their respective state websites and a filing fee is paid to the state. Most U.S. states charge between $175 and $350 for a simple divorce filing. Collaborative divorce and mediated divorce are considered uncontested divorces.
Because of additional requirements that must be met, most military divorces are typically uncontested.
In the United States, many state court systems are experiencing an increasing proportion of "pro se" ("i.e.," litigants represent themselves without a lawyer) in divorce cases. In San Diego, for example, the number of divorce filings involving at least one self-representing litigant rose from 46% in 1992 to 77% in 2000, and in Florida from 66% in 1999 to 73% in 2001. Urban courts in California report that approximately 80% of the new divorce filings are filed "pro se."
Collaborative divorce.
Collaborative divorce is a method for divorcing couples to come to agreement on divorce issues. In a collaborative divorce, the parties negotiate an agreed resolution with the assistance of attorneys who are trained in the collaborative divorce process and in mediation, and often with the assistance of a neutral financial specialist and/or divorce coach(es). The parties are empowered to make their own decisions based on their own needs and interests, but with complete information and full professional support.
Once the collaborative divorce starts, the lawyers are disqualified from representing the parties in a contested legal proceeding, should the collaborative law process end prematurely. Most attorneys who practice collaborative divorce claim that it can be more cost-effective than other divorce methods, "e.g.," going to court. Expense, they say, has to be looked at under the headings of financial and emotional. Also, the experience of working collaboratively tends to improve communication between the parties, particularly when collaborative coaches are involved, and the possibility of going back to court post-separation or divorce is minimized. In the course of the collaboration, should the parties not reach any agreements, any documents or information exchanged during the collaborative process cannot be used in court except by agreement between the parties.
Neither can any of the professional team retained in the course of the collaboration be brought to court. Essentially, they have the same protections as in mediation. There are two exceptions: 1) Any affidavit sworn in the course of the collaboration and vouching documentation attaching to same and 2) any interim agreement made and signed off in the course of the collaboration or correspondence relating thereto. The parties are in control of the time they are prepared to give their collaboration. Some people need a lot of time to complete, whereas others will reach solutions in a few meetings. Collaborative practitioners offer a tightly orchestrated model with meetings scheduled in advance every two weeks, and the range of items to be discussed apportioned in advance of signing up as well as the more open ended process, the clients decide.
Mediated divorce.
Divorce mediation is an alternative to traditional divorce litigation. In a divorce mediation session, a mediator facilitates the discussion between the two parties by assisting with communication and providing information and suggestions to help resolve differences. At the end of the mediation process, the separating parties have typically developed a tailored divorce agreement that can be submitted to the court. Mediation sessions can include either party's attorneys, a neutral attorney, or an attorney-mediator who can inform both parties of their legal rights, but does not provide advice to either, or can be conducted with the assistance of a facilitative or transformative mediator without attorneys present at all. Some mediation companies, such as Wevorce, also pair clients with counselors, financial planners and other professionals to work through common mediation sticking points. Divorce mediators may be attorneys who have experience in divorce cases, or they may be professional mediators who are not attorneys, but who have training specifically in the area of family court matters. Divorce mediation can be significantly less costly, both financially and emotionally, than litigation. The adherence rate to mediated agreements is much higher than that of adherence to court orders.
Polygamy and divorce.
Polygamy is a significant structural factor governing divorce in countries where this is permitted. Little-to-no analysis has been completed to explicitly explain the link between marital instability and polygamy which leads to divorce. The frequency of divorce rises in polygamous marriages compared to monogamous relationships. Within polygamous unions, differences in conjugal stability are found to occur by wife order. There are 3 main mechanisms through which polygamy affects divorce: economic restraint, sexual satisfaction, and childlessness. Many women escape economic restraint through divorcing their spouses when they are allowed to initiate a divorce.
Causes of divorce.
An annual study in the UK by management consultants Grant Thornton, estimates the main proximal causes of divorce based on surveys of matrimonial lawyers.
The main causes in 2004 were:
According to this survey, husbands engaged in extramarital affairs in 75% of cases; wives in 25%. In cases of family strain, wives' families were the primary source of strain in 78%, compared to 22% of husbands' families. Emotional and physical abuse were more evenly split, with wives affected in 60% and husbands in 40% of cases. In 70% of workaholism-related divorces it was husbands who were the cause, and in 30%, wives. The 2004 survey found that 93% of divorce cases were petitioned by wives, very few of which were contested. 53% of divorces were of marriages that had lasted 10 to 15 years, with 40% ending after 5 to 10 years. The first 5 years are relatively divorce-free, and if a marriage survives more than 20 years it is unlikely to end in divorce.
Social scientists study the causes of divorce in terms of underlying factors that may possibly motivate divorce. One of these factors is the age at which a person gets married; delaying marriage may provide more opportunity or experience in choosing a compatible partner. Wage, income, and sex ratios are other such underlying factors that have been included in analyses by sociologists and economists.
The elevation of divorce rates among couples who cohabited prior to marriage is called the "cohabitation effect." Evidence suggests that although this correlation is partly due to two forms of selection ("a"] that persons whose moral and/or religious codes permit cohabitation are also more likely to consider divorce permitted by morality and/or religion and "b"] that marriage based on low levels of commitment is more common among couples who cohabit than among couples who do not, such that the mean and median levels of commitment at the start of marriage are lower among cohabiting than among non-cohabiting couples), the cohabitation experience itself exerts at least some independent effect on the subsequent marital union.
A 2010 study published in "Journal of Marriage and Family" found that there was a correlation between female pre-maritial promiscuity and higher rates of divorce. The research, conducted by Jay Teachman, found that women with 16 or more sexual partners prior to marriage had an 80% rate of subsequent divorce.
Effects of divorce.
Some of the effects associated with divorce include academic, behavioral, and psychological problems. Although this may not always be true, studies suggest that children from divorced families are more likely to exhibit such behavioral issues than those from non-divorced families.
Divorce and relationships.
Research done at Northern Illinois University on Family and Child Studies suggests that divorce of couples experiencing high conflict can have a positive effect on families by reducing conflict in the home. There are, however, many instances when the parentâchild relationship may suffer due to divorce. Financial support is many times lost when an adult goes through a divorce. The adult may be obligated to obtain additional work to maintain financial stability. In turn, this can lead to a negative relationship between the parent and child; the relationship may suffer due to lack of attention towards the child as well as minimal parental supervision
Studies have also shown that parental skills decrease after a divorce occurs; however, this effect is only a temporary change. "A number of researchers have shown that a disequilibrium, including diminished parenting skills, occurs in the year following the divorce but that by two years after the divorce re-stabilization has occurred and parenting skills have improved"
Some couples choose divorce even when one spouse's desire to remain married is greater than the other spouse's desire to obtain a divorce. In economics this is known as the Zelder Paradox, and is more common with marriages that have produced children, and less common with childless couples.
In an American Psychological Association study of parentsâ relocation after a divorce, researchers found that a move has a long-term effect on children. In the first study conducted amongst 2,000 college students on the effects of parental relocation relating to their children's well-being after divorce, researchers found major differences. In divorced families in which one parent moved, the students received less financial support from their parents compared with divorced families in which neither parent moved. These findings also imply other negative outcomes for these students, such as more distress related to the divorce and did not feel a sense of emotional support from their parents. Although the data suggests negative outcomes for these students whose parents relocate after divorce, there is insufficient research that can alone prove the overall well-being of the child A newer study in the "Journal of Family Psychology" found that parents who move more than an hour away from their children after a divorce are much less well off than those parents who stayed in the same location
Effects of divorce on children.
Psychological.
Divorce is associated with diminished psychological well-being in children and adult offspring of divorced parents, including greater unhappiness, less satisfaction with life, weaker sense of personal control, anxiety, depression, and greater use of mental health services. A preponderance of evidence indicates that there is a causal effect between divorce and these outcomes.
A study in Sweden led by the Centre for Health Equity Studies (Chess) at Stockholm University/Karolinska Institutet, is published in the Journal of Epidemiology & Community Health found that children living with just one parent after divorce suffer from more problems such as headaches, stomach aches, feelings of tension and sadness than those whose parents share custody.
Children of divorced parents are also more likely to experience conflict in their own marriages, and are more likely to experience divorce themselves. They are also more likely to be involved in short-term cohabiting relationships, which often dissolve before marriage. There are many studies that show proof of an intergenerational transmission of divorce, but this doesn't mean that having divorced parents will absolutely lead a child to divorce. There are two key factors that make this transmission of divorce more likely. First, inherited biological tendencies or genetic conditions may predispose a child to divorce as well as the "model of marriage" presented by the child's parents.
According to Nicholas Wall, former President of the Family Division of the English High Court, "People think that post-separation parenting is easyÂ â in fact, it is exceedingly difficult, and as a rule of thumb my experience is that the more intelligent the parent, the more intractable the dispute. There is nothing worse, for most children, than for their parents to denigrate each other. Parents simply do not realize the damage they do to their children by the battles they wage over them. Separating parents rarely behave reasonably, although they always believe that they are doing so, and that the other party is behaving unreasonably."
Although not the intention of most parents, putting children in the middle of conflict is particularly detrimental. Examples of this are asking children to carry messages between parents, grilling children about the other parent's activities, and putting the other parent down in front of the children. High-conflict divorce or custody cases can experience varying forms of Parental Alienation. The Family Courts often consider Parental Alienation as a form of child abuse. Specific examples of Parental Alienation include brainwashing the child to cease their relationship with the other parent, telling the child that the other parent does not love them, teaching the child to call another adult by a parental name in effort to replace the other parent, limiting communication between the child and the other parent, and limiting quality time between the child and the other parent. If evidence reveals that a parent is actively alienating the child from their other parent, their case for custody can be severely damaged.
Poorly managed conflict between parents increases children's risk of behavior problems, depression, substance abuse and dependence, poor social skills, and poor academic performance. Fortunately, there are approaches by which divorce professionals can help parents reduce conflict. Options include mediation, collaborative divorce, coparent counseling, and parenting coordination.
Children begin to be affected 2â4 years before the separation or divorce even occurs. This time period before the separation tends to be more detrimental for the children than the actual divorce or separation. This can be due to parental conflict and anticipation of a divorce, and decreased parental contact. Many couples believe that by separating, or becoming legally divorced that they are helping their children, and in situations of extreme parental conflict of abuse it most likely will be beneficial.
Exposure to marital conflict and instability, most often has negative consequences for children. Several mechanisms are likely to be responsible. First, observing overt conflict between parents is a direct stressor for children. Observational studies reveal that children react to inter-parental conflict with fear, anger, or the inhibition of normal behavior. Preschool childrenÂ â who tend to be egocentricÂ â may blame themselves for marital conflict, resulting in feelings of guilt and lowered self-esteem. Conflict between parents also tends to spill over and negatively affect the quality of parents' interactions with their children. Researchers found that the associations between marital conflict and children's externalizing and internalizing problems were largely mediated by parents' use of harsh punishment and parentâchild conflict. Furthermore, modeling verbal or physical aggression, parents "teach" their children that disagreements are resolved through conflict rather than calm discussion. As a result, children may not learn the social skills (such as the ability to negotiate and reach compromises) that are necessary to form mutually rewarding relationships with peers.
Girls and boys deal with divorce differently, for instance girls who initially show signs of adapting well, later suffer from anxiety in romantic relationships with men. Studies also showed that girls who were separated from their fathers at a younger age tended to be more angry toward the situation as they aged, anger and sadness were also observed at common feeling in adolescents who had experienced parental divorce.
Academic and socioeconomic.
Frequently, children who have experienced a divorce have lower academic achievement than children from non-divorced families
In a review of family and school factors related to adolescentsâ academic performance, it noted that a child from a divorced family is two times more likely to drop out of high school than a child from a non-divorced family. These children from divorced families may also be less likely to attend college, resulting in the discontinuation of their academic career.
Many times academic problems are associated with those children from single-parent families. Studies have shown that this issue may be directly related to the economical influence of divorce. A divorce may result in the parent and children moving to an area with a higher poverty rate and a poor education system all due to the financial struggles of a single parent.
Children of divorced parents also achieve lower levels of socioeconomic status, income, and wealth accumulation than children of continuously married parents. These outcomes are associated with lower educational achievement.
Young men or women between the ages of 7 and 16 who had experienced the divorce of their parents were more likely than youths who had not experienced the divorce of their parents to leave home because of friction, to cohabit before marriage, and to parent a child before marriage.
Divorce often leads to worsened academic achievement in children ages 7â12. The most heightened negative effect being reading test scores. These negative effects tend to persist, and even escalate after the divorce or separation occurs.
Divorce of elderly couples.
Since the mid-1990s, the divorce rate has increased to over 50% among baby boomers. More and more seniors are staying single; an analysis of census data conducted at Bowling Green State University predicted that divorce numbers will continue to rise. Baby boomers that remain unmarried are five times more likely to live in poverty compared to those who are married. They are also three times as likely to receive food stamps, public assistance or disability payments.
Sociologists believe that the rise in the number of older Americans who are not married is a result of factors such as longevity and economics. Women, especially, are becoming more and more financially independent which allows them to feel more secure with being alone, in addition to changing perceptions of being divorced or single. This has resulted in less pressure for baby boomers to marry or stay married.
Statistics.
Asia.
In Japan, divorces were on a generally upward trend from the 1960s until 2002 when they hit a peak of 290,000. Since then, both the number of divorces and the divorce rate have declined for six years straight. In 2010, the number of divorces totalled 251,000, and the divorce rate was 1.99 (per 1,000 population).
Europe.
One study estimated that legal reforms accounted for about 20% of the increase in divorce rates in Europe between 1960 and 2002.
The 10 places with the highest divorce rates in the UK are all beside the sea, with Blackpool in the top position.
North America.
United States.
On average, first marriages that end in divorce last about eight years. Of the first marriages for women from 1955 to 1959, about 79% marked their 15th anniversary, compared with only 57% for women who married for the first time from 1985 to 1989. The median time between divorce and a second marriage was about three and a half years.
In 2000, the divorce rate reached its peak at 4.0 per 1,000 total population and has slowly declined since. By 2014, the rate was down to 3.2 per 1,000 total population.
A 1995 study found a wide range of factors correlating with the divorce rate including frequency of sex, wealth, race, and religious commitment.
In 2001, marriages between people of different faiths were three times more likely to be divorced than those of the same faith. In a 1993 study, members of two mainline Protestant religions had a 20% chance of being divorced in 5 years; a Catholic and an Evangelical, a 33% chance; a Jew and a Christian, a 40% chance.
A study by the Barna Group, that conducts polls of interest to Christians, reports that a higher divorce rate was associated with infrequent church attendance.
Success in marriage has been associated with higher education and higher age. 81% of college graduates, over 26 years of age, who wed in the 1980s, were still married 20 years later. 65% of college graduates under 26, who married in the 1980s, were still married 20 years later. 49% of high school graduates under 26 years old, who married in the 1980s, were still married 20 years later. 2.9% of adults age 35â39 without a college degree divorced in the year 2009, compared with 1.6% with a college education. A population study found that in 2004 and 2008, liberal-voting states have lower rates of divorce than conservative-voting states, possibly because people in liberal states tend to wait longer before getting married. An analysis of this study found it to be misleading due to sampling at an aggregate level. It revealed that when sampling the same data by individuals, Republican leaning voters are less likely to have a divorce or extramarital affair than Democrat leaning voters and independents.
The National Center for Health Statistics reports that from 1975 to 1988 in the U.S., in families with children present, wives file for divorce in approximately two-thirds of cases. In 1975, 71.4% of the cases were filed by women, and in 1988, 65% were filed by women.
It is estimated that upwards of 95% of divorces in the U.S. are "uncontested", because the two parties are able to come to an agreement without a hearing (either with or without lawyers/mediators/collaborative counsel) about the property, children, and support issues.
A 2011 study found a 1% increase in the unemployment rate correlated with a 1% decrease in the divorce rate, presumably because more people were financially challenged to afford the legal proceedings.
Oceania.
In Australia, nearly every third marriage ends in divorce. After reaching a peak divorce rate of 2.7 per 1000 residents in 2001, the Australian rate declined to 2.3 per 1000 in 2007.
Divorce of same-sex married couples (United States).
All states permit same-sex marriage. For same-sex couples in the United States, divorce law is in its infancy and is less than clear on how such unions may be legally dissolved in another state. For example, if a same-sex couple is married in a state that recognizes gay marriage but returns to reside in a state that does not, they might find themselves in a situation where their own state, in failing to recognize their union, will also fail to enable them to divorce. In addition, splitting up the couple's financial resources may prove to be legally difficult and well as determining which spouse is entitled to the custody of their children.
Rights of spouses to custody of children.
Upon dissolution of a same-sex marriage, legal questions remain as to the rights of spouses to custody of the biological children of their spouses. Unresolved legal questions abound in this area.
Child custody policies include several guidelines that determine with whom the child lives following divorce, how time is divided in joint custody situations, and visitation rights. The most frequently applied custody guideline is the ââbest interests of the childââ standard, which takes into account the parentsâ preferences, the childâs preferences, the interactions between parents and children, childrenâs adjustment, and all family membersâ mental and physical health.
Same-sex divorce in a state that does not recognize same-sex marriage.
Since same-sex marriages are not recognized in a multitude of states, couples who are married in states that do recognize same-sex marriages will find themselves in a position of being precluded from dissolving their marriages in the states in which they live. When this happens, legal questions will remain unanswered as to which state laws will be applicable to determine the rights of each divorcing partner. In addition, special problems will present themselves when same-sex couples cannot be divorced in states that do recognize same sex marriage because they are not residents of such states.
Religion and divorce.
In some countries (commonly in Europe and North America), the government defines and administers marriages and divorces. While ceremonies may be performed by religious officials on behalf of the state, a civil marriage and thus, civil divorce (without the involvement of a religion) is also possible. Due to differing standards and procedures, a couple can be legally unmarried, married, or divorced by the state's definition, but have a different status as defined by a religious order. Other countries use religious law to administer marriages and divorces, eliminating this distinction. In these cases, religious officials are generally responsible for interpretation and implementation.
Islam allows divorce, and it can be initiated by either the husband or the wife. However, the initiations are subject to certain conditions and waiting periods, which are meant to force the initiating party to reconsider.
Dharmic religions allow divorce under some circumstances. Christian views on divorce vary, Catholic teaching allows only annulment, most other denominations discourage it except in the event of adultery. Jewish views of divorce differ, with Reform Judaism considering civil divorces adequate. Conservative and Orthodox Judaism require that the husband grant his wife a divorce in the form of a "get".
The Millet System, where each religious group regulates its own marriages and divorces, is still present in varying degrees in some postâOttoman countries like Iraq, Syria, Jordan, Lebanon, Israel, the Palestinian Authority, Egypt, and Greece. Several countries use sharia (Islamic law) to administrate marriages and divorces for Muslims. Thus, Marriage in Israel is administered separately by each religious community (Jews, Christians, Muslims, and Druze), and there is no provision for interfaith marriages other than marrying in another country. For Jews, marriage and divorce are administered by Orthodox rabbis. Partners can file for divorce either in rabbinical court or Israeli civil court.
Gender and divorce.
According to a study published in the American Law and Economics Review, women have filed slightly more than two-thirds of divorce cases in the United States. This trend is mirrored in the UK where a recent study into web search behavior found that 70% of divorce inquiries were from women. These findings also correlate with the Office for National Statistics publication "Divorces in England and Wales 2012 which reported that divorce petitions from women outnumber those from men by 2 to 1.
Regarding divorce settlements, according to the 2004 Grant Thornton survey in the UK, women obtained a better or considerably better settlement than men in 60% of cases. In 30% of cases the assets were split 50-50, and in only 10% of cases did men achieve better settlements (down from 24% the previous year). The report concluded that the percentage of shared residence orders would need to increase in order for more equitable financial divisions to become the norm.
Some jurisdictions give unequal rights to men and women when filing for divorce.
For couples to Conservative or Orthodox Jewish law (which by Israeli civil law includes all Jews in Israel), the husband must grant his wife a divorce through a document called a "get". If the man refuses, the woman can appeal to a court or the community to pressure the husband. A woman whose husband refuses to grant the get or who is missing is called an agunah, is still married, and therefore cannot remarry. Under Orthodox law, children of an extramarital affair involving a married Jewish woman are considered "mamzerim" (illegitimate) and cannot marry non-"mamzerim".
History.
Greco-Roman culture.
The ancient Athenians liberally allowed divorce, but the person requesting divorce had to submit the request to a magistrate, and the magistrate could determine whether the reasons given were sufficient.
Divorce was rare in early Roman culture but as their empire grew in power and authority Roman civil law embraced the maxim, "" ("marriages ought to be free"), and either husband or wife could renounce the marriage at will. Though civil authority rarely intervened in divorces, social and familial taboos guaranteed that divorce occurred only after serious circumspection. The Christian emperors Constantine and Theodosius restricted the grounds for divorce to grave cause, but this was relaxed by Justinian in the 6th century.
Medieval Europe.
After the fall of the Roman Empire, familial life was regulated more by ecclesiastical authority than civil authority. By the 9th or 10th century, the divorce rate had been greatly reduced under the influence of the Church, which considered marriage a sacrament instituted by God and Christ indissoluble by mere human action.
Although divorce, as known today, was generally prohibited after the 10th century, separation of husband and wife and the annulment of marriage were well-known. What is today referred to as "separate maintenance" (or "legal separation") was termed "divorce a mensa et thoro" ("divorce from bed-and-board"). The husband and wife physically separated and were forbidden to live or cohabit together; but their marital relationship did not fully terminate. Civil courts had no power over marriage or divorce. The grounds for annulment were determined by Church authority and applied in ecclesiastical courts. Annulment was for canonical causes of impediment existing at the time of the marriage. "For in cases of total divorce, the marriage is declared null, as having been absolutely unlawful ab initio." The Church held that the sacrament of marriage produced one person from two, inseparable from each other: "By marriage the husband and wife are one person in law: that is, the very being of legal existence of the woman is suspended during the marriage or at least incorporated and consolidated into that of the husband: under whose wing, protection and cover, she performs everything." Since husband and wife became one person upon marriage, recognition of that oneness could be rescinded only on the grounds that the unity never existed to begin with, "i.e.", that the proclamation of marriage was erroneous and void from the start.
Secularisation in Europe.
After the Reformation, marriage came to be considered a civil contract in the newly Protestant regions of Europe, and on that basis civil authorities gradually asserted their power to decree a "divortium a vinculo matrimonii", or "divorce from all the bonds of marriage".
Since no precedents existed defining the circumstances under which marriage could be dissolved, civil courts heavily relied on the previous determinations of the ecclesiastic courts and freely adopted the requirements set down by those courts. As the civil courts assumed the power to dissolve marriages, courts still strictly construed the circumstances under which they would grant a divorce, and considered divorce to be contrary to public policy. Because divorce was considered to be against the public interest, civil courts refused to grant a divorce if evidence revealed any hint of complicity between the husband and wife to divorce, or if they attempted to manufacture grounds for a divorce. Divorce was granted only because one party to the marriage had violated a sacred vow to the "innocent spouse". If both husband and wife were guilty, "neither would be allowed to escape the bonds of marriage".
Eventually, the idea that a marriage could be dissolved in cases in which one of the parties violated the sacred vow gradually allowed expansion of the grounds upon which divorce could be granted from those grounds which existed at the time of the marriage to grounds which occurred after the marriage, but which exemplified violation of that vow, such as abandonment, adultery, or "extreme cruelty". An exception to this trend was the Anglican Church, which maintained the doctrine of marital indissolubility.
During the English Civil War, the Puritans briefly passed a law that divested marriage of all sacrament, leaving it as a secular contract that could be broken. John Milton wrote four divorce tracts from 1643â1645 that argued for the legitimacy of divorce on grounds of spousal incompatibility. His ideas were ahead of their time; arguing for divorce at all, let alone a version of no-fault divorce, was extremely controversial and religious figures sought to ban his tracts. In 1670 a precedent was first set with an Act of Parliament allowing Lord John Manners to divorce his wife, Lady Anne Pierpon, and until the passage of the Matrimonial Causes Act 1857, divorce could only be obtained through a specific Act of Parliament.
The move towards secularisation and liberalisation was reinforced by the individualistic and secular ideals of the Enlightenment. The Enlightened absolutist, King Frederick II ("the Great") of Prussia decreed a new divorce law in 1752, in which marriage was declared to be a purely private concern, allowing divorce to be granted on the basis of mutual consent. This new attitude heavily influenced the law in neighbouring Austria under Emperor Joseph II, where it was applied to all non-Catholic Imperial subjects. Divorce was legalised in France after the French revolution on a similar basis, although the legal order of the ancien regime was reinstated at the Bourbon restoration of 1816. The trend in Europe throughout the 19th century, was one of increased liberalisation; by the mid-19th century divorce was generally granted by civil courts in the case of adultery.
In Britain before 1857 wives were regarded as under the economic and legal protection of their husbands, and divorce was almost impossible. It required a very expensive private Act of Parliament costing perhaps Â£200, of the sort only the richest could possibly afford. It was very difficult to secure divorce on the grounds of adultery, desertion, or cruelty. The first key legislative victory came with the Matrimonial Causes Act 1857, which passed over the strenuous opposition of the highly traditional Church of England. The new law made divorce a civil affair of the courts, rather than a Church matter, with a new civil court in London handling all cases. The process was still quite expensive, at about Â£40, but now became feasible for the middle class. A woman who obtained a judicial separation took the status of a "feme sole," with full control of her own civil rights. Additional amendments came in 1878, which allowed for separations handled by local justices of the peace. The Church of England blocked further reforms until the final breakthrough came with the Matrimonial Causes Act 1973.
In Spain, the 1931 Constitution of the Second Spanish Republic for the first time recognised a right to divorce. The first law to regulated divorce was the "Divorce Act of 1932", that passed the Republican Parliament despite the opposition of the Catholic Church and a coalition of the Agrarian Minority and Minority Basque-Navarre Catholic parties. The dictatorship of General Franco abolished the law. After the restoration of democracy, a new divorce law was passed in 1981, again over the opposition of the Catholic Church and part of the Christian Democrat party, then a part of the ruling Union of Democratic Center. During the first socialist government of Felipe GonzÃ¡lez MÃ¡rquez the 1981 law was amended to expedite the process of separation and divorce of marriages, which was again opposed by the Church, which called it "express divorce".
In Italy, the first divorce law was introduced on 1 December 1970, despite the opposition of the Christian Democrats, and entered into force on 18 December 1970. In the following years, the Christian Democrats, supported also by parties opposed to the law, promoted a recall referendum. In 1974, in a referendum the majority of the population voted against a repeal of the divorce law. A feature of the 1970 divorce law was the long period of marital separation of five years required. This period was reduced to three in 1987 and to a year in 2015, in the case of judicial separation, and six months in the case of separation by mutual agreement.
Ireland and Malta approved divorce at a referendum in 1995 and 2011 respectively.
Divorce rates increased markedly during the 20th century in developed countries, as social attitudes towards family and sex changed dramatically. Divorce has become commonplace in some countries, including the United States, Canada, Australia, Germany, New Zealand, Scandinavia, and the United Kingdom.
Japan.
In the Edo Period (1603â1868), only husbands could divorce their wives by writing letters of divorce. But actually, their relatives or marriage arrangers often kept these letters and tried to restore the marriages. It was not allowed for wives to divorce their husbands. Some wives were able to gain sanctuary in certain Shinto "divorce temples" for several years, and were able to obtain a divorce thereby. In 19th century Japan, at least one in eight marriages ended in divorce.
There are four types of divorce in Japan: Divorce by agreement in which the divorce is mutual, divorce by mediation which happens in family court, divorce by decision of family court that takes place when a couple cannot complete a divorce through mediation, and divorce by judgment of district court.
India.
On an all-India level, the Special Marriage Act was passed in 1954, is an inter-religious marriage law permitting Indian nationals to marry and divorce irrespective of their religion or faith. The Hindu Marriage Act, in 1955 which legally permitted divorce to Hindus and other communities who chose to marry under these acts. The Indian Divorce Act 1869 is the law relating to the divorce of person professing the Christian religion. Divorce can be sought by a husband or wife on grounds including adultery, cruelty, desertion for two years, religious conversion, mental abnormality, venereal disease, and leprosy. Divorce is also available based on mutual consent of both the spouses, which can be filed after at least one year of separated living. Mutual consent divorce can not be appealed, and the law mandates a minimum period of six months (from the time divorce is applied for) for divorce to be granted. Contested divorce is when one of the spouse is not willing to divorce the other spouse, under such condition the divorce is granted only on certain grounds according to the Hindu marriage act of 1955. While a Muslim husband can unilaterally bring an end to the marriage by pronouncing talaq, Muslim women must go to court, claiming any of the grounds provided under the Dissolution of Muslim Marriage Act.
Official figures of divorce rates are not available, but it has been estimated that 1 in 100 or another figure of 11 in 1,000 marriages in India end up in divorce.
Various communities are governed by specific marital legislation, distinct to Hindu Marriage Act, and consequently have their own divorce laws:
An amendment to the marriage laws to allow divorce based on "irretrievable breakdown of marriage" (as alleged by one of the spouses) is under consideration in India. In June 2010, the Union Cabinet of India approved the Marriage Laws (Amendment) Bill 2010, which, if cleared by Parliament, would establish "irretrievable breakdown" as a new ground for divorce. Under the proposed amendment, the court before proceeding to the merits of the case must be satisfied by the evidences produced that parties have been living apart for a continuous period of not less than three years immediately preceding the presentation of the petition.
Islam ( Muslim Law ).
The Quran regulates divorce in several suras, including the following:
In Islamic law and marital jurisprudence, divorce is referred to as "talaq". Khula is the right of a woman in Islam to divorce or separate from her husband. The triple talaq is a mechanism for divorce which exists in Sunni sect of Islam while rejected by the Shia sect. Talaq (conflict) deals with the relationship between religious and secular systems for terminating the marriage in the conflict of laws.
According to Yossef Rapoport, in the 15th century, the rate of divorce was higher than it is today in the modern Middle East, which has generally low rates of divorce. In 15th century Egypt, Al-Sakhawi recorded the marital history of 500 women, the largest sample on marriage in the Middle Ages, and found that at least a third of all women in the Mamluk Sultanate of Egypt and Syria married more than once, with many marrying three or more times. According to Al-Sakhawi, as many as three out of ten marriages in 15th century Cairo ended in divorce. In the early 20th century, some villages in western Java and the Malay peninsula had divorce rates as high as 70%.
The Philippines.
Divorce as a means of terminating marriage is illegal for all Filipinos except Filipino Muslims. There is only civil annulment after a lengthy legal separation. The process is costly and long, and there are many legally married couples in extramarital relations, even without a divorce law.
Code of Muslim Personal Laws of the Philippines, known as Presidential Decree (PD) No. 1083, Title II- Marriage and Divorce, Chapter 3-Divorce allows for divorce recognized by the state. There are two sharia courts in the Philippine judicial system that hear these cases.
On July 27, 2010, Gabriela Women's Party filed in Congress House Bill No 1799, or the Divorce Bill of the Philippines, as one of many attempts to introduce pro-divorce legislation. Senator Pia Cayetano has filed a separate divorce bill in the Senate.
Patterns of Divorce.
Divorce rates increase during times of hardship, war, and major events. Divorce rates increased after World War II because people were quick to marry each other before they went to war. When soldiers returned, they found out they don't have much in common with their spouses, so they divorced. 

</doc>
<doc id="40148" url="https://en.wikipedia.org/wiki?curid=40148" title="Harold Godwinson">
Harold Godwinson

Harold II (or Harold Godwinson; ; ; 1022Â â 14 October 1066) was the last Anglo-Saxon king of England. Harold reigned from 6 January 1066 until his death at the Battle of Hastings on 14 October, fighting the Norman invaders led by William the Conqueror during the Norman conquest of England. His death marked the end of Anglo-Saxon rule over England.
Harold was a powerful earl and member of a prominent Anglo-Saxon family with ties to King Cnut. Upon the death of Edward the Confessor in January 1066, the "Witenagemot" convened and chose Harold to succeed; he was crowned in Westminster Abbey. In late September he successfully repelled an invasion by rival claimant Harald Hardrada of Norway, before marching his army back south to meet William the Conqueror at Hastings some two weeks later.
Family background.
Harold was a son of Godwin (1001â1053), the powerful Earl of Wessex, and of Gytha ThorkelsdÃ³ttir, sister-in-law of King Cnut the Great of England and Denmark. Gytha's brother was Ulf Jarl, who married Cnut's sister Estrith (c.Â 1015/1016). This made Ulf the son-in-law of King Sweyn Forkbeard (died 1014); Ulf and Estrith's son would become King Sweyn II of Denmark in 1047. Godwin was the son of Wulfnoth, probably a "thegn" and a native of Sussex. Godwin remained an earl throughout the remainder of Cnut's reign, one of only two earls to survive to the end of Cnut's reign. On Cnut's death in 1035, Godwin originally supported Harthacnut instead of Cnut's initial successor Harold Harefoot, but managed to switch sides in 1037, although not without becoming involved in the 1036 murder of Alfred Aetheling, half brother of Harthacnut and younger brother of the later King Edward the Confessor. When Harold Harefoot died (1040), Harthacnut became King of England and Godwin's power was imperiled by his earlier involvement in Alfred's murder, but an oath and large gift secured the new king's favour for Godwin. Harthacnut's death in 1042 likely involved Godwin in a role as kingmaker, helping to secure the English throne for Edward the Confessor. In 1045 Godwin reached the height of his power when the new king married Godwin's daughter Edith.
Godwin and Gytha had several childrenÂ â six sons: Sweyn, Harold, Tostig, Gyrth, Leofwine and Wulfnoth; and three daughters: Edith of Wessex (originally named Gytha but renamed Ealdgyth (or Edith) when she married King Edward the Confessor), Gunhild and Ãlfgifu. The birthdates of the children are unknown, but Sweyn was the eldest and Harold was the second son. Harold was aged about 25 in 1045, which makes his birth year around 1020.
Powerful nobleman.
Edith married Edward on 23 January 1045, and around that time Harold became Earl of East Anglia. Harold is called "earl" when he appears as a witness in a will, that may date to 1044, but by 1045 Harold regularly appears as an earl in documents. One reason for his appointment to East Anglia may have been a need to defend against the threat from King Magnus the Good of Norway. It is possible that Harold led some of the ships from his earldom that were sent to Sandwich in 1045 against Magnus. Sweyn, Harold's elder brother, had been named an earl in 1043. It was also around the time that Harold was named an earl that he began a relationship with Edith, who appears to have been the heiress to lands in Cambridgeshire, Suffolk and Essex, lands in Harold's new earldom. The relationship was a form of marriage that was not blessed or sanctioned by the Church, known as "more Danico", or "in the Danish manner", and was accepted by most laypeople in England at the time. Any children of such a union were considered legitimate. Harold likely entered the relationship in part to secure support in his new earldom.
In 1047 Harold's elder brother Sweyn was exiled after abducting the abbess of Leominster. Sweyn's lands were divided between Harold and a cousin, Beorn. In 1049, Harold was in command of a ship or ships that were sent with a fleet to aid the German Emperor Henry III against Baldwin V, Count of Flanders, who was in revolt against Henry. During this campaign, Sweyn returned to England and attempted to secure a pardon from the king, but Harold and Beorn refused to return any of their lands, and Sweyn, after leaving the royal court, took Beorn hostage and later killed him.
When in 1051 Earl Godwin was sent into exile, Harold accompanied his father and helped him to regain his position a year later. Then Godwin died in 1053, and Harold succeeded him as Earl of Wessex (the southern third of England). This arguably made him the most powerful figure in England after the king.
In 1058, Harold also became Earl of Hereford and replaced his late father as the focus of opposition to growing Norman influence in England under the restored monarchy (1042â66) of Edward the Confessor, who had spent more than 25 years in exile in Normandy. He led a series of successful campaigns (1062â63) against Gruffydd ap Llywelyn of Gwynedd, the ruler of Wales. This conflict ended with Gruffydd's defeat and death in 1063.
Harold in northern France.
In 1064, Harold apparently was shipwrecked at Ponthieu. There is much speculation about this voyage. The earliest post-conquest Norman chroniclers report that King Edward had previously sent Robert, Archbishop of Canterbury, to appoint as his heir Edward's maternal kinsman, William of Normandy, and that at this later date Harold was sent to swear fealty. Scholars disagree as to the reliability of this story. William, at least, seems to have believed he had been offered the succession, but there must have been some confusion either on William's part or perhaps by both men, since the English succession was neither inherited nor determined by the reigning monarch. Instead the Witenagemot, the assembly of the kingdom's leading notables, would convene after a king's death to select a successor. Other acts of Edward are inconsistent with his having made such a promise, such as his efforts to return his nephew Edward the Exile, son of king Edmund Ironside, from Hungary in 1057. Later Norman chroniclers suggest alternative explanations for Harold's journey: that he was seeking the release of members of his family who had been held hostage since Godwin's exile in 1051, or even that he had simply been travelling along the English coast on a hunting and fishing expedition and had been driven across the Channel by an unexpected storm. There is general agreement that he left from Bosham, and was blown off course, landing at Ponthieu. He was captured by Guy I, Count of Ponthieu, and was then taken as a hostage to the count's castle at Beaurain, 24.5Â km up the River Canche from its mouth at what is now Le Touquet. Duke William arrived soon afterward and ordered Guy to turn Harold over to him. Harold then apparently accompanied William to battle against William's enemy, Conan II, Duke of Brittany. While crossing into Brittany past the fortified abbey of Mont Saint-Michel, Harold is recorded as rescuing two of William's soldiers from quicksand. They pursued Conan from Dol-de-Bretagne to Rennes, and finally to Dinan, where he surrendered the fortress's keys at the point of a lance. William presented Harold with weapons and arms, knighting him. The Bayeux Tapestry, and other Norman sources, then record that Harold swore an oath on sacred relics to William to support his claim to the English throne. After Edward's death, the Normans were quick to point out that in accepting the crown of England, Harold had broken this alleged oath.
The chronicler Orderic Vitalis wrote of Harold that he "was very tall and handsome, remarkable for his physical strength, his courage and eloquence, his ready jests and acts of valour. But what were these gifts to him without honour, which is the root of all good?"
Due to a doubling of taxation by Tostig in 1065 that threatened to plunge England into civil war, Harold supported Northumbrian rebels against his brother, Tostig, and replaced him with Morcar. This strengthened his acceptability as Edward's successor, but fatally split his own family, driving Tostig into alliance with King Harald Hardrada ("Hard Ruler") of Norway.
Reign as king.
At the end of 1065 King Edward the Confessor fell into a coma without clarifying his preference for the succession. He died on 5 January 1066, according to the "Vita Ãdwardi Regis", but not before briefly regaining consciousness and commending his widow and the kingdom to Harold's "protection". The intent of this charge remains ambiguous, as is the Bayeux Tapestry, which simply depicts Edward pointing at a man thought to represent Harold. When the Witenagemot convened the next day they selected Harold to succeed, and his coronation followed on 6 January, most likely held in Westminster Abbey; though no evidence from the time survives to confirm this. Although later Norman sources point to the suddenness of this coronation, the reason may have been that all the nobles of the land were present at Westminster for the feast of Epiphany, and not because of any usurpation of the throne on Harold's part.
In early January 1066, hearing of Harold's coronation, Duke William II of Normandy began plans to invade England, building 700 warships and transports at Dives-sur-Mer on the Normandy coast. Initially, William could not get support for the invasion but, claiming that Harold had sworn on sacred relics to support his claim to the throne after having been shipwrecked at Ponthieu, William received the Church's blessing and nobles flocked to his cause. In anticipation of the invasion, Harold assembled his troops on the Isle of Wight, but the invasion fleet remained in port for almost seven months, perhaps due to unfavourable winds. On 8 September, with provisions running out, Harold disbanded his army and returned to London. On the same day Harald Hardrada of Norway, who also claimed the English crown joined Tostig and invaded, landing his fleet at the mouth of the Tyne.
The invading forces of Hardrada and Tostig defeated the English earls, Edwin of Mercia and Morcar of Northumbria, at the Battle of Fulford near York on 20 September 1066. They in turn were defeated and slain by Harold's army five days later at the Battle of Stamford Bridge, Harold having led his army north on a forced march from London in four days and having caught them by surprise. According to Snorri Sturluson, before the battle a man bravely rode up to Harald Hardrada and Tostig and offered Tostig his earldom if he would but turn on Harald Hardrada. When Tostig asked what his brother Harold would be willing to give Harald Hardrada for his trouble, the rider replied that he would be given seven feet of ground as he was taller than other men. Harald Hardrada was impressed with the rider and asked Tostig his name. Tostig replied that the rider was none other than Harold Godwinson. According to Henry of Huntingdon, "Six feet of ground or as much more as he needs, as he is taller than most men", was Harold's response.
Battle of Hastings.
On 12 September 1066, William's fleet sailed from Normandy. Several ships sank in storms, and the fleet was forced to take shelter at Saint-Valery-sur-Somme and wait for the wind to change. On 27 September, the Norman fleet finally set sail for England, arriving, it is believed, the following day at Pevensey on the coast of East Sussex. Harold's army marched 241 miles (386 kilometres) to intercept William, who had landed perhaps 7,000 men in Sussex, southern England. Harold established his army in hastily built earthworks near Hastings. The two armies clashed at the Battle of Hastings, at Senlac Hill (near the present town of Battle) close by Hastings on 14 October, where after nine hours of hard fighting and probably less than 30 minutes from victory, Harold was killed and his forces routed. His brothers Gyrth and Leofwine were also killed in the battle.
Death.
The account of the battle, "Carmen de Hastingae Proelio" ("Song of the Battle of Hastings"), said to have been written shortly after the battle by Guy, Bishop of Amiens, says that Harold was killed by four knights, probably including Duke William, and his body brutally dismembered. Amatus of Montecassino's "L'Ystoire de li Normant" ("History of the Normans"), written thirty years after the battle of Hastings, is the first report of Harold being shot in the eye with an arrow. Later accounts reflect one or both of these two versions. A figure in the panel of the Bayeux Tapestry with the inscription "Harold Rex Interfectus Est" (Harold the King is killed) is depicted gripping an arrow that has struck his eye, but some historians have questioned whether this man is intended to be Harold, or if Harold is intended as the next figure lying to the right almost supine, being mutilated beneath a horse's hooves. Etchings made of the Tapestry in the 1730s show the standing figure with differing objects. BenoÃ®t's 1729 sketch shows only a dotted line indicating stitch marks without any indication of fletching (all other arrows in the Tapestry are fletched). Bernard de Montfaucon's 1730 engraving has a solid line resembling a spear being held overhand matching the manner of the figure to the left. Stothard's 1819 water-colour drawing has, for the first time, a fletched arrow in the figure's eye. Although not apparent in the earlier depictions, the Tapestry today has stitch marks indicating the fallen figure once had an arrow in its eye. It has been proposed that the second figure once had an arrow added by over-enthusiastic nineteenth-century restorers that was later unstitched. Many believe that as the name "Harold" is above the figure with an arrow in his eye, Harold died in an arrow volley. Further evidence is that an arrow volley would be fired before the Norman cavalry charge. This strengthens the arrow to the eye account. A further suggestion is that both accounts are accurate, and that Harold suffered first the eye wound, then the mutilation, and the Tapestry is depicting both in sequence.
Burial and legacy.
The account of the contemporary chronicler William of Poitiers, states that the body of Harold was given to William Malet for burial:
The two brothers of the King were found near him and Harold himself, stripped of all badges of honour, could not be identified by his face but only by certain marks on his body. His corpse was brought into the Duke's camp, and William gave it for burial to William, surnamed Malet, and not to Harold's mother, who offered for the body of her beloved son its weight in gold. For the Duke thought it unseemly to receive money for such merchandise, and equally he considered it wrong that Harold should be buried as his mother wished, since so many men lay unburied because of his avarice. They said in jest that he who had guarded the coast with such insensate zeal should be buried by the seashore.
Another source states that Harold's widow, Edith Swannesha, was called to identify the body, which she did by some private mark known only to her. Harold's strong association with Bosham, his birthplace, and the discovery in 1954 of an Anglo-Saxon coffin in the church there, has led some to suggest it as the place of King Harold's burial. A request to exhume a grave in Bosham church was refused by the Diocese of Chichester in December 2003, the Chancellor having ruled that the chances of establishing the identity of the body as Harold's were too slim to justify disturbing a burial place. A prior exhumation had revealed the remains of a man, estimated at up to 60 years of age from photographs of the remains, lacking a head, one leg and the lower part of his other leg, a description consistent with the fate of the king as recorded in the Carmen. The poem also claims Harold was buried by the sea, which is consistent with William of Poitiers' account and with the identification of the grave at Bosham Church that is only yards from Chichester Harbour and in sight of the English Channel.
There were legends of Harold's body being given a proper funeral years later in his church of Waltham Holy Cross in Essex, which he had refounded in 1060. Legends grew up that Harold had not died at Hastings but instead fled England or that he later ended his life as a hermit at Chester or Canterbury.
Harold's son Ulf, along with Morcar and two others, were released from prison by King William as he lay dying in 1087. Ulf threw his lot in with Robert Curthose, who knighted him, and then disappeared from history. Two of Harold's other sons, Godwine and Edmund, invaded England in 1068 and 1069 with the aid of Diarmait mac MÃ¡el na mBÃ³ (High King of Ireland). They raided Cornwall as late as 1082, but died in obscurity in Ireland.
He is considered by some Orthodox Christians and theologians to be the last Orthodox King of England and a possible passion-bearer, after conspiracy by William the Conqueror and Pope Alexander II to secure a strict Roman Rite over the British Isles, which at the time may not have yet realized the effects of the East-West Schism and still adhered to the Celtic Rite in most areas.
Marriages and children.
For some twenty years Harold was married "More danico" (Latin: "in the Danish manner") to Edith the Fair (Edith Swannesha) and had at least six children with her. The marriage was widely accepted by the laity, although Edith was considered Harold's mistress by the clergy.
According to Orderic Vitalis, Harold was at some time betrothed to Adeliza, a daughter of William, Duke of Normandy, later William the Conqueror; if so, the betrothal never led to marriage.
About January 1066, Harold married Edith (or Ealdgyth), daughter of Ãlfgar, Earl of Mercia, and widow of the Welsh prince Gruffydd ap Llywelyn. Edith had two sonsâpossibly twinsânamed Harold and Ulf (born around November 1066), both of whom survived into adulthood and probably lived out their lives in exile.
After her husband's death, Edith fled for refuge to her brothers, Edwin, Earl of Mercia and Morcar of Northumbria, but both men made their peace with King William initially before rebelling and losing their lands and lives. Edith may have fled abroad (possibly with Harold's mother, Gytha, or with Harold's daughter, Gytha). Harold's sons, Godwine and Edmund, fled to Ireland and then invaded Devon, but were defeated by Brian of Brittany.

</doc>
<doc id="40149" url="https://en.wikipedia.org/wiki?curid=40149" title="Godwin, Earl of Wessex">
Godwin, Earl of Wessex

Godwin of Wessex () (100115 April 1053) was one of the most powerful earls in England under the Danish king Cnut the Great and his successors. Cnut made him the first Earl of Wessex. Godwin was the father of King Harold Godwinson and Edith of Wessex, wife of King Edward the Confessor.
Rise to power.
Godwin's father was probably Wulfnoth Cild, who was a thegn of Sussex. His origin is unknown but 'Cild' normally refers to a man of rank. In 1009 Wulfnoth was accused of unknown crimes at a muster of Ãthelred the Unready's fleet and fled with twenty ships; the ships sent to pursue him were destroyed in a storm. Godwin was probably an adherent of Ãthelred's eldest son, Ãthelstan, who left him an estate when he died in 1014. This estate in Compton, Sussex, had once belonged to Godwinâs father. Although he is now always thought of as connected with Wessex, Godwin had probably been raised in Sussex, not Wessex and was probably a native of Sussex.
After Cnut seized the throne in 1016, Godwin's rise was rapid. By 1018 he was an earl, probably of eastern Wessex, and then by around 1020 of all Wessex. Between 1019 and 1023 he accompanied Cnut on an expedition to Denmark, where he distinguished himself, and shortly afterwards married Gytha, the sister of the Danish earl, Ulf, who was married to Cnut's sister, Estrid.
Height of power: support of Harold.
On 12 November 1035, Cnut died. His kingdoms were divided among three rival rulers. Harold Harefoot, Cnut's illegitimate son with Ãlfgifu of Northampton, seized the throne of England. Harthacnut, Cnut's legitimate son with Emma of Normandy, reigned in Denmark. Norway rebelled under Magnus the Noble. In 1035, the throne of England was reportedly claimed by Alfred Ãtheling, younger son of Emma of Normandy and Ãthelred the Unready, and half-brother of Harthacnut. Godwin is reported to have either captured Alfred himself or to have deceived him by pretending to be his ally and then surrendering him to the forces of Harold Harefoot. Either way Alfred was blinded and soon died at Ely.
In 1040, Harold Harefoot died and Godwin supported the accession of his half-brother Harthacnut to the throne of England. When Harthacnut himself died in 1042 Godwin supported the claim of Ãthelred's last surviving son Edward the Confessor to the throne. Edward had spent most of the previous thirty years in Normandy. His reign restored the native royal house of Wessex to the throne of England.
Later conflicts, decline, and death.
Despite his alleged responsibility for the death of Edward's brother Alfred, Godwin secured the marriage of his daughter Edith (Eadgyth) to Edward in 1045. As Edward drew advisors, nobles and priests from his former place of refuge in a bid to develop his own power base, Godwin soon became the leader of opposition to growing Norman influence. After a violent clash between the people of Dover and the visiting Eustace II, Count of Boulogne, Edward's brother-in-law, Godwin was ordered to punish the people of Dover (as he and Leofric, Earl of Mercia had done in Worcester, in Leofric's own earldom). This time, however, Godwin refused, choosing to champion his own countrymen against a (visiting) foreign ruler and his own king. Edward saw this as a test of power, and managed to enlist the support of Siward, Earl of Northumbria and Earl Leofric. Godwin and his sons were exiled from the kingdom in September 1051. Godwin, along with his wife Gytha and sons Sweyn, Tostig and Gyrth sought refuge in Flanders, while his sons Leofwine and Harold fled to Dublin, where they gained the shelter and help of Diarmait mac MÃ¡el na mBÃ³, King of Leinster. They all returned to England the following year with armed forces, gaining the support of the navy, burghers, and peasants, so compelling Edward to restore his earldom. This however set a precedent to be followed by a rival earl some years later, and then by Godwin's own son, Tostig, in 1066.
On 15 April 1053 Godwin died suddenly, after collapsing during a royal banquet at Winchester. Some colourful accounts claim that he choked on a piece of bread while denying any disloyalty to the king. However this appears to be later Norman propaganda. Contemporary accounts indicate that he just had a sudden illness, possibly a stroke.
His son Harold succeeded him as Earl of Wessex, an area then covering roughly the southernmost third of England. With the death of Earl Siward (1055) and later Earl Ãlfgar (1062), the children of Godwin were poised to assume sole control. Tostig was helped into the earldom of Northumbria, thus controlling the north. The Mercian earl was sidelined, especially after Harold and Tostig broke the Welsh-Mercian alliance in 1063. Harold later succeeded Edward the Confessor and became King of England in his own right in 1066. At this point, both Harold's remaining brothers in England were earls in their own right, Harold was himself king and in control of Wessex, and he had married the sister of Earl Edwin of Mercia and Morcar, Earl of Northumbria (who had replaced Tostig). Godwin's family looked set to inaugurate a new royal dynasty, but instead Harold was overthrown and killed in the Norman Conquest.
In popular culture.
Godwin has been portrayed by Torin Thatcher in the film "Lady Godiva of Coventry" (1955) and by Bill Wallis in an episode of the British educational TV series "Historyonics" entitled "1066" (2004). Godwin is also the lead character of Justin Hill's novel, "Shieldwall" (2011).

</doc>
<doc id="40151" url="https://en.wikipedia.org/wiki?curid=40151" title="Alappuzha district">
Alappuzha district

Alappuzha () () is one of the 14 districts in the state of Kerala in India. It was formed as Alleppey District on August 17, 1957. The name of the district was officially changed to Alappuzha in 1990. The district is a widely known tourist destination and is well known for its Coir factories. Most of Kerala's coir industries are situated in and around Alappuzha.
The district is also known for its communist traditions. It is home to the Punnapra-Vayalar uprising against the British and also the revolt against the Feudal raj. Alappuzha is strongly connected by waterways to various other parts of Kerala, including the famous tourist destination, Kumarakom.
History.
The present town owes its existence to Raja Kesavadas in the second half of the 18th century but the district of Alappuzha figures in classical literature. Kuttanad, the rice bowl of Kerala, was well-known from the early periods of the Sangam age. History says Alappuzha had trade relations with ancient Greece and Rome in B.C and in the Middle Ages. 
Early members of the Chera dynasty had their home in Kuttanad and were called Kuttuvans. There is archaeological evidence of the early period of the district, such as stone inscriptions and monuments, in temples and caves, as well as in literary works such as "Unnuneeli Sandesam". The famous literary work of this period was âAscharya Choodamaniâ a Sanskrit drama written by Sakthibhadra who was a scholar of Chengannur grammar. The kingdom of Chempakasseri was at its zenith during the reign of Pooradam Thirunal Devanarayana, a great scholar and a poet who was the author of âVedantha Retnamalaâ, a commentary on the first verse of Bhagavat Geetha. It is said that Sreekrishna Swami temple, at Ambalappuzha was constructed and the idol of Lord Krishna installed during that time. It is believed that Melpathur Narayana Bhattathiri, Neelakanta Deekshithar and Kumaran Namboothiri were eminent scholars who patronized his court.
In the 17th century the Portuguese power declined and the Dutch had a predominant position in the principalities of this district. The church located at Kokkamangalam or Kokkothamangalam was one of the seven churches founded by St.Thomas, one of the twelve disciples of Jesus Christ. The picturesque CSI Christ Church in Alappuzha town was built in 1818 by the first CMS (Church Missionary Society) missionary to India, Rev. Thomas Norton. It was the first Anglican Church to be established in the erstwhile state of Travancore.
It was at that time Maharaja Marthandavarma, the âMaker of modern Travancoreâ interfered in the political affairs of those principalities. Marthandavarma Maharaja had a remarkable role in the internal progress of the district. The Krishnapuram Palace, which is now a protected monument of the State Archaeology Department, was constructed during that period. It was at that time that the great and talented poet Kunjan Nambiar was installed in the court. He was known as the âMaker of modern Alleppeyâ and played a key role in making Alappuzha a premier port town of Travancore.
During the reign of Balaramavarma Maharaja, Velu Thampi Dalava took keen interest in the development of the town and port. He brought the whole area of the island Pathiramanal under coconut cultivation and large tracts under paddy cultivation. The role of Velu Thampi Dalava in the development of Alappuzha is worth mentioning. In the 19th century the district attained progress in all spheres.
The first modern factory for the manufacture of coir mats and mattings was also established in 1859 at Alappuzha. The town Improvement Committee was set up in 1894.
This district had a prominent role in the freedom struggle of the country. The campaign for the eradication of untouchability was organized much earlier in this district by T.K. Madhavan, a fearless journalist and in 1925 the approach roads to the temples, especially in Ambalappuzha Sree Krishna Swami temple were thrown open to the Hindus of all castes. The district also witnessed the âNivarthanaâ movement which was started as a protest against the constitutional repression in 1932. The first political strike in Kerala was held at Alappuzha in 1938.
Geography.
Alappuzha is on a landmass between the broad Arabian sea and a network of rivers flowing into it.
Panchayats.
The panchayats in the district are:
Municipalities.
The municipalities in the district are:
Taluks.
Taluks in Alappuzha municipality are:
Taluks in Chengannur municipality are:
Vehicle registration.
Following are the vehicle registrations in Alappuzha District:
Old structure:-
Following are the old registration numbers in Alappuzha District:-
Demographics.
According to the 2011 census, Alappuzha district has a population of 2,121,943, roughly equal to the nation of Namibia or the US state of New Mexico. This gives it a ranking of 216th in India (out of a total of 640). The district has a population density of . Its population growth rate over the decade 2001-2011 was 0.61%. Alappuzha has a sex ratio of 1100 females for every 1000 males, and a literacy rate of 96.26%.
In the 2001 Indian Census, the Hindu population is 69.08%, Christian 20.94, and Muslim 9.86.
It has the highest population density among all districts of the state. It is 29.46% urbanized, and is the smallest district in Kerala.
Culture.
"Snake boat races" are the most significant traditional event in Alleppey. These spectacular regattas are usually held between August and October, and involve long thin boats powered by up to 120 oarsmen. The most famous snake boat race is the Nehru Trophy Boat Race.
Chemmeen was filmed in two villages in Alappuzha. In the opening credits, a written statement in Malayalam thanks the people of both villages.
Tourism.
The name Alappuzha is derived from 'Aal(Sea)+ puzhai(River-mouth)(The joining place of a river and the sea)' (Malayalam/Tamil ). Alappuzha is one of the most important tourist centres in the state, with a large network of inland canals earning it the sobriquet "Venice of the East". These large networks of canals provide Alleppey its lifeline. Alappuzha was one of the busiest centers of trade in the past with one of the best-known ports along the Malabar coast. Even today it retains its charm as the center for Coir carpet industries and prawn farming. Alappuzha, the ideal headquarters for backwater tourism as well as for visits to the lovely church filled town of Kottayam, and the town of Aranmula, are famous for their historic Aranmula Snake Boat Race which is an annual event. Chengannur in Alappuzha is the nearest railway station to Sabarimala. The Krishnapuram Palace is in Kayamkulam. The Buddha idol, Saradamandiram are the main attraction of Mavelikkara. The Buddha statue is in a seated posture, resembling Padmasana. A feature common to the idols is that hair has not been engraved on the head. Studies by the Archaeology Department have not been able to explain the absence of hair which is common in Buddha statues of the Gandhara and Mathura tradition. The head has markings resembling a headgear. Though the department has made a pagoda-like structure for the statue, no information on the idol is available to tourists who visit the area. Local people in the area light lamps before the idol. The idol at Mavelikara is high and is perhaps, the biggest. The engravings on the head resemble a helmet of Greek statues. The mark of a sacred thread is visible on the body. Another feature is the marking of a shawl on one shoulder. Here the Archaeological Department has put up a board specifying the age of the statue. Saradamandiram was the residence of Keralapanini.
Alappuzha is also known for its snake-boat races held on the second Saturday of August, every year. This competition; the Nehru boat race takes its name from India's first prime minister Jawaharlal Nehru, which was inaugurated in 1952. It is excitement all around as snake-boats, each manned by over a hundred oarsmen, cut through the waters like wind. The event is a tremendous success with tourists and the local population alike.
The boat cruise along the backwaters of Alappuzha gives one a first hand experience of the lifestyle; toddy tapping, fishing for small fry, Coir-making, prawn farming etc., which remains more or less unchanged over the years.
The latest addition to Alappuzha is the Revi Karunakaran Memorial Museum which features countless arts and artifacts. Revi Karunakaran was the architect of a modern Coir industry that still employs more than 500,000 people in the state of Kerala. The objects featured at the Museum were collected by his family over three generations and features unique artistic pieces from all parts of the world.
Alappuzha, the district headquarters, is a town with picturesque canals, backwaters and lagoons, was described as the "Venice of the East" by Lord Curzon.
Kuttanadu.
Kuttanad or Kuttanadu is an area of Alappuzha District, densely covered with waterways. Kuttanad is famous because of its paddy fields and farmers dedicated to the growth of paddy. It was once called the "Keralathinte Nellara", which means "rice bowl of Kerala". Many factors such as expense, labor shortage etc. seriously affected the agriculture in this region. Many former rice fields are now used for other crops which require much lesser investment. Kuttanadu is the birthplace of literary legend Thakazhi Sivasankara Pillai.
Festivals.
Chettikulangara Bharani is the most important festival in Alappuzha district. The festival is one among the important temple festivals of Kerala. A Chettikulagara Bhagavathi Temple, a temple dedicated to the Goddess Bhagavathi is about four kilometers from Mavelikkara. The festival occurs on the Bharani asterism in February/March. The main rituals of the festival are the 'Kuthiyottam' and 'Kettukazcha'. The 'Kuthiyottam' features a procession of young boys who have observed rigorous ritual penance. Traditional drums, music and glittering ornamental parasols accompany this procession of boys who dance in a trance.
'Chirappu Mahotsavam' is a big occasion at Mullackal Temple in December. Christmas comes in between the festival and Alappuzha town is a really happening place at the time. The streets are full of wandering markets and entertainment ventures like circuses and exhibitions. The streets are be crowded throughout the month and there is be a 'Shiveli' or the magnificent display of nine Tuskers accompanied by the 'Chenda' and the 'Panchavadyam' music.
Padanilam Sivarathri is another important religious event in Alappuzha district. This festival is held every year in the Padanilam Parabrahma Temple. The temple is situated in the small town of Padanilam. Padanilam is situated 'about 16Â km from Mavelikkara town. This place can also be called the festival Village of Alappuzha because Padanilam witnesses a large number of festivals every year including vrischika mahotsavam and irupathiyetttamonam. Padanilam is a place of religious unity.
A grand annual festival is celebrated at the unique Nagaraja Temple in October/November. Another festival celebrated by the temple is a one-day Thaipooyan Kavadi. The famous Chandanakudam is celebrated at the Kidangam-Parampu Temple during December every year. Kottamkulangara Temple in Alappuzha has two festive seasons in February and March, because of the two deities with separate flag masts in the same compound wall.
The famous Kandamangalam Rajarajeshwari Temple is located in Kadakkarappally, Cherthala 1Â km west of Thankey junction on NH 47. The annual festival comes in MarchâApril. Chikkara, offering of children to the mother goddess during the festival, is the major attraction. The Chamanju Valathu of children starts on the 2nd day of the festival and lasts till the 8th day. Procession named Thalappoli start on the flag-hoisting day itself. The holy bath (Aarattu) of the goddess is held in a pool within the temple compound on the 10th day of festival. Elephant processions, fireworks, stage shows, etc. are major events that attract thousands of devotees and others.
The churches here celebrate grand annual feasts. The 'Arthunkal Perunnal' feast is celebrated at the Arthunkal Church. The famous regatta forms part of many festivals here in many places. The annual Vallam Kali (Nehru Trophy Boat Race) is held in the backwaters in the month of September associated with the Onam festival. The main attraction is the Chundan Vallam (Snake Boat) race, in which a number of contestants are in the running for the famous Prime Minister's trophy, a trophy donated by Jawaharlal Nehru, the first Prime Minister of India. Another important celebration in Alappuzha is the "Beach Festival", held from December 30 to January 2. The annual festival conducted in Champakulam "Valiya Palli" is another big festival.
Education.
Medical colleges
Arts and Science colleges
Engineering colleges

</doc>
<doc id="40156" url="https://en.wikipedia.org/wiki?curid=40156" title="Khlysts">
Khlysts

Khlysts or Khlysty (Ð¥Ð»ÑÑÑÑ in Russian) was an underground sect from late 17th to early 20th century that split off the Russian Orthodox Church and belonged to the Spiritual Christians (Ð´ÑÑÐ¾Ð²Ð½ÑÐµ ÑÑÐ¸ÑÑÐ¸Ð°Ð½Ðµ) tendency.
Definition.
'Khlyst', the name commonly applied to them, is a distortion of the name they used; the original name was the invented word Ð¥ÑÐ¸ÑÑÐ¾Ð²Ð¾Ð²ÐµÑÑ (Khristovovery, "Christ-believers") or Ð¥ÑÐ¸ÑÑÑ (Khristy); their critics corrupted the name, mixing it with the word ÑÐ»ÑÑÑ (khlyst), meaning "a whip".
It is also possible that the word 'Khlysty' is related to the Greek word 'ÏÎ¹Î»Î¹Î±ÏÏÎ±Î¯' (=millennialists, chiliasts; pronounced 'khiliastÃ©'), or with "klyster", meaning "one that purges". Millennialism has many different branches and sects and their teachings have common points with those of the Khlysty.
History.
It is said to have been founded by a peasant, Daniil Filippovich, (or Filippov), of Kostroma. The Khlysty renounced priesthood, holy books and veneration of the saints (excluding the Theotokos). They believed in a possibility of direct communication with the Holy Spirit and of His embodiment in living people. Curiously enough, they allowed their members to attend Orthodox churches. The central idea of Khlystys' ideology was to practice asceticism. Khlysty practiced the attainment of divine grace for sin in ecstatic rituals (called "ÑÐ°Ð´Ã©Ð½Ð¸Ñ", or radeniya) that were rumored to sometimes turn into sexual orgies.
Flagellation was also rumored, possibly due to the similarity of their name to the word for "whip".
Secret Khlysty cells existed throughout pre-revolutionary Russia (with approximately 40,000 followers in total); they were most common in the factories of the Perm district. Each cell was normally led by a male and a female leader, who were called the "Christ" and the "Mother of God" respectively. The cells themselves were referred to as 'Arks' among members and messages were carried between them clandestinely in order to facilitate communication. They were often subject to persecution and perceived as a subversive element by the nineteenth century Russian authorities and ecclesiastical bodies.
Rasputin.
In 1910, Grigori Rasputin was accused of having been a Khlyst by Sofia Ivanovna Tyutcheva, a governess of the Grand Duchesses of Russia, after being horrified that Rasputin was allowed access by the Tsar to the nursery of the Grand Duchesses, when the four girls were in their nightgowns.
C.L. Sulzberger, in his book "The Fall of Eagles", says that Rasputin "adopted the philosophy (if not proven membership)," of the Khlysts. Sulzberger goes on to say the Khlysts', "...foremost idea was that salvation could be attained only by total repentance and that this became far more achievable for one who had truly transgressed. 'Sin in order that you may obtain forgiveness,' was the practical side of the Khlysty."
Rasputin's daughter contested these claims, writing that her father investigated but ultimately rejected the sect.
Soviet era.
The number of cells dropped drastically in the Soviet times. However, a few secluded Khlysty communities existed in Soviet Russia in Tambov, Kuibyshev, Orenburg and Northern Caucasus and in Soviet Ukraine.

</doc>
<doc id="40157" url="https://en.wikipedia.org/wiki?curid=40157" title="Russian Orthodox Church">
Russian Orthodox Church

The Russian Orthodox Church (ROC; ), alternatively legally known as the Moscow Patriarchate (), is one of the autocephalous Eastern Orthodox churches, in full communion with other Eastern Orthodox patriarchates. The Primate of the ROC is the Patriarch of Moscow and all Rus'. The ROC, as well as the primate thereof, officially ranks fifth in the Orthodox order of precedence, immediately below the four ancient Patriarchates of the Greek Orthodox Church, those of Constantinople, Alexandria, Antioch, and Jerusalem. The official Christianization of Kievan Rus' widely seen as the birth of the ROC is believed to have occurred in 988 through the baptism of the Kievan prince Vladimir and his people by the clergy of the Ecumenical Patriarchate whose constituent part the ROC remained for the next six centuries, while the Kievan see remained in the jurisdiction of the Ecumenical Patriarchate until 1686.
The ROC currently claims its exclusive jurisdiction over the Orthodox Christians, irrespective of their ethnic background, who reside in the former member republics of the USSR, excluding Georgia and Armenia, although this claim is disputed in such countries as Estonia and Moldova and consequently parallel canonical Orthodox jurisdictions exist in those: Estonian Apostolic Orthodox Church and Metropolis of Bessarabia, respectively. It also exercises ecclesiastical jurisdiction over the autonomous Church of Japan and the Orthodox Christians resident in the People's Republic of China. The ROC branches in Belarus, Estonia, Latvia, Moldova and Ukraine since the 1990s enjoy various degrees of self-government, albeit short of the status of formal ecclesiastical autonomy. In Ukraine, ROC (represented by the Ukrainian Orthodox Church) has tensions with schismatic groups supported by the current government, while it enjoys the position of numerically dominant religious organisation.
The ROC should not be confused with the Orthodox Church in America (OCA), another autocephalous Orthodox Church (since 1970, albeit not universally recognised in this status), that traces its existence in North America to the time of the Russian missionaries in Alaska (then part of the Russian Empire) in the late 18th century, and still largely adheres to the ROC liturgical tradition.
The ROC should also not be confused with the Russian Orthodox Church Outside Russia (also known as the Russian Orthodox Church Abroad, or ROCOR), headquartered in New York, New York, U.S.A. The ROCOR was instituted in the 1920s by Russian communities outside then Communist Russia, which refused to recognize the authority of the Moscow Patriarchate then "de facto" headed by Metropolitan Sergius Stragorodsky. The two Churches reconciled on May 17, 2007; the ROCOR is now a self-governing part of the Russian Orthodox Church.
History.
The Kievan period.
The Christian community that developed into what is now known as the Russian Orthodox Church is traditionally said to have been founded by the Apostle Andrew, who is thought to have visited Scythia and Greek colonies along the northern coast of the Black Sea. According to one of the legends, Andrew reached the future location of Kiev and foretold the foundation of a great Christian city. The spot where he reportedly erected a cross is now marked by St. Andrew's Cathedral.
By the end of the first millennium AD, eastern Slavic lands started to come under the cultural influence of the Eastern Roman Empire. In 863â69, the Byzantine Greek monks Saint Cyril and Saint Methodius, both from Greek Macedonia, translated parts of the Bible into Old Church Slavonic language for the first time, paving the way for the Christianization of the Slavs and Slavicized peoples of Eastern Europe, the Balkans, and Southern Russia. There is evidence that the first Christian bishop was sent to Novgorod from Constantinople either by Patriarch Photius or Patriarch Ignatios, c. 866â67.
By the mid-10th century, there was already a Christian community among Kievan nobility, under the leadership of Byzantine Greek priests, although paganism remained the dominant religion. Princess Olga of Kiev was the first ruler of Kievan Rusâ² to convert to Christianity, either in 945 or 957. Her grandson, Vladimir of Kiev, made Rus' officially a Christian state. The official Christianization of Kievan Rus' is widely believed to have occurred in 988 AD, when Prince Vladimir was baptised himself and ordered his people to be baptised by the priests from the Eastern Roman Empire.
The Kievan church was a junior metropolitanate of the Patriarchate of Constantinople and the Ecumenical patriarch appointed the metropolitan, who usually was a Greek, who governed the Church of Rus'. The Metropolitan's residence was originally located in Kiev itself, the capital of the medieval Rus' state.
Transfer of the see to Moscow; "de facto" independence of the Moscow Church.
As Kiev was losing its political, cultural, and economical significance due to the Mongol invasion, Metropolitan Maximus moved to Vladimir in 1299; his successor, Metropolitan Peter moved the residence to Moscow in 1325.
Following the tribulations of the Mongol invasion, the Russian Church was pivotal in the survival and life of the Russian state. Despite the politically motivated murders of Mikhail of Chernigov and Mikhail of Tver, the Mongols were generally tolerant and even granted tax exemption to the Church. Such holy figures as Sergius of Radonezh and Metropolitan Alexis helped the country to withstand years of Tatar oppression, and to expand both economically and spiritually. The Trinity monastery founded by Sergius of Radonezh became the setting for the flourishing of spiritual art, exemplified by the work of Andrey Rublev, among others. The followers of Sergius founded four hundred monasteries, thus greatly extending the geographical extent of the Grand Duchy of Moscow.
In 1439, at the Council of Florence, some Orthodox hierarchs from Byzantium as well as Metropolitan Isidore, who represented the Russian Church, signed a union with the Roman Church, whereby the Eastern Church would recognise the primacy of the Pope. However, the Moscow Prince Vasili II rejected the act of the Council of Florence brought to Moscow by Isidore in March 1441. Isidore was in the same year removed from his position as an apostate and expelled from Moscow. The Russian metropolitanate remained effectively vacant for the next few years due largely to the dominance of Uniates in Constantinople then. In December 1448, Jonas, a Russian bishop, was installed by the Council of Russian bishops in Moscow as Metropolitan of Kiev and All Russia (with permanent residence in Moscow) without the consent from Constantinople. This occurred five years prior to the fall of Constantinople in 1453 and, unintentionally, signified the beginning of an effectively independent church structure in the Moscow (North-Eastern Russian) part of the Russian Church. Subsequently, there developed a theory in Moscow that saw Moscow as the Third Rome, the legitimate successor to Constantinople, and the Primate of the Moscow Church as head of all the Russian Church. Meanwhile, the newly established in 1458 Russian Orthodox (initially Uniate) metropolitanate in Kiev (then in the Grand Duchy of Lithuania and subsequently in the PolishâLithuanian Commonwealth) continued under the jurisdiction of the Ecumenical See until 1686, when it was transferred to the jurisdiction of Moscow.
The reign of Ivan III and his successor was plagued by a number of heresies and controversies. One party, led by Nil Sorsky and Vassian Kosoy, called for the secularisation of monastic properties. They were opposed by the influential Joseph of Volotsk, who defended ecclesiastical ownership of land and property. The sovereign's position fluctuated, but eventually he threw his support to Joseph. New sects sprang up, some of which showed a tendency to revert to Mosaic law: for instance, the archpriest Aleksei converted to Judaism after meeting a certain Zechariah the Jew.
In the 1540s, Metropolitan Macarius codified Russian hagiography and convened a number of church synods, which culminated in the Hundred Chapter Council of 1551. This Council unified church ceremonies and duties throughout the Moscow Church. At the demand of the church hierarchy, the government lost its jurisdiction over ecclesiastics. Reinforced by these reforms, the Moscow Church felt powerful enough to occasionally challenge the policies of the tsar. Metropolitan Philip, in particular, decried the abuses of Ivan the Terrible, who eventually engineered his deposition and murder.
Autocephaly and schism.
During the reign of Tsar Fyodor I his brother-in-law Boris Godunov contacted the Ecumenical Patriarch, who "was much embarrassed for want of funds," with a view to establishing a patriarchal see in Moscow. As a result of Godunov's efforts, Metropolitan Job of Moscow became in 1589 the first Patriarch of Moscow and All Rus', making the Russian Church autocephalous. The four other patriarchs have recognized the Moscow Patriarchate as one of the five honourable Patriarchates. During the next half a century, when the tsardom was weak, the patriarchs (notably Hermogenes and Philaret) would help run the state along with (and sometimes instead of) the tsars.
At the urging of the Zealots of Piety, in 1652 Patriarch Nikon resolved to centralize power that had been distributed locally, while conforming Russian Orthodox rites and rituals to those of the Greek Orthodox Church, as interpreted by pundits from the Kiev Ecclesiastical Academy. For instance, he insisted that Russian Christians cross themselves with three fingers, rather than the then-traditional two. This aroused antipathy among a substantial section of believers, who saw the changed rites as heresy, although the extent to which these changes can be regarded as minor or major ritual significance remains open to debate. After the implementation of these innovations at the church council of 1666â1667, the Church anathematized and suppressed those who acted contrary to them with the support of Muscovite state power. These traditionalists became known as "Old Believers" or "Old Ritualists".
Although Nikon's far-flung ambitions of steering the country to a theocratic form of government precipitated his defrocking and exile, Tsar Aleksey deemed it reasonable to uphold many of his innovations. During the Schism of the Russian Church, the Old Ritualists were separated from the main body of the Orthodox Church. Archpriest Avvakum Petrov and many other opponents of the church reforms were burned at the stake, either forcibly or voluntarily. Another prominent figure within the Old Ritualists' movement, Boyarynya Morozova, was starved to death in 1675. Others escaped from the government persecutions to Siberia.
Several years after the Council of Pereyaslav (1654) that heralded the subsequent incorporation of eastern regions of the PolishâLithuanian Commonwealth into the Tsardom of Russia, the see of the Metropolitan of Kiev and all Rus' was transferred to the Moscow patriarchate (1686).
Peter the Great.
Peter the Great (1682â1725) had an agenda of radical modernization of Russian government, army, dress and manners. He made Russia a formidable political power. Peter was not religious and had a low regard for the Church, so he put it under tight governmental control. He replaced the Patriarch with a Holy Synod, which he controlled. The Tsar appointed all bishops. A clerical career was not a route chosen by upper-class society. Most parish priests were sons of priests, Were very poorly educated, and very poorly paid. The monks in the monasteries had a slightly higher status; they were not allowed to marry. Politically, the church was impotent. Catherine the Great later in the 18th century seized most of the church lands, and put the priests on a small salary supplemented by fees for services such as baptism and marriage.
Expansion.
In the late 17th and early 18th centuries, the Russian Orthodox Church experienced a vast geographic expansion. Numerous financial and political incentives (as well as immunity from military service) were offered local political leaders who would convert to Orthodoxy, and bring their people with them.
In the following two centuries, missionary efforts stretched out across Siberia into Alaska. Eminent people on that missionary effort included St. Innocent of Irkutsk and St. Herman of Alaska. In emulation of Stephen of Perm, they learned local languages and translated gospels and hymns. Sometimes those translations required the invention of new systems of transcription.
In the aftermath of the Treaty of Pereyaslav, the Ottomans (supposedly acting on behalf of the Russian regent Sophia Alekseyevna) pressured the Patriarch of Constantinople into transferring the Metropoly of Kiev from the jurisdiction of Constantinople to that of Moscow. The controversial transfer brought millions of faithful and half a dozen dioceses under the pastoral and administrative care of the Patriarch of Moscow and all Rus', leading to the significant Ukrainian domination of the Russian Orthodox Church, which continued well into the 18th century, with Theophanes Prokopovich, Epiphanius Slavinetsky, Stephen Yavorsky and Demetrius of Rostov being among the most notable representatives of this trend.
In 1700, after Patriarch Adrian's death, Peter the Great prevented a successor from being named, and in 1721, following the advice of Feofan Prokopovich, Archbishop of Pskov, the Holy and Supreme Synod was established under Archbishop Stephen Yavorsky to govern the church instead of a single primate. This was the situation until shortly after the Russian Revolution of 1917, at which time the Local Council (more than half of its members being lay persons) adopted the decision to restore the Patriarchy. On November 5 (according to the Julian calendar) a new patriarch, Tikhon, was named through casting lots.
The late 18th century saw the rise of "starchestvo" under Paisiy Velichkovsky and his disciples at the Optina Monastery. This marked a beginning of a significant spiritual revival in the Russian Church after a lengthy period of modernization, personified by such figures as Demetrius of Rostov and Platon of Moscow. Aleksey Khomyakov, Ivan Kireevsky and other lay theologians with Slavophile leanings elaborated some key concepts of the renovated Orthodox doctrine, including that of "sobornost". The resurgence of Eastern Orthodoxy was reflected in Russian literature, an example is the figure of Starets Zosima in Fyodor Dostoyevsky's "Brothers Karamazov".
Fin-de-siÃ¨cle religious renaissance.
During the final decades of the imperial order in Russia many educated Russians sought to return to the church and tried to bring their faith back to life. No less evident were non-conformist paths of spiritual searching known as "God-Seeking". Writers, artists and intellectuals in large numbers were drawn to private prayer, mysticism, spiritualism, theosophy and Eastern religions. A fascination with primitive feeling, with the unconscious and the mythic was apparent, along with visions of coming catastrophes and redemption.
In 1909, a volume of essays appeared under the title "Vekhi" ("Milestones" or "Landmarks"), authored by a group of leading left-wing intellectuals, including Sergei Bulgakov, Peter Struve and former Marxists. They bluntly repudiated the materialism and atheism that had dominated the thought of the intelligentsia for generations as leading inevitably to failure and moral disaster. The essays created a sensation.
It is possible to see a similarly renewed vigor and variety in religious life and spirituality among the lower classes, especially after the upheavals of 1905. Among the peasantry there was widespread interest in spiritual-ethical literature and non-conformist moral-spiritual movements, an upsurge in pilgrimage and other devotions to sacred spaces and objects (especially icons), persistent beliefs in the presence and power of the supernatural (apparitions, possession, walking-dead, demons, spirits, miracles and magic), the renewed vitality of local "ecclesial communities" actively shaping their own ritual and spiritual lives, sometimes in the absence of clergy, and defining their own sacred places and forms of piety. Also apparent was the proliferation of what the Orthodox establishment branded as "sectarianism", including both non-Orthodox Christian denominations, notably Baptists, and various forms of popular Orthodoxy and mysticism.
Russian revolution.
In 1914 there were 55,173 Russian Orthodox churches and 29,593 chapels, 112,629 priests and deacons, 550 monasteries and 475 convents with a total of 95,259 monks and nuns in Russia.
The year 1917 was a major turning point in Russian history, and also the Russian Orthodox Church. The Russian empire was dissolved and the Tsarist government - which had granted the Church numerous privileges - was overthrown. After a few months of political turmoil, the Bolsheviks took power in October 1917 and declared a separation of church and state. Thus the Russian Orthodox Church found itself without official state backing for the first time in its history. One of the first decrees of the new Communist government (issued in January 1918) declared freedom from "religious and anti-religious propaganda". This led to a marked decline in the power and influence of the Church. The Church was also caught in the crossfire of the Russian Civil War that began later the same year, and many leaders of the Church supported what would ultimately turn out to be the losing side (the White movement).
The Russian Orthodox Church supported the White Army in the Russian Civil War (see White movement) after the October Revolution. This may have further strengthened the Bolshevik antipathy against the church. Actually as early as 1905, Lenin, leader of the Bolshevik party, berated religion in Novaya Zhizn in 1905 "... Religion is opium for the people. Religion is a sort of spiritual booze, in which the slaves of capital drown their human image, their demand for a life more or less worthy of man..."
Even before the end of the civil war and the establishment of the Soviet Union, the Russian Orthodox Church came under pressure from the secular Communist government. The Soviet government stood on a platform of antireligion, viewing the church as a "counter-revolutionary" organization and an independent voice with a great influence in society. While the Soviet Union officially claimed religious tolerance, in practice the government discouraged organized religion and did much to remove religious influence from Soviet society.
Under Communist rule.
Lenin era.
After the October Revolution of November 7, 1917, the officially proclaimed objective of the Soviet Union was to unite all of the people of the world in a Communist state free of "capitalist exploitation" (see Communist International). With such a view of the world any ethnic heritage closely tied to traditional religion and its clergy was targeted by Soviet authorities.
The Soviet Union was the first state to have elimination of religion as an ideological objective. Toward that end, the Communist regime confiscated church property, ridiculed religion, harassed believers, and propagated atheism in schools. Actions toward particular religions, however, were determined by State interests, and most organized religions were never outlawed.
It is alleged that Orthodox priests and believers were variously tortured and sent to prison camps, labour camps or mental hospitals. Many Orthodox (along with people of other faiths) were also subjected to psychological punishment or torture and mind control experimentation in order to force them give up their religious convictions.
Thousands of churches and monasteries were taken over by the government and either destroyed or converted to secular use. It was impossible to build new churches. Practising Orthodox Christians were restricted from prominent careers and membership in communist organizations (the party, the Komsomol). Anti-religious propaganda was openly sponsored and encouraged by the government, which the Church was not given an opportunity to publicly respond to. The government youth organization, the Komsomol, encouraged its members to vandalize Orthodox churches and harass worshippers. Seminaries were closed down, and the church was restricted from using the press.
The history of Orthodoxy (and other religions) under Communism was not limited to this story of repression and secularization. Bolshevik policies toward religious belief and practice tended to vacillate over time between, on the one hand, a utopian determination to substitute secular rationalism for what they considered to be an unmodern, "superstitious" worldview and, on the other, pragmatic acceptance of the tenaciousness of religious faith and institutions. In any case, religious beliefs and practices did persist, not only in the domestic and private spheres but also in the scattered public spaces allowed by a state that recognized its failure to eradicate religion and the political dangers of an unrelenting culture war.
In August 1917, following the collapse of the tsarist government, a council of the Russian Orthodox church reestablished the patriarchate and elected the metropolitan Tikhon, the former Metropolitan of All America and Canada, as patriarch. But the new Soviet government soon declared the separation of church and state and also nationalized all church-held lands. These administrative measures were followed by brutal state-sanctioned persecutions that included the wholesale destruction of churches, as well as the arrest and execution of many clerics. The Russian Orthodox church was further weakened in 1922, when the Renovated Church, a reform movement supported by the Soviet government, seceded from Patriarch Tikhon's church (also see the Josephites and the Russian True Orthodox Church), restored a Holy Synod to power, and brought division among clergy and faithful.
In the first five years after the Bolshevik revolution, 28 bishops and 1,200 priests were executed.
Stalin era.
The main target of the anti-religious campaign in the 1920s and 1930s was the Russian Orthodox Church, which had the largest congregation. Nearly all of its clergy, and many of its believers, were shot or sent to labor camps. Theological schools were closed, and church publications were prohibited.
The sixth sector of the OGPU, led by Yevgeny Tuchkov, began aggressively arresting and executing bishops, priests, and devout worshippers, such as Metropolitan Veniamin in Petrograd in 1922 for refusing to accede to the demand to hand in church valuables (including sacred relics). In the time between 1927 and 1940, the number of Orthodox Churches in the Russian Republic fell from 29,584 to less than 500. Between 1917 and 1935, 130,000 Orthodox priests were arrested. Of these, 95,000 were put to death. Many thousands of victims of persecution became recognized in a special canon of saints known as the "new martyrs and confessors of Russia".
In January 1918 Patriarch Tikhon proclaimed anathema to the Bolsheviks (without explicitly naming them), which further antagonized relations. When Tikhon died in 1925, Soviet authorities forbade patriarchal elections to be held. Patriarchal "locum tenens" (acting Patriarch) Metropolitan Sergius (Stragorodsky, 1887â1944), going against the opinion of a major part of the church's parishes, in 1927 issued a declaration accepting the Soviet authority over the church as legitimate, pledging the church's cooperation with the government and condemning political dissent within the church. By this declaration Sergius granted himself authority that he, being a deputy of imprisoned Metropolitan Peter and acting against his will, had no right to assume according to the XXXIV Apostolic canon, which led to a split with the Russian Orthodox Church Outside of Russia abroad and the Russian True Orthodox Church (Russian Catacomb Church) within the Soviet Union, as they allegedly remained faithful to the Canons of the Apostles, declaring the part of the church led by Metropolitan Sergius schism, sometimes coined "Sergianism". Due to this canonical disagreement it is disputed which church has been the legitimate successor to the Russian Orthodox Church that had existed before 1925.
Moreover, in the 1929 elections, the Orthodox Church attempted to formulate itself as a full-scale opposition group to the Communist Party, and attempted to run candidates of its own against the Communist candidates. Article 124 of the 1936 Soviet Constitution officially allowed for freedom of religion within the Soviet Union, and along with initial statements of it being a multi-candidate election, the Church again attempted to run its own religious candidates in the 1937 elections. However the support of multicandidate elections was retracted several months before the elections were held and in neither 1929 nor 1937 were any candidates of the Orthodox Church elected.
After Nazi Germany's attack on the Soviet Union in 1941, Joseph Stalin revived the Russian Orthodox Church to intensify patriotic support for the war effort. On September 4, 1943, Metropolitans Sergius, Alexy and Nikolay had a meeting with Stalin and received a permission to convene a council on September 8, 1943, which elected Sergius Patriarch of Moscow and all the Rus'. This is considered by some as violation of the XXX Apostolic canon, as no church hierarch could be consecrated by secular authorities. A new patriarch was elected, theological schools were opened, and thousands of churches began to function. The Moscow Theological Academy Seminary, which had been closed since 1918, was re-opened.
Between 1945 and 1959 the official organization of the church was greatly expanded, although individual members of the clergy were occasionally arrested and exiled. The number of open churches reached 25,000. By 1957 about 22,000 Russian Orthodox churches had become active. But in 1959 Nikita Khrushchev initiated his own campaign against the Russian Orthodox Church and forced the closure of about 12,000 churches. By 1985 fewer than 7,000 churches remained active. Members of the church hierarchy were jailed or forced out, their places taken by docile clergy, many of whom had ties with the KGB. This decline was evident from the dramatic decay of many of the abandoned churches and monasteries that were previously common in even the smallest villages from the pre-revolutionary period.
Persecution under Khrushchev.
A new and widespread persecution of the church was subsequently instituted under the leadership of Nikita Khrushchev and Leonid Brezhnev. A second round of repression, harassment and church closures took place between 1959 and 1964 when Nikita Khrushchev was in office.
The Church and the government remained on unfriendly terms until 1988. In practice, the most important aspect of this conflict was that openly religious people could not join the Communist Party of the Soviet Union, which meant that they could not hold any political office. However, among the general population, large numbers remained religious.
Some Orthodox believers and even priests took part in the dissident movement and became prisoners of conscience. The Orthodox priests Gleb Yakunin, Sergiy Zheludkov and others spent years in Soviet prisons and exile for their efforts in defending freedom of worship. Among the prominent figures of that time were Father Dmitri Dudko and Father Aleksandr Men. Although he tried to keep away from practical work of the dissident movement intending to better fulfil his calling as a priest, there was a spiritual link between Fr Aleksandr and many of the dissidents. For some of them he was a friend, for others - a godfather, for many (including Yakunin) - spiritual father.
By 1987 the number of functioning churches in the Soviet Union had fallen to 6893 and the number of functioning monasteries to just 18. In 1987 in the Russian SFSR, between 40% and 50% of newborn babies (depending on the region) were baptized. Over 60% of all deceased received Christian funeral services.
Glasnost and evidence of KGB links.
Beginning in the late 1980s, under Mikhail Gorbachev, the new political and social freedoms resulted in many church buildings being returned to the church, to be restored by local parishioners. A pivotal point in the history of the Russian Orthodox Church came in 1988 - the millennial anniversary of the Baptism of Kievan Rus'. Throughout the summer of that year, major government-supported celebrations took place in Moscow and other cities; many older churches and some monasteries were reopened. An implicit ban on religious propaganda on state TV was finally lifted. For the first time in the history of the Soviet Union, people could see live transmissions of church services on television.
Gleb Yakunin, a critic of the Moscow Patriarchate who was one of those who briefly gained access to the KGB archive documents in the early 1990s, argued that the Moscow Patriarchate was "practically a subsidiary, a sister company of the KGB". Critics charge that the archives showed the extent of active participation of the top ROC hierarchs in the KGB efforts overseas. George Trofimoff, the highest-ranking US military officer ever indicted for, and convicted of, espionage by the United States and sentenced to life imprisonment on September 27, 2001, had been "recruited into the service of the KGB" by Igor Susemihl (a.k.a. Zuzemihl), a bishop in the Russian Orthodox Church (subsequently, a high-ranking hierarchâthe ROC Metropolitan Iriney of Vienna, who died in July 1999).
Konstanin Kharchev, former chairman of the Soviet Council on Religious Affairs, explained: "Not a single candidate for the office of bishop or any other high-ranking office, much less a member of Holy Synod, went through without confirmation by the Central Committee of the CPSU and the KGB". Professor Nathaniel Davis points out: "If the bishops wished to defend their people and survive in office, they had to collaborate to some degree with the KGB, with the commissioners of the Council for Religious Affairs, and with other party and governmental authorities.". Patriarch Alexy II, acknowledged that compromises were made with the Soviet government by bishops of the Moscow Patriarchate, himself included, and publicly repented of these compromises 
Post-Soviet recovery and problems.
Under Patriarch Aleksey II (1990â2008).
Metropolitan Alexy (Ridiger) of Leningrad, ascended the patriarchal throne in 1990 and presided over the partial return of Orthodox Christianity to Russian society after 70 years of repression, transforming the ROC to something resembling a state religion; some 15,000 churches had been re-opened or built by the end of his reign. The Russian Church also sought to fill the ideological vacuum left by the collapse of Communism and even, in the opinion of some analysts, became "a separate branch of power".
In August 2000 the ROC adopted its Basis of the Social Concept and in July 2008 its Basic Teaching on Human Dignity, Freedom and Rights.
Under Patriarch Aleksey, there were difficulties in the relationship between the Russian Orthodox Church and the Vatican, especially since 2002, when Pope John Paul II created a Catholic diocesan structure for Russian territory. The leaders of the Russian Church saw this action as a throwback to prior attempts by the Vatican to proselytize the Russian Orthodox faithful to become Roman Catholic. This point of view was based upon the stance of the Russian Orthodox Church (and the Eastern Orthodox Church) that the Church of Rome is in schism, after breaking off from the Orthodox Church. The Roman Catholic Church, on the other hand, while acknowledging the primacy of the Russian Orthodox Church in Russia, believed that the small Roman Catholic minority in Russia, in continuous existence since at least the 18th century, should be served by a fully developed church hierarchy with a presence and status in Russia, just as the Russian Orthodox Church is present in other countries (including constructing a cathedral in Rome, near the Vatican).
There occurred strident conflicts with the Ecumenical Patriarchate, most notably over the Orthodox Church in Estonia in the mid-1990s, which resulted in unilateral suspension of eucharistic relationship between the churches by the ROC. The tension lingered on and could be observed at the meeting in Ravenna in early October 2007 of participants in the OrthodoxâCatholic Dialogue: the representative of the Moscow Patriarchate, Bishop Hilarion Alfeyev, walked out of the meeting due to the presence of representatives from the Estonian Apostolic Orthodox Church which is in the jurisdiction of the Ecumenical Patriarchate. At the meeting, prior to the departure of the Russian delegation, there were also substantive disagreements about the wording of a proposed joint statement among the Orthodox representatives. After the departure of the Russian delegation, the remaining Orthodox delegates approved the form which had been advocated by the representatives of the Ecumenical Patriarchate. The Ecumenical See's representative in Ravenna said that Hilarion's position "should be seen as an expression of authoritarianism whose goal is to exhibit the influence of the Moscow Church. But like last year in Belgrade, all Moscow achieved was to isolate itself once more since no other Orthodox Church followed its lead, remaining instead faithful to Constantinople."
Canon Michael Bourdeaux, former president of the Keston Institute, said in January 2008 that "the Moscow Patriarchate acts as though it heads a state church, while the few Orthodox clergy who oppose the church-state symbiosis face severe criticism, even loss of livelihood." Such a view is backed up by other observers of Russian political life. Clifford J. Levy of "The New York Times" wrote in April 2008: "Just as the government has tightened control over political life, so, too, has it intruded in matters of faith. The Kremlin's surrogates in many areas have turned the Russian Orthodox Church into a de facto official religion, warding off other Christian denominations that seem to offer the most significant competition for worshipers. [â¦] This close alliance between the government and the Russian Orthodox Church has become a defining characteristic of Mr. Putin's tenure, a mutually reinforcing choreography that is usually described here as working 'in symphony'."
Throughout Patriarch Alexy's reign, the massive-scale program of costly restoration of re-opened churches and monasteries (as well as the construction of new ones) was criticized for having eclipsed the church's principal mission of evangelizing.
On 5 December 2008, the day of Patriarch Alexy's death, the "Financial Times" said: "While the church had been a force for liberal reform under the Soviet Union, it soon became a center of strength for conservatives and nationalists in the post-communist era. Alexei's death could well result in an even more conservative church."
Under Patriarch Kirill.
On January 27, 2009, the ROC Local Council (the 2009 Pomestny Sobor) elected Metropolitan Kirill of Smolensk Patriarch of Moscow and All Rus; with 508 votes out of 700. He was enthroned on February 1, 2009.
In 2010, news broke of a child abuse scandal involving a monastery in the city of Vladimir, where children are said to have been "hit multiple times, forced to do agricultural labor from 3 a.m. till 10 p.m. with 30-minute breaks for breakfast and lunch".
In February 2011 the official spokesman of the Synodal Department of the Patriarchate denied reports that the Church was about to merge with the Russian State. He said, "The Russian Church has never in its history been so independent of the state as it is now. It treasures this independence. However, it also treasures the dialogue that it has with the modern state. No doubt, this dialogue cannot be called easy, but it can be called constructive". At a conference at the Moscow State University on September 2012 Patriarch Kirill said church is not interested in obtaining state powers or even a state status "as in certain European countries".
Structure and organization.
Overview.
The ROC constituent parts in other than the Russian Federation countries of its exclusive jurisdiction such as Ukraine, Belarus et al., are legally registered as separate legal entities in accordance with the relevant legislation of those independent states.
Ecclesiastiacally, the ROC is organized in a hierarchical structure. The lowest level of organization, which normally would be a single ROC building and its attendees, headed by a priest who acts as Father superior (, "nastoyatel"), constitute a parish (, "prihod"). All parishes in a geographical region belong to an eparchy ( â equivalent to a Western diocese). Eparchies are governed by bishops (, episcop or Ð°ÑÑÐ¸ÐµÑÐµÐ¹, archiereus). There are 261 Russian Orthodox eparchies worldwide (June 2012).
Further, some eparchies may be organized into exarchates (currently the Belorussian exarchate), and since 2003 into metropolitan districts (Ð¼Ð¸ÑÑÐ¾Ð¿Ð¾Ð»Ð¸ÑÐ¸Ð¹ Ð¾ÐºÑÑÐ³), such as the ROC eparchies in Kazakhstan and the Central Asia (Ð¡ÑÐµÐ´Ð½ÐµÐ°Ð·Ð¸Ð°ÑÑÐºÐ¸Ð¹ Ð¼Ð¸ÑÑÐ¾Ð¿Ð¾Ð»Ð¸ÑÐ¸Ð¹ Ð¾ÐºÑÑÐ³).
Since the early 1990s, the ROC eparchies in some newly independent states of the former USSR enjoy the status of self-governing Churches within the Moscow Patriarchate (which status, according to the ROC legal terminology, is distinct from the â³autonomousâ³ one): the Estonian Orthodox Church of Moscow Patriarchate, Latvian Orthodox Church, Moldovan Orthodox Church, Ukrainian Orthodox Church, the last one being virtually fully independent in administrative matters. Similar status, since 2007, is enjoyed by the Russian Orthodox Church Outside of Russia (previously fully independent and deemed schismatic by the ROC). The Chinese Orthodox Church and the Japanese Orthodox Churches were granted full autonomy by the Moscow Patriarchate, but this autonomy is not universally recognized.
Smaller eparchies are usually governed by a single bishop. Larger eparchies, exarchates, and self-governing Churches are governed by a Metropolitan archbishop and sometimes also have one or more bishops assigned to them.
The highest level of authority in the ROC is vested in the Local Council ("Pomestny Sobor"), which comprises all the bishops as well as representatives from the clergy and laypersons. Another organ of power is the Bishops' Council ("ÐÑÑÐ¸ÐµÑÐµÐ¹ÑÐºÐ¸Ð¹ Ð¡Ð¾Ð±Ð¾Ñ"). In the periods between the Councils the highest administrative powers are exercised by the Holy Synod of the Russian Orthodox Church, which includes seven permanent members and is chaired by the Patriarch of Moscow and All Russia, Primate of the Moscow Patriarchate.
Although the Patriarch of Moscow enjoys extensive administrative powers, unlike the Pope, he has no direct canonical jurisdiction outside the diocese of Moscow, nor does he have single-handed authority over matters pertaining to faith as well as issues concerning the entire Orthodox Christian community such as the Catholic-Orthodox split.
Orthodox Church in America (OCA).
Russian traders settled in Alaska during the 18th century. In 1740, a Divine Liturgy was celebrated on board a Russian ship off the Alaskan coast. In 1794, the Russian Orthodox Church sent missionariesâamong them Saint Herman of Alaskaâto establish a formal mission in Alaska. Their missionary endeavors contributed to the conversion of many Alaskan natives to the Orthodox faith. A diocese was established, whose first bishop was Saint Innocent of Alaska. The headquarters of this North American Diocese of the Russian Orthodox Church was moved from Alaska to California around the mid-19th century.
It was moved again in the last part of the same century, this time to New York, New York. This transfer coincided with a great movement of Greek-Catholics to the Orthodox Church in the East of the United States. This movement, which increased the numbers of Orthodox Christians in America, resulted from a conflict between John Ireland, the politically powerful Roman Catholic Archbishop of Saint Paul, Minnesota; and Alexis Toth, an influential Ruthenian Catholic priest of St. Mary's church in Minneapolis. Archbishop Ireland's refusal to accept Fr. Toth's credentials as a priest induced Fr. Toth to convert St. Mary's to the Orthodox Church, and further resulted in the conversion of tens of thousands of other Greek-Catholics in North America to the Orthodox Church under his guidance and inspiration. For this reason, Ireland is sometimes ironically remembered as the "Father of the Orthodox Church in America". These Greek-Catholics were received into Orthodoxy into the existing North American diocese of the Russian Orthodox Church. At the same time large numbers of Greeks and other Orthodox Christians were also immigrating to America. At this time all Orthodox Christians in North America were united under the "omophorion" (church authority and protection) of the Patriarch of Moscow, through the Russian Church's North American diocese. The unity was not merely theoretical, but was a reality, since there was then no other diocese on the continent. Under the aegis of this diocese, which at the turn of the 20th century was ruled by Bishop (and future Patriarch) Tikhon, Orthodox Christians of various ethnic backgrounds were ministered to, both non-Russian and Russian; a Syro-Arab mission was established under the episcopal leadership of Saint Raphael of Brooklyn, who was the first Orthodox bishop to be consecrated in America.
In 1920 Patriarch Tikhon issued an "ukase" (decree) that "dioceses" of the Church of Russia that were cut off from the governance of the highest Church authority (i.e. the Holy Synod and the Patriarch) should be managed independently until such time as normal relations with the highest Church authority could be resumed; and on this basis, the North American diocese of the Russian Orthodox Church (known as the "Metropolia") continued to exist in a "de facto" autonomous mode of self-governance. The financial hardship that beset the North American diocese as the result of the Russian Revolution resulted in a degree of administrative chaos, with the result that other national Orthodox communities in North America turned to the churches in their respective homelands for pastoral care and governance.
A group of bishops who had left Russia in the wake of the Russian Civil War gathered in Sremski-Karlovci, Yugoslavia, and adopted a pro-monarchist stand. The group further claimed to speak as a synod for the entire "free" Russian church. This group, which to this day includes a sizable portion of the Russian emigration, was formally dissolved in 1922 by Patriarch Tikhon, who then appointed metropolitans Platon and Evlogy as ruling bishops in America and Europe, respectively. Both of these metropolitans continued to entertain relations intermittently with the synod in Karlovci.
Between the World Wars, the Metropolia coexisted and at times cooperated with an independent synod later known as Russian Orthodox Church Outside Russia (ROCOR), sometimes also called the Russian Orthodox Church Abroad. The two groups eventually went their separate ways. ROCOR, which moved its headquarters to North America after the Second World War, claimed but failed to establish jurisdiction over all parishes of Russian origin in North America. The Metropolia, as a former diocese of the Russian Church, looked to the latter as its highest church authority, albeit one from which it was temporarily cut off under the conditions of the Communist regime in Russia.
After World War II the Patriarchate of Moscow made unsuccessful attempts to regain control over these groups. After resuming communication with Moscow in early 1960s, and being granted autocephaly in 1970, the Metropolia became known as the Orthodox Church in America. However, recognition of this autocephalous status is not universal, as the Ecumenical Patriarch (under whom is the Greek Orthodox Archdiocese of America) and some other jurisdictions have not officially accepted it. The reasons for this are complex; nevertheless the Ecumenical Patriarch and the other jurisdictions remain in communion with the OCA. The Patriarchate of Moscow thereby renounced its former canonical claims in the United States and Canada; it also acknowledged an autonomous church established in Japan that same year.
Russian Orthodox Church Outside Russia (ROCOR).
Russia's Church was devastated by the repercussions of the Bolshevik Revolution. One of its effects was a flood of refugees from Russia to the United States, Canada, and Europe. The Revolution of 1918 severed large sections of the Russian churchâdioceses in America, Japan, and Manchuria, as well as refugees in Europeâfrom regular contacts with the main church.
Based on an "ukase" (decree) issued by Patriarch Tikhon, which stated that "dioceses" of the Church of Russia that were cut off from the governance of the highest Church authority (i.e. the Holy Synod and the Patriarch) should be managed independently until such time as normal relations with the highest Church authority could be resumed, the Russian Orthodox Church Outside of Russia was established; by bishops who had left Russia in the wake of the Russian Civil War. They first met in Constantinople, and then moved to Sremski-Karlovci, Yugoslavia. After World War II, they moved their headquarters to New York City, New York, where it remains to this day.
On December 28, 2006, it was officially announced that the Act of Canonical Communion would finally be signed between the ROC and ROCOR. The signing took place on the May 17, 2007, followed immediately by a full restoration of communion with the Moscow Patriarchate, celebrated by a Divine Liturgy at the Cathedral of Christ the Saviour in Moscow, at which the Patriarch of Moscow and All Russia Alexius II and the First Hierarch of ROCOR concelebrated for the first time.
Under the Act, the ROCOR remains a self-governing entity within the Church of Russia. It is independent in its administrative, pastoral, and property matters. It continues to be governed by its Council of Bishops and its Synod, the Council's permanent executive body. The First-Hierarch and bishops of the ROCOR are elected by its Council and confirmed by the Patriarch of Moscow. ROCOR bishops participate in the Council of Bishops of the entire Russian Church.
In response to the signing of the act of canonical communion, Bishop Agafangel and parishes and clergy in opposition to the Act broke communion with ROCOR, and established ROCA, or the Russian Orthodox Church Abroad. Some others opposed to the Act have joined themselves to other Greek Old Calendarist groups.
Currently both the OCA and ROCOR, since 2007, are in communion with the ROC.
Self-governing branches of ROC.
The Russian Orthodox Church has four levels of self-government.
Worship and practices.
Canonization.
In accordance with the practice of the Orthodox Church, a particular hero of faith can initially be canonized only at a local level within local churches and eparchies. Such rights belong to the ruling hierarch and it can only happen when the blessing of the patriarch is received. The task of believers of the local eparchy is to record descriptions of miracles, to create the hagiography of a saint, to paint an icon, as well as to compose a liturgical text of a service where the saint is glorified. All of this is sent to the Synodal Commission for canonization which decides whether to canonize the local hero of faith or not. Then the patriarch gives his blessing and the local hierarch performs the act of canonization at the local level. However, the liturgical texts in honor of a saint are not published in all Church books but only in local publications. In the same way these saints are not yet glorified and venerated by the whole Church, only locally. When the glorification of a saint exceeds the limits of an eparchy, then the patriarch and Holy Synod decides about their canonization on the Church level. After receiving the Synodâs support and the patriarchâs blessing, the question of glorification of a particular saint on the scale of the entire Church is given for consideration to the Local Council of the Russian Orthodox Church.
In the period following the revolution, and during the communist persecutions up to 1970, no canonizations took place. Only in 1970 did the Holy Synod made a decision to canonize a missionary to Japan, Nicholas Kasatkin (1836â1912). In 1977, St. Innocent of Moscow (1797â1879), the Metropolitan of Siberia, the Far East, the Aleutian Islands, Alaska, and Moscow was also canonized. In 1978 it was proclaimed that the Russian Orthodox Church had created a prayer order for Meletius of Kharkov, which practically signified his canonization because that was the only possible way to do it at that time. Similarly, the saints of other Orthodox Churches were added to the Church calendar: in 1962 St. John the Russian, in 1970 St. Herman of Alaska, in 1993 Silouan the Athonite, the elder of Mount Athos, already canonized in 1987 by the Ecumenical Patriarchate of Constantinople. In the 1980s the Russian Orthodox Church re-established the process for canonization; a practice that had ceased for half a century.
In 1989 the Holy Synod established the Synodal Commission for canonization. The 1990 Local Council of the Russian Orthodox Church gave an order for the Synodal Commission for Canonisation to prepare documents for canonization of new martyrs who had suffered from the 20th century Communist repressions. In 1991 it was decided that a local commission for canonization would be established in every eparchy which would gather the local documents and would send them to the Synodal Commission. Its task was to study the local archives, collect memories of believers, record all the miracles that are connected with addressing the martyrs. In 1992 the Church established 25 January as a day when it venerates the new 20th century martyrs of faith. The day was specifically chosen because on this day in 1918 the Metropolitan of Kiev Vladimir (Bogoyavlensky) was killed, thus becoming the first victim of communist terror among the hierarchs of the Church.
During the 2000 Council of the Russian Orthodox Church, the greatest general canonization in the history of the Orthodox Church took place: not only regarding the number of saints but also as in this canonization, all unknown saints were mentioned. There were 1,765 canonized saints known by name and others unknown by name but "known to God".
Icon painting.
The use and making of icons entered Kievan Rus' following its conversion to Orthodox Christianity in AD 988. As a general rule, these icons strictly followed models and formulas hallowed by Byzantine art, led from the capital in Constantinople. As time passed, the Russians widened the vocabulary of types and styles far beyond anything found elsewhere in the Orthodox world. Russian icons are typically paintings on wood, often small, though some in churches and monasteries may be much larger. Some Russian icons were made of copper. Many religious homes in Russia have icons hanging on the wall in the "krasny ugol", the "red" or "beautiful" corner. There is a rich history and elaborate religious symbolism associated with icons. In Russian churches, the nave is typically separated from the sanctuary by an iconostasis (Russian "ikonostas", Ð¸ÐºÐ¾Ð½Ð¾ÑÑÐ°Ñ), or icon-screen, a wall of icons with double doors in the centre. Russians sometimes speak of an icon as having been "written", because in the Russian language (like Greek, but unlike English) the same word ("pisat"', Ð¿Ð¸ÑÐ°ÑÑ in Russian) means both to paint and to write. Icons are considered to be the Gospel in paint, and therefore careful attention is paid to ensure that the Gospel is faithfully and accurately conveyed. Icons considered miraculous were said to "appear." The "appearance" (Russian: "yavlenie", ÑÐ²Ð»ÐµÐ½Ð¸Ðµ) of an icon is its supposedly miraculous discovery. "A true icon is one that has 'appeared', a gift from above, one opening the way to the Prototype and able to perform miracles".
Bell ringing.
Bell ringing, which has a history in the Russian Orthodox tradition dating back to the baptism of Rus', plays an important part in the traditions of the Russian Orthodox Church.
Ecumenism and interfaith relations.
In May 2011, Hilarion Alfeyev, the Metropolitan of Volokolamsk and head of external relations for the Moscow Patriarchate of the Russian Orthodox Church, stated that Orthodox and Evangelical Christians share the same positions on "such issues as abortion, the family, and marriage" and desires "vigorous grassroots engagement" between the two Christian communions on such issues.
The Metropolitan also believes in the possibility of peaceful coexistence between Islam and Christianity as the two religions have never had religious wars in Russia. Alfeyev stated that the Russian Orthodox Church "disagrees with atheist secularism in some areas very strongly" and "believes that it destroys something very essential about human life."
The Russian Orthodox Church today has ecclesiastical missions in Jerusalem and some other countries around the world.
Numerical strength.
The ROC is often said to be the largest of the Eastern Orthodox churches in the world. Including all the autocephalous churches under its supervision, its adherents number more than 150 million worldwideâabout half of the 300 million estimated adherents of the Eastern Orthodox Church. Among Christian churches, the Russian Orthodox Church is second only to the Roman Catholic Church in terms of numbers of followers. Within Russia the results of a 2007 VTsIOM poll indicated that about 75% of the population considered themselves Orthodox Christians. Up to 65% of ethnic Russians as well as Russian-speakers belonging to other ethnic groups from Russia (Ossetians, Caucasus Greeks etc.) and a similar percentage of Belarusians and Ukrainians identify themselves as "Orthodox". However, according to a poll published by the highly respected church related journal Pravmir in December 2012, only 41% of the Russian population identified itself with the Russian Orthodox Church. Pravmir also published a 2012 poll by the respected Levada organization VTsIOM indicating that 74% of Russians considered themselves Orthodox. According to figures released on March 2, 2011, the Church had 164 dioceses, 217 bishops, and 30,675 parishes served by 28,934 priests and 3,625 deacons. There were 805 monasteries and 30 theological schools.

</doc>
<doc id="40158" url="https://en.wikipedia.org/wiki?curid=40158" title="Berchtesgaden">
Berchtesgaden

Berchtesgaden (), is a municipality in the German Bavarian Alps. It is located in the south district of Berchtesgadener Land in Bavaria, near the border with Austria, some 30Â km south of Salzburg and 180Â km southeast of Munich. To the south of the city the Berchtesgaden National Park stretches along three parallel valleys.
Berchtesgaden is often associated with the Watzmann, at 2,713Â m the third-highest mountain in Germany (after Zugspitze and Hochwanner), which is renowned in the rock climbing community for its "Ostwand" (East Face), and a deep glacial lake by the name of KÃ¶nigssee (5.2Â kmÂ²). Another notable peak is the Kehlstein mountain (1,835Â m) with its "Kehlsteinhaus" ("Eagle's Nest"), which offers spectacular views to its visitors.
Geography.
Berchtesgaden's neighbouring towns are Bischofswiesen, Marktschellenberg, Ramsau and SchÃ¶nau am KÃ¶nigssee.
The municipality counts the following villages which are ("Ortsteil"): Am EtzerschlÃ¶Ãl, Anzenbach, Hintergern, Metzenleiten, Mitterbach, Oberau, Obergern, Obersalzberg, Resten, Unterau, Untersalzberg I, Untersalzberg II and Vordergern.
Etymology.
Berchtesgaden, Upper Bavaria (Achental), earlier "Perchterscadmen", "Perhtersgadem", "Berchirchsgadem", "Berchtoldesgadem"; the word underwent a Latin distortion of Old High German "parach", Romance "bareca" 'hay shed'. After the basic meaning was forgotten, they added a variant word of Old High German "gadem" âroom, one-room hutâ, implying the same meaning: âhay shedâ. Cf. Old High German "muosgadem" âspice roomâ. There was a folk etymology that supported a derivation based on the legendary figure of Mrs. ("Frau") Perchta, Berchta, a woman (Holle < Holda âwell disposed, dearâ) with good and bad changing features, who was venerated on "Perchtertag" (= Three Kings Day) and at Shrovetide was sworn to during the Perchta procession.
History.
First ever historical note dates back to 1102 and it mentions the area because of its rich salt deposits. Much of Berchtesgaden's wealth has been derived from its salt mines, the first of which started operations in 1517. The town served as independent "FÃ¼rstpropstei" until the "Reichsdeputationshauptschluss" in 1803. During the Napoleonic wars, Berchtesgaden changed hands a few times, such as in 1805 under the Treaty of Pressburg, when the area was ceded to Austria. Salzburg was always interested in Berchtesgaden , and French troops occupied the area a short time. Berchtesgaden came under Bavarian rule in 1810 and became instantly popular with the Bavarian royal family, the House of Wittelsbach, who often visited KÃ¶nigssee and maintained a royal hunting residence in the former Augustine monastery (still used today by Franz, Duke of Bavaria). Nascent tourism started to evolve and a number of artists came to the area, which reportedly gave rise to ""Malereck"" (literally "painter's corner") on the shore of KÃ¶nigssee in nearby Ramsau bei Berchtesgaden. The most famous author who lived in Berchtesgaden was Ludwig Ganghofer.
Nazi era.
Adolf Hitler had been vacationing in the Berchtesgaden area since the 1920s. He purchased a home in the Obersalzberg above the town on the flank of the Hoher Goll and began extensive renovations on his "Berghof" in the following years. As other top Nazi Party leaders such as Herman Goering, Joseph Goebbels, and Albert Speer began to frequent the area the Party began to purchase and requisition land in the Obersalzberg. 
In order to serve as an outpost of the German "Reichskanzlei" (Imperial Chancellery), Berchtesgaden and its environs ("Stanggass") saw substantial expansion of offices, security, and support services, mainly on the Obersalzberg. Included in the town were a new railway station with reception area for Hitler and his guests, and adjacent post office. The Berchtesgadener Hof Hotel, where famous visitors such as Neville Chamberlain and David Lloyd George stayed, was substantially upgraded. The "Kehlsteinhaus" (known as the "Eagle's Nest" among the Allies) atop the Kehlstein subpeak of the Hoher Goll was built as a present for Hitler's 50th birthday in 1939. 
Even though a feared "National Redoubt" last stand of the Nazi Regime in the Alps failed to materialize, late in World War II the Allies launched a devastating air raid on the Berchtesgaden area. Concentrated on the Obersalzberg, the April 25, 1945 bombing did little damage to the town. On May 4th forward elements of the 7th Infantry Regiment of the 3rd Infantry Division arrived and received the town's surrender.
Post war.
After the war, Obersalzberg became a military zone and most of its buildings were requisitioned by the US Army. "Hotel Platterhof" was rebuilt and renamed the "General Walker Hotel"in 1952. It served as an integral part of the US Armed Forces Recreation Centers [http://www.defense.gov/news/Feb1998/n02191998_9802191.html (AFRC) for the duration of the Cold War and beyond. The remnants of homes of former Nazi leaders were all demolished in the early postwar years, though traces of some remained. 
In 1995, 50 years after the end of World War II and five years after German reunification, the AFRC Berchtesgaden was turned over to Bavarian authorities to facilitate military spending reductions mandated within the Base Realignment and Closure program by the United States Congress and the Pentagon during the administration of US President Bill Clinton. The General Walker Hotel was brought down in 2000.
Berchtesgaden today.
In 1972, local government reform united the then independent municipalities of Salzberg, Maria Gern and Au (consisting of Oberau and Unterau) under the administration of the town of Berchtesgaden. Another suggested reform uniting all remaining five municipalities in the Berchtesgaden valley (Bischofswiesen, Ramsau, Marktschellenberg and SchÃ¶nau) failed to gain enough popular support; it passed in Berchtesgaden but failed everywhere else.
The Berchtesgaden National Park was established in 1978 and has gradually become one of Berchtesgaden's largest draws. Mass tourism is confined to a few popular spots, leaving the rest to nature-seekers. Major tourist draws are the KÃ¶nigssee, the salt mine, the "Kehlsteinhaus" (open seasonally as a restaurant). and the new "Dokumentationszentrum Obersalzberg" (built on the site of the former guest house "HÃ¶her GÃ¶ll"). It is the first German museum of its kind to chronicle the entire span of World War II in one spot. An InterContinental Hotel Resort was built where the house of Hermann GÃ¶ring stood, on the GÃ¶ring hill.
Very few other traces of the Third Reich era remain in the area, including the former SS HQ at Hotel Zum TÃ¼rken, Albert Speer's house, and a small part of the "Platterhof".
Recreational and competitive sports have grown in importance. The town's ski slope is popular. The KÃ¶nigssee bobsleigh, luge, and skeleton track has hosted ski-running and a number of international events and competitions. Berchtesgaden's most famous sports personality is Georg Hackl, a multiple Olympic medal winner. The city is home to the International Luge Federation (FIL).
Unlike the northern part of Berchtesgadener Land and the Salzburg area, Berchtesgaden has virtually no manufacturing industry.
Berchtesgaden Central Station is connected by the SalzburgâBerchtesgaden railway to the RosenheimâSalzburg railway at Freilassing.

</doc>
<doc id="40163" url="https://en.wikipedia.org/wiki?curid=40163" title="Darmstadtium">
Darmstadtium

Darmstadtium is a chemical element with symbol Ds and atomic number 110. It is an extremely radioactive synthetic element. The most stable known isotope, darmstadtium-281, has a half-life of approximately 10Â seconds. Darmstadtium was first created in 1994 by the GSI Helmholtz Centre for Heavy Ion Research near the city of Darmstadt, Germany, after which it was named.
In the periodic table, it is a d-block transactinide element. It is a member of the 7th period and is placed in the group 10 elements, although no chemical experiments have yet been carried out to confirm that it behaves as the heavier homologue to platinum in group 10. Darmstadtium is calculated to have similar properties to its lighter homologues, nickel, palladium, and platinum.
History.
Discovery.
Darmstadtium was first created on November 9, 1994, at the Institute for Heavy Ion Research (Gesellschaft fÃ¼r Schwerionenforschung) in Darmstadt, Germany, by Peter Armbruster and Gottfried MÃ¼nzenberg, under the direction of Sigurd Hofmann. The team bombarded a lead-208 target with accelerated nuclei of nickel-62 in a heavy ion accelerator and detected a single atom of the isotope darmstadtium-269:
In the same series of experiments, the same team also carried out the reaction using heavier nickel-64 ions. During two runs, 9 atoms of 271Ds were convincingly detected by correlation with known daughter decay properties:
The IUPAC/IUPAP Joint Working Party (JWP) recognised the GSI team as discoverers in their 2001 report.
Naming.
Using Mendeleev's nomenclature for unnamed and undiscovered elements, darmstadtium should be known as "eka-platinum". In 1979, IUPAC published recommendations according to which the element was to be called "ununnilium" (with the corresponding symbol of "Uun"), a systematic element name as a placeholder, until the element was discovered (and the discovery then confirmed) and a permanent name was decided on. Although widely used in the chemical community on all levels, from chemistry classrooms to advanced textbooks, the recommendations were mostly ignored among scientists in the field, who either called it "element 110", with the symbol of "(110)" or even simply "110".
The name "darmstadtium" (Ds) was suggested by the GSI team in honor of the city of Darmstadt, where the element was discovered. The GSI team originally also considered naming the element "wixhausium", after the suburb of Darmstadt known as Wixhausen where the element was discovered, but eventually decided on "darmstadtium". The new name was officially recommended by IUPAC on August 16, 2003.
Isotopes.
Darmstadtium has no stable or naturally-occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Eight different isotopes of darmstadtium have been reported with atomic masses 267, 269â271, 273, 277, 279, and 281, although darmstadtium-267 is unconfirmed. Three darmstadtium isotopes, darmstadtium-270, darmstadtium-271, and darmstadtium-281, have known metastable states (although that of darmstadtium-281 is unconfirmed). Most of these decay predominantly through alpha decay, but some undergo spontaneous fission.
Stability and half-lives.
All darmstadtium isotopes are extremely unstable and radioactive; in general, the heavier isotopes are more stable than the lighter. The most stable known darmstadtium isotope, 281Ds, is also the heaviest known darmstadtium isotope; it has a half-life of 11Â seconds, although a metastable state, 281mDs, has been reported to have a longer half-life of about 3.7Â minutes. The isotope 279Ds has a half-life of 0.18Â seconds respectively. The remaining six isotopes and two metastable states have half-lives between 1Â microsecond and 70Â milliseconds. Some unknown isotopes in this region, such as 272Ds, 274â276Ds, and 280Ds, are predicted to also have rather long half-lives of a few seconds. Before its discovery, 277Ds was predicted to have a half-life of around 5Â seconds, but it has since been found to have a half-life of only 5.7Â milliseconds.
The undiscovered isotope 284Ds has been predicted to be the most stable towards beta decay; however, no known darmstadtium isotope has been observed to undergo beta decay. Theoretical calculation in a quantum tunneling model reproduces the experimental alpha decay half-life data for the known darmstadtium isotopes. It also predicts that the undiscovered isotope 294Ds, which has a magic number of neutrons (184), would have an alpha decay half-life on the order of 311Â years: exactly the same approach as for this latter case also predicts a ~3,500 year half life for the non-neutronically magic 293Ds isotope, however.
Predicted properties.
Chemical.
Darmstadtium is the eighth member of the 6d series of transition metals. Since copernicium (element 112) has been shown to be a transition metal, it is expected that all the elements from 104 to 112 would form a fourth transition metal series, with darmstadtium as part of the platinum group metals and a noble metal. Calculations on its ionization potentials and atomic and ionic radii are similar to that of its lighter homologue platinum, thus implying that darmstadtium's basic properties will resemble those of the other group 10 elements, nickel, palladium, and platinum.
Prediction of the probable chemical properties of darmstadtium has not received much attention recently. Darmstadtium is expected to be a noble metal. Based on the most stable oxidation states of the lighter group 10 elements, the most stable oxidation states of darmstadtium are predicted to be the +6, +4, and +2 states; however, the neutral state is predicted to be the most stable in aqueous solutions. In comparison, only palladium and platinum are known to show the maximum oxidation state in the group, +6, while the most stable states are +4 and +2 for both nickel and palladium. It is further expected that the maximum oxidation states of elements from bohrium (element 107) to darmstadtium (element 110) may be stable in the gas phase but not in aqueous solution. Darmstadtium hexafluoride (DsF6) is predicted to have very similar properties to its lighter homologue platinum hexafluoride (PtF6), having very similar electronic structures and ionization potentials. It is also expected to have the same octahedral molecular geometry as PtF6. Other predicted darmstadtium compounds are darmstadtium carbide (DsC) and darmstadtium tetrachloride (DsCl4), both of which are expected to behave like their lighter homologues.
Physical and atomic.
Darmstadtium is expected to be a solid under normal conditions and to crystallize in the body-centered cubic structure, unlike its lighter congeners which crystallize in the face-centered cubic structure, because it is expected to have different electron charge densities from them. It should be a very heavy metal with a density of around 34.8Â g/cm3. In comparison, the densest known element that has had its density measured, osmium, has a density of only 22.61Â g/cm3. This results from darmstadtium's high atomic weight, the lanthanide and actinide contractions, and relativistic effects, although production of enough darmstadtium to measure this quantity would be impractical, and the sample would quickly decay.
The outer electron configuration of darmstadtium is calculated to be 6d87s2, which obeys the Aufbau principle and does not follow platinum's outer electron configuration of 5d96s1. This is due to the relativistic stabilization of the 7s2 electron pair over the whole seventh period, so that none of the elements from 104 to 112 are expected to have electron configurations violating the Aufbau principle. The atomic radius of darmstadtium is expected to be around 132Â pm.
Experimental chemistry.
Unambiguous determination of the chemical characteristics of darmstadtium has yet to have been established due to the short half-lives of darmstadtium isotopes and a limited number of likely volatile compounds that could be studied on a very small scale. One of the few darmstadtium compounds that are likely to be sufficiently volatile is darmstadtium hexafluoride (), as its lighter homologue platinum hexafluoride () is volatile above 60Â Â°C and therefore the analogous compound of darmstadtium might also be sufficiently volatile; a volatile octafluoride () might also be possible. For chemical studies to be carried out on a transactinide, at least four atoms must be produced, the half-life of the isotope used must be at least 1Â second, and the rate of production must be at least one atom per week. Even though the half-life of 281Ds, the most stable confirmed darmstadtium isotope, is 11Â seconds, long enough to perform chemical studies, another obstacle is the need to increase the rate of production of darmstadtium isotopes and allow experiments to carry on for weeks or months so that statistically significant results can be obtained. Separation and detection must be carried out continuously to separate out the darmstadtium isotopes and automated systems can then experiment on the gas-phase and solution chemistry of darmstadtium as the yields for heavier elements are predicted to be smaller than those for lighter elements; some of the separation techniques used for bohrium and hassium could be reused. However, the experimental chemistry of darmstadtium has not received as much attention as that of the heavier elements from copernicium to livermorium.
The more neutron-rich darmstadtium isotopes are the most stable and are thus more promising for chemical studies; however, they can only be produced indirectly from the alpha decay of heavier elements, and indirect synthesis methods are not favourable for chemical studies. The more neutron-rich isotopes 276Ds and 277Ds might be produced directly in the reaction between thorium-232 and calcium-48, but the yield is expected to be low. Furthermore, this reaction has already been tested without success, and more recent experiments that have successfully synthesized 277Ds using indirect methods show that it has a short half-life of 5.7Â ms, not long enough to perform chemical studies.

</doc>
<doc id="40166" url="https://en.wikipedia.org/wiki?curid=40166" title="Broca's area">
Broca's area

Broca's area or the Broca area or is a region in the frontal lobe of the dominant hemisphere (usually the left) of the hominid brain with functions linked to speech production.
Language processing has been linked to Broca's area since Pierre Paul Broca reported impairments in two patients. They had lost the ability to speak after injury to the posterior inferior frontal gyrus of the brain. Since then, the approximate region he identified has become known as Broca's area, and the deficit in language production as Broca's aphasia, also called expressive aphasia. Broca's area is now typically defined in terms of the pars opercularis and pars triangularis of the inferior frontal gyrus, represented in Brodmann's cytoarchitectonic map as areas 44 and 45 of the dominant hemisphere. Studies of chronic aphasia have implicated an essential role of Broca's area in various speech and language functions. Further, fMRI studies have also identified activation patterns in Broca's area associated with various language tasks. However, slow destruction of the Broca's area by brain tumors can leave speech relatively intact suggesting its functions can shift to nearby areas in the brain.
Structure.
Broca's area is often identified by visual inspection of the topography of the brain either by macrostructural landmarks such as sulci or by the specification of coordinates in a particular reference space. The currently used Talairach and Tournoux atlas projects Brodmann's cytoarchitectonic map onto a template brain. Because Brodmann's parcelation was based on subjective visual inspection of cytoarchitectonic borders and also Brodmann analyzed only one hemisphere of one brain, the result is imprecise. Further, because of considerable variability across brains in terms of shape, size, and position relative to sulcal and gyral structure, a resulting localization precision is limited.
Nevertheless, Broca's area in the left hemisphere and its homologue in the right hemisphere are designations usually used to refer to pars triangularis (PTr) and pars opercularis (POp) of the inferior frontal gyrus. The PTr and POp are defined by structural landmarks that only probabilistically divide the inferior frontal gyrus into anterior and posterior cytoarchitectonic areas of 45 and 44, respectively, by Brodmann's classification scheme.
Area 45 receives more afferent connections from prefrontal cortex, the superior temporal gyrus, and the superior temporal sulcus, compared to area 44, which tends to receive more afferent connections from motor, somatosensory, and inferior parietal regions.
The differences between area 45 and 44 in cytoarchitecture and in connectivity suggest that these areas might perform different functions. Indeed, recent neuroimaging studies have shown that the PTr and Pop, corresponding to areas 45 and 44, respectively, play different functional roles in the human with respect to language comprehension and action recognition/understanding.
Functions.
Language comprehension.
For a long time, it was assumed that the role of Broca's area was more devoted to language production than language comprehension. However, there is evidence to demonstrates that Broca's area also plays a significant role in language comprehension. Patients with lesions in Broca's area who exhibit agrammatical speech production also show inability to use syntactic information to determine the meaning of sentences. Also, a number of neuroimaging studies have implicated an involvement of Broca's area, particularly of the pars opercularis of the left inferior frontal gyrus, during the processing of complex sentences. Further, it has recently been found in functional magnetic resonance imaging (fMRI) experiments involving highly ambiguous sentences result in a more activated inferior frontal gyrus. Therefore, the activity level in the inferior frontal gyrus and the level of lexical ambiguity are directly proportional to each other, because of the increased retrieval demands associated with highly ambiguous content. Moreover, Broca's area has revealed to be sensitive to the distinction between "possible" vs. "impossible" languages as determined by principles of generative grammar as in the works coordinated by Andrea Moro 
There is also specialisation for particular aspects of comprehension within Broca's area. Work by Devlin et al. (2003) showed in an repetitive transcranial magnetic stimulation (rTMS) study that there was a increase in reaction times when performing a semantic task under rTMS aimed at the pars triangularis (situated in the anterior part of Broca's area). The increase in reaction times is indicative that that particular area is responsible for processing that cognitive function. Disrupting these areas via TMS disrupts computations performed in the areas leading to an increase in time needed to perform the computations (reflected in reaction times). Later work by Nixon et al. (2004) showed that when the pars opercularis (situated in the posterior part of Broca's area) was stimulated under rTMS there was an increase in reaction times in a phonological task. Gough et al. (2005) performed an experiment combining elements of these previous works in which both phonological and semantic tasks were performed with rTMS stimulation directed at either the anterior or the posterior part of Broca's area. The results from this experiment conclusively distinguished anatomical specialisation within Broca's area for different components of language comphrension. Here the results showed that under rTMS stimulation: 
To summarise, the work above shows anatomical specialisation in Broca's area for language comphrension, with the anterior part of Broca's area responsible for understanding the meaning of words (semantics) and the posterior part of Broca's area responsible for understanding how words sound (phonology).
Action recognition and production.
Recent experiments have indicated that Broca's area is involved in various cognitive and perceptual tasks. One important contribution of Brodmann's area 44 is also found in the motor-related processes. Observation of meaningful hand shadows resembling moving animals activates frontal language area, demonstrating that Broca's area indeed plays a role in interpreting action of others. An activation of BA 44 was also reported during execution of grasping and manipulation.
Speech-associated gestures.
It has been speculated that because speech-associated gestures could possibly reduce lexical or sentential ambiguity, comprehension should improve in the presence of speech-associated gestures. As a result of improved comprehension, the involvement of Broca's area should be reduced.
Many neuroimaging studies have also shown activation of Broca's area when representing meaningful arm gestures. A recent study has shown evidence that word and gesture are related at the level of translation of particular gesture aspects such as its motor goal and intention. This finding helps explain why, when this area is defective, those who use sign language also suffer from language deficits. This finding that aspects of gestures are translated in words within Broca's area also explains language development in terms of evolution. Indeed, many authors have proposed that speech evolved from a primitive communication that arose from gestures. (See below.)
Speaking without Broca's area.
Damage to Broca's area is commonly associated with telegraphic like speech made up of content vocabulary. For example, a person with Broca's aphasia may say something like, "Drive, store. Mom." meaning to say, "My mom drove me to the store today". Therefore, the content of the information is correct, but the grammar and fluidity of the sentence is missing.
The essential role of the Broca's area in speech production has been questioned since it can be destroyed while leaving language nearly intact. In one case of a computer engineer, a slow-growing glioma tumor was removed. The tumor and the surgery destroyed the left inferior and middle frontal gyrus, the head of the caudate nucleus, the anterior limb of the internal capsule, and the anterior insula. However, there were minimal language problems three months after removal and the individual returned to his professional work. These minor problems include the inability to create syntactically complex sentences including more than two subjects, multiple causal conjunctions, or reported speech. These were explained by researchers as due to working memory problems. They also attributed his lack of problems to extensive compensatory mechanisms enabled by neural plasticity in the nearby cerebral cortex and a shift of some functions to the homologous area in the right hemisphere.
Mirror neurons.
Communication, both verbal and nonverbal, requires that the interacting individuals stay "tuned" to one another. Mirror neurons were discovered in the 1990s in frontal area F5 of the monkey cortex. These neurons are active during execution of object-related hand actions, but they are also active, importantly, when the monkey is just observing similar acts. For example, the mirror neurons are activated when the monkey takes a raisin from a tray and also when he views another monkey or the human experimenter doing the same. No information is yet available about possible hemispheric lateralization of the monkey mirror neurons.
Mirror neurons have visuomotor properties, being sensitive to goal-related motor acts, but they can also be activated by sounds that imply actions. Importantly, the mirror neurons do not only react to visual input and then project, via some transformational step, to motor-output-related neurons but are also part of a system that forms a neuronal representation of the observed motor acts. Similar to F5, the rostral part of the inferior parietal cortex contains neurons that are active during action observation and execution; this region receives input from the STS, which is known to contain neurons responding to biological motion 
Clinical significance.
Stuttering.
A speech disorder known as stuttering is seen to be associated with underactivity in Broca's area.
Aphasia.
Aphasia is an acquired language disorder affecting all modalities such as writing, reading, speaking, and listening and results from brain damage. It is often a chronic condition that creates changes in all areas of one's life.
Expressive aphasia vs. other aphasias.
Patients with expressive aphasia, also known as Broca's aphasia, are individuals who know "what they want to say, they just cannot get it out". They are typically able to comprehend words, and sentences with a simple syntactic structure (see above), but are more or less unable to generate fluent speech. Other symptoms that may be present include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing.
This specific group of symptoms distinguishes those who have expressive aphasia from individuals with other types of aphasia. There are several distinct "types" of aphasia, and each type is characterized by a different set of language deficits. Although those who have expressive aphasia tend to retain good spoken language comprehension, other types of aphasia can render patients completely unable to understand any language at all, unable to understand any spoken language (auditory verbal agnosia), whereas still other types preserve language comprehension, but with deficits. People with expressive aphasia may struggle less with reading and writing (see alexia) than those with other types of aphasia. Although individuals with expressive aphasia tend to have a good ability to self-monitor their language output (they "hear what they say" and make corrections), other types of aphasics can seem entirely unaware of their language deficits.
In the classical sense, expressive aphasia is the result of injury to Broca's area; it is often the case that lesions in specific brain areas cause specific, dissociable symptoms, although case studies show there is not always a one-to-one mapping between lesion location and aphasic symptoms. The correlation between damage to certain specific brain areas (usually in the left hemisphere) and the development of specific types of aphasia makes it possible to deduce (albeit very roughly) the location of a suspected brain lesion based only on the presence (and severity) of a certain type of aphasia, though this is complicated by the possibility that a patient may have damage to a number of brain areas and may exhibit symptoms of more than one type of aphasia. The examination of lesion data in order to deduce which brain areas are essential in the normal functioning of certain aspects of cognition is called the deficit-lesion method; this method is especially important in the branch of neuroscience known as aphasiology. Cognitive science - to be specific, cognitive neuropsychology - are branches of neuroscience that also make extensive use of the deficit-lesion method.
Newer implications related to lesions in Broca's Area.
It is presently perceived that the relationship between Broca's area and Broca's aphasia is not as consistent as once thought. Lesions to Broca's area alone don't result in a Broca's aphasia, nor do Broca's aphasic patients necessarily have lesions in Broca's area. Truth be told, lesions to Broca's area alone are known to produce just a transient mutism that resolves inside 3â6 weeks. This discovery suggests that Broca's area may be included in some aspect of verbalization or articulation, however, it does not address its part in sentence comprehension. Still, Brocaâs area frequently emerges in functional imaging studies of sentence processing. However, it also becomes activated in word-level tasks. This suggests that Brocaâs area is not dedicated to sentence processing but supports a function common to both. In fact, Brocaâs area can show activation in such non-linguistic tasks as imagery of motion.
Considering the hypothesis that Brocaâs area may be most involved in articulation, its activation in all of these tasks may be due to subjectsâ covert articulation while formulating a response. Despite this caveat, a consensus seems to be forming that whatever role Brocaâs area may play, it may relate to known working memory functions of the frontal areas. (It should be noted that there is a wide distribution of Talairach coordinates reported in the functional imaging literature that are referred to as part of Brocaâs area.) The processing of a passive voice sentence, for example, may require working memory to assist in the temporary retention of information while other relevant parts of the sentence are being manipulated (i.e. to resolve the assignment of thematic roles to arguments). Miyake, Carpenter, and Just have proposed that sentence processing relies on such general verbal working memory mechanisms while Caplan and Waters consider Brocaâs area to be involved in working memory specifically for syntactic processing. Friederici (2002) breaks Brocaâs area into its component regions and suggests that Brodmannâs area 44 is involved in working memory for both phonological and syntactic structure. This area becomes active first for phonology and later for syntax as the time course for the comprehension process unfolds. Brodmannâs area 45 together with Brodmannâs area 47 is viewed as being specifically involved in working memory for semantic features and thematic structure where processes of syntactic reanalysis and repair are required. These areas come online after Brodmannâs area 44 has finished its processing role and where comprehension of complex sentences must rely on general memory resources. All of these theories indicate a move towards a view that syntactic comprehension problems arise from a computational rather than a conceptual deficit. Newer theories are taking a more dynamic view of how the brain integrates different linguistic and cognitive components and are examining the time course of these operations.
Neurocognitive studies have already implicated frontal areas adjacent to Brocaâs area as important for working memory in non-linguistic as well as linguistic tasks. Cabeza and Nybergâs analysis of imaging studies of working memory supports the view that BA45/47 is recruited for selecting or comparing information, while BA9/46 might be more involved in the manipulation of information in working memory. Since large lesions are typically required to produce a Brocaâs aphasia, it is likely that these regions may also become compromised in some patients and may contribute to their comprehension deficits for complex morphosyntactic structures.
Broca's Area: A Key Center in the Linking Phonemic Sequences
Brocaâs area has been previously associated with a variety of processes, including phonological segmentation, syntactic processing, and unification, all of which involve segmenting and linking different types of linguistic information. Although repeating and reading single words do not engage semantic and syntactic processing, they do require an operation linking phonemic sequences with motor gestures. Findings indicate that this linkage is coordinated by Brocaâs area through reciprocal interactions with temporal and frontal cortices responsible for phonemic and articulatory representations, respectively, including interactions with motor cortex before the actual act of speech. Based on these unique findings, it has been proposed that Brocaâs area is not the seat of articulation per se, but rather is a key node in manipulating and forwarding neural information across large-scale cortical networks responsible for key components of speech production.
History.
In a study published in 2007, the preserved brains of both Leborgne and Lelong (patients of Broca) were reinspected using high-resolution volumetric MRI. The purpose of this study was to scan the brains in three dimensions and to identify the extent of both cortical and subcortical lesions in more detail. The study also sought to locate the exact site of the lesion in the frontal lobe in relation to what is now called Broca's area with the extent of subcortical involvement.
Broca's patients.
Leborgne (Tan).
Leborgne was a patient of Broca's. Almost completely unable to produce any words or phrases, he was able to repetitively produce only the word "tan". After his death, a lesion was discovered on the surface the left frontal lobe.
Lelong.
Lelong was another patient of Broca's. He also exhibited reduced productive speech. He could only say five words, 'yes,' 'no,' 'three,' 'always,' and 'lelo' (a mispronunciation of his own name). At autopsy, a lesion was also found in the same region of lateral frontal lobe as in Leborgne. These two cases led Broca to believe that speech was localized to this particular area.
MRI findings.
Examination of the brains of Broca's two historic patients with high-resolution MRI has produced several interesting findings. First, the MRI findings suggest that other areas besides Broca's area may also have contributed to the patients' reduced productive speech. This finding is significant because it has been found that, though lesions to Broca's area alone can possibly cause temporary speech disruption, they do not result in severe speech arrest. Therefore, there is a possibility that the aphasia denoted by Broca as an absence of productive speech also could have been influenced by the lesions in the other region. Another interesting finding is that the region, which was once considered to be critical for speech by Broca, is not precisely the same region as what is now known as Broca's area. This study provides further evidence to support the claim that language and cognition are far more complicated than once thought and involve various networks of brain regions. 
Evolution of language.
The pursuit of a satisfying theory that addresses the origin of language in humans has led to the consideration of a number of evolutionary "models." These models attempt to show how modern language might have evolved, and a common feature of many of these theories is the idea that vocal communication was initially used to complement a far more dominant mode of communication through gesture. Human language might have evolved as the "evolutionary refinement of an implicit communication system already present in lower primates, based on a set of hand/mouth goal-directed action representations."
"Hand/mouth goal-directed action representations" is another way of saying "gestural communication", "gestural language", or "communication through body language." The recent finding that Broca's area is active when people are observing others engaged in meaningful action is evidence in support of this idea. It was hypothesized that a precursor to the modern Broca's area was involved in translating gestures into abstract ideas by interpreting the movements of others as meaningful action with an intelligent purpose. It is argued that over time the ability to predict the intended outcome and purpose of a set of movements eventually gave this area the capability to deal with truly abstract ideas, and therefore (eventually) became capable of associating sounds (words) with abstract meanings. The observation that frontal language areas are activated when people observe Hand Shadows is further evidence that human language may have evolved from existing neural substrates that evolved for the purpose of gesture recognition. The study, therefore, claims that Broca's area is the "motor center for speech", which assembles and decodes speech sounds in the same way it interprets body language and gestures. Consistent with this idea is that the neural substrate that regulated motor control in the common ancestor of apes and humans was most likely modified to enhance cognitive and linguistic ability. Studies of speakers of American Sign Language and English suggest that the human brain recruited systems that had evolved to perform more basic functions much earlier; these various brain circuits, according to the authors, were tapped to work together in creating language.
Another recent finding has showed significant areas of activation in subcortical and neocortical areas during the production of communicative manual gestures and vocal signals in chimpanzees. Further, the data indicating that chimpanzees intentionally produce manual gestures as well as vocal signals to communicate with humans suggests that the precursors to human language are present at both the behavioral and neuronanatomical levels. More recently, the neocortical distribution of activity-dependent gene expression in marmosets provided direct evidence that the ventrolateral prefrontal cortex, which comprises Broca's area in humans and has been associated with auditory processing of species-specific vocalizations and orofacial control in macaques, is engaged during vocal output in a New World monkey. These findings putatively set the origin of vocalization-related neocortical circuits to at least 35 million years ago, when the Old and New World monkey lineages split.

</doc>
<doc id="40168" url="https://en.wikipedia.org/wiki?curid=40168" title="ATF">
ATF

ATF may refer to:

</doc>
<doc id="40171" url="https://en.wikipedia.org/wiki?curid=40171" title="Lead(II) azide">
Lead(II) azide

Lead azide (Pb(N3)2) is an inorganic compound. More so than other azides, is explosive. It is used in detonators to initiate secondary explosives. In a commercially usable form, it is a white to buff powder.
Preparation and handling.
Lead azide is prepared by metathesis between sodium azide and lead nitrate. Dextrin can be added to the solution to stabilize the precipitated product. The solid is not very hygroscopic, and water does not reduce its impact sensitivity. It is normally shipped in a dextrinated solution that lowers its sensitivity. When protected from humidity, it is completely stable in storage. An alternative method involves dissolving lead acetate in a sodium azide solution.
Production History.
Lead azide in its pure form was first prepared by Theodor Curtius in 1891. Due to sensitivity and stability concerns, the dextrinated form of lead azide (MIL-L-3055) was developed in the 1920s and 1930s with large scale production by DuPont Co beginning in 1932. Detonator development during World War II resulted in the need for a form of lead azide with a more brisant output. RD-1333 lead azide (MIL-DTL-46225), a version of lead azide with sodium carboxymethylcellulose as a precipitating agent, was developed to meet that need. The Vietnam War saw an accelerated need for lead azide and it was during this time that Special Purpose Lead Azide (MIL-L-14758) was developed; the US government also began stockpiling lead azide in large quantities. After the Vietnam War, the use of lead azide dramatically decreased. Due to the size of the US stockpile, the manufacture of lead azide in the US ceased completely by the early 1990s. In the 2000s, concerns about the age and stability of stockpiled lead azide led the US government to investigate methods to dispose of its stockpiled lead azide and obtain new manufacturers.
Explosive characteristics.
Lead azide is highly sensitive and usually handled and stored under water in insulated rubber containers. It will explode after a fall of around 150Â mm (6Â in) or in the presence of a static discharge of 7 millijoules. Its detonation velocity is around .
Ammonium acetate and sodium dichromate are used to destroy small quantities of lead azide.
Lead azide reacts with copper, zinc, cadmium, or alloys containing these metals to form other azides. For example, copper azide is even more explosive and too sensitive to be used commercially.
Lead azide was a component of the six .22 caliber Devastator rounds fired from a RÃ¶hm RG-14 revolver by John Hinckley, Jr. in his assassination attempt on U.S. President Ronald Reagan on March 30, 1981. The rounds consisted of lead azide centers with lacquer-sealed aluminum tips designed to explode upon impact.

</doc>
<doc id="40172" url="https://en.wikipedia.org/wiki?curid=40172" title="Botulinum toxin">
Botulinum toxin

Botulinum toxin (BTX) is a neurotoxic protein produced by the bacterium "Clostridium botulinum" and related species. It is also produced commercially for medical, cosmetic, and research use. There are two main commercial types: botulinum toxin type A and botulinum toxin type B.
Infection with the bacterium may result in a potentially fatal disease called botulism. Botulinum is the most acutely lethal toxin known, with an estimated human median lethal dose (LD50) of 1.3â2.1 ng/kg intravenously or intramuscularly and 10â13Â ng/kg when inhaled.
Botulinum toxin types A and B are used in medicine for, among others, upper motor neuron syndrome, focal hyperhidrosis, blepharospasm, strabismus, chronic migraine and bruxism. It is also widely used in cosmetic treatments. The U.S. Food and Drug Administration requires a boxed warning stating that when locally administered the toxin may spread from the injection site to other areas of the body, causing botulism. The warning was the result of deaths associated with its uses. The commercial form is marketed under the brand name Botox, among others. Botox is made by Allergan.
Uses.
Medical uses.
Botulinum toxin is used for a number of medical problems. When injected in small amounts, it can effectively weaken a muscle for a period of three to four months.
It is used in the treatment of spasms and dystonias.
The conditions approved for treatment with botulinum toxin include:
Other adult uses of botulinum toxin type A include:
Uses of botulinum toxin type A in children include:
Emerging uses for botulinum toxin type A include chronic musculoskeletal pain.
Cosmetic.
In cosmetic applications, injection of botulinum toxin can be used to prevent development of wrinkles by paralyzing facial muscles. Following treatment, results are usually seen within 3â5 days, however it can take up to 2 weeks to see full results.
Adverse effects.
Off-target effects.
Off-target, or side effects, that have been reported are consistent with the mechanism of the protein toxin's function, and its known modes of action; there are, consequently, two major areas of off-target effects: allergic reaction, and paralysis of the wrong muscle group.
Adverse events or reactions from cosmetic use include facial paralysis resulting in inappropriate facial expression, drooping eyelid, and double vision, bruising, swelling, or redness at the site of injection, headaches, dysphagia, flu-like syndromes, blurred vision, dry mouth, fatigue, and allergic reactions. Cosmetic treatments are of limited duration; they can be as short as six weeks, but can last from two to three months; hence paralysis side-effects can have the same durations. The results of inappropriate facial expression, drooping eyelid, and double vision are foremost, but the list extends to uneven smiling, and loss of the ability to close ones eyes; at least in some cases, these effects are reported to dissipate in the weeks after treatment. Bruising at the site of injection is not a side effect of the toxin but rather of the mode of administration, and is reported as preventable if the clinician applies pressure to the injection site; when it occurs, it is reported in specific cases to last 7â11 days. When injecting the masseter muscle of the jaw, loss of muscle function can result in a loss or reduction of power to chew solid foods.
Individuals who are pregnant, have egg allergies, or a neuromuscular disorder are advised to avoid botulinum toxin drugs, and breastfeeding mothers are advised to consult their doctors.
The psychological and emotional consequences associated with cosmetic treatments is not yet well documented, and reports are not yet consistent. A study of treatment of glabellar lines with consequent reduction of ability to frown correlated with a "more positive moodwhile a study on the treatment of "crow's feet" or "laughter lines" suggested the opposite effect as a consequence of the impact of the treatment on the patient's ability to smile.
Poisoning.
If the symptoms of botulism are diagnosed early, an equine antitoxin, use of enemas, and extracorporeal removal of the gut contents can be used to treat the food-borne illness. Wound infections can be treated surgically. Information regarding methods of safe canning, and public education about the disease are methods of prevention. Tests to detect botulism include a brain scan, a nerve conduction test, and a tensilon test for myasthenia gravis to differentiate botulism from other diseases that manifest in the same way. Electromyography can be used to differentiate myasthenia gravis and Guillain-BarrÃ© syndrome, diseases that botulism often mimics. Toxicity testing of serum specimens, wound tissue cultures, and toxicity testing, and stool specimen cultures are the best methods for identifying botulism. Laboratory tests of the patient's serum or stool, which are then injected into mice, are also indicative of botulism. The faster way to detect botulinum toxin in people, however, is using the mass spectrometer technology, because it reduces testing time to three or four hours and at the same time can identify the type of toxin present.
The case fatality rate for botulinum poisoning between 1950 and 1996 was 15.5%, down from about 60% over the previous 50 years. Death is generally secondary to respiratory failure due to paralysis of the respiratory muscles, so treatment consists of antitoxin administration and artificial ventilation until the neurotoxins are excreted or metabolised. If initiated on time, these treatments are quite effective, although antisera can not affect toxin polypeptides that have already entered cells. Occasionally, functional recovery may take several weeks to months or more.
Two primary botulinum antitoxins are available for treatment of botulism.
Links to deaths.
The US Food and Drug Administration (FDA) has formally linked complications from use of botulinum drug products to patient deaths. In September 2005, the "Journal of American Academy of Dermatology" communicated information from the FDA reporting 28 deaths between 1989 and 2003 associated with the use of botulinum toxin products, though none attributed to cosmetic use.
In January 2008, a petition filed by Public Citizen with the FDA requested regulatory action concerning the possible spread of the effects of botulinum toxin injectable products, including Botox and Myobloc, from the site of injection to other parts of the body.
On February 8, 2008, the FDA announced its conclusion that this class of drugs had "been linked in some cases to adverse reactions, including respiratory failure and death, following treatment of a variety of conditions using a wide range of doses", due to its ability to spread to areas distant from the site of the injection. The communication was a result of ongoing FDA safety reviews of the on-market product, and found adverse reactions associated with uses that were both FDA-approved and non-approved, the most severe being in children with cerebral palsy treated for limb spasticity (not approved for either adult or pediatric use).
On April 30, 2009, based on a continuing safety evaluation of on-market botulinum toxin products, the FDA reported its conclusion that the prescribing information for Botox, Botox Cosmetic, and Myobloc must be updated to ensure their continued safe use. On July 31, 2009, FDA, under the authorities granted by the Food and Drug Administration Amendments Act of 2007, approved revisions to the prescribing information (see following).
Further, on April 30, the FDA announced an update to its mandatory boxed warnings for four on-market productsâBotox, Botox Cosmetic, Myobloc, and Dysportâand on July 31, it approved revisions to the prescribing information for the four drugs. In the revisions, it made clear that the effects of botulinum toxin may spread from the area of injection to other body areas, causing symptoms similar to those of botulism, including potentially life-threatening swallowing and breathing difficulties resulting in patient death. Most accumulated adverse reactions were again reported for pediatric palsy patients (off-label use, see above), though adverse reaction reports were also fielded for adult patients involved in both approved and unapproved uses; the FDA emphasized that at "recommended/approved doses" there were few serious adverse reactions for common, standard treatments for focal hyperhidrosis, blepharospasm, or strabismus, or for cosmetic/dermatologic treatments, e.g., for glabellar lines (i.e., when label instructions were followed). The FDA further emphasized that the activity units of each product do not interconvert, specifically that "different botulinum toxin products are not interchangeable, because the units used to measure the products are different", and required a change in the established drug names of older drugs, from:
doing so to "emphasize the differing dose to potency ratios of of these products."
A further FDA communication aimed at health care professionals reiterated the approved drugs for each adult indication:
These have been extended, through later announcement, to include:
which is defined for patients having a history of migraine, and experiencing a headache on most days of the month."
In the 2009 communication to professionals, the FDA reiterated the foregoing adverse reaction observations and the possibility of "unexpected loss of strength or muscle weakness", leading to:
and that "swallowing and breathing difficulties can be life-threatening" (i.e., that there have been "deaths related to the effects of spread of botulinum toxin"). The communication to professionals reiterated that pediatric spasticity patients were at greatest risk from existing treatment practices, but also that approved and lower doses used to treat cervical dystonia and adult spasticity were also seen among the "cases of toxin spread", so that in all cases of drug administration, patients and their caregivers needed to:
and that these events may occur "as late as several weeks after treatment."
Warning labels.
In January 2009, the Canadian government warned that botulinum toxin products can have the adverse effect of spreading to other parts of the body, which could cause muscle weakness, swallowing difficulties, pneumonia, speech disorders and breathing problems.
In April 2009, the FDA updated its mandatory boxed warning cautioning that the effects of the botulinum toxin may spread from the area of injection to other areas of the body, causing symptoms similar to those of botulism, and that these adverse reactions, which were more likely in cases ignoring approved use guidance and label directions, could result in patient death (see above).
Mechanism of action.
The toxin produced by Clostridum species is a two-chain protein composed of a 100-kDa heavy chain polypeptide joined via disulfide bond to a 50-kDa light chain polypeptide. The seven serologically distinct toxin types possessing different tertiary structures and significant sequence divergence are designated A to G; six of the seven have subtypes, and five further subtypes of target molecules of botulinum A have been described. The A, B, and E serotypes cause human botulism, with the activities of types A and B enduring longest "in vivo" (from several weeks to months).
The terminals of specific axons must internalize the toxin to cause paralysis, and the heavy chain of the toxins is implicated in targeting the toxin to such axon terminals; following the attachment of the toxin heavy chain to proteins on the surface of the terminals, toxin molecules enter the neurons by endocytosis. The light chain, which has zinc metalloprotease activity, is released from the endocytotic vesicles and reaches the cytoplasm. Specific serotypes of the toxin cleave "synaptosomal-associated protein (25 kDa)" (SNAP-25), a protein from the "soluble N-ethylmaleimide-sensitive factor attachment receptor "(SNARE) family involved in vesicle fusion and mediating release of neurotransmitter, in particular acetylcholine, from axon endings. Cleavage of the SNARE proteins inhibits release of acetylcholine. Hence, botulinum toxins A, B, and E specifically cleave SNAREs, preventing "neurosecretory vesicles" from docking/fusing with the interior surface of the plasma membrane of the nerve synapse, and so block release of neurotransmitter. In inhibiting acetylcholine release, nerve impulses are blocked, causing the flaccid (sagging) paralysis of muscles characteristic of botulism (in contrast to the distinct spastic paralysis seen in tetanus).
History.
In 1820, Justinus Kerner, a small-town German medical officer and romantic poet, gave the first complete description of clinical botulism based on extensive clinical observations of so-called âsausage poisoningâ. Following experiments on animals and on himself, he concluded that the toxin acts by interrupting signal transmission in the somatic and autonomic motor systems, without affecting sensory signals or mental functions. He observed that the toxin develops under anaerobic conditions, and can be lethal in minute doses. His prescience in suggesting that the toxin might be used therapeutically to block both abnormal movements and hypersecretions earned him recognition as the intellectual founder of modern botulinum toxin therapy.
Seventy-five years later, Ãmile van Ermengem, professor of bacteriology and a student of Robert Koch, correctly described "Clostridium botulinum" as the bacterial source of the toxin. Thirty-four attendees at a funeral were poisoned by eating partially salted ham, an extract of which was found to cause botulism-like paralysis in laboratory animals. Van Ermengem isolated and grew the bacterium, and described its toxin, which was later purified by P Tessmer Snipe and Hermann Sommer.
Over the next three decades, as food canning was approaching a billion dollar a year industry, botulism was becoming a public health hazard. Karl Friedrich Meyer, a prodigiously productive Swiss-American veterinary scientist (and supervisor of Alan B. Scottâs motherâs 1925 MA degree in bacteriology), created a center at the Hooper Foundation in San Francisco, where he developed techniques for growing the organism and extracting the toxin, and conversely, for preventing organism growth and toxin production, and inactivating the toxin by heating. The California canning industry was thereby preserved.
With the outbreak of World War II, weaponization of botulinum toxin was investigated at Fort Detrick in Maryland. Carl Lamanna and James Duff developed the concentration and crystallization techniques that Edward J. Schantz used to create the first clinical product. When the Armyâs Chemical Corps was disbanded, Schantz moved to the Food Research Institute in Wisconsin, where he manufactured toxin for experimental use and generously provided it to the academic community.
The mechanism of botulinum toxin action â blocking the release from nerve endings of the neurotransmitter acetylcholine â was elucidated in the mid-1900s, and remains an important research topic. Nearly all toxin treatments are based on this effect in various body tissues.
Eye muscle disorders.
Ophthalmologists specializing in eye muscle disorders (strabismus) had developed the method of EMG-guided injection (using the electromyogram, the electrical signal from an activated muscle, to guide injection) of local anesthetics as a diagnostic technique for evaluating an individual muscleâs contribution to an eye movement. Because strabismus surgery frequently needed repeating, a search was undertaken for non-surgical, injection treatments using various anesthetics, alcohols, enzymes, enzyme blockers, and snake neurotoxins. Finally, inspired by Daniel Drachmanâs work with chicks at Johns Hopkins, Alan B Scott and colleagues injected botulinum toxin into monkey extraocular muscles. The result was remarkable: a few picograms induced paralysis that was confined to the target muscle, long in duration, and without side-effects.
After working out techniques for freeze-drying, buffering with albumin, and assuring sterility, potency, and safety, Scott applied to the FDA for investigational drug use, and began manufacturing botulinum type A neurotoxin in his San Francisco lab. He injected the first strabismus patients in 1977, reported its clinical utility in 1980, and had soon trained hundreds of ophthalmologists in EMG-guided injection of the drug he named "Oculinumâ¢" (âeye alignerâ).
Strabismus is caused by imbalances in the actions of muscles that rotate the eyes, and can sometimes be relieved by weakening a muscle that pulls too strongly, or pulls against one that has been weakened by disease or trauma. Muscles weakened by toxin injection recover from paralysis after several months, so it might seem that injection would then need to be repeated. However, muscles adapt to the lengths at which they are chronically held, so that if a paralyzed muscle is stretched by its antagonist, it grows longer, while the antagonist shortens, yielding a permanent effect. If there is good binocular vision, the brain mechanism of "motor fusion", which aligns the eyes on a target visible to both, can stabilize the corrected alignment.
Other muscle disorders.
By 1982, eye muscles had been injected for strabismus and nystagmus (jerky, involuntary eye movements), eyelid muscles for retraction and blepharospasm (sustained, involuntary contractions of muscles around the eye), facial muscles for hemifacial spasm, and limb muscles for dystonia (sustained muscle spasm), all as predicted in Scottâs 1973 study.
Scott also injected the first cases of torticollis (painful, spastic twisting of the neck), which were later published by Joseph Tsui of Vancouver. But even a century and a half after Kernerâs work, it was difficult for many to accept that the specificity and molecular tenacity that made ingested toxin so deadly also made it remarkably safe when injected directly into a target muscle, and no Bay Area neurology, orthopedic, or rehabilitation physician would try toxin for muscle contractures with stroke, dystonia, torticollis, or cerebral palsy. L Andrew Koman of Wake Forest University in North Carolina pioneered use of toxin to treat pediatric leg spasm in cerebral palsy.
Patient groups quickly spread the word that there were now effective treatments for previously untreatable motility disorders such as blepharospasm, which can result in functional blindness despite an otherwise normal visual system. Torticollis patients discovered that their pain could be markedly reduced by toxin injection, motility increased, head position somewhat improved, even if tremor was not. In 1993, Scott, Pankaj Pasricha, and colleagues showed that botulinum toxin could be used for the treatment of achalasia, a spasm of the lower esophageal sphincter. Spasmodic dysphonia (difficulty speaking), various gastroenteric and urinary sphincter spasms, muscle spasm in stroke, and many other muscle disorders, were also treated with botulinum toxin injection.
In January 2014, botulinum toxin was approved by UK's Medicines and Healthcare Products Regulatory Agency (MHRA) for treatment of restricted ankle motion due to lower limb spasticity associated with stroke in adults.
Botulinum toxin has not been approved for pediatric use. However, it has been used off-label for several pediatric conditions, including infantile esotropia and spastic conditions in cerebral palsy.
Supply problems.
In 1986, Oculinum Inc, Scott's micromanufacturer and distributor of botulinum toxin, was unable to obtain product liability insurance, and could no longer supply the drug. As supplies became exhausted, patients who had come to rely on periodic injections became desperate. For 4 months, as liability issues were resolved, American blepharospasm patients traveled to Canadian eye centers for their injections.
Based on data from thousands of patients collected by 240 investigators, under the 1983 US Orphan Drug Act, Scott got FDA approval in 1989 to market Oculinum for clinical use in the United States to treat adult strabismus and blepharospasm. Allergan served as the drugâs distributor for almost 2 years, and in 1991 took over the licenses and changed the drugâs name to BotoxÂ®.
Hypersecretion.
Finally pursuing Kernerâs suggestion 175 years earlier, Khalafalla Bushara and David Park in England made the first non-muscular use of botulinum toxin in humans with a demonstration that injections could inhibit excess sweating.
The toxin was also used by Drobik and Laskawi to treat hyperhidrosis in Freyâs Syndrome, in which facial sweating occurs after parotid gland surgery due to anomalous regrowth of injured salivary nerves to the face. It was a natural extension to use the toxin to ameliorate the poorly handled salivary secretions in amyotrophic lateral sclerosis and to decrease excessive lacrimal gland secretion. The concept of blocking cholinergic innervation to sweat glands as a treatment for hyperhidrosis in the axilla, hands, and elsewhere, followed.
Cosmetics.
Richard Clark, a plastic surgeon from Sacramento (CA), was the first to document a cosmetic use for botulinum toxin. He treated facial asymmetry caused by unilateral facial nerve paralysis by injecting toxin into the non-paralyzed frontal muscle.
Marrying ophthalmology to dermatology, Jean and Alistair Carruthers observed that blepharospasm patients who received injections around the eyes and upper face also enjoyed diminished facial glabellar lines (âfrown linesâ between the eyebrows), thereby initiating the highly-popular cosmetic use of the toxin. Brin, and a group at Columbia University under Monte Keen made similar reports. In 2002, following clinical trials, the FDA approved Botox Cosmetic, botulinum A toxin to temporarily improve the appearance of moderate-to-severe glabellar lines. The FDA approved a fully "in vitro" assay for use in the stability and potency testing of BotoxÂ® in response to increasing public concern that LD50 testing was required for each batch sold in the market.
Chronic pain.
William Binder reported that patients who had cosmetic injections around the face reported relief from chronic headache. This was initially thought to be an indirect effect of reduced muscle tension, but it is now known that the toxin inhibits release of peripheral nociceptive neurotransmitters, suppressing the central pain processing systems responsible for migraine headache. In 2010, the FDA approved intramuscular botulinum toxin injections for prophylactic treatment of chronic migraine headache.
Society and culture.
Economics.
As of 2013, botulinum toxin injections are the most common cosmetic operation, with 6.3 million procedures in the United States, according to the American Society of Plastic Surgeons. Qualifications for Botox injectors vary by county, state and country. Botox cosmetic providers include dermatologists, plastic surgeons, aesthetic spa physicians, dentists, nurse practitioners, nurses and physician assistants.
The global market for botulinum toxin products, driven by their cosmetic applications, is forecast to reach $2.9 billion by 2018. The facial aesthetics market, of which they are a component, is forecast to reach $4.7 billion ($2 billion in the U.S.) in the same timeframe.
Bioterrorism.
Botulinum toxin has been recognized as a potential agent for use in bioterrorism. It can be absorbed through the eyes, mucous membranes, respiratory tract, or non-intact skin.
The effects of botulinum toxin are different from those of nerve agents involved insofar in that botulism symptoms develop relatively slowly (over several days), while nerve agent effects are generally much more rapid and can be instantaneous. Evidence suggests that nerve exposure (simulated by injection of atropine and pralidoxime) will increase mortality by enhancing botulinum toxin's mechanism of toxicity.
With regard to detection, current protocols using NBC detection equipment (such as M-8 paper or the ICAM) will not indicate a "positive" when samples containing botulinum toxin are tested. To confirm a diagnosis of botulinum toxin poisoning, therapeutically or to provide evidence in death investigations, botulinum toxin may be quantitated by immunoassay of human biological fluids; serum levels of 12â24 mouse LD50 units per milliliter have been detected in poisoned patients.
Brand names.
Botulinum toxin A is marketed under the brand names Botox (marketed by Allergan), Dysport (marketed by Ipsen), and Xeomin (marketed by Merz Pharma). Botulinum toxin B is marketed under the brand name Myobloc (marketed by Solstice Neurosciences).
In the United States, botulinum toxin products are manufactured by a variety of companies, for both therapeutic and cosmetic use. Allergan, Inc., a principal U.S. supplier through their Botox products, reported in its company materials in 2011 that it could "supply the world's requirements for 25 indications approved by Government agencies around the world" with less than one gram of raw botulinum toxin. Myobloc or Neurobloc, a botulinum toxin type B product, is produced by Solstice Neurosciences, a subsidiary of US WorldMeds. Dysport, a therapeutic formulation of the type A toxin manufactured by Galderma in the United Kingdom, is licensed for the treatment of focal dystonias and certain cosmetic uses in the U.S. and other countries.
After the three primary U.S. manufacturers, there many reports of other sources of production. Xeomin, manufactured in Germany by Merz, is also available for both therapeutic and cosmetic use in the U.S. Lanzhou Institute of Biological Products in China manufactures a BTX-A product; as of 2014 it was the only BTX-A approved in China. BTX-A is also sold as Lantox and Prosigne on the global market. Neuronox, a BTX-A product, was introduced by Medy-Tox Inc. of South Korea in 2009; Neuronox is also markets as Siax in the U.S.
Toxin production.
Botulism toxins are produced by bacteria of the genus "Clostridium," namely "Clostridium botulinum", "C. butyricum, C. baratii" and "C. argentinense," which are widely distributed, including in soil and dust. As well, the bacteria can be found inside homes on floors, carpet, and countertops even after cleaning. Some food products such as honey can contain amounts of the bacteria.
Food-borne botulism results, indirectly, from ingestion of food contaminated with Clostridium spores, where exposure to an anaerobic environment allows the spores to germinate, after which the bacteria can multiply and produce toxin. Critically, "it is ingestion of toxin rather than spores or vegetative bacteria" that causes botulism. Botulism is nevertheless known to be transmitted through canned foods not cooked correctly before canning or after can opening, and so is preventable. Infant botulism cases arise chiefly as a result of environmental exposure and are therefore more difficult to prevent. Infant botulism arising from consumption of honey can be prevented by eliminating honey from diets of children less than 12 months old.
Therapeutic and weaponisable forms of the toxin are sourced from strains of "Clostriudium" where both the growth and toxin isolation are under specialized conditions.
Organism and toxin susceptibilities.
Proper refrigeration at temperatures below 3Â Â°C (38Â Â°F) retards the growth of "Clostridium botulinum". The organism is also susceptible to high salt, high oxygen, and low pH levels. The toxin itself is rapidly destroyed by heat, such as in thorough cooking. The spores that produce the toxin are heat-tolerant and will survive boiling water for an extended period of time.
The botulinum toxin is denatured and thus deactivated at temperatures greater than . As a zinc metalloprotease (see below), the toxin's activity is also susceptible, post-exposure, to inhibition by protease inhibitors, e.g., zinc-coordinating hydroxamates.
Research.
Blepharospasm and strabismus.
In the early 1980s, university-based ophthalmologists in the USA and Canada further refined the use of botulinum toxin as a therapeutic agent. By 1985, a scientific protocol of injection sites and dosage had been empirically determined for treatment of blepharospasm and strabismus. Side effects in treatment of this condition were deemed to be rare, mild and treatable. The beneficial effects of the injection lasted only 4â6 months. Thus, blepharospasm patients required re-injection two or three times a year.
In 1986, Scott's micromanufacturer and distributor of Botox was no longer able to supply the drug because of an inability to obtain product liability insurance. Patients became desperate, as supplies of Botox were gradually consumed, forcing him to abandon patients who would have been due for their next injection. For a period of four months, American blepharospasm patients had to arrange to have their injections performed by participating doctors at Canadian eye centers until the liability issues could be resolved.
In December 1989, Botox, manufactured by Allergan, Inc., was approved by the US Food and Drug Administration (FDA) for the treatment of strabismus, blepharospasm, and hemifacial spasm in patients over 12 years old.
Botox has not been approved for any pediatric use. It has, however, been used off-label by physicians for several conditions. including spastic conditions in pediatric patients with cerebral palsy, a therapeutic course that has resulted in patient deaths. In the case of treatment of infantile esotropia in patients younger than 12 years of age, several studies have yielded differing results.
Cosmetic.
The cosmetic effect of BTX-A on wrinkles was originally documented by a plastic surgeon from Sacramento, California, Richard Clark, and published in the journal "Plastic and Reconstructive Surgery" in 1989. Canadian husband and wife ophthalmologist and dermatologist physicians, JD and JA Carruthers, were the first to publish a study on BTX-A for the treatment of glabellar frown lines in 1992. Similar effects had reportedly been observed by a number of independent groups (Brin, and the Columbia University group under Monte Keen.) After formal trials, on April 12, 2002, the FDA announced regulatory approval of botulinum toxin type A (Botox Cosmetic) to temporarily improve the appearance of moderate-to-severe frown lines between the eyebrows (glabellar lines). Subsequently, cosmetic use of botulinum toxin type A has become widespread. The results of Botox Cosmetic can last up to four months and may vary with each patient. The US Food and Drug Administration approved an alternative product-safety testing method in response to increasing public concern that LD50 testing was required for each batch sold in the market.
Upper motor neuron syndrome.
BTX-A is now a common treatment for muscles affected by the upper motor neuron syndrome (UMNS), such as cerebral palsy, for muscles with an impaired ability to effectively lengthen. Muscles affected by UMNS frequently are limited by weakness, loss of reciprocal inhibition, decreased movement control and hypertonicity (including spasticity). In January 2014, Botulinum toxin was approved by UK's Medicines and Healthcare Products Regulatory Agency (MHRA) for the treatment of ankle disability due to lower limb spasticity associated with stroke in adults. Joint motion may be restricted by severe muscle imbalance related to the syndrome, when some muscles are markedly hypertonic, and lack effective active lengthening. Injecting an overactive muscle to decrease its level of contraction can allow improved reciprocal motion, so improved ability to move and exercise.
Sweating.
As noted, Bushara and Park were the first to demonstrate a nonmuscular use of BTX-A while treating patients with hemifacial spasm in England in 1993, showing that botulinum toxin injections inhibit sweating, and so are useful in treating hyperhidrosis (excessive sweating). BTX-A has since been approved for the treatment of severe primary axillary hyperhidrosis (excessive underarm sweating of unknown cause), which cannot be managed by topical agents.
Cervical dystonia.
BTX-A is commonly used to treat cervical dystonia, but it can become ineffective after a time. Botulinum toxin type B (BTX-B) received FDA approval for treatment of cervical dystonia on December 21, 2000. Trade names for BTX-B are Myobloc in the United States, and Neurobloc in the European Union.
Chronic migraine.
Onabotulinumtoxin A (trade name Botox) received FDA approval for treatment of chronic migraines on October 15, 2010. The toxin is injected into the head and neck to treat these chronic headaches. Approval followed evidence presented to the agency from two studies funded by Allergan, Inc. showing a very slight improvement in incidence of chronic migraines for migraine sufferers undergoing the Botox treatment.
Since then, several randomized control trials have shown botulinum toxin type A to improve headache symptoms and quality of life when used prophylactically for patients with chronic migraine who exhibit headache characteristics consistent with: pressure perceived from outside source, shorter total duration of chronic migraines (<30 years), "detoxification" of patients with coexisting chronic daily headache due to medication overuse, and no current history of other preventive headache medications.

</doc>
<doc id="40173" url="https://en.wikipedia.org/wiki?curid=40173" title="8th century BC">
8th century BC

The 8th century BC started the first day of 800 BC and ended the last day of 701 BC. The 8th century BC was a period of great changes in civilizations. In Egypt, the 23rd and 24th dynasties led to rule from Nubia in the 25th Dynasty. The Neo-Assyrian Empire reaches the peak of its power, conquering the Kingdom of Israel as well as nearby countries.
Greece colonizes other regions of the Mediterranean Sea and Black Sea. Rome is founded in 753 BC, and the Etruscan civilization expands in Italy. The 8th century BC is conventionally taken as the beginning of Classical Antiquity, with the first Olympiad set at 776 BC, and the epics of Homer dated to between 750 to 650 BC.
Iron Age India enters the later Vedic period. Vedic ritual is annotated in many priestly schools in Brahmana commentaries, and the earliest Upanishads mark the beginning of Vedanta philosophy.
Significant persons.
Although many human societies were literate at this time, some of the individuals mentioned below must be considered legendary rather than historical.
Sovereign states.
See: List of sovereign states in the 8th century BC.

</doc>
<doc id="40174" url="https://en.wikipedia.org/wiki?curid=40174" title="9th century BC">
9th century BC

The 9th century BC started the first day of 900 BC and ended the last day of 801 BC. It was a period of great change for several civilizations. In Africa, Carthage is founded by the Phoenicians. In Egypt, a severe flood covers the floor of Luxor temple, and years later, a civil war starts.
It is the beginning of the Iron Age in Central Europe, with the spread of the Proto-Celtic Hallstatt culture, and the Proto-Celtic language.
Sovereign States.
See: List of sovereign states in the 9th century BC.

</doc>
<doc id="40176" url="https://en.wikipedia.org/wiki?curid=40176" title="Joseph Priestley">
Joseph Priestley

Joseph Priestley (; â 6 February 1804) was an 18th-century English theologian, dissenting clergyman, natural philosopher, chemist, educator, and Liberal political theorist who published over 150 works. He is usually credited with the discovery of oxygen, having isolated it in its gaseous state, although Carl Wilhelm Scheele and Antoine Lavoisier also have a claim to the discovery.
During his lifetime, Priestley's considerable scientific reputation rested on his invention of soda water, his writings on electricity, and his discovery of several "airs" (gases), the most famous being what Priestley dubbed "dephlogisticated air" (oxygen). However, Priestley's determination to defend phlogiston theory and to reject what would become the chemical revolution eventually left him isolated within the scientific community.
Priestley's science was integral to his theology, and he consistently tried to fuse Enlightenment rationalism with Christian theism. In his metaphysical texts, Priestley attempted to combine theism, materialism, and determinism, a project that has been called "audacious and original". He believed that a proper understanding of the natural world would promote human progress and eventually bring about the Christian Millennium. Priestley, who strongly believed in the free and open exchange of ideas, advocated toleration and equal rights for religious Dissenters, which also led him to help found Unitarianism in England. The controversial nature of Priestley's publications combined with his outspoken support of the French Revolution aroused public and governmental suspicion; he was eventually forced to flee, in 1791, first to London, and then to the United States, after a mob burned down his home and church. He spent the last ten years of his life living in Northumberland County, Pennsylvania.
A scholar and teacher throughout his life, Priestley also made significant contributions to pedagogy, including the publication of a seminal work on English grammar, books on history, and he prepared some of the most influential early timelines. These educational writings were some of Priestley's most popular works. It was his metaphysical works, however, that had the most lasting influence: leading philosophers including Jeremy Bentham, John Stuart Mill, and Herbert Spencer credit them among the primary sources for utilitarianism.
Early life and education (1733â55).
Priestley was born to an established English Dissenting family (i.e. they did not conform to the Church of England) in Birstall, near Batley in the West Riding of Yorkshire. He was the oldest of six children born to Mary Swift and Jonas Priestley, a finisher of cloth. To ease his mother's burdens, Priestley was sent to live with his grandfather around the age of one. He returned home, five years later, after his mother died. When his father remarried in 1741, Priestley went to live with his aunt and uncle, the wealthy and childless Sarah and John Keighley, from Fieldhead. Because Priestley was precociousâat the age of four he could flawlessly recite all 107 questions and answers of the Westminster Shorter Catechismâhis aunt sought the best education for the boy, intending him for the ministry. During his youth, Priestley attended local schools where he learned Greek, Latin, and Hebrew.
Around 1749, Priestley became seriously ill and believed he was dying. Raised as a devout Calvinist, he believed a conversion experience was necessary for salvation, but doubted he had had one. This emotional distress eventually led him to question his theological upbringing, causing him to reject election and to accept universal salvation. As a result, the elders of his home church, the Independent Upper Chapel of Heckmondwike, refused him admission as a full member.
Priestley's illness left him with a permanent stutter and he gave up any thoughts of entering the ministry at that time. In preparation for joining a relative in trade in Lisbon, he studied French, Italian, and German in addition to Aramaic, and Arabic. He was tutored by the Reverend George Haggerstone, who first introduced him to higher mathematics, natural philosophy, logic, and metaphysics through the works of Isaac Watts, Willem 's Gravesande, and John Locke.
Daventry Academy.
Priestley eventually decided to return to his theological studies and, in 1752, matriculated at Daventry, a Dissenting academy. Because he had already read widely, Priestley was allowed to skip the first two years of coursework. He continued his intense study; this, together with the liberal atmosphere of the school, shifted his theology further leftward and he became a Rational Dissenter. Abhorring dogma and religious mysticism, Rational Dissenters emphasised the rational analysis of the natural world and the Bible.
Priestley later wrote that the book that influenced him the most, save the Bible, was David Hartley's "Observations on Man" (1749). Hartley's psychological, philosophical, and theological treatise postulated a material theory of mind. Hartley aimed to construct a Christian philosophy in which both religious and moral "facts" could be scientifically proven, a goal that would occupy Priestley for his entire life. In his third year at Daventry, Priestley committed himself to the ministry, which he described as "the noblest of all professions".
Needham Market and Nantwich (1755â61).
Robert Schofield, Priestley's major modern biographer, describes his first "call" in 1755 to the Dissenting parish in Needham Market, Suffolk, as a "mistake" for both Priestley and the congregation. Priestley yearned for urban life and theological debate, whereas Needham Market was a small, rural town with a congregation wedded to tradition. Attendance and donations dropped sharply when they discovered the extent of his heterodoxy. Although Priestley's aunt had promised her support if he became a minister, she refused any further assistance when she realised he was no longer a Calvinist. To earn extra money, Priestley proposed opening a school, but local families informed him that they would refuse to send their children. He also presented a series of scientific lectures titled "Use of the Globes" that was more successful.
Priestley's Daventry friends helped him obtain another position and in 1758 he moved to Nantwich, Cheshire; this time there was happier. The congregation cared less about Priestley's heterodoxy and he successfully established a school. Unlike many schoolmasters of the time, Priestley taught his students natural philosophy and even bought scientific instruments for them. Appalled at the quality of the available English grammar books, Priestley wrote his own: "The Rudiments of English Grammar" (1761). His innovations in the description of English grammar, particularly his efforts to dissociate it from Latin grammar, led 20th-century scholars to describe him as "one of the great grammarians of his time". After the publication of "Rudiments" and the success of Priestley's school, Warrington Academy offered him a teaching position in 1761.
Warrington Academy (1761â1767).
In 1761, Priestley moved to Warrington and assumed the post of tutor of modern languages and rhetoric at the town's Dissenting academy, although he would have preferred to teach mathematics and natural philosophy. He fitted in well at Warrington, and made friends quickly. On 23 June 1762, he married Mary Wilkinson of Wrexham. Of his marriage, Priestley wrote:
This proved a very suitable and happy connexion, my wife being a woman of an excellent understanding, much improved by reading, of great fortitude and strength of mind, and of a temper in the highest degree affectionate and generous; feeling strongly for others, and little for herself. Also, greatly excelling in every thing relating to household affairs, she entirely relieved me of all concern of that kind, which allowed me to give all my time to the prosecution of my studies, and the other duties of my station.
On 17 April 1763, they had a daughter, whom they named Sarah after Priestley's aunt.
Educator and historian.
All of the books Priestley published while at Warrington emphasised the study of history; Priestley considered it essential for worldly success as well as religious growth. He wrote histories of science and Christianity in an effort to reveal the progress of humanity and, paradoxically, the loss of a pure, "primitive Christianity".
In his "Essay on a Course of Liberal Education for Civil and Active Life" (1765), "Lectures on History and General Policy" (1788), and other works, Priestley argued that the education of the young should anticipate their future practical needs. This principle of utility guided his unconventional curricular choices for Warrington's aspiring middle-class students. He recommended modern languages instead of classical languages and modern rather than ancient history. Priestley's lectures on history were particularly revolutionary; he narrated a providentialist and naturalist account of history, arguing that the study of history furthered the comprehension of God's natural laws. Furthermore, his millennial perspective was closely tied to his optimism regarding scientific progress and the improvement of humanity. He believed that each age would improve upon the previous and that the study of history allowed people to perceive and to advance this progress. Since the study of history was a moral imperative for Priestley, he also promoted the education of middle-class women, which was unusual at the time. Some scholars of education have described Priestley as the most important English writer on education between the 17th-century John Locke and the 19th-century Herbert Spencer. "Lectures on History" was well received and was employed by many educational institutions, such as New College at Hackney, Brown, Princeton, Yale, and Cambridge. Priestley designed two "Charts" to serve as visual study aids for his "Lectures". These charts are in fact timelines; they have been described as the most influential timelines published in the 18th century. Both were popular for decades, and the trustees of Warrington were so impressed with Priestley's lectures and charts that they arranged for the University of Edinburgh to grant him a Doctor of Law degree in 1764.
History of Electricity.
The intellectually stimulating atmosphere of Warrington, often called the "Athens of the North" (of England) during the 18th century, encouraged Priestley's growing interest in natural philosophy. He gave lectures on anatomy and performed experiments regarding temperature with another tutor at Warrington, his friend John Seddon. Despite Priestley's busy teaching schedule, he decided to write a history of electricity. Friends introduced him to the major experimenters in the field in BritainâJohn Canton, William Watson, and the visiting Benjamin Franklinâwho encouraged Priestley to perform the experiments he wanted to include in his history. In the process of replicating others' experiments, Priestley became intrigued by unanswered questions and was prompted to undertake experiments of his own design. (Impressed with his "Charts" and the manuscript of his history of electricity, Canton, Franklin, Watson, and Richard Price nominated Priestley for a fellowship in the Royal Society; he was accepted in 1766.)
In 1767, the 700-page "The History and Present State of Electricity" was published to positive reviews. The first half of the text is a history of the study of electricity to 1766; the second and more influential half is a description of contemporary theories about electricity and suggestions for future research. Priestley reported some of his own discoveries in the second section, such as the conductivity of charcoal and other substances and the continuum between conductors and non-conductors. This discovery overturned what he described as "one of the earliest and universally received maxims of electricity", that only water and metals could conduct electricity. This and other experiments on the electrical properties of materials and on the electrical effects of chemical transformations demonstrated Priestley's early and ongoing interest in the relationship between chemical substances and electricity. Based on experiments with charged spheres, Priestley was among the first to propose that electrical force followed an inverse-square law, similar to Newton's law of universal gravitation.May we not infer from this experiment, that the attraction of electricity is subject to the same laws with that of gravitation, and is therefore according to the squares of the distances; since it is easily demonstrated, that were the earth in the form of a shell, a body in the inside of it would not be attracted to one side more than another?</ref> However, he did not generalise or elaborate on this, and the general law was enunciated by French physicist Charles-Augustin de Coulomb in the 1780s.
Priestley's strength as a natural philosopher was qualitative rather than quantitative and his observation of "a current of real air" between two electrified points would later interest Michael Faraday and James Clerk Maxwell as they investigated electromagnetism. Priestley's text became the standard history of electricity for over a century; Alessandro Volta (who later invented the battery), William Herschel (who discovered infrared radiation), and Henry Cavendish (who discovered hydrogen) all relied upon it. Priestley wrote a popular version of the "History of Electricity" for the general public titled "A Familiar Introduction to the Study of Electricity" (1768). He marketed the book with his brother Timothy, but unsuccessfully.
Leeds (1767â73).
Perhaps prompted by Mary Priestley's ill health, or financial problems, or a desire to prove himself to the community that had rejected him in his childhood, Priestley moved with his family from Warrington to Leeds in 1767, and he became Mill Hill Chapel's minister. Two sons were born to the Priestleys in Leeds: Joseph junior on 24 July 1768 and William three years later. Theophilus Lindsey, a rector at Catterick, Yorkshire, became one of Priestley's few friends in Leeds, of whom he wrote: "I never chose to publish any thing of moment relating to theology, without consulting him." Although Priestley had extended family living around Leeds, it does not appear that they communicated. Schofield conjectures that they considered him a heretic. Each year Priestley travelled to London to consult with his close friend and publisher, Joseph Johnson, and to attend meetings of the Royal Society.
Minister of Mill Hill Chapel.
When Priestley became its minister, Mill Hill Chapel was one of the oldest and most respected Dissenting congregations in England; however, during the early 18th century the congregation had fractured along doctrinal lines, and was losing members to the charismatic Methodist movement. Priestley believed that by educating the young, he could strengthen the bonds of the congregation.
In his magisterial three-volume "Institutes of Natural and Revealed Religion" (1772â74), Priestley outlined his theories of religious instruction. More importantly, he laid out his belief in Socinianism. The doctrines he explicated would become the standards for Unitarians in Britain. This work marked a change in Priestley's theological thinking that is critical to understanding his later writingsâit paved the way for his materialism and necessitarianism (the belief that a divine being acts in accordance with necessary metaphysical laws).
Priestley's major argument in the "Institutes" was that the only revealed religious truths that could be accepted were those that matched one's experience of the natural world. Because his views of religion were deeply tied to his understanding of nature, the text's theism rested on the argument from design. The "Institutes" shocked and appalled many readers, primarily because it challenged basic Christian orthodoxies, such as the divinity of Christ and the miracle of the Virgin Birth. Methodists in Leeds penned a hymn asking God to "the Unitarian fiend expel / And chase his doctrine back to Hell." Priestley wanted to return Christianity to its "primitive" or "pure" form by eliminating the "corruptions" which had accumulated over the centuries. The fourth part of the "Institutes", "An History of the Corruptions of Christianity", became so long that he was forced to issue it separately in 1782. Priestley believed that the "Corruptions" was "the most valuable" work he ever published. In demanding that his readers apply the logic of the emerging sciences and comparative history to the Bible and Christianity, he alienated religious and scientific readers alikeâscientific readers did not appreciate seeing science used in the defence of religion and religious readers dismissed the application of science to religion.
Religious controversialist.
Priestley engaged in numerous political and religious pamphlet wars. According to Schofield, "he entered each controversy with a cheerful conviction that he was right, while most of his opponents were convinced, from the outset, that he was willfully and maliciously wrong. He was able, then, to contrast his sweet reasonableness to their personal rancor", but as Schofield points out Priestley rarely altered his opinion as a result of these debates. While at Leeds he wrote controversial pamphlets on the Lord's Supper and on Calvinist doctrine; thousands of copies were published, making them some of Priestley's most widely read works.
Priestley founded the "Theological Repository" in 1768, a journal committed to the open and rational inquiry of theological questions. Although he promised to print any contribution, only like-minded authors submitted articles. He was therefore obliged to provide much of the journal's content himself (this material became the basis for many of his later theological and metaphysical works). After only a few years, due to a lack of funds, he was forced to cease publishing the journal. He revived it in 1784 with similar results.
Defender of Dissenters and political philosopher.
Many of Priestley's political writings supported the repeal of the Test and Corporation Acts, which restricted the rights of Dissenters. They could not hold political office, serve in the armed forces, or attend Oxford and Cambridge unless they subscribed to the Thirty-nine Articles of the Church of England. Dissenters repeatedly petitioned Parliament to repeal the Acts, arguing that they were being treated as second-class citizens.
Priestley's friends, particularly other Rational Dissenters, urged him to publish a work on the injustices experienced by Dissenters; the result was his "Essay on the First Principles of Government" (1768). An early work of modern liberal political theory and Priestley's most thorough treatment of the subject, itâunusually for the timeâdistinguished political rights from civil rights with precision and argued for expansive civil rights. Priestley identified separate private and public spheres, contending that the government should only have control over the public sphere. Education and religion, in particular, he maintained, were matters of private conscience and should not be administered by the state. Priestley's later radicalism emerged from his belief that the British government was infringing upon these individual freedoms.
Priestley also defended the rights of Dissenters against the attacks of William Blackstone, an eminent legal theorist, whose "Commentaries on the Laws of England" (1765â69) had become the standard legal guide. Blackstone's book stated that dissent from the Church of England was a crime and that Dissenters could not be loyal subjects. Furious, Priestley lashed out with his "Remarks on Dr. Blackstone's Commentaries" (1769), correcting Blackstone's interpretation of the law, his grammar (a highly politicised subject at the time), and history. Blackstone, chastened, altered subsequent editions of his "Commentaries": he rephrased the offending passages and removed the sections claiming that Dissenters could not be loyal subjects, but he retained his description of Dissent as a crime.
Natural philosopher: electricity, "Optics", and soda water.
Although Priestley claimed that natural philosophy was only a hobby, he took it seriously. In his "History of Electricity", he described the scientist as promoting the "security and happiness of mankind". Priestley's science was eminently practical and he rarely concerned himself with theoretical questions; his model was Benjamin Franklin. When he moved to Leeds, Priestley continued his electrical and chemical experiments (the latter aided by a steady supply of carbon dioxide from a neighbouring brewery). Between 1767 and 1770, he presented five papers to the Royal Society from these initial experiments; the first four papers explored coronal discharges and other phenomena related to electrical discharge, while the fifth reported on the conductivity of charcoals from different sources. His subsequent experimental work focused on chemistry and pneumatics.
Priestley published the first volume of his projected history of experimental philosophy, "The History and Present State of Discoveries Relating to Vision, Light and Colours" (referred to as his "Optics"), in 1772. He paid careful attention to the history of optics and presented excellent explanations of early optics experiments, but his mathematical deficiencies caused him to dismiss several important contemporary theories. Furthermore, he did not include any of the practical sections that had made his "History of Electricity" so useful to practising natural philosophers. Unlike his "History of Electricity", it was not popular and had only one edition, although it was the only English book on the topic for 150 years. The hastily written text sold poorly; the cost of researching, writing, and publishing the "Optics" convinced Priestley to abandon his history of experimental philosophy.
Priestley was considered for the position of astronomer on James Cook's second voyage to the South Seas, but was not chosen. Still, he contributed in a small way to the voyage: he provided the crew with a method for making soda water, which he erroneously speculated might be a cure for scurvy. He then published a pamphlet with "Directions for Impregnating Water with Fixed Air" (1772). Priestley did not exploit the commercial potential of soda water, but others such as made fortunes from it. In 1773, the Royal Society recognised Priestley's achievements in natural philosophy by awarding him the Copley Medal.
Priestley's friends wanted to find him a more financially secure position. In 1772, prompted by Richard Price and Benjamin Franklin, Lord Shelburne wrote to Priestley asking him to direct the education of his children and to act as his general assistant. Although Priestley was reluctant to sacrifice his ministry, he accepted the position, resigning from Mill Hill Chapel on 20 December 1772, and preaching his last sermon on 16 May 1773.
Calne (1773â80).
In 1773, the Priestleys moved to Calne and a year later Lord Shelburne and Priestley took a tour of Europe. According to Priestley's close friend Theophilus Lindsey, Priestley was "much improved by this view of mankind at large". Upon their return, Priestley easily fulfilled his duties as librarian and tutor. The workload was intentionally light, allowing him time to pursue his scientific investigations and theological interests. Priestley also became a political adviser to Shelburne, gathering information on parliamentary issues and serving as a liaison between Shelburne and the Dissenting and American interests. When the Priestleys' third son was born on 24 May 1777, they named him Henry at the lord's request.
Materialist philosopher.
Priestley wrote his most important philosophical works during his years with Lord Shelburne. In a series of major metaphysical texts published between 1774 and 1780â"An Examination of Dr. Reid's Inquiry into the Human Mind" (1774), "Hartley's Theory of the Human Mind on the Principle of the Association of Ideas" (1775), "Disquisitions relating to Matter and Spirit" (1777), "The Doctrine of Philosophical Necessity Illustrated" (1777), and "Letters to a Philosophical Unbeliever" (1780)âhe argues for a philosophy that incorporates four concepts: determinism, materialism, causation, and necessitarianism. By studying the natural world, he argued, people would learn how to become more compassionate, happy, and prosperous.
Priestley strongly suggested that there is no mind-body duality, and put forth a materialist philosophy in these works; that is, one founded on the principle that everything in the universe is made of matter that we can perceive. He also contended that discussing the soul is impossible because it is made of a divine substance, and humanity cannot perceive the divine. Despite his separation of the divine from the mortal, this position shocked and angered many of his readers, who believed that such a duality was necessary for the soul to exist.
Responding to Baron d'Holbach's "SystÃ¨me de la Nature" (1770) and David Hume's "Dialogues Concerning Natural Religion" (1779) as well as the works of the French "philosophers", Priestley maintained that materialism and determinism could be reconciled with a belief in God. He criticised those whose faith was shaped by books and fashion, drawing an analogy between the scepticism of educated men and the credulity of the masses.
Maintaining that humans had no free will, Priestley argued that what he called "philosophical necessity" (akin to absolute determinism) is consonant with Christianity, a position based on his understanding of the natural world. Like the rest of nature, man's mind is subject to the laws of causation, Priestley contended, but because a benevolent God created these laws, the world and the people in it will eventually be perfected. Evil is therefore only an imperfect understanding of the world.
Although Priestley's philosophical work has been characterised as "audacious and original", it partakes of older philosophical traditions on the problems of free will, determinism, and materialism. For example, the 17th-century philosopher Baruch Spinoza argued for absolute determinism and absolute materialism. Like Spinoza and Priestley,
Leibniz argued that human will was completely determined by natural laws;
however, unlike them, Leibniz argued for a "parallel universe" of immaterial objects (such as human souls) so arranged by God that its outcomes agree exactly with those of the material universe.
Leibniz
and Priestley
share an optimism that God has chosen the chain of events benevolently; however, Priestley believed that the events were leading to a glorious Millennial conclusion, whereas for Leibniz the entire chain of events was optimal in and of itself, as compared with other conceivable chains of events.
Founder of Unitarianism.
When Priestley's friend Theophilus Lindsey decided to found a new Christian denomination that would not restrict its members' beliefs, Priestley and others hurried to his aid. On 17 April 1774, Lindsey held the first Unitarian service in Britain, at the newly formed Essex Street Chapel in London; he had even designed his own liturgy, of which many were critical. Priestley defended his friend in the pamphlet "Letter to a Layman, on the Subject of the Rev. Mr. Lindsey's Proposal for a Reformed English Church" (1774), claiming that only the form of worship had been altered, not its substance, and attacking those who followed religion as a fashion. Priestley attended Lindsey's church regularly in the 1770s and occasionally preached there. He continued to support institutionalised Unitarianism for the rest of his life, writing several "Defenses" of Unitarianism and encouraging the foundation of new Unitarian chapels throughout Britain and the United States.
Experiments and Observations on Different Kinds of Air.
Priestley's years in Calne were the only ones in his life dominated by scientific investigations; they were also the most scientifically fruitful. His experiments were almost entirely confined to "airs", and out of this work emerged his most important scientific texts: the six volumes of "Experiments and Observations on Different Kinds of Air" (1774â86). These experiments helped repudiate the last vestiges of the theory of four elements, which Priestley attempted to replace with his own variation of phlogiston theory. According to that 18th-century theory, the combustion or oxidation of a substance corresponded to the release of a material substance, "phlogiston".
Priestley's work on "airs" is not easily classified. As historian of science Simon Schaffer writes, it "has been seen as a branch of physics, or chemistry, or natural philosophy, or some highly idiosyncratic version of Priestley's own invention". Furthermore, the volumes were both a scientific and a political enterprise for Priestley, in which he argues that science could destroy "undue and usurped authority" and that government has "reason to tremble even at an air pump or an electrical machine".
Volume I of "Experiments and Observations on Different Kinds of Air" outlined several discoveries: "nitrous air" (nitric oxide, NO); "vapor of spirit of salt", later called "acid air" or "marine acid air" (anhydrous hydrochloric acid, HCl); "alkaline air" (ammonia, NH3); "diminished" or "dephlogisticated nitrous air" (nitrous oxide, N2O); and, most famously, "dephlogisticated air" (oxygen, O2) as well as experimental findings that showed plants revitalised enclosed volumes of air, a discovery that would eventually lead to the discovery of photosynthesis. Priestley also developed a "nitrous air test" to determine the "goodness of air". Using a pneumatic trough, he would mix nitrous air with a test sample, over water or mercury, and measure the decrease in volumeâthe principle of eudiometry. After a small history of the study of airs, he explained his own experiments in an open and sincere style. As an early biographer writes, "whatever he knows or thinks he tells: doubts, perplexities, blunders are set down with the most refreshing candour." Priestley also described his cheap and easy-to-assemble experimental apparatus; his colleagues therefore believed that they could easily reproduce his experiments. Faced with inconsistent experimental results, Priestley employed phlogiston theory. This, however, led him to conclude that there were only three types of "air": "fixed", "alkaline", and "acid". Priestley dismissed the burgeoning chemistry of his day. Instead, he focused on gases and "changes in their sensible properties", as had natural philosophers before him. He isolated carbon monoxide (CO), but apparently did not realise that it was a separate "air".
Discovery of oxygen.
In August 1774 he isolated an "air" that appeared to be completely new, but he did not have an opportunity to pursue the matter because he was about to tour Europe with Shelburne. While in Paris, however, Priestley managed to replicate the experiment for others, including French chemist Antoine Lavoisier. After returning to Britain in January 1775, he continued his experiments and discovered "vitriolic acid air" (sulphur dioxide, SO2).
In March he wrote to several people regarding the new "air" that he had discovered in August. One of these letters was read aloud to the Royal Society, and a paper outlining the discovery, titled "An Account of further Discoveries in Air", was published in the Society's journal "Philosophical Transactions". Priestley called the new substance "dephlogisticated air", which he made in the famous experiment by focusing the sunâs rays on a sample of mercuric oxide. He first tested it on mice, who surprised him by surviving quite a while entrapped with the air, and then on himself, writing that it was "five or six times better than common air for the purpose of respiration, inflammation, and, I believe, every other use of common atmospherical air". He had discovered oxygen gas (O2).
Priestley assembled his oxygen paper and several others into a second volume of "Experiments and Observations on Air", published in 1776. He did not emphasise his discovery of "dephlogisticated air" (leaving it to Part III of the volume) but instead argued in the preface how important such discoveries were to rational religion. His paper narrated the discovery chronologically, relating the long delays between experiments and his initial puzzlements; thus, it is difficult to determine when exactly Priestley "discovered" oxygen. Such dating is significant as both Lavoisier and Swedish pharmacist Carl Wilhelm Scheele have strong claims to the discovery of oxygen as well, Scheele having been the first to isolate the gas (although he published after Priestley) and Lavoisier having been the first to describe it as purified "air itself entire without alteration" (that is, the first to explain oxygen without phlogiston theory).
In his paper "Observations on Respiration and the Use of the Blood", Priestley was the first to suggest a connection between blood and air, although he did so using phlogiston theory. In typical Priestley fashion, he prefaced the paper with a history of the study of respiration. A year later, clearly influenced by Priestley, Lavoisier was also discussing respiration at the AcadÃ©mie des sciences. Lavoisier's work began the long train of discovery that produced papers on oxygen respiration and culminated in the overthrow of phlogiston theory and the establishment of modern chemistry.
Around 1779 Priestley and Shelburne had a rupture, the precise reasons for which remain unclear. Shelburne blamed Priestley's health, while Priestley claimed Shelburne had no further use for him. Some contemporaries speculated that Priestley's outspokenness had hurt Shelburne's political career. Schofield argues that the most likely reason was Shelburne's recent marriage to Louisa Fitzpatrickâapparently, she did not like the Priestleys. Although Priestley considered moving to America, he eventually accepted Birmingham New Meeting's offer to be their minister.
Both Priestley and Shelburne's families upheld their Unitarian faith for generations. 
In December 2013, it was reported that Sir Christopher Bullock - the direct descendant of Shelburne's brother, Thomas Fitzmaurice (MP), had married his wife, Lady Bullock, nÃ©e Barbara May Lupton, at London's Unitarian Essex Church in 1917. Barbara Lupton was the second cousin of Olive Middleton, nÃ©e Lupton - the great grandmother of Catherine, Duchess of Cambridge. In 1914, Olive and Noel Middleton had married at Leeds' Mill Hill Chapel, which Priestly, as its minister, had once guided towards Unitarianism.
Birmingham (1780â91).
In 1780 the Priestleys moved to Birmingham and spent a happy decade surrounded by old friends, until they were forced to flee in 1791 by religiously motivated mob violence in what became known as the Priestley Riots. Priestley accepted the ministerial position at New Meeting on the condition that he be required to preach and teach only on Sundays, so that he would have time for his writing and scientific experiments. As in Leeds, Priestley established classes for the youth of his parish and by 1781, he was teaching 150 students. Because Priestley's New Meeting salary was only 100 guineas, friends and patrons donated money and goods to help continue his investigations. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1782.
Chemical Revolution.
Many of the friends that Priestley made in Birmingham were members of the Lunar Society, a group of manufacturers, inventors, and natural philosophers who assembled monthly to discuss their work. The core of the group included men such as the manufacturer Matthew Boulton, the chemist and geologist James Keir, the inventor and engineer James Watt, and the botanist, chemist, and geologist William Withering. Priestley was asked to join this unique society and contributed much to the work of its members. As a result of this stimulating intellectual environment, he published several important scientific papers, including "Experiments relating to Phlogiston, and the seeming Conversion of Water into Air" (1783). The first part attempts to refute Lavoisier's challenges to his work on oxygen; the second part describes how steam is "converted" into air. After several variations of the experiment, with different substances as fuel and several different collecting apparatuses (which produced different results), he concluded that air could travel through more substances than previously surmised, a conclusion "contrary to all the known principles of hydrostatics". This discovery, along with his earlier work on what would later be recognised as gaseous diffusion, would eventually lead John Dalton and Thomas Graham to formulate the kinetic theory of gases.
In 1777, Antoine Lavoisier had written "MÃ©moire sur la combustion en gÃ©nÃ©ral", the first of what proved to be a series of attacks on phlogiston theory; it was against these attacks that Priestley responded in 1783. While Priestley accepted parts of Lavoisier's theory, he was unprepared to assent to the major revolutions Lavoisier proposed: the overthrow of phlogiston, a chemistry based conceptually on elements and compounds, and a new chemical nomenclature. Priestley's original experiments on "dephlogisticated air" (oxygen), combustion, and water provided Lavoisier with the data he needed to construct much of his system; yet Priestley never accepted Lavoisier's new theories and continued to defend phlogiston theory for the rest of his life. Lavoisier's system was based largely on the "quantitative" concept that mass is neither created nor destroyed in chemical reactions (i.e., the conservation of mass). By contrast, Priestley preferred to observe "qualitative" changes in heat, color, and particularly volume. His experiments tested "airs" for "their solubility in water, their power of supporting or extinguishing flame, whether they were respirable, how they behaved with acid and alkaline air, and with nitric oxide and inflammable air, and lastly how they were affected by the electric spark."
By 1789, when Lavoisier published his "TraitÃ© ÃlÃ©mentaire de Chimie" and founded the "Annales de Chimie", the new chemistry had come into its own. Priestley published several more scientific papers in Birmingham, the majority attempting to refute Lavoisier. Priestley and other Lunar Society members argued that the new French system was too expensive, too difficult to test, and unnecessarily complex. Priestley in particular rejected its "establishment" aura. In the end, Lavoisier's view prevailed: his new chemistry introduced many of the principles on which modern chemistry is founded.
Priestley's refusal to accept Lavoisier's "new chemistry"âsuch as the conservation of massâand his determination to adhere to a less satisfactory theory has perplexed many scholars. Schofield explains it thus: "Priestley was never a chemist; in a modern, and even a Lavoisierian, sense, he was never a scientist. He was a natural philosopher, concerned with the economy of nature and obsessed with an idea of unity, in theology and in nature." Historian of science John McEvoy largely agrees, writing that Priestley's view of nature as coextensive with God and thus infinite, which encouraged him to focus on facts over hypotheses and theories, prompted him to reject Lavoisier's system. McEvoy argues that "Priestley's isolated and lonely opposition to the oxygen theory was a measure of his passionate concern for the principles of intellectual freedom, epistemic equality and critical inquiry." Priestley himself claimed in the last volume of "Experiments and Observations" that his most valuable works were his theological ones because they were "superior dignity and importance".
Defender of English Dissenters and French revolutionaries.
Although Priestley was busy defending phlogiston theory from the "new chemists", most of what he published in Birmingham was theological. In 1782 he published the fourth volume of his "Institutes", "An History of the Corruptions of Christianity", describing how he thought the teachings of the early Christian church had been "corrupted" or distorted. Schofield describes the work as "derivative, disorganized, wordy, and repetitive, detailed, exhaustive, and devastatingly argued". The text addresses issues ranging from the divinity of Christ to the proper form for the Lord's Supper. Priestley followed up in 1786 with the provocatively titled book, "An History of Early Opinions concerning Jesus Christ, compiled from Original Writers, proving that the Christian Church was at first Unitarian". Thomas Jefferson would later write of the profound effect that these two books had on him: "I have read his Corruptions of Christianity, and Early Opinions of Jesus, over and over again; and I rest on themÂ ... as the basis of my own faith. These writings have never been answered." Although a few readers such as Jefferson and other Rational Dissenters approved of the work, it was harshly reviewed because of its extreme theological positions, particularly its rejection of the Trinity.
In 1785, while Priestley was engaged in a pamphlet war over "Corruptions", he also published "The Importance and Extent of Free Enquiry", claiming that the Reformation had not really reformed the church. In words that would boil over into a national debate, he challenged his readers to enact change:
Let us not, therefore, be discouraged, though, for the present, we should see no great number of churches professedly unitarianÂ ... We are, as it were, laying gunpowder, grain by grain, under the old building of error and superstition, which a single spark may hereafter inflame, so as to produce an instantaneous explosion; in consequence of which that edifice, the erection of which has been the work of ages, may be overturned in a moment, and so effectually as that the same foundation can never be built upon againÂ ...
Although discouraged by friends from using such inflammatory language, Priestley refused to back down from his opinions in print and he included it, forever branding himself as "Gunpowder Joe". After the publication of this seeming call for revolution in the midst of the French Revolution, pamphleteers stepped up their attacks on Priestley and he and his church were even threatened with legal action.
In 1787, 1789, and 1790, Dissenters again tried to repeal the Test and Corporation Acts. Although initially it looked as if they might succeed, by 1790, with the fears of revolution looming in Parliament, few were swayed by appeals to equal rights. Political cartoons, one of the most effective and popular media of the time, skewered the Dissenters and Priestley. In Parliament, William Pitt and Edmund Burke argued against the repeal, a betrayal that angered Priestley and his friends, who had expected the two men's support. Priestley wrote a series of "Letters to William Pitt" and "Letters to Burke" in an attempt to persuade them otherwise, but these publications only further inflamed the populace against him.
Dissenters such as Priestley who supported the French Revolution came under increasing suspicion as scepticism regarding the revolution grew. In its propaganda against "radicals", Pitt's administration used the "gunpowder" statement to argue that Priestley and other Dissenters wanted to overthrow the government. Burke, in his famous "Reflections on the Revolution in France" (1790), tied natural philosophers, and specifically Priestley, to the French Revolution, writing that radicals who supported science in Britain "considered man in their experiments no more than they do mice in an air pump". Burke also associated republican principles with alchemy and insubstantial air, mocking the scientific work done by both Priestley and French chemists. He made much in his later writings of the connections between "Gunpowder Joe", science, and Lavoisierâwho was improving gunpowder for the French in their war against Britain. Paradoxically, a secular statesman, Burke, argued against science and maintained that religion should be the basis of civil society, whereas a Dissenting minister, Priestley, argued that religion could not provide the basis for civil society and should be restricted to one's private life.
Birmingham riots of 1791.
The animus that had been building against Dissenters and supporters of the American and French Revolutions exploded in July 1791. Priestley and several other Dissenters had arranged to have a celebratory dinner on the anniversary of the storming of the Bastille, a provocative action in a country where many disapproved of the French Revolution and feared that it might spread to Britain. Amid fears of violence, Priestley was convinced by his friends not to attend. Rioters gathered outside the hotel during the banquet and attacked the attendees as they left. The rioters moved on to the New Meeting and Old Meeting churchesâand burned both to the ground. Priestley and his wife fled from their home; although their son William and others stayed behind to protect their property, the mob overcame them and torched Priestley's house "Fairhill" at Sparkbrook, destroying his valuable laboratory and all of the family's belongings. Twenty-six other Dissentersâ homes and three more churches were burned in the three-day riot. Priestley spent several days hiding with friends until he was able to travel safely to London. The carefully executed attacks of the "mob" and the farcical trials of only a handful of the "leaders" convinced many at the timeâand modern historians laterâthat the attacks were planned and condoned by local Birmingham magistrates. When George III was eventually forced to send troops to the area, he said: "I cannot but feel better pleased that Priestley is the sufferer for the doctrines he and his party have instilled, and that the people see them in their true light."
Hackney (1791â94).
Unable to return to Birmingham, the Priestleys eventually settled in Lower Clapton, a district in Hackney, Middlesex where he gave a series of lectures on history and natural philosophy at the Dissenting academy, the New College at Hackney. Friends helped the couple rebuild their lives, contributing money, books, and laboratory equipment. Priestley tried to obtain restitution from the government for the destruction of his Birmingham property, but he was never fully reimbursed. He also published "An Appeal to the Public on the Subject of the Riots in Birmingham" (1791), which indicted the people of Birmingham for allowing the riots to occur and for "violating the principles of English government".
The couple's friends urged them to leave Britain and emigrate to either France or the new United States, even though Priestley had received an appointment to preach for the Gravel Pit Meeting congregation. Priestley was minister between 1793 and 1794 and the sermons he preached there, particularly the two Fast Sermons, reflect his growing millenarianism, his belief that the end of the world was fast approaching. After comparing Biblical prophecies to recent history, Priestley concluded that the French Revolution was a harbinger of the Second Coming of Christ. Priestley's works had always had a millennial cast, but after the beginning of the French Revolution, this strain increased. He wrote to a younger friend that while he himself would not see the Second Coming, his friend "may probably live to see itÂ ... It cannot, I think be more than twenty years ."
Daily life became more difficult for the family: Priestley was burned in effigy along with Thomas Paine; vicious political cartoons continued to be published about him; letters were sent to him from across the country, comparing him to the devil and Guy Fawkes; tradespeople feared the family's business; and Priestley's Royal Academy friends distanced themselves. As the penalties became harsher for those who spoke out against the government, Priestley examined options for removing himself and his family from England.
Joseph Priestley's son William was presented to the French Assembly and granted letters of naturalization on 8 June 1792. Priestley learned about it from the "Morning Chronicle". A decree of 26 August 1792 by the French National Assembly conferred French citizenship on Joseph Priestley and others who had "served the cause of liberty" by their writings. Priestley accepted French citizenship, considering it "the greatest of honours". In the French National Convention election on 5 September 1792, Joseph Priestley was elected to the French National Convention by at least two departments, (Orne and RhÃ´ne-et-Loire). However, he declined the honor, on the grounds that he was not fluent in French.
As relations between England and France worsened, however, a removal to France became impracticable. Following the declaration of war of February 1793, and the Aliens Bill of March 1793, which forbade correspondence or travel between England and France, William Priestley left France for America. Joseph Priestley's sons Harry and Joseph chose to leave England for America in August 1793. Finally Priestley himself followed with his wife, boarding the "Sansom" at Gravesend on 7 April 1793. Five weeks after Priestley left, William Pitt's administration began arresting radicals for seditious libel, resulting in the famous 1794 Treason Trials.
Pennsylvania (1794â1804).
The Priestleys arrived in New York City in 1794, where they were fÃªted by various political factions vying for Priestley's endorsement. Priestley declined their entreaties, hoping to avoid political discord in his new country. Before travelling to a new home in the backwoods of Northumberland County, Pennsylvania, at Point township (now Northumberland borough), Dr and Mrs Priestley lodged in Philadelphia, where Priestley gave a series of sermons which led to the founding of the First Unitarian Church of Philadelphia. Priestley turned down an opportunity to teach chemistry at the University of Pennsylvania.
Priestley's son Joseph Priestley Jr. was a leading member of a consortium that had purchased 300,000 acres of virgin woodland between the forks of Loyalsock Creek, which they intended to lease or sell in 400-acre plots, with payment deferred to seven annual instalments, with interest. His brothers, William and Henry, bought a 284-acre plot of woodland which they attempted to transform into a farm, later called "Fairhill", felling and uprooting trees, and making lime to sweeten the soil by building their own lime kilns. Henry Priestley died 11 December 1795, possibly of malaria which he may have contracted after landing at New York. Mary Priestley's health, already poor, deteriorated further; although William's wife, Margaret Foulke-Priestley, moved in with the couple to nurse Mary twenty-four hours a day, Mary Priestley died 17 September 1796. Dr Priestley now moved in with his elder son, Joseph Jr., and wife Elizabeth Ryland-Priestley. Thomas Cooper, whose son, Thomas Jr., was living with the Priestleys, was a frequent visitor.
Since his arrival in America, Priestley had continued to defend his Christian Unitarian beliefs; now, falling increasingly under the influence of Thomas Cooper and Elizabeth Ryland-Priestley, he was unable to avoid becoming embroiled in political controversy. In 1798, when, in response to the Pinckney affair, a belligerent President Adams sought to enlarge the navy and mobilise the militia into what Priestley and Cooper saw as a 'standing army', Priestley published an anonymous newspaper article: "Maxims of political arithmetic", which attacked Adams, defended free trade, and advocated a form of Jeffersonian isolationism. In the same year, a small package, addressed vaguely: "Dr Priestley in America," was seized by the Royal Navy on board a neutral Danish boat. It was found to contain three letters, one of which was signed by the radical printer John Hurford Stone. These intercepted letters were published in London, and copied in numerous papers in America. One of the letters was addressed to "MBP", with a note: "I inclose a note for our friend MBPâbut, as ignorant of the name he bears at present among you, I must beg you to seal and address it." This gave the intercepted letters a tinge of intrigue. Fearful lest they be taken as evidence of him being a 'spy in the interest of France', Priestley sent a clumsy letter to numerous newspaper editors, in which he naively named "MBP" (Member of the British Parliament) as Mr. Benjamin Vaughan, who "like me, thought it necessary to leave England, and for some time is said to have assumed a feigned name." William Cobbett, in his "Porcupine's Gazette", 20 August 1798, added that Priestley "has told us who Mr MBP is, and has confirmed me in the opinion of their both being spies in the interest of France."
Joseph Priestley Jr. left on a visit to England at Christmas 1798, not returning until August 1800. In his absence, his wife Elizabeth Ryland-Priestley and Thomas Cooper became increasing close, collaborating in numerous political essays. Priestley allowed himself to fall too heavily under Elizabeth and Cooper's influences, even helping hawk a seditious handbill Cooper had printed, around Point township, and across the Susquehanna at Sunbury. In September 1799, William Cobbett printed extracts from this handbill, asserting that: "Dr Priestley has taken great pains to circulate this address, has travelled through the country for the purpose, and is in fact the patron of it." He challenged Priestley to "clear himself of the accusation" or face prosecution." Barely a month later, in November and December 1799, Priestley stepped forward in his own defence, with his "Letters to the inhabitants of Northumberland".
Priestleyâs son, William, now living in Philadelphia, was increasingly embarrassed by his father's actions. He confronted his father, expressing John and Benjamin Vaughanâs unease, his own wife's concerns about Elizabeth Ryland-Priestley's dietary care, and his own concerns at the closeness of Elizabeth Ryland-Priestley and Thomas Cooper's relationship, and their adverse influence on Dr Priestley; but this only led to a further estrangement between William and his sister-in-law. When, a while later, Priestley's household suffered a bout of food poisoning, perhaps from puking sickness or a bacterial infection, Elizabeth Ryland-Priestley, falsely accused William of having poisoned the family's flour. Although this allegation has attracted the attention of some modern historians, it is believed to be without foundation.
Priestley continued the educational projects that had always been important to him, helping to establish the "Northumberland Academy" and donating his library to the fledgling institution. He exchanged letters regarding the proper structure of a university with Thomas Jefferson, who used this advice when founding the University of Virginia. Jefferson and Priestley became close, and when he had completed his "General History of the Christian Church", he dedicated it to President Jefferson, writing that "it is now only that I can say I see nothing to fear from the hand of power, the government under which I live being for the first time truly favourable to me."
Priestley tried to continue his scientific investigations in America with the support of the American Philosophical Association. He was hampered by lack of news from Europe; unaware of the latest scientific developments, Priestley was no longer on the forefront of discovery. Although the majority of his publications focused on defending phlogiston theory, he also did some original work on spontaneous generation and dreams. Despite Priestley's reduced scientific output, his presence stimulated American interest in chemistry.
By 1801, Priestley had become so ill that he could no longer write or experiment. He died on the morning of 6 February 1804, aged seventy and was buried at Riverview Cemetery in Northumberland, Pennsylvania.
Priestley's epitaph reads:
Legacy.
By the time he died in 1804, Priestley had been made a member of every major scientific society in the Western world and he had discovered numerous substances. The 19th-century French naturalist George Cuvier, in his eulogy of Priestley, praised his discoveries while at the same time lamenting his refusal to abandon phlogiston theory, calling him "the father of modern chemistry never acknowledged his daughter". Priestley published more than 150 works on topics ranging from political philosophy to education to theology to natural philosophy. He led and inspired British radicals during the 1790s, paved the way for utilitarianism, and helped found Unitarianism. A wide variety of philosophers, scientists, and poets became associationists as a result of his redaction of David Hartley's "Observations on Man", including Erasmus Darwin, Coleridge, William Wordsworth, John Stuart Mill, Alexander Bain, and Herbert Spencer. Immanuel Kant praised Priestley in his "Critique of Pure Reason" (1781), writing that he "knew how to combine his paradoxical teaching with the interests of religion". Indeed, it was Priestley's aim to "put the most 'advanced' Enlightenment ideas into the service of a rationalized though heterodox Christianity, under the guidance of the basic principles of scientific method".
Considering the extent of Priestley's influence, relatively little scholarship has been devoted to him. In the early 20th century, Priestley was most often described as a conservative and dogmatic scientist who was nevertheless a political and religious reformer. In a historiographic review essay, historian of science Simon Schaffer describes the two dominant portraits of Priestley: the first depicts him as "a playful innocent" who stumbled across his discoveries; the second portrays him as innocent as well as "warped" for not understanding their implications better. Assessing Priestley's works as a whole has been difficult for scholars because of his wide-ranging interests. His scientific discoveries have usually been divorced from his theological and metaphysical publications to make an analysis of his life and writings easier, but this approach has been challenged recently by scholars such as John McEvoy and Robert Schofield. Although early Priestley scholarship claimed that his theological and metaphysical works were "distractions" and "obstacles" to his scientific work, scholarship published in the 1960s, 1970s, and 1980s maintained that Priestley's works constituted a unified theory. However, as Schaffer explains, no convincing synthesis of his work has yet been expounded. More recently, in 2001, historian of science Dan Eshet has argued that efforts to create a "synoptic view" have resulted only in a rationalisation of the contradictions in Priestley's thought, because they have been "organized around philosophical categories" and have "separate the producers of scientific ideas from any social conflict".
Priestley has been remembered by the towns in which he served as a reforming educator and minister and by the scientific organisations he influenced. Two educational institutions have been named in his honourâPriestley College in Warrington and Joseph Priestley College in Leeds (now part of Leeds City College)âand an asteroid, 5577 Priestley, discovered in 1986 by Duncan Waldron. In Birstall, the Leeds City Square, and in Birmingham, he is memorialised through statues, and plaques commemorating him have been posted in Birmingham, Calne and Warrington. Also, since 1952 Dickinson College, Pennsylvania, has presented the Priestley Award to a scientist who makes "discoveries which contribute to the welfare of mankind". The main undergraduate chemistry laboratories at the University of Leeds were refurbished as part of a Â£4m refurbishment plan in 2006 and renamed as the Priestley Laboratories in his honour as a prominent chemist from Leeds.
Additional recognition for Priestley's work is marked by a National Historic Chemical Landmark designation for his discovery of oxygen, made on 1 August 1994, at the Priestley House in Northumberland, Penn., by the American Chemical Society. Similar international recognition was made on 7 August 2000, at Bowood House in Wiltshire, UK.
References.
Biographies.
The most exhaustive biography of Priestley is Robert Schofield's recent two-volume work; several one-volume treatments exist, all somewhat older: Gibbs, Holt and Thorpe. Graham and Smith focus on Priestley's life in America and Uglow and Jackson both discuss Priestley's life in the context of other developments in science.

</doc>
<doc id="40177" url="https://en.wikipedia.org/wiki?curid=40177" title="550s BC">
550s BC


</doc>
<doc id="40178" url="https://en.wikipedia.org/wiki?curid=40178" title="7th millennium BC">
7th millennium BC

During the 7th millennium BC, agriculture spreads from Anatolia to the Balkans.
World population was essentially stable at around 5 million people, living mostly scattered around the globe in small hunter-gatherer bands. In the agricultural communities of the Middle East, the cow was domesticated and use of pottery became common, spreading to Europe and South Asia, and the first metal (gold and copper) ornaments were made.

</doc>
<doc id="40179" url="https://en.wikipedia.org/wiki?curid=40179" title="6th millennium BC">
6th millennium BC

During the 6th millennium BC, agriculture spread from the Balkans to Italy and Eastern Europe, and also from Mesopotamia to Egypt. World population was essentially stable at numbers ranging between approximately 5 and 7 million.

</doc>
<doc id="40180" url="https://en.wikipedia.org/wiki?curid=40180" title="Bessemer process">
Bessemer process

The Bessemer process was the first inexpensive industrial process for the mass-production of steel from molten pig iron prior to the open hearth furnace. The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron. The oxidation also raises the temperature of the iron mass and keeps it molten.
Related decarburizing with air processes had been used outside of Europe for hundreds of years, but not on an industrial scale. The process has existed since the 11th century in East Asia, where the scholar Shen Kuo describes its use in the Chinese iron and steel industry. In the 17th century, accounts by European travelers detailed its possible use by the Japanese. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was also claimed to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back this claim up.
The process using a basic refractory lining is known as the "basic Bessemer process" or "Gilchrist-Thomas process" after the discoverer Sidney Gilchrist Thomas.
Details.
Oxidation.
The oxidation process removes and skims off impurities such as silicon, manganese, and carbon in the form of oxides. These oxides either escape as gas or form a solid slag. The refractory lining of the converter also plays a role in the conversionâthe clay lining is used in the "acid Bessemer", in which there is low phosphorus in the raw material. Dolomite is used when the phosphorus content is high in the alkaline Bessemer (limestone or magnesite linings are also sometimes used instead of dolomite)âthis is also known as a "Gilchrist-Thomas converter", named after its inventor, Sidney Gilchrist Thomas. In order to give the steel the desired properties, other substances could be added to the molten steel when conversion was complete, such as spiegeleisen (a ferromanganese alloy).
Managing the process.
When the required steel has been formed, it is poured out into ladles and then transferred into moulds while the lighter slag is left behind. The conversion process, called the "blow", is completed in around twenty minutes. During this period the progress of the oxidation of the impurities is judged by the appearance of the flame issuing from the mouth of the converter: the modern use of photoelectric methods of recording the characteristics of the flame has greatly aided the blower in controlling the final quality of the product. After the blow, the liquid metal is recarburized to the desired point and other alloying materials are added, depending on the desired product.
A Bessemer converter can treat a "heat," the term for a batch of hot metal, of 5 to 30 tons at a time. They usually are operated in pairs; one being blown while another being filled or tapped.
Predecessor processes.
Before the Bessemer process, Western Europe and the United States relied on the puddling process to reduce the carbon content of white cast iron (refined pig iron), converting it to wrought iron. It was possible to make low-quality puddled steel, but the process was difficult to control and quality varied. High-quality steel was made by the reverse process of adding carbon to carbon-free wrought iron, usually imported from Sweden. The manufacturing process, called the cementation process, consisted of heating bars of wrought iron together with charcoal for periods of up to a week in a long stone box. This produced blister steel. The blister steel was then put in a crucible with wrought iron and melted, producing crucible steel. Up to 3 tons of expensive coke was burnt for each ton of steel produced. Such steel when rolled into bars was sold at Â£50 to Â£60 (approximately Â£3,390 to Â£4,070 in 2008) a long ton. The most difficult and work-intensive part of the process, however, was the production of wrought iron done in finery forges in Sweden.
This process was refined in the 18th century with the introduction of Benjamin Huntsman's crucible steel-making techniques, which added an additional three hours firing time and required additional large quantities of coke. In making crucible steel the blister steel bars were broken into pieces and melted in small crucibles each containing 20Â kg or so. This produced higher quality crucible steel but increased the cost. The Bessemer process reduced the time needed to make steel of this quality to about half an hour while requiring only the coke needed to melt the pig iron initially. The earliest Bessemer converters produced steel for Â£7 a long ton, although it initially sold for around Â£40 a ton.
History.
A system akin to the Bessemer process has existed since the 11th century in East Asia. Economic historian Robert Hartwell writes that the Chinese of the Song Dynasty innovated a "partial decarbonization" method of repeated forging of cast iron under a cold blast. Sinologist Joseph Needham and historian of metallurgy Theodore A. Wertime have described the method as a predecessor to the Bessemer process of making steel. This process was first described by the prolific scholar and polymath government official Shen Kuo (1031â1095) in 1075 when he visited Cizhou. Hartwell states that perhaps the earliest center where this was practiced was the great iron-production district along the Henan-Hebei border during the 11th century. In the 15th century the finery process, another process which shares the air-blowing principle with the Bessemer process, was developed in Europe, having first been independently developed in the 11th century by the Chinese. In 1740 Benjamin Huntsman developed the crucible technique for steel manufacture, at his workshop in the district of Handsworth in Sheffield. This process had an enormous impact on the quantity and quality of steel production, but it was unrelated to the Bessemer-type process employing decarburization.
The Japanese may have made use of the Bessemer process, which was observed by European travelers in the 17th century. The adventurer Johan Albrecht de Mandelslo describes the process in a book published in English in 1669. He writes, "They have, among others, particular invention for the melting of iron, without the using of fire, casting it into a tun done about on the inside without about half a foot of earth, where they keep it with continual blowing, take it out by ladles full, to give it what form they please." According to historian Donald Wagner, Madelslo did not personally visit Japan, so his description of the process is likely derived from the accounts of other Europeans who had traveled to Japan. Wagner believes there is a possibility that the Japanese process is similar to the Bessemer process, but cautions that alternative explanations are also plausible.
In the early 1850s, the American inventor William Kelly experimented with a method similar to the Bessemer process. Wagner writes that Kelly may have been inspired by techniques introduced by Chinese ironworkers hired by Kelly in 1854. When Bessemer's patent for the process was reported by "Scientific American", Kelly responded by writing a letter to the magazine. In the letter, Kelly states that he had previously experimented with the process and claimed that Bessemer knew of Kelly's discovery. He wrote that "I have reason to believe my discovery was known in England three or four years ago, as a number of English puddlers visited this place to see my new process. Several of them have since returned to England and may have spoken of my invention there."
Sir Henry Bessemer described the origin of his invention in his autobiography written in 1890. During the outbreak of the Crimean War, many English industrialists and inventors became interested in military technology. According to Bessemer, his invention was inspired by a conversation with Napoleon III in 1854 pertaining to the steel required for better artillery. Bessemer claimed that it "was the spark which kindled one of the greatest revolutions that the present century had to record, for during my solitary ride in a cab that night from Vincennes to Paris, I made up my mind to try what I could to improve the quality of iron in the manufacture of guns." At the time steel was used to make only small items like cutlery and tools, but was too expensive for cannons. Starting in January 1855 he began working on a way to produce steel in the massive quantities required for artillery and by October he filed his first patent related to the Bessemer process. He patented the method a year later in 1856.
According to his autobiography Bessemer was working with an ordinary reverberatory furnace but during a test, some pieces of pig iron were jostled off the side of the ladle, and were left above the ladle in the furnace's heat. When Bessemer went to push them into the ladle, he found that they were steel shells: the hot air alone had converted the outsides of the iron pieces to steel. This crucial discovery led him to completely redesign his furnace so that it would force high-pressure air through the molten iron using special air pumps. Intuitively this would seem to be folly because it would cool the iron. Instead, the oxygen in the forced air ignited silicon and carbon impurities in the iron, starting a positive feedback loop. As the iron became hotter, more impurities burned off, making the iron even hotter and burning off more impurities, producing a batch of hotter, purer, molten iron, which converts to steel more easily.
Bessemer licensed the patent for his process to four ironmasters, for a total of Â£27,000, but the licensees failed to produce the quality of steel he had promisedâit was "rotten hot and rotten cold", according to his friend, William Clayâand he later bought them back for Â£32,500. His plan had been to offer the licenses to one company in each of several geographic areas, at a royalty price per ton that included a lower rate on a proportion of their output in order to encourage production, but not so large a proportion that they might decide to reduce their selling prices. By this method he hoped to cause the new process to gain in standing and market share.
He realised that the technical problem was due to impurities in the iron and concluded that the solution lay in knowing when to turn off the flow of air in his process so that the impurities were burned off but just the right amount of carbon remained. However, despite spending tens of thousands of pounds on experiments, he could not find the answer. Certain grades of steel are sensitive to the 78% nitrogen which was part of the air blast passing through the steel.
Bessemer was sued by the patent purchasers who couldn't get it to work. In the end Bessemer set up his own steel company because he knew how to do it, even though he could not convey it to his patent users. Bessemer's company became one of the largest in the world and changed the face of steel making.
The solution was first discovered by English metallurgist Robert Forester Mushet, who had carried out thousands of experiments in the Forest of Dean. His method was to first burn off, as far as possible, "all" the impurities and carbon, then reintroduce carbon and manganese by adding an exact amount of spiegeleisen. This had the effect of improving the quality of the finished product, increasing its malleabilityâits ability to withstand rolling and forging at high temperatures and making it more suitable for a vast array of uses.
The first company to license the process was the Manchester firm of W & J Galloway, and they did so before Bessemer announced it at Cheltenham in 1856. They are not included in his list of the four to whom he refunded the license fees. However, they subsequently rescinded their license in 1858 in return for the opportunity to invest in a partnership with Bessemer and others. This partnership began to manufacture steel in Sheffield from 1858, initially using imported charcoal pig iron from Sweden. This was the first commercial production.
Sidney Gilchrist Thomas, a Londoner with a Welsh father, was an industrial chemist who decided to tackle the problem of phosphorus in iron, which resulted in the production of low grade steel. Believing that he had discovered a solution, he contacted his cousin, Percy Gilchrist, who was a chemist at the Blaenavon ironworks. The manager at the time, Edward Martin, offered Sidney equipment for large-scale testing and helped him draw up a patent that was taken out in May, 1878. Sidney Gilchrist Thomas's invention consisted of using dolomite or sometimes limestone linings for the Bessemer converter rather than clay, and it became known as the 'basic' Bessemer rather than the 'acid' Bessemer process. An additional advantage was that the processes formed more slag in the converter, and this could be recovered and used very profitably as a phosphate fertilizer.
Patent battles.
Patents of such value did not escape criticism, and invalidity was urged against them on various grounds. But Bessemer was able to maintain them intact without litigation, though he found it advisable to buy up the rights of one patentee.
In the case of Robert Forester Mushet, he was assisted by the patent being allowed to lapse in 1859 through non-payment of fees. Mushet's procedure was not essential and Bessemer proved this in 1865 by exhibiting a series of steel samples made using his process alone, but the value of the procedure was shown by its near universal adoption in conjunction with the Bessemer process. Whether or not Mushet's patents could have been sustained is not known, but in 1866 Robert Mushet's 16-year-old daughter travelled to London to confront Henry Bessemer at his offices, arguing that Bessemer's success was based on the results of her fatherâs work. Bessemer decided to pay Mushet an annual pension of Â£300, a very considerable sum, which he paid for 25 years.
In 1866, Bessemer also provided finance for Zerah Colburn, the American locomotive engineer and journalist, to start a new weekly engineering newspaper called "Engineering" based in Bedford Street, London. It was not until many years later that the name of Colburn's benefactor was revealed. Prior to the launch of "Engineering", Colburn, through the pages of "The Engineer", had given support to Bessemer's work on steel and steelmaking.
Importance.
The Bessemer process revolutionized steel manufacture by decreasing its cost, from Â£40 per long ton to Â£6â7 per long ton, along with greatly increasing the scale and speed of production of this vital raw material. The process also decreased the labor requirements for steel-making. Prior to its introduction, steel was far too expensive to make bridges or the framework for buildings and thus wrought iron had been used throughout the Industrial Revolution. After the introduction of the Bessemer process, steel and wrought iron became similarly priced, and some users, primarily railroads, turned to steel. Quality problems, such as brittleness caused by nitrogen in the blowing air, prevented Bessemer steel from being used for many structural applications. Open-hearth steel was suitable for structural applications.
Steel greatly improved the productivity of railroads. Steel rails lasted ten times longer than iron rails. Steel rails, which became heavier as prices fell, could carry heavier locomotives, which could pull longer trains. Steel rail cars were longer and were able to increase the freight to car weight from 1:1 to 2:1.
As early as 1895 in the UK it was being noted that the heyday of the Bessemer process was over and that the open hearth method predominated. The "Iron and Coal Trades Review" said that it was "in a semi-moribund condition. Year after year, it has not only ceased to make progress, but it has absolutely declined." It has been suggested, both at that time and more recently, that the cause of this was the lack of trained personnel and investment in technology rather than anything intrinsic to the process itself. For example, one of the major causes of the decline of the giant ironmaking company Bolckow Vaughan of Middlesbrough was its failure to upgrade its technology. The basic process, the Thomas-Gilchrist process, remained longer in use, especially in Continental Europe, where iron ores were of high phosphorus content and open hearth process was not able to remove all phosphorus; almost all inexpensive construction steel in Germany was produced with this method in the 1950s and 1960s. It was eventually superseded by basic oxygen steelmaking.
The Bessemer Process in the United States.
While visiting Europe to obtain information on shipbuilding, armor, and armaments from 1862 to 1863, Alexander Lyman Holley visited Bessemer's Sheffield works, and expressed interest in licensing the process for use in the US. Upon returning to the US, Holley met with the famous inventor John Ericsson, who referred Holley to a pair of businessmen who had helped him build the Civil War ironclad USS Monitor, John F. Winslow and John Augustus Griswold. With Winslow and Griswold's support, Holley returned to England in 1863, and paid Bessemer Â£10,000 to license the technology. The trio began setting up a mill in Troy, New York in 1865. The factory contained a number of Holley's innovations that greatly improved productivity over Bessemer's factory in Sheffield, and the owners gave a successful public exhibition in 1867. The Troy factory attracted the attention of the Pennsylvania Railroad, who wanted to use the new process to manufacture steel rail, and ended up funding Holley's second mill as part of its Pennsylvania Steel subsidiary. Between 1866 and 1877, the partners were able to license a total of 11 Bessemer steel mills. One of the investors they attracted was Andrew Carnegie, who saw great promise in the new steel technology after a visit to Bessemer in 1872, and saw it as a useful adjunct to his existing businesses, the Keystone Bridge Company and the Union Iron Works. Holley built the new steel mill for Carnegie, and continued to improve and refine the process. The new mill, known as the Edgar Thomson Steel Works, opened in 1875, and started the growth of the United States as a major world steel producer.
Obsolescence.
In the U.S., commercial steel production using this method stopped in 1968. It was replaced by processes such as the basic oxygen (Linz-Donawitz) process, which offered better control of final chemistry. The Bessemer process was so fast (10â20 minutes for a heat) that it allowed little time for chemical analysis or adjustment of the alloying elements in the steel. Bessemer converters did not remove phosphorus efficiently from the molten steel; as low-phosphorus ores became more expensive, conversion costs increased. The process permitted only limited amount of scrap steel to be charged, further increasing costs, especially when scrap was inexpensive. Use of electric arc furnace technology competed favourably with the Bessemer process resulting in its obsolescence.
Basic oxygen steelmaking is essentially an improved version of the Bessemer process (decarburization by blowing oxygen as gas into the heat rather than burning the excess carbon away by adding oxygen carrying substances into the heat). The advantages of pure oxygen blast over air blast was known to Henry Bessemer, but the 19th-century technology was not advanced enough to allow for the production of the large quantities of pure oxygen to make it economically feasible for use.

</doc>
<doc id="40181" url="https://en.wikipedia.org/wiki?curid=40181" title="9th millennium BC">
9th millennium BC

The 9th millennium BC marks the beginning of the Neolithic period.
Agriculture spread throughout the Fertile Crescent and use of pottery became more widespread. Larger settlements like Jericho arose along salt and flint trade routes. Northern Eurasia was resettled as the glaciers of the last glacial maximum retreated. World population was at a few million people, likely below 5 million.

</doc>
<doc id="40182" url="https://en.wikipedia.org/wiki?curid=40182" title="Photomontage">
Photomontage

Photomontage is the process and the result of making a composite photograph by cutting, gluing, rearranging and overlapping two or more photographs into a new image. Sometimes the resulting composite image is photographed so that a final image may appear as a seamless photographic print. A similar method, although one that does not use film, is realized today through image-editing software. This latter technique is referred to by professionals as "compositing", and in casual usage is often called "photoshopping" (from the name of the most popular software). A composite of related photographs to extend a view of a single scene or subject would not be labeled as a montage.
History.
Author Oliver Grau in his book, "Virtual Art: From Illusion to Immersion", notes that the creation of artificial immersive virtual reality, arising as a result of technical exploitation of new inventions, is a long-standing human practice throughout the ages. Such environments as dioramas were made of composited images.
The first and most famous mid-Victorian photomontage (then called combination printing) was "The Two Ways of Life" (1857) by Oscar Rejlander, followed shortly thereafter by the images of photographer Henry Peach Robinson such as "Fading Away" (1858). These works actively set out to challenge the then-dominant painting and theatrical tableau vivants.
Fantasy photomontage postcards were popular in the Victorian and Edwardian periods. The preeminent producer in this period was the Bamforh Company, in Holmfirth, West Yorkshire, and New York. The high point of its popularity came, however, during World War I, when photographers in France, Great Britain, Germany, Austria, and Hungary produced a profusion of postcards showing soldiers on one plane and lovers, wives, children, families, or parents on another. Many of the early examples of fine-art photomontage consist of photographed elements superimposed on watercolours, a combination returned to by (e.g.) George Grosz in about 1915. He was part of the Dada movement in Berlin, which was instrumental in making montage into a modern art-form. They first coined the term "photomontage" at the end of World War I, around 1918 or 1919.
The other major exponents of photomontages were John Heartfield, Hannah HÃ¶ch, Kurt Schwitters, Raoul Hausmann, and Johannes Baader. Individual photographs combined together to create a new subject or visual image proved to be a powerful tool for the Dadists protesting World War I and the interests that they believed inspired the war. Photomontage survived Dada and was a technique inherited and used by European Surrealists such as Salvador DalÃ­. Its influence also spread to Japan where avant-garde painter Harue Koga produced photomontage-style paintings based on images culled from magazines. The world's first retrospective show of photomontage was held in Germany in 1931. A later term coined in Europe was, "photocollage", which usually referred to large and ambitious works that added typography, brushwork, or even objects stuck to the photomontage.
Parallel to the Germans, Russian Constructivist artists such as El Lissitzky, Alexander Rodchenko, and the husband-and-wife team of Gustav Klutsis and Valentina Kulagina created pioneering photomontage work as propaganda, such as the journal USSR in Construction, for the Soviet government. In the education sphere, media arts director Rene Acevedo and Adrian Brannan have left their mark on art classrooms the world over.
Following his exile to Mexico in the late 1930s, Spanish Civil War activist and montage artist, Joseph Renau, compiled his acclaimed, "Fata Morgana USA: the American Way of Life", a book of photomontage images highly critical of Americana and North American "consumer culture". His contemporary, Lola Alvarez Bravo, experimented with photomontage on life and social issues in Mexican cities.
In Argentina during the late 1940s, the German exile, Grete Stern, began to contribute photomontage work on the theme of "SueÃ±os" (Dreams), as part of a regular psychoanalytical article in the magazine, "Idilio".
The pioneering techniques of early photomontage artists were co-opted by the advertising industry from the late 1920s onward. The American photographer Alfred Gescheidt, while working primarily in advertising and commercial art in the 1960s and 1970s, used photomontage techniques to create satirical posters and postcards.
Techniques.
Other methods for combining images are also called photomontage, such as Victorian "combination printing", the printing of more than one negative on a single piece of printing paper (e.g. O. G. Rejlander, 1857), front-projection and computer montage techniques. Much as a collage is composed of multiple facets, artists also combine montage techniques. A series of black and white "photomontage projections" by Romare Bearden (1912â1988) is an example. His method began with compositions of paper, paint, and photographs put on boards measuring 8Â½ Ã 11Â inches. Bearden fixed the imagery with an emulsion that he then applied with hand roller. Subsequently, he photographed and enlarged them. The nineteenth century tradition of physically joining multiple images into a composite and photographing the results prevailed in press photography and offset lithography until the widespread use of digital image editing.
Contemporary photograph editors in magazines now create "paste-ups" digitally. Creating a photomontage has, for the most part, become easier with the advent of computer software such as Adobe Photoshop, Paint Shop Pro, Corel Photopaint, Pixelmator, Paint.NET, or GIMP. These programs make the changes digitally, allowing for faster workflow and more precise results. They also mitigate mistakes by allowing the artist to "undo" errors. Yet some artists are pushing the boundaries of digital image editing to create extremely time-intensive compositions that rival the demands of the traditional arts. The current trend is to create images that combine painting, theatre, illustration, and graphics in a seamless photographic whole.
Ethical issues.
A photomontage may contain elements at once real and imaginary. Combined photographs and digital manipulations may set up a conflict between aesthetics and ethics â for instance, in fake photographs that are presented to the world as real news. For example, in the United States, the National Press Photographers Association (NPPA) has set out a Code of Ethics promoting the accuracy of published images, advising that photographers "do not manipulate imagesÂ ... that can mislead viewers or misrepresent subjects."
Scrapbooking.
Photomontage also may be present in the scrapbooking phenomenon, in which family images are pasted into scrapbooks and a collage created along with paper ephemera and decorative items.
Digital art scrapbooking employs a computer to create simple collage designs and captions. The amateur scrapbooker can turn home projects into professional output, such as CDs, DVDs, displays on television, uploads to a website for viewing, or assemblies into one or more books for sharing.
Photograph manipulation.
Photograph manipulation refers to alterations made to an image. Often, the goal of photograph manipulation is to create another 'realistic' image. This has led to numerous political and ethical concerns, particularly in journalism.

</doc>
<doc id="40183" url="https://en.wikipedia.org/wiki?curid=40183" title="10th century BC">
10th century BC

The 10th century BC started the first day of 1000 BC and ended the last day of 901 BC. This period followed the Bronze Age collapse in the Near East, and the century saw the Early Iron Age take hold there. The Greek Dark Ages which had come about in 1200 BC continued. The Neo-Assyrian Empire is established towards the end of the 10th century BC. In Iron Age India, the Vedic period is ongoing. In China, the Zhou Dynasty is in power. The European Bronze Age continued with Urnfield culture. Japan was inhabited by an evolving hunter-gatherer society during the Jomon period.
Events.
Late 10th century BC: 
Sovereign States.
See: List of sovereign states in the 10th century BC.

</doc>
<doc id="40186" url="https://en.wikipedia.org/wiki?curid=40186" title="8th millennium BC">
8th millennium BC

In the 8th millennium BC, agriculture became widely practised in the Fertile Crescent and Anatolia.
Pottery became widespread (with independent development in Central America) and animal husbandry (pastoralism) spread to Africa and Eurasia. World population was approximately 5 million.

</doc>
<doc id="40187" url="https://en.wikipedia.org/wiki?curid=40187" title="Conjugate acid">
Conjugate acid

A conjugate acid, within the BrÃ¸nstedâLowry acidâbase theory, is a species formed by the reception of a proton (H+) by a baseâin other words, it is a base with a hydrogen ion added to it. On the other hand, a conjugate base is merely what is left after an acid has donated a proton in a chemical reaction. Hence, a conjugate base is a species formed by the removal of a proton from an acid.
In summary, this can be represented as the following chemical reaction:
Johannes Nicolaus BrÃ¸nsted and Martin Lowry introduced the BrÃ¸nstedâLowry theory,
which proposed that any compound that can transfer a proton to any other compound is an acid, and the compound that accepts the proton is a base. A proton is a nuclear particle with a unit positive electrical charge; it is represented by the symbol H+ because it constitutes the nucleus of a hydrogen atom, that is, a hydrogen cation.
A cation can be a conjugate acid, and an anion can be a conjugate base, depending on which substance is involved and which acidâbase theory is the viewpoint.
Acid-base reactions.
In an acid-base reaction, an acid plus a base reacts to form a conjugate base plus a conjugate acid:
Conjugates are formed when an acid loses a hydrogen proton or a base gains a hydrogen proton. Refer to the following figure:
We say that the water molecule is the conjugate acid of the hydroxide ion after the latter received the hydrogen proton donated by ammonium. On the other hand, ammonia is the conjugate base for the acid ammonium after ammonium has donated a hydrogen ion towards the production of the water molecule. We can also refer to OH- as a conjugate base of , since the water molecule donates a proton towards the production of in the reverse reaction, which is the predominating process in nature due to the strength of the base over the hydroxide ion. Based on this information, it is clear that the terms "Acid", "Base", "conjugate acid", and "conjugate base" are not fixed for a certain chemical species; but are interchangeable according to the reaction taking place.
Strength of conjugates.
The strength of a conjugate acid is directly proportional to its dissociation constant. If a conjugate acid is strong, its dissociation will have a higher equilibrium constant and the products of the reaction will be favored. The strength of a conjugate base can be seen as the tendency of the species to "pull" hydrogen protons towards itself. If a conjugate base is classified as strong, it will "hold on" to the hydrogen proton when in solution and its acid will not dissociate. 
If a chemical species is classified as a weak acid, its conjugate base will be strong in nature. This can be observed in ammonia's (relatively strong base) reaction with water. The reaction proceeds until most of the ammonia has been transformed to ammonium. This shift to the right in the chemical equilibrium of the reaction means that ammonium does not dissociate easily in water (weak acid), and its conjugate base is stronger than the hydroxide ion.
On the other hand, if a species is classified as a strong acid, its conjugate base will be weak in nature. An example of this case would be the dissociation of Hydrochloric acid in water. Since HCl is a strong acid (it dissociates to a great extent), its conjugate base (Cl-) will be a weak conjugate base. Therefore, in this system, most H+ will be in the form of a Hydronium ion + instead of attached to a Cl anion and the conjugate base will be weaker than a water molecule.
To summarize, the stronger the acid or base, the weaker the conjugate and vice versa.
Identifying conjugate acid-base pairs.
The acid and conjugate base as well as the base and conjugate acid are known as conjugate pairs. When finding a conjugate acid or base, it is important to look at the reactants of the chemical equation. In this case, the reactants are the acids and bases, and the acid corresponds to the conjugate base on the product side of the chemical equation; as does the base to the conjugate acid on the product side of the equation.
To identify the conjugate acid, look for the pair of compounds that are related. The acid-base reaction can be viewed in a before and after sense. The before is the reactant side of the equation, the after is the product side of the equation. The conjugate acid in the after side of an equation gains a hydrogen ion, so in the before side of the equation the compound that has one less hydrogen ion of the conjugate acid is the base. The conjugate base in the after side of the equation lost a hydrogen ion, so in the before side of the equation the compound that has one more hydrogen ion of the conjugate base is the acid.
Consider the following acid-base reaction:
Nitric acid () is an "acid" because it donates a proton to the water molecule and its "conjugate base" is nitrate (). The water molecule acts as a base because it receives the Hydrogen Proton and its conjugate acid is the hydronium ion ().
Applications.
One use of conjugate acids and bases lies in buffering systems, which include a buffer solution. In a buffer, a weak acid and its conjugate base (in the form of a salt), or a weak base and its conjugate acid are used in order to limit the pH change during a titration process. Buffers have both organic and non-organic chemical applications; for instance, besides buffers being used in lab processes, our blood acts as a buffer to maintain pH. The most important buffer in our bloodstream is the carbonic acid-bicarbonate buffer, which prevents drastic pH changes when is introduced. This functions as such:
Furthermore, here is a table of common buffers.
A second common application with an organic compound would be the production of a buffer with acetic acid. If acetic acid, a weak acid with the formula , was made into a buffer solution, it would need to be combined with its conjugate base in the form of a salt. The resulting mixture is called an acetate buffer, consisting of aqueous and aqueous . Acetic acid, along with many other weak acids, serve as useful components of buffers in different lab settings, each useful within their own pH range.
An example with an inorganic compound would be the medicinal use of lactic acidâs conjugate base known as lactate in Lactated Ringer's solution and Hartmann's solution. Lactic acid has the formula and its conjugate base is used in intravenous fluids that consist of sodium and potassium cations along with lactate and chloride anions in solution with distilled water. These fluids are commonly isotonic in relation to human blood and are commonly used for spiking up the fluid level in a system after severe blood loss due to trauma, surgery, or burn injury.
Table of acids and their conjugate bases.
Tabulated below are several examples of acids and their conjugate bases; notice how they differ by just one proton (H+ ion). Acid strength decreases and conjugate base strength increases down the table.
Table of bases and their conjugate acids.
In contrast, here is a table of bases and their conjugate acids. Similarly, base strength decreases and conjugate acid strength increases down the table.

</doc>
<doc id="40189" url="https://en.wikipedia.org/wiki?curid=40189" title="Founding of Rome">
Founding of Rome

The founding of Rome can be investigated through archaeology, but traditional stories handed down by the ancient Romans themselves explain the earliest history of their city in terms of legend and myth. The most familiar of these myths, and perhaps the most famous of all Roman myths, is the story of Romulus and Remus, the twins who were suckled by a she-wolf. This story had to be reconciled with a dual tradition, set earlier in time, the one that had the Trojan refugee Aeneas escape to Italy and found the line of Romans through his son Iulus, the namesake of the Julio-Claudian dynasty. 
Founding myths.
Aeneas.
The national epic of mythical Rome, the "Aeneid" of Virgil, tells the story of how Trojan prince Aeneas came to Italy. The "Aeneid" was written under Augustus, who claimed ancestry through Julius Caesar from the hero and his mother Venus. According to the "Aeneid", the survivors from the fallen city of Troy banded together under Aeneas and underwent a series of adventures around the Mediterranean Sea, including a stop at newly founded Carthage under the rule of Queen Dido, eventually reaching the Italian coast. The Trojans were thought to have landed in an area between modern Anzio and Fiumicino, southwest of Rome, probably at Laurentum or, in other versions, at Lavinium, a place named for Lavinia, the daughter of King Latinus whom Aeneas married. This started a series of armed conflicts with Turnus over the marriage of Lavinia. Before the arrival of Aeneas, Turnus was engaged to Lavinia, who then married Aeneas, starting the war. Aeneas won the war and killed Turnus. The Trojans won the right to stay and to assimilate with the local peoples. The young son of Aeneas Ascanius, also known as Iulus, went on to found Alba Longa and the line of Alban kings who filled the chronological gap between the Trojan saga and the traditional founding of Rome in the 8th century BC.
Toward the end of this line, King Procas was the father of Numitor and Amulius. At Procas' death, Numitor became king of Alba Longa, but Amulius captured him and sent him to prison; he also forced Numitor's daughter Rhea Silvia to become a virgin priestess among the Vestals. For many years, Amulius was the king. The tortuous nature of the chronology is indicated by Rhea Silvia's ordination among the Vestals, whose order was traditionally said to have been founded by Romulus's successor Numa Pompilius.
Romulus and Remus.
The myth of Aeneas was of Greek origin and had to be reconciled with the Italian myth of Romulus and Remus, who would have been born around 771 BC if taken as historical figures. They were purported to be sons of Rhea Silvia and Mars, the god of war. They were abandoned at birth, in the manner of many mythological heroes, because of a prophecy that they would overthrow their great-uncle Amulius, who had overthrown Silvia's father Numitor. They were abandoned on the Tiber River by servants who took pity on the infants, despite their orders. The twins were nurtured by a she-wolf until a shepherd named Faustulus found the boys and took them as his sons. Faustulus and his wife Acca Larentia raised the children. When Remus and Romulus became adults, they killed Amulius and restored Numitor. They decided to establish a city; however, they quarreled, and Romulus killed his brother. Thus, Rome began with a fratricide, a story that was later taken to represent the city's history of internecine political strife and bloodshed.
Date.
The ancient Romans were certain of the day Rome was founded, April 21, the day of the festival sacred to Pales, goddess of shepherds, on which date they celebrated the "Par ilia" (or "Palilia"). However, they did not know the exact year the city had been founded; this is one reason they preferred to date their years to the presiding consuls over using the formula A.U.C. or Ab Urbe Condita. Several had been proposed by ancient authorities, and Dionysius of Halicarnassus records these: the Greek historian Timaeus, the first to write a history of the Romans, stated that Rome was founded in the 38th year prior to the first Olympiad, or 814 BC; Quintus Fabius Pictor, the first Roman to write the history of his people, stated Rome was founded in the first year of the eighth Olympiad, or 748/7 BC; Cincius Alimentus claimed Rome was founded in the fourth year of the twelfth Olympiad, or 719/8 BC; and Cato the Elder calculated that Rome was founded 432 years after the Trojan War, which Dionysius stated was the first year of the seventh Olympiad, or 752/3 BC. Dionysius himself provided calculations showing that Rome was founded in 751 BC, starting with the Battle of the Allia, which he dated to the first year of the ninth Olympiad, or 390 BC, then added 119 years to reach the date of the first consuls, Junius Brutus and Tarquinius Collatinus, then added the combined total of the reigns of the Kings of Rome (244 years) to arrive at his own date, 751 BC. Even the official Fasti Capitolini offers its own date, 752 BC.
The most familiar date given for the foundation of Rome, 753 BC, was derived by the Roman antiquarian Atticus, and adopted by Varro, having become part of what has come to be known as the Varronian chronology. An anecdote in Plutarch where the astrologer Lucius Tarrutius of Firmum provides an argument based on a non-existent eclipse and other erroneous astronomical details that Rome was founded in 753 BC suggests this had become the most commonly-accepted date. Through its use by the third-century writer Censorinus, whose "De Die Natali" was the ultimate influence of Julius Caesar Scaliger's work to establish a scientific basis of ancient chronology, it became familiar.
Recent discoveries on Palatine Hill in Rome have offered the date of Rome's founding. Chief among these is a series of fortification walls on the north slope of Palatine Hill that can be dated to the middle of the 8th century BC, when legend says that Romulus plowed a furrow ("sulcus") around the Palatine Hill in order to mark the boundary of his new city. The remains of the wall and other evidence like it have been discovered by the Excavations of Andrea Carandini.
The name of Rome.
The name of the city is generally considered to refer to Romulus, but there are other hypotheses. Jean-Jacques Rousseau (1712â1778) suggested Greek "" (""), meaning "strength, vigor". A modern theory of etymology holds that the name of the city is of Etruscan origin (and perhaps the city itself, though this cannot be proven), derived from "rumon", "river".
The name "Romulus" is probably a back-formation; that is, the name "Romulus" was derived from the word "Rome". The suffix "-ulus" is masculine and a diminutive, so "Romulus" means "the little boy from Rome."
Archaeology.
The original Italian people inhabited the Alban Hills. They later moved down into the valleys, which provided better land for agriculture. The area around the Tiber river was particularly advantageous and offered notable strategic resources; the river was a natural border on one side, and the hills could provide a safe defensive position on the other side. This position would also have enabled the Latins to control the river and the commercial and military traffic on it from the natural observation point at Isola Tiberina. Moreover, road traffic could be controlled, since Rome was at the intersection of the principal roads to the sea coming from Sabinum (in the northeast) and Etruria (to the northwest).
The development of the town is presumed to have started from the development of separate small villages located at the tops of hills that eventually accreted to form Rome. In any case, the location that became the city of Rome was inhabited by Latin settlers from various regions, farmers and pastoralists, as evidenced by differences in pottery and burial techniques.
Recent studies suggest that the Quirinal hill was very important in ancient times, although the first hill to be inhabited seems to have been the Palatine (therefore confirming the legend), which is also at the center of ancient Rome. Its three peaks, the minor hills ("Cermalus" or "Germalus", "Palatium", and "Velia"), were united with the three peaks of the Esquiline ("Cispius", "Fagutal", and "Oppius"), and then villages on the Caelian Hill and Suburra.
These hills had expressive names. The Caelian Hill was also called "Querquetulanus" (from ""quercus""", oak) and ""Fagutal"" (pointing to beech-woods, from ""fagus"" meaning "beech"). Recent discoveries revealed that the "Germalus" on the northern part of the Palatine was the site of a village (dated to the 9th century BC) with circular or elliptical dwellings. It was protected by a clay wall (perhaps reinforced with wood), and it is likely that this is where Rome was really founded.
The territory of this federation was surrounded by a sacred border called the "pomerium", which enclosed the so-called e Servian expansion of Rome.
Festivals for the "Septimontium" (literally "of the seven hills") on December 11 were previously considered to be related to the foundation of Rome. However, April 21 is the only date for Rome's foundation upon which all the legends agree, and it has recently been argued that Septimontium celebrated the first federations among Roman hills. A similar federation was, in fact, celebrated by the Latins at Cave, Italy or at Monte Cavo (in "Castelli").
Later commemoration.
During the Italian Renaissance, a group of humanists affiliated with the Roman Academy formed a sodality to pursue antiquarian interests, celebrating the "birthday of Rome" annually on April 20. In 1468, the Academy was suppressed by Pope Paul II for fomenting "republicanism, paganism, and conspiracy", but the sodality was reinstated about ten years later under Sixtus IV as the "Societas Literatorum S. Victoris in Esquiliis" ("Literary Society of Saint Victor on the Esquiline"). The reformed group placed itself under the new patronage of saints Victor, Fortunatus, and Genesius, "whose feast day was conveniently proven to coincide with the Palilia". Their "Palilia" was organized by Pomponio Leto and featured speeches, a communal meal, and a poetry competition.

</doc>
<doc id="40195" url="https://en.wikipedia.org/wiki?curid=40195" title="Telecommunications in Azerbaijan">
Telecommunications in Azerbaijan

Telecommunications in Azerbaijan provides information about television, radio, fixed and mobile telephones, and the Internet in Azerbaijan.
The Azerbaijan economy has been markedly stronger in recent years and, not surprisingly, the country has been making progress in developing ICT sector. Nonetheless, it still faces problems. These include poor infrastructure and an immature telecom regulatory regime. The Ministry of Communications and Information Technologies of Azerbaijan (MCIT), as well as being an operator through its role in Aztelekom, is both a policy-maker and regulator.
Telephones.
Telephone system.
Azerbaijan's telephone system is a combination of old Soviet era technology used by Azerbaijani citizens and small- to medium-size commercial establishments, and modern cellular telephones used by an increasing middle class, large commercial ventures, international companies, and most government officials; the average citizen waits on a 200,000-person list for telephone service; Internet and e-mail service are available in all major cities and some remote towns.
There are three major mobile phone operators currently in Azerbaijan: Azercell, Bakcell and Azerfon. Azercell, Bakcell and Azerfon offer 2G, 3G and 4G services. All three networks are widely modern and reliable with shops located in major towns and cities where one can purchase a sim card or get assistance if needed. Most unlocked mobile phones are able to be used on roaming however network charges apply. Azercell, Bakcell and Azerfon are often recommended to tourists due to the variety of tariffs available and the help available in a variety of languages. Other mobile phone operators include Aztelekom, AzEuroTel, Caspian Telecom and Catel Eurasiacom.
As of June 2014, approximately 95% of all main lines are digitized and provide excellent quality services for the region. The remaining 5% is in modernization process.
International system.
Azerbaijan is connected to the Trans-Asia-Europe (TAE) fiber-optic cable providing international connectivity to the rest of the World. Additionally the old Soviet system by microwave radio relay and landline connections to other countries of the Commonwealth of Independent States is still available, and by satellite earth stations. The main backbones of Azerbaijani networks are made by E3 or STM-1 lines via microwave units across whole country with many passive retranslations.
Radio.
As of 2014, Azerbaijan has 9 AM stations, 17 FM stations, and one shortwave station. Additionally, there are approximately 4,350,000 radios in existence. Primary network provider is the Ministry of Communications and Information Technologies of Azerbaijan (MCIT). According to MCIT, the FM radio penetration rate is 97% according to 2014 data.
Television.
Azerbaijan has a total of 47 television channels, of which 4 are public television channels and 43 are private television channels of which 12 are national television channels and 31 regional television channels. According to the Ministry of Communications and Information Technologies of Azerbaijan (MCIT), the television penetration rate is 99% according to 2014 data. The penetration rate of cable television in Azerbaijan totaled 28.1% of households in 2013, from a study by the State Statistical Committee of the Azerbaijan Republic. Almost 39% of the cable television subscriber base is concentrated in major cities. The penetration rate is 59.1% in the city of Baku.

</doc>
<doc id="40196" url="https://en.wikipedia.org/wiki?curid=40196" title="Transport in Azerbaijan">
Transport in Azerbaijan

The transport in Azerbaijan involves air traffic, waterways and railroads. All transportation services in Azerbaijan except for oil and gas pipelines are regulated by the Ministry of Transportation of Azerbaijan Republic.
Railways.
There are of rail tracks out of which only are in common carrier service and are industrial lines. of rail tracks were occupied by Armenia between 1988 and 1994 and due to Armenian occupation, the railway link between Nakhichevan and Azerbaijan proper has been broken since 1991.
Of the of rail tracks, 72% or are single track and 28% or are double track.
Of the total exploitation length of route 43% or are electrified at 3Â kV (3,000Â V) DC.
About 38% of the length of the railway routes or are equipped with full automatic blocks and 16% or are equipped with centralized dispatchers.
The railways has 176 stations, 2 of which, Bilajari and Shirvan are completely automated, 12 stations have container courts with adapted mechanisms and machines, 3 stations â KeÅlÉ, Ganja and Khirdalan are able to supply high cargo containers.
In freight traffic, the exportation of oil from the oil wells from Baku at the Caspian Sea to the Georgian port of Batumi at the Black Sea, forms an important share of the rail transport in Azerbaijan.
The freight market share of the Azerbaijan State Railway was 21% in 1999. The freight market share of the railways are also expected to rise rapidly with completion of the KarsâTbilisiâBaku railway. Much of the rail track and rolling stock is in need of repair or replacement.
The national network has no high-speed lines and is not served by high-speed trains.
<br>"Total:" (2013)
<br>"Country comparison to the world:" 59
<br>"Broad gauge:" gauge
Kars-Tbilisi-Baku Railway Project Timeline.
2008.
The Russian-Georgian-Ossetian conflict (2008 South Ossetia war) and environmental problems delayed the project, which was originally to be completed by 2010 but is now scheduled for completion by 2012.
Metro System.
Currently the only metro system in Azerbaijan is the Baku Metro, located in Baku, the country's capital.
New plans to open metro systems in the most populated and developed cities of Azberbaijan were unveiled. Sumgayit, Nakhchivan and Ganja all plan to have subway systems in the future.
Roadways.
There are about 25,000 kilometers of roads in Azerbaijan, serving domestic cargo traffic and giving access to international main highways. Highways are mostly in fair condition and need an upgrade to international standards in a view to accommodate growing transit traffic. Main and rural roads are in poor condition and in urgent need of rehabilitation and maintenance. The total vehicle fleet in Azerbaijan was about 517,000 in 2004, with about 49 private passenger cars per 1,000 inhabitants, which is quite low compared to European benchmarks but rapidly increasing due to the fast economic growth. Road transport accounted for 54% of all freight in 2003, up from about 48% in 1999.
International highways.
Main highways carrying international traffic are the Baku-Alat-Ganja-Qazakh-Georgian Border corridor (Azerbaijani section of TRACECA corridor) with a length of 503Â km and the so-called North-South Transport Corridor that stretches out from the Russian to the Iranian border along 521Â km. Road connections are disrupted with Armenia because of the unresolved conflict regarding the possession of the Nagorno-Karabakh. Travel between mainland and the detached exclave of Nakhichevan is made by air or by road through Iran. Nakhichevan has a 9-kilometre strategic border with Turkey.
<br>"Total:" 59,142Â km
<br>"Country comparison to the world:" 74
<br>"Paved:" 29,210Â km
<br>"Unpaved:" 29,931Â km (2013)
Pipelines.
Baku is the centre of a major oil- and gas-producing region, and major long-distance pipelines radiate from the region's oil fields to all neighboring areas. Pipelines are generally high capacity lines and have diameters of either 1,020 or 1,220 millimeters. The main petroleum pipeline was completed in 2005 under American pressure to limit Russian and Iranian influence in the area. It runs from Baku via Tbilisi to Ceyhan in Turkey, therefore the acronym BTC pipeline. It made partly obsolete the old Soviet pipeline pumping crude oil from the onshore and offshore Caspian fields near Baku west across Azerbaijan and Georgia to the port of Batumi, where the oil is either exported in its crude form or processed at Batumi's refinery. Two natural gas lines parallel the old petroleum line as far as Tbilisi, where they turn north across the Caucasus Mountains to join the grid of natural gas pipelines that supply cities throughout Russia and Eastern Europe.
Condensate 89Â km; gas 3,890Â km; oil 2,446Â km (2013)
Ports and harbours.
Sea and water cargo transportation have vital importance for Azerbaijan, especially in regions where road and rail connections are disputed. Azerbaijan has direct maritime connections only with other Caspian littoral states (Iran, Kazakhstan, Russia, and Turkmenistan). However, the Volga-Don canal provides a maritime access to the high seas. The main activity is transport of cargo, mainly of oil and oil products. Shipping regions are Caspian, Black, Mediterranean and Marmara Seas. The main shipping company owes 72 ships, 37 of which are tankers (including 1 water-carrier).
Baku International Marine Trade Port is the largest port on the Caspian Sea. Its ferry terminal underwent a major reconstruction supported by a US$16.2 million loan from EBRD. It is now able to handle 30 million tons of freight a year. The Caspian Sea provides vital transport links with other countries and is being used to ship oil until various pipeline projects are completed.
In 2014 Azberbaijan stated it would seek to ease transportation on the Caspian Sea due increased demand by its neighboring states.
On June 4, 2004 the Ministry of Transportation of the Republic of Azerbaijan established the Maritime Administration. As the regulatory authority in maritime transport, its functions include participating in the formulation of state policy, regulating transport demand of goods and passengers and for other types of maritime transport services, as well as implementing state programs, concepts and projects for the development of maritime transport.
Merchant marine.
"Total:" 90 ships 
<br>"Country comparison to the world:" 53
<br>"Ships by type:" cargo 37, passenger 1, passenger/cargo 8, petroleum tanker 47, chemical tanker 1, roll on/roll off 3, specialized tanker 2
<br>"Registered in other countries:" 2 (Malta 1, Saint Vincent and the Grenadines 1) (2013)
Airports.
There are regular flights between Azerbaijan and former Soviet countries, UK, Germany, France, Austria, Italy, Israel, Iran, Turkey, UAE, United States, China, Georgia and has a cargo flights in UAE, Turkey, Luxembourg, Germany, China, Kyrgyzstan, Afghanistan, and Iraq. The national airline is Azerbaijan Airlines (AZAL). There are 5 international airports located in Baku, Ganja, Nakhchivan, Lenkaran, Zaqatala. Heydar Aliyev International Airport in Baku reopened in 1999 after a US$64 million upgrading and extension financed by Turkish company Enka. The airport can now handle 1,600 passengers an hour. The new runways are also able to serve jumbojets. The complete overhaul of the international airport in Nakhchivan has been completed in May 2004. The US$32 million reconstruction project of Ganja Airport has been launched by the Government and was completed by mid-2006. In 2008, two more airports were opened in Azerbaijan. The Lankaran International Airport is located in southern part of Azerbaijan, Zaqatala Airport is in the north-west of Azerbaijan territory.
Airports: 37 (2008)
<br>"Country comparison to the world:" 108
Airports - with paved runways.
"Total:" 30
<br>"Over 3,047 m:" 5
<br>"2,438 to 3,047 m:" 5
<br>"1,524 to 2,437 m:" 13
<br>"914 to 1,523 m:" 4
<br>"Under 914 m:" 3 (2013)
Airports - with unpaved runways.
"Total:" 7
<br>"914 to 1,523 m:" 7
<br>"Under 914 m:" 1 (2013)
Heliports.
"Total:" 1 (2013)

</doc>
<doc id="40197" url="https://en.wikipedia.org/wiki?curid=40197" title="Vapor pressure">
Vapor pressure

Vapor pressure or equilibrium vapor pressure is defined as the pressure exerted by a vapor in thermodynamic equilibrium with its condensed phases (solid or liquid) at a given temperature in a closed system. The equilibrium vapor pressure is an indication of a liquid's evaporation rate. It relates to the tendency of particles to escape from the liquid (or a solid). A substance with a high vapor pressure at normal temperatures is often referred to as "volatile". The pressure exhibited by vapor present above a liquid surface is known as vapor pressure. As the temperature of a liquid increases, the kinetic energy of its molecules also increases. As the kinetic energy of the molecules increases, the number of molecules transitioning into a vapor also increases, thereby increasing the vapor pressure.
The vapor pressure of any substance increases non-linearly with temperature according to the ClausiusâClapeyron relation. The atmospheric pressure boiling point of a liquid (also known as the normal boiling point) is the temperature at which the vapor pressure equals the ambient atmospheric pressure. With any incremental increase in that temperature, the vapor pressure becomes sufficient to overcome atmospheric pressure and lift the liquid to form vapor bubbles inside the bulk of the substance. Bubble formation deeper in the liquid requires a higher pressure, and therefore higher temperature, because the fluid pressure increases above the atmospheric pressure as the depth increases.
The vapor pressure that a single component in a mixture contributes to the total pressure in the system is called partial pressure. For example, air at sea level, and saturated with water vapor at 20Â Â°C, has partial pressures of about 2.3 kPa of water, 78 kPa of nitrogen, 21 kPa of oxygen and 0.9 kPa of argon, totaling 102.2 kPa, making the basis for standard atmospheric pressure.
Measurement and units.
Vapor pressure is measured in the standard units of pressure. The International System of Units (SI) recognizes pressure as a derived unit with the dimension of force per area and designates the pascal (Pa) as its standard unit. One pascal is one newton per square meter (NÂ·mâ2 or kgÂ·mâ1Â·sâ2).
Experimental measurement of vapor pressure is a simple procedure for common pressures between 1 and 200 kPa. Most accurate results are obtained near the boiling point of substances and large errors result for measurements smaller than . Procedures often consist of purifying the test substance, isolating it in a container, evacuating any foreign gas, then measuring the equilibrium pressure of the gaseous phase of the substance in the container at different temperatures. Better accuracy is achieved when care is taken to ensure that the entire substance and its vapor are at the prescribed temperature. This is often done, as with the use of an isoteniscope, by submerging the containment area in a liquid bath.
Estimating vapor pressures with Antoine equation.
The Antoine equation is a mathematical expression of the relation between the vapor pressure and the temperature of pure liquid or solid substances. The basic form of the equation is:
and it can be transformed into this temperature-explicit form:
where: formula_3 is the absolute vapor pressure of a substance<br>
A simpler form of the equation with only two coefficients is sometimes used:
which can be transformed to:
Sublimations and vaporizations of the same substance have separate sets of Antoine coefficients, as do components in mixtures. Each parameter set for a specific compound is only applicable over a specified temperature range. Generally, temperature ranges are chosen to maintain the equation's accuracy of a few up to 8â10 percent. For many volatile substances, several different sets of parameters are available and used for different temperature ranges. The Antoine equation has poor accuracy with any single parameter set when used from a compound's melting point to its critical temperature. Accuracy is also usually poor when vapor pressure is under 10 Torr because of the limitations of the apparatus used to establish the Antoine parameter values.
The Wagner Equation gives "one of the best" fits to experimental data but is quite complex. It expresses reduced vapor pressure as a function of reduced temperature.
Relation to boiling point of liquids.
As a general trend, vapor pressures of liquids at ambient temperatures increase with decreasing boiling points. This is illustrated in the vapor pressure chart (see right) that shows graphs of the vapor pressures versus temperatures for a variety of liquids.
For example, at any given temperature, methyl chloride has the highest vapor pressure of any of the liquids in the chart. It also has the lowest normal boiling point (â24.2Â Â°C), which is where the vapor pressure curve of methyl chloride (the blue line) intersects the horizontal pressure line of one atmosphere (atm) of absolute vapor pressure.
Although the relation between vapor pressure and temperature is non-linear, the chart uses a logarithmic vertical axis to produce slightly curved lines, so one chart can graph many liquids. A nearly straight line is obtained when the logarithm of the vapor pressure is plotted against 1/(T+230) where T is the temperature in degrees Celsius. The vapor pressure of a liquid at its boiling point equals the pressure of its surrounding environment.
Liquid mixtures.
Raoult's law gives an approximation to the vapor pressure of mixtures of liquids. It states that the activity (pressure or fugacity) of a single-phase mixture is equal to the mole-fraction-weighted sum of the components' vapor pressures:
where p tot is the mixture's vapor pressure, i is one of the components of the mixture and Î§i is the mole fraction of that component in the liquid mixture. The term piÎ§i is the partial pressure of component i in the mixture. Raoult's Law is applicable only to non-electrolytes (uncharged species); it is most appropriate for non-polar molecules with only weak intermolecular attractions (such as London forces).
Systems that have vapor pressures higher than indicated by the above formula are said to have positive deviations. Such a deviation suggests weaker intermolecular attraction than in the pure components, so that the molecules can be thought of as being "held in" the liquid phase less strongly than in the pure liquid. An example is the azeotrope of approximately 95% ethanol and water. Because the azeotrope's vapor pressure is higher than predicted by Raoult's law, it boils at a temperature below that of either pure component.
There are also systems with negative deviations that have vapor pressures that are lower than expected. Such a deviation is evidence for stronger intermolecular attraction between the constituents of the mixture than exists in the pure components. Thus, the molecules are "held in" the liquid more strongly when a second molecule is present. An example is a mixture of trichloromethane (chloroform) and 2-propanone (acetone), which boils above the boiling point of either pure component.
The negative and positive deviations can be used to determine thermodynamic activity coefficients of the components of mixtures.
Solids.
Equilibrium vapor pressure can be defined as the pressure reached when a condensed phase is in equilibrium with its own vapor. In the case of an equilibrium solid, such as a crystal, this can be defined as the pressure when the rate of sublimation of a solid matches the rate of deposition of its vapor phase. For most solids this pressure is very low, but some notable exceptions are naphthalene, dry ice (the vapor pressure of dry ice is 5.73 MPa (831 psi, 56.5 atm) at 20 degrees Celsius, which causes most sealed containers to rupture), and ice. All solid materials have a vapor pressure. However, due to their often extremely low values, measurement can be rather difficult. Typical techniques include the use of thermogravimetry and gas transpiration.
There are a number of methods for calculating the sublimation pressure (i.e., the vapor pressure) of a solid. One method is to estimate the sublimation pressure from extrapolated liquid vapor pressures (of the supercooled liquid), if the heat of fusion is known, by using this particular form of the ClausiusâClapeyron relation:
with:
This method assumes that the heat of fusion is temperature-independent, ignores additional transition temperatures between different solid phases, and it gives a fair estimation for temperatures not too far from the melting point. It also shows that the sublimation pressure is lower than the extrapolated liquid vapor pressure (Î"H"m is positive) and the difference grows with increased distance from the melting point.
Boiling point of water.
Like all liquids, water boils when its vapor pressure reaches its surrounding pressure. In nature, the atmospheric pressure is lower at higher elevations and water boils at a lower temperature. The boiling temperature of water for atmospheric pressures can be approximated by the Antoine equation:
or transformed into this temperature-explicit form:
where the temperature formula_17 is the boiling point in degrees Celsius and the pressure formula_18 is in Torr.
DÃ¼hring's rule.
DÃ¼hring's rule states that a linear relationship exists between the temperatures at which two solutions exert the same vapor pressure.
Examples.
The following table is a list of a variety of substances ordered by increasing vapor pressure (in absolute units).
Estimating vapor pressure from molecular structure.
Several empirical methods exist to estimate liquid vapor pressure from molecular structure for organic molecules. Some examples are SIMPOL, the method of Moller et al., and EVAPORATION.
Meaning in meteorology.
In meteorology, the term "vapor pressure" is used to mean the partial pressure of water vapor in the atmosphere, even if it is not in equilibrium, and the "equilibrium vapor pressure" is specified otherwise. Meteorologists also use the term "saturation vapor pressure" to refer to the equilibrium vapor pressure of water or brine above a flat surface, to distinguish it from equilibrium vapor pressure, which takes into account the shape and size of water droplets and particulates in the atmosphere.

</doc>
<doc id="40202" url="https://en.wikipedia.org/wiki?curid=40202" title="12th century BC">
12th century BC

The 12th century BC is the period from 1200 to 1101 BC. The Late Bronze Age collapse in the ancient Near East and eastern Mediterranean is often considered to begin in this century.
Sovereign States.
See: List of sovereign states in the 12th century BC.

</doc>
<doc id="40203" url="https://en.wikipedia.org/wiki?curid=40203" title="Hubble Space Telescope">
Hubble Space Telescope

The Hubble Space Telescope (HST) is a space telescope that was launched into low Earth orbit in 1990, and remains in operation. Although not the first space telescope, Hubble is one of the largest and most versatile, and is well known as both a vital research tool and a public relations boon for astronomy. The HST is named after the astronomer Edwin Hubble, and is one of NASA's Great Observatories, along with the Compton Gamma Ray Observatory, the Chandra X-ray Observatory, and the Spitzer Space Telescope.
With a mirror, Hubble's four main instruments observe in the near ultraviolet, visible, and near infrared spectra. Hubble's orbit outside the distortion of Earth's atmosphere allows it to take extremely high-resolution images, with substantially lower background light than ground-based telescopes. Hubble has recorded some of the most detailed visible-light images ever, allowing a deep view into space and time. Many Hubble observations have led to breakthroughs in astrophysics, such as accurately determining the rate of expansion of the universe.
The HST was built by the United States space agency NASA, with contributions from the European Space Agency. The Space Telescope Science Institute (STScI) selects Hubble's targets and processes the resulting data, while the Goddard Space Flight Center controls the spacecraft.
Space telescopes were proposed as early as 1923. Hubble was funded in the 1970s, with a proposed launch in 1983, but the project was beset by technical delays, budget problems, and the "Challenger" disaster (1986). When finally launched in 1990, Hubble's main mirror was found to have been ground incorrectly, compromising the telescope's capabilities. The optics were corrected to their intended quality by a servicing mission in 1993.
Hubble is the only telescope designed to be serviced in space by astronauts. After launch by in 1990, four subsequent Space Shuttle missions repaired, upgraded, and replaced systems on the telescope. A fifth mission was canceled on safety grounds following the "Columbia" disaster (2003). However, after spirited public discussion, NASA administrator Mike Griffin approved one final servicing mission, completed in 2009. The telescope is operating , and could last until 2030â2040. Its scientific successor, the James Webb Space Telescope (JWST), is scheduled for launch in 2018.
Conception, design and aim.
Proposals and precursors.
In 1923, Hermann Oberthâconsidered a father of modern rocketry, along with Robert H. Goddard and Konstantin Tsiolkovskyâpublished "" ("The Rocket into Planetary Space"), which mentioned how a telescope could be propelled into Earth orbit by a rocket.
The history of the Hubble Space Telescope can be traced back as far as 1946, to the astronomer Lyman Spitzer's paper "Astronomical advantages of an extraterrestrial observatory". In it, he discussed the two main advantages that a space-based observatory would have over ground-based telescopes. First, the angular resolution (the smallest separation at which objects can be clearly distinguished) would be limited only by diffraction, rather than by the turbulence in the atmosphere, which causes stars to twinkle, known to astronomers as seeing. At that time ground-based telescopes were limited to resolutions of 0.5â1.0Â arcseconds, compared to a theoretical diffraction-limited resolution of about 0.05Â arcsec for a telescope with a mirror 2.5Â m in diameter. Second, a space-based telescope could observe infrared and ultraviolet light, which are strongly absorbed by the atmosphere.
Spitzer devoted much of his career to pushing for the development of a space telescope. In 1962, a report by the US National Academy of Sciences recommended the development of a space telescope as part of the space program, and in 1965 Spitzer was appointed as head of a committee given the task of defining scientific objectives for a large space telescope.
Space-based astronomy had begun on a very small scale following World War II, as scientists made use of developments that had taken place in rocket technology. The first ultraviolet spectrum of the Sun was obtained in 1946, and the National Aeronautics and Space Administration (NASA) launched the Orbiting Solar Observatory (OSO) to obtain UV, X-ray, and gamma-ray spectra in 1962. An orbiting solar telescope was launched in 1962 by the United Kingdom as part of the Ariel space program, and in 1966 NASA launched the first Orbiting Astronomical Observatory (OAO) mission. OAO-1's battery failed after three days, terminating the mission. It was followed by OAO-2, which carried out ultraviolet observations of stars and galaxies from its launch in 1968 until 1972, well beyond its original planned lifetime of one year.
The OSO and OAO missions demonstrated the important role space-based observations could play in astronomy, and in 1968, NASA developed firm plans for a space-based reflecting telescope with a mirror 3Â m in diameter, known provisionally as the Large Orbiting Telescope or Large Space Telescope (LST), with a launch slated for 1979. These plans emphasized the need for manned maintenance missions to the telescope to ensure such a costly program had a lengthy working life, and the concurrent development of plans for the reusable space shuttle indicated that the technology to allow this was soon to become available.
Quest for funding.
The continuing success of the OAO program encouraged increasingly strong consensus within the astronomical community that the LST should be a major goal. In 1970, NASA established two committees, one to plan the engineering side of the space telescope project, and the other to determine the scientific goals of the mission. Once these had been established, the next hurdle for NASA was to obtain funding for the instrument, which would be far more costly than any Earth-based telescope. The U.S. Congress questioned many aspects of the proposed budget for the telescope and forced cuts in the budget for the planning stages, which at the time consisted of very detailed studies of potential instruments and hardware for the telescope. In 1974, public spending cuts led to Congress deleting all funding for the telescope project.
In response to this, a nationwide lobbying effort was coordinated among astronomers. Many astronomers met congressmen and senators in person, and large scale letter-writing campaigns were organized. The National Academy of Sciences published a report emphasizing the need for a space telescope, and eventually the Senate agreed to half of the budget that had originally been approved by Congress.
The funding issues led to something of a reduction in the scale of the project, with the proposed mirror diameter reduced from 3Â m to 2.4Â m, both to cut costs and to allow a more compact and effective configuration for the telescope hardware. A proposed precursor 1.5Â m space telescope to test the systems to be used on the main satellite was dropped, and budgetary concerns also prompted collaboration with the European Space Agency. ESA agreed to provide funding and supply one of the first generation instruments for the telescope, as well as the solar cells that would power it, and staff to work on the telescope in the United States, in return for European astronomers being guaranteed at least 15% of the observing time on the telescope. Congress eventually approved funding of US$36 million for 1978, and the design of the LST began in earnest, aiming for a launch date of 1983. In 1983 the telescope was named after Edwin Hubble, who made one of the greatest scientific breakthroughs of the 20th century when he discovered that the universe is expanding.
Construction and engineering.
Once the Space Telescope project had been given the go-ahead, work on the program was divided among many institutions. Marshall Space Flight Center (MSFC) was given responsibility for the design, development, and construction of the telescope, while Goddard Space Flight Center was given overall control of the scientific instruments and ground-control center for the mission. MSFC commissioned the optics company Perkin-Elmer to design and build the Optical Telescope Assembly (OTA) and Fine Guidance Sensors for the space telescope. Lockheed was commissioned to construct and integrate the spacecraft in which the telescope would be housed.
Optical Telescope Assembly (OTA).
Optically, the HST is a Cassegrain reflector of RitcheyâChrÃ©tien design, as are most large professional telescopes. This design, with two hyperbolic mirrors, is known for good imaging performance over a wide field of view, with the disadvantage that the mirrors have shapes that are hard to fabricate and test. The mirror and optical systems of the telescope determine the final performance, and they were designed to exacting specifications. Optical telescopes typically have mirrors polished to an accuracy of about a tenth of the wavelength of visible light, but the Space Telescope was to be used for observations from the visible through the ultraviolet (shorter wavelengths) and was specified to be diffraction limited to take full advantage of the space environment. Therefore, its mirror needed to be polished to an accuracy of 10Â nanometers, or about 1/65 of the wavelength of red light. On the long wavelength end, the OTA was not designed with optimum IR performance in mindâfor example, the mirrors are kept at stable (and warm, about 15Â Â°C) temperatures by heaters. This limits Hubble's performance as an infrared telescope.
Perkin-Elmer intended to use custom-built and extremely sophisticated computer-controlled polishing machines to grind the mirror to the required shape. However, in case their cutting-edge technology ran into difficulties, NASA demanded that PE sub-contract to Kodak to construct a back-up mirror using traditional mirror-polishing techniques. (The team of Kodak and Itek also bid on the original mirror polishing work. Their bid called for the two companies to double-check each other's work, which would have almost certainly caught the polishing error that later caused such problems.) The Kodak mirror is now on permanent display at the National Air and Space Museum. An Itek mirror built as part of the effort is now used in the 2.4Â m telescope at the Magdalena Ridge Observatory.
Construction of the Perkin-Elmer mirror began in 1979, starting with a blank manufactured by Corning from their ultra-low expansion glass. To keep the mirror's weight to a minimum it consisted of top and bottom plates, each one inch (25.4Â mm) thick, sandwiching a honeycomb lattice. Perkin-Elmer simulated microgravity by supporting the mirror from the back with 130 rods that exerted varying amounts of force. This ensured that the mirror's final shape would be correct and to specification when finally deployed. Mirror polishing continued until May 1981. NASA reports at the time questioned Perkin-Elmer's managerial structure, and the polishing began to slip behind schedule and over budget. To save money, NASA halted work on the back-up mirror and put the launch date of the telescope back to October 1984. The mirror was completed by the end of 1981; it was washed using 2,400 gallons (9,100 L) of hot, deionized water and then received a reflective coating of 65Â nm-thick aluminum and a protective coating of 25Â nm-thick magnesium fluoride.
Doubts continued to be expressed about Perkin-Elmer's competence on a project of this importance, as their budget and timescale for producing the rest of the OTA continued to inflate. In response to a schedule described as "unsettled and changing daily", NASA postponed the launch date of the telescope until April 1985. Perkin-Elmer's schedules continued to slip at a rate of about one month per quarter, and at times delays reached one day for each day of work. NASA was forced to postpone the launch date until March and then September 1986. By this time, the total project budget had risen to US$1.175 billion.
Spacecraft systems.
The spacecraft in which the telescope and instruments were to be housed was another major engineering challenge. It would have to withstand frequent passages from direct sunlight into the darkness of Earth's shadow, which would cause major changes in temperature, while being stable enough to allow extremely accurate pointing of the telescope. A shroud of multi-layer insulation keeps the temperature within the telescope stable, and surrounds a light aluminum shell in which the telescope and instruments sit. Within the shell, a graphite-epoxy frame keeps the working parts of the telescope firmly aligned. Because graphite composites are hygroscopic, there was a risk that water vapor absorbed by the truss while in Lockheed's clean room would later be expressed in the vacuum of space; the telescope's instruments would be covered in ice. To reduce that risk, a nitrogen gas purge was performed before launching the telescope into space.
While construction of the spacecraft in which the telescope and instruments would be housed proceeded somewhat more smoothly than the construction of the OTA, Lockheed still experienced some budget and schedule slippage, and by the summer of 1985, construction of the spacecraft was 30% over budget and three months behind schedule. An MSFC report said that Lockheed tended to rely on NASA directions rather than take their own initiative in the construction.
Initial instruments.
When launched, the HST carried five scientific instruments: the Wide Field and Planetary Camera (WF/PC), Goddard High Resolution Spectrograph (GHRS), High Speed Photometer (HSP), Faint Object Camera (FOC) and the Faint Object Spectrograph (FOS). WF/PC was a high-resolution imaging device primarily intended for optical observations. It was built by NASA's Jet Propulsion Laboratory, and incorporated a set of 48 filters isolating spectral lines of particular astrophysical interest. The instrument contained eight charge-coupled device (CCD) chips divided between two cameras, each using four CCDs. Each CCD has a resolution of 0.64 megapixels. The "wide field camera" (WFC) covered a large angular field at the expense of resolution, while the "planetary camera" (PC) took images at a longer effective focal length than the WF chips, giving it a greater magnification.
The GHRS was a spectrograph designed to operate in the ultraviolet. It was built by the Goddard Space Flight Center and could achieve a spectral resolution of 90,000. Also optimized for ultraviolet observations were the FOC and FOS, which were capable of the highest spatial resolution of any instruments on Hubble. Rather than CCDs these three instruments used photon-counting digicons as their detectors. The FOC was constructed by ESA, while the University of California, San Diego, and Martin Marietta Corporation built the FOS.
The final instrument was the HSP, designed and built at the University of WisconsinâMadison. It was optimized for visible and ultraviolet light observations of variable stars and other astronomical objects varying in brightness. It could take up to 100,000 measurements per second with a photometric accuracy of about 2% or better.
HST's guidance system can also be used as a scientific instrument. Its three Fine Guidance Sensors (FGS) are primarily used to keep the telescope accurately pointed during an observation, but can also be used to carry out extremely accurate astrometry; measurements accurate to within 0.0003Â arcseconds have been achieved.
Ground support.
The Space Telescope Science Institute (STScI) is responsible for the scientific operation of the telescope and the delivery of data products to astronomers. STScI is operated by the Association of Universities for Research in Astronomy (AURA) and is physically located in Baltimore, Maryland on the Homewood campus of Johns Hopkins University, one of the 39 US universities and seven international affiliates that make up the AURA consortium. STScI was established in 1981 after something of a power struggle between NASA and the scientific community at large. NASA had wanted to keep this function in-house, but scientists wanted it to be based in an academic establishment. The Space Telescope European Coordinating Facility (ST-ECF), established at Garching bei MÃ¼nchen near Munich in 1984, provided similar support for European astronomers until 2011, when these activities were moved to the European Space Astronomy Centre.
One rather complex task that falls to STScI is scheduling observations for the telescope. Hubble is in a low-Earth orbit to enable servicing missions, but this means that most astronomical targets are occulted by the Earth for slightly less than half of each orbit. Observations cannot take place when the telescope passes through the South Atlantic Anomaly due to elevated radiation levels, and there are also sizable exclusion zones around the Sun (precluding observations of Mercury), Moon and Earth. The solar avoidance angle is about 50Â°, to keep sunlight from illuminating any part of the OTA. Earth and Moon avoidance keeps bright light out of the FGSs, and keeps scattered light from entering the instruments. If the FGSs are turned off, however, the Moon and Earth can be observed. Earth observations were used very early in the program to generate flat-fields for the WFPC1 instrument. There is a so-called continuous viewing zone (CVZ), at roughly 90Â° to the plane of Hubble's orbit, in which targets are not occulted for long periods. Due to the precession of the orbit, the location of the CVZ moves slowly over a period of eight weeks. Because the limb of the Earth is always within about 30Â° of regions within the CVZ, the brightness of scattered earthshine may be elevated for long periods during CVZ observations.
Hubble orbits in the upper atmosphere at an altitude of approximately and an inclination of 28.5Â°. The position along its orbit changes over time in a way that is not accurately predictable. The density of the upper atmosphere varies according to many factors, and this means that Hubble's predicted position for six weeks' time could be in error by up to . Observation schedules are typically finalized only a few days in advance, as a longer lead time would mean there was a chance that the target would be unobservable by the time it was due to be observed.
Engineering support for HST is provided by NASA and contractor personnel at the Goddard Space Flight Center in Greenbelt, Maryland, south of the STScI. Hubble's operation is monitored 24Â hours per day by four teams of flight controllers who make up Hubble's Flight Operations Team.
"Challenger" disaster, delays, and eventual launch.
By early 1986, the planned launch date of October that year looked feasible, but the "Challenger" accident brought the U.S. space program to a halt, grounding the Space Shuttle fleet and forcing the launch of Hubble to be postponed for several years. The telescope had to be kept in a clean room, powered up and purged with nitrogen, until a launch could be rescheduled. This costly situation (about $6 million per month) pushed the overall costs of the project even higher. This delay did allow time for engineers to perform extensive tests, swap out a possibly failure-prone battery, and make other improvements. Furthermore, the ground software needed to control Hubble was not ready in 1986, and in fact was barely ready by the 1990 launch.
Eventually, following the resumption of shuttle flights in 1988, the launch of the telescope was scheduled for 1990. On April 24, 1990, shuttle mission STS-31 saw "Discovery" launch the telescope successfully into its planned orbit.
From its original total cost estimate of about US$400 million, the telescope had by now cost over $2.5 billion to construct. Hubble's cumulative costs were estimated to be about US$10 billion in 2010, twenty years after launch.
Flawed mirror.
Within weeks of the launch of the telescope, the returned images indicated a serious problem with the optical system. Although the first images appeared to be sharper than those of ground-based telescopes, Hubble failed to achieve a final sharp focus and the best image quality obtained was drastically lower than expected. Images of point sources spread out over a radius of more than one arcsecond, instead of having a point spread function (PSF) concentrated within a circle 0.1Â arcsec in diameter as had been specified in the design criteria.
Analysis of the flawed images showed that the cause of the problem was that the primary mirror had been ground to the wrong shape. Although it was probably the most precisely figured mirror ever made, with variations from the prescribed curve of only 10 nanometers, at the perimeter it was too flat by about 2,200 nanometers (2.2 micrometers). This difference was catastrophic, introducing severe spherical aberration, a flaw in which light reflecting off the edge of a mirror focuses on a different point from the light reflecting off its center.
The effect of the mirror flaw on scientific observations depended on the particular observationâthe core of the aberrated PSF was sharp enough to permit high-resolution observations of bright objects, and spectroscopy of point sources was only affected through a sensitivity loss. However, the loss of light to the large, out of focus halo severely reduced the usefulness of the telescope for faint objects or high-contrast imaging. This meant that nearly all of the cosmological programs were essentially impossible, since they required observation of exceptionally faint objects. NASA and the telescope became the butt of many jokes, and the project was popularly regarded as a white elephant. For instance, in the 1991 comedy "", Hubble was pictured with the "Titanic", the "Hindenburg", and the Edsel. Nonetheless, during the first three years of the Hubble mission, before the optical corrections, the telescope still carried out a large number of productive observations of less demanding targets. The error was well characterized and stable, enabling astronomers to partially compensate for the defective mirror by using sophisticated image processing techniques such as deconvolution.
Origin of the problem.
A commission headed by Lew Allen, director of the Jet Propulsion Laboratory, was established to determine how the error could have arisen. The Allen Commission found that the main null corrector, a testing device used to achieve a properly shaped non-spherical mirror, had been incorrectly assembledâone lens was out of position by 1.3Â mm. During the initial grinding and polishing of the mirror, Perkin-Elmer analyzed its surface with two conventional null correctors. However, for the final manufacturing step (figuring), they switched to a custom-built null corrector, designed explicitly to meet very strict tolerances. The incorrect assembly of the device resulted in the mirror being ground very precisely but to the wrong shape. There was one later opportunity to catch the error, since for technical reasons a few of the final tests needed to use the two conventional null correctors. These tests correctly reported spherical aberration, but were dismissed since the reflective null corrector was considered more accurate.
The commission blamed the failings primarily on Perkin-Elmer. Relations between NASA and the optics company had been severely strained during the telescope construction, due to frequent schedule slippage and cost overruns. NASA found that Perkin-Elmer did not review or supervise the mirror construction adequately, did not assign its best optical scientists to the project (as it had for the prototype), and in particular did not involve the optical designers in the construction and verification of the mirror. While the commission heavily criticized Perkin-Elmer for these managerial failings, NASA was also criticized for not picking up on the quality control shortcomings, such as relying totally on test results from a single instrument.
Design of a solution.
The design of the telescope had always incorporated servicing missions, and astronomers immediately began to seek potential solutions to the problem that could be applied at the first servicing mission, scheduled for 1993. While Kodak had ground a back-up mirror for Hubble, it would have been impossible to replace the mirror in orbit, and too expensive and time-consuming to bring the telescope back to Earth for a refit. Instead, the fact that the mirror had been ground so precisely to the wrong shape led to the design of new optical components with exactly the same error but in the opposite sense, to be added to the telescope at the servicing mission, effectively acting as "spectacles" to correct the spherical aberration.
The first step was a precise characterization of the error in the main mirror. Working backwards from images of point sources, astronomers determined that the conic constant of the mirror as built was â1.01390Â±0.0002, instead of the intended â1.00230. The same number was also derived by analyzing the null corrector used by Perkin-Elmer to figure the mirror, as well as by analyzing interferograms obtained during ground testing of the mirror.
Because of the way the HST's instruments were designed, two different sets of correctors were required. The design of the Wide Field and Planetary Camera 2, already planned to replace the existing WF/PC, included relay mirrors to direct light onto the four separate charge-coupled device (CCD) chips making up its two cameras. An inverse error built into their surfaces could completely cancel the aberration of the primary. However, the other instruments lacked any intermediate surfaces that could be figured in this way, and so required an external correction device.
The Corrective Optics Space Telescope Axial Replacement (COSTAR) system was designed to correct the spherical aberration for light focused at the FOC, FOS, and GHRS. It consists of two mirrors in the light path with one ground to correct the aberration. To fit the COSTAR system onto the telescope, one of the other instruments had to be removed, and astronomers selected the High Speed Photometer to be sacrificed. By 2002, all of the original instruments requiring COSTAR had been replaced by instruments with their own corrective optics. COSTAR was removed and returned to Earth in 2009 where it is exhibited at the National Air and Space Museum. The area previously used by COSTAR is now occupied by the Cosmic Origins Spectrograph.
Servicing missions and new instruments.
Hubble was designed to accommodate regular servicing and equipment upgrades. Five servicing missions (SM 1, 2, 3A, 3B, and 4) were flown by NASA space shuttles, the first in December 1993 and the last in May 2009. Servicing missions were delicate operations that began with maneuvering to intercept the telescope in orbit and carefully retrieving it with the shuttle's mechanical arm. The necessary work was then carried out in multiple tethered spacewalks over a period of four to five days. After a visual inspection of the telescope, astronauts conducted repairs, replaced failed or degraded components, upgraded equipment, and installed new instruments. Once work was completed, the telescope was redeployed, typically after boosting to a higher orbit to address the orbital decay caused by atmospheric drag.
Servicing Mission 1.
After the problems with Hubble's mirror were discovered, the first servicing mission assumed greater importance, as the astronauts would need to do extensive work to install corrective optics. The seven astronauts for the mission were trained to use about a hundred specialized tools. SM1 flew aboard "Endeavour" in December 1993, and involved installation of several instruments and other equipment over ten days.
Most importantly, the High Speed Photometer was replaced with the COSTAR corrective optics package, and WFPC was replaced with the Wide Field and Planetary Camera 2 (WFPC2) with an internal optical correction system. The solar arrays and their drive electronics were also replaced, as well as four gyroscopes in the telescope pointing system, two electrical control units and other electrical components, and two magnetometers. The onboard computers were upgraded with added coprocessors, and Hubble's orbit was boosted.
On January 13, 1994, NASA declared the mission a complete success and showed the first sharper images. At the time, the mission was one of the most complex, involving five long extra-vehicular activity periods. Its success was a boon for NASA, as well as for the astronomers with a more capable space telescope.
Servicing Mission 2.
Servicing Mission 2, flown by "Discovery" in February 1997, replaced the GHRS and the FOS with the Space Telescope Imaging Spectrograph (STIS) and the Near Infrared Camera and Multi-Object Spectrometer (NICMOS), replaced an Engineering and Science Tape Recorder with a new Solid State Recorder, and repaired thermal insulation. NICMOS contained a heat sink of solid nitrogen to reduce the thermal noise from the instrument, but shortly after it was installed, an unexpected thermal expansion resulted in part of the heat sink coming into contact with an optical baffle. This led to an increased warming rate for the instrument and reduced its original expected lifetime of 4.5 years to about 2 years.
Servicing Mission 3A.
Servicing Mission 3A, flown by "Discovery", took place in December 1999, and was a split-off from Servicing Mission 3 after three of the six onboard gyroscopes had failed. The fourth failed a few weeks before the mission, rendering the telescope incapable of performing scientific observations. The mission replaced all six gyroscopes, replaced a Fine Guidance Sensor and the computer, installed a Voltage/temperature Improvement Kit (VIK) to prevent battery overcharging, and replaced thermal insulation blankets. The new computer is 20 times faster, with six times more memory, than the DF-224 it replaced. It increases throughput by moving some computing tasks from the ground to the spacecraft, and saves money by allowing the use of modern programming languages.
Servicing Mission 3B.
Servicing Mission 3B flown by "Columbia" in March 2002 saw the installation of a new instrument, with the FOC (which, except for the Fine Guidance Sensors when used for astrometry, was the last of the original instruments) being replaced by the Advanced Camera for Surveys (ACS). This meant that COSTAR was no longer required, since all new instruments had built-in correction for the main mirror aberration. The mission also revived NICMOS by installing a closed-cycle cooler and replaced the solar arrays for the second time, providing 30 percent more power.
Servicing Mission 4.
Plans called for Hubble to be serviced in February 2005, but the "Columbia" disaster in 2003, in which the orbiter disintegrated on re-entry into the atmosphere, had wide-ranging effects on the Hubble program. NASA Administrator Sean O'Keefe decided that all future shuttle missions had to be able to reach the safe haven of the International Space Station should in-flight problems develop. As no shuttles were capable of reaching both HST and the ISS during the same mission, future manned service missions were canceled. This decision was assailed by numerous astronomers, who felt that Hubble was valuable enough to merit the human risk. HST's planned successor, the James Webb Telescope (JWST), is not expected to launch until at least 2018. A gap in space-observing capabilities between a decommissioning of Hubble and the commissioning of a successor is of major concern to many astronomers, given the significant scientific impact of HST. The consideration that JWST will not be located in low Earth orbit, and therefore cannot be easily upgraded or repaired in the event of an early failure, only makes these concerns more acute. On the other hand, many astronomers felt strongly that the servicing of Hubble should not take place if the expense were to come from the JWST budget.
In January 2004, O'Keefe said he would review his decision to cancel the final servicing mission to HST due to public outcry and requests from Congress for NASA to look for a way to save it. The National Academy of Sciences convened an official panel, which recommended in July 2004 that the HST should be preserved despite the apparent risks. Their report urged "NASA should take no actions that would preclude a space shuttle servicing mission to the Hubble Space Telescope". In August 2004, O'Keefe asked Goddard Space Flight Center to prepare a detailed proposal for a robotic service mission. These plans were later canceled, the robotic mission being described as "not feasible". In late 2004, several Congressional members, led by Senator Barbara Mikulski, held public hearings and carried on a fight with much public support (including thousands of letters from school children across the country) to get the Bush Administration and NASA to reconsider the decision to drop plans for a Hubble rescue mission.
The nomination in April 2005 of a new NASA Administrator with an engineering rather than accounting background, Michael D. Griffin, changed the situation, as Griffin stated he would consider a manned servicing mission. Soon after his appointment Griffin authorized Goddard to proceed with preparations for a manned Hubble maintenance flight, saying he would make the final decision after the next two shuttle missions. In October 2006 Griffin gave the final go-ahead, and the 11-day mission by "Atlantis" was scheduled for October 2008. Hubble's main data-handling unit failed in September 2008, halting all reporting of scientific data until its back-up was brought online on October 25, 2008. Since a failure of the backup unit would leave the HST helpless, the service mission was postponed to incorporate a replacement for the primary unit.
Servicing Mission 4, flown by "Atlantis" in May 2009, was the last scheduled shuttle mission for HST. SM4 installed the replacement data-handling unit, repaired the ACS and STIS systems, installed improved nickel hydrogen batteries, and replaced other components. SM4 also installed two new observation instrumentsâWide Field Camera 3 (WFC3) and the Cosmic Origins Spectrograph (COS)âand the Soft Capture and Rendezvous System, which will enable the future rendezvous, capture, and safe disposal of Hubble by either a crewed or robotic mission. Except for the High Resolution Channel of the ACS which was unable to be repaired, the work accomplished during SM4 rendered the telescope fully functional, and it remains so .
Major projects.
Since the start of the program, a number of research projects have been carried out, some of them almost solely with Hubble, others coordinated facilities such as Chandra X-ray Observatory and ESO's Very Large Telescope. Although the Hubble observatory is nearing the end of its life, there are still major projects scheduled for it. One example is the upcoming Frontier Fields program, inspired by the results of Hubble's deep observation of the galaxy cluster Abell 1689.
Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey.
In an August 2013 press release, CANDELS was referred to as "the largest project in the history of Hubble". The survey "aims to explore galactic evolution in the early Universe, and the very first seeds of cosmic structure at less than one billion years after the Big Bang." The CANDELS project site describes the survey's goals as the following:
The Cosmic Assembly Near-IR Deep Extragalactic Legacy Survey is designed to document the ï¬rst third of galactic evolution from z = 8 to 1.5 via deep imaging of more than 250,000 galaxies with WFC3/IR and ACS. It will also find the first Type Ia SNe beyond z > 1.5 and establish their accuracy as standard candles for cosmology. Five premier multi-wavelength sky regions are selected; each has multi-wavelength data from Spitzer and other facilities, and has extensive spectroscopy of the brighter galaxies. The use of ï¬ve widely separated ï¬elds mitigates cosmic variance and yields statistically robust and complete samples of galaxies down to 109 solar masses out to z ~ 8.
Frontier Fields program.
The program, officially named "Hubble Deep Fields Initiative 2012", is aimed to advance the knowledge of early galaxy formation by studying high-redshift galaxies in blank fields with the help of gravitational lensing to see the "faintest galaxies in the distant universe." The Frontier Fields web page describes the goals of the program being:
Public use.
Anyone can apply for time on the telescope; there are no restrictions on nationality or academic affiliation, but funding for analysis is only available to US institutions. Competition for time on the telescope is intense, with about one-fifth of the proposals submitted in each cycle earning time on the schedule.
Calls for proposals are issued roughly annually, with time allocated for a cycle lasting about one year. Proposals are divided into several categories; "general observer" proposals are the most common, covering routine observations. "Snapshot observations" are those in which targets require only 45 minutes or less of telescope time, including overheads such as acquiring the target. Snapshot observations are used to fill in gaps in the telescope schedule that cannot be filled by regular GO programs.
Astronomers may make "Target of Opportunity" proposals, in which observations are scheduled if a transient event covered by the proposal occurs during the scheduling cycle. In addition, up to 10% of the telescope time is designated "director's discretionary" (DD) time. Astronomers can apply to use DD time at any time of year, and it is typically awarded for study of unexpected transient phenomena such as supernovae.
Other uses of DD time have included the observations that led to views of the Hubble Deep Field and Hubble Ultra Deep Field, and in the first four cycles of telescope time, observations that were carried out by amateur astronomers.
Amateur observations.
The first director of STScI, Riccardo Giacconi, announced in 1986 that he intended to devote some of his director discretionary time to allowing amateur astronomers to use the telescope. The total time to be allocated was only a few hours per cycle but excited great interest among amateur astronomers.
Proposals for amateur time were stringently reviewed by a committee of amateur astronomers, and time was awarded only to proposals that were deemed to have genuine scientific merit, did not duplicate proposals made by professionals, and required the unique capabilities of the space telescope. Thirteen amateur astronomers were awarded time on the telescope, with observations being carried out between 1990 and 1997. One such study was "Transition CometsâUV Search for OH". The very first proposal, "A Hubble Space Telescope Study of Posteclipse Brightening and Albedo Changes on Io", was published in "Icarus", a journal devoted to solar system studies. A second study from another group of amateurs was also published in "Icarus". After that time, however, budget reductions at STScI made the support of work by amateur astronomers untenable, and no additional amateur programs have been carried out.
20th and 25th anniversaries.
The Hubble Space Telescope celebrated its 20th anniversary in space on April 24, 2010. To commemorate the occasion, NASA, ESA, and the Space Telescope Science Institute (STScI) released an image from the Carina Nebula.
To commemorate Hubble's 25th anniversary in space on April 24, 2015, STScI released images of the Westerlund 2 cluster, located about away in the constellation Carina, through its Hubble 25 website. The European Space Agency created a dedicated 25th anniversary page on its website.
Scientific results.
Key projects.
In the early 1980s, NASA and STScI convened four panels to discuss Key Projects. These were projects that were both scientifically important and would require significant telescope time, which would be explicitly dedicated to each project. This guaranteed that these particular projects would be completed early, in case the telescope failed sooner than expected. The panels identified three such projects: 1) a study of the nearby intergalactic medium using quasar absorption lines to determine the properties of the intergalactic medium and the gaseous content of galaxies and groups of galaxies; 2) a medium deep survey using the Wide Field Camera to take data whenever one of the other instruments was being used and 3) a project to determine the Hubble Constant within ten percent by reducing the errors, both external and internal, in the calibration of the distance scale.
Important discoveries.
Hubble has helped resolve some long-standing problems in astronomy, as well as raising new questions. Some results have required new theories to explain them. Among its primary mission targets was to measure distances to Cepheid variable stars more accurately than ever before, and thus constrain the value of the Hubble constant, the measure of the rate at which the universe is expanding, which is also related to its age. Before the launch of HST, estimates of the Hubble constant typically had errors of up to 50%, but Hubble measurements of Cepheid variables in the Virgo Cluster and other distant galaxy clusters provided a measured value with an accuracy of Â±10%, which is consistent with other more accurate measurements made since Hubble's launch using other techniques. The estimated age is now about 13.7 billion years, but before the Hubble Telescope scientists predicted an age ranging from 10 to 20 billion years.
While Hubble helped to refine estimates of the age of the universe, it also cast doubt on theories about its future. Astronomers from the High-z Supernova Search Team and the Supernova Cosmology Project used ground-based telescopes and HST to observe distant supernovae and uncovered evidence that, far from decelerating under the influence of gravity, the expansion of the universe may in fact be accelerating. The cause of this acceleration remains poorly understood; the most common cause attributed is dark energy.
The high-resolution spectra and images provided by the HST have been especially well-suited to establishing the prevalence of black holes in the nuclei of nearby galaxies. While it had been hypothesized in the early 1960s that black holes would be found at the centers of some galaxies, and astronomers in the 1980s identified a number of good black hole candidates, work conducted with Hubble shows that black holes are probably common to the centers of all galaxies. The Hubble programs further established that the masses of the nuclear black holes and properties of the galaxies are closely related. The legacy of the Hubble programs on black holes in galaxies is thus to demonstrate a deep connection between galaxies and their central black holes.
The collision of Comet Shoemaker-Levy 9 with Jupiter in 1994 was fortuitously timed for astronomers, coming just a few months after Servicing Mission 1 had restored Hubble's optical performance. Hubble images of the planet were sharper than any taken since the passage of Voyager 2 in 1979, and were crucial in studying the dynamics of the collision of a comet with Jupiter, an event believed to occur once every few centuries.
Other discoveries made with Hubble data include proto-planetary disks (proplyds) in the Orion Nebula; evidence for the presence of extrasolar planets around Sun-like stars; and the optical counterparts of the still-mysterious gamma ray bursts. HST has also been used to study objects in the outer reaches of the Solar System, including the dwarf planets Pluto and Eris.
A unique window on the Universe enabled by Hubble are the Hubble Deep Field, Hubble Ultra-Deep Field, and Hubble Extreme Deep Field images, which used Hubble's unmatched sensitivity at visible wavelengths to create images of small patches of sky that are the deepest ever obtained at optical wavelengths. The images reveal galaxies billions of light years away, and have generated a wealth of scientific papers, providing a new window on the early Universe. The Wide Field Camera 3 improved the view of these fields in the infrared and ultraviolet, supporting the discovery of some of the most distant objects yet discovered, such as MACS0647-JD.
The non-standard object SCP 06F6 was discovered by the Hubble Space Telescope in February 2006. During June and July 2012, US astronomers using Hubble discovered a tiny fifth moon moving around icy Pluto.
In March 2015, researchers announced that measurements of aurorae around Ganymede revealed that the moon has a subsurface ocean. Using Hubble to study the motion of its aurorae, the researchers determined that a large saltwater ocean was helping to suppress the interaction between Jupiter's magnetic field and that of Ganymede. The ocean is estimated to be deep, trapped beneath a ice crust.
On December 11, 2015, Hubble captured an image of the first-ever predicted reappearance of a supernova, dubbed "Refsdal", which was calculated using different mass models of a galaxy cluster whose gravity is warping the supernova's light. The supernova was previously seen in November 2014 behind galaxy cluster MACS J1149.5+2223 as part of Hubble's Frontier Fields program. Astronomers spotted four separate images of the supernova in an arrangement known as an Einstein Cross. The light from the cluster has taken about five billion years to reach Earth, though the supernova exploded some 10 billion years ago. The detection of Refsdal's reappearance served as a unique opportunity for astronomers to test their models of how mass, especially dark matter, is distributed within this galaxy cluster.
On March 3, 2016, researchers using Hubble data announced the discovery of the farthest known galaxy to date: GN-z11. The Hubble observations occurred on February 11, 2015, and April 3, 2015, as part of the CANDELS/GOODS-North surveys.
Impact on astronomy.
Many objective measures show the positive impact of Hubble data on astronomy. Over 9,000 papers based on Hubble data have been published in peer-reviewed journals, and countless more have appeared in conference proceedings. Looking at papers several years after their publication, about one-third of all astronomy papers have no citations, while only 2% of papers based on Hubble data have no citations. On average, a paper based on Hubble data receives about twice as many citations as papers based on non-Hubble data. Of the 200 papers published each year that receive the most citations, about 10% are based on Hubble data.
Although the HST has clearly helped astronomical research, its financial cost has been large. A study on the relative astronomical benefits of different sizes of telescopes found that while papers based on HST data generate 15 times as many citations as a ground-based telescope such as the William Herschel Telescope, the HST costs about 100 times as much to build and maintain.
Deciding between building ground- versus space-based telescopes is complex. Even before Hubble was launched, specialized ground-based techniques such as aperture masking interferometry had obtained higher-resolution optical and infrared images than Hubble would achieve, though restricted to targets about 108 times brighter than the faintest targets observed by Hubble. Since then, advances in adaptive optics have extended the high-resolution imaging capabilities of ground-based telescopes to the infrared imaging of faint objects. The usefulness of adaptive optics versus HST observations depends strongly on the particular details of the research questions being asked. In the visible bands, adaptive optics can only correct a relatively small field of view, whereas HST can conduct high-resolution optical imaging over a wide field. Only a small fraction of astronomical objects are accessible to high-resolution ground-based imaging; in contrast Hubble can perform high-resolution observations of any part of the night sky, and on objects that are extremely faint.
Hubble data.
Transmission to Earth.
Hubble data was initially stored on the spacecraft. When launched, the storage facilities were old-fashioned reel-to-reel tape recorders, but these were replaced by solid state data storage facilities during servicing missions 2 and 3A. About twice daily, the Hubble Space Telescope radios data to a satellite in the geosynchronous Tracking and Data Relay Satellite System (TDRSS), which then downlinks the science data to one of two 60-foot (18-meter) diameter high-gain microwave antennas located at the White Sands Test Facility in White Sands, New Mexico. From there they are sent to the Space Telescope Operations Control Center at Goddard Space Flight Center, and finally to the Space Telescope Science Institute for archiving. Each week, HST downlinks approximately 140 gigabytes of data.
Color images.
All images from Hubble are monochromatic grayscale, in which its cameras incorporate a variety of filters each sensitive to specific wavelengths of light. Color images are created by combining separate monochrome images taken through different filters. This process can also create false-color versions of images including infrared and ultraviolet channels, where infrared is typically rendered as a deep red and ultraviolet is rendered as a deep blue.
Archives.
All Hubble data is eventually made available via the Mikulski Archive for Space Telescopes at STScI, CADC and ESA/ESAC. Data is usually proprietaryâavailable only to the principal investigator (PI) and astronomers designated by the PIâfor one year after being taken. The PI can apply to the director of the STScI to extend or reduce the proprietary period in some circumstances.
Observations made on Director's Discretionary Time are exempt from the proprietary period, and are released to the public immediately. Calibration data such as flat fields and dark frames are also publicly available straight away. All data in the archive is in the FITS format, which is suitable for astronomical analysis but not for public use. The Hubble Heritage Project processes and releases to the public a small selection of the most striking images in JPEG and TIFF formats.
Pipeline reduction.
Astronomical data taken with CCDs must undergo several calibration steps before they are suitable for astronomical analysis. STScI has developed sophisticated software that automatically calibrates data when they are requested from the archive using the best calibration files available. This 'on-the-fly' processing means that large data requests can take a day or more to be processed and returned. The process by which data are calibrated automatically is known as 'pipeline reduction', and is increasingly common at major observatories. Astronomers may if they wish retrieve the calibration files themselves and run the pipeline reduction software locally. This may be desirable when calibration files other than those selected automatically need to be used.
Data analysis.
Hubble data can be analyzed using many different packages. STScI maintains the custom-made Space Telescope Science Data Analysis System (STSDAS) software, which contains all the programs needed to run pipeline reduction on raw data files, as well as many other astronomical image processing tools, tailored to the requirements of Hubble data. The software runs as a module of IRAF, a popular astronomical data reduction program.
Outreach activities.
It has always been important for the Space Telescope to capture the public's imagination, given the considerable contribution of taxpayers to its construction and operational costs. After the difficult early years when the faulty mirror severely dented Hubble's reputation with the public, the first servicing mission allowed its rehabilitation as the corrected optics produced numerous remarkable images.
Several initiatives have helped to keep the public informed about Hubble activities.
In the United States, outreach efforts are coordinated by the Space Telescope Science Institute (STScI) Office for Public Outreach, which was established in 2000 to ensure that U.S. taxpayers saw the benefits of their investment in the space telescope program. To that end, STScI operates the HubbleSite.org website. The Hubble Heritage Project, operating out of the STScI, provides the public with high-quality images of the most interesting and striking objects observed. The Heritage team is composed of amateur and professional astronomers, as well as people with backgrounds outside astronomy, and emphasizes the aesthetic nature of Hubble images. The Heritage Project is granted a small amount of time to observe objects which, for scientific reasons, may not have images taken at enough wavelengths to construct a full-color image.
Since 1999, the leading Hubble outreach group in Europe has been the Hubble European Space Agency Information Centre (HEIC). This office was established at the Space Telescope European Coordinating Facility in Munich, Germany. HEIC's mission is to fulfill HST outreach and education tasks for the European Space Agency. The work is centered on the production of news and photo releases that highlight interesting Hubble results and images. These are often European in origin, and so increase awareness of both ESA's Hubble share (15%) and the contribution of European scientists to the observatory. ESA produces educational material, including a videocast series called Hubblecast designed to share world-class scientific news with the public.
The Hubble Space Telescope has won two Space Achievement Awards from the Space Foundation, for its outreach activities, in 2001 and 2010.
There is a replica of the Hubble Space Telescope on the courthouse lawn in Marshfield, Missouri, the hometown of namesake Edwin P. Hubble.
Future.
Equipment failure.
Past servicing missions have exchanged old instruments for new ones, both avoiding failure and making possible new types of science. Without servicing missions, all of the instruments will eventually fail. In August 2004, the power system of the Space Telescope Imaging Spectrograph (STIS) failed, rendering the instrument inoperable. The electronics had originally been fully redundant, but the first set of electronics failed in May 2001. This power supply was fixed during servicing mission 4 in May 2009. Similarly, the Advanced Camera for Surveys (ACS) main camera primary electronics failed in June 2006, and the power supply for the backup electronics failed on January 27, 2007. Only the instrument's Solar Blind Channel (SBC) was operable using the side-1 electronics. A new power supply for the wide angle channel was added during SM 4, but quick tests revealed this did not help the high resolution channel.
HST uses gyroscopes to stabilize itself in orbit and point accurately and steadily at astronomical targets. Normally, three gyroscopes are required for operation; observations are still possible with two, but the area of sky that can be viewed would be somewhat restricted, and observations requiring very accurate pointing are more difficult. There are further contingency plans for observations with just one gyro, but if all gyros fail, continued scientific observations will not be possible. In 2005, it was decided to switch to two-gyroscope mode for regular telescope operations as a means of extending the lifetime of the mission. The switch to this mode was made in August 2005, leaving Hubble with two gyroscopes in use, two on backup, and two inoperable. One more gyro failed in 2007. By the time of the final repair mission, during which all six gyros were replaced (with two new pairs and one refurbished pair), only three gyros were still working. Engineers are confident that they have identified the root causes of the gyro failures, and the new models should be much more reliable.
Orbital decay.
Hubble orbits the Earth in the extremely tenuous upper atmosphere, and over time its orbit decays due to drag. If it is not re-boosted, it will re-enter the Earth's atmosphere within some decades, with the exact date depending on how active the Sun is and its impact on the upper atmosphere. If Hubble were to descend in a completely uncontrolled re-entry, parts of the main mirror and its support structure would probably survive, leaving the potential for damage or even human fatalities. In 2013, deputy project manager James Jeletic projected that Hubble could survive into 2020. Based on solar activity and atmospheric drag, or lack thereof, a natural atmospheric reentry for Hubble will occur between 2030 and 2040.
NASA's original plan for safely de-orbiting Hubble was to retrieve it using a space shuttle. Hubble would then have most likely been displayed in the Smithsonian Institution. This is no longer possible since the space shuttle fleet has been retired, and would have been unlikely in any case due to the cost of the mission and risk to the crew. Instead NASA considered adding an external propulsion module to allow controlled re-entry. Ultimately NASA installed the Soft Capture and Rendezvous System, to enable deorbit by either a crewed or robotic mission.
Successors.
There is no direct successor to Hubble as an ultraviolet and visible-light space telescope, as near-term space telescopes do not duplicate Hubble's wavelength coverage (near-ultraviolet to near-infrared wavelengths), instead concentrating on the farther infrared bands. These bands are preferred for studying high redshift and low-temperature objects, objects generally older and farther away in the universe. These wavelengths are also difficult or impossible to study from the ground, justifying the expense of a space-based telescope. Large ground-based telescopes can image some of the same wavelengths as Hubble, sometimes challenge HST in terms of resolution by using adaptive optics (AO), have much larger light-gathering power, and can be upgraded more easily, but cannot yet match Hubble's excellent resolution over a wide field of view with the very dark background of space.
Plans for a Hubble successor materialized as the Next Generation Space Telescope project, which culminated in plans for the James Webb Space Telescope (JWST), the formal successor of Hubble. Very different from a scaled-up Hubble, it is designed to operate colder and farther away from the Earth at the L2 Lagrangian point, where thermal and optical interference from the Earth and Moon are lessened. It is not engineered to be fully serviceable (such as replaceable instruments), but the design includes a docking ring to enable visits from other spacecraft. A main scientific goal of JWST is to observe the most distant objects in the universe, beyond the reach of existing instruments. It is expected to detect stars in the early Universe approximately 280 million years older than stars HST now detects. The telescope is an international collaboration between NASA, the European Space Agency, and the Canadian Space Agency since 1996, and is planned for launch on an Ariane 5 rocket. Although JWST is primarily an infrared instrument, its coverage extends down to 600Â nm wavelength light, or roughly orange in the visible spectrum. A typical human eye can see to about 750Â nm wavelength light, so there is some overlap with the longest visible wavelength bands, including orange and red light.
A complementary telescope, looking at even longer wavelengths than Hubble or JWST, was the European Space Agency's Herschel Space Observatory, launched on May 14, 2009. Like JWST, Herschel was not designed to be serviced after launch, and had a mirror substantially larger than Hubble's, but observed only in the far infrared and submillimeter. It needed helium coolant, of which it ran out on April 29, 2013.
Further concepts for advanced 21st-century space telescopes include the Advanced Technology Large-Aperture Space Telescope, a conceptualized 8- to 16-meter (320- to 640-inch) optical space telescope that if realized could be a more direct successor to HST, with the ability to observe and photograph astronomical objects in the visible, ultraviolet, and infrared wavelengths, with substantially better resolution than Hubble or the Spitzer Space telescope. This effort is being planned for the 2025â2035 time frame.
Existing ground-based telescopes, and various proposed Extremely Large Telescopes, can exceed the HST in terms of sheer light-gathering power and diffraction limit due to larger mirrors, but other factors affect telescopes. In some cases, they may be able to match or beat Hubble in resolution by using adaptive optics. However, AO on large ground-based reflectors will not make Hubble and other space telescopes obsolete. Most AO systems sharpen the view over a very narrow fieldâLucky Cam, for example, produces crisp images just 10" to 20" wide, whereas Hubble's cameras are super sharp across a 2Â½' (150") field. Furthermore, space telescopes can study the universe across the entire electromagnetic spectrum, most of which is blocked by Earth's atmosphere. Finally, the background sky is darker in space than on the ground, because air absorbs solar energy during the day and then releases it at night, producing a faintâbut nevertheless discernibleâairglow that washes out low-contrast astronomical objects.

</doc>
