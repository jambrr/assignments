<doc id="44393" url="https://en.wikipedia.org/wiki?curid=44393" title="Claudius Gothicus">
Claudius Gothicus

Claudius II (; May 10, 210 – July 270), commonly known as Claudius Gothicus, was Roman Emperor from 268 to 270. During his reign he fought successfully against the Alamanni and scored a victory against the Goths at the Battle of Naissus. He died after succumbing to a plague (perhaps smallpox) that ravaged the provinces of the Empire.
Early life and origin.
Claudius' origin is Illyrian. Born on May 10, 210, he was either from Sirmium in Pannonia Inferior or from Naissus Dardania (in Moesia Superior).
Military career and rise to power.
Claudius had served with the Roman army for all his adult life, making his way up the military hierarchy until Emperor Gallienus made him the commander of his elite cavalry force ("hipparchos") and subsequently his military deputy. In September 268, he found himself assigned as a military tribune with the Imperial Army besieging the usurper Aureolus in Milan. His troops then proclaimed him Emperor amid charges, never proven, that he murdered his predecessor Gallienus. However, he soon proved to be less than bloodthirsty, as he asked the Roman Senate to spare the lives of Gallienus' family and supporters. He was less magnanimous toward Rome's enemies, however, and it was to this that he owed his popularity.
It is possible Claudius gained his position and the respect of the soldiers by being physically strong and especially cruel. A legend tells of Claudius knocking out a horse's teeth with one punch. When Claudius performed as a wrestler in the 250s, he supposedly knocked out the teeth of his opponent when his genitalia had been grabbed in the match.
Claudius, like Maximinus Thrax before him, was of barbarian birth. After an interlude of failed aristocratic Roman emperors since Maximinus' death, Claudius was the first in a series of tough soldier-emperors who would eventually restore the Empire from the Crisis of the third century.
Downfall of Gallienus.
During the 260s, the breakup of the Roman Empire into three distinct governing entities (the core Roman Empire, the Gallic Empire and the Palmyrene Empire) placed the whole Roman imperium into a precarious position. Gallienus was seriously weakened by his failure to defeat Postumus in the West, and the ability of Odaenathus to live with his arrangement with Gallienus in the East. By 268, however, the situation had changed, as Odaenathus was assassinated, most likely out of court intrigue, and Gallienus fell victim to a mutiny in his own ranks. Upon the death of Odaenathus, power fell to his younger son, who was dominated by his mother, Zenobia.
Under threat of invasion by multiple tribes, Gallienus' troubles primarily lay with Postumus, whom he could not attack because his attention was required in dealing with Macrianus and the invading "Skythai." After four years of delay, Postumus had established power, but in 265, when Gallienus and his men crossed the Alps, they defeated and besieged Postumus in an (unnamed) Gallic city. When victory appeared to be near, Gallienus made the mistake of approaching the city walls too closely and was gravely injured, compelling him to withdraw the campaign. In the next three years, Gallienus' troubles would only get worse. The "Skythai" successfully invaded the Balkans in the early months of 268, and Aureolus, a commander of the cavalry, declared himself an ally of Postumus and the new emperor in Milan.
At this time, another invasion was taking place. A group called the Herulians navigated through Asia Minor and then into Greece on a naval expedition. Details of these invasions are abstract, as it is nearly impossible to reconstruct the happenings, due to the chain of conflicts initiated by the Herulians in 268. Scholars assume Gallienus' efforts were focused on Aureolus, the officer who betrayed him, and the defeat of the Herulians was left to his successor, Claudius Gothicus.
The death of Gallienus is surrounded by conspiracy and betrayal, as were many emperors' deaths. Different accounts of the incident are recorded, but they agree that senior officials wanted Gallienus dead. According to two accounts, the prime conspirator was Aurelius Heraclianus, the Praetorian Prefect. One version of the story tells of Heraclianus bringing Claudius into the plot while the account given by Historia Augusta exculpates the would-be emperor and adds the prominent general Lucius Aurelius Marcianus into the plot. The removal of Claudius from the conspiracy is due to his later role as the progenitor of the house of Constantine, a fiction of Constantine's time, and may serve to guarantee that the original version from which these two accounts spring was current prior to the reign of Constantine. It is written that while sitting down at dinner, Gallienus was told that Aureolus and his men were approaching the camp. Gallienus rushed to the front lines, ready to give orders, when he was struck down by a commander of his cavalry. In a different and more controversial account, Aureolus forges a document in which Gallienus appears to be plotting against his generals and makes sure it falls into the hands of the emperor's senior staff. In this plot, Aurelian is added as a possible conspirator. The tale of his involvement in the conspiracy might be seen as at least partial justification for the murder of Aurelian himself under circumstances that seem remarkably similar to those in this story.
Whichever story is true, Gallienus was killed in the summer of 268, and Claudius was chosen by the army outside of Milan to succeed him. Accounts tell of people hearing the news of the new Emperor, and reacting by murdering Gallienus' family members until Claudius declared he would respect the memory of his predecessor. Claudius had the deceased emperor deified and buried in a family tomb on the Appian Way. The traitor Aureolus was not treated with the same reverence, as he was killed by his besiegers after a failed attempt to surrender.
The Campaigns of Claudius.
At the time of his Claudius' accession, the Roman Empire was in serious danger from several incursions, both within and outside its borders. The most pressing of these was an invasion of Illyricum and Pannonia by the Goths. Although Gallienus had already inflicted some damage on them at the Battle of Nestus, Claudius, not long after being named Emperor, followed this up by winning his greatest victory, and one of the greatest in the history of Roman arms.
At the Battle of Naissus, Claudius and his legions routed a huge Gothic army. Together with his cavalry commander, the future Emperor Aurelian, the Romans took thousands of prisoners, destroyed the Gothic cavalry as a force, and stormed their laager (a circular alignment of wagons long favored by the Goths). The victory earned Claudius his surname of "Gothicus" (conqueror of the Goths), and that is how he is known to this day. More importantly, the Goths were soon driven back across the Danube River by Aurelian, and nearly a century passed before they again posed a serious threat to the empire.
At the same time, the Alamanni had crossed the Alps and attacked the empire. Claudius responded quickly, routing the Alamanni at the Battle of Lake Benacus in the late fall of 268, a few months after the battle of Naissus. For this he was awarded the title of "Germanicus Maximus." He then turned on the Gallic Empire, ruled by a pretender for the past eight years and encompassing Britain, Gaul, and the Iberian Peninsula. He won several victories and soon regained control of Hispania and the Rhone river valley of Gaul. This set the stage for the ultimate destruction of the Gallic Empire under Aurelian.
However, Claudius did not live long enough to fulfill his goal of reuniting all the lost territories of the empire. Late in 269 he had traveled to Sirmium and was preparing to go to war against the Vandals, who were raiding in Pannonia. However, he fell victim to the Plague of Cyprian (possibly smallpox), and died early in January 270. Before his death, he is thought to have named Aurelian as his successor, though Claudius' brother Quintillus briefly seized power.
The Senate immediately deified Claudius as "Divus Claudius Gothicus".
The Empire and Foreign Affairs Under Claudius.
Claudius was not the only man to reap the benefits of holding high office after the death of Gallienus. Before the rule of Claudius Gothicus, there had only been two emperors from the Balkans, but afterwards there would only be one emperor who did not hail from the provinces of Pannonia, Moesia or Illyricum until the year 378, when Theodosius I from Hispania would take the throne. To comprehend the structure of government during the reign of Claudius, we must look at four inscriptions that deepen our understanding of a new, truncated empire. The first is a dedication to Aurelius Heraclianus, the prefect involved in the conspiracy against Gallienus, from Traianus Mucianus, who also gave a dedication to Heraclianus' brother, Aurelius Appollinaris, who was the equestrian governor of the province of "Thracia" in 267-68 AD. Because these men shared the family name, Marcus Aurelius, a name given to those made citizens by the constitutio Antoniniana, we can understand that these men did not come from the imperial "élite". The third inscription reveals the career of Marcianus, another leading general by the time that Gallienus died. The fourth honors Julius Placidianus, the prefect of the vigiles. While we cannot prove that Heraclianus, Appollinaris, Placidianus, or Marcianus were of Danubian origin themselves, it is clear that none of them were members of the Severan aristocracy, and all of them appear to owe their prominence to their military roles. To those men must be added Marcus Aurelius Aurelianus (the future emperor Aurelian) and Marcus Aurelius Probus (another emperor in waiting), both men of Balkan background, and from families enfranchised in the time of Caracalla.
Although we see a rise in Pannonian, Moesian and Illyrian marshals, and foreigners become notable figures, it would be impractical to think the government could function without help from the traditional classes within the empire. Although their influence was weakened, there were still a number of men with influence from the older aristocracy. Claudius assumed the consulship in 269 with Paternus, a member of the prominent senatorial family, the Paterni, who had supplied consuls and urban prefects throughout Gallienus' reign, and thus were quite influential. In addition, Flavius Antiochianus, one of the consuls of 270, who was an urban prefect the year before, would continue to hold his office for the following year. A colleague of Antiochianus, Virius Orfitus, also the descendant of a powerful family, would continue to hold influence during his father's term as prefect. Aurelian's colleague as consul was another such man, Pomponius Bassus, a member of one of the oldest senatorial families, as was one of the consuls in 272, Junius Veldumnianus.
In his first full year of power, Claudius was greatly assisted by the sudden destruction of the imperium Galliarum. When Ulpius Cornelius Laelianus, a high official under Postumus, declared himself emperor in Germania Superior, in the spring of 269, Postumus defeated him, but in doing so, refused to allow the sack of Mainz, which had served as Laelianus' headquarters. This proved to be his downfall, for out of anger, Postumus' army mutinied and murdered him. Selected by the troops, Marcus Aurelius Marius was to replace Postumus as ruler. Marius' rule did not last long though, as Victorinus, Postumus' praetorian prefect, defeated him. Now emperor of the Gauls, Victorinus was soon in a precarious position, for the Spanish provinces had deserted the Gallic Empire and declared their loyalty to Claudius, while in southern France, Placidianus had captured Grenoble. Luckily, it was there that Placidianus stopped and Victorinus' position stabilized. In the next year, when Autun revolted, declaring itself for Claudius, the central government made no moves to support it. As a result, the city went through a siege, lasting many weeks, until it was finally captured and sacked by Victorinus.
It is still unknown why Claudius did nothing to help the city of Autun, but sources tell us his relations with Palmyra were waning in the course of 270. An obscure passage in the Historia Augusta life of Gallienus states that he had sent an army under Aurelius Heraclianus to the region that had been annihilated by Zenobia. But because Heraclianus was not actually in the east in 268 (instead, at this time, he was involved in the conspiracy of Gallienus' death), we can see that this can not be correct. But the confusion evident in this passage, which also places the bulk of "Skythian" activity during 269 a year earlier, under Gallienus, may stem from a later effort to pile all possible disasters in this year into the reign of the former Emperor. This would keep Claudius' record of being an ancestor of Constantine from being tainted. If this understanding of the sources is correct, it might also be correct to see the expedition of Heraclianus to the east as an event of Claudius' time.
The victories of Claudius over the Goths would not only make him a hero in Latin tradition, but an admirable choice as an ancestor for Constantine, who was born at Naissus, the site of Claudius' victory in 269. Claudius is also held in high esteem by Zonaras, whose Greek tradition seems to have been influenced by Latin. For Zosimus, a more reasoned contemporary view shows him as less grand. Claudius' successes in the year 269 were not continued in his next year as Emperor. As the "Skythai" starved in the mountains or surrendered, the legions pursuing them began to see an epidemic spreading throughout the men. Also, Claudius' unwillingness to do anything at the siege of Autun likely provoked a quarrel with Zenobia.
Although it is not proven that the invasion of Gaul was the breaking point between Claudius and Zenobia, the sequence of events point to the siege as an important factor. The issue at hand was the position that Odaenathus held as corrector totius orientis. Vaballathus, the son of Zenobia, was given this title when Zenobia claimed it for him. From then on, tension between the two empires would only get worse. Aurelius Heraclianus' fabled arrival might have been an effort to reassert central control after the death of Odaenathus, but, if so, it failed. Although coins were never minted with the face of Odaenathus, soon after his death coins were made with image of his son.
Under Zabdas, a Palmyrene army invaded Arabia and moved into Egypt in the late summer. At this time, the prefect of Egypt was Tenagino Probus, described as an able soldier who not only defeated an invasion of Cyrenaica by the nomadic tribes to the south in 269, but also was successful in hunting down "Skythian" ships in the Mediterranean. However, he did not see the same success in Egypt, for a Palmyrene underground, led by Timagenes, undermined Probus, defeated his army, and killed him in a battle near the modern city of Cairo in the late summer of 270.
Generally when a Roman commander is slaughtered it is taken as a sign that a state of war is in existence, and if we can associate the death of Heraclianus in 270, as well as an inscription from Bostra recording the rebuilding of a temple destroyed by the Palmyrene army, then these violent acts could be interpreted the same way. Yet they apparently were not. As David Potter writes, "The coins of Vaballathus avoid claims to imperial power: he remains vir consularis, rex, imperator, dux Romanorum, a range of titles that did not mimic those of the central government. The status vir consularis was, as we have seen, conferred upon Odaenathus; the title rex, or king, is simply a Latin translation of mlk, or king; imperator in this context simply means "victorious general"; and dux Romanorum looks like yet another version of corrector totius orientis" (Potter, 263). These titles suggest that Odaenathus' position, not unlike a king in the Semitic world, was inheritable. In Roman culture, the status gained in procuring a position could be passed on, but not the position itself. It is possible that the thin line between office and the status that accompanied it were dismissed in Palmyrene court, especially when the circumstance worked against the interests of a regime that was able to defeat Persia, which a number of Roman emperors had failed to do. Vaballathus stressed the meanings of titles, because in Palmyrene context, the titles of Odaenathus meant a great deal. When the summer of 270 ended, things were looking very different in the empire than they did a year before. After its success, Gaul was in a state of inactivity and the empire was failing in the east. Insufficient resources plagued the state, as a great deal of silver was used for the antoninianus, which was again diluted.
Religion.
An account written by Aurelius Victor states that Claudius consulted the Sibylline Books prior to his campaigns against the Goths. Hinting that Claudius "revived the tradition of the Decii",
Victor illustrates the senatorial view, which saw Claudius' predecessor, Gallienus, as too relaxed when it came to religious policies.
Links to Constantinian dynasty.
The unreliable "Historia Augusta" reports Claudius and Quintillus having another brother named Crispus and through him a niece, Claudia, who reportedly married Eutropius and was mother to Constantius Chlorus. Some historians suspect this account to be a genealogical fabrication, however, intended to link the family of Constantine I to that of a well-respected emperor.
Saint Valentine.
Claudius Gothicus has been linked to Saint Valentine since the Middle Ages. Contemporary records of his deeds were most probably destroyed during the Diocletianic Persecution on early 4th century and a tale of martydom was recorded in "Passio Marii et Marthae", a work published in the 5th or 6th century. 20th-century historians agree that the accounts from this period cannot be verified. The legend refers to "Emperor Claudius", but Claudius I did not persecute Christians, so people believe he was Claudius II even though this emperor spent most of his time warring outside his territory. The legend was retold in later texts. In the "Nuremberg Chronicle" of 1493 AD, the emperor martyred the Roman priest during a general persecution of Christians. The text states that St. Valentine was beaten with clubs and finally beheaded for giving aid to Christians in Rome. The "Golden Legend" of 1260 AD recounts how St. Valentine refused to deny Christ before the "Emperor Claudius" in 270 AD and as a result was beheaded. Since then, February 14 marks Valentine's Day, a day set aside by the Christian church in memory of the Roman priest and physician.

</doc>
<doc id="44397" url="https://en.wikipedia.org/wiki?curid=44397" title="Defenestrations of Prague">
Defenestrations of Prague

The Defenestrations of Prague (, ) were two incidents in the history of Bohemia in which multiple people were defenestrated; there have been more (see below). The first occurred in 1419 and the second in 1618, although the term "Defenestration of Prague" more commonly refers to the later incident. Both helped to trigger prolonged conflict within Bohemia and beyond. Defenestration is the act of throwing someone or something out of a window.
First Defenestration of Prague.
The First Defenestration of Prague involved the killing of seven members of the city council by a crowd of radical Czech Hussites on 30 July 1419.
Jan Želivský, a Hussite priest at the church of the Virgin Mary of the Snows, led his congregation on a procession through the streets of Prague to the New Town Hall (Novoměstská radnice) on Charles Square. The town council members had refused to exchange their Hussite prisoners. While they were marching, a stone was thrown at Želivský from the window of the town hall. This enraged the mob and they stormed the town hall. Once inside the hall, the group defenestrated the judge, the burgomaster, and some thirteen members of the town council, where they were killed by the fall or dispatched by the mob.
King Wenceslaus IV of Bohemia, upon hearing this news, was stunned and died shortly after, supposedly due to the shock.
The procession was a result of the growing discontent at the contemporary direction of the Church and the inequality between the peasants and the Church's prelates, and the nobility. This discontent combined with rising feelings of nationalism and increased the influence of radical preachers such as Jan Želivský, influenced by Wycliffe, who saw the current state of the Catholic Church as corrupt. These preachers urged their congregations to action, including taking up arms, to combat these perceived transgressions.
The First Defenestration was thus the turning point between talk and action leading to the prolonged Hussite Wars. The wars broke out shortly afterward and lasted until 1436.
Second Defenestration of Prague.
The Second Defenestration of Prague precipitated the Thirty Years' War.
Background.
In 1555, the Peace of Augsburg had settled religious disputes in the Holy Roman Empire by enshrining the principle of 
"Cuius regio, eius religio", allowing a prince to determine the religion of his subjects. The Kingdom of Bohemia since 1526 had been governed by Habsburg Kings, who did not, however, force their Catholic religion on their largely Protestant subjects. In 1609, Rudolf II, Holy Roman Emperor and King of Bohemia (1576–1612), increased Protestant rights. He was increasingly viewed as unfit to govern, and other members of the Habsburg dynasty declared his younger brother, Matthias, to be family head in 1606. Matthias began to gradually wrest territory from Rudolf, beginning with Hungary. In order to strengthen his hold on Bohemia, Rudolf in 1609 issued the "Letter of Majesty", which granted Bohemia's largely Protestant estates the right to freely exercise their religion, essentially setting up a Protestant Bohemian state church controlled by the estates, "dominated by the towns and rural nobility". Upon Rudolf's death, Matthias succeeded in the rule of Bohemia (1612–1619) and extended his offer of more legal and religious concessions to Bohemia, relying mostly on the advice of his chancellor, Bishop Melchior Klesl.
Conflict was precipitated by two factors: Matthias, already aging and without children, made his cousin Ferdinand of Styria his heir and had him elected king in 1617. Ferdinand was a proponent of the Catholic Counter-Reformation and not likely to be well-disposed to Protestantism or Bohemian freedoms. Bohemian Protestants opposed the royal government as they interpreted the Letter of Majesty to extend not only to the land controlled by the nobility or self-governing towns but also to the King's own lands. Whereas Matthias and Klesl were prepared to appease these demands, Ferdinand was not, and in 1618 forced the Emperor to order the cessation of construction of some Protestant chapels on royal land. When the Bohemian estates protested against this order, Ferdinand had their assembly dissolved.
The Defenestration.
On May 23, 1618, four Catholic Lords Regent, Count Jaroslav Borzita of Martinice, Count Vilem Slavata of Chlum, Adam II von Sternberg (who was the supreme burgrave), and Matthew Leopold Popel Lobcowitz (who was the grand prior), arrived at the Bohemian Chancellory at 8:30 am. After preparing the meeting hall, members of the dissolved assembly of the three main Protestant estates gathered at 9:00 am, led by Count Thurn, who had been deprived of his post as Castellan of Karlstadt by the Emperor. The Protestant Lords' agenda was to clarify whether or not the four regents present were responsible for persuading King Matthias to order the cessation of churches on royal land. According to Martinice himself:
Before the regents gave any answer, they requested that the Protestants give them the opportunity to confer with their superior, Adam von Waldstein, who was not present. If they were given the opportunity, the Protestants would get an official answer to their grievance by the next Friday (this was taking place on the eve of Ascension Day and they all must observe the holy day). The Protestants demanded an immediate answer. Two regents, Adam II von Sternberg and Matthew Leopold Popel Lobcowitz, were declared innocent by the Protestant Estate holders and too pious to have any responsibility in the letter's creation. They in turn were removed from the room; however, before leaving, Adam II von Sternberg made it clear that they "did not advise anything that was contrary to the Letter of Majesty". This left only Count Vilem Slavata of Chlum, Count Jaroslav Borzita of Martinice (who had replaced Thurn as Castellan), known Catholic hard-liners, and Philip Fabricius the secretary to the Regents. They eventually claimed responsibility for the letter and, assuming they were only going to be arrested, welcomed any punishment the Protestants had planned.
Count von Thurn turned to both Martinice and Slavata and said "you are enemies of us and of our religion, have desired to deprive us of our Letter of Majesty, have horribly plagued your Protestant subjects... and have tried to force them to adopt your religion against their wills or have had them expelled for this reason". Then to the crowd of Protestants, he continued "were we to keep these men alive, then we would lose the Letter of Majesty and our religion... for there can be no justice to be gained from or by them". Soon after, the two Regents were defenestrated along with the Regents' secretary, Philipus Fabricius, but survived the fall from the third floor. Catholics maintained the men were saved by angels or by the intercession of the Virgin Mary, who caught them; later Protestant pamphleteers asserted that they survived due to falling onto a dung heap, a story unknown to contemporaries and probably coined in response to divine intervention claims. Philip Fabricius was later ennobled by the emperor and granted the title "Baron von Hohenfall" (literally "Baron of Highfall").
Aftermath.
Immediately after the Defenestration, the Protestant estates and Catholic Habsburgs started gathering allies for war. After the death of Matthias in 1619, Ferdinand II was elected Holy Roman Emperor. At the same time, the Bohemian estates deposed him as King of Bohemia and replaced him with Frederick V, Elector Palatine, a leading Calvinist and son-in-law of the Protestant James VI and I, King of Scotland, England and Ireland.
Because they deposed a properly chosen king, the Protestants could not gather the international support they needed for war. Just two years after the Defenestration, Ferdinand and the Catholics regained power in the Battle of White Mountain on November 8, 1620. This became known as the first battle in the Thirty Years' War.
There was plundering and pillaging in Prague for weeks following the Battle. Several months later, twenty-seven nobles and citizens were tortured and executed in the Old Town Square. Twelve of their heads were impaled on iron hooks and hung from the Bridge Tower as a warning. This also contributed to catalyzing the Thirty Years' War.
Further defenestrations.
More events of defenestration have occurred in Prague during its history, but they are not usually called "defenestrations of Prague".
A defenestration (chronologically the second defenestration of Prague, sometimes called "one-and-halfth defenestration") happened on 24 September 1483, when a violent overthrow of the municipal governments of the Old and New Towns ended with throwing the Old-Town portreeve and the bodies of seven killed aldermen out of the windows of the respective town halls.
Sometimes, the name "the third defenestration of Prague" is used, although it has no standard meaning. For example, it has been used to describe the death of Jan Masaryk, who was found below the bathroom window of the building of the Czechoslovak Ministry of Foreign Affairs on 10 March 1948. The official report listed the death as a suicide. However, it was widely believed he was murdered, either by the nascent Communist government in which he served as a non-partisan Foreign Minister, or by the Soviet secret services. A Prague police report in 2004 concluded after forensic research that Masaryk had indeed been thrown out the window to his death. This report was seemingly corroborated in 2006 when a Russian journalist claimed that his mother knew the Russian intelligence officer who defenestrated Masaryk.
References.
An English translation of part of Slavata's report of the incident is printed in Henry Frederick Schwarz, "The Imperial Privy Council in the Seventeenth Century" (Cambridge, Mass.: Harvard University Press, 1943, issued as volume LIII of "Harvard Historical Studies"), pp. 344–347.

</doc>
<doc id="44399" url="https://en.wikipedia.org/wiki?curid=44399" title="Conrad II, Holy Roman Emperor">
Conrad II, Holy Roman Emperor

Conrad II ( – 4 June 1039), also known as and , was Emperor of the Holy Roman Empire from 1027 until his death in 1039. The founder of the Salian dynasty of emperors, Conrad also served as King of Germany from 1024, King of Italy from 1026, and King of Burgundy from 1033.
The son of a mid-level nobleman in Franconia, Count Henry of Speyer and Adelaide of Alsace, he inherited the titles of count of Speyer and of Worms as an infant when his father died. Conrad extended his power beyond his inherited lands, receiving the favor of the princes of the Kingdom of Germany. When the Saxon-based Ottonian dynasty of emperors died off with the childless Emperor Henry II, Conrad was elected to succeed him as King in 1024 at the age of 34. Conrad founded his own dynasty of rulers, known as the Salian dynasty, which ruled the Holy Roman Empire for over a century.
Conrad continued the policies and achievements of the Ottonian Henry II regarding the Catholic Church and the affairs of Italy. Conrad continued to build the Church as a center for imperial power, preferring to appoint church bishops over secular lords to important posts across the Empire. Like Henry II before him, Conrad also continued a policy of benign neglect over Italy, especially for the city of Rome. His reign marked a high point of the medieval imperial rule and a relatively peaceful period for the Empire. Following the death of the childless King Rudolph III of Burgundy in 1032, Conrad claimed dominion over the Kingdom of Arles and incorporated it into the Empire. The three kingdoms (Germany, Italy, and Burgundy) formed the basis of the Empire as the "royal triad" ("regna tria").
Early life.
Family background.
The Salian dynasty has its origins with Count Werner V of Worms, a mid-level Frankish noble from Germany's Duchy of Franconia east of the Rhine River. His son, Conrad the Red, succeeded him as Count in 941 and King Otto I of Germany (the future Holy Roman Emperor) appointed him as Duke of Lorraine in 944. He was subsequently married to Liutgarde, one of Otto's daughters, in 947 and became one of the king's closest allies. The relationship was strained, however, when Otto refused to honor a peace treaty Conrad, as Otto's representative, had conducted with the rebellious Berengar II of Italy. Conrad also resented the growing influence of Otto's brother Henry I of Bavaria, which he saw as threatening his own power. In 953 Conrad joined the king's son Liudolf in rebellion against Otto, but the rebellion was defeated and Conrad was stripped of his duchy. Conrad and Otto were soon reconciled, with Conrad fighting for Otto in the great Battle of Lechfeld in 955. Though the Germans were successful in halting the Hungarian invasions of Europe, Conrad lost his life in the battle. Conrad was succeeded as Count of Worms in 956 by his son Otto of Worms, a grandson of Otto I. Sometime between 965 and 970 Otto of Worms' oldest son, Henry of Speyer, was born. Little is known of his life as he died the age of 20 between 985 and 990. Conrad II's father was Henry of Speyer, and his mother was Adelaide of Alsace, an area of Upper Lorraine. After Henry's death, Adelaide married a Frankish nobleman. After her remarriage, Adelaide demonstrated no close relationship with her son.
In 978 Emperor Otto II appointed his nephew Otto of Worms as Duke of Carinthia after deposing the rebellious Duke Henry I of Carinthia during the War of the Three Henries. Upon receiving the ducal title, however, Otto lost his position at Worms, which was given to Bishop Hildebald, Otto II's imperial chancellor. When Otto II died suddenly in 983, his infant son Otto III succeeded him, with his mother Theophanu serving as regent. Theophanu sought to reconcile the imperial house with Henry I, restoring him as Duke of Carinthia in 985, with Otto of Worms allowed to regain his ancestral position as Count of Worms. However, Otto was allowed to style himself "Duke of Worms" and his original territory was expanded so as not to diminish his rank. Otto of Worms remained loyal to the new Emperor, receiving rulership of the March of Verona in 955, though the actual Duchy of Carinthia passed to Henry IV of Bavaria. In 996, Otto III appointed Otto of Worms's son Bruno as Pope Gregory V. When Emperor Otto III died in 1002, both Otto of Worms, Conrad's grandfather, and Henry IV were candidates for election as King of Germany. In a compromise, Otto withdrew and received the Duchy of Carinthia from the newly elected Henry IV, who ruled as "Henry II of Germany", in return. As a result, Otto of Worms renounced his holdings in Worms to Bishop Burchard of Worms, a long-time political rival. Buchard assumed care for Conrad, providing his education and upbringing by 1000.
After the early death of his uncle Duke Conrad I of Carinthia, the elder Conrad's infant son, Conrad the Younger, was named Count of Worms by Emperor Henry II while the Duchy of Carinthia passed to Adalbero of Eppenstein due to Conrad the Younger's infancy. Conrad the Younger was placed in Conrad's care.
Adulthood.
Conrad married Gisela of Swabia, a twice widowed duchess, in 1016. Gisela was the daughter of Duke Herman II of Swabia who, in 1002, unsuccessfully claimed the German throne following Emperor Otto III's death, losing the election to Emperor Henry II. Gisela was first married to Count Bruno I of Brunswick the same year. Following Bruno's death around 1010, Gisela married Ernest I of the House of Babenberg. By the marriage, Ernest I inherited the Duchy of Swabia at the death of Gisela's brother Duke Herman III of Swabia in 1012. This marriage produced two sons: Ernest II and Herman. After the death of Ernest I in 1015, Emperor Henry II named Ernest II as Duke of Swabia. As Gisela's new husband, Conrad hoped to serve as regent for his minor stepson in the administration of the duchy, seeing it as an opportunity to increase his own rank and subsequently make a claim for his own duchy. Emperor Henry II blocked this attempt by placing the guardianship of Ernest II, and regency over Swabia, in the hands of Archbishop Poppo of Trier in 1016. This action further strained the already rough relationship between the imperial House of Otto and the Salian family.
Conrad II's hopes of obtaining his own duchy failed, but his marriage to Gisela brought him wealth. Her mother, Gerberga of Burgundy, was the daughter of reigning Burgundian King Conrad of Burgundy and granddaughter of the late Frankish King Louis IV. Gisela also claimed descent from Charlemagne through both her mother and her father. The marriage was problematic because of the familial relationship shared by Gisela and Conrad: both were descendants of Ottonian King Henry I, Henry in the fifth generation and Gisela in the fourth. According to canon law, marriage was not allowed among relatives of the first to seventh generations. Though Conrad's marriage differed little from the usual practice of the time, strict canonists took exception to the marriage and Emperor Henry II used this breach of canonical law to force Conrad into temporary exile. During this exile, Gisela bore Conrad a son, Henry III, on October 28, 1017. Conrad and Emperor Henry II were eventually reconciled, allowing him to return to Germany.
Reign as King.
Royal election.
Emperor Henry II died in 1024. Childless, Henry's death brought the Ottonian dynasty, which had ruled Germany since 919, to an end. Without a clear successor as King of Germany, Henry's widow Cunigunde of Luxembourg served as regent while the German dukes gathered to elect a new king. Cunigunde was assisted by her brothers Bishop Dietrich I of Metz and Duke Henry V of Bavaria. Archbiship Aribo of Mainz, the Primate of Germany, also assisted Cunigunde.
On September 4, 1024, the German princes gathered at Kamba, an historical name for an area on the east banks of the Rhine River opposite the German town Oppenheim. (Today the position of Kamba is marked by a small monument, which displays Conrad on a horse.) Archbishop Aribo served as the assembly's president. Conrad presented himself before the assembly as a candidate for election, as did his younger cousin Conrad the Younger. Both were descendants from Emperor Otto I by their common grandfather Otto of Worms, son of Liutgarde, one of Otto's daughters. Although other extended members of the Ottonian dynasty existed, none were seriously considered for election. The chronicler Wipo of Burgundy, Conrad's chaplain, attended the meeting and recorded the election. The Duchy of Saxony adopted a neutral strategy while the Duchy of Lorraine favored the younger Conrad. A majority of the assembled princes favored the elder Conrad, whose seven-year-old son ensured a stable dynasty for the kingdom. As president of the assembly, Archbishop Aribo cast the first vote and supported the elder Conrad. He was joined by the other clergy in supporting the elder Conrad. The secular dukes then cast their votes for the elder Conrad as well. Only Archbishop Pilgrim of Cologne, Duke Gothelo I of Lower Lorraine, and Duke Frederick II of Upper Lorraine refused to support him.
Conrad was crowned King of Germany by Archbishop Aribo in Mainz Cathedral on September 8, 1024 at the age of 34. To mark his election, Conrad commissioned the construction of the Speyer Cathedral in Speyer, near his ancestral home of Worms. Construction began in 1030. Archbishop Aribo, as archbishop of Mainz, was already the chancellor of Germany. Conrad wanted to reward the archbishop for his electoral support, so he made Aribo chancellor of Italy as well, making Aribo the second most powerful man in the Holy Roman Empire as the imperial chancellor.
Aribo refused to crown Conrad's wife Gisela as queen due to a violation of canon law. Conrad refused to accept Archbishop Aribo's position. Archbishop Pilgrim of Cologne saw the situation as an opportunity to restore his relationship with the king, after refusing to support Conrad's election, and he crowned Gisela queen on September 21, 1024. The political reorientation of Pilgrim also weakened the opposition towards the new king.
Early reign.
Conrad inherited a kingdom troubled by numerous problems. The duchies of Saxony and Lorraine were in opposition to his rule, as well as his cousin Conrad of Carinthia. To secure his reign, Conrad went on a tour of Germany, making stops in Augsburg to receive the support of Bishop Bruno, and at Strasbourg to receive the support of Bishop Werner, the brothers of the late Emperor Henry II. Both were appointed to high-ranking offices at Conrad's court. Traveling from Cologne to Aachen, the site of Charlemagne's old capital, Conrad continued the tradition of claiming the right to rule Germany as successor to Charlemagne. Despite the continuance of this Ottonian tradition, the Duchy of Lorraine still did not accept his rule. Conrad then traveled north to Saxony, visiting Abbess Adelaide I of Quedlinburg and Abbess Sophia I of Gandersheim, both daughters of the late Ottonian Emperor Otto II. Their support of Conrad's rule greatly influenced the Saxony nobility. Celebrating Christmas at Minden, the Saxon nobles, led by Duke Bernard II, recognized Conrad as their king after he promised he would respect Saxon law. Conrad and Gisela would remain in Saxony during the winter until March 1025. Upon leaving Saxony, Conrad traveled to the Duchy of Swabia, celebrating Easter at Augsburg. He then traveled to the Duchy of Bavaria to celebrate Pentecost at Regensburg. Conrad next traveled to Zurich near the German-Burgundian border. In 1016, Emepror Henry II forced the childless Burgundian King Rudolph III to name him as his heir. With Henry's death in 1024, Conrad claimed the same rights over Burgundy. This ended his tour of Germany, visiting all major regions of the kingdom within ten months of his election.
Conrad had to address the longstanding "Gandersheim Conflict" upon assuming the German throne. The forty-year conflict stretched back to 989, during the reign of Emperor Otto III, over control of Gandersheim Abbey and its estates. Both the Archbishop of Mainz and the Bishop of Hildesheim claimed authority over the Abbey, including the authority to anoint the Abbey's nuns. Though Otto III eased the tensions between the parties by declaring that both bishops would anoint the Abbess, the conflict continued. Archbishop Aribo of Mainz, the new Primate of Germany, sought to overturn this precedent. Conrad was indebted to Aribo for his support during the royal election and worked to support his ally. In January 1027, the king called a synod at Frankfurt to resolve the dispute, but a conclusion was not reached. Conrad called a second synod in September 1028, which likewise failed to find a solution. Only a third synod in 1030 ended the conflict when Bishop Gotthard of Hildesheim renounced his claims to the monastery in favor of Aribo.
During his travel to Augsburg, a conflict broke out between Conrad and his younger cousin Conrad the Younger. The reasons for the rebellion are not recorded, but the younger Conrad claimed he did not receive some compensation the king promised him for withdrawing from the 1024 election.
Unrest in Italy.
In Bavaria, Conrad was brought into contact with the Italian ruling elite for the first time. In June 1025, Archbishop Aribert of Milan, and other bishops from Northern Italy, traveled north over the Alps to pay homage to Conrad. In exchange for certain privileges in the governing of Italy, Aribert agreed to crown Conrad with the Iron Crown of Lombardy. The situation in Italy was unstable after the death of the Henry II. The secular nobles believed the Italian throne to be vacant, not accepting Conrad's automatic succession as a matter of right. Instead, the secular nobles offered the Italian crown to the Capetian King Robert II of France and his son Hugh Magnus. After he rejected the offer, the secular lords approached Duke William V of Aquitaine. Though initially excited by the offer, William V subsequently rejected it as well.
In addition to the ecclesiastical mission, secular Italian nobles from Pavia also traveled north to Conrad. While Conrad's election did not meet significant obstacles north of the Alps, in Italy, in the aftermath of the death of Emperor Henry II, there were several riots, and some Italian nobles attempted to separate the Kingdom of Italy from the Holy Roman Empire. When the news spread of Henry's death, the citizens of Pavia revolted, destroying the imperial palace, which dated to the Ostrogothic King Theodoric the Great during the 5th century. Though Pavia had lost is position as the seat of royal administration in Italy under the Ottonian dynasty, the palace had been a great symbol of imperial authority in Italy. Pavia, thanks to its strategic location situated on the trade routes from Italy to Burgundy and France, had become an important commercial center. Traders of the lower nobility demanded greater autonomy from imperial control. The nobility saw the mere presence of the imperial palace within the city walls intolerable.
Ambassadors from Pavia traveled north to meet with the German king. According to Conrad's personal cleric Wipo, the Italian kingship was not "durable" with the German throne but instead a mere "personal union". Italy was a separate nation from Germany with its own identity, not a permanent political union. They tried to justify the actions of their fellow citizens, claiming that Pavia had always been loyal to the Italian king, as long as the king was alive, and that the revolt had taken place when the Italian throne was vacant. Therefore, the burning of the palace should be excused. Conrad rejected their argument, however, saying that just as a ship remains after the death of its captain, the Empire remains after the death of the Emperor. The kingship of Italy, according to Conrad, belonged to him as king of Germany as a matter of legal right. Conrad also declared that the palace was property of the Empire, not of the old king, and therefore the new king had the right to punish those responsible. The secular nobles returned to Italy in opposition to Salian rule.
In February 1026, Conrad assembled an army of thousands of armored knights for an expedition into Italy, including troops commanded by both Archbishop Aribo of Mainz and Archbishop Pilgrim of Cologne. Conrad's army marched south, besieging Pavia, but the city walls blocked the attackers. Conrad decided to leave a contingent of soldiers to keep the city under siege, blocking all trade in the area, and continued his campaign. By March 1026, Conrad arrived in Milan and was crowned with the Iron Crown of the Lombards by Archbishop Aribert of Milan as King of the Lombards. From Milan, Conrad traveled to Vercelli, where he celebrated Easter with the aged Bishop Leo of Vercelli, who had been a chief advisor to the late Emperor Otto III. When Leo died a few days later, Archbishop Aribert became the chief supporter of the Salian dynasty in Italy. With Conrad's assistance, Aribert became highest ranking religious figure in Italy and oversaw the expansion of the Basilica of Sant'Ambrogio in Milan. In June 1026, Conrad marched with his army to Ravenna, but quartering his soldiers alongside the Ravennese population caused tension in the city. Conrad marched north to mitigate the risk the summer heat posed to his army. In autumn Conrad left his summer camp in the Po valley and marched to the Burgundian border. Conrad then celebrated Christmas at Ivrea. By the end of winter, the secular nobles of Italy voluntarily ended their opposition to Conrad's reign. Pavia, however, remained in revolt until early 1027 when Abbot Odilo of Cluny brokered a peace deal between the city and Conrad.
Reign as Emperor.
Imperial coronation.
On March 26, 1027, Pope John XIX crowned Conrad and his wife Gisela as Emperor and Empress, respectively, in Old Saint Peter's Basilica in Rome. The coronation was attended by Cnut the Great, King of England, Denmark and Norway, Rudolph III of Burgundy and 70 high-ranking clerics, including the Archbishops of Cologne, Mainz, Trier, Magdeburg, Salzburg, Milan, and Ravenna. Conrad's son and heir Henry also attended. Rudolph's attendance marked an improvement in the relationship between Burgundy and the Holy Roman Empire. During the seven-day coronation ceremony, a rank dispute between the archbishops of Milan and Ravenna arose, with Conrad deciding in favor of Milan. Following the synod, Conrad traveled south to receive homage from the southern Italian states of Principality of Capua, the Principality of Salerno, and the Duchy of Benevento.
After his coronation, Conrad issued decrees to reorganize the monasteries and dioceses of Italy with the particular goal of bringing the church at Venice under Imperial control (see the "Schism of the Three Chapters"). On April 6, 1027, at a synod held in the Lateran Basilica with Pope John XIX, the Emperor resolved the dispute in favor of Old-Aquileia. The Patriarch of Aquleai Poppo had been a loyal supporter of Emperor Henry II, who appointed him as Patriarch in 1020 during the Emperor's campaign to reassert his authority in Italy. Conrad's action placed the church at Grado under Poppo's authority, securing Poppo's loyalty by making him the Emperor's to official in northern Italy. The synod ended the independence of the Grado church and limited the political autonomy of Venice. In so doing, Conrad broke with the policies of his predecessors and revoked Venice's privileged trading status.
Toward the end of May 1027, Conrad returned north to Germany to attend the funeral of Duke Henry V of Bavaria at Regensburg. With the Duchy of Bavaria left vacant, Conrad asserted his right to name a next duke as a matter of royal prerogative, taking the unprecedented decision of naming his 10-year-old son Henry as Duke of Bavaria despite the existence of candidates with a better claim to the Duchy. Never before had the Bavarian Duchy passed to a non-member of the Bavarian ducal family.
The young prince assumed the Bavarian dignity on 24 June 1027. Following Henry's appointment, Conrad held court at Regensburg and issued a decree requiring an accounting of all imperial property in the duchy. This required the various counts and bishops to report to Conrad all property they possessed in their castles and abbeys that belonged to the Emperor. Even the Dowager Empress Cunigunde of Luxembourg was required to report to Conrad, with the Emperor even claiming Cunegonde's "wittum" (money and property left to her by her late husband Emperor Henry II) as belonging to him. Conrad's promotion of imperial authority over the ducal succession and his claims to property throughout Bavaria caused tension between him and the German aristocracy, who viewed Conrad's actions as infringing upon their privileges.
Uprising in Swabia.
In 1025, Duke Ernest II of Swabia, Conrad's stepson from his marriage to Gisela of Swabia, rebelled against his stepfather when he was elected king of Germany. By 1026, Conrad had defeated the resistance and Ernest submitted to his reign. Due to the intervention of his mother Gisela, Ernest was allowed to accompany Conrad on his expedition to Italy in 1026. During the expedition, the rebellion led by Conrad of Carinthia and Count Welf II of Swabia continued. Conrad had named Bishop Bruno of Augsburg regent of Germany while he marched south to Italy. When Bruno was defeated by the rebels, Conrad sent Ernest back to Germany in September 1026 to end the revolt. When Ernest returned, he joined the opposition and rebelled against Conrad again. 
Conrad returned to Germany in 1027, after being crowned Emperor, and held court at Augsburg in Swabia, calling upon the rebels to surrender. Ernest, trusting in the number and fidelity of his vassals, rejected the peace officer, and appealed to his Swabian counts to join him in rebellion. According to Wipo of Burgundy, the counts refused, stating that while they had sworn loyalty to Ernest, but they would not rebel against their Emperor. Without the support of the Swabian counts, Ernest, Conrad of Carinthia and Count Welf submitted to Conrad at Worms on September 9, 1027, ending the rebellion. Conrad stripped Ernest of his ducal title and imprisoned him at Giebichenstein Castle in Saxony. Gisela supported Conrad against her son, but did not want Ernest to be entirely humiliated. As a result of his mother's intervention, Conrad allowed Ernest to retain his title while imprisoned, with Gisela serving as regent over the duchy.
In 1028, after Conrad's son Henry was crowned as King of Germany, Gisela again intervened on Ernest's behalf. Conrad pardoned Ernest and released him from prison in 1028, but Gisela retained regency over Swabia. Ernest served as duke in name only. On Easter 1030, Conrad offered to restore Ernest his full powers as Duke of Swabia if he would crack down on the Emperor's enemies there. Ernest's refusal, especially against his friend Count Werner of Kyburg, resulted in his final downfall. Conrad stripped his stepson of his title, declared him a public enemy, and had him excommunicated. Even his mother Gisela did not come to his rescue. Within a few months, both Ernest and Werner were killed in battle against the Bishop of Constance near in the Black Forest. The fall of Ernest greatly weakened the independence of Swabia. Conrad named Ernest's younger brother Herman as the new Duke. Herman was a minor, so Conrad named the Bishop of Constance regent. Eight years later in 1038, Herman was dead and Conrad named his own son Henry as duke, securing imperial control over the duchy.
Conflict with Adalbero.
Conrad had to enforce his royal prerogatives in the Duchy of Carinthia and the Duchy of Swabia. Duke Adalbero of Carinthia had been appointed as duke in 1012 under Emperor Henry II and remained loyal to imperial authority, supporting Conrad's election as German king in 1024. At a synod in Frankfurt in September 1027, Conrad attempted to resolve the decades' long "Gandersheim Conflict". Adalbero accompanied the Emperor and acted as his sword-bearer during the proceeding, indicating Conrad's trust in him. From 1028 on, Adalbero governed his Duchy as an independent state.
In particular, he attempted to conduct peaceful relations with the King Stephen I of the Kingdom of Hungary. Under Emperor Henry II, who was the brother-in-law to Stephen, relations between the Empire and Hungary had been friendly. Upon Henry's death in 1024, Conrad adopted a more aggressive policy, prompting border raids into the Empire from Hungary. The raids particularly affected Adalbero's domain of Carinthia, which shared a long, eastern border with Hungary.
Conrad summoned Adalbero to court at Bamberg on 18 May 1035, to answer an indictment of treason for his actions regarding Hungary. In the presence of the German dukes, Conrad demanded that Adalbero be stripped of all his titles and lands. The dukes hesitated and demanded that Conrad's son Henry, the Germany's co-King and Conrad's designated successor, join the assembly before a decision was made. Henry refused to depose Adalbero, citing an earlier agreement with Adelbero to be his ally in negotiating a settlement between him and his father. Conrad resorted to exhortations, pleas, and threats to convince Henry to support Adalbero's deposition. Henry's support was soon followed by that of the other dukes. Conrad then ordered Adalbero to be removed as Duke and sentenced him and his son to exile. After attacking Conrad's allies in Carinthia, Adalbero fled to his mother's estates in Ebersberg in the Duchy of Bavaria, where he remained until his death in 1039.The duchy of Carinthia remained unoccupied until February 2, 1035, when Conrad named his cousin Conrad the Younger as the new duke. With the appointment, the three southern German duchies of Swabia, Bavaria, and Carinthia were all under the control of Emperor Conrad through his family members (his stepson Herman in Swabia, his son Henry in Bavaria, and his cousin Conrad in Carinthia).
Control of the southern duchies allowed Conrad to continue the process begun under the Ottonian dynasty, centralizing the Emperors authority over the Empire at the expense of the regional dukes. Conrad broke with Ottonian tradition, however, in favoring a more strict means of controlling rebellious vassals. Whereas the Ottonians followed a policy of informal public submission and subsequent reconciliation, Conrad used treason trials to declare rebels as "public enemies" to legitimize his subsequent harsh treatment, as he had done with Ernest II of Swabia and Adalbero. The nobles saw use of these treason trials not as mere power shifts in favor of the Emperor, but as a cruel breach of German tradition.
Policy towards the Church.
Conrad continued the Ottonian dynasty's policy of using the German Church as a vehicle for imperial control. Beginning in the 950s, the Ottonians had favored Church officials over secular nobles for appointment to the Empire's most important offices. Claiming "divine right" to rule the Empire, the Ottonians increasingly viewed themselves as protectors of the Church and thus demanded loyalty from the Church officials. In return, the various bishoprics and abbeys of the Empire were granted extensive landholdings and secular authority, providing immunity from the jurisdiction of the secular nobles. As such, the Church officials reported exclusively to the Emperor, acting as his personal vassals. As the Emperor's vassals, the Church officials were subject to providing two services to him: the "servitium regis" (royal service) and "servitium militum" (military service). Under royal service, the bishops and abbots were required to provide hospitality and accommodations to the Emperor and his court when he arrived. It also required the Church officials to act as quasi-bureaucracy for the Empire. Under military service, the Church was required to supply soldiers for the Emperors' army or to act as diplomats at his direction. Conrad energetically continued this tradition.
In his biography of Conrad, the chronicler Wipo of Burgundy stated the promotion of the Church was of little value to the Emperor. Conrad and the other members of the Salian dynasty had little interest in the founding of new monasteries. Through their hundred-year dynasty, the Salians only founded one: Limburg Abbey which was converted from a fortress to a monastery in 1025. The Ottonians established at least eight in their hundred-year reign. Additionally, the Ottonians were active in the establishment of Church affairs, but Conrad was uninterested, only calling five synods during his reign and usually only to restore peace. Conrad's decisions on Church policy were often left to his wife Gisela of Swabia. When Archbishop Aribo of Mainz, Primate of Germany, died in 1031, Conrad considered both Abbot Bardo of Hersfeld Abbey and the renowned theologian Wazo of Liège, then serving as the dean of the cathedral chapter for the Bishop of Liege. Though Conrad favored Wazo to lead the German Church as Archbishop and Primate, Gisela convinced him to appoint Bardo instead.
Relations with Poland.
War with Mieszko.
Duke Bolesław I of Poland warred with Emperor Henry II three times during the German-Polish Wars from 1002 to 1018. In January 1018, Henry II and Bolesław I signed a peace treaty, known as the Peace of Bautzen, in which the Empire and Poland declared a permanent peace with Bolesław recognizing Henry II as his nominal feudal lord. In return, Henry II granted to Bolesław lands on the Empire's eastern border. To seal the peace, Bolesław I, a widower, reinforced his dynastic bonds with the German nobility by marrying Oda of Meissen, daughter of the Saxon Margrave Eckard I of Meissen. Empire and Poland remained at peace for the remainder of Henry's reign. Henry's death in 1024 gave Bolesław an opportunity to increase his own power. Bolesław took advantage of the interregnum in Germany and crowned himself king on Easter, April 25, 1025. Bolesław was thus the first Polish king as his predecessors had been considered mere "dukes" by both the Empire and the Pope in Rome. Bolesław died within two months of the coronation, most likely due to an illness. Bolesław's son, Mieszko II Lambert, succeeded him as King, being crowned on Christmas Day 1025. Upon assuming the Polish throne, Mieszko expelled his older half-brother Bezprym and his younger brother Otto Bolesławowic. Otto went to Germany to seek Conrad's protection.
Conrad considered the assumption of the title "king" by Mieszko an act of war and a disregard of his imperial authority, but had to address domestic issues before marching against Mieszko. In 1026 Conrad II marched into Italy to assert German authority south of the Alps and to claim the imperial crown from the Pope. In his absence, Duke Ernest II of Swabia, Conrad the Younger, and Duke Frederick II of Upper Lorraine rebelled against his authority.
The rebels sought the support of Mieszko, which the Polish king granted and promised to take military action against Conrad. Conrad returned to Germany in mid-1027, putting an end to the rebellion before Mieszko could marshal his forces. In preparations for his own invasion of Poland, Conrad developed a closer relationship with Cnut, King of England and Denmark (whose kingdom lay along the Empire's northern border). Cnut accompanied Conrad to his coronation as emperor in 1027, and Conrad granted authority over the March of Schleswig, the land-bridge between Denmark and Germany.
Fearing a joint German-Danish attack, Mieszko invaded the Empire's March of Lusatia and the territory of the Lutician Federation in 1028. The Lutici were a federation of West Slavic Polabian tribes that developed in the 10th century. Located on the northeast border of Germany, the Lutici were the regular target of German aggression during the early years of the Ottonian dynasty with Emperor Otto I's lieutenants Herman Billung and Gero, subjugating many of the Slavic tribes beginning in the 940s. In 983, as part of the Great Slav Rising, the Lutici initiated an open rebellion. In the ensuing war (983-995), the Lutici succeeded in reclaiming their independence and gained control of the Billung March and Northern March from the Empire. Though Emperor Otto III allied with Duke Bolesław I of Poland to reintegrate them into the Empire, Otto III's death ended the friendly relationship between Poland the Empire. Instead, Bolesław competed with Otto III's successor, Emperor Henry II, for dominion over the Lutici, causing Henry II to ally the Empire with the Lutici against Poland. Under the Peace of Bautzen in 1018, all three parties remained in uneasy peace, with Poland allowed to hold the Empire's Margraviate of Meissen. Of the eastern marches, the Empire only retained the March of Lusatia. Mieszko's 1028 invasion ended the peace. The Lutici sent ambassadors to seek Conrad's protection against Mieszko, which Conrad granted and renewed the German-Lutician alliance.
Seeking to protect the Lutici from Polish invasion, Conrad launched a counter-invasion in 1029 and placed the Polish-held Bautzen under siege. Faced with a potential invasion by Hungary and the failure of the Lutici to provide their promised contingent of troops, Conrad retreated. In 1030, Poland secured an alliance with Hungary, with Stephen I invading Bavaria while Mieszko invaded Saxony. Conrad responded by allying with Yaroslav the Wise, Grand Prince of Kiev, to attack and capture Red Ruthenia on Poland's eastern border. In 1031, Conrad concluded a peace treaty with Hungary by ceding territory in eastern Carinithia to Hungarian control. Freed from the threat of Hungarian attack, the Emperor was able to focus his attention on attacking Poland. Marching on Mieszko in autumn 1031, Conrad laid siege at the Polish held-Bautzen in the Margraviate of Meissen. Mieszko's authority was shaken by the German and Kieven invasions, and the rebellion led by his exiled brother Bezprym. Mieszko surrendered to Conrad in fall 1031. Under the Treaty of Merseburg, Mieszko returned control over the Margraviate of Meissen and the March of Lusatia to the Empire.
Treaty of Merseburg.
Soon after Mieszko concluded peace with the Empire, he was deposed by his half-brother Bezprym. When Mieszko assumed the Polish throne in 1025 he exiled his brother, who fled to the protection of Kievan Rus to the east of Poland. With Meiszko's position weakened by his wars with the Empire, Bezprym, supported by Conrad, persuaded the Kevian Grand Price Yaroslav I the Wise to invade Poland and install Bezprym as the country's ruler. The Kievan invasion was a success. Mieszko fled to the Duchy of Bohemia where he was imprisoned and castrated by Duke Oldrich in retribution for Mieszko's father Bolesław's blinding Duke Boleslaus III, Oldrich's brother, thirty years earlier. Shortly after taking power, Bezprym sent the Polish royal crown and regalia to Conrad, officially renouncing the title "king" in favor of the traditional title "duke" and accepting the overlordship of the Empire over Poland. The Royal crown and regalia were delivered by Mieszko II's wife, Queen Richeza.
Bezprym's reign was short. Bezprym's extreme cruelty caused his half-brother Otto Bolesławowic to lead a conspiracy. Bezprym's own men murdered him in spring 1032, created a power vacuum in Poland. Conrad responded by holding an assembly at Merseburg in 1033 to address the situation. Conrad's wife, the Empress Gisela of Swabia, interceded on Mieszko's behalf and requested he be freed from imprisonment in Bohemia and allowed to regain the Polish throne. Under the terms of the Treaty of Merseburg, Conrad divided Poland between Mieszko, Otto, and another half brother Detric. Mieszko was allowed to retain the title Duke and nominal authority over all of Poland. With a strong central leader to guide it, the treaty significantly increased the Empire's influence over Poland.
The division was short-lived: in 1033 Otto was killed by one of his own men, and Mieszko II took his domains. Shortly after, Mieszko expelled Detric, reuniting the whole country in his hands. Though Mieszko regained his former power, he still had to fight against the nobility and his own subjects. Mieszko did not accept Bezprym's renunciation of the Polish crown and continued to style himself as "King" instead of "Duke". Mieszko II died soon after in 1034, and upon his death, a Pagan reaction in Poland erupted. Subsequently, his wife Richeza and son Casimir I fled to Germany.
Relations with Eastern Europe.
Bohemia.
The Duchy of Bohemia was incorporated into the Holy Roman Empire in 1004 during the German-Polish Wars, which stretched from 1002 to 1018. Emperor Henry II installed Jaromir as Duke of Bohemia and promised protection against Polish aggression in return for incorporation. Jaromir ruled only a smaller territory, however, as Poland occupied the traditional Czech territories of Moravia, Silesia, Lesser Poland and Lusatia. In 1012, Jaromir was deposed by his brother Oldrich, who assumed the Bohemian throne for himself. Following the resumption of hostilities between the Empire and Poland in 1028, Oldrich went on the offensive against Poland, reconquering Moravia by 1029, which helped to stabilize his duchy. The war ended in 1031 when Polish King Mieszko II surrendered to Conrad. In the civil war which followed, Meiszko was forced to flee Poland for Bohemia, where Oldrich had him imprisoned and castrated in revenge for the torture Meiszko's father, Bolesław I of Poland, inflicted upon Duke Boleslaus III, Oldrich's brother, thirty years before.
Poland was unable to stabilize in the wake of Mieszko's exile, forcing Conrad to convene an assembly in July 1033 to issue the Treaty of Merseburg which restored Meiszko to the Polish throne. Conrad summoned Oldrich to appear to the assembly, but Oldrich refused. His absence raised the ire of the Emperor and Conrad, busy with securing his succession to the Burgundy throne, charged his son Duke Henry of Bavaria with punishing the recalcitrant Bohemian. At age 17, Henry's march on Bohemia was his first independent military command. The expedition was complete success, with Henry deposing Oldrich and restoring his brother Jaromir to the Bohemian throne, with Oldrich's son Bretislaus I appointed as Count of Moravia. Oldrich was imprisoned in Bavaria but by 1034 was pardoned and allowed to return to Bohemia.
Oldrich deposed and blinded Jaromir, reclaimed the Bohemian throne, and exiled his son. While the reason for the conflict between father and son has been lost, it is believed Bretislaus supported Jaromir over his father. Oldrich died suddenly on November 9, 1034, allowing Bretislaus to return from exile. Though Jaromir was offered the throne, he declined in favor of his nephew. Bretislaus was then installed as the new Duke of Bohemia by Conrad.
Hungary.
With Otto III's approval, Stephen was crowned as the first Christian king of Hungary on Christmas Day, 1000. Otto III's successor, Emperor Henry II, was Stephen's brother-in-law by Stephen's marriage to Henry's sister Gisela, furthering the friendly relationship between the Empire and Germany. Under Conrad, however, relations quickly turned hostile as Conrad pursued a more aggressive policy regarding eastern Europe. Conrad II expelled Venetian Doge Otto Orseolo, the husband of Stephen's sister Grimelda of Hungary, from Venice in 1026. Conrad also persuaded the Bavarians to proclaim his own son, Henry, as their duke in 1027, although Stephen's son, Emeric of Hungary, had a strong claim to the Duchy of Bavaria through his mother.
Emperor Conrad planned a marriage alliance with the Byzantine Empire and dispatched one of his advisors, Bishop Werner of Strasbourg, to Constantinople. The bishop seemingly traveled as a pilgrim, but Stephen, who had been informed of his actual purpose, refused to let him enter into his country in the autumn of 1027. Conrad's biographer, Wipo of Burgundy recorded that the Bavarians incited skirmishes along the common Imperial-Hungarian border in 1029, causing a rapid deterioration in relations between the two countries. In 1030, open conflict erupted. Conrad launched an invasion of Hungary, but had to retreat when the Hungarians successfully used scorched earth tactics. Conrad left matters in Hungary to his son Henry, so he could address his problems with his stepson Ernest II, the deposed Duke of Swabia. Henry settled the conflict by 1031 by granting lands between the Leitha River and Fischa River in eastern Bavaria to Hungary. Hungary and the Empire remained at peace from 1031 through to Henry's own reign as Emperor in 1040.
Annexation of Burgundy.
King Rudolph III of Burgundy, ruler of the Kingdom of Arles, had no sons, so Emperor Henry II was able to force the Burgundian ruler to name Henry as Rudolph's successor in 1016. Henry II was Rudolph's nephew, and his closest living male relative, as Henry II was the son of Rudolph's sister Gisela of Burgundy. When Emperor Henry II died in 1024, Rudolph was still alive, sparking a new controversy in the Burgundian succession. Conrad II, as Henry II's successor, claimed he inherited Henry II's rights, but Rudolph disputed his claim. Count Odo II of Blois, who had familial ties to Rudolph, also claimed a right in the succession. Conrad II met Rudolph in August 1027 near Basel to settle the contested succession. Henry II's widowed wife, the Empress Gisela of Burgundy, mediated between the two parties. A settlement was reached that allowed Conrad II to succeed to the Burgundian throne upon Rudolph's death under the same conditions as Henry II. In return, Rudolph was allowed to retain independent rule over his kingdom.
Rudolph died on September 6, 1032, while Conrad was campaigning against Duke Mieszko II of Poland. Having forced Mieszko II to surrender, Conrad marched with his army to Burgundy in the winter of 1032/1033. Count Odo II of Blois, Conrad's former rival for the Burgundian throne, had already invaded the kingdom to secure his rule, controlling large portions of the kingdom's western territories. On February 2, 1033, Conrad arrived at Vaud, where he held an assembly at the abbey of Payerne and was crowned King of Burgundy. Initially, Conrad made little headway against Odo and had to withdraw to Zurich in March. After two large-scale military campaigns in summer 1033 and summer 1034, Conrad defeated Odo. On August 1, 1034, Conrad officially incorporated Burgundy into the Holy Roman Empire at a ceremony held in the Cathedral of Geneva.
Though Burgundy was definitively under imperial control, the kingdom was allowed significant autonomy. Conrad rarely intervened in its affairs following his coronation, returning only in 1038 to name his son Henry as the kingdom's new ruler. The chief importance of the annexation of Burgundy was to augment the influence and dignity of the Emperor himself. Control of Burgundy did benefit the Empire. With Burgundy secured, the Empire controlled the western Alpine passes in Italy, allowing the Empire to secure its hold over Italy by blocking foreign invasions.
Politics.
Conrad formally confirmed the popular legal traditions of Saxony and issued new constitutions for Lombardy. In 1028 at Aachen, he had his son Henry elected and anointed king of Germany. Henry married Gunhilda of Denmark, daughter of King Canute the Great of England, Denmark, and Norway by Emma of Normandy. This was an arrangement that Conrad had made many years prior, when he gave Canute parts of northern Germany to administer. Henry, who would later become Emperor Henry III, became his father's chief counselor.
Conrad campaigned unsuccessfully against Poland in 1028–1030. In 1031, Conrad and the Kievan Rus' forced King Mieszko II, son and heir of Bolesław I, to make peace and return the land that Bolesław had taken from the Empire during the reign of Henry II. Mieszko II was compelled to give up his royal title, and for the remainder of his troubled rule became the Duke of Poland and Conrad's vassal.
In 1029 some Bavarian border conflicts undermined the good relations with Stephen I of Hungary. One year later Conrad launched a campaign against Hungary. The Hungarians successfully used scorched earth tactics, and Conrad had to withdraw his army. Finally, the Hungarian army forced him to surrender at Vienna. After his defeat, Conrad was obliged to cede some border territory to Hungary.
When Rudolph III, King of Burgundy died on February 2, 1032, Conrad claimed the Kingship on the basis of an inheritance that Henry II had extorted from Rudolph in 1006, after Henry invaded Burgundy to enforce his claim in 1016. Despite some opposition, the Burgundian and Provençal nobles paid homage to Conrad in Zürich in 1034. This Kingdom of Burgundy, later known as the Kingdom of Arles under Conrad's successors, corresponded to most of the southeastern quarter of modern France and included western Switzerland, the Franche-Comté, and Dauphiné. It did not include the smaller Duchy of Burgundy to the north, ruled by a cadet branch of the Capetian King of France. (Most of the former Kingdom of Arles was incorporated into France piecemeal over the next centuries, but the King of Arles remained one of the Holy Roman Emperor's subsidiary titles until the dissolution of the Empire in 1806.)
Conrad upheld the rights of the "valvassores" (knights and burghers of the cities) of Italy against Archbishop Aribert of Milan and the local nobles. The nobles, as vassal lords, and the bishop had conspired to rescind rights from the burghers. Conrad restored order with skillful diplomacy and luck.
Late life.
Second Italian expedition.
In 1038, Prince Guaimar IV of Salerno requested that Conrad adjudicate in a dispute over Capua with its Prince Pandulf, whom Conrad had released from imprisonment in 1024, immediately after his coronation. Hearing that Michael IV the Paphlagonian of the Byzantine Empire had received the same request, Conrad went to Southern Italy, to Salerno and Aversa. He appointed Richer, from Germany, as abbot of Monte Cassino, the abbot Theobald being imprisoned by Pandulf. At Troia, he ordered Pandulf to restore stolen property to Monte Cassino. Pandulf sent his wife and son to ask for peace, giving 300 lb of gold and a son and daughter as hostages. The Emperor accepted Pandulf's offer, but the hostage escaped and Pandulf holed up in his outlying castle of Sant'Agata de' Goti. Conrad besieged and took Capua and gave it to Guaimar with the title of Prince. He also recognised Aversa as a county of Salerno under Ranulf Drengot, the Norman adventurer. Pandulf, meanwhile, fled to Constantinople. Conrad thus left the "Mezzogiorno" firmly in Guaimar's hands and loyal, for once, to the Holy Roman Empire.
Death.
During the return trip to Germany an epidemic broke out among the troops. Conrad's daughter-in-law and stepson died. Conrad himself returned safely and held several important courts in Solothurn, Strasbourg, and Goslar. His son Henry was invested with the kingdom of Burgundy.
A year later in 1039 Conrad fell ill and died of gout in Utrecht. His heart and bowels are buried at the Cathedral of Saint Martin, Utrecht. His body was transferred to Speyer via Cologne, Mainz, and Worms, where the funeral procession made stops. His body is buried at Speyer Cathedral, which was still under construction at this time. During a major excavation in 1900 his sarcophagus was relocated from his original resting place in front of the altar to the crypt, where it is still visible today along with those of seven of his successors.
A biography of Conrad II in chronicle form, "Gesta Chuonradi II imperatoris", was written by his chaplain Wipo of Burgundy, and presented to Henry III in 1046, not long after the latter was crowned.
Family and children.
Conrad married Gisela of Swabia in 1016, the daughter of Duke Herman II of Swabia. They had three children:

</doc>
<doc id="44400" url="https://en.wikipedia.org/wiki?curid=44400" title="RV Triton">
RV Triton

The Research Vessel "Triton" is a trimaran vessel owned by Gardline Marine Sciences Limited and a former prototype British warship demonstrator for the UK's Defence Evaluation and Research Agency (later QinetiQ). She was built as a technology demonstrator ship for the Royal Navy's Future Surface Combatant, and has been used to both prove the viability of the hull-form and as a trials platform for other QinetiQ innovations. Since 2007 the ship has been used by the Australian Customs and Border Protection Service's Customs Marine Unit.
Construction.
In August 1998, the UK Ministry of Defence (MoD) awarded a contract to Vosper Thornycroft to construct the trimaran, at a cost of £13.5m RV "Triton" was launched in May 2000 and delivered in August 2000. "Triton" then began a two-year risk reduction trials programme for the UK MoD and the US Department of Defense.
The vessel's three parallel hulls are reflected in her name which refers to the maritime god Triton who carried the three-pronged spear, the trident. The outriggers are thinner and much shorter than the dominant central hull.
Operational history.
DERA and QinetiQ.
"Triton" was designed as a demonstrator to prove that the trimaran concept would work successfully in a large warship. Following her launch in 2000, the ship began an extensive series of trials in 2001, which covered general ship handling, performance, sea-keeping behaviour, but also areas more specific to its design for which the Royal Navy had no experience. For example, a series of docking manoeuvres were undertaken by the pilot boats of HMNB Portsmouth to determine the problems of docking a large trimaran, and the ship underwent underway replenishment alongside and the tanker RFA "Brambleleaf" to ascertain the characteristics of a trimaran and a monohull replenishing at the same time. "Triton" also undertook the first helicopter take off and landing on a trimaran.
"Triton" was present at the International Festival of the Sea in 2001, but visitors were not permitted on board.
Gardline Marine Sciences.
In January 2005, Triton was sold to Gardline Marine Sciences, a UK company based in Great Yarmouth, Norfolk. Triton was used for hydrographic survey work for the civil hydrography programme (CHP) on behalf of the Maritime and Coastguard Agency (MCA). The vessel was fitted with a sensor suite which includes the Kongsberg Simrad EM1002 multibeam echo-sounder, a GPS attitude / heading system, surface navigation and ultra-short baseline sub-surface acoustic tracking system, Gardline Voyager5 integrated survey system and Caris post-processing system. The vessel was enhanced by Gardline by installing a bowthrust unit, additional accommodation and survey equipment facilities. In 2009, two new MTU engines were fitted; MTU 16v 4000 M40B. Output 2,080kW each.
Australian Customs.
In December 2006, Gardline contracted "Triton" to the Australian Customs and Border Protection Service to patrol Australia's northern waters as one of the service's fleet of patrol vessels. Australian Customs Vessel "Triton" has been fitted with two .50 calibre heavy machine guns and carries up to 28 armed customs officers. The vessel is also equipped with two 7.3m high-speed rigid hull inflatable boats (RHIBs). The ship arrived from the UK in mid-January 2007 and started operations immediately. Austere accommodation is provided for 100 embarked persons in addition to conventional accommodation for 45.

</doc>
<doc id="44401" url="https://en.wikipedia.org/wiki?curid=44401" title="Brown dwarf">
Brown dwarf

Brown dwarfs are substellar objects not massive enough to sustain hydrogen-1 fusion reactions in their cores, unlike main-sequence stars. Brown dwarfs occupy the mass range between the heaviest gas giants and the lightest stars, with an upper limit around 75 to 80 Jupiter masses (). Brown dwarfs heavier than about are thought to fuse deuterium and those above , fuse lithium as well. Brown dwarfs may be fully convective, with no layers or chemical differentiation by depth.
The defining differences between a very low-mass brown dwarf and a gas giant () are debated. One school of thought is based on formation; the other, on the physics of the interior. Part of the debate concerns whether "brown dwarfs" must, by definition, have experienced fusion at some point in their history.
Stars are categorized by spectral class, with brown dwarfs being designated as types M, L, T, and Y. Despite their name, brown dwarfs are of different colors. Many brown dwarfs would likely appear magenta to the human eye, or possibly orange/red. Brown dwarfs are not very luminous at visible wavelengths.
Some planets are known to orbit brown dwarfs: 2M1207b, MOA-2007-BLG-192Lb, and 2MASS J044144b
At a distance of about 6.5 light years, the nearest known brown dwarf is Luhman 16, a binary system of brown dwarfs discovered in 2013. DENIS-P J082303.1-491201 b is listed as the most-massive known exoplanet (as of March 2014) in NASA's exoplanet archive, despite having a mass () more than twice the 13-Jupiter-mass cutoff between planets and brown dwarfs.
History.
The objects now called "brown dwarfs" were theorized to exist in the 1960s by Shiv S. Kumar. They were originally called black dwarfs, a classification for dark substellar objects floating freely in space that were not massive enough to sustain hydrogen fusion. However: a) the term black dwarf was already in use to refer to a cold white dwarf; b) red dwarfs fuse hydrogen, and c) these objects may be luminous at visible wavelengths early in their lives. Because of this, alternate names for these objects were proposed, including planetar and substar. In 1975, Jill Tarter suggested the term "brown dwarf", using brown as an approximate color. This has been the term used in astronomy ever since.
The term black dwarf still refers to a white dwarf that has cooled to the point that it no longer emits significant light. However, the time required for even the lowest-mass white dwarf to cool to this temperature is calculated to be longer than the current age of the universe; hence such objects are thought not to exist yet.
Early theories concerning the nature of the lowest-mass stars and the hydrogen-burning limit suggested that a population I object with a mass less than 0.07 solar masses () or a population II object less than would never go through normal stellar evolution and would become a completely degenerate star (Kumar 1963). The first self-consistent calculation of the hydrogen-burning minimum mass confirmed a value between 0.08 and 0.07 solar masses for population I objects
(Hayashi and Nakano 1963). The discovery of deuterium burning down to 0.012 solar masses and the impact of dust formation in the cool outer atmospheres of brown dwarfs in the late 1980s brought these theories into question. However, such objects were hard to find because they emit almost no visible light. Their strongest emissions are in the infrared (IR) spectrum, and ground-based IR detectors were too imprecise at that time to readily identify any brown dwarfs.
Since then, numerous searches by various methods have sought to find these objects. These methods included multi-color imaging surveys around field stars, imaging surveys for faint companions to main-sequence dwarfs and white dwarfs, surveys of young star clusters, and radial velocity monitoring for close companions.
For many years, efforts to discover brown dwarfs were fruitless. In 1988, however, University of California, Los Angeles professors Eric Becklin and Ben Zuckerman identified a faint companion to a star known as GD 165 in an infrared search of white dwarfs. The spectrum of the companion GD 165B was very red and enigmatic, showing none of the features expected of a low-mass red dwarf. It became clear that GD 165B would need to be classified as a much cooler object than the latest M dwarfs then known. GD 165B remained unique for almost a decade until the advent of the Two Micron All Sky Survey (2MASS) when Davy Kirkpatrick, of the California Institute of Technology, and others discovered many objects with similar colors and spectral features.
Today, GD 165B is recognized as the prototype of a class of objects now called "L dwarfs". Although the discovery of the coolest dwarf was highly significant at the time, it was debated whether GD 165B would be classified as a brown dwarf or simply a very-low-mass star, because observationally it is very difficult to distinguish between the two.
Soon after the discovery of GD 165B, other brown-dwarf candidates were reported. Most failed to live up to their candidacy, however, because the absence of lithium showed them to be stellar objects. True stars burn their lithium within a little over 100 Myr, whereas brown dwarfs (which can, confusingly, have temperatures and luminosities similar to true stars) will not. In other words, the detection of lithium in the atmosphere of a candidate object ensures that, as long as it is older than the relatively young age of 100 Myr, it is a brown dwarf.
In 1995, the study of brown dwarfs changed substantially with the discovery of two incontrovertible substellar objects (Teide 1 and Gliese 229B), which were identified by the presence of the 670.8 nm lithium line. The more notable of these objects was the latter, which was found to have a temperature and luminosity well below the stellar range. Remarkably, its near-infrared spectrum clearly exhibited a methane absorption band at 2 micrometres, a feature that had previously only been observed in the atmospheres of giant planets and that of Saturn's moon Titan. Methane absorption is not expected at the temperatures of main-sequence stars. This discovery helped to establish yet another spectral class even cooler than L dwarfs, known as "T dwarfs", for which Gliese 229B is the prototype.
The first confirmed brown dwarf was discovered by Spanish astrophysicists Rafael Rebolo (head of team), Maria Rosa Zapatero Osorio, and Eduardo Martín in 1994. They called this object Teide 1 and it was found in the Pleiades open cluster. The discovery article was submitted to "Nature" in spring 1995, and published on September 14, 1995. "Nature" highlighted "Brown dwarfs discovered, official" in the front page of that issue.
Teide 1 was discovered in images collected by the IAC team on January 6, 1994 using the 80 cm telescope (IAC 80) at Teide Observatory and its spectrum was first recorded in December 1994 using the 4.2 m William Herschel Telescope at Roque de los Muchachos Observatory (La Palma). The distance, chemical composition, and age of Teide 1 could be established because of its membership in the young Pleiades star cluster. Using the most advanced stellar and substellar evolution models at that moment, the team estimated for Teide 1 a mass of , which is clearly below the stellar-mass limit. The object became a reference in subsequent young brown dwarf related works.
In theory, a brown dwarf below is unable to burn lithium by thermonuclear fusion at any time during its evolution. This fact is one of the lithium test principles to examine the substellar nature in low-luminosity and low-surface-temperature astronomical bodies.
High-quality spectral data acquired by the Keck 1 telescope in November 1995 showed that Teide 1 had kept the initial lithium amount of the original molecular cloud from which Pleiades stars formed, proving the lack of thermonuclear fusion in its core. These observations confirmed that Teide 1 is a brown dwarf, as well as the efficiency of the spectroscopic lithium test.
For some time, Teide 1 was the smallest known object outside the Solar System that had been identified by direct observation. Since then, over 1,800 brown dwarfs have been identified, even some very close to Earth like Epsilon Indi Ba and Bb, a pair of brown dwarfs gravitationally bound to a Sun-like star around 12 light-years from the Sun, and Luhman 16, a binary system of brown dwarfs about 6.5 light-years away.
Theory.
The standard mechanism for star birth is through the gravitational collapse of a cold interstellar cloud of gas and dust. As the cloud contracts it heats due to the Kelvin–Helmholtz mechanism. Early in the process the contracting gas quickly radiates away much of the energy, allowing the collapse to continue. Eventually, the central region becomes sufficiently dense to trap radiation. Consequently, the central temperature and density of the collapsed cloud increases dramatically with time, slowing the contraction, until the conditions are hot and dense enough for thermonuclear reactions to occur in the core of the protostar. For most stars, gas and radiation pressure generated by the thermonuclear fusion reactions within the core of the star will support it against any further gravitational contraction. Hydrostatic equilibrium is reached and the star will spend most of its lifetime fusing hydrogen into helium as a main-sequence star.
If, however, the mass of the protostar is less than about , normal hydrogen thermonuclear fusion reactions will not ignite in the core. Gravitational contraction does not heat the small protostar very effectively, and before the temperature in the core can increase enough to trigger fusion, the density reaches the point where electrons become closely packed enough to create quantum electron degeneracy pressure. According to the brown dwarf interior models, typical conditions in the core for density, temperature and pressure are expected to be the following:
This means that the protostar is not massive enough and not dense enough to ever reach the conditions needed to sustain hydrogen fusion. The infalling matter is prevented, by electron degeneracy pressure, from reaching the densities and pressures needed.
Further gravitational contraction is prevented and the result is a "failed star", or brown dwarf that simply cools off by radiating away its internal thermal energy.
Low-mass brown dwarfs vs. high-mass planets.
A remarkable property of brown dwarfs is that they are all roughly the same radius as Jupiter. At the high end of their mass range (), the volume of a brown dwarf is governed primarily by electron-degeneracy pressure, as it is in white dwarfs; at the low end of the range (), their volume is governed primarily by Coulomb pressure, as it is in planets. The net result is that the radii of brown dwarfs vary by only 10–15% over the range of possible masses. This can make distinguishing them from planets difficult.
In addition, many brown dwarfs undergo no fusion; those at the low end of the mass range (under ) are never hot enough to fuse even deuterium, and even those at the high end of the mass range (over ) cool quickly enough that they no longer undergo fusion after a period of time on the order of 10 million years.
X-ray and infrared spectra are telltale signs. Some brown dwarfs emit X-rays; and all "warm" dwarfs continue to glow tellingly in the red and infrared spectra until they cool to planetlike temperatures (under 1000 K).
Gas giants have some of the characteristics of brown dwarfs. For example, Jupiter and Saturn are both made primarily of hydrogen and helium, like the Sun. Saturn is nearly as large as Jupiter, despite having only 30% the mass. Three of the giant planets in the Solar System (Jupiter, Saturn, and Neptune) emit much more heat than they receive from the Sun. And all four giant planets have their own "planetary systems"—their moons. Brown dwarfs form independently, like stars, but lack sufficient mass to "ignite" as stars do. Like all stars, they can occur singly or in close proximity to other stars. Some orbit stars and can, like planets, have eccentric orbits.
Currently, the International Astronomical Union considers an object with a mass above the limiting mass for thermonuclear fusion of deuterium (currently calculated to be for objects of solar metallicity) to be a brown dwarf, whereas an object under that mass (and orbiting a star or stellar remnant) is considered a planet.
The 13 Jupiter-mass cutoff is a rule of thumb rather than something of precise physical significance. Larger objects will burn most of their deuterium and smaller ones will burn only a little, and the 13 Jupiter mass value is somewhere in between. The amount of deuterium burnt also depends to some extent on the composition of the object, specifically on the amount of helium and deuterium present and on the fraction of heavier elements, which determines the atmospheric opacity and thus the radiative cooling rate.
The Extrasolar Planets Encyclopaedia includes objects up to 25 Jupiter masses, and the Exoplanet Data Explorer up to 24 Jupiter masses.
Sub-brown dwarf.
A sub-brown dwarf or planetary-mass brown dwarf is an astronomical object formed in the same manner as stars and brown dwarfs (i.e. through the collapse of a gas cloud) but that has a mass below the limiting mass for thermonuclear fusion of deuterium (about ).
Some researchers call them free-floating planets whereas others call them planetary-mass brown dwarfs.
Observations.
Classification of brown dwarfs.
Spectral class M.
There are brown dwarfs with a spectral class of M6.5 or later. They are also called late-M dwarfs.
Spectral class L.
The defining characteristic of spectral class M, the coolest type in the long-standing classical stellar sequence, is an optical spectrum dominated by absorption bands of titanium(II) oxide (TiO) and vanadium(II) oxide (VO) molecules. However, GD 165B, the cool companion to the white dwarf GD 165, had none of the hallmark TiO features of M dwarfs. The subsequent identification of many field counterparts to GD 165B ultimately led Kirkpatrick and others to the definition of a new spectral class, the L dwarfs, defined in the red optical region not by weakening metal-oxide bands (TiO, VO), but strong metal hydride bands (FeH, CrH, MgH, CaH) and prominent alkali metal lines (Na I, K I, Cs I, Rb I). , over 900 L dwarfs have been identified, most by wide-field surveys: the Two Micron All Sky Survey (2MASS), the Deep Near Infrared Survey of the Southern Sky (DENIS), and the Sloan Digital Sky Survey (SDSS).
Spectral class T.
As GD 165B is the prototype of the L dwarfs, Gliese 229B is the prototype of a second new spectral class, the T dwarfs. Whereas near-infrared (NIR) spectra of L dwarfs show strong absorption bands of H2O and carbon monoxide (CO), the NIR spectrum of Gliese 229B is dominated by absorption bands from methane (CH4), features that were only found in the giant planets of the Solar System and Titan. CH4, H2O, and molecular hydrogen (H2) collision-induced absorption (CIA) give Gliese 229B blue near-infrared colors. Its steeply sloped red optical spectrum also lacks the FeH and CrH bands that characterize L dwarfs and instead is influenced by exceptionally broad absorption features from the alkali metals Na and K. These differences led Kirkpatrick to propose the T spectral class for objects exhibiting H- and K-band CH4 absorption. , 355 T dwarfs are known. NIR classification schemes for T dwarfs have recently been developed by Adam Burgasser and Tom Geballe. Theory suggests that L dwarfs are a mixture of very-low-mass stars and sub-stellar objects (brown dwarfs), whereas the T dwarf class is composed entirely of brown dwarfs. Because of the absorption of sodium and potassium in the green part of the spectrum of T dwarfs, the actual appearance of T dwarfs to human visual perception is estimated to be not brown, but the color of magenta coal tar dye. T-class brown dwarfs, such as WISE 0316+4307, have been detected over 100 light-years from the Sun.
Spectral class Y.
There is some doubt as to what, if anything, should be included in the class Y dwarfs. They are expected to be much cooler than T-dwarfs. They have been modelled, though there is no well-defined spectral sequence yet with prototypes.
In 2009, the coolest known brown dwarfs had estimated effective temperatures between 500 and 600 K, and have been assigned the spectral class T9. Three examples are the brown dwarfs CFBDS J005910.90-011401.3, ULAS J133553.45+113005.2, and ULAS J003402.77−005206.7. The spectra of these objects display absorption around 1.55 micrometers. Delorme et al. have suggested that this feature is due to absorption from ammonia and that this should be taken as indicating the T–Y transition, making these objects of type Y0. However, the feature is difficult to distinguish from absorption by water and methane, and other authors have stated that the assignment of class Y0 is premature.
In April 2010, two newly discovered ultracool sub-brown dwarfs (UGPS 0722-05 and SDWFS 1433+35) were proposed as prototypes for spectral class Y0.
In February 2011, Luhman et al. reported the discovery of a ~300 K, 7-Jupiter-mass 'brown-dwarf' companion to a nearby white dwarf. Though of 'planetary' mass, Rodriguez et al. suggest it is unlikely to have formed in the same manner as planets.
Shortly after that, Liu et al. published an account of a "very cold" (~370 K) brown dwarf orbiting another very-low-mass brown dwarf and noted that "Given its low luminosity, atypical colors and cold temperature, CFBDS J1458+10B is a promising candidate for the hypothesized Y spectral class."
In August 2011, scientists using data from NASA's Wide-field Infrared Survey Explorer (WISE) discovered six "Y dwarfs"—star-like bodies with temperatures as cool as the human body.
WISE data has revealed hundreds of new brown dwarfs. Of these, fourteen are classified as cool Ys. One of the Y dwarfs, called WISE 1828+2650, was, as of August 2011, the record holder for the coldest brown dwarf – emitting no visible light at all, this type of object resembles free-floating planets more than stars. WISE 1828+2650 was initially estimated to have an atmospheric temperature cooler than 300 K—for comparison the upper end of room temperature is 298 K (25 °C, 80 °F). Its temperature has since been revised and newer estimates put it in the range of 250 to 400 K (−23–127 °C, −10–260 °F).
In April 2014, WISE 0855−0714 was announced with a temperature profile estimated around 225 to 260 K and a mass of . It was also unusual in that its observed parallax meant a distance close to 7.2±0.7 light years from the Solar System.
Spectral and atmospheric properties of brown dwarfs.
The majority of flux emitted by L and T dwarfs is in the 1 to 2.5 micrometre near-infrared range. Low and decreasing temperatures through the late M-, L-, and T-dwarf sequence result in a rich near-infrared spectrum containing a wide variety of features, from relatively narrow lines of neutral atomic species to broad molecular bands, all of which have different dependencies on temperature, gravity, and metallicity. Furthermore, these low temperature conditions favor condensation out of the gas state and the formation of grains.
Typical atmospheres of known brown dwarfs range in temperature from 2200 down to 750 K. Compared to stars, which warm themselves with steady internal fusion, brown dwarfs cool quickly over time; more massive dwarfs cool slower than less massive ones.
Observational techniques.
Coronagraphs have recently been used to detect faint objects orbiting bright visible stars, including Gliese 229B.
Sensitive telescopes equipped with charge-coupled devices (CCDs) have been used to search distant star clusters for faint objects, including Teide 1.
Wide-field searches have identified individual faint objects, such as Kelu-1 (30 ly away).
Brown dwarfs are often discovered in surveys to discover extrasolar planets. Methods of detecting extrasolar planets work for brown dwarfs as well, although brown dwarfs are much easier to detect.
Brown dwarf as an X-ray source.
X-ray flares detected from brown dwarfs since 1999 suggest changing magnetic fields within them, similar to those in very-low-mass stars.
With no strong central nuclear energy source, the interior of a brown dwarf is in a rapid boiling, or convective state. When combined with the rapid rotation that most brown dwarfs exhibit, convection sets up conditions for the development of a strong, tangled magnetic field near the surface. The flare observed by Chandra from LP 944-20 could have its origin in the turbulent magnetized hot material beneath the brown dwarf's surface. A sub-surface flare could conduct heat to the atmosphere, allowing electric currents to flow and produce an X-ray flare, like a stroke of lightning. The absence of X-rays from LP 944-20 during the non-flaring period is also a significant result. It sets the lowest observational limit on steady X-ray power produced by a brown dwarf, and shows that coronas cease to exist as the surface temperature of a brown dwarf cools below about 2800K and becomes electrically neutral.
Using NASA's Chandra X-ray Observatory, scientists have detected X-rays from a low-mass brown dwarf in a multiple star system. This is the first time that a brown dwarf this close to its parent star(s) (Sun-like stars TWA 5A) has been resolved in X-rays. "Our Chandra data show that the X-rays originate from the brown dwarf's coronal plasma which is some 3 million degrees Celsius", said Yohko Tsuboi of Chuo University in Tokyo. "This brown dwarf is as bright as the Sun today in X-ray light, while it is fifty times less massive than the Sun", said Tsuboi. "This observation, thus, raises the possibility that even massive planets might emit X-rays by themselves during their youth!"
Recent developments.
The brown dwarf Cha 110913-773444, located 500 light years away in the constellation Chamaeleon, may be in the process of forming a miniature planetary system. Astronomers from Pennsylvania State University have detected what they believe to be a disk of gas and dust similar to the one hypothesized to have formed the Solar System. Cha 110913-773444 is the smallest brown dwarf found to date (), and if it formed a planetary system, it would be the smallest known object to have one. Their findings were published in the December 10, 2005 issue of Astrophysical Journal Letters.
Recent observations of known brown dwarf candidates have revealed a pattern of brightening and dimming of infrared emissions that suggests relatively cool, opaque cloud patterns obscuring a hot interior that is stirred by extreme winds. The weather on such bodies is thought to be extremely violent, comparable to but far exceeding Jupiter's famous storms.
On January 8, 2013 astronomers using NASA's Hubble and Spitzer space telescopes probed the stormy atmosphere of a brown dwarf named 2MASS J22282889-431026, creating the most detailed "weather map" of a brown dwarf thus far. It shows wind-driven, planet-sized clouds. The new research is a stepping stone toward a better understanding not only brown dwarfs, but also of the atmospheres of planets beyond the Solar System.
NASA's WISE mission has detected 200 new brown dwarfs. There are actually fewer brown dwarfs in our cosmic neighborhood than previously thought. Rather than one star for every brown dwarf, there may be as many as six stars for every brown dwarf.
Planets around brown dwarfs.
The super-Jupiter planetary-mass objects 2M1207b and 2MASS J044144 that are orbiting brown dwarfs at large orbital distances may have formed by cloud collapse rather than accretion and so may be sub-brown dwarfs rather than planets, which is inferred from relatively large masses and large orbits. The first discovery of a low-mass companion orbiting a brown dwarf (ChaHα8) at a small orbital distance using the radial velocity technique paved the way for the detection of planets around brown dwarfs on orbits of a few AU or smaller. However, with a mass ratio between the companion and primary in ChaHα8 of about 0.3, this system rather resembles a binary star. Then, in 2013, the first planetary-mass companion (OGLE-2012-BLG-0358L b) in a relatively small orbit was discovered orbiting a brown dwarf.
In 2015, the first terrestrial-mass planet orbiting a brown dwarf was found, OGLE-2013-BLG-0723LBb.
Disks around brown dwarfs have been found to have many of the same features as disks around stars; therefore, it is expected that there will be accretion-formed planets around brown dwarfs. Given the small mass of brown dwarf disks, most planets will be terrestrial planets rather than gas giants. If a giant planet orbits a brown dwarf across our line of sight, then, because they have approximately the same diameter, this would give a large signal for detection by transit. The accretion zone for planets around a brown dwarf is very close to the brown dwarf itself, so tidal forces would have a strong effect.
Planets around brown dwarfs are likely to be carbon planets depleted of water.
Habitability.
Habitability for hypothetical planets orbiting brown dwarfs has been studied. Computer models suggesting conditions for these bodies to have habitable planets are very stringent, the habitable zone being narrow and decreasing with time, due to the cooling of the brown dwarf. The orbits there would have to be of "very" low eccentricity (of the order of 10−6) to avoid strong tidal forces that would trigger a greenhouse effect on the planets, rendering them uninhabitable.

</doc>
<doc id="44403" url="https://en.wikipedia.org/wiki?curid=44403" title="Shakers">
Shakers

The United Society of Believers in Christ's Second Appearing is a religious sect, also known as the Shakers, founded in the 18th century in England, having branched off from a Quaker community. They were known as "Shaking Quakers" because of their ecstatic behavior during worship services. In 1747, women assumed leadership roles within the sect, notably Jane Wardley and Mother Ann Lee. Shakers settled in colonial America, with initial settlements in New Lebanon, New York (called Mount Lebanon after 1861) today are mostly known for their celibate and communal lifestyle, pacifism, and their model of equality of the sexes, which they institutionalized in their society in the 1780s. They are also known for their simple living, architecture, and furniture.
During the mid-19th century, an Era of Manifestations resulted in a period of dances, gift drawings and gift songs inspired by spiritual revelations. At its peak in the mid-19th century, there were 6,000 Shaker believers. By 1920, there were only 12 Shaker communities remaining in the United States. In the present day, there is only one active Shaker village, Sabbathday Lake Shaker Village, which is located in Maine. Their celibacy resulted in the thinning of the Shaker community, and consequently many of the other Shaker settlements are now village museums, like Hancock Shaker Village in Massachusetts.
History.
Origins.
The Shakers were one of a few religious groups formed in 18th century in the Northwest of England; they branched off from a group of Quakers in England. James and Jane Wardley and others left at a time when the Quakers were weaning themselves away from frenetic spiritual expression. The Wardleys formed the Wardley Society, which was also known as the "Shaking Quakers". Future leader Ann Lee and her parents were early members of the sect. This group of "charismatic" Christians became the United Society of Believers in Christ's Second Appearing (USBCSA), or the Shakers. Their belief was based upon spiritualism and included the notion that they received messages from the spirit of God which were expressed during religious revivals. They also experienced what they interpreted as messages from God during silent meditations and became known as "Shaking Quakers" because of the ecstatic nature of their worship services. They believed in the renunciation of sinful acts and that the end of the world was near.
Meetings were first held in Bolton, where the articulate preacher, Jane Wardley, urged her followers to:
Other meetings were then held in Manchester, Meretown (also spelled Mayortown), Chester and other places near Manchester. As their numbers grew, members began to be persecuted, mobbed, and stoned; Lee was imprisoned in Manchester. The members looked to women for leadership, believing that the second coming of Christ would be through a woman. In 1770, Ann Lee was revealed in "manifestation of Divine light" to be the second coming of Christ and was called Mother Ann.
Mother Ann Lee.
Ann Lee joined the Shakers by 1758 and then became the leader of the small community. "Mother Ann", as her followers later called her, claimed numerous revelations regarding the fall of Adam and Eve and its relationship to sexual intercourse. A powerful preacher, she called her followers to confess their sins, give up all their worldly goods, and take up the cross of celibacy and forsake marriage, as part of the renunciation of all "lustful gratifications".
She said:
Having supposedly received a revelation, on May 19, 1774, Ann Lee and eight of her followers sailed from Liverpool for colonial America. Ann and her husband Abraham Stanley, brother William Lee, niece Nancy Lee, James Whittaker, father and son John Hocknell and Richard Hocknell, James Shephard and Mary Partington traveled to colonial America, and except for Abraham Stanley who remarried and settled in Watervliet, New York. Her vision of the Shakers in America was represented in a vision: "I saw a large tree, every leaf of which shone with such brightness as made it appear like a burning torch, representing the Church of Christ, which will yet be established in this land." Unable to "swear" an Oath of Allegiance, as it was against their faith, the members were imprisoned for about six months. Since they were only imprisoned because of their faith, this raised sympathy of citizens and thus helped to spread their religious beliefs. Lee, revealed as the "second coming" of Christ, traveled throughout the eastern states, preaching her gospel views.
Community growth.
Aside from the first community, Mount Lebanon, a number of new Shaker communities formed during the 5-year-period between 1787 and 1792. Also in New York, there was Groveland and Watervliet Shaker Villages. In Massachusetts were Hancock, Harvard; Shirley and Tyringham Shaker Villages. Other locations were Enfield Shaker Villages in Connecticut and New Hampshire; Canterbury; and in Maine the Sabbathday Lake Shaker Village in New Gloucester and Alfred Shaker Historic District.
Joseph Meacham and communalism.
After Ann Lee and James Whittaker died, Joseph Meacham (1742–1796) became the leader of the Shakers in 1787. He had been a New Light Baptist minister in Enfield, Connecticut, and was reputed to have, second only to Mother Ann, the spiritual gift of revelation.
Joseph Meacham brought Lucy Wright (1760–1821) into the Ministry to serve with him and together they developed the Shaker form of communalism (religious communism). By 1793 property had been made a "consecrated whole" in each Shaker community.
Shakers developed written covenants in the 1790s. Those who signed the covenant had to confess their sins, consecrate their property and their labor to the society, and live as celibates. If they were married before joining the society, their marriages ended when they joined. A few less-committed Believers lived in "noncommunal orders" as Shaker sympathizers who preferred to remain with their families. The Shakers never forbade marriage for such individuals, but considered it less perfect than the celibate state.
Lucy Wright and westward expansion.
After Joseph Meacham died, Lucy Wright continued Ann Lee's missionary tradition. Shaker missionaries proselytized at revivals, not only in New England and New York, but also farther west. Missionaries such as Issachar Bates and Benjamin Seth Youngs (older brother of Isaac Newton Youngs) gathered hundreds of proselytes into the faith.
Mother Lucy Wright introduced new hymns and dances to make sermons more lively. She also helped write Benjamin S. Youngs' book "The Testimony of Christ’s Second Appearing" (1808).
Shaker missionaries entered Kentucky and Ohio after the Cane Ridge, Kentucky revival of 1801–1803, which was an outgrowth of the Logan County, Kentucky, Revival of 1800. From 1805 to 1807, they founded Shaker societies at Union Village, Ohio; South Union, Logan County, Kentucky; and Pleasant Hill, Kentucky (in Mercer County, Kentucky). In 1824, the Whitewater Shaker settlement was established in southwestern Ohio. The westernmost Shaker community was located at West Union (called Busro because it was on Busseron Creek) on the Wabash River a few miles north of Vincennes in Knox County, Indiana.
Era of Manifestations.
The Shaker movement was at its height between 1820 and 1860. It was at this time that the sect had its most members, and the period was considered its "golden age". It had expanded from New England to the Midwestern states of Indiana, Kentucky and Ohio. It was during this period that it became known for its furniture design and craftsmanship. In the late 1830s a spiritual revivalism, the Era of Manifestations was born. It was also known as the "period of Mother's work", for the spiritual revelations that were passed from the late Mother Ann Lee.
The expression of "spirit gifts" or messages were realized in "gift drawings" made by Hannah Cohoon, Polly Reed, Polly Collins, and other Shaker sisters. A number of those drawings remain as important artifacts of Shaker folk art.
Isaac N. Youngs, the scribe and historian for the New Lebanon, New York, Church Family of Shakers, preserved a great deal of information on the era of manifestations, which Shakers referred to as Mother Ann's Work, in his Domestic Journal, his diary, Sketches of Visions, and his history, A Concise View of the Church of God. 
In addition, Shakers preserved thousands of spirit communications still extant in collections now held by the Berkshire Athenaeum, Fruitlands Museums Library, Hamilton College Library, Hancock Shaker Village, Library of Congress, New York Public Library, New York State Library, the Shaker Library at Sabbathday Lake Shaker Village, Shaker Museum | Mount Lebanon, Western Reserve Historical Society, Williams College Archives, Winterthur Museum Library, and other repositories.
American Civil War period.
As pacifists, the Shakers did not believe that it was acceptable to kill or harm others, even in time of war. As a result, the Civil War brought with it a strange time for the Shaker communities in America. Both Union and Confederate soldiers found their way to the Shaker communities. Shakers tended to sympathize with the Union but they did feed and care for both Union and Confederate soldiers. President Lincoln exempted Shaker males from military service, and they became some of the first conscientious objectors in American history. The end of the Civil War brought large changes to the Shaker communities. One of the most important changes was the postwar economy.
The Shakers had a hard time competing in the industrialized economy that followed the Civil War. With prosperity falling, converts were hard to come by. By the early 20th century, the once numerous Shaker communities were failing and closing. Today, in the 21st century, the Shaker community that still exists–the Sabbathday Lake Shaker Community–denies that Shakerism was a failed utopian experiment.
Their message, surviving over two centuries in America, reads in part as follows:
Shakerism is not, as many would claim, an anachronism; nor can it be dismissed as the final sad flowering of 19th century liberal utopian fervor. Shakerism has a message for this present age–a message as valid today as when it was first expressed. It teaches above all else that God is Love and that our most solemn duty is to show forth that God who is love in the World.
Theology.
Dualism.
Shaker theology is based on the idea of the dualism of God as male and female: "So God created him; male and female he created them" (Genesis 1:27). This passage was interpreted as showing the dual nature of the Creator.
First and second coming.
Shakers believed that Jesus, born of a woman, the son of a Jewish carpenter, was the male manifestation of Christ and the first Christian Church; and that Mother Ann, daughter of an English blacksmith, was the female manifestation of Christ and the second Christian Church (which the Shakers believed themselves to be). She was seen as the Bride made ready for the Bridegroom, and in her, the promises of the Second Coming were fulfilled.
Adam's sin was understood to be sex, which was considered to be an act of impurity. Therefore, marriage was done away with in the body of the Believers in the Second Appearance, which was patterned after the Kingdom of God, in which there would be no marriage or giving in marriage. The four highest Shaker virtues were virgin purity; communalism; confession of sin—without which one could not become a Believer; and separation from world.
Celibacy and children.
Shakers were celibate; procreation was forbidden after they joined the society (except for women who were already pregnant at admission). Children were added to their communities through indenture, adoption, or conversion. Occasionally a foundling was anonymously left on a Shaker doorstep. They welcomed all, often taking in orphans and the homeless. For children, Shaker life was structured, safe and predictable, with no shortage of adults who cared about their young charges.
When Shaker youngsters, girls and boys, reached the age of 21, they were free to leave or to remain with the Shakers. Unwilling to remain celibate, many chose to leave; today there are thousands of descendants of Shaker-raised seceders.
Gender roles.
Shaker religion valued women and men equally in religious leadership. The church was hierarchical, and at each level women and men shared authority. This was reflective of the Shaker belief that God was both female and male. They believed men and women were equal in the sight of God, and should be treated equally on earth, too. Thus two Elders and two Eldresses formed the Ministry at the top of the administrative structure. Two lower-ranking Elders and two Eldresses led each family, women overseeing women and men overseeing men.
In their temporal labor, Shakers followed traditional gender work-related roles. Their homes were segregated by sex, as were women and men's work areas. Women worked indoors spinning, weaving, cooking, sewing, cleaning, washing, and making or packaging goods for sale. In good weather, groups of Shaker women were outdoors, gardening and gathering wild herbs for sale or home consumption. Men worked in the fields doing farm work and in their shops at crafts and trades. Shakers thus simultaneously valued women's status in society and realized the importance and difficulty of women's work, not following traditional prejudices that would consider women a "weaker sex" simply to elevate the male, as it was unnecessary in their egalitarian social structure to do so. This also allowed the continuation of church leadership when there was a shortage of men.
Worship.
Shakers worshipped in meetinghouses painted white and unadorned; pulpits and decorations were eschewed as worldly things. In meeting, they marched, sang, danced, and sometimes turned, twitched, jerked, or shouted. The earliest Shaker worship services were unstructured, loud, chaotic and emotional. However, Shakers later developed precisely choreographed dances and orderly marches accompanied by symbolic gestures. Many outsiders disapproved of or mocked Shakers' mode of worship without understanding the symbolism of their movements or the content of their songs.
Shaker communities.
The Shakers built more than 20 Shaker communities in the United States. Women and men shared leadership of the Shaker communities. Women preached and received revelations as the Spirit fell upon them. Thriving on the religious enthusiasm of the first and second Great Awakenings, the Shakers declared their messianic, communitarian message with significant response. One early convert observed: “The wisdom of their instructions, the purity of their doctrine, their Christ-like deportment, and the simplicity of their manners, all appeared truly apostolical.” The Shakers represent a small but important Utopian response to the gospel. Preaching in their communities knew no boundaries of gender, social class, or education.
Economics.
The communality of the Believers was an economic success, and their cleanliness, honesty and frugality received the highest praise. All Shaker villages ran farms, using the latest scientific methods in agriculture. They raised most of their own food, so farming, and preserving the produce required to feed them through the winter, had to be priorities. Their livestock were fat and healthy, and their barns were commended for convenience and efficiency.
When not doing farm work, Shaker brethren pursued a variety of trades and hand crafts, many documented by Isaac N. Youngs. When not doing housework, Shaker sisters did likewise, spinning, weaving, sewing, and making sale goods.
Shakers ran a variety of businesses to support their communities. Many Shaker villages had their own tanneries, sold baskets, brushes, bonnets, brooms, fancy goods, and homespun fabric that was known for high quality, but were more famous for their medicinal herbs, garden seeds of the Shaker Seed Company, apple-sauce, and knitted garments (Canterbury).
The Shaker goal in their temporal labor was perfection. Ann Lee's followers preserved her admonitions about work:
Mother Ann also cautioned them against getting into debt.
Shaker craftsmen were known for a style of Shaker furniture that was plain in style, durable, and functional. Shaker chairs were usually mass-produced because a great number of them were needed to seat all the Shakers in a community.
Around the time of the American Civil War, the Shakers at Mount Lebanon, New York, increased their production and marketing of Shaker chairs. They were so successful that several furniture companies produced their own versions of "Shaker" chairs. Because of the quality of their craftsmanship, original Shaker furniture is costly.
Shakers won respect and admiration for their productive farms and orderly communities. Their industry brought about many inventions like Babbitt metal, the rotary harrow, the circular saw, the clothespin, the Shaker peg, the flat broom, the wheel-driven washing machine, a machine for setting teeth in textile cards, a threshing machine, metal pens, a new type of fire engine, a machine for matching boards, numerous innovations in waterworks, planing machinery, a hernia truss, silk reeling machinery, small looms for weaving palm leaf, machines for processing broom corn, ball-and-socket tilters for chair legs, and a number of other useful inventions.
Shakers were the first large producers of medicinal herbs in the United States, and pioneers in the sale of seeds in paper packets. Brethren grew the crops, but sisters picked, sorted, and packaged their products for sale, so those industries were built on a foundation of women's labor in the Shaker partnership between the sexes.
The Shakers believed in the value of hard work and kept comfortably busy. Mother Ann said: "Labor to make the way of God your own; let it be your inheritance, your treasure, your occupation, your daily calling".
Architecture and furnishings.
The Shakers' dedication to hard work and perfection has resulted in a unique range of architecture, furniture and handicraft styles. They designed their furniture with care, believing that making something well was in itself, "an act of prayer." Before the late 19th century, they rarely fashioned items with elaborate details or extra decoration, but only made things for their intended uses. The ladder-back chair was a popular piece of furniture. Shaker craftsmen made most things out of pine or other inexpensive woods and hence their furniture was light in color and weight.
Early 19th-century Shaker interiors are characterized by an austerity and simplicity. For example, they had a "peg rail," a continuous wooden device like a pelmet with hooks running all along it near the lintel level. They used the pegs to hang up clothes, hats, and very light furniture pieces such as chairs when not in use. The simple architecture of their homes, meeting houses, and barns have had a lasting influence on American architecture and design. There is a collection of furniture and utensils at Hancock Shaker Village outside of Pittsfield, Massachusetts that is famous for its elegance and practicality.
At the end of the 19th century, however, Shakers adopted some aspects of Victorian decor, such as ornate carved furniture, patterned linoleum, and cabbage-rose wallpaper. Examples are on display in the Hancock Shaker Village Trustees' Office, a formerly spare, plain building "improved" with ornate additions such as fish-scale siding, bay windows, porches, and a tower.
Culture.
Artifacts.
By the middle of the 20th century, as the Shaker communities themselves were disappearing, some American collectors whose visual tastes were formed by the stark aspects of the modernist movement found themselves drawn to the spare artifacts of Shaker culture, in which "form follows function" was also clearly expressed. Kaare Klint, an architect and famous furniture designer, used styles from Shaker furniture in his work.
Other artifacts of Shaker culture are their spirit drawings, dances, and songs, which are important genres of Shaker folk art. Doris Humphrey, an innovator in technique, choreography, and theory of dance movement, made a full theatrical art with her dance entitled Dance of The Chosen, which depicted Shaker religious fervor.
Music.
The Shakers composed thousands of songs, and also created many dances; both were an important part of the Shaker worship services. In Shaker society, a spiritual "gift" could also be a musical revelation, and they considered it important to record musical inspirations as they occurred.
Scribes, many of whom had no formal musical training, used a form of music notation called the letteral system. This method used letters of the alphabet, often not positioned on a staff, along with a simple notation of conventional rhythmic values, and has a curious, and coincidental, similarity to some ancient Greek music notation.
Many of the lyrics to Shaker tunes consist of syllables and words from unknown tongues, the musical equivalent of glossolalia. It has been surmised that many of them were imitated from the sounds of Native American languages, as well as from the songs of African slaves, especially in the southernmost of the Shaker communities , but in fact the melodic material is derived from European scales and modes.
Most early Shaker music is monodic, that is to say, composed of a single melodic line with no harmonization. The tunes and scales recall the folksongs of the British Isles, but since the music was written down and carefully preserved, it is "art" music of a special kind rather than folklore. Many melodies are of extraordinary grace and beauty, and the Shaker song repertoire, though still relatively little known, is an important part of the American cultural heritage and of world religious music in general.
Shakers' earliest hymns were shared by word of mouth and letters circulated among their villages. Many Believers wrote out the lyrics in their own manuscript hymnals. In 1813, they published "Millennial Praises", a hymnal containing only lyrics.
In the late 19th century, the Shakers published several hymnbooks with both lyrics and music in conventional four-part harmonies. These works are less strikingly original than the earlier, monodic repertoire.
The surviving Shakers sing songs drawn from both the earlier repertoire and the four part songbooks. They perform all of these unaccompanied, in single-line unison singing. The many recent, harmonized arrangements of older Shaker songs for choirs and instrumental groups mark a departure from traditional Shaker practice.
"Simple Gifts" was composed by Elder Joseph Brackett and originated in the Shaker community at Alfred, Maine in 1848. Many contemporary Christian denominations incorporate this tune into hymnals, under various names, including "Lord of the Dance," adapted in 1963 by English poet and songwriter Sydney Carter.
Some scholars, such as Daniel W. Patterson and Roger Lee Hall, have compiled books of Shaker songs, and groups have been formed to sing the songs and perform the dances.
The most extensive recordings of the Shakers singing their own music were made between 1960 and 1980 and released on a 2-CD set with illustrated booklet, "Let Zion Move: Music of the Shakers." . Other recordings are available of Shaker songs, both documentation of singing by the Shakers themselves, as well as songs recorded by other groups (see external links). Two widely distributed commercial recordings by The Boston Camerata, "Simple Gifts" (1995) and "The Golden Harvest" (2000), were recorded at the Shaker community of Sabbathday Lake, Maine, with active cooperation from the surviving Shakers, whose singing can be heard at several points on both recordings.
Aaron Copland's iconic 1944 ballet score "Appalachian Spring", written for Martha Graham, uses the now famous Shaker tune "Simple Gifts" as the basis of its finale. Given to Graham with the working title "Ballet for Martha," it was named by her for the scenario she had in mind, though Copland often said he was thinking of neither Appalachia nor Spring while he wrote it.
Works inspired by Shaker culture.
Shaker lifestyle and tradition is celebrated in Arlene Hutton's play "As It Is in Heaven", which is a re-creation of a decisive time in the history of the Shakers. The play is written by Arlene Hutton, the pen name of actor/director Beth Lincks. Born in Louisiana and raised in Florida, Lincks was inspired to write the play after visiting the Pleasant Hills Shaker village in Harrodsburg, Kentucky, a restored community that the Shakers occupied for more than a century, before abandoning it in 1927 because of the inability of the sect to attract new converts.
Novelist John Fowles wrote in 1985 "A Maggot", a postmodern historical novel culminating in the birth of Ann Lee, and describing early Shakers in England.
In 2004 the Finnish choreographer Tero Saarinen and Boston Camerata music director Joel Cohen created a live performance work with dance and music entitled "Borrowed Light." While all the music is Shaker song performed in a largely traditional manner, the dance intermingles only certain elements of Shaker practice and belief with Saarinen's original choreographic ideas, and with distinctive costumes and lighting. "Borrowed Light" has been given over 60 performances since 2004 in eight countries, recently (early 2008) in Australia and New Zealand, and most recently (2011) in France, Germany, Finland, the Netherlands, and Belgium. In addition to Doris Humphrey, Martha Graham and Tero Saarinen cited above, choreographers Twyla Tharp (“Sweet Fields,” 1996) and Martha Clarke (“Angel Reapers,” 2011) also set movement to Shaker hymns. Playwright Alfred Uhry collaborated with Martha Clarke on "Angel Reapers" and used Shaker texts as source material. The music of "Angel Reapers" was successfully and uniquely arranged by Music Director Arthur Solari.
In 2009, Toronto-based, American-born poet Damian Rogers released her first volume of poetry, "Paper Radio". The lifestyle and philosophy of the Shakers and their matriarch Ann Lee are recurring themes in her work.
Education.
New Lebanon, New York, Shakers began keeping school in 1815. Certified as a public school by the state of New York beginning in 1817, the teachers operated on the Lancastrian system, which was considered advanced for its time. Boys attended class during the winter and the girls in the summer. The first Shaker schools taught reading, spelling, oration, arithmetic and manners, but later diversified their coursework to include music, algebra, astronomy, and agricultural chemistry. 
Non-Shaker parents respected the Shakers' schooling so much that they often took advantage of schools that the Shaker villages provided, sending their worldly children there for an education. State inspectors and other outsiders visited the schools and made favorable comments on teachers and students.
Modern-day Shakers.
Turnover was high; the group reached maximum size of about 5,000 full members in 1840, and/or 6,000 believers at the peak of the Shaker movement. There were only 12 Shaker communities left by 1920. The Shaker communities continued to lose members, partly through attrition, since believers did not give birth to children, and also due to economics; hand-made products by Shakers were not as competitive as mass-produced products and individuals moved to the cities for better livelihoods.
In 1957, after "months of prayer," Eldresses Gertrude, Emma, and Ida, the leaders of the United Society of Believers, and members of the Canterbury Shaker Village, voted to close the Shaker Covenant, the document which all new members need to sign to become members of the Shakers. In 1988, speaking about the three men and women in their 20s and 30s who had joined the Shakers and were living in the Sabbathday Lake Shaker Village, Eldress Bertha Lindsay "To become a Shaker you have to sign a legal document taking the necessary vows and that document, the official covenant, is locked up in our safe. Membership is closed forever." 
However, Shaker covenants lack a "sunset clause." And despite their predecessors' views, today's Shakers welcome sincere newcomers into the society.
As of 2010, the remaining active Shaker community in the United States is Sabbathday Lake Shaker Village in Maine, had one novitiate and three full members: Sister June Carpenter, Brother Arnold Hadd, and Sister Frances Carr.

</doc>
<doc id="44405" url="https://en.wikipedia.org/wiki?curid=44405" title="Kabala">
Kabala

Kabala can refer to:

</doc>
<doc id="44406" url="https://en.wikipedia.org/wiki?curid=44406" title="Zoroaster">
Zoroaster

Zoroaster ( or , from Greek "Zōroastrēs"), also known as Zarathustra (; ("Zaraθuštra"); "Zartosht", "Zardosht"), or as Zarathushtra Spitama, was the founder of Zoroastrianism. He was a native speaker of Old Avestan and lived in the eastern part of the Iranian Plateau, but his birthplace is uncertain. Zoroastrianism was the official religion of Persia and its distant subdivisions from 600 BCE to 650 CE. In modern scholarship Zoroaster is often dated to the 10th century BCE, though he is traditionally dated from 628 to 551 BCE, and the religion named after him is not attested to historically until the 5th century BCE.
He is credited with the authorship of the Yasna Haptanghaiti as well as the Gathas, hymns which are at the liturgical core of Zoroastrian thinking. Most of his life is known through the Zoroastrian texts.
Etymology.
Zoroaster's name in his native language, Avestan, was probably "Zaraϑuštra". His English name, "Zoroaster", derives from a later (5th century BCE) Greek transcription, "Zōroastrēs" (), as used in Xanthus's "Lydiaca" (Fragment 32) and in Plato's "First Alcibiades" (122a1). This form appears subsequently in the Latin "" and, in later Greek orthographies, as "Zōroastris". The Greek form of the name appears to be based on a phonetic transliteration or semantic substitution of Avestan "zaraϑ-" with the Greek "zōros" (literally "undiluted") and the Avestan "-uštra" with "astron" ("star").
In Avestan, "Zaraϑuštra" is generally accepted to derive from an Old Iranian "*Zaratuštra-"; The element half of the name ("-uštra-") is thought to be the Indo-Iranian root for "camel", with the entire name meaning "he who can manage camels".
Reconstructions from later Iranian languages—particularly from the Middle Persian (300 BCE) "Zardusht", which is the form that the name took in the 9th- to 12th-century Zoroastrian texts—suggest that "*Zaratuštra-" might be a zero-grade form of "*Zarantuštra-".
Subject then to whether "Zaraϑuštra" derives from "*Zarantuštra-" or from "*Zaratuštra-", several interpretations have been proposed.
If "Zarantuštra" is the original form, it may mean
"with old/aging camels", related to Avestic "zarant-". ("cf." Pashto "zōṛ" and Ossetian "zœrond", "old"; Middle Persian "zāl", "old")
But if "Zaratuštra-", meaning
"of the golden camel", is correct, it is derived from old Eastern Iranian word "*zar-" for gold and "ushtra" for camel. An Eastern Iranian origin is also suggested by the fact that the Old Persian word "dar" as a Western-Iranian dialect would be the equal term of Eastern Iranian "zar", and Modern Persian uses the Eastern Iranian word for gold.
The interpretation of the "-ϑ-" () in Avestan "zaraϑuštra" was for a time itself subjected to heated debate because the "-ϑ-" is an irregular development: As a rule, "*zarat-" (a first element that ends in a dental consonant) should have Avestan "zarat-" or "zarat̰-" as a development from it. Why this is not so for "zaraϑuštra" has not yet been determined. Notwithstanding the phonetic irregularity, that Avestan "zaraϑuštra" with its "-ϑ-" was linguistically an actual form is shown by later attestations reflecting the same basis. All present-day, Iranian-language variants of his name derive from the Middle Iranian variants of "Zarϑošt", which, in turn, all reflect Avestan's fricative "-ϑ-".
Date.
Modern scholars of Zoroastrianism generally place Zarathushtra as having lived in north-east Iran or northern Afghanistan some time between 1700 and 1300 BCE. Avestan, the language spoken by Zoroaster and used for composing the Yasna Haptanghaiti and the Gathas, on archaeological and linguistic grounds, is dated to have been spoken probably in the first half of the 2nd millennium BCE.
Mary Boyce (1700 BC-1200 BC) and Gherhardo Gnoli (1000 BC) have considered linguistic and socio-cultural evidence to place Zoroaster between 1500 and 500 BC. The basis of this theory is based primarily on proposed linguistic similarities between the Old Avestan language of the Zoroastrian Gathas and the Sanskrit of the Rigveda, a collection of early Vedic hymns. For both texts to have a common Indo-Iranian origin, it is implausible that the Gathas and Rigveda could have been composed more than a few centuries apart, thus these scholars suggest that Zoroaster lived and composed the Gathas much earlier than the 6th century BC. A date of 11th or 10th century BCE is sometimes considered among Iranists, who in recent decades found that the social customs described in the Gathas roughly coincide with what is known of other pre-historic peoples of that period.
Classical scholarship first attests to Zoroaster in the 5th century BC. Zoroastrian sources themselves (the "Bundahishn", "258 years before Alexander") place Zoroaster in the 6th century BC, which coincided with historiographic accounts (Ammianus Marcellinus xxiii.6.32, 4th century CE). The Traditional Zoroastrian date originates in the period immediately following Alexander the Great's conquest of the Achaemenid Empire in 330 BCE. The Seleucid kings who gained power following Alexander's death instituted an "Age of Alexander" as the new calendrical epoch. This did not appeal to the Zoroastrian priesthood who then attempted to establish an "Age of Zoroaster". To do so, they needed to establish when Zoroaster had lived, which they accomplished by counting back the length of successive generations until they concluded that Zoroaster must have lived "258 years before Alexander". This estimate then re-appeared in the 9th- to 12th-century texts of Zoroastrian tradition.
Place.
"Yasna" 9 and 17 cite the Ditya River in Airyanem Vaējah (Middle Persian "Ērān Wēj") as Zoroaster's home and the scene of his first appearance. The Avesta (both Old and Younger portions) does not mention the Achaemenids or of any West Iranian tribes such as the Medes, Persians, or even Parthians.
However, in "Yasna" 59.18, the "zaraϑuštrotema", or supreme head of the Zoroastrian priesthood, is said to reside in 'Ragha'. In the 9th- to 12th-century Middle Persian texts of Zoroastrian tradition, this 'Ragha'—along with many other places—appear as locations in Western Iran. While the land of Media does not figure at all in the Avesta (the westernmost location noted in scripture is Arachosia), the "Būndahišn", or "Primordial Creation," (20.32 and 24.15) puts Ragha in Media (medieval Rai). However, in Avestan, Ragha is simply a toponym meaning "plain, hillside."
Apart from these indications in Middle Persian sources which are open to interpretations, there are a number of other sources. The Greek and Latin sources are divided on the birthplace of Zarathustra. There are many Greek accounts of Zarathustra, referred usually as Persian or Perso-Median Zoroaster. Moreover, they have the suggestion that there has been more than one Zoroaster. On the other hand, in post-Islamic sources Shahrastani (1086–1153) an Iranian writer originally from Shahristān, present-day Turkmenistan, proposed that Zoroaster's father was from Atropatene (also in Medea) and his mother was from Rey. Coming from a reputed scholar of religions, this was a serious blow for the various regions who all claimed that Zoroaster originated from "their" homelands, some of which then decided that Zoroaster must then have then been buried in their regions or composed his Gathas there or preached there. Also Arabic sources of the same period and the same region of historical Persia consider Azerbaijan as the birthplace of Zarathustra.
By the late 20th century, most scholars had settled on an origin in Eastern Iran. Gnoli proposed Sistan, Baluchistan (though in a much wider scope than the present-day province) as the homeland of Zoroastrianism; Frye voted for Bactria and Chorasmia; Khlopin suggests the Tedzen Delta in present-day Turkmenistan.
Sarianidi considered the Bactria–Margiana Archaeological Complex region as "the native land of the Zoroastrians and, probably, of Zoroaster himself." Boyce includes the steppes to the west from the Volga. The medieval "from Media" hypothesis is no longer taken seriously, and Zaehner has even suggested that this was a Magi-mediated issue to garner legitimacy, but this has been likewise rejected by Gershevitch and others.
The 2005 "Encyclopedia Iranica" article on the history of Zoroastrianism summarizes the issue with "while there is general agreement that he did not live in western Iran, attempts to locate him in specific regions of eastern Iran, including Central Asia, remain tentative."
Life.
Zoroaster initially learned the trade of a cobbler and lived by the rivers of Bactria. By the age of 30, he was a preacher of monotheism and his followers were adherents of Ahura Mazda (Wise Lord).
He received revelations and saw a vision of Amesha Spenta, and his teachings were collected in the Gathas and the Avesta. His teachings of the Golden Rule and as a shaman had gained him much attention among the leading figures of his time.
His thoughts about free will earned him a patron ruler named Vishtaspa an early adherent of Zoroastrianism (possibly from Bactria according to the Shahnameh).
Zoroaster was interested in the occult, such as the spirit elements of Water, Air, Earth, and Fire. His ideas about the secrets of beauty and health had gained him much prosperity and wealth possibly in gemstones. Persian rulers associated the faith with prosperity and fortune (except Cyrus the Great).
He married Hvōvi (an Avestan high priestess). He opposed the use of the hallucinogenic Haoma plant, polytheism and an oppressive class system in Persia. His followers spread throughout Rsis, Elam, Babylon, Media, Sardis; Fire temples were built in Armenia in his honor and led to the rise of the Achaemenid Empire.
Death.
Zoroaster was murdered because he opposed the Daevas. The Shahnameh, however claims an obscure conflict with Turan, in which Zoroaster was murdered. Jamaspa, his son-in-law, then became Zoroaster's successor.
Influences.
In Islam.
It is very likely that Zoroaster or his descendants or followers (who unlike most Persians were unharmed by the Diadochi, due to their location in the Desert of Paran) were the progenitors of the monotheistic Ishmaelites such as Quraysh (among whom many supported Sassanid Persia), Rasulids, Alids, Umayyads, and Abbasids.
The similarities between Amesha Spenta and the archangel Gabriel are also evident. So are the mention of Thamud, Iram of the Pillars in the Quran (indicating the vast influence of the Achaemenid Empire).
The Sabaeans who practiced Free Will (somehow coincidentally with Zoroastrians) are also mentioned in the Quran.
Muslim scholastic views.
Like the Greeks of classical antiquity, Islamic tradition understands Zoroaster to be the founding prophet of the Magians (via Aramaic, Arabic "Majus", collective "Majusya"). The 11th-century Cordoban Ibn Hazm (Zahiri school) contends that "Kitabi" "of the Book" cannot apply in light of the Zoroastrian assertion that their books were destroyed by Alexander. -->
Citing the authority of the 8th-century al-Kalbi, the 9th- and 10th-century Sunni historian al-Tabari (i.648) reports that Zaradusht bin Isfiman (an Arabic adaptation of "Zarathustra Spitama") was an inhabitant of Israel and a servant of one of the disciples of the prophet Jeremiah. According to this tale, Zaradusht defrauded his master, who cursed him, causing him to become leprous (cf. Elisha's servant Gehazi in Jewish Scripture). The apostate Zaradusht then eventually made his way to Balkh (present day Afghanistan) where he converted Bishtasb (i.e. Vishtaspa), who in turn compelled his subjects to adopt the religion of the Magians. Recalling other tradition, al-Tabari (i.681–683) recounts that Zaradusht accompanied a Jewish prophet to Bishtasb/Vishtaspa. Upon their arrival, Zaradusht translated the sage's Hebrew teachings for the king and so convinced him to convert (Tabari also notes that they had previously been "Sabi"s) to the Magian religion.
The 12th-century heresiographer al-Shahrastani describes the Majusiya into three sects, the "Kayumarthiya", the "Zurwaniya" and the "Zaradushtiya", among which Al-Shahrastani asserts that only the last of the three were properly followers of Zoroaster. As regards the recognition of a prophet, the Zoroaster has said: "They ask you as to how should they recognize a prophet and believe him to be true in what he says; tell them what he knows the others do not, and he shall tell you even what lies hidden in your nature; he shall be able to tell you whatever you ask him and he shall perform such things which others cannot perform." (Namah Shat Vakhshur Zartust, .5–7. 50–54) Shortly before the advent of the prophet of Islam, , Persia was under the sovereignty of Sasan V. When the companions of the Prophet, on invading Persia, came in contact with the Zoroastrian people and learned these teachings, they at once came to the conclusion that Zoroaster was really a Divinely inspired prophet. Thus they accorded the same treatment to the Zoroastrian people which they did to other "People of the Book". Though the name of Zoroaster is not mentioned in the Qur'an, still he was regarded as one of those prophets whose names have not been mentioned in the Qur'an, for there is a verse in the Qur'an: "And We did send apostles before thee: there are some of them that We have mentioned to thee and there are others whom We have not mentioned to Thee." (40 : 78). Accordingly, the Muslims treated the founder of Zoroastrianism as a true prophet and believed in his religion as they did in other inspired creeds, and thus according to the prophecy, protected the Zoroastrian religion. James Darmestar remarked in the translation of Zend Avesta: "When Islam assimilated the Zoroastrians to the People of the Book, it evinced a rare historical sense and solved the problem of the origin of the Avesta." (Introduction to Vendiad. p. 69.)
Ahmadiyya view.
Ahmadi Muslims view Zoroaster as a Prophet of God and describe the expressions of Ahura Mazda, the God of goodness and Ahraman, the God of evil as merely referring to the coexistence of forces of good and evil enabling humans to exercise free will. Mirza Tahir Ahmad, the fourth Caliph of the Ahmadiyya Muslim Community, in his book "Revelation, Rationality, Knowledge & Truth" views Zoroaster as Prophet of God and describes such the expressions to be a concept which is similar to the concepts in Judaism, Christianity and Islam.
In Manichaeism.
Manichaeism considered Zoroaster to be a figure (along with Jesus and the Buddha) in a line of prophets of which Mani (216–276) was the culmination. Zoroaster's ethical dualism is—to an extent—incorporated in Mani's doctrine, which viewed the world as being locked in an epic battle between opposing forces of good and evil. Manicheanism also incorporated other elements of Zoroastrian tradition, particularly the names of supernatural beings; however, many of these other Zoroastrian elements are either not part of Zoroaster's own teachings or are used quite differently from how they are used in Zoroastrianism.
In the Bahá'í Faith.
Zoroaster appears in the Bahá'í Faith as a "Manifestation of God", one of a line of prophets who have progressively revealed the Word of God to a gradually maturing humanity. Zoroaster thus shares an exalted station with Abraham, Moses, Krishna, Jesus, Muhammad, the Báb, and the founder of the Bahá'í Faith, Bahá'u'lláh. Shoghi Effendi, the head of the Bahá'í Faith in the first half of the 20th century, saw Bahá'u'lláh as the fulfillment of a post-Sassanid Zoroastrian prophecy that saw a return of Sassanid emperor Bahram: Shoghi Effendi also stated that Zoroaster lived roughly 1000 years before Jesus.
Philosophy.
In the Gathas, Zoroaster sees the human condition as the mental struggle between "aša" (truth) and "druj" (lie). The cardinal concept of "aša"—which is highly nuanced and only vaguely translatable—is at the foundation of all Zoroastrian doctrine, including that of Ahura Mazda (who is "aša"), creation (that is "aša"), existence (that is "aša") and as the condition for free will.
The purpose of humankind, like that of all other creation, is to sustain "aša". For humankind, this occurs through active participation in life and the exercise of constructive thoughts, words and deeds.
Elements of Zoroastrian philosophy entered the West through their influence on Judaism and Middle Platonism and have been identified as one of the key early events in the development of philosophy. Among the classic Greek philosophers, Heraclitus is often referred to as inspired by Zoroaster's thinking.
In 2005, the Oxford Dictionary of Philosophy ranked Zarathustra as first in the chronology of philosophers. Zarathustra's impact lingers today due in part to the system of rational ethics he founded called Mazda-Yasna. The word Mazda-Yasna is avestan and is translated as "Worship of Wisdom" in English. Zoroastrians later educated the Greeks, who used a similar term, philosophy, or “love of wisdom,” to describe the search for ultimate truth.
Zoroaster emphasized the freedom of the individual to choose right or wrong and individual responsibility for one's deeds. This personal choice to accept "aša" or arta (the divine order), and shun "druj" (ignorance and chaos) is one's own decision and not a dictate of Ahura Mazda. For Zarathustra, by thinking good thoughts, saying good words, and doing good deeds (e.g. assisting the needy or doing good works) we increase this divine force "aša" or arta in the world and in ourselves, celebrate the divine order, and we come a step closer on the everlasting road to being one with the Creator. Thus, we are not the slaves or servants of Ahura Mazda, but we can make a personal choice to be his co-workers, thereby refreshing the world and ourselves.
Iconography.
Although a few recent depictions of Zoroaster show the prophet performing some deed of legend, in general the portrayals merely present him in white vestments (which are also worn by present-day Zoroastrian priests). He often is seen holding a "baresman" (Avestan; Middle Persian "barsom"), which is generally considered to be another symbol of priesthood, or with a book in hand, which may be interpreted to be the Avesta. Alternatively, he appears with a mace, the "varza"—usually stylized as a steel rod crowned by a bull's head—that priests carry in their installation ceremony. In other depictions he appears with a raised hand and thoughtfully lifted finger, as if to make a point. Zoroaster is rarely depicted as looking directly at the viewer; instead, he appears to be looking slightly upwards, as if beseeching. Zoroaster is almost always depicted with a beard, this along with other factors bearing similarities to 19th-century portraits of Jesus.
A common variant of the Zoroaster images derives from a Sassanid-era rock-face carving. In this depiction at Taq-e Bostan, a figure is seen to preside over the coronation of Ardashir I or II. The figure is standing on a lotus, with a "baresman" in hand and with a gloriole around his head. Until the 1920s, this figure was commonly thought to be a depiction of Zoroaster, but in recent years is more commonly interpreted to be a depiction of Mithra. Among the most famous of the European depictions of Zoroaster is that of the figure in Raphael's 1509 The School of Athens. In it, Zoroaster and Ptolemy are having a discussion in the lower right corner. The prophet is holding a star-studded globe.
Western civilization.
In classical antiquity.
Although, at the core, the Greeks (in the Hellenistic sense of the term) understood Zoroaster to be the "prophet and founder of the religion of the Iranian peoples" (e.g. Plutarch "Isis and Osiris" 46-7, Diogenes Laertius 1.6–9 and Agathias 2.23-5), "the rest was mostly fantasy". He was set in the impossibly ancient past, six to seven millennia before the Common Era, and was variously a king of Bactria, or a Babylonian (or teacher of Babylonians), and with a biography typical for every Neopythagorean sage, i.e. a mission preceded by ascetic withdrawal and enlightenment.
Most importantly however, was their picture of Zoroaster as the sorcerer-astrologer "non-plus-ultra", and indeed as the "inventor" of both magic and astrology. Deriving from that image, and reinforcing it, was a "mass of literature" attributed to him and that circulated the Mediterranean world from the 3rd century BCE to the end of antiquity and beyond. "The Greeks considered the best wisdom to be exotic wisdom" and "what better and more convenient authority than the distant—temporally and geographically—Zoroaster?"
The language of that literature was predominantly Greek, though at one stage or another various parts of it passed through Aramaic, Syriac, Coptic or Latin. Its ethos and cultural matrix was likewise Hellenistic, and "the ascription of literature to sources beyond that political, cultural and temporal framework represents a bid for authority and a fount of legitimizing "alien wisdom". Zoroaster and the magi did not compose it, but their names sanctioned it." The attributions to "exotic" names (not restricted to magians) conferred an "authority of a remote and revelation wisdom."
Once the magi were associated with magic in Greek imagination, Zoroaster was bound to metamorphose into a magician too. The 1st-century Pliny the Elder names Zoroaster as the inventor of magic ("Natural History" 30.2.3). "However, a principle of the division of labor appears to have spared Zoroaster most of the responsibility for introducing the dark arts to the Greek and Roman worlds." That "dubious honor" went to the "fabulous magus, Ostanes, to whom most of the pseudepigraphic magical literature was attributed." Although Pliny calls him the inventor of magic, the Roman does not provide a "magician's persona" for him. Moreover, the little "magical" teaching that is ascribed to Zoroaster is actually very late, with the very earliest example being from the 14th century.
One factor for the association with astrology was Zoroaster's name, or rather, what the Greeks made of it. Within the scheme of Greek thinking (which was always on the lookout for hidden significances and "real" meanings of words) his name was identified at first with star-worshiping ("astrothytes" "star sacrificer") and, with the "Zo-", even as the "living" star. Later, an even more elaborate mythoetymology evolved: Zoroaster died by the living ("zo-") flux ("-ro-") of fire from the star ("-astr-") which he himself had invoked, and even, that the stars killed him in revenge for having been restrained by him.
Similar ideas about Zoroaster also appear in early Christian literature, beginning with the "Clementine Homilies" 9.4–5, which identifies him with a parallel series of traditions about Nimrod having been the founder of astrology. In this account, Nimrod is killed by lightning and posthumously deified by the Persians as "Zoroaster, on account of the living ("zosan") stream of the star ("asteros") being poured upon him."
The second, and "more serious" factor for the association with astrology was the notion that Zoroaster was a Babylonian. The alternate Greek name for Zoroaster was Zaratas/Zaradas/Zaratos ("cf." Agathias 2.23-5, Clement "Stromata" I.15), which—so Cumont and Bidez—derived from a Semitic form of his name. The Pythagorean tradition considered the mathematician to have studied with Zoroaster in Babylonia (Porphyry "Life of Pythagoras" 12, Alexander Polyhistor apud Clement's "Stromata" I.15, Diodorus of Eritrea, Aristoxenus apud Hippolitus VI32.2). Lydus ("On the Months" II.4) attributes the creation of the seven-day week to "the Babylonians in the circle of Zoroaster and Hystaspes," and who did so because there were seven planets. The Suda's chapter on "astronomia" notes that the Babylonians learned their astrology from Zoroaster. Lucian of Samosata ("Mennipus" 6) decides to journey to Babylon "to ask one of the magi, Zoroaster's disciples and successors," for their opinion.
While the division along the lines of Zoroaster/astrology and Ostanes/magic is an "oversimplification, the descriptions do at least indicate what the works are "not"." They were not expressions of Zoroastrian doctrine, they were not even expressions of what the Greeks and Romans ""imagined" the doctrines of Zoroastrianism to have been." The assembled fragments do not even show noticeable commonality of outlook and teaching among the several authors who wrote under each name.
Almost all Zoroastrian pseudepigrapha is now lost, and of the attested texts—with only one exception—only fragments have survived. Pliny's 2nd- or 3rd-century attribution of "two million lines" to Zoroaster suggest that (even if exaggeration and duplicates are taken into consideration) a formidable pseudepigraphic corpus once existed at the Library of Alexandria. This corpus can safely be assumed to be pseudepigrapha because no one before Pliny refers to literature by "Zoroaster", and on the authority of the 2nd-century Galen of Pergamon and from a 6th-century commentator on Aristotle it is known that the acquisition policies of well-endowed royal libraries created a market for fabricating manuscripts of famous and ancient authors.
The exception to the fragmentary evidence (i.e. reiteration of passages in works of other authors) is a complete Coptic tractate titled "Zostrianos" (after the first-person narrator) discovered in the Nag Hammadi library in 1945. A three-line cryptogram in the colophones following the 131-page treatise identify the work as "words of truth of Zostrianos. God of Truth ["logos"]. Words of Zoroaster." Invoking a "God of Truth" might seem Zoroastrian, but there is otherwise "nothing noticeably Zoroastrian" about the text and "in content, style, ethos and intention, its affinities are entirely with the congeners among the Gnostic tractates."
Among the named works attributed to "Zoroaster" is a treatise "On Nature" ("Peri physeos"), which appears to have originally constituted four volumes (i.e. papyrus rolls). The framework is a retelling of Plato's "Myth of Er", with Zoroaster taking the place of the original hero. While Porphyry imagined Pythagoras listening to Zoroaster's discourse, "On Nature" has the sun in middle position, which was how it was understood in the 3rd century. In contrast, Plato's 4th-century BCE version had the sun in second place above the moon. Ironically, Colotes accused Plato of plagiarizing Zoroaster, and Heraclides Ponticus wrote a text titled "Zoroaster" based on (what the author considered) "Zoroastrian" philosophy in order to express his disagreement with Plato on natural philosophy. With respect to substance and content in "On Nature" only two facts are known: that it was crammed with astrological speculations, and that Necessity ("Ananké") was mentioned by name and that she was in the air.
Another work circulating under the name of "Zoroaster" was the "Asteroskopita" (or "Apotelesmatika"), and which ran to five volumes (i.e. papyrus rolls). The title and fragments suggest that it was an astrological handbook, "albeit a very varied one, for the making of predictions." A third text attributed to Zoroaster is "On Virtue of Stones" ("Peri lithon timion"), of which nothing is known other than its extent (one volume) and that pseudo-Zoroaster "sang" it (from which Cumont and Bidez conclude that it was in verse). Numerous other fragments (preserved in the works of other authors) are attributed to "Zoroaster," but the titles of whose books are not mentioned.
These pseudepigraphic texts aside, some authors did draw on a few genuinely Zoroastrian ideas. The "Oracles of Hystaspes", by "Hystaspes", another prominent magian pseudo-author, is a set of prophecies distinguished from other Zoroastrian pseudepigrapha in that it draws on real Zoroastrian sources. Some allusions are more difficult to assess: in the same text that attributes the invention of magic to Zoroaster, Pliny states that Zoroaster laughed on the day of his birth, although in an earlier place (VII, I), Pliny had sworn in the name of Hercules that no child had ever done so before the 40th day from his birth. This notion of Zoroaster's laughter (like that of "two million verses") also appears in the 9th– to 11th-century texts of genuine Zoroastrian tradition, and for a time it was assumed that the origin of those myths lay with indigenous sources. Pliny also records (VII, XV) that Zoroaster's head had pulsated so strongly that it repelled the hand when laid upon it, a presage of his future wisdom. The Iranians were however just as familiar with the Greek writers. The provenance of other descriptions are clear, so for instance, Plutarch's description of its dualistic theologies: "Others call the better of these a god and his rival a daemon, as, for example, Zoroaster the Magus, who lived, so they record, five thousand years before the siege of Troy. He used to call the one Horomazes and the other Areimanius" ("Isis and Osiris" 46-7).
In the post-classical era.
Zoroaster was known as a sage, magician, and miracle-worker in post-Classical Western culture. Although almost nothing was known of his ideas until the late 18th century, his name was already associated with lost ancient wisdom. Statements by Sir Thomas Browne as early as 1643 are the earliest recorded references to Zoroaster in the English language.
He is also the subject of the 1749 opera "Zoroastre", by Jean-Philippe Rameau.
Enlightenment writers such as Voltaire promoted research into Zoroastrianism in the belief that it was a form of rational Deism, preferable to Christianity. With the translation of the Avesta by Abraham Anquetil-Duperron, Western scholarship of Zoroastrianism began.
In E. T. A. Hoffmann's novel "Klein Zaches, genannt Zinnober", the mage Prosper Alpanus states that Professor Zoroaster was his teacher.
In his seminal work "Also sprach Zarathustra (Thus Spoke Zarathustra)" (1885) the philosopher Friedrich Nietzsche uses the native Iranian name Zarathustra which has a significant meaning as he had used the familiar Greek-Latin name in his earlier works. It is believed that Nietzsche invents a characterization of Zarathustra as the mouthpiece for Nietzsche's own ideas against morality. Richard Strauss's Opus 30, inspired by Nietzsche's book, is also called "Also sprach Zarathustra".
Zoroaster was mentioned by the Irish poet William Butler Yeats. He and his wife were said to have claimed to have contacted Zoroaster through "automatic writing".
The Appellate Division of the Supreme Court of New York has a sculpture of Zoroaster towering over the building on E. 25th St. and Madison Ave in Manhattan, representing the ancient Persian judicial wisdom. The sculpture was made by Edward Clarke Potter in 1896. Also on the south side of the exterior of Rockefeller Memorial Chapel in the campus of the University of Chicago, there is a sculpture of Zoroaster among other prominent religious figures.
The protagonist and narrator of Gore Vidal's 1981 novel "Creation" is described to be the grandson of Zoroaster.
Zarathustra, the mythic hero in Giannina Braschi's 2011 dramatic novel "United States of Banana", joins forces with Shakespeare's Hamlet.

</doc>
<doc id="44408" url="https://en.wikipedia.org/wiki?curid=44408" title="Microphone array">
Microphone array

A microphone array is any number of microphones operating in tandem. There are many applications:
Typically, an array is made up of omnidirectional microphones, directional microphones, or a mix of omnidirectional and directional microphones distributed about the perimeter of a space, linked to a computer that records and interprets the results into a coherent form. Arrays may also be formed using numbers of very closely spaced microphones. Given a fixed physical relationship in space between the different individual microphone transducer array elements, simultaneous DSP (digital signal processor) processing of the signals from each of the individual microphone array elements can create one or more "virtual" microphones. Different algorithms permit the creation of virtual microphones with extremely complex virtual polar patterns and even the possibility to steer the individual lobes of the virtual microphones patterns so as to home-in-on, or to reject, particular sources of sound. 
In case the array consists of omnidirectional microphones they accept sound from all directions, so electrical signals of the microphones contain the information about the sounds coming from all directions. Joint processing of these sounds allows to select the sound signal coming from the given direction. So, microphone array selects the sound coming from a given direction by processing multichannel signals. 
An array of 1020 microphones [http://cag.csail.mit.edu/mic-array/], the largest in the world until August 21st 2014, was built by researchers at the MIT Computer Science and Artificial Intelligence Laboratory.
Currently the largest microphone array in the world was constructed by Sorama, a Netherlands based sound engineering firm, in August of 2014. Their array consists of 4096 microphones. [http://www.guinnessworldrecords.com/world-records/largest-microphone-array/][http://www.sorama.eu/node/201]
Soundfield microphone.
The Soundfield microphone system is a well established example of the use of a microphone array in professional sound recording.

</doc>
<doc id="44410" url="https://en.wikipedia.org/wiki?curid=44410" title="Conjunctivitis">
Conjunctivitis

Conjunctivitis, also known as pink eye, is inflammation of the outermost layer of the white part of the eye and the inner surface of the eyelid. It makes the eye appear pink or reddish. --> There may also be pain, burning, scratchiness, or itchiness. --> The affected eye may have increased tears or be "stuck shut" in the morning. --> Swelling of the white part of the eye may also occur. Itching of the eye is more common in cases due to allergies. Conjunctivitis can affect one or both eyes.
The most common infectious causes are viral followed by a bacterial infections. The viral infection may occur along with other symptoms of a common cold. --> Viral and bacterial cases are easily spread between people. Allergies to pollen or animal hair is also a common cause. Diagnosis is often based on signs and symptoms. --> Occasionally a sample of the discharge is sent for culture.
Prevention is partly by handwashing. --> Treatment depends on the underlying cause. In the majority of viral cases, there is no specific treatment. Most cases due to a bacterial infection will also resolve without treatment; however, antibiotics can shorten the illness. Those who wear contact lens and those with either gonorrhea or chlamydia as the cause should be treated. --> Allergic cases can be treated with antihistamine or mast cell inhibitor drops.
About 3 to 6 million people get conjunctivitis each year in the United States. In adults viral causes are more common, while in children bacterial causes are more common. Typically people get better in one or two weeks. If there is visual loss, significant pain, sensitivity to light, signs of herpes, or a person is not improving after a week, further diagnosis and treatment may be required. Conjunctivitis in a newborn, known as neonatal conjunctivitis, may also require specific treatment.
Signs and symptoms.
Red eye, swelling of conjunctiva and watering of the eyes are symptoms common to all forms of conjunctivitis. However, the pupils should be normally reactive, and the visual acuity normal.
Viral.
Viral conjunctivitis is often associated with an infection of the upper respiratory tract, a common cold, and/or a sore throat. Its symptoms include excessive watering and itching. The infection usually begins with one eye, but may spread easily to the other.
Viral conjunctivitis shows a fine, diffuse pinkness of the conjunctiva, which is easily mistaken for the ciliary infection of Iris (Iritis), but there are usually corroborative signs on microscopy, particularly numerous lymphoid follicles on the tarsal conjunctiva, and sometimes a punctate keratitis.
Some other viruses that can infect the eye include Herpes simplex virus and Varicella zoster.
Allergic.
Allergic conjunctivitis is inflammation of the conjunctiva (the membrane covering the white part of the eye) due to allergy. Allergens differ among patients.
Symptoms consist of redness (mainly due to vasodilation of the peripheral small blood vessels), swelling of the conjunctiva, itching, and increased lacrimation (production of tears). If this is combined with rhinitis, the condition is termed "allergic rhinoconjunctivitis". The symptoms are due to release of histamine and other active substances by mast cells, which stimulate dilation of blood vessels, irritate nerve endings, and increase secretion of tears.
Bacterial.
Bacterial conjunctivitis causes the rapid onset of conjunctival redness, swelling of the eyelid, and mucopurulent discharge. Typically, symptoms develop first in one eye, but may spread to the other eye within 2–5 days. Bacterial conjunctivitis due to common pyogenic (pus-producing) bacteria causes marked grittiness/irritation and a stringy, opaque, greyish or yellowish mucopurulent discharge that may cause the lids to stick together, especially after sleep. Severe crusting of the infected eye and the surrounding skin may also occur. The gritty and/or scratchy feeling is sometimes localized enough for patients to insist they must have a foreign body in the eye. The more acute pyogenic infections can be painful. Common bacteria responsible for non-acute bacterial conjunctivitis are Staphylococci and Streptococci.
Bacteria such as "Chlamydia trachomatis" or "Moraxella" can cause a non-exudative but persistent conjunctivitis without much redness. Bacterial conjunctivitis may cause the production of membranes or pseudomembranes that cover the conjunctiva. Pseudomembranes consist of a combination of inflammatory cells and exudates, and are loosely adherent to the conjunctiva, while true membranes are more tightly adherent and cannot be easily peeled away. Cases of bacterial conjunctivitis that involve the production of membranes or pseudomembranes are associated with Neisseria gonorrhoeae, β-hemolytic streptococci, and C. diphtheriae. "Corynebacterium diphtheriae" causes membrane formation in conjunctiva of non-immunized children.
Chemical.
Chemical eye injury is due to either an acidic or alkali substance getting in the eye. Alkalis are typically worse than acidic burns. Mild burns will produce conjunctivitis, while more severe burns may cause the cornea to turn white. Litmus paper is an easy way to rule out the diagnosis by verifying that the pH is within the normal range of 7.0—7.2. Large volumes of irrigation is the treatment of choice and should continue until the pH is 6—8. Local anaesthetic eye drops can be used to decrease the pain.
Irritant or toxic conjunctivitis show primarily marked redness. If due to splash injury, it is often present in only the lower conjunctival sac. With some chemicals, above all with caustic alkalis such as sodium hydroxide, there may be necrosis of the conjunctiva with a deceptively white eye due to vascular closure, followed by sloughing of the dead epithelium. This is likely to be associated with slit-lamp evidence of anterior uveitis.
Other.
Inclusion conjunctivitis of the newborn (ICN) is a conjunctivitis that may be caused by the bacteria "Chlamydia trachomatis", and may lead to acute, purulent conjunctivitis. However, it is usually self-healing.
Conjunctivitis is identified by irritation and redness of the conjunctiva. Except in obvious pyogenic or toxic/chemical conjunctivitis, a slit lamp (biomicroscope) is needed to have any confidence in the diagnosis. Examination of the tarsal conjunctiva is usually more diagnostic than the bulbar conjunctiva.
Causes.
Conjunctivitis when caused by an infection is most commonly caused by a viral infection. Bacterial infections, allergies, other irritants and dryness are also common causes. Both bacterial and viral infections are contagious and passed from person to person, but can also spread through contaminated objects or water.
The most common cause of viral conjunctivitis is adenoviruses (see: Adenoviral keratoconjunctivitis). Herpetic keratoconjunctivitis (caused by herpes simplex viruses) can be serious and requires treatment with acyclovir. Acute hemorrhagic conjunctivitis is a highly contagious disease caused by one of two enteroviruses, Enterovirus 70 and Coxsackievirus A24. These were first identified in an outbreak in Ghana in 1969, and have spread worldwide since then, causing several epidemics.
The most common causes of acute bacterial conjunctivitis are "Staphylococcus aureus", "Streptococcus pneumoniae", and "Haemophilus influenzae". Though very rare, hyperacute cases are usually caused by "Neisseria gonorrhoeae" or "N. meningitidis". Chronic cases of bacterial conjunctivitis are those lasting longer than 3 weeks, and are typically caused by "Staphylococcus aureus", "Moraxella lacunata", or gram-negative enteric flora.
Conjunctivitis may also be caused by allergens such as pollen, perfumes, cosmetics, smoke, dust mites, Balsam of Peru, and eye drops.
Conjunctivitis is part of the triad of reactive arthritis, which is thought to be caused by autoimmune cross-reactivity following certain bacterial infections. Reactive arthritis is highly associated with HLA-B27. Conjunctivitis is associated with the autoimmune disease relapsing polychondritis.
Diagnosis.
Cultures are not often taken or needed as most cases resolve either with time or typical antibiotics. Swabs for bacterial culture are necessary if the history and signs suggest bacterial conjunctivitis but there is no response to topical antibiotics. Viral culture may be appropriate in epidemic case clusters.
A patch test is used to identify the causative allergen in the case where conjunctivitis is caused by allergy.
Conjunctival scrapes for cytology can be useful in detecting chlamydial and fungal infections, allergy, and dysplasia, but are rarely done because of the cost and the general lack of laboratory staff experienced in handling ocular specimens. Conjunctival incisional biopsy is occasionally done when granulomatous diseases ("e.g.", sarcoidosis) or dysplasia are suspected.
Classification.
Classification can be either by cause or by extent of the inflamed area.
By extent of involvement.
Blepharoconjunctivitis is the dual combination of conjunctivitis with blepharitis (inflammation of the eyelids).
Keratoconjunctivitis is the combination of conjunctivitis and keratitis (corneal inflammation).
Differential diagnosis.
There are more serious conditions that can present with a red eye such as infectious keratitis, angle closure glaucoma, or iritis. These conditions require the urgent attention of an ophthalmologist. Signs of such conditions include decreased vision, significantly increased sensitivity to light, inability to keep eye open, a pupil that does not respond to light, or a severe headache with nausea. Fluctuating blurring is common, due to tearing and mucoid discharge. Mild photophobia is common. However, if any of these symptoms are prominent, it is important to consider other diseases such as glaucoma, uveitis, keratitis and even meningitis or carotico-cavernous fistula.
A more comprehensive differential diagnosis for the red or painful eye includes:
Prevention.
The best effective prevention is hygiene and not rubbing the eyes by infected hands. Vaccination against adenovirus, haemophilus influenzae, pneumococcus, and neisseria meningitidis is also effective.
Povidone-iodine eye solution has been found to prevent conjunctivitis follow birth. As it is less expensive it is being more commonly used for this purpose globally.
Management.
Conjunctivitis resolves in 65% of cases without treatment, within two to five days. The prescription of antibiotics is not necessary in most cases.
Viral.
Viral conjunctivitis usually resolves on its own and does not require any specific treatment. Antihistamines (e.g., promethazine) or mast cell stabilizers (e.g., cromolyn) may be used to help with the symptoms. Povidone iodine has been suggested as a treatment, but as of 2008 evidence to support it was poor.
Allergic.
For the allergic type, cool water poured over the face with the head inclined downward constricts capillaries, and artificial tears sometimes relieve discomfort in mild cases. In more severe cases, nonsteroidal anti-inflammatory medications and antihistamines may be prescribed. Persistent allergic conjunctivitis may also require topical steroid drops.
Bacterial.
Bacterial conjunctivitis usually resolves without treatment. Topical antibiotics may be needed only if no improvement is observed after three days. In people who received no antibiotics, recovery was in 4.8 days, with immediate antibiotics it was 3.3 days, and with delayed antibiotics 3.9 days. No serious effects were noted either with or without treatment. As they do speed healing in bacterial conjunctivitis, their use is also reasonable.
In those who wear contact lenses, are immunocompromised, have disease which is thought to be due to chlamydia or gonorrhea, have a fair bit of pain, or who have lots of discharge, antibiotics are recommended. Gonorrhea or chlamydia infections require both oral and topical antibiotics.
When appropriate, the choice of antibiotic varies, differing based on the cause (if known) or the likely cause of the conjunctivitis. Fluoroquinolones, sodium sulfacetamide, or trimethoprim/polymyxin may be used, typically for 7–10 days. Cases of meningococcal conjunctivitis can be treated with systemic penicillin, as long as the strain is sensitive to penicillin.
When investigated as a treatment, Povidone-iodine ophthalmic solution has also been observed to have some effectiveness against bacterial and chlamydial conjunctivitis, with a possible role suggested in locations where topical antibiotics are unavailable or costly.
Chemical.
Conjunctivitis due to chemicals is treated via irrigation with Ringer's lactate or saline solution. Chemical injuries (particularly alkali burns) are medical emergencies, as they can lead to severe scarring and intraocular damage. People with chemically induced conjunctivitis should not touch their eyes, regardless of whether or not their hands are clean, as they run the risk of spreading the condition to another eye.
Epidemiology.
Conjunctivitis is the most common eye disease.
History.
A former superintendent of the Regional Institute of Ophthalmology in the city of Madras (the present-day Chennai) Tamil Nadu in India, Kirk Patrick, was the first to have found the adenovirus that caused conjunctivitis, leading to the name Madras eye for the disease.

</doc>
<doc id="44412" url="https://en.wikipedia.org/wiki?curid=44412" title="Sedimentary rock">
Sedimentary rock

Sedimentary rocks are types of rock that are formed by the deposition and subsequent cementation of that material at the Earth's surface and within bodies of water. Sedimentation is the collective name for processes that cause mineral and/or organic particles (detritus) to settle in place. The particles that form a sedimentary rock by accumulating are called sediment. Before being deposited, the sediment was formed by weathering and erosion from the source area, and then transported to the place of deposition by water, wind, ice, mass movement or glaciers, which are called agents of denudation. Sedimentation may also occur as minerals precipitate from water solution or shells of aquatic creatures settle out of suspension.
The sedimentary rock cover of the continents of the Earth's crust is extensive, but the total contribution of sedimentary rocks is estimated to be only 8% of the total volume of the crust. Sedimentary rocks are only a thin veneer over a crust consisting mainly of igneous and metamorphic rocks. Sedimentary rocks are deposited in layers as strata, forming a structure called bedding. The study of sedimentary rocks and rock strata provides information about the subsurface that is useful for civil engineering, for example in the construction of roads, houses, tunnels, canals or other structures. Sedimentary rocks are also important sources of natural resources like coal, fossil fuels, drinking water or ores.
The study of the sequence of sedimentary rock strata is the main source for an understanding of the Earth's history, including palaeogeography, paleoclimatology and the history of life. The scientific discipline that studies the properties and origin of sedimentary rocks is called sedimentology. Sedimentology is part of both geology and physical geography and overlaps partly with other disciplines in the Earth sciences, such as pedology, geomorphology, geochemistry and structural geology. Sedimentary rocks have also been found on Mars.
Classification based on origin.
Sedimentary rocks can be subdivided into four groups based on the processes responsible for their formation: clastic sedimentary rocks, biochemical (biogenic) sedimentary rocks, chemical sedimentary rocks, and a fourth category for "other" sedimentary rocks formed by impacts, volcanism, and other minor processes.
Clastic sedimentary rocks.
Clastic sedimentary rocks are composed of other rock fragments that were cemented by silicate minerals. Clastic rocks are composed largely of quartz, feldspar, rock (lithic) fragments, clay minerals, and mica; any type of mineral may be present, but they in general represent the minerals that exist locally.
Clastic sedimentary rocks, are subdivided according to the dominant particle size. Most geologists use the Udden-Wentworth grain size scale and divide unconsolidated sediment into three fractions: gravel (>2 mm diameter), sand (1/16 to 2 mm diameter), and mud (clay is <1/256 mm and silt is between 1/16 and 1/256 mm). The classification of clastic sedimentary rocks parallels this scheme; conglomerates and breccias are made mostly of gravel, sandstones are made mostly of sand, and mudrocks are made mostly of the finest material. This tripartite subdivision is mirrored by the broad categories of rudites, arenites, and lutites, respectively, in older literature.
The subdivision of these three broad categories is based on differences in clast shape:conglomerates and breccias), composition (sandstones), grain size and/or texture (mudrocks).
Conglomerates and breccias.
Conglomerates are dominantly composed of rounded gravel, while breccias are composed of dominantly angular gravel.
Sandstones.
Sandstone classification schemes vary widely, but most geologists have adopted the Dott scheme, which uses the relative abundance of quartz, feldspar, and lithic framework grains and the abundance of a muddy matrix between the larger grains.
Six sandstone names are possible using the descriptors for grain composition (quartz-, feldspathic-, and lithic-) and the amount of matrix (wacke or arenite). For example, a quartz arenite would be composed of mostly (>90%) quartz grains and have little or no clayey matrix between the grains, a lithic wacke would have abundant lithic grains and abundant muddy matrix, etc.
Although the Dott classification scheme is widely used by sedimentologists, common names like greywacke, arkose, and quartz sandstone are still widely used by non-specialists and in popular literature.
Mudrocks.
Mudrocks are sedimentary rocks composed of at least 50% silt- and clay-sized particles. These relatively fine-grained particles are commonly transported by turbulent flow in water or air, and deposited as the flow calms and the particles settle out of suspension.
Most authors presently use the term "mudrock" to refer to all rocks composed dominantly of mud. Mudrocks can be divided into siltstones, composed dominantly of silt-sized particles; mudstones with subequal mixture of silt- and clay-sized particles; and claystones, composed mostly of clay-sized particles. Most authors use "shale" as a term for a fissile mudrock (regardless of grain size) although some older literature uses the term "shale" as a synonym for mudrock.
Biochemical sedimentary rocks.
Biochemical sedimentary rocks are created when organisms use materials dissolved in air or water to build their tissue. Examples include:
Chemical sedimentary rocks.
Chemical sedimentary rock forms when mineral constituents in solution become supersaturated and inorganically precipitate. Common chemical sedimentary rocks include oolitic limestone and rocks composed of evaporite minerals, such as halite (rock salt), sylvite, barite and gypsum.
"Other" sedimentary rocks.
This fourth miscellaneous category includes rocks formed by Pyroclastic flows, impact breccias, volcanic breccias, and other relatively uncommon processes.
Compositional classification schemes.
Alternatively, sedimentary rocks can be subdivided into compositional groups based on their mineralogy:
Deposition and transformation.
Sediment transport and deposition.
Sedimentary rocks are formed when sediment is deposited out of air, ice, wind, gravity, or water flows carrying the particles in suspension. This sediment is often formed when weathering and erosion break down a rock into loose material in a source area. The material is then transported from the source area to the deposition area. The type of sediment transported depends on the geology of the hinterland (the source area of the sediment). However, some sedimentary rocks, such as evaporites, are composed of material that form at the place of deposition. The nature of a sedimentary rock, therefore, not only depends on the sediment supply, but also on the sedimentary depositional environment in which it formed.
Transformation (Diagenesis).
The term diagenesis is used to describe all the chemical, physical, and biological changes, exclusive of surface weathering, undergone by a sediment after its initial deposition. Some of those processes cause the sediment to consolidate into a compact, solid substance from the originally loose material. Young sedimentary rocks, especially those of Quaternary age (the most recent period of the geologic time scale) are often still unconsolidated. As sediment deposition builds up, the overburden (lithostatic) pressure rises, and a process known as lithification takes place.
Sedimentary rocks are often saturated with seawater or groundwater, in which minerals can dissolve, or from which minerals can precipitate. Precipitating minerals reduce the pore space in a rock, a process called cementation. Due to the decrease in pore space, the original connate fluids are expelled. The precipitated minerals form a cement and make the rock more compact and competent. In this way, loose clasts in a sedimentary rock can become "glued" together.
When sedimentation continues, an older rock layer becomes buried deeper as a result. The lithostatic pressure in the rock increases due to the weight of the overlying sediment. This causes compaction, a process in which grains mechanically reorganize. Compaction is, for example, an important diagenetic process in clay, which can initially consist of 60% water. During compaction, this interstitial water is pressed out of pore spaces. Compaction can also be the result of dissolution of grains by pressure solution. The dissolved material precipitates again in open pore spaces, which means there is a net flow of material into the pores. However, in some cases, a certain mineral dissolves and does not precipitate again. This process, called leaching, increases pore space in the rock.
Some biochemical processes, like the activity of bacteria, can affect minerals in a rock and are therefore seen as part of diagenesis. Fungi and plants (by their roots) and various other organisms that live beneath the surface can also influence diagenesis.
Burial of rocks due to ongoing sedimentation leads to increased pressure and temperature, which stimulates certain chemical reactions. An example is the reactions by which organic material becomes lignite or coal. When temperature and pressure increase still further, the realm of diagenesis makes way for metamorphism, the process that forms metamorphic rock.
Properties.
Color.
The color of a sedimentary rock is often mostly determined by iron, an element with two major oxides: iron(II) oxide and iron(III) oxide. Iron(II) oxide (FeO) only forms under low oxygen (anoxic) circumstances and gives the rock a grey or greenish colour. Iron(III) oxide (Fe2O3) in a richer iron environment is often found in the form of the mineral hematite and gives the rock a reddish to brownish colour. In arid continental climates rocks are in direct contact with the atmosphere, and oxidation is an important process, giving the rock a red or orange colour. Thick sequences of red sedimentary rocks formed in arid climates are called red beds. However, a red colour does not necessarily mean the rock formed in a continental environment or arid climate.
The presence of organic material can colour a rock black or grey. Organic material is formed from dead organisms, mostly plants. Normally, such material eventually decays by oxidation or bacterial activity. Under anoxic circumstances, however, organic material cannot decay and leaves a dark sediment, rich in organic material. This can, for example, occur at the bottom of deep seas and lakes. There is little water mixing in such environments, as a result oxygen from surface water is not brought down, and the deposited sediment is normally a fine dark clay. Dark rocks, rich in organic material, are therefore often shales.
Texture.
The size, form and orientation of clasts (the original pieces of rock) in a sediment is called its texture. The texture is a small-scale property of a rock, but determines many of its large-scale properties, such as the density, porosity or permeability.
The 3D orientation of the clasts is called the fabric of the rock. Between the clasts, the rock can be composed of a matrix (a cement) that consists of crystals of one or more precipitated minerals. The size and form of clasts can be used to determine the velocity and direction of current in the sedimentary environment that moved the clasts from their origin; fine, calcareous mud only settles in quiet water while gravel and larger clasts are moved only by rapidly moving water. The grain size of a rock is usually expressed with the Wentworth scale, though alternative scales are sometimes used. The grain size can be expressed as a diameter or a volume, and is always an average value – a rock is composed of clasts with different sizes. The statistical distribution of grain sizes is different for different rock types and is described in a property called the sorting of the rock. When all clasts are more or less of the same size, the rock is called 'well-sorted', and when there is a large spread in grain size, the rock is called 'poorly sorted'.
The form of the clasts can reflect the origin of the rock.
Coquina, a rock composed of clasts of broken shells, can only form in energetic water. The form of a clast can be described by using four parameters:
Chemical sedimentary rocks have a non-clastic texture, consisting entirely of crystals. To describe such a texture, only the average size of the crystals and the fabric are necessary.
Mineralogy.
Most sedimentary rocks contain either quartz (especially siliciclastic rocks) or calcite (especially carbonate rocks). In contrast to igneous and metamorphic rocks, a sedimentary rock usually contains very few different major minerals. However, the origin of the minerals in a sedimentary rock is often more complex than in an igneous rock. Minerals in a sedimentary rock can have formed by precipitation during sedimentation or by diagenesis. In the second case, the mineral precipitate can have grown over an older generation of cement. A complex diagenetic history can be studied by optical mineralogy, using a petrographic microscope.
Carbonate rocks dominantly consist of carbonate minerals such as calcite, aragonite or dolomite. Both the cement and the clasts (including fossils and ooids) of a carbonate sedimentary rock can consist of carbonate minerals. The mineralogy of a clastic rock is determined by the material supplied by the source area, the manner of its transport to the place of deposition and the stability of that particular mineral. The resistance of rock forming minerals to weathering is expressed by Bowen's reaction series. In this series, quartz is the most stable, followed by feldspar, micas, and finally other less stable minerals that are only present when little weathering has occurred. The amount of weathering depends mainly on the distance to the source area, the local climate and the time it took for the sediment to be transported to the point where it is deposited. In most sedimentary rocks, mica, feldspar and less stable minerals have been reduced to clay minerals like kaolinite, illite or smectite.
Fossils.
Among the three major types of rock, fossils are most commonly found in sedimentary rock. Unlike most igneous and metamorphic rocks, sedimentary rocks form at temperatures and pressures that do not destroy fossil remnants. Often these fossils may only be visible under magnification.
Dead organisms in nature are usually quickly removed by scavengers, bacteria, rotting and erosion, but sedimentation can contribute to exceptional circumstances where these natural processes are unable to work, causing fossilisation. The chance of fossilisation is higher when the sedimentation rate is high (so that a carcass is quickly buried), in anoxic environments (where little bacterial activity occurs) or when the organism had a particularly hard skeleton. Larger, well-preserved fossils are relatively rare.
Fossils can be both the direct remains or imprints of organisms and their skeletons. Most commonly preserved are the harder parts of organisms such as bones, shells, and the woody tissue of plants. Soft tissue has a much smaller chance of being fossilized, and the preservation of soft tissue of animals older than 40 million years is very rare. Imprints of organisms made while they were still alive are called trace fossils, examples of which are burrows, footprints, etc.
As a part of a sedimentary or metamorphic rock, fossils undergo the same diagenetic processes as does the containing rock. A shell consisting of calcite can, for example, dissolve while a cement of silica then fills the cavity. In the same way, precipitating minerals can fill cavities formerly occupied by blood vessels, vascular tissue or other soft tissues. This preserves the form of the organism but changes the chemical composition, a process called permineralization. The most common minerals involved in permineralization are cements of carbonates (especially calcite), forms of amorphous silica (chalcedony, flint, chert) and pyrite. In the case of silica cements, the process is called lithification.
At high pressure and temperature, the organic material of a dead organism undergoes chemical reactions in which volatiles such as water and carbon dioxide are expulsed. The fossil, in the end, consists of a thin layer of pure carbon or its mineralized form, graphite. This form of fossilisation is called carbonisation. It is particularly important for plant fossils. The same process is responsible for the formation of fossil fuels like lignite or coal.
Primary sedimentary structures.
Structures in sedimentary rocks can be divided into 'primary' structures (formed during deposition) and 'secondary' structures (formed after deposition). Unlike textures, structures are always large-scale features that can easily be studied in the field. Sedimentary structures can indicate something about the sedimentary environment or can serve to tell which side originally faced up where tectonics have tilted or overturned sedimentary layers.
Sedimentary rocks are laid down in layers called beds or strata. A bed is defined as a layer of rock that has a uniform lithology and texture. Beds form by the deposition of layers of sediment on top of each other. The sequence of beds that characterizes sedimentary rocks is called bedding. Single beds can be a couple of centimetres to several meters thick. Finer, less pronounced layers are called laminae, and the structure it forms in a rock is called lamination. Laminae are usually less than a few centimetres thick. Though bedding and lamination are often originally horizontal in nature, this is not always the case. In some environments, beds are deposited at a (usually small) angle. Sometimes multiple sets of layers with different orientations exist in the same rock, a structure called cross-bedding. Cross-bedding forms when small-scale erosion occurs during deposition, cutting off part of the beds. Newer beds then form at an angle to older ones.
The opposite of cross-bedding is parallel lamination, where all sedimentary layering is parallel. Differences in laminations are generally caused by cyclic changes in the sediment supply, caused, for example, by seasonal changes in rainfall, temperature or biochemical activity. Laminae that represent seasonal changes (similar to tree rings) are called varves. Any sedimentary rock composed of millimeter or finer scale layers can be named with the general term "laminite". When sedimentary rocks have no lamination at all, their structural character is called massive bedding.
Graded bedding is a structure where beds with a smaller grain size occur on top of beds with larger grains. This structure forms when fast flowing water stops flowing. Larger, heavier clasts in suspension settle first, then smaller clasts. Although graded bedding can form in many different environments, it is a characteristic of turbidity currents.
The surface of a particular bed, called the bedform, can be indicative of a particular sedimentary environment, too. Examples of bed forms include dunes and ripple marks. Sole markings, such as tool marks and flute casts, are groves dug into a sedimentary layer that are preserved. These are often elongated structures and can be used to establish the direction of the flow during deposition.
Ripple marks also form in flowing water. There are two types of ripples: symmetric and asymmetric. Environments where the current is in one direction, such as rivers, produce asymmetric ripples. The longer flank of such ripples is on the upstream side of the current. Symmetric wave ripples occur in environments where currents reverse directions, such as tidal flats.
Mudcracks are a bed form caused by the dehydration of sediment that occasionally comes above the water surface. Such structures are commonly found at tidal flats or point bars along rivers.
Secondary sedimentary structures.
Secondary sedimentary structures are those which formed after deposition. Such structures form by chemical, physical and biological processes within the sediment. They can be indicators of circumstances after deposition. Some can be used as way up criteria.
Organic materials in a sediment can leave more traces than just fossils. Preserved tracks and burrows are examples of trace fossils (also called ichnofossils). Such traces are relatively rare. Most trace fossils are burrows of molluscs or arthropods. This burrowing is called bioturbation by sedimentologists. It can be a valuable indicator of the biological and ecological environment that existed after the sediment was deposited. On the other hand, the burrowing activity of organisms can destroy other (primary) structures in the sediment, making a reconstruction more difficult.
Secondary structures can also form by diagenesis or the formation of a soil (pedogenesis) when a sediment is exposed above the water level. An example of a diagenetic structure common in carbonate rocks is a stylolite. Stylolites are irregular planes where material was dissolved into the pore fluids in the rock. This can result in the precipitation of a certain chemical species producing colouring and staining of the rock, or the formation of concretions. Concretions are roughly concentric bodies with a different composition from the host rock. Their formation can be the result of localized precipitation due to small differences in composition or porosity of the host rock, such as around fossils, inside burrows or around plant roots. In carbonate based rocks such as limestone or chalk, chert or flint concretions are common, while terrestrial sandstones can have iron concretions. Calcite concretions in clay are called septarian concretions.
After deposition, physical processes can deform the sediment, producing a third class of secondary structures. Density contrasts between different sedimentary layers, such as between sand and clay, can result in flame structures or load casts, formed by inverted diapirism. While the clastic bed is still fluid, diapirism can cause a denser upper layer to sink into a lower layer. Sometimes, density contrasts can result or grow when one of the lithologies dehydrates. Clay can be easily compressed as a result of dehydration, while sand retains the same volume and becomes relatively less dense. On the other hand, when the pore fluid pressure in a sand layer surpasses a critical point, the sand can break through overlying clay layers and flow through, forming discordant bodies of sedimentary rock called sedimentary dykes. The same process can form mud volcanoes on the surface where they broke through upper layers.
Sedimentary dykes can also be formed in a cold climate where the soil is permanently frozen during a large part of the year. Frost weathering can form cracks in the soil that fill with rubble from above. Such structures can be used as climate indicators as well as way up structures.
Density contrasts can also cause small-scale faulting, even while sedimentation progresses (synchronous-sedimentary faulting). Such faulting can also occur when large masses of non-lithified sediment are deposited on a slope, such as at the front side of a delta or the continental slope. Instabilities in such sediments can result in the deposited material to slump, producing fissures and folding. The resulting structures in the rock are syn-sedimentary folds and faults, which can be difficult to distinguish from folds and faults formed by tectonic forces acting on lithified rocks.
Sedimentary environments.
The setting in which a sedimentary rock forms is called the sedimentary environment. Every environment has a characteristic combination of geologic processes and circumstances. The type of sediment that is deposited is not only dependent on the sediment that is transported to a place, but also on the environment itself.
A marine environment means that the rock was formed in a sea or ocean. Often, a distinction is made between deep and shallow marine environments. Deep marine usually refers to environments more than 200 m below the water surface. Shallow marine environments exist adjacent to coastlines and can extend to the boundaries of the continental shelf. The water movements in such environments have a generally higher energy than that in deep environments, as wave activity diminishes with depth. This means that coarser sediment particles can be transported and the deposited sediment can be coarser than in deeper environments. When the sediment is transported from the continent, an alternation of sand, clay and silt is deposited. When the continent is far away, the amount of such sediment deposited may be small, and biochemical processes dominate the type of rock that forms. Especially in warm climates, shallow marine environments far offshore mainly see deposition of carbonate rocks. The shallow, warm water is an ideal habitat for many small organisms that build carbonate skeletons. When these organisms die, their skeletons sink to the bottom, forming a thick layer of calcareous mud that may lithify into limestone. Warm shallow marine environments also are ideal environments for coral reefs, where the sediment consists mainly of the calcareous skeletons of larger organisms.
In deep marine environments, the water current working the sea bottom is small. Only fine particles can be transported to such places. Typically sediments depositing on the ocean floor are fine clay or small skeletons of micro-organisms. At 4 km depth, the solubility of carbonates increases dramatically (the depth zone where this happens is called the lysocline). Calcareous sediment that sinks below the lysocline dissolves, as a result no limestone can be formed below this depth. Skeletons of micro-organisms formed of silica (such as radiolarians) are not as soluble and still deposit. An example of a rock formed of silica skeletons is radiolarite. When the bottom of the sea has a small inclination, for example at the continental slopes, the sedimentary cover can become unstable, causing turbidity currents. Turbidity currents are sudden disturbances of the normally quite deep marine environment and can cause the geologically speaking instantaneous deposition of large amounts of sediment, such as sand and silt. The rock sequence formed by a turbidity current is called a turbidite.
The coast is an environment dominated by wave action. At a beach, dominantly denser sediment such as sand or gravel, often mingled with shell fragments, is deposited, while the silt and clay sized material is kept in mechanical suspension. Tidal flats and shoals are places that sometimes dry because of the tide. They are often cross-cut by gullies, where the current is strong and the grain size of the deposited sediment is larger. Where rivers enter the body of water, either on a sea or lake coast, deltas can form. These are large accumulations of sediment transported from the continent to places in front of the mouth of the river. Deltas are dominantly composed of clastic sediment (in contrast to chemical).
A sedimentary rock formed on land has a continental sedimentary environment. Examples of continental environments are lagoons, lakes, swamps, floodplains and alluvial fans. In the quiet water of swamps, lakes and lagoons, fine sediment is deposited, mingled with organic material from dead plants and animals. In rivers, the energy of the water is much greater and can transport heavier clastic material. Besides transport by water, sediment can in continental environments also be transported by wind or glaciers. Sediment transported by wind is called aeolian and is always very well sorted, while sediment transported by a glacier is called glacial till and is characterized by very poor sorting.
Aeolian deposits can be quite striking. The depositional environment of the Touchet Formation, located in the Northwestern United States, had intervening periods of aridity which resulted in a series of rhythmite layers. Erosional cracks were later infilled with layers of soil material, especially from aeolian processes. The infilled sections formed vertical inclusions in the horizontally deposited layers of the Touchet Formation, and thus provided evidence of the events that intervened over time among the forty-one layers that were deposited.
Sedimentary facies.
Sedimentary environments usually exist alongside each other in certain natural successions. A beach, where sand and gravel is deposited, is usually bounded by a deeper marine environment a little offshore, where finer sediments are deposited at the same time. Behind the beach, there can be dunes (where the dominant deposition is well sorted sand) or a lagoon (where fine clay and organic material is deposited). Every sedimentary environment has its own characteristic deposits. The typical rock formed in a certain environment is called its sedimentary facies. When sedimentary strata accumulate through time, the environment can shift, forming a change in facies in the subsurface at one location. On the other hand, when a rock layer with a certain age is followed laterally, the lithology (the type of rock) and facies eventually change.
Facies can be distinguished in a number of ways: the most common are by the lithology (for example: limestone, siltstone or sandstone) or by fossil content. Coral for example only lives in warm and shallow marine environments and fossils of coral are thus typical for shallow marine facies. Facies determined by lithology are called lithofacies; facies determined by fossils are biofacies.
Sedimentary environments can shift their geographical positions through time. Coastlines can shift in the direction of the sea when the sea level drops, when the surface rises due to tectonic forces in the Earth's crust or when a river forms a large delta. In the subsurface, such geographic shifts of sedimentary environments of the past are recorded in shifts in sedimentary facies. This means that sedimentary facies can change either parallel or perpendicular to an imaginary layer of rock with a fixed age, a phenomenon described by Walther's Law.
The situation in which coastlines move in the direction of the continent is called transgression. In the case of transgression, deeper marine facies are deposited over shallower facies, a succession called onlap. Regression is the situation in which a coastline moves in the direction of the sea. With regression, shallower facies are deposited on top of deeper facies, a situation called offlap.
The facies of all rocks of a certain age can be plotted on a map to give an overview of the palaeogeography. A sequence of maps for different ages can give an insight in the development of the regional geography.
Sedimentary basins.
Places where large-scale sedimentation takes place are called sedimentary basins. The amount of sediment that can be deposited in a basin depends on the depth of the basin, the so-called accommodation space. The depth, shape and size of a basin depend on tectonics, movements within the Earth's lithosphere. Where the lithosphere moves upward (tectonic uplift), land eventually rises above sea level, so that and erosion removes material, and the area becomes a source for new sediment. Where the lithosphere moves downward (tectonic subsidence), a basin forms and sedimentation can take place. When the lithosphere keeps subsiding, new accommodation space keeps being created.
A type of basin formed by the moving apart of two pieces of a continent is called a rift basin. Rift basins are elongated, narrow and deep basins. Due to divergent movement, the lithosphere is stretched and thinned, so that the hot asthenosphere rises and heats the overlying rift basin. Apart from continental sediments, rift basins normally also have part of their infill consisting of volcanic deposits. When the basin grows due to continued stretching of the lithosphere, the rift grows and the sea can enter, forming marine deposits.
When a piece of lithosphere that was heated and stretched cools again, its density rises, causing isostatic subsidence. If this subsidence continues long enough, the basin is called a sag basin. Examples of sag basins are the regions along passive continental margins, but sag basins can also be found in the interior of continents. In sag basins, the extra weight of the newly deposited sediments is enough to keep the subsidence going in a vicious circle. The total thickness of the sedimentary infill in a sag basins can thus exceed 10 km.
A third type of basin exists along convergent plate boundaries - places where one tectonic plate moves under another into the asthenosphere. The subducting plate bends and forms a fore-arc basin in front of the overriding plate—an elongated, deep asymmetric basin. Fore-arc basins are filled with deep marine deposits and thick sequences of turbidites. Such infill is called flysch. When the convergent movement of the two plates results in continental collision, the basin becomes shallower and develops into a foreland basin. At the same time, tectonic uplift forms a mountain belt in the overriding plate, from which large amounts of material are eroded and transported to the basin. Such erosional material of a growing mountain chain is called molasse and has either a shallow marine or a continental facies.
At the same time, the growing weight of the mountain belt can cause isostatic subsidence in the area of the overriding plate on the other side to the mountain belt. The basin type resulting from this subsidence is called a back-arc basin and is usually filled by shallow marine deposits and molasse.
Influence of astronomical cycles.
In many cases facies changes and other lithological features in sequences of sedimentary rock have a cyclic nature. This cyclic nature was caused by cyclic changes in sediment supply and the sedimentary environment. Most of these cyclic changes are caused by astronomic cycles. Short astronomic cycles can be the difference between the tides or the spring tide every two weeks. On a larger time-scale, cyclic changes in climate and sea level are caused by Milankovitch cycles: cyclic changes in the orientation and/or position of the Earth's rotational axis and orbit around the Sun. There are a number of Milankovitch cycles known, lasting between 10,000 and 200,000 years.
Relatively small changes in the orientation of the Earth's axis or length of the seasons can be a major influence on the Earth's climate. An example are the ice ages of the past 2.6 million years (the Quaternary period), which are assumed to have been caused by astronomic cycles. Climate change can influence the global sea level (and thus the amount of accommodation space in sedimentary basins) and sediment supply from a certain region. Eventually, small changes in astronomic parameters can cause large changes in sedimentary environment and sedimentation.
Sedimentation rates.
The rate at which sediment is deposited differs depending on the location. A channel in a tidal flat can see the deposition of a few metres of sediment in one day, while on the deep ocean floor each year only a few millimetres of sediment accumulate. A distinction can be made between normal sedimentation and sedimentation caused by catastrophic processes. The latter category includes all kinds of sudden exceptional processes like mass movements, rock slides or flooding. Catastrophic processes can see the sudden deposition of a large amount of sediment at once. In some sedimentary environments, most of the total column of sedimentary rock was formed by catastrophic processes, even though the environment is usually a quiet place. Other sedimentary environments are dominated by normal, ongoing sedimentation.
In many cases, sedimentation occurs slowly. In a desert, for example, the wind deposits siliciclastic material (sand or silt) in some spots, or catastrophic flooding of a wadi may cause sudden deposits of large quantities of detrital material, but in most places eolian erosion dominates. The amount of sedimentary rock that forms is not only dependent on the amount of supplied material, but also on how well the material consolidates. Erosion removes most deposited sediment shortly after deposition.
Stratigraphy.
That new rock layers are above older rock layers is stated in the principle of superposition. There are usually some gaps in the sequence called unconformities. These represent periods where no new sediments were laid down, or when earlier sedimentary layers were raised above sea level and eroded away.
Sedimentary rocks contain important information about the history of the Earth. They contain fossils, the preserved remains of ancient plants and animals. Coal is considered a type of sedimentary rock. The composition of sediments provides us with clues as to the original rock. Differences between successive layers indicate changes to the environment over time. Sedimentary rocks can contain fossils because, unlike most igneous and metamorphic rocks, they form at temperatures and pressures that do not destroy fossil remains.

</doc>
<doc id="44417" url="https://en.wikipedia.org/wiki?curid=44417" title="Senate">
Senate

A Senate is a deliberative assembly, often the upper house or chamber of a bicameral legislature or parliament. The name comes from the ancient Roman Senate (Latin: "Senatus"), so-called as an assembly of the senior (Latin: "senex" meaning "the elder" or "the old one") and therefore allegedly wiser and more experienced members of the society or ruling class.
Thus, the literal meaning of the word "senate" is: Assembly of Elders.
Many countries have an assembly named a "senate", composed of "senators" who may be elected, appointed, have inherited the title, or gained membership by other methods, depending on the country. Modern senates typically serve to provide a chamber of "sober second thought" to consider legislation passed by a lower house, whose members are usually elected.
Overview.
The modern word "senate" is derived from the word "senātus" (senate), which comes from "senex", “old man”. The members or legislators of a senate are called senators. The Latin word "senator" was adopted into English with no change in spelling. Its meaning is derived from a very ancient form of social organization, in which advisory or decision-making powers are reserved for the eldest men. For the same reason, the word "senate" is correctly used when referring to any powerful authority characteristically composed by the eldest members of a community, as a deliberative body of a faculty in an institution of higher learning is often called a senate. This form adaptation was used to show the power of those in body and for the decision-making process to be thorough, which could take a long period of time. The original senate was the Roman Senate, which lasted until 580 (various efforts to revive it were made in Medieval Rome). In the Eastern Roman Empire, the Byzantine Senate continued until the Fourth Crusade, circa 1202–1204.
Modern democratic states with bicameral parliamentary systems are sometimes equipped with a senate, often distinguished from an ordinary parallel lower house, known variously as the “House of Representatives”, “House of Commons”, “Chamber of Deputies”, “National Assembly”, “Legislative Assembly”, or "House of Assembly", by electoral rules. This may include minimum age required for voters and candidates, proportional or majoritarian or plurality system, and an electoral basis or "collegium". Typically, the senate is referred to as the upper house and has a smaller membership than the lower house. In some federal states senates also exist at the subnational level. In the United States all states with the exception of Nebraska (whose legislature is a unicameral body called the “Legislature” but whose members refer to themselves as “senators”) have a state senate. There is also the US Senate at the federal level. 
Similarly in Argentina, in addition to the Senate at federal level, eight of the country's provinces, Buenos Aires, Catamarca, Corrientes, Entre Ríos, Mendoza, Salta, San Luis (since 1987) and Santa Fe, have bicameral legislatures with a Senate. Córdoba and Tucumán changed to unicameral systems in 2001 and 2003 respectively.
In Australia and Canada, only the upper house of the federal parliament is known as the Senate. All states other than Queensland have an upper house known as a Legislative council. Several Canadian provinces also once had a Legislative Council, but these have all been abolished, the last being Quebec's Legislative council in 1968.
In Germany, the last Senate of a State parliament, the Senate of Bavaria, was abolished in 1999.
Senate membership can be determined either through elections or appointments. For example, elections are held every three years for half the membership of the Australian Senate, the term of a senator being six years. In contrast, members of the Canadian Senate are appointed by the Governor General upon the recommendation of the Prime Minister of Canada, holding the office until they resign, are removed, or retire at the mandatory age of 75.
Alternative meanings.
The terms Senate and Senator, however, do not necessarily refer to a second chamber of a legislature:
In the "Bundesländer" (Federated States) of Germany which form a City State (in German: "Stadtstaat"), i.e. Berlin (Senate of Berlin), Bremen (Senate of Bremen) and Hamburg (Senate of Hamburg), the Senates ("Senat" in German) are the executive branch, with Senator ("Senator") being the holders of ministerial portfolios.
In a number of cities which were former members of the "Hanse" (a medieval confederacy of port cities mainly at the shores of the Baltic Sea and the North Sea), such as Greifswald, Lübeck, Rostock, Stralsund, or Wismar, the city government is also called a Senate.
However, in Bavaria, the Senate was a second legislative chamber until its abolition in 1999.
The term Senat (senate) in higher courts of appeal refers to the "bench" in its broader metonymy meaning, describing members of the judiciary collectively (usually five judges), often occupied with a particular subject-matter jurisdiction. However, the judges are not called "senators". The German term "Strafsenat" (literally "Penal Senate") in a German court translates to "Bench of penal-law jurisdiction" and "Zivilsenat" (literally "Civil Senate") to "Bench of private-law jurisdiction". The Federal Constitutional Court of Germany consists of two senates of eight judges each. In its case the division is mostly of an organizational nature, as a matter of dividing the work load; both senates handle the same kind of constitutional cases. At some points in the past, one senate was considered more conservative and the other more liberal, but that is not the case as of 2011.
Defunct senates.
Notes

</doc>
<doc id="44418" url="https://en.wikipedia.org/wiki?curid=44418" title="Deliberative assembly">
Deliberative assembly

A deliberative assembly is a gathering of members who use parliamentary procedure to make decisions. 
History of term.
In a speech to the electorate at Bristol in 1774, Edmund Burke described the British Parliament as a "deliberative assembly," and the expression became the basic term for a body of persons meeting to discuss and determine common action.
Characteristics.
"Robert's Rules of Order Newly Revised" describes the following characteristics of a deliberative assembly:
Rights of members.
A member of a deliberative assembly has the right to attend meetings, make motions, speak in debate, and vote. Organizations may have different classes of members (such as regular members, active members, associate members, and honorary members), but the rights of each class of membership must be defined (such as whether a "member" in a class has the right to vote). There may also be ex-officio members, or persons who are members by virtue of some other office or position they hold. Ex-officio members have the same rights as other members.
Types.
"Robert's Rules of Order Newly Revised" identifies several types of deliberative assemblies.
Mass meeting.
A "mass meeting", which is an unorganized group meeting open to all individuals in a sector of the population who are interested in deliberating about a subject proposed by the meeting's sponsors. Examples include meetings to discuss common political concerns or community interests.
Local assembly of an organized society.
A "local assembly of an organized society", which is a membership meeting of a local chapter or branch of a membership organization. Examples include local chapter meetings of organizations like the Sierra Club.
Convention.
A "convention", which is a meeting of delegates who represent constituent units of a population. Conventions are not permanently established bodies, and delegates are normally elected for only one term. A convention may be held by an organized society, where each local assembly is represented by a delegate.
Legislative body.
A "legislative body", which is a legally established public lawmaking body. It consists of representatives chosen by the electorate. Examples include congresses, state legislatures, and city councils.
Board.
A "board", which is an administrative, managerial, or quasi-judicial body. A board derives its power from an outside authority that defines the scope of its operations. Examples include an organized society's or company's board of directors and government agency boards like a board of education.
Committees.
A "committee" is a body of one or more persons subordinate to a deliberative assembly. A committee is not itself considered to be a form of assembly.

</doc>
<doc id="44419" url="https://en.wikipedia.org/wiki?curid=44419" title="Robert's Rules of Order">
Robert's Rules of Order

""'Robert's Rules of Order is the short title of a book, written by Henry Martyn Robert, that is intended to be a guide for conducting meetings and making decisions as a group.
Originally published in 1876, it has been revised regularly through the years, including two major revisions, by Robert and his successors based on feedback from users. The most recent version is the 11th Edition published in 2011 under the name Robert's Rules of Order Newly Revised (abbreviated RONR""').
This book has details on the types of groups that use it, the ways that decisions could be made, and the various situations in which decisions are made.
Several resources, including an official concise guide and information on the official website, have been released by Robert's successors to help the many different organizations and groups that use the book.
History and origins.
The first edition of the book, whose full title was "Pocket Manual of Rules of Order for Deliberative Assemblies", was published in February 1876 by then U.S. Army Major Henry Martyn Robert (1837–1923) with the short title "Robert's Rules of Order" placed on its cover.
The procedures prescribed by the book were loosely modeled after those used in the United States House of Representatives, with such adaptations as Robert saw fit for use in ordinary societies. Although he was in the military, the rules in his book were not based on military rules. The author's interest in parliamentary procedure began in 1863 when he was chosen to preside over a church meeting and, although he accepted the task, he felt that he did not have the necessary knowledge of proper procedure.
In his later work as an active member of several organizations, Robert discovered that members from different areas of the country had very different views regarding what the proper parliamentary rules were, and these conflicting views hampered the organizations in their work. He eventually became convinced of the need for a new manual on the subject, one which would enable many organizations to adopt the same set of rules.
Official editions and other versions.
Official editions.
The following three tables list the official versions of the body of work known as "Robert's Rules of Order" developed by Henry M. Robert and maintained by his successors. The formal titles of the books appear above the editions they refer to (also see List of books with Robert's Rules in the title). Each successive edition was intended to supersede the previous editions.
Pocket Manual of Rules of Order for Deliberative Assemblies (cover short title: "Robert's Rules of Order")
"Robert's Rules of Order Revised
Robert's Rules of Order Newly Revised""'
Henry M. Robert himself published the first four editions before his death in 1923, the last being the thoroughly revised and expanded Fourth Edition published as "Robert's Rules of Order Revised" in May 1915. By this time Robert had long been retired from the Army with the rank of brigadier general. The revisions were based on the feedback from hundreds of letters that Robert had received through the years. In addition, to explain the rules in "Robert's Rules of Order Revised" (abbreviated ROR), Robert published an introductory book for beginners titled "Parliamentary Practice: An Introduction to Parliamentary Law" in 1921 and a full book of explanations titled "Parliamentary Law" in 1923.
Through a family trust, and later through the Robert's Rules Association (which is made up of descendants of Henry M. Robert), several subsequent editions of Robert's Rules of Order have been published, including another major revision of the work. The Seventh Edition, published in February 1970 on the 94th anniversary of the publication of the First Edition, was the first under the title "Robert's Rules of Order Newly Revised" (RONR). The subsequent editions were based on additional feedback from users, including feedback received by electronic means in recent years. These later editions included material from Robert's "Parliamentary Practice" and "Parliamentary Law".
The current edition of the series became effective on September 23, 2011 under the title "Robert's Rules of Order Newly Revised", Eleventh Edition. This edition states that it:
The authorship team of the current Eleventh Edition consists of a grandson of General Robert, an attorney, a lobbyist and legislative analyst, a mathematics professor, and a copy editor, all of them being experienced parliamentarians.
More than five and a half million copies have been printed (which is a total of all editions).
"In Brief" version.
Henry M. Robert III, grandson of the original author and Trustee for the Robert's Rules Association, had acknowledged that "there has been controversy among parliamentarians concerning the length of "Robert's Rules" in its various editions and the complexity of the rules it describes." As a result, a supplemental book was developed.
In 2005, a shorter reference guide, "Robert's Rules of Order Newly Revised In Brief" (abbreviated RONRIB), was published by the same authorship team and publisher as the Tenth Edition of "Robert's Rules of Order Newly Revised" (RONR) and was made to be in accord with that edition of RONR. A second edition of this shorter guide was published in 2011 to conform with the current Eleventh Edition of "Robert's Rules of Order Newly Revised".
The "In Brief" book is the only authorized concise guide for "Robert's Rules of Order Newly Revised" and is intended as an introductory book for those unfamiliar with parliamentary procedure. The authors say, "In only twenty minutes, the average reader can learn the bare essentials, and with about an hour's reading can cover all the basics." It is meant to be an introductory supplement to the current edition of "Robert's Rules of Order Newly Revised" and is not suitable for adoption as a parliamentary authority in itself.
Other variations.
Since the copyrights for several of the original editions (1915 or earlier) have expired, numerous other books and manuals have been published incorporating "Robert's Rules of Order" as part of their titles, with some of them based on those earlier editions (see List of books with Robert's Rules in the title).
The existence of multiple editions and other variations, all published as "Robert's Rules of Order", can sometimes cause confusion, as the various publications may differ in some details.
If an organization has adopted "Robert's Rules of Order", the current edition of "Robert's Rules of Order Newly Revised" is automatically its reference authority unless another version was adopted explicitly. The most recent edition of "Robert's Rules of Order Newly Revised" (i.e. the 11th edition published in 2011) is the only current official version of the body of work known as "Robert's Rules of Order".
Explanation of purpose of book.
Generally, "Robert's Rules of Order" is a guide for conducting meetings and making decisions as a group. The purpose of the book is "to enable assemblies of any size, with due regard for every member's opinion, to arrive at the general will on the maximum number of questions of varying complexity in a minimum amount of time and under all kinds of internal climate ranging from total harmony to hardened or impassioned division of opinion."
The book is designed for use in ordinary societies rather than legislative assemblies, and it is the most commonly adopted parliamentary authority among societies in the United States. It is also recognized as "the most widely used reference for meeting procedure and business rules in the English-speaking world."
The book states that it is "a codification of the present-day general parliamentary law". "General parliamentary law" refers to the common rules and customs for conducting business in organizations and assemblies. It does not refer to statutory legal requirements nor to common-law precedent derived from court judgments. In other words, the book is about procedures for meetings and not about what is "legal" (i.e. it is not a law book).
As a reference, it is designed to answer, as nearly as possible, any question of parliamentary procedure that may arise. The Eleventh Edition contains 669 pages of text, and all of its original content was included because it "has at some time come up as a question of procedure somewhere". The completeness of the book was made so that organizations would not have to write extensive rules for themselves. In addition, members of different organizations could refer to the same book of rules.
If an assembly or society has adopted a book of rules (such as "Robert's Rules of Order") for conducting its meetings, it is still free to adopt its own rules which supersede any rules in the adopted book with which they conflict. The only limitations might come from the rules in a parent organization or from national, state, or local law. Otherwise, the rules in the book are binding on the society.
If an assembly has not formally adopted a particular manual as its parliamentary authority, the provisions of any manual can be cited as "persuasive" in such a situation.
Contents of current (11th) edition.
The contents of the current (11th) edition of "Robert's Rules of Order Newly Revised" (RONR), published in 2011, include details on the types of groups that use the book, the ways that decisions could be made, and the various situations in which decisions are made.
The Basics.
The Introduction in the book provides a history of parliamentary procedure and includes the background and history of Robert's Rules of Order. Rules in the book are based on the rights of the majority, of the minority (especially a strong minority that is greater than one third), of individual members, of absentees, and of all these together. Some fundamental principles upon which the book is based include: one question at a time; one person, one vote; and a vote being limited to members present.
A group that uses the book is called a deliberative assembly. The types of deliberative assemblies are a mass meeting, a local assembly of an organized society (local club or local branch), a convention, a legislative body, and a board. An organization may have rules which could include a corporate charter, a constitution or bylaws, rules of order (special rules of order and parliamentary authority), standing rules, and customs. To conduct business, groups have meetings or sessions that may be separated by more than or be within a quarterly time interval. The types of meetings are a regular meeting, a special meeting, an adjourned meeting, an annual meeting, an executive session, a public session, and electronic meetings.
A member of a deliberative assembly has the right to attend meetings, make motions, speak in debate, and vote. The process of making a decision is done through a motion, which is a proposal to do something. The formal steps in handling a motion are the making of a motion, having a second, stating the motion, having debate on the motion, putting the motion to a vote, and announcing the results of the vote. Action could be taken informally without going through these steps by using unanimous consent. When making a choice, the basic principle of decision is majority vote. In situations when more than majority vote is required, the requirement could include a two-thirds vote, previous notice, or a vote of a majority of the entire membership.
Motions.
The book provides details about main motions including the motion to ratify. In addition, the book lists other motions and provides details (including explanations, forms, and examples) on these motions which include: 
Details for each motion include its purpose, when it could be made, if it is debatable, if it is amendable, the vote required for adoption, and if it could be reconsidered. The "order of precedence", or rank, of the motions is also described in detail.
Various topics.
The second half of the book covers various topics in detail. Brief summaries of these topics are as follows:
Depending on the situation, motions could be renewed, or made again. On the other hand, members should not use legitimate motions for dilatory and improper purposes to waste time.
A quorum, or minimum number of members, is required to be present at a meeting in order to validly conduct business. The business that is to come up in a meeting could be listed in an order of business or an agenda.
Each member could get a chance to speak through assignment of the floor and debate. Debate may be limited in the number of speeches and time and should be respectful to others at all times. Voting takes place to decide the course of action and it could be done in a multitude of ways, such as voice vote, standing vote, and ballot vote.
Officers in an organization could be elected through the process of nominations and elections. Each organization decides for itself which officers to have, but the minimum officers in a deliberative assembly are a presiding officer (usually "president" or "chairman") and a secretary. The secretary keeps the minutes, or the official records of the proceedings, for each meeting. As part of their duties, the officers may have reports to give, such as a financial report given by the treasurer. In addition, an organization may have a board to handle business on behalf of the organization. Officers and boards only have such authority and powers that are given to them in the governing documents of the organization. There may also be committees that are formed to assist the organization. The boards and committees may have reports to give as well.
People may gather in mass meetings for a specific purpose or cause. One such purpose of the mass meetings could be for the intent of organizing a permanent society.
Each organization has its basic rules contained in its bylaws. The bylaws could describe the name of the organization and its purpose, the requirements to be a member or an officer, how meetings are scheduled, if there are boards or committees (or both), its parliamentary authority, and how to amend the bylaws.
Representatives from constituent groups may gather as delegates in conventions to conduct business on behalf of the organization. Conventions may consist of several meetings and may last for several days or more on an annual basis or other such infrequent interval.
If members do not act according to the organization's rules, they could be subject to disciplinary procedures. Such action could range from censure to the extreme of expulsion from the organization. Officers could be disciplined by removal from office.
Charts, tables, and lists.
The tinted pages (pages marked by a gray band along the outer edge) in the rear of the book contain the following charts, tables, and lists: (1) Chart for Determining When Each Subsidiary or Privileged Motion Is In Order, (2) Table of Rules Relating to Motions, (3) Sample Forms Used in Making Motions, (4) and (5) Motions and Parliamentary Steps, (6) Motions Which Require a Two-Thirds Vote, (7) Motions Whose Reconsideration Is Prohibited Or Limited, and (8) Table of Rules for Counting Election Ballots.
Additional information related to current edition.
In addition to containing a summary of basic points from the current (11th) edition of "Robert's Rules of Order Newly Revised" (RONR), the following contents are unique to the current (2nd) edition of "Robert's Rules of Order Newly Revised In Brief" (RONRIB)":" an example of an agenda, additional sample dialogues, frequently asked questions, an example of a call of a meeting, an example of a memorandum listing the order of business, and the following tables: (A) Handling Motions as Chair, (B) When Chair Stands and Sits, (C) Conducting a Meeting as Chair, (D) Table of Rules Relating to Motions, and (E) Words to Use as a Member.
The Robert's Rules Association has also made the Eleventh Edition available in CD-ROM format (designed for installation on Windows PCs) through American Legal Publishing. The CD contains the current editions of "Robert's Rules of Order Newly Revised" and "Robert's Rules of Order Newly Revised In Brief" as well as a Timekeeper’s Guide, Teller’s Report, Sample Rules for Electronic Meetings, various Forms, and resources for Ballot Voting and Understanding Secondary Amendments.
An e-book version of the current Eleventh Edition has not been released by the Robert's Rules Association. Any copy of Robert's Rules of Order that is downloaded online is likely an older edition (1915 or earlier) that is available in the public domain.
Translations of any edition of Robert's Rules of Order into other languages have not been published by the Robert's Rules Association. Any translated copy of Robert's Rules of Order done by a third party may not accurately reflect the correct meaning in the target language.
Changes between editions.
The following table lists some of the changes that were made between the editions of Robert's Rules of Order. The numbered pages may not correspond to the total number of pages in the edition due to additional material in the preface, introduction, and other miscellaneous pages that were not included in the numbering system. 
Generally, a fuller list and more details of the changes are found in the preface of each edition. A detailed list of changes for the current (11th) edition is provided on the website maintained by the Robert's Rules Association. All the changes were a result of questions and comments received from users.
Explanations of rules in book.
Starting in the period between the Tenth Edition and the Eleventh Edition, the authors released official interpretations of rules in the book onto the website maintained by the Robert's Rules Association. The interpretations from that period were later incorporated into the Eleventh Edition.
In addition, the authors addressed common misunderstandings of the rules coming from frequently asked questions. Some of the misunderstandings involve: when the president can vote, if ex-officio members can vote, the definition of majority, how abstentions affect the vote, a "friendly amendment", "calling the question", "tabling" a motion, getting items on the agenda, and the contents of minutes. While these misunderstandings are of the rules in the current edition of "Robert's Rules of Order Newly Revised", the organization may be governed by other rules which supersede these "default" rules.
The official interpretations and addressed common misunderstandings were a result of questions posted in the Question & Answer Forum at the Official Robert's Rules of Order Web Site. This forum is actively moderated by members of the authorship team.
Application to specific organizations.
In those cases in which the bylaws or other governing documents of an organization refer to "Robert's Rules of Order," certain rules in the book may be subordinate to other specified rules, including any conflicting provisions in applicable law, the corporate charter, the constitution or bylaws, and special rules of order.
Types of organizations.
In the Question & Answer Forum on the website maintained by the Robert's Rules Association, members of the following types of organizations have posted questions regarding how the rules in the book apply to their specific organization: 
Law-making bodies.
Generally, "Robert's Rules of Order" is designed for ordinary societies. However, law-making bodies at the local level (such as a city council or a county commission) function similarly to boards of societies. The book has found application to such bodies. Such bodies are also subject to open meeting laws (Sunshine laws) and other applicable laws, all of which supersede any conflicting provisions in the book.
On the other hand, legislative bodies at the state or national level have their own well-defined set of rules (such as Mason's Manual of Legislative Procedure). However, a survey found that four state legislative chambers in the United States still use "Robert's Rules of Order".
Corporate world.
"Robert's Rules of Order" is based on each member of a group having equal weight as expressed by vote. This book has found application in the corporate world, such as in shareholder meetings and in board of director meetings. However, the rules have to be modified to account for when some individuals within the group have more power than others (see Parliamentary procedure in the corporate world).
Parliamentarians.
A parliamentarian is an expert on parliamentary procedure. To be effective consultants for the organizations they work for, parliamentarians are expected to be knowledgeable on "Robert's Rules of Order".
The National Association of Parliamentarians (NAP) is the largest non-profit association of parliamentarians in the world. This organization bases its opinions and instruction upon "Robert’s Rules of Order Newly Revised" (11th ed.). Membership in this organization requires passing an exam which is based on the first half of the concise guide, "Robert’s Rules of Order Newly Revised In Brief" (2nd ed.).
The American Institute of Parliamentarians is another non-profit association of parliamentarians. This organization stresses proficiency and familiarity with a variety of parliamentary authorities, although it states on its website that ""Robert's Rules of Order" is the most frequently used parliamentary authority". The website also states that it "is the premier manual on parliamentary authority" and "a 'must-have' text for every parliamentarian".
Youth organizations.
Youth organizations, such as Business Professionals of America (BPA), Family, Career and Community Leaders of America (FCCLA), Future Business Leaders of America-Phi Beta Lambda (FBLA-PBL), HOSA-Future Health Professionals, the National FFA Organization, and SkillsUSA, sponsor parliamentary procedure competitions (such as Parli Pro) as part of their programs for their student members. These competitions are based on "Robert’s Rules of Order Newly Revised". The National Association of Parliamentarians have partnered with some of these organizations.
"Robert's Rules of Order" is also used in Model United Nations conferences. While the chair of each committee in an MUN conference may sometimes deviate from the written rules for educational purposes, the format of the rules in the specific committees is mostly based on "Robert's Rules of Order". Another program in which "Robert's Rules of Order" may be used is Model Congress, although the rules in these programs may more closely resemble those in the legislative assemblies that the programs simulate.
Alternative rules for organizations.
Organization-specific rules.
Even if an organization has adopted "Robert's Rules of Order", it can still adopt its own rules which supersede any rules in this book. The only limitations might come from the rules in a parent organization or from national, state, or local law. An example of a rule that organizations sometimes adopt is one that allows the use of proxy voting. Such a rule is not allowed unless the organization specifically provides for it in its bylaws.
Other parliamentary authorities.
Parliamentarians have estimated that about 85 to 95 percent of organizations in the United States use "Robert's Rules of Order". The remaining percentage of organizations use other books on meeting procedures. Notable examples of such books include "The Standard Code of Parliamentary Procedure", "Demeter's Manual of Parliamentary Law and Procedure", and "Riddick's Rules of Procedure" (also see parliamentary authority). These books along with "Robert's Rules of Order" share the general idea of rule of the majority with respect for the minority. A difference may be a "simplification" of the rules. Henry M. Robert III responded to the simplification by saying the following:
Also in response to the simplification was the publication of a supplemental guide to the official book (see "In Brief" version).
Consensus decision-making.
In modern parliamentary procedure, the usual practice is having a proposal first, then discussion on this proposal with any modifications to it, and finally a vote on it, with majority vote deciding the issue if there are any disagreements. An alternative to this process is consensus decision-making. In this alternative, discussion of potential proposals is held first, followed by the framing of a proposal, and then modifying it until the group reaches a consensus, when there is no longer any disagreement.
As a response to this alternative, the authors of "Robert's Rules of Order" stated their belief in using debate and majority vote as part of the process in making decisions for the group.
External links.
Sites providing full text of older editions (from public domain).
The following sites are not maintained by the Robert's Rules Association and have no relation to the Official Robert's Rules of Order Web Site:

</doc>
<doc id="44421" url="https://en.wikipedia.org/wiki?curid=44421" title="Legislature">
Legislature

A legislature is the law-making body of a political unit, usually a national government, that has power to amend and repeal public policy. Laws enacted by legislatures are known as legislation. Legislatures observe and steer governing actions and usually have exclusive authority to amend the budget or budgets involved in the process. Names for national legislatures include "parliament", "congress", "diet" and "assembly". The members of a legislature are called legislators.
Terminology.
Because members of legislatures usually sit together in a specific room to deliberate, seats in that room may be assigned exclusively to members of the legislature. In parliamentary language, the term "seat" is sometimes used to mean that someone is a member of a legislature. For example, to say that a legislature has 100 "seats" means that there are 100 members of the legislature; and saying that someone is "contesting a seat" means they are trying to be elected as a member of the legislature. By extension, the term "seat" is often used in less formal contexts to refer to an electoral district itself, as, for example, in the phrases "safe seat" and "marginal seat".
In parliamentary systems of government, the executive is responsible to the legislature which may remove it with a vote of no confidence. According to the separation of powers doctrine, the legislature in a presidential system is considered an independent and coequal branch of government along with both the judiciary and the executive.
Institutional framework.
A legislature creates a complex interaction between individual members, political parties, committees, rules of parliamentary procedure, and informal norms.
Chambers.
A legislature is composed of one or more deliberative assemblies that separately debate and vote upon bills. These assemblies, as well as the physical spaces in which they meet, are normally known as "chambers" or "houses". A legislature with only one house is a unicameral legislature, while a bicameral legislature possesses two separate chambers, usually described as an "upper house" and a "lower house". These usually differ in the duties and powers they exercisethe upper house being more revisionary or advisory in parliamentary systemsand the methods used for the selection of members. Tricameral legislatures are rare; the Massachusetts Governor's Council still exists, but the most recent national example existed in the waning years of Caucasian-minority rule in South Africa. Tetracameral legislatures no longer exist, but they were previously used in Scandinavia.
In presidential systems, the powers of the two houses are often similar or equal, while in federations, the upper house typically represents the federation's component states. This is a case with the supranational legislature of the European Union. The upper house may either contain the delegates of state governmentsas in the European Union and in Germany and, before 1913, in the United Statesor be elected according to a formula that grants equal representation to states with smaller populations, as is the case in Australia and the United States since 1913.
List of Legislatures.
Some legislatures are known simply as the Legislature, including:

</doc>
<doc id="44422" url="https://en.wikipedia.org/wiki?curid=44422" title="Adjara">
Adjara

Adjara ( ), officially the Autonomous Republic of Adjara (აჭარის ავტონომიური რესპუბლიკა ), is an autonomous republic of Georgia.
Adjara, located in the southwestern corner of Georgia, is on the eastern end of the Black Sea and is bordered by Turkey to the south. Adjara is a home to the Adjar ethnic subgroup of Georgians.
Adjara is also known as Ajara, Adzhara, Ajaria, Adjaria, Adzharia, Achara, Acharia and Ajaristan. Under the Soviet Union, it was known as the Adjarian Autonomous Soviet Socialist Republic (Adjar ASSR).
History.
Adjara has been part of Colchis and Caucasian Iberia since ancient times. Colonized by Greeks in the 5th century BC, the region fell under Rome in the 2nd century BC. It became part of the region of Egrisi before being incorporated into the unified Georgian Kingdom in the 9th century AD. 
The Ottomans conquered the area in 1614. The people of Adjara converted to Islam in this period. The Ottomans were forced to cede Adjara to the expanding Russian Empire in 1878.
After a temporary occupation by Turkish and British troops in 1918–1920, Adjara became part of the Democratic Republic of Georgia in 1920. After a brief military conflict in March 1921, Ankara's government ceded the territory to Georgia under Article VI of Treaty of Kars on the condition that autonomy be provided for the Muslim population. The Soviet Union established the Adjar Autonomous Soviet Socialist Republic in 1921 in accord with this clause. Thus, Adjara was still a component part of Georgia, but with considerable local autonomy.
Independent Georgia.
After the dissolution of the Soviet Union in 1991, Adjara became part of a newly independent but politically divided Republic of Georgia. It avoided being dragged into the chaos and civil war that afflicted the rest of the country between 1991 and 1993 due largely to the authoritarian rule of its leader Aslan Abashidze. Although he successfully maintained order in Adjara and made it one of the country's most prosperous regions, he was accused of involvement in organised crime—notably large-scale smuggling to fund his government and enrich himself. The central government in Tbilisi had very little say in what went on in Adjara during the presidency of Eduard Shevardnadze.
This changed following the Rose Revolution of 2003 when Shevardnadze was deposed in favour of the reformist opposition leader Mikheil Saakashvili, who pledged to crack down on separatism within Georgia. In the spring of 2004, a major crisis in Adjara erupted as the central government sought to reimpose its authority on the region. It threatened to develop into an armed confrontation. However, Saakashvili's ultimatums and mass protests against Abashidze's autocratic rule forced the Adjaran leader to resign in May 2004, following which he went into exile in Russia. After Abashidze's ousting, a new law was introduced to redefine the terms of Adjara's autonomy. Levan Varshalomidze succeeded Abashidze as the chairman of the government.
In July 2007, the seat of the Georgian Constitutional Court was moved from Tbilisi to Batumi.
In November 2007 Russia ended its two century military presence in Georgia by withdrawing from the 12th Military Base (the former 145th Motor Rifle Division) in Batumi.
Since mid-2000s Turkey has expanded its influence over Adjara. Turkish influence can be seen in the region's economy and in the religious life—through the region's Muslim population.
Law and government.
The status of the Adjaran Autonomous Republic is defined by Georgia's law on Adjara and the region's new constitution, adopted following the ousting of Aslan Abashidze. The local legislative body is the Parliament. The head of the region's government—the Council of Ministers of Adjara—is nominated by the President of Georgia who also has powers to dissolve the assembly and government and to overrule local authorities on issues where the constitution of Georgia is contravened. Archil Khabadze is the current head of the Adjaran government.
Adjara is subdivided into six administrative units:
Geography and climate.
Adjara is located on the south-eastern coast of the Black Sea and extends into the wooded foothills and mountains of the Lesser Caucasus. It has borders with the region of Guria to the north, Samtskhe-Javakheti to the east and Turkey to the south. Most of Adjara's territory either consists of hills or mountains. The highest mountains rise more than above sea level. Around 60% of Adjara is covered by forests. Many parts of the Meskheti Range (the west-facing slopes) are covered by temperate rain forests.
Adjara is traversed by the northeasterly line of equal latitude and longitude.
Climate.
Adjara is well known for its humid climate (especially along the coastal regions) and prolonged rainy weather, although there is plentiful sunshine during the spring and summer months. Adjara receives the highest amounts of precipitation both in Georgia and in the Caucasus. It is also one of the wettest temperate regions in the northern hemisphere. No region along Adjara's coast receives less than of precipitation per year. The west-facing (windward) slopes of the Meskheti Range receive upwards of of precipitation per year. The coastal lowlands receive most of the precipitation in the form of rain (due to the area's subtropical climate). September and October are usually the wettest months. Batumi's average monthly rainfall for the month of September is . The interior parts of Adjara are considerably drier than the coastal mountains and lowlands. Winter usually brings significant snowfall to the higher regions of Adjara, where snowfall often reaches several meters. Average summer temperatures are between 22–24 degrees Celsius in the lowland areas and 17–21 degrees Celsius in the highlands. The highest areas of Adjara have lower temperatures. Average winter temperatures are between 4–6 degrees Celsius along the coast while the interior areas and mountains average around -3–2 degrees Celsius. Some of the highest mountains of Adjara have average winter temperatures of -8–(-7) degrees Celsius.
Economy.
Adjara has good land for growing tea, citrus fruits and tobacco. Mountainous and forested, the region has a subtropical climate, and there are many health resorts. Tobacco, tea, citrus fruits, and avocados are leading crops; livestock raising is also important. Industries include tea packing, tobacco processing, fruit and fish canning, oil refining, and shipbuilding.
The regional capital, Batumi, is an important gateway for the shipment of goods heading into Georgia, Azerbaijan and landlocked Armenia. The port of Batumi is used for the shipment of oil from Kazakhstan and Turkmenistan. Its oil refinery handles Caspian oil from Azerbaijan which arrives by pipeline to Supsa port and is transported from there to Batumi by rail. The Adjaran capital is a centre for shipbuilding and manufacturing.
Adjara is the main center of Georgia's coastal tourism industry, having displaced the northwestern province of Abkhazia since that region's "de facto" secession from Georgia in 1993.
Population.
According to the 2014 census, the population of Adjara is 336,077. The Adjarians (Ajars) are an ethnographic group of the Georgian people who speak a group of local dialects known collectively as Adjarian. The written language is Georgian.
The Georgian population of Adjara had been generally known as "Muslim Georgians" until the 1926 Soviet census which listed them as "Ajars" and counted 71,000 of them. Later, they were simply classified under a broader category of Georgians as no official Soviet census asked about religion. Today, calling them "Muslim Georgians" would be a misnomer in any case as Adjarans are now about 70% Christian (see below).
Ethnic minorities include Russians, Armenians, Pontic Greeks, Abkhaz, etc.
Religion.
The collapse of the Soviet Union and the re-establishment of Georgia's independence accelerated re-Christianisation, especially among the young. However, there are still remaining Sunni Muslim communities in Adjara, mainly in the Khulo district. According to the 2006 estimates by the Department of Statistics of Adjara, 63% are Georgian Orthodox Christians, and 30% Muslim. The remaining are Armenian Christians (2.3%), Roman Catholics (0.2%), and others (6%). 
Traditional public festivals.
Selimoba.
Selimoba is held in Bako village, Khulo Municipality on July 3 and commemorates the life of Selim Khimshiashvili. A concert with the participation of local amateur groups of a folk handicraft products exhibition is held during the festival. It is supported by Ministry of Education, Culture and Sports of Adjara.
Shuamtoba.
Shuamtoba ("inter-mountain festival") is a traditional festival, which is held on the summer mountain pastures of two municipalities (Khulo and Shuakhevi), in the first weekend of every August. Horse racing, folk handicraft products exhibition and a concert involving folk ensembles are held on Shuamtoba.
Machakhloba.
Machakhloba is Machakhela gorge festivity, held in the second half of September. It is a traditional holiday celebrated in Machakhela gorge, Khelvachauri Municipality. Festival begins at the Machakhela rifle monument (at the point of convergence of rivers Machakhela and Chorokhi), continues in the village Machakhispiri and ends in the village Zeda Chkhutuneti.
Kolkhoba.
Kolkhoba is an ancient Laz festival. It is held at the end of August or at the beginning of September in Sarpi village, Khelvachauri District. The myth about Argonauts is performed on stage during the festival.

</doc>
<doc id="44424" url="https://en.wikipedia.org/wiki?curid=44424" title="Metamorphic rock">
Metamorphic rock

Metamorphic rocks arise from the transformation of existing rock types, in a process called metamorphism, which means "change in form". The original rock (protolith) is subjected to heat (temperatures greater than 150 to 200 °C) and pressure (1500 bars), causing profound physical and/or chemical change. The protolith may be a sedimentary rock, an igneous rock or another older metamorphic rock.
Metamorphic rocks make up a large part of the Earth's crust and are classified by texture and by chemical and mineral assemblage (metamorphic facies). They may be formed simply by being deep beneath the Earth's surface, subjected to high temperatures and the great pressure of the rock layers above it. They can form from tectonic processes such as continental collisions, which cause horizontal pressure, friction and distortion. They are also formed when rock is heated up by the intrusion of hot molten rock called magma from the Earth's interior. The study of metamorphic rocks (now exposed at the Earth's surface following erosion and uplift) provides information about the temperatures and pressures that occur at great depths within the Earth's crust.
Some examples of metamorphic rocks are gneiss, slate, marble, schist, and quartzite.
Metamorphic minerals.
Metamorphic minerals are those that form only at the high temperatures and pressures associated with the process of metamorphism. These minerals, known as index minerals, include sillimanite, kyanite, staurolite, andalusite, and some garnet.
Other minerals, such as olivines, pyroxenes, amphiboles, micas, feldspars, and quartz, may be found in metamorphic rocks, but are not necessarily the result of the process of metamorphism. These minerals formed during the crystallization of igneous rocks. They are stable at high temperatures and pressures and may remain chemically unchanged during the metamorphic process. However, all minerals are stable only within certain limits, and the presence of some minerals in metamorphic rocks indicates the approximate temperatures and pressures at which they formed.
The change in the particle size of the rock during the process of metamorphism is called recrystallization. For instance, the small calcite crystals in the sedimentary rock limestone and chalk change into larger crystals in the metamorphic rock marble, or in metamorphosed sandstone, recrystallization of the original quartz sand grains results in very compact quartzite, also known as metaquartzite, in which the often larger quartz crystals are interlocked. Both high temperatures and pressures contribute to recrystallization. High temperatures allow the atoms and ions in solid crystals to migrate, thus reorganizing the crystals, while high pressures cause solution of the crystals within the rock at their point of contact.
Foliation.
The layering within metamorphic rocks is called "foliation" (derived from the Latin word "folia", meaning "leaves"), and it occurs when a rock is being shortened along one axis during recrystallization. This causes the platy or elongated crystals of minerals, such as mica and chlorite, to become rotated such that their long axes are perpendicular to the orientation of shortening. This results in a banded, or foliated rock, with the bands showing the colors of the minerals that formed them.
Textures are separated into foliated and non-foliated categories. Foliated rock is a product of differential stress that deforms the rock in one plane, sometimes creating a plane of cleavage. For example, slate is a foliated metamorphic rock, originating from shale. Non-foliated rock does not have planar patterns of strain.
Rocks that were subjected to uniform pressure from all sides, or those that lack minerals with distinctive growth habits, will not be foliated. Where a rock has been subject to differential stress, the type of foliation that develops depends on the metamorphic grade. For instance, starting with a mudstone, the following sequence develops with increasing temperature: slate is a very fine-grained, foliated metamorphic rock, characteristic of very low grade metamorphism, while phyllite is fine-grained and found in areas of low grade metamorphism, schist is medium to coarse-grained and found in areas of medium grade metamorphism, and gneiss coarse to very coarse-grained, found in areas of high-grade metamorphism. Marble is generally not foliated, which allows its use as a material for sculpture and architecture.
Another important mechanism of metamorphism is that of chemical reactions that occur between minerals without them melting. In the process atoms are exchanged between the minerals, and thus new minerals are formed. Many complex high-temperature reactions may take place, and each mineral assemblage produced provides us with a clue as to the temperatures and pressures at the time of metamorphism.
Metasomatism is the drastic change in the bulk chemical composition of a rock that often occurs during the processes of metamorphism. It is due to the introduction of chemicals from other surrounding rocks. Water may transport these chemicals rapidly over great distances. Because of the role played by water, metamorphic rocks generally contain many elements absent from the original rock, and lack some that originally were present. Still, the introduction of new chemicals is not necessary for recrystallization to occur.
Types of metamorphism.
Contact metamorphism.
Contact metamorphism is the name given to the changes that take place when magma is injected into the surrounding solid rock (country rock). The changes that occur are greatest wherever the magma comes into contact with the rock because the temperatures are highest at this boundary and decrease with distance from it. Around the igneous rock that forms from the cooling magma is a metamorphosed zone called a "contact metamorphism aureole". Aureoles may show all degrees of metamorphism from the contact area to unmetamorphosed (unchanged) country rock some distance away. The formation of important ore minerals may occur by the process of metasomatism at or near the contact zone.
When a rock is contact altered by an igneous intrusion it very frequently becomes more indurated, and more coarsely crystalline. Many altered rocks of this type were formerly called hornstones, and the term "hornfels" is often used by geologists to signify those
fine grained, compact, non-foliated products of contact metamorphism. A shale may become a dark argillaceous hornfels, full of tiny plates of brownish biotite; a marl or impure limestone may change to a grey, yellow or greenish lime-silicate-hornfels or siliceous marble, tough and splintery, with abundant augite, garnet, wollastonite and other minerals in which calcite is an important component. A diabase or andesite may become a diabase hornfels or andesite hornfels with development of new hornblende and biotite and a partial recrystallization of the original feldspar. Chert or flint may become a finely crystalline quartz rock; sandstones lose their clastic structure and are converted into a mosaic of small close-fitting grains of quartz in a metamorphic rock called quartzite.
If the rock was originally banded or foliated (as, for example, a laminated sandstone or a foliated calc-schist) this character may not be obliterated, and a banded hornfels is the product; fossils even may have their shapes preserved, though entirely recrystallized, and in many contact-altered lavas the vesicles are still visible, though their contents have usually entered into new combinations to form minerals that were not originally present. The minute structures, however, disappear, often completely, if the thermal alteration is very profound. Thus small grains of quartz in a shale are lost or blend with the surrounding particles of clay, and the fine ground-mass of lavas is entirely reconstructed.
By recrystallization in this manner peculiar rocks of very distinct types are often produced. Thus shales may pass into cordierite rocks, or may show large crystals of andalusite (and chiastolite), staurolite, garnet, kyanite and sillimanite, all derived from the aluminous content of the original shale. A considerable amount of mica (both muscovite and biotite) is often simultaneously formed, and the resulting product has a close resemblance to many kinds of schist. Limestones, if pure, are often turned into coarsely crystalline marbles; but if there was an admixture
of clay or sand in the original rock such minerals as garnet, epidote, idocrase, wollastonite, will be present. Sandstones when greatly heated may change into coarse quartzites composed of large clear grains of quartz. These more intense stages of alteration are not
so commonly seen in igneous rocks, because their minerals, being formed at high temperatures, are not so easily transformed or recrystallized.
In a few cases rocks are fused and in the dark glassy product minute crystals of spinel, sillimanite and cordierite may separate out. Shales are occasionally thus altered by basalt dikes, and feldspathic sandstones may be completely vitrified. Similar changes may be induced in shales by the burning of coal seams or even by an ordinary furnace.
There is also a tendency for metasomatism between the igneous magma and sedimentary country rock, whereby the chemicals in each are exchanged or introduced into the other. Granites may absorb fragments of shale or pieces of basalt. In that case, hybrid rocks called skarn arise, which don't have the characteristics of normal igneous or sedimentary rocks. Sometimes an invading granite magma permeates the rocks around, filling their joints and planes of bedding, etc., with threads of quartz and feldspar. This is very exceptional but instances of it are known and it may take place on a large scale.
Regional metamorphism.
Regional metamorphism, also known as dynamic metamorphism, is the name given to changes in great masses of rock over a wide area. Rocks can be metamorphosed simply by being at great depths below the Earth's surface, subjected to high temperatures and the great pressure caused by the immense weight of the rock layers above. Much of the lower continental crust is metamorphic, except for recent igneous intrusions. Horizontal tectonic movements such as the collision of continents create orogenic belts, and cause high temperatures, pressures and deformation in the rocks along these belts. If the metamorphosed rocks are later uplifted and exposed by erosion, they may occur in long belts or other large areas at the surface. The process of metamorphism may have destroyed the original features that could have revealed the rock's previous history. Recrystallization of the rock will destroy the textures and fossils present in sedimentary rocks. Metasomatism will change the original composition.
Regional metamorphism tends to make the rock more indurated and at the same time to give it a foliated, shistose or gneissic texture, consisting of a planar arrangement of the minerals, so that platy or prismatic minerals like mica and hornblende have their longest axes arranged parallel to one another. For that reason many of these rocks split readily in one direction along mica-bearing zones (schists). In gneisses, minerals also tend to be segregated into bands; thus there are seams of quartz and of mica in a mica schist, very thin, but consisting essentially of one mineral. Along the mineral layers composed of soft or fissile minerals the rocks will split most readily, and the freshly split specimens will appear to be faced or coated with this mineral; for example, a piece of mica schist looked at facewise might be supposed to consist entirely of shining scales of mica. On the edge of the specimens, however, the white folia of granular quartz will be visible. In gneisses these alternating folia are sometimes thicker and less regular than in schists, but most importantly less micaceous; they may be lenticular, dying out rapidly. Gneisses also, as a rule, contain more feldspar than schists do, and are tougher and less fissile. Contortion or crumbling of the foliation is by no means uncommon; splitting faces are undulose or puckered. Schistosity and gneissic banding (the two main types of foliation) are formed by directed pressure at elevated temperature, and to interstitial movement, or internal flow arranging the mineral particles while they are crystallizing in that directed pressure field.
Rocks that were originally sedimentary and rocks that were undoubtedly igneous may be metamorphosed into schists and gneisses. If originally of similar composition they may be very difficult to distinguish from one another if the metamorphism has been great. A quartz-porphyry, for example, and a fine feldspathic sandstone, may both be metamorphosed into a grey or pink mica-schist.
Metamorphic rock textures.
The five basic metamorphic textures with typical rock types are slaty (includes slate and phyllite; the foliation is called "slaty cleavage"), schistose (includes schist; the foliation is called "schistosity"), gneissose (gneiss; the foliation is called "gneissosity"), granoblastic (includes granulite, some marbles and quartzite), and hornfelsic (includes hornfels and skarn).

</doc>
<doc id="44426" url="https://en.wikipedia.org/wiki?curid=44426" title="National Security Act of 1947">
National Security Act of 1947

The National Security Act of 1947 was a major restructuring of the United States government's military and intelligence agencies following World War II. The majority of the provisions of the Act took effect on September 18, 1947, the day after the Senate confirmed James Forrestal as the first Secretary of Defense. His power was initially limited and it was difficult for him to exercise the authority to make his office effective. This was later changed in the amendment to the act in 1949, creating what was to be the Department of Defense.
The Act merged the Department of War (renamed as the Department of the Army) and the Department of the Navy into the National Military Establishment (NME), headed by the Secretary of Defense. It also created the Department of the Air Force, which separated the Army Air Forces into its own service. Initially, each of the three service secretaries maintained quasi-cabinet status, but the act was amended on August 10, 1949, to ensure their subordination to the Secretary of Defense. At the same time, the NME was renamed as the Department of Defense. The purpose was to unify the Army, Navy, and Air Force into a federated structure.
Aside from the military reorganization, the act established the National Security Council, a central place of coordination for national security policy in the executive branch, and the Central Intelligence Agency, the U.S.'s first peacetime intelligence agency. The council's function was to advise the president on domestic, foreign, and military policies, and to ensure cooperation between the various military and intelligence agencies.
The Joint Chiefs of Staff was officially established under Title II, Section 211 of the original National Security Act of 1947 before Sections 209–214 of Title II were repealed by the law enacting Title 10 and Title 32, United States Code (Act of August 10, 1956, 70A Stat. 676) to replace them.
The act and its changes, along with the Truman Doctrine and the Marshall Plan, were major components of the Truman administration's Cold War strategy.
The bill signing took place aboard Truman's VC-54C presidential aircraft "Sacred Cow", the first aircraft used for the role of Air Force One.

</doc>
<doc id="44427" url="https://en.wikipedia.org/wiki?curid=44427" title="Four Pillars of the Green Party">
Four Pillars of the Green Party

The Four Pillars of the Green Party are a foundational statement of Green politics and form the basis of many worldwide Green parties. Different Green Parties that list the "Four Pillars" phrase them somewhat differently. In general, the four pillars define a Green Party as a political movement that interrelates its philosophy from four different social movements: the environmental movement, the labour movement, the civil rights movement, and the peace movement.
The "Four Pillars" are:
At the 2001 Canberra Global Gathering delegates for Green Parties from 72 countries decided upon a Global Greens Charter which proposes six key principles.
History of the Four Pillars.
For the Australian Greens, they are known as "Ecological sustainability", "Social and economic justice", "Peace and nonviolence", and "Grassroots democracy".
For the German Greens (Die Grünen/Bündnis 90), they are known as "ökologisch", "sozial", "basisdemokratisch" and "gewaltfrei" (latter is "non-violent").
For the Swedish Greens (Miljöpartiet de Gröna), in the 1980s they were called the "Four Solidarities": "Solidarity with the ecological systems", "Solidarity with the people throughout the world", "Solidarity with future generations", and "Solidarity with the underprivileged people in our own country". Today they omit the pillar of Solidarity with the underprivileged, leaving them with the "Three Solidarities": "Solidarity with animals, nature and the ecological system", "Solidarity with future generations", and "Solidarity with all the world’s people."
On the global level, the "Six Principles" of the Global Greens Charter - which at the Global Greens conference of 2001 were arrived upon as a compromise of the North American and European traditions - added Respect for diversity and Sustainability.

</doc>
<doc id="44428" url="https://en.wikipedia.org/wiki?curid=44428" title="Chondrus crispus">
Chondrus crispus

Chondrus crispus—commonly called Irish moss or carrageen moss (Irish "carraigín", "little rock")—is a species of red algae which grows abundantly along the rocky parts of the Atlantic coast of Europe and North America. In its fresh condition this protist is soft and cartilaginous, varying in color from a greenish-yellow, through red, to a dark purple or purplish-brown. The principal constituent is a mucilaginous body, made of the polysaccharide carrageenan, which constitutes 55% of its weight. The organism also consists of nearly 10% protein and about 15% mineral matter, and is rich in iodine and sulfur. When softened in water it has a sea-like odour and because of the abundant cell wall polysaccharides it will form a jelly when boiled, containing from 20 to 100 times its weight of water.
Description.
"Chondrus crispus" is a relatively small red alga, reaching up to a little over than 20 cm in length. It grows from a discoid holdfast and branches four or five times in a dichotomous, fan-like manner. The morphology is highly variable, especially the broadness of the thalli. The branches are 2–15 mm broad, firm in texture and dark reddish brown in color bleaching to yellowish in sunlight. The gametophytes (see below) often show a blue iridescence at the tip of the fronds and fertile sporophytes show a spotty pattern. "Mastocarpus stellatus" (Stackhouse) Guiry is a similar species which can be readily distinguished by its strongly channelled and often somewhat twisted thallus. The cystocarpic plants of "Mastocarpus" show reproductive papillae quite distinctively different from "Chondrus". When washed and sun-dried for preservation, it has a yellowish, translucent, horn-like aspect and consistency.
Distribution.
"Chondrus crispus" is common all around the shores of Ireland and can also be found along the coast of Europe including Iceland, the Faroe Islands western Baltic Sea to southern Spain. It is found on the Atlantic coasts of Canada and recorded from California in the United States to Japan. However, any distribution outside the Northern Atlantic needs to be verified.
There are also other species of the same genus in the Pacific Ocean, for example, "C. ocellatus" Holmes, "C. nipponicus" Yendo, "C. yendoi" Yamada "et" Mikami, "C. pinnulatus" (Harvey) Okamura and "C. armatus" (Harvey) Yamada "et" Mikami.
Ecology.
"Chondrus crispus" is found growing on rock from the middle intertidal zone into the subtidal zone, all the way to the ocean floor. So it is very hard for sunlight to reach it.
Uses.
"Chondrus crispus" is an industrial source of carragheen, which is commonly used as a thickener and stabilizer in milk products such as ice cream and processed foods, including lunch meat. In Europe, it is indicated as E407 or E407b. It may also be used as a thickener in calico-printing and for fining beer or wine. Irish moss is frequently used with "Mastocarpus stellatus" ("Gigartina mamillosa"), "Chondracanthus acicularis " ("G. acicularis") and other seaweeds, which are all commonly found growing together. Carragheen and agar-agar are also used in Asia for gelatin-like desserts, such as almond jelly. Presently, the major source of carrageenan is tropical seaweeds of the genera "Kappaphycus" and "Eucheuma".
In Ireland and parts of Scotland (where it is also known as "(An) Cairgean" in Scottish Gaelic), it is boiled in milk and strained, before sugar and other flavourings such as vanilla, cinnamon, brandy or whiskey are added. The end-product is a kind of jelly similar to pannacotta, tapioca, or blancmange. Similarly, in Jamaica and Trinidad and Tobago "Gracilaria" spp is boiled with cinnamon and milk to make a thick drink called Irish Moss that is believed to be an aphrodisiac. In Venezuela it has been used for generations as a home remedy for sore throat and chest congestion, boiled in milk and served with honey before bed.
Irish moss is commonly used as a clarifying agent in the process of brewing (beer), particularly in homebrewing. A small amount is boiled with the wort, attracting proteins and other solids, which is then removed from the mixture after cooling.
Life history.
"Chondrus crispus" undergoes an alternation of generation life cycle common in many species of algae (see figure below). There are two distinct stages: the sexual haploid gametophyte stage and the asexual diploid sporophyte stage. In addition, there is a third stage- the carposporophyte, which is formed on the female gametophyte after fertilization. The male and female gametophytes produce gametes which fuse to form a diploid carposporophyte, which forms carpospores, which develops into the sporophyte. The sporophyte then undergoes meiosis to produce haploid tetraspores (which can be male or female) that develop into gametophytes. The three stages (male, female and sporophyte) are difficult to distinguish when they are not fertile; however, the gametophytes often show a blue iridescence.
Scientific interest.
"Chondrus crispus" is, compared to most other seaweeds, well-investigated scientifically. It has been used as a model species to study photosynthesis, carrageenan biosynthesis, and stress responses.The nuclear genome was sequenced in 2013. The genome size is 105 Mbp and is coding for 9,606 genes. It is characterised by relatively few genes with very few introns. The genes are clustered together, with normally short distances between genes and then large distances between groups of genes.

</doc>
<doc id="44430" url="https://en.wikipedia.org/wiki?curid=44430" title="Glacis">
Glacis

A glacis (; ) in military engineering is an artificial slope as part of a medieval castle or in early modern fortresses. They may be constructed of earth as a temporary structure or of stone in more permanent structure.
A "glacis plate" is the sloped front-most section of the hull of a tank or other armored fighting vehicle.
More generally, the term "glacis" can denote any slope, natural or artificial, which fulfils the above requirements. The etymology of this French word suggests a slope made dangerous with ice, hence the relationship with "glacier".
Ancient fortifications.
A glacis could also appear in ancient fortresses, such as the one built at Semna, by the ancient Egyptians. Here it was used by them to prevent enemy siege engines from weakening defensive walls.
Ancient British hill forts started to incorporate glacis around 350 BC. Those at Maiden Castle in Dorset were high.
Medieval fortifications.
Glacis were incorporated into medieval fortifications to strengthen the walls against undermining, to hamper escalades and so that missiles dropped from the battlements would ricochet off the glacis into attacking forces.
Towards the end of the medieval period some castles were modified to make them defensible against cannons. Glacis consisting of earthen slopes faced with stones were placed in front of the curtain walls and bastions (towers) to absorb the impact of cannon shots or to deflect them. Towers were lowered to the same height as the curtain walls and converted into gun platforms.
Early modern European fortifications.
Early modern European fortresses were so constructed as to keep any potential assailant under the fire of the defenders until the last possible moment. On natural, level ground, troops attacking any high work have a degree of shelter from its fire when close up to it; the glacis consists of a slope with a low grade inclined towards the top of the wall. This gave defenders a direct line of sight into the assaulting force, allowing them to efficiently sweep the field with fire from the parapet. Additionally, but secondarily, the bank of earth would shield the walls from being hit directly by cannon fire.
Though defenders on a high ground already have a direct line of sight, a glacis allows the field of fire to be swept more efficiently by minimizing changes to the angle of their guns while firing. Furthermore, the glacis prevents attacking cannon from having a clear shot at the walls of a fortress, as usually these cannot be seen until the glacis is crossed and the ditch, bounded on either side by the smooth, masoned scarp and counterscarp, is reached.
Armored vehicles.
The term glacis plate describes the sloped front-most section of the hull of a tank or other armored fighting vehicle, often composed of upper and lower halves. In a head-on-head armored engagement, the glacis plate is the largest and most obvious target available to an enemy gunner.
Sloping it has two powerful advantages: many projectiles will deflect rather than penetrate; those that attempt to will have to travel on a longer diagonal route through any given thickness of armor than if it were perpendicular to their trajectory. For example, a round aimed at 4" of plate steel set on a 45-degree angle will have to pass through 5.67" of material to penetrate, increasing effective thickness of the armor by 41.5 percent.
Anti-tank mines which employ a tilt-rod fuze are also designed to detonate directly underneath the glacis plate. As a result, it is generally the thickest, most robust armored section of a tank, followed by the turret face and gun mantlet.

</doc>
<doc id="44431" url="https://en.wikipedia.org/wiki?curid=44431" title="Biafra">
Biafra

Biafra, officially the Republic of Biafra, was a secessionist state in then southeastern Nigeria that existed from 30 May 1967 to 1970, taking its name from the Bight of Biafra (the Atlantic bay to its south). The inhabitants were mostly the Igbo people who led the secession due to economic, ethnic, cultural and religious tensions among the various peoples of Nigeria. The creation of the new state that was pushing for recognition was among the causes of the Nigerian Civil War, also known as the Nigerian-Biafran War.
The state was formally recognised by Gabon, Haiti, Ivory Coast, Tanzania, and Zambia. Other nations which did not give official recognition but which did provide support and assistance to Biafra included Israel, France, Spain, Portugal, Norway, Rhodesia, South Africa and Vatican City. Biafra also received aid from non-state actors, including Joint Church Aid, Holy Ghost Fathers of Ireland, Caritas International, MarkPress and U.S. Catholic Relief Services.
After two-and-a-half years of war, during which over three million civilians died in fighting and from starvation resulting from blockades, Biafran forces under the slogan 'no-victor, no-vanquish' surrendered to the Nigerian Federal Military Government (FMG), and Biafra was reintegrated into Nigeria.
History.
Secession.
In 1960, Nigeria became independent of the United Kingdom. As with many other new African states, the borders of the country did not reflect earlier ethnic boundaries. Thus the northern Sudan and Sahelian Savannah region of the country is made up of Muslim majority, while the southern population was predominantly Christian and Animist. Furthermore, Nigeria's oil, its primary source of income, was located in the south of the country.
Following independence, Nigeria was divided primarily along ethnic lines with Hausa and Fulani in the north, Yoruba in the south-west, Ijaws and Igbo in the south-east.
In January 1966, a military coup occurred during which 30 political leaders including Nigeria's Prime Minister, Sir Abubakar Tafawa Balewa, and the Northern premier, Sir Ahmadu Bello, were killed. It was alleged to be an Igbo coup because Nnamdi Azikiwe, the President, of Igbo extraction, and the premier of the southeastern part of the country were not killed. Many others who held the 1966 coup in mind as being master-minded by the "igbo" ethnic group of Nigeria did so because Major Kaduna Nzeogu was perceived to be an "igbo soldier" and he led the coup.
In July 1966 northern officers and army units staged a counter-coup. Muslim officers named a Christian from a small ethnic group (the Angas) in central Nigeria, General Yakubu "Jack" Gowon, as the head of the Federal Military Government (FMG). The two coups deepened Nigeria's ethnic tensions. In September 1966, approximately 30,000 Igbo were killed in the north, and some Northerners were killed in backlashes in eastern cities.
Biafra as a territory existed long before the amalgamation and independence of Nigeria as a republic. Chukwuemeka Odumegwu Ojukwu in pursuit of a more agreeable arrangement for peaceful co-existence of all regions in Nigeria proposed for a confederated Nigeria.
In January 1967, the military leaders and senior police officials of each region met in Aburi, Ghana and agreed on a loose confederation of regions. The Northerners were at odds with the Aburi Accord; Obafemi Awolowo, the leader of the Western Region warned that if the Eastern Region seceded, the Western Region would also, which persuaded the northerners.
After the federal and eastern governments failed to reconcile, on 26 May the Eastern region voted to secede from Nigeria. On 30 May, Chukwuemeka Odumegwu Ojukwu, the South Eastern Region's military governor, announced the Republic of Biafra, citing the Easterners killed in the post-coup violence. The large amount of oil in the region created conflict, as oil is a major component of the Nigerian economy. The Eastern region was very ill-equipped for war, out-manned and out-gunned by the military of the remainder of Nigeria. Their advantages included fighting in their homeland and support of most South Easterners.
War.
The FMG launched "police measures" to annex the Eastern Region on 6 July 1967. The FMG's initial efforts were unsuccessful;
the Biafrans successfully launched their own offensive, occupying areas in the mid-Western Region in August 1967. By October 1967,
the FMG had regained the land after intense fighting. In September 1968, the federal army planned what Gowon described as the "final offensive". Initially the final offensive was neutralised by Biafran troops. In the latter stages, a Southern FMG offensive managed to break through the fierce resistance.
During the war there were great shortages of food and medicine throughout Biafra, due largely to the Nigerian government's blockade of the region as suggested by a good number of arguments by leaders of the Nigerian Government:
Chief Anthony Enahoro, stated that "there are various ways of fighting a war. You might starve your enemy into submission, or you might kill him on the battlefield."
Chief Obafemi Awolowo said "ALL is fair in war, and starvation is one of the weapons of war and I don't see why we should feed our enemies in order for them to fight harder."
Many volunteer bodies organised the Biafran airlift which provided blockade-breaking relief flights into Biafra, carrying food and medicines in, and later provided means of evacuation for refugee children. On 30 June 1969, the Nigerian government banned all Red Cross aid to Biafra; two weeks later it allowed medical supplies through the front lines, but restricted food supplies. Later in October 1969, Ojukwu appealed to the United Nations to mediate a cease-fire. The federal government called for Biafra's surrender. In December, the FMG managed to cut Biafra in half, primarily by the efforts of 3 Marine Commando Division of the Nigerian Army, led by then Colonel Benjamin Adekunle, popularly called "The Black Scorpion", and later by Olusegun Obasanjo. Ojukwu fled to Ivory Coast, leaving his chief of staff, Philip Effiong, to act as the "officer administering the government". Effiong called for a cease-fire 12 January and submitted to the FMG. More than one million people had died in battle or from starvation. Biafra was reabsorbed into Nigeria on 15 January.
Geography.
Biafra comprised over of land, with terrestrial borders shared with Nigeria to the north and with Cameroon to the east. Its coast was on the Gulf of Guinea in the south.
The former country's southeast borders the Benue Hills and mountains that lead to Cameroon. Two rivers flow from Biafra into the Gulf of Guinea: the Cross River and the Niger River.
The late territory of Biafra is covered nowadays by the Nigerian states of Cross River, Ebonyi, Enugu, Anambra, Imo, Bayelsa, Rivers, Abia, Delta and Akwa Ibom.
Language.
The English language is spoken throughout Nigeria and carried on into the new state of Biafra.
The predominant language of Biafra is Igbo. Along with Igbo there were a variety of other languages, including Efik, Ijaw, Annang and Ibibio.
Economy.
An early institution created by the Biafran government was the Bank of Biafra, accomplished under "Decree No. 3 of 1967". The bank carried out all central banking functions including the administration of foreign exchange and the management of the public debt of the Republic. The bank was administered by a governor and four directors; the first governor, who signed on bank notes, was Sylvester Ugoh. A second decree, "Decree No. 4 of 1967", modified the Banking Act of the Federal Republic of Nigeria for the Republic of Biafra.
The bank was first located in Enugu, but due to the ongoing war, the bank was relocated several times.
Biafra attempted to finance the war through foreign exchange. After Nigeria announced their currency would no longer be legal tender (to make way for a new currency), this effort increased. After the announcement, tons of Nigerian bank notes were transported in an effort to acquire foreign exchange. The currency of Biafra had been the Nigerian pound, until the Bank of Biafra started printing out its own notes, the Biafran pound. The new currency went public on 28 January 1968, and the Nigerian pound was not accepted as an exchange unit. The first issue of the bank notes included only 5 shillings notes and 1 pound notes. The Bank of Nigeria exchanged only 30 pounds for an individual and 300 pounds for enterprises in the second half of 1968.
In 1969 new notes were introduced: £10, £5, £1, 10/- and 5/-.
It is estimated that a total of £115–140 million Biafran pounds were in circulation by the end of the conflict, with a population of about 14 million, approximately £10 per person. In uncirculated condition these are very inexpensive and readily available for collectors.
Military.
At the beginning of the war Biafra had 3,000 soldiers, but at the end of the war the soldiers totalled 30,000. There was no official support for the Biafran army by any other nation throughout the war, although arms were clandestinely acquired. Because of the lack of official support, the Biafrans manufactured many of their weapons locally. A number of Europeans served in the Biafran cause; German born Rolf Steiner was a Lt. Colonel assigned to the 4th Commando Brigade and Welshman Taffy Williams served as a Major until the very end of the conflict.
The Biafrans managed to set up a small yet effective air force. The BAF commanders were Chude Sokey and later Godwin Ezeilo, who had trained with the Royal Canadian Air Force. Early inventory included two B-25 Mitchells, one B-26 Invader (piloted by Polish WWII ace Jan Zumbach, known also as John Brown), a converted DC-3 and one Dove. In 1968 the Swedish pilot Carl Gustaf von Rosen suggested the MiniCOIN project to General Ojukwu. By the spring of 1969, Biafra had assembled five MFI-9Bs in Gabon, calling them "Biafra Babies". They were coloured green, were able to carry six 68 mm anti-armour rockets under each wing and had simple sights. The six aeroplanes were flown by three Swedish pilots and three Biafran pilots. In September 1969, Biafra acquired four ex-Armee de l'Air North American T-6Gs, which were flown to Biafra the following month, with another aircraft lost on the ferry flight. These aircraft flew missions until January 1970 and were flown by Portuguese ex-military pilots.
Legacy.
The international humanitarian organisation Médecins Sans Frontières ("Doctors Without Borders") originated in response to the suffering in Biafra. During the crisis, French medical volunteers, in addition to Biafran health workers and hospitals, were subjected to attacks by the Nigerian army and witnessed civilians being murdered and starved by the blockading forces. French doctor Bernard Kouchner also witnessed these events, particularly the huge number of starving children, and, when he returned to France, he publicly criticised the Nigerian government and the Red Cross for their seemingly complicit behaviour. With the help of other French doctors, Kouchner put Biafra in the media spotlight and called for an international response to the situation. These doctors, led by Kouchner, concluded that a new aid organisation was needed that would ignore political/religious boundaries and prioritise the welfare of victims.
In their study, "Smallpox and its Eradication", Fenner and colleagues describe how vaccine supply shortages during the Biafra smallpox campaign led to the development of the focal vaccination technique, later adopted worldwide by the World Health Organization, which led to the early and cost effective interruption of smallpox transmission in west Africa and elsewhere.
On 29 May 2000, the Lagos "Guardian" newspaper reported that the now ex-president Olusegun Obasanjo commuted to retirement the dismissal of all military persons who fought for the breakaway state of Biafra during Nigeria's 1967–1970 civil war. In a national broadcast, he said the decision was based on the belief that "justice must at all times be tempered with mercy".
In July 2006 the Center for World Indigenous Studies reported that government sanctioned killings were taking place in the southeastern city of Onitsha, because of a shoot-to-kill policy directed toward Biafran loyalists, particularly members of the Movement for the Actualization of the Sovereign State of Biafra (MASSOB).
In 2010, researchers from Karolinska Institutet in Sweden and University of Nigeria, Nsukka, showed that Igbos born in Biafra during the years of the famine were of higher risk of suffering from overweight, hypertension and impaired glucose metabolism compared to controls born a short period after the famine had ended. The findings are in line with the developmental origin of health and disease hypothesis suggesting that malnutrition in early life is a predisposing factor for cardiovascular diseases and diabetes later in life.
Movement to re-secede.
The Movement for the Actualization of the Sovereign State of Biafra (MASSOB) advocates a separate country for the people of south-eastern Nigeria. They accuse the state of marginalising the Igbo people. MASSOB says it is a peaceful group and advertises a 25-stage plan to achieve its goal peacefully. There are two arms to the government, the Biafra Government in Exile and Biafra Shadow Government. The Nigerian government accuses MASSOB of violence; MASSOB's leader, Ralph Uwazuruike, was arrested in 2005 and is being detained on treason charges; MASSOB is calling for his release. MASSOB is also championing the release of oil militant Mujahid Dokubo-Asari, who is facing similar charges. In 2009, The MASSOB launched "the Biafran International Passport" in response to persistent demand by Biafrans in diaspora. On June 16, 2015, the Supreme Council of Elders of the Indigenous People of Biafra sued the Federal Republic of Nigeria for the right to self-determination within their region as a sovereign state.
Another group, Indigenous People of Biafra (IPOB), Led by a United Kingdom-based Biafran, Nnamdi Kanu, has reinvigorated the quest for Biafran realisation since 2012. He recently set up a registered radio station, Radio Biafra, which has been broadcasting at various frequencies around the world. The Nigerian Government, through her broadcasting regulator, the Broadcasting Organisation of Nigerian and Nigerian Communications Commission, has sought to clamp down on the UK based Radio Station without success. on November 17, 2015 the Abia police command seized an IPOB's radion transmitter in Umuahia North, Abia State.
On October 19, 2015, Chief Ralph Uwazuruike of the Movement for the Actualization of Sovereign State of Biafra (MASSOB) disclosed that the Director of Radio Biafra and Leader of the Indigenous People of Biafra (IPOB), Nnamdi Kanu, does not belong to the movement and was sacked for indiscipline and for inciting violence among members.
During November 2015, Biafran independence protests have erupted in cities across Nigeria's south-east; analysts believe the scale of these protests is unprecedented. Though peaceful, the protesters have been attacked by the Nigerian Police and army. Scores have been reportedly killed. Many others have been injured and others have been arrested.
On December 23, 2015, the federal government charged Nnamdi Kanu with treasonable felony in the Federal High court in Abuja.
There is an ongoing renewed killing of peaceful pro-Biafra agitators by Nigerian security agencies. According to the South-East Based Coalition of Human Rights Organizations (SBCHROs), security forces under the directive of the Federal Government has killed 80 members of the Indigenous People of Biafra (IPOB) and their supporters between August 30, 2015 and February 9, 2016.
Meaning of "Biafra" and location.
Little is known about the literal meaning of the word Biafra. The word Biafra most likely derives from the subgroup Biafar or Biafada of the Tenda ethnic group who reside primarily in Guinea-Bissau. Manuel Álvares (1526–1583), a Portuguese Jesuit educator, in his work "Ethiopia Minor and a geographical account of the Province of Sierra Leone", writes about the ""Biafar heathen"" in chapter 13 of the same book. The word Biafar thus appears to have been a common word in the Portuguese language back in the 16th century
Historical maps.
Early modern maps of Africa from the 15th–19th centuries, drawn by European cartographers from accounts written by explorers and travellers, reveal some information about Biafra:
Maps indicating the word "Biafara" (sometimes also "Biafares" or "Biafar") with corresponding year:
Maps from the 19th century indicating Biafra as the region around today's Cameroon:
Government.
The Coustomary Government of the Indigenous People of Biafra (CGIPB) is a shadow government established for the Republic of Biafra through the merger of Indigenous Peoples of Biafra (IPOB), the Movement for the Actualization of Sovereign State of Biafra (MASSOB) as well as all other smaller pro-Biafra movements, with Nnamdi Kanu as the current globally acknowledged Igbo leader of the Biafra shadow government.

</doc>
<doc id="44433" url="https://en.wikipedia.org/wiki?curid=44433" title="Danish West Indies">
Danish West Indies

The Danish West Indies () or Danish Antilles was a Danish colony in the Caribbean, consisting of the islands of Saint Thomas with ; Saint John with ; and Saint Croix with . The Danish West India Guinea Company annexed the uninhabited island of Saint Thomas in 1672 and St. John in 1675. In 1733, Saint Croix was purchased from the French West India Company. When the Company went bankrupt in 1755, the King of Denmark-Norway assumed direct control of the three islands. The Danish West Indies was occupied by Britain in 1802–1803 and 1807–1815, during the Napoleonic Wars.
The intention of Danish colonization in the West Indies was to exploit the profitable triangular trade, involving the exportation of firearms and other manufactured goods to Africa in exchange for slaves who were then transported to the Caribbean to staff the sugar plantations. The final stage of the triangle was the exportation of cargo of sugar and rum to Denmark. The economy of the Danish West Indies was dependent on slavery. After a rebellion, slavery was officially abolished in 1848, leading to the near economic collapse of the plantations.
In 1852, the sale of the increasingly unprofitable colony was first debated in the Danish parliament. Denmark tried several times to sell or exchange the Danish West Indies in the late 19th and early 20th century, to the United States and the German Empire respectively. The islands were eventually sold for 25 million dollars to the United States, which took over the administration on 31 March 1917, renaming the islands the United States Virgin Islands.
History.
Foundation.
Merchants in Copenhagen asked King Christian IV for permission to establish a West Indian trading company in 1622 but, by the time an eight-year monopoly on trade with the West Indies, Virginia, Brazil, and Guinea was granted on 25 January 1625, the failure of the Danish East India and Iceland Companies and the beginning of Danish involvement in the Thirty Years' War dried up any interested capital. Prince Frederick organized a trading mission to Barbados in 1647 under Gabriel Gomez and the de Casseres brothers, but it and a 1651 expedition of two ships were unsuccessful. It was not until Erik Smit's private 1652 expedition aboard the "Fortuna" proved successful that interest in the West Indies' trade grew into consideration of a new Danish colony.
Smit's 1653 expedition and a separate expedition of five ships were quite successful, but Smit's third found his two vessels captured for a loss of 32,000 rigsdaler. In August two years later, an argosy was destroyed by a hurricane. Smit returned from his fourth expedition in 1663 and formally proposed the settlement of St. Thomas to the king in April 1665. After only three weeks' deliberation, the scheme was approved and Smit named governor. Settlers departed aboard the "Eendragt" on 1 July, but the expedition was ill-starred: the ship hit two large storms and suffered from fire before reaching its destination, where it was raided by English privateers prosecuting the Second Anglo-Dutch War. Smit died of illness, and a second band of privateers stole the ship used to trade with neighboring islands. Following a hurricane and a renewed outbreak of disease, the colony collapsed, with the English departing for the nearby French colony on Sainte-Croix, the Danes fleeing to Saint Christopher and home, and the Dutch assisting their countrymen on Ter Tholen in stealing everything of value, particularly the remaining Danish guns and ammunition.
Danish West India Company.
The Danish formed a Board of Trade in 1668 and secured a commercial treaty with Britain, providing for the unmolested settlement of uninhabited islands, in July of 1670. The Danish West India Company was organized in December and formally chartered by King Christian V the next year on March 11, 1671. Jørgen Iversen Dyppel, a successful trader on Saint Christopher, was made governor and the king provided convicts from his jails and two vessels for the establishment of the colony, the yacht "Den forgyldte Krone" and the frigate "Færøe". "Den forgyldte Krone" was ordered to run ahead and wait but ended up returning to Denmark after the "Færøe" under Capt. Bang was delayed for repairs in Bergen. The "Færøe" completed her mission alone, establishing a settlement on St. Thomas on May 25, 1672. From an original contingent of 190 12 officials, 116 company "employees" (indentured servants), and 62 felons and former prostitutes only 104 remained, 9 having escaped and 77 having died in transit. Another 75 died within the first year, leaving only 29 to carry on the colony.
In 1675, Iversen claimed St. John and placed two men there; in 1684, Governor Esmit granted it to two English merchants from Barbados but their men were chased off the island by two British sloops sent by Governor Stapleton of the British Leeward Islands. Further instructions in 1688 to establish a settlement on St. John seem not to have been acted on until Governor Bredal made an official establishment on March 25, 1718.
The islands quickly became a base for pirates attacking ships in the vicinity and also for the Brandenburg African Company. Governor Lorentz raised enormous taxes upon them and seized warehouses and cargoes of tobacco, sugar, and slaves in 1689 only to have his actions repudiated by the authorities in Copenhagen; his hasty action to seize Crab Island prohibited the Brandenburgers from establishing their own Caribbean colony, however. Possession of the island was subsequently disputed with the Scottish in 1698 and fully lost to the Spanish in 1811.
St. Croix was purchased from the French West Indies Company in 1733. In 1754, the islands were sold to the Danish king, Frederick V of Denmark, becoming royal Danish colonies.
Later history (1801–1917).
The first British invasion and occupation of the Danish West Indies occurred during the French Revolutionary Wars when at the end of March 1801 a British fleet arrived at St Thomas. The Danes accepted the Articles of Capitulation the British proposed and the British occupied the islands without a shot being fired. The British occupation lasted until April 1802, when the British returned the islands to Denmark.
The second British invasion of the Danish West Indies took place during the Napoleonic Wars in December 1807 when a British fleet captured St Thomas on 22 December and Saint Croix on 25 December. The Danes did not resist and the invasion was bloodless. This British occupation of the Danish West Indies lasted until 20 November 1815, when Britain returned the islands to Denmark.
In the 1850s the Danish West Indies had a total population of about 41,000 people. The government of the islands were under a governor-general, whose jurisdiction extended to the other Danish colonies of the group. However, because the islands formerly belonged to Great Britain the inhabitants were English in customs and in language. The islands of that period consisted of:
On 17 January 1917, the Danish government sold the islands to the United States for $25 million ($ in current prices), when the United States and Denmark exchanged their respective treaty ratifications. Danish administration ended on 31 March 1917, when the United States took formal possession of the territory and renamed it the United States Virgin Islands.
The United States had been interested in the islands since at least the 1860s. The United States finally acted in 1917 because of the islands' strategic position near the approach to the Panama Canal and because of a fear that Germany might seize them to use as U-boat bases during World War I.
Postage stamps.
St Thomas was a hub of the West Indies packet service from 1851 to 1885. Denmark issued stamps for the Danish West Indies from 1856 onward.
Religion.
The Danish West Indies were inhabited by many different cultures, and each had its own traditions and religions. The king and the church worked closely together to maintain law and order; the church was responsible for people's moral upbringing, and the King led the civil order. There was no state-sponsored religion in Denmark until 1849, but in the Danish West Indies there had always been a great deal of religious freedom. Danish authorities tended to be lenient towards religious beliefs, but required that all citizens had to observe Danish holidays. Freedom of religion was partially granted to help settle the islands, as there was a shortage of willing settlers from Europe. This worked to an extent, seeing that a large proportion of settlers were in fact Dutch and British natives fleeing religious persecution.
In spite of a general tolerance for religion, many African religions were not recognized because they typically revolved around belief in animism and magic, beliefs which were consistently met with scorn, and were regarded as immoral and subservient. A widespread viewpoint was that if you could convert slaves to Christianity, they could have a better life, and many slaves were converted.
Slavery and property rights.
Laws and regulations in the Danish West Indies were based on Denmark's laws, but the local government was allowed to adapt them to match local conditions. For example, things like animals, land, and buildings were regulated according to Danish law, but Danish law did not regulate slavery. Slaves were treated as common property, and therefore did not necessitate specific laws.
In 1733, differentiation between slaves and other property was implied by a regulation that stated that slaves had their own will and thus could behave inappropriately or be disobedient.
The regulation also stated that the authorities were to punish slaves for participating in illegal activity, but many owners punished slaves on their own. There was a general consensus that if the slaves were punished too hard or were malnourished, the slaves would start to rebel. In 1755 Frederick V of Denmark issued more new Regulations, in which slaves were guaranteed the right not to be separated from their children and the right to medical support during periods of illness or old age. However, the colonial government had the ability to amend laws and regulations according to local conditions, and thus the regulations were never enacted in the colony, on grounds that it was more disadvantageous than advantageous.
By 1778, it was estimated that the Danish were bringing about 3,000 Africans to the Danish West Indies yearly for enslavement.
When Denmark abolished slavery in 1848, many plantation owners wanted full reimbursement, on the grounds that their assets were damaged by the loss of the slaves, and by the fact that they would have to pay for labor in the future. The Danish government paid fifty dollars for every slave the plantation owners had owned and recognized that the slaves' release had caused a financial loss for the owners. However, the lives of the former slaves changed very little. Most were hired at the plantations where they had previously worked and were offered one-year contracts, a small hut, a little land and some money. As employees, former slaves were not plantation owners' responsibility and did not receive food from their employers.

</doc>
<doc id="44434" url="https://en.wikipedia.org/wiki?curid=44434" title="Tractor beam">
Tractor beam

A tractor beam is a device with the ability to attract one object to another from a distance. The concept originates in fiction: the term was coined by E. E. Smith (an update of his earlier "attractor beam") in his novel "Spacehounds of IPC" (1931). Since the 1990s, technology and research has laboured to make it a reality, and have had some success on a microscopic level. Another method to realize tractor beams is based on the use of biaxial birefringent media. Less commonly, a similar beam that repels is called a pressor beam or repulsor beam. Gravity impulse and gravity propulsion beams are traditionally areas of research from fringe physics that coincide with the concepts of tractor and repulsor beams.
Physics.
A force field confined to a collimated beam with clean borders is one of the principal characteristics of tractor and repulsor beams. Several theories that have predicted repulsive effects do not fall within the category of tractor and repulsor beams because of the absence of field collimation. For example, Robert L. Forward, Hughes Research Laboratories, Malibu, California, showed that general relativity theory allowed the generation of a very brief impulse of a gravity-like repulsive force along the axis of a helical torus containing accelerated condensed matter. The mainstream scientific community has accepted Forward’s work. A variant of Burkhard Heim’s theory by Walter Dröscher, Institut für Grenzgebiete der Wissenschaft (IGW), Innsbruck, Austria, and Jocham Häuser, University of Applied Sciences and CLE GmbH, Salzgitter, Germany, predicted a repulsive force field of gravitophotons could be produced by a ring rotating above a very strong magnetic field. Heim’s theory, and its variants, have been treated by the mainstream scientific community as fringe physics. But the works by Forward, Dröscher, and Häuser could not be considered as a form of repulsor or tractor beam because the predicted impulses and field effects were not confined to a well defined, collimated region.
The following are a summary of experiments and theories that resemble repulsor and tractor beam concepts:
1960s.
In July 1960, "Missiles and Rockets" reported Martin N. Kaplan, Senior Research Engineer, Electronics Division, Ryan Aeronautical Company, San Diego, had conducted experiments that justified planning for a more comprehensive research program. The article indicated such a program, if successful, would yield either “restricted” or “general” results. It described the “restricted” results as an ability to direct an anti-gravitational force towards or away from a second body.
In 1964, Copenhagen physicists, L. Halpern, Universitetets Institut fűr Teoretisk Fysik, and B. Laurent, Nordisk Institut fűr Teoretisk Atomfysik, indicated general relativity theory and quantum theory allowed the generation and amplification of gravitons in a manner like the LASER. They showed, in principle, gravitational radiation in the form of a beam of gravitons could be generated and amplified by using induced, resonant emissions.
1980s.
According to Paul LaViolette, Starburst Foundation, Schenectady, New York, Eric Dollard, and Guy Obolensky had independently conducted gravity-like beam experiments during the 1980s that had been inspired by observations reported by Nikola Tesla. Those experiments were not reported in peer reviewed journals.
1990s.
In 1992, Russian Professor of Chemistry, Yevgeny Podkletnov, and Nieminen, Tampere University of Technology, Tampere, Finland, discovered weight fluctuations in objects above an electromagnetically levitated, massive, composite superconducting disk. Three years later, Podkletnov reported the results of additional experiments with a toroidal disk superconductor. They reported the weight of the samples would fluctuate between -2.5% and +5.4% as the angular speed of the superconductor increased. Certain combinations of disk angular speeds and electromagnetic frequencies caused the fluctuations to stabilize at a 0.3% reduction. The experiments with the toroidal disk yielded reductions that reached a maximum of 1.9-2.1%. Reports about both sets of experiments stated the weight loss region was cylindrical, extending vertically for at least three meters above the disk. Qualitative observations of an expulsive force at the border of the shielded zone were reported in the Fall of 1995.
Italian physicist Giovanni Modanese, while a Von Humboldt Fellow at the Max Planck Institute for Physics, made the first attempt to provide a theoretical explanation of Podkletnov’s observations. He argued the shielding effect and slight expulsive force at the border of the shielded zone could be explained in terms of induced changes in the local cosmological constant. Modanese described several effects in terms of responses to modifications to the local cosmological constant within the superconductor. Ning Wu, Institute of High Energy Physics, Beijing, China, used the theory of quantum gauge theory of gravity he had developed in 2001 to explain Podkletnov’s observations. Wu’s theory approximated the relative gravity loss as 0.03% (an order of magnitude smaller than the reported range of 0.3 – 0.5%).
Several groups around the world tried to replicate Podkletnov’s gravity shielding observations. According to R. Clive Woods, Department of Electrical and Computer Engineering, Iowa State University, those groups were not able to overcome the extremely challenging technical problems of replicating all aspects of the 1992 experimental conditions. Woods summarised those shortcomings in the following list:
C. S. Unnikrishan, Tata Institute of Fundamental Research, Bombay, India, showed that if the effect had been caused by gravitational shielding, the shape of the shielded region would be similar to a shadow from the gravitational shield. For example, the shape of the shielded region above a disk would be conical. The height of the cone's apex above the disk would vary directly with the height of the shielding disk above the earth. Podkeltnov and Nieminen described the shape of the weight loss region as a cylinder that extended through the ceiling above the cryostat. That factor and others precipitated a recommendation to reclassify the effect as gravitational modification instead of gravitational shielding. Such a reclassification means the region causing the weight modifications can be directed and is not limited to the space above the superconductor.
2000s.
In 2001, Podkeltnov and Modanese reported the generation of a beam of gravity-like impulses. Their paper indicated a high voltage discharge device had been constructed that emitted a horizontal, collimated beam, with sharp borders, of short impulses of a repulsive force field that could penetrate different bodies without any noticeable loss of energy. Subsequently, the apparatus was dubbed an impulse gravity generator. Measurements of the impulses taken three to six meters beyond the emitter and in a building 150 meters away yielded identical results. Analyses of the measurements indicated the impulses briefly caused accelerations one thousand times the rate of gravity.
The gravity impulse generator received further theoretical support from David Maker and Glen A. Robertson, Gravi Atomic Research, Madison, Alabama and Wu. Chris Taylor, Jupiter Research Corporation, Houston, Texas, along with a private individual Robert Hendry and the original theorist Modanese conducted an analysis of the suitability of impulse gravity generators for Earth-to-orbit, interplanetary, and interstellar applications, this was repeated again in 2008 and a United States and European patent was received. In general, mainstream scientific community have treated the impulse gravity generator reports as extremely speculative and controversial. At least one other group based in central Europe has attempted to replicate Podkletnov's gravity impulse generator experiment, but they have elected not to publish their results.
2010s.
A team of scientists at the Australian National University led by Professor Andrei Rode created a device similar to a tractor beam to move small particles 1.5 meters through the air. Rather than create a new gravitational field, however, the device utilizes a doughnut-shaped Laguerre-Gaussian laser beam, which has a high intensity ring of light that surrounds a dark core along the beam axis. This method confines particles to the centre of the beam using photophoresis, whereby illuminated sections of the particle have a higher temperature and thus impart more momentum to air molecules incident on the surface. Owing to this method, it is impossible for such a device to work in space due to lack of air, but Professor Rode states that there are practical applications for the device on Earth such as, for example, the transportation of microscopic hazardous materials and other microscopic objects.
Prof. John Sinko and Dr. Clifford Schlecht researched a form of reversed-thrust laser propulsion as a macroscopic laser tractor beam. Intended applications include remotely manipulating space objects at distances up to about 100 km, removal of space debris, and retrieval of adrift astronauts or tools on-orbit.
In March 2011, Chinese scientists posited that a specific type of Bessel beam (a special kind of laser that that does not diffract at the centre) is capable of creating a pull-like effect on a given microscopic particle, forcing it towards the beam source. The underlining physics is the maximization of forward scattering via interference of the radiation multipoles. They show explicitly that the necessary condition to realize a negative (pulling) optical force is the simultaneous excitation of multipoles in the particle and if the projection of the total photon momentum along the propagation direction is small, attractive optical force is possible. The Chinese scientists suggest this possibility may be implemented for optical micromanipulation.
Functioning tractor beams based on solenoidal modes of light were demonstrated in 2010 by physicists at New York University.
The spiraling intensity distribution in these non-diffracting beams tends to trap illuminated objects and thus helps to 
overcome the radiation pressure that ordinarily would drive them down the optical axis. 
Orbital angular momentum transferred from the solenoid beam's helical wavefronts then 
drives the trapped objects upstream along the spiral. Both Bessel-beam and solenoidal tractor beams are being considered for 
applications in space exploration by NASA.
In 2013, scientists at the Institute of Scientific Instruments (ISI) and the university of St Andrews succeeded in creating a tractor beam that pulls objects on a microscopic level. The new study states that while this technique is new, it may have potential for bio-medical research. 
Professor Zemanek said: “The whole team have spent a number of years investigating various configurations of particles delivery by light. 
Dr Brzobohaty said: “These methods are opening new opportunities for fundamental phonics as well as applications for life-sciences.”
Dr Cizmar said: “Because of the similarities between optical and acoustic particle manipulation we anticipate that this concept will provide inspiration for exciting future studies in areas outside the field of photonics.”
Physicist from the Australian National University successfully built a reversible tractor beam, capable of transporting particles "one fifth of a millimetre in diameter a distance of up to 20 centimetres, around 100 times further than previous experiments." According to Professor Wieslaw Krolikowski, of the Research School of Physics and Engineering, “demonstration of a large scale laser beam like this is a kind of holy grail for laser physicists.” The work was published in Nature in 2014.
In 2015, A team of researchers have built the world's first sonic tractor beam that can lift and move objects using sound waves.
Fiction.
Science fiction movies and telecasts normally depict tractor and repulsor beams as audible, narrow rays of visible light that cover a small area of a target. Tractor beams are most commonly used on spaceships and space stations. They are generally used in two ways:
In the latter case, there are usually countermeasures that can be employed against tractor beams. These may include pressor beams (a stronger pressor beam will counteract a weaker tractor beam) or "plane shears" aka "shearing planes" (a device to "cut" the tractor beam and render it ineffective). In some fictional realities, shields can block tractor beams, or the generators can be disabled by sending a large amount of energy back up the beam to its source.
Tractor beams and pressor beams can be used together as a weapon: by attracting one side of an enemy spaceship while repelling the other, one can create severely damaging shear effects in its hull. Another mode of destructive use of such beams is rapid alternating between pressing and pulling force in order to cause structural damage to the ship as well as inflicting lethal forces on its crew.
Two objects being brought together by a tractor beam are usually attracted toward their common centre of gravity. This means that if a small spaceship applies a tractor beam to a large object such as a planet, the ship will be drawn towards the planet, rather than vice versa.
In "Star Trek", tractor beams are imagined to work by placing a target in the focus of a subspace/graviton interference pattern created by two beams from an emitter. When the beams are manipulated correctly the target is drawn along with the interference pattern. The target may be moved toward or away from the emitter by changing the polarity of the beams. Range of the beam affects the maximum mass that can be moved by the emitter, and the emitter subjects its anchoring structure to significant force.

</doc>
<doc id="44435" url="https://en.wikipedia.org/wiki?curid=44435" title="Rostrum">
Rostrum

Rostrum may refer to:

</doc>
<doc id="44436" url="https://en.wikipedia.org/wiki?curid=44436" title="Wilhelm Johannsen">
Wilhelm Johannsen

Wilhelm Johannsen (3 February 1857 – 11 November 1927) was a Danish botanist, plant physiologist, and geneticist. 
Biography.
He was born in Copenhagen. While very young, he was apprenticed to a pharmacist and worked in Denmark and Germany beginning in 1872 until passing his pharmacist's exam in 1879. In 1881, he became assistant in the chemistry department at the Carlsberg Laboratory under the chemist Johan Kjeldahl. Johannsen studied the metabolism of dormancy and germination in seeds, tubers and buds. He showed that dormancy could be broken by various anesthetic compounds, such as diethyl ether and chloroform.
In 1892, he was appointed lecturer at Royal Veterinary and Agricultural University and later became professor of botany and plant physiology. He taught plant physiology. His most well-known research concerned so-called "pure lines" of the self-fertile common bean. He was able to show that even in populations homozygous for all traits, i.e. without genetic variation, seed size followed a normal distribution. This was attributable to resource provision to the mother plant and to the position of seeds in pods and of pods on the plant. This led him to coin the terms "phenotype" and "genotype".
His findings led him to oppose contemporary Darwinists, most notably Francis Galton and Karl Pearson, who held the occurrence of normal distributed trait variation in populations as proof of gradual genetic variation on which selection could act. Only with the modern evolutionary synthesis, was it established that variation needed to be heritable to act as the raw material for selection.
The terms "phenotype" and "genotype" were created by Wilhelm Johannsen and first used in his paper "Om arvelighed i samfund og i rene linier" and in his book "Arvelighedslærens Elementer". This book was rewritten, enlarged and translated to German as "Elemente der exakten Erblichkeitslehre". It was in this book Johannsen introduced the term "gene". This term was coined in opposition to the then common "pangene" that stemmed from Darwin's theory of pangenesis. The book became one of the founding texts of genetics.
Also in 1905, Johannsen was appointed professor of plant physiology at the University of Copenhagen, becoming vice-chancellor in 1917. In December 1910, Johannsen was invited to give an address before the American Society of Naturalists. This talk was printed in the American Naturalist. In 1911, he was invited to give a series of four lectures at Columbia University.
Johannsen was a corresponding member of the Academy of Natural Sciences of Philadelphia (elected 1915).

</doc>
<doc id="44437" url="https://en.wikipedia.org/wiki?curid=44437" title="The Great Ziegfeld">
The Great Ziegfeld

The Great Ziegfeld is a 1936 American musical drama film directed by Robert Z. Leonard and produced by Hunt Stromberg. It stars William Powell as the theatrical impresario Florenz "Flo" Ziegfeld, Jr., Luise Rainer as Anna Held, and Myrna Loy as Billie Burke.
The film, shot at MGM Studios in Culver City, California in the fall of 1935, is a fictionalized tribute to Florenz Ziegfeld, Jr. and a cinematic adaption of Broadway's Ziegfeld Follies, with highly elaborate costumes, dances and sets. Many of the performers of the theatrical Ziegfeld Follies were cast in the film as themselves, including Fanny Brice and Harriet Hoctor, and Billie Burke acted as a supervisor for the film. The "A Pretty Girl Is Like a Melody" set alone was reported to have cost US$220,000 (US$ in dollars), featuring a towering rotating volute of diameter with 175 spiral steps, weighing 100 tons. The music to the film was provided by Walter Donaldson, Irving Berlin, and lyricist Harold Adamson, with choreographed scenes. The extravagant costumes were designed by Adrian, taking some 250 tailors and seamstresses six months to prepare them using of silver sequins and of white ostrich plumes. Over a thousand people were employed in the production of the film, which required 16 reels of film after the cutting.
One of the biggest successes in film in the 1930s and the pride of MGM at the time, it was acclaimed as the greatest musical biography to be made in Hollywood and still remains a standard in musical film making. It won three Academy Awards, including Best Picture for producer Hunt Stromberg, Best Actress for Luise Rainer, and Best Dance Direction for Seymour Felix, and was nominated for four others. Although the film is still praised for its lavish production and as a symbol of glamor and excess during the Golden Age of Hollywood, today "The Great Ziegfeld" is generally seen less favorably and is considered by many critics to be excessively showy and long at just under three hours.
MGM made two more "Ziegfeld" films – one entitled "Ziegfeld Girl" (1941), starring James Stewart, Judy Garland, Hedy Lamarr, and Lana Turner, which recycled some footage from "The Great Ziegfeld", and in 1946, "Ziegfeld Follies" by Vincente Minnelli. In 1951, they produced their Technicolor remake of "Show Boat", which Ziegfeld had presented as a stage musical.
Plot.
The son of a highly respected music professor, Florenz "Flo" Ziegfeld, Jr. yearns to make his mark in show business. He begins by promoting Eugen Sandow, the "world's strongest man", at the 1893 Chicago World's Fair, overcoming the competition of rival Billings and his popular attraction, belly dancer Little Egypt, with savvy marketing (allowing women to feel Sandow's muscles).
Ziegfeld returns to his father and young Mary Lou at the Chicago Musical College, and departs to San Francisco, where he and Sandow are deemed frauds for putting on a show in which Sandow faces a lion who falls asleep as soon as it is let out of the cage. Flo travels to England on an ocean liner, where he runs into Billings again who is laughing at a newspaper article denouncing him as a fraud.
Flo discovers that Billings is on his way to sign a contract with beautiful French star, Anna Held. Despite losing all his money gambling at Monte Carlo, Flo charms Anna into signing with him instead, pretending that he doesn't know Billings. Anna twice almost sends him away for his rudeness and for being broke, before revealing that she appreciates his honesty. Ziegfeld promises to give her "more publicity than she ever dreams of" and to feature her alongside America's most prominent theatrical performers.
At first, Anna's performance at the Herald Square Theatre is not a success. However, Flo manages to generate publicity by sending 20 gallons of milk to Anna every day for a fictitious milk bath beauty treatment, then refusing to pay the bill. The newspaper stories soon bring the curious to pack his theater, and Ziegfeld introduces eight new performers to back her. Audience members comment on how the milk must make her skin beautiful and the show is a major success. Flo sends Anna flowers and jewelry and a note saying "you were magnificent my wife", and she agrees to marry him, flaunting her new diamonds to her fellow performers.
However, one success is not enough for the showman. He has an idea for an entirely new kind of show featuring a bevy of blondes and brunettes, one that will "glorify" the American girl. The new show, the "Ziegfeld Follies", an opulent production filled with beautiful women and highly extravagant costumes and sets, is a smash hit, and is followed by more versions of the Follies.
Ziegfeld tries to make a star out of Audrey Dane, who is plagued with alcoholism and lures Fanny Brice away from vaudeville, showering both with lavish gifts. He gives stagehand Ray Bolger his break as well. Mary Lou, now a young woman, visits Ziegfeld, who doesn't recognize her initially, and hires her as a dancer.
The new production upsets Anna, who realizes that Flo's world does not revolve around just her, and she becomes envious of the attention he pays to Audrey. She divorces him after walking in on Flo and a drunk Audrey at the wrong moment. Audrey walks out on Flo and the show after an angry confrontation. Broke, Flo borrows money from Billings for a third time for the new show.
Flo meets the red-headed Broadway star Billie Burke and soon marries her. When she hears the news, a heartbroken Anna telephones Flo and pretends to be glad for him. Flo and Billie eventually have a daughter named Patricia.
Flo's new shows are a success, but after a while, the public's taste changes, and people begin to wonder if the times have not passed him by. After a string of negative reviews in the press, Flo overhears three men in a barber's shop saying that he'll "never produce another hit". Stung, he vows to have "four" hits on Broadway at the same time.
He achieves his goal, with the hits "Show Boat" (1927), "Rio Rita" (1927), "Whoopee!" (1928), and "The Three Musketeers", and invests over $1 million (US$ in dollars) of his earnings in the stock market. However, the stock market crash of 1929 bankrupts him, forcing Billie to return to the stage.
Shaken by the reversal of his financial fortunes and the growing popularity of movies over live stage shows, he becomes seriously ill. Billings pays him a friendly visit, and the two men agree to become partners in a new, even grander production of "The Ziegfeld Follies". But the reality is that both men are broke and Ziegfeld realizes this. In the final scene in his apartment overlooking the Ziegfeld Theatre, in a half-delirium, he recalls scenes from several of his hits, exclaiming, "I've got to have more steps, higher, higher", before slumping over dead in his chair.
Production.
Ziegfeld's widow, Billie Burke, was keen to pay off Ziegfeld's debts without filing for bankruptcy, and sold the rights to a biopic of him to Universal Pictures in late 1933. As a result, the film went into the pre-production phase in January 1934. Macguire had initially proposed the biographical film to them in the form of a "filmusical entertainment" set in a "theatrical tradition" and William Powell was cast as Ziegfeld. However, by February 1935, Macguire had fallen into disagreement with Universal over financial problems at the studio, and the entire production, including some already constructed sets and musical arrangements, were sold to MGM for US$300,000 (US$ in dollars). As part of the deal however, Universal retained the services of Powell for the classic screwball comedy "My Man Godfrey", which was released the same year as "The Great Ziegfeld".
The film was shot at MGM Studios in Culver City, California mostly in the latter half of 1935 under a budget of US$1,500,000 (US$ in dollars), produced by Hunt Stromberg. The cost exceeded US$2 million (US$ in dollars) by the end of the production in early 1936, exorbitant for the period, and it was MGM's most expensive film to date after "Ben Hur" (1925). The principal cinematography was shot by Oliver T. Marsh, and George Folsey and Karl Freund were brought in to shoot the Ziegfeld Roof numbers. Ray June shot the "Melody" number and Merritt B. Gerstad is credited for the Hoctor Ballet.
In the advertising for the film, MGM boasted of the film's ostentatious nature, bragging that it was "SO BIG that only MGM could handle it", with its "countless beauties, trained lions, ponies, dogs and other animals". Busby Berkeley, who had led Warner Brothers to become the leading producer of musicals in Hollywood in the 1930s, was a major influence on the producers which had "glamorous, excessive 1930s cinematic musical numbers". The film also came at a time when producers had begun seeing the economic and cultural importance of the cinematic medium in comparison to theater. "Variety" notes that the film producers were likely very concerned with the presentation of the film after production was wrapped up, and that the long length of the film at 176 minutes was understandable in that they probably "wanted to preserve as much footage as possible". William S. Gray was responsible for the editing of the film. Over a thousand people were employed in the production, and "The Great Ziegfeld" required 16 reels of film after the cutting.
By coincidence, Universal's 1936 film version of the Ziegfeld musical "Show Boat", the most faithful of all the film versions of the stage production, was filmed at the same time as "The Great Ziegfeld" and released in the same year.
Screenplay.
The screenplay by William Anthony McGuire was a "novelty" to many audiences who were familiar with the theatrical Broadway shows of the follies. The script, although fictionalized with embellishments needed for the motion picture, did show some accuracies in the life of Ziegfeld. Frank S. Nugent of "The New York Times" said of the script: "What William Anthony McGuire has attempted in his screen play, and with general success, is to encompass not merely the fantastic personal history of Ziegfeld but the cross-sectional story of the development of the Follies, the Midnight Frolic on the New Amsterdam Roof and the other theatrical enterprises floated under the Glorifier's aegis during a span of about forty years. The two biographies—of the man and of his creations—are, naturally, inseparable; but both have been told with such wealth of detail and circumstance (real and imaginative) that even the three-hour film narrative is fragmentary and, in some places, confused."
Although it has some accuracies, "The Great Ziegfeld" takes many key liberties with Ziegfeld's life and the history of the "Follies", resulting in many inaccuracies. The earlier scenes with Sandow, the milk bath advertising scenario, and many other sequences including several of the dramatic ups and downs of the film were fictional. George Gershwin's "Rhapsody in Blue" was never featured in the "Follies", and the number "A Pretty Girl Is Like a Melody" was written for the 1919 "Follies", not the first edition of the revue, as shown in the film. Ray Bolger was never cast in a "Follies" show, and although she was born in the U.S, Billie Burke grew up in England and spoke with a Mid-Atlantic accent throughout her life; Loy who portrays her clearly has an American accent in the film.
In the film, the last few lines of the song "Ol' Man River" (from "Show Boat") are sung by what sounds like a tenor, while the song was intended for bass Paul Robeson and sung in the original production by bass-baritone Jules Bledsoe. Further, the screenplay also gives the impression that the successful original production of "Show Boat", which Ziegfeld produced, closed because of the Great Depression. In fact "Show Boat" ended its original 1927 run in the spring of 1929 and the stock market crash did not occur until October of that year. It was the 1932 revival of the show (also produced by Ziegfeld shortly before his death), not the original production, that was affected by the Depression. 
In real life, Ziegeld did not die in his room at the Hotel Warwick (not mentioned) which stood in front of the Ziegfeld Theatre; he actually died in Los Angeles and had not even spent his last years in New York. However, McGuire did capture a number of Ziegfeld's traits, such as sending telegrams to people even in close proximity, his belief that elephants were a symbol of good luck, his exquisite taste in costumes and design, and perfectionism over his productions, especially lighting and rostrum pedestaling. McGuire's script, now in the Henry E. Huntington Library, San Marino, California, is dated September 21, 1935, probably the date when it was finalized.
Casting.
Initially, the main cast proposed for the film included Marilyn Miller, Gilda Gray, Ann Pennington, and Leon Errol. Featured in the film are William Powell as Ziegfeld, Myrna Loy as Billie Burke, Luise Rainer as Anna Held, Nat Pendleton as Eugen Sandow, and Frank Morgan. Powell admitted to being "amazed" with the film after viewing it and was very grateful at having had the privilege to portray Ziegfeld, considering it to be a very important moment in his career. He said, "After seeing this film I can see that most of the characters I have played before were contrived. They had no 'folks', as the character of Ziegfeld had in this picture. Their father was a pen and their mother was a bottle of ink. Here was a character with flesh, blood and sinews. I felt for the first time in my acting career I had tried the full measure of a man, regardless of my shortcomings in playing him."
Many of the performers of the earlier Broadway version of the Ziegfeld Follies were cast in the film as themselves, including Fanny Brice and Harriet Hoctor, the ballet dancer and contortionist. "The Great Ziegfeld" marked Rainer's second Hollywood film role after "Escapade" (also with Powell). Fanny Brice appears as a comedian in the abridged song sequence "My Man" and played an effective version of herself in addition to her routine comic role as the funny girl. 
Nat Pendleton, a freestyle wrestler who had won the silver medal at the 1920 Summer Olympics in Antwerp and had appeared alongside Powell in "The Thin Man" (1934), was cast as the circus strongman Eugen Sandow.
Billie Burke objected to her role being cast with another actress (Myrna Loy) since she was also an actress under contract to the studio and could play herself, but the producers concluded that at that point she was not a big enough star to play herself in "The Great Ziegfeld". However, according to Emily W. Leider, Burke was not keen on playing her younger self and says that Billie Burke's biographer stated that Miriam Hopkins would have been her first choice to play her part, not Loy. Burke herself worked as technical consultant, and although she did not object to Marilyn Miller performing a number, she was influential in the studio's refusal to give her the higher billing and salary she had demanded, which led to Miller walking away from the film.
Both Miller and Lillian Lorraine threatened legal action if so much as their names were mentioned in the film. Thus Miller's character was renamed "Sally Manners", and Lorraine's character was renamed "Audrey Dane" (played by Virginia Bruce). In real life, Ziegfeld had reportedly been obsessed with Miller, and was involved in numerous sex scandals. In 1922 Miller had given an interview in which she accused him of "making love to chorus girls" and sending her a diamond ring as "big as her hand"; this essence of Ziegfeld's character is captured in the film. Incidentally, Miller died from toxicity complications after surgery just before the release of the film on April 7, 1936, which led one reviewer writing in "Liberty" to denounce an urban legend which had arisen surrounding the timing of her death, saying, "It's not true that Marilyn Miller died of a broken heart at not getting the lead in this." Another myth surrounding her untimely death at the age of 37 is that she had contracted syphilis.
Frank Morgan, a stage and film character actor, played the role of promoter Billings in the film. Dennis Morgan, in an uncredited role, performs in "A Pretty Girl Is Like a Melody" (dubbed by Allan Jones). Pat Ryan, the future Pat Nixon, wife of Richard Nixon and First Lady of the United States, was an extra in the film. Will Rogers was to appear in the film, but he was killed in a plane crash in August 1935. He was played by stand-in A. A. Trimble.
Costumes.
The extravagant costumes, which even Ziegfeld initially considered too flamboyant, were designed by Adrian, who had worked with many of the greatest actresses of the period including Greta Garbo, Norma Shearer, Jeanette MacDonald, Jean Harlow, Katharine Hepburn and Joan Crawford, and later designed for films such as "Marie Antoinette" (1938), "The Women" (1939), and "The Wizard of Oz" (1939). Howard Gutner documents that due to MGM's wealth and the high budget, Adrian was able to indulge in "sheer lavishness" in making the costumes, surpassing anything he had done previously. It took 250 tailors and seamstresses six months to sew the costumes that Adrian had designed for the film, using of silver sequins and of white ostrich plumes. The costumes worn by women in the film are diverse, varying from "puffy hooped skirts to catlike leotards" to "layers of tulle and chiffron", with the men mostly wearing black tuxedos.
Mise en scène and music.
Leonard, a film director who specialized in melodrama and musicals, anchored the music for the film, working with Walter Donaldson, Irving Berlin, and lyricist Harold Adamson. The extravagant dances and ensemble sequences were choreographed by Seymour Felix and Harold Adamson, including the song sequence of "A Pretty Girl Is Like a Melody" (it was Irving Berlin's 13th annual edition in 1919). The "A Pretty Girl Is Like a Melody" set, known as the "Wedding Cake", involved several weeks of shooting time and was reported to have cost US$220,000 (US$ in dollars). As many as 180 performers were involved in the scenes which included singers, dancers and musicians. The sequence presented started with the "Rhapsody in Blue" and concluded with Virginia Bruce descending from the volute as it rotated, a satin curtain being lowered from the top enclosing the volute.
The curtains, made of rayon silk, measured . Sheldon Hall and Stephen Neale note the theatrical sense that the cinematographers achieved through shooting the sequence in virtually a single take. They mention that "the camera traverses an enormous platform set contained within a curtained proscenium (also enormous)", and that the "set itself revolves to meet the camera, rather than the camera entering the space of the set." Linda Mizejewski, author of a book on the Ziegfeld girls, argues that the Pretty Girl sequence is more than just about being showy; it is symbolic of womanhood which "powerfully visualizes women as the raw material for male aesthetic vision and design". In the film she believes that womanhood is defined by the "young, white, blond and slender" female, which in the sequence are "delineated as the fluffy, artificial tiers of costuming and staging".
The Harriet Hoctor ballet music was scored by Con Conrad to lyrics written by Herb Magidson. The circus ballet was an adaptation from the old Ziegfeld stage shows. "Variety" called the Hoctor ballet "in itself intricate with its maneuverings of six Russian wolfhounds in terp formations", and said that the "A Pretty Girl Is Like a Melody" sequence in the film is a "nifty Berlin tune becomes the fulcrum for one of Frank Skinner's best arrangements as Arthur Lange batons the crescendos into a mad, glittering potpourri of Saint-Saëns and Gershwin, Strauss and Verdi, beautifully blended against the Berlinesque background. It's a scenic flash which makes the auditor wonder 'What can they do to follow that?' meaning in this or future film production." Juan Antonio Ramírez refers to the wedding cake as a "famous spiral column", citing it as one of the best known pieces of mobile architecture in film, but notes that in design the cake was not exclusive to "The Great Ziegfeld", explaining that a wedding cake, albeit less flamboyant, had appeared in previous films such "The King of Jazz" (1930), "The Kid from Spain" (1932), "Top Hat" (1935), and "Follow the Fleet" (1935). Ramírez describes the film's "Mise en scène" as representing "the last word in flashy vulgarity, Surrealist kitsch, or perhaps both at once".
Finale:
Aftermath.
Farida Mahzar filed a lawsuit against the filmmakers shortly before her death, claiming that they "presented Little Egypt as a lewd character". 14 witnesses who had seen the act at the 1893 Chicago World Fair supported this, although the lawsuit was dropped after Mahzar died from a heart attack. Burke caused much controversy and upset among many of Ziegfeld's friends and colleagues when she sold the rights to a production on Broadway, the "Ziegfeld Follies", also starring Fanny Brice, at the time the film was released in 1936, due to the fact that the show was produced by the Shubert brothers, whom Ziegfeld detested. Worse still for his associates, was that the show was a bigger success than Ziegfeld's last production of the Follies in 1931. The "Ziegfeld Follies" under Vincente Minnelli was initially performed in December 1935, before making its Broadway debut on January 30, 1936. It was performed in Boston and Philadelphia until the production was postponed after Brice collapsed on stage with exhaustion. When it reopened on Broadway in September 1936, five months after the release of the film, it was retitled "The New Ziegfeld Follies of 1936–1937", and was revamped considerably, with changes to the show's humor.
In 1941, Metro-Goldwyn-Mayer produced a sequel entitled "Ziegfeld Girl", starring James Stewart, Judy Garland, Hedy Lamarr, and Lana Turner, which recycled some film from "The Great Ziegfeld". In 1946, MGM made another sequel, "Ziegfeld Follies", directed by Vincente Minnelli, director of the stage show.
Reception.
Box office.
According to MGM records, the film earned a then-massive $3,089,000 in the US and Canada and $1,584,000 elsewhere resulting in a profit of $822,000.
Critical response at the time of release.
The film, which premiered in Los Angeles at the Carthay Circle Theatre, was the first musical film in history for which one of its cast members won an Academy Award. Luise Rainer received the Best Actress Oscar for her portrayal of Ziegfeld's first wife, Anna Held. The film, the pride of MGM at a time when Warner Brothers and RKO Pictures were the leading studios in Hollywood for musical production, was a major commercial and critical success and one of the most successful films of the 1930s, grossing US$4,673,000 (US$ in dollars) worldwide at the box office. It was acclaimed upon release as the greatest musical biography to be made in Hollywood and still remains a standard in musical film making. At just short of three hours, "The Great Ziegfeld" was also the longest talking film of the time. (D. W. Griffith's "The Birth of a Nation" and "Intolerance", both silent films, had each run over three hours.) TCM has acclaimed the "A Pretty Girl Is Like a Melody" sequence as one of "the most famous musical numbers ever filmed". Thomas S. Hischak has said that the film has rarely been topped for pure showmanship and glamor, and "Variety" considered it an "outstanding picture", a "symbol of a tradition of show business". "Variety" praised the performances of the cast, remarking that as Ziegfeld, William Powell "endows the impersonation with all the qualities of a great entrepreneur and sentimentalist without sacrificing the shades and moods called for" and noting that Luise Rainer is "tops of the femmes with her vivacious Anna Held". Stanley Green cited the "The Great Ziegfeld" as "the first of a number of elaborate show-business screen biographies". Otis Ferguson, writing for "New Republic" magazine, remarked that the "musical numbers seem as irresistible as Ziegfeld himself". The "New York American" said that the film is "pretty nearly everything such an extravaganza should be", with "romance and reality, song and dance, gaiety and beauty, pathos and bathos". "Time" magazine qualified it as "Pretentious, packed with hokum and as richly sentimental as an Irving Berlin lyric, it is, as such, top-notch entertainment." A reviewer for the "Spokane Chronicle" praised the film for its superb acting, writing that "the great producer [Ziegfeld would have been unable to produce scenes of magnitude and splendor that are given as part of the picture telling his life." Frank S. Nugent of "The New York Times" was also highly praising of the film, noting that it had "more stars than there are in the heavens" and remarking that "the picture achieves its best moments in the larger sequences devoted to the Girls — ballet, chorus and show. At least one of these spectacular numbers, filmed to the music of Irving Berlin's "A Pretty Girl Is Like a Melody", with overtones of "Rhapsody in Blue", never has been equaled on the musical comedy stage or screen." John Mosher of "The New Yorker" called it "the most lavish display the screen has had to offer" with chorus numbers that were "gigantic and effective", though he found the romance to be "peculiarly average screen-story stuff." Both "The New York Times" and "Film Daily" rated the film in the "Ten Best" of the year.
However, not all critics were as enthusiastic about the film; Graham Green of the British "Spectator" called it a "huge inflated glass-blown object" and criticized its length, comparing it to the feat of a flagpole sitter. A number of critics, although praising the film in general, felt that Myrna Loy, who appears rather late on in the film, gave a lackluster performance as Billie Burke. Nugent said that "Miss Loy is a stately Bille Burke, and somewhat lacking, we fear, in Miss Burke's effervescence and gaiety", and Cecilia Agner thought she came across as "stilted, like her rigidly waxed and set blonde wig". Harrison Carroll of the "Los Angeles Herald-Express", however, sympathized with the difficulty of her role in portraying a prominent living actress, confessing that he was pleased that Loy did not attempt to imitate Burke's mannerisms. Emily W. Leider believes that any of her character flaws were due to a "mushy" script, rather than her performance as an actress.
Critical re-evaluation.
Although the film is still viewed as a symbol of glamor and excess during the Golden Age of Hollywood, 
today the film has more of a mixed reception, with many critics believing that the film relies on its (now-dated) extravagance and is too long; Christopher Null stated that "The Great Ziegfeld" is a "textbook case of how a film can lose its appeal over the years". Since its release the film has been criticized in particular for being unnecessarily lengthy and its overacting (particularly by Rainer), and is occasionally cited as a "prime example of the Academy's fallibility" in a year when other critically acclaimed pictures such as "Mr. Deeds Goes to Town" were released, which some argue was more deserving of Best Picture. The consensus today on the review site Rotten Tomatoes is that although the "biopic is undeniably stylish", it "loses points for excessive length, an overreliance on clichés, and historical inaccuracies", and has a 61% fresh rating. Emily W. Leider claims the film to be "more remarkable for its "legs and tinsel" extravagance than for its excellence." David Parkinson of "Empire" magazine gave the film 3 out of 5 stars and concluded that it "Drags in places and doesn't even try for a true-to-life portrait of the great theatre entrepreneur but it's shiny and big spectacle with impressive choreography." Dave Kehr of the "Chicago Reader" called it "amazingly dull, even with William Powell in the lead and guest appearances by the likes of Ray Bolger and Fanny Brice." Emanuel Levy gave it a C grade and stated that it was "overlong and overblown but ultimately mediocre as a musical movie and as a biopic of the legendary showman." James Berardinelli awarded it 2.5 out of 4 stars and stated that "although some of the production's technical aspects remain impressive, the dramatic elements come across as trite and many of the musical numbers are dated", but said that it was a "reasonably competent – albeit "airbrushed" – presentation of the main character's life."
Accolades.
The seven Academy Award nominations were announced on February 7, 1937, and on March 4, 1937, "The Great Ziegfeld" won three Oscars at the 9th Academy Awards for 1936:
Although he was not nominated for an Academy Award for his performance, Powell did receive the Screen Actor's Guild award for Best Actor in a tie with C. Aubrey Smith who was in "Little Lord Fauntleroy". In addition the Guild's Best Actress was given to Luise Rainer.
References.
Notes
Bibliography

</doc>
<doc id="44438" url="https://en.wikipedia.org/wiki?curid=44438" title="Gosnells">
Gosnells

The name Gosnells may refer to:

</doc>
<doc id="44439" url="https://en.wikipedia.org/wiki?curid=44439" title="Erotic spanking">
Erotic spanking

Erotic spanking is the act of spanking another person for the sexual arousal or gratification of either or both parties. Activities range from a spontaneous smack on bare buttocks during a sexual activity, to occasional sexual roleplay, such as ageplay, to domestic discipline and may involve the use of a hand or the use of a variety of spanking implements, such as a spanking paddle or cane. Erotic spankings are commonly combined with other forms of sexual foreplay. The most common type of erotic spanking is administered on the bare buttocks, but can also be combined with bondage, in order to heighten sexual arousal and feelings of helplessness.
Many cultures describe pain as an aphrodisiac. For example, the Kama Sutra, in particular, goes into specific detail on how to properly strike a partner during sex.
History and literature.
In some cultures, the spanking of women by the male head of the family or by the husband – sometimes called domestic discipline – has been, and sometimes continues to be, a common and approved custom. In those cultures people believe that the husband, as head of the family, has a right and duty to discipline his wife and children when he sees fit. Manuals are available to instruct the husband how to discipline his household. In most western countries, this practice has come to be regarded as unlawful and socially unacceptable wife-beating, domestic violence or abuse. Routine corporal punishment of women by their husbands, however, does still exist in some parts of the developing world, and still occurs in isolated cases in western countries. However, today, spanking of an adult tends to be confined to erotic spanking or to BDSM contexts.
One of the earliest depictions of erotic flagellation is found in the Etruscan Tomb of the Whipping from the fifth century BC, named after its depictions of eroticized flagellation.
Representations of erotic spanking and flagellation make up a large portion of Victorian pornography, for instance "1000 Nudes" by Koetzle.) Hundreds of thousands of engravings, photographs, and literary depictions of spanking and flagellation ("birching") fantasies circulated during the Victorian era, including erotic novellas like "The Whippingham Papers", "The Birchen Bouquet", "Exhibition of Female Flagellants" or the pornographic comic opera "Lady Bumtickler's Revels". Since their deaths, many well-known people have been discovered to have enjoyed spankings for erotic purposes or emotional gratification, including the noted British Army officer T. E. Lawrence ("Lawrence of Arabia"), influential English theatre critic Kenneth Tynan, TV broadcaster Frank Bough, and English writer John Mortimer.
Other examples include the poet Algernon Swinburne, as implied repeatedly in his poetry, and the philosopher Jean-Jacques Rousseau, as detailed in his autobiography "Confessions":
... Miss Lambercier... exerted a
mother's authority, even to inflicting on us... the
punishment of infants... Who would believe this childish discipline, received at eight years
old, from the hands of a woman of thirty,
should influence my propensities,
my desires, my passions, for the rest of my life...
To fall at the feet of an imperious mistress, obey her mandates, or
implore pardon, were for me the most exquisite enjoyments, and the more
my blood was inflamed by the efforts of a lively imagination the more I
acquired the appearance of a whining lover."
According to Dan Savage, journalist Jillian Keenan is "America's most prominent spanking fetishist" today. She has written about erotic spanking for the New York Times, Slate, and Pacific Standard. Keenan has argued that spanking fetishism is a form of sexual orientation, which should not be considered a mental illness.
Practice.
Implements.
A spanking may be carried out with the use of a bare or gloved hand, or with any of a variety of implements, including a paddle, strap, hairbrush, feather duster or belt. Other popular implements are canes, riding crops, whips, switches, birches, sneakers, rolled-up newspapers, rulers or "martinet".
Costume.
A spank skirt or spanking skirt has an additional opening in back designed to expose the buttocks. While the name "spank skirt" suggests that the wearer could be spanked "bare bottom" without removing or repositioning the skirt, this item may be worn for reasons other than spanking, for instance, exposure). Considered fetish wear, spank skirts are typically tight-fitting and made of fetishistic materials (such as leather, PVC or latex). Regardless of the gender of the wearer, spank skirts are usually considered female attire. The male gender role equivalent might be motorcycle chaps.
Other garments associated with spanking as well as humiliation are ruffled or rhumba panties, women's panties with rows of ruffles on the rear panel or outside.
Apparatus.
A spanking bench or spanking horse is a piece of furniture used to position a spankee on, with or without restraints. They come in many sizes and styles, the most popular of which is similar to a sawhorse with a padded top and rings for restraints. The 19th-century British dominatrix Mrs. Theresa Berkley became famous for her invention of the Berkley Horse, a similar form of BDSM apparatus.
Howard Stern's paddle machine, the "Robospanker", has been used on his show to spank numerous guests, including Jessica Jaymes, Jennifer Krum, Haydn Porter, Tabitha Stevens, Victoria Zdrok, and Valentina Vaughn.
Spanking positions.
Spanking can be administered in a number of spanking positions. The choice of position takes into account the spankee's comfort in the position for long periods of time, the spanker's ability to swing at the spankee at a comfortable, natural angle, complete access to the spankee's buttocks, the spanker's control of the spankee's position and ability to read just as necessary, safety, and the amount of strength the top is able to generate from such a position. Positions can also be chosen specifically for added effects such as increased humiliation, elevation and suspension.
References.
Notes
Further reading

</doc>
<doc id="44441" url="https://en.wikipedia.org/wiki?curid=44441" title="Pax Romana">
Pax Romana

Pax Romana (Latin for "Roman Peace") was the long period of peacefulness and minimal expansion by the Roman military force experienced by the Roman Empire after the end of the Final War of the Roman Republic and before the beginning of the Crisis of the Third Century. Since it was established by Augustus, it is sometimes called Pax Augusta. Its span was approximately 206 years (27 BC to 180 AD) according to "Encyclopedia Britannica" or 122 years (70 AD to 192 AD) according to "The Cambridge Ancient History".
Overview.
The Pax Romana is said to have been a "miracle" because prior to it there had never been peace for so many centuries in a given period of history. According to Walter Goffart however, "peace is not what one finds in itpages". Arthur M. Eckstein writes that the period needs to be seen in contrast with the much more frequent warfare that occurred in the Roman Republic in the 4th and 3rd centuries BC. Eckstein also notes that the incipient Pax Romana appeared during the Republic and that its temporal span varied with geographical region as well: "Although the standard textbook dates for the Pax Romana, the famous “Roman Peace” in the Mediterranean, are 31 BC to AD 250, the fact is that the Roman Peace was emerging in large regions of the Mediterranean at a much earlier date: Sicily after 210 peninsular Italy after 200 [BC; the Po Valley after 190 most of Spain after 133 [BC; North Africa after 100 ; and for ever longer stretches of time in the Greek East".
The first historical record of the term "Pax Romana" appears to be in a writing of Seneca the Younger in 55 AD. The concept was highly influential, being theorized upon and attempted to be copied in subsequent ages. Arnaldo Momigliano noted that ""Pax Romana" is a simple formula for propaganda, but a difficult subject for research."
The Pax Romana started after Octavian (Augustus) defeated Marc Antony in the Battle of Actium on 2 September 31 BC. He became princeps, or "first citizen". Lacking a good precedent of successful one-man rule, Augustus created a junta of the greatest military magnates and stood as the front man. By binding together these leading magnates in a coalition, he eliminated the prospect of civil war. The Pax Romana was not immediate, despite the end of the civil wars, because fighting continued in Hispania and in the Alps. Nevertheless, Augustus closed the Gates of Janus (the Roman ceremony to mark world Peace) three times, first in 29 BC and again in 25 BC. The third closure is undocumented, but Inez Scott Ryberg (1949) and Gaius Stern (2006) have persuasively dated the third closure to 13 BC with the Ara Pacis ceremony. At the time of the Ludi Saeculares in 17 BC the concept of Peace was publicized, and in 13 BC was proclaimed when Augustus and Agrippa jointly returned from pacifying the provinces. The Ara Pacis ceremony was no doubt part of this announcement.
Augustus faced a problem making peace an acceptable mode of life for the Romans, who had been at war with one power or another continuously for 200 years. Romans regarded peace not as an absence of war, but the rare situation that existed when all opponents had been beaten down and lost the ability to resist. Augustus' challenge was to persuade Romans that the prosperity they could achieve in the absence of warfare was better for the Empire than the potential wealth and honor acquired when fighting a risky war. Augustus succeeded by means of skillful propaganda. Subsequent emperors followed his lead, sometimes producing lavish ceremonies to close the Gates of Janus, issuing coins with Pax on the reverse, and patronizing literature extolling the benefits of the Pax Romana.
Similar terms generic notion.
Given the prominence of the concept of the "Pax Romana", historians have coined variants of the term to describe systems of relative peace that have been established, attempted or argued to have existed. Such times have been credited to the British Empire during the 19th century. Some variants include:
More generically, the concept has been referred to as pax imperia, (sometimes spelled as pax imperium) meaning imperial peace, or—less literally—hegemonic peace. Raymond Aron notes that imperial peace—peace achieved through hegemony—sometimes, but not always—can become civil peace. As an example, the German Empire's imperial peace of 1871 (over its internal components like Saxony) slowly evolved into the later German state. As a counter-example, the imperial peace of Alexander the Great's empire dissolved because the Greek city states maintained their political identity and more importantly, embrios of their own armed forces. Aron notes that during the Pax Romana, the Jewish war was a reminder that the overlapping of the imperial institutions over the local ones did not erase them and the overlap was a source of tension and flare-ups. Aron summarizes that "In other words, "imperial peace" becomes civil peace insofar as the memory of the previously independent political units are effaced, insofar as individuals within a pacified zone feel themselves less united to the traditional or local community and more to the conquering state.'
The concept of Pax Romana was highly influential, and attempted to be imitated in the Byzantine Empire as well as in the Christian West, where it morphed into the Peace and Truce of God ("pax Dei" and "treuga Dei"). A theoretician of the imperial peace during the Middle Ages was Dante Aligheri. Dante's works on the topic were analyzed at the beginning of the 20th century by William Mitchell Ramsay in the book "The Imperial Peace; An Ideal in European History" (1913).

</doc>
<doc id="44442" url="https://en.wikipedia.org/wiki?curid=44442" title="Thora Birch">
Thora Birch

Thora Birch (born March 11, 1982) is an American actress. She made her early roles in the short-lived sitcom "Day by Day" and in "Purple People Eater" (1988), in which she won a Young Artist Award for "Best Young Actress Under Nine Years of Age". She also starred in other films, such as "All I Want for Christmas" (1991), "Patriot Games" (1992), "Hocus Pocus" (1993), "Monkey Trouble" (1994), "Now and Then" (1995) and "Alaska" (1996).
Her breakthrough role came in 1999 with the Academy Award winning film, "American Beauty". Her performance was well received by both critics and audiences and brought Birch to international recognition. She later played the lead role in "Ghost World" (2001) for which she received a Golden Globe Award nomination for Best Actress – Motion Picture Musical or Comedy. She appeared in independent films, such as "Dark Corners" (2006), "Train" (2008) and "Winter of Frozen Dreams" (2009). 
After taking a break from acting, Birch resumed her acting career and plays software engineer Morgan in Carlton Cuse's 2016 television series "Colony".
Early life.
Birch was born in Los Angeles, the eldest child of Jack Birch and Carol Connors. Her parents, who have been her business managers throughout her acting career, are former adult film actors; both appeared in the film "Deep Throat". Birch is of German Jewish, Scandinavian, and Italian ancestry. The family's original surname was Biersch. Her name Thora is derived from the name of the Norse God of Thunder and Lightning, Thor; she has a younger brother named Bolt. Because of their own experience with the entertainment industry, Birch's parents were reluctant to encourage her, but they were persuaded to show her photograph to agents by a babysitter who noticed her imitating commercials. She had several parts in the late '80s, such as advertisements for Burger King, California Raisins, Quaker Oats and Vlasic Pickles.
Career.
1988–1995.
Birch made her film debut in "Purple People Eater" and won her a Youth In Film Award. She also played Molly in the short-lived television series "Day By Day". She was credited as "Thora". Birch played 'tomboy' Billie Pike in "Paradise", which starred Don Johnson, Melanie Griffith and Elijah Wood. During the 1990s, she starred in "All I Want for Christmas" (1991), "Hocus Pocus" (1993) and "Monkey Trouble" (1994). She appeared in "Patriot Games" (1992) and "Clear and Present Danger" (1994), as the daughter of Jack Ryan (Harrison Ford). Birch starred in "Now and Then" (1995) with Gaby Hoffmann, Christina Ricci, Demi Moore, Rosie O'Donnell and Melanie Griffith.
1996–2001.
In 1996, she landed a leading role in the adventure film, "Alaska" (1996). After guest-starring appearances in "The Outer Limits", "Promised Land" and "Touched by an Angel", Birch took a break from acting.
In 1999, she returned in the made-for-TV film "Night Ride Home" and also took a small uncredited role in the Natalie Portman film "Anywhere but Here". Later, Birch won critical praise playing the role of Jane Burnham in "American Beauty" and was nominated for a British Academy of Film and Television Arts award. The film itself went on to win the Academy Award for Best Picture. As Birch was 16 at the time she made the film, and thus classified as a minor in the United States, her parents had to approve her brief topless scene in the film. They and child labor representatives were on the set for the shooting of the scene. After supporting roles in "The Smokers" (2000) where Birch was called "a scene-stealer" by "The Hollywood Reporter", and "Dungeons & Dragons" (2000), she landed the lead role alongside Keira Knightley in the horror film "The Hole" (2001). The film was released in the cinema in the UK, and went direct-to-video in the US almost two years later and gained divided reviews. "BBC.co.uk" wrote: "Given that she has a much leaner role than the one she enjoyed in ""American Beauty"", the qualities which made her flourish in that multi-Oscar-winner are still abundantly clear".
Birch landed the leading role in "Ghost World" (2001), with Scarlett Johansson, Steve Buscemi and Brad Renfro. Her performances gained positive response from film critics and she was nominated for a Golden Globe for her performance. In his review for "The New York Times", A. O. Scott praised her: "Thora Birch, whose performance as Lester Burnham's alienated daughter was the best thing about "American Beauty", plays a similar character here, with even more intelligence and restraint". In his "Chicago Reader" review, Jonathan Rosenbaum wrote, "Birch makes the character an uncanny encapsulation of adolescent agonies without ever romanticizing or sentimentalizing her attitudes, and Clowes and Zwigoff never allow us to patronize her". However, in his review for "The New York Observer", Andrew Sarris disliked Birch's character of Enid and remarked: "I found Enid smug, complacent, cruel, deceitful, thoughtless, malicious and disloyal".
2002–2012.
Birch played Liz Murray in the television film "" (2003), for which she received an Emmy nomination. The next year, she played Karen in "Silver City" (2004), written and directed by John Sayles, which after premiering at that year's Cannes Film Festival, received a mixed reception.
In 2006, Birch starred in the low-budget horror film "Dark Corners", as a troubled young woman who wakes up one day as a different person—someone who is stalked by creatures. Tony Sullivan, for "Eyeforfilm.co.uk", found Birch "convincing as the two halves of this split personality". She also had the leading role in the 2008 slasher "Train".
She starred alongside Brittany Murphy in the psychological thriller "Deadline". The film first premiered directly-to-video in October 2009 in the U.K. before being released in December in the U.S. In 2009. She starred in the mystery film "Winter of Frozen Dreams". A controversy during filming involving Birch's father and his forced presence during Birch's taping of a sex scene for the film made tabloid headlines. In January 2010, Birch played Sidney Bloom in the Lifetime movie "The Pregnancy Pact".
Birch was cast and scheduled to make her American stage debut in the off Broadway revival of "Dracula", but was fired for the behavior of her father, her manager at the time, who physically threatened one of the show's cast members. Reflecting on the incident in January 2014, Birch revealed that not only was she in a "state of shock," but later accepted that she had upset a lot of people and those around her wanted her to "be not fine."
In 2012, she appeared as the lead character in "Petunia", in which she also produced and one that received a limited release. About the film, Birch said: "I think it's just something that's a little bit different from your standard summer fare. It's a little bit more intimate. It's also a very modern tale. I think it's actually honest."
2015–present.
After resuming her acting career, Birch portrays software engineer Morgan in the Carlton Cuse series "Colony". She is also starring in the independent film "The Etruscan Smile" with Brian Cox, currently shooting in San Francisco and Scotland and set for release in 2017.

</doc>
<doc id="44443" url="https://en.wikipedia.org/wiki?curid=44443" title="Anti-capitalism">
Anti-capitalism

Anti-capitalism encompasses a wide variety of movements, ideas and attitudes that oppose capitalism. Anti-capitalists, in the strict sense of the word, are those who wish to replace capitalism with another type of economic system.
Socialism.
Socialism advocates public or direct worker ownership and administration of the means of production and allocation of resources, and a society characterized by equal access to resources for all individuals, with an egalitarian method of compensation.
1. A theory or policy of social organisation which aims at or advocates the ownership and control of the means of production, capital, land, property, etc., by the community as a whole, and their administration or distribution in the interests of all.
2. Socialists argue for a cooperative/community economy, or the commanding heights of the economy, with democratic control by the people over the state, although there have been some undemocratic philosophies. "State" or "worker cooperative" ownership is in fundamental opposition to "private" ownership of means of production, which is a defining feature of capitalism. Most socialists argue that capitalism unfairly concentrates power, wealth and profit, among a small segment of society that controls capital and derives its wealth through exploitation.
Socialists argue that the accumulation of capital generates waste through externalizations that require costly corrective regulatory measures. They also point out that this process generates wasteful industries and practices that exist only to generate sufficient demand for products to be sold at a profit (such as high-pressure advertisement); thereby creating rather than satisfying economic demand.
Socialists argue that capitalism consists of irrational activity, such as the purchasing of commodities only to sell at a later time when their price appreciates, rather than for consumption, even if the commodity cannot be sold at a profit to individuals in need; they argue that "making money", or accumulation of capital, does not correspond to the satisfaction of demand.
Private ownership imposes constraints on planning, leading to inaccessible economic decisions that result in immoral production, unemployment and a tremendous waste of material resources during crisis of overproduction. According to socialists, private property in the means of production becomes obsolete when it concentrates into centralized, socialized institutions based on private appropriation of revenue (but based on cooperative work and internal planning in allocation of inputs) until the role of the capitalist becomes redundant. With no need for capital accumulation and a class of owners, private property in the means of production is perceived as being an outdated form of economic organization that should be replaced by a free association of individuals based on public or common ownership of these socialized assets. Socialists view private property relations as limiting the potential of productive forces in the economy.
Early socialists (Utopian socialists and Ricardian socialists) criticized capitalism for concentrating power and wealth within a small segment of society, and does not utilise available technology and resources to their maximum potential in the interests of the public.
Anarchist and libertarian socialist criticisms.
For the influential German individualist anarchist philosopher Max Stirner "private property is a spook which "lives by the grace of law" and it "becomes 'mine' only by effect of the law". In other words, private property exists purely "through the protection of the State, through the State's grace." Recognising its need for state protection, Stirner is also aware that "t need not make any difference to the 'good citizens' who protects them and their principles, whether an absolute King or a constitutional one, a republic, if only they are protected. And what is their principle, whose protector they always 'love'? Not that of labour", rather it is "interest-bearing possession . . . labouring capital, therefore . . . labour certainly, yet little or none at all of one's own, but labour of capital and of the -- subject labourers"." French anarchist Pierre Joseph Proudhon opposed government privilege that protects capitalist, banking and land interests, and the accumulation or acquisition of property (and any form of coercion that led to it) which he believed hampers competition and keeps wealth in the hands of the few. The Spanish individualist anarchist Miguel Gimenez Igualada sees "capitalism is an effect of government; the disappearance of government means capitalism falls from its pedestal vertiginously...That which we call capitalism is not something else but a product of the State, within which the only thing that is being pushed forward is profit, good or badly acquired. And so to fight against capitalism is a pointless task, since be it State capitalism or Enterprise capitalism, as long as Government exists, exploiting capital will exist. The fight, but of consciousness, is against the State.".
Within anarchism there emerged a critique of wage slavery which refers to a situation perceived as quasi-voluntary slavery, where a person's livelihood depends on wages, especially when the dependence is total and immediate. It is a negatively connoted term used to draw an analogy between slavery and wage labor by focusing on similarities between owning and renting a person. The term "wage slavery" has been used to criticize economic exploitation and social stratification, with the former seen primarily as unequal bargaining power between labor and capital (particularly when workers are paid comparatively low wages, e.g. in sweatshops), and the latter as a lack of workers' self-management, fulfilling job choices and leisure in an economy. Libertarian socialists believe if freedom is valued, then society must work towards a system in which individuals have the power to decide economic issues along with political issues. Libertarian socialists seek to replace unjustified authority with direct democracy, voluntary federation, and popular autonomy in all aspects of life, including physical communities and economic enterprises. With the advent of the industrial revolution, thinkers such as Proudhon and Marx elaborated the comparison between wage labor and slavery in the context of a critique of societal property not intended for active personal use, Luddites emphasized the dehumanization brought about by machines while later Emma Goldman famously denounced wage slavery by saying: "The only difference is that you are hired slaves instead of block slaves.". American anarchist Emma Goldman believed that the economic system of capitalism was incompatible with human liberty. "The only demand that property recognizes," she wrote in "Anarchism and Other Essays", "is its own gluttonous appetite for greater wealth, because wealth means power; the power to subdue, to crush, to exploit, the power to enslave, to outrage, to degrade." She also argued that capitalism dehumanized workers, "turning the producer into a mere particle of a machine, with less will and decision than his master of steel and iron."
Noam Chomsky contends that there is little moral difference between chattel slavery and renting one's self to an owner or "wage slavery". He feels that it is an attack on personal integrity that undermines individual freedom. He holds that workers should own and control their workplace. Many libertarian socialists argue that large-scale voluntary associations should manage industrial manufacture, while workers retain rights to the individual products of their labor. As such, they see a distinction between the concepts of "private property" and "personal possession". Whereas "private property" grants an individual exclusive control over a thing whether it is in use or not, and regardless of its productive capacity, "possession" grants no rights to things that are not in use.
In addition to individualist anarchist Benjamin Tucker's "big four" monopolies (land, money, tariffs, and patents), Carson argues that the state has also transferred wealth to the wealthy by subsidizing organizational centralization, in the form of transportation and communication subsidies. He believes that Tucker overlooked this issue due to Tucker's focus on individual market transactions, whereas Carson also focuses on organizational issues. The theoretical sections of "Studies in Mutualist Political Economy" are presented as an attempt to integrate marginalist critiques into the labor theory of value. Carson has also been highly critical of intellectual property. The primary focus of his most recent work has been decentralized manufacturing and the informal and household economies. Carson holds that “Capitalism, arising as a new class society directly from the old class society of the Middle Ages, was founded on an act of robbery as massive as the earlier feudal conquest of the land. It has been sustained to the present by continual state intervention to protect its system of privilege without which its survival is unimaginable.” Carson coined the pejorative term "vulgar libertarianism," a phrase that describes the use of a free market rhetoric in defense of corporate capitalism and economic inequality. According to Carson, the term is derived from the phrase "vulgar political economy," which Karl Marx described as an economic order that "deliberately becomes increasingly apologetic and makes strenuous attempts to talk out of existence the ideas which contain the contradictions in economic life."
Marxism.
Karl Marx saw capitalism as a historical stage, once progressive but which would eventually stagnate due to internal contradictions and would eventually be followed by socialism. Karl Marx claimed that capitalism was nothing more than a necessary stepping stone for the progression of man, which would then face a political revolution before embracing the classless society. Marxists define capital as "a social, economic relation" between people (rather than between people and things). In this sense they seek to abolish capital. They believe that private ownership of the means of production enriches capitalists (owners of capital) at the expense of workers ("the rich get richer, and the poor get poorer"). In brief, they argue that the owners of the means of production do not work and therefore exploit the workerforce. In Karl Marx's view, the capitalists would eventually accumulate more and more capital impoverishing the working class, creating the social conditions for a revolution that would overthrow the institutions of capitalism. Private ownership over the means of production and distribution is seen as a dependency of non-owning classes on the ruling class, and ultimately a source of restriction of human freedom.
Criticisms of anti-capitalism.
In constantly observing the negative side(s) of capitalism, anti-capitalists remain focused on capitalism, thus co-"performing" and further sustaining the actually criticised unsustainable capitalist system. Thus, the impression of capitalism as "hyper-adaptive" "system without an outside". One way out of the trap is to understand that the observation of capitalism, a system strongly biased by and to the economy, implies functional differentiation. As the economy is only one out of 10 function systems, however, "both" pro- and anti-capitalist visions of society imply this economy-bias and, in return, a neglect of other function systems. Effective strategies for alternatives to capitalism therefore require a stronger focus on the non-economic function systems. A corresponding re-coding of capitalist organisations has recently been proposed.

</doc>
<doc id="44445" url="https://en.wikipedia.org/wiki?curid=44445" title="Greg Bear">
Greg Bear

Gregory Dale "Greg" Bear (born August 20, 1951) is an American writer best known for science fiction. His work has covered themes of galactic conflict ("Forge of God" books), artificial universes ("The Way" series), consciousness and cultural practices ("Queen of Angels"), and accelerated evolution ("Blood Music", "Darwin's Radio", and "Darwin's Children"). His most recent work is the Forerunner Trilogy, written in the Halo universe. Greg Bear has written 44 books in total. Greg Bear was also one of the five co-founders of the San Diego Comic-Con.
Early life.
Bear was born in San Diego, California. He attended San Diego State University (1968–73), where he received a Bachelor of Arts degree. At the University, he was a teaching assistant to Elizabeth Chater in her course on science fiction writing, and in later years her friend.
Career.
Bear is often classified as a hard science fiction author, based on the scientific details in his work. Early in his career, he also published work as an artist, including illustrations for an early version of the Star Trek Concordance and covers for "Galaxy" and "F&SF". He sold his first story, "Destroyers", to "Famous Science Fiction" in 1967.
Bear often addresses major questions in contemporary science and culture with fictional solutions. For example, "The Forge of God" offers an explanation for the Fermi paradox, supposing that the galaxy is filled with potentially predatory intelligences and that young civilizations that survive are those that don't attract their attention—by staying quiet. In "Queen of Angels", Bear examines crime, guilt, and punishment in society. He frames these questions around an examination of consciousness and awareness, including the emergent self-awareness of highly advanced computers in communication with humans. In "Darwin's Radio" and "Darwin's Children", he addresses the problem of over-population with a mutation in the human genome making, basically, a new series of humans. The question of cultural acceptance of something new and unavoidable is also brought up.
One of Bear's favorite themes is reality as a function of observers. In "Blood Music", reality becomes unstable as the number of observers—trillions of intelligent single-cell organisms—spirals higher and higher. "Anvil of Stars" (sequel to "The Forge of God") and "Moving Mars" postulate a physics based on information exchange between particles, capable of being altered at the "bit level". (Bear has credited the inspiration for this idea to Frederick Kantor's 1967 treatise "Information Mechanics.") In "Moving Mars", this knowledge is used to remove Mars from the solar system and transfer it to an orbit around a distant star.
"Blood Music" was first published as a short story (1983) and then expanded to a novel (1985). It has also been credited as the first account of nanotechnology in science fiction. More certainly, the short story is the first in science fiction to describe microscopic medical machines and to treat DNA as a computational system capable of being reprogrammed; that is, expanded and modified. In later works, beginning with "Queen of Angels" and continuing with its sequel, "Slant", Bear gives a detailed description of a near-future nanotechnological society. This historical sequence continues with "Heads"—which may contain the first description of a so-called "quantum logic computer"—and with "Moving Mars". This sequence also charts the historical development of self-awareness in AIs. Its continuing character Jill was inspired in part by Robert A. Heinlein's self-aware computer Mycroft HOLMES (High-Optional, Logical, Multi-Evaluating Supervisor) in "The Moon Is a Harsh Mistress".
Bear, Gregory Benford, and David Brin wrote a trilogy of prequel novels to Isaac Asimov's influential "Foundation" trilogy. Bear is credited for the middle book.
While most of Bear's work is science fiction, he has written in other fiction genres. Examples include "Songs of Earth and Power" (fantasy) and "Psychlone" (horror). Bear has described his "Dead Lines", which straddles the line between science fiction and fantasy, as a "high-tech ghost story". He has received many accolades, including five Nebula Awards and two Hugo Awards.
Bear cites Ray Bradbury as the most influential writer in his life. He met Bradbury in 1967 and had a lifelong correspondence. As a teenager Bear attended Bradbury lectures and events in Southern California. 
He also serves on the Board of Advisors for the Museum of Science Fiction.
Personal life.
In 1975, Bear married Christina M. Nielson; they divorced in 1981. In 1983, he married Astrid Anderson, the daughter of science fiction author Poul Anderson. They have two children, Erik and Alexandra. They have resided near Seattle, Washington.
He is a deist.
On September 23, 2014, Bear underwent surgery to repair an aortic artery dissection. The procedure included installation of a mechanical aortic valve
Works.
Novels.
Series.
Novels in internal chronology:

</doc>
<doc id="44446" url="https://en.wikipedia.org/wiki?curid=44446" title="Condorcet method">
Condorcet method

A Condorcet method () is any election method that elects the candidate that would win by majority rule in all pairings against the other candidates, whenever one of the candidates has that property. A candidate with that property is called a "Condorcet winner" (named for the 18th-century French mathematician and philosopher Marie Jean Antoine Nicolas Caritat, the Marquis de Condorcet, who championed such outcomes). A Condorcet winner doesn't always exist because majority preferences can be like rock-paper-scissors: for each candidate, there can be another that is preferred by some majority (this is known as Condorcet paradox).
Voting methods that always elect the Condorcet winner (when one exists) are the ones that satisfy the Condorcet criterion.
Most Condorcet methods have a single round of voting, in which each voter ranks the candidates from top to bottom. A voter's ranking is often called his or her "order of preference," although it may not match his or her sincere order of preference since voters are free to rank in any order they choose and may have strategic reasons to misrepresent preferences. There are many ways that the votes can be tallied to find a winner, and not all will elect the Condorcet winner whenever one exists. The methods that will—the Condorcet methods—can elect different winners when no candidate is a Condorcet winner. Thus the Condorcet methods can differ on which other criteria they satisfy.
The Robert's Rules method for voting on motions and amendments is also a Condorcet method even though the voters do not vote by expressing their orders of preference. There are multiple rounds of voting, and in each round the vote is between two of the alternatives. The loser (by majority rule) of a pairing is eliminated, and the winner of a pairing survives to be paired in a later round against another alternative. Eventually only one alternative remains, and it is the winner. This is analogous to a single-winner tournament; the total number of pairings is one less than the number of alternatives. Since a Condorcet winner will win by majority rule in each of its pairings, it will never be eliminated by Robert's Rules. But this method cannot reveal a voting paradox in which there is no Condorcet winner and a majority prefer an early loser over the eventual winner. A considerable portion of the literature on social choice theory is about the properties of this method since it is widely used and is used by important organizations (legislatures, councils, committees, etc.). It is not practical for use in public elections, however, since its multiple rounds of voting would be very expensive for voters, for candidates, and for governments to administer.
Ramon Llull devised the earliest known Condorcet method in 1299. His method did not have voters express orders of preference; instead, it had a round of voting for each of the possible pairings of candidates. (This was more like the Robert's Rules method except it was analogous to a round-robin tournament instead of a single-elimination tournament.) The winner was the alternative that won the most pairings.
Summary.
The concise rule that defines a Condorcet method can be stated in a single sentence: 
Because of the possibility of the Condorcet paradox, it is possible, but unlikely, that this objective cannot be realized in a specific election. This is sometimes called a "Condorcet cycle" or just "cycle" and can be thought of as Candidate Rock beating Candidate Scissors, Candidate Scissors beating Candidate Paper, and Candidate Paper beating Candidate Rock. It is only in how the various Condorcet methods resolve such a cycle is how they effectively differ. If there is no cycle, all Condorcet methods elect the same candidate and are operationally equivalent.
For most Condorcet methods, those counts usually suffice to determine the complete order of finish. They always suffice to determine whether there is a Condorcet winner. Additional information may be needed in the event of ties. Ties can be pairings that have no majority, or they can be majorities that are the same size; these ties will be rare when there are many voters. Some Condorcet methods may have other kinds of ties; for example, it would not be rare for two or more candidates to win the same number of pairings, when there is no Condorcet winner.
Definition.
A Condorcet method is a voting system that will always elect the Condorcet winner; this is the candidate whom voters prefer to each other candidate, when compared to them one at a time. This candidate can be found by conducting a series of pairwise comparisons, using the basic procedure described above. For "N" candidates, this requires ½"N"("N"−1) pairwise hypothetical elections. For example, with 5 candidates there are 10 pairwise comparisons to be made. The family of Condorcet methods is also referred to collectively as Condorcet's method. A voting system that always elects the Condorcet winner when there is one is described by electoral scientists as a system that satisfies the Condorcet criterion.
In certain circumstances an election has no Condorcet winner. This occurs as a result of a kind of tie known as a "majority rule cycle", described by Condorcet's paradox. The manner in which a winner is then chosen varies from one Condorcet method to another. Some Condorcet methods involve the basic procedure described below, coupled with a Condorcet completion method—a method used to find a winner when there is no Condorcet winner. Other Condorcet methods involve an entirely different system of counting, but are classified as Condorcet methods because they will still elect the Condorcet winner if there is one.
It is important to note that not all single winner, ranked voting systems are Condorcet methods. For example, instant-runoff voting and the Borda count do not satisfy the Condorcet criterion.
Basic procedure.
Voting.
In a Condorcet election the voter ranks the list of candidates in order of preference. So, for example, the voter gives a '1' to his first preference, a '2' to his second preference, and so on. In this respect it is the same as an election held under non-Condorcet methods such as instant runoff voting or the single transferable vote. Some Condorcet methods allow voters to rank more than one candidate equally, so that, for example, the voter might express two first preferences rather than just one.
Usually, when a voter does not give a full list of preferences he is assumed, for the purpose of the count, to prefer the candidates he has ranked over all other candidates. Some Condorcet elections permit write-in candidates but, because this can be difficult to implement, software designed for conducting Condorcet elections often does not allow this option.
Finding the winner.
The count is conducted by pitting every candidate against every other candidate in a series of hypothetical one-on-one contests. The winner of each pairing is the candidate preferred by a majority of voters. Unless they tie, there is always a majority when there are only two choices. The candidate preferred by each voter is taken to be the one in the pair that the voter ranks higher on their ballot paper. For example, if Alice is paired against Bob it is necessary to count both the number of voters who have ranked Alice higher than Bob, and the number who have ranked Bob higher than Alice. If Alice is preferred by more voters then she is the winner of that pairing. When all possible pairings of candidates have been considered, if one candidate beats every other candidate in these contests then they are declared the Condorcet winner. As noted above, if there is no Condorcet winner a further method must be used to find the winner of the election, and this mechanism varies from one Condorcet method to another.
Pairwise counting and matrices.
Condorcet methods use pairwise counting. For each possible pair of candidates, one pairwise count indicates how many voters prefer one of the paired candidates over the other candidate, and another pairwise count indicates how many voters have the opposite preference. The counts for all possible pairs of candidates summarize all the preferences of all the voters.
Pairwise counts are often displayed in matrices such as those below. In these matrices each row represents each candidate as a 'runner', while each column represents each candidate as an 'opponent'. The cells at the intersection of rows and columns each show the result of a particular pairwise comparison. Cells comparing a candidate to themselves are left blank.
Imagine there is an election between four candidates: A, B, C and D. The first matrix below records the preferences expressed on a single ballot paper, in which the voter's preferences are (B, C, A, D); that is, the voter ranked B first, C second, A third, and D fourth. In the matrix a '1' indicates that the runner is preferred over the 'opponent', while a '0' indicates that the runner is defeated.
Using a matrix like the one above, one can find the overall results of an election. Each ballot can be transformed into this style of matrix, and then added to all other ballot matrices using matrix addition. The sum of all ballots in an election is called the sum matrix.
Suppose that in the imaginary election there are two other voters. Their preferences are (D, A, C, B) and (A, C, B, D). Added to the first voter, these ballots would give the following sum matrix:
When the sum matrix is found, the contest between each pair of candidates is considered. The number of votes for runner over opponent (runner,opponent) is compared with the number of votes for opponent over runner (opponent,runner) to find the Condorcet winner. In the sum matrix above, A is the Condorcet winner because A beats every other candidate. When there is no Condorcet winner Condorcet completion methods, such as Ranked Pairs and the Schulze method, use the information contained in the sum matrix to choose a winner.
Cells marked '—' in the matrices above have a numerical value of '0', but a dash is used since candidates are never preferred to themselves. The first matrix, that represents a single ballot, is inversely symmetric: (runner,opponent) is ¬(opponent,runner). Or (runner,opponent) + (opponent,runner) = 1. The sum matrix has this property: (runner,opponent) + (opponent,runner) = N for N voters, if all runners were fully ranked by each voter.
Example: Voting on the location of Tennessee's capital.
To find the Condorcet winner every candidate must be matched against every other candidate in a series of imaginary one-on-one contests. In each pairing the winner is the candidate preferred by a majority of voters. When results for every possible pairing have been found they are as follows:
The results can also be shown in the form of a matrix:
As can be seen from both of the tables above, Nashville beats every other candidate. This means that Nashville is the Condorcet winner. Nashville will thus win an election held under any possible Condorcet method.
While any Condorcet method will elect Nashville as the winner, if instead an election based on the same votes were held using first-past-the-post or instant-runoff voting, these systems would select Memphis and Knoxville respectively. This would occur despite the fact that most people would have preferred Nashville to either of those "winners". Condorcet methods make these preferences obvious rather than ignoring or discarding them.
On the other hand, note that in this example Chattanooga also defeats Knoxville and Memphis when paired against those cities. If we changed the basis for defining preference and determined that Memphis voters preferred Chattanooga as a second choice rather than as a third choice, Chattanooga would be the Condorcet winner even though finishing in last place in a first-past-the-post election.
Circular ambiguities.
As noted above, sometimes an election has no Condorcet winner because there is no candidate who is preferred by voters to all other candidates. When this occurs the situation is known as a 'majority rule cycle', 'circular ambiguity', 'circular tie', 'Condorcet paradox', or simply 'cycle'. This situation emerges when, once all votes have been added up, the preferences of voters with respect to some candidates form a circle in which every candidate is beaten by at least one other candidate. For example, if there are three candidates, Candidate Rock, Candidate Scissors, and Candidate Paper, there will be no Condorcet winner if voters prefer Candidate Rock over Candidate Scissors and Scissors over Paper, but also Candidate Paper over Rock. Depending on the context in which elections are held, circular ambiguities may or may not be common. Nonetheless an ambiguity is always possible, and so every Condorcet method must be capable of determining a winner when this occurs. A mechanism for resolving an ambiguity is known as ambiguity resolution or Condorcet completion method.
Circular ambiguities arise as a result of the voting paradox—the result of an election can be intransitive (forming a cycle) even though all individual voters expressed a transitive preference. In a Condorcet election it is impossible for the preferences of a single voter to be cyclical, because a voter must rank all candidates in order and can only rank each candidate once, but the paradox of voting means that it is still possible for a circular ambiguity to emerge.
The idealized notion of a political spectrum is often used to describe political candidates and policies. Where this kind of spectrum exists, and voters prefer candidates who are closest to their own position on the spectrum, there is a Condorcet winner (Black's Single-Peakedness Theorem).
In Condorcet methods, as in most electoral systems, there is also the possibility of an ordinary tie. This occurs when two or more candidates tie with each other but defeat every other candidate. As in other systems this can be resolved by a random method such as the drawing of lots. Ties can also be settled through other methods like seeing which of the tied winners had the most first choice votes, but this and some other non-random methods may re-introduce a degree of tactical voting, especially if voters know the race will be close.
The method used to resolve circular ambiguities is the main difference between Condorcet methods. There are countless ways in which this can be done, but every Condorcet method involves ignoring the majorities expressed by voters in at least some pairwise matchings.
Condorcet methods fit within two categories:
Many one-method systems and some two-method systems will give the same result as each other if there are fewer than 4 candidates in the circular tie, and all voters separately rank at least two of those candidates. These include Smith-Minimax, Ranked Pairs, and Schulze.
Two-method systems.
One family of Condorcet methods consists of systems that first conduct a series of pairwise comparisons and then, if there is no Condorcet winner, fall back to an entirely different, non-Condorcet method to determine a winner. The simplest such methods involve entirely disregarding the results of pairwise comparisons. For example, the Black method chooses the Condorcet winner if it exists, but uses the Borda count instead if there is an ambiguity (the method is named for Duncan Black).
A more sophisticated two-stage process is, in the event of an ambiguity, to use a separate voting system to find the winner but to restrict this second stage to a certain subset of candidates found by scrutinizing the results of the pairwise comparisons. Sets used for this purpose are defined so that they will always contain only the Condorcet winner if there is one, and will always, in any case, contain at least one candidate. Such sets include the
One possible method is to apply instant-runoff voting to the candidates of the Smith set. This method has been described as 'Smith/IRV'.
Single-method systems.
Some Condorcet methods use a single procedure that inherently meets the Condorcet criteria and, without any extra procedure, also resolves circular ambiguities when they arise. In other words, these methods do not involve separate procedures for different situations. Typically these methods base their calculations on pairwise counts. These methods include:
Ranked Pairs and Schulze are procedurally in some sense opposite approaches (although they very frequently give the same results):
Minimax could be considered as more "blunt" than either of these approaches, as instead of removing defeats it can be seen as immediately removing candidates by looking at the strongest defeats (although their victories are still considered for subsequent candidate eliminations).
Kemeny-Young method.
The Kemeny-Young method considers every possible sequence of choices in terms of which choice might be most popular, which choice might be second-most popular, and so on down to which choice might be least popular. Each such sequence is associated with a Kemeny score that is equal to the sum of the pairwise counts that apply to the specified sequence. The sequence with the highest score is identified as the overall ranking, from most popular to least popular.
When the pairwise counts are arranged in a matrix in which the choices appear in sequence from most popular (top and left) to least popular (bottom and right), the winning Kemeny score equals the sum of the counts in the upper-right, triangular half of the matrix (shown here in bold on a green background).
In this example, the Kemeny Score of the sequence Nashville > Chattanooga > Knoxville > Memphis would be 393.
Calculating every Kemeny score requires considerable computation time in cases that involve more than a few choices. However, fast calculation methods based on integer programming allow a computation time in seconds for some cases with as many as 40 choices.
Ranked Pairs.
The order of finish is constructed a piece at a time by considering the (pairwise) majorities one at a time, from largest majority to smallest majority. For each majority, their higher-ranked candidate is placed ahead of their lower-ranked candidate in the (partially constructed) order of finish, except when their lower-ranked candidate has already been placed ahead of their higher-ranked candidate.
For example, suppose the voters' orders of preference are such that 75% rank B over C, 65% rank A over B, and 60% rank C over A. (The three majorities are a rock-paper-scissors cycle.) Ranked Pairs begins with the largest majority, who rank B over C, and places B ahead of C in the order of finish. Then it considers the second largest majority, who rank A over B, and places A ahead of B in the order of finish. At this point, it has been established that A finishes ahead of B and B finishes ahead of C, which implies A also finishes ahead of C. So when Ranked Pairs considers the third largest majority, who rank C over A, their lower-ranked candidate A has already been placed ahead of their higher-ranked candidate C, so C is not placed ahead of A. The order of finish is "A, B, C" and A is the winner.
An equivalent definition is to find the order of finish that minimizes the size of the largest reversed majority. (In the 'lexicographical order' sense. If the largest majority reversed in two orders of finish is the same, the two orders of finish are compared by their second largest reversed majorities, etc. See the discussion of MinMax, MinLexMax and Ranked Pairs in the 'Motivation and uses' section of the Lexicographical Order article). (In the example, the order of finish "A, B, C" reverses the 60% who rank C over A. Any other order of finish would reverse a larger majority.) This definition is useful for simplifying some of the proofs of Ranked Pairs' properties, but the "constructive" definition executes much faster (small polynomial time).
Schulze method.
The Schulze method resolves votes as follows:
In other words, this procedure repeatedly throws away the weakest pairwise defeat within the top set, until finally the number of votes left over produce an unambiguous decision.
Defeat strength.
Some pairwise methods—including minimax, Ranked Pairs, and the Schulze method—resolve circular ambiguities based on the relative strength of the defeats. There are different ways to measure the strength of each defeat, and these include considering "winning votes" and "margins":
If voters do not rank their preferences for all of the candidates, these two approaches can yield different results. Consider, for example, the following election:
The pairwise defeats are as follows:
Using the winning votes definition of defeat strength, the defeat of B by C is the weakest, and the defeat of A by B is the strongest. Using the margins definition of defeat strength, the defeat of C by A is the weakest, and the defeat of A by B is the strongest.
Using winning votes as the definition of defeat strength, candidate B would win under minimax, Ranked Pairs and the Schulze method, but, using margins as the definition of defeat strength, candidate C would win in the same methods.
If all voters give complete rankings of the candidates, then winning votes and margins will always produce the same result. The difference between them can only come into play when some voters declare equal preferences amongst candidates, as occurs implicitly if they do not rank all candidates, as in the example above.
The choice between margins and winning votes is the subject of scholarly debate. Because all Condorcet methods always choose the Condorcet winner when one exists, the difference between methods only appears when cyclic ambiguity resolution is required. The argument for using winning votes follows from this: Because cycle resolution involves disenfranchising a selection of votes, then the selection should disenfranchise the fewest possible number of votes. When margins are used, the difference between the number of two candidates' votes may be small, but the number of votes may be very large—or not. Only methods employing winning votes satisfy Woodall's plurality criterion.
An argument in favour of using margins is the fact that the result of a pairwise comparison is decided by the presence of more votes for one side than the other and thus that it follows naturally to assess the strength of a comparison by this "surplus" for the winning side. Otherwise, changing only a few votes from the winner to the loser could cause a sudden large change from a large score for one side to a large score for the other. In other words, one could consider losing votes being in fact disenfranchised when it comes to ambiguity resolution with winning votes. Also, using winning votes, a vote containing ties (possibly implicitly in the case of an incompletely ranked ballot) doesn't have the same effect as a number of equally weighted votes with total weight equaling one vote, such that the ties are broken in every possible way (a violation of Woodall's symmetric-completion criterion), as opposed to margins.
Under winning votes, if two more of the "B" voters decided to vote "BC", the A->C arm of the cycle would be overturned and Condorcet would pick C instead of B. This is an example of "Unburying" or "Later does harm". The margin method would pick C anyway.
Under the margin method, if three more "BC" voters decided to "bury" C by just voting "B", the A->C arm of the cycle would be strengthened and the resolution strategies would end up breaking the C->B arm and giving the win to B. This is an example of "Burying". The winning votes method would pick B anyway.
Related terms.
Other terms related to the Condorcet method are:
Condorcet ranking methods.
Some Condorcet methods produce not just a single winner, but a ranking of all candidates from first to last place. A Condorcet ranking is a list of candidates with the property that the Condorcet winner (if one exists) comes first and the Condorcet loser (if one exists) comes last, and this holds recursively for the candidates ranked between them.
Methods that satisfy this property include:
Comparison with instant runoff and first-past-the-post (plurality).
Many proponents of instant runoff voting (IRV) are attracted by the belief that if their first choice does not win, their vote will be given to their second choice; if their second choice does not win, their vote will be given to their third choice, etc. This sounds perfect, but it is not true for every voter with IRV. If someone voted for a strong candidate, and their 2nd and 3rd choices are eliminated before their first choice is eliminated, IRV gives their vote to their 4th choice candidate, not their 2nd choice. Condorcet voting takes all rankings into account simultaneously, but at the expense of violating the later-no-harm criterion and the later-no-help criterion. With IRV, indicating a second choice will never affect your first choice. With Condorcet voting, it is possible that indicating a second choice will cause your first choice to lose.
Plurality voting is simple, and theoretically provides incentives for voters to compromise for centrist candidates rather than throw away their votes on candidates who can't win. Opponents to plurality voting point out that voters often vote for the lesser of evils because they heard on the news that those two are the only two with a chance of winning, not necessarily because those two are the two natural compromises. This gives the media significant election powers. And if voters do compromise according to the media, the post election counts will prove the media right for next time. Condorcet runs each candidate against the other head to head, so that voters elect the candidate who would win the most sincere runoffs, instead of the one they thought they had to vote for.
There are circumstances, as in the examples above, when both instant-runoff voting and the 'first-past-the-post' plurality system will fail to pick the Condorcet winner. In cases where there is a Condorcet Winner, and where IRV does not choose it, a majority would by definition prefer the Condorcet Winner to the IRV winner. Proponents of the Condorcet criterion see it as a principal issue in selecting an electoral system. They see the Condorcet criterion as a natural extension of majority rule. Condorcet methods tend to encourage the selection of centrist candidates who appeal to the median voter. Here is an example that is designed to support IRV at the expense of Condorcet:
B is preferred by a 501-499 majority to A, and by a 502-498 majority to C. So, according to the Condorcet criterion, B should win, despite the fact that very few voters rank B in first place. By contrast, IRV elects C and plurality elects A. The goal of a ranked voting system is for voters to be able to vote sincerely and trust the system to protect their intent. Plurality voting forces voters to do all their tactics before they vote, so that the system does not need to figure out their intent.
The significance of this scenario, of two parties with strong support, and the one with weak support being the Condorcet winner, may be misleading, though, as it is a common mode in plurality voting systems (see Duverger's law), but much less likely to occur in Condorcet or IRV elections, which unlike Plurality voting, punish candidates who alienate a significant block of voters.
Here is an example that is designed to support Condorcet at the expense of IRV:
B would win against either A or C by more than a 65–35 margin in a one-on-one election, but IRV eliminates B first, leaving a contest between the more "polar" candidates, A and C. Proponents of plurality voting state that their system is simpler than any other and more easily understood.
All three systems are susceptible to tactical voting, but the types of tactics used and the frequency of strategic incentive differ in each method.
Potential for tactical voting.
Like most voting methods, Condorcet methods are vulnerable to compromising. That is, voters can help avoid the election of a less-preferred candidate by insincerely raising the position of a more-preferred candidate on their ballot. However, Condorcet methods are only vulnerable to compromising when there is a majority rule cycle, or when one can be created.
Many Condorcet methods are vulnerable to burying. That is, voters can help a more-preferred candidate by insincerely lowering the position of a less-preferred candidate on their ballot.
Example with the Schulze method:
Supporters of Condorcet methods which exhibit this potential problem could rebut this concern by pointing out that pre-election polls are most necessary with plurality voting, and that voters, armed with ranked choice voting, could lie to pre-election pollsters, making it impossible for Candidate A to know whether or how to bury. It is also nearly impossible to predict ahead of time how many supporters of A would actually follow the instructions, and how many would be alienated by such an obvious attempt to manipulate the system.
Evaluation by criteria.
Scholars of electoral systems often compare them using mathematically defined voting system criteria. The criteria which Condorcet methods satisfy vary from one Condorcet method to another. However, the Condorcet criterion implies the majority criterion; the Condorcet criterion is incompatible with independence of irrelevant alternatives, later-no-harm, the participation criterion, and the consistency criterion.
Use of Condorcet voting.
Condorcet methods are not known to be currently in use in government elections anywhere in the world, but a Condorcet method known as Nanson's method was used in city elections in the U.S. town of Marquette, Michigan in the 1920s, and today Condorcet methods are used by a number of private organizations. Organizations which currently use some variant of the Condorcet method are:

</doc>
<doc id="44447" url="https://en.wikipedia.org/wiki?curid=44447" title="The Forge of God">
The Forge of God

The Forge of God is a 1987 science fiction novel by American writer Greg Bear. Earth faces destruction when an inscrutable and overwhelming alien form of life attacks.
"The Forge of God" was nominated for the Nebula Award for Best Novel in 1987, and was also nominated for the Hugo and Locus Awards in 1988.
Plot.
The novel features scenes and events including the discovery of a near-dead alien in the desert, who clearly says in English, "I'm sorry, but there is bad news," and this alien's subsequent interrogation and autopsy; the discovery of an artificial geological formation and its subsequent nuclear destruction by a desperate military; and the Earth's eventual destruction by the mutual annihilation of a piece of neutronium and a piece of antineutronium dropped into Earth's core.
There is another alien faction at work, however, represented on Earth by small spider-like robots that recruit human agents through some form of mind control. They frantically collect all the human data, biological records, tissue samples, seeds, and DNA from the biosphere that they can, and evacuate a handful of people from Earth. In space, this faction's machines combat and eventually destroy the attackers, though not before Earth's fate is sealed. The evacuees eventually settle a newly terraformed Mars while some form the crew of a Ship of the Law to hunt down the home world of the killers, a quest described in the sequel, "Anvil of Stars".
One of the point of view characters is Arthur Gordon, a scientist who, with his wife Francine and son Martin is among those rescued from the destruction of Earth. Some other characters are close to an American president who fails to take action against the threat.
The two books show at least one solution to the Fermi paradox, with electromagnetically noisy civilisations being snuffed out by the arrival of self-replicating machines designed to destroy any potential threat to their (possibly long-dead) creators. (A similar theme is explored in Fred Saberhagen's "Berserker" novels.)
Cultural reference.
It features a character, Lawrence Van Cott, that is modelled on science fiction author Larry Niven, whose full name is "Laurence van Cott Niven".
Movie.
In the early 2000s, "The Forge of God" and "Anvil of Stars", as well as an as-yet-unwritten third book, were optioned by Warner Bros. to be made into movies. It was reported that Stephen Susco worked on a script for "The Forge Of God". In July 2006 Greg Bear mentioned on his website that the movie is "Still under option. Studio engaged in 'silent running.' "
However, in October 2010, Bear commented on his website that Ken Nolan (who wrote the screen adaptation for Ridley Scott's Black Hawk Down film), was actively working on a screenplay.

</doc>
<doc id="44449" url="https://en.wikipedia.org/wiki?curid=44449" title="Blood Music (novel)">
Blood Music (novel)

Blood Music is a science fiction novel by Greg Bear (ISBN 0-7434-4496-5).
It was originally published as a short story in 1983 in the American science fiction magazine Analog Science Fact & Fiction, winning the 1983 Nebula Award for Best Novelette and the 1984 Hugo Award for Best Novelette.
Greg Bear published an expanded version in novel form in 1985. The completed novel was nominated for the Nebula Award in 1985 and for the Hugo, Campbell, and British Science Fiction Awards in 1986.
"Blood Music" deals with themes including biotechnology, nanotechnology (including the grey goo hypothesis), the nature of reality, consciousness and artificial intelligence.
Plot summary.
In the novel, renegade biotechnologist Vergil Ulam creates simple biological computers based on his own lymphocytes. Faced with orders from his nervous employer to destroy his work, he injects them into his own body, intending to smuggle the 'noocytes' (as he calls them) out of the company and work on them elsewhere. Inside Ulam's body, the noocytes multiply and evolve rapidly, altering their own genetic material and quickly becoming self-aware. The nanoscale civilization they construct soon begins to transform Ulam, then others. The people who are infected start to find that genetic faults such as myopia and high blood pressure get fixed. Ulam's eyesight, posture, strength and intelligence are all improved. The infected can even have conversations with their noocytes, some reporting that the cells seem to sing.
Through infection, conversion and assimilation of humans and other organisms the cells eventually aggregate most of the biosphere of North America into a region seven thousand kilometres wide. This civilization, which incorporates both the evolved noocytes and recently assimilated conventional humans, is eventually forced to abandon the normal plane of existence in favor of one in which thought does not require a physical substrate. The reason for the noocytes' inability to remain in this reality is somewhat related to the strong anthropic principle.
The book's structure is titled "inter-phase", "prophase", "metaphase", "anaphase", "telophase" and "interphase." This mirrors the major phases of cell cycle: interphase and mitosis.
Significance.
This book introduces one of Bear's favorite themes - reality as a function of observers. In "Blood Music", reality becomes unstable as the number of observers—trillions of intelligent single-cell organisms—spirals higher and higher.

</doc>
<doc id="44454" url="https://en.wikipedia.org/wiki?curid=44454" title="Battle of Passchendaele">
Battle of Passchendaele

The Battle of Passchendaele, also known as the Third Battle of Ypres, was a campaign of the First World War, fought by the Allies against the German Empire. The battle took place on the Western Front, from July to November 1917, for control of the ridges south and east of the Belgian city of Ypres in West Flanders, as part of a strategy decided by the Allies at conferences in November 1916 and May 1917. Passchendaele lay on the last ridge east of Ypres, from a railway junction at Roulers, which was vital to the supply system of the German 4th Army. The next stage of the Allied plan was an advance to Thourout–Couckelaere, to close the German-controlled railway running through Roulers and Thourout.
Further operations and a British supporting attack along the Belgian coast from Nieuwpoort, combined with Operation Hush (an amphibious landing), were to have reached Bruges and then the Dutch frontier. The resistance of the German 4th Army, unusually wet weather, the onset of winter and the diversion of British and French resources to Italy, following the Austro-German victory at the Battle of Caporetto enabled the Germans to avoid a general withdrawal, which had seemed inevitable in early October. The campaign ended in November, when the Canadian Corps captured Passchendaele, apart from local attacks in December and the new year. In 1918, the Battle of the Lys and the Fifth Battle of Ypres were fought before the Allies occupied the Belgian coast and reached the Dutch frontier.
A campaign in Flanders was controversial in 1917 and has remained so. The British Prime Minister Lloyd George opposed the offensive, as did General Ferdinand Foch the French Chief of the General Staff. Field Marshal Douglas Haig, commanding the British Expeditionary Force, did not receive approval for the Flanders operation from the War Cabinet until 25 July. Matters of dispute by the participants, writers and historians since the war, have included the wisdom of pursuing an offensive strategy in the wake of the Nivelle Offensive, rather than waiting for the arrival of the American Expeditionary Forces in France.
The choice of Flanders over areas further south or the Italian front, the climate and weather in Flanders, the choice of General Hubert Gough and the Fifth Army to conduct the offensive, debates over the nature of the opening attack and between advocates of shallow and deeper objectives, have also been controversial. The passage of time between the Battle of Messines and the opening attack of the Battles of Ypres, the extent to which the internal troubles of the French armies motivated British persistence with the offensive, the effect of the weather, the decision to continue the offensive in October and the human cost of the campaign on the soldiers of the German and British armies, have also been argued over ever since.
Background.
Flanders 1914–1917.
Belgian independence had been recognised in the Treaty of London (1839) which created a sovereign and neutral state. The German invasion of Belgium on 4 August 1914, in violation of Article VII of the treaty, was the reason given by the British government for declaring war on Germany. British military operations in Belgium began with the arrival of the British Expeditionary Force (BEF) at Mons on 22 August. On 16 October, the Belgians and some French reinforcements, began the defence of the French channel ports and what remained of unoccupied Belgium at the Battle of the Yser. Operations further south in Flanders commenced after reciprocal attempts by the French and German armies to turn their opponents' northern flank through Picardy, Artois and Flanders, known as the Race to the Sea, reached Ypres. On 10 October, Lieutenant-General Erich von Falkenhayn, the Chief of the General Staff since mid-September, ordered an attack towards Dunkirk and Calais, followed by a turn south to gain a decisive victory. When the offensive failed, Falkenhayn ordered the capture of Ypres to gain a local advantage. By 12 November, the attempt in the First Battle of Ypres had also failed, at a cost of casualties and was stopped on 18 November.
In December 1914, the Admiralty began discussions with the War Office, for a combined operation to occupy the Belgian coast to the Dutch frontier, with an attack along the coast combined with a landing at Ostend. Eventually the British were obliged to participate in the French offensives further south. Large British offensive operations in Flanders were not possible in 1915, due to the consequent lack of resources. The Germans conducted their own Flanders offensive at the Ypres (22 April – 15 May 1915), making the Ypres salient more costly to defend. Sir Douglas Haig succeeded Sir John French as Commander-in-Chief of the BEF on 19 December 1915. A week after his appointment, Haig met Vice-Admiral Sir Reginald Bacon, who emphasised the importance of obtaining control of the Belgian coast, to end the threat posed by German naval forces. Haig was sceptical of a coast operation, believing that a landing from the sea would be far more difficult than anticipated and that an advance along the coast would require so much preparation, that the Germans would have ample warning. Haig preferred an advance from Ypres, to bypass the flooded area around the Yser and the coast, before Operation Hush a coastal attack was attempted, to clear the coast to the Dutch border.
In January 1916, Haig ordered General Plumer to plan offensives against Messines Ridge, Lille and Houthoulst Forest. General Henry Rawlinson was also ordered to plan an attack from the Ypres Salient on 4 February. Planning by Plumer continued but the demands of the Battles of Verdun and the Somme absorbed the offensive capacity of the BEF. On 15 and 29 November 1916, Haig met Général d'Armée Joseph Joffre and the other Allies at Chantilly. An offensive strategy to overwhelm the Central Powers was agreed, with attacks planned on the Western, Eastern and Italian fronts, by the first fortnight in February 1917. A meeting in London of the Admiralty and General Staff urged that the Flanders operation be undertaken in 1917 and Joffre replied on 8 December, agreeing to the proposal for a Flanders campaign after the spring offensive. The plan for a year of steady attrition on the Western Front, with the main effort in the summer being made by the BEF, was scrapped by Nivelle and the French government in preference for a decisive battle, to be conducted in February by the French army, with the British contribution becoming a preliminary operation, the Battles of Arras.
Nivelle planned an operation in three parts, with preliminary offensives to pin German reserves by the British at Arras and the French between the Somme and the Oise, a French breakthrough offensive on the Aisne, then pursuit and exploitation. The plan was welcomed by Haig with reservations, which he addressed on 6 January. Nivelle agreed to a proviso that if the first two parts of the operation failed to lead to part three, they would be stopped so that the British could move their main forces north for the Flanders offensive, which Haig argued was of great importance to the British government. Haig wrote on 23 January, that it would take six weeks to move British troops and equipment from the Arras front to Flanders and on 14 March he noted that the attack on Messines Ridge could be made in May. On 21 March, he wrote to Nivelle that it would take two months to prepare the attacks from Messines to Steenstraat but that the Messines attack could be ready in On 16 May, Haig wrote that he had divided the Flanders operation into two phases, one to take Messines Ridge and the main attack several weeks later. British determination to clear the Belgian coast took on more urgency, after the Germans resumed unrestricted submarine warfare on 1 February 1917.
Small operations took place in the Ypres salient in 1916, some being German initiatives to distract the Allies from the preparations for the offensive at Verdun and later attempts to divert Allied resources from the Battle of the Somme. Other operations were begun by the British to regain territory or to evict the Germans from ground overlooking their positions. Engagements took place on 12 February at Boesinghe and on 14 February at Hooge and Sanctuary Wood. There were actions from and at The Bluff, April at the St. Eloi Craters and the Battle of Mont Sorrel from In January 1917, the Second Army (II Anzac, IX, X and VIII corps) held the line in Flanders from Laventie to Boesinghe, with eleven divisions and up to two in reserve. There was much trench mortaring, mining and raiding by both sides and from January to May, the Second Army had In May, reinforcements began moving to Flanders from the south; the II Corps headquarters and had arrived by the end of the month.
Strategic background.
Several British and French operations took place beyond Flanders during the Third Battle of Ypres, intended to assist Allied operations at Ypres, by obstructing the flow of munitions and reinforcements to the 4th Army in Belgium and to exploit opportunities created by the German need to economise elsewhere. German offensives in Russia and against Italy were postponed several times, as demand for men and munitions in Flanders, left little available for other operations and the French army was able to continue its recuperation after the Nivelle Offensive, conduct a limited offensive at Verdun in August and the Battle of La Malmaison in October.
Prelude.
Geography and climate.
The front line around Ypres had changed relatively little since the end of the Second Battle of Ypres ( May 1915). The British held the city, while the Germans held the high ground of the Messines–Wytschaete ridge to the south, the lower ridges to the east and the flat ground to the north. The Ypres front was a salient bulging into German positions, overlooked by German artillery on the higher ground. It was difficult for the British forces to gain ground observation of the German rear areas east of the ridges.
In Flanders, sands, gravels and marls predominate, in places covered by silts. The coastal strip is sand but a short way inland, the ground rises to the vale of Ypres, which before 1914 was a flourishing market garden. Ypres is above sea level; Bixshoote to the north is at . To the east the land is at for several miles, with the Steenbeek river at near St Julien. There is a low ridge from Messines, at its highest point, running north-east past "Clapham Junction" at the west end of Gheluvelt plateau ( miles from Ypres at and Gheluvelt (above ) to Passchendaele, ( miles from Ypres at ) declining from there to a plain further north. Gradients vary from negligible, to at Hooge and at Zonnebeke.
Underneath the soil is London clay, sand and silt; according to the Commonwealth War Graves Commission categories of "sand", "sandy soils" and "well-balanced soils", Messines ridge is well-balanced soil and the ground around Ypres is sandy soil. The ground is drained by many streams, canals and ditches which need regular maintenance. Since 1914 much of the drainage had been destroyed, although some parts had been restored by Land Drainage Companies brought from England. The area was considered by the British to be drier than Loos, Givenchy and Plugstreet Wood further south. A 1989 study of weather data recorded at Lille, from Ypres from showed that August was more often dry than wet, that there was a trend towards dry autumns (September–November) and that average rainfall in October had decreased over the previous fifty years.
British plans.
Preparations for operations in Flanders began in 1915, with the doubling of the Hazebrouck–Ypres rail line and the building of a new line from Bergues–Proven which was doubled in early 1917. Progress on roads, rail lines, railheads and spurs in the Second Army zone was continuous and by mid-1917, gave the area the most efficient supply system of the BEF. Several plans and memoranda for a Flanders offensive were produced between January 1916 and May 1917, in which the writers tried to relate the offensive resources available to the terrain and the likely German defence. In early 1916, the importance of the capture of the Gheluvelt plateau for an advance further north was emphasised by Haig and the army commanders.
On 14 February 1917, Colonel C. N. Macmullen of GHQ proposed that the plateau be taken by a mass tank attack, reducing the need for artillery; in April a reconnaissance by Captain G. le Q Martel found that the area was unsuitable for tanks. On 9 February, General Rawlinson, commander of the Fourth Army, suggested that Messines Ridge could be taken in one day and that the capture of the Gheluvelt plateau should be fundamental to the attack further north. He suggested that the southern attack from St. Yves to Mont Sorrel should come first and that Mont Sorrel to Steenstraat should be attacked within After discussions with Rawlinson and Plumer and the incorporation of Haig's changes, Macmullen submitted his memorandum on 14 February. With amendments the memorandum became the "GHQ 1917" plan.
On 1 May 1917, Haig wrote that the Nivelle Offensive had weakened the German army but that an attempt at a decisive blow would be premature. An offensive at Ypres would continue the wearing-out process, on a front where the Germans could not refuse to fight. Even a partial success would improve the tactical situation in the Ypres salient, reducing the exceptional "wastage" which occurred even in quiet periods. In early May, Haig set the timetable for the Flanders offensive, with 7 June the date for the preliminary attack on Messines Ridge. A week after the Battle of Messines Ridge, Haig gave his objectives to his Army commanders: wearing out the enemy, securing the Belgian coast and connecting with the Dutch frontier by the capture of Passchendaele ridge, followed by an advance on Roulers and Operation Hush, an attack along the coast with an amphibious landing. If manpower and artillery were insufficient, only the first part of the plan might be fulfilled. On 30 April, Haig told Gough the Fifth Army commander, that he would lead the "Northern Operation" and the coastal force, although Cabinet approval for the offensive was not granted until 21 June.
German defences in Flanders.
The 4th Army held a front of with three , composed of corps headquarters and a varying complement of divisions and Group Staden, based on the headquarters of the Guards Reserve Corps was added later. Group Dixmude held with four front divisions and two "Eingreif" divisions, Group Ypres held from Pilckem to Menin Road with three front divisions and two divisions and Group held a similar length of front south of the Menin road, with three front divisions and three divisions. The divisions were stationed behind the Menin and Passchendaele ridges. About further back, were four more divisions and beyond them, another two in Oberste Heeresleitung (OHL) reserve.
German anxiety that the British would exploit their victory at Messines, by advancing to the Bassevillebeek (Tower Hamlets) spur, beyond the north end of Messines ridge, led Crown Prince Rupprecht on 9 June, to propose a withdrawal to the line in the area east of Messines. Construction of defences in the area began but on 13 June, Colonel Fritz von Lossberg arrived as the new Chief of Staff of the 4th Army. Lossberg rejected the proposed withdrawal to the line and ordered that the current front line east of the line (Oosttaverne Line) be held rigidly, as the front of a deepened (Flanders Position), in front of the line. The existing line was to become , with a new line to be built west of Menin, northwards to Terhand and Passchendaele, at the back of a new . Construction of was begun east of Menin to run north to Moorslede.
On 25 June, Erich Ludendorff the First Quartermaster General, suggested to Rupprecht, that Group Ypres should withdraw to the (third) line, leaving only outposts in the (second) line. On 30 June, the army group Chief of Staff, General von Kuhl suggested a withdrawal to along Passchendaele ridge, meeting the old front line in the north near Langemarck and close to Armentières in the south. Such a withdrawal would avoid a hasty retreat from Pilckem Ridge and force the British into a time-consuming redeployment. Lossberg disagreed, believing that the British would launch a broad front offensive, that the ground east of the line was easy to defend, that the Menin road ridge could be held, if it was made the (point of main effort) of the German defensive effort. Pilckem Ridge deprived the British of ground observation over the Steenbeek Valley, while the Germans could see the area from Passchendaele Ridge, allowing German infantry to be supported by observed artillery fire. Lossberg's judgement was accepted and no withdrawal was made.
Messines Ridge: 7–17 June.
The first stage in the British plan, was a preparatory attack on the German positions south of Ypres at Messines Ridge. The German positions had observation over Ypres and unless captured, would enable observed enfilade artillery-fire against a British attack eastwards from the salient. The British attack began on 7 June, preceded by a unique display of military pyrotechnics. Since mid-1915, the British had been covertly digging mines under the German positions on the ridge. By June 1917, had been filled with nearly of explosives. The Germans knew the British were mining and had taken some counter-measures but they were taken by surprise at the extent of the British effort. Two of the mines failed to detonate but off on 7 June, at British Summer Time. The final objectives were largely gained before dark and the British had fewer losses than expected, the plan having provided for up to the initial attack. As the infantry advanced over the far edge of the ridge, German artillery and machine-guns east of the ridge began to fire and the British artillery was less able to suppress them. Fighting continued on the lower slopes on the east side of the ridge until 14 June. The offensive removed the Germans from the dominating ground on the southern face of the Ypres salient, which the 4th Army had held since the First Battle of Ypres 
Kerensky offensive.
The Russian army launched the Kerensky Offensive to honour the agreement struck with its allies, at the Chantilly meeting of 1916. After a brief period of success from the German strategic reserve of six divisions, captured Riga from 1917. In Operation Albion (September–October 1917), the Germans took the islands at the mouth of the Gulf of Riga and the British and French commanders on the Western Front, had to reckon on the German western army being strengthened by reinforcements from the Eastern Front, in late 1917. Haig wished to exploit the diversion of German forces in Russia for as long as it continued and urged that the maximum amount of manpower and munitions be committed to the battle in Flanders.
Battles.
First phase, July–August.
Haig selected Gough to command the offensive on 30 April and on 10 June, Gough took over the Ypres salient north of Messines Ridge. Gough planned an offensive based on the "GHQ 1917" plan and the instructions he had received from Haig. On the understanding that Haig wanted a more ambitious version, Gough held meetings with his Corps commanders on 6 and 16 June, where the third objective, which included the German (third) line, a second-day objective, was added to the two objectives due to be taken on the first day. A fourth objective was also given for the first day but was only to be attempted at the discretion of divisional and corps commanders, in places where the German defence had collapsed. An attack of this nature was not a breakthrough operation, because the German defensive position Flandern I lay behind the front line and would not be attacked on the first day. The Fifth Army plan was more ambitious than Plumer's earlier version, which had involved an advance of . Major-General J. Davidson, Director of Operations at GHQ, wrote in a memorandum that there was "ambiguity as to what was meant by a step-by-step attack with limited objectives" and suggested reverting to a advance, to increase the concentration of British artillery. Gough stressed the need to plan to exploit an opportunity to take ground left temporarily undefended and that this was more likely in the first attack, which would have the benefit of long preparation. After discussions at the end of June, Haig and Plumer the Second Army commander endorsed the Fifth Army plan.
Battle of Pilckem Ridge.
The British attack began at on 31 July; the attack was to commence at dawn but a layer of unbroken low cloud, meant that it was still dark. The main attack of the offensive, by II Corps across the Ghelveult Plateau to the south, confronted the principal German defensive concentration of artillery, ground-holding and "Eingreif" divisions. The attack had most success on the left (north), in front of XIV Corps and the French First Army. In this section of the front, the Entente forces advanced , up to the line of the Steenbeek stream. In the centre of the British attack, XVIII Corps and XIX Corps pushed forward to the line of the Steenbeek to consolidate and sent reserve troops towards the Green and Red lines (on the XIX Corps front), an advance of about . Group Ypres counter-attacked the flanks of the British break-in, supported by all available artillery and aircraft at about midday. The German counter-attack was able to drive the three British brigades back to the black line with losses, where the German counter-attack was stopped by mud, artillery and machine-gun fire.
Capture of Westhoek.
II Corps attacked on 10 August, to capture the rest of the black line on the Gheluvelt plateau. The advance succeeded but German artillery fire and infantry counter-attacks isolated the infantry of the 18th Division, which had captured Glencorse Wood. At about German infantry attacked behind a smokescreen and recaptured all but the north-west corner of the wood, only the 25th Division gains on Westhoek Ridge being held. Albrecht von Thaer, Staff Officer at Group Wytshchate, noted that casualties after in the line averaged compared to the Somme 1916 average of and that German troop morale was higher than in 1916.
Battle of Hill 70.
The Battle of Hill 70, was a subsidiary operation by the Canadian Corps against five divisions of the German 6th Army. The battle took place on the outskirts of Lens, Pas-de-Calais, from Kuhl wrote later that it was a costly defeat and "wrecked" the plan for relieving divisions which had been "fought-out" in Flanders.
Battle of Langemarck.
The Battle of Langemarck was fought from the Fifth Army headquarters was influenced by the effect that delay would have on Operation Hush, which needed the high tides at the end of August or it would have to be postponed for a month. Gough intended that the rest of the green line (just beyond the German (third) line, from Polygon Wood to Langemarck) to be taken and the Steenbeek crossed further north. In the II Corps area, the disappointment of 10 August was repeated, with the infantry managing to advance, then being isolated by German artillery and (except in the 25th Division area near Westhoek) forced back to their start line by German counter-attacks. Attempts by the German infantry to advance further were stopped by British artillery fire with many losses. The advance further north in the XVIII Corps area, retook and held the north end of St Julien and the area south-east of Langemarck, while XIV Corps captured Langemarck and the (third) line, north of the Ypres–Staden railway near the Kortebeek. The French First Army conformed, pushing up to the Kortebeek and St. Jansbeck stream west of the northern stretch of the (third) line, where it crossed to the east side of the Kortebeek.
Subsidiary operations.
Smaller British attacks from also failed to hold captured ground, although a XVIII Corps attack on 19 August succeeded. Exploiting observation from higher ground to the east, the Germans were able to inflict many losses on the British divisions holding the new line beyond Langemarck. After two fine dry days from XIX Corps and XVIII Corps began pushing closer to the (third) line. On 20 August, an operation by British tanks, artillery and infantry captured strong points along the St. Julien–Poelcappelle road and two days later, more ground was gained by the two corps, which still left them overlooked by the Germans in the un-captured part of the (third) line. II Corps resumed operations to capture Nonne Bosschen, Glencorse Wood and Inverness Copse around the Menin Road on which failed and were costly to both sides. Gough laid down a new infantry formation of skirmish lines to be followed by "worms" on 24 August. Cavan noted that pill-box defences required broad front attacks, so as to engage them simultaneously. The British general offensive intended for 25 August, was delayed because of the failure of previous attacks to hold ground, following the Battle of Langemarck and then postponed due to more bad weather. Attacks on 27 August were minor operations, which were costly and inconclusive. Haig called a halt to operations amidst tempestuous weather.
Second offensive battle of Verdun.
Petain had committed the French Second Army to an attack at Verdun in mid-July, in support of the operations in Flanders. The Second Offensive Battle of Verdun was delayed, partly due to the mutinies which had affected the French army after the failure of the Nivelle Offensive and also because of a German attack at Verdun from which captured some of the ground intended as a jumping-off point for the French attack. A French counter-attack on 17 July re-captured the ground, the Germans regained it on 1 August, then took ground on the east bank on 16 August. The battle began on 20 August and by 9 September, had taken . Fighting continued sporadically into October, adding to the German difficulties on the Western Front and elsewhere. Ludendorff wrote:
yet there was no German counter-attack, because the local divisions were in Flanders.
Second phase: September–October.
The German 4th Army had defeated the British advance to all of the 31 July objectives during August but high casualties and sickness caused by the ground conditions, endless bombardments and air attacks worsened the manpower shortage that the German defensive strategy for 1917 was intended to alleviate. Haig transferred command of the offensive to General Plumer, the Second Army commander on 25 August and moved the northern boundary of the Second Army closer to the Ypres–Roulers railway. More heavy artillery was sent to Flanders from the armies further south and placed opposite the Gheluvelt plateau. Plumer continued the development of British attacking methods, which had also taken place in the Fifth Army, during the slow and costly progress in August, against the German defence-in-depth and the unusually wet weather. After a pause of about three weeks, Plumer intended to capture Gheluvelt plateau in four steps, with six days between each step to allow time to bring forward artillery and supplies. Each attack was to have limited geographical objectives like the attacks in August, with infantry brigades re-organised to attack the first objective with one battalion each and the final one with two battalions.
Plumer arranged for much more medium and heavy artillery to be added to the creeping bombardment, which had been impossible with the amount of artillery available to Gough. The revised attack organisation was intended to have more infantry attacking on narrower fronts, to a shallower depth than the attack of 31 July. The quicker and shorter advances were intended to be consolidated on tactically advantageous ground (particularly on reverse slopes), with the infantry in contact with their artillery and air support, ready to repulse counter-attacks. The faster tempo of the operations was intended to add to German difficulties in replacing tired divisions through the transport bottlenecks behind the German front. The pause in British operations while Plumer moved more artillery into the area of the Gheluvelt plateau, helped to mislead the Germans, Albrecht von Thaer, Staff Officer at Group wrote that it was ""almost boring"". At first, Kuhl doubted that the offensive had ended but by 13 September, had changed his mind and despite reservations allowed two divisions, thirteen heavy batteries and twelve field batteries of artillery, three fighter squadrons and four other air force units to be transferred from the 4th Army.
German defensive changes.
Instead of setting objectives distant as on 31 July, the British planned an advance of approximately , without the disadvantages of rain soaked ground and poor visibility encountered in August. The advances were much quicker and the final objective was reached a few hours after dawn, which confounded the German counter-attack divisions. Having crossed of mud, the divisions found the British already established along a new defence line, with the forward battle zone and its weak garrison gone beyond recapture. After the Battle of the Menin Road Ridge, the German defensive system was changed, beginning a resort to expedients which lasted for the rest of the battle. In August, German front-line divisions had two regiments of three battalions each deployed forward, with the third regiment in reserve. The front battalions had needed to be relieved much more frequently than expected, due to the power of British attacks, constant artillery fire and the weather, which caused replacement units to become mixed up with ones holding the front, rather than operate as formed bodies. Reserve regiments had not been able to intervene early enough, leaving front battalions unsupported until divisions arrived, some hours after the commencement of the attack.
After another severe defeat on 26 September, the German commanders made more changes to the defensive dispositions of the infantry and altered their counter-attack tactics, which had been negated by Plumer's more conservative form of limited attacks. In July and August, German counter-attack () divisions had engaged in a manner analogous to an advance to contact during mobile operations, which had given the Germans several costly defensive successes. The counter-attacks in September had been assaults on reinforced field positions, due to the restrained nature of British infantry advances. The fine weather in early September had greatly eased British supply difficulties, especially in the delivery of huge amounts of artillery ammunition. Immediately after their infantry advances, the British had made time to establish a defence in depth, behind standing barrages. The British attacks took place in dry clear weather, with increased air support over the battlefield for counter-attack reconnaissance, contact patrol and ground-attack operations. Systematic defensive artillery support was forfeited by the Germans, due to uncertainty over the position of their infantry, just when the British infantry benefitted from the opposite. German counter-attacks were defeated with many casualties and on 28 September, Albrecht von Thaer, staff officer at Group Wytschaete, wrote that the experience was "awful" and that he did not know what to do.
Ludendorff ordered a strengthening of forward garrisons by the ground-holding divisions. All machine-guns, including those of the support and reserve battalions of the front line regiments, were sent into the forward zone, to form a cordon of four to eight guns every . The ground holding divisions were reinforced by the regiment of an division being moved up behind each front division into the artillery protective line behind the forward battle zone, to launch earlier counter-attacks while the British were consolidating. The bulk of the divisions were to be held back and used for a methodical counter-stroke on the next day or the one after and for counter-attacks and spoiling attacks between British offensives. Further changes of the 4th Army defensive methods were ordered on 30 September. Operations to increase British infantry losses in line with the instructions of 22 September were to continue. Gas bombardments of forward British infantry and artillery positions, were to be increased whenever the winds allowed. Every effort was to be made to induce the British to reinforce their forward positions, where the German artillery could engage them. Between 26 September and 3 October, the Germans attacked at least Operation , a bigger German methodical counter-attack, intended to recapture the area around Zonnebeke was planned for 4 October.
Battle of the Menin Road Ridge.
The British plan for the battle fought from included more emphasis on the use of heavy and medium artillery to destroy German concrete pill-boxes and machine-gun nests, which were more numerous in the battle zones being attacked and to engage in more counter-battery fire. The British had and medium and guns and howitzers, having more than doubled the quantity of artillery available at the Battle of Pilckem Ridge. Aircraft were to be used for systematic air observation of German troop movements, to avoid the failures of previous battles, where too few aircraft crews had been burdened with too many duties and had flown in bad weather.
On 20 September, the Allies attacked on a front and captured most of their objectives, to a depth of about by mid-morning. The Germans made many counter-attacks, beginning around until early evening, all of which failed to gain ground or made only a temporary penetration of the new British positions. The German defence had failed to stop a well-prepared attack made in good weather. Minor attacks took place after 20 September, as both sides jockeyed for position and reorganised their defences. A mutually-costly attack by the Germans on 25 September, recaptured pillboxes at the south western end of Polygon Wood. Next day, the German positions near the wood were swept away in the Battle of Polygon Wood.
Counter-attack, 25 September.
Two regiments of the German 50th Reserve Division attacked on a front, on either side of the Reutelbeek, supported by aircraft and and batteries of artillery, four times the usual amount of artillery for a division. The German infantry managed to advance on the flanks, for about near the Menin road and north of the Reutelbeek, close to Black Watch Corner, supported by artillery-observation and ground-attack aircraft and a box-barrage fired behind the British front-line, which isolated the British defenders from reinforcements and cut off the supply of ammunition. Return-fire from the 33rd Division (Major-General Reginald Pinney) and the 15th Australian Brigade of the 5th Australian Division (Major-General Talbot Hobbs) along the southern edge of Polygon wood, forced the attackers under cover around some of the line pillboxes, near Black Watch Corner, at the south-western edge of Polygon Wood. German attempts to reinforce the attacking troops failed, due to British artillery observers isolating the advanced German troops with artillery barrages.
Plumer ordered the attack scheduled for 26 September to go ahead but modified the objectives of the 33rd Division. The 98th Brigade was to advance and cover the right flank of the 5th Australian Division and the 100th Brigade was to re-capture the lost ground further south. The 5th Australian Division advance the next day began with uncertainty as to the security of the right flank; the attack of the depleted 98th Brigade was delayed and only managed to reach Black Watch Corner, short of its objectives. Reinforcements moved forward into the 5th Australian Division area to the north and attacked south-westwards at noon, as a frontal attack was made from Black Watch Corner without artillery support, because troops were known to be still holding out. The attack succeeded by and later in the afternoon, the 100th Brigade re-took the ground lost north of the Menin road. Casualties in the 33rd Division were so great that it was relieved on 27 September by the 23rd Division, which had only been withdrawn on the night of 
Battle of Polygon Wood.
The Second Army altered its Corps frontages soon after the attack of 20 September, for the next effort so that each attacking division could be concentrated on a front. Roads and light railways were extended to the new front line, to allow artillery and ammunition to be moved forward. The artillery of VIII Corps and IX Corps on the southern flank, simulated preparations for attacks on Zandvoorde and Warneton. At on 26 September, five layers of barrage fired by British artillery and machine-guns began. Dust and smoke thickened the morning mist and the infantry advanced using compass bearings. Each of the three German ground-holding divisions attacked on 26 September, had an division in support, twice the ratio of 20 September. No ground captured by the British was lost and German counter-attacks managed only to reach ground to which survivors of the front-line divisions had retired.
Third phase: October–November.
Battle of Broodseinde.
The Battle of Broodseinde , was the last assault launched by Plumer in good weather. The operation aimed to complete the capture of the Gheluvelt Plateau and occupy Broodseinde Ridge. The Germans sought to recapture their defences around Zonnebeke, with a methodical counter-attack also to begin on 4 October. The British attacked along a front and by coincidence, Australian troops from I Anzac Corps met attacking troops from the German 45th Reserve Division in no man's land, when Operation commenced simultaneously. The Germans had reinforced their front line to delay the British capture of their forward positions, until divisions could intervene, which put more German troops into the area most vulnerable to British artillery. The British inflicted devastating casualties on the 4th Army divisions opposite.
German defensive changes.
On 7 October, the 4th Army again dispersed its troops in the front defence zone. Reserve battalions moved back behind the artillery protective line and the divisions were organised to intervene as swiftly as possible once an attack commenced, despite the risk of being devastated by the British artillery. Counter-battery fire to reduce British artillery fire was to be increased, to protect the divisions as they advanced. All of the German divisions holding front zones were relieved and an extra division brought forward, as the British advances had lengthened the front line. Without the forces necessary for a counter-offensive south of the Gheluvelt plateau towards Kemmel Hill, Rupprecht began to plan for a slow withdrawal from the Ypres salient, even at the risk of uncovering German positions further north and the Belgian coast.
Battle of Poelcappelle.
The French First Army and British Second and Fifth armies attacked on 9 October, on a front, from south of Broodseinde to St. Jansbeek, to advance half of the distance from Broodseinde ridge to Passchendaele, on the main front, which led to many casualties on both sides. Advances in the north of the attack front were retained by British and French troops but most of the ground taken in front of Passchendaele and on the Becelaere and Gheluvelt spurs was lost to German counter-attacks. General William Birdwood later wrote that the return of heavy rain and mud sloughs was the main cause of the failure to hold captured ground. Kuhl concluded that the fighting strained German fighting power to the limit but that the German forces managed to prevent a breakthrough, although it was becoming much harder to replace losses.
First Battle of Passchendaele.
The First Battle of Passchendaele on 12 October, was another Allied attempt to gain ground around Passchendaele. Heavy rain and mud again made movement difficult and little artillery could be brought closer to the front. Allied troops were exhausted and morale had fallen. After a modest British advance, German counter-attacks recovered most of the ground lost opposite Passchendaele. There were casualties, including Zealanders, whom had been killed or lay wounded and stranded in the mud of no-man's-land. In lives lost in a day, this was the worst day in New Zealand history. At a conference on 13 October, Haig and the army commanders agreed that attacks would stop until the weather improved and roads could be extended, to carry more artillery and ammunition forward for better fire support.
Battle of La Malmaison.
After numerous requests from Haig, Petain began the Battle of La Malmaison, a long-delayed French attack on the Chemin des Dames, by the Sixth Army (General Paul Maistre). The artillery preparation started on 17 October and on 23 October, the German defenders were swiftly defeated, losing and as the French advanced up to , capturing the village and fort of La Malmaison, gaining control of the Chemin des Dames ridge. The Germans had to withdraw to the north of the Ailette Valley early in November. Haig was pleased with the French success but regretted the delay, which had lessened its effect on the Flanders operations.
Second Battle of Passchendaele.
The British Fifth Army undertook minor operations from to maintain pressure on the Germans and support the French attack at La Malmaison, while the Canadian Corps prepared for a series of attacks from The four divisions of the Canadian Corps had been transferred to the Ypres Salient from Lens, to capture Passchendaele and the ridge. The Canadians relieved the II Anzac Corps on 18 October and found that the front line was mostly the same as that occupied by the 1st Canadian Division in April 1915. The Canadian operation was to be three limited attacks, on 26 October, 30 October and 6 November. On 26 October, the 3rd Canadian Division captured its objective at Wolf Copse, then swung back its northern flank to link with the adjacent division of the Fifth Army. The 4th Canadian Division captured its objectives but was forced slowly to retire from Decline Copse, against German counter-attacks and communication failures between the Canadian and Australian units to the south.
The second stage began on 30 October, to complete the previous stage and gain a base for the final assault on Passchendaele. The attackers on the southern flank quickly captured Crest Farm and sent patrols beyond the final objective into Passchendaele. The attack on the northern flank again met with exceptional German resistance. The 3rd Canadian Division captured Vapour Farm on the corps boundary, Furst Farm to the west of Meetcheele and the crossroads at Meetcheele but remained short of its objective. During a seven-day pause, the Second Army took over another section of the Fifth Army front adjoining the Canadian Corps. Three rainless days from eased preparation for the next stage, which began on the morning of 6 November, with the 1st Canadian Division and the 2nd Canadian Division. In fewer than three hours, many units reached their final objectives and Passchendaele was captured. The Canadian Corps launched a final action on 10 November, to gain control of the remaining high ground north of the village near which ended the campaign apart from a night attack at Passchendaele on an attack on the Polderhoek Spur on 2 December and some minor operations in the new year.
Aftermath.
Analysis.
In a German General Staff publication, it was written that "Germany had been brought near to certain destruction () by the Flanders battle of 1917". In his Memoirs of 1938, Lloyd George wrote, "Passchendaele was indeed one of the greatest disasters of the war ... No soldier of any intelligence now defends this senseless campaign ...". In 1939, G. C. Wynne wrote that the British had eventually reached Passchendaele Ridge and captured ; beyond them was and , which was nearly complete. The German submarine bases on the coast had not been captured but the objective of diverting the Germans from the French further south, while they recovered from the Nivelle Offensive in April had succeeded.
In 1997, Griffith wrote that the "bite and hold" system kept moving until November, because the BEF had developed a workable system of offensive tactics, against which the Germans ultimately had no answer. A decade later, Sheldon wrote that relative casualty figures were irrelevant, because the German army could not afford great numbers of losses or to lose the initiative, by being compelled to fight another defensive battle on ground of the Allies' choosing. The Third Battle of Ypres pinned the German army to Flanders and caused unsustainable casualties. At a conference on 13 October, a scheme of the Third Army for an attack in mid-November was discussed. Byng wanted the operations at Ypres to continue, to hold German troops in Flanders. The Battle of Cambrai began on 20 November, when the British breached the first two parts of the Hindenburg Line, in the first successful mass use of tanks in a combined arms operation.
The experience of the failure to contain the British attacks at Ypres and the drastic reduction in areas of the western front which could be considered "quiet", after the tank and artillery surprise at Cambrai, left the OHL with little choice but to return to a strategy of decisive victory in 1918. On 24 October, the Austro-German 14th Army, under Otto von Below, attacked the Italian Second Army on the Isonzo, at the Battle of Caporetto and in 18 days, inflicted casualties of and In fear that Italy might be put out of the war, the French and British Governments offered reinforcements. British and French troops were swiftly moved from but the diversion of resources from the BEF forced Haig to conclude the 3rd Battle of Ypres short of Westrozebeke, the last substantial British attack being made on 10 November.
Casualties.
Various casualty figures have been published, sometimes with acrimony, although the highest estimates for British and German casualties appear to be discredited. In the Official History, Brigadier-General J. E. Edmonds put British casualties at and wrote that equivalent German figures were not available, estimating German losses at Edmonds considered that to be added to German statistics, to make them comparable with British casualty criteria. In 2007, Sheldon wrote that although German casualties from a figure available in Volume III of the (1934), Edmonds may not have included them as they did not fit his case. Sheldon recorded wounded and sick soldiers "not struck off unit strength", which if included would make losses. The British claim to have taken has not been disputed.
Commemoration.
The Menin Gate Memorial to the Missing commemorates those of all Commonwealth nations, except New Zealand, who died in the Ypres Salient and have no known grave. In the case of the United Kingdom only casualties before 16 August 1917 are commemorated on the memorial. United Kingdom and New Zealand servicemen who died after that date are named on the memorial at Tyne Cot Cemetery. There are numerous tributes and memorials all over Australia and New Zealand to ANZAC soldiers who died in the battle, including plaques at the Christchurch and Dunedin railway stations. The Canadian Corps participation in the Second Battle of Passchendaele is commemorated with the Passchendaele Memorial located at the former site of the Crest Farm on the south-west fringe of Passchendaele village. One of the newest monuments to be dedicated to the fighting contribution of a group is the Celtic Cross memorial, commemorating the Scottish contributions and efforts in the fighting in Flanders during the Great War. This memorial is located on the Frezenberg Ridge where the Scottish 9th and 15th Divisions, fought during the Battle of Passchendaele. The monument was dedicated by Linda Fabiani, the Minister for Europe of the Scottish Parliament, during the late summer of 2007, the 90th anniversary of the battle.

</doc>
<doc id="44457" url="https://en.wikipedia.org/wiki?curid=44457" title="Green Card (film)">
Green Card (film)

Green Card is a 1990 romantic comedy film written, produced, directed by Peter Weir and starring Gérard Depardieu and Andie MacDowell. The screenplay focuses on an American woman who enters into a marriage of convenience with a Frenchman so he can obtain a green card and remain in the United States. Depardieu won the Golden Globe Award for Best Actor. The film won the Golden Globe for Best Motion Picture – Musical or Comedy, and was nominated for an Academy Award for Best Original Screenplay.
Plot summary.
Brontë Parrish (MacDowell), a horticulturalist and an environmentalist, enters into a sham marriage with Georges Fauré (Depardieu), an illegal alien from France, so he may obtain a green card. In turn, Brontë uses her fake marriage credentials to rent the apartment of her dreams. After moving in, to explain her spouse's absence, she tells the doorman and neighbors he is conducting musical research in Africa.
Contacted by the Immigration and Naturalization Service for an interview to determine if her marriage is legitimate, Brontë tracks down Georges, who is working as a waiter. Although the two have little time to get their facts straight, the agents who question them appear to be satisfied with their answers. But when one of the agents asks to use the bathroom and Georges directs him to a closet, their suspicions are aroused, and they schedule a full, formal interview to be conducted two days later at their office.
Advised by her attorney she could face criminal charges if their deception is uncovered, Brontë reluctantly invites Georges to move in with her. They try to learn about each other's past and their quirks and habits but quickly find they can barely tolerate each other. Georges is a fiery-tempered selfish slob and smoker who prefers red meat to vegetarian food, while Brontë is shown as uptight and cold, obsessed with her plants and wrapped up in environmental issues.
Brontë's best friend Lauren Adler's parents plan to leave New York City and may donate their trees and plants to the Green Guerrillas, a group overseeing the development of inner city gardens. Brontë is invited to a dinner party to discuss the issue and discovers Georges is there, having been asked by Lauren. He so impresses the Adlers with an impressionistic piano piece set to a poem about children and trees that they agree to donate their plants to the Green Guerrillas. When Brontë's parents later arrive at the apartment for an unannounced visit, Georges pretends to be the handyman.
When Brontë's boyfriend Phil returns from a trip, Georges reveals he is her husband. Brontë angrily kicks Georges out, but the pair nonetheless appear at the immigration interview the next day. The two are questioned separately, and when Georges is caught out by the interviewer, he confesses the marriage is a sham. He agrees to deportation but insists Brontë not be charged for her role in the charade. He lets Brontë believe the interview was a success and the two go their separate ways.
A few days later, Georges invites Brontë to join him at the cafe where they first met. When she notices one of the immigration agents is seated nearby, she realizes Georges is being deported, and finally aware she loves him, tries to stop him from leaving. Georges promises to write every day asking the same question "When are you coming, Cherie?", a line he had also used when describing their fabricated courtship to the INS. Then, Georges is deported back to France, just as they have admitted their love for each other.
Production.
Peter Weir wrote the script, an original, specifically as a vehicle for Gérard Depardieu to introduce him to a wide English-speaking audience.
Partial funding for the film was provided by the Film Finance Corporation Australia and Union Générale Cinématographique. Although the film was set in America and did not feature Australian actors, the fact it was written, directed, filmed, designed and edited by an Australian enabled it to receive funding from the Australian government. This was $3.8 million from the FFC.
Music.
Original soundtrack.
"Green Card: Original Motion Picture Soundtrack" was released on January 22, 1991 on Varèse Sarabande.
Some of the music like "River", "Watermark", and "Storms in Africa" by Enya, "Holdin' On" by Soul II Soul, "Oyin Momo Ado" by Babatunde Olatunji and "Surfin' Safari" by The Beach Boys are heard in the movie, but not included in the soundtrack.
Reception.
Critical response.
The film earned mixed reviews from critics, as it currently holds a 56% rating on Rotten Tomatoes based on 18 reviews.
Janet Maslin of "The New York Times" called it "as breezily escapist as a film this facile can be" and added, "Ms. MacDowell ... has a lovely, demure ease that makes George's appreciative gaze quite understandable. Mr. Depardieu, in the role that gets him into a New York Yankees cap, proves that he is nothing if not a sport ... He comes to life most fully when he lapses into French or is otherwise momentarily freed from the story's constraints." Roger Ebert of the "Chicago Sun-Times" observed the film "is not blindingly brilliant, and is not an example of the very best work of the director who made "The Year of Living Dangerously" or the actor who starred in "Cyrano de Bergerac". But it is a sound, entertaining work of craftsmanship, a love story between two people whose meet is not as cute as it might have been."
Peter Travers of "Rolling Stone" called the film a "captivating romantic bonbon" and added, "Don't look for the originality and grit that distinguished Weir's Australian films "Picnic at Hanging Rock" and "Gallipoli", "Green Card" has all the heft of a potato chip. But Depardieu's charm recognizes no language barriers, and MacDowell, the revelation of "Sex, Lies, and Videotape", proves a fine, sexy foil." Rita Kempley of the "Washington Post" said, "Like "Ghost" and "Pretty Woman", this romance is blissfully dependent on our staying good and starry-eyed, seduced by the charisma of the leads. And we do, despite its lackadaisical pace and disappointing ending."
"Variety" said, "Although a thin premise endangers its credibility at times, "Green Card" is a genial, nicely played romance." "Time Out London" stated "Weir's first romantic comedy boasts a central relationship which is tentative and hopeful, a mood beautifully realised by Depardieu (venturing into new territory with a major English-speaking role). Complemented by the refined MacDowell, his gracious, generous performance is never dominating, and their exchanges offer unexpected pleasures. In terms of the genre's conventions, Weir likens this film to 'a light meal.' It's one to savour." Channel 4 said, "Weir's film has its fair share of cute moments as the opposites slowly begin to attract, but this is largely over rated stuff, which proved curiously popular with critics on its release. Depardieu does his obnoxious-yet-strangely-lovable act with ease; however, the romantic comedy fixture MacDowell is less convincing."
Box office.
"Green Card" grossed $10,585,060 at the box office in Australia, which is equivalent to $16,725,817 in 2009 dollars.
Home media release.
Touchstone released the film on VHS around 1991 and Touchstone Home Entertainment released the film on Region 1 DVD on 4 March 2003. It is in anamorphic widescreen format with audio tracks in English and French.
"Green Card" was released on DVD by Umbrella Entertainment in February 2004. The DVD is compatible with all region codes and includes special features such as the original theatrical trailer, Umbrella Entertainment trailers, and interviews with Peter Weir, Gérard Depardieu and Andie MacDowell.

</doc>
