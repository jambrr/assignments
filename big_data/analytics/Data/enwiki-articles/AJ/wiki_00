<doc id="65905" url="https://en.wikipedia.org/wiki?curid=65905" title="Ideal gas">
Ideal gas

An ideal gas is a theoretical gas composed of many randomly moving point particles that do not interact except when they collide elastically. The ideal gas concept is useful because it obeys the ideal gas law, a simplified equation of state, and is amenable to analysis under statistical mechanics. One mole of an ideal gas has a volume of 22.7 L at STP as defined by IUPAC.
At normal conditions such as standard temperature and pressure, most real gases behave qualitatively like an ideal gas. Many gases such as nitrogen, oxygen, hydrogen, noble gases, and some heavier gases like carbon dioxide can be treated like ideal gases within reasonable tolerances. Generally, a gas behaves more like an ideal gas at higher temperature and lower pressure, as the potential energy due to intermolecular forces becomes less significant compared with the particles' kinetic energy, and the size of the molecules becomes less significant compared to the empty space between them.
The ideal gas model tends to fail at lower temperatures or higher pressures, when intermolecular forces and molecular size become important. It also fails for most heavy gases, such as many refrigerants, and for gases with strong intermolecular forces, notably water vapor. At high pressures, the volume of a real gas is often considerably greater than that of an ideal gas. At low temperatures, the pressure of a real gas is often considerably less than that of an ideal gas. At some point of low temperature and high pressure, real gases undergo a phase transition, such as to a liquid or a solid. The model of an ideal gas, however, does not describe or allow phase transitions. These must be modeled by more complex equations of state. The deviation from the ideal gas behaviour can be described by a dimensionless quantity, the compressibility factor, Z.
The ideal gas model has been explored in both the Newtonian dynamics (as in "kinetic theory") and in quantum mechanics (as a "gas in a box"). The ideal gas model has also been used to model the behavior of electrons in a metal (in the Drude model and the free electron model), and it is one of the most important models in statistical mechanics.
Types of ideal gas.
There are three basic classes of ideal gas:
The classical ideal gas can be separated into two types: The classical thermodynamic ideal gas and the ideal quantum Boltzmann gas. Both are essentially the same, except that the classical thermodynamic ideal gas is based on classical statistical mechanics, and certain thermodynamic parameters such as the entropy are only specified to within an undetermined additive constant. The ideal quantum Boltzmann gas overcomes this limitation by taking the limit of the quantum Bose gas and quantum Fermi gas in the limit of high temperature to specify these additive constants. The behavior of a quantum Boltzmann gas is the same as that of a classical ideal gas except for the specification of these constants. The results of the quantum Boltzmann gas are used in a number of cases including the Sackur–Tetrode equation for the entropy of an ideal gas and the Saha ionization equation for a weakly ionized plasma.
Classical thermodynamic ideal gas.
Macroscopic account.
The ideal gas law is an extension of experimentally discovered gas laws. Real fluids at low density and high temperature approximate the behavior of a classical ideal gas. However, at lower temperatures or a higher density, a real fluid deviates strongly from the behavior of an ideal gas, particularly as it condenses from a gas into a liquid or as it deposits from a gas into a solid. This deviation is expressed as a compressibility factor.
The classical thermodynamic properties of an ideal gas can be described by two equations of state:.
One of them is the well known ideal gas law
where
This equation is derived from Boyle's law: formula_7 (at constant T and n); Charles's law: formula_8 (at constant P and n); and Avogadro's law: formula_9 (at constant T and P); where
By combining the three laws, it would demonstrate that formula_15 which would mean that formula_16.
Under ideal conditions, formula_17 ;
that is, 
formula_18.
The other equation of state of an ideal gas must express Joule's law, that the internal energy of a fixed mass of ideal gas is a function only of its temperature. For the present purposes it is convenient to postulate an exemplary version of this law by writing:
where
Microscopic model.
In order to switch from macroscopic quantities (left hand side of the following equation) to microscopic ones (right hand side), we use
where
The probability distribution of particles by velocity or energy is given by the Maxwell speed distribution.
The ideal gas model depends on the following assumptions:
The assumption of spherical particles is necessary so that there are no rotational modes allowed, unlike in a diatomic gas. The following three assumptions are very related: molecules are hard, collisions are elastic, and there are no inter-molecular forces. The assumption that the space between particles is much larger than the particles themselves is of paramount importance, and explains why the ideal gas approximation fails at high pressures.
Heat capacity.
The heat capacity at constant volume, including an ideal gas is:
where "S" is the entropy. This is the dimensionless heat capacity at constant volume, which is generally a function of temperature due to intermolecular forces. For moderate temperatures, the constant for a monatomic gas is formula_26 while for a diatomic gas it is formula_27. It is seen that macroscopic measurements on heat capacity provide information on the microscopic structure of the molecules.
The heat capacity at constant pressure of 1/R mole of ideal gas is:
where formula_29 is the enthalpy of the gas.
Sometimes, a distinction is made between an ideal gas, where formula_21 and formula_31 could vary with temperature, and a perfect gas, for which this is not the case.
The ratio of the constant volume and constant pressure heat capacity is 
For air, which is a mixture of gases, this ratio is 1.4.
Entropy.
Using the results of thermodynamics only, we can go a long way in determining the expression for the entropy of an ideal gas. This is an important step since, according to the theory of thermodynamic potentials, if we can express the entropy as a function of "U" (U is a thermodynamic potential), volume "V" and the number of particles "N", then we will have a complete statement of the thermodynamic behavior of the ideal gas. We will be able to derive both the ideal gas law and the expression for internal energy from it.
Since the entropy is an exact differential, using the chain rule, the change in entropy when going from a reference state 0 to some other state with entropy "S" may be written as formula_33 where:
where the reference variables may be functions of the number of particles "N". Using the definition of the heat capacity at constant volume for the first differential and the appropriate Maxwell relation for the second we have:
Expressing formula_36 in terms of formula_21 as developed in the above section, differentiating the ideal gas equation of state, and integrating yields:
which implies that the entropy may be expressed as:
where all constants have been incorporated into the logarithm as "f(N)" which is some function of the particle number "N" having the same dimensions as formula_40 in order that the argument of the logarithm be dimensionless. We now impose the constraint that the entropy be extensive. This will mean that when the extensive parameters ("V" and "N") are multiplied by a constant, the entropy will be multiplied by the same constant. Mathematically:
From this we find an equation for the function "f(N)"
Differentiating this with respect to "a", setting "a" equal to unity, and then solving the differential equation yields "f(N)":
where formula_44 may vary for different gases, but will be independent of the thermodynamic state of the gas. It will have the dimensions of formula_45. Substituting into the equation for the entropy:
and using the expression for the internal energy of an ideal gas, the entropy may be written:
Since this is an expression for entropy in terms of "U", "V", and "N", it is a fundamental equation from which all other properties of the ideal gas may be derived.
This is about as far as we can go using thermodynamics alone. Note that the above equation is flawed — as the temperature approaches zero, the entropy approaches negative infinity, in contradiction to the third law of thermodynamics. In the above "ideal" development, there is a critical point, not at absolute zero, at which the argument of the logarithm becomes unity, and the entropy becomes zero. This is unphysical. The above equation is a good approximation only when the argument of the logarithm is much larger than unity — the concept of an ideal gas breaks down at low values of "V/N". Nevertheless, there will be a "best" value of the constant in the sense that the predicted entropy is as close as possible to the actual entropy, given the flawed assumption of ideality. A quantum-mechanical derivation of this constant is developed in the derivation of the Sackur–Tetrode equation which expresses the entropy of a monatomic formula_48 ideal gas. In the Sackur-Tetrode theory the constant depends only upon the mass of the gas particle. The Sackur–Tetrode equation also suffers from a divergent entropy at absolute zero, but is a good approximation for the entropy of a monatomic ideal gas for high enough temperatures.
Thermodynamic potentials.
Expressing the entropy as a function of "T", "V", and "N":
The chemical potential of the ideal gas is calculated from the corresponding equation of state (see thermodynamic potential):
where "G" is the Gibbs free energy and is equal to formula_51 so that:
The thermodynamic potentials for an ideal gas can now be written as functions of "T", "V", and "N" as:
where, as before, formula_53. The most informative way of writing the potentials is in terms of their natural variables, since each of these equations can be used to derive all of the other thermodynamic variables of the system. In terms of their natural variables, the thermodynamic potentials of a single-species ideal gas are:
In statistical mechanics, the relationship between the Helmholtz free energy and the partition function is fundamental, and is used to calculate the thermodynamic properties of matter; see configuration integral for more details.
Speed of sound.
The speed of sound in an ideal gas is given by
where
Table of ideal gas equations.
See Table of thermodynamic equations: Ideal gas.
Ideal quantum gases.
In the above-mentioned Sackur–Tetrode equation, the best choice of the entropy constant was found to be proportional to the quantum thermal wavelength of a particle, and the point at which the argument of the logarithm becomes zero is roughly equal to the point at which the average distance between particles becomes equal to the thermal wavelength. In fact, quantum theory itself predicts the same thing. Any gas behaves as an ideal gas at high enough temperature and low enough density, but at the point where the Sackur–Tetrode equation begins to break down, the gas will begin to behave as a quantum gas, composed of either bosons or fermions. (See the gas in a box article for a derivation of the ideal quantum gases, including the ideal Boltzmann gas.)
Gases tend to behave as an ideal gas over a wider range of pressures when the temperature reaches the Boyle temperature.
Ideal Boltzmann gas.
The ideal Boltzmann gas yields the same results as the classical thermodynamic gas, but makes the following identification for the undetermined constant Φ:
where Λ is the thermal de Broglie wavelength of the gas and "g" is the degeneracy of states.
Ideal Bose and Fermi gases.
An ideal gas of bosons (e.g. a photon gas) will be governed by Bose–Einstein statistics and the distribution of energy will be in the form of a Bose–Einstein distribution. An ideal gas of fermions will be governed by Fermi–Dirac statistics and the distribution of energy will be in the form of a Fermi–Dirac distribution.

</doc>
<doc id="65907" url="https://en.wikipedia.org/wiki?curid=65907" title="Elastic collision">
Elastic collision

An elastic collision is an encounter between two bodies in which the total kinetic energy of the two bodies after the encounter is equal to their total kinetic energy before the encounter. Elastic collisions occur only if there is no net conversion of kinetic energy into other forms.
During the collision of small objects, kinetic energy is first converted to potential energy associated with a repulsive force between the particles (when the particles move against this force, i.e. the angle between the force and the relative velocity is obtuse), then this potential energy is converted back to kinetic energy (when the particles move with this force, i.e. the angle between the force and the relative velocity is acute).
The collisions of atoms are elastic collisions (Rutherford backscattering is one example).
The "molecules"—as distinct from atoms—of a gas or liquid rarely experience perfectly elastic collisions because kinetic energy is exchanged between the molecules’ translational motion and their internal degrees of freedom with each collision. At any one instant, half the collisions are, to a varying extent, "inelastic collisions" (the pair possesses less kinetic energy in their translational motions after the collision than before), and half could be described as “super-elastic” (possessing "more" kinetic energy after the collision than before). Averaged across the entire sample, molecular collisions can be regarded as essentially elastic as long as Planck's law forbids black-body photons to carry away energy from the system.
In the case of macroscopic bodies, perfectly elastic collisions are an ideal never fully realized, but approximated by the interactions of objects such as billiard balls.
When considering energies, possible rotational energy before and/or after a collision may also play a role.
Equations.
One-dimensional Newtonian.
Consider two particles, denoted by subscripts 1 and 2. Let "m1" and "m2" be the masses, "u1" and "u2" the velocities before collision, and "v1" and "v2" the velocities after collision.
The conservation of the total momentum demands that the total momentum before the collision is the same as the total momentum after the collision, and is expressed by the equation
Likewise, the conservation of the total kinetic energy is expressed by the equation
These equations may be solved directly to find "vi" when "ui" are known or vice versa. An alternative solution is to first change the frame of reference such that one of the known velocities is zero. The unknown velocities in the new frame of reference can then be determined and followed by a conversion back to the original frame of reference to reach the same result. Once one of the unknown velocities is determined, the other can be found by symmetry.
Solving these simultaneous equations for "vi" we get:
or
The latter is the trivial solution, corresponding to the case that no collision has taken place (yet).
For example:
After collision:
Property:
Derivation:
Using the kinetic energy we can write
Rearrange momentum equation:
Dividing kinetic energy equation by the momentum equation we get:
As can be expected, the solution is invariant under adding a constant to all velocities, which is like using a frame of reference with constant translational velocity.
The velocity of the center of mass does not change by the collision:
The center of mass at time formula_13 before the collision and at time formula_14 after the collision is given by two equations:
Hence, the velocities of the center of mass before and after the collision are:
The numerator of formula_19 is the total momentum before the collision, and numerator of formula_20 is the total momentum after the collision. Since momentum is conserved, we have formula_21.
With respect to the center of mass both velocities are reversed by the collision: in the case of particles of different mass, a heavy particle moves slowly toward the center of mass, and bounces back with the same low speed, and a light particle moves fast toward the center of mass, and bounces back with the same high speed.
From the equations for formula_22 and formula_23 above we see that in the case of a large formula_24, the value of formula_25 is small if the masses are approximately the same: hitting a much lighter particle does not change the velocity much, hitting a much heavier particle causes the fast particle to bounce back with high speed.
This is why a neutron moderator (a medium which slows down fast neutrons, thereby turning them into thermal neutrons capable of sustaining a chain reaction) is a material full of atoms with light nuclei (with the additional property that they do not easily absorb neutrons): the lightest nuclei have about the same mass as a neutron.
One-dimensional relativistic.
According to special relativity,
Where p denotes momentum of any particle with mass, v denotes velocity, and c is the speed of light.
In the center of momentum frame where the total momentum equals zero, 
Where formula_32 represents the rest mass of the first colliding body, formula_33 represents the rest mass of the second colliding body, formula_34 represents the initial velocity of the first colliding body, formula_35 represents the initial velocity of the second colliding body, formula_36 represents the velocity after collision of the first colliding body, formula_37 represents the velocity after collision of the second colliding body, formula_38 denotes the momentum of the first colliding body, formula_39 denotes the momentum of the second colliding body and formula_40 denotes the speed of light in vacuum, formula_41 denotes the total energy of the system (i.e. the sum of rest masses and kinetic energies of the colliding bodies).
Since the total energy and momentum of the system are conserved and the rest masses of the colliding bodies do not change, it is shown that the momentum of the colliding body is decided by the rest masses of the colliding bodies, total energy and the total momentum. The magnitude of the momentum of the colliding body does not change after collision but the direction of movement is opposite relative to the center of momentum frame.
Classical Mechanics is only a good approximation. It will give accurate results when it deals with the object which is macroscopic and running with much lower speed than the speed of light. Beyond the classical limits, it will give a wrong result. Total momentum of the two colliding bodies is frame-dependent. In the center of momentum frame, according to Classical Mechanics,
It is shown that formula_31 remains true in relativistic calculation despite other differences. One of the postulates in Special Relativity states that the Laws of Physics should be invariant in all inertial frames of reference. That is, if total momentum is conserved in a particular inertial frame of reference, total momentum will also be conserved in any inertial frame of reference, although the amount of total momentum is frame-dependent. Therefore, by transforming from an inertial frame of reference to another, we will be able to get the desired results. In a particular frame of reference where the total momentum could be any,
We can look at the two moving bodies as one system of which the total momentum is formula_53, the total energy is formula_41 and its velocity formula_55 is the velocity of its center of mass. Relative to the center of momentum frame the total momentum equals zero. It can be shown that formula_55 is given by:
Now the velocities before the collision in the center of momentum frame formula_58 and formula_59 are:
When formula_66 and formula_67,
Therefore, the classical calculation holds true when the speed of both colliding bodies is much lower than the speed of light (about 300 million m/s).
Another derivation relativistic formulas for the collision.
We express the so-called parameter of velocity formula_86:
hence we get
Relativistic energy and momentum are expressed as follows:
Equations sum of energy and momentum colliding masses formula_91 and formula_92, (velocitiesformula_93, formula_94, formula_95,formula_96 correspond to the velocity parameters formula_97, formula_98, formula_99, formula_100), after dividing by adequate power formula_101 are as follows:
and dependent equation, the sum of above equations:
subtract squares both sides equations "momentum" from "energy" and use the identity formula_105, after simplicity we get:
for non-zero mass, we get:
as functions formula_108 is even we get two solutions:
from the last equation, leading to a non-trivial solution, we solve formula_111 and substitute into the dependent equation, we obtain formula_112 and then formula_113, we have:
It is a solution to the problem, but expressed by the parameters of velocity. Return substitution to get the solution for velocities is:
Substitute the previous solutions and replace:
formula_118 and formula_119, after long transformation, with substituting:
formula_120
we get:
Two-dimensional.
For the case of two colliding bodies in two dimensions, the overall velocity of each body must be split into two perpendicular velocities: one tangent to the common normal surfaces of the colliding bodies at the point of contact, the other along the line of collision. Since the collision only imparts force along the line of collision, the velocities that are tangent to the point of collision do not change. The velocities along the line of collision can then be used in the same equations as a one-dimensional collision. The final velocities can then be calculated from the two new component velocities and will depend on the point of collision. Studies of two-dimensional collisions are conducted for many bodies in the framework of a two-dimensional gas.
In a center of momentum frame at any time the velocities of the two bodies are in opposite directions, with magnitudes inversely proportional to the masses. In an elastic collision these magnitudes do not change. The directions may change depending on the shapes of the bodies and the point of impact. For example, in the case of spheres the angle depends on the distance between the (parallel) paths of the centers of the two bodies. Any non-zero change of direction is possible: if this distance is zero the velocities are reversed in the collision; if it is close to the sum of the radii of the spheres the two bodies are only slightly deflected.
Assuming that the second particle is at rest before the collision, the angles of deflection of the two particles, formula_123 and formula_124, are related to the angle of deflection formula_125 in the system of the center of mass by
The magnitudes of the velocities of the particles after the collision are:
Two-dimensional collision with two moving objects.
The final x and y velocities components of the first ball can be calculated as:
where "v"1 and "v"2 are the scalar sizes of the two original speeds of the objects, "m"1 and "m"2 are their masses, "θ"1 and "θ"2 are their movement angles, that is, formula_129 (meaning moving directly down to the right is either a -45° angle, or a 315°angle), and lowercase phi (φ) is the contact angle. (To get the x and y velocities of the second ball, one needs to swap all the '1' subscripts with '2' subscripts.)
This equation is derived from the fact that the interaction between the two bodies is easily calculated along the contact angle, meaning the velocities of the objects can be calculated in one dimension by rotating the x and y axis to be parallel with the contact angle of the objects, and then rotated back to the original orientation to get the true x and y components of the velocities.
In an angle-free representation, the changed velocities are computed using the centers x1 and x2 at the time of contact as
where the angle brackets indicate the inner product (or dot product) of two vectors.

</doc>
<doc id="65908" url="https://en.wikipedia.org/wiki?curid=65908" title="Inelastic collision">
Inelastic collision

An inelastic collision, in contrast to an elastic collision, is a collision in which kinetic energy is not conserved due to the action of internal friction.
In collisions of macroscopic bodies, some kinetic energy is turned into vibrational energy of the atoms, causing a heating effect, and the bodies are deformed.
The molecules of a gas or liquid rarely experience perfectly elastic collisions because kinetic energy is exchanged between the molecules' translational motion and their internal degrees of freedom with each collision. At any one instant, half the collisions are – to a varying extent – inelastic (the pair possesses less kinetic energy after the collision than before), and half could be described as “super-elastic” (possessing "more" kinetic energy after the collision than before). Averaged across an entire sample, molecular collisions are elastic. 
Inelastic collisions may not conserve kinetic energy, but they do obey conservation of momentum. Simple ballistic pendulum problems obey the conservation of kinetic energy "only" when the block swings to its largest angle.
In nuclear physics, an inelastic collision is one in which the incoming particle causes the nucleus it strikes to become excited or to break up. Deep inelastic scattering is a method of probing the structure of subatomic particles in much the same way as Rutherford probed the inside of the atom (see Rutherford scattering). Such experiments were performed on protons in the late 1960s using high-energy electrons at the Stanford Linear Accelerator (SLAC). As in Rutherford scattering, deep inelastic scattering of electrons by proton targets revealed that most of the incident electrons interact very little and pass straight through, with only a small number bouncing back. This indicates that the charge in the proton is concentrated in small lumps, reminiscent of Rutherford's discovery that the positive charge in an atom is concentrated at the nucleus. However, in the case of the proton, the evidence suggested three distinct concentrations of charge (quarks) and not one.
Formula.
The formula for the velocities after a one-dimensional collision is:
where
In a center of momentum frame the formulas reduce to:
For two- and three-dimensional collisions the velocities in these formulas are the components perpendicular to the tangent line/plane at the point of contact.
Perfectly inelastic collision.
A perfectly inelastic collision occurs when the maximum amount of kinetic energy
of a system is lost. In a perfectly inelastic collision, i.e., a zero coefficient of restitution, the colliding particles stick together. In such a collision, kinetic energy is lost by bonding the two bodies together. This bonding energy usually results in a maximum kinetic energy loss of the system. It is necessary to consider conservation of momentum: (Note: In the sliding block example above, momentum of the two body system is only conserved if the surface has zero friction. With friction, momentum of the two bodies is transferred to the surface that the two bodies are sliding upon. Similarly, if there is air resistance, the momentum of the bodies can be transferred to the air.) The equation below holds true for the two-body (Body A, Body B) system collision in the example above. In this example, momentum of the system is conserved because there is no friction between the sliding bodies and the surface.
where "v" is the final velocity, which is hence given by
The reduction of total kinetic energy is equal to the total kinetic energy before the collision in a center of momentum frame with respect to the system of two particles, because in such a frame the kinetic energy after the collision is zero. In this frame most of the kinetic energy before the collision is that of the particle with the smaller mass. In another frame, in addition to the reduction of kinetic energy there may be a transfer of kinetic energy from one particle to the other; the fact that this depends on the frame shows how relative this is. 
With time reversed we have the situation of two objects pushed away from each other, e.g. shooting a projectile, or a rocket applying thrust (compare the derivation of the Tsiolkovsky rocket equation).
Partially inelastic collisions.
Partially inelastic collisions are the most common form of collisions in the real world. In this type of collision, the objects involved in the collisions do not stick, but some kinetic energy is still lost. Friction, sound and heat are some ways the kinetic energy can be lost through partial inelastic collisions.

</doc>
<doc id="65909" url="https://en.wikipedia.org/wiki?curid=65909" title="Neonatal heel prick">
Neonatal heel prick

The neonatal heel prick or Guthrie test is a screening test done on newborns. It consists of making a pinprick puncture in one heel of the newborn and soaking the blood into pre-printed collection cards known as Guthrie cards.
The classical Guthrie test is named after Robert Guthrie, an American bacteriologist and physician who devised it in 1962. The test has been widely used throughout North America and Europe as one of the core newborn screening tests since the late 1960s. The test was initially a bacterial inhibition assay, but is gradually being replaced in many areas by newer techniques such as tandem mass spectrometry that can detect a wider variety of congenital diseases.
Detected diseases.
The blood samples can be used for a variety of metabolic test to detect genetic conditions, including:
Mechanism.
The test uses the growth of a strain of bacteria on a specially-prepared agar plate as a sign for the presence of high levels of phenylalanine, phenylpyruvate, and/or phenyllactate. The compound B-2-thienylalanine will inhibit the growth of the bacterium "Bacillus subtilis" (ATCC 6051) on minimal culture media. If phenylalanine, phenylpyruvate, and/or phenyllactate is added to the medium, then growth is restored. Such compounds will be present in excess in the blood or urine of patients with PKU. If a suitably-prepared sample of blood or urine is applied to the seeded agar plate, the growth of the bacteria in the test will be a positive indicator for PKU in the patient.
To prepare the sample for application, a small amount of blood (from a heel puncture, for example) or urine (from a diaper, for example) is applied to a piece of filter paper. Then a small disc is punched from the center of the spot of blood or urine, and the disc applied to the surface of a seeded, minimal-medium agar plate that contains added beta-2-thienylalanine. If the sample contains phenylalanine, phenylpyruvate, and/or phenyllactate then these compounds will diffuse into the agar medium. If their concentrations are high enough (as with the excess levels seen with PKU), bacteria will grow under the disc, but not elsewhere. Generally an overnight incubation is enough to determine whether phenylalanine, phenylpyruvate, and/or phenyllactate are present in unusual concentrations in blood or urine.
Timing.
The blood spot sample should be taken on day 5 and in
exceptional circumstances between day 5 and day 8 for
all babies regardless of medical condition, milk feeding
and prematurity. For the purpose of screening, date
of birth is day 0 (some IT systems record date of birth
as day 1). False positives and false negatives can sometimes occur when the screening tests are performed before 48 hours.
With genetic tests becoming more common, a wide variety of tests may use the blood drawn by this method. Many neonatal units (SCBUs) now use this method to carry out the daily blood tests (blood count, electrolytes) required to check the progress of ill neonates.
Controversy.
In Ireland, a controversy emerged in 2012 whereby a number of hospitals retained heel prick test cards and thereby a DNA database with over a million samples from 1984, without consent or notification of parents. This resulted in a ten-year rolling destruction cycle being introduced. Similar practices exist in the United Kingdom, New Zealand, and several states of the United States. 
External links.
references: 
6. http://www.health.vic.gov.au/neonatalhandbook/procedures/neonatal-screening.htm

</doc>
<doc id="65910" url="https://en.wikipedia.org/wiki?curid=65910" title="Printed circuit board">
Printed circuit board

A printed circuit board (PCB) mechanically supports and electrically connects electronic components using conductive tracks, pads and other features etched from copper sheets laminated onto a non-conductive substrate. Components — capacitors, resistors or active devices — are generally soldered on the PCB. Advanced PCBs may contain components embedded in the substrate.
PCBs can be "single sided" (one copper layer), "double sided" (two copper layers) or "multi-layer" (outer and inner layers). Conductors on different layers are connected with vias. Multi-layer PCBs allow for much higher component density. 
FR-4 glass epoxy is the primary insulating substrate. A basic building block of the PCB an FR-4 panel with a thin layer of copper foil is laminated to one or both sides. In multi-layer boards multiple layers of material are laminated together.
Printed circuit boards are used in all but the simplest electronic products. Alternatives to PCBs include wire wrap and point-to-point construction. PCBs require the additional design effort to lay out the circuit, but manufacturing and assembly can be automated. Manufacturing circuits with PCBs is cheaper and faster than with other wiring methods as components are mounted and wired with one single part. Furthermore, operator wiring errors are eliminated.
When the board has no embedded components it is more correctly called a "printed wiring board" ("PWB") or "etched wiring board". However, the term printed wiring board has fallen into disuse. A PCB populated with electronic components is called a "printed circuit assembly" ("PCA"), "printed circuit board assembly" or "PCB assembly" ("PCBA"). The IPC preferred term for assembled boards is "circuit card assembly" ("CCA"), and for assembled backplanes it is "backplane assemblies". The term PCB is used informally both for bare and assembled boards.
The world market for bare PCBs exceeded $60.2 billion in 2014.
Design.
Initially PCBs were designed manually by creating a photomask on a clear mylar sheet, usually at two or four times the true size. Starting from the schematic diagram the component pin pads were laid out on the mylar and then traces were routed to connect the pads. Rub-on dry transfers of common component footprints increased efficiency. Traces were made with self-adhesive tape. Pre-printed non-reproducing grids on the mylar assisted in layout. To fabricate the board, the finished photomask was photolithographically reproduced onto a photoresist coating on the blank copper-clad boards.
Modern PCBs are designed with dedicated layout software, generally in the following steps:
Manufacturing.
PCB manufacturing consists of many steps.
PCB CAM.
Manufacturing starts from the PCB fabrication data generated by CAD: Gerber layer images, Gerber or Excellon drill files, IPC-D-356 netlist and component information. The Gerber or Excellon files in the fabrication data are never used directly on the manufacturing equipment but always read into the CAM (Computer Aided Manufacturing) software. CAM performs the following functions:
Panelization.
Panelization is a procedure whereby a number of PCBs are grouped for manufacturing onto a larger board - the panel. Usually a panel consists of a single design but sometimes multiple designs are mixed on a single panel. There are two types of panels: assembly panels - often called arrays - and bare board manufacturing panels. The assemblers often mount components on panels rather than single PCBs because this is efficient. The bare board manufactures always uses panels, not only for efficiency, but because of the requirements the plating process. Thus a manufacturing panel can consist of a grouping of individual PCBs or of arrays, depending on what must be delivered.
The panel is eventually broken apart into individual PCBs; this is called depaneling. Separating the individual PCBs is frequently aided by drilling or routing perforations along the boundaries of the individual circuits, much like a sheet of postage stamps. Another method, which takes less space, is to cut V-shaped grooves across the full dimension of the panel. The individual PCBs can then be broken apart along this line of weakness. Today depaneling is often done by lasers which cut the board with no contact. Laser panelization reduces stress on the fragile circuits.
Copper patterning.
The first step is to replicate the pattern in the fabricator's CAM system on a protective mask on the copper foil PCB layers. Subsequent etching removes the unwanted copper. (Alternatively, a conductive ink can be ink-jetted on a blank (non-conductive) board. This technique is also used in the manufacture of hybrid circuits.)
The method chosen depends on the number of boards to be produced and the required resolution.
Subtractive, additive and semi-additive processes.
Subtractive methods remove copper from an entirely copper-coated board to leave only the desired copper pattern. In additive methods the pattern is electroplated onto a bare substrate using a complex process. The advantage of the additive method is that less material is needed and less waste is produced. In the full additive process the bare laminate is covered with a photosensitive film which is imaged (exposed to light through a mask and then developed which removes the unexposed film). The exposed areas are sensitized in a chemical bath, usually containing palladium and similar to that used for through hole plating which makes the exposed area capable of bonding metal ions. The laminate is then plated with copper in the sensitized areas. When the mask is stripped, the PCB is finished.
Semi-additive is the most common process: The unpatterned board has a thin layer of copper already on it. A reverse mask is then applied. (Unlike a subtractive process mask, this mask exposes those parts of the substrate that will eventually become the traces.) Additional copper is then plated onto the board in the unmasked areas; copper may be plated to any desired weight. Tin-lead or other surface platings are then applied. The mask is stripped away and a brief etching step removes the now-exposed bare original copper laminate from the board, isolating the individual traces. Some single-sided boards which have plated-through holes are made in this way. General Electric made consumer radio sets in the late 1960s using additive boards.
The (semi-)additive process is commonly used for multi-layer boards as it facilitates the plating-through of the holes to produce conductive vias in the circuit board.
Chemical etching.
Chemical etching is usually done with ammonium persulfate or ferric chloride. For PTH (plated-through holes), additional steps of electroless deposition are done after the holes are drilled, then copper is electroplated to build up the thickness, the boards are screened, and plated with tin/lead. The tin/lead becomes the resist leaving the bare copper to be etched away.
The simplest method, used for small-scale production and often by hobbyists, is immersion etching, in which the board is submerged in etching solution such as ferric chloride. Compared with methods used for mass production, the etching time is long. Heat and agitation can be applied to the bath to speed the etching rate. In bubble etching, air is passed through the etchant bath to agitate the solution and speed up etching. Splash etching uses a motor-driven paddle to splash boards with etchant; the process has become commercially obsolete since it is not as fast as spray etching. In spray etching, the etchant solution is distributed over the boards by nozzles, and recirculated by pumps. Adjustment of the nozzle pattern, flow rate, temperature, and etchant composition gives predictable control of etching rates and high production rates.
As more copper is consumed from the boards, the etchant becomes saturated and less effective; different etchants have different capacities for copper, with some as high as 150 grams of copper per litre of solution. In commercial use, etchants can be regenerated to restore their activity, and the dissolved copper recovered and sold. Small-scale etching requires attention to disposal of used etchant, which is corrosive and toxic due to its metal content.
The etchant removes copper on all surfaces exposed by the resist. "Undercut" occurs when etchant attacks the thin edge of copper under the resist; this can reduce conductor widths and cause open-circuits. Careful control of etch time is required to prevent undercut. Where metallic plating is used as a resist, it can "overhang" which can cause short-circuits between adjacent traces when closely spaced. Overhang can be removed by wire-brushing the board after etching.
Inner layer automated optical inspection (AOI).
The inner layers are given a complete machine inspection before lamination because afterwards mistakes cannot be corrected. The automatic optical inspection system scans the board and compares it with the digital image generated from the original design data.
Lamination.
Multi-layer printed circuit boards have trace layers inside the board. This is achieved by laminating a stack of materials in a press by applying pressure and heat for a period of time. This results in an inseparable one piece product. For example, a four-layer PCB can be fabricated by starting from a two-sided copper-clad laminate, etch the circuitry on both sides, then laminate to the top and bottom pre-preg and copper foil. It is then drilled, plated, and etched again to get traces on top and bottom layers.
Drilling.
Holes through a PCB are typically drilled with small-diameter drill bits made of solid coated tungsten carbide. Coated tungsten carbide is recommended since many board materials are very abrasive and drilling must be high RPM and high feed to be cost effective. Drill bits must also remain sharp so as not to mar or tear the traces. Drilling with high-speed-steel is simply not feasible since the drill bits will dull quickly and thus tear the copper and ruin the boards. The drilling is performed by automated drilling machines with placement controlled by a "drill tape" or "drill file". These computer-generated files are also called "numerically controlled drill" (NCD) files or "Excellon files". The drill file describes the location and size of each drilled hole.
Holes may be made conductive, by electroplating or inserting metal eyelets (hollow), to electrically and thermally connect board layers. Some conductive holes are intended for the insertion of through-hole-component leads. Others, typically smaller and used to connect board layers, are called vias.
When very small vias are required, drilling with mechanical bits is costly because of high rates of wear and breakage. In this case, the vias may be laser drilled—evaporated by lasers. Laser-drilled vias typically have an inferior surface finish inside the hole. These holes are called "micro vias".
It is also possible with "controlled-depth" drilling, laser drilling, or by pre-drilling the individual sheets of the PCB before lamination, to produce holes that connect only some of the copper layers, rather than passing through the entire board. These holes are called "blind vias" when they connect an internal copper layer to an outer layer, or "buried vias" when they connect two or more internal copper layers and no outer layers.
The hole walls for boards with two or more layers can be made conductive and then electroplated with copper to form "plated-through holes".  These holes electrically connect the conducting layers of the PCB. For multi-layer boards, those with three layers or more, drilling typically produces a "smear" of the high temperature decomposition products of bonding agent in the laminate system. Before the holes can be plated through, this smear must be removed by a chemical "de-smear" process, or by "plasma-etch". The de-smear process ensures that a good connection is made to the copper layers when the hole is plated through. On high reliability boards a process called etch-back is performed chemically with a potassium permanganate based etchant or plasma. The etch-back removes resin and the glass fibers so that the copper layers extend into the hole and as the hole is plated become integral with the deposited copper.
Plating and coating.
PCBs are plated with solder, tin, or gold over nickel as a resist for etching away the unneeded underlying copper.
After PCBs are etched and then rinsed with water, the solder mask is applied, and then any exposed copper is coated with solder, nickel/gold, or some other anti-corrosion coating.
Matte solder is usually fused to provide a better bonding surface or stripped to bare copper. Treatments, such as benzimidazolethiol, prevent surface oxidation of bare copper. The places to which components will be mounted are typically plated, because untreated bare copper oxidizes quickly, and therefore is not readily solderable. Traditionally, any exposed copper was coated with solder by hot air solder levelling (HASL). The HASL finish prevents oxidation from the underlying copper, thereby guaranteeing a solderable surface. This solder was a tin-lead alloy, however new solder compounds are now used to achieve compliance with the RoHS directive in the EU and US, which restricts the use of lead. One of these lead-free compounds is SN100CL, made up of 99.3% tin, 0.7% copper, 0.05% nickel, and a nominal of 60ppm germanium.
It is important to use solder compatible with both the PCB and the parts used. An example is ball grid array (BGA) using tin-lead solder balls for connections losing their balls on bare copper traces or using lead-free solder paste.
Other platings used are OSP (organic surface protectant), immersion silver (IAg), immersion tin, electroless nickel with immersion gold coating (ENIG), electroless nickel electroless palladium immersion gold (ENEPIG) and direct gold plating (over nickel). Edge connectors, placed along one edge of some boards, are often nickel plated then gold plated. Another coating consideration is rapid diffusion of coating metal into Tin solder. Tin forms intermetallics such as Cu5Sn6 and Ag3Cu that dissolve into the Tin liquidus or solidus(@50C), stripping surface coating or leaving voids.
"Electrochemical migration" (ECM) is the growth of conductive metal filaments on or in a printed circuit board (PCB) under the influence of a DC voltage bias. Silver, zinc, and aluminum are known to grow whiskers under the influence of an electric field. Silver also grows conducting surface paths in the presence of halide and other ions, making it a poor choice for electronics use. Tin will grow "whiskers" due to tension in the plated surface. Tin-Lead or solder plating also grows whiskers, only reduced by the percentage Tin replaced. Reflow to melt solder or tin plate to relieve surface stress lowers whisker incidence. Another coating issue is tin pest, the transformation of tin to a powdery allotrope at low temperature.
Solder resist application.
Areas that should not be soldered may be covered with solder resist (solder mask). One of the most common solder resists used today is called "LPI" (liquid photoimageable solder mask).  A photo-sensitive coating is applied to the surface of the PWB, then exposed to light through the solder mask image film, and finally developed where the unexposed areas are washed away. Dry film solder mask is similar to the dry film used to image the PWB for plating or etching. After being laminated to the PWB surface it is imaged and develop as LPI. Once common but no longer commonly used because of its low accuracy and resolution is to screen print epoxy ink. Solder resist also provides protection from the environment.
Legend printing.
A legend is often printed on one or both sides of the PCB. It contains the component designators, switch settings, test points and other indications helpful in assembling, testing and servicing the circuit board.
There are three methods to print the legend.
Bare-board test.
Unpopulated boards are usually "bare-board tested" for "shorts" and "opens". A short is a connection between two points that should not be connected. An open is a missing connection between points that should be connected. For high-volume production a fixture or a rigid needle adapter is used to make contact with copper lands on the board. Building the adapter is a significant fixed cost and is only economical for high-volume or high-value production. For small or medium volume production "flying probe" testers are used where test probes are moved over the board by an XY drive to make contact with the copper lands. The CAM system "instructs" the electrical tester to apply a voltage to each contact point as required and to check that this voltage appears on the appropriate contact points and only on these.
Assembly.
In assembly the bare board is populated with electronic components to form a functional "printed circuit assembly" (PCA), sometimes called a "printed circuit board assembly" (PCBA). In through-hole technology component leads are inserted in holes. In surface-mount technology (SMT) the components are glued on "pads" or "lands" on the surfaces of the PCB. In both component leads are then mechanically fixed and electrically connected to the board by soldering.
There are a variety of soldering techniques used to attach components to a PCB. High volume production is usually done with SMT placement machine and bulk wave soldering or reflow ovens, but skilled technicians are able to solder very tiny parts (for instance 0201 packages which are 0.02 in. by 0.01 in.) by hand under a microscope, using tweezers and a fine tip soldering iron for small volume prototypes. Some parts cannot be soldered by hand, such as BGA packages.
Often, through-hole and surface-mount construction must be combined in a single assembly because some required components are available only in surface-mount packages, while others are available only in through-hole packages. Another reason to use both methods is that through-hole mounting can provide needed strength for components likely to endure physical stress, while components that are expected to go untouched will take up less space using surface-mount techniques.
"For further comparison, see the SMT page."
After the board has been populated it may be tested in a variety of ways:
To facilitate these tests, PCBs may be designed with extra pads to make temporary connections. Sometimes these pads must be isolated with resistors. The in-circuit test may also exercise boundary scan test features of some components. In-circuit test systems may also be used to program nonvolatile memory components on the board.
In boundary scan testing, test circuits integrated into various ICs on the board form temporary connections between the PCB traces to test that the ICs are mounted correctly. Boundary scan testing requires that all the ICs to be tested use a standard test configuration procedure, the most common one being the Joint Test Action Group (JTAG) standard. The JTAG test architecture provides a means to test interconnects between integrated circuits on a board without using physical test probes. JTAG tool vendors provide various types of stimulus and sophisticated algorithms, not only to detect the failing nets, but also to isolate the faults to specific nets, devices, and pins.
When boards fail the test, technicians may desolder and replace failed components, a task known as "rework".
Protection and packaging.
PCBs intended for extreme environments often have a conformal coating, which is applied by dipping or spraying after the components have been soldered. The coat prevents corrosion and leakage currents or shorting due to condensation. The earliest conformal coats were wax; modern conformal coats are usually dips of dilute solutions of silicone rubber, polyurethane, acrylic, or epoxy. Another technique for applying a conformal coating is for plastic to be sputtered onto the PCB in a vacuum chamber. The chief disadvantage of conformal coatings is that servicing of the board is rendered extremely difficult.
Many assembled PCBs are static sensitive, and therefore must be placed in antistatic bags during transport. When handling these boards, the user must be grounded (earthed). Improper handling techniques might transmit an accumulated static charge through the board, damaging or destroying components. Even bare boards are sometimes static sensitive. Traces have become so fine that it's quite possible to blow an etch off the board (or change its characteristics) with a static charge. This is especially true on non-traditional PCBs such as MCMs and microwave PCBs.
PCB characteristics.
Much of the electronics industry's PCB design, assembly, and quality control follows standards published by the IPC organization.
Through-hole technology.
The first PCBs used through-hole technology, mounting electronic components by leads inserted through holes on one side of the board and soldered onto copper traces on the other side. Boards may be single-sided, with an unplated component side, or more compact double-sided boards, with components soldered on both sides. Horizontal installation of through-hole parts with two axial leads (such as resistors, capacitors, and diodes) is done by bending the leads 90 degrees in the same direction, inserting the part in the board (often bending leads located on the back of the board in opposite directions to improve the part's mechanical strength), soldering the leads, and trimming off the ends. Leads may be soldered either manually or by a wave soldering machine.
Through-hole PCB technology almost completely replaced earlier electronics assembly techniques such as point-to-point construction. From the second generation of computers in the 1950s until surface-mount technology became popular in the late 1980s, every component on a typical PCB was a through-hole component.
Through-hole manufacture adds to board cost by requiring many holes to be drilled accurately, and limits the available routing area for signal traces on layers immediately below the top layer on multi-layer boards since the holes must pass through all layers to the opposite side. Once surface-mounting came into use, small-sized SMD components were used where possible, with through-hole mounting only of components unsuitably large for surface-mounting due to power requirements or mechanical limitations, or subject to mechanical stress which might damage the PCB.
Surface-mount technology.
Surface-mount technology emerged in the 1960s, gained momentum in the early 1980s and became widely used by the mid-1990s.
Components were mechanically redesigned to have small metal tabs or end caps that could be soldered directly onto the PCB surface, instead of wire leads to pass through holes. Components became much smaller and component placement on both sides of the board became more common than with through-hole mounting, allowing much smaller PCB assemblies with much higher circuit densities.
Surface mounting lends itself well to a high degree of automation, reducing labor costs and greatly increasing production rates. Components can be supplied mounted on carrier tapes. Surface mount components can be about one-quarter to one-tenth of the size and weight of through-hole components, and passive components much cheaper; prices of semiconductor surface mount devices (SMDs) are determined more by the chip itself than the package, with little price advantage over larger packages. Some wire-ended components, such as 1N4148 small-signal switch diodes, are actually significantly cheaper than SMD equivalents.
Circuit properties of the PCB.
Each trace consists of a flat, narrow part of the copper foil that remains after etching. The resistance, determined by width and thickness, of the traces must be sufficiently low for the current the conductor will carry. Power and ground traces may need to be wider than signal traces. In a multi-layer board one entire layer may be mostly solid copper to act as a ground plane for shielding and power return. For microwave circuits, transmission lines can be laid out in the form of stripline and microstrip with carefully controlled dimensions to assure a consistent impedance. In radio-frequency and fast switching circuits the inductance and capacitance of the printed circuit board conductors become significant circuit elements, usually undesired; but they can be used as a deliberate part of the circuit design, obviating the need for additional discrete components.
Materials.
Excluding exotic products using special materials or processes all printed circuit boards manufactured today can be built using the following four materials:
Laminates.
Laminates are manufactured by curing under pressure and temperature layers of cloth or paper with thermoset resin to form an integral final piece of uniform thickness. The size can be up to in width and length. Varying cloth weaves (threads per inch or cm), cloth thickness, and resin percentage are used to achieve the desired final thickness and dielectric characteristics. Available standard laminate thickness are listed in
Notes:
The cloth or fiber material used, resin material, and the cloth to resin ratio determine the laminate's type designation (FR-4, CEM-1, G-10, etc.) and therefore the characteristics of the laminate produced. Important characteristics are the level to which the laminate is fire retardant, the dielectric constant (er), the loss factor (tδ), the tensile strength, the shear strength, the glass transition temperature (Tg), and the Z-axis expansion coefficient (how much the thickness changes with temperature).
There are quite a few different dielectrics that can be chosen to provide different insulating values depending on the requirements of the circuit. Some of these dielectrics are polytetrafluoroethylene (Teflon), FR-4, FR-1, CEM-1 or CEM-3. Well known pre-preg materials used in the PCB industry are FR-2 (phenolic cotton paper), FR-3 (cotton paper and epoxy), FR-4 (woven glass and epoxy), FR-5 (woven glass and epoxy), FR-6 (matte glass and polyester), G-10 (woven glass and epoxy), CEM-1 (cotton paper and epoxy), CEM-2 (cotton paper and epoxy), CEM-3 (non-woven glass and epoxy), CEM-4 (woven glass and epoxy), CEM-5 (woven glass and polyester). Thermal expansion is an important consideration especially with ball grid array (BGA) and naked die technologies, and glass fiber offers the best dimensional stability.
FR-4 is by far the most common material used today. The board with copper on it is called "copper-clad laminate".
With decreasing size of board features and increasing frequencies, small nonhomogeneities like uneven distribution of fiberglass or other filler, thickness variations, and bubbles in the resin matrix, and the associated local variations in the dielectric constant, are gaining importance. 
Key substrate parameters.
The circuitboard substrates are usually dielectric composite materials. The composites contain a matrix (usually an epoxy resin), a reinforcement (usually a woven, sometimes nonwoven, glass fibers, sometimes even paper), and in some cases a filler is added to the resin (e.g. ceramics; titanate ceramics can be used to increase the dielectric constant).
The reinforcement type defines two major classes of materials - woven and non-woven. Woven reinforcements are cheaper, but the high dielectric constant of glass may not be favorable for many higher-frequency applications. The spatially nonhomogeneous structure also introduces local variations in electrical parameters, due to different resin/glass ratio at different areas of the weave pattern. Nonwoven reinforcements, or materials with low or no reinforcement, are more expensive but more suitable for some RF/analog applications.
The substrates are characterized by several key parameters, chiefly thermomechanical (glass transition temperature, tensile strength, shear strength, thermal expansion), electrical (dielectric constant, loss tangent, dielectric breakdown voltage, leakage current, tracking resistance...), and others (e.g. moisture absorption).
At the glass transition temperature the resin in the composite softens and significantly increases thermal expansion; exceeding Tg then exerts mechanical overload on the board components - e.g. the joints and the vias. Below Tg the thermal expansion of the resin roughly matches copper and glass, above it gets significantly higher. As the reinforcement and copper confine the board along the plane, virtually all volume expansion projects to the thickness and stresses the plated-through holes. Repeated soldering or other exposition to higher temperatures can cause failure of the plating, especially with thicker boards; thick boards therefore require high Tg matrix.
The materials used determine the substrate's dielectric constant. This constant is also dependent on frequency, usually decreasing with frequency. As this constant determines the signal propagation speed, frequency dependence introduces phase distortion in wideband applications; as flat dielectric constant vs frequency characteristics as achievable is important here. The impedance of transmission lines decreases with frequency, therefore faster edges of signals reflect more than slower ones.
Dielectric breakdown voltage determines the maximum voltage gradient the material can be subjected to before suffering a breakdown.
Tracking resistance determines how the material resists high voltage electrical discharges creeping over the board surface.
Loss tangent determines how much of the electromagnetic energy from the signals in the conductors is absorbed in the board material. This factor is important for high frequencies. Low-loss materials are more expensive. Choosing unnecessarily low-loss material is a common error in high-frequency digital design; it increases the cost of the boards without a corresponding benefit. Signal degradation by loss tangent and dielectric constant can be easily assessed by an eye pattern.
Moisture absorption occurs when the material is exposed to high humidity or water. Both the resin and the reinforcement may absorb water; water may be also soaked by capillary forces through voids in the materials and along the reinforcement. Epoxies of the FR-4 materials aren't too susceptible, with absorption of only 0.15%. Teflon has very low absorption of 0.01%. Polyimides and cyanate esters, on the other side, suffer from high water absorption. Absorbed water can lead to significant degradation of key parameters; it impairs tracking resistance, breakdown voltage, and dielectric parameters. Relative dielectric constant of water is about 73, compared to about 4 for common circuitboard materials. Absorbed moisture can also vaporize on heating and cause cracking and delamination, the same effect responsible for "popcorning" damage on wet packaging of electronic parts. Careful baking of the substrates may be required.
Common substrates.
Often encountered materials:
Less-often encountered materials:
Copper thickness.
Copper thickness of PCBs can be specified as units of length (in micrometers or mils) but is often specified as weight of copper per area (in ounce per square foot) which is easier to measure. One ounce per square foot is 1.344 mils or 34 micrometers thickness.
The printed circuit board industry defines heavy copper as layers exceeding three ounces of copper, or approximately 0.0042 inches (4.2 mils, 105 μm) thick. PCB designers and fabricators often use heavy copper when design and manufacturing circuit boards in order to increase current-carrying capacity as well as resistance to thermal strains. Heavy copper plated vias transfer heat to external heat sinks. IPC 2152 is a standard for determining current-carrying capacity of printed circuit board traces.
On the common FR-4 substrates, 1 oz copper (35 µm) is the usual, most common thickness; 2 oz (70 µm) and 0.5 oz (18 µm) thickness is often an option. Less common are 12 and 105 µm, 9 µm is sometimes available on some substrates. Flexible substrates typically have thinner metalization; 18 and 35 µm seem to be common, with 9 and 70 µm sometimes available. Aluminium or metal-core boards for high power devices commonly use thicker copper; 35 µm is usual but also 140 and 400 µm can be encountered.
Safety certification (US).
Safety Standard UL 796 covers component safety requirements for printed wiring boards for use as components in devices or appliances. Testing analyzes characteristics such as flammability, maximum operating temperature, electrical tracking, heat deflection, and direct support of live electrical parts.
Multiwire boards.
Multiwire is a patented technique of interconnection which uses machine-routed insulated wires embedded in a non-conducting matrix (often plastic resin). It was used during the 1980s and 1990s. (Kollmorgen Technologies Corp, filed 1978) Multiwire is still available in 2010 through Hitachi. There are other competitive discrete wiring technologies that have been developed (Jumatech [http://www.jumapcb.com/], layered sheets).
Since it was quite easy to stack interconnections (wires) inside the embedding matrix, the approach allowed designers to forget completely about the routing of wires (usually a time-consuming operation of PCB design): Anywhere the designer needs a connection, the machine will draw a wire in straight line from one location/pin to another. This led to very short design times (no complex algorithms to use even for high density designs) as well as reduced crosstalk (which is worse when wires run parallel to each other—which almost never happens in Multiwire), though the cost is too high to compete with cheaper PCB technologies when large quantities are needed.
Corrections can be made to a Multiwire board more easily than to a PCB.
Cordwood construction.
Cordwood construction can save significant space and was often used with wire-ended components in applications where space was at a premium (such as missile guidance and telemetry systems) and in high-speed computers, where short traces were important. In cordwood construction, axial-leaded components were mounted between two parallel planes. The components were either soldered together with jumper wire, or they were connected to other components by thin nickel ribbon welded at right angles onto the component leads. To avoid shorting together different interconnection layers, thin insulating cards were placed between them. Perforations or holes in the cards allowed component leads to project through to the next interconnection layer. One disadvantage of this system was that special nickel-leaded components had to be used to allow the interconnecting welds to be made. Differential thermal expansion of the component could put pressure on the leads of the components and the PCB traces and cause physical damage (as was seen in several modules on the Apollo program). Additionally, components located in the interior are difficult to replace. Some versions of cordwood construction used soldered single-sided PCBs as the interconnection method (as pictured), allowing the use of normal-leaded components.
Before the advent of integrated circuits, this method allowed the highest possible component packing density; because of this, it was used by a number of computer vendors including Control Data Corporation. The cordwood method of construction was used only rarely once semiconductor electronics and PCBs became widespread.
History.
Development of the methods used in modern printed circuit boards started early in the 20th century. In 1903, a German inventor, Albert Hanson, described flat foil conductors laminated to an insulating board, in multiple layers. Thomas Edison experimented with chemical methods of plating conductors onto linen paper in 1904. Arthur Berry in 1913 patented a print-and-etch method in Britain, and in the United States Max Schoop obtained a patent to flame-spray metal onto a board through a patterned mask. Charles Ducas in 1927 patented a method of electroplating circuit patterns.
The Austrian engineer Paul Eisler invented the printed circuit as part of a radio set while working in England around 1936. Around 1943 the USA began to use the technology on a large scale to make proximity fuses for use in World War II. After the war, in 1948, the USA released the invention for commercial use. Printed circuits did not become commonplace in consumer electronics until the mid-1950s, after the "Auto-Sembly" process was developed by the United States Army. At around the same time in Britain work along similar lines was carried out by Geoffrey Dummer, then at the RRDE. 
Before printed circuits (and for a while after their invention), point-to-point construction was used. For prototypes, or small production runs, wire wrap or turret board can be more efficient. Predating the printed circuit invention, and similar in spirit, was John Sargrove's 1936–1947 Electronic Circuit Making Equipment (ECME) which sprayed metal onto a Bakelite plastic board. The ECME could produce 3 radios per minute.
During World War II, the development of the anti-aircraft proximity fuse required an electronic circuit that could withstand being fired from a gun, and could be produced in quantity. The Centralab Division of Globe Union submitted a proposal which met the requirements: a ceramic plate would be screenprinted with metallic paint for conductors and carbon material for resistors, with ceramic disc capacitors and subminiature vacuum tubes soldered in place. The technique proved viable, and the resulting patent on the process, which was classified by the U.S. Army, was assigned to Globe Union. It was not until 1984 that the Institute of Electrical and Electronics Engineers (IEEE) awarded Mr. Harry W. Rubinstein, the former head of Globe Union's Centralab Division, its coveted Cledo Brunetti Award for early key contributions to the development of printed components and conductors on a common insulating substrate. As well, Mr. Rubinstein was honored in 1984 by his alma mater, the University of Wisconsin-Madison, for his innovations in the technology of printed electronic circuits and the fabrication of capacitors., every electronic component had wire leads, and the PCB had holes drilled for each wire of each component. The components' leads were then passed through the holes and soldered to the PCB trace. This method of assembly is called "through-hole" construction. In 1949, Moe Abramson and Stanislaus F. Danko of the United States Army Signal Corps developed the "Auto-Sembly" process in which component leads were inserted into a copper foil interconnection pattern and dip soldered. The patent they obtained in 1956 was assigned to the U.S. Army. With the development of board lamination and etching techniques, this concept evolved into the standard printed circuit board fabrication process in use today. Soldering could be done automatically by passing the board over a ripple, or wave, of molten solder in a wave-soldering machine. However, the wires and holes are wasteful since drilling holes is expensive and the protruding wires are merely cut off.
From the 1980s small surface mount parts have been used increasingly instead of through-hole components; this has led to smaller boards for a given functionality and lower production costs, but with some additional difficulty in servicing faulty boards.
Historically many measurements related to PCB design were specified in multiples of a thousandth of an inch, often called "mils".
For example, DIP and most other through-hole components have pins located on a grid spacing of 100 mils, in order to be breadboard-friendly.
Surface-mount SOIC components have a pin pitch of 50 mils.
SOP components have a pin pitch of 25 mils.
Level B technology recommends a minimum trace width of 8 mils, which allows "double-track" – two traces between DIP pins.
See also.
PCB materials
PCB layout software

</doc>
<doc id="65913" url="https://en.wikipedia.org/wiki?curid=65913" title="Equations of motion">
Equations of motion

In mathematical physics, equations of motion are equations that describe the behaviour of a physical system in terms of its motion as a function of time. More specifically, the equations of motion describe the behaviour of a physical system as a set of mathematical functions in terms of dynamic variables: normally spatial coordinates and time are used, but others are also possible, such as momentum components and time. The most general choice are generalized coordinates which can be any convenient variables characteristic of the physical system. The functions are defined in a Euclidean space in classical mechanics, but are replaced by curved spaces in relativity. If the dynamics of a system is known, the equations are the solutions to the differential equations describing the motion of the dynamics.
There are two main descriptions of motion: dynamics and kinematics. Dynamics is general, since momenta, forces and energy of the particles are taken into account. In this instance, sometimes the term refers to the differential equations that the system satisfies (e.g., Newton's second law or Euler–Lagrange equations), and sometimes to the solutions to those equations.
However, kinematics is simpler as it concerns only variables derived from the positions of objects, and time. In circumstances of constant acceleration, these simpler equations of motion are usually referred to as the "SUVAT" equations, arising from the definitions of kinematic quantities: displacement (), initial velocity (), final velocity (), acceleration (), and time (). (see below).
Equations of motion can therefore be grouped under these main classifiers of motion. In all cases, the main types of motion are translations, rotations, oscillations, or any combinations of these.
A differential equation of motion, usually identified as some physical law and applying definitions of physical quantities, is used to set up an equation for the problem. Solving the differential equation will lead to a general solution with arbitrary constants, the arbitrariness corresponding to a family of solutions. A particular solution can be obtained by setting the initial values, which fixes the values of the constants.
To state this formally, in general an equation of motion is a function of the position of the object, its velocity (the first time derivative of , ), and its acceleration (the second derivative of , ), and time . Euclidean vectors in 3D are denoted throughout in bold. This is equivalent to saying an equation of motion in is a second order ordinary differential equation (ODE) in ,
where is time, and each overdot denotes one time derivative. The initial conditions are given by the "constant" values at ,
The solution to the equation of motion, with specified initial values, describes the system for all times after . Other dynamical variables like the momentum of the object, or quantities derived from and like angular momentum, can be used in place of as the quantity to solve for from some equation of motion, although the position of the object at time is by far the most sought-after quantity.
Sometimes, the equation will be linear and is more likely to be exactly solvable. In general, the equation will be non-linear, and cannot be solved exactly so a variety of approximations must be used. The solutions to nonlinear equations may show chaotic behavior depending on how "sensitive" the system is to the initial conditions.
History.
Historically, equations of motion first appeared in classical mechanics to describe the motion of massive objects, a notable application was to celestial mechanics to predict the motion of the planets as if they orbit like clockwork (this was how Neptune was predicted before its discovery), and also investigate the stability of the solar system.
It is important to observe that the huge body of work involving kinematics, dynamics and the mathematical models of the universe developed in baby steps – faltering, getting up and correcting itself – over three millennia and included contributions of both known names and others who have since faded from the annals of history.
In antiquity, notwithstanding the success of priests, astrologers and astronomers in predicting solar and lunar eclipses, the solstices and the equinoxes of the Sun and the period of the Moon, there was nothing other than a set of algorithms to help them. Despite the great strides made in the development of geometry in the Ancient Greece and surveys in Rome, we were to wait for another thousand years before the first equations of motion arrive.
The exposure of Europe to the collected works by the Muslims of the Greeks, the Indians and the Islamic scholars, such as Euclid’s "Elements", the works of Archimedes, and Al-Khwārizmī's treatises began in Spain, and scholars from all over Europe went to Spain, read, copied and translated the learning into Latin. The exposure of Europe to Arabic numerals and their ease in computations encouraged first the scholars to learn them and then the merchants and invigorated the spread of knowledge throughout Europe.
By the 13th century the universities of Oxford and Paris had come up, and the scholars were now studying mathematics and philosophy with lesser worries about mundane chores of life—the fields were not as clearly demarcated as they are in the modern times. Of these, compendia and redactions, such as those of Johannes Campanus, of Euclid and Aristotle, confronted scholars with ideas about infinity and the ratio theory of elements as a means of expressing relations between various quantities involved with moving bodies. These studies led to a new body of knowledge that is now known as physics.
Of these institutes Merton College sheltered a group of scholars devoted to natural science, mainly physics, astronomy and mathematics, of similar in stature to the intellectuals at the University of Paris. Thomas Bradwardine, one of those scholars, extended Aristotelian quantities such as distance and velocity, and assigned intensity and extension to them. Bradwardine suggested an exponential law involving force, resistance, distance, velocity and time. Nicholas Oresme further extended Bradwardine's arguments. The Merton school proved the that the quantity of motion of a body undergoing a uniformly accelerated motion is equal to the quantity of a uniform motion at the speed achieved halfway through the accelerated motion.
For writers on kinematics before Galileo, since small time intervals could not be measured, the affinity between time and motion was obscure. They used time as a function of distance, and in free fall, greater velocity as a result of greater elevation. Only Domingo de Soto, a Spanish theologian, in his commentary on Aristotle's "Physics" published in 1545, after defining "uniform difform" motion (which is uniformly accelerated motion) – the word velocity wasn't used – as proportional to time, declared correctly that this kind of motion was identifiable with freely falling bodies and projectiles, without his proving these propositions or suggesting a formula relating time, velocity and distance. De Soto's comments are shockingly correct regarding the definitions of acceleration (acceleration was a rate of change of motion (velocity) in time) and the observation that during the violent motion of ascent acceleration would be negative.
Discourses such as these spread throughout the Europe and definitely influenced Galileo and others, and helped in laying the foundation of kinematics. Galileo deduced the equation in his work geometrically, using Merton's rule, now known as a special case of one of the equations of kinematics. He couldn't use the now-familiar mathematical reasoning. The relationships between speed, distance, time and acceleration was not known at the time.
Galileo was the first to show that the path of a projectile is a parabola. Galileo had an understanding of centrifugal force and gave a correct definition of momentum. This emphasis of momentum as a fundamental quantity in dynamics is of prime importance. He measured momentum by the product of velocity and weight; mass is a later concept, developed by Huygens and Newton. In the swinging of a simple pendulum, Galileo says in "Discourses" that "every momentum acquired in the descent along an arc is equal to that which causes the same moving body to ascend through the same arc." His analysis on projectiles indicates that Galileo had grasped the first law and the second law of motion. He did not generalize and make them applicable to bodies not subject to the earth's gravitation. That step was Newton's contribution.
The term "inertia" was used by Kepler who applied it to bodies at rest.The first law of motion is now often called the law of inertia.
Galileo did not fully grasp the third law of motion, the law of the equality of action and reaction, though he corrected some errors of Aristotle. With Stevin and others Galileo also wrote on statics. He formulated the principle of the parallelogram of forces, but he did not fully recognize its scope.
Galileo also was interested by the laws of the pendulum, his first observations was when he was a young man. In 1583, while he was praying in the cathedral at Pisa, his attention was arrested by the motion of the great lamp lighted and left swinging, referencing his own pulse for time keeping. To him the period appeared the same, even after the motion had greatly diminished, discovering the isochronism of the pendulum.
More careful experiments carried out by him later, and described in his Discourses, revealed the period of oscillation varies with the square root of length but is independent of the mass the pendulum.
Thus we arrive at René Descartes, Isaac Newton, Gottfried Leibniz, et al.; and the evolved forms of the equations of motion that begin to be recognized as the modern ones.
Later the equations of motion also appeared in electrodynamics, when describing the motion of charged particles in electric and magnetic fields, the Lorentz force is the general equation which serves as the definition of what is meant by an electric field and magnetic field. With the advent of special relativity and general relativity, the theoretical modifications to spacetime meant the classical equations of motion were also modified to account for the finite speed of light, and curvature of spacetime. In all these cases the differential equations were in terms of a function describing the particle's trajectory in terms of space and time coordinates, as influenced by forces or energy transformations.
However, the equations of quantum mechanics can also be considered "equations of motion", since they are differential equations of the wavefunction, which describes how a quantum state behaves analogously using the space and time coordinates of the particles. There are analogs of equations of motion in other areas of physics, for collections of physical phenomena that can be considered waves, fluids, or fields.
Kinematic equations for one particle.
Kinematic quantities.
From the instantaneous position , instantaneous meaning at an instant value of time , the instantaneous velocity and acceleration have the general, coordinate-independent definitions;
Notice that velocity always points in the direction of motion, in other words for a curved path it is the tangent vector. Loosely speaking, first order derivatives are related to tangents of curves. Still for curved paths, the acceleration is directed towards the center of curvature of the path. Again, loosely speaking, second order derivatives are related to curvature.
The rotational analogues are the "angular vector" (angle the particle rotates about some axis) , angular velocity , and angular acceleration :
where is a unit vector in the direction of the axis of rotation, and is the angle the object turns through about the axis.
The following relation holds for a point-like particle, orbiting about some axis with angular velocity :
where is the position vector of the particle (radial from the rotation axis) and the tangential velocity of the particle. For a rotating continuum rigid body, these relations hold for each point in the rigid body.
Uniform acceleration.
The differential equation of motion for a particle of constant or uniform acceleration in a straight line is simple: the acceleration is constant, so the second derivative of the position of the object is constant. The results of this case are summarized below.
Constant translational acceleration in a straight line.
These equations apply to a particle moving linearly, in three dimensions in a straight line with constant acceleration. Since the position, velocity, and acceleration are collinear (parallel, and lie on the same line) – only the magnitudes of these vectors are necessary, and because the motion is along a straight line, the problem effectively reduces from three dimensions to one.
where:
Equations and [2 are from integrating the definitions of velocity and acceleration, subject to the initial conditions and ;
in magnitudes,
where and are the polar unit vectors. For the velocity , is the component of velocity in the radial direction, and is the additional component due to the rotation. For the acceleration , is the centripetal acceleration and the Coriolis acceleration, in addition to the radial acceleration and angular acceleration .
Special cases of motion described be these equations are summarized qualitatively in the table below. Two have already been discussed above, in the cases that either the radial components or the angular components are zero, and the non-zero component of motion describes uniform acceleration.
General 3D motion.
In 3D space, the equations in spherical coordinates with corresponding unit vectors , and , the position, velocity, and acceleration generalize respectively to
In the case of a constant this reduces to the planar equations above.
Dynamic equations of motion.
Newtonian mechanics.
The first general equation of motion developed was Newton's second law of motion, in its most general form states the rate of change of momentum of an object equals the force acting on it,
The force in the equation is "not" the force the object exerts. Replacing momentum by mass times velocity, the law is also written more famously as
since is a constant in Newtonian mechanics.
Newton's second law applies to point-like particles, and to all points in a rigid body. They also apply to each point in a mass continua, like deformable solids or fluids, but the motion of the system must be accounted for, see material derivative. In the case the mass is not constant, it is not sufficient to use the product rule for the time derivative on the mass and velocity, and Newton's second law requires some modification consistent with conservation of momentum, see variable-mass system.
It may be simple to write down the equations of motion in vector form using Newton's laws of motion, but the components may vary in complicated ways with spatial coordinates and time, and solving them is not easy. Often there is an excess of variables to solve for the problem completely, so Newton's laws are not always the most efficient way to determine the motion of a system. In simple cases of rectangular geometry, Newton's laws work fine in Cartesian coordinates, but in other coordinate systems can become dramatically complex.
The momentum form is preferable since this is readily generalized to more complex systems, generalizes to special and general relativity (see four-momentum). It can also be used with the momentum conservation. However, Newton's laws are not more fundamental than momentum conservation, because Newton's laws are merely consistent with the fact that zero resultant force acting on an object implies constant momentum, while a resultant force implies the momentum is not constant. Momentum conservation is always true for an isolated system not subject to resultant forces.
For a number of particles (see many body problem), the equation of motion for one particle influenced by other particles is
where is the momentum of particle , is the force on particle by particle , and is the resultant external force due to any agent not part of system. Particle does not exert a force on itself.
Euler's laws of motion are similar to Newton's laws, but they are applied specifically to the motion of rigid bodies. The Newton–Euler equations combine the forces and torques acting on a rigid body into a single equation.
Newton's second law for rotation takes a similar form to the translational case,
by equating the torque acting on the body to the rate of change of its angular momentum . Analogous to mass times acceleration, the moment of inertia tensor depends on the distribution of mass about the axis of rotation, and the angular acceleration is the rate of change of angular velocity,
Again, these equations apply to point like particles, or at each point of a rigid body.
Likewise, for a number of particles, the equation of motion for one particle is
where is the angular momentum of particle , the torque on particle by particle , and is resultant external torque (due to any agent not part of system). Particle does not exert a torque on itself.
Applications.
Some examples of Newton's law include describing the motion of a simple pendulum,
and a damped, sinusoidally driven harmonic oscillator,
For describing the motion of masses due to gravity, Newton's law of gravity can be combined with Newton's second law. For two examples, a ball of mass thrown in the air, in air currents (such as wind) described by a vector field of resistive forces ,
where is the gravitational constant, the mass of the Earth, and is the acceleration of the projectile due to the air currents at position and time .
The classical -body problem for particles each interacting with each other due to gravity is a set of nonlinear coupled second order ODEs,
where labels the quantities (mass, position, etc.) associated with each particle.
Analytical mechanics.
Using all three coordinates of 3D space is unnecessary if there are constraints on the system. If the system has degrees of freedom, then one can use a set of generalized coordinates , to define the configuration of the system. They can be in the form of arc lengths or angles. They are a considerable simplification to describe motion, since they take advantage of the intrinsic constraints that limit the system's motion, and the number of coordinates is reduced to a minimum. The time derivatives of the generalized coordinates are the "generalized velocities"
The Euler–Lagrange equations are
where the "Lagrangian" is a function of the configuration and its time rate of change (and possibly time )
Setting up the Lagrangian of the system, then substituting into the equations and evaluating the partial derivatives and simplifying, a set of coupled second order ODEs in the coordinates are obtained.
Hamilton's equations are
where the Hamiltonian
is a function of the configuration and conjugate ""generalized" momenta"
in which is a shorthand notation for a vector of partial derivatives with respect to the indicated variables (see for example matrix calculus for this denominator notation), and possibly time ,
Setting up the Hamiltonian of the system, then substituting into the equations and evaluating the partial derivatives and simplifying, a set of coupled first order ODEs in the coordinates and momenta are obtained.
The Hamilton–Jacobi equation is
where
is "Hamilton's principal function", also called the "classical action" is a functional of . In this case, the momenta are given by
Although the equation has a simple general form, for a given Hamiltonian it is actually a single first order "non-linear" PDE, in variables. The action allows identification of conserved quantities for mechanical systems, even when the mechanical problem itself cannot be solved fully, because any differentiable symmetry of the action of a physical system has a corresponding conservation law, a theorem due to Emmy Noether.
All classical equations of motion can be derived from the variational principle known as Hamilton's principle of least action
stating the path the system takes through the configuration space is the one with the least action .
Electrodynamics.
In electrodynamics, the force on a charged particle of charge is the Lorentz force:
Combining with Newton's second law gives a first order differential equation of motion, in terms of position of the particle:
or its momentum:
The same equation can be obtained using the Lagrangian (and applying Lagrange's equations above) for a charged particle of mass and charge :
where and are the electromagnetic scalar and vector potential fields. The Lagrangian indicates an additional detail: the canonical momentum in Lagrangian mechanics is given by:
instead of just , implying the motion of a charged particle is fundamentally determined by the mass and charge of the particle. The Lagrangian expression was first used to derive the force equation.
Alternatively the Hamiltonian (and substituting into the equations):
can derive the Lorentz force equation.
General relativity.
Geodesic equation of motion.
The above equations are valid in flat spacetime. In curved space spacetime, things become mathematically more complicated since there is no straight line; this is generalized and replaced by a "geodesic" of the curved spacetime (the shortest length of curve between two points). For curved manifolds with a metric tensor , the metric provides the notion of arc length (see line element for details), the differential arc length is given by:
and the geodesic equation is a second-order differential equation in the coordinates, the general solution is a family of geodesics:
where is a Christoffel symbol of the second kind, which contains the metric (with respect to the coordinate system).
Given the mass-energy distribution provided by the stress–energy tensor , the Einstein field equations are a set of non-linear second-order partial differential equations in the metric, and imply the curvature of space time is equivalent to a gravitational field (see principle of equivalence). Mass falling in curved spacetime is equivalent to a mass falling in a gravitational field - because gravity is a fictitious force. The "relative acceleration" of one geodesic to another in curved spacetime is given by the "geodesic deviation equation":
where is the separation vector between two geodesics, ("not" just ) is the covariant derivative, and is the Riemann curvature tensor, containing the Christoffel symbols. In other words, the geodesic deviation equation is the equation of motion for masses in curved spacetime, analogous to the Lorentz force equation for charges in an electromagnetic field.
For flat spacetime, the metric is a constant tensor so the Christoffel symbols vanish, and the geodesic equation has the solutions of straight lines. This is also the limiting case when masses move according to Newton's law of gravity.
Spinning objects.
In general relativity, rotational motion is described by the relativistic angular momentum tensor, including the spin tensor, which enter the equations of motion under covariant derivatives with respect to proper time. The Mathisson–Papapetrou–Dixon equations describe the motion of spinning objects moving in a gravitational field.
Analogues for waves and fields.
Unlike the equations of motion for describing particle mechanics, which are systems of coupled ordinary differential equations, the analogous equations governing the dynamics of waves and fields are always partial differential equations, since the waves or fields are functions of space and time. For a particular solution, boundary conditions along with initial conditions need to be specified.
Sometimes in the following contexts, the wave or field equations are also called "equations of motion".
Field equations.
Equations that describe the spatial dependence and time evolution of fields are called "field equations". These include
This terminology is not universal: for example although the Navier–Stokes equations govern the velocity field of a fluid, they are not usually called "field equations", since in this context they represent the momentum of the fluid and are called the "momentum equations" instead.
Wave equations.
Equations of wave motion are called "wave equations". The solutions to a wave equation give the time-evolution and spatial dependence of the amplitude. Boundary conditions determine if the solutions describe traveling waves or standing waves.
From classical equations of motion and field equations; mechanical, gravitational wave, and electromagnetic wave equations can be derived. The general linear wave equation in 3D is:
where is any mechanical or electromagnetic field amplitude, say:
and is the phase velocity. Nonlinear equations model the dependence of phase velocity on amplitude, replacing by . There are other linear and nonlinear wave equations for very specific applications, see for example the Korteweg–de Vries equation.
Quantum theory.
In quantum theory, the wave and field concepts both appear.
In quantum mechanics, in which particles also have wave-like properties according to wave–particle duality, the analogue of the classical equations of motion (Newton's law, Euler–Lagrange equation, Hamilton–Jacobi equation, etc.) is the Schrödinger equation in its most general form:
where is the wavefunction of the system, is the quantum Hamiltonian operator, rather than a function as in classical mechanics, and is the Planck constant divided by 2. Setting up the Hamiltonian and inserting it into the equation results in a wave equation, the solution is the wavefunction as a function of space and time. The Schrödinger equation itself reduces to the Hamilton–Jacobi equation in when one considers the correspondence principle, in the limit that becomes zero.
Throughout all aspects of quantum theory, relativistic or non-relativistic, there are various formulations alternative to the Schrödinger equation that govern the time evolution and behavior of a quantum system, for instance: 

</doc>
<doc id="65914" url="https://en.wikipedia.org/wiki?curid=65914" title="Kinematics">
Kinematics

Kinematics is the branch of classical mechanics which describes the motion of points (alternatively "particles"), bodies (objects), and systems of bodies without consideration of the masses of those objects nor the forces that may have caused the motion. Kinematics as a field of study is often referred to as the "geometry of motion" and as such may be seen as a branch of mathematics. Kinematics begins with a description of the geometry of the system and the initial conditions of known values of the position, velocity and or acceleration of various points that are a part of the system, then from geometrical arguments it can determine the position, the velocity and the acceleration of any part of the system. The study of the influence of forces acting on masses falls within the purview of kinetics. For further details, see analytical dynamics.
Kinematics is used in astrophysics to describe the motion of celestial bodies and collections of such bodies. In mechanical engineering, robotics, and biomechanics kinematics is used to describe the motion of systems composed of joined parts (multi-link systems) such as an engine, a robotic arm or the skeleton of the human body.
The use of geometric transformations, also called rigid transformations, to describe the movement of components of a mechanical system simplifies the derivation of its equations of motion, and is central to dynamic analysis.
Kinematic analysis is the process of measuring the kinematic quantities used to describe motion. In engineering, for instance, kinematic analysis may be used to find the range of movement for a given mechanism, and working in reverse, using kinematic synthesis used to design a mechanism for a desired range of motion. In addition, kinematics applies algebraic geometry to the study of the mechanical advantage of a mechanical system or mechanism.
Etymology of the term.
The term kinematic is the English version of A.M. Ampère's "cinématique", which he constructed from the Greek "kinema" ("movement, motion"), itself derived from "kinein" ("to move").
Kinematic and cinématique are related to the French word cinéma, but neither are directly derived from it. However, they do share a root word in common, as cinéma came from the shortened form of cinématographe, "motion picture projector and camera," once again from the Greek word for movement but also the Greek word for writing.
Kinematics of a particle trajectory in a non-rotating frame of reference.
Particle kinematics is the study of the trajectory of a particle. The position of a particle is defined to be the coordinate vector from the origin of a coordinate frame to the particle. For example, consider a tower 50 m south from your home, where the coordinate frame is located at your home, such that East is the x-direction and North is the y-direction, then the coordinate vector to the base of the tower is r=(0, -50, 0). If the tower is 50 m high, then the coordinate vector to the top of the tower is r=(0, -50, 50)'".
In the most general case, a three-dimensional coordinate system is used to define the position of a particle. However, if the particle is constrained to move in a surface, a two-dimensional coordinate system is sufficient. All observations in physics are incomplete without those observations being described with respect to a reference frame.
The position vector of a particle is a vector drawn from the origin of the reference frame to the particle. It expresses both the distance of the point from the origin and its direction from the origin. In three dimensions, the position of point "P" can be expressed as
where "xP", "yP", and "zP" are the Cartesian coordinates and "i", "j" and "k" are the unit vectors along the "x", "y", and "z" coordinate axes, respectively. The magnitude of the position vector |P| gives the distance between the point "P" and the origin.
The direction cosines of the position vector provide a quantitative measure of direction.
It is important to note that the position vector of a particle isn't unique. The position vector of a given particle is different relative to different frames of reference.
The "trajectory" of a particle is a vector function of time, P(t), which defines the curve traced by the moving particle, given by
where the coordinates "x"P, "y"P, and "z"P are each functions of time.
Velocity and speed.
The velocity of a particle is a vector quantity that describes the direction of motion and the magnitude of the motion of particle. More mathematically, the rate of change of the position vector of a point, with respect to time is the velocity of the point. Consider the ratio of the difference of two positions of a particle divided by the time interval, which is called the average velocity over that time interval. This average velocity is defined as
where ΔP is the change in the position vector over the time interval Δ"t".
In the limit as the time interval Δ"t" becomes smaller and smaller, the average velocity becomes the time derivative of the position vector,
Thus, velocity is the time rate of change of position of a point, and the dot denotes the derivative of those functions x, y, and z with respect to time. Furthermore, the velocity is tangent to the trajectory of the particle at every position the particle occupies along its path. Note that in a non-rotating frame of reference, the derivatives of the coordinate directions are not considered as their directions and magnitudes are constants.
The speed of an object is the magnitude |V| of its velocity. It is a scalar quantity:
where "s" is the arc-length measured along the trajectory of the particle. This arc-length traveled by a particle over time is a non-decreasing quantity. Hence, "ds"/"dt" is non-negative, which implies that speed is also non-negative.
Acceleration.
The velocity vector can change in magnitude and in direction or both at once. Hence, the acceleration is the rate of change of the magnitude of the velocity vector plus the rate of change of direction of that vector. The same reasoning used with respect to the position of a particle to define velocity, can be applied to the velocity to define acceleration. The acceleration of a particle is the vector defined by the rate of change of the velocity vector. The average acceleration of a particle over a time interval is defined as the ratio.
where ΔV is the difference in the velocity vector and Δ"t" is the time interval.
The acceleration of the particle is the limit of the average acceleration as the time interval approaches zero, which is the time derivative,
or
Thus, acceleration is the first derivative of the velocity vector and the second derivative of the position vector of that particle. Note that in a non-rotating frame of reference, the derivatives of the coordinate directions are not considered as their directions and magnitudes are constants.
The magnitude of the acceleration of an object is the magnitude |A| of its acceleration vector. It is a scalar quantity:
Relative position vector.
A relative position vector is a vector that defines the position of one point relative to another. It is the difference in position of the two points.
The position of one point "A" relative to another point "B" is simply the difference between their positions
formula_11
which is the difference between the components of their position vectors.
If point "A" has position components 
formula_12
If point "B" has position components 
formula_13
then the position of point "A" relative to point "B" is the difference between their components: 
formula_14
Relative velocity.
The velocity of one point relative to another is simply the difference between their velocities
formula_15
which is the difference between the components of their velocities.
If point "A" has velocity components 
formula_16
and point "B" has velocity components 
formula_17
then the velocity of point "A" relative to point "B" is the difference between their components: 
formula_18
Alternatively, this same result could be obtained by computing the time derivative of the relative position vector RB/A.
In the case where the velocity is close to the speed of light "c" (generally within 95%), another scheme of relative velocity called rapidity, that depends on the ratio of V to c, is used in special relativity.
Relative acceleration.
The acceleration of one point "C" relative to another point "B" is simply the difference between their accelerations.
formula_19
which is the difference between the components of their accelerations.
If point "C" has acceleration components 
formula_20
and point "B" has acceleration components 
formula_21
then the acceleration of point "C" relative to point "B" is the difference between their components: 
formula_22
Alternatively, this same result could be obtained by computing the second time derivative of the relative position vector PB/A.
Particle trajectories under constant acceleration.
For the case of constant acceleration, the differential equation Eq 1) can be integrated as the acceleration vector A of a point "P" is constant in magnitude and direction. Such a point is said to be undergoing "uniformly accelerated motion". In this case, the velocity V(t) and then the trajectory P(t) of the particle can be obtained by integrating the acceleration equation A with respect to time.
Assuming that the initial conditions of the position, formula_23, and velocity formula_24 are known, the first integration yields the velocity of the particle as a function of time.
A second integration yields its path (trajectory),
Additional relations between displacement, velocity, acceleration, and time can be derived. Since the acceleration is constant, 
A relationship between velocity, position and acceleration without explicit time dependence can be had by solving the average acceleration for time and substituting and simplifying
where ∘ denotes the dot product, which is appropriate as the products are scalars rather than vectors. 
The dot can be replaced by the cosine of the angle ∝ between the vectors and the vectors by their magnitudes, in which case:
In the case of acceleration always in the direction of the motion ∝ = 0, cosine(0) = 1 and, 
This can be simplified using the notation for the magnitudes of the vectors formula_34 where formula_35 can be any curvaceous path taken as the constant tangential acceleration is applied along that path, so
This reduces the parametric equations of motion of the particle to a cartesian relationship of speed versus position. This relation is useful when time is not known explicitly.
Particle trajectories in cylindrical-polar coordinates.
It is often convenient to formulate the trajectory of a particle P(t) = (X(t), Y(t) and Z(t)) using polar coordinates in the "X"-"Y" plane. In this case, its velocity and acceleration take a convenient form.
Recall that the trajectory of a particle "P" is defined by its coordinate vector P measured in a fixed reference frame "F". As the particle moves, its coordinate vector P(t) traces its trajectory, which is a curve in space, given by:
where "i", "j", and "k" are the unit vectors along the "X", "Y" and "Z" axes of the reference frame "F", respectively.
Consider a particle "P" that moves only on the surface of a circular cylinder R(t)=constant, it is possible to align the "Z" axis of the fixed frame "F" with the axis of the cylinder. Then, the angle θ around this axis in the "X-Y" plane can be used to define the trajectory as,
The cylindrical coordinates for P(t) can be simplified by introducing the radial and tangential unit vectors,
and their time derivatives from elementary calculus:
Using this notation, P(t) takes the form,
where "R" is constant in the case of the particle moving only on the surface of a cylinder of radius "R".
In general, the trajectory P(t) is not constrained to lie on a circular cylinder, so the radius "R" varies with time and the trajectory of the particle in cylindrical-polar coordinates becomes:
Where R, theta, and Z might be continuously differentiable functions of time and the function notation is dropped for simplicity. The velocity vector VP is the time derivative of the trajectory P(t), which yields:
Similarly, the acceleration AP, which is the time derivative of the velocity VP, is given by:
The term formula_48 acts toward the center of curvature of the path at that point on the path, is commonly called the centripetal acceleration. The term formula_49 is called the Coriolis acceleration.
Constant radius.
If the trajectory of the particle is constrained to lie on a cylinder, then the radius "R" is constant and the velocity and acceleration vectors simplify. The velocity of VP is the time derivative of the trajectory P(t),
The acceleration vector becomes:
Planar circular trajectories.
A special case of a particle trajectory on a circular cylinder occurs when there is no movement along the "Z" axis:
where "R" and "Z"0 are constants. In this case, the velocity VP is given by:
where
is the angular velocity of the unit vector et around the "z" axis of the cylinder.
The acceleration AP of the particle "P" is now given by:
The components
are called, respectively, the "radial" and "tangential components" of acceleration.
The notation for angular velocity and angular acceleration is often defined as
so the radial and tangential acceleration components for circular trajectories are also written as
Point trajectories in a body moving in the plane.
The movement of components of a mechanical system are analyzed by attaching a reference frame to each part and determining how the various reference frames move relative to each other. If the structural stiffness of the parts are sufficient, then their deformation can be neglected and rigid transformations can be used to define this relative movement. This reduces the description of the motion of the various parts of a complicated mechanical system to a problem of describing the geometry of each part and geometric association of each part relative to other parts.
Geometry is the study of the properties of figures that remain the same while the space is transformed in various ways---more technically, it is the study of invariants under a set of transformations. These transformations can cause the displacement of the triangle in the plane, while leaving the vertex angle and the distances between vertices unchanged. Kinematics is often described as applied geometry, where the movement of a mechanical system is described using the rigid transformations of Euclidean geometry.
The coordinates of points in a plane are two-dimensional vectors in R2 (two dimensional space). Rigid transformations are those that preserve the distance between any two points. The set of rigid transformations in an "n"-dimensional space is called the special Euclidean group on Rn, and denoted "SE(n)."
Displacements and motion.
The position of one component of a mechanical system relative to another is defined by introducing a reference frame, say "M", on one that moves relative to a fixed frame, "F," on the other. The rigid transformation, or displacement, of "M" relative to "F" defines the relative position of the two components. A displacement consists of the combination of a rotation and a translation.
The set of all displacements of "M" relative to "F" is called the configuration space of "M." A smooth curve from one position to another in this configuration space is a continuous set of displacements, called the motion of "M" relative to "F." The motion of a body consists of a continuous set of rotations and translations.
Matrix representation.
The combination of a rotation and translation in the plane R2 can be represented by a certain type of 3x3 matrix known as a homogeneous transform. The 3x3 homogeneous transform is constructed from a 2x2 rotation matrix A(φ) and the 2x1 translation vector d=(dx, dy), as:
These homogeneous transforms perform rigid transformations on the points in the plane z=1, that is on points with coordinates p=(x, y, 1).
In particular, let p define the coordinates of points in a reference frame "M" coincident with a fixed frame "F." Then, when the origin of "M" is displaced by the translation vector d relative to the origin of "F" and rotated by the angle φ relative to the x-axis of "F," the new coordinates in "F" of points in "M" are given by:
Homogeneous transforms represent affine transformations. This formulation is necessary because a translation is not a linear transformation of R2. However, using projective geometry, so that R2 is considered to be a subset of R3, translations become affine linear transformations.
Pure translation.
If a rigid body moves so that its reference frame "M" does not rotate (∅=0) relative to the fixed frame "F", the motion is said to be pure translation. In this case, the trajectory of every point in the body is an offset of the trajectory d(t) of the origin of "M," that is:
Thus, for bodies in pure translation, the velocity and acceleration of every point "P" in the body are given by:
where the dot denotes the derivative with respect to time and VO and AO are the velocity and acceleration, respectively, of the origin of the moving frame "M". Recall the coordinate vector p in "M" is constant, so its derivative is zero.
Rotation of a body around a fixed axis.
Rotational or angular kinematics is the description of the rotation of an object. The description of rotation requires some method for describing orientation. Common descriptions include Euler angles and the kinematics of turns induced by algebraic products.
In what follows, attention is restricted to simple rotation about an axis of fixed orientation. The "z"-axis has been chosen for convenience.
The description of rotation then involves these three quantities:
The equations of translational kinematics can easily be extended to planar rotational kinematics for constant angular acceleration with simple variable exchanges:
Here "θ"i and "θ"f are, respectively, the initial and final angular positions, "ω"i and "ω"f are, respectively, the initial and final angular velocities, and "α" is the constant angular acceleration. Although position in space and velocity in space are both true vectors (in terms of their properties under rotation), as is angular velocity, angle itself is not a true vector.
Point trajectories in body moving in three dimensions.
Important formulas in kinematics define the velocity and acceleration of points in a moving body as they trace trajectories in three-dimensional space. This is particularly important for the center of mass of a body, which is used to derive equations of motion using either Newton's second law or Lagrange's equations.
Position.
In order to define these formulas, the movement of a component "B" of a mechanical system is defined by the set of rotations and translations d(t) assembled into the homogeneous transformation [T(t)=d(t). If p is the coordinates of a point "P" in "B" measured in the moving reference frame "M", then the trajectory of this point traced in "F" is given by:
This notation does not distinguish between P = (X, Y, Z, 1), and P = (X, Y, Z), which is hopefully clear in context.
This equation for the trajectory of "P" can be inverted to compute the coordinate vector p in "M" as:
This expression uses the fact that the transpose of a rotation matrix is also its inverse, that is:
Velocity.
The velocity of the point "P" along its trajectory P(t) is obtained as the time derivative of this position vector,
The dot denotes the derivative with respect to time; because p is constant, its derivative is zero.
This formula can be modified to obtain the velocity of "P" by operating on its trajectory P(t) measured in the fixed frame "F". Substituting the inverse transform for p into the velocity equation yields:
The matrix is given by:
where
is the angular velocity matrix.
Multiplying by the operator , the formula for the velocity VP takes the form:
where the vector ω is the angular velocity vector obtained from the components of the matrix [Ω]; the vector
is the position of "P" relative to the origin "O" of the moving frame "M"; and 
is the velocity of the origin "O".
Acceleration.
The acceleration of a point "P" in a moving body "B" is obtained as the time derivative of its velocity vector:
This equation can be expanded firstly by computing
and
The formula for the acceleration AP can now be obtained as:
or
where α is the angular acceleration vector obtained from the derivative of the angular velocity matrix;
is the relative position vector (the position of "P" relative to the origin "O" of the moving frame "M"); and 
is the acceleration of the origin of the moving frame "M".
Kinematic constraints.
Kinematic constraints are constraints on the movement of components of a mechanical system. Kinematic constraints can be considered to have two basic forms, (i) constraints that arise from hinges, sliders and cam joints that define the construction of the system, called holonomic constraints, and (ii) constraints imposed on the velocity of the system such as the knife-edge constraint of ice-skates on a flat plane, or rolling without slipping of a disc or sphere in contact with a plane, which are called non-holonomic constraints. The following are some common examples.
Kinematic coupling.
A kinematic coupling exactly constrains all 6 degrees of freedom.
Rolling without slipping.
An object that rolls against a surface without slipping obeys the condition that the velocity of its center of mass is equal to the cross product of its angular velocity with a vector from the point of contact to the center of mass:
For the case of an object that does not tip or turn, this reduces to formula_97.
Inextensible cord.
This is the case where bodies are connected by an idealized cord that remains in tension and cannot change length. The constraint is that the sum of lengths of all segments of the cord is the total length, and accordingly the time derivative of this sum is zero. A dynamic problem of this type is the pendulum. Another example is a drum turned by the pull of gravity upon a falling weight attached to the rim by the inextensible cord. An "equilibrium" problem (i.e. not kinematic) of this type is the catenary.
Kinematic pairs.
Reuleaux called the ideal connections between components that form a machine kinematic pairs. He distinguished between higher pairs which were said to have line contact between the two links and lower pairs that have area contact between the links. J. Phillips shows that there are many ways to construct pairs that do not fit this simple classification.
Lower pair.
A lower pair is an ideal joint, or holonomic constraint, that maintains contact between a point, line or plane in a moving solid (three-dimensional) body to a corresponding point line or plane in the fixed solid body. There are the following cases:
Higher pairs.
Generally speaking, a higher pair is a constraint that requires a curve or surface in the moving body to maintain contact with a curve or surface in the fixed body. For example, the contact between a cam and its follower is a higher pair called a "cam joint". Similarly, the contact between the involute curves that form the meshing teeth of two gears are cam joints.
Kinematic chains.
Rigid bodies ("links") connected by kinematic pairs ("joints") are known as "kinematic chains." Mechanisms and robots are examples of kinematic chains. The degree of freedom of a kinematic chain is computed from the number of links and the number and type of joints using the mobility formula. This formula can also be used to enumerate the topologies of kinematic chains that have a given degree of freedom, which is known as "type synthesis" in machine design.
Examples.
The planar one degree-of-freedom linkages assembled from "N" links and "j" hinged or sliding joints are:
For larger chains and their linkage topologies, see R. P. Sunkari and L. C. Schmidt, "Structural synthesis of planar kinematic chains by adapting a Mckay-type algorithm", "Mechanism and Machine Theory" #41, pp. 1021–1030 (2006).

</doc>
<doc id="65918" url="https://en.wikipedia.org/wiki?curid=65918" title="List of newspaper comic strips">
List of newspaper comic strips

The following is a list of comic strips. Dates after names indicate the time frames when the strips appeared. There is usually a fair degree of accuracy about a start date, but because of rights being transferred or the very gradual loss of appeal of a particular strip, the termination date is sometimes uncertain. In the event a strip has its own page, the originator of the strip is listed. Otherwise, all creators who worked on a strip are listed. Note that many of characters appeared in both strip and comic book format as well as in other media.
The word Reuben after a name identifies winners of the National Cartoonists Society's Reuben Award for Outstanding Cartoonist of the Year, but many of leading strip artists worked in the years before the first Reuben and Billy DeBeck Awards in 1946.
Webcomics are comic strips that exist only on the World Wide Web and are not created primarily for newspapers or magazines. Primary sites for webcomics are Modern Tales, Serializer and KeenSpot.
Lists of comic strips.
The following lists include only newspaper comic strips:

</doc>
<doc id="65919" url="https://en.wikipedia.org/wiki?curid=65919" title="Point-to-point construction">
Point-to-point construction

Point-to-point construction refers to a non-automated method of construction of electronics circuits widely used before the use of printed circuit boards (PCBs) and automated assembly gradually became widespread following their introduction in the 1950s. Circuits using thermionic valves (vacuum tubes) were relatively large, relatively simple (the number of large, hot, expensive devices which needed replacing was minimised), and used large sockets, all of which made the PCB less obviously advantageous than with later complex semiconductor circuits. Point-to-point construction is still used to construct prototype equipment with few or heavy electronic components.
Before point-to-point connection, electrical assemblies used screws or wire nuts to hold wires to an insulating wooden or ceramic board. The resulting devices were prone to fail from corroded contacts, or mechanical loosening of the connections. Early premium marine radios, especially from Marconi, sometimes used welded copper in the bus-bar circuits, but this was expensive.
Point-to-point wiring is not suitable for automation and is carried out manually, making it both more expensive and more susceptible to wiring errors than PCBs, as connections are determined by the person doing assembly rather than by an etched circuit board. For production, rather than prototyping, errors can be minimised by carefully designed operating procedures.
Point-to-point construction uses terminal strips (sometimes called "tag boards") or turret boards. 
The crucial invention was to apply soldering to electrical assembly. In soldering, an alloy of tin and lead, or later bismuth and tin, is melted and adheres to other, nonmolten metals, such as copper or tinned steel. Solder makes a strong electrical and mechanical connection. Note that if components are arranged on boards with tags or turrets at both ends and wires going to the next components, then the construction is tag or turret construction respectively, as the components are not going from point to point.
Terminal strip construction.
Point-to-point construction uses terminal strips (also called "tag boards"). A terminal strip has stamped tin-plated copper terminals, each with a hole through which wire ends could be pushed, fitted on an insulating strip, usually made of a cheap, heat-resistant material such as synthetic-resin bonded paper (FR-2), or bakelite reinforced with cotton. The insulator has an integral mounting bracket, sometimes electrically connected to one or more of the stamped loops to ground them to the chassis.
The chassis was constructed first, from sheet metal or wood. Insulated terminal strips were then riveted, nailed or screwed to the underside or interior of the chassis. Transformers, large capacitors, tube sockets and other large components were mounted to the top of the chassis. Their wires were led through holes to the underside or interior. The ends of lengths of wire or wire-ended components such as capacitors and resistors were pushed through the terminals, and usually looped and twisted. When all wires to be connected had been fitted to the terminal, they were soldered together (and to the terminal).
Professional electronics assemblers used to operate from books of photographs and follow an exact assembly sequence to ensure that they did not miss any components. This process is labor-intensive, subject to error and not suitable for automated production. Even after the introduction of printed circuit boards, it did not require laying out and manufacturing circuit boards.
Point-to-point construction continued to be used for some vacuum tube equipment even after the introduction of printed circuit boards. The heat of the tubes can degrade the circuit boards and cause them to become brittle and break. Circuit board degradation is often seen on inexpensive tube radios produced in the 1960s, especially around the hot output and rectifier tubes. American manufacturer Zenith continued to use point-to-point wiring in its tube-based television sets until the early 1970s.
Some audiophile equipment, such as amplifiers, continues to be point-to-point wired using terminal pins, often in very small quantities. Point-to-point wiring is used as a design feature, not due to the economics of very-small-scale production.
Sometimes point-to-point wiring—without terminal strips—with very short connections, is used at very high radio frequencies (in the gigahertz range) to minimise stray capacitance and inductance; the capacitance between a circuit-board trace and some other conductor, and the inductance of a short track, become significant or dominant at high frequencies. In some cases careful PCB layout on a substrate with good high-frequency properties (e.g., ceramic) is sufficient. An example of this design is illustrated in an application note describing an avalanche transistor-based generator of pulses with risetime of a fraction of a nanosecond; the (few) critical components are connected directly to each other and to the output connector with the shortest possible leads.
Particularly in complex equipment, point-to-point wired circuits are often laid out as a "ladder" of side-by-side components, which need connecting to ladders or components by wire links. A good layout minimizes such links and wiring complexity. Amongst complex devices, the pre-PCB Tektronix vacuum-tube oscilloscopes stand out for their very well-designed point-to-point wiring.
If parasitic effects are significant, point-to-point wiring has the disadvantage compared to a PCB of indeterminate parasitic components; while the inductance and capacitance due to a PCB are the same for all samples, values may vary between point-to-point wired units, changing circuit operation.
Placing the completed unit in an enclosure protects the circuit from its environment, and users from electrical hazards.
A few large brand names still use point-to-point boards, but usually for special product lines. Electric guitar amplifier manufacturer Marshall have reissued some of their older models, using point-to-point construction as a design feature, although their standard products have long used PCBs. Thermionic valve equipment usually do not have the valves mounted on the PCB, to avoid heat damage, but use PCBs for the wiring, achieving the economy of mass-produced PCBs without the heat damage.
Breadboard.
Prototypes which are subject to modification are often not made on PCBs, using instead breadboard construction. Historically this could be literally a breadboard, a wooden board with components attached to it and joined up with wire. More recently the term is applied to a board of thin insulating material with holes at standard 0.1-inch pitch; components are pushed through the holes to anchor them, and point-to-point wired on the other side of the board. Some prototyping "breadboards" have this layout, but with metal socket strips into which components are pushed; all the terminals in a straight line in one direction are electrically connected. Such breadboards, and stripboards, fall somewhere between PCBs and point-to-point; they do not require design and manufacture of a PCB, and are as easily modified as a point-to-point setup.
Stripboard.
A stripboard is a board with holes in a 0.1-inch pitch; all the holes in a straight line are connected by a copper strip as on a PCB. Components are pushed through from the side without strips and soldered in place. The strips can be interrupted by rotating a tool like a drill bit at a perforation.
"Dead bug" construction.
Free-form construction can be used in cases where a PCB would be too big or too much work for a small number of components. Several methods of construction are used. At one extreme a wiring pen can be used with a perforated board, producing neat and professional results. At the other extreme is "dead bug" style, with the ICs flipped upside-down with their pins sticking up into the air like a dead insect. While it is messy-looking, free-form construction can be used to make more compact circuits than other methods. This is often used in BEAM robotics and in RF circuits where component leads must be kept short. This form of construction is used by amateurs for one-off circuits, and also professionally for circuit development, particularly at high frequencies.
For high-frequency work a grounded solderable metallic base such as the copper side of an unetched printed circuit board can be used as base and ground plane. Information on high-frequency breadboarding and illustrations of dead bug with ground plane construction are in a Linear Technologies application note.

</doc>
<doc id="65922" url="https://en.wikipedia.org/wiki?curid=65922" title="Treaty of Shimonoseki">
Treaty of Shimonoseki

The () was an unequal treaty signed at the Shunpanrō hall in Japan on April 17, 1895, between the Empire of Japan and the Qing Empire, ending the First Sino-Japanese War. The peace conference took place from March 20 to April 17, 1895. This treaty followed and superseded the Sino-Japanese Friendship and Trade Treaty of 1871.
Treaty terms.
The treaty ended the First Sino-Japanese War of 1894–1895 as a clear victory for Japan. In this treaty, China recognized the independence of Korea and renounced any claims to that country. It also ceded the Liaodong Peninsula (then known to the Western press as "Liaotung", now southern part of modern Liaoning province), and the islands of Formosa (Taiwan) and Penghu (also known as the Pescadores) to Japan. China also paid Japan a war indemnity of 200 million Kuping taels, payable over seven years, and the signing of a commercial treaty similar to ones previously signed by China with various western powers in the aftermath of the First and Second Opium Wars. This commercial treaty confirmed the opening of various ports and rivers to Japanese trade. As a result of the Treaty of Shimonoseki (1895), China recognized the "full and complete independence and autonomy" of Joseon. In the next year Yeongeunmun was demolished leaving its two stone pillars.
Value of the indemnity.
Qing China's indemnity to Japan of 200 million silver kuping taels, or about . After the Triple intervention, they paid another 30 million taels for a total of over silver, worth about $5 billion US Dollars in 2015.
The Treaty of Shimonoseki and Taiwan.
During the summit between Japanese and Qing representatives in March and April 1895, Prime Minister Hirobumi Ito and Foreign Minister Munemitsu Mutsu were serious about reducing the power of Qing Dynasty on not only Korean Peninsula but also Taiwan islands. Moreover, Mutsu had already noticed its importance in order to expand Japanese military power towards South China and Southeast Asia. It was also time of imperialism so that Japan wished to follow what the West was doing. Imperial Japan was seeking for enough colonies and resources in Korean Peninsula and Mainland China to compete with Western powers at that time, and this was the only way to prove how fast Imperial Japan since Meiji Restoration in 1867 had run after the West and how serious it was about amending unequal treaties among Western powers.
At the peace conference between Imperial Japan and Qing Dynasty, Li Hongzhang and Li Jingfang, the ambassadors at the negotiation desk of Qing Dynasty, originally did not plan to cede Taiwan because they also realised Taiwan’s great location for trading with the West. Therefore, even though the Qing had lost wars against Britain and France in the 19th century, the Qing Emperor was serious to keep Taiwan under its rule, which begin in 1683. On 20 March 1895, at Sunpanro (春帆楼) in Shimonoseki in Japan, 1-month-long peace conference had started.
At the first half of the conference, Ito and Li talked mainly about a cease-fire agreement, and during the second half of the conference, the contents of the peace treaty were discussed. Ito and Mutsu claimed that yielding the full sovereignty of Taiwan was an absolute condition and requested Li to hand over full sovereignty of Penghu Islands and the eastern portion of the bay of Liaodong Peninsula. Li Hongzhang refused on the grounds that Taiwan had never been a battlefield during the first Sino-Japanese War between 1894 and 1895. By the final stage of the conference, while Li Hongzhang agreed to the transfer of full sovereignty of the Penghu islands and the eastern portion of the bay of Liaodong Peninsula to Imperial Japan, he still refused to hand over Taiwan. As Taiwan had been a province since 1885, Li stated, "Taiwan is already a province, and therefore not to be given away (臺灣已立一行省，不能送給他國)."
However, Imperial Japan was too strong for the Qing Dynasty to cope with, and eventually Li gave Taiwan up. On 17 April 1895, the peace treaty between Imperial Japan and the Qing Dynasty had been signed and was followed by the successful Japanese invasion of Taiwan. This had a huge impact on Taiwan, the turning over of the island to Imperial Japan marking the end of 200 years of Qing rule despite an attempt to avoid annexation by Qing loyalists.
Signatories and diplomats.
The treaty was drafted with John W. Foster, former American Secretary of State, advising the Qing Empire. It was signed by Count Ito Hirobumi and Viscount Mutsu Munemitsu for the Emperor of Japan and Li Hongzhang and Li Jingfang on behalf of the Emperor of China. Before the treaty was signed, Li Hongzhang was attacked by a right-wing Japanese extremist on March 24: he was fired at and wounded on his way back to his lodgings at Injoji temple. The public outcry aroused by the assassination attempt caused the Japanese to temper their demands and agree to a temporary armistice. The conference was temporarily adjourned and resumed on April 10.
Aftermath.
Entry of the Western powers.
The conditions imposed by Japan on China led to the Triple Intervention of Russia, France, and Germany, western powers all active in China, with established enclaves and ports, just six days after its signing. They demanded that Japan withdraw its claim on the Liaodong peninsula, concerned that Lüshun, then called Port Arthur by Westerners, would fall under Japanese control. Tsar Nicholas II of Russia (a de jure ally of France) and his imperial advisors, including his cousin-advisor-friend-rival Kaiser Wilhelm II of Germany, had designs on Port Arthur, which could serve as Russia's long sought-after 'ice-free' port.
Under threat of war from three Western political powers, in November 1895, Japan — a weaker emerging nation not yet perceived as even a regional power — returned control of the territory and withdrew its "de jure" claim on the Liaotung peninsula in return for an increased war indemnity from China of 30 million Taels. At that time, the European powers were not concerned with any of the other conditions, or the free hand Japan had been granted in Korea under the other terms of the Treaty of Shimonoseki, and this would prove to be a diplomatically short-sighted error.
Within months after Japan re-ceded the Liaodong peninsula, Russia started construction on the peninsula and a railway to Harbin from Port Arthur, despite a protesting China. Eventually, Russia agreed to offer a diplomatic solution (See Kwantung Leased Territory) to the Chinese Empire, and agreed to a token lease of the region to save face, instead of annexing Manchuria outright, its de facto effect. Within two years, Germany, France, and Great Britain had similarly taken advantage of the economic and political opportunities in the weak Chinese Empire, each taking control of significant local regions. Japan also took note of how the international community allowed the great powers to treat weaker nation states, and continued its remarkable measures to bootstrap itself into a modern industrial state and military power, with great success as it would demonstrate in the Russo-Japanese War less than a decade later.
In Taiwan, pro-Qing officials and elements of the local gentry declared a Republic of Formosa in 1895, but failed to win international recognition.
In China, the Treaty was considered a national humiliation by the bureaucracy and greatly weakened support for the Qing dynasty. The previous decades of the Self-Strengthening Movement were considered to be a failure, and support grew for more radical changes in China's political and social systems which led to Hundred Days' Reform and the abolition of the bureaucratic examinations followed by the fall of the Qing dynasty itself in 1911.
The Triple Intervention is regarded by many Japanese historians as being a crucial historic turning point in Japanese foreign affairs – from this point on, the nationalist, expansionist, and militant elements began to join ranks and steer Japan from a foreign policy based mainly on economic hegemony toward outright imperialism — a case of "the coerced" turning increasingly "to coercion".
Both the Republic of China, now controlling Taiwan, and the People's Republic of China, now controlling mainland China consider that the provisions of the treaty transferring Taiwan to Japan to have been reversed by the Instrument of Surrender of Japan. Additionally, it is alleged that on April 28, 1952 the contents of the Treaty of Shimonoseki treaty were formally nullified through what is commonly known as the Treaty of Taipei with the Republic of China. However, argues that only those provisions of the 1895 treaty which had not yet been fulfilled in their entirety could be subject to nullification. The cession provision which had already been carried out was no longer existent and, therefore, could no longer be subjected to nullification. In support of this reasoning, Ng points to the reparations provision of Article IV of the 1895 treaty, as well as additional reparations provisions from earlier Sino-Japanese agreements & treaties. These were all regarded as "fulfilled provisions" and not subject to later nullification or cancellation. The People's Republic of China does not recognize the Treaty of Taipei.
Prelude to war.
Russia wasted little time after the Triple Intervention to move men and materials down into the Liaodong to start building a railroad from both ends — Port Arthur and Harbin, as it already had railway construction in progress across northern Inner Manchuria to shorten the rail route to Russia's sole Pacific Ocean naval base at Sakhalin Island, a port closed by ice four months of each year. Russia also improved the port facilities at Port Arthur and founded the commercial port town at Dalny (Dalian), before inking the lease of the territory.
When the de facto governance of Port Arthur and the Liaodong peninsula was granted de jure to Russia by China along with an increase in other rights she had obtained in Manchuria (especially those in Jilin and Heilongjiang provinces) the construction of the 550 mile Southern spurline of the Manchurian Railway was redoubled. Russia finally seemed to have gotten what the Russian Empire had been wanting in its quest to become a global power since the reign of Peter the Great. This ice-free natural harbor of Port Arthur/Lüshun would serve to make Russia a great sea as well as the largest land power. Russia needed this ice-free port to achieve world power status as it was tired of being blocked by the balance of power politics in Europe (The Ottoman Empire and its allies had repeatedly frustrated Russian power fruition).
However, the omission of the geopolitical reality in ignoring the free hand Japan had been granted by the Treaty (of Shimonoseki) with respect to Korea and Japan was short-sighted of Russia with respect to its strategic goals; to get to and maintain a strong point in Port Arthur Russia would have to dominate and control many additional hundreds of miles of Eastern Manchuria (the Fengtian province of Imperial China, modern Jilin and Heilongjiang) up to Harbin. Japan had long considered the lands paralleling the whole Korean border as part of its strategic Sphere of Influence. By leasing "Liaodong" and railway concessions, Russia crashed its Sphere of Influence squarely into Japan's.
This acted as a further goad to emerging Japanese anger at their disrespectful treatment by all the West. In the immediate fallout of the "Triple Intervention", Japanese popular resentment at Russia's deviousness and the perceived weakness of its own government caving in to foreign pressure led to riots in Tokyo. The disturbance almost brought down the government, as well as a strengthening of imperial and expansionist factions within Japan. The Russian spear into the sphere also brought about the ensuing struggle with Russia for dominance in Korea and Manchuria. These events eventually led to the Russo-Japanese War of 1904–1905 by a renewed and modernized Japanese military.

</doc>
<doc id="65923" url="https://en.wikipedia.org/wiki?curid=65923" title="The Surgeon of Crowthorne">
The Surgeon of Crowthorne

"The Surgeon of Crowthorne: A Tale of Murder, Madness and the Love of Words" is a book by Simon Winchester that was first published in England in 1998. It was retitled "The Professor and the Madman: A Tale of Murder, Insanity, and the Making of the Oxford English Dictionary" in the United States and Canada.
It tells the story of the making of the "Oxford English Dictionary" (OED) and one of its most prolific early contributors, Dr. W. C. Minor, a retired United States Army surgeon. Minor was, at the time, imprisoned in the Broadmoor Criminal Lunatic Asylum, near the village of Crowthorne in Berkshire, England. The 'professor' of the American title is the chief editor of the "OED" during most of the project, Sir James Murray. Murray was a talented linguist and had other scholarly interests, and he had taught in schools and worked in banking. Faced with the enormous task of producing a comprehensive dictionary, with a quotation illustrating the uses of each meaning of each word, and with evidence for the earliest use of each, Murray had turned to an early form of crowdsourcing (a word not coined until the 21st century)— enlisting the help of dozens of amateur philologists as volunteer researchers.
A journalist with three decades of experience, and the author of a dozen travel-inspired books, Winchester's initial proposal to write a book about an obscure lexicographer met with rejection. Only when Harper Collins editor Larry Ashmead read the proposal and championed the book did Winchester pursue the necessary research in earnest. Of the project Ashmead said "we can make lexicography cool". It was Ashmead that persuaded Winchester to call the US edition "The Professor and the Madman" (over Winchester's objection that Murray was not a professor), saying "No one here knows what the hell a Crowthorne is."
The book was a major success. Winchester went on to write "The Meaning of Everything: The Story of the Oxford English Dictionary" (2003) about the broader history of the "OED".
The movie rights for the book were bought by Mel Gibson's Icon Productions in 1998, but production has not begun. John Boorman wrote a script and was at one time tapped to direct, as was Luc Besson.

</doc>
<doc id="65924" url="https://en.wikipedia.org/wiki?curid=65924" title="Photoplotter">
Photoplotter

A photoplotter is an electro-mechanical-optical machine that exposes a latent image on a media, usually high-contrast monochromatic (black-and-white) photographic film, using a light source under computer control. Once the exposing step is complete, the media is processed in a film processor using a developer solution, along with fixing, washing, and drying.
Nearly any conceivable image can be formed. Photoplotters are used primarily for the production of PCBs (printed circuit boards) and IC packaging. Other application areas include chemical milling and specialized graphic arts. Photoplotting is the first step of making photolithography masks for printed circuit boards. In the PCB industry, these masks are called photoplots and are generally limited to features of 20 µm or more. Integrated circuits are made in a similar fashion utilizing "photomasks" with sub-micrometer feature sizes; photomasks are traditionally made by photoreducing photoplotter output.
The first photoplotter was introduced by the Gerber Scientific Inc. (now Ucamco, see http://www.ucamco.com) in the 1960s. Early machines used a xenon flash lamp, and projected an image mounted in a rotating "aperture wheel" onto the photosensitive surface of the film or glass plate. The imaging head assembly traversed over the surface of the media without touching it to produce "draws" and "flashes". Draws are vectors or arcs created by continuous illumination as the imaging head moves over the photosensitive surface. A flashe create single simple graphic in a location by shining light through an aperture of the appropriate shape at a fixed location.
Modern photoplotters are generally raster-scan devices that use a laser beam focused to one or more spots, and modulated at multi-megahertz rates, to form the image. Initially, green argon-ion lasers and blue helium-cadmium lasers were frequently used. Current models utilize a red helium-neon laser, red laser diodes or even red LEDs (light-emitting diodes).
Photoplotters are closely related to imagesetters. Photoplotters differ from their imagesetting counterparts in the type of controller used to produce the image, and in the resolution and absolute accuracy of the image, with photoplotters meeting much more stringent specifications than imagesetters.
The most recent development related to photoplotting is LDI (Laser Direct Imaging) which utilizes a high-power laser or Xenon lamp to directly expose photoresist on a coated substrate instead of exposing photographic film. This eliminates the handling of photographic film. LDI machines currently sell for prices in the one-half million U.S. dollar range.
The input of photoplotters is a vector graphics file, typically in Gerber Format. Some photoplotters also accept bitmap formats such as TIFF.

</doc>
<doc id="65926" url="https://en.wikipedia.org/wiki?curid=65926" title="Angular displacement">
Angular displacement

Angular displacement of a body is the angle in radians (degrees, revolutions) through which a point or line has been rotated in a specified sense about a specified axis. When an object rotates about its axis, the motion cannot simply be analyzed as a particle, since in circular motion it undergoes a changing velocity and acceleration at any time ("t"). When dealing with the rotation of an object, it becomes simpler to consider the body itself rigid. A body is generally considered rigid when the separations between all the particles remains constant throughout the objects motion, so for example parts of its mass are not flying off. In a realistic sense, all things can be deformable, however this impact is minimal and negligible. Thus the rotation of a rigid body over a fixed axis is referred to as rotational motion. 
Example.
In the example illustrated to the right (or above in some mobile versions) , a particle on object P at a fixed distance "r" from the origin, "O", rotating counterclockwise. It becomes important to then represent the position of particle P in terms of its polar coordinates ("r", "θ"). In this particular example, the value of "θ" is changing, while the value of the radius remains the same. (In rectangular coordinates ("x", "y") both "x" and "y" vary with time). As the particle moves along the circle, it travels an arc length "s", which becomes related to the angular position through the relationship: 
Measurements of angular displacement.
Angular displacement may be measured in radians or degrees. If using radians, it provides a very simple relationship between distance traveled around the circle and the distance "r" from the centre. 
For example if an object rotates 360 degrees around a circle of radius "r", the angular displacement is given by the distance traveled around the circumference - which is 2π"r"
divided by the radius: formula_3 which easily simplifies to formula_4. Therefore 1 revolution is formula_5 radians.
When object travels from point P to point Q, as it does in the illustration to the left, over formula_6 the radius of the circle goes around a change in angle. formula_7 which equals the Angular Displacement.
Three dimensions.
In three dimensions, angular displacement is an entity with a direction and a magnitude. The direction specifies the axis of rotation, which always exists by virtue of the Euler's rotation theorem; the magnitude specifies the rotation in radians about that axis (using the right-hand rule to determine direction).
Despite having direction and magnitude, angular displacement is not a vector because it does not obey the commutative law for addition.
Matrix notation.
Given that any frame in the space can be described by a rotation matrix, the displacement among them can also be described by a rotation matrix. Being formula_8 and formula_9 two matrices, the angular displacement matrix between them can be obtained as formula_10

</doc>
<doc id="65927" url="https://en.wikipedia.org/wiki?curid=65927" title="Angular velocity">
Angular velocity

In physics, the angular velocity is defined as the rate of change of angular displacement and is a vector quantity (more precisely, a pseudovector) which specifies the angular speed (rotational speed) of an object and the axis about which the object is rotating. This speed can be measured in the SI unit of angular velocity, radians per second, or in terms of degrees per second, degrees per hour, etc. Angular velocity is usually represented by the symbol omega (ω, rarely Ω).
The direction of the angular velocity vector is perpendicular to the plane of rotation, in a direction which is usually specified by the right-hand rule.
Angular velocity of a particle.
Particle in two dimensions.
The angular velocity of a particle is measured around or relative to a point, called the origin. As shown in the diagram (with angles "ɸ" and "θ" in radians), if a line is drawn from the origin (O) to the particle (P), then the velocity (v) of the particle has a component along the radius (radial component, v‖) and a component perpendicular to the radius (cross-radial component, v⊥). If there is no radial component, then the particle moves in a circle. On the other hand, if there is no cross-radial component, then the particle moves along a straight line from the origin.
A radial motion produces no change in the direction of the particle relative to the origin, so for purposes of finding the angular velocity the radial component can be ignored. Therefore, the rotation is completely produced by the perpendicular motion around the origin, and the angular velocity is completely determined by this component.
In two dimensions the angular velocity "ω" is given by
This is related to the cross-radial (tangential) velocity by:
An explicit formula for v⊥ in terms of v and "θ" is:
Combining the above equations gives a formula for "ω":
which, by the definition of the cross product, can be written:
Addition of angular velocity vectors.
If a point rotates with formula_6 in a frame formula_7 which rotates itself with angular speed formula_8 with respect to an external frame formula_9, we can define the addition of formula_10 as the angular velocity vector of the point with respect to formula_9.
With this operation defined like this, angular velocity, which is a pseudovector, becomes also a real vector because it has two operations:
This is the definition of a vector space. The only property that presents difficulties to prove is the commutativity of the addition. This can be proven from the fact that the velocity tensor W (see below) is skew-symmetric. Therefore, formula_12 is a rotation matrix and in a time dt is an infinitesimal rotation matrix. Therefore, it can be expanded as formula_13
The composition of rotations is not commutative, but when they are infinitesimal rotations the first order approximation of the previous series can be taken and formula_14 and therefore formula_15
Rotating frames.
Given a rotating frame composed by three unitary vectors, all the three must have the same angular speed in any instant. In such a frame each vector is a particular case of the previous case (moving particle), in which the module of the vector is constant.
Though it just a particular case of a moving particle, this is a very important one for its relationship with the rigid body study, and special tools have been developed for this case. There are two possible ways to describe the angular velocity of a rotating frame: the angular velocity vector and the angular velocity tensor. Both entities are related and they can be calculated from each other.
Angular velocity vector for a frame.
It is defined as the angular velocity of each of the vectors of the frame, in a consistent way with the general definition.
It is known by the Euler's rotation theorem that for a rotating frame there exists an instantaneous axis of rotation in any instant. In the case of a frame, the angular velocity vector is over the instantaneous axis of rotation.
Any transversal section of a plane perpendicular to this axis has to behave as a two dimensional rotation. Thus, the magnitude of the angular velocity vector at a given time "t" is consistent with the two dimensions case.
Angular velocity is a vector defining an addition operation. Components can be calculated from the derivatives of the parameters defining the moving frame (Euler angles or rotation matrices)
Addition of angular velocity vectors in frames.
As in the general case, the addition operation for angular velocity vectors can be defined using movement composition. In the case of rotating frames, the movement composition is simpler than the general case because the final matrix is always a product of rotation matrices.
As in the general case, addition is commutative formula_15
Components from the vectors of the frame.
Substituting in the expression
any vector e of the frame we obtain formula_18, and therefore formula_19
As the columns of the matrix of the frame are the components of its vectors, this allows also to calculate formula_20 from the matrix of the frame and its derivative.
Components from Euler angles.
The components of the angular velocity pseudovector were first calculated by Leonhard Euler using his Euler angles and an intermediate frame made out of the intermediate frames of the construction:
Euler proved that the projections of the angular velocity pseudovector over these three axes was the derivative of its associated angle (which is equivalent to decompose the instant rotation in three instantaneous Euler rotations). Therefore:
This basis is not orthonormal and it is difficult to use, but now the velocity vector can be changed to the fixed frame or to the moving frame with just a change of bases. For example, changing to the mobile frame:
where formula_23 are unit vectors for the frame fixed in the moving body. This example has been made using the Z-X-Z convention for Euler angles.
Components from infinitesimal rotation matrices.
The components of the angular velocity vector can be calculated from infinitesimal rotations (if available) as follows:
Angular velocity tensor.
It can be introduced from rotation matrices. Any vector formula_24 that rotates around an axis with an angular speed vector formula_25 (as defined before) satisfies:
We can introduce here the angular velocity tensor associated to the angular speed formula_20:
This tensor W(t) will act as if it were a formula_29 operator :
Given the orientation matrix A(t) of a frame, we can obtain its instant angular velocity tensor W as follows. We know that:
As angular speed must be the same for the three vectors of a rotating frame, if we have a matrix A(t) whose columns are the vectors of the frame, we can write for the three vectors as a whole:
And therefore the angular velocity tensor we are looking for is:
Properties of angular velocity tensors.
In general, the angular velocity in an n-dimensional space is the time derivative of the angular displacement tensor which is a second rank skew-symmetric tensor.
This tensor W will have n(n-1)/2 independent components and this number is the dimension of the Lie algebra of the Lie group of rotations of an "n"-dimensional inner product space.
Exponential of W.
In three dimensions angular velocity can be represented by a pseudovector because second rank tensors are dual to pseudovectors in three dimensions.
As formula_34. This can be read as a differential equation that defines A(t) knowing W(t).
And if the angular speed is constant then is also constant and the equation can be integrated. The result is:
which shows a connection with the Lie group of rotations.
W is skew-symmetric.
It is possible to prove that angular velocity tensor are skew symmetric matrices which means that a formula_37 satisfies formula_38.
To prove it we start taking the time derivative of formula_39 being R(t) a rotation matrix:
Applying the formula (AB)T = BTAT:
Thus, "W" is the negative of its transpose, which implies it is a skew symmetric matrix.
Duality with respect to the velocity vector.
The tensor is a matrix with this structure:
As it is a skew symmetric matrix it has a Hodge dual vector which is precisely the previous angular velocity vector formula_25:
Coordinate-free description.
At any instant, formula_46, the angular velocity tensor represents a linear map between the position vectors formula_47
and their velocity vectors formula_48 of a rigid body rotating around the origin:
where we omitted the formula_46 parameter, and regard formula_51 and formula_52 as elements of the same 3-dimensional Euclidean vector space formula_53.
The relation between this linear map and the angular velocity pseudovector formula_20 is the following.
Because of "W" is the derivative of an orthogonal transformation, the
bilinear form is skew-symmetric. (Here formula_56 stands for the scalar product). So we can apply the fact of exterior algebra that there is a unique linear form formula_57 on formula_58 that
where formula_60 is the wedge product of formula_61 and formula_62.
Taking the dual vector "L"* of "L" we get
Introducing formula_64, as the Hodge dual of "L"*, and apply further Hodge dual identities we arrive at
where
by definition.
Because formula_62 is an arbitrary vector, from nondegeneracy of scalar product follows
Angular velocity as a vector field.
For angular velocity tensor maps velocities to positions, it is a vector field. In particular, this vector field is a Killing vector field belonging to an element of the Lie algebra so(3) of the 3-dimensional rotation group SO(3). This element of so(3) can also be regarded as the angular velocity vector.
Rigid body considerations.
The same equations for the angular speed can be obtained reasoning over a rotating rigid body. Here is not assumed that the rigid body rotates around the origin. Instead it can be supposed rotating around an arbitrary point which is moving with a linear velocity V(t) in each instant.
To obtain the equations it is convenient to imagine a rigid body attached to the frames and consider a coordinate system that is fixed with respect to the rigid body. Then we will study the coordinate transformations between this coordinate and the fixed "laboratory" system.
As shown in the figure on the right, the lab system's origin is at point O, the rigid body system origin is at O' and the vector from O to O' is R. A particle ("i") in the rigid body is located at point P and the vector position of this particle is Ri in the lab frame, and at position ri in the body frame. It is seen that the position of the particle can be written:
The defining characteristic of a rigid body is that the distance between any two points in a rigid body is unchanging in time. This means that the length of the vector formula_70 is unchanging. By Euler's rotation theorem, we may replace the vector formula_70 with formula_72 where formula_73 is a 3x3 rotation matrix and formula_74 is the position of the particle at some fixed point in time, say t=0. This replacement is useful, because now it is only the rotation matrix formula_73 which is changing in time and not the reference vector formula_74, as the rigid body rotates about point O'. Also, since the three columns of the rotation matrix represent the three versors of a reference frame rotating together with the rigid body, any rotation about any axis becomes now visible, while the vector formula_70 would not rotate if the rotation axis were parallel to it, and hence it would only describe a rotation about an axis perpendicular to it (i.e., it would not see the component of the angular velocity pseudovector parallel to it, and would only allow the computation of the component perpendicular to it). The position of the particle is now written as:
Taking the time derivative yields the velocity of the particle:
where Vi is the velocity of the particle (in the lab frame) and V is the velocity of O' (the origin of the rigid body frame). Since formula_73 is a rotation matrix its inverse is its transpose. So we substitute formula_81:
or
where formula_86 is the previous angular velocity tensor.
It can be proved that this is a skew symmetric matrix, so we can take its dual to get a 3 dimensional pseudovector which is precisely the previous angular velocity vector formula_25:
Substituting ω for "W" into the above velocity expression, and replacing matrix multiplication by an equivalent cross product:
It can be seen that the velocity of a point in a rigid body can be divided into two terms – the velocity of a reference point fixed in the rigid body plus the cross product term involving the angular velocity of the particle with respect to the reference point. This angular velocity is the "spin" angular velocity of the rigid body as opposed to the angular velocity of the reference point O' about the origin O.
Consistency.
We have supposed that the rigid body rotates around an arbitrary point. We should prove that the angular velocity previously defined is independent from the choice of origin, which means that the angular velocity is an intrinsic property of the spinning rigid body.
See the graph to the right: The origin of lab frame is O, while O1 and O2 are two fixed points on the rigid body, whose velocity is formula_90 and formula_91 respectively. Suppose the angular velocity with respect to O1 and O2 is formula_92 and formula_93 respectively. Since point P and O2 have only one velocity,
The above two yields that
Since the point P (and thus formula_97) is arbitrary, it follows that
If the reference point is the instantaneous axis of rotation the expression of velocity of a point in the rigid body will have just the angular velocity term. This is because the velocity of instantaneous axis of rotation is zero. An example of instantaneous axis of rotation is the hinge of a door. Another example is the point of contact of a purely rolling spherical (or, more generally, convex) rigid body.

</doc>
<doc id="65928" url="https://en.wikipedia.org/wiki?curid=65928" title="Bass Strait">
Bass Strait

Bass Strait is a sea strait separating Tasmania from the Australian mainland, specifically the state of Victoria.
Extent.
The International Hydrographic Organization defines the limits of Bass Strait as follows:
Differing views of location and context.
Some authorities consider the strait to be part of the Pacific Ocean as in the never-approved 2002 IHO "Limits of Oceans and Seas" draft. In the currently in-force IHO 1953 draft, it is instead listed as part of the Indian Ocean.
The Australian Hydrographic Service does not consider it to be part of the Southern Ocean, using the expanded Australian definition, and states that it lies with the Tasman Sea. The strait between the Furneaux Islands and Tasmania is Banks Strait, a subdivision of Bass Strait.
Discovery and exploration by Europeans.
The strait was named after George Bass, after he and Matthew Flinders passed through it while circumnavigating Van Diemen's Land (now named Tasmania) in the "Norfolk" in 1798–99. At Flinders' recommendation, the Governor of New South Wales, John Hunter, in 1800 named the stretch of water between the mainland and Van Diemen's Land "Bass's Straits". Later it became known as Bass Strait.
The existence of the strait had been suggested in 1797 by the master of the "Sydney Cove" when he reached Sydney after deliberately grounding his foundering ship and being stranded on Preservation Island (at the eastern end of the strait). He reported that the strong south westerly swell and the tides and currents suggested that the island was in a channel linking the Pacific and southern Indian Ocean. Governor Hunter thus wrote to Joseph Banks in August 1797 that it seemed certain a strait existed.
Geography.
Bass Strait is approximately 350 km wide and 500 km long, with an average depth of 60 m. Jennings’ study of the submarine topography of Bass Strait described the bathymetric Bass Basin, a shallow depression approximately 120 km wide and 400 km long (>65,000 km2 in area) in the centre of Bass Strait, with a maximum depth near its geographic centre of 83 m. Two plateaus, the Bassian Rise and King Island Rise located on the eastern and western margins of Bass Strait, respectively, are composed of a basement of Palaeozoic granite. These features form sills separating Bass Basin from the adjacent ocean basins. Associated with the <50 m deep Bassian Rise is the Furneaux Islands, the largest of which is Flinders Island (max. elevation 760 m). The surface of the King Island Rise also occurs in water depths of <50 m, and includes the shallow (40 m) Tail Bank at its northern margin as well as King Island itself. Subaqueous dunes (sandwaves) and tidal current ridges and subaqueous dunes cover approximately 6,000 km2 of the seabed in Bass Strait.
During Pleistocene low sea level stands the central basin of Bass Strait was enclosed by raised sills forming a large shallow lake. This occurred during the last glacial maximum (18,000 yrs ago), when the basin was completely isolated. Sea level rise during the marine transgression flooded the basin, forming a marine embayment from 11,800 to 8,700 and the basin rim was completely flooded by about 8,000 years BP, at which point Bass Strait was formed and Tasmania became a separate island.
Like the rest of the waters surrounding Tasmania, and particularly because of its limited depth, it is notoriously rough, with many ships lost there during the 19th century. A lighthouse was erected on Deal Island in 1848 to assist ships in the eastern part of the Straits, but there were no guides to the western entrance until the Cape Otway Lighthouse was first lit in 1848, followed by another at Cape Wickham at the northern end of King Island in 1861.
Maritime history.
Strong currents between the Antarctic-driven southeast portions of the Indian Ocean and the Tasman Sea's Pacific Ocean waters provide a strait of powerful, wild storm waves. To illustrate its wild strength, Bass Strait is both twice as wide and twice as rough as the English Channel. The shipwrecks on the Tasmanian and Victorian coastlines number in the hundreds, although stronger metal ships and modern marine navigation have greatly reduced the danger.
Many vessels, some quite large, have disappeared without trace, or left scant evidence of their passing. Despite myths and legends of piracy, wrecking and alleged supernatural phenomena akin to those of the Bermuda Triangle, such disappearances can be invariably ascribed to treacherous combinations of wind and sea conditions, and the numerous semi-submerged rocks and reefs within the Straits.
Despite the strait's difficult waters it provided a safer and less boisterous passage for ships on the route from Europe or India to Sydney in the early 19th century. The strait also saved distance on the voyage.
Islands.
There are over 50 islands in Bass Strait. Major islands include:
Western section:
South eastern section:
North eastern section:
Natural resources.
A number of oil and gas fields exist in the eastern portion of Bass Strait, in what is known as the Gippsland Basin. Most large fields were discovered in the 1960s, and are located about 50 km to 65 km off the coast of Gippsland in water depths of about 70 m. These oil fields include the Halibut Field discovered in 1967, the Cobia Field discovered in 1972, the Kingfish Field, the Mackerel Field, and the Fortescue Field discovered in 1978. Large gas fields include the Whiptail field, the Barracouta Field, the Snapper Field, and the Marlin Field. Oil and gas are produced from the Cretaceous-Eocene clastic rocks of the Latrobe Group, deposited with the breakup of Australia and Antarctica.
The western field, known as the Otway Basin, was discovered in the 1990s offshore near Port Campbell. Its exploitation began in 2005.
The oil and gas is sent via a pipeline to gas processing facilities and oil refineries at Longford, Western Port, Altona and Geelong, as well as by tanker to New South Wales.
Infrastructure.
Transport.
The fastest and often the cheapest method of travel across Bass Strait is by air. The major airports in Tasmania are Hobart International Airport and Launceston Airport, where the main airlines are Jetstar Airways and Virgin Australia. Qantas and Tiger Airways Australia also operate services. The smaller airports in the north of the state and on the islands in the strait are served either by Regional Express Airlines, QantasLink or King Island Airlines.
Ferries.
"See also Bass Strait Ferries"
The domestic sea route is serviced by two Spirit of Tasmania passenger vehicle ferries, based in Devonport, Tasmania. The ships travel daily in opposite directions between Devonport and Station Pier in Melbourne, as overnight trips with additional daytime trips during the peak summer season.
Energy.
The Basslink HVDC electrical cable has been in service since 2006. It has the capacity to carry up to 630 megawatts of electrical power across the strait.
Alinta owns a submarine gas pipeline, delivering natural gas to large industrial customers near George Town, as well as the Powerco gas network in Tasmania.
Communications.
The first submarine communications cable across Bass Strait was laid in 1859. Starting at Cape Otway, Victoria, it went via King Island and Three Hummock Island, made contact with the Tasmanian mainland at Stanley Head, and then continued on to George Town. However it started failing within a few weeks of completion, and by 1861 it failed completely.
Tasmania is currently connected to the mainland via two Telstra-operated fibre optic cables; since 2006, dark fibre capacity has also been available on the Basslink HVDC cable.
Other submarine cables include:
Popular culture.
The issue of planes, ships and people having been lost in the strait over time has spawned a number of theories. Perhaps the most thorough list of losses and disappearances has been the oft re-printed book of Jack Loney though it is possible that most losses can be adequately explained by extreme weather events.
On the popular Australian soap "Neighbours", one of its most dramatic storylines unfolded when a 1940s themed joy flight to Tasmania was sabotaged by a bomb. The plane crashed into Bass Strait in the middle of the night and many character's lives were put at risk, with some drowning.
In 1978, one of the most famous UFO incidents in Australian history occurred over Bass Strait. Frederick Valentich was flying a small aeroplane over the strait when he reported to personnel at a local airport that a strange object was buzzing his plane. He then claimed that the object had moved directly in front of his plane; the airport personnel then heard a metallic "scraping" sound, followed by silence. Valentich and his plane subsequently vanished and neither Valentich nor his plane were ever seen again.
Non-motorised crossings.
Bass Strait is regularly crossed by sailing vessels, including during the annual Melbourne to Hobart Yacht Race. The Sydney to Hobart Yacht Race passes generally east of the strait but is affected by its weather conditions.
Australian Olympic bronze medalist Michael Blackburn set a record in October 2005 when he crossed the strait in just over 13 hours in a Laser sailing dinghy.
Lone rower David Bowen (Mt Martha) crossed Bass Strait in 1971 rowing a 20' dory, leaving from Devonport he landed on Wilson's Promontory. Tammy van Wisse swam part of the strait in 1996, from King Island to Apollo Bay in Victoria, a distance of about 100 km in 17 hours and 46 minutes. Rod Harris, Ian and Peter Richards are credited with the first kayak crossing in 1971. Many sea kayakers have since made the crossing, usually by island hopping on the eastern side of the strait. Fewer sea kayak crossings have been made via King Island, due to the 100 km leg between Cape Wickam and Apollo Bay. Andrew McAuley was the first person to cross Bass Strait non-stop in a sea kayak in 2003. He made two more crossings of Bass Strait before he died attempting to cross the Tasman Sea in February 2007. The first windsurfer crossing was in 1982 by Mark Paul and Les Tokolyi. Kitesurfers have also completed the crossing. The first crossing by paddleboard was made by Jack Bark, Brad Gaul and Zeb Walsh, leaving Wilsons Promontory in Victoria on 25 February 2014 and arriving at Cape Portland in Tasmania's north-east on 4 March 2014.

</doc>
<doc id="65929" url="https://en.wikipedia.org/wiki?curid=65929" title="Angular acceleration">
Angular acceleration

Angular acceleration is the rate of change of angular velocity. In SI units, it is measured in radians per second squared (rad/s), and is usually denoted by the Greek letter alpha ("α").
Mathematical definition.
The angular acceleration can be defined as either:
where formula_3 is the angular velocity, formula_4 is the linear tangential acceleration, and formula_5, (usually defined as the radius of the circular path of which a point moving along), is the distance from the origin of the coordinate system that defines formula_6 and formula_7 to the point of interest.
Equations of motion.
For two-dimensional rotational motion (constant formula_8), Newton's second law can be adapted to describe the relation between torque and angular acceleration:
where formula_10 is the total torque exerted on the body, and formula_11 is the mass moment of inertia of the body.
Constant acceleration.
For all constant values of the torque, formula_10, of an object, the angular acceleration will also be constant. For this special case of constant angular acceleration, the above equation will produce a definitive, constant value for the angular acceleration:
Non-constant acceleration.
For any non-constant torque, the angular acceleration of an object will change with time. The equation becomes a differential equation instead of a constant value. This differential equation is known as the equation of motion of the system and can completely describe the motion of the object. It is also the best way to calculate the angular velocity.

</doc>
<doc id="65930" url="https://en.wikipedia.org/wiki?curid=65930" title="ANSI escape code">
ANSI escape code

In computing, ANSI escape codes (or escape sequences) are a method using in-band signaling to control the formatting, color, and other output options on video text terminals. To encode this formatting information, certain sequences of bytes are embedded into the text, which the terminal looks for and interprets as commands, not as character codes.
ANSI codes were introduced in the 1970s and became widespread in the minicomputer/mainframe market by the early 1980s. They were used by the nascent bulletin board system market to offer improved displays compared to earlier systems lacking cursor movement, leading to even more widespread use.
Although hardware text terminals have become increasingly rare in the 21st century, the relevance of the ANSI standard persists because most terminal emulators interpret at least some of the ANSI escape sequences in the output text. One notable exception was the Win32 console component of Microsoft Windows before Windows 10 update TH2.
History.
Almost all manufacturers of video terminals added vendor-specific escape sequences to perform operations such as placing the cursor at arbitrary positions on the screen. One example is the VT52 terminal, which allowed the cursor to be placed at an x,y location on the screen by sending the codice_1 character, a codice_2 character, and then two characters representing with numerical values equal to the x,y location plus 32 (thus starting at the ASCII space character and avoiding the control characters).
As these sequences were different for different platforms, elaborate libraries such as termcap had to be created so programs could use the same API to work with any terminal. Most of these systems required sending numbers (such as row and column) as the binary values of the characters; for some programming languages, and for systems that did not use ASCII internally, it was often difficult or impossible to turn a number into the correct character.
The ANSI standard attempted to address these problems by making a command set that all terminals would use and requiring all numeric information to be transmitted as ASCII numbers. The first standard in the series was ECMA-48, adopted in 1976. It was a continuation of a series of character coding standards, the first one being ECMA-6 from 1961, a 7-bit standard from which ASCII originates. The name "ANSI escape sequence" dates from 1979 when ANSI adopted ANSI X3.64. The ANSI X3L2 committee collaborated with the ECMA committee TC 1 to produce nearly identical standards. These two standards were merged into an international standard, ISO 6429. In 1994, ANSI withdrew its standard in favor of the international standard.
In 1981, ANSI X3.64 was adopted for use in the US government by FIPS publication 86. Later, the US government stopped duplicating industry standards, so FIPS pub. 86 was withdrawn.
The first popular video terminal to support these sequences was the Digital VT100, introduced in 1978. This model was very successful in the market, which sparked a variety of VT100 clones, among the earliest and most popular of which was the much more affordable Zenith Z-19 in 1979. Others included the Qume QVT-108, Televideo TVI-970, Wyse WY-99GT as well as optional "VT100" or "VT103" or "ANSI" modes with varying degrees of compatibility on many other brands. The popularity of these gradually led to more and more software (especially bulletin board systems) assuming the escape sequences worked, leading to almost all new terminals and emulator programs supporting them.
ECMA-48 has been updated several times and is currently at its 5th edition, from 1991. It is also adopted by ISO and IEC as standard ISO/IEC 6429.
Platform support.
The widespread use of ANSI by bulletin boards and online services led to almost universal platform support by the mid 1980s. In most cases this took the form of a terminal emulator (such as xterm on Unix or the OS X Terminal or ZTerm on MacOS and many communication programs for the IBM PC), although there was increasing support in the standard text output of many operating systems.
Unix and the AmigaOS all included some ANSI support in the OS, which led to widespread use of ANSI by programs running on those platforms. Unix-like operating systems could produce ANSI codes through libraries such as termcap and curses used by many pieces of software to update the display. These libraries are supposed to support non-ANSI terminals as well, but this is so rarely tested nowadays that they are unlikely to work. Many games and shell scripts (such as colored prompts) directly write the ANSI sequences and thus cannot be used on a terminal that does not interpret them.
AmigaOS not only interprets ANSI code sequences for text output to the screen, the AmigaOS printer driver also interprets them (with extensions proprietary to AmigaOS) and translates them into the codes required for the particular printer that is actually attached.
In spite of its popularity, ANSI codes were not universally supported. Support was not built-in on the original "classic" Mac OS, while the Atari ST used the command system adapted from the VT52 with some expansions for color support.
Windows and DOS.
MS-DOS 1.x did not support the ANSI or any other escape sequences. Only a few control characters (BEL, CR, LF, BS) were interpreted by the underlying BIOS, making it almost impossible to do any kind of full-screen application. Any display effects had to be done with BIOS calls, which were notoriously slow, or by directly manipulating the IBM PC hardware.
DOS 2.0 introduced the ability to add a device driver for the ANSI escape sequences – the "de facto" standard being ANSI.SYS, but others like ANSI.COM, NANSI.SYS and ANSIPLUS.EXE are used as well (these are considerably faster as they bypass the BIOS). Slowness and the fact that it was not installed by default made software rarely take advantage of it; instead, applications continued to directly manipulate the hardware to get the text display needed. ANSI.SYS and similar drivers continued to work in Windows 9x up to Windows Me, and in NT-derived systems for 16-bit legacy programs executing under the NTVDM.
The Win32 console did not support ANSI escape sequences at all until Windows 10 "Threshold 2". Some replacements or additions for the console window such as JP Software's TCC (formerly 4NT), Michael J. Mefford's ANSI.COM, Jason Hood's ANSICON 
and Maximus5's ConEmu do interpret ANSI escape sequences printed by programs.
Some software internally interprets ANSI escape sequences in text being printed and translates them to calls to manipulate the color and cursor position in the command output window, to make it easier to port software using ANSI to Windows.
Sequence elements.
Escape sequences start with the character codice_1 (ASCII decimal codice_4/hex codice_5/octal codice_6). For two character sequences, the second character is in the range ASCII codice_7–codice_8 (codice_9 to codice_10).
However, most of the sequences are more than two characters, and start with the characters codice_1 and codice_12 (left bracket). This sequence is called CSI for Control Sequence Introducer (or Control Sequence Initiator). The final character of these sequences is in the range ASCII codice_7–codice_14 (codice_9 to codice_16).
There is a single-character CSI (codice_17/codice_18 /codice_19) as well. The codice_20 two-character sequence is more often used than the single-character alternative (for details see C0 and C1 control codes).
Only the two-character sequence is recognized by devices that support just ASCII (7-bit bytes) or devices that support 8-bit bytes, but use the codice_21–codice_22 control character range for other purposes. On terminals that use UTF-8 encoding, both forms take 2 bytes (CSI in UTF-8 is codice_23, codice_18) but the codice_20 sequence is clearer.
Though some encodings use multiple bytes per character, the following discussion is restricted to ASCII characters, and thus assumes a single byte for each character.
Non-CSI codes.
Note: other C0 codes besides ESC — commonly BEL, BS, CR, LF, FF, TAB, VT, SO, and SI — may produce similar or identical effects to some control sequences when output.
Note: pressing special keys on the keyboard, as well as outputting many xterm CSI, DCS, or OSC sequences, often produces a CSI, DCS, or OSC sequence.
CSI codes.
The general structure of most ANSI escape sequences is codice_26. The final byte, modified by private mode characters and trailing intermediate characters, specifies the command. The numbers are optional parameters. The default value used for omitted parameters varies with the command, but is usually codice_27 or codice_28. If trailing parameters are omitted, the trailing semicolons may also be omitted.
The final byte is technically any character in the range codice_7–codice_14 (hex codice_31–codice_32, ASCII codice_9 to codice_16), and may be modified with leading intermediate bytes in the range codice_35 to codice_36 (hex codice_37–codice_38, ASCII codice_39 to codice_40).
The colon (codice_41, hex codice_42) is the only character not a part of the general sequence. It was left for future standardization, so any sequence containing it should be ignored.
Although multiple private mode characters or trailing intermediates are permitted, there are no such known usages.
If there are any leading private mode characters, the main body of the sequence could theoretically contain any order of characters in the range codice_43–codice_44 (hex codice_45–codice_46, ASCII codice_28 to codice_48) instead of a well-formed semicolon-separated list of numbers, but all known terminals are nice and just use the non-digit characters in this range as flags.
Sequences are also private if the final byte is in the range codice_49–codice_14 (hex codice_51–codice_32, ASCII codice_53–codice_16).
Examples of private escape codes include the DECTCEM (DEC text cursor enable mode) shown below.
It was first introduced for the VT-300 series of video terminals.
The behavior of the terminal is undefined in the case where a CSI sequence contains any character outside of the range codice_35 to codice_14 (hex codice_37–codice_32, ASCII codice_39–codice_16). These illegal characters are either C0 control characters (the range codice_28–codice_62, hex codice_63–codice_64), character codice_65 (hex codice_66, ASCII codice_67), or high-ASCII characters (the range codice_68–codice_69, hex codice_21–codice_71).
Possibilities for handling illegal characters in a CSI sequence include: 
1. Assuming the end of the CSI sequence, ignoring it and treating further characters as data;
2. Ignoring this sequence including all future characters through the next character that would normally end a CSI sequence (anything in the range codice_7–codice_14 (hex codice_31–codice_32, ASCIIcodice_9–codice_16)); or
3. Processing any control code as the terminal normally would outside of a CSI sequence before continuing to parse the rest of the sequence.
Colors.
The original specification only had 8 colors, and just gave them names. The SGR parameters 30-37 selected the foreground color, while 40-47 selected the background. Quite a few terminals implemented "bold" (SGR code 1) as a brighter color rather than a different font, thus providing 8 additional foreground colors. Usually you could not get these as background colors, though sometimes inverse video (SGR code 7) would allow that. Examples: to get black letters on white background use codice_78, to get red use codice_79, to get bright red use codice_80. To reset colors to their defaults, use codice_81 (not supported on some terminals) (or reset all attributes with codice_82).
When hardware started using 8-bit DACs several pieces of software assigned 24-bit color numbers to these names. The chart below shows default RGB assignments for some common terminal programs, together with the CSS and the X Window System colors for these color names.
The VGA column denotes the typical colors that are used when booting PCs and leaving them in their classical 80×25 text mode. The colors are different in the EGA/VGA graphic modes.
In July 2004, the blue colors of xterm changed, RGB (0,0,205) → (0,0,238) for normal and (0,0,255) → (92,92,255) for bright. As of 2010, old xterm versions still linger on many computers though.
Xterm, GNOME Terminal and KDE's Konsole support ISO-8613-3 24-bit foreground and background color setting Quoting one of the text-files in its source-tree:
In 256-color mode (ESC[38;5;"<fgcode>"m and ESC[48;5;"<bgcode>"m), the color-codes are the following:
Xterm allows also to set the default foreground and background colors using
where codice_91 and codice_92 are X color specifications, and BEL is the ASCII BEL character (code 7). The closing bracket instead of an opening bracket reveals that it belongs to the operating system control commands.
Examples.
codice_93 — This clears the screen and, on some devices, locates the cursor to the y,x position 1,1 (upper left corner).
codice_94 — This makes text green. On MS-DOS, normally the green would be dark, dull green, so you may wish to enable Bold with the sequence codice_95 which would make it bright green, or combined as codice_96. MS-DOS ANSI.SYS uses the Bold state to make the character Bright; also the Blink state can be set (via codice_97) to render the Background in the Bright mode. MS-DOS ANSI.SYS does not support SGR codes 90–97 and 100–107 directly.
codice_98 — This reassigns the key F10 to send to the keyboard buffer the string "DIR" and ENTER, which in the DOS command line would display the contents of the current directory. (MS-DOS ANSI.SYS only) This was sometimes used for ANSI bombs. This is a private-use code (as indicated by the letter p), using a non-standard extension to include a string-valued parameter. Following the letter of the standard would consider the sequence to end at the letter D.
codice_99 — This saves the cursor position. Using the sequence codice_100 will restore it to the position. Say the current cursor position is 7(y) and 10(x). The sequence codice_99 will save those two numbers. Now you can move to a different cursor position, such as 20(y) and 3(x), using the sequence codice_102 or codice_103. Now if you use the sequence CSI u the cursor position will return to 7(y) and 10(x). Some terminals require the DEC sequences codice_104 / codice_105 instead which is more widely supported.
Example of use in shell scripting.
ANSI escape codes are often used in UNIX and UNIX-like terminals to provide syntax highlighting. For example, on compatible terminals, the following "list" command color-codes file and directory names by type.
codice_106
Users can employ escape codes in their scripts by including them as part of "standard output" or "standard error". For example, the following GNU "sed" command embellishes the output of the "make" command by displaying lines containing words starting with "WARN" in reverse video and words starting with "ERR" in bright yellow on a dark red background (letter case is ignored). The representations of the codes are highlighted.
The following Bash function flashes the terminal (by alternately sending reverse and normal video mode codes) until the user presses a key.
This can be used to alert a programmer when a lengthy command terminates, such as with codice_107 .
This will reset the console, similar to the command codice_108 on modern Linux systems; however it should work even on older Linux systems and on other (non-Linux) UNIX variants.

</doc>
<doc id="65931" url="https://en.wikipedia.org/wiki?curid=65931" title="Jean Hersholt">
Jean Hersholt

Jean Pierre Hersholt (12 July 1886 – 2 June 1956) was a Danish-born actor who lived in the United States, where he was a leading film and radio talent, best known for his 17 years starring on radio in "Dr. Christian" and for playing Shirley Temple's grandfather in "Heidi". Asked how to pronounce his name, he told "The Literary Digest", "In English, "her'sholt"; in Danish, "hairs'hult"." Of his total credits, 75 were silent films and 65 were sound films (140 total); he directed four.
Early life.
Hersholt was born in Copenhagen, Denmark, the son of Claire (née Petersen) and Henry Hersholt, actors who worked with the Danish Folk Theatre. Hersholt toured Europe performing with his family when he was young. He then graduated from the Copenhagen Art School. His first two films were made in Germany in 1906. He emigrated to the US in 1913, and the remainder of his movies were made in America.
Career.
Hersholt's best remembered film roles include Marcus Schouler in Erich von Stroheim's 1924 "Greed" and Shirley Temple's beloved grandfather in the 1937 film version of the 1880 children's book, "Heidi", written by Swiss author Johanna Spyri. During his long career in the movies, his roles ran the gamut from early silent villains to secondary parts in which his mild Danish accent and pleasant voice suited him to depict a succession of benevolent fathers, doctors, professors and European noblemen. Hersholt's last role was in the 1955 movie "Run for Cover".
In "The Country Doctor" (1936), a movie starring the Dionne quintuplets, Hersholt portrayed Dr. John Luke, a character based on Dr. Allan Roy Dafoe, the Canadian obstetrician who delivered and cared for the Dionne Quintuplets. Two sequels followed. Hersholt wanted to do the role on radio but could not get the rights. He decided to create his own doctor character for radio, and since he was a Hans Christian Andersen enthusiast, he borrowed that name for his character of the philosophical Dr. Paul Christian who practiced in the Midwest town of River's End with the assistance of Nurse Judy Price. With the opening theme music of "Rainbow on the River", "Dr. Christian" was introduced on CBS on 7 November 1937 on "The Vaseline Program", aka "Dr. Christian's Office" and later "Dr. Christian".
The small-town physician's good humor, innate common sense and scientific training helped drive off a series of villainous types who tried to interfere with the peaceful lifestyle of River's End. Produced by Dorothy McCann, the radio series became a popular long-run hit, continuing on CBS until 6 January 1954, with Hersholt so strongly identified with the role that he received mail asking for medical advice. There were various spin-offs as Hersholt co-wrote a Dr. Christian novel and made a series of six family films as Christian from 1939 to 1941, for instance "Dr. Christian Meets the Women" in 1940. In 1956, his Dr. Christian character made the transition to television, scripted by Gene Roddenberry, with Macdonald Carey as his nephew Dr. Mark Christian. From the '30s through the '50s, Neil Reagan, brother of Ronald Reagan, directed the radio series Dr. Christian, starring Jean Hersholt.
In 1939, Hersholt helped form the Motion Picture Relief Fund to support industry employees with medical care when they were down on their luck. The fund was used to create the Motion Picture Country House and Hospital in Woodland Hills, California, and it led to the creation in 1956 of the Jean Hersholt Humanitarian Award, an honorary Academy Award given to an ""individual in the motion picture industry whose humanitarian efforts have brought credit to the industry"".
Hersholt's large collection of Hans Christian Andersen books is now in the Library of Congress. He translated over 160 of Andersen's fairy tales into the English language. These were published in 1949 in six volumes as "The Complete Andersen", this work is "... rated as "the" standard translation, being one of the best" in English. Hersholt was appointed a knight of the Order of the Dannebrog in 1948, partly due to this endeavour.
Family.
Hersholt was married to his wife, Via, in 1914. They had one child: Allan. He was the paternal half-uncle of the late actor Leslie Nielsen and former Canadian Deputy Prime Minister Erik Nielsen.
Death.
Hersholt died of cancer in Hollywood, and is interred in Forest Lawn Memorial Park Cemetery in Glendale, California. His grave is marked with a statue of Klods-Hans (English: Clumsy Hans), a Hans Christian Andersen character who left home to find his way in the world — much as Hersholt himself had done.
Honors and awards.
Hersholt was honored for his services to the industry twice with an honorary Academy Award, first in 1940 and the second time in 1950, and in his honor the Jean Hersholt Humanitarian Award was named by the Academy of Motion Picture Arts and Sciences. He has a star on the Hollywood Walk of Fame at 6501 Hollywood Boulevard for his work in motion pictures and another one at 6701 Hollywood Boulevard for his work in radio.

</doc>
<doc id="65937" url="https://en.wikipedia.org/wiki?curid=65937" title="Tael">
Tael

Tael (; ) or tahil can refer to any one of several weight measures of the Far East. Most commonly, it refers to the Chinese tael, a part of the Chinese system of weights and currency.
In Taiwan, Hong Kong, and Southeast Asia it is equivalent to 10 mace () or catty, albeit with slightly different metric equivalents in these two places. These Chinese units of measurement are usually used in the Chinese herbal medicine stores as well as gold and silver exchange.
Names and etymology.
The English word "tael" comes through Portuguese from the Malay word ', meaning "weight". Early English forms of the name such as "tay" or "taes" derive from the Portuguese plural of tael, '.
Tahil ( in Singaporean English) is used in Malay "and" English today when referring to the weight in Malaysia, Singapore, and Brunei where it is still used in some contexts especially related to the significant Overseas Chinese population.
In Chinese, tael is written (simplified Chinese: ) and has the Mandarin Chinese pronunciation in . In Chinese and Vietnamese, the phrase "half a catty, eight taels" (; Vietnamese:), meaning two different presentations of the same thing (similar to the English phrase "Six of one and half-a-dozen of the other"), is still often used today.
Historical usage.
In China, there were many different weighting standards of tael depending on the region or type of trade. In general the silver tael weighed around . The most common government measure was the "Kuping" () tael, weighing . A common commercial weight, the "Caoping" () tael weighed of marginally less pure silver.
As in China, Japan used the as both a unit of weight and, by extension, a currency.
Tael currency.
Traditional Chinese silver sycees and other currencies of fine metals were not denominated or made by a central mint and their value was determined by their weight in taels. They were made by individual silversmiths for local exchange, and as such the shape and amount of extra detail on each ingot were highly variable; square and oval shapes were common but "boat", flower, tortoise and others are known. The local tael also took precedence over any central measure, so the Canton tael weighed 37.5 grams, the Convention or Shanghai tael was 33.9 g (1.09 ozt), and the "Haiguan" () tael 37.8 g (defined as  oz avoirdupois, about 1.22 ozt). The conversion rates between various common taels were well known. The tael was still the basis of the silver currency and sycee remained in use until the end of the Qing Dynasty in 1911. Common weights were 50 tael, 10 tael, and 5 down to 1.
Modern studies suggest that, on purchasing power parity basis, one tael of silver was worth about 4130 RMB (modern Chinese yuan) in the early Tang Dynasty, 2065 RMB in the late Tang Dynasty, and 660.8 RMB in the mid Ming Dynasty.
The Thai equivalent of the tael is known as the "tamlueng", a term derived from Khmer. It was used as a unit of currency equal to four baht, and as a unit of weight is now standardised at 60 grams.
Current usage.
The tael is still in use as a weight measurement in a number of countries though usually only in limited contexts.
China.
China's standardised "market tael" () of 31.25 g was modified by the People's Republic of China in 1959. The new market tael was 50 g or catty (500 g) to make it compatible with metric measures. (see Chinese unit for details.) In Shanghai, silver is still traded in taels.
Some foodstuffs in China are sold in units also called "taels", but which do not necessarily weigh one tael. For cooked rice, the weight of the tael is approximated using special tael-sized ladles. Other items sold in taels include the shengjian mantou and the xiaolongbao, both small buns commonly found in Shanghai. In these cases, one tael is traditionally four and eight buns respectively.
Hong Kong and Singapore.
The tael is a legal weight measure in Hong Kong, and is still in active use. In Hong Kong, one tael is 37.799364167 g, and in ordinance 22 of 1884 is oz. avoir. Similar to Hong Kong, in Singapore, one tael is defined as ounce and is approximated as 37.7994 g
Taiwan.
The Taiwan tael is 37.5 g and is still used in some contexts. The Taiwan tael is derived from the tael or of the Japanese system (equal to 10 "momme") which was 37.5 g. Although the catty (equal to 16 taels) is still frequently used in Taiwan, the tael is only used for precious metals and medicines.
Vietnam.
In French Indochina, the colonial administration standardised the tael "()" as 100 g, which is commonly used at food markets where many items typically weigh in the 100–900 g range. However, a different tael (called ', ', or "") unit of 37.5 g is used for domestic transactions in gold. Real estate prices are often quoted in taels of gold rather than the local currency over concerns over monetary inflation.

</doc>
<doc id="65941" url="https://en.wikipedia.org/wiki?curid=65941" title="Comic magazine">
Comic magazine

Comic magazine may refer to:

</doc>
<doc id="65942" url="https://en.wikipedia.org/wiki?curid=65942" title="Judith Durham">
Judith Durham

Judith Mavis Durham (born Judith Mavis Cock; 3 July 1943) is an Australian singer and musician who became the lead vocalist for the Australian popular folk music group The Seekers in 1963. The group subsequently became the first Australian pop music group to achieve major chart and sales success in the United Kingdom and the United States, and as of 2004 had sold over 50 million records. Durham left the group in mid-1968 to pursue her solo career. In 1993, Durham began to make sporadic recordings and performances with The Seekers, though she remains primarily a solo performer.
On 1 July 2015, she was named Victorian of the Year for her services to music and a range of charities.
Early life.
Durham was born in Essendon, Victoria, to William Alexander Cock DFC, a navigator and World War II pathfinder, and his wife, Hazel ("née" Durham). From her birth until 1949, Durham spent summer holidays at her family's weatherboard house on the west side of Durham Place in Rosebud, which has been demolished. A myth has circulated that "Morningtown Ride" was prompted by these holidays and the nearby town of Mornington. However, Durham has stated that the song was written by American songwriter Malvina Reynolds and that the lyrics refer to sweet dreams rather than the Mornington Peninsula. Durham lived in Hobart, Tasmania, where she attended the Fahan School before moving back to Melbourne in 1956. In Melbourne, she was educated at Ruyton Girls' School and then enrolled at RMIT.
Durham at first planned to be a pianist and gained the qualification of Associate in Music, Australia (AMusA), in classical piano at the University of Melbourne Conservatorium. She had some professional engagements playing piano and also had classical vocal training and performed blues, gospel and jazz pieces. Her singing career began one night at the age of 18 when she asked Nicholas Ribush, leader of the Melbourne University Jazz Band, at the Memphis Jazz Club in Malvern, whether she could sing with the band. In 1963 she began performing at the same club with Frank Traynor's Jazz Preachers, using her mother's maiden name of Durham. In that year she also recorded her first EP, "Judy Durham with Frank Traynor's Jazz Preachers", for W&G Records.
Durham was working as a secretary at the J. Walter Thompson advertising agency where she met account executive Athol Guy. Guy was in a folk group called The Seekers which sang on Monday nights at the Treble Clef, a coffee lounge on Toorak Road in Melbourne.
The Seekers.
The Seekers consisted of Durham, Athol Guy, Bruce Woodley and Keith Potger, the last being an ABC radio producer. It was through Potger's position that the three were able to make a demo tape in their spare time. This was given to W&G Records, which wanted another sample of Durham's voice before agreeing to record a Jazz Preachers' album. W&G instead signed The Seekers for an album, "Introducing the Seekers", in 1963. (Potger does not appear on the album cover because he was not allowed to have a second job.) Durham, however, recorded two other songs with the Jazz Preachers, "Muddy Water" (which appeared on their album "Jazz From the Pulpit") and "Trombone Frankie" (an adapted version of Bessie Smith's "Trombie Cholly").
In early 1964 The Seekers sailed to the United Kingdom on the "S.S. Fairsky" on which the group provided the musical entertainment. Originally they had planned to return after ten weeks, but they received a steady stream of bookings through the Grade Agency because they had sent the agency a copy of their first album. In November 1964 The Seekers released "I'll Never Find Another You" composed by Tom Springfield. In February 1965 the record reached number one in the UK and Australia, while their 1966 recording of Springfield and Jim Dale's "Georgy Girl" (from the film of the same name) reached number two (Billboard chart) and number one (Cashbox chart) in the United States.
Solo career.
Durham returned to Australia in August 1968 and her first solo television special screened on the Nine Network in September. During her solo career she has released albums titled "For Christmas With Love", "Gift of Song" and "Climb Ev'ry Mountain". In 1970 she made the television special "Meet Judith Durham" in London, ending with her rendition of "When You Come to the End of a Perfect Day" by Carrie Jacobs-Bond (1862–1946). In the 1970s she returned to traditional jazz and recorded Volumes 1 and 2 of "The Hottest Band in Town" and "The Hot Jazz Duo". She then moved to Queensland and focused on her songwriting.
In 1994, Durham began recording albums again, including "Mona Lisas" in 1996 under the direction of producer Gus Dudgeon. This was re-released as "Always There" in 1997 with the addition of Durham's solo recording of fellow Seeker Bruce Woodley's "I am Australian" (with Russell Hitchcock of Air Supply and Mandawuy Yunupingu of Yothu Yindi) and the Smith Family theme song of the title. Her recording of "Always There" was first released on the 1997 double CD "Anthems", which also featured Bruce Woodley's "Common Ground" and the Seekers' "Advance Australia Fair" arrangement.
In 2000, Durham's album "Let Me Find Love", a top ten hit on the Australian album charts, was re-released as "Hold on to Your Dream", with the addition of "Australia Land of Today" (which she had written). In 2001, she did another Australian tour and in 2003 she toured the UK to celebrate her 60th birthday. Her birthday concert at the Royal Festival Hall in London was filmed and released on DVD in late 2004.
In 2006, The Seekers were awarded the "Key to the City" of Melbourne by Lord Mayor John So. As part of the ceremony, Durham sang part of her song "Seldom Melbourne Leaves My Mind" and was later invited by the Lord Mayor's Charitable Fund to record the song, as a fund-raiser, with Orchestra Victoria. The decision was then made to record Durham's entire "Australian Cities Suite" with all proceeds from the sale of the CD to go to the charitable sector. The album was released in October 2008. The project was to benefit charities such as the Motor Neurone Disease Association of Australia (Durham is national patron) and Orchestra Victoria, in addition to other charities which benefit from the Lord Mayor's Charitable Fund or its national affiliated network United Way.
By 2009, Durham's rendition of "A Perfect Day" by Carrie Jacobs-Bond achieved more hits on YouTube than even the version by Paul Robeson but was withdrawn from availability because of questions involving access to intellectual property.
The "Australian Cities Suite" features songs for all the capital cities including:
On 13 February 2009, Durham made a surprise return to the Myer Music Bowl when she performed the closing number at the "RocKwiz Salutes the Bowl – Sidney Myer Music Bowl 50th Anniversary" with "The Carnival is Over".
On 23 May 2009, Durham performed a one-hour "a cappella" concert in Melbourne as a launch for her album "Up Close & Personal Vol 1".http://www.judithdurham.com/news/120344_01.html</ref>
Personal life.
On 21 November 1969, she married her musical director, British pianist Ron Edgeworth, in Melbourne. They lived in the UK and Switzerland until the mid-1980s when they bought property in Nambour, Queensland.
In 1990 Durham, Edgeworth and their tour manager, Peter Summers, were involved in a car accident on the Calder Freeway. The driver of the other car died at the scene and Durham sustained a fractured wrist and leg. The response from her fans made Durham consider getting back together with the other members of The Seekers for a silver jubilee show. This reunion, however, was cut short when Edgeworth was diagnosed with motor neurone disease. He died on 10 December 1994 with Durham by his side.
In the late 1990s Durham was stalked by her former personal assistant, a woman who sent her dozens of doormats through the post. The woman was subsequently prosecuted.
In May 2013 Durham suffered a brain hemorrhage which diminished her ability to read and write not only visual language but also musical scores. During her convalescence she made progress to rebuild those skills. Her singing ability was never affected.
Solo releases.
With the exception of the 1963 jazz EP, all of Durham's solo recordings have been rereleased on CD as of April 2015.
Durham has also contributed to various compilations, including the CD single "Yil Lull", "Slowly Gently" for the Motor Neurone Disease fundraiser "One Man's Journey", and an ethnic version of "The Carnival Is Over" with Melbourne group Inka Marka for the Melbourne Immigration Museum's compilation CD "This Is the Place for a Song". In 2007 Durham also made a cameo appearance on "English Garden", a bonus track featured only on the digital download version of the 2007 Silverchair album "Young Modern".

</doc>
<doc id="65944" url="https://en.wikipedia.org/wiki?curid=65944" title="Plankalkül">
Plankalkül

Plankalkül (, "Plan Calculus") is a programming language designed for engineering purposes by Konrad Zuse between 1943 and 1945. It was the first high-level (non-von Neumann) programming language to be designed for a computer. Also, notes survive with scribblings about such a plan calculation dating back to 1941. Plankalkül was not published at that time owing to a combination of factors such as conditions in wartime and postwar Germany and his efforts to commercialise the Z3 computer and its successors. In 1944 Zuse met with the German logician and philosopher Heinrich Scholz and they discussed Zuse's Plankalkül. In March 1945 Scholz personally expressed his deep appreciation for Zuse's utilization of the logical calculus.
By 1946, Zuse had written a book on the subject but this remained unpublished. In 1948 Zuse published a paper about the Plankalkül in the "Archiv der Mathematik" but still did not attract much feedback – for a long time to come programming a computer would only be thought of as programming with machine code. The Plankalkül was eventually more comprehensively published in 1972 and the first compiler for it was implemented in 1975 in a dissertation by Joachim Hohmann. Other independent implementations followed in 1998 and then in 2000 by the Free University of Berlin.
""Kalkül"" means formal system – the Hilbert-style deduction system is for example originally called ""Hilbert-Kalkül"", so Plankalkül means "formal system for planning".
Description.
Plankalkül has drawn comparisons to APL and relational algebra. It includes assignment statements, subroutines, conditional statements, iteration, floating point arithmetic, arrays, hierarchical record structures, assertions, exception handling, and other advanced features such as goal-directed execution. The Plankalkül provides a data structure called "general graph" ("verallgemeinerter Graph"), which can be used to represent geometrical structures.
Plankalkül shared an idiosyncratic notation using multiple lines with Frege's "Begriffsschrift" of 1879 (dealing with mathematical logic).
Terminology.
Zuse called a single program a "Rechenplan" (i.e. "computation plan"), and in 1944 he already envisioned a device that should read and then automatically translate a mathematical formulation of a program into machine readable punched film stock – a device which he called "Planfertigungsgerät" (i.e. "plan construction device").
Example.
The original notation was two dimensional. For a later implementation in the 1990s, a linear notation was developed.
The following example shows a program (in a linear transcription), which calculates the maximum of three variables by calling the function max 3:
Quotations.
In a lecture in 1957 Zuse mentioned his hope that the Plankalkül "after some time as a Sleeping Beauty, will yet come to life."
Heinz Rutishauser, one of the founders of ALGOL:

</doc>
<doc id="65946" url="https://en.wikipedia.org/wiki?curid=65946" title="Consumer confidence index">
Consumer confidence index

The U.S. consumer confidence index (CCI) is an indicator designed to measure consumer confidence, which is defined as the degree of optimism on the state of the economy that consumers are expressing through their activities of savings and spending. Global consumer confidence is not measured. Country by country analysis indicates huge variance around the globe. In an interconnected global economy, tracking international consumer confidence is a lead indicator of economic trends.
In the United States consumer confidence is issued monthly by The Conference Board, an independent economic research organization, and is based on 5,000 households. Such measurement is indicative of consumption component level of the gross domestic product. The Federal Reserve looks at the CCI when determining interest rate changes, and it also affects stock market prices.
The consumer confidence index was started in 1967 and is benchmarked to 1985=100. This year was chosen because it was neither a peak nor a trough. The Index is calculated each month on the basis of a household survey of consumers' opinions on current conditions and future expectations of the economy. Opinions on current conditions make up 40% of the index, with expectations of future conditions comprising the remaining 60%. In the glossary on its website, The Conference Board defines the Consumer Confidence Survey as "a monthly report detailing consumer attitudes and buying intentions, with data available by age, income and region".
Another well-established index that measures consumer confidence is the University of Michigan Consumer Sentiment Index, run by University of Michigan's Institute for Social Research.
Calculation.
In simple terms, increased consumer confidence indicates economic growth in which consumers are spending money, indicating higher consumption. Decreasing consumer confidence implies slowing economic growth, and so consumers are likely to decrease their spending. The idea is that the more confident people feel about the economy and their jobs and incomes, the more likely they are to make purchases. Declining consumer confidence is a sign of slowing economic growth and may indicate that the economy is headed into trouble.
Each month The Conference Board surveys 5,000 US households. The survey consists of five questions that ask the respondents' opinions about the following:
Survey participants are asked to answer each question as "positive", "negative" or "neutral". The preliminary results from the consumer confidence survey are released on the last Tuesday of each month at 10am EST.
Once the data have been gathered, a proportion known as the "relative value" is calculated for each question separately. Each question's positive responses are divided by the sum of its positive and negative responses. The relative value for each question is then compared against each relative value from 1985. This comparison of the relative values results in an "index value" for each question.
The index values for all five questions are then averaged together to form the consumer confidence index; the average of index values for questions one and three form the present situation index, and the average of index values for questions two, four and five form the expectations index. The data are calculated for the United States as a whole and for each of the country's nine census regions.
Usage.
Manufacturers, retailers, banks and the government monitor changes in the CCI in order to factor in the data in their decision-making processes. While index changes of less than 5% are often dismissed as inconsequential, moves of 5% or more often indicate a change in the direction of the economy.
A month-on-month decreasing trend suggests consumers have a negative outlook on their ability to secure and retain good jobs. Thus, manufacturers may expect consumers to avoid retail purchases, particularly large-ticket items that require financing. Manufacturers may pare down inventories to reduce overhead and/or delay investing in new projects and facilities. Likewise, banks can anticipate a decrease in lending activity, mortgage applications and credit card use. When faced with a down-trending index, the government has a variety of options, such as issuing a tax rebate or taking other fiscal or monetary action to stimulate the economy.
Conversely, a rising trend in consumer confidence indicates improvements in consumer buying patterns. Manufacturers can increase production and hiring. Banks can expect increased demand for credit. Builders can prepare for a rise in home construction and government can anticipate improved tax revenues based on the increase in consumer spending.
Consumer-demand surveys versus consumer-confidence and -sentiment surveys.
Consumer-demand surveys are interview-based statistical surveys that measure the percentage of households that will buy a car, white goods, PCs, TVs, home furnishings, kitchenware or toys in, for example, the next three-month period. The surveys provide a percentage of those who will purchase more, less or the same amount of food and clothing in the next three months than in the corresponding period the year before. If you ask people about their purchasing behavior within the coming six or 12 months, there will be more of those who “hope to be able to buy”, than if consumers are asked about what they will purchase in the next three months. The shorter the time spans, the closer to actual behavior.
Consumer-confidence and -sentiment surveys measure how people are doing financially, how they look at the overall economy of the country or business conditions in the country, if they think that the government is doing a good or a poor job and if people think that it is a good or a bad time to buy a car or to buy or sell a house.
When the business cycle is fairly stable, consumer demand surveys and consumer confidence and sentiment indices will often correlate closely and indicate the same direction of the economy, but in times with a high degree of economic or political uncertainty or during a prolonged crisis, the two types of consumer surveys might differ significantly. In 2011 the confidence and sentiment surveys went up from March to April, while consumer demand surveys dropped significantly. In August 2011 the confidence and sentiment surveys dropped significantly and stayed low during September and October, while consumer demand surveys showed resilience, a development confirmed later by official statistics.
Thomson Reuters/University of Michigan and the Conference Board both publish a monthly consumer confidence and attitude survey. The Institute for Business Cycle Analysis publishes a monthly consumer demand survey known as US Consumer Demand Indices.
Consumer confidence index in the United States.
The Conference Board's consumer confidence index is the most widely accepted index among the United States media, businesspeople, and many consumers. The chart to the left shows the index over time from December 1966 to April 2012.
Other measures of consumer confidence in the United States.
In addition to the Conference Board's CCI, other survey-based indices attempt to track consumer confidence in the U.S.:
Given the potential for sampling biases of individual survey reports, researchers and investors try sometimes to average the values of different index reports into a single aggregated measure of consumer confidence.
Consumer confidence index in India.
"Original Article Indian consumer confidence index"
The ZyFin India Consumer Outlook Index is a monthly index of consumer sentiment in India. The COI is designed to provide reliable insights into the direction of the Indian national and regional economies. Released once a month, the index is computed from the results of a monthly survey of 4,000 consumers in 18 cities across India.
Consumer confidence index in the Republic of Ireland.
KBC Bank Ireland (formerly IIB Bank) and the Economic and Social Research Institute (a think-tank) have published a monthly consumer sentiment index since January 1996.
Consumer confidence index in Canada.
The Conference Board of Canada's index of consumer confidence has been ongoing since 1980. It is constructed from responses to four attitudinal questions posed to a random sample of Canadian households. Those surveyed are asked to give their views about their households' current and expected financial positions and the short-term employment outlook. They are also asked to assess whether now is a good or a bad time to make a major purchase such as a house, car or other big-ticket items.
Consumer confidence index in Indonesia.
Consumer Survey-Bank Indonesia (CS-BI) is a monthly survey that has been conducted since October 1999 by Bank Indonesia. The survey represents the consumer confidence about the overall economic condition, general price level, household income, and consumption plans three and six months ahead. Since January 2007, the survey is conducted with approximately 4,600 household respondents (stratified random sampling) in 18 cities: Jakarta, Bandung, Semarang, Surabaya, Medan, Makassar, Bandar Lampung, Palembang, Banjarmasin, Padang, Pontianak, Samarinda, Manado, Denpasar, Mataram, Pangkal Pinang, Ambon, and Banten. At a significance level of 99%, the survey has a sampling error of 2%. Data canvassing run through interviews by phone and direct visits in particular cities that is based on rotational system. The Balance Score Method (net balance + 100) has been adopted to construct the index, where the index above 100 points indicates optimism (positive responses) and vice versa. The consumer confidence index (CCI), is an average of the current economic condition index (CECI) and consumer expectation index (CEI).
The CECI is made up of the average of current condition of several factors compared to six months ago
The CEI is made up from the average of future prospects of several factors 
Other sources.
Danareksa conducts a monthly consumer survey to produce the Consumer Confidence Index.

</doc>
<doc id="65948" url="https://en.wikipedia.org/wiki?curid=65948" title="Disulfide">
Disulfide

In chemistry and biology a disulfide refers to a functional group with the general structure "R–S–S–R". The linkage is also called an SS-bond or a disulfide bridge and is usually derived by the coupling of two thiol groups. In formal terms, the connection is a persulfide, in analogy to its congener, peroxide ("R–O–O–R"), but this terminology is rarely used, except in reference to hydrodisulfides ("R–S–S–H" or "H–S–S–H" compounds).
In inorganic chemistry disulfide usually refers to the corresponding anion , or −S–S−, for example in disulfur dichloride.
Organic disulfides.
Properties.
The disulfide bonds are strong, with a typical bond dissociation energy of 60 kcal/mol (251 kJ mol−1). However, being about 40% weaker than C–C and C–H bonds, the disulfide bond is often the "weak link" in many molecules. Furthermore, reflecting the polarizability of divalent sulfur, the S–S bond is susceptible to scission by polar reagents, both electrophiles and especially nucleophiles:
The disulfide bond is about 2.05 Å in length, about 0.5 Å longer than a C–C bond. Rotation about the S–S axis is subject to a low barrier. Disulfides show a distinct preference for dihedral angles approaching 90°. When the angle approaches 0° or 180°, then the disulfide is a significantly better oxidant.
Disulfides where the two R groups are the same are called symmetric, examples being diphenyl disulfide and dimethyl disulfide. When the two R groups are not identical, the compound is said to be an asymmetric or mixed disulfide.
Although the hydrogenation of disulfides is usually not practical, the equilibrium constant for the reaction provides a measure of the standard redox potential for disulfides:
This value is about −250 mV vs NHE (pH = 7). By comparison, the standard reduction potential for ferrodoxins is about −430 mV.
Synthesis.
Disulfide bonds are usually formed from the oxidation of sulfhydryl (–SH) groups, especially in biological contexts. The transformation is depicted as follows:
A variety of oxidants promote this reaction including air and hydrogen peroxide. Such reactions are thought to proceed via sulfenic acid intermediates. In the laboratory, iodine in the presence of base is commonly employed to oxidize thiols to disulfides. Several metals, such as copper(II) and iron(III) complexes affect this reaction. Alternatively, disulfide bonds in proteins often formed by thiol-disulfide exchange:
Such reactions are mediated by enzymes in some cases and in other cases are under equilibrium control, especially in the presence of a catalytic amount of base.
The alkylation of alkali metal di- and polysulfides gives disulfides. "Thiokol" polymers arise when sodium polysulfide is treated with an alkyl dihalide. In the converse reaction, carbanionic reagents react with elemental sulfur to afford mixtures of the thioether, disulfide, and higher polysulfides. These reactions are often unselective but can be optimized for specific applications.
Many specialized methods have been developed for forming disulfides, usually for applications in organic synthesis. Reagents that deliver the equivalent of "RS+" react with thiols to give asymmetrical disulfides:
Reactions.
The most important aspect of disulfide bonds is their cleavage, which occurs via reduction. A variety of reductants can be used. In biochemistry, thiols such as mercaptoethanol (b-ME) or dithiothreitol (DTT) serve as reductants; the thiol reagents are used in excess to drive the equilibrium to the right:
The reductant Tris(2-carboxyethyl)phosphine (TCEP) is useful, beside being odorless compared to b-ME and DTT, because it is selective, working at both alkaline and acidic conditions (unlike DTT), is more hydrophilic and more resistant to oxidation in air. Furthermore, it is often not needed to remove TCEP before modification of protein thiols.
In organic synthesis, hydride agents are typically employed for scission of disulfides, such as sodium borohydride. More aggressive, alkali metals will effect this reaction:
These reactions are often followed by protonation of the resulting metal thiolate:
Thiol–disulfide exchange is a chemical reaction in which a thiolate group –S− attacks a sulfur atom of a disulfide bond –S–S–. The original disulfide bond is broken, and its other sulfur atom (green atom in Figure 1) is released as a new thiolate, carrying away the negative charge. Meanwhile, a new disulfide bond forms between the attacking thiolate (red atom in Figure 1) and the original sulfur atom (blue atom in Figure 1).
Thiolates, not thiols, attack disulfide bonds. Hence, thiol–disulfide exchange is inhibited at low pH (typically, below 8) where the protonated thiol form is favored relative to the deprotonated thiolate form. (The p"K"a of a typical thiol group is roughly 8.3, but can vary due to its environment.)
Thiol–disulfide exchange is the principal reaction by which disulfide bonds are formed and rearranged in a protein. The rearrangement of disulfide bonds within a protein generally occurs via intra-protein thiol–disulfide exchange reactions; a thiolate group of a cysteine residue attacks one of the protein's own disulfide bonds. This process of disulfide rearrangement (known as "disulfide shuffling") does not change the number of disulfide bonds within a protein, merely their location (i.e., which cysteines are bonded). Disulfide reshuffling is generally much faster than oxidation/reduction reactions, which change the number of disulfide bonds within a protein. The oxidation and reduction of protein disulfide bonds "in vitro" also generally occurs via thiol–disulfide exchange reactions. Typically, the thiolate of a redox reagent such as glutathione or dithiothreitol attacks the disulfide bond on a protein forming a "mixed disulfide bond" between the protein and the reagent. This mixed disulfide bond when attacked by another thiolate from the reagent, leaves the cysteine oxidized. In effect, the disulfide bond is transferred from the protein to the reagent in two steps, both thiol–disulfide exchange reactions.
The "in vivo" oxidation and reduction of protein disulfide bonds by thiol–disulfide exchange is facilitated by a protein called thioredoxin. This small protein, essential in all known organisms, contains two cysteine amino acid residues in a vicinal arrangement (i.e., next to each other), which allows it to form an internal disulfide bond, or disulfide bonds with other proteins. As such, it can be used as a repository of reduced or oxidized disulfide bond moieties.
Many specialized organic reactions have been developed for disulfides, again mainly associated with the scission of the S–S bond, which is usually the weakest bond in a molecule. In the Zincke disulfide cleavage reactions, disulfides are cleaved to give the to a sulfenyl halide by reaction with bromine or chlorine.
Occurrence in proteins.
Disulfide bonds play an important role in the folding and stability of some proteins, usually proteins secreted to the extracellular medium. Since most cellular compartments are reducing environments, in general, disulfide bonds are unstable in the cytosol, with some exceptions as noted below, unless a sulfhydryl oxidase is present.
Disulfide bonds in proteins are formed between the thiol groups of cysteine residues by the process of oxidative folding. The other sulfur-containing amino acid, methionine, cannot form disulfide bonds. A disulfide bond is typically denoted by hyphenating the abbreviations for cysteine, e.g., when referring to Ribonuclease A the "Cys26–Cys84 disulfide bond", or the "26–84 disulfide bond", or most simply as "C26–C84" where the disulfide bond is understood and does not need to be mentioned. The prototype of a protein disulfide bond is the two-amino-acid peptide cystine, which is composed of two cysteine amino acids joined by a disulfide bond (shown in Figure 2 in its unionized form). The structure of a disulfide bond can be described by its "χ"ss dihedral angle between the Cβ–Sγ–Sγ–Cβ atoms, which is usually close to ±90°.
The disulfide bond stabilizes the folded form of a protein in several ways:
A "disulfide species" is a particular pairing of cysteines in a disulfide-bonded protein and is usually depicted by listing the disulfide bonds in parentheses, e.g., the "(26–84, 58–110) disulfide species". A "disulfide ensemble" is a grouping of all disulfide species with the same number of disulfide bonds, and is usually denoted as the 1S ensemble, the 2S ensemble, etc. for disulfide species having one, two, etc. disulfide bonds. Thus, the (26–84) disulfide species belongs to the 1S ensemble, whereas the (26–84, 58–110) species belongs to the 2S ensemble. The single species with no disulfide bonds is usually denoted as R for "fully reduced". Under typical conditions, disulfide reshuffling is much faster than the formation of new disulfide bonds or their reduction; hence, the disulfide species within an ensemble equilibrate more quickly than between ensembles.
The native form of a protein is usually a single disulfide species, although some proteins may cycle between a few disulfide states as part of their function, e.g., thioredoxin. In proteins with more than two cysteines, non-native disulfide species may be formed, which are almost always misfolded. As the number of cysteines increases, the number of nonnative species increases factorially.
Predicting disulfide abundance.
The number of ways "i" in which "p" disulfide bonds can be formed from "n" cysteine residues present in a protein is given by the formula
Here, 
The above formula is the most general relation which can be used to calculate the number of possible disulfide bond isomers (or connectivities) when "n" is either even or odd, and when all or only some of the cysteines are involved in the formation of disulfide bonds.
However, many of the naturally occurring proteins that have disulfide bonds possess an even number of cysteines with all of the cysteines participating in the formation of disulfide bonds. For this specific case, "n" is an even number and "p" is equal to .
Substituting the value of "p", the above formula for the possible number of disulfide bond connectivities simplifies to:
For this particular case ("n" is even and all cysteines form disulfide bonds), a formula which is more easier to remember is given by:
Both of the above relations hold good for the proteins which have an even number of cysteines and all the cysteines are involved in the formation of disulfide bonds. Both of the above formulae are derived using the same logic and essentially represent a simplification of the same starting formula.
As a specific example for the above case, an eight-cysteine protein such as ribonuclease A can form 105 different four-disulfide species when all the cysteines are involved in the formation of disulfide bonds. Here "n" = 8 and "p" = 4.
So, here
Only one of the 105 possible isomers is the native disulfide species. Isomerases have been identified that catalyze the interconversion of disulfide species, accelerating the formation of the native disulfide species.
Disulfide species that have only native disulfide bonds (but not all of them) are denoted by "des" followed by the lacking native disulfide bond(s) in square brackets. For example, the des[40–95] disulfide species has all the native disulfide bonds except that between cysteines 40 and 95. Disulfide species that lack one native disulfide bond are frequently folded, in particular, if the missing disulfide bond is exposed to solvent in the folded, native protein.
In order to analyze the structure of proteins, it is often necessary to break disulfide bonds. This reduction of disulfide bonds can be accomplished by treatment with 2-mercaptoethanol, dithiothreitol, or tris(2-carboxyethyl)phosphine.
In prokaryotes and archaea.
Disulfide bonds play an important protective role for bacteria as a reversible switch that turns a protein on or off when bacterial cells are exposed to oxidation reactions. Hydrogen peroxide (H2O2) in particular could severely damage DNA and kill the bacterium at low concentrations if not for the protective action of the SS-bond. Archaea typically have fewer disulfides than higher organisms.
In eukaryotes.
In eukaryotic cells, in general, stable disulfide bonds are formed in the lumen of the RER (rough endoplasmic reticulum) and the mitochondrial intermembrane space but not in the cytosol. This is due to the more oxidizing environment of the aforementioned compartments and more reducing environment of the cytosol (see glutathione). Thus disulfide bonds are mostly found in secretory proteins, lysosomal proteins, and the exoplasmic domains of membrane proteins.
Notable exceptions to this rule include a number of cytosolic proteins which have cysteine residues in proximity to each other that function as oxidation sensors or redox catalysts; when the reductive potential of the cell fails, they oxidize and trigger cellular response mechanisms. "Vaccinia" virus also produces cytosolic proteins and peptides that have many disulfide bonds; although the reason for this is unknown presumably they have protective effects against intracellular proteolysis machinery.
Disulfide bonds are also formed within and between protamines in the sperm chromatin of many mammalian species.
Disulfides in regulatory proteins.
As disulfide bonds can be reversibly reduced and re-oxidized, the redox state of these bonds has evolved into a signaling element. In chloroplasts, for example, the enzymatic reduction of disulfide bonds has been linked to the control of numerous metabolic pathways as well as gene expression. The reductive signaling activity has been shown, thus far, to be carried by the ferredoxin thioredoxin system, channeling electrons from the light reactions of photosystem I to catalytically reduce disulfides in regulated proteins in a light dependent manner. In this way chloroplasts adjust the activity of key processes such as the Calvin–Benson cycle, starch degradation, ATP production and gene expression according to light intensity.
In hair and feathers.
Over 90% of the dry weight of hair comprises proteins called keratins, which have a high disulfide content, from the amino acid cysteine. The robustness conferred in part by disulfide linkages is illustrated by the recovery of virtually intact hair from ancient Egyptian tombs. Feathers have similar keratins and are extremely resistant to protein digestive enzymes. Different parts of the hair and feather have different cysteine levels, leading to harder or softer material. Manipulating disulfide bonds in hair is the basis for the permanent wave in hairstyling. Reagents that affect the making and breaking of S–S bonds are key, e.g., ammonium thioglycolate. The high disulfide content of feathers dictates the high sulfur content of bird eggs. The high sulfur content of hair and feathers contributes to the disagreeable odor that results when they are burned.
Inorganic disulfides.
The disulfide anion is , or −S–S−. Sulfur is usually assigned to the reduced oxidation number −2, described as S2− and called sulfide. It has the electron configuration of a noble gas (argon). In disulfide, sulfur is only reduced to a state with oxidation number −1. Its configuration then resembles that of a chlorine atom. It thus tends to form a covalent bond with another S− center to form group. Oxygen also behaves similarly, e.g. in peroxides such as H2O2. Examples:
In industry.
Disulfide and (polysulfide) bonds are the crosslinking groups that result from the vulcanization of rubber. In analogy to the role of disulfides in proteins, the S–S linkages in rubber are crosslinkers, and strongly affect the rheology of the material.
Related compounds.
Thiosulfoxides are orthogonally isomeric with disulfides, having the second sulfur branching from the first and not partaking in a continuous chain, i.e. >S=S rather than –S–S–.
Disulfide bonds are analogous but more common than related peroxides and diselenide bonds. Intermediate compounds of these also exist, for example, thioperoxides, also known as oxadisulfide bonds, have formula R1OSR2 (equivalently R2SOR1). These are isomeric to sulfoxides in a similar manner to the above; i.e. >S=O rather than –S–O–.
Thiuram disulfides, with the formula (R2NC(S)S)2, are disulfides but they behave distinctly because of the thiocarbonyl group.
Compounds with three sulfur atoms, e.g., CH3S–S–SCH3, are called trisulfides, or trisulfide bonds.
Misnomers.
Disulfide is also used to refer to compounds that contain two sulfide (S2−) centers. The compound carbon disulfide, CS2 is described with the structural formula i.e. S=C=S. This molecule is not a disulfide in the sense that it lacks a S-S bond. Similarly, molybdenum disulfide, MoS2, is not a disulfide in the sense again that its sulfur atoms are not linked.

</doc>
<doc id="65951" url="https://en.wikipedia.org/wiki?curid=65951" title="Fielding (cricket)">
Fielding (cricket)

Fielding in the sport of cricket is the action of fielders in collecting the ball after it is struck by the batsman, in such a way either to limit the number of runs that the batsman scores or to get the batsman out by catching the ball in flight or running the batsman out. Cricket fielding position can be broken down into offside and legside parts of the field.
A "fielder" or "fieldsman" may field the ball with any part of his person. However, if while the ball is in play he wilfully fields it otherwise (e.g. by using his hat), the ball becomes dead and 5 penalty runs are awarded to the batting side unless the ball previously struck a batsman not attempting to hit or avoid the ball. Most of the rules covering fielders are in Law 41 of the Laws of cricket.
In the early days of Test cricket, fielding was not a priority and many players were sloppy when it came to fielding. With the advent of One Day International matches, fielding became more professional as saving runs became more important. A good fielding side can often save 30+ runs in the course of an ODI innings.
Fielding position names and locations.
Since there are only 11 players on a team, one of whom is the bowler, and usually another as the wicket-keeper, at most nine other fielding positions can be used at any given time. Which positions are filled by players and which remain vacant is a tactical decision made by the captain of the fielding team. The captain (usually in consultation with the bowler and sometimes other members of the team) may move players between fielding positions at any time except when a bowler is in the act of bowling to a batsman.
There are a number of named basic fielding positions, some of which are employed very commonly and others that are used less often. However, fielding positions are not fixed, and fielders can be placed in positions that differ from the basic positions. The nomenclature of the positions' names is somewhat esoteric, but roughly follow a system of polar coordinates – one word (leg, cover, mid-wicket) specifies the angle from the batsman, and is optionally preceded by an adjective describing the distance from the batsman (silly, short, deep or long). Words such as "backward", "forward", or "square" can further indicate the angle.
The image shows the location of most of the named fielding positions. This image assumes the batsman is right-handed. The area to the left of a right-handed batsman (from the batsman's point of view – facing the bowler) is called the "leg side" or "on side", while that to the right is the "off side". If the batsman is left-handed, the leg and off sides are reversed and the fielding positions are a mirror image of those shown.
Catching positions.
Some fielding positions are used offensively. That is, players are put there with the main aim being to catch out the batsman rather than to stop or slow down the scoring of runs. These positions include Slip (often there are multiple slips next to each other, designated "First slip", "Second slip", "Third slip", etc., numbered outwards from the wicket-keeper—collectively known as the "slips cordon") meant to catch balls that just edge off the bat; Gully; Fly slip; Leg slip; Leg gully; the "short" and "silly" positions. "Short leg", also known as "bat pad", is a position specifically intended to catch balls that unintentionally strike the bat and leg pad, and thus end up only a metre or two to the leg side.
Other positions.
Other positions worth noting include:
Also the bowler, after delivering the ball, must avoid running on the pitch so usually ends up fielding near silly mid on or silly mid off, but somewhat closer to the pitch.
Modifiers.
Additionally, commentators or spectators discussing the details of field placement will often use the terms for descriptive phrases such as "gully is a bit wider than normal" (meaning he is more to the side than normal) or "mid off is standing too deep, he should come in shorter" (meaning he is too far away and should be positioned closer to the batsman).
Restrictions on field placement.
Fielders may be placed anywhere on the field, subject to the following rules. At the time the ball is bowled:
If any of these rules is violated, an umpire will call the delivery a no ball. Additionally a player may not make any significant movement after the ball comes into play and before the ball reaches the striker. If this happens, an umpire will call and signal 'dead ball'. For close fielders anything other than minor adjustments to stance or position in relation to the striker is significant. In the outfield, fielders may move in towards the striker or striker's wicket; indeed, they usually do. However, anything other than slight movement off line or away from the striker is to be considered significant.
Tactics of field placement.
With only nine fielders (apart from the bowler and wicket-keeper), the captain of the fielding team must decide which fielding positions to cover, and which to leave vacant. The placement of fielders is one of the major tactical considerations for the fielding captain.
Attacking and defending.
The main decision for a fielding captain is to strike a balance between setting an "attacking" field and a "defensive" field. An attacking field is one in which fielders are positioned in such a way that they are likely to take catches, and thus likely to get the batsman out. Such a field generally involves having many fielders close to the batsman, especially in either slip short leg positions.
A defensive field is one in which most of the field is covered by a fielder; the batsman will therefore find it hard to score large numbers of runs. This generally involves having many fielders far from the batsman and in front of him, in the positions where he is most likely to hit the ball.
Many elements govern the decisions on field placements, including: the tactical situation in the match; which bowler is bowling; how long the batsman has been in; the wear on the ball; the state of the wicket; the light; or even how close you are to an interval in play.
Some general principles:
Off- and leg-side fields.
Another consideration when setting a field is how many fielders to have on each side of the pitch. With nine fielders to place, the division must necessarily be unequal, but the degree of inequality varies.
When describing a field setting, the numbers of fielders on the off side and leg side are often abbreviated into a shortened form, with the off side number quoted first. For example, a "5–4 field" means 5 fielders on the off side and 4 on the leg side.
Usually, most fielders are placed on the off side. This is because most bowlers tend to concentrate the line of their deliveries on or outside the off stump, so most shots are hit into the off side.
When attacking, there may be 3 or 4 slips and 1 or 2 gullies, potentially using up to six fielders in that region alone. This would typically be accompanied by a mid off, mid on, and fine leg, making it a 7–2 field. Although there are only two fielders on the leg side, they should get relatively little work as long as the bowlers maintain a line outside off stump. This type of field leaves large gaps in front of the wicket, and is used to entice the batsmen to attack there, with the hope that they make a misjudgment and edge the ball to the catchers waiting behind them.
As fields get progressively more defensive, fielders will move out of the slip and gully area to cover more of the field, leading to 6–3 and 5–4 fields.
If a bowler, usually a leg spin bowler, decides to attack the batsman's legs in an attempt to force a stumping, bowl him behind his legs, or induce a catch on the leg side, the field may stack 4–5 towards the leg side. It is unusual to see more than 5 fielders on the leg side, because of the restriction that there must be no more than two fielders placed behind square leg. 
Sometimes a spinner will bowl leg theory and have seven fielders on the leg side, and will bowl significantly wide of the leg stump to prevent scoring. Often the ball is so wide that the batsman cannot hit the ball straight of mid-on while standing still, and cannot hit to the off side unless they try unorthodox and risky shots such as a reverse sweep or pull, or switch their handedness. The batsman can back away to the leg side to hit through the off side, but can expose their stumps in doing so.
The reverse tactic can be used, by fast and slow bowlers alike, by placing seven or eight fielders on the off side and bowling far outside off stump. The batsman can safely allow the ball to pass without fear of it hitting the stumps, but will not score. If they want to score they will have to try and risk an edge to a wide ball and hit through the packed off side, or trying and drag the ball from far outside the stumps to the sparsely-populated leg side.
Another attacking placement on the leg side is the "leg side trap", which involves placing fielders near the boundary at deep square and backward square leg and bowling bouncers to try to induce the batsman to hook the ball into the air. For slower bowlers, the leg trap fieldsmen tend to be placed within 10–15 m from the bat behind square, to catch leg glances and sweeps.
Protective equipment.
No member of the fielding side other than the wicket-keeper may wear gloves or external leg guards, though fielders (in particular players fielding near to the bat) may also wear shin protectors, groin protectors ('boxes') and chest protectors beneath their clothing. Apart from the wicket-keeper, protection for the hand or fingers may be worn only with the consent of the umpires.
Fielders are permitted to wear a helmet and face guard. This is usually employed in a position such as silly point or silly mid-wicket, where proximity to the batsman gives little time to avoid a shot directly at their head. Due to the discomfort and risk of being hit, the duty of fielding "under the helmet" or "under the lid" is often delegated to the most junior member of the team. If the helmet is only being used for overs from one end, it will be placed behind the wicketkeeper when not in use. Some grounds have purpose-built temporary storage in the form of a cavity beneath the pitch, approximately 1m x 1m x 1m in size, accessed through a hatch flush with the grass, which can be used for storing a helmet, shin pads or drinks for the fielding side. 5 penalty runs are awarded to the batting side should the ball touch a fielder's headgear whilst it is not being worn unless the ball previously struck a batsman not attempting to hit or avoid the ball. This rule was introduced in the 19th century to prevent the unfair practice of a fielder using a hat (often a top hat) to take a catch.
As cricket balls are hard and can travel at high speeds off the bat, protective equipment is recommended to prevent injury. There have been a few recorded deaths in cricket, but they are extremely rare, and not always related to fielding.
Fielding skills.
Fielding in cricket requires a range of skills. 
Close catchers require the ability to be able to take quick reaction catches with a high degree of consistency. This can require considerable efforts of concentration as a catcher may only be required to take one catch in an entire game, but his success in taking that catch may have a considerable effect on the outcome of the match.
Infielders field between 20 to 40 yards away from the batsman. The ball will often be hit at them extremely hard, and they require excellent athleticism as well as courage in stopping it from passing them. Infield catches range from simple, slow moving chances known as "dollies" to hard hit balls that require a spectacular diving catch. Finally, infielders are the main source of run outs in a game of cricket, and their ability to get to the ball quickly, throw it straight and hard and make a direct hit on the stumps is an important skill.
Outfielders field furthest from the bat, typically right on the boundary edge. Their main role is to prevent the ball from going over the boundary and scoring four or six runs. They need good footspeed to be able to get around the field quickly, and a strong arm to be able to make the 50–80-yard throw. Outfielders also often have to catch high hit balls that go over the infield.
Fielding specialities.
Many cricketers are particularly adept in one fielding position and will usually be found there:
However, players are rarely selected purely because of their fielding skills, and all players are expected to win their place in the team as either a specialist batsman or bowler (or both). This even applies to wicket keepers, who are generally expected to be competent middle-order batsmen.
Throwing a cricket ball.
There have been many competitions for throwing a cricket ball the furthest distance, particularly in the earlier years of the game. Wisden describes how the record was set around 1882, by one Robert Percival at Durham Sands Racecourse, at 140 yards and two feet (128.7 m). Former Essex all-rounder Ian Pont threw a ball 138 yards (126.19 m) in Cape Town in 1981. There are unconfirmed reports that Jānis Lūsis, the non-cricketer Soviet javelin thrower, who won the Olympic gold medal in 1968, once threw a ball 150 yards.
Specialist fielding coaches.
The use of specialist fielding coaches has become more prevalent in recent years, following the trend of specialist batting & bowling coaches within professional cricket. The most well known specialist fielding coaches currently working in cricket are:

</doc>
<doc id="65952" url="https://en.wikipedia.org/wiki?curid=65952" title="Antigonae">
Antigonae

Antigonae ("Antigone"), written by Carl Orff, was first presented on 9 August 1949 under the direction of Ferenc Fricsay in the Felsenreitschule, Salzburg, Austria. Antigonae is in Orff's words a "musical setting" for the Greek tragedy by Sophocles of the same name. However, it functions as an opera.
Orff used the German translation of Sophocles' play by Friedrich Hölderlin (1770–1843). The original play was written in 442 BC, and the German translation copies faithfully the mood and movement of Greek tragedy.
The music.
With this work Orff drew a line in his musical output, setting up a demarcation between pre-"Antigonae" and post-"Antigonae" style. Hölderlin's translation into lines of ecstatic German inspired the declamatory technique Orff uses for the first time in much of "Antigonae". It pre-dates a similar style of the minimalist school by about 50 years. In this way Orff creates unusual sound effects that captures both the dramatic and psychological setting of the original Greek tragedy with emotional color ranging from the ecstatic to the orgiastic. Much of the singing is performed a cappella.
Frequently an ostinato in the orchestra builds up an almost unbearable tension which is resolved only in the final bars of the piece. Orff frequently uses the technique called Singstimmen, which is half way between singing and speaking, somewhat like Schönberg's Sprechgesang, but still within the tonal language of work.
The sense of antiquity is often enhanced when the text is treated psalmodically in a manner resembling Gregorian Chant. Another early device found in Antigone is the melisma, where many notes are assigned to a single syllable, which is found as well in the music of other ancient and modern cultures.
The structure of the work, its heavy emotional content, its novel fabrics of sound, all demand more of the listener than required in the usual opera performance. While "Antigone" has never been very popular, it has set new standards for the orchestra, the singers and the committed listener.
Synopsis.
The opera begins in the early morning following a battle in Thebes between the armies of the two sons of Oedipus: Eteocles and Polynices. King Kreon (Creon), who ascended the throne of Thebes after both brothers are killed in battle, decrees that Polynices is not to be buried. Antigonae, his sister, defies the order, but is caught. Kreon decrees that she be buried alive in spite of the fact that she is betrothed to his son, Haemon. The gods, through the blind prophet Tiresias, express their disapproval of Kreon's decision, which convinces him to rescind his order, and he goes to bury Polynices. However, Antigonae has already hanged herself rather than be buried alive. When Kreon arrives at the tomb where she was to be interred, his son, Haemon, attacks him and then kills himself. Finally, when Kreon's wife, Eurydice, is informed of Haemon's and Antigonae's death she, too, takes her own life. At the end of the play, and the opera, Kreon is the only principal left alive.
Instrumentation.
According to the score, which is published by Schott Music, "Antigonae" is scored for an unusual orchestra with a strong percussion section. This orchestra is to be well screened from the audience when the opera is performed.
(*) At several points, the strings are struck with various items, including Wooden Drum sticks on the higher strings, Timpani sticks on the lower strings, and also a Plectrum.
The percussion section requires 10-15 players to perform on the following instruments:
(*) These are Orff Schulwerk instruments.
For the percussion, Carl Orff insisted on using the right kind of instruments. The two bells must be of typical shape; tubular bells and "plate" bells are not acceptable. The castanets must be of the type without handles, e.g. those only connected together via a string.
Carl Orff also gave extensive performance directions that should be taken into account at performances. For instance, some of the 12 pianists switch to other pianos at several sections. In another place, the entire trumpet section should move to just behind the stage, in action, before returning into the orchestra.

</doc>
<doc id="65953" url="https://en.wikipedia.org/wiki?curid=65953" title="Antigone (Sophocles play)">
Antigone (Sophocles play)

Antigone ( ; ) is a tragedy by Sophocles written in or before 441 BC.
It is the third of the three Theban plays but was the first written, chronologically. The play expands on the Theban legend that predated it and picks up where Aeschylus' "Seven Against Thebes" ends.
Synopsis.
In the beginning of the play, two brothers leading opposite sides in Thebes' civil war died fighting each other for the throne. Creon, the new ruler of Thebes, has decided that Eteocles will be honored and Polyneices will be in public shame. The rebel brother's body will not be sanctified by holy rites, and will lie unburied on the battlefield, prey for carrion animals like worms and vultures, the harshest punishment at the time. Antigone and Ismene are the sisters of the dead Polyneices and Eteocles. In the opening of the play, Antigone brings Ismene outside the palace gates late at night for a secret meeting: Antigone wants to bury Polyneices' body, in defiance of Creon's edict. Ismene refuses to help her, fearing the death penalty, but she is unable to stop Antigone from going to bury her brother herself, causing Antigone to disown her out of anger.
Creon enters, along with the Chorus of Theban Elders. He seeks their support in the days to come, and in particular wants them to back his edict regarding the disposal of Polyneices' body. The Chorus of Elders pledges their support. A Sentry enters, fearfully reporting that the body has been given funeral rites and a symbolic burial with a thin covering of earth. A furious Creon orders the Sentry to find the culprit or face death himself. The Sentry leaves and the Chorus sings about honouring the gods, but after a short absence he returns, bringing Antigone with him. The Sentry explains that the watchmen uncovered Polyneices' body, and then caught Antigone as she returned to repeat the funeral rituals. Creon questions her after sending the Sentry away, and she does not deny what she has done. She argues unflinchingly with Creon about the morality of the edict and the morality of her actions. Creon becomes furious, and, thinking Ismene must have known of Antigone's plan, seeing her upset, summons the girl. Ismene tries to confess falsely to the crime, wishing to die alongside her sister, but Antigone will not have it. Creon orders that the two women be temporarily imprisoned.
Haemon, Creon's son, enters to pledge allegiance to his father, even though he is engaged to Antigone. He initially seems willing to forsake Antigone, but when Haemon gently tries to persuade his father to spare Antigone, claiming that 'under cover of darkness the city mourns for the girl', the discussion deteriorates and the two men are soon bitterly insulting each other. Haemon leaves, vowing never to see Creon again.
Creon decides to spare Ismene and to bury Antigone alive in a cave. She is brought out of the house, and she bewails her fate and defends her actions one last time. She is taken away to her living tomb, with the Chorus expressing great sorrow for what is going to happen to her.
Tiresias, the blind prophet, enters. Tiresias warns Creon that Polyneices should now be urgently buried because the gods are displeased, refusing to accept any sacrifices or prayers from Thebes. Creon accuses Tiresias of being corrupt. Tiresias responds that because of Creon's mistakes, he will lose "a son of own loins" for the crimes of leaving Polyneices unburied and putting Antigone into the earth (he does not say that Antigone should not be condemned to death, only that it is improper to keep a living body underneath the earth). All of Greece will despise him, and the sacrificial offerings of Thebes will not be accepted by the gods. The Chorus, terrified, asks Creon to take their advice. He assents, and they tell him that he should free Antigone and bury Polyneices. Creon, shaken, agrees to do it. He leaves with a retinue of men to help him right his previous mistakes. The Chorus delivers a choral ode to the god Dionysus (god of wine and of the theater; this part is the offering to their patron god), and then a Messenger enters to tell them that Antigone has killed herself. Eurydice, Creon's wife and Haemon's mother, enters and asks the Messenger to tell her everything. The Messenger reports that Creon saw to the burial of Polynices. Creon then proceeds to the tomb to free Antigone. There he found Haemon lamenting over the dead Antigone, who had hanged herself. After unsuccessfully attempting to stab Creon, Haemon stabs himself. Having listened to the Messenger's account, Eurydice disappears into the palace.
Creon enters, carrying Haemon's body. He understands that his own actions have caused these events and blames himself. A Second Messenger arrives to tell Creon and the Chorus that Eurydice has killed herself. With her last breath, she cursed her husband. Creon blames himself for everything that has happened, and, a broken man, he asks his servants to help him inside. The order he valued so much has been protected, and he is still the king, but he has acted against the gods and lost his children and his wife as a result. The Chorus closes by saying that although the gods punish the proud, punishment brings wisdom.
Characters.
Antigone, compared to her beautiful and docile sister, is portrayed as a heroine who recognizes her familial duty. Her dialogues with Ismene reveal her to be as stubborn as her uncle. In her, the ideal of the female character is boldly outlined. She defies Creon’s decree despite the consequences she may face, in order to honor her deceased brother.
Ismene serves as a foil for Antigone, presenting the contrast in their respective responses to the royal decree. Considered the beautiful one, she is more lawful and obedient to authority. She hesitates to bury Polyneices because she fears Creon.
Creon is the current King of Thebes, who views law as the guarantor of personal happiness. He can also be seen as a tragic hero, losing everything for upholding what he believed was right. Even when he is forced to amend his decree to please the gods, he first tends to the dead Polyneices before releasing Antigone.
Eurydice of Thebes is the Queen of Thebes and Creon’s wife. She appears towards the end and only to hear confirmation of her son Haemon’s death. In her grief, she commits suicide, cursing Creon whom she blames for her son’s death.
Haemon is the son of Creon and Eurydice, betrothed to Antigone. Proved to be more reasonable than Creon, he attempts to reason with his father for the sake of Antigone. However, when Creon refuses to listen to him, Haemon leaves angrily and shouts he will never see him again. He commits suicide after finding Antigone dead.
Tiresias is the blind prophet whose prediction brings about the eventual proper burial of Polyneices. Portrayed as wise and full of reason, Tiresias attempts to warn Creon of his foolishness and tells him the gods are angry. He manages to convince Creon, but is too late to save the impetuous Antigone.
The Chorus, a group of elderly Theban men, is at first deferential to the king. Their purpose is to comment on the action in the play and add to the suspense and emotions, as well as connecting the story to myths. As the play progresses they counsel Creon to be more moderate. Their pleading persuades Creon to spare Ismene. They also advise Creon to take Tiresias's advice.
Historical context.
"Antigone" was written at a time of national fervor. In 441 BC, shortly after the play was performed, Sophocles was appointed as one of the ten generals to lead a military expedition against Samos. It is striking that a prominent play in a time of such imperialism contains little political propaganda, no impassioned apostrophe, and, with the exception of the epiklerate (the right of the daughter to continue her dead father's lineage), and arguments against anarchy, makes no contemporary allusion or passing reference to Athens. Rather than become sidetracked with the issues of the time, "Antigone" remains focused on the characters and themes within the play. It does, however, expose the dangers of the absolute ruler, or tyrant, in the person of Creon, a king to whom few will speak freely and openly their true opinions, and who therefore makes the grievous error of condemning Antigone, an act which he pitifully regrets in the play's final lines. Athenians, proud of their democratic tradition, would have identified his error in the many lines of dialogue which emphasize that the people of Thebes believe he is wrong, but have no voice to tell him so. Athenians would identify the folly of tyranny.
Notable features.
The Chorus in "Antigone" departs significantly from the chorus in Aeschylus' "Seven Against Thebes", the play of which "Antigone" is a continuation. The chorus in "Seven Against Thebes" is largely supportive of Antigone's decision to bury her brother. Here, the chorus is composed of old men who are largely unwilling to see civil disobedience in a positive light. The chorus also represents a typical difference in Sophocles' plays from those of both Aeschylus and Euripides. A chorus of Aeschylus' almost always continues or intensifies the moral nature of the play, while one of Euripides' frequently strays far from the main moral theme. The chorus in "Antigone" lies somewhere in between; it remains within the general moral and the immediate scene, but allows itself to be carried away from the occasion or the initial reason for speaking.
Significance and interpretation.
"Antigone" deals with three main questions:
Creon was perfectly justified in issuing the edict which deprived funeral rites to Polynices, who led a foreign army to lay siege to his own city. Creon, as head of the state, viewed exemplary punishment as appropriate. Antigone had a right to assert that in defying Creon's edict she was loyal to an unwritten law which had a higher sanction. Once the initial premises behind the characters in "Antigone" have been established, the action of the play moves steadily and inevitably towards the outcome. Once Creon has discovered that Antigone buried her brother against his orders, the ensuing discussion of her fate is devoid of arguments for mercy because of youth or sisterly love from the Chorus, Haemon or Antigone herself. Most of the arguments to save her center on a debate over which course adheres best to strict justice.
Both Antigone and Creon claim divine sanction for their actions; but Tiresias the prophet supports Antigone's claim that the gods demand Polynices' burial. It is not until the interview with Tiresias that Creon transgresses in act and is guilty of sin. He had had no divine intimation before that his edict was displeasing to the Gods and against their will. He is here warned that it is, but he defends it and insults the prophet of the Gods. This is his sin, and it is this which leads to his punishment. The terrible calamities, then, which overtake Creon are not the result of his exalting the law of the state over the unwritten and divine law which Antigone vindicates, but his intemperance which led him to disregard the warnings of Tiresias until it was too late. This is emphasized by the Chorus in the lines which conclude the play.
The German poet Friedrich Hölderlin, whose translation of the play had strong impact on Heidegger's reading, brings out a more subtle reading of the play: he focuses on Antigone's legal and political status within the palace, her privilege to be the hearth (according to the legal instrument of the epiklerate) and thus protected by Zeus. According to the legal practice of classical Athens, Creon is obliged to marry his closest relative (Haemon) to the late king's daughter in an inverted marriage rite, which would oblige Haemon to produce a son and heir for his dead father in law. Creon would be deprived of grandchildren and heirs to his lineage - a fact which provides a strong realistic motif for his hatred against Antigone. This modern perspective has remained submerged for a long time.
The problem of the second burial.
An important issue still debated regarding Sophocles' "Antigone" is the problem of the second burial. When she poured dust over her brother's body, Antigone completed the burial ritual and thus fulfilled her duty to him. Having been properly buried, Polynices' soul could proceed to the underworld whether or not the dust was removed from his body. However, Antigone went back after his body was uncovered and performed the ritual again, an act that seems to be completely unmotivated by anything other than a plot necessity so that she could be caught in the act of disobedience, leaving no doubt of her guilt. More than one commentator has suggested that it was the gods, not Antigone, who performed the first burial, citing both the guard's description of the scene and the chorus's observation.
Richard Jebb suggests that the only reason for Antigone's return to the burial site is that the first time she forgot the Choaí (libations), and "perhaps the rite was considered completed only if the Choaí were poured while the dust still covered the corpse."
Gilbert Norwood explains Antigone's performance of the second burial in terms of her stubbornness. His argument says that had Antigone not been so obsessed with the idea of keeping her brother covered, none of the deaths of the play would have happened. This argument states that if nothing had happened, nothing would have happened, and doesn't take much of a stand in explaining why Antigone returned for the second burial when the first would have fulfilled her religious obligation, regardless of how stubborn she was. This leaves that she acted only in passionate defiance of Creon and respect to her brothers earthly vessel.
Tycho von Wilamowitz-Moellendorff justifies the need for the second burial by comparing Sophocles' "Antigone" to a theoretical version where Antigone is apprehended during the first burial. In this situation, news of the illegal burial and Antigone's arrest would arrive at the same time and there would be no period of time in which Antigone's defiance and victory could be appreciated.
J. L. Rose maintains that the solution to the problem of the second burial is solved by close examination of Antigone as a tragic character. Being a tragic character, she is completely obsessed by one idea, and for her this is giving her brother his due respect in death and demonstrating her love for him and for what is right. When she sees her brother's body uncovered, therefore, she is overcome by emotion and acts impulsively to cover him again, with no regards to the necessity of the action or its consequences for her safety.
Bonnie Honig uses the problem of the second burial as the basis for her claim that Ismene performs the first burial, and that her pseudo-confession before Creon is actually an honest admission of guilt.
Themes.
Civil disobedience.
A well established theme in Antigone is the right of the individual to reject society's infringement on her freedom to perform a personal obligation. Antigone's comments to Ismene regarding Creon's edict, "He has no right to keep me from my own." Related to this theme is the question of whether Antigone's will to bury her brother is based on rational thought or instinct, a debate whose contributors include Goethe.
The contrasting views of Creon and Antigone with regard to laws higher than those of state inform their different conclusions about civil disobedience. Creon demands obedience to the law above all else, right or wrong. He says that "there is nothing worse than disobedience to authority" ("An." 671). Antigone responds with the idea that state law is not absolute, and that it can be broken in civil disobedience in extreme cases, such as honoring the gods, whose rule and authority outweigh Creon's.
Natural law and contemporary legal institutions.
In "Antigone", Sophocles asks the question, which law is greater: the gods' or man's. Sophocles votes for the law of the gods. He does this in order to save Athens from the moral destruction which seems imminent. Sophocles wants to warn his countrymen about hubris, or arrogance, because he believes this will be their downfall. In Antigone, the hubris of Creon is revealed.
Creon's decree to leave Polyneices unburied in itself makes a bold statement about what it means to be a citizen, and what constitutes abdication of citizenship. It was the firmly kept custom of the Greeks that each city was responsible for the burial of its citizens. Herodotus discussed how members of each city would collect their own dead after a large battle to bury them. In "Antigone", it is therefore natural that the people of Thebes did not bury the Argives, but very striking that Creon prohibited the burial of Polyneices. Since he is a citizen of Thebes, it would have been natural for the Thebans to bury him. Creon is telling his people that Polyneices has distanced himself from them, and that they are prohibited from treating him as a fellow-citizen and burying him as is the custom for citizens.
In prohibiting the people of Thebes from burying Polyneices, Creon is essentially placing him on the level of the other attackers—the foreign Argives. For Creon, the fact that Polyneices has attacked the city effectively revokes his citizenship and makes him a foreigner. As defined by this decree, citizenship is based on loyalty. It is revoked when Polyneices commits what in Creon's eyes amounts to treason. When pitted against Antigone's view, this understanding of citizenship creates a new axis of conflict. Antigone does not deny that Polyneices has betrayed the state, she simply acts as if this betrayal does not rob him of the connection that he would have otherwise had with the city. Creon, on the other hand, believes that citizenship is a contract; it is not absolute or inalienable, and can be lost in certain circumstances. These two opposing views - that citizenship is absolute and undeniable and alternatively that citizenship is based on certain behavior - are known respectively as citizenship 'by nature' and citizenship 'by law.'
Fidelity.
Antigone's determination to bury Polyneices arises from a desire to bring honor to her family, and to honor the higher law of the gods. She repeatedly declares that she must act to please "those that are dead" ("An." 77), because they hold more weight than any ruler, that is the weight of divine law. In the opening scene, she makes an emotional appeal to her sister Ismene saying that they must protect their brother out of sisterly love, even if he did betray their state. Antigone believes that there are rights that are inalienable because they come from the highest authority, or authority itself, that is the divine law.
While he rejects Antigone's actions based on family honor, Creon appears to value family himself. When talking to Haemon, Creon demands of him not only obedience as a citizen, but also as a son. Creon says "everything else shall be second to your father's decision" ("An." 640-641). His emphasis on being Haemon's father rather than his king may seem odd, especially in light of the fact that Creon elsewhere advocates obedience to the state above all else. It is not clear how he would personally handle these two values in conflict, but it is a moot point in the play, for, as absolute ruler of Thebes, Creon is the state, and the state is Creon. It is clear how he feels about these two values in conflict when encountered in another person, Antigone: loyalty to the state comes before family fealty, and he sentences her to death.
Portrayal of the gods.
In "Antigone" as well as the other Theban Plays, there are very few references to the gods. Hades is the god who is most commonly referred to, but he is referred to more as a personification of Death. Zeus is referenced a total of 13 times by name in the entire play, and Apollo is referenced only as a personification of prophecy. This lack of mention portrays the tragic events that occur as the result of human error, and not divine intervention. The gods are portrayed as chthonic, as near the beginning there is a reference to "Justice who dwells with the gods beneath the earth." Sophocles references Olympus twice in "Antigone." This contrasts with the other Athenian tragedians, who reference Olympus often.
Love for family.
Antigone's love for family is shown when she buries her brother, Polyneices. Haemon was deeply in love with his cousin and fiancée Antigone, and he killed himself in grief when he found out that his beloved Antigone had hanged herself.
Modern adaptations.
Cinema.
The play was adapted into a 1961 film.
Liliana Cavani's 1969 "I Cannibali" is a contemporary political fantasy based upon the Sophocles play, with Irene Papas playing Antigone and Pierre Clémenti as Tiresias.

</doc>
<doc id="65954" url="https://en.wikipedia.org/wiki?curid=65954" title="John Cage">
John Cage

John Milton Cage Jr. (September 5, 1912 – August 12, 1992) was an American composer, music theorist, writer, and artist. A pioneer of indeterminacy in music, electroacoustic music, and non-standard use of musical instruments, Cage was one of the leading figures of the post-war avant-garde. Critics have lauded him as one of the most influential American composers of the 20th century. He was also instrumental in the development of modern dance, mostly through his association with choreographer Merce Cunningham, who was also Cage's romantic partner for most of their lives.
Cage is perhaps best known for his 1952 composition "4′33″", which is performed in the absence of deliberate sound; musicians who present the work do nothing aside from being present for the duration specified by the title. The content of the composition is not "four minutes and 33 seconds of silence," as is often assumed, but rather the sounds of the environment heard by the audience during performance. The work's challenge to assumed definitions about musicianship and musical experience made it a popular and controversial topic both in musicology and the broader aesthetics of art and performance. Cage was also a pioneer of the prepared piano (a piano with its sound altered by objects placed between or on its strings or hammers), for which he wrote numerous dance-related works and a few concert pieces. The best known of these is "Sonatas and Interludes" (1946–48).
His teachers included Henry Cowell (1933) and Arnold Schoenberg (1933–35), both known for their radical innovations in music, but Cage's major influences lay in various East and South Asian cultures. Through his studies of Indian philosophy and Zen Buddhism in the late 1940s, Cage came to the idea of aleatoric or chance-controlled music, which he started composing in 1951. The "I Ching", an ancient Chinese classic text on changing events, became Cage's standard composition tool for the rest of his life. In a 1957 lecture, "Experimental Music", he described music as "a purposeless play" which is "an affirmation of life – not an attempt to bring order out of chaos nor to suggest improvements in creation, but simply a way of waking up to the very life we're living".
Life.
1912–31: Early years.
Cage was born September 5, 1912, at Good Samaritan Hospital in downtown Los Angeles. His father, John Milton Cage, Sr. (1886–1964), was an inventor, and his mother, Lucretia ("Crete") Harvey (1885–1969), worked intermittently as a journalist for the "Los Angeles Times". The family's roots were deeply American: in a 1976 interview, Cage mentioned that George Washington was assisted by an ancestor named John Cage in the task of surveying the Colony of Virginia. Cage described his mother as a woman with "a sense of society" who was "never happy", while his father is perhaps best characterized by his inventions: sometimes idealistic, such as a diesel-fueled submarine that gave off exhaust bubbles, the senior Cage being uninterested in an undetectable submarine; others revolutionary and against the scientific norms, such as the "electrostatic field theory" of the universe. John Milton Sr. taught his son that "if someone says 'can't' that shows you what to do." In 1944–45 Cage wrote two small character pieces dedicated to his parents: "Crete" and "Dad". The latter is a short lively piece that ends abruptly, while "Crete" is a slightly longer, mostly melodic contrapuntal work.
Cage's first experiences with music were from private piano teachers in the Greater Los Angeles area and several relatives, particularly his aunt Phoebe Harvey James who introduced him to the piano music of the 19th century. He received first piano lessons when he was in the fourth grade at school, but although he liked music, he expressed more interest in sight reading than in developing virtuoso piano technique, and apparently was not thinking of composition. During high school, one of his music teachers was Fannie Charles Dillon. By 1928, though, Cage was convinced that he wanted to be a writer. He graduated that year from Los Angeles High School as a valedictorian, having also in the spring given a prize-winning speech at the Hollywood Bowl proposing a day of quiet for all Americans. "By being hushed and silent, he said, 'we should have the opportunity to hear what other people think'," anticipating "4'33"" by more than thirty years.
Cage enrolled at Pomona College in Claremont as a theology major in 1928. Often crossing disciplines again, though, he encountered at Pomona the work of artist Marcel Duchamp via professor José Pijoan, of writer James Joyce via Don Sample, of philosopher Ananda Coomaraswamy and of Cowell. In 1930 he dropped out, having come to believe that "college was of no use to a writer" after an incident described in the 1991 autobiographical statement:
I was shocked at college to see one hundred of my classmates in the library all reading copies of the same book. Instead of doing as they did, I went into the stacks and read the first book written by an author whose name began with Z. I received the highest grade in the class. That convinced me that the institution was not being run correctly. I left.
Cage persuaded his parents that a trip to Europe would be more beneficial to a future writer than college studies. He subsequently hitchhiked to Galveston and sailed to Le Havre, where he took a train to Paris. Cage stayed in Europe for some 18 months, trying his hand at various forms of art. First he studied Gothic and Greek architecture, but decided he was not interested enough in architecture to dedicate his life to it. He then took up painting, poetry and music. It was in Europe that, encouraged by his teacher Lazare Levy, he first heard the music of contemporary composers (such as Igor Stravinsky and Paul Hindemith) and finally got to know the music of Johann Sebastian Bach, which he had not experienced before.
After several months in Paris, Cage's enthusiasm for America was revived after he read Walt Whitman's "Leaves of Grass" – he wanted to return immediately, but his parents, with whom he regularly exchanged letters during the entire trip, persuaded him to stay in Europe for a little longer and explore the continent. Cage started traveling, visited various places in France, Germany and Spain, as well as Capri and, most importantly, Majorca, where he started composing. His first compositions were created using dense mathematical formulas, but Cage was displeased with the results and left the finished pieces behind when he left. Cage's association with theater also started in Europe: during a walk in Seville he witnessed, in his own words, "the multiplicity of simultaneous visual and audible events all going together in one's experience and producing enjoyment."
1931–36: Apprenticeship.
Cage returned to the United States in 1931. He went to Santa Monica, California, where he made a living partly by giving small, private lectures on contemporary art. He got to know various important figures of the Southern California art world, such as pianist Richard Buhlig (who became his first teacher) and arts patron Galka Scheyer. By 1933 Cage decided to concentrate on music rather than painting. "The people who heard my music had better things to say about it than the people who looked at my paintings had to say about my paintings", Cage later explained. In 1933 he sent some of his compositions to Henry Cowell; the reply was a "rather vague letter", in which Cowell suggested that Cage study with Arnold Schoenberg—Cage's musical ideas at the time included composition based on a 25-tone row, somewhat similar to Schoenberg's twelve-tone technique. Cowell also advised that, before approaching Schoenberg, Cage should take some preliminary lessons, and recommended Adolph Weiss, a former Schoenberg pupil.
Following Cowell's advice, Cage travelled to New York City in 1933 and started studying with Weiss as well as taking lessons from Cowell himself at The New School. He supported himself financially by taking up a job washing walls at a Brooklyn YWCA. Cage's routine during that period was apparently very tiring, with just four hours of sleep on most nights, and four hours of composition every day starting at 4 am. Several months later, still in 1933, Cage became sufficiently good at composition to approach Schoenberg. He could not afford Schoenberg's price, and when he mentioned it, the older composer asked whether Cage would devote his life to music. After Cage replied that he would, Schoenberg offered to tutor him free of charge.
Cage studied with Schoenberg in California: first at USC and then at UCLA, as well as privately. The older composer became one of the biggest influences on Cage, who "literally worshipped him", particularly as an example of how to live one's life being a composer. The vow Cage gave, to dedicate his life to music, was apparently still important some 40 years later, when Cage "had no need for it writing music", he continued composing partly because of the promise he gave. Schoenberg's methods and their influence on Cage are well documented by Cage himself in various lectures and writings. Particularly well-known is the conversation mentioned in the 1958 lecture "Indeterminacy":
After I had been studying with him for two years, Schoenberg said, "In order to write music, you must have a feeling for harmony." I explained to him that I had no feeling for harmony. He then said that I would always encounter an obstacle, that it would be as though I came to a wall through which I could not pass. I said, 'In that case I will devote my life to beating my head against that wall.' "
Cage studied with Schoenberg for two years, but although he admired his teacher, he decided to leave after Schoenberg told the assembled students that he was trying to make it impossible for them to write music. Much later, Cage recounted the incident: "[...] When he said that, I revolted, not against him, but against what he had said. I determined then and there, more than ever before, to write music." Although Schoenberg was not impressed with Cage's compositional abilities during these two years, in a later interview, where he initially said that none of his American pupils were interesting, he further stated in reference to Cage: "There was one...of course he's not a composer, but he's an inventor—of genius." Cage would later adopt the "inventor" moniker and deny that he was in fact a composer.
At some point in 1934–35, during his studies with Schoenberg, Cage was working at his mother's arts and crafts shop, where he met artist Xenia Andreyevna Kashevaroff. She was an Alaskan-born daughter of a Russian priest; her work encompassed fine bookbinding, sculpture and collage. Although Cage was involved in relationships with Don Sample and with architect Rudolph Schindler's wife Pauline when he met Xenia, he fell in love immediately. Cage and Kashevaroff were married in the desert at Yuma, Arizona, on June 7, 1935.
1937–49: Modern dance and Eastern influences.
The newly married couple first lived with Cage's parents in Pacific Palisades, then moved to Hollywood. During 1936–38 Cage changed numerous jobs, including one that started his lifelong association with modern dance: dance accompanist at UCLA. He produced music for choreographies and at one point taught a course on "Musical Accompaniments for Rhythmic Expression" at UCLA, with his aunt Phoebe. It was during that time that Cage first started experimenting with unorthodox instruments, such as household items, metal sheets, and so on. This was inspired by Oskar Fischinger, who told Cage that "everything in the world has a spirit that can be released through its sound." Although Cage did not share the idea of spirits, these words inspired him to begin exploring the sounds produced by hitting various non-musical objects.
In 1938, with help from a fellow Cowell student Lou Harrison, Cage became a faculty member at Mills College, teaching the same program as at UCLA, and collaborating with choreographer Marian van Tuyl. Several famous dance groups were present, and Cage's interest in modern dance grew further. After several months he left and moved to Seattle, Washington, where he found work as composer and accompanist for choreographer Bonnie Bird at the Cornish College of the Arts. The Cornish School years proved to be a particularly important period in Cage's life. Aside from teaching and working as accompanist, Cage organized a percussion ensemble that toured the West Coast and brought the composer his first fame. His reputation was enhanced further with the invention of the prepared piano—a piano which has had its sound altered by objects placed on, beneath or between the strings—in 1940. This concept was originally intended for a performance staged in a room too small to include a full percussion ensemble. It was also at the Cornish School that Cage met a number of people who became lifelong friends, such as painter Mark Tobey and dancer Merce Cunningham. The latter was to become Cage's lifelong romantic partner and artistic collaborator.
Cage left Seattle in the summer of 1941 after the painter László Moholy-Nagy invited him to teach at the Chicago School of Design (what later became the IIT Institute of Design. The composer accepted partly because he hoped to find opportunities in Chicago, that were not available in Seattle, to organize a center for experimental music. These opportunities did not materialize. Cage taught at the Chicago School of Design and worked as accompanist and composer at the University of Chicago. At one point, his reputation as percussion composer landed him a commission from the Columbia Broadcasting System to compose a soundtrack for a radio play by Kenneth Patchen. The result, "The City Wears a Slouch Hat", was received well, and Cage deduced that more important commissions would follow. Hoping to find these, he left Chicago for New York City in the spring of 1942.
In New York, the Cages first stayed with painter Max Ernst and Peggy Guggenheim. Through them, Cage met numerous important artists such as Piet Mondrian, André Breton, Jackson Pollock, Marcel Duchamp, and many others. Guggenheim was very supportive: the Cages could stay with her and Ernst for any length of time, and she offered to organize a concert of Cage's music at the opening of her gallery, which included paying for transportation of Cage's percussion instruments from Chicago. After she learned that Cage secured another concert, at the Museum of Modern Art, Guggenheim withdrew all support, and, even after the ultimately successful MoMA concert, Cage was left homeless, unemployed and penniless. The commissions he hoped for did not happen. He and Xenia spent the summer of 1942 with dancer Jean Erdman and her husband. Without the percussion instruments, Cage again turned to prepared piano, producing a substantial body of works for performances by various choreographers, including Merce Cunningham, who moved to New York City several years earlier. Cage and Cunningham eventually became romantically involved, and Cage's marriage, already breaking up during the early 1940s, ended in divorce in 1945. Cunningham remained Cage's partner for the rest of his life. Cage also countered the lack of percussion instruments by writing, on one occasion, for voice and closed piano: the resulting piece, "The Wonderful Widow of Eighteen Springs" (1942), quickly became popular and was performed by the celebrated duo of Cathy Berberian and Luciano Berio.
Like his personal life, Cage's artistic life went through a crisis in mid-1940s. The composer was experiencing a growing disillusionment with the idea of music as means of communication: the public rarely accepted his work, and Cage himself, too, had trouble understanding the music of his colleagues. In early 1946 Cage agreed to tutor Gita Sarabhai, an Indian musician who came to the US to study Western music. In return, he asked her to teach him about Indian music and philosophy. Cage also attended, in late 1940s and early 1950s, D. T. Suzuki's lectures on Zen Buddhism, and read further the works of Coomaraswamy. The first fruits of these studies were works inspired by Indian concepts: "Sonatas and Interludes" for prepared piano, "String Quartet in Four Parts", and others. Cage accepted the goal of music as explained to him by Sarabhai: "to sober and quiet the mind, thus rendering it susceptible to divine influences".
Early in 1946, his former teacher Richard Buhlig arranged for Cage to meet Berlin-born pianist Grete Sultan, who had escaped from Nazi persecution to New York in 1941. They became close, lifelong friends, and Cage later dedicated part of his Music for Piano and his monumental piano cycle Etudes Australes to her.
1950s: Discovering chance.
"Sonatas and Interludes" were received well by the public. After a 1949 performance at Carnegie Hall, New York, Cage received a grant from the Guggenheim Foundation, which enabled him to make a trip to Europe, where he met composers such as Olivier Messiaen and Pierre Boulez. More important was Cage's chance encounter with Morton Feldman in New York City in early 1950. Both composers attended a New York Philharmonic Orchestra concert, where the orchestra performed Anton Webern's "Symphony", op. 21, followed by a piece by Sergei Rachmaninoff. Cage felt so overwhelmed by Webern's piece that he left before the Rachmaninoff; and in the lobby, he met Feldman, who was leaving for the same reason. The two composers quickly became friends; some time later Cage, Feldman, Earle Brown, David Tudor and Cage's pupil Christian Wolff came to be referred to as "the New York school."
In early 1951, Wolff presented Cage with a copy of the "I Ching"—a Chinese classic text which describes a symbol system used to identify order in chance events. This version of the "I Ching" was the first complete English translation and had been published by Wolff's father, Kurt Wolff of Pantheon Books in 1950. The "I Ching" is commonly used for divination, but for Cage it became a tool to compose using chance. To compose a piece of music, Cage would come up with questions to ask the "I Ching"; the book would then be used in much the same way as it is used for divination. For Cage, this meant "imitating nature in its manner of operation": his lifelong interest in sound itself culminated in an approach that yielded works in which sounds were free from the composer's will:
When I hear what we call music, it seems to me that someone is talking. And talking about his feelings, or about his ideas of relationships. But when I hear traffic, the sound of traffic—here on Sixth Avenue, for instance—I don't have the feeling that anyone is talking. I have the feeling that sound is acting. And I love the activity of sound [...] I don't need sound to talk to me.
Although Cage had used chance on a few earlier occasions, most notably in the third movement of "Concerto for Prepared Piano and Chamber Orchestra" (1950–51), the "I Ching" opened new possibilities in this field for him. The first results of the new approach were "Imaginary Landscape No. 4" for 12 radio receivers, and "Music of Changes" for piano. The latter work was written for David Tudor, whom Cage met through Feldman—another friendship that lasted until Cage's death. Tudor premiered most of Cage's works until the early 1960s, when he stopped performing on the piano and concentrated on electronic music. The "I Ching" became Cage's standard tool for composition: he used it in practically every work composed after 1951.
Despite the fame "Sonatas and Interludes" earned him, and the connections he cultivated with American and European composers and musicians, Cage was quite poor. Although he still had an apartment, at 326 Monroe Street (which he occupied since around 1946) his financial situation in 1951 worsened so much that, while working on "Music of Changes", he prepared a set of instructions for Tudor as to how to complete the piece in the event of his death. Nevertheless, Cage managed to survive and maintained an active artistic life, giving lectures, performances, etc. In 1952–53 he completed another mammoth project—the "Williams Mix", a piece of tape music, which Earle Brown helped to put together. Also in 1952, Cage composed the piece that became his best-known and most controversial creation: "4′33″". The score instructs the performer not to play the instrument during the entire duration of the piece—four minutes, thirty-three seconds—and is meant to be perceived as consisting of the sounds of the environment that the listeners hear while it is performed. Cage conceived "a silent piece" years earlier, but was reluctant to write it down; and indeed, the premiere (given by Tudor on August 29, 1952 at Woodstock, New York) caused an uproar in the audience. The reaction to "4′33″" was just a part of the larger picture: on the whole, it was the adoption of chance procedures that had disastrous consequences for Cage's reputation. The press, which used to react favorably to earlier percussion and prepared piano music, ignored his new works, and many valuable friendships and connections were lost. Pierre Boulez, who used to promote Cage's work in Europe, was opposed to Cage's use of chance, and so were other composers who came to prominence during the 1950s, e.g. Karlheinz Stockhausen and Iannis Xenakis.
During this time John Cage was also teaching at the avant-garde Black Mountain College just outside Asheville, NC. Cage taught at the college in the summers of 1948 and 1952 and was in residence the summer of 1953. While at Black Mountain College in 1952, he organized what has been called the first "happening" (see discussion below) in the United States, later titled "Theatre Piece No. 1", a multi-layered, multi-media performance event staged the same day as Cage conceived it that "that would greatly influence 1950s and 60s artistic practices". In addition to Cage, the participants included Cunningham and Tudor.
From 1953 onward, Cage was busy composing music for modern dance, particularly Cunningham's dances (Cage's partner adopted chance too, out of fascination for the movement of the human body), as well as developing new methods of using chance, in a series of works he referred to as "The Ten Thousand Things". In the summer of 1954 he moved out of New York and settled in a cooperative community in Stony Point, New York, where his neighbors included David Tudor, M. C. Richards, Karen Karnes, Stan VanDerBeek, and Sari Dienes. The composer's financial situation gradually improved: in late 1954 he and Tudor were able to embark on a European tour. From 1956 to 1961 Cage taught classes in experimental composition at The New School, and from 1956 to 1958 he also worked as an art director and designer of typography. Among his works completed during the last years of the decade were "Concert for Piano and Orchestra" (1957–58), a seminal work in the history of graphic notation, and "Variations I" (1958).
1960s: Fame.
Cage was affiliated with Wesleyan University and collaborated with members of its Music Department from the 1950s until his death in 1992. At the University, the philosopher, poet, and professor of classics Norman O. Brown befriended Cage, an association that proved fruitful to both. In 1960 the composer was appointed a Fellow on the faculty of the Center for Advanced Studies (now the Center for Humanities) in the Liberal Arts and Sciences at Wesleyan, where he started teaching classes in experimental music. In October 1961, Wesleyan University Press published "", a collection of Cage's lectures and writings on a wide variety of subjects, including the famous "Lecture on Nothing" that was composed using a complex time length scheme, much like some of Cage's music. "Silence" was Cage's first book. He went on to publish five more. "Silence" remained his most widely read and influential book. In the early 1960s Cage began his lifelong association with C.F. Peters Corporation. Walter Hinrichsen, the president of the corporation, offered Cage an exclusive contract and instigated the publication of a catalog of Cage's works, which appeared in 1962.
Edition Peters soon published a large number of scores by Cage, and this, together with the publication of "Silence", led to much higher prominence for the composer than ever before—one of the positive consequences of this was that in 1965 Betty Freeman set up an annual grant for living expenses for Cage, to be issued from 1965 to his death. By the mid-1960s, Cage was receiving so many commissions and requests for appearances that he was unable to fulfill them. This was accompanied by a busy touring schedule; consequently Cage's compositional output from that decade was scant. After the orchestral "Atlas Eclipticalis" (1961–62), a work based on star charts, which was fully notated, Cage gradually shifted to, in his own words, "music (not composition)." The score of "0′00″", completed in 1962, originally comprised a single sentence: "In a situation provided with maximum amplification, perform a disciplined action", and in the first performance the disciplined action was Cage writing that sentence. The score of "Variations III" (1962) abounds in instructions to the performers, but makes no references to music, musical instruments or sounds.
Many of the "Variations" and other 1960s pieces were in fact "happenings", an art form established by Cage and his students in late 1950s. Cage's "Experimental Composition" classes at The New School have become legendary as an American source of Fluxus, an international network of artists, composers, and designers. The majority of his students had little or no background in music. Most were artists. They included Jackson Mac Low, Allan Kaprow, Al Hansen, George Brecht, and Dick Higgins, as well as many others Cage invited unofficially. Famous pieces that resulted from the classes include George Brecht's "Time Table Music" and Al Hansen's "Alice Denham in 48 Seconds". As set forth by Cage, happenings were theatrical events that abandon the traditional concept of stage-audience and occur without a sense of definite duration. Instead, they are left to chance. They have a minimal script, with no plot. In fact, a "happening" is so-named because it occurs in the present, attempting to arrest the concept of passing time. Cage believed that theater was the closest route to integrating art and real life. The term "happenings" was coined by Allan Kaprow, one of his students, who defined it as a genre in the late fifties. Cage met Kaprow while on a mushroom hunt with George Segal and invited him to join his class. In following these developments Cage was strongly influenced by Antonin Artaud's seminal treatise "The Theatre and Its Double", and the happenings of this period can be viewed as a forerunner to the ensuing Fluxus movement. In October 1960, Mary Bauermeister's Cologne studio hosted a joint concert by Cage and the video artist Nam June Paik, who in the course of his "Etude for Piano" cut off Cage's tie and then washed his co-performer’s hair with shampoo.
In 1967, Cage's "A Year from Monday" was first published by Wesleyan University Press. Cage's parents died during the decade: his father in 1964, and his mother in 1969. Cage had their ashes scattered in Ramapo Mountains, near Stony Point, and asked for the same to be done to him after his death.
1969–87: New departures.
Cage's work from the sixties features some of his largest and most ambitious, not to mention socially utopian pieces, reflecting the mood of the era yet also his absorption of the writings of both Marshall McLuhan, on the effects of new media, and R. Buckminster Fuller, on the power of technology to promote social change. "HPSCHD" (1969), a gargantuan and long-running multimedia work made in collaboration with Lejaren Hiller, incorporated the mass superimposition of seven harpsichords playing chance-determined excerpts from the works of Cage, Hiller, and a potted history of canonical classics, with fifty-two tapes of computer-generated sounds, 6,400 slides of designs, many supplied by NASA, and shown from sixty-four slide projectors, with forty motion-picture films. The piece was initially rendered in a five-hour performance at the University of Illinois in 1969, in which the audience arrived after the piece had begun and left before it ended, wandering freely around the auditorium in the time for which they were there.
Also in 1969, Cage produced the first fully notated work in years: "Cheap Imitation" for piano. The piece is a chance-controlled reworking of Erik Satie's "Socrate", and, as both listeners and Cage himself noted, openly sympathetic to its source. Although Cage's affection for Satie's music was well-known, it was highly unusual for him to compose a personal work, one in which the composer "is" present. When asked about this apparent contradiction, Cage replied: "Obviously, "Cheap Imitation" lies outside of what may seem necessary in my work in general, and that's disturbing. I'm the first to be disturbed by it." Cage's fondness for the piece resulted in a recording—a rare occurrence, since Cage disliked making recordings of his music—made in 1976. Overall, "Cheap Imitation" marked a major change in Cage's music: he turned again to writing fully notated works for traditional instruments, and tried out several new approaches, such as improvisation, which he previously discouraged, but was able to use in works from the 1970s, such as "Child of Tree" (1975).
"Cheap Imitation" became the last work Cage performed in public himself. Arthritis had troubled Cage since 1960, and by the early 1970s his hands were painfully swollen and rendered him unable to perform. Nevertheless, he still played "Cheap Imitation" during the 1970s, before finally having to give up performing. Preparing manuscripts also became difficult: before, published versions of pieces were done in Cage's calligraphic script; now, manuscripts for publication had to be completed by assistants. Matters were complicated further by David Tudor's departure from performing, which happened in early 1970s. Tudor decided to concentrate on composition instead, and so Cage, for the first time in two decades, had to start relying on commissions from other performers, and their respective abilities. Such performers included Grete Sultan, Paul Zukofsky, Margaret Leng Tan, and many others. Aside from music, Cage continued writing books of prose and poetry (mesostics). "M" was first published by Wesleyan University Press in 1973. In January 1978 Cage was invited by Kathan Brown of Crown Point Press to engage in printmaking, and Cage would go on to produce series of prints every year until his death; these, together with some late watercolors, constitute the largest portion of his extant visual art. In 1979 Cage's "Empty Words" was first published by Wesleyan University Press.
1987–92: Final years and death.
In 1987, Cage completed a piece called "Two", for flute and piano, dedicated to performers Roberto Fabbriciani and Carlo Neri. The title referred to the number of performers needed; the music consisted of short notated fragments to be played at any tempo within the indicated time constraints. Cage went on to write some forty such pieces, one of the last being "Eighty" (1992, premiered in Munich on 28 October 2011), usually employing a variant of the same technique; together, these works are known as "Number Pieces". The process of composition, in many of the later Number Pieces, was simple selection of pitch range and pitches from that range, using chance procedures; the music has been linked to Cage's anarchic leanings. "One11" (i.e. the eleventh piece for a single performer), completed in early 1992, was Cage's first and only foray into film.
Another new direction, also taken in 1987, was opera: Cage produced five operas, all sharing the same title "Europera", in 1987–91. Europeras I and II require greater forces than III, IV and V, which are on a chamber scale.
Already in the course of the eighties, Cage's health worsened progressively: he suffered not only from arthritis, but also from sciatica and arteriosclerosis. He suffered a stroke that left the movement of his left leg restricted, and, in 1985, broke an arm. During this time, Cage pursued a macrobiotic diet. Nevertheless, ever since arthritis started plaguing him, the composer was aware of his age, and, as biographer David Revill observed, "the fire which he began to incorporate in his visual work in 1985 is not only the fire he has set aside for so long—the fire of passion—but also fire as transitoriness and fragility." On August 11, 1992, while preparing evening tea for himself and Cunningham, Cage suffered another stroke. He was taken to the nearest hospital, where he died on the morning of August 12.
According to his wishes, Cage's body was cremated, and the ashes scattered in the Ramapo Mountains, near Stony Point, New York, the same place where Cage scattered the ashes of his parents, years before. The composer's death occurred only weeks before a celebration of his 80th birthday organized in Frankfurt by the composer Walter Zimmermann and the musicologist Stefan Schaedler was due to take place. The event went ahead as planned, including a performance of the "Concert for Piano and Orchestra" by David Tudor and Ensemble Modern. Merce Cunningham lived another 17 years, dying of natural causes in July 2009.
Music.
Early works, rhythmic structure, and new approaches to harmony.
Cage's first completed pieces are currently lost. According to the composer, the earliest works were very short pieces for piano, composed using complex mathematical procedures and lacking in "sensual appeal and expressive power." Cage then started producing pieces by improvising and writing down the results, until Richard Buhlig stressed to him the importance of structure. Most works from the early 1930s, such as "Sonata for Clarinet" (1933) and "Composition for 3 Voices" (1934), are highly chromatic and betray Cage's interest in counterpoint. Around the same time, the composer also developed a type of a tone row technique with 25-note rows. After studies with Schoenberg, who never taught dodecaphony to his students, Cage developed another tone row technique, in which the row was split into short motives, which would then be repeated and transposed according to a set of rules. This approach was first used in "Two Pieces for Piano" (c. 1935), and then, with modifications, in larger works such as "Metamorphosis" and "Five Songs" (both 1938).
Soon after Cage started writing percussion music and music for modern dance, he started using a technique that placed the rhythmic structure of the piece into the foreground. In "Imaginary Landscape No. 1" (1939) there are four large sections of 16, 17, 18, and 19 bars, and each section is divided into four subsections, the first three of which were all 5 bars long. "First Construction (in Metal)" (1939) expands on the concept: there are five sections of 4, 3, 2, 3, and 4 units respectively. Each unit contains 16 bars, and is divided the same way: 4 bars, 3 bars, 2 bars, etc. Finally, the musical content of the piece is based on sixteen motives. Such "nested proportions", as Cage called them, became a regular feature of his music throughout the 1940s. The technique was elevated to great complexity in later pieces such as "Sonatas and Interludes" for prepared piano (1946–48), in which many proportions used non-integer numbers (1¼, ¾, 1¼, ¾, 1½, and 1½ for "Sonata I", for example), or "A Flower", a song for voice and closed piano, in which two sets of proportions are used simultaneously.
In late 1940s, Cage started developing further methods of breaking away with traditional harmony. For instance, in "String Quartet in Four Parts" (1950) Cage first composed a number of "gamuts": chords with fixed instrumentation. The piece progresses from one "gamut" to another. In each instance the "gamut" was selected only based on whether it contains the note necessary for the melody, and so the rest of the notes do not form any directional harmony. "Concerto for prepared piano" (1950–51) used a system of charts of durations, dynamics, melodies, etc., from which Cage would choose using simple geometric patterns. The last movement of the concerto was a step towards using chance procedures, which Cage adopted soon afterwards.
Chance.
A chart system was also used (along with nested proportions) for the large piano work "Music of Changes" (1951), only here material would be selected from the charts by using the "I Ching". All of Cage's music since 1951 was composed using chance procedures, most commonly using the "I Ching". For example, works from "Music for Piano" were based on paper imperfections: the imperfections themselves provided pitches, coin tosses and "I Ching" hexagram numbers were used to determine the accidentals, clefs, and playing techniques. A whole series of works was created by applying chance operations, i.e. the "I Ching", to star charts: "Atlas Eclipticalis" (1961–62), and a series of etudes: "Etudes Australes" (1974–75), "Freeman Etudes" (1977–90), and "Etudes Boreales" (1978). Cage's etudes are all extremely difficult to perform, a characteristic dictated by Cage's social and political views: the difficulty would ensure that "a performance would show that the impossible is not impossible"—this being Cage's answer to the notion that solving the world's political and social problems is impossible. Cage described himself as an anarchist, and was influenced by Henry David Thoreau.
Another series of works applied chance procedures to per-existing music by other composers: "Cheap Imitation" (1969; based on Erik Satie), "Some of "The Harmony of Maine"" (1978; based on Belcher), and "Hymns and Variations" (1979). In these works, Cage would borrow the rhythmic structure of the originals and fill it with pitches determined through chance procedures, or just replace some of the originals' pitches. Yet another series of works, the so-called "Number Pieces", all completed during the last five years of the composer's life, make use of "time brackets": the score consists of short fragments with indications of when to start and to end them (e.g. from anywhere between 1′15″ and 1′45″, and to anywhere from 2′00″ to 2′30″).
Cage's method of using the "I Ching" was far from simple randomization. The procedures varied from composition to composition, and were usually complex. For example, in the case of "Cheap Imitation", the exact questions asked to the "I Ching" were these:
In another example of late music by Cage, "Etudes Australes", the compositional procedure involved placing a transparent strip on the star chart, identifying the pitches from the chart, transferring them to paper, then asking the "I Ching" which of these pitches were to remain single, and which should become parts of aggregates (chords), and the aggregates were selected from a table of some 550 possible aggregates, compiled beforehand.
Finally, some of Cage's works, particularly those completed during the 1960s, feature instructions to the performer, rather than fully notated music. The score of "Variations I" (1958) presents the performer with six transparent squares, one with points of various sizes, five with five intersecting lines. The performer combines the squares and uses lines and points as a coordinate system, in which the lines are axes of various characteristics of the sounds, such as lowest frequency, simplest overtone structure, etc. Some of Cage's graphic scores (e.g. "Concert for Piano and Orchestra", "Fontana Mix" (both 1958)) present the performer with similar difficulties. Still other works from the same period consist just of text instructions. The score of "0'00"" (1962; also known as "4'33" No. 2") consists of a single sentence: "In a situation provided with maximum amplification, perform a disciplined action." The first performance had Cage write that sentence.
"Musicircus" (1967) simply invites the performers to assemble and play together. The first "Musicircus" featured multiple performers and groups in a large space who were all to commence and stop playing at two particular time periods, with instructions on when to play individually or in groups within these two periods. The result was a mass superimposition of many different musics on top of one another as determined by chance distribution, producing an event with a specifically theatric feel. Many Musicircuses have subsequently been held, and continue to occur even after Cage's death. The English National Opera became the first opera company to hold a Cage Musicircus on 3 March 2012 at the London Coliseum. The ENO's Musicircus featured artists including Led Zeppelin bassist John Paul Jones and composer Michael Finnissy alongside ENO Music Director Edward Gardner, the ENO Community Choir, ENO Opera Works singers, and a collective of professional and amateur talents performing in the bars and front of house at London's Coliseum Opera House.
This concept of circus was to remain important to Cage throughout his life and featured strongly in such pieces as "Roaratorio, an Irish circus on Finnegans Wake" (1979), a many-tiered rendering in sound of both his text "Writing for the Second Time Through Finnegans Wake", and traditional musical and field recordings made around Ireland. The piece was based on James Joyce's famous novel, "Finnegans Wake", which was one of Cage's favorite books, and one from which he derived texts for several more of his works.
Improvisation.
Since chance procedures were used by Cage to eliminate the composer's and the performer's likes and dislikes from music, Cage disliked the concept of improvisation, which is inevitably linked to the performer's preferences. In a number of works beginning in the 1970s, he found ways to incorporate improvisation. In "Child of Tree" (1975) and "Branches" (1976) the performers are asked to use certain species of plants as instruments, for example the cactus. The structure of the pieces is determined through the chance of their choices, as is the musical output; the performers had no knowledge of the instruments. In "Inlets" (1977) the performers play large water-filled conch shells – by carefully tipping the shell several times, it is possible to achieve a bubble forming inside, which produced sound. Yet, as it is impossible to predict when this would happen, the performers had to continue tipping the shells – as a result the performance was dictated by pure chance.
Visual art, writings, and other activities.
Although Cage started painting in his youth, he gave it up in order to concentrate on music instead. His first mature visual project, "Not Wanting to Say Anything About Marcel", dates from 1969. The work comprises two lithographs and a group of what Cage called "plexigrams": silk screen printing on plexiglas panels. The panels and the lithographs all consist of bits and pieces of words in different typefaces, all governed by chance operations.
From 1978 to his death Cage worked at Crown Point Press, producing series of prints every year. The earliest project completed there was the etching "Score Without Parts" (1978), created from fully notated instructions, and based on various combinations of drawings by Henry David Thoreau. This was followed, the same year, by "Seven Day Diary", which Cage drew with his eyes closed, but which conformed to a strict structure developed using chance operations. Finally, Thoreau's drawings informed the last works produced in 1978, "Signals".
Between 1979 and 1982 Cage produced a number of large series of prints: "Changes and Disappearances" (1979–80), "On the Surface" (1980–82), and "Déreau" (1982). These were the last works in which he used engraving. In 1983 he started using various unconventional materials such as cotton batting, foam, etc., and then used stones and fire ("Eninka", "Variations", "Ryoanji", etc.) to create his visual works. In 1988–1990 he produced watercolors at the Mountain Lake Workshop.
The only film Cage produced was one of the Number Pieces, "One11", commissioned by composer and film director Henning Lohner who worked with Cage to produce and direct the 90-minute monochrome film. It was completed only weeks before his death in 1992. "One11" consists entirely of images of chance-determined play of electric light. It premiered in Cologne, Germany, on September 19, 1992, accompanied by the live performance of the orchestra piece "103".
Throughout his adult life, Cage was also active as lecturer and writer. Some of his lectures were included in several books he published, the first of which was "" (1961). "Silence" included not only simple lectures, but also texts executed in experimental layouts, and works such as "Lecture on Nothing" (1949), which were composed in rhythmic structures. Subsequent books also featured different types of content, from lectures on music to poetry—Cage's mesostics.
Cage was also an avid amateur mycologist: he co-founded the New York Mycological Society with four friends, and his mycology collection is presently housed by the Special Collections department of the McHenry Library at the University of California, Santa Cruz.
Reception and influence.
Cage's pre-chance works, particularly pieces from the late 1940s such as "Sonatas and Interludes", earned critical acclaim: the "Sonatas" were performed at Carnegie Hall in 1949. Cage's adoption of chance operations in 1951 cost him a number of friendships and led to numerous criticisms from fellow composers. Adherents of serialism such as Pierre Boulez and Karlheinz Stockhausen dismissed indeterminate music; Boulez, who was once on friendly terms with Cage, criticized him for "adoption of a philosophy tinged with Orientalism that masks a basic weakness in compositional technique." Prominent critics of serialism, such as the Greek composer Iannis Xenakis, were similarly hostile towards Cage: for Xenakis, the adoption of chance in music was "an abuse of language and [...] an abrogation of a composer's function."
An article by teacher and critic Michael Steinberg, "Tradition and Responsibility", criticized avant-garde music in general:
The rise of music that is totally without social commitment also increases the separation between composer and public, and represents still another form of departure from tradition. The cynicism with which this particular departure seems to have been made is perfectly symbolized in John Cage's account of a public lecture he had given: "Later, during the question period, I gave one of six previously prepared answers regardless of the question asked. This was a reflection of my engagement in Zen." While Mr. Cage's famous silent piece 4′33″, or his "Landscapes" for a dozen radio receivers may be of little interest as music, they are of enormous importance historically as representing the complete abdication of the artist's power.
Cage's aesthetic position was criticized by, among others, prominent writer and critic Douglas Kahn. In his 1999 book "Noise, Water, Meat: A History of Sound in the Arts", Kahn acknowledged the influence Cage had on culture, but noted that "one of the central effects of Cage's battery of silencing techniques was a silencing of the social."
While much of Cage's work remains controversial, his influence on countless composers, artists, and writers is notable. After Cage introduced chance, Boulez, Stockhausen, and Xenakis remained critical, yet all adopted chance procedures in some of their works (although in a much more restricted manner); and Stockhausen's piano writing in his later Klavierstücke was influenced by Cage's "Music of Changes" and David Tudor. Other composers who adopted chance procedures in their works included Witold Lutosławski, Mauricio Kagel, and many others. Music in which some of the composition and/or performance is left to chance was labelled "aleatoric music"—a term popularized by Pierre Boulez. Helmut Lachenmann's work was influenced by Cage's work with extended techniques.
Cage's rhythmic structure experiments and his interest in sound influenced a number of composers, starting at first with his close American associates Earle Brown, Morton Feldman, and Christian Wolff (and other American composers, such as La Monte Young, Terry Riley, Steve Reich, and Philip Glass), and then spreading to Europe. For example, almost all composers of the English experimental school acknowledge his influence: Michael Parsons, Christopher Hobbs, John White, Gavin Bryars, who studied under Cage briefly, and Howard Skempton. The Japanese composer Tōru Takemitsu has also cited Cage's influence.
Cage's influence was also acknowledged by rock acts such as Sonic Youth (who performed some of the Number Pieces) and Stereolab (who named a song after Cage), composer and rock and jazz guitarist Frank Zappa, and various noise music artists and bands: indeed, one writer traced the origin of noise music to "4′33″". The development of electronic music was also influenced by Cage: in the mid-1970s Brian Eno's label Obscure Records released works by Cage. Prepared piano, which Cage popularized, is featured heavily on Aphex Twin's 2001 album "Drukqs". Cage's work as musicologist helped popularize Erik Satie's music, and his friendship with Abstract expressionist artists such as Robert Rauschenberg helped introduce his ideas into visual art. Cage's ideas also found their way into sound design: for example, Academy Award-winning sound designer Gary Rydstrom cited Cage's work as a major influence. Radiohead undertook a composing and performing collaboration with Cunningham's dance troupe in 2003 because the music-group's leader Thom Yorke considered Cage one of his “all-time art heroes”.
Centenary commemoration.
In 2012, amongst a wide range of American and international centennial celebrations, an 8-day festival was held in Washington DC, with venues found notably more amongst the city's art museums and universities than performance spaces. Earlier in the centennial year, conductor Michael Tilson Thomas presented Cage’s “Song Books” with the San Francisco Symphony at Carnegie Hall in New York. Another celebration came, for instance, in Darmstadt, Germany, which in July 2012 renamed its central station the John Cage Railway Station during the term of its annual new-music courses. Jacaranda 
has four concerts planned in Santa Monica, CA for the centennial week.
John Cage Day was the name given to several events held during 2012 to mark the centenary of his birth.
A 2012 project was curated by Juraj Kojs to celebrate the centenary of Cage's birth, titled "On Silence: Homage to Cage." It consisted of 13 commissioned works created by composers from around the global such as Kasia Glowicka, Adrian Knight and Henry Vega, each being 4 minutes and 33 seconds long in honor of Cage’s infamous 1952 opus, "4'33"." The program was supported by the Foundation for Emerging Technologies and Arts, Laura Kuhn and the John Cage Trust.
In an homage to Cage's dance work, the Bill T. Jones/Arnie Zane Dance Company in July 2012 "performed an engrossing piece called 'Story/Time'. It was modeled on Cage’s 1958 work 'Indeterminacy', in which and then Jones, respectively, sat alone onstage, reading aloud ... series of one-minute stories written. Dancers from Jones’s company performed as [Jones read."
External links.
General information and catalogues
Link collections
Specific topics
Listening
Media

</doc>
<doc id="65955" url="https://en.wikipedia.org/wiki?curid=65955" title="Denim">
Denim

Denim is a sturdy cotton warp-faced textile in which the weft passes under two or more warp threads. This twill weaving produces a diagonal ribbing that distinguishes it from cotton duck.
The most common denim is indigo denim, in which the warp thread is dyed, while the weft thread is left white. As a result of the warp-faced twill weaving, one side of the textile is dominated by the blue warp threads and the other side is dominated by the white weft threads. This causes blue jeans to be white on the inside. The indigo dyeing process, in which the core of the warp threads remains white, creates denim's signature fading characteristics.
Etymology and origin.
The name "denim" derives .
Denim was traditionally colored blue with indigo dye to make blue jeans, although "jean" formerly denoted a different, lighter, cotton fabric. The contemporary use of the word "jeans" comes from the French word for Genoa, Italy (Gênes), where the first denim trousers were made. 
Denim has been used in the USA since the mid 19th century. Denim initially gained popularity in 1873 when Jacob Davis, a tailor from Nevada, manufactured the first pair of “rivet-reinforced” denim pants. His concept for making reinforced jeans was inspired when a lady customer requested a pair of durable and strong pants for her husband to chop wood. When Davis was about to finish making the denim jeans, he saw some copper rivets lying on a table and used the rivets to fasten the pockets. At this time, clothes for Western labourers, such as teamsters, surveyors, and miners, were not very durable. Soon, the popularity of denim jeans began to spread rapidly and Davis was overwhelmed with requests. He soon sold 200 pairs to workers in need of heavy work clothing. Nevertheless, because of the production capacity in his small shop, Davis was struggling to keep up with the demand . He then wrote a proposal to the dry goods wholesaler Levi Strauss & Co. that had been supplying Davis with bolts of denim fabric. Davis’s proposal was “to patent the design of the rivet-reinforced denim pant, with Davis listed as inventor, in exchange for certain rights of manufacture”. Levi Strauss & Co. was so impressed by the possibilities for profit in the manufacture of the garment that they then hired Davis to be in charge of the mass-production in San Francisco.
Dry or raw denim.
Dry or raw denim (contrasted with "washed denim") is denim that is not washed after having been dyed during production.
Over time, dry denim will usually fade, which is considered desirable by some people. During the process of wear, fading will usually occur on those parts of the article that receive the most stress. On a pair of jeans, this includes the upper thighs, the ankles, and the areas behind the knees.
After being made into an article of clothing, most denim articles are washed to make them softer and to reduce or eliminate shrinkage (which could cause the article to not fit properly after its owner washes it). In addition to being washed, "washed denim" is sometimes artificially distressed to produce a "worn" look. Much of the appeal of artificially distressed denim is that it resembles dry denim which has faded. In jeans made from dry denim, such fading is affected by the body of the person who wears them and by the activities of their daily life. This process creates what many enthusiasts feel to be a look more "natural" than artificially distressed denim.
To facilitate the natural distressing process, some wearers of dry denim will abstain from washing their jeans for more than six months.
Most dry denim is made with 100% cotton and comes from several different countries. In particular, the United States, Zimbabwe and Japan are popular sources of cotton for making raw denim.
Dry denim also varies in weight, typically measured in by the weight of a yard of denim in ounces. 12 Oz. or less is considered light denim, 12 Oz. to 16 Oz. is considered mid-weight, and over 16 Oz. is considered heavy weight. Heavier denim is much more rigid and resistant to wear, but can also take more wears to break in and feel comfortable.
Patterns of fading.
Patterns of fading in jeans, caused by prolonged periods of wearing them without washing, have become the main allure of dry denim. Such patterns are a way of "personalizing" the garment.
These patterns have specific names:
Selvedge/selvage denim.
"Selvedge", or "selvage" (both spellings are correct), is the edge of a fabric as it comes from the loom. Selvedges are woven or knit so that they will not fray, ravel, or curl.
"Selvedge denim" refers to a unique type of selvedge that is made by means of using one continuous cross-yarn (the weft), which is passed back and forth through the vertical warp beams. This is traditionally finished at both edges with a contrasting warp (most commonly red); that is why this type of denim is sometimes referred to as "red selvedge." This method of weaving the selvage is possible only when using a shuttle loom.
Shuttle looms weave a narrower 30-inch fabric, which is on average half the width of modern shuttleless Sulzer looms. Consequently, a longer piece of fabric is required to make a pair of jeans from selvedge denim (approximately three yards).
To maximize yield, most jeans are made from wide denim and have a straight outseam that utilizes the full width of the fabric, including the edges. Selvedge denim has come to be associated with premium quality jeans, which show the finished edges from the loom rather than the overlocked edges that are shown on other jeans.
A detailed look at selvedge denim.
Dyeing.
Denim was originally dyed with a dye produced from the plant "Indigofera tinctoria", but most denim today is dyed with synthetic indigo dye. In both cases, the yarn undergoes a repeated sequence of dipping and oxidation — the more dips, the stronger the color of the indigo.
Rope dyeing is considered the best yarn-dyeing method, as it eliminates shading across the fabric width. The alternative "slasher process" is cheaper because only one beaming process is needed. In rope dyeing, beaming is done twice.
Colored denim.
Denim fabric dyeing is divided into two categories: indigo dyeing and sulfur dyeing. Indigo dyeing produces the traditional blue color or shades similar to it. Sulfur dyeing produces speciality black colors and other colors, such as red, pink, purple, grey, rust, mustard, and green.
Stretch denim.
Stretch denim incorporates an elastic component, such as spandex. This creates a certain amount of "give" in garments made from stretch denim.
Only a small percentage (about 3%) of spandex is required within the fabric to create a significant stretching capacity of about 15%. However, this feature will shorten the wearing life of the garment.
Uses.
Vehicles.
Starting with the 1973 model year, American Motors Corporation (AMC) offered a regular production option consisting of a Levi's interior trim package. Over the years it was available on the Gremlin, Hornet, and Pacer, as well as Jeep models.
Although the car's jean material looks just like the real thing, AMC used spun nylon that was made to imitate denim. This was because real denim fabric is not tough enough for automobile use and cannot pass fire resistance safety standards. The copper rivets were the actual versions and the seat design included traditional contrasting stitching with the Levi's tab on both the front seat backs. The option also included unique door panels with Levis trim and removable map pockets, as well as "Levi's" decal identification on the front fenders. The Levi's interior was available through the 1978 AMC Concord.
A Levi's trim package was also made available by AMC on the Jeep CJ line in 1975. This consisted of demin-like vinyl upholstery and a matching canvas top. This option was available on all CJ models in blue or tan, and was the standard trim on the top-level Renegade versions.
Between 1973 and 1975 Volkswagen produced the Jeans Beetle, which had all-denim trim. They also repeated this concept in some later models.
Worldwide market.
In 2007, the worldwide denim market equalled USD 51.6 billion, with demand growing by 5% and supply growing by 8% annually. Over 50% of denim is produced in Asia, most of it in China, India, Turkey, Pakistan, and Bangladesh.
The following table shows where the world's denim mills are located.
Denim in Bollywood.
In Bollywood denim jeans and jackets are a symbol of the middle class and a representation of what is appropriate for modern Indian bodies. Denim jeans can even belong to lavish costume displays that represent the aspirations of Indian people. Wilkinson-Weber (2011) refers to Miller (2007) that initially there were only a few choices and styles of jeans in India compared to those in other countries of the world. However, Indians from the urban middle and upper class began to find it easier than ever to buy jeans “domestic or imported (often fake) versions from elsewhere in Asia provide a range of price and quality alongside foreign high-priced labels”. What attracts the young Indians to purchase denim is the emulation of celebrities on the screens. Denim in Bollywood signifies bold behavior on the part of characters and a willingness to explore new forms of identity as well as the pursuit of Western values and social mobility. Indeed, many Indian viewers “imaginatively anticipate” their own identities by watching Bollywood films, and some even hire personal tailors to make jeans so they can fulfil their dreams of imitating favorite film characters.

</doc>
<doc id="65956" url="https://en.wikipedia.org/wiki?curid=65956" title="Rigoletto (film)">
Rigoletto (film)

Rigoletto is a 1993 musical fantasy/drama produced for Feature Films for Families.
Plot synopsis.
Rigoletto stars Joseph Paur as Ari Ribaldi and Ivey Lloyd as Bonnie Nelson, a singer.
Bonnie reads a part of Rigoletto each night to her younger brother.
The film time shifts to the 1930s, during America's Great Depression. The following scene shows an old house which newcomer Mr. Ribaldi purchases.
The next day, Bonnie performs in a singing contest. While Bonnie did not win, she manages to attract the attention of a suspicious man. He says nothing to her and he only nods and leaves.
That night as the children walk home, they spot the old house which has been renovated. The townspeople also spot the house and think it is unusual for a house to be renovated so fast.
The same moment, the town banker sells the mortgage on one of his houses and the Nelson family are immediately evicted. Bonnie's mother immediately leaves but to locate the person who bought their house. She knocks on the door only to find the same man who was watching Bonnie's contest. The man is Hans the Butler. He is tense but welcomes Mrs. Nelson inside. He shows her to The Master of the home (Mr. Ribaldi), and she is sternly instructed to stop at the rug. The man remains seated in the darkness.
He answers to Mrs. Nelson's demands by returning their home directly to them in exchange for an agreement in which Bonnie would "work" for him. Mrs. Nelson asks why she can't do the job instead of her daughter. He evades the question which alarms Mrs. Nelson. She tells him no which causes Ribaldi to become enraged and throws her out of the mansion. She manages to see Ribaldi's battle-scarred face.
Later, she tells Bonnie the bad news but Bonnie asks her permission to accept the job. Mrs. Nelson reluctantly agrees and she sends Bonnie to the mansion. For the moment, her only chores are to assist Hans.
He informs Bonnie that she is free to go into any room in the house, except for the master suite. He had to resort to bribery to keep her from asking why. However, she walks into the forbidden area once she hears a woman taking singing lessons from Mr. Ribaldi. He angrily grabs Bonnie but the woman (Gabriella) sends him away "to pout".
Meanwhile, many in the town are risking foreclosure and a result of the Depression and suspect the mysterious Ribaldi, who initially did the very same thing to The Nelsons.
The people in town were also receiving unknown sources of financial assistance. Some receive checks to pay for expensive medical procedures to heal crippling illnesses. A few others have found employment. The townspeople suspect nothing of any of this.
The children become curious and decide to prowl the mansion late at night. Their pranks are halted when the "bloodsucker" abducted a young girl who had walked with a limp. A riot occurs over the missing child, who reappears unharmed (and with no limp.)
Trouble still plagues the citizens who place the blame on Ribaldi and his apparent antisocial behavior. They manage to disqualify Bonnie unless she stops visiting him. She refuses but Ribaldi insists she goes and kicks her out of the mansion. However, Hans and Ribaldi are astonished.
Hans takes Bonnie to the competition at the state capital and prepares to sing a song written by Ribaldi.
Georgie walks into the mansion and finds Ribaldi by himself. She asks for singing lessons, but Ribaldi says it is not a good day. He offers to take her part of the way home but Georgie insists on taking a dangerous shortcut. She slips near a torrent and falls in the water.
The film returns to the competition, and it is now Bonnie's turn to sing.
Later, Mr. Ribaldi has an unconscious Georgie in his arms and he limps to find help. The townspeople think he battered her and so they attacked him. The town banker stops the attack. They proceed to the mansion in search of his bank book, leaving behind Ribaldi, Mrs. Nelson, and a few bystanders.
The film cuts to Bonnie, who finishes singing. She receives a standing ovation and first prize. 
The next scene, the angry mob breaks into the completely empty house, trashing it, and leave once they find the bank book. When opening the book they are delighted. Upon reading it however, they are shocked, disappointed, and saddened. They only find transactions proving that he has paid their medical bills.
The banker then admits to increasing their house payments. The mob leaves in disgust. The banker and his son take Mr. Ribaldi to the hospital.
Bonnie and Hans return only to find Mr. Ribaldi died a few hours ago. They hold a funeral. Later, Hans says he is returning home to a "former" employer.
After Hans departs, some of the people walk past the mansion. They hear familiar piano music. Bonnie walks in to discover man who resembles Ribaldi, but with no scars. The man seems to have no knowledge of previous events but then returns something Porter has left behind, despite having never met before.
Hans and Gabriella appear, and
Bonnie asks for the man's name. He says "Some people call me Rigoletto. But you probably don't believe that, would you?"
The movie ends with Bonnie reading the final lines of the story of the book "Rigoletto", and her brother asks, "do you believe that Bonnie?" She replies, "I do." and the film ends on a close-up of the book.
Characters.
Ari Ribaldi - Rigoletto (Joseph Paur) - Ari Ribaldi is a wounded man with a scarred face and walks with a limp. His injuries occurred when his nation (or Kingdom) was invaded by outsiders. This caused years of bitterness. Because the trauma was caused by outsiders, he had to leave his home to travel in search of an outsider to heal his pain. He moves to Castle Gate at the same time Bonnie is reading her story, in the same dilemma. He moves into an old mansion and supposedly, begins buying people's homes and land. He is a gifted singer and composer, who provided singing lessons to Bonnie.
Bonnie Nelson (Ivey Lloyd) - Bonnie is a naive and curious young girl who goes to work for Ribaldi in order to save her home. She eventually realizes that Ribaldi is not the monster he appears to be. She lives with her mother and brother, who exist both inside and outside of the book.
Hans (John Huntington) - Ribaldi's butler with a German accent. In the beginning of the film he is seen at one of Bonnie's singing competitions, and it is assumed that he has been sent there by Ribaldi to spy on the singers. Ribaldi treats him cruelly, but is convinced by Bonnie to give him singing lessons which resulted in disaster.
Margie Nelson (Cynthia Jump) - Mother of Bonnie and Timmy. She had rented a house from the local banker. He sold this house to Ribaldi, who evicted them. This was a lure to get her to confront Ribaldi. Without telling her why, he said he would give them their home as long as she agrees to let her daughter visit him. She cringes at Ribaldi, but is nowhere near as hateful compared to the other townspeople.
Timmy Nelson Timmy Nelson is the younger brother of Bonnie Nelson and the son of Mrs. Nelson.
Kathleen Hamilton (Natalie Terry) -
Kathleen Hamilton is a competitor in the talent contests, barely interacting with Bonnie and ridiculing Georgie. Bonnie loses to Kathleen, despite the audience reaction. Bonnie tries to get along with Kathleen because she believes hating Kathleen will not help her win the contests.
Georgie Baker (Alyson Brienholt) - One of Bonnie's friends, who wants to be a singer just like Bonnie. Georgie is mocked by Kathleen and a few others due to her old, filthy clothes and shoes. Georgie and her friends like to walk dangerous shortcuts of which Ribaldi rescued her when she fell and almost died.
Porter Baker (Ryan Healey) - Georgie's brother, who speaks with stutter and does not get along with his father. He cannot handle his father's temper and so runs away. In tears, he finds Ribaldi. He calms Porter and gives him advice. Also, he shows Porter "Snow White's magic mirror" and is suddenly cured of his speech impediment.
Elaina Papanikolas (Stephanie Paur) - Elaina is a young girl that wandered into Ribaldi's house. This causes the town to panic and hate Ribaldi, despite his medical care he had given to her foot.
Gabriella (Tracey Williams) - a princess who loves Mr. Ribaldi and takes singing lessons from him.
Dallin Avery (Dalin Christiansen) - A farmer and pig enthusiast. He treats his pigs as humans, loathes eating bacon, and ultimately had to sell his livestock to pay his mortgage. He somewhat judges people on behavior and actions instead of appearance. He did not approve of Mr. Ribaldi moving in so fast and believed Ribaldi to be a wealthy and aggressive banker. Mr. Avery was the leader of the angry mob.
Emelda Avery (Ruth Margaret Nickerson) - She was confined to a wheelchair until she was sent to the Winchester Clinic, courtesy of Ribaldi. She had a lengthy recovery but was expected to be able to walk afterwards.
Tommy Avery (Josh Goodwin)
Gordon Baker (Tom Nibley) - a temperamental drunk who yelled at his family. He did not get along with his son, who reprimanded him for his speech trouble. He loathed being poor and exploded when his daughter needed new shoes. This caused Porter to run away. When Ribaldi found out, he sent Mr. Baker away to find work.
Mr. Papanikolas (Frank Gerrish) - An eccentric man similar to Mr. Avery. After his daughter was found, he spontaneously threw a party.
Mrs. Papanikolas (Micaela Nelligan)
James McBride (Scott Wilkinson) - the town's banker who supported himself by increasing mortgage payments, demanding all past due to be paid immediately, and selling properties. He agreed to sell two of his properties to Ribaldi: an abandoned mansion, and the home of Mrs. Nelson. He also attempted to disqualify Bonnie.
The Crew.
The movie was written and directed by Leo D. Paur (brother of Ribaldi actor Joseph Paur), who formerly worked as a writer on animated series such as "The Transformers". There are several points analogous in the movie and the Verdi opera of the same name: there is a beautiful daughter, there is fighting with worlds, and there is a "curse", but the movie is otherwise unrelated.
Songs from the movie include: "Let Me In", "The Curse", "April Child", and "The Melody Within". "April Child" written by Chance Thomas, and the other three by Kurt Bestor.
The casting director for Rigoletto was Rick Macy.
Stage Versions.
Around the mid 1990s and early 2000s "Rigoletto" was performed as a stage musical. It was popular among church drama departments, middle schools, and community theatres. Even today church theatres perform Rigoletto.

</doc>
<doc id="65957" url="https://en.wikipedia.org/wiki?curid=65957" title="Rigoletto">
Rigoletto

Rigoletto () is an opera in three acts by Giuseppe Verdi. The Italian libretto was written by Francesco Maria Piave based on the play "Le roi s'amuse" by Victor Hugo. Despite serious initial problems with the Austrian censors who had control over northern Italian theatres at the time, the opera had a triumphant premiere at La Fenice in Venice on 11 March 1851.
It is considered by many to be the first of the operatic masterpieces of Verdi's middle-to-late career. Its tragic story revolves around the licentious Duke of Mantua, his hunch-backed court jester Rigoletto and Rigoletto's beautiful daughter Gilda. The opera's original title, "La maledizione" (The Curse), refers to the curse placed on both the Duke and Rigoletto by a courtier whose daughter had been seduced by the Duke with Rigoletto's encouragement. The curse comes to fruition when Gilda likewise falls in love with the Duke and eventually sacrifices her life to save him from the assassins hired by her father.
Composition history.
Verdi was commissioned to write a new opera by the La Fenice opera house in Venice in 1850. By this time he was already a well-known composer and had a degree of freedom in choosing the works he would prefer to set to music. He then asked Francesco Maria Piave (with whom he had already created "Ernani", "I due Foscari", "Macbeth", "Il Corsaro" and "Stiffelio") to examine the play "Kean" by Alexandre Dumas, père, but he felt he needed a more energetic subject to work on.
Verdi soon stumbled upon Victor Hugo's five-act play "Le roi s'amuse". He later explained that "The subject is grand, immense, and there is a character that is one of the greatest creations that the theatre can boast of, in any country and in all history." It was a highly controversial subject, and Hugo himself had already had trouble with censorship in France, which had banned productions after its first performance nearly twenty years earlier (it would not be performed again until 1882). As Austria at that time directly controlled much of Northern Italy, it came before the Austrian Board of Censors. Hugo's play depicted a king (Francis I of France) as an immoral and cynical womanizer, something that was not accepted in Europe during the Restoration period.
From the beginning, Verdi was aware of the risks, as was Piave. In a letter which Verdi wrote to Piave: "Use four legs, run through the town and find me an influential person who can obtain the permission for making "Le Roi s'amuse"." Correspondence between a prudent Piave and an already committed Verdi followed, but the two underestimated the power and the intentions of Austrians and remained at risk. Even the friendly Guglielmo Brenna, secretary of La Fenice, who had promised them that they would not have problems with the censors, was wrong. At the beginning of the summer of 1850, rumours started to spread that Austrian censorship was going to forbid the production. The censors considered the Hugo work to verge on "lèse majesté" and would never permit such a scandalous work to be performed in Venice. In August, Verdi and Piave prudently retired to Busseto, Verdi's hometown, to continue the composition and prepare a defensive scheme. They wrote to the theatre, assuring them that the censor's doubts about the morality of the work were not justified but since very little time was left, very little could be done. At the time, Piave and Verdi had titled the opera "La maledizione" (The Curse), and this unofficial title was used by Austrian censor De Gorzkowski in an emphatic letter written in December 1850 in which he definitively denied consent to its production, calling it "a repugnant of immorality and obscene triviality."
In order not to waste all their work, Piave tried to revise the libretto and was even able to pull from it another opera, "Il Duca di Vendome", in which the sovereign was with a duke and both the hunchback and the curse disappeared. Verdi was completely against this proposed solution and preferred instead to have direct negotiations with censors, arguing over each and every point of the work. At this point, Brenna, La Fenice's secretary, showed the Austrians some letters and articles depicting the bad character but the great value of the artist, helping to mediate the dispute. By January 1851 the parties were able to agree that the action of the opera would be moved from the royal court of France to a duchy of France or Italy, and some of the characters would have to be renamed. In the new version the Duke reigns over Mantua and belongs to the Gonzaga family. The House of Gonzaga had long been extinct by the mid-19th century, and the Dukedom of Mantua no longer existed, thus no one could be offended. The scene in which the sovereign retires to Gilda's bedroom would be deleted and the visit of the Duke to the "Taverna" (inn) was no longer intentional, but provoked by a trick. The hunchback jester (originally called Triboulet) was renamed Rigoletto from a parody of Hugo's play, "Rigoletti, ou Le dernier des fous" (Rigoletti, or The last of the fools). By 14 January, the opera's definitive title had become "Rigoletto".
Verdi finally completed the composition of the opera on 5 February 1851, a little more than a month before the premiere, although as he worked on the final stages of Act 3, Piave had already arranged for the sets to be designed. The singers were given some of their music to learn on 7 February. However, Verdi kept at least a third of the score at Busseto. He brought it with him when he arrived in Venice for the rehearsals on 19 February and would continue to refine the orchestration during the rehearsal period. For the première, La Fenice had cast Felice Varesi as Rigoletto, the young tenor Raffaele Mirate as the Duke, and Teresa Brambilla as Gilda (although Verdi would have preferred Teresa De Giuli Borsi). Due to the high risk of unauthorised copying, Verdi had demanded the maximum secrecy from all his singers and musicians. Mirate had use of his score only a few evenings before the première and had to swear that he would not sing or even whistle the tune of "La donna è mobile" except during the rehearsals.
Performance history.
19th-century productions
"Rigoletto" premiered on 11 March 1851 in a sold-out La Fenice as the first part of a double bill with Giacomo Panizza's ballet "Faust". Gaetano Mares conducted, and the sets were designed and executed by Giuseppe Bertoja and Francesco Bagnara. The opening night was a complete triumph, especially the "scena drammatica" and the Duke's cynical aria, "La donna è mobile", which was sung in the streets the next morning (Verdi had maximised the aria's impact by only revealing it to the cast and orchestra a few hours before the premiere, and forbidding them to sing, whistle or even think of the melody outside of the theatre). Many years later, Giulia Cora Varesi, the daughter of Felice Varesi (the original Rigoletto), described her father's performance at the premiere. Varesi was very uncomfortable with the false hump he had to wear; he was so uncertain that, even though he was quite an experienced singer, he had a panic attack when it was his turn to enter the stage. Verdi immediately realised he was paralysed and roughly pushed him on the stage, so he appeared with a clumsy tumble. The audience, thinking it was an intentional gag, was very amused.
"Rigoletto" was a great box-office success for La Fenice and Verdi's first major Italian triumph since the 1847 premiere of "Macbeth" in Florence. It initially had a run of 13 performances and was revived in Venice the following year, and again in 1854. Despite a rather disastrous production in Bergamo shortly after its initial run at La Fenice, the opera soon entered the repertory of Italian theatres. By 1852, it had premiered in all the major cities of Italy, although sometimes under different titles due to the vagaries of censorship (e.g. as "Viscardello", "Lionello", and "Clara de Perth"). From 1852, it also began to be performed in major cities worldwide, reaching as far afield as Alexandria and Constantinople in 1854 and both Montevideo and Havana in 1855. The UK premiere took place on 14 May 1853 at what is now the Royal Opera House, Covent Garden in London with Giovanni Matteo Mario as the Duke of Mantua and Giorgio Ronconi as Rigoletto. In the US, the opera was first seen on 19 February 1855 at New York's Academy of Music in a performance by the Max Maretzek Italian Opera Company.
20th century and beyond
In modern times, it has become a staple of the standard operatic repertoire. It appears as number 9 (with 395 performances) on the Operabase list of the most-performed operas worldwide between 2008/2009 and 2012/13 seasons, and was also the 9th most frequently performed opera in Italy during that period.
Several modern productions have radically changed the original setting. These include Jonathan Miller's 1982 production for the English National Opera, which is set amongst the Mafia in New York City's Little Italy during the 1950s; Doris Dorrie's 2005 production for the Bavarian State Opera, where the Court of Mantua became The Planet of the Apes; director Linda Brovsky's production for Seattle Opera, placing the story in Mussolini's fascist Italy, in 2004 (repeated in 2014); and Michael Mayer's 2013 production for the Metropolitan Opera, which is set in a casino in 1960's Las Vegas. Different characters portray different archetypes from the Rat Pack era, with the Duke becoming a Frank Sinatra-type character and Rigoletto becoming Don Rickles. In March 2014, Lindy Hume, artistic director of Australia's Opera Queensland staged the opera set in the party-going world of disgraced former Italian prime minister Silvio Berlusconi.
Synopsis.
Act 1.
"Scene 1: A room in the palace"
At a ball in his palace, the Duke sings of a life of pleasure with as many women as possible: "Questa o quella" ("This woman or that"). He has seen an unknown beauty in church and desires to possess her, but he also wishes to seduce the Countess of Ceprano. Rigoletto, the Duke's hunchbacked court jester, mocks the husbands of the ladies to whom the Duke is paying attention, and advises the Duke to get rid of them by prison or death. Marullo, one of the guests at the ball, informs the noblemen that Rigoletto has a "lover", and the noblemen cannot believe it. The noblemen resolve to take vengeance on Rigoletto. Subsequently Rigoletto mocks Count Monterone, whose daughter the Duke had seduced. Count Monterone is arrested at the Duke's order and curses the Duke and Rigoletto. The curse genuinely terrifies Rigoletto.
"Scene 2: A street, with the courtyard of Rigoletto's house"
Thinking of the curse, Rigoletto approaches his house and is accosted by the assassin Sparafucile, who walks up to him and offers his services. Rigoletto considers the proposition but finally declines; Sparafucile wanders off, after repeating his own name a few times. Rigoletto contemplates the similarities between the two of them: "Pari siamo!" ("We are alike!"); Sparafucile kills men with his sword, and Rigoletto uses "a tongue of malice" to stab his victims. Rigoletto opens a door in the wall and returns home to his daughter Gilda. They greet each other warmly: "Figlia!" "Mio padre!" ("Daughter!" "My father!"). Rigoletto has been concealing his daughter from the Duke and the rest of the city, and she does not know her father's occupation. Since he has forbidden her to appear in public, she has been nowhere except to church and does not even know her own father's name.
When Rigoletto has gone, the Duke appears and overhears Gilda confess to her nurse Giovanna that she feels guilty for not having told her father about a young man she had met at the church. She says that she fell in love with him, but that she would love him even more if he were a student and poor. As she declares her love, the Duke enters, overjoyed. Gilda, alarmed, calls for Giovanna, unaware that the Duke had sent her away. Pretending to be a student, the Duke convinces Gilda of his love: "È il sol dell'anima" ("Love is the sunshine of the soul"). When she asks for his name, he hesitantly calls himself Gualtier Maldè. Hearing sounds and fearing that her father has returned, Gilda sends the Duke away after they quickly trade vows of love: "Addio, addio" ("Farewell, farewell"). Alone, Gilda meditates on her love for the Duke, whom she believes is a student: "Gualtier Maldè!... Caro nome" ("Dearest name").
Later, a preoccupied Rigoletto returns: "Riedo!... perché?" ("I've returned!... why?"), while the hostile noblemen outside the walled garden (believing Gilda to be the jester's mistress, unaware she is his daughter) get ready to abduct the helpless girl. Convincing Rigoletto that they are actually abducting the Countess Ceprano, they blindfold him and use him to help with the abduction: "Zitti, zitti" ("Softly, softly"). With her father's unknowing assistance Gilda is carried away by the noblemen. Upon realizing that it was in fact Gilda who was carried away, Rigoletto collapses, remembering the curse.
Act 2.
"The Duke's Palace"
The Duke is concerned that Gilda has disappeared: "Ella mi fu rapita!" ("She was stolen from me!") and "Parmi veder le lagrime" ("I seem to see tears"). The noblemen then enter and inform him that they have captured Rigoletto's mistress. By their description, he recognizes it to be Gilda and rushes off to the room where she is held: "Possente amor mi chiama" ("Mighty love beckons me"). Pleased by the Duke's strange excitement, the courtiers now make sport with Rigoletto, who enters singing. He tries to find Gilda by pretending to be uncaring, as he fears she may fall into the hands of the Duke. Finally, he admits that he is in fact seeking his daughter and asks the courtiers to return her to him: "Cortigiani, vil razza dannata" ("Accursed race of courtiers"). Rigoletto attempts to run into the room in which Gilda is being held, but the noblemen beat him. Gilda rushes in and begs her father to send the people away. The men leave the room, believing Rigoletto has gone mad. Gilda describes to her father what has happened to her in the palace: "Tutte le feste al tempio" ("On all the blessed days"). In a duet Rigoletto demands vengeance against the Duke, while Gilda pleads for her lover: "Sì! Vendetta, tremenda vendetta!" ("Yes! Revenge, terrible revenge!").
Act 3.
"A street outside Sparafucile's house"
A portion of Sparafucile's house is seen, with two rooms open to the view of the audience. Rigoletto and Gilda, who still loves the Duke, arrive outside. The Duke's voice can be heard singing "La donna è mobile" ("Woman is fickle"), laying out the infidelity and fickle nature of women. Rigoletto makes Gilda realize that it is the Duke who is in the assassin's house attempting to seduce Sparafucile's sister, Maddalena: "Bella figlia dell’amore" ("Beautiful daughter of love").
Rigoletto bargains with the assassin, who is ready to murder his guest for money, and offers him 20 scudi to kill the Duke. He orders his daughter to put on a man's clothes to prepare to leave for Verona and states that he plans to follow later. With falling darkness, a thunderstorm approaches and the Duke determines to remain in the house. Sparafucile assigns to him the ground floor sleeping quarters.
Gilda, who still loves the Duke despite knowing him to be unfaithful, returns dressed as a man. She overhears Maddalena begging for the Duke's life, and Sparafucile promises her that if by midnight another can be found in place of the Duke, he will spare the Duke's life. Gilda resolves to sacrifice herself for the Duke and enters the house. She is immediately mortally wounded and collapses.
At midnight, when Rigoletto arrives with money, he receives a corpse wrapped in a sack, and rejoices in his triumph. Weighting it with stones, he is about to cast the sack into the river when he hears the voice of the Duke singing a reprise of his "La donna è mobile" aria. Bewildered, Rigoletto opens the sack and, to his despair, discovers his mortally wounded daughter. For a moment, she revives and declares she is glad to die for her beloved: "V'ho ingannato" ("Father, I deceived you"). She dies in his arms. Rigoletto's wildest fear materializes when he cries out in horror: "La maledizione!" ("The curse!")
Instrumentation.
The orchestra calls for 2 flutes (Flute 2 doubles piccolo), 2 oboes (Oboe 2 doubles English horn), 2 clarinets, 2 bassoons, 4 horns in Eb, D, C, Ab, G, and F, 2 trumpets in C, D, and Eb, 3 trombones, cimbasso, timpani, bass drum and cymbals, strings.
Music.
Musicologist Julian Budden regards the opera as "revolutionary", just as Beethoven' "Eroica" Symphony was: "the barriers between formal melody and recitative are down as never before. In the whole opera, there is only one conventional double aria [...and there are...] no concerted act finales." Verdi used that same word – "revolutionary" – in a letter to Piave, and Budden also refers to a letter which Verdi wrote in 1852 in which the composer states that "I conceived "Rigoletto" almost without arias, without finales but only an unending string of duets."
Budden's conclusions about this opera and its place in Verdi's output are summed up by noting that:
Recordings and adaptations.
There have been dozens of commercial recordings of "Rigoletto". The earliest ones include the 1912 performance in French with François Ruhlmann conducting the orchestra and chorus of the Opéra Comique (Pathé) and the 1916 performance in Italian with Lorenzo Molajoli conducting the orchestra and chorus of La Scala (Columbia Records). The first LP edition was released by RCA Victor in 1950 conducted by Renato Cellini and featured Leonard Warren in the title role. The opera has also been recorded in German with Wilhelm Schüchter conducting the orchestra and chorus of the Berlin State Opera in a 1953 recording for EMI Records and in English with Mark Elder conducting the orchestra and chorus of the English National Opera in a 1983 recording for EMI. In the 21st century there have been several live performances released on DVD including a 2001 performance from London's Royal Opera House with Paolo Gavanelli as Rigoletto and Marcelo Álvarez as the Duke (BBC/Opus Arte) and a 2006 performance at the Opernhaus Zürich with Leo Nucci as Rigoletto and Piotr Beczala as The Duke (ArtHaus Musik). The Duke of Mantua's arias, particularly "La donna è mobile" and "Questa o quella", have long been showcases for the tenor voice and appear on numerous recital discs. Amongst Enrico Caruso's earliest recordings are both these arias, recorded with piano accompaniment in 1903 and again in 1906 with a full orchestra. Luciano Pavarotti, who has recorded the arias for several recital discs, also sings The Duke on three complete studio recordings of the opera: Decca (1972) conducted by Richard Bonynge; Decca (1989) conducted by Riccardo Chailly and Deutsche Grammophon (1993) conducted by James Levine.
"Rigoletto" has been a popular subject for movies since the silent film era. On 15 April 1923, Lee DeForest presented 18 short films in his sound-on-film process Phonofilm, including an excerpt of Act Two of "Rigoletto" with Eva Leoni and Company. One of the most famous films based on the opera is the 1982 film by Jean-Pierre Ponnelle starring Luciano Pavarotti as The Duke and Ingvar Wixell as Rigoletto. Some film versions, such as the 1993 children's film "Rigoletto", are based on the opera's plot, but do not use Verdi's music. Curtiss Clayton's 2003 film "Rick", set in modern-day New York, has a plot based on "Rigoletto", but apart from "La donna è mobile" heard in the background during a restaurant scene, does not include any other music from the opera. In the 21st century, the opera was filmed as "Rigoletto Story" directed by Vittorio Sgarbi with costumes by Vivienne Westwood. First screened at the Venice Biennale in 2004, it subsequently received two Grammy nominations. In September 2010, RAI Television filmed the opera on location in Mantua with the court scenes taking place in the Palazzo Te. The film faithfully followed Verdi's original specification for the action to take place over two days, and each act was performed at the time of day indicated in the libretto. Broadcast live to 148 countries, the film starred Plácido Domingo in the title role, and Vittorio Grigolo as The Duke. The plot of the film "Quartet" revolves around the quartet "Bella figlia dell’amore", with which the film concludes.
Adaptations of the opera's music include Franz Liszt's "Rigoletto Paraphrase", a piano transcription of "Bella figlia dell’amore" (the famous quartet from Act 3) and a Fantasia on "Rigoletto" (Op.82) by Sigismond Thalberg which was published in Paris in the 1860s.
References.
Notes
Cited sources
Other sources

</doc>
<doc id="65959" url="https://en.wikipedia.org/wiki?curid=65959" title="Xukuru people">
Xukuru people

The Xukuru (Xucuru) are an indigenous people of Brazil, with a population of approximately 8,500, living in the state of Pernambuco, Brazil. They have recently gained governmental recognition of their rights to their indigenous homeland in the Ororubo Mountains, though this has brought them into conflict with the local settler population of the region. In 1998, a Xukuru leader, Chicão (Francisco Lacerda), was assassinated, apparently because of his opposition to the encroachment of ranchers in Xukuru territory. However his children carried on his legacy.

</doc>
<doc id="65961" url="https://en.wikipedia.org/wiki?curid=65961" title="Pete Sampras">
Pete Sampras

Petros "Pete" Sampras (born August 12, 1971) is a retired American tennis player and former world No. 1 regarded as being one of the greatest players in tennis history. He debuted on the professional tour in 1988 and finished his career at the 2002 US Open, which he won, defeating rival Andre Agassi in the final. He was particularly esteemed for his precise serve, earning the nickname "Pistol Pete".
Sampras became the first professional to break Roy Emerson's pre-Open Era record of 12 Grand Slam singles titles and retired with 14 titles (seven Wimbledon, five US Open, two Australian Open), though this is no longer the record. He also won seven elite indoor titles (five ATP World Tour Finals and two Grand Slam Cups) and still holds the ATP record of six year-end No. 1 rankings, which were in consecutive years from 1993 through 1998.
Tennis career.
Early life and career.
Sampras was born in Washington, D.C., the third child of Sammy and Georgia Sampras. His mother emigrated from Sparta, Greece, and his father was born in the United States to a Greek father and a Jewish mother. He attended regular services of the Greek Orthodox Church on Sundays.
From an early age, Sampras showed signs of outstanding athletic ability. At the age of 3, Sampras discovered a tennis racket in the basement of his home and spent hours hitting balls against the wall.
In 1978, the Sampras family moved to Palos Verdes, California, and the warmer climate there allowed the seven-year-old Sampras to play more tennis. From early on, his great idol was Rod Laver, and at the age of 11, Sampras met and played with him. The Sampras family joined the Jack Kramer Club, and it was here that Sampras's talent became apparent. He was spotted by Peter Fischer, a pediatrician and tennis enthusiast, who coached Sampras until 1989. Fischer was responsible for converting Sampras's double-handed backhand to single-handed with the goal of being better prepared to win Wimbledon.
1988–1990.
Sampras turned professional in 1988, at the age of 16, and finished the year ranked World No. 97 after starting the year at World No. 893. His first professional match was a loss to Sammy Giammalva, Jr. at the February Ebel U.S. Pro Indoor in Philadelphia. However, just one week later at the Lipton International Players Championships in Miami, Sampras defeated two top-40 players before losing to world number 18 Emilio Sánchez. He did not defeat another top-40 player for almost six months, when he defeated World No. 39 Michiel Schapers at a US Open warm-up tournament in Rye Brook, New York. In his first Grand Slam singles match, Sampras lost to World No. 69 Jaime Yzaga of Peru in the first round of the US Open. Sampras did not advance past the quarterfinals in his next three tournaments, although he did record wins over World No. 79 Jim Courier in their first career match-up, and world number 8 Tim Mayotte.
The following year, Sampras slightly improved his ranking to a year-ending world number 81. He lost in the first round of the 1989 Australian Open to Christian Saceanu and the first round of Wimbledon to Todd Woodbridge. He won a Grand Slam singles match for the first time at the French Open, before losing in the second round to eventual champion, 17-year-old Michael Chang, in their first career match-up. At the US Open, Sampras defeated defending champion and fifth-seeded Mats Wilander in the second round before losing to World No. 13 Jay Berger in the fourth round. To end the year, Sampras lost in the first round of four consecutive tournaments.
Sampras finished 1990 at World No. 5, having started the year ranked World No. 61 just prior to the start of the Australian Open. He lost to Wilander in the quarterfinals of the tournament in Sydney. At the Australian Open, Sampras upset twelfth-ranked Mayotte in the first round before losing to thirteenth-ranked Yannick Noah in the fourth round in four sets. His first professional singles title came in February at the Ebel U.S. Pro Indoor in Philadelphia, where he defeated sixth-ranked Andre Agassi, eighth-ranked Mayotte, and eighteenth-ranked Andrés Gómez in the final. This title elevated his ranking into the top 20 for the first time.
Sampras did not play in the 1990 French Open and again lost in the first round of Wimbledon, this time to Christo van Rensburg. Sampras played seven consecutive weeks during the North American summer hard-court season. He defeated John McEnroe in the quarterfinals of the Canadian Open, but then lost to Chang in the semifinals. He also reached the semifinals of the tournament in Los Angeles, where he lost to World No. 2 Stefan Edberg. He did not advance past the quarterfinals in his next three tournaments, losing to Chang, Richey Reneberg, and Goran Ivanišević.
In September, Sampras captured his first Grand Slam title at the US Open. Along the way, he defeated sixth-ranked Thomas Muster in the fourth round and third-ranked Ivan Lendl in a five-set quarterfinal, breaking Lendl's streak of eight consecutive US Open finals. He then defeated 20th-ranked McEnroe in a four-set semifinal to set up a final with fourth-ranked Agassi. Sampras beat Agassi in straight sets to become the US Open's youngest-ever male singles champion at the age of 19 years and 28 days. He played five more tournaments and won the Grand Slam Cup to complete his year.
1991–1992.
In 1991, Sampras captured the first of his five career titles at the year-end Tennis Masters Cup. Upon entering the US Open as the defending champion that year, he caused controversy when, after losing in the quarterfinals to Jim Courier, Sampras said that he was not disappointed and felt relieved that the pressure to defend his title was no longer on him. This led to widespread criticism, which included disparaging remarks from Courier and Jimmy Connors.
In 1992, Sampras reached the quarter finals of the French Open for the first of three consecutive years, made it to the Wimbledon semifinals, and was the runner-up at the US Open to Stefan Edberg. Sampras later stated that his loss in the US Open final that year was a "wake-up call" and that he needed to figure out how to become the world number 1. He also played doubles with John McEnroe on the US team that won the Davis Cup, duplicating the feat in 1995.
1992 was also the year when Sampras made his only appearance at a Summer Olympics. The event was played on clay, which was considered his worst surface. Nonetheless, Sampras advanced to the third round before giving up a two-set lead and losing to Andrei Cherkasov of Russia.
1993–1996.
Sampras reached the semifinals of the Australian Open in early 1993, losing again to Stefan Edberg and matched the previous year's quarterfinal performance at the French Open. In April 1993, Sampras attained the world number 1 ranking for the first time. His rise to the top of the rankings was controversial because he had not recently won any Grand Slam titles, but he justified his ranking three months later by claiming his first Wimbledon title, beating former world number 1 Jim Courier in the final. This was followed by his second US Open title. He finished the year as the clear no. 1 and set a new ATP Tour record that year by becoming the first player to serve more than 1,000 aces in a season.
Except for a loss in the 1996 quarterfinals to eventual winner Richard Krajicek, Sampras continued to win at Wimbledon for the rest of the decade, becoming the most successful male player in Wimbledon history.
Sampras won the first of two Australian Open titles in 1994, defeating American Todd Martin in the final. In 1995, Sampras experienced one of the most emotional matches of his career, when he played Courier in the quarterfinals. Sampras' longtime coach and close friend, Tim Gullikson, had mysteriously collapsed during the tournament and was forced to return to the United States. Gullikson was later diagnosed with brain cancer, to which he succumbed the following year. Saddened by Gullikson's illness, Sampras began visibly weeping during the match, but managed to win. He lost the final to Agassi. Paul Annacone took over as Sampras' full-time coach after Gullikson's illness made it impossible for him to continue coaching.
Sampras's best surface was undoubtedly the fast-playing grass courts, He was also known for his all-round game and strong competitive instinct. He won back-to-back US Open titles in 1995 and 1996, despite vomiting on the court at 1–1 in the final set tiebreak due to dehydration in the 1996 quarterfinals against Àlex Corretja.
Sampras's only real weakness was on clay courts, where the slow surface tempered his natural attacking serve-and-volley game. His best performance at the French Open came in 1996, when he lost a semifinal match to the eventual winner, Yevgeny Kafelnikov.
Despite his limited success at Roland Garros, Sampras did win some significant matches on clay. He won a 1992 clay court tournament in Kitzbühel, defeating Alberto Mancini in the final. He won the prestigious Italian Open in 1994, defeating Boris Becker in the final, and two singles matches in the 1995 Davis Cup final against Russians Andrei Chesnokov and Yevgeny Kafelnikov in Moscow. Sampras also won a 1998 clay court tournament in Atlanta, defeating Jason Stoltenberg in the final.
1997.
Sampras won his second Australian Open title in January, defeating Carlos Moyá in the final. In July, he won Wimbledon for the fourth time, defeating Cédric Pioline in the final. Sampras also won singles titles in San Jose, Philadelphia, Cincinnati, Munich, and Paris, and the ATP Tour World Championships in Hanover, Germany. He became the only player to win both the Grand Slam Cup and the ATP Tour World Championships in the same year.
He had a 10–1 win–loss record against top-10 opponents and was undefeated in eight singles finals. He held the world number 1 ranking for the entire year and joined Jimmy Connors (1974–1978) as the only male players to hold the year-end world number 1 ranking for five consecutive years. His prize money earnings of US$6,498,211 for the year was a career high.
1998.
In 1998, Sampras's no. 1 ranking was challenged by Chilean player Marcelo Ríos. (In 1993, 1994, 1995, 1996, and 1997, Sampras had finished as the year-end world number one player.) Sampras failed to defend his Australian Open title, losing in the quarterfinals to Karol Kučera, and won Wimbledon only after a hard-fought five-set victory over Goran Ivanišević. Sampras lost a five-set US Open semifinal to the eventual winner Patrick Rafter, after leading the match two sets to one. He lost another semifinal at the Tennis Masters Cup to eventual champion Àlex Corretja. Nevertheless, Sampras finished the year as the top-ranked player for the sixth year in a row.
1999.
This year also started out disappointingly, as Sampras withdrew from the Australian Open and failed to win a title during the early part of the season. However, he then went on a 24-match winning streak, including the Stella Artois Championships, Wimbledon (equaling Roy Emerson's record of 12 Grand Slam singles titles), Los Angeles, and Cincinnati. His victory over Andre Agassi in the Wimbledon final is often cited as one of Sampras' greatest performances (despite this, he lost his no. 1 ranking to Agassi the following day, when ATP Tour rankings were updated). That run ended when he was forced to retire from the RCA Championships and the US Open because of a herniated disc in his back.
Sampras' ranking was hurt through a combination of withdrawing from the Australian and US Opens, tournaments in which he had strong performances during the previous year, and the resurgence of longtime rival Agassi, putting an end to Sampras' six consecutive years of finishing as world number 1. Agassi took over the top ranking and held it for the rest of the season, but Sampras recovered and managed to beat him in the season-ending Tennis Masters Cup for the fifth and final time, enabling Sampras to place third in the rankings.
In a 1999 Master's final against Patrick Rafter, in Cincinnati, one of Pete's serves burst right through the strings of Rafter's racket, when he attempted to return it. It appeared as if hit by a shotgun blast.
2000–2002.
Sampras reached the semifinals of the Australian Open in early 2000 (falling to the eventual champion Agassi in a five-set match) and won the Ericsson Open in Key Biscayne, Florida for the third time in March. He then won a record-breaking 13th Grand Slam title at Wimbledon, battling through tendinitis in his right shin and a painful back injury in the process. This victory was his eighth consecutive year winning in a Grand Slam final (starting at 1993 Wimbledon), a record in the Open Era until being surpassed by Rafael Nadal in 2013. After this victory, Sampras did not win another title for more than two years.
Sampras lost handily in the finals of the 2000 and 2001 US Open to Marat Safin and Lleyton Hewitt, respectively, leading many to speculate that Sampras would never capture another major title. At the 2001 Wimbledon Championships, Sampras lost to Roger Federer, then aged 19, 6–7(7), 7–5, 4–6, 7–6(2), 5–7, in the fourth round, ending Sampras' 31-match winning streak at Wimbledon, and a match that marked the only time that the two men ever played each other on the ATP tour. Federer would go on to equal Sampras' record of 7 Wimbledon victories, and break his record of 14 Grand Slam titles. At the 2001 US Open, Sampras defeated Patrick Rafter, Andre Agassi and Marat Safin in the round of sixteen, quarterfinals, and semi-finals, respectively. In the final, Sampras was beaten in straight sets by Lleyton Hewitt.
In 2002, Sampras suffered an early exit from Wimbledon, losing in the second round to no. 145 fast-court specialist George Bastl of Switzerland. After that loss, Sampras asked his former coach Paul Annacone to return and coach through the US Open. Sampras had a relatively poor summer leading up to the US Open, losing at Cincinnati to No. 70-ranked Wayne Arthurs in the second round, and then being eliminated at the opening round at Long Island by No. 85. Paul-Henri Mathieu.
At the US Open, Sampras was seeded 17th. Greg Rusedski, whom Sampras had defeated in a long five-set third round match at the US Open, said that Sampras was "a step and a half slower" and predicted that Sampras would lose his next match. Sampras, however, then defeated two young stars, Tommy Haas in the fourth round and Andy Roddick in the quarterfinals. He then defeated Sjeng Schalken in the semifinals to reach his third straight US Open final, and eighth US Open final overall, tying Ivan Lendl's all-time record. This time, he faced Agassi, whom he had met in his very first Grand Slam final 12 years earlier. After a four-set battle between the two veterans, Sampras claimed a then-record 14th Grand Slam singles title and matched Jimmy Connors' record of five US Open singles championships.
Sampras did not compete in any tour events in the following 12 months, but he did not officially announce his retirement until August 2003, just prior to the US Open. He chose not to defend his title there, but his retirement announcement was timed so that he could say farewell at a special ceremony organized for him at the Open. At the time of his retirement, many regarded Sampras as the greatest player of all time.
Sampras won 64 top-level singles titles (including 14 Grand Slam titles, 11 Super 9/ATP Masters Series/ATP World Tour Masters 1000 titles and five Tennis Masters Cup titles) and two doubles titles. He was ranked the world number 1 for a total of 286 weeks (the second most of all-time) and was year-end no. 1 for a record six consecutive years from 1993 through 1998.
Post-retirement activity.
On April 6, 2006, three and a half years after his retirement, Sampras resurfaced and played his first exhibition match in River Oaks, Houston, Texas, against 23-year-old Robby Ginepri. Ginepri won the match in two sets. Sampras later announced that he would be playing in World Team Tennis events.
2007 saw Sampras announcing that he would play in a few events on the Outback Champions Series, a group of tournaments for former ATP players who have met certain criteria during their careers. Sampras won his first two events on tour, defeating Todd Martin in both finals (one of which included Sampras's first trip to his ancestral homeland, Greece). Many observers noted that despite his lengthy layoff from competitive tournaments, Sampras still possessed many of the previous skills he had displayed while on the ATP tour, with tennis legend John McEnroe going as far as to say that Sampras would be worthy of a top five seeding at Wimbledon were he to enter the tournament.
On November 20, 2007, Sampras lost the first of three exhibition matches in Asia against Roger Federer in Seoul, Korea. Two days later in Kuala Lumpur, Sampras again lost to Federer in two tiebreaks. However, Sampras was able to win the last match of the series, winning in two sets on fast carpet.
On February 18, 2008, in an exhibition match during the SAP Open, Sampras defeated another active player, former world No. 2 Tommy Haas. Sampras dispatched the German in 43 minutes.
On March 10, 2008, Sampras played another exhibition match against world No. 1 Roger Federer at Madison Square Garden in New York City. Sampras once again lost the match in three tight sets.
In 2009 Sampras won two Outback Champions Series titles. He defeated McEnroe in the final of the Champions Cup Boston in February and Patrick Rafter in the final of The Del Mar Development Champions Cup in March.
Sampras was present at the 2009 Wimbledon final between Andy Roddick and Roger Federer to witness Federer eclipse his mark of 14 major titles and become the most successful man in Grand Slam history. Sampras's record of 14 majors had lasted for seven years.
The following year along with Federer, Andre Agassi and Rafael Nadal, he played an exhibition doubles match at Indian Wells to raise money for the people of Haiti who had been affected by the earthquake.
In November 2010 Sampras reported that many of his trophies and memorabilia had been stolen from a West Los Angeles public storage facility. The loss included the trophy from his first Australian Open victory, two Davis Cups, an Olympic ring and six trophies for finishing top in the year-end rankings. Most of the stolen items have since been recovered and returned.
On November 17, 2011, Sampras played and lost an exhibition match against Milos Raonic. Sampras’ serve approached 200 km/h throughout the night.
Rivalries.
Sampras vs. Agassi.
Sampras won 20 of the 34 matches he played against Agassi.
The 1990 US Open was their first meeting in a Grand Slam tournament final. Agassi was favored because he was ranked world number 4, compared to the world number 12 ranking of Sampras and because Agassi had defeated Sampras in their only previously completed match. However, Agassi lost the final to Sampras in straight sets.
Their next meeting in a Grand Slam was at the 1992 French Open, where they met in the quarterfinals. Although Sampras was higher ranked, Agassi prevailed in straight sets. Their next Grand Slam meeting was at the quarterfinals of Wimbledon in 1993, where Agassi was the defending champion and Sampras was the newly minted world number 1. Sampras prevailed in five sets, and went on to win his first Wimbledon championship.
With both Sampras and Agassi participating, the U.S. won the Davis Cup in 1995. Notable Sampras-Agassi matches of 1995 included the finals of the Australian Open, the Newsweek Champions Cup, the Lipton International Players Championships, the Canadian Open, and the US Open, with Sampras winning the Newsweek Champions Cup and the US Open.
The next time Sampras and Agassi met in a Grand Slam final was at Wimbledon in 1999, where Sampras won in straight sets. For both, it was considered a career rejuvenation, as Sampras had suffered a string of disappointments in the last year while Agassi was regaining his status as a top-ranked player after winning the French Open. Sampras forfeited the world number 1 ranking to Agassi when injury forced Sampras to withdraw from that year's US Open, which Agassi went on to win. They faced each other twice in the season-ending ATP Tour World Championships, with Sampras losing the round-robin match, but winning the final.
They played each other only once in 2000. The top-ranked Agassi defeated world number 3 Sampras in the semifinals of the Australian Open in five sets.
In arguably their most memorable match, Sampras defeated Agassi in the 2001 US Open quarterfinals 6–7, 7–6, 7–6, 7–6. There were no breaks of serve during the entire match. Reruns of the match are frequently featured on television, especially during US Open rain delays.
The final of the 2002 US Open was their first meeting in a US Open final since 1995. The match also was notable because they had defeated several up-and-coming players en route to the final. Sampras had defeated world number 3 Tommy Haas in the fourth round and future world number 1 Andy Roddick in the quarterfinals, while Agassi had defeated world number 1 and defending champion Lleyton Hewitt in the semifinals. Sampras defeated Agassi in four sets. This was the final ATP tour singles match of Sampras's career.
On August 2010 Sampras played an exhibition game with Andre Agassi at the indoor arena Coliseo Cubierto El Campin in Bogotá, Colombia.
Sampras vs. Rafter.
Sampras won 12 of the 16 matches he played against Rafter, including eight of their first nine.
Their rivalry began to truly develop after Rafter shocked the tennis world by winning the 1997 US Open, a tournament that many expected Sampras to win, having won in 1995 and 1996. The win catapulted Rafter to the year-end no. 2 rankings behind Sampras. Many, including seven-time Grand Slam champion John McEnroe believed Rafter to be a "one-slam wonder", since it was only his second career ATP title.
In 1998, after Rafter defeated Sampras in the Cincinnati Masters final, Sampras, at the time winner of 11 Grand Slams, when asked about the difference between himself and Rafter, famously stated "Ten grand slams", that a controversial line-call cost him the match, and that a player had to come back and win another Grand Slam title in order to be considered great. During that match Rafter's serve was called out, but the umpire overruled the call to give Rafter the ace and the Cincinnati title. In displeasure, Sampras stood at the baseline for several seconds, making the victorious Rafter wait at the net, and then refused to shake the umpire's hand. Rafter went on to win the Canadian Masters as well, earning the third seed at the 1998 US Open.
The two met in the semifinals of the 1998 US Open, with Rafter winning in five sets. Sampras's loss denied him the chance to match two records—Jimmy Connors' mark of five U.S. Open titles and Roy Emerson's record of 12 Grand Slam singles titles. Sampras cited a leg injury as the reason Rafter won, an attitude that upset the generally mild-mannered Aussie: "He really does say some funny things at the wrong time", said Rafter, "We are out there busting our guts and he doesn't show a lot of respect at the end of the day. He tries to play down the reason why he lost, giving no respect to the other player, and that is what really upsets me about him and the reason I try to piss him off as much as I can."
Following Rafter's successful defense of his 1997 U.S. Open title by defeating Mark Philippoussis in the 1998 final, when asked about Sampras' earlier comments about having to win another Grand Slam in order to be considered great, Rafter replied: "Maybe you can ask him that question, if he thinks that now. For me, I won another Slam, and it hasn't sunk in yet. It's very, very exciting for me, especially to repeat it". For his part, Sampras said about Rafter, "When I see him holding the US Open trophy, it pisses me off."
After losing for a third consecutive time against Rafter in the early part of the 1999 season, Sampras won their final four meetings, including a victory in the 2000 Wimbledon final (after Rafter overcame Agassi in the semi-finals), with Sampras losing the first set tiebreaker and trailing in the second-set tiebreaker but eventually winning that set and then the next two sets for the Championship. That victory gave Sampras his 13th Grand Slam title, breaking the record of 12 by Roy Emerson for the most Grand Slam titles in history, until Roger Federer broke the record by winning Wimbledon in 2009.
Playing style.
Sampras was an all-court player who would often serve and volley. Possessing an all-around skill, in the early years of his career, when not serving, his strategy was to be offensive from the baseline, put opponents in a defensive position, and finish points at the net. In his later years, he became even more offensive and would either employ a chip-and-charge strategy or try to hit an offensive shot on the return and follow his return to the net.
He was known for producing aces on critical points, even with his second serves. He had an accurate and powerful first serve, one of the best of all time. His second serve was nearly as powerful as his first. He had great disguise on both his first and second serves.
Sampras was able to hit winners from both his forehand and backhand from all over the court. He was able to catch attacks wide to his forehand using his speed and hitting a forehand shot on the run. When successfully executed, he won many points outright or put opponents immediately on the defensive, because of the extreme pace and flat nature of the shot. This style didn't help him on clay courts according to some critics.
Equipment.
Sampras used one racket type, the Wilson Pro Staff Original, for his entire professional career—a racket first introduced in 1983. He played with Babolat natural gut, with all his rackets re-strung before each match (used or not) at 75 lbs tension (more or less, depending on conditions). His rackets had weight added to bring them close to 400 g, but the frame proper was a production model manufactured at a Wilson factory on the Caribbean island of St. Vincent. The handles were custom-built.
Post-retirement, Sampras has used a slightly modified Pro Staff Tour 90 and, from 2008, a new version of the original Pro Staff, produced with in-between head size of 88 square inches and heavier weight at 349 grams unstrung.
Since mid-2010, Sampras has been spotted at multiple exhibitions playing with a Babolat Pure Storm Tour, along with Babolat's popular RPM Blast strings.
"I need a little more pop...I need it if I'm going to play some tennis," he said after playing Gael Monfils in an exhibition at the SAP Open.
During a good part of 2011, Sampras used a racquet that was painted all black, with Tourna Grip and Tourna Damper.
In the late 1980s, Sampras signed a three-year endorsement contract with Sergio Tacchini. It was extended to five years before Sampras signed with Nike in 1994. He wore Nike apparel and Nike Air Oscillate footwear on court.
Personal and family life.
Pete's father and mother are from Greece. Sampras's older sister, Stella Sampras Webster, is the women's tennis head coach at UCLA, and his younger sister, Marion, is a teacher in Los Angeles. His older brother, Gus, has been tournament director at the Scottsdale ATP event, but in 2007 he became president of the firm managing Pete's business activities.
On September 30, 2000, Sampras married American actress and former Miss Teen USA, Bridgette Wilson. On November 21, 2002, their son, Christian Charles Sampras, was born. On July 29, 2005, the couple welcomed their second son, Ryan Nikolaos Sampras. They reside in Lake Sherwood, California.
Sampras has β-thalassemia minor, a genetic trait that sometimes causes mild anemia.
Records and achievements.
Other achievements.
(Federer 7 US Open and 10 Wimbledon).
Other awards.
Summary of professional awards.

</doc>
<doc id="65962" url="https://en.wikipedia.org/wiki?curid=65962" title="George Everest">
George Everest

Colonel Sir George Everest (; 4 July 1790 — 1 December 1866) was a Welsh surveyor and geographer, and the Surveyor General of India from 1830 through 1843.
Everest was largely responsible for completing the section of the Great Trigonometric Survey of India along the meridian arc from southern India extending north to Nepal, a distance of about . This survey was started by William Lambton in 1806 and it lasted for several decades.
In 1865, Mount Everest was named in his honour in the English language despite his objections by the Royal Geographical Society. This enormous peak was surveyed by Everest's successor, Andrew Scott Waugh, in his role as the Surveyor-General of India.
Biography.
Everest was born in Gwernvale Manor, just west of Crickhowell in Powys, Wales, in 1790, and he was baptised in Greenwich.
Commissioned into the Royal Artillery, in 1818, Lt. Everest was appointed as assistant to Colonel William Lambton, who had started the Great Trigonometrical Survey of the subcontinent in 1806. On Lambton's death in 1823, Everest succeeded to the post of superintendent of the survey, and in 1830 he was appointed as the Surveyor-General of India.
Everest retired in 1843 and he returned to the UK, where he became a Fellow of the Royal Society. He was dubbed a knight in 1861, and in 1862 he was elected as the vice-president of the Royal Geographical Society. Everest died in London in 1866 and is buried in St Andrew's Church, Hove, near Brighton.
Everest's house in Mussoorie, India.
Everest owned a house in Mussoorie, Uttarakhand, India, for about 11 years. He purchased it, sight unseen, from General Whish. Although now virtually derelict, it still has its roof, and there have been various plans to make it into a museum.
Built in 1832, the house is known today as Sir George Everest's House and Laboratory, or Park House. The house is situated in Park Estate about west of Gandhi Chowk / Library Bazaar, (the west end of Mall Road in Mussoorie). Its location has panoramic views of the Doon Valley on one side and the Aglar River valley and the Himalayan Range to the north.
The house is under the jurisdiction of the Tourism Department. These underground water cisterns (or perhaps pits for storing ice, although water is scarce in the area) are quite deep and lie uncovered in the front yard outside the house, filled with litter and posing danger of slipping. 
The interior has been stripped but the fireplaces, roof, and the door and window frames still remain. The house is secured by steel grills and cannot be entered. Now that this property is better known and the access road has been improved, the walls are covered with graffiti and then periodically whitewashed clean. 
Recent new fencing, tree planting and the construction of a ticket booth (as of late 2015) indicate that at some point it will cost to enter the property. The inside has signs of renovation several years ago, such as ceramic floor tiles in the kitchen and electrical switch boxes. Conservation architects at the Indian National Trust are vying for this project.
Family.
Sir George had several siblings, including two younger brothers. George's first younger brother was the Rev. Robert Everest, M.A., chaplain to the East India Company and author of A Journey Through the United States and Part of Canada. His second (his youngest brother) was the Rev. Thomas Roupell Everest, M.A., the father of Mary Everest and a lay homeopath.
Sir George's third daughter, Ethel Everest, was an associate of Emma Cons, and friend of Lilian Baylis. She provided financial support for the founding of Morley College in south London.
One of Sir George's sons, Lancelot Feilding Everest, was educated at Harrow and Trinity College, Cambridge, and was called to the Bar by Lincoln's Inn. He practised as a barrister in chambers in London and was also the principal author of The Law of Estoppel.
Sir George's niece, Mary Everest, married mathematician George Boole in Gloucestershire on 11 September 1855. In spite of the absence of formal training, Mary was a fine mathematician in her own right, as was one of her daughters, Alicia Boole Stott. Alicia's son, Leonard Boole Stott, studied medicine and became a pioneer in the treatment and control of tuberculosis, work for which he was later appointed an O.B.E. Mary Boole's daughter Margaret was the mother of Sir Geoffrey Ingram Taylor OM, a graduate of Trinity College, Cambridge, a renowned mathematician and physicist, and a major figure in fluid dynamics and wave theory.
Pronunciation of "Everest".
Sir George's surname is pronounced . (i.e. Eve-rest with "Eve" pronounced as in the woman's name). The mountain named after him – "Mount Everest" – is generally pronounced or (i.e. Ever-est with ever as in evermore).

</doc>
<doc id="65964" url="https://en.wikipedia.org/wiki?curid=65964" title="Pétanque">
Pétanque

Pétanque (; ) is a form of boules where the goal is to throw hollow metal balls as close as possible to a small wooden ball called a "cochonnet" (literally "piglet") or jack, while standing inside a circle with both feet on the ground. The game is normally played on hard dirt or gravel. It can be played in public areas in parks, or in dedicated facilities called "boulodromes". Similar games are bocce, bowls and (adapted to ice) curling.
The current form of the game originated in 1907 or 1910 in La Ciotat, in Provence, France. The French name "pétanque" (borrowed into English, with or without the acute accent) comes from "petanca" in the Provençal dialect of the Occitan language, deriving from the expression "pès tancats" , meaning 'feet fixed' or 'feet planted' (on the ground).
History.
Boules games, broadly speaking, are games that involve rolling or throwing balls toward some sort of target. The category includes such games as (French) petanque, (Italian) bocce, (English) lawn bowling, and (American) bowling. Boules games have a very long history.
Boules games in history.
As early as the 6th century BC the ancient Greeks are recorded to have played a game of tossing coins, then flat stones, and later stone balls, called "spheristics", trying to have them go as far as possible. The ancient Romans modified the game by adding a target that had to be approached as closely as possible. This Roman variation was brought to Provence by Roman soldiers and sailors. A Roman sepulchre in Florence shows people playing this game, stooping down to measure the points.
After the Romans, the stone balls were replaced by wooden balls. In the Middle Ages, Erasmus referred to the game as "globurum," but it became commonly known as "boules" (i.e. 'balls'), and it was played throughout Europe. King Henry III of England banned the playing of the game by his archers — he wanted them to be practicing archery, not playing boules. In the 14th century, Charles IV and Charles V of France forbade the sport to commoners; only in the 17th century was the ban lifted.
By the 19th century, in England the game had become "bowls" or "lawn bowling". In France it was known as "boules" and was played throughout the country. The French artist Meissonnier made two paintings showing people playing the game, and Honoré de Balzac described a match in "La Comédie Humaine".
In the South of France the game evolved into "jeu provençal" (or "boule lyonnaise"), similar to today's pétanque, except that the playing area was longer and players ran three steps before throwing the ball. The game was played in villages all over Provence, usually on squares of land in the shade of plane trees. Matches of "jeu provençal" around the start of the 20th century are memorably described in the memoirs of novelist Marcel Pagnol.
The invention of petanque.
According to a document in the Musée Ciotaden in La Ciotat signed by Ernest Pitiot, pétanque in its present form was first played in 1910 in what is now called the Jules Lenoir Boulodrome in the town of La Ciotat near Marseilles. It was invented by Ernest Pitiot, a local café owner, to accommodate a French "jeu provençal" player named Jules Lenoir, whose rheumatism prevented him from running before he threw the ball. In the new game, the length of the pitch or field was reduced by roughly half, and a player no longer engaged in a run-up while throwing a ball—he stood, stationary, in a circle.
The first pétanque tournament with the new rules was organized in 1910 by the brothers Ernest and Joseph Pitiot, proprietors of a café at La Ciotat. After that the game spread quickly and soon became the most popular form of boules in France.
Before the mid-1800s, European boules games were played with solid wooden balls, usually made from boxwood root, a very hard wood. The late 1800s saw the introduction of cheap mass-manufactured nails, and wooden boules gradually began to be covered with nails, producing "boules cloutées" ("nailed boules"). After World War I, cannonball manufacturing technology was adapted to allow the manufacture of hollow, all-metal boules. The first all-metal boule, "la Boule Intégrale", was introduced in the mid-1920s by Paul Courtieu. The "Intégrale" was cast in a single piece from a bronze-aluminum alloy. Shortly thereafter Jean Blanc invented a process of manufacturing steel boules by stamping two steel blanks into hemispheres and then welding the two hemispheres together to create a boule. With this technological advance, hollow all-metal balls rapidly became the norm.
Global spread of the game.
After the development of the all-metal boule, petanque spread rapidly from Provence to the rest of France, then to the rest of Europe, and then to Francophone colonies and countries around the globe. Today, many countries have their own national governing bodies.
In France, the "Fédération Française de Pétanque et Jeu Provençal" ( FFPJP) has more than 300,000 licensed members.
There are strong national federations in Germany, Spain, and England. Petanque is actively played in many nations with histories of French colonial influence, especially in Southeast Asia, including Laos, Thailand, Vietnam, Cambodia, and Puducherry, India, as well as some parts of Africa. Today, some of the strongest players in the world come from Madagascar and Thailand.
Pétanque was featured at the 2015 All-Africa Games, which were hosted by the Republic of Congo, a former French colony.
Petanque is not widely played in the Americas. There is a Canadian petanque federation based in Québec. In the United States the Federation of Petanque USA (FPUSA) has approximately 1,800 members in 40 clubs, and estimates about 30,000 play nationwide.
On the international level, the governing body of petanque is the "Fédération Internationale de Pétanque et Jeu Provençal" (FIPJP). It was founded in 1958 in Marseille and has about 600,000 members in 52 countries .
National and international competitions.
There are a number of important world championship tournaments.
The FIPJP world championships take place every two years. Men's championships are held in even-numbered years, while Women's and Youth championships are held in odd-numbered years.
Perhaps the best-known international championship is the "Mondial la Marseillaise de pétanque", which takes place every year in Marseille, France, with more than 10,000 participants and more than 150,000 spectators.
The largest annual tournament in the USA is the Petanque America Open, held in November at Amelia Island, Florida.
Pétanque is not currently an Olympic sport, although the Confédération Mondiale des Sports de Boules — which was created in 1985 by several international boules organizations specifically for this purpose — has been lobbying the Olympic committee since 1985 to make it part of the summer Olympics.
Playing the game.
Equipment.
Pétanque is played by two teams, where each team consists of one, two, or three players.
In the singles and doubles games each player plays with three metal boules. In triples each player uses only two.
The area where a petanque game is played is called a "terrain". A game can be played in an open area like a public park, where the boundaries of the terrain are not marked. Or it can be played on a "marked terrain" where the terrain boundaries are marked (traditionally, by strings tightly strung between nails driven into the ground).
In petanque, players throw while standing in a circle. Traditionally, the circle was simply scratched in the dirt. Starting around 2005, red plastic "prefabricated" circles were introduced and are now widely used. A circle drawn on the ground must be 35–50 cm in diameter, while a plastic circle must have an inside diameter of 50 cm.
The "ends".
A game consists of several "mènes". The French word "mène" is usually translated into English as "end" or "round".
An end consists of the throwing out of the jack (the little wooden target ball), followed by the two teams throwing their boules.
After both teams have thrown all of their boules, the team with the boule closest to the jack wins the end. The winning team scores one point for each of its boules that is closer than the opposing team's closest boule. That means that the winning team could in theory score as many as six points in an end, although a score of one or two points is more typical.
As the game progresses, each team accumulates points until one of the teams reaches 13, the winning number of points.
Order of play.
A game begins with a coin toss to determine which team plays first.
The team that wins the toss begins the game by placing the circle and throwing the jack. The jack must be thrown to a distance of 6-10m from the circle — a jack that is thrown too short or too long must be re-thrown.
A player from the team that threw the jack, throws the first boule. Then a player from the opposing team throws a boule.
From that point on, the team with the boule that is closest to the jack is said to "have the point", and the team that does NOT have the point, throws the next boule. The team that does NOT have the point continues to throw boules until it either (a) gains the point, or (b) runs out of boules.
If at any point the closest boules from each team are equally distance from the jack, then the team that threw the last boule throws again. If the boules are still equidistant then the teams play alternately until the tie is broken. If the boules are still equidistant at the end of the "mène" then neither team scores any points.
The team that won the end, starts the next end. A player from the winning team places (or draws) a circle around the jack. He/she then picks up the jack, stands in the circle, and throws the jack to start the next end.
Scoring.
If the end finishes in the usual way—with the jack still alive and one team with the closest boule—then the team with the closest boule receives one point for each of its boules that is closer to the jack than other team's closest boule.
If the jack is alive but there is an "equidistant boules" situation at the end of the mène, then neither team scores any points.
If the jack is dead at the finish of the end, then —
Equipment specifications.
Boules.
Competition boules must meet specifications set by the FIPJP. They must be hollow and made of metal (usually steel) with a diameter between 70.5 and 80mm and a weight between 650 and 800g.
Leisure boules are boules that do not meet the FIPJP standards for competition boules, but are less expensive than competition boules and completely adequate for "backyard" games. Unlike competition boules, leisure boules are a "one size fits all" affair — they come in one weight and size.
When purchasing competition boules, a purchaser has a choice of a number of characteristics of the boules, including the size, weight, and hardness of the boules, as well as the striations (patterned grooves on the surface of the boules).
The jack.
The jack is a small ball made of wood, usually boxwood or beechwood. Modern regulations require the jack to be 30mm in diameter (+/- 1mm). In the past jacks were often left "natural"—unfinished or with a clear finish—but nowadays they are often painted in bright colors. In recent years the FIPJP began authorizing the manufacture of non-wooden "synthetic" or "resin" jacks, but many national organizations (including the FPUSA) forbid the use of synthetic jacks for safety reasons.
Playing area.
Pétanque can be played on almost any flat, open space. The ground may be irregular and interrupted by trees or rocks, and the surface is likely to be uneven, with some areas hard and smooth and other areas rough and stony. When an area is constructed specifically for the purposes of playing petanque, the playing surface is typically loose gravel, decomposed granite, brick grog or crushed sea shell. Sandy beaches are not suitable, although light plastic boules are sometimes used to adapt the game for the beach. There is no requirement for backboards or sideboards (as in bocce), but dedicated playing areas are often enclosed in boards or some other structural barrier.
In France, village squares and park pathways are often used as pétanque playing areas. In addition, many towns have recreational facilities ("boulodromes") constructed especially for playing pétanque.
An area where a single pétanque game is played is called a "terrain". A "playing area" is an area where one or more petanque games are being played. At any given time a "playing area" may be hosting one or more "terrains".
For tournaments, a large playing area is subdivided and marked off (typically using nails and string) into rectangular "marked terrains" (also known as "lanes" ("cadres") or "pistes") so that multiple games may be carried on simultaneously. For tournament play, a marked terrain is a rectangle at least 4 meters wide and 15 meters long.
In the United States, proponents of pétanque such as author Byron Putman often urge the use of non-dedicated public terrains – public walking paths, playground areas, dirt/gravel parking lots, and baseball infields – as terrains.
Strategy.
Pointing and shooting.
Generally speaking, a player throws a boule with one of two objectives.
The best throw of all is called a "carreau". It is a shot that knocks away the opponent's boule, leaving the thrown boule exactly in its place.
Players who are skillful enough to shoot effectively are called "shooters"; players who usually point are called "pointers". (The French terms are "tireur" and "pointeur", respectively.) As a matter of strategy, pointers play first and shooters are held in reserve in case the opponents place well. Good pointing is what scores points, but national and international championships are usually dominated by skillful shooters, who target any opposing boule that comes close to scoring.
Throwing a boule.
Some strategic considerations involved in the throw of a boule include:
Throwing the jack.
Strategic considerations involved in the throw of the jack include:

</doc>
<doc id="65965" url="https://en.wikipedia.org/wiki?curid=65965" title="Boules">
Boules

Boules () is a collective name for a wide range of games in which the objective is to throw or roll heavy balls (called "boules" in France, and "bocce" in Italy) as close as possible to a small target ball.
Boules-type games are traditional and popular in France, Italy, Malta and Croatia, and are also popular in some former French colonies. Boules games are often played in open spaces (town squares and parks) in villages and towns. Dedicated playing areas for boules-type games are typically large, level, rectangular courts made of flattened earth, gravel, or crushed stone, enclosed in wooden rails or back boards.
In the south of France, the word "boules" is also often used as a synonym for pétanque.
Types.
Boules games may be sub-divided into two categories based on typical throwing technique: 
Boules games may also be subdivided into two other categories based on typical throwing technique: 
Alternatively, boules games may be subdivided into categories based on the structure and material of the ball: 
Alternatively, boules games may be subdivided into categories based on the shape of the ball: 
There may be other variations as well, for instance in the way the ball is launched, in the dimensions of the playing area, whether obstacles (such as trees) are considered in-bounds or out-of-bounds, and whether it is legal to play balls off of enclosing boards or obstacles. 
Finally, some boules games (bocce, pétanque) began as variations of earlier games, deliberately created and designed to accommodate the needs of players with physical disabilities.
Such variations produce a wide variety of boules-type games played all over the world.
Terminology.
In Italian bocce, balls may be thrown in three ways: punto, raffa and volo.
Balls.
There is a wide variation in the size and materials of the balls used in boules-type games.
Originally, in ancient Egypt, Greece, and Rome, the balls were probably made of stone.
Gallic tribes, which were introduced to boules by the Romans, used wooden boules. In the 1800s in France, boules were typically made of a very hard wood, boxwood root.
In the mid-1800s techniques were developed for the mass production of iron nails. Following this technological improvement, boxwood balls studded with nails (boules cloutées) were introduced in an effort to improve the durability of the balls. This eventually lead to the development of balls that were completely covered in nails, creating a ball that appeared almost to be made of metal.
By the 1920s, the growing popularity of boules in France created a demand that could not be satisfied using the available supplies of natural boxwood root, which were beginning to disappear. Paul Courtieu and Vincent Miles had the idea of manufacturing a ball made entirely of metal. Avoiding steel-based alloys (which were too hard and rust-prone) they developed an alloy based on aluminum and bronze, and (in 1923) patented a metal ball made of two welded-together hemispheres. A year later, in 1924, they filed a patent for a ball that was cast in a single piece -- "La Boule intégrale". Other companies began manufacturing metal balls in a variety of metals and metal alloys, including bronze.
Today, some boules sports (e.g. bocce) still use wooden (or epoxy composite) balls, while others (e.g. pétanque) use metal balls.
The wooden balls used in bocce tend to be bigger than the smaller (but denser) metal balls used in pétanque.
Games.
The same game can be known by different names in different languages and locations or the same name can be used for different local variations of a game.
The category of boules games includes 
International boules organizations.
The Confédération Mondiale des Sports de Boules - CMSB - was created (on December 21, 1985 in Monaco) by three international boules organizations for the purpose of lobbying the Olympic committee to make boules sports part of the summer Olympics. To date, its efforts have been unsuccessful. The organizations were:
World Bowls (bowls) is also a member.

</doc>
<doc id="65968" url="https://en.wikipedia.org/wiki?curid=65968" title="City News Bureau of Chicago">
City News Bureau of Chicago

City News Bureau of Chicago, or City Press, was a news bureau that served as one of the first cooperative news agencies in the United States. It was founded in the late 19th century by the newspapers of Chicago to provide a common source of local and breaking news and also used by them as a training ground for new reporters. Hundreds of reporters have "graduated" from the City News Bureau into newspaper dailies - both local and national - or other avenues of writing.
The City News Bureau had reporters in all important news sites, courthouses, Chicago City Hall, the County Building, Criminal Courts, as well as having as many as ten police reporters on duty. It operated around the clock and all year round. The reporters, though young, worked in competition with some of the best reporters in the country, working on the same stories as all the others, questioning politicians and police, and fighting for scoops.
They covered every single death reported to the coroner's office, every important meeting, every news conference, every court case that had once been a news story, even if the trial wasn't newsworthy.
The training was rigorous. The reporters were all amateurs when they came to work, but the rewrite men were professionals, accustomed to teaching in a hard school.
One graduate was Kurt Vonnegut. He described his work there in the late 1940s in terms that could have been used by almost any other City Press reporter of any era:
A legendary story held that a young reporter who called in a story of the slaying of an infant was sent back to get the answer to the question, "What color were the dead baby's eyes?" Certainly, all the young reporters were sent back to get more information so that they would learn to get it in the first place. Another watchword: "If your mother tells you she loves you, check it out with two independent sources."
The City News Bureau had special operations for covering elections in Chicago and Cook County, providing regular updates precinct by precinct years before such coverage was common. A similar service reported on the scores of most high-school games in Chicago, but otherwise there was no sports coverage.
The film "Call Northside 777", in which James Stewart plays a reporter whose articles free an innocent man from prison, was based on a story that originated at the City News Bureau.
The City News Bureau broke the story of the St. Valentine's Day Massacre in 1929, but, for once, didn't quite believe its reporter, Walter Spirko, and sent the following bulletin:
Spirko continued as a Chicago reporter for many years, breaking a story of thieving policemen known as the Summerdale police scandal.
Playwright Charles MacArthur, co-author of the play "The Front Page", was a City Press reporter; several of the characters in the play were based on City Press personalities, notably the skittish managing editor Larry Mulay.
Other well-known alumni: syndicated columnist and "Politico" editor Roger Simon, reclusive media mogul Fred Eychaner, environmental journalist William Allen, investigative reporter Seymour Hersh, "New York Times" columnist David Brooks (author of "Bobos in Paradise"), pop artist Claes Oldenburg, public-television personality John Callaway, editor Russell Freeburg, consumer advocate David Horowitz, Pulitzer Prize-winning columnist Mike Royko, and Pulitzer Prize-winning editorial cartoonist Herbert Lawrence Block (commonly known as Herblock).
Clarence John Boettiger, son-in-law of Franklin Delano Roosevelt, became a "Chicago Tribune" police reporter after working for the City News Bureau to begin his career. Elizabeth Austin of the bureau later became a speechwriter for one Illinois governor and communications director for another.
Other mainstays of City News Bureau's staff included Arnold Dornfeld, Susan Kuczka, Paul Zimbrakos and Bernard Judge.
The City News Bureau had three teletype wires, one for the Chicago dailies, one for radio and television stations, and one for press releases. In addition, it owned a pneumatic tube system that connected all the Chicago dailies, including those that no longer existed.
As Chicago went down to only two daily newspapers, the City News Bureau slowly faded and was reduced to a minor operation. It was still widely used by both papers, the "Chicago Tribune" and "Chicago Sun-Times", until the "Sun-Times" decided to pull out of the joint ownership agreement it had inherited from the City News Bureau's original owners, for which the "Sun-Times" was a successor paper. The PR Newswire, which was part of City News, was sold; the "Sun-Times" decided it cost too much to keep City News running, and it was closed after its last dispatch February 28, 1999. Electronic news media—both radio and television—both used City News throughout the 1990s, until the "Sun-Times", owned by Conrad Black's Hollinger International, decided to pull out. (After Black was indicted in 2005 on charges of looting Hollinger, some speculated his desire to squeeze cash out of the company's properties helped hasten the demise of the original City News.)
The New City News Service, owned by the "Tribune", opened soon thereafter, and soon changed its name to the City News Service. Though smaller, it was run by Paul Zimbrakos, a 40-plus year employee of the old CNB, and the bureau's last editor. "Sun-Times" management had thought they would be able to create a new, cheaper wire service, staffed with few people. When that venture—called Alliance News—failed, for a while the "Sun-Times" used the part-time help of Medill News Service, staffed by unpaid journalism students from the Medill School of Journalism. The "Sun-Times", however, was barred from receiving the New City News Service wire because of its being in competition with the "Tribune".
Though the "Tribune" had been hailed by former City Newsers as a savior of CNB, on December 1, 2005, the "Tribune" informed the 19 employees of City News Service that their jobs were being eliminated as part of cost-cutting measures going on throughout the Tribune Company. (See Associated Press and other news stories of December 1 & December 2, 2005.) "Tribune" editors and executives reasoned that CNS was providing the "Tribune's" competitors' Web sites with news that the paper itself should have exclusively, the better to compete in an age of Internet news distribution.
The City News Service closed at the end of 2005, and was swallowed into a smaller "Tribune" Internet news operation.
City News lives on, in spirit, at least, at the "Sun-Times". In February 2006, the "Sun-Times" worked to fill the void felt at the city's TV and radio stations by the demise of the old City News by starting its own 24-hour newswire, the STNG Wire. The key to the operation, staffed by veterans of both the original and the "Tribune"-run City News, is the Daybook, the invaluable daily listing of press conferences, court activity and other events throughout the Chicago metropolitan area, which is shared with subscribers and the Sun Times News Group family. The STNG wire also covers the blood and guts news—the fires, murders, shootings, stabbings, automobile accidents—that City News was known for, 24 hours a day, seven days a week.
Former City News Editor Paul Zimbrakos continues to teach young journalists through his City News Bureau course at Loyola University Chicago. Here is the course description from the Loyola School of Communication website:
"In fall 2009 the School of Communication started offering students access to a Chicago news gathering institution the City News Bureau. For over 100 years Chicago hosted one of the best news bureaus in the country. Young reporters learned at The City New Bureau of Chicago how the city worked and how they could best cover the city. We are re-launching that bureau in the form of a course this fall. It will be taught by two remarkable journalism veterans. Paul Zimbrakos was the Managing Editor of the bureau for a number of years before it closed its doors and tutored many of the best journalists in the country. Jack Smith was the former CBS Bureau Chief in Chicago and Washington DC. Together they will make this class a rich learning lab and help students discover how best to cover a city and its inner-workings."

</doc>
<doc id="65969" url="https://en.wikipedia.org/wiki?curid=65969" title="Salem, Illinois">
Salem, Illinois

Salem is a city in and the county seat of Marion County, Illinois, United States. The population was 7,485 at the 2010 census.
Geography.
Salem is located at (38.6282, -88.9482).
According to the 2010 census, Salem has a total area of , of which (or 97.79%) is land and (or 2.21%) is water.
Demographics.
As of the census of 2000, there were 7,909 people, 3,249 households, and 2,082 families residing in the city. The population density was 1,296.5 people per square mile (500.6/km²). There were 3,473 housing units at an average density of 569.3 per square mile (219.8/km²). The racial makeup of the city was 97.13% White, 0.72% African American, 0.30% Native American, 1.15% Asian, 0.04% Pacific Islander, 0.14% from other races, and 0.52% from two or more races. Hispanic or Latino of any race were 0.72% of the population.
There were 3,249 households out of which 28.6% had children under the age of 18 living with them, 48.8% were married couples living together, 11.0% had a female householder with no husband present, and 35.9% were non-families. 32.3% of all households were made up of individuals and 17.2% had someone living alone who was 65 years of age or older. The average household size was 2.32 and the average family size was 2.91.
In the city the population was spread out with 23.5% under the age of 18, 8.7% from 18 to 24, 26.1% from 25 to 44, 22.1% from 45 to 64, and 19.6% who were 65 years of age or older. The median age was 39 years. For every 100 females there were 87.6 males. For every 100 females age 18 and over, there were 83.9 males.
The median income for a household in the city was $34,339, and the median income for a family was $42,070. Males had a median income of $31,811 versus $21,931 for females. The per capita income for the city was $16,954. About 6.1% of families and 9.2% of the population were below the poverty line, including 13.2% of those under age 18 and 9.2% of those age 65 or over.
Education.
Public schools:
Catholic schools:
Arts and culture.
Salem is home to Miracle Whip salad dressing and three homes on the National Register of Historic Places: the Charles and Naomi Bachmann House, the Badollet House, and the William Jennings Bryan Boyhood Home.

</doc>
<doc id="65971" url="https://en.wikipedia.org/wiki?curid=65971" title="FEC">
FEC

FEC may refer to:

</doc>
<doc id="65974" url="https://en.wikipedia.org/wiki?curid=65974" title="First-person narrative">
First-person narrative

A first-person narrative is a story from the first-person perspective: the viewpoint of a character writing or speaking directly about themselves. In films, videos, or video games, a first-person perspective may also mean that the narrative is shot or presented as if directly coming from a character's in-body point of view, portraying exactly what the character sees or experiences (for example, in first-person shooter games).
The narrators of written works explicitly refer to themselves using variations of "I" (the first-person singular pronoun) and/or "we" (the first-person plural pronoun), typically as well as other characters. This allows the reader or audience to see the point of view (including opinions, thoughts, and feelings) only of the narrator, and not of other characters. In some stories, first-person narrators may refer to information they have heard from the other characters, in order to try to deliver a larger point of view. Other stories may switch from one narrator to another, allowing the reader or audience to experience the thoughts and feelings of more than one character or character plural.
Forms.
First-person narratives can appear in several forms; interior monologue, as in Fyodor Dostoevsky's "Notes from Underground"; dramatic monologue, also in Albert Camus' "The Fall"; or explicitly, as Mark Twain's "Adventures of Huckleberry Finn."
Point of view device.
Since the narrator is within the story, he or she may not have knowledge of all the events. For this reason, first-person narrative is often used for detective fiction, so that the reader and narrator uncover the case together. One traditional approach in this form of fiction is for the main detective's principal assistant, the "Watson", to be the narrator: this derives from the character of Dr Watson in Sir Arthur Conan Doyle's Sherlock Holmes stories.
In the first-person-plural point of view, narrators tell the story using "we". That is, no individual speaker is identified; the narrator is a member of a group that acts as a unit. The first-person-plural point of view occurs rarely but can be used effectively, sometimes as a means to increase the concentration on the character or characters the story is about. Examples include:
First-person narrators can also be multiple, as in Ryūnosuke Akutagawa's "In a Grove" (the source for the movie "Rashomon") and Faulkner's novel "The Sound and the Fury". Each of these sources provides different accounts of the same event, from the point of view of various first-person narrators.
The first-person narrator may be the principal character or one who closely observes the principal character (see Emily Brontë's "Wuthering Heights" or F. Scott Fitzgerald's "The Great Gatsby", each narrated by a minor character). These can be distinguished as "first person major" or "first person minor" points of view.
There can also be multiple co-principal characters as narrator, such as in Robert A. Heinlein's "The Number of the Beast". The first chapter introduces four characters, including the initial narrator, who is named at the beginning of the chapter. The narrative continues in subsequent chapters with a different character explicitly identified as the narrator for that chapter. Other characters later introduced in the book also have their "own" chapters where they narrate the story for that chapter. The story proceeds in linear fashion, and no event occurs more than once, i.e. no two narrators speak "live" about the same event.
Styles.
First-person narratives can tend towards a stream of consciousness and Interior monologue, as in Marcel Proust's "In Search of Lost Time". The whole of the narrative can itself be presented as a false document, such as a diary, in which the narrator makes explicit reference to the fact that he is writing or telling a story. This is the case in Bram Stoker's "Dracula". As a story unfolds, narrators may be aware that they are telling a story and of their reasons for telling it. The audience that they believe they are addressing can vary. In some cases, a frame story presents the narrator as a character in an outside story who begins to tell his own story, as in Mary Shelley's "Frankenstein".
First-person narrators are often unreliable narrators since a narrator might be impaired (such as Benjy in Faulkner's "The Sound and the Fury"), lie (as in "The Quiet American" by Graham Greene, or "The Book of the New Sun" series by Gene Wolfe), or manipulate his or her own memories intentionally or not (as in "The Remains of the Day" by Kazuo Ishiguro, or in Ken Kesey's "One Flew Over the Cuckoo's Nest"). Henry James discusses his concerns about "the romantic privilege of the 'first person'" in his preface to "The Ambassadors", calling it "the darkest abyss of romance."
One example of a multi-level narrative structure is Joseph Conrad's novella "Heart of Darkness", which has a double framework: an unidentified "I" (first person singular) narrator relates a boating trip during which another character, Marlow, uses first person to tell a story that comprises the majority of the work. Within this nested story, it is mentioned that another character, Kurtz, told Marlow a lengthy story; however, its content is not revealed to readers. Thus, there is an "I" narrator introducing a storyteller as "he" (Marlow), who talks about himself as "I" and introduces another storyteller as "he" (Kurtz), who in turn presumably told his story from the perspective of "I".
References.
Notes
Further reading

</doc>
<doc id="65975" url="https://en.wikipedia.org/wiki?curid=65975" title="Other Losses">
Other Losses

Other Losses is a 1989 book by Canadian writer James Bacque, in which Bacque alleges that U.S. General Dwight Eisenhower intentionally caused the deaths by starvation or exposure of around a million German prisoners of war held in Western internment camps briefly after the Second World War. "Other Losses" charges that hundreds of thousands of German prisoners that had fled the Eastern front were designated as "Disarmed Enemy Forces" in order to avoid recognition under the third Geneva Convention, for the purpose of carrying out their deaths through disease or slow starvation. "Other Losses" cites documents in the U.S. National Archives and interviews with people who stated they witnessed the events. The book claims that there was a "method of genocide" in the banning of Red Cross inspectors, the returning of food aid, the policy regarding shelter building, and soldier ration policy.
Stephen Ambrose and seven other historians examined the book soon after its publication, and came to the conclusion that it was inaccurate and the product of conspiracy theory. Other historians, including the former senior historian of the United States Army Center of Military History, Colonel Ernest F. Fisher, who was involved in the 1945 investigations into the allegations of misconduct by U.S. troops in Germany and who wrote the book's foreword, argues that the claims are accurate.
Claims of "Other Losses".
Other Losses.
The title of "Other Losses" derives from a column of figures in weekly U.S. Army reports that Bacque states actually reflects a body count of German prisoners that died of slow starvation or diseases. The book states that Colonel Philip Lauben, chief of German Affairs Branch at SHAEF (Supreme Headquarters Allied Expeditionary Force), confirmed that "other losses" meant deaths and escapes, with escapes being a minor part. This is supported by a US Army document lodged in the US National Archives which "plainly states" that the "Other Losses" category of prisoners was for deaths and escapes. Bacque dismisses claims from his opponents that "other losses" meant transfers or discharges, as these are accounted for in other columns in the same tables. Furthermore, there is no separate column in which deaths were recorded.
The book refers to the Army Chief Historians report that was published in 1947; in the 20 pages dealing with the capture, transfer and discharge of prisoners, the report makes no mention of releasing prisoners without formal discharge. Furthermore, Bacque cites Army orders from Eisenhower himself (Disbandment Directive No. 1) stating that every prisoner leaving captivity had to have discharge papers.
Disarmed Enemy Forces designation.
"Other Losses" states that Eisenhower sought to sidestep the requirements of the Geneva Convention through the designation of these prisoners as Disarmed Enemy Forces (DEF), specifically stating that "in March, as Germany was being cracked ... a message was being signed and initialed by Eisenhower proposed a startling departure from the Geneva Convention (GC)—the creation of a new class of prisoners who would not be fed by the Army after the surrender of Germany."
The book states that, against the orders of his superiors, Eisenhower took 2 million additional prisoners after Germany's surrender that fell under the DEF designation. "Other Losses" states that the million soldiers it alleges died had fled the Eastern front and most likely ended up in Rheinwiesenlager prisoner transit camps run by United States and French forces where many such prisoners died of disease or starvation under the cover of the DEF designation.
The book cites orders from Eisenhower which stipulated that the Germans would be solely responsible for feeding and maintaining the DEFs, however he then prevented any aid from reaching them.
Number of prisoners who died.
"Other Losses" claims that nearly one million German prisoners died while being held by United States and French forces at the end of World War II. Specifically, it claims: "The victims undoubtedly number over 800,000, almost certainly over 900,000 and quite likely over a million. Their deaths were knowingly caused by army officers who had sufficient resources to keep the prisoners alive."
"Other Losses" contains an analysis of a medical record that it states supports the conclusion of a prisoner death rate of 30%. Bacque also referred to a 1950 report from the German Red Cross which stated that 1.5 million former German POWs were still officially listed as missing, fate unknown.
The book claims that approximately 15% of the deaths in the U.S. camps were from starvation or dehydration and that most deaths were caused by dysentery, pneumonia, or septicaemia, as a result of the unsanitary conditions and lack of medicine. "Other Losses" further claims that officers from the U.S. Medical Corps reported death rates far higher than they had ever seen before.
The book further states that Eisenhower's staff was complicit in the scheme. "Other Losses" also states that, in order to carry out his scheme, Eisenhower kept these prisoners in camps far longer than it was necessary It claims that, by the end of 1945, only 40% of prisoners had been released. "Other Losses" further characterizes the 22-volume German "Maschke" Commission report investigating the deaths of German prisoners as written by "client-academics" as part of a "cover up" of the deaths that "Other Losses" alleged occurred.
Treatment of prisoners.
"Other Losses" claims that the U.S. dismantled the German welfare agencies, including the German Red Cross, then dismissed the Swiss Government from its role as Protecting Power. No agencies were allowed to visit the camps or provide any assistance to the prisoners, including delegates from ICRC (International Committee of the Red Cross), which was a violation of the Geneva Convention. It further states that the only notable protest against this was from William Lyon Mackenzie King, Prime Minister of Canada.
Bacque states that the press was also prevented from visiting the camps, and therefore was unable to report on the state of the camps and the condition of the prisoners.
The book states that many of the U.S. camps consisted of open fields surrounded by barbed wire, with no shelter or toilet facilities. In these camps prisoners were forced to sleep on the ground in the open, though it claims that the U.S. Army had plenty of surplus tents which could have been issued. No supplies such as blankets were supplied to the prisoners, even though these were in good supply at various locations such as the depot at Naples. In a letter General Everett Hughes stated that there were "more stocks than we can ever use; stretch as far as eye can see."
The book quotes Dr. Konrad Adenauer (later Chancellor of Germany) stating that "The German prisoners have been penned up for weeks without any protection from the weather, without drinking water, without medical care. They are being held in a manner contrary to all humanitarian principles and flagrantly contrary to the Hague and Geneva Conventions."
Both J. P. Pradervand (ICRC French Delegation) and Henry Dunning (American Red Cross) sent letters to the State Department condemning the poor treatment of the German prisoners. Colonel Philip Lauben stated that "The Vosges was just one big death camp."
Prisoner totals.
The book claims that the U.S. Army employed a number of methods to reduce the number of prisoners officially on hand. One method was to accuse the Russians of taking far more prisoners than they reported. Another was the "midnight shift", whereby the opening balance of a given week was less than the closing balance of the previous week.
The book claims that a "Missing Million" prisoners exist in the difference in totals between two U.S. army reports (the last of the daily reports and the first of the weekly reports) issued on June 2, 1945. As a consequence of this, according to Quartermaster's reports the number of rations issued to the camps was reduced by 900,000.
After visiting many of the camps in August 1945, "Other Losses" states that General Robert Littlejohn (Quartermaster of the ETO) concluded that the U.S. Army was reporting 3.7 million prisoners while it actually possessed 5.2 million, thereby corroborating the conclusions made in a report three months earlier from General J. Lee (in charge of logistics for the ETO), which he had sent to SHAEF headquarters. "Other Losses" states that Littlejohn subsequently wrote in a report to Washington that because requisitions for supplies were based on these faulty numbers, 1.5 million prisoners were getting no food.
"Other Losses" states that, three years later, in 1948 the ICRC formally requested documents confirming the total number of prisoners in the U.S. Zone and was eventually told that 3.5 million were there, which omitted approximately 1.7 million from the actual number of 5,224,000.
Food shortage.
"Other Losses" explicates the 1944–1949 German food crisis to support the claims for a high mortality rate.
"Other Losses" concludes that the 1945 food crisis in Europe was contrived by Allied forces by the use of restrictive food import policy, including restrictions on Red Cross food deliveries, and other means. It claims that Eisenhower purposefully starved German prisoners given that "here was a lot more wheat available in the combined areas of western Germany, France, Britain, Canada and the USA than there had been in the same year in 1939." "Other Losses" states that, in May 1945, the ICRC had 100,000 tons of food in storage warehouses in Switzerland. The book claims that, when they tried to send train loads of this food into the U.S. Zone, the U.S. Army sent the trains back, saying their own warehouses were full. "Other Losses" states that this prompted Max Huber, head of the ICRC, to send a strong letter of protest to the State Department, in which he described the difficulties placed by SHAEF in the way of the ICRC efforts to provide aid. He said "Our responsibility for the proper use of relief supplies placed in our care is incompatible with a restriction to the fulfillment of orders which render us powerless to furnish relief which we ourselves judge necessary."
U.S. Army warehouses had 13.5 million Red Cross food parcels taken from the ICRC, which were never distributed. The book also states that German civilians were prevented from bringing food to the camps, and that Red Cross food parcels were confiscated by SHAEF, and the War Department banned them from being given to the men in the camps. The book states that Bacque found no evidence of a drastic food shortage in the U.S. Army —
Criticism of "Other Losses".
The New Orleans panel.
After the publication of Bacque's book, a panel of eight historians gathered for a symposium in the Eisenhower Center for American Studies at the University of New Orleans from December 7–8, 1990 to review Bacque's work. The introduction to a book later published containing each panelists' papers noted that Bacque is a Canadian novelist with no previous historical research or writing experience. The introduction concludes that ""Other Losses" is seriously—nay, spectacularly—flawed in its most fundamental aspects." The historians conclude that, among its many problems, "Other Losses":
As a consequence of those and other shortcomings, the book "makes charges that are demonstrably absurd." Panel member Stephen Ambrose later wrote in the "New York Times":
Historians Gunter Bischof and Brian Loring Villa stated that a research report from the panel "soundly refuted the charges of Other Losses, especially Bacque's fanciful handling of statistics." The historians further stated:
New Orleans panel conclusions regarding "Other Losses".
The New Orleans panel's book introduction concluded "hat Bacque is wrong on nearly every major and nearly all his minor charges seem to us to be overwhelmingly obvious. To sum up: Eisenhower was not a Hitler, he did not run death camps, German prisoners did not die by the hundreds of thousands, there was indeed a severe world food shortage in 1945, there was nothing sinister or secret about DEF designation or about the Other Losses column. Bacque's "Missing Million" were old and young boys in the militia dismissed early from the American camps; they were escapees from camps and POWs/DEFs transferred from camp to camp in Germany and Europe for various reasons."
Villa states that "James Bacque's "Other Losses" illustrates what happens when the context surrounding historical persons and important events is lost. The effect to give known facts a twist that seems dramatically new in important ways, but this is means appearance of originality is a little deceptive. For the most part, Bacque's book is not very original at all. When it seems so, the price is purchased at the price of accuracy." He further stated that "hose parts of Other Losses that might rise above a failing grade in an undergraduate term paper are not new. It has long been known that German prisoners of war suffered terribly at the end of World War II, that they died by the thousands after hostilities ceased in the European theater, and that many were required to work as forced laborers for the victors." The main lines of the story have long been known, written up for example in the extensive German "Maschke Commission" between 1962 and 1975. Villa states that Bacque only adds two "novel" propositions: first, that the number that died was in the hundreds of thousands, and seconds, that these deaths were the result of deliberate extermination on the part of Eisenhower. "The falsity of Bacque's charges can be easily demonstrated once the context, particularly the decision-making environment, is examined."
Bischoff concludes that just the application of common sense alone refutes many of the most "fantastical charges" of Bacque, such as asking the question "How could a single man order one million men killed without being caught in the heinous act? How could the bodies disappear without one soldier's coming forward in nearly fifty years to relieve his conscience? How could the Americans (almost one-third of whom are by ethnic background German) conspire for so long to cover up such a vast crime?"
In a 1989 "Time Magazine" book review, Ambrose did, however, apart from his criticisms of the book, concede that "We as Americans can't duck the fact that terrible things happened. And they happened at the end of a war we fought for decency and freedom, and they are not excusable."
"Other Losses" documentary evidence of deaths.
"Other Losses" claimed that "The victims undoubtedly number over 800,000, almost certainly over 900,000 and quite likely over a million. Their deaths were knowingly caused by army officers who had sufficient resources to keep the prisoners alive." "Other Losses" asserts that roughly a million German prisoners—the "Missing Million"—disappeared between two reports issued on June 2, 1945, with one (the last of the daily reports) totaling prisoners in the European Theater of Operations (ETO) in U.S. custody at 2,870,400, while the other (the first of the weekly reports) gives the figure as 1,836,000 prisoners in the Communication Zone (COM Z). As a consequence of this, according to Quartermaster Reports the number of rations issued to the camps was reduced by 900,000.
Historian Albert Cowdrey states that the reason for this is simply that COM Z is a subordinate of the ETO, and its figures omit prisoners held by other armies. In fact, Cowdrey states that the two documents further both cite exactly the same number of total prisoners in the ETO: 3,193,747. Cowdrey concludes "o judge by these documents, there was no Missing Million. There was not even a missing one."
The title of ""Other Losses"" derives from the heading of a column in weekly reports of the U.S. Army's theater provost marshal, which "Other Losses" states is actually a "body count" of dead prisoners. Cowdrey states that, in many cases, as explained by the footnotes in the very documents themselves, the "other losses" were transfers between zones and camps, which were regularly done for a variety of reasons, none of them sinister and all properly noted in the accompanying documents. Cowdrey further states that, not only are these figures many times mentioned in the footnotes, but they are also reflected in the actual increase and decrease in numbers of each camp in the individual army reports. Cowdrey concludes "it is unclear how Bacque could have failed either to see these documents or, if he saw them, to understand their significance to the book he was writing." In addition, while "Other Losses" asserts that these prisoners died of diseases or slow starvation, Cowdrey states that even a cursory glance at the figures shows that this would have been impossible, with figures varying between zero and over 189,000 from week to week.
The introduction to the book publishing many of the New Orleans panel papers also noted that Bacque ignored the greatest source of for the "other losses" column, an August 1945 Report of the Military Governor that states "An additional group of 664,576 are lists as " 'other losses' ", consisting largely of members of the Volkssturm Militia released without a formal charge." It stated that Bacque ignored this document despite its presence in the National Archives, the Eisenhower Library and elsewhere. It further stated the dismissal of the Volksstrum (mostly old men and boys) "accounts for most, quite probably all, of Bacque's 'Missing Million'". Bischoff notes that, in his later American edition of "Other Losses", Bacque discredits the document as a fake "with a further fantastic twist in his convoluted cycle of conspiracy theories, he claims that Eisenhower and the army 'camouflaged' dead POWs/DEFs by listing them as 'discharged Volkssturm.'" Even though Eisenhower himself did not write the document, Bacque concludes that it must have been "doctored".
Regarding prisoners in French custody, historian Rudiger Overmans states that, while the total number of prisoners dying in French custody might have exceeded the official statistic of 21,000, no evidence exists that it was hundreds of thousands of deaths higher than that figure, as Bacque claims. Overmans states that, in addition to the various problems with the Bacque's "death rate" calculations regarding the Rheinwiesenlager transit camps, he ignores that these camps were managed almost entirely by Germans and falsely claimed the no record existed of the handover of the camps to the French in June and July 1945, when detailed records of the handover exist. Overmans also said that Bacque incorrectly claimed that the United States did nothing to help with the French Rheinwiesenlager camps, when the United States engaged in a large operation to raise the caloric intake of those prisoners. Bacque's claims that the 167,000 in French camps that were "dus pour des raisons divers" (other losses) actually died in the winter of 1945-46 not only are not supported by the evidence, but they ignore French documents stating that that figure reflects the release of Volkssturm, women and the sick from those camps.
In addition, Overmans states that Bacque's claim that the 800,000 to 1,000,000 missing prisoners were originally German soldiers that fled from the east into western hands contradicts Soviet POW evidence "well established that we can exclude the idea of an extra million hiding somewhere in the figures." Overmans states that Bacque's claim that one million less prisoners were taken by the Soviet Union than thought produces absurd results, such as that only 100,000 total prisoners could have died in Soviet hands when it is well documented that this amount was exceeded by the dead prisoners from Stalingrad alone. In fact Bacque claimed that up to 500,000 of the missing prisoners were in Soviet camps. Post war Soviet POW evidence was discredited when the KGB opened its archives in the 1990s and an additional 356,687 German soldiers and 93,900 civilians previously recorded as missing were found to be listed as dying in the Soviet camps. Overmans also states that, did they as Bacque claims, flee to the American Rheinwiesenlager camps, they could have easily had contact with their relatives and that it is "quite inconceivable that these prisoners would not have been reported as missing by their relatives." Moreover, Overmans states that the vast majority of this extra million would have been recorded in registrations that occurred in 1947-1948 and 1950, "but the registrations showed nothing of the kind." Overmans further states that, as evidence that Germans believed that missing veterans were mostly in the west, Bacque relies on a statement by Chancellor Adenauer that turns out in the minutes of the purported meeting to be a "statement related to a TASS report concerning the POWs in the Soviet Union. So much for Bacque's careful use of sources."
The plausibility of Eisenhower getting away with such atrocities.
Overmans states that, comporting with the most basic matters of common sense, "if indeed 726,000 soldiers had died in the American camps (Bacque's number excluding those who supposedly died in French custody or after discharge), what became of the bodies?" Given that the Rheinwiesenlager stretched along 200 kilometers of the Rhine river, "Bacque's 726,000 dead would mean roughly 3,600 dead per kilometer or 5,800 per mile – better than one corpse per foot. Yet despite the widespread construction work carried out after the war, not a single one of these legion of dead was found." However, the sites where the camps were located are considered war graves where excavation is officially forbidden making such research problematical.
Villa states that, by Bacque's reasoning, George C. Marshall, who gave SHAEF as much or more attention to detail than did Eisenhower, would be similarly guilty, perhaps more so under his reasoning, though "Bacque" who cares little for exploring the context, does not even raise the question." Villa states that "It is a virtual impossibility that Eisenhower could have executed an extermination policy on his own" and "a near absolute impossibility that Marshall would not have noticed it, let alone that he would ever have tolerated it" and "what about the scores of officers and millions of soldiers who served under Eisenhower?"
"Other Losses" explains that Eisenhower's staff must have been implicated, charging "squalor of the camps came from the moral squalor polluting the higher levels of the army." Villa states that "[perhaps realizing that he already has a thesis involving a massive American conspiracy, Bacque is careful to exclude British officers from any participation or even knowledge of the crime. Although in his vast indictment, Bacque has included virtually Eisenhower's entire staff, all the doctors and personnel running the camps, the press who failed to uncover the monstrous crime and a whole generation of knowing but silent Germans, he has included not a single Briton." Villa notes that Bacque ignores that SHAEF was a fully integrated Anglo-American command, and many of Eisenhower's top officers were Britons who would have also had to cover up the conspiracy. Villa states that Bacque did not even need to read books to realize this, "all he had to do was to look at the pictures: in slightly more than half the portraits contained therein, the staff officers wear British uniforms. Bacque, one understands, wants a villain in the piece. A complicated modern military bureaucracy such as SHAEF, is a tedious subject to study, unlikely to yield the insidious conspiracy apparently sought by this ex-publisher." Villa stated regarding the plausibility of the claims in "Other Losses" that "The impossibility of Bacque's selective crime thesis—an American but not a British crime—becomes all the more evident when one examines the basic decisions affecting occupation policy."
Regarding the impossibility of a conspiracy on the scale purported by Bacque, Villa states that "n truth, had Eisenhower committed the crimes Bacque alleges, someone surely would have gossiped, ratted, leaked, or even just hinted. None did. Not even Field Marshal Montgomery. Certainly, if there had been a holocaust, it could never have been covered up." Regarding the overall bureaucracy within which Eisenhower had to operate, Villa stated that "Although the average reader of "Other Losses" would never know it, there was a constellation of authorities to whom Eisenhower had to report his actions. Examining the situation as of May 8, 1945, when his murderous policy is said to have gone into full gear, no responsible historian could ignore the many limitations on Eisenhower's authority that made it impossible for him to carry out an independent policy in Germany."
"Other Losses" methodology.
Cowdrey stated that Bacque's methodology for determining just the "Other Losses" figures was also "slipshod", with Bacque filling gaps in the records where no "other losses" were recorded by "comput the number of deaths by applying the death rate given in Army statistics for another period to the known number of prisoners at hand." Cowdrey states that the "rate given in Army statistics" turned out to be a "rate invented by Bacque himself." Cowdrey states that, with regard to Bacque's attempt to analyze a U.S. Army hospital record document, Bacque not only missed an obvious typo throwing his calculations off by 10, but he also badly erred in the math used to tabulate purported death rates of 30%, which he attempts to use to support his claim that the "other losses" column in the weekly army reports reflects a body count. Cowdrey concludes that "the mathematical blunders of "Other Losses" are elementary. One turns from them feeling only embarrassment for the author who naively grounds his thesis upon them."
Historian Rolf Steininger stated that Bacque's claim that the failure to publish the 1960s and 1970s German Maschke Commission finding death figures to be a "cover up" contradicts that the entire 22 volume series was actually published in 1972 without any restrictions, to which only an oblique reference is made in an "Other Losses" endnote. Steininger says that "Bacque himself is one of the mythmakers" and that, when Bacque attacks the Maschke Commission scholars as "client-academics", "he oversteps the bounds of mythmaking and enters the territory of libel." Historian Gunter Bischoff states that it is simply "outrageous to dismiss this vast and impressive body of scholarship as being designed to produce 'soothing conclusions' for the German public, as Bacque puts it."
Bischoff said that while "most scholarly reviewers of Bacque's book have pointed out that Bacque fails to establish the proper historical context", "worse, the historical records that Bacque did use are amateurishly misrepresented and often misleading or wrong. Once Bacque's endnotes are checked, frequent misreadings of documents are easily discernible." As an example, Bischoff states that Bacque charged that General Mark Clark's raising of caloric intake in the Ebensee camp was "trying to exculpate himself before history" of Eisenhower's scheme to exterminate Germans. Bischoff states that Bacque fails to tell his readers, first, that Ebensee was not even an Allied prisoner of war camp, but a camp for displaced persons that was actually housing Polish Jews liberated from a nearby concentration camp, second, that Clark raised the caloric intake levels in response to a report critical of the treatment of liberated Jews that had just been released and, third, that Eisenhower soon thereafter also raised the levels for his Jewish displaced persons in camps run by Eisenhower.
Oral histories.
Regarding oral histories, Bischoff concludes that "Bacque abuses the process through his highly selective presentation of oral histories and memoir literature." "Other Losses" cited Colonel Phillip S. Lauben as the source for the claim that the "other losses" weekly report column covered up deaths. The New Orleans panel noted that Lauben himself twice has since repudiated this. When describing his interview with Bacque, Lauben stated "I am 91 years old, legally blind, and my memory has lapsed to a point where it is quite unreliable ... Often during my talk with Mr. Bacque I reminded him that my memory has deteriorated badly during the 40 odd years since 1945. Mr. Bacque read to me the USFET POW figures for discharge and transfers to other national zones. It seemed to me that, after accounting for transfers and discharges, there was nothing left to make up the grand total except deaths and escapes. I.e.: the term OTHER LOSSES. I was mistaken ... many POWs were transferred from one U.S. Command to another U.S. Command. This left one with a loss and the other with a gain."
Bacque described his other witness, John Foster, as a camp guard "in charge of the work detail of fifty men, Germans and Americans, who did nothing all day but drag bodies out of the camp." Bischoff cites a researcher for the Canadian Broadcasting Corporation (CBC) who tracked down Foster who told the researcher that "he never was a member of a burial detail, he never buried a body in his life. And he's unaware of any such activity in any camps." When the CBC interviewer confronted Bacque with Foster's denial, Bacque responded "well, he's wrong. He's just wrong."
Bacque also interviewed Martin Brech, a U.S. soldier who was a guard at the Andernach camp. Brech discussed his experiences in detail, in which he witnessed the poor conditions in the camp, the large number of deaths, and the systematic starving of the prisoners. He said "The silence about this atrocity has pained me for forty-five years and I'm deeply grateful that James Bacque's 'Other Losses' has at last brought the truth to light."
Bacque states that he has received letters and phone calls from about 2,000 Germans who survived the camps, expressing gratitude that the truth about their experience has finally been published.
European food shortage.
Historian James Tent concludes that "James Bacque might be willing to relegate the world food shortage to the category of myth. Few others will do so. Perhaps he can try the interviewing techniques that he employed in "Other Losses"—namely putting words in the mouths of selective eyewitnesses." The introduction to the New Orleans panel's book concludes that Bacque's insistence not only defies common sense, but it would have shocked anyone in Europe in 1945. "Other Losses" states "There was a lot more wheat available in the combined areas of western Germany, France, Britain, Canada and the USA than there had been in the same year in 1939." Tent states that Bacque selectively cited diary entries and other sources to come to the conclusion of a food abundance and the lack of transportation problems. Tent further stated that Bacque's statements that the German population was 4% smaller in 1945 than in 1939 while mentioning only an "influx of refugees from the East", completely ignored that that "influx" consisted of a staggering 10 to 13 million Germans displaced from the east and south into Germany that had to be fed and housed. The panel introduction also stated that Bacque ignored the overriding reality that German agriculture had suffered extreme productivity decreases in 1944 and 1945, a shortage of synthetic fertilizers had developed after nitrogen and phosphate stocks were channeled into ammunition production, Tent stated that Bacque completely ignored that, because coal reserves had disappeared from the industrial pipeline, fertilizer plants and other food production facilities were inoperable, meaning that German farmers could expect little if any fertilizer over the next one to two years and that fuel was next to non-existent to power run-down farm equipment. In addition, the panel introduction said that Bacque ignored that the destroyed German transportation infrastructure created additional logistical nightmares, with railroad lines, bridges and terminals left in ruins, the turnaround time for railroad wagons was five times higher than the prewar average, and, of the 15,600 German locomotives, 38.6% were no longer operating and 31% were damaged.
The introduction to the panel's book also states that Bacque ignored that Eisenhower himself was the one warning his superiors about food shortages as early as February 1945—months before the war had even ended—then again in May when Eisenhower requested food imports from the United States. Tent stated that Bacque also misleadingly cited only part of a June 1945 war report that 630,000 tons of imported wheat would meet the minimum German civilians minimum food requirements, leaving the reader thinking that the food shortage could easily be solved by United States shipments, without informing the reader of an accompanying report that the Allies brought in 600,000 tons of grain, and that it was quickly used up.
While "Other Losses" claims that the United States dismissed the Swiss Government from its role as a protecting power, Villa states that Bacque ignores that it was the Soviets that had vetoed permitting the continued existence of the German government in May 1945, leaving the Swiss no longer wanting to remain the protecting power because they no longer had a German government to which to report, and that the United Nations—including Canada—had concluded the same. Villa adds that, contrary to Bacque's implications, there is no evidence that Eisenhower would not have wanted the German government to continue operating under Doenitz' leadership in Flemsberg. Even with regard to the supposed Canadian protest, Villa states "this is another case of Bacque's outrageous editing of a document" with Bacque using ellipses to edit out of his quote of the document the key text stating "in the present unique situation there can be no protecting power for a Government which cannot exist."
Bischoff stated that, even in Bacque's later released American edition, "Bacque refuses to address the overwhelming evidence that there had been a great shortage of food in central Europe, beyond admitting that there was a food crisis in Germany in 1946" and "but again he turns the evidence on its head when he charges that 'Allied food policy longer does he heap the blame on the Americas alone, as in his Canadian edition deliberately hampered the Germans in attempting to feed themselves.'" Bischoff states "the opposite is true", citing the large amounts of U.S. Army GARDA Aid, without which "German and Austrian civilians would have had a much tougher time surviving the hunger months of 1945 and 1946."
"Other Losses" treatment of Eisenhower statements.
Bischoff and Ambrose stated that "Other Losses" states that of Eisenhower, "he felt ashamed that he bore a German name", citing Stephen Ambrose and Colonel Ernest Fisher, when what Ambrose said to Fischer was "It is rumored that Ike once said, 'I'm ashamed my name is Eisenhower,' but I've never seen it, never used it, and don't believe it." They concluded that "twisting of historical evidence—both primary and secondary—is not unusual in "Other Losses". In the end, Bacque usually resorts to conspiracy theories to salvage his outrageous charges." Regarding another example, Bischoff and Ambrose stated that "[one of Bacque's strongest quotations is a line from one of Eisenhower's letters to his wife, Mamie: 'God I hate the Germans.' Bacque seems not to understand that the words were appropriate to the subject, that Ike was by no means unique, and that John Eisenhower printed the letter in his book "Letters to Mamie", where Bacque found it, without embarrassment." They also stated that, when in 1943, when discussing that he had never been trained for such logistics when he faced a similar problem in Tunisia, Eisenhower stated "we should have killed more of them", which Bacque took seriously in "Other Losses" (it was also removed in 1969 from a report lest it offend Allies). POWs from Tunisia fared well after being shipped to the United States, where they were well fed in U.S. POW camps.
"Other Losses" discussion of DEF designations.
With regard to DEF designations, Historian Brian Loring Villa stated that Bacque ignores the 1943 debates of the European Advisory Commission (EAC) and the 1944 EAC's instruments of surrender, not picking up until the March 1945. "Other Losses" states that "in March, as Germany was being cracked ... a message was being signed and initialed by Eisenhower proposed a startling departure from the Geneva Convention(GC)—the creation of a new class of prisoners who would not be fed by the Army after the surrender of Germany. The message, dated March 10, reads: ... " "Other Losses" then quotes the cable from the third paragraph, which, Villa states, permits the casual reader to believe that Eisenhower invented the term "disarmed enemy forces", specifically omitting the other parts of the document referencing the EAC's draft surrender terms suggesting a designation to avoid the Geneva Convention categories, or the later use of the term "disarmed enemy forces." Villa states that, when the actual full correspondence is read, Eisenhower was merely proposing, in March 1945 with thousands of prisoners surrendering, to act on the surrender condition drafts worked out months earlier. Villa concludes that "ll Bacque had to do was look for the EAC draft surrender terms mentioned in the cable—these can readily be found in the standard collection of printed United States Diplomatic documents."
Villa further states that "Other Losses" wrongly cites a March CCS directive to Eisenhower, claiming that it directs Eisenhower to not take any prisoners after Victory in Europe (V-E) Day, when in fact, the directive states that those taken after V-E day should not be designated as "Prisoners of War" under the Geneva Convention. In fact, JCS 1067 required Eisenhower to continue to take prisoners after V-E Day. Moreover, if Bacque truly believes that Eisenhower was supposed to stop taking prisoners, Villa states that Bacque does not explain how Eisenhower could have gotten away with taking 2 million prisoners after this date without CCS action.
Villa also states that Bacque's assertion that the British rejected designations to not comply with the GC requirements are entirely unfounded and ignore that the British themselves requested that they be permitted to use such designations, with that request being granted by the CCS and used in surrenders to British troops. Villa states that Bacque also entirely ignores that it was the Soviets that had first raised issues about GC requirements in wartime conferences because they were not GC signatories, and as such, did not want condition surrender terms reflecting GC requirements. Villa stated that Bacque goes further regarding the Soviets, implying that the scale of Soviet gulags were a myth invented to cover up the American crime he asserts. Villa also stated that Bacque claims that Eisenhower initially underestimated the expected POW figures as part of his attempt to starve them, while in actuality, Eisenhower was desperately requesting to have food imports approved. "Other Losses" fails to cite JCS 1067, the primary restriction on food importation, even once in its notes. Villa also states that Bacque misrepresented a June 5, 1945 memorandum in a way that makes the reader believe that Eisenhower could have requisitioned additional food if he had wanted to, while the memorandum itself makes clear that Eisenhower had requested and was denied additional imports. Villa concludes: "Need it be added that anyone going back to the documents to find purported confessions of an extermination policy by one of Eisenhower's principal staff officers will find nothing even suggestive of it? Bacque has simply distorted the context beyond all recognition."
Other evidence for German POW deaths.
Several historians rebutting Bacque have argued that the missing POWs simply went home, that Red Cross food aid was sent to displaced civilians and that German POWs were fed the same rations that the U.S. Army was providing to the civilian population. U.S. and German sources estimate the number of German POWs who died in captivity at between 56,000 and 78,000, or about one percent of all German prisoners, which is roughly the same as the percentage of American POWs who died in German captivity. The book "Other Losses" alleged 1.5 million prisoners were missing and estimated that up to 500,000 of these were in Soviet camps. When the KGB opened its archives in the 1990s, 356,687 German soldiers and 93,900 civilians previously recorded as missing were found to be listed in the Bulanov report as dying in the Soviet camps.
German POW expert Kurt W. Bohme noted that, of the 5 million prisoners in American hands, the European Theater of Operations provost marshall recorded a total of 15,285 prisoner deaths. In 1974, the German Red Cross reported that about 41,000 German MIAs were last reported in western Germany, which is also the location of the prisoner camps. It is reasonable to assume that some deaths in transit camps just before the end of the war went unreported in the chaos at the time. Historian Albert Cowdrey estimates that the total figure is unlikely to be above the aggregate of the recorded deaths and the MIAs, which together total 56,285. That maximum number would constitute approximately 1.1% of the 5 million total prisoners held by U.S. forces. That figure also is close to Bohme's estimate of 1% for deaths of prisoners held by the Western powers.
Many of these occurred in the initial Rheinwiesenlager transit camps. The German Maschke Commission which studied prisoner deaths in the 1960s and 1970s concluded that 557,000 prisoners lived in the Rheinwiesenlager camps. The official death toll for those camps was 3,053. The number registered by local Parish authorities was 5,311. The Maschke Commission noted that the largest claim was that "32,000 fatalities had been heard of", but the Maschke Commission considered this account to be impossible, as was anything in excess of double the Parish authorities' figure.
While harsh treatment of prisoners occurred, no evidence exists that it was part of an organized systematic effort. Bohme concluded that Eisenhower and the U.S. Army had to improvise for months in taking care of the masses of prisoners to prevent a catastrophe: "In spite of all the misery that occurred behind the barbed wire, the catastrophe was prevented; the anticipated mass deaths did not happen."
The total death rates for United States-held prisoners is also far lower than those held by most countries throughout the war. In 1941 alone, two million of the 3.3 million German-held Soviet POWs—about 60%—died or were executed by the special SS "Action Groups" (Einsatzgruppen). By 1944, only 1.05 million of 5 million Soviet prisoners in German hands had survived. Of some 2–3 million German POWs in Russian hands, more than 1 million died. Of the 132,000 British and American POWs taken by the Japanese army, 27.6% died in captivity—the Bataan death march being the most notorious incident, producing a POw death rate of between 40 and 60%.
The historian Niall Ferguson claims a significantly lower death rate of 0.15% for German POWs held by Americans, less than every other country except for fellow allied power Britain. Ferguson further claims that another advantage to surrendering to the British rather than the Americans was that the British were also less likely to hand German prisoners over to the Soviet Union. Large numbers of German prisoners were transferred between the Allies. The U.S gave 765,000 to France, 76,000 to Benelux countries, and 200,000 to the Soviet Union. The U.S. also chose to refuse to accept the surrender of German troops attempting to surrender in Saxony and Bohemia. These soldiers were instead handed over to the Soviet Union. (The Soviet Union in turn handed German prisoners over to other Eastern European nations, for example 70,000 to Poland) According to Ferguson the death rate of German soldiers held prisoner in the Soviet Union was 35.8%.
Ferguson tabulated the total death rate for POWs in World War II as follows:
Lack of records.
There are no longer any surviving records showing which German POWs and Disarmed Enemy Forces were in U.S. custody prior to roughly September 1945. The early standard operating procedure for handling POWs and Disarmed Enemy Forces was to send a copy of the POW form to the Central Registry of War Criminals and Security Suspects (CROWCASS). However, this practice was apparently stopped as impractical, and all copies of the POW forms, roughly eight million, were destroyed. By way of contrast, the Soviet archives contain dossiers for every German POW they held, averaging around 15 pages for each.
References.
Primary
Secondary

</doc>
<doc id="65976" url="https://en.wikipedia.org/wiki?curid=65976" title="List of Canadian writers">
List of Canadian writers

This is a list of Canadian literary figures, including poets, novelists, children's writers, essayists, and scholars.
__NOTOC__

</doc>
<doc id="65980" url="https://en.wikipedia.org/wiki?curid=65980" title="Jaundice">
Jaundice

Jaundice, also known as icterus, is a yellowish pigmentation of the skin, the conjunctival membranes over the sclerae (whites of the eyes), and other mucous membranes caused by high blood bilirubin levels. This hyperbilirubinemia causes increased levels of bilirubin in the extracellular fluid. Concentration of bilirubin in blood plasma is normally below 1.2 mg/dL (<25µmol/L). A concentration higher than approx. 3 mg/dL (>50µmol/L) leads to jaundice. The term jaundice is from the French word "jaune", meaning yellow.
Jaundice is often seen in liver disease such as hepatitis or liver cancer. It may also indicate leptospirosis or obstruction of the biliary tract, for example by gallstones or pancreatic cancer, or less commonly be congenital in origin (e.g., biliary atresia).
Yellow discoloration of the skin, especially on the palms and the soles, but not of the sclera and mucous membranes (i.e., oral cavity) is due to carotenemia—a harmless condition important to differentiate from jaundice. Other things that can cause similar discoloration include as a side effect to the use of drug mepacrine or excessive exposure to phenols.
Signs and symptoms.
The main symptom of jaundice is a yellowish discoloration of the white area of the eye and the skin. Urine is dark in colour.
Slight increases in serum bilirubin are best detected by examining the sclerae, which have a particular affinity for bilirubin due to their high elastin content. The presence of scleral icterus indicates a serum bilirubin of at least 3 mg/dL.
The conjunctiva of the eye are one of the first tissues to change color as bilirubin levels rise in jaundice. This is sometimes referred to as "scleral icterus". However, the sclera themselves are not "icteric" (stained with bile pigment) but rather the conjunctival membranes that overlie them. The yellowing of the "white of the eye" is thus more properly termed "conjunctival icterus". The term "icterus" itself is sometimes incorrectly used to refer to jaundice that is noted in the sclera of the eyes, however its more common and more correct meaning is entirely synonymous with jaundice.
Complications.
Hyperbilirubinemia, more precisely hyperbilirubinemia due to the unconjugated fraction, may cause bilirubin to accumulate in the gray matter of the central nervous system, potentially causing irreversible neurological damage leading to a condition known as kernicterus. Depending on the level of exposure, the effects range from clinically unnoticeable to severe brain damage and even death. Newborns are especially vulnerable to hyperbilirubinemia-induced neurological damage and therefore must be carefully monitored for alterations in their serum bilirubin levels.
Differential diagnosis.
When a pathological process interferes with the normal functioning of the metabolism and excretion of bilirubin just described, jaundice may be the result. Jaundice is classified into three categories, depending on which part of the physiological mechanism the pathology affects. The three categories are:
Pre-hepatic.
"Pre-hepaticular" jaundice is caused by anything which causes an increased rate of hemolysis (breakdown of red blood cells). Unconjugated bilirubin comes from the breakdown of the heme pigment found in red blood cells' hemoglobin. The increased breakdown of red blood cells leads to an increase in the amount of unconjugated bilirubin present in the blood and deposition of this unconjugated bilirubin into various tissues can lead to a jaundiced appearance. In tropical countries, severe malaria can cause jaundice in this manner. Certain genetic diseases, such as sickle cell anemia, spherocytosis, thalassemia, pyruvate kinase deficiency, and glucose 6-phosphate dehydrogenase deficiency can lead to increased red cell lysis and therefore hemolytic jaundice. Commonly, diseases of the kidney, such as hemolytic uremic syndrome, can also lead to coloration. Defects in bilirubin metabolism also leads to jaundice, as in Gilbert's syndrome (a genetic disorder of bilirubin metabolism which can result in mild jaundice, which is found in about 5% of the population) and Crigler-Najjar syndrome, Type I and II.
In jaundice secondary to hemolysis, the increased production of bilirubin leads to the increased production of urine-urobilinogen. Bilirubin is not usually found in the urine because unconjugated bilirubin is not water-soluble, so, the combination of increased urine-urobilinogen with no bilirubin (since, unconjugated) in urine is suggestive of hemolytic jaundice.
Laboratory findings include:
Hepatocellular.
"Hepatocellular (hepatic)" jaundice can be caused by acute or chronic hepatitis, hepatotoxicity, cirrhosis, drug-induced hepatitis and alcoholic liver disease. Cell necrosis reduces the liver's ability to metabolize and excrete bilirubin leading to a buildup of unconjugated bilirubin in the blood. Other causes include primary biliary cirrhosis leading to an increase in plasma conjugated bilirubin because there is impairment of excretion of conjugated bilirubin into the bile. The blood contains an abnormally raised amount of conjugated bilirubin and bile salts which are excreted in the urine. Jaundice seen in the newborn, known as "neonatal jaundice", is common in newborns as hepatic machinery for the conjugation and excretion of bilirubin does not fully mature until approximately two weeks of age. Rat fever (leptospirosis) can also cause hepatic jaundice. In hepatic jaundice, there is invariably cholestasis.
Laboratory findings depend on the cause of jaundice.
Bilirubin transport across the hepatocyte may be impaired at any point between the uptake of unconjugated bilirubin into the cell and transport of conjugated bilirubin into biliary canaliculi. In addition, swelling of cells and oedema due to inflammation cause mechanical obstruction of intrahepatic biliary tree. Hence in hepatocellular jaundice, concentration of both unconjugated and conjugated bilirubin rises in the blood. In hepatocellular disease, there is usually interference in all major steps of bilirubin metabolism—uptake, conjugation and excretion. However, excretion is the rate-limiting step, and usually impaired to the greatest extent. As a result, conjugated hyperbilirubinaemia predominates.
The unconjugated bilirubin still enters the liver cells and becomes conjugated in the usual way. This conjugated bilirubin is then returned to the blood, probably by rupture of the congested bile canaliculi and direct emptying of the bile into the lymph leaving the liver. Thus, most of the bilirubin in the plasma becomes the conjugated type rather than the unconjugated type, and this conjugated bilirubin which did not go to intestine to become urobilinogen gives the urine the dark color.
Post-hepatic.
"Post-hepatic" jaundice, also called obstructive jaundice, is caused by an interruption to the drainage of bile containing conjugated bilirubin in the biliary system. The most common causes are gallstones in the common bile duct, and pancreatic cancer in the head of the pancreas. Also, a group of parasites known as "liver flukes" can live in the common bile duct, causing obstructive jaundice. Other causes include strictures of the common bile duct, biliary atresia, cholangiocarcinoma, pancreatitis, cholestasis of pregnancy, and pancreatic pseudocysts. A rare cause of obstructive jaundice is Mirizzi's syndrome.
In complete obstruction of the bile duct, no urobilinogen is found in the urine, since bilirubin has no access to the intestine and it is in the intestine that bilirubin gets converted to urobilinogen to be later released into the general circulation. In this case, presence of bilirubin (conjugated) in the urine without urine-urobilinogen suggests obstructive jaundice, either intra-hepatic or post-hepatic.
The presence of pale stools and dark urine suggests an obstructive or post-hepatic cause as normal feces get their color from bile pigments. However, although pale stools and dark urine are a feature of biliary obstruction, they can occur in many intra-hepatic illnesses and are therefore not a reliable clinical feature to distinguish obstruction from hepatic causes of jaundice.
Patients also can present with elevated serum cholesterol, and often complain of severe itching or "pruritus" because of the deposition of bile salts.
No single test can differentiate between various classifications of jaundice. A combination of liver function tests is essential to arrive at a diagnosis.
Neonatal jaundice.
"Neonatal jaundice" is usually harmless: this condition is often seen in infants around the second day after birth, lasting until day 8 in normal births, or to around day 14 in premature births. Typical causes for neonatal jaundice include normal physiologic jaundice, jaundice due to formula supplementation, and hemolytic disorders that include hereditary spherocytosis, glucose-6-phosphate dehydrogenase deficiency, pyruvate kinase deficiency, ABO/Rh blood type autoantibodies, or infantile pyknocytosis. Serum bilirubin normally drops to a low level without any intervention required. In cases where bilirubin rises higher, a brain-damaging condition known as kernicterus can occur, leading to significant disability. This condition has been rising in recent years due to less time spent outdoors. A Bili light is often the tool used for early treatment, which often consists of exposing the baby to intensive phototherapy. Sunbathing is effective treatment, and has the advantage of ultra-violet-B, which promotes Vitamin D production. Bilirubin count is lowered through bowel movements and urination, so frequent and effective feedings are especially important.
Pathophysiology.
Jaundice itself is not a disease, but rather a sign of one of many possible underlying pathological processes that occur at some point along the normal physiological pathway of the metabolism of bilirubin in blood.
When red blood cells have completed their life span of approximately 120 days, or when they are damaged, their membranes become fragile and prone to rupture. As each red blood cell traverses through the reticuloendothelial system, its cell membrane ruptures when its membrane is fragile enough to allow this. Cellular contents, including hemoglobin, are subsequently released into the blood. The hemoglobin is phagocytosed by macrophages, and split into its heme and globin portions. The globin portion, a protein, is degraded into amino acids and plays no role in jaundice. Two reactions then take place with the heme molecule. The first oxidation reaction is catalyzed by the microsomal enzyme heme oxygenase and results in biliverdin (green color pigment), iron and carbon monoxide. The next step is the reduction of biliverdin to a yellow color tetrapyrol pigment called bilirubin by cytosolic enzyme biliverdin reductase. This bilirubin is "unconjugated," "free" or "indirect" bilirubin. Approximately 4 mg of bilirubin per kg of blood is produced each day. The majority of this bilirubin comes from the breakdown of heme from expired red blood cells in the process just described. However approximately 20 percent comes from other heme sources, including ineffective erythropoiesis, and the breakdown of other heme-containing proteins, such as muscle myoglobin and cytochromes.
Hepatic events.
The unconjugated bilirubin then travels to the liver through the bloodstream. Because this bilirubin is not soluble, however, it is transported through the blood bound to serum albumin. Once it arrives at the liver, it is conjugated with glucuronic acid (to form bilirubin diglucuronide, or just "conjugated bilirubin") to become more water-soluble. The reaction is catalyzed by the enzyme UDP-glucuronyl transferase.
This conjugated bilirubin is excreted from the liver into the biliary and cystic ducts as part of bile. Intestinal bacteria convert the bilirubin into urobilinogen. From here urobilinogen can take two pathways. It can either be further converted into stercobilinogen, which is then oxidized to stercobilin and passed out in the feces, or it can be reabsorbed by the intestinal cells, transported in the blood to the kidneys, and passed out in the urine as the oxidised product urobilin. Stercobilin and urobilin are the products responsible for the coloration of feces and urine, respectively.
Diagnostic approach.
Most patients presenting with jaundice will have various predictable patterns of liver panel abnormalities, though significant variation does exist. The typical liver panel will include blood levels of enzymes found primarily from the liver, such as the aminotransferases (ALT, AST), and alkaline phosphatase (ALP); bilirubin (which causes the jaundice); and protein levels, specifically, total protein and albumin. Other primary lab tests for liver function include gamma glutamyl transpeptidase (GGT) and prothrombin time (PT).
Some bone and heart disorders can lead to an increase in ALP and the aminotransferases, so the first step in differentiating these from liver problems is to compare the levels of GGT, which will only be elevated in liver-specific conditions. The second step is distinguishing from biliary (cholestatic) or liver (hepatic) causes of jaundice and altered laboratory results. The former typically indicates a surgical response, while the latter typically leans toward a medical response. ALP and GGT levels will typically rise with one pattern while aspartate aminotransferase (AST) and alanine aminotransferase (ALT) rise in a separate pattern. If the ALP (10–45 IU/L) and GGT (18–85) levels rise proportionately about as high as the AST (12–38 IU/L) and ALT (10–45 IU/L) levels, this indicates a cholestatic problem. On the other hand, if the AST and ALT rise is significantly higher than the ALP and GGT rise, this indicates an hepatic problem. Finally, distinguishing between hepatic causes of jaundice, comparing levels of AST and ALT can prove useful. AST levels will typically be higher than ALT. This remains the case in most hepatic disorders except for hepatitis (viral or hepatotoxic). Alcoholic liver damage may see fairly normal ALT levels, with AST 10x higher than ALT. On the other hand, if ALT is higher than AST, this is indicative of hepatitis. Levels of ALT and AST are not well correlated to the extent of liver damage, although rapid drops in these levels from very high levels can indicate severe necrosis. Low levels of albumin tend to indicate a chronic condition, while it is normal in hepatitis and cholestasis.
Lab results for liver panels are frequently compared by the magnitude of their differences, not the pure number, as well as by their ratios. The AST:ALT ratio can be a good indicator of whether the disorder is alcoholic liver damage (above 10), some other form of liver damage (above 1), or hepatitis (less than 1). Bilirubin levels greater than 10x normal could indicate neoplastic or intrahepatic cholestasis. Levels lower than this tend to indicate hepatocellular causes. AST levels greater than 15x tends to indicate acute hepatocellular damage. Less than this tend to indicate obstructive causes. ALP levels greater than 5x normal tend to indicate obstruction, while levels greater than 10x normal can indicate drug (toxic) induced cholestatic hepatitis or Cytomegalovirus. Both of these conditions can also have ALT and AST greater than 20× normal. GGT levels greater than 10x normal typically indicate cholestasis. Levels 5–10× tend to indicate viral hepatitis. Levels less than 5× normal tend to indicate drug toxicity. Acute hepatitis will typically have ALT and AST levels rising 20–30× normal (above 1000), and may remain significantly elevated for several weeks. Acetaminophen toxicity can result in ALT and AST levels greater than 50x normal.
Etymology.
Jaundice comes from the French "jaune", meaning yellow.
The medical term for jaundice is icterus.
Icterus is from the Greek word "ίκτερος"; adjectival form, icteric.

</doc>
