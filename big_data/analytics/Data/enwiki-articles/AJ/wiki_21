<doc id="68276" url="https://en.wikipedia.org/wiki?curid=68276" title="Microtonal music">
Microtonal music

Microtonal music or microtonality is the use in music of microtones—intervals smaller than a semitone, which are also called "microintervals". It may also be extended to include any music using intervals not found in the customary Western tuning of twelve equal intervals per octave.
Terminology.
Microtone.
"Microtonal music" can refer to any music containing microtones, therefore it is important to comprehend what a "microtone" is. The words "microtone" and "microtonal" were coined before 1912 by Maud MacCarthy Mann in order to avoid the misnomer "quarter tone" when speaking of the srutis of Indian music . Prior to this time the term "quarter tone" was used, confusingly, not only for an interval actually half the size of a semitone, but also for all intervals (considerably) smaller than a semitone (; ). It may have been even slightly earlier, perhaps as early as 1895, that the Mexican composer Julián Carrillo, writing in Spanish or French, coined the terms "microtono"/"micro-ton" and "microtonalismo"/"micro-tonalité" . 
In French, the usual term is the somewhat more self-explanatory "micro-intervalle", and French sources give the equivalent German and English terms as "Mikrointervall" (or "Kleinintervall") and "micro interval" (or "microtone"), respectively (; ; ; . "Microinterval" is a frequent alternative in English, especially in translations of writings by French authors and in discussion of music by French composers (; ; ). In English, the two terms "microtone" and "microinterval" are synonymous . The English analogue of the related French term, "micro-intervallité", however is rare or nonexistent, normally being translated as "microtonality"; in French, the terms "micro-ton", "microtonal" (or "micro-tonal"), and "microtonalité" are also sometimes used, occasionally mixed in the same passage with "micro-intervalle" and "micro-intervalité" (; ; ).
Ezra Sims, in the article "Microtone" in the second edition of the "Harvard Dictionary of Music" defines "microtone" as "an interval smaller than a semitone", which corresponds with Aristoxenus's use of the term "diesis" . However, the unsigned article "Comma, Schisma" in the same reference source calls comma, schisma and diaschisma "microintervals" but not "microtones" , and in the fourth edition of the same reference (which retains Sims's article on "Microtone") a new "Comma, Schisma" article by André Barbera calls them simply "intervals" . In the second edition of "The New Grove Dictionary of Music and Musicians", Paul Griffiths, Mark Lindley, and Ioannis Zannos define "microtone" as a musical rather than an acoustical entity: "any musical interval or difference of pitch distinctly smaller than a semitone", including "the tiny enharmonic melodic intervals of ancient Greece, the several divisions of the octave into more than 12 parts, and various discrepancies among the intervals of just intonation or between a sharp and its enharmonically paired flat in various forms of mean-tone temperament", as well as the Indian sruti, and small intervals used in Byzantine chant, Arabic music theory from the 10th century onward, and various other Near Eastern musical traditions (), but do not actually name the "mathematical" terms schisma, comma, and diaschisma.
"Microtone" is also sometimes used to refer to individual notes, "microtonal pitches" added to and distinct from the familiar twelve notes of the chromatic scale , as "enharmonic microtones" , for example.
In English the word "microtonality" is mentioned in 1946 by Rudi Blesh who related it to microtonal inflexions of the so-called "blues scales" . It was used still earlier by W. McNaught with reference to developments in "modernism" in a 1939 record review of the "Columbia History of Music, Vol. 5" . In German the term "Mikrotonalität" came into use at least by 1958 (; ), though "Mikrointervall" is still common today in contexts where very small intervals of early European tradition (diesis, comma etc.) are described, as e.g. in the new "Geschichte der Musiktheorie" while "Mikroton" seems to prevail in discussions of the avant-garde music and music of Eastern traditions. The term "microinterval" is used alongside "microtone" by American musicologist Margo Schulter in her articles on medieval music (; ).
Microtonal.
The term "microtonal music" usually refers to music containing very small intervals but can include any tuning that differs from Western twelve-tone equal temperament. Traditional Indian systems of 22 śruti; Indonesian gamelan music; Thai, Burmese, and African music, and music using just intonation, meantone temperament or other alternative tunings may be considered microtonal (; ). Microtonal variation of intervals is standard practice in the African-American musical forms of spirituals, blues and jazz .
Many microtonal equal divisions of the octave have been proposed, usually (but not always) in order to achieve approximation to the intervals of just intonation (; ).
Terminology other than "microtonal" has been used or proposed by some theorists and composers. In 1914, A. H. Fox Strangways objected that "'heterotone' would be a better name for śruti than the usual translation 'microtone'" . Modern Indian researchers yet write: "microtonal intervals called shrutis" . In Germany, Austria, and Czechoslovakia in the 1910s and 1920s the usual term continued to be "Viertelton-Musik" (quarter-tone music; ), and the type of intervallic structure found in such music was called the "Vierteltonsystem" (,), which was (in the mentioned region) regarded as the main term for referring to music with microintervals, though as early as 1908 Georg Capellan had qualified his use of "quarter tone" with the alternative term "Bruchtonstufen (Viertel- und Dritteltöne)" (fractional degrees (quarter and third-tones)) . Despite the inclusion of other fractions of a whole tone, this music continued to be described under the heading "Vierteltonmusik" until at least the 1990s, for example in the twelfth edition of the Riemann Musiklexikon , and in the second edition of the popular "Brockhaus Riemann Musiklexikon" . 
Ivan Wyschnegradsky used the term "ultra-chromatic" for intervals smaller than the semitone and "infra-chromatic" for intervals larger than the semitone ; this same term has been used since 1934 by ethnomusicologist Victor Belaiev (Belyaev) in his studies of Azerbaijan and Turkish traditional music (; ). A similar term, "subchromatic", has been used recently by theorist Marek Žabka . Ivor Darreg proposed (where and when?) the term "xenharmonic". (See xenharmonic music). The Austrian composer Franz Richter Herf and his colleague at the Salzburg Mozarteum, the music theorist Rolf Maedel, preferred using the Greek word "ekmelic" when referring to "all the pitches lying outside the traditional twelve-tone system" . Some autors in Russia (; ; ; ; ; ), and some musicology dissertations (; ; ; ; , more references can be located here) disseminate the term "микрохроматика" (microchromatics), coined in the 1970s by Yuri Kholopov , to describe a kind of 'intervallic genus' (интервальный род) for all possible microtonal structures, both ancient (as enharmonic genus—γένος ἐναρμόνιον—of Greeks) and modern (as quarter-tone scales of Alois Haba); this generalization term allowed also to avoid derivatives such as "микротональность" (microtonality, which could be understood in Russian as a sub-tonality, which is subordinate to the dominating tonality, especially in the context of European music of the 19th century) and "микротоника" (microtonic, "a barely perceptible tonic"; see a clarification in ). Another Russian authors use more international adjective 'microtonal' and rendered it in Russian as 'микротоновый', but not 'microtonality' ('микротональность') (; ; ; etc. ). However are used 'микротональность' and 'микротоника' also. Some authors writing in French have adopted the term "micro-intervallique" to describe such music (e.g., ; ). Italian musicologist Luca Conti dedicated two his monographs to "microtonalismo" (; ), which is the usual term in Italian, and also in Spanish (e.g., as found in the title of ). The analogous English form, "microtonalism", is also found occasionally instead of "microtonality", e.g., "At the time when serialism and neoclassicism were still incipient a third movement emerged: microtonalism" .
The term "macrotonal" has been used for intervals wider than twelve-tone equal temperament , or where there are "fewer than twelve notes per octave," though "this term is not very satisfactory and is used only because there seems to be no other" . The term "macrotonal" has also been used for musical form .
History.
The Hellenic civilizations of ancient Greece left fragmentary records of their music—e.g. the Delphic Hymns. The ancient Greeks approached the creation of different musical intervals and modes by dividing and combining tetrachords, recognizing three genera of tetrachords: the enharmonic, the chromatic, and the diatonic. Ancient Greek intervals were of many different sizes, including microtones. The enharmonic genus in particular featured intervals of a distinctly "microtonal" nature, which were sometimes smaller than 50 cents, less than half of the contemporary Western semitone of 100 cents. In the ancient Greek enharmonic genus, the tetrachord contained a semitone of varying sizes (approximately 100 cents) divided into two equal intervals called dieses (single "diesis", δίεσις); in conjunction with a larger interval of roughly 400 cents, these intervals comprised the perfect fourth (approximately 498 cents, or the ratio of 4/3 in just intonation) . Theoretics usually described several diatonic and chromatic genera (some as chroai, "coloration" of one specific intervallic type), but the enarmonic genus was always the only one (argumented as one with the smallest intervals possible). 
Guillaume Costeley's "Chromatic Chanson", "Seigneur Dieu ta pitié" of 1558 used 1/3 comma meantone and explored the full compass of 19 pitches in the octave .
The Italian Renaissance composer and theorist Nicola Vicentino (1511–1576) worked with microtonal intervals and built a keyboard with 36 keys to the octave known as the archicembalo. While theoretically an interpretation of ancient Greek tetrachordal theory, in effect Vicentino presented a circulating system of quarter-comma meantone, maintaining major thirds tuned in just intonation in all keys .
In 1760 the French flautist [Charles?] De Lusse published a treatise, "L ’Art de la flute traversiere", all surviving copies of which conclude with a composition (possibly added a year or two after the actual publication of the volume) incorporating several quarter tones, titled "Air à la grecque", accompanied by explanatory notes tying it to the realization of the Greek enharmonic genus and a chart of quarter-tone fingerings for the entire range of the one-keyed flute. Shortly afterward, in a letter published in the "Mercure de France" in September 1764, the celebrated flautist Pierre-Gabriel Buffardin mentioned this piece and expressed an interest in quarter tones for the flute (; ).
Jacques Fromental Halévy composed a cantata "Prométhée enchaîné" for a solo voice, choir and orchestra (premiered in 1849), where in one movement ("Choeur des Océanides") he used quartertones, to imitate the enharmonic genus of Greeks. 
In the 1910s and 1920s, quarter tones (24 equal pitches per octave) received attention from such composers as Charles Ives, Julián Carrillo, Alois Hába, Ivan Wyschnegradsky, and Mildred Couper.
Alexander John Ellis, who in the 1880s produced a translation of Hermann Helmholtz's "On the Sensations of Tone", proposed an elaborate set of exotic just intonation tunings and non-harmonic tunings . Ellis also studied the tunings of non-Western cultures and, in a report to the Royal Society, stated that they did not use either equal divisions of the octave or just intonation intervals . Ellis inspired Harry Partch immensely .
During the Exposition Universelle of 1889, Claude Debussy heard a Balinese gamelan performance and was exposed to non-Western tunings and rhythms. Some scholars have ascribed Debussy's subsequent innovative use of the whole-tone (six equal pitches per octave) tuning in such compositions as the "Fantaisie for piano and orchestra" and the Toccata from the suite "Pour le piano" to his exposure to the Balinese gamelan at the Paris exposition , and have asserted his rebellion at this time "against the rule of equal temperament" and that the gamelan gave him "the confidence to embark (after the 1900 world exhibition) on his fully characteristic mature piano works, with their many bell- and gong-like sonorities and brilliant exploitation of the piano’s natural resonance" . Still others have argued that Debussy's works like "L'isle joyeuse", "La cathédrale engloutie", "Prélude à l'après-midi d'un faune", "La mer", "Pagodes", "Danseuses de Delphes", and "Cloches à travers les feuilles" are marked by a more basic interest in the microtonal intervals found between the higher members of the overtone series, under the influence of Helmholtz's writings . Emil Berliner's introduction of the phonograph in the 1890s allowed much non-Western music to be recorded and heard by Western composers, further spurring the use of non-12-equal tunings.
Major microtonal composers of the 1920s and 1930s include Alois Hába (quarter tones, or 24 equal pitches per octave, and sixth tones), Julián Carrillo (24 equal, 36, 48, 60, 72, and 96 equal pitches to the octave embodied in a series of specially custom-built pianos), Ivan Wyschnegradsky (third tones, quarter tones, sixth tones and twelfth tones, non octaving scales) and the early works of Harry Partch (just intonation using frequencies at ratios of prime integers 3, 5, 7, and 11, their powers, and products of those numbers, from a central frequency of G-196) .
Prominent microtonal composers or researchers of the 1940s and 1950s include Adriaan Daniel Fokker (31 equal tones per octave), Partch (continuing to build his handcrafted orchestra of microtonal just intonation instruments), and Eivind Groven.
Digital synthesizers from the Yamaha TX81Z (1987) on and inexpensive software synthesizers have contributed to the ease and popularity of exploring microtonal music.
Microtonality in electronic music.
Electronic music facilitates the use of any kind of microtonal tuning, and sidesteps the need to develop new notational systems . In 1954, Karlheinz Stockhausen built his electronic "Studie II" on an 81-step scale starting from 100 Hz with the interval of 51/25 between steps , and in "Gesang der Jünglinge" (1955–56) he used various scales, ranging from seven up to sixty equal divisions of the octave . In 1955, Ernst Krenek used 13 equal-tempered intervals per octave in his Whitsun oratorio, "Spiritus intelligentiae, sanctus" .
In 1979–80 Easley Blackwood composed a set of "Twelve Microtonal Etudes for Electronic Music Media," a cycle that explores all of the equal temperaments from 13 notes to the octave through 24 notes to the octave, including 15-ET and 19-ET . "The project," he wrote, "was to explore the tonal and modal behavior of all these equal tunings…, devise a notation for each tuning, and write a composition in each tuning to illustrate good chord progressions and the practical application of the notation" .
In 1986, Wendy Carlos experimented with many microtonal systems including just intonation, using alternate tuning scales she invented for the album "Beauty In the Beast". "This whole formal discovery came a few weeks after I had completed the album, "Beauty in the Beast", which is wholly in new tunings and timbres" .
Aphex Twin has been making microtonal electronic music with software and various analog and digital synthesizers since his 1994 album, "Selected Ambient Works Volume II". 
Microtonality in rock music.
A form of microtone known as the blue note is an integral part of rock music and one of its predecessors, the blues. The blue notes, located on the third, fifth, and seventh notes of a diatonic major scale, are flattened by a variable microtone .
Musicians like Jon Catler have incorporated microtonal guitars like 31-tone equal tempered guitar and a 62-tone just intonation guitar in blues and jazz rock music .
The band Radiohead have used microtonal string arrangements in their music, such as on "How to Disappear Completely" from their album "Kid A" .
See also.
Western microtonal pioneers.
Pioneers of modern Western microtonal music include:

</doc>
<doc id="68281" url="https://en.wikipedia.org/wiki?curid=68281" title="Venera">
Venera

The Venera (, ) series space probes were developed by the Soviet Union between 1961 and 1984 to gather data from Venus, Venera being the Russian name for Venus. As with some of the Soviet Union's other planetary probes, the later versions were launched in pairs with a second vehicle being launched soon after the first of the pair.
Ten probes from the Venera series successfully landed on Venus and transmitted data from the surface of Venus, including the two Vega program and Venera-Halley probes. In addition, thirteen Venera probes successfully transmitted data from the atmosphere of Venus.
Among the other results, probes of the series became the first human-made devices to enter the atmosphere of another planet (Venera 4 on October 18, 1967), to make a soft landing on another planet (Venera 7 on December 15, 1970), to return images from the planetary surface (Venera 9 on June 8, 1975), and to perform high-resolution radar mapping studies of Venus (Venera 15 on June 2, 1983). The entire series could be considered highly successful. The surface conditions on Venus are extreme, therefore the probes only survived on the surface for a duration of 23 minutes (initial probes) up to about two hours (final probes).
The Venera probes.
The first Soviet attempt at a flyby probe to Venus was launched on February 4, 1961, but failed to leave Earth orbit. In keeping with the (then) Soviet policy of not announcing details on failed missions, the launch was announced under the name Tyazhely Sputnik ("Heavy Satellite"). It is also known as Venera 1VA.
Venera 1 and Venera 2 were intended as fly-by probes to fly past Venus without entering orbit. Venera 1 was launched on February 12, 1961. Telemetry on the probe failed seven days after launch. It is believed to have passed within 100,000 km of Venus and remains in heliocentric orbit. Venera 2 launched on November 12, 1965, but also suffered a telemetry failure after leaving Earth orbit.
Several other failed attempts at Venus flyby probes were launched by the Soviet Union in the early 1960s, but were not announced as planetary missions at the time, and hence did not officially receive the "Venera" designation.
Venera 3 to 6.
The Venera 3 to 6 probes were similar. Weighing approximately one ton, and launched by the Molniya-type booster rocket, they included a cruise "bus" and a spherical atmospheric entry probe. The probes were optimised for atmospheric measurements, but not equipped with any special landing apparatus. Although it was hoped they would reach the surface still functioning, the first probes failed almost immediately, thereby disabling data transmission to Earth.
Venera 3 became the first human-made object to impact another planet's surface as it crash-landed on March 1, 1966. However, as the spacecraft's dataprobes had failed upon atmospheric penetration, no data from within the Venusian boundary were retrieved from the mission.
On 18 October 1967, Venera 4 became the first spacecraft to measure the atmosphere of another planet. While the Soviet Union initially claimed the craft reached the surface intact, re-analysis including atmospheric occultation data from the American Mariner 5 spacecraft that flew by Venus the day after its arrival demonstrated that Venus's surface pressure was 75-100 atmospheres, much higher than Venera 4's 25 atm hull strength, and the claim was retracted.
Realizing the ships would be crushed before reaching the surface, the Soviets launched Venera 5 and Venera 6 as atmospheric probes. Designed to jettison nearly half their payload prior to entering the planet's atmosphere, these craft recorded 53 and 51 minutes of data, respectively, while slowly descending by parachute before their batteries failed.
Venera 7.
The Venera 7 probe was the first one designed to survive Venus surface conditions and to make a soft landing. Massively overbuilt to ensure survival, it had few experiments on board, and scientific output from the mission was further limited due to an internal switchboard failure which stuck in the "transmit temperature" position. Still, the control scientists succeeded in extrapolating the pressure (90 atm) from the temperature data (), which resulted from the first direct surface measurements. The Doppler measurements of the Venera 4 to 7 probes were the first evidence of the existence of high-speed zonal winds (up to or ) in the Venusian atmosphere (super rotation).
Venera 7's parachute failed shortly before landing very close to the surface. It impacted at and toppled over, but survived. Due to the resultant antenna misalignment, the radio signal was very weak, but was detected (with temperature telemetry) for 23 more minutes before its batteries expired. Thus, it became, on 15 December 1970, the first human-made probe to transmit data from the surface of Venus.
Venera 8.
Venera 8 was equipped with an extended set of scientific instruments for studying the surface (gamma-spectrometer etc.). The cruise bus of Venera 7 and 8 was similar to that of earlier ones, with the design ascending to the Zond 3 mission. The lander transmitted data during the descent and landed in sunlight. It measured the light level but had no camera. It continued to send back data for almost an hour.
Venera 9 to 12.
The Venera 9 to 12 probes were of a different design. They weighed approximately five tons and were launched by the powerful Proton booster. They included a transfer and relay bus that had engines to brake into Venus orbit (Venera 9 and 10, 15 and 16) and to serve as receiver and relay for the entry probe's transmissions. The entry probe was attached to the top of the bus in a spherical heat shield. The probes were optimized for surface operations with an unusual looking design that included a spherical compartment to protect the electronics from atmospheric pressure and heat for as long as possible. Beneath this was a shock absorbing "crush ring" for landing. Above the pressure sphere was a cylindrical antenna structure and a wide dish shaped structure that resembled an antenna but was actually an aerobrake. They were designed to operate on the surface for a minimum of 30 minutes. Instruments varied on different missions, but included cameras and atmospheric and soil analysis equipment. All four landers had problems with some or all of their camera lens caps not releasing.
The Venera 9 lander operated for at least 53 minutes and took pictures with one of two cameras; the other lens cap did not release.
The Venera 10 lander operated for at least 65 minutes and took pictures with one of two cameras; the other lens cap did not release.
The Venera 11 lander operated for at least 95 minutes but neither cameras' lens caps released.
The Venera 12 lander operated for at least 110 minutes but neither cameras' lens caps released.
Venera 13 and 14.
The descent craft/lander contained most of the instrumentation and electronics, and was topped by an antenna. The design was similar to the earlier Venera 9–12 landers. They carried instruments to take scientific measurements of the ground and atmosphere once landed, including cameras, a microphone, a drill and surface sampler, and a seismometer. They also had instruments to record electric discharges during its descent phase through the Venusian atmosphere.
The two descent craft landed about apart, just east of the eastern extension of an elevated region known as Phoebe Regio. The Venera 13 lander survived for 127 minutes, and the Venera 14 lander for 57 minutes, where the planned design life was only 32 minutes. The Venera 14 craft had the misfortune of ejecting the camera lens cap directly under the surface compressibility tester arm, and returned information for the compressibility of the lens cap rather than the surface. The descent vehicles transmitted data to the buses, which acted as data relays as they flew by Venus.
Veneras 15 and 16.
Venera 15 and 16 were similar to previous probes, but replaced the entry probes with surface imaging radar equipment. Radar imaging was necessary to penetrate the dense cloud of Venus.
Vega probes.
The Vega probes to Venus and comet Halley launched in 1985 also used this basic Venera design, including landers but also atmospheric balloons which relayed data for about two days.
Scientific findings.
There were many scientific findings about Venus from the data retrieved by the Venera probes. For example, after analyzing the radar images returned from Venera 15 and 16, it was concluded that the ridges and grooves on the surface of Venus were the result of tectonic deformations.
Venera camera failures and success.
The Venera 9 and 10 landers had two cameras each. Only one functioned because the lens covers failed to separate from the second camera on each lander. The design was changed for Venera 11 and 12, but this change made the problem worse and all cameras failed on those missions. Venera 13 and 14 were the only landers on which all cameras worked properly; although unfortunately, the titanium lens cap on Venera 14 landed precisely on the area which was targeted by the soil compression probe.
The external link at the bottom of the page shows all lander imagery.

</doc>
<doc id="68282" url="https://en.wikipedia.org/wiki?curid=68282" title="Peasant">
Peasant

A peasant is a member of a traditional class of farmers, either laborers or owners of small farms, especially in the Middle Ages under feudalism, or more generally, in any pre-industrial society. In Europe, peasants were divided into three classes according to their personal status: slave, serf, and free tenant. Peasants either hold title to land in fee simple, or hold land by any of several forms of land tenure, among them socage, quit-rent, leasehold, and copyhold.
The word "peasant" is—and long has been—often used pejoratively to refer to poor or landless farmers and agricultural workers, especially in the poorer countries of the world in which the agricultural labor force makes up a large percentage of the population. The implication of the term is that the "peasant" is uneducated, ignorant, and unfamiliar with the more sophisticated mannerisms of the urban population. 
The word "peasant" is also commonly used in a non-pejorative sense as a collective noun for the rural population in the poor and under-developed countries of the world.
Etymology.
The word "peasant" is derived from the 15th century French word "païsant" (compare Italian "paesano"), meaning one from the "pays", or countryside; ultimately from the Latin "pagus", or outlying administrative district.
Social position.
Peasants typically made up the majority of the agricultural labour force in a pre-industrial society. The majority of the people in the Middle Ages were peasants.
Though "peasant" is a word of loose application, once a market economy had taken root, the term "peasant proprietors" was frequently used to describe the traditional rural population in countries where smallholders farmed much of the land. More generally, the word "peasant" is sometimes used to refer pejoratively to those considered to be "lower class", perhaps defined by poorer education and/or a lower income.
Medieval European peasants.
The open field system of agriculture dominated most of northern Europe during medieval times and endured until the nineteenth century in many areas. Under this system, peasants lived on a manor presided over by a lord or a bishop of the church. Peasants paid rent or labor services to the lord in exchange for their right to cultivate the land. Fallowed land, pastures, forests, and wasteland were held in common. The open field system required cooperation among the peasants of the manor. It was gradually replaced by individual ownership and management of land.
The relative position of peasants in Western Europe improved greatly when the Black Death reduced the population of medieval Europe in the mid-14th century, resulting in more land for the survivors and making labor more scarce. In the wake of this disruption to the established order, later centuries saw the invention of the printing press, the development of widespread literacy and the enormous social and intellectual changes of the Enlightenment.
The evolution of ideas in an environment of relatively widespread literacy laid the groundwork for the Industrial Revolution, which enabled mechanically and chemically augmented agricultural production while simultaneously increasing the demand for factory workers in cities who became what Karl Marx called the proletariat. The trend toward individual ownership of land, typified in England by Enclosure, displaced many peasants from the land and compelled them, often unwillingly, to become urban factory-workers, who came to occupy the socio-economic stratum formerly the preserve of the medieval peasants.
This process happened in an especially pronounced and truncated way in Eastern Europe. Lacking any catalysts for change in the 14th century, Eastern European peasants largely continued upon the original medieval path until the 18th and 19th centuries. Serfdom was abolished in Russia in 1861, and while many peasants would remain in areas where their family had farmed for generations, the changes did allow for the buying and selling of lands traditionally held by peasants, and for landless ex-peasants to move to the cities. Even before emancipation in 1861, serfdom was on the wane in Russia. The proportion of serfs within the empire had gradually decreased "from 45-50 percent at the end of the eighteenth century, to 37.7 percent in 1858."
Early modern Germany.
In Germany, peasants continued to center their lives in the village well into the 19th century. They belonged to a corporate body and helped to manage the community resources and to monitor community life. In the East they had the status of serfs bound permanently to parcels of land. A peasant is called a "Bauer" in German and "Bur" in Low German (pronounced in English like "boor").
In most of Germany, farming was handled by tenant farmers who paid rents and obligatory services to the landlord—typically a nobleman. Peasant leaders supervised the fields and ditches and grazing rights, maintained public order and morals, and supported a village court which handled minor offenses. Inside the family the patriarch made all the decisions, and tried to arrange advantageous marriages for his children. Much of the villages' communal life centered around church services and holy days. In Prussia, the peasants drew lots to choose conscripts required by the army. The noblemen handled external relationships and politics for the villages under their control, and were not typically involved in daily activities or decisions.
19th century France.
In his seminal book "Peasants into Frenchmen: the Modernization of Rural France, 1880–1914" (1976), historian Eugen Weber traced the modernization of French villages and argued that rural France went from backward and isolated to modern and possessing a sense of French nationhood during the late 19th and early 20th centuries. He emphasized the roles of railroads, republican schools, and universal military conscription. He based his findings on school records, migration patterns, military-service documents and economic trends. Weber argued that until 1900 or so a sense of French nationhood was weak in the provinces. Weber then looked at how the policies of the Third Republic created a sense of French nationality in rural areas. The book was widely praised, but some argued that a sense of Frenchness existed in the provinces before 1870.
Use of the term for Chinese farmers.
Farmers in China have been sometimes referred to as "peasants" in English-language sources. However, the traditional term for farmer, "nongfu" (农夫), simply refers to "farmer" or "agricultural worker". In the 19th century, Japanese intellectuals reinvented the Chinese terms "fengjian" (封建) for "feudalism" and "nongmin" (农民), or "farming people," terms used in the description of feudal Japanese society. These terms created a negative image of Chinese farmers by making a class distinction where one had not previously existed. Anthropologist Myron Cohen considers these terms to be neologisms that represented a cultural and political invention. He writes:
Modern Western writers often continue to use the term "peasant" for Chinese farmers, typically without ever defining what the term means. This Western use of the term suggests that China is stagnant, "medieval", underdeveloped, and held back by its rural population. Cohen writes that the "imposition of the historically burdened Western contrasts of town and country, shopkeeper and peasant, or merchant and landlord, serves only to distort the realities of the Chinese economic tradition".
Bur in Jewish scripture.
A bur is presented by the Rambam (Maimonides) as a person having neither (ethical) torah education nor virtues of manners nor the ability to acquire them. Maimonides gives five definitions of Hebrew terms found in Jewish scripture, that discuss foolishness and wisdom, they are, in ascending order: bur, am ha'aretz, golem, chacham, and chasid. The definition of the Hebrew term "bur" is extracted by Maimonides from the phrase "sedeh bur", which translates as an "uncultivated field". The Talmud and Mishnah (Pirke Avot II:4) also have this term.
Commonly, "bur" would be translated into English as "boor".
Historiography.
Since the literate classes have left the most records, and these tended to dismiss peasants as figures of coarse appetite and rustic comedy, the term "peasant" may have a pejorative rather than descriptive connotation in historical memory. Society was theorized as being organized into three "estates": those who work, those who pray, and those who fight. The Annales School of French historians emphasized the importance of peasants. Its leader Fernand Braudel devoted the first volume—called "The Structures of Everyday Life"—of his major work, "Civilization and Capitalism 15th–18th Century" to the largely silent and invisible world that existed below the market economy.
Other research in the field of peasant studies was promoted by Florian Znaniecki and Fei Xiaotong, and in the post-1945 studies of the "great tradition" and the "little tradition" in the work of Robert Redfield. In the 1960s, anthropologists and historians began to rethink the role of peasant revolt in world history and in their own disciplines. Peasant revolution was seen as a Third World response to capitalism and imperialism.
The anthropologist Eric Wolf, for instance, drew on the work of earlier scholars in the Marxist tradition such as Daniel Thorner, who saw the rural population as a key element in the transition from feudalism to capitalism. Wolf and a group of scholars criticized both Marx and the field of modernization theorists for treating peasants as lacking the ability to take action. James C. Scott's field observations in Malaysia convinced him that villagers were active participants in their local politics even though they were forced to use indirect methods. Many of these activist scholars looked back to the peasant movement in India and to the theories of the revolution in China led by Mao Zedong starting in the 1920s. The anthropologist Myron Cohen, however, asked why the rural population in China were called "peasants" rather than "farmers", a distinction he called political rather than scientific. One important outlet for their scholarly work and theory was the "Journal of Peasant Studies".

</doc>
<doc id="68283" url="https://en.wikipedia.org/wiki?curid=68283" title="Robert Towne">
Robert Towne

Robert Towne (born Robert Bertram Schwartz; November 23, 1934) is an American screenwriter, producer, director and actor. He was part of the New Hollywood wave of filmmaking. His most notable work was his Academy Award-winning original screenplay for Roman Polanski's "Chinatown" (1974), which is widely considered one of the greatest movie screenplays ever written. He also wrote its sequel "The Two Jakes" in 1990, and wrote the Hal Ashby comedy-dramas "The Last Detail" (1973), and "Shampoo" (1975), as well as the first two "Mission Impossible" films (, ).
Towne has also directed various films such as the sports dramas "Personal Best" (1982), and "Without Limits" (1998), the crime thriller "Tequila Sunrise" (1988), and the romantic crime drama "Ask the Dust" (2006).
Career.
Film.
Towne is the author of many notable film scripts, including "Chinatown" (1974), for which he received an Academy Award; its sequel, "The Two Jakes" (1990); the Oscar-nominated screenplays "The Last Detail" and "Shampoo"; as well as the first two "" films.
Towne has also a "stellar reputation" in the motion-picture industry as an uncredited script doctor, having worked in this capacity on "The Godfather", "Bonnie and Clyde", "The Parallax View", "The Rock" and on dozens of other Hollywood films.
After working for years on a script of "" (1984), he grew dissatisfied with the production and credited his dog, P.H. Vazak, with the script. Vazak became the first dog nominated for an Oscar for screenwriting, but he did not fetch the award.
Towne co-wrote the film "8 Million Ways to Die" using the alias David Lee Henry. Towne also wrote and directed "Personal Best" (1982), a fictional drama of female track-and-field athletes, and "Without Limits" (1998), a biopic based on the life of distance runner Steve Prefontaine. His crime story "Tequila Sunrise" (1988) co-starred Mel Gibson as a reformed cocaine dealer and Kurt Russell as a detective, with Michelle Pfeiffer as a woman who becomes romantically involved with both. Towne told "The New York Times" that "Tequila Sunrise" is "a movie about the use and abuse of friendship."
A project Towne had long sought to bring to the screen came to fruition in 2006 with "Ask the Dust", a romantic period piece set in Los Angeles based on the acclaimed novel by John Fante and starring Colin Farrell and Salma Hayek. Towne had found the novel while researching "Chinatown", looking for material that would honestly describe that particular era of Los Angeles. He became so entranced by the book that he arranged to meet with its author—himself a screenwriter—in person. "I was an unknown," Towne said. "I hadn't written anything of note." But Fante greeted the young fan with accusations like "What makes you think you're any kind of judge of my work?" "Ask the Dust" received mixed reviews and failed at the box office. The film was entered into the 28th Moscow International Film Festival.
Towne has framed several of his signature films as elaborate melodramas. He told "The New York Times" "I think melodrama is always a splendid occasion to entertain an audience and say things you want to say without rubbing their noses in it," he says. "With melodrama, as in dreams, you're always flirting with the disparity between appearance and reality, which is a great deal of fun. And that's also not unrelated to my perception of my life working in Hollywood, where you're always wondering, 'What does that guy really mean?'"
In 2006, Towne was the subject of artist Sarah Morris's film, "Robert Towne". Morris describes him as an “elliptical figure” whose career exemplifies a certain characteristic mode of working in the film industry, marked by collaboration, shared or changing roles. Morris's painting installation on the ceiling of the Lever House in Manhattan, commissioned by the Public Art Fund, was also titled "Robert Towne".
Two Jakes.
Robert Towne expressed his disappointment in "The Two Jakes" in many interviews. He told writer Alex Simon "In the interest of maintaining my friendships with Jack Nicholson and Robert Evans, I’d rather not go into it, but let’s just say "The Two Jakes" wasn’t a pleasant experience for any of us. But, we’re all still friends, and that’s what matters most."
In a November 5, 2007 interview with MTV, Jack Nicholson claimed that Towne had written the part of Gittes specifically for him. In the same interview, Nicholson also said that Towne had conceived "Chinatown" as a trilogy, with the third film set in 1968 and dealing in some way with Howard Hughes. However, Towne says he "does not know how that got started" and denies there was any trilogy planned.
Television.
Towne has also written for television, including an acclaimed episode of the 1962-1963 CBS anthology series "The Lloyd Bridges Show" entitled "My Daddy Can Beat Your Daddy," with starring roles for Jeff Bridges and Gary Lockwood. He joined the writing staff of the final season of "Mad Men" (credited as consulting producer).
On Screen.
On occasion, Towne has taken the role of performer, as in 1960's Roger Corman sci-fi film "Last Woman on Earth", which Towne also wrote. He also starred in the Corman film "Creature From the Haunted Sea". In 2008, Towne was the subject of the documentary short film "Robert Towne", by artist Sarah Morris.
Personal life.
Towne’s parentage was Romanian on his mother’s side, Russian on his father’s; the family was Jewish. He grew up in San Pedro, Los Angeles, the son of Helen and Lou Schwartz. His father ran a ladies clothing shop called the Towne Smart Shop, and changed the family name to Towne. Lou then moved into real estate and moved his family to the affluent Rolling Hills, a gated community in Palos Verdes, where Robert attended Chadwick School. He graduated from Pomona College in Claremont, California.
Robert has a brother Roger, who is six years younger. He is married to Luisa Gaule. His former father-in-law is late actor John Payne, star of the western series, "The Restless Gun". Towne's daughter (with actress Julie Payne) is Katharine Towne. He is a former father-in-law of Charlie Hunnam.
Filmography.
Unmade Projects.
Future projects.
In 2011, Towne was announced as writer-director of "The 39 Steps", a proposed remake of the 1935 film directed by Alfred Hitchcock. The British producer Graham King revealed that he had hired Towne to write a remake of "The Battle of Britain" in a December 2011 interview. 

</doc>
<doc id="68284" url="https://en.wikipedia.org/wiki?curid=68284" title="Chop suey">
Chop suey

Chop suey (; ) is a dish in American Chinese cuisine and other forms of overseas Chinese cuisine, consisting of meat (often chicken, fish, beef, prawns, or pork) and eggs, cooked quickly with vegetables such as bean sprouts, cabbage, and celery and bound in a starch-thickened sauce. It is typically served with rice but can become the Chinese-American form of chow mein with the addition of stir-fried noodles.
Chop suey has become a prominent part of American Chinese cuisine, Filipino cuisine, Canadian Chinese cuisine, German Chinese cuisine, Indian Chinese cuisine, and Polynesian cuisine. In Chinese Indonesian cuisine it is known as "cap cai" (雜菜, "mixed vegetables") and mainly consists of vegetables.
Origins.
Chop suey is widely believed to have been invented in America by Chinese Americans, but the anthropologist E.N. Anderson concludes that the dish is based on "tsap seui" (杂碎, “miscellaneous leftovers”), common in Taishan (Toisan), a county in Guangdong Province, the home of many early Chinese immigrants to the U.S. This "became the infamous ‘chop suey’ of third-string Chinese restaurants in the western world, but it began life as a good if humble dish among the specialist vegetable farmers of the area. At the end of the day, they would stir-fry the small shoots, thinnings, and unsold vegetables—up to ten species in a dish!" The Hong Kong doctor Li Shu-fan likewise reported that he knew it in Toisan in the 1890s.
The long list of colorful and conflicting stories about the origin of chop suey is, in the words of the food historian Alan Davidson, “a prime example of culinary mythology” and typical of popular foods.
One account claims that it was invented by Chinese American cooks working on the transcontinental railroad in the 19th century. Another tale is that it was created during Qing Dynasty premier Li Hongzhang's visit to the United States in 1896 by his chef, who tried to create a meal suitable for both Chinese and American palates. Another story is that Li wandered to a local Chinese restaurant after the hotel kitchen had closed, where the chef, embarrassed that he had nothing ready to offer, came up with the new dish using scraps of leftovers. Yet recent research by the scholar Renqui Yu led him to conclude that "no evidence can be found in available historical records to support the story that Li Hung Chang ate chop suey in the United States." Li brought three Chinese chefs with him, and would not have needed to eat in local restaurants or invent new dishes in any case. Yu speculates that shrewd Chinese American restaurant owners took advantage of the publicity surrounding his visit to promote chop suey as Li's favorite.
Yet another myth is that, in the 1860s, a Chinese restaurant cook in San Francisco was forced to serve something to drunken miners after hours, when he had no fresh food. To avoid a beating, the cook threw leftovers in a wok and served the miners who loved it and asked what dish is this—he replied Chopped Sui. There is no good evidence for any of these stories.
Chop suey appears in an 1884 article in the "Brooklyn Eagle", by Wong Chin Foo, "Chinese Cooking," which he says "may justly be called the "national dish of China"." An 1888 description states "A staple dish for the Chinese gourmand is chow chop svey , a mixture of chickens' livers and gizzards, fungi, bamboo buds, pigs' tripe, and bean sprouts stewed with spices." In 1898, it is described as "A Hash of Pork, with Celery, Onions, Bean Sprouts, etc."
During his travels in the United States, Liang Qichao, a Guangdong (Canton) native, wrote in 1903 that there existed in the United States a food item called "chop suey" which was popularly served by Chinese restaurateurs, but which local Chinese people did not eat.
In earlier periods of Chinese history, ""chop suey"" or ""shap sui"" in Cantonese, and ""za sui"", in Mandarin, has the different meaning of cooked animal offal or entrails. For example, in the classic novel "Journey to the West" (circa 1590), Sun Wukong tells a lion-monster in chapter 75: "When I passed through Guangzhou, I bought a pot for cooking "za sui" – so I'll savour your liver, entrails, and lungs." This may be the same as the ""Chop Suey Kiang"" found in 1898 New York. The term ""za sui"" (杂碎) is found in newer Chinese-English dictionaries with both meanings listed: cooked entrails, and "chop suey" in the Western sense.
Variations.
In Filipino cuisine, chop suey is composed of mixed vegetables like cauliflower, chayote, bell peppers and snow peas; and meat like pork, chicken, beef, chicken or pork liver, and cuttlefish balls.
Popular culture.
The idea of chop suey was featured as a theme in the musical "Flower Drum Song".
It is also the title of a song by the Armenian-American band "System of a Down".

</doc>
<doc id="68286" url="https://en.wikipedia.org/wiki?curid=68286" title="Viet Cong">
Viet Cong

The Việt Cộng (()) was the name given by Western sources to the National Liberation Front during the Vietnam War (1955-1975). The National Liberation Front was a political organization with its own army - People's Liberation Armed Forces of South Vietnam (PLAF) - in South Vietnam and Cambodia, that fought the United States and South Vietnamese governments, eventually emerging on the winning side. It had both guerrilla and regular army units, as well as a network of cadres who organized peasants in the territory it controlled. Many soldiers were recruited in South Vietnam, but others were attached to the People's Army of Vietnam (PAVN), the regular North Vietnamese army. During the war, communists and anti-war spokesmen insisted the Việt Cộng was an insurgency indigenous to the South, while the U.S. and South Vietnamese governments portrayed the group as a tool of Hanoi. Although the terminology distinguishes northerners from the southerners, communist forces were under a single command structure set up in 1958.
North Vietnam established the National Liberation Front on December 20, 1960 to foment insurgency in the South. Many of the Việt Cộng's core members were volunteer "regroupees", southern Viet Minh who had resettled in the North after the Geneva Accord (1954). Hanoi gave the regroupees military training and sent them back to the South along the Ho Chi Minh trail in the early 1960s. The NLF called for southern Vietnamese to "overthrow the camouflaged colonial regime of the American imperialists" and to make "efforts toward the peaceful unification". The People's Liberation Armed Forces of South Vietnam (PLAF)'s best-known action was the Tet Offensive, a massive assault on more than 100 South Vietnamese urban centers in 1968, including an attack on the U.S. embassy in Saigon. The offensive riveted the attention of the world's media for weeks, but also overextended the Việt Cộng. Later communist offensives were conducted predominantly by the North Vietnamese. The organisation was dissolved in 1976 when North and South Vietnam were officially unified under a communist government.
Names.
The term "Việt cộng" appeared in Saigon newspapers beginning in 1956. It is a contraction of "Việt Nam Cộng-sản" (Vietnamese communist), or alternatively "Việt gian cộng sản" ("Communist Traitor to Vietnam"). The earliest citation for "Việt Cộng" in English is from 1957. American soldiers referred to the Viet Cong as Victor Charlie or V-C. "Victor" and "Charlie" are both letters in the NATO phonetic alphabet. "Charlie" referred to communist forces in general, both Việt Cộng and North Vietnamese.
The official Vietnamese history gives the group's name as the Liberation Army of South Vietnam or the National Liberation Front for South Vietnam (NLFSV; "Mặt trận Dân tộc Giải phóng miền Nam Việt Nam"). Many writers shorten this to National Liberation Front (NLF). In 1969, the Viet Cong created the "Provisional Revolutionary Government of the Republic of South Vietnam" ("Chính Phủ Cách Mạng Lâm Thời Cộng Hòa Miền Nam Việt Nam"), abbreviated PRG. Although the NLF was not officially abolished until 1977, the Viet Cong no longer used the name after PRG was created. Members generally referred to the Viet Cong as "the Front" ("Mặt trận"). Today's Vietnamese media most frequently refers to the group as the "People's Liberation Armed Forces of South Vietnam (PLAF)" ("Quân Giải phóng Miền Nam Việt Nam").
History.
Origin.
By the terms of the Geneva Accord (1954), which ended the Indochina War, France and the Viet Minh agreed to a truce and to a separation of forces. The Viet Minh had become the government of Democratic Republic of Vietnam since the Vietnamese 1946 general election and military forces of communists regrouped there. Military forces of non-communists regrouped in South Vietnam, which became a separate state. The political forces was not compulsory to regroup. Elections on reunification were scheduled for July 1956. A divided Vietnam angered Vietnamese nationalists, but it made the country less of a threat to China. Democratic Republic of Vietnam in the past and Vietnam in the present do not recognise that Vietnam was divided into two countries. Chinese Premier Zhou Enlai negotiated the terms of the ceasefire with France and then imposed them on the Viet Minh.
About 90,000 Viet Minh were evacuated to the North while 5,000 to 10,000 cadre remained in the South, most of them with orders to refocus on political activity and agitation. The Saigon-Cholon Peace Committee, the first Việt Cộng front, was founded in 1954 to provide leadership for this group. Other front names used by the Việt Cộng in the 1950s implied that members were fighting for religious causes, for example, "Executive Committee of the Fatherland Front", which suggested affiliation with the Hòa Hảo sect, or "Vietnam-Cambodia Buddhist Association". Front groups were favored by the Việt Cộng to such an extent that its real leadership remained shadowy until long after the war was over, prompting the expression, "the faceless Vietcong".
Led by Ngô Đình Diệm, South Vietnam refused to sign the Geneva Accord. Arguing that a free election was impossible under the conditions that existed in communist-held territory, Diệm announced in July 1955 that the scheduled election on reunification would not be held. After subduing the Bình Xuyên organized crime gang in the Battle for Saigon in 1955, and the Hòa Hảo and other militant religious sects in early 1956, Diệm turned his attention to the Việt Cộng. Within a few months, the Việt Cộng had been driven into remote swamps. The success of this campaign inspired U.S. President Dwight Eisenhower to dub Diệm the "miracle man" when he visited the U.S. in May 1957. France withdrew its last soldiers from Vietnam in April 1956.
In March 1956, southern communist leader Lê Duẩn presented a plan to revive the insurgency entitled "The Road to the South" to the other members of the Politburo in Hanoi. He argued adamantly that war with the United States was necessary to achieve unification. But as China and the Soviets both opposed confrontation at this time, Lê Duẩn's plan was rejected and communists in the South were ordered to limit themselves to economic struggle. Leadership divided into a "North first", or pro-Beijing, faction led by Trường Chinh, and a "South first" faction led by Lê Duẩn.
As the Sino-Soviet split widened in the following months, Hanoi began to play the two communist giants off against each other. The North Vietnamese leadership approved tentative measures to revive the southern insurgency in December 1956. Lê Duẩn's blueprint for revolution in the South was approved in principle, but implementation was conditional on winning international support and on modernizing the army, which was expected to take at least until 1959. President Hồ Chí Minh stressed that violence was still a last resort. Nguyễn Hữu Xuyên was assigned military command in the South, replacing Lê Duẩn, who was appointed North Vietnam's acting party boss. This represented a loss of power for Hồ, who preferred the more moderate Võ Nguyên Giáp, who was defense minister.
An assassination campaign, referred to as "extermination of traitors" or "armed propaganda" in communist literature, began in April 1957. Tales of sensational murder and mayhem soon crowded the headlines. Seventeen civilians were killed by machine gun fire at a bar in Châu Đốc in July and in September a district chief was killed with his entire family on a main highway in broad daylight. In October 1957, a series of bombs exploded in Saigon and left 13 Americans wounded.
In a speech given on September 2, 1957, Hồ reiterated the "North first" line of economic struggle. The launch of Sputnik in October boosted Soviet confidence and led to a reassessment of policy regarding Indochina, long treated as a Chinese sphere of influence. In November, Hồ traveled to Moscow with Lê Duẩn and gained approval for a more militant line. In early 1958, Lê Duẩn met with the leaders of "Inter-zone V" (northern South Vietnam) and ordered the establishment of patrols and safe areas to provide logistical support for activity in the Mekong Delta and in urban areas. In June 1958, the Viet Cong created a command structure for the eastern Mekong Delta. French scholar Bernard Fall published an influential article in July 1958 which analyzed the pattern of rising violence and concluded that a new war had begun.
Launches "armed struggle".
The North Vietnamese Communist Party approved a "people's war" on the South at a session in January 1959 and this decision was confirmed by the Politburo in March. In May 1959, Group 559 was established to maintain and upgrade the Ho Chi Minh trail, at this time a six-month mountain trek through Laos. About 500 of the "regroupees" of 1954 were sent south on the trail during its first year of operation. The first arms delivery via the trail, a few dozen rifles, was completed in August 1959.
Two regional command centers were merged to create the Central Office for South Vietnam ("Trung ương Cục miền Nam"), a unified communist party headquarters for the South. COSVN was initially located in Tây Ninh Province near the Cambodian border. On July 8, the Viet Cong killed two U.S. military advisors at Biên Hòa, the first American dead of the Vietnam War. The "2d Liberation Battalion" ambushed two companies of South Vietnamese soldiers in September 1959, the first large unit military action of the war. This was considered the beginning of the "armed struggle" in communist accounts. A series of uprisings beginning in the Mekong Delta province of Bến Tre in January 1960 created "liberated zones", models of Viet Cong-style government. Propagandists celebrated their creation of battalions of "long-hair troops" (women). The fiery declarations of 1959 were followed by a lull while Hanoi focused on events in Laos (1960–61). Moscow favored reducing international tensions in 1960, as it was election year for the U.S. presidency. Despite this, 1960 was a year of unrest in South Vietnam, with pro-democracy demonstrations inspired by the South Korean student uprising that year and a failed military coup in November.
To counter the accusation that North Vietnam was violating the Geneva Accord, the independence of the Viet Cong was stressed in communist propaganda. The Viet Cong created the National Liberation Front of South Vietnam in December 1960 at Tân Lập village in Tây Ninh as a "united front", or political branch intended to encourage the participation of non-communists. The group's formation was announced by Radio Hanoi and its ten-point manifesto called for, "overthrow the disguised colonial regime of the imperialists and the dictatorial administration, and to form a national and democratic coalition administration." Thọ, a lawyer and the NLF's "neutralist" chairman, was an isolated figure among cadres and soldiers. South Vietnam's Law 10/59, approved in May 1959, authorized the death penalty for crimes "against the security of the state" and featured prominently in Viet Cong propaganda. Violence between the Viet Cong and government forces soon increased drastically from 180 clashes in January 1960 to 545 clashes in September.
By 1960, the Sino-Soviet split was a public rivalry, making China more supportive of Hanoi's war effort. For Chinese leader Mao Zedong, aid to North Vietnam was a way to enhance his "anti-imperialist" credentials for both domestic and international audiences. About 40,000 communist soldiers infiltrated the South in 1961–63. The Viet Cong grew rapidly; an estimated 300,000 members were enrolled in "liberation associations" (affiliated groups) by early 1962. The ratio of Viet Cong to government soldiers jumped from 1:10 in 1961 to 1:5 a year later.
The level of violence in the South jumped dramatically in the fall of 1961, from 50 guerrilla attacks in September to 150 in October. U.S President John F. Kennedy decided in November 1961 to substantially increase American military aid to South Vietnam. The arrived in Saigon with 35 helicopters in December 1961. By mid-1962, there were 12,000 U.S. military advisors in Vietnam. The "special war" and "strategic hamlets" policies allowed Saigon to push back in 1962, but in 1963 the Viet Cong regained the military initiative. The Viet Cong won its first military victory against South Vietnamese forces at Ấp Bắc in January 1963.
A landmark party meeting was held in December 1963, shortly after a military coup in Saigon in which Diệm was assassinated. North Vietnamese leaders debated the issue of "quick victory" vs "protracted war" (guerrilla warfare). After this meeting, the communist side geared up for a maximum military effort and PAVN troop strength increased from 174,000 at the end of 1963 to 300,000 in 1964. The Soviets cut aid in 1964 as an expression of annoyance with Hanoi's ties to China. Even as Hanoi embraced China's international line, it continued to follow the Soviet model of reliance on technical specialists and bureaucratic management, as opposed to mass mobilization. The winter of 1964–1965 was a high-water mark for the Viet Cong, with the Saigon government on the verge of collapse. Soviet aid soared following a visit to Hanoi by Soviet Premier Alexei Kosygin in February 1965. Hanoi was soon receiving up-to-date surface-to-air missiles. The U.S. would have 200,000 soldiers in South Vietnam by the end of the year. In January 1966, Australian troops uncovered a tunnel complex which had been used by COSVN. Six thousand documents were captured, revealing the inner workings of the Viet Cong. COSVN retreated to Mimot in Cambodia. As a result of an agreement with the Cambodian government made in 1966, weapons for the Viet Cong were shipped to the Cambodian port of Sihanoukville and then trucked to Viet Cong bases near the border along the "Sihanouk Trail", which replaced the Ho Chi Minh Trail.
Many People's Liberation Armed Forces of South Vietnam (PLAF) units operated at night, and employed terror as a standard tactic. Rice procured at gunpoint sustained the Viet Cong. Squads were assigned monthly assassination quotas. Government employees, especially village and district heads, were the most common targets. But there were a wide variety of targets, including clinics and medical personnel. Notable Viet Cong atrocities include the massacre of over 3,000 unarmed civilians at Huế, 48 killed in the bombing of My Canh floating restaurant in Saigon in June 1965 and a massacre of 252 Montagnards in the village of Đắk Sơn in December 1967 using flamethrowers.Jones, C. Don, "Massacre at Dak Son", United States Information Service, 1967
Tet Offensive.
Major reversals in 1966 and 1967, as well as the growing American presence in Vietnam, inspired Hanoi to consult its allies and reassess strategy in April 1967. While Beijing urged a fight to the finish, Moscow suggested a negotiated settlement. Convinced that 1968 could be the last chance for decisive victory, General Nguyễn Chí Thanh, suggested an all-out offensive against urban centers. He submitted a plan to Hanoi in May 1967. After Thanh's death in July, Giáp was assigned to implement this plan, now known as the Tet Offensive. The Parrot's Beak, an area in Cambodia only 30 miles from Saigon, was prepared as a base of operations. Funeral processions were used to smuggle weapons into Saigon. Viet Cong entered the cities concealed among civilians returning home for Tết. The U.S. and South Vietnamese expected that an announced seven-day truce would be observed during Vietnam's main holiday.
At this point, there were about 500,000 U.S. troops in Vietnam, as well as 900,000 allied forces. General William Westmoreland, the U.S. commander, received reports of massive troop movements and understood that an offensive was being planned, but his attention was focused on Khe Sanh, a remote U.S. base near the DMZ. In January and February 1968, some 80,000 Viet Cong struck more than 100 towns with orders to "crack the sky" and "shake the Earth." The offensive included a commando raid on the U.S. Embassy in Saigon and a massacre at Huế of about 3,500 residents.</ref> House-to-house fighting between Viet Cong and South Vietnamese Rangers left much of Cholon, a section of Saigon, in ruins. The Viet Cong used any available tactic to demoralize and intimidate the population, including the assassination of South Vietnamese commanders. A photo by Eddie Adams showing the summary execution of a Viet Cong in Saigon on February 1 became a symbol of the brutality of the war. In an influential broadcast on February 27, newsman Walter Cronkite stated that the war was a "stalemate" and could be ended only by negotiation.
The offensive was undertaken in the hope of triggering a general uprising, but urban Vietnamese did not respond as the Viet Cong anticipated. About 75,000 communist soldiers were killed or wounded, according to Trần Văn Trà, commander of the "B-2" district, which consisted of southern South Vietnam. "We did not base ourselves on scientific calculation or a careful weighing of all factors, but...on an illusion based on our subjective desires", Trà concluded. Earle G. Wheeler, chairman of the Joint Chiefs of Staff, estimated that Tet resulted in 40,000 communist dead (compared to about 10,600 U.S. and South Vietnamese dead). "It is a major irony of the Vietnam War that our propaganda transformed this debacle into a brilliant victory. The truth was that Tet cost us half our forces. Our losses were so immense that we were unable to replace them with new recruits", said PRG Justice Minister Trương Như Tảng. Tet had a profound psychological impact because South Vietnamese cities were otherwise safe areas during the war. U.S. President Lyndon Johnson and Westmoreland argued that panicky news coverage gave the public the unfair perception that America had been defeated.
Aside from some districts in the Mekong Delta, the Viet Cong failed to create a governing apparatus in South Vietnam following Tet, according to an assessment of captured documents by the U.S. CIA. The breakup of larger Viet Cong units increased the effectiveness of the CIA's Phoenix Program (1967–72), which targeted individual leaders, as well as the Chiêu Hồi Program, which encouraged defections. By the end of 1969, there was little communist-held territory, or "liberated zones", in South Vietnam, according to the official communist military history. There were no predominantly southern units left and 70 percent of communist troops in the South were northerners.
The Viet Cong created an urban front in 1968 called the Alliance of National, Democratic, and Peace Forces. The group's manifesto called for an independent, non-aligned South Vietnam and stated that "national reunification cannot be achieved overnight." In June 1969, the alliance merged with the NLF to form a "Provisional Revolutionary Government." (PRG)
Vietnamization.
The Tet Offensive increased public discontent with American participation in the Vietnam War and led the U.S. to gradually withdraw combat forces and to shift responsibility to the South Vietnamese, a process called Vietnamization. Pushed into Cambodia, the Viet Cong could no longer draw South Vietnamese recruits. In May 1968, Trường Chinh urged "protracted war" in a speech that was published prominently in the official media, so the fortunes of his "North first" fraction may have revived at this time. COSVN rejected this view as "lacking resolution and absolute determination." The Soviet invasion of Czechoslovakia in August 1968 led to intense Sino-Soviet tension and to the withdrawal of Chinese forces from North Vietnam. Beginning in February 1970, Lê Duẩn's prominence in the official media increased, suggesting that he was again top leader and had regained the upper hand in his longstanding rivalry with Trường Chinh. After the overthrow of Prince Sihanouk in March 1970, the Viet Cong faced a hostile Cambodian government which authorized a U.S. offensive against its bases in April. However, the capture of the Plain of Jars and other territory in Laos, as well as five provinces in northeastern Cambodia, allowed the North Vietnamese to reopen the Ho Chi Minh trail. Although 1970 was a much better year for the Viet Cong than 1969, it would never again be more than an adjunct to the PAVN. The 1972 Easter Offensive was a direct North Vietnamese attack across the DMZ between North and South. Despite the Paris Peace Accords, signed by all parties in January 1973, fighting continued. In March, Trà was recalled to Hanoi for a series of meetings to hammer out a plan for a massive offense against Saigon.
Fall of Saigon.
In response to the anti-war movement, the U.S. Congress passed the Case–Church Amendment to prohibit further U.S. military intervention in Vietnam in June 1973 and reduced aid to South Vietnam in August 1974. With U.S. bombing ended, communist logistical preparations could be accelerated. An oil pipeline was built from North Vietnam to Viet Cong headquarters in Lộc Ninh, about 75 miles northwest of Saigon. (COSVN was moved back to South Vietnam following the Easter Offensive.) The Ho Chi Minh Trail, once a treacherous mountain trek, was upgraded into a drivable road. Between the beginning of 1974 and April 1975, the communists delivered nearly 365,000 tons of war material to battlefields, 2.6 times the total for the previous 13 years.
The success of the 1973–74 dry season offensive convinced Hanoi to accelerate its timetable. When there was no U.S. response to a successful communist attack on Phước Bình in January 1975, South Vietnamese morale collapsed. The next major battle, at Buôn Ma Thuột in March, was a communist walkover. After the Fall of Saigon on April 30, 1975, the PRG moved into government offices there. At the victory parade, Tạng noticed that the units formerly dominated by southerners were missing, replaced by northerners years earlier. The bureaucracy of the Republic of Vietnam was uprooted and authority over the South was assigned to the PAVN. Perhaps 1 million people considered tainted by association with the former South Vietnamese government were sent to reeducation camps, despite the protests of the non-communist PRG members including Tạng. Without consulting the PRG, North Vietnamese leaders decided to rapidly dissolve the PRG at a party meeting in August 1975. North and South were merged as the Socialist Republic of Vietnam in July 1976 and the PRG was dissolved. The NLF was merged with the Vietnamese Fatherland Front in February 1977.
Relationship with Hanoi.
Spokesmen against American involvement in Vietnam said that the Viet Cong was a nationalist insurgency indigenous to the South. They claimed that Viet Cong was composed of several parties: People's Revolutionary Party, the Democratic Party and the Radical Socialist Party. NLF Chairman Nguyễn Hữu Thọ was not a communist.
Anti-communists counter that the Viet Cong was merely a front for Hanoi. They say some statements issued by communist leaders in the 1980s and 1990s suggest that southern communist forces were influenced by Hanoi. According to the memoirs of Trần Văn Trà, the Viet Cong's top commander and PRG defense minister, he followed orders issued by the "Military Commission of the Party Central Committee" in Hanoi, which in turn implemented resolutions of the Politburo. Trà himself was deputy chief of staff for the PAVN before being assigned to the South. The official Vietnamese history of the war states that, "The Liberation Army of South Vietnam Cong is a part of the People's Army of Vietnam".

</doc>
<doc id="68292" url="https://en.wikipedia.org/wiki?curid=68292" title="My Lai Massacre">
My Lai Massacre

The Mỹ Lai Massacre ( , ; , , or ) was the Vietnam War mass killing of between 347 and 504 unarmed civilians in South Vietnam on March 16, 1968. It was committed by U.S. Army soldiers from the Company C of the 1st Battalion, 20th Infantry Regiment, 11th Brigade of the 23rd (Americal) Infantry Division. Victims included men, women, children, and infants. Some of the women were gang-raped and their bodies mutilated. Twenty-six soldiers were charged with criminal offenses, but only Lieutenant William Calley Jr., a platoon leader in C Company, was convicted. Found guilty of killing 22 villagers, he was originally given a life sentence, but served only three and a half years under house arrest.
The massacre, which was later called "the most shocking episode of the Vietnam War", took place in two hamlets of Sơn Mỹ village in Quảng Ngãi Province. These hamlets were marked on the U.S. Army topographic maps as My Lai and My Khe. The U.S. military codeword for the alleged Viet Cong stronghold in that area was "Pinkville", and the carnage was initially referred to as the "Pinkville Massacre". Later, when the U.S. Army started its investigation, the media changed it to the "Massacre at Songmy". Currently, the event is referred to as the "My Lai Massacre" in the United States and called the "Son My Massacre" in Vietnam.
The incident prompted global outrage when it became public knowledge in November 1969. The My Lai massacre increased to some extent domestic opposition to the U.S. involvement in the Vietnam War when the scope of killing and cover-up attempts were exposed. Initially, three U.S. servicemen who had tried to halt the massacre and rescue the hiding civilians were shunned, and even denounced as traitors by several U.S. Congressmen, including Mendel Rivers, Chairman of the House Armed Services Committee. Only after thirty years were they recognized and decorated, one posthumously, by the U.S. Army for shielding non-combatants from harm in a war zone.
Incident.
Charlie Company of the 1st Battalion, 20th Infantry Regiment, 11th Brigade, 23rd Infantry Division, arrived in South Vietnam in December 1967. Though their first three months in Vietnam passed without any direct enemy contact, by mid-March the company had suffered 28 casualties involving mines or booby-traps.
During the Tet Offensive of January 1968, attacks were carried out in Quảng Ngãi by the 48th Local Force Battalion of the National Liberation Front (NLF), commonly referred to by the U.S. Army as the Viet Cong or "Victor Charlie" from the initials "VC" corresponding with the NATO phonetic alphabet. U.S. military intelligence assumed that the 48th NLF Battalion, having retreated and dispersed, was taking refuge in the village of Sơn Mỹ, in Quảng Ngãi Province. A number of specific hamlets within that village—designated Mỹ Lai (1) through My Lai (6) — were suspected of harboring the 48th.
In February and March 1968, the U.S. Military Assistance Command, Vietnam was aggressively trying to regain the strategic initiative in South Vietnam after the Tet Offensive, and the search-and-destroy operation against the 48th Local Force Battalion of Viet Cong thought to be located in Son My became a small part of America's grand strategy. Task Force (TF) Barker, a battalion-sized ad hoc unit of the 11th Brigade, was to be employed for the job. It was formed in January 1968, composed of three rifle companies of the 11th Brigade, including Company C from the 20th Infantry, led by Lieutenant Colonel (LTC) Frank A. Barker. Son My village was included in the area of operations of TF Barker codenamed Muscatine AO. (Muscatine was the name of the home county of the American Division commander Major General (MG) Samuel W. Koster.) In February 1968, TF Barker had already tried to secure Son My, with limited success. After that, the village area began to be called "Pinkville" by TF Barker troops.
On March 16–18, TF Barker planned to engage and destroy the remnants of the 48th Viet Cong Local Force Battalion, allegedly hiding in the Son My village area. Before engagement, Colonel (COL) Oran K. Henderson, the 11th Brigade commander, urged his officers to "go in there aggressively, close with the enemy and wipe them out for good". In turn, LTC Barker reportedly ordered the 1st Battalion commanders to burn the houses, kill the livestock, destroy food supplies, and destroy the wells.
On the eve of the attack, at the Charlie Company briefing, Captain (CPT) Ernest Medina told his men that nearly all the civilian residents of the hamlets in Sơn Mỹ village would have left for the market by 07:00, and that any who remained would be NLF or NLF sympathizers. He was asked whether the order included the killing of women and children. Those present later gave differing accounts of Medina's response. Some, including platoon leaders, testified that the orders as they understood them were to kill all guerrilla and North Vietnamese combatants and "suspects" (including women and children, as well as all animals), to burn the village, and pollute the wells. He was also quoted as saying, "They're all VC, now go and get them", and was heard to reply to the question "Who is my enemy?" by saying, "Anybody that was running from us, hiding from us, or appeared to be the enemy. If a man was running, shoot him, sometimes even if a woman with a rifle was running, shoot her." At Calley's trial, one defense witness testified that he remembered Medina instructing to destroy everything in the village that was "walking, crawling or growing".
Charlie Company was to enter the village of Son My spearheaded by its 1st Platoon, engage the enemy, and flush it out. The other two companies from TF Barker were ordered to secure the area and provide support if needed. The area was designated a free fire zone, where American forces were allowed to deploy artillery and air strikes in populated areas. In 1966, Quảng Ngãi Province witnessed two massacres at the hands of South Korean troops, the Bình Hòa massacre and the Diên Niên - Phước Bình massacre. In February 1968, in neighboring Quảng Nam province, during a similar counterinsurgency search-and-destroy operation, the Phong Nhị and Phong Nhất massacre and the Hà My massacre were committed by South Korean Marines. As for the U.S. military, seven months prior to the My Lai Massacre, on Robert McNamara's order, the Inspector General of the U.S. Defense Department investigated press coverage of alleged atrocities committed in South Vietnam. In August 1967, the 200-page report "Alleged Atrocities by U.S. Military Forces in South Vietnam" was completed. It concluded that many American troops did not fully understand the Geneva Conventions. No action was taken, however.
Killings.
On the Saturday morning of March 16 at 07:30, around 100 soldiers from the Charlie Company led by CPT Ernest Medina, following a short artillery and helicopter gunship barrage, landed in helicopters on the spreading coastal village of Sơn Mỹ, a patchwork of settlements, rice paddies, irrigation ditches, dikes, and dirt roads, connecting an assortment of hamlets and sub-hamlets. The largest among them were the hamlets My Lai, Co Luy, My Khe, and Tu Cung. Though the GIs were not fired upon after landing, they still suspected there were Vietcong guerrillas hiding underground or in the huts. Confirming their suspicions, the gunships engaged several armed enemy in a vicinity of My Lai; later, one weapon (a carbine) was retrieved from the site.
According to the operational plan, the 1st Platoon led by Second Lieutenant (2LT) William Calley and the 2nd Platoon led by 2LT Stephen Brooks entered the hamlet of Tu Cung in line formation at 08:00, while the 3rd Platoon commanded by 2LT Jeffrey U. Lacross and Captain Medina's command post remained outside. On approach, both platoons fired at people they saw in the rice fields and in the brush.
The villagers, who were getting ready for a market day, at first did not panic or run away, and they were herded into the hamlet's commons. Harry Stanley, a machine gunner from the Charlie Company, said during the U.S. Army Criminal Investigation Division's (CID) inquiry that the killings started without warning. He first observed a member of the 1st Platoon strike a Vietnamese man with a bayonet. Then, the same trooper pushed another villager into a well and threw a grenade in the well. Further, he saw fifteen or twenty people, mainly women and children, kneeling around a temple with burning incense. They were praying and crying. They were all killed by shots in the head.
Most of the killings occurred in the southern part of Tu Cung, a sub-hamlet of Xom Lang, which was a home to 700 residents. Xom Lang was erroneously marked on the U.S. military operational maps of Quảng Ngãi Province as My Lai. 
A large group of approximately 70–80 villagers was rounded up by the 1st Platoon in Xom Lang, and then led to an irrigation ditch to the east of the settlement. All detainees were pushed into the ditch and then killed after repeated orders issued by Lieutenant Calley, who was also shooting. Paul Meadlo, a Private First Class (PFC), testified that he expended several M16 magazines. He recollected that women were allegedly saying "No VC" and were trying to shield their children. He remembered that he was shooting into women with babies in their hands since he was convinced at that time that they were all booby-trapped with grenades and were poised to attack. On another occasion during the security sweep of My Lai, Meadlo again fired into civilians side-by-side with Lieutenant Calley.
PFC Dennis Konti, a witness for the prosecution, told about one especially gruesome episode during the shooting, "A lot of women had thrown themselves on top of the children to protect them, and the children were alive at first. Then, the children who were old enough to walk got up and Calley began to shoot the children". Other 1st Platoon members testified that many of the deaths of individual Vietnamese men, women and children occurred inside My Lai during the security sweep. Livestock was shot as well.
When PFC Michael Bernhardt entered the subhamlet of Xom Lang, the massacre was underway:
One group of 20-50 villagers was walked to the south of Xom Lang and killed on a dirt road. According to Ronald Haeberle's eyewitness account of the massacre, in one instance, 
Lieutenant Calley testified that he heard the shooting and arrived on the scene. He observed his men firing into a ditch with Vietnamese people inside and he then started shooting, with an M16, from a distance of 5 feet. Then, a helicopter landed on the other side of the ditch and a pilot asked Calley if he could provide any medical assistance to the wounded civilians in My Lai; Calley admitted replying that a hand grenade was the only available means that he had for their evacuation. After that, around 11:00, Captain Medina radioed to cease fire and the 1st Platoon took a lunch break.
Members of the 2nd platoon killed at least 60–70 Vietnamese, as they swept through the northern half of Mỹ Lai and through Binh Tay, a small sub-hamlet about north of Mỹ Lai. The platoon suffered one dead and seven wounded by mines and booby traps. After the initial sweeps by the 1st and 2nd platoons, the 3rd Platoon was dispatched to deal with any "remaining resistance". The 3rd platoon, which stayed in reserve, also reportedly rounded up and killed a group of seven to twelve women and children.
Since Charlie Company had not met any enemy opposition at My Lai and did not request back-up, Bravo Company of the 4th Battalion, 3rd Infantry Regiment of TF Barker was transported by air between 08:15 and 08:30 away. It attacked the subhamlet My Hoi of the Co Luy hamlet, which was mapped by the Army as My Khe. During this operation, between 60 to 155 people, including women and children, were killed.
Over the next day, both companies were involved in additional burning and destruction of dwellings, as well as mistreatment of Vietnamese detainees. While some soldiers of Charlie Company did not participate in the crimes, they neither openly protested nor complained later to their superiors.
William Thomas Allison, a professor of Military History at Georgia Southern University, wrote, "By midmorning, members of Charlie Company had killed hundreds of civilians and raped or assaulted countless women and young girls. They encountered no enemy fire and found no weapons in My Lai itself".
Helicopter crew intervention.
Warrant Officer One (WO1) Hugh Thompson, Jr., a helicopter pilot from Company B (Aero-Scouts), 123rd Aviation Battalion, Americal Division, saw dead and wounded civilians as he was flying over the village of Son My providing close-air support for ground forces. The crew made several attempts to radio for help for the wounded. They landed their helicopter by a ditch, which they noted was full of bodies and in which there was movement. Thompson asked a sergeant he encountered there (David Mitchell of the 1st Platoon) if he could help get the people out of the ditch, and the sergeant replied that he would "help them out of their misery". Thompson, shocked and confused, then spoke with 2LT Calley, who claimed to be "just following orders". As the helicopter took off, Thompson saw Mitchell firing into the ditch.
Thompson and his crew witnessed an unarmed woman being kicked and shot at point-blank range by Captain Medina, who later claimed that he thought she had a hand grenade. Thompson then saw a group of civilians (again consisting of children, women, and old men) at a bunker being approached by ground personnel. Thompson landed and told his crew that if the soldiers shot at the Vietnamese while he was trying to get them out of the bunker that they were to open fire on these soldiers. Thompson later testified that he spoke with a lieutenant (identified as Stephen Brooks of the 2nd Platoon) and told him there were women and children in the bunker, and asked if the lieutenant would help get them out. According to Thompson, "he lieutenant said the only way to get them out was with a hand grenade". Thompson testified that he then told Brooks to "just hold your men right where they are, and I'll get the kids out". He found 12–16 people in the bunker, coaxed them out and led them to the helicopter, standing with them while they were flown out in two groups.
Returning to Mỹ Lai, Thompson and other air crew members noticed several large groups of bodies. Spotting some survivors in the ditch, Thompson landed again. A crew member entered the ditch and returned with a bloodied, but apparently unharmed child who was flown to safety. The child was thought to be a boy, but later turned out to be a four-year-old girl. Thompson then reported what he had seen to his company commander, Major (MAJ) Frederic W. Watke, using terms such as "murder" and "needless and unnecessary killings". Thompson's statements were confirmed by other helicopter pilots and air crew members.
For the actions at My Lai, Thompson was awarded the Distinguished Flying Cross (DFC) and his crew members Glenn Andreotta and Lawrence Colburn were awarded Bronze Star medals. Glenn Urban Andreotta received his medal posthumously, as he was killed in Vietnam on April 8, 1968. As the DFC citation included a fabricated account of rescuing a young girl from My Lai from "intense crossfire" Thompson threw his medal away. He later received a Purple Heart for other services in Vietnam.
In March 1998, the helicopter crew's medals were replaced by the Soldier's Medal, "the highest the U.S. Army can award for bravery not involving direct conflict with the enemy". The medal citations state they were "for heroism above and beyond the call of duty while saving the lives of at least 10 Vietnamese civilians during the unlawful massacre of non-combatants by American forces at My Lai". Thompson initially refused the medal when the US Army wanted to award it quietly. He demanded it be done publicly and that his crew also be honored in the same way. The veterans also made contact with the survivors of Mỹ Lai.
Aftermath.
After returning to base at about 11:00, Thompson reported the massacre to his superiors. His allegations of civilian killings quickly reached Lieutenant Colonel Frank Barker, the operation's overall commander. Barker radioed his executive officer to find out from Captain Medina what was happening on the ground. Medina then gave the cease-fire order to Charlie Company to "knock off the killing".
Since Thompson made an official report of the civilian killings, he was interviewed by Colonel Oran Henderson, the commander of the 11th Infantry Brigade (the parent organization of the 20th Infantry). Concerned, senior Americal officers canceled similar planned operations by Task Force Barker against other villages (My Lai 5, My Lai 1, etc.) in Quảng Ngãi Province.
Despite Thompson's revealing information, Colonel Henderson issued a Letter of Commendation to Captain Medina on March 27, 1968. The next day, March 28, 1968, the commander of Task Force Barker submitted a combat action report for the March 16 operation in which he stated that the operation in My Lai was a success with 128 Viet Cong partisans killed. The Americal Division commander, Major General S. W. Koster, sent a congratulatory message to Company C. General William C. Westmoreland, the head of Military Assistance Command, Vietnam (MACV), also congratulated Company C, 1st Battalion, 20th Infantry for "outstanding action", saying that they had "dealt enemy [a heavy blow". Later, he reversed himself by writing in his memoir that it was "the conscious massacre of defenseless babies, children, mothers, and old men in a kind of diabolical slow-motion nightmare that went on for the better part of a day, with a cold-blooded break for lunch".
Owing to the chaotic circumstances of the war and the U.S. Army's decision not to undertake a definitive body count of noncombatants in Vietnam, the number of civilians killed at Mỹ Lai cannot be stated with certainty. Estimates vary from source to source, with 347 and 504 being the most commonly cited figures. The memorial at the site of the massacre lists 504 names, with ages ranging from one to 82. A later investigation by the U.S. Army arrived at a lower figure of 347 deaths, the official U.S. estimate. The official estimate by the local government remains 504.
Reporting, cover-up and investigation.
First reports claimed that "128 Viet Cong and 22 civilians" were killed in the village during a "fierce fire fight". General William Westmoreland, the Military Assistance Command, Vietnam commander, congratulated the unit on the "outstanding job". As relayed at the time by "Stars and Stripes" magazine, "U.S. infantrymen had killed 128 Communists in a bloody day-long battle." On March 16, 1968, in the official press briefing known as the "Five O'Clock Follies", a mimeographed release included this passage: "In an action today, Americal Division forces killed 128 enemy near Quang Ngai City. Helicopter gunships and artillery missions supported the ground elements throughout the day."
Initial investigations of the Mỹ Lai operation were undertaken by the 11th Light Infantry Brigade's commanding officer, Colonel Henderson, under orders from the Americal Division's executive officer, Brigadier General George H. Young. Henderson interviewed several soldiers involved in the incident, then issued a written report in late-April claiming that some 20 civilians were inadvertently killed during the operation. The Army at this time was still describing the event as a military victory that had resulted in the deaths of 128 enemy combatants.
Six months later, Tom Glen, a 21-year-old soldier of the 11th Light Infantry Brigade, wrote a letter to General Creighton Abrams, the new overall commander of U.S. forces in Vietnam. He described an ongoing and routine brutality against Vietnamese civilians on the part of American forces in Vietnam that he personally witnessed and then concluded, 
It would indeed be terrible to find it necessary to believe that an American soldier that harbors such racial intolerance and disregard for justice and human feeling is a prototype of all American national character; yet the frequency of such soldiers lends credulity to such beliefs. ... What has been outlined here I have seen not only in my own unit, but also in others we have worked with, and I fear it is universal. If this is indeed the case, it is a problem which cannot be overlooked, but can through a more firm implementation of the codes of MACV (Military Assistance Command Vietnam) and the Geneva Conventions, perhaps be eradicated.
Colin Powell, then a 31-year-old Army major, was charged with investigating the letter, which did not specifically refer to Mỹ Lai, as Glen had limited knowledge of the events there. In his report, Powell wrote, "In direct refutation of this portrayal is the fact that relations between Americal Division soldiers and the Vietnamese people are excellent." Powell's handling of the assignment was later characterized by some observers as "whitewashing" the atrocities of Mỹ Lai. In May 2004, Powell, then United States Secretary of State, told CNN's Larry King, "I mean, I was in a unit that was responsible for My Lai. I got there after My Lai happened. So, in war, these sorts of horrible things happen every now and again, but they are still to be deplored."
Independently of Glen, Specialist 5 Ronald L. Ridenhour, a former door gunner from the Aviation Section, Headquarters Company of the 11th Infantry Brigade, sent a letter in March 1969 to thirty members of Congress imploring them to investigate the circumstances surrounding the "Pinkville" incident. He and his pilot, Warrant Officer Gilbert Honda, flew over My Lai several days after the operation and observed a scene of complete destruction. At one point, they hovered over a dead Vietnamese woman with a patch of the 11th Brigade on her body. Ridenhour had learned about the events at Mỹ Lai secondhand from talking to members of Charlie Company over a period of months beginning in April 1968. He became convinced that something "rather dark and bloody did indeed occur" at Mỹ Lai, and was so disturbed by the tales he heard that within three months of being discharged from the Army he penned his concerns to Congress. He included the name of Michael Bernhardt, an eyewitness who agreed to testify, in the letter.
Most recipients of Ridenhour's letter ignored it, with the exception of Congressman Mo Udall and Senators Barry Goldwater and Edward Brooke. Udall urged the House Armed Services Committee to call on Pentagon officials to conduct an investigation.
Independent investigative journalist Seymour Hersh, after extensive interviews with Calley, broke the Mỹ Lai story on November 12, 1969, on the Associated Press wire service; on November 20, "Time", "Life" and "Newsweek" magazines all covered the story, and CBS televised an interview with Paul Meadlo, a soldier in Calley's unit during the massacre. "The Plain Dealer" (Cleveland, Ohio) published explicit photographs of dead villagers killed at Mỹ Lai.
In November 1969, Lieutenant General William R. Peers was appointed by the Secretary of the Army and the Army Chief of Staffs to conduct a thorough review of the My Lai incident, March 16–19, 1968, and its investigation by the Army. Peers's final report, presented to higher-ups on March 17, 1970, was highly critical of top officers at brigade and divisional levels for participating in the cover-up, and the Charlie Company officers for their actions at Mỹ Lai. According to Peers' findings:
1st Battalion members had killed at least 175–200 Vietnamese men, women, and children. The evidence indicates that only 3 or 4 were confirmed as Viet Cong although there were undoubtedly several unarmed VC (men, women, and children) among them and many more active supporters and sympathizers. One man from the company was reported as wounded from the accidental discharge of his weapon. ... a tragedy of major proportions had occurred at Son My.
Critics of the Peers Report pointed out that it sought to place the real blame on four officers who were already dead, foremost among them the commander of Task Force Barker, Lieutenant Colonel Frank Barker, who was killed in a mid-air collision on June 13, 1968. Also, the Peers Report avoided drawing any conclusions or recommendations regarding the further examination of the treatment of civilians in a war zone. In 1967, an American journalist, Jonathan Schell, wrote that in the Vietnamese province of Quang Ngai, where the My Lai massacre occurred, up to 70% of all villages were destroyed by the air strikes and artillery bombardments, including the use of napalm; 40% percent of the population were refugees, and the overall civilian casualties were close to 50,000 a year. Regarding the massacre at My Lai, he stated, "There can be no doubt that such an atrocity was possible only because a number of other methods of killing civilians and destroying their villages had come to be the rule, and not the exception, in our conduct of the war". 
In May 1970, a sergeant who participated in Operation Speedy Express wrote a confidential letter to then Army Chief of Staff Westmoreland describing civilian killings he said were on the scale of the massacre occurring as "a My Lai each month for over a year" during 1968–1969. Two other letters to this effect from enlisted soldiers to military leaders in 1971, all signed "Concerned Sergeant", were uncovered within declassified National Archive documents. The letters describe common occurrences of civilian killings during population pacification operations. Army policy also stressed very high body counts and this resulted in dead civilians being marked down as combatants. Alluding to indiscriminate killings described as unavoidable, the commander of the 9th Division, then Major General Julian Ewell, in September 1969, submitted a confidential report to Westmoreland and other generals describing the countryside in some areas of Vietnam as resembling the battlefields of Verdun.
In July 1969, the Office of Provost Marshal General of the Army began to examine the evidence collected by the General Peers inquiry regarding possible criminal charges. Eventually, Calley was charged with several counts of premeditated murder in September 1969, and 25 other officers and enlisted men were later charged with related crimes.
Courts Martial.
On November 17, 1970, a court-martial in the United States charged 14 officers, including Major General Samuel W. Koster, the Americal Division's commanding officer, with suppressing information related to the incident. Most of the charges were later dropped. Brigade commander Colonel Henderson was the only high ranking commanding officer who stood trial on charges relating to the cover-up of the My Lai massacre; he was acquitted on December 17, 1971.
During the four-month-long trial, Lieutenant Calley consistently claimed that he was following orders from his commanding officer, Captain Medina. Despite that, he was convicted and sentenced to life in prison on March 29, 1971, after being found guilty of premeditated murder of not fewer than twenty people. Two days later, President Richard Nixon made the controversial decision to have Calley released from armed custody at Fort Benning, Georgia, and put under house arrest pending appeal of his sentence. Calley's conviction was upheld by the Army Court of Military Review in 1973 and by the U.S. Court of Military Appeals in 1974. In August 1971, Calley's sentence was reduced by the Convening Authority from life to twenty years. Calley would eventually serve three and one-half years under house arrest at Fort Benning including three months in a disciplinary barracks in Fort Leavenworth, Kansas. In September 1974, he was paroled by the Secretary of the Army Howard Callaway.
In a separate trial, Captain Medina denied giving the orders that led to the massacre, and was acquitted of all charges, effectively negating the prosecution's theory of "command responsibility", now referred to as the "Medina standard". Several months after his acquittal, however, Medina admitted that he had suppressed evidence and had lied to Colonel Henderson about the number of civilian deaths. Captain Kotouc, an intelligence officer from the 11th Brigade, was also court-martialed and found not guilty. Major General Koster was demoted to brigadier general and lost his position as the Superintendent of West Point. His deputy, Brigadier General Young, received a letter of censure. Both were stripped of Distinguished Service Medals which had been awarded for service in Vietnam.
Most of the enlisted men who were involved in the events at My Lai had already left military service. In the end, of the 26 men initially charged, Lieutenant Calley was the only one convicted.
Some have argued that the outcome of the Mỹ Lai courts-martial failed to uphold the laws of war established in the Nuremberg and Tokyo War Crimes Tribunals. For example, Telford Taylor, senior American prosecutor at Nuremberg, wrote that legal principles established at the war crimes trials could have been used to prosecute senior American military commanders for failing to prevent atrocities such as the one at My Lai. The U.S. Secretary of the Army Howard Callaway was quoted in "The New York Times" as stating that Calley's sentence was reduced because Calley honestly believed that what he did was a part of his orders—a rationale that contradicts the standards set at Nuremberg and Tokyo, where following orders was not a defense for committing war crimes. On the whole, other than the My Lai courts-martial, there were thirty six military trials held by the U.S. Army from January 1965 to August 1973 for crimes against civilians in Vietnam.
Survivors.
In early 1972, the camp at Mỹ Lai (2) where the survivors of the Mỹ Lai massacre had been relocated, was largely destroyed by Army of the Republic of Vietnam (South Vietnam) artillery and aerial bombardment, and remaining eyewitnesses were dispersed. The destruction was officially attributed to "Viet Cong terrorists". The truth was revealed by Quaker service workers in the area through testimony in May 1972 by Martin Teitel at hearings before the "Congressional Subcommittee to Investigate Problems Connected with Refugees and Escapees" in South Vietnam. In June 1972, Teitel's account was published in "The New York Times".
Many American soldiers who had been in My Lai during the massacre accepted personal responsibility for the loss of civilian lives. Some of them expressed regrets without acknowledging any personal guilt, as, for example, Ernest L. Medina, who said, "I have regrets for it, but I have no guilt over it because I didn't cause it. That's not what the military, particularly the United States Army, is trained for."
Lawrence La Croix, a squad leader in Charlie Company in My Lai, stated in 2010: “A lot of people talk about My Lai, and they say, ‘Well, you know, yeah, but you can’t follow an illegal order.’ Trust me. There is no such thing. Not in the military. If I go into a combat situation and I tell them, ‘No, I’m not going. I’m not going to do that. I’m not going to follow that order,’ well, they’d put me up against the wall and shoot me."
On March 16, 1998, a gathering of local people and former American and Vietnamese soldiers stood together at the place of the My Lai massacre in Vietnam to commemorate its 30th anniversary. American veterans Hugh Thompson and Lawrence Colburn, who were shielding civilians during the massacre, addressed the crowd. Among the listeners was Phan Thi Nhanh, a 14-year-old girl at the time of the massacre. She was saved by Thompson and vividly remembered that tragic day, "We don't say we forget. We just try not to think about the past, but in our hearts we keep a place to think about that". Colburn challenged Lieutenant Calley, "...to face the women we faced today who asked the questions they asked, and look at the tears in their eyes and tell them why it happened". No American diplomats nor any other officials attended the meeting.
More than a thousand people turned out March 16, 2008, forty years after the massacre, to remember the victims of one of the most notorious chapters of the Vietnam War. The Son My Memorial drew survivors of the massacre, the families of the victims and returning U.S. war veterans alike. One survivor, who was an 8-year girl on March 16, 1968, said, "Everyone in my family was killed in the My Lai massacre — my mother, my father, my brother and three sisters. They threw me into a ditch full of dead bodies. I was covered with blood and brains". The U.S. was unofficially represented by a volunteer group from Wisconsin called Madison Quakers, who in 10 years built three schools in My Lai and planted a peace garden.
On August 19, 2009, Calley made his first public apology for the massacre in a speech to the Kiwanis club of Greater Columbus, Georgia:
There is not a day that goes by that I do not feel remorse for what happened that day in My Lai", he told members of the club. "I feel remorse for the Vietnamese who were killed, for their families, for the American soldiers involved and their families. I am very sorry...If you are asking why I did not stand up to them when I was given the orders, I will have to say that I was a 2nd lieutenant getting orders from my commander and I followed them—foolishly, I guess.
Duc Tran Van, who was seven years old at the time of My Lai massacre and now resides in Remscheid, Germany, called the apology "terse". He wrote a public letter to Calley describing the plight of his and many other families to remind him that time did not ease the pain, and that grief and sorrow over lost lives will forever stay in My Lai.
Participants.
Commanders.
Altogether, 14 officers directly and indirectly involved with the operation, including two generals, were investigated in connection with the My Lai massacre, for except LTC Frank A. Barker, CPT Earl Michaels, and 2LT Stephen Brooks, who died before the beginning of the investigation.
1st Platoon, Charlie Company 1st Battalion 20th Infantry.
Before being shipped to South Vietnam, all of Charlie Company's soldiers went through an advanced infantry training and basic unit training at Pohakuloa Training Area in Hawaii. At Schofield Barracks they were taught how to treat POWs and how to distinguish Vietcong guerrillas from civilians by a Judge Advocate.
Media coverage.
News press.
A photographer and a reporter from the 11th Brigade Information Office were attached to the Task Force Barker and landed with Charlie Company in Son My on March 16, 1968. However, the "Americal News Sheet" published on March 17, 1968, as well as the "Trident", 11th Infantry Brigade newsletter from March 22, 1968, did not mention the death of noncombatants in great numbers in My Lai. The "Stars and Stripes" published a laudatory piece, "U.S. troops Surrounds Red, Kill 128" on March 18. On April 12, 1968, the "Trident" wrote that, "The most punishing operations undertaken by the brigade in Operation Muscatine's area involved three separate raids into the village and vicinity of My Lai, which cost the VC 276 killed". On April 4, 1968, the information office of the 11th Brigade issued a press-release, "Recent Operations in Pinkville," without any information about mass casualties among civilians. Subsequent criminal investigation uncovered that, "Both individuals failed to report what they had seen, the reporter wrote a false and misleading account of the operation, and the photographer withheld and suppressed from proper authorities the photographic evidence of atrocities he had obtained."
The first mentions of the My Lai massacre appeared in the American media after Fort Benning's vague press release concerning the charges pressed against Lieutenant Calley, which was distributed on September 5, 1969. Consequently, NBC aired on September 10, 1969 a segment in the "Huntley-Brinkley Report" which mentioned the murder of a number of civilians in South Vietnam. Following that, emboldened Ronald Ridenhour decided to disobey the Army's order to withhold the information from the media. He approached reporter Ben Cole of the "Phoenix Republic", who chose not to handle the scoop. Charles Black from the "Columbus Enquirer" uncovered the story on his own but also decided to put it on hold. Two major national news press outlets—"The New York Times" and "The Washington Post", received some tips with partial information but did not act on them.
A phone call on October 22, 1969, answered by freelance investigative journalist, Seymour Hersh, and his subsequent independent inquiry, broke the wall of silence that was surrounding the My Lai massacre. Hersh initially tried to sell the story to "Life" and "Look" magazines; both turned it down. Hersh then went to the small Washington-based Dispatch News Service, which sent it to fifty major American newspapers; thirty of them accepted it for publication. "New York Times" reporter Henry Kamm investigated further and found several My Lai massacre survivors in South Vietnam. He estimated the number of killed civilians as 567. Next, Ben Cole published an article about Ronald Ridenhour, a helicopter gunner and an Army whistleblower, who was among the first started to uncover the truth about the My Lai massacre. Joseph Eszterhas of "The Plain Dealer", who was a friend of Ronald Haeberle and knew about the photo evidence of the massacre, published the grisly images of the dead bodies of old men, women, and children on November 20, 1969. "Time" magazine's article on November 28, 1969 and in "Life" magazine on December 5, 1969, finally brought My Lai to the fore of the public debate about Vietnam War.
Richard L. Strout, the "Christian Science Monitor" political commentator, emphasized that, "American press self-censorship thwarted Mr. Ridenhour's disclosures for a year." "No one wanted to go into it", his agent said of telegrams sent to "Life", "Look", and "Newsweek" magazines outlining allegations.
Afterwards, interviews and stories connected to My Lai massacre started to appear regularly in the American and international press.
Photography.
The My Lai massacre, like many other events in Vietnam, was captured on camera by U.S. Army personnel. The most published and graphic images were taken by Ronald Haeberle, a U.S Army Public Information Detachment photographer who accompanied the men of Charlie Company that day. In 2009, Ronald Haeberle admitted that he destroyed a number of photographs he took during the My Lai massacre. Unlike the photographs of the dead bodies, the destroyed photographs depicted Americans in the actual process of murdering Vietnamese civilians.
The epithet "baby killers" was often used by anti-war activists to describe American soldiers, largely as a result of the Mỹ Lai Massacre. Although American soldiers had been so taunted since at least 1966, the Mỹ Lai massacre and the Haeberle photographs both further solidified the stereotype of drug-addled soldiers who killed babies. According to M. Paul Holsinger, the "And babies" poster, which used a Haeberle photo, was "easily the most successful poster to vent the outrage that so many felt about the human cost of the conflict in Southeast Asia. Copies are still frequently seen in retrospectives dealing with the popular culture of the Vietnam War era or in collections of art from the period."
Another soldier, John Henry Smail of the 3rd Platoon, took at least 16 color photographs depicting U.S. Army personnel, helicopters, and aerial views of Mỹ Lai. These, along with Haeberle's photographs, were included in the "Report of the Department of the Army review of the Preliminary Investigations into the My Lai Incident". Former First Lieutenant (1LT) Roger L. Alaux Jr., a forward artillery observer, who was assigned to Charlie Company during the combat assault on Ly Mai 4, also took some photographs from a helicopter that day, including aerial views of Mỹ Lai, and of the C Company's landing zone.
Remembrance.
My Lai holds a special place in American and Vietnamese collective memory. A Son My Memorial dedicated to victims of the Son My (My Lai) massacre was created in the village of Tịnh Khê, Son Tinh District, Quang Ngai Province of Vietnam. The graves with headstones, signs on the places of killing and a museum are all located on memorial site. The War Remnants Museum in Ho Chi Minh City has an exhibition on My Lai.
Some American veterans chose to go on pilgrimage to the site of the My Lai massacre to heal and reconcile. On the 30th anniversary of the My Lai massacre (March 16, 1998), a groundbreaking ceremony for the My Lai Peace Park was held away from the site of the massacre. Many Vietnam era veterans, including Hugh Thompson, Jr. and Larry Colburn from the helicopter rescue crew, were at the ceremony. Mike Boehm, a veteran who was instrumental in the peace park effort, said, "We cannot forget the past, but we cannot live with anger and hatred either. With this park of peace, we have created a green, rolling, living monument to peace". On March 16, 2001, the park was dedicated. It became a joint venture of the Quang Ngai province Women's Union, the Madison Quakers' charitable organization, and the Vietnamese government.

</doc>
<doc id="68293" url="https://en.wikipedia.org/wiki?curid=68293" title="Eryngium">
Eryngium

Eryngium is a genus of flowering plants in the family Apiaceae. There are about 250 species. The genus has a cosmopolitan distribution, with the center of diversity in South America. Common names include eryngo and sea holly (though the genus is not related to the true hollies, "Ilex").
These are annual and perennial herbs with hairless and usually spiny leaves. The dome-shaped umbels of steely blue or white flowers have whorls of spiny basal bracts. Some species are native to rocky and coastal areas, but the majority are grassland plants.
Uses.
Species are grown as ornamental plants in gardens. Numerous hybrids have been selected for garden use, of which "E." × "oliverianum" and "E." × "tripartitum" have gained the Royal Horticultural Society's Award of Garden Merit.
Many species of "Eryngium" have been used as food and medicine. "Eryngium campestre" is used as a folk medicine in Turkey. "Eryngium creticum" is a herbal remedy for scorpion stings in Jordan. "Eryngium elegans" is used in Argentina and "Eryngium foetidum" in Latin America and South-East Asia. Native American peoples used many species for varied purposes. Cultures worldwide have used "Eryngium" extracts as anti-inflammatory agents. "Eryngium" yields an essential oil and contains many kinds of terpenoids, saponins, flavonoids, coumarins, and steroids.
The roots have been used as vegetables or sweetmeats. Young shoots and leaves are sometimes used as vegetables like asparagus. "E. foetidum" is used in parts of the Americas and Asia as a culinary herb. It is similar to coriander or cilantro, and is sometimes mistaken for it. It may be called spiny coriander or culantro.
Species.
Species include:

</doc>
<doc id="68296" url="https://en.wikipedia.org/wiki?curid=68296" title="Cabrera, Balearic Islands">
Cabrera, Balearic Islands

Cabrera (, ) is an uninhabited islet in the Balearic Islands, Spain, located in the Mediterranean Sea off the southern coast of Majorca. It is a National Park. The highest point is Na Picamosques (172 m).
Cabrera is the largest island of the small archipelago that includes (from south to north) the islands of Estells de Fora, L'Imperial, Illa de ses Bledes, Na Redona, Conillera, L'Esponja, Na Plana, Illot Pla, Na Pobra, and Na Foradada.
History.
Cabrera was used to house French prisoners during the Napoleonic Wars. Of 9,000 sent to Cabrera, only 3,600 survived.
Late in 1916 a malfunctioning Austro-Hungarian Navy submarine remained at Cabrera for several hours, and the Spanish government subsequently decided to expropriate the island for defense. It is alleged that Juan March Ordinas, avoiding the blockade, had been selling supplies, including fuel, to submarine personnel, from the area of Cala Ganduf and S'Olla. There was strong international protest, particularly by the British Admirality, as Spain was officially neutral during the First World War.
Cabrera remained a military zone until the 1980s, although from the 1920s some Mallorcan civilians rented out their Cabrera land for agriculture. 
In 1936, during the Spanish Civil War, a Republican Air Force Dornier Wal D-1 airplane fell near the island. The crew were captured by military nationalist forces, but two Republican submarines (a B2 and B3) sent by order of Pedro Marqués Barber (an old officer and former military Minorca governor) came immediately and the small Cabreran force surrendered. Facundo Flores Horrach (the chief military officer), Mariano Ferrer Bravo (a retired Spanish officer) and three civilians (males of the Suñer Mas family) were taken to Minorca and executed in harbour place named S'Hort d'en Morillo (Mahón). After the failure of Captain Alberto Bayo Column landing in Mallorca, from 15 August to 4 September, the Republican troops left Cabrera. Bayo's plan was for the CNT column, stationed in Cabrera, to appear at Dragonera Island just southwest of Mallorca and simulate a false landing. But the anarchist CNT command refused this tactic and later went to Mallorca. A bloody battle destroyed them in Porto Cristo. The rest of this column failed before it arrived and was killed on Sa Cabana, just outside their point of entry at Manacor. 
In 1944, during World War II, a German airplane crashed into the sea close to Cabrera. One of the crew, Johanes Blocher, died.
Cabrera, which had been a former Santa Catalina, Palma de Mallorca district, was declared a National Park in April 1991. The Cabrera National Park is now administratively grouped with the municipality of Palma de Mallorca.

</doc>
<doc id="68297" url="https://en.wikipedia.org/wiki?curid=68297" title="Lluís Companys">
Lluís Companys

Lluís Companys i Jover () (El Tarròs, Spain, June 21, 1882 – Montjuïc Castle in Barcelona, Spain, October 15, 1940) was the President of Catalonia (Spain), from 1934 and during the Spanish Civil War.
He was a lawyer and leader of the Republican Left of Catalonia (ERC) political party. Exiled after the war, he was captured and handed over by the Nazi secret police, the Gestapo, to the Spanish dictatorship of Francisco Franco, who had him executed by firing squad in 1940. Companys is the only incumbent democratically elected president in European history to have been executed, and seventy-five years later the council of war which sentenced him is still in force.
Early life.
Born in El Tarròs, on June 21, 1882 into a peasant family with aristocratic roots, he was the second brother of ten. His parents were Josep Companys and Maria Lluïsa de Jover. His parent sent him to Barcelona in order to study at the boarding school of "Liceu Poliglot". Later, after obtaining his degree in law from the University of Barcelona, where he met Francesc Layret, Companys participated in the political life of Catalonia from a young age. In 1906, as a result of the military attack to the writings of Catalan newspapers "Cu-Cut!" and "La Veu de Catalunya", and after the passing of the "Ley de Jurisdicciones" ("Law of Jurisdictions"), which made speech against Spain and its symbols a criminal offense, he participated in the creation of Solidaritat Catalana.
Later, he became affiliated with the ephemeral "Unió Federal Nacionalista Republicana", where he was president of the youth section. He was investigated for his intense youth activities and was jailed fifteen times, being classified after the Tragic Week of Barcelona as a "dangerous individual" in police records.
With Francesc Layret, Companys represented the left-wing labor faction of the Partit Republicà Català (Catalan Republican Party), to which he was elected councilor of Barcelona in 1916. In November 1920, he was arrested together with Salvador Seguí (known as "El Noi del Sucre"), Martí Barrera and other trade unionists and he was deported to the "Castell de la Mola" in Mahón, Menorca. Shortly afterward, Layret was assassinated while preparing his defense.
Despite having been deported, Companys was elected deputy of Sabadell in the 1920 Spanish legislative elections, taking the place of Layret, who was to have taken that seat prior to his assassination. This gave him parliamentary immunity, which secured his release from prison.
Companys was one of the founders of the Unió de Rabassaires in 1922, where he worked as lawyer and director of the magazine "La Terra" during the years of the regime of Primo de Rivera.
Detained again, he was unable to attend the "Conferencia de Izquierdas" (Conference of Leftists) held from March 12 to March 19, 1931 that produced the ERC political party; however, he was elected as an executive member of that party, representing the Partit Republicà Català. Thanks to the bonds between the Spanish labor movement and the Spanish union movement, the election of Companys to this position gave the ERC great prestige amongst left-wing public opinion whereas it had prior been considered a party of the small progressive bourgeoisie.
Proclamation of the Republic.
In the 1931 Spanish Local elections ERC won a surprise victory in Barcelona. After knowing the results, Companys, who was elected a city representative, and other ERC candidates together with the Party's leader Francesc Macià, decided to take over by surprise the office of Mayor and assaulted the City Hall. At gunpoint, the transitional Mayor was deposed and Companys was proclaimed new Mayor. Subsequently, he hung a tricolour Spanish Republican Flag from the City Hall's balcony and proclaimed the Republic. Shortly after, Francesc Macià proclaimed the Catalan State within the "Federation of Iberian Republics", a project that was later abandoned after gaining the promise of regional devolution and the restitution of the Catalan Generalitat (as a regional government) from the new Republican government.
After controlling the Barcelona City Hall, Macià ordered Companys to take the office of "Gobernador Civil" of the Barcelona province (provincial political authority, which at that time held considerable powers, policing included), which had been controlled by radicals during the process of the Republic proclamation. Macià probably wanted a less public office for Companys, whom he thought of as a political rival. Compays run as a Barcelona provincial candidate in the December 1931 Spanish Legislative Elections. After gaining a seat he led the ERC representation and the Catalan minority group in the new Republican Parliament. He described his political objectives in Madrid as: "We, the Catalan Members of the Parliament, have come here not only to defend our regional constitution "Estatuto, Spanish original", and the fraternal and democratic understanding of the members of Parliament; but, also to participate in matters that affect the greatness of Spain: the Constitution, the agrarian reforms and social legislation." In 1932 Companys was elected Speaker of the regional Catalan Parliament.
Proclamation of the Catalan State.
After the death of Francesc Macià in 1933, at that time presiding over the Catalan government (Generalitat), Companys was elected the successor President of the Generalitat by the Catalan Parliament. In October 6, 1934, Companys led a Catalan Nationalist uprising not supported by the center and conservatives Catalan representatives, against the center and right-wing republican government, and proclaimed the Catalan State (Estat Català) within the "Spanish Federal Republic", an action by which he was arrested and sentenced to thirty years in prison. This action was an attempt of Coup d'État as Companys revolted against the newly democratically elected center-right republican government and joined the Asturias miners revolution. Companys asked Manuel Azaña, who happened to be in Barcelona during the events, to lead a newly proclaimed Spanish Republican government, a proposition that Azaña rejected. After the 1936 election and the victory of the left-wing coalition Frente Popular, he was set free by the new government.
Civil War.
When the Spanish Civil War began shortly after, in July 1936, Companys sided with the Second Spanish Republic against the "Nacionales" rebels and was instrumental in organizing a collaboration between the Central Committee of Anti-Fascist Militias, which was sponsored by his Catalan government, and the Workers' Party of Marxist Unification (POUM), a revolutionary anti-Stalinist communist party, and Confederación Nacional del Trabajo (CNT), an anarchist syndicalist trade union. During the events, Companys opened the police and gendarmery armories to the anarchist and POUM groups, who after defeating the coupists, created havoc and carnage in the city rounding up and shooting hundreds of civilians deemed "bourgeoisie" or "rightist", religious orders members and priests, as well as burning all the churches, monasteries and convents of the city. De facto, Companys lost the control of the city and Catalonia until the May Days of 1937 when the anarchists and POUM were suppressed. After the coup, the CNT had 30,000 armed men in Barcelona, while the government had only 5000. Antony Beevor estimates the total number of people killed in Catalonia in the summer and autumn of 1936 at 8,352.
Exile and execution.
Exiled to France in 1939 after the Civil War, Companys had passed up various chances to leave France because his son Lluis was seriously ill in a clinic in Paris. He was arrested in La Baule-les-Pins near Nantes on 13 August 1940, and detained in La Santé Prison. He was then extradited by Nazi German authorities to the Spanish government in Madrid in early September 1940 and imprisoned in the cellars of the headquarters of the Dirección General de Seguridad (State Security) at the Real Casa de Correos in Puerta del Sol. He was held there for five weeks, kept in solitary confinement, tortured and beaten, while senior figures of the Franco regime visited his cell, insulted him and threw coins or crusts of bread at him. After a military trial which lasted less than one hour, lacking legal guarantees where he was accused of military rebellion, Companys was executed at Montjuïc Castle in Barcelona at 6:30 a.m. on October 15, 1940. Refusing to wear a blindfold, he was taken before a firing squad of Civil Guards and, as they fired, he cried 'Per Catalunya!' (For Catalonia!). He is buried at the Montjuïc Cemetery, near the castle. The cause of death was given as 'traumatic internal haemorrhage'.
The main stadium used for the 1992 Summer Olympics, located on Montjuïc, is officially named in his memory. In 1998 a monument to Companys was installed near Arc de Triomf, on Passeig de Lluís Companys in Barcelona. A friend of Companys, Conxita Julià, is portrayed next to Companys' image in the monument. Several streets and squares in many cities and villages of Catalonia are named "Lluís Companys" after him.

</doc>
<doc id="68298" url="https://en.wikipedia.org/wiki?curid=68298" title="Huesca">
Huesca

Huesca (; ) is a city in north-eastern Spain, within the autonomous community of Aragon. It is also the capital of the Spanish province of the same name and of the comarca of Hoya de Huesca. In 2009 it had a population of 52,059, almost a quarter of the total population of the province. The city is one of the smallest provincial capitals in Spain.
Huesca celebrates its main festival "Fiestas de San Lorenzo" from 9 to 15 August.
History.
Huesca dates from pre-Roman times, and was once known as Bolskan in the ancient Iberian language. It was once the capital of the Vescetani, in the north of Hispania Tarraconensis, on the road from Tarraco (modern Tarragona) and Ilerda (modern Lleida) to Caesaraugusta (modern Zaragoza). During Roman times, the city was known as Osca, and was a Roman colony under the rule of Quintus Sertorius, who made Osca his base. The city minted its own coinage and was the site of a prestigious school founded by Sertorius to educate young Iberians in Latin and Roman customs. After Sertorius, it it thought that it was renamed Ileoscan () by Strabo. It appears to have been situated on silver mines.
18th-century Spanish historian Enrique Flórez has pointed out the impossibility of one city supplying such vast quantities of minted silver as has been recorded by ancient writers under the terms "argentum Oscense", "signatum Oscense"; and is of the opinion that "Oscense" meant "Spanish", being a corruption of "Eus-cara". The Romanised city was made a "municipium" by decree of Augustus in 30 BC.
The Arabs conquered the city in the late 8th century, and the city came to be called "Washqah" (وشقة inArabic), falling within the Upper March territory of the Emirate of Córdoba. It was ruled by a local governor appointed from Córdoba, but was repeatedly subject to political turmoil, rebellion and assassination as the Banu Qasi, Banu Amrus and Banu al-Tawil clans, as well as the Arista dynasty of Pamplona, struggled for control, autonomy and independence from the Emirate. In the mid-10th century, Wasqah was transferred to the Banu Tujibi, who governed the Upper March from Zaragoza, and it became part of the Taifa of Zaragoza in 1018 when they successfully freed themselves from the disintegrating Caliphate. In 1094 Sancho Ramirez built the nearby Castle of Montearagón with the intention of laying siege to Wasqah but was killed by a stray arrow as he reached the city's walls. It was conquered in 1096 by Peter I of Aragon.
In 1354, King Peter IV of Aragon founded the University of Huesca, which initially had a faculty of theology. The school expanded, but by the end of the 16th century was eclipsed by the University of Zaragoza. The university was abolished in 1845.
During the Spanish Civil War (1936–39) the "Huesca Front" was the scene of some of the worst fighting between the Republicans and Franco's army. The city was besieged by the Republicans, George Orwell among them, but didn't fall.
Modern Huesca.
Huesca celebrates its most important annual festival in August: the festival (or fiesta) of San Lorenzo (Saint Lawrence), a native of Huesca martyred in 268 AD. The anniversary of his martyrdom falls on August 10. The fiesta starts on 9 August and finishes on the 15. Many of the inhabitants dress in green and white for the duration.
San Lorenzo, born in Huesca, was a deacon in Rome and a martyr who, according to legend, was burned on a grille by the Romans. The grille is the symbol of San Lorenzo and can be seen in a number of decorative works in the city.
Huesca is also the birthplace of film director Carlos Saura and his brother Antonio Saura, a contemporary artist. There is an international film festival held annually.
The writer Oscar Sipan, winner of several literary prizes, was born in Huesca in 1974. The celebrated illustrator Isidro Ferrer, though born in Madrid, lives in the city.
Geography.
Huesca lies on a plateau in the northern region of Aragón, at an altitude of 488 m (1,601.05 ft) above sea level. Close to the city lie the Sierra de Guara mountains, which reach 2,077 m. The geographical coordinates of the city are: 42° 08´ N, 0° 24´ W.
Its municipal area is 161.02 km ² and borders the municipalities of Almudévar, Vicién, Monflorite-Lascasas Tierz, Quicena, Loporzano, Nueno, Igriés, Banastás, Chimillas, Alerre, Barbués and Albero Bajo.
The city lies 71 kilometres (44 mi) from Zaragoza, 160 kilometres (99 mi) from Pamplona, 118 kilometres (73 mi) from Lleida, 380 kilometres (236 mi) from Madrid and 273 kilometres (169 mi) from Barcelona.
Climate.
Huesca has a mediterranean climate (Köppen climate classification "Csa"), with fairly dry summers, and wetter springs and autumns, but with some characteristics of a continental climate, such as more extreme temperatures, as the town lies in a wide basin (the Ebro basin) which is entirely surrounded by mountains.
The average precipitation is 480 mm per year. There are annual droughts in summer. The temperatures are also fairly high in summer reaching up to 35 °C (95 °F). In winter the temperatures are low (usually 1 to 10 °C). Frost is common and there is sporadic snowfall.
Main sights.
A double line of ancient walls can still be seen in present-day Huesca.
Nearby, in the territory of Quicena, lie the ruins of the Castle of Montearagón Monastery.
Popular references.
Huesca is notable for the saying "Tomorrow we'll have coffee in Huesca", a running joke among militiamen of the Spanish Civil War. In February 1937, George Orwell was stationed near the falangist-held Huesca as a member of the POUM militia. In "Homage to Catalonia", Orwell writes about this running joke, originally a naïvely optimistic comment made by one of the Spanish Republican generals:
Orwell never did, but the Indian writer Shashi Tharoor fulfilled his wish on his behalf in 1980, and has written about the experience. Huesca is also famous for the legend of the Bell of Huesca.
Twin towns - sister cities.
The following are Sister cities of Huesca:

</doc>
<doc id="68299" url="https://en.wikipedia.org/wiki?curid=68299" title="Teruel">
Teruel

Teruel () is a town in Aragon, located in eastern Spain, and is also the capital of Teruel Province. It has a population of 35,961 in 2013 making it the least populated provincial capital in the country. It is noted for its harsh climate (hot in summer and very cold in winter), its renowned "jamón serrano" (cured ham), its pottery, its surrounding archaeological sites, rock outcrops containing some of the oldest dinosaur remains of the Iberian Peninsula, and its famous Fiestas ("La vaquilla del ángel" during the second weekend of July and "Bodas de Isabel de Segura" around the third weekend of February). Teruel is regarded as the "town of mudéjar" (Moorish-influenced architecture) due to numerous buildings designed in this style. All of them are comprised in the Mudéjar Architecture of Aragon which is a World Heritage Site by the UNESCO.
Teruel's remote and mountainous location above sea level and its low population has led to relative isolation within Spain. A campaign group with the slogan "Teruel existe" ("Teruel exists") was founded in 1999 to press for greater recognition and investment in the town and the province. Due in part to the campaign, transport connections to Teruel are being greatly improved with the construction of a motorway between Zaragoza and Sagunto, large parts of which are now open. However, Teruel remains the only provincial capital in peninsular Spain without a direct railway link to the capital, Madrid.
Climate.
Teruel's climate is a moderate continental one typical of a mountainous region. Summer temperatures are mild, although there is much temperature variation, and winters are cold, with low minimum temperatures sometimes dropping to . The lowest amount of rainfall is in winter and the greatest falls at the end of spring.
The temperature records recorded at the Observatoire de Teruel on August 10, 2012 and on December 26, 2001.
History.
Teruel was founded in 1176 by Sancho Sánchez Muñoz and Blasco Garcés Marcilla. In the Middle Ages Teruel possessed a prominent Jewish community, which was robust during the centuries Muslims were in power and enjoyed several privileges. Later on after the Christian reconquest of Spain, the Jewish community paid a yearly tax of 300 sueldos (in the 14th century). Its members were engaged in commerce and industry, especially in wool-weaving. During the persecutions of 1391 many of them were killed, while others accepted Christianity in order to save their lives.
Teruel was fought over in the Spanish Civil War and suffered much destruction. The Battle of Teruel in December 1937-February 1938, was one of the bloodiest of the war. The town changed hands several times, first falling to the Republicans and eventually being re-taken by the Nationalists. In the course of the fighting, Teruel was subjected to heavy artillery and aerial bombardment. The two sides suffered up to 140,000 casualties between them in the three-month battle. The Nationalists won a decisive victory.
Main sights.
The beauty of the town's cultural inheritance, which has some Islamic influence, has been recognised by UNESCO, which includes four churches in the World Heritage Site Mudéjar Architecture of Aragon, notably the town's ornate cathedral in the Mudéjar style.
One of Teruel's best known monuments is very small statue of a bull on top of a tall column, known as "El Torico" ("the little bull"). It is located in the main square, "Plaza Carlos Castell", more commonly known as the "Plaza del Torico" in the middle of the town center.
Other sights include:
On the outskirts of Teruel is Dinópolis Teruel, a combined theme park and museum centred on dinosaurs. Promoted as a paleontological park, it includes a life-size robotic model of a "Tyrannosaurus rex".Dinópolis also owns three other museums in the surrounding area, which display the remains of dinosaurs discovered in the region.[http://www.dinopolis.com/. The chimney of the Teruel Power Plant is one of the tallest freestanding structures in Western Europe.
Transportation.
The city buses are run by Grupo Autobuses Jimenez.

</doc>
<doc id="68300" url="https://en.wikipedia.org/wiki?curid=68300" title="Dominance (genetics)">
Dominance (genetics)

Dominance in genetics is a relationship between alleles of one gene, in which the effect on phenotype of one allele masks the contribution of a second allele at the same locus. The first allele is dominant and the second allele is recessive. For genes on an autosome (any chromosome other than a sex chromosome), the alleles and their associated traits are autosomal dominant or autosomal recessive. Dominance is a key concept in Mendelian inheritance and classical genetics. Often the dominant allele codes for a functional protein whereas the recessive allele does not.
A classic example of dominance is the inheritance of seed shape in peas. Peas may be round, associated with allele "R" or wrinkled, associated with allele "r". In this case, three combinations of alleles (genotypes) are possible: "RR", "Rr", and "rr". The "RR" individuals have round peas and the "rr" individuals have wrinkled peas. In "Rr" individuals the "R" allele masks the presence of the "r" allele, so these individuals also have round peas. Thus, allele "R" is dominant to allele "r", and allele "r" is recessive to allele "R". This use of upper case letters for dominant alleles and lower case ones for recessive alleles is a widely followed convention.
More generally, where a gene exists in two allelic versions (designated "A" and "a"), three combinations of alleles are possible: "AA", "Aa", and "aa". If "AA" and "aa" individuals (homozygotes) show different forms of some trait (phenotypes), and "Aa" individuals (heterozygotes) show the same phenotype as "AA" individuals, then allele "A" is said to "dominate" or "be dominant to" or "show dominance to" allele "a", and "a" is said to "be recessive to" "A".
Dominance is not inherent to an allele. It is a relationship between alleles; one allele can be dominant over a second allele, recessive to a third allele, and codominant to a fourth. Also, an allele may be dominant for a particular aspect of phenotype but not for other aspects influenced by the same gene. Dominance differs from epistasis, a relationship in which an allele of one gene affects the expression of another allele at a different gene.
Background.
The concept of dominance was introduced by Gregor Mendel. Though Mendel, "The Father of Genetics", first used the term in the 1860s, it was not widely known until the early twentieth century. Mendel observed that, for a variety of traits of garden peas having to do with the appearance of seeds, seed pods, and plants, there were two discrete phenotypes, such as round versus wrinkled seeds, yellow versus green seeds, red versus white flowers or tall versus short plants. When bred separately, the plants always produced the same phenotypes, generation after generation. However, when lines with different phenotypes were crossed (interbred), one and only one of the parental phenotypes showed up in the offspring (green, or round, or red, or tall). However, when these hybrid plants were crossed, the offspring plants showed the two original phenotypes, in a characteristic 3:1 ratio, the more common phenotype being that of the parental hybrid plants. Mendel reasoned that each parent in the first cross was a homozygote for different alleles (one parent AA and the other parent aa), that each contributed one allele to the offspring, with the result that all of these hybrids were heterozygotes (A), and that one of the two alleles in the hybrid cross dominated expression of the other: A masked a. The final cross between two heterozygotes (Aa X Aa) would produce AA, Aa, and aa offspring in a 1:2:1 genotype ratio with the first two classes showing the (A) phenotype, and the last showing the (a) phenotype, thereby producing the 3:1 phenotype ratio.
Mendel did not use the terms gene, allele, phenotype, genotype, homozygote, and heterozygote, all of which were introduced later. He did introduce the notation of capital and lowercase letters for dominant and recessive alleles, respectively, still in use today.
Chromosomes, genes, and alleles.
Most animals and some plants have paired chromosomes, and are described as diploid. They have two versions of each chromosome, one contributed by the mother's ovum, and the other by the father's sperm, known as gametes, described as haploid, and created through meiosis. These gametes then fuse during fertilization during sexual reproduction, into a new single cell zygote, which divide twice, resulting in a new organism with the same number of pairs of chromosomes in each (non-gamete) cell as its parents.
Each chromosome of a matching (homologous) pair is structurally similar to the other, and has a very similar DNA sequence (loci, singular locus). The DNA in each chromosome functions as a series of discrete genes that influence various traits. Thus, each gene also has a corresponding homologue, which may exist in different versions called alleles. The alleles at the same locus on the two homologous chromosomes may be identical or different.
Blood types in humans is determined by a gene that creates an A, B, AB or, O blood type and is located in the long arm of chromosome nine. There are three different alleles that could be present at this locus, but only two can be present in any individual, one inherited from their mother and one from their father.
If two alleles of a given gene are identical, the organism is called a homozygote and is said to be homozygous with respect to that gene; if instead the two alleles are different, the organism is a heterozygote and is heterozygous. The genetic makeup of an organism, either at a single locus or over all its genes collectively, is called its genotype. The genotype of an organism directly and indirectly affects its molecular, physical, and other traits, which individually or collectively are called its phenotype. At heterozygous gene loci, the two alleles interact to produce the phenotype.
Dominance.
Complete dominance.
In complete dominance, the effect of one allele in a heterozygous genotype completely masks the effect of the other. The allele that masks the other is said to be "dominant" to the latter, and the allele that is masked is said to be "recessive" to the former. Complete dominance therefore means that the phenotype of the heterozygote is indistinguishable from that of the dominant homozygote.
A classic example of dominance is the inheritance of seed shape (pea shape) in peas. Peas may be round (associated with allele "R") or wrinkled (associated with allele "r"). In this case, three combinations of alleles (genotypes) are possible: "RR" and "rr" are homozygous and "Rr" is heterozygous. The "RR" individuals have round peas and the "rr" individuals have wrinkled peas. In "Rr" individuals the "R" allele masks the presence of the "r" allele, so these individuals also have round peas. Thus, allele "R" is dominant to allele "r", and allele "r" is recessive to allele "R".
Incomplete dominance.
Incomplete dominance (also called "partial dominance" or "semi-dominance") occurs when the phenotype of the heterozygous phenotype is distinct from and often intermediate to the phenotypes of the homozygous phenotypes. For example, the snapdragon flower color is either homozygous for red or white. When the red homozygous flower is paired with the white homozygous flower, the result yields a pink snapdragon flower. The pink snapdragon is the result of incomplete dominance. A similar type of incomplete dominance is found in the four o'clock plant wherein pink color is produced when true-bred parents of white and red flowers are crossed. In quantitative genetics, where phenotypes are measured and treated numerically, if a heterozygote's phenotype is exactly between (numerically) that of the two homozygotes, the phenotype is said to exhibit "no dominance" at all, i.e. dominance exists only when the heterozygote's phenotype measure lies closer to one homozygote than the other.
When plants of the F1 generation are self-pollinated, the phenotypic and genotypic ratio of the F2 generation will be 1:2:1 (Red:Pink:White).
See partial dominance hypothesis theory.
Co-dominance.
Co-dominance occurs when the contributions of both alleles are visible in the phenotype.
For example, in the ABO blood group system, chemical modifications to a glycoprotein (the H antigen) on the surfaces of blood cells are controlled by three alleles, two of which are co-dominant to each other ("IA", "IB") and dominant over the recessive "i" at the ABO locus. The "IA" and "IB" alleles produce different modifications. The enzyme coded for by "IA" adds an N-acetylgalactosamine to the membrane-bound H antigen. The "IB" enzyme adds a galactose. The "i" allele produces no modification. Thus "IA" and "IB" alleles are each dominant to "i" ("IAIA" and "IAi" individuals both have type A blood, and "IBIB" and "IBi" individuals both have type B blood, but "IAIB" individuals have both modifications on their blood cells and thus have type AB blood, so the "IA" and "IB" alleles are said to be co-dominant).
Another example occurs at the locus for the Beta-globin component of hemoglobin, where the three molecular phenotypes of "HbA/HbA", "HbA/HbS", and "HbS/HbS" are all distinguishable by protein electrophoresis. (The medical condition produced by the heterozygous genotype is called "sickle-cell trait" and is a milder condition distinguishable from "sickle-cell anemia", thus the alleles show "incomplete dominance" with respect to anemia, see above). For most gene loci at the molecular level, both alleles are expressed co-dominantly, because both are transcribed into RNA.
Co-dominance, where allelic products co-exist in the phenotype, is different from incomplete dominance, where the quantitative interaction of allele products produces an intermediate phenotype. For example, in co-dominance, a red homozygous flower and a white homozygous flower will produce offspring that have red and white spots. When plants of the F1 generation are self-pollinated, the phenotypic and genotypic ratio of the F2 generation will be 1:2:1 (Red:Spotted:White). These ratios are the same as those for incomplete dominance. Again, note that this classical terminology is inappropriate – in reality such cases should not be said to exhibit dominance at all.
Which trait is "dominating"?
By definition, the terms "dominant" and "recessive" refer to the genotypic interaction of alleles in producing the phenotype of the heterozygote. The key concept is genetic: Which of the two alleles present in the heterozygote is expressed, such that the organism is phenotypically identical to one of the two homozygotes. It is sometimes convenient to talk about the trait corresponding to the dominant allele as the "dominant trait", and the trait corresponding to the hidden allele as the "recessive trait". However, this can easily lead to confusion in understanding the concept as phenotypic. For example, to say that "green peas" dominate "yellow peas" confuses inherited genotypes and expressed phenotypes, and will subsequently confuse discussion of the molecular basis of the phenotypic difference.
Addressing common misconceptions.
Dominance is not inherent: one allele can be dominant to a second allele, recessive to a third allele, and codominant to a fourth.
Dominance is unrelated to the nature of the phenotype itself, that is, whether it is regarded as "normal" or "abnormal," "standard" or "nonstandard," "healthy" or "diseased," "stronger" or "weaker," or more or less extreme. A dominant allele may account for any of these trait types.
Dominance does not determine whether an allele is deleterious, neutral or advantageous. However, selection works through differential reproduction of phenotypes, and dominance affects the exposure of alleles in phenotypes, and hence the rate of change in allele frequencies under selection. Deleterious recessive alleles may persist in a population at low frequencies, with most copies carried in heterozygotes, at no cost to those individuals. These rare recessives are the basis for many hereditary genetic disorders.
Dominance is also unrelated to the distribution of alleles in the population. Some dominant alleles are extremely common, while others are extremely rare. The most common allele in a population may be recessive when combined with some rare variants.
Nomenclature.
In genetics, symbols began as algebraic placeholders. When one allele is dominant to another, the oldest convention is to symbolize the dominant allele with a capital letter. The recessive allele is assigned the same letter in lower case. In the pea example, once the dominance relationship between the two alleles is known, it is possible to designate the dominant allele that produces a round shape by a capital-letter symbol R, and the recessive allele that produces a wrinkled shape by a lower-case symbol r. The homozygous dominant, heterozygous, and homozygous recessive genotypes are then written RR, Rr, and rr, respectively. It would also be possible to designate the two alleles as W and w, and the three genotypes WW, Ww, and ww, the first two of which produced round peas and the third wrinkled peas. Note that the choice of "R" or "W" as the symbol for the dominant allele does not pre-judge whether the allele causing the "round" or "wrinkled" phenotype when homozygous is the dominant one.
A gene may have several alleles. Each allele is symbolized by the locus symbol followed by a unique superscript. In many species, the most common allele in the wild population is designated the wild type allele. It is symbolized with a + character as a superscript. Other alleles are dominant or recessive to the wild type allele. For recessive alleles, the locus symbol is in lower case letters. For alleles with any degree of dominance to the wild type allele, the first letter of the locus symbol is in upper case. For example, here are some of the alleles at the "a" locus of the laboratory mouse, "Mus musculus": "Ay", dominant yellow; "a+", wild type; and "abt", black and tan. The "abt" allele is recessive to the wild type allele, and the "Ay" allele is codominant to the wild type allele. The "Ay" allele is also codominant to the "abt" allele, but showing that relationship is beyond the limits of the rules for mouse genetic nomenclature.
Rules of genetic nomenclature have evolved as genetics has become more complex. Committees have standardized the rules for some species, but not for all. Rules for one species may differ somewhat from the rules for a different species.
Relationship to other genetic concepts.
Multiple alleles.
Although any individual of a diploid organism has at most two different alleles at any one locus (barring aneuploidies), most genes exist in a large number of allelic versions in the population as a whole. If the alleles have different effects on the phenotype, sometimes their dominance interactions with each other can be described as a series.
For example, coat color in domestic cats is affected by a series of alleles of the "TYR" gene (which encodes the enzyme tyrosinase). The alleles "C", "cb", "cs", and "ca" (full colour, Burmese, Siamese, and albino, respectively) produce different levels of pigment and hence different levels of colour dilution. The "C" allele (full colour) is completely dominant over the last three and the "ca" allele (albino) is completely recessive to the first three.
Autosomal "versus" sex-linked dominance.
In humans and other mammal species, sex is determined by two sex chromosomes called the X chromosome and the Y chromosome. Human females are typically XX; males are typically XY. The remaining pairs of chromosome are found in both sexes and are called autosomes; genetic traits due to loci on these chromosomes are described as autosomal, and may be dominant or recessive. Genetic traits on the X and Y chromosomes are called sex-linked, because they are linked to sex chromosomes, not because they are characteristic of one sex or the other. In practice, the term almost always refers to X-linked traits and a great many such traits (such as red-green colour vision deficiency) are not affected by sex. Females have two copies of every gene locus found on the X chromosome, just as for the autosomes, and the same dominance relationships apply. Males however have only one copy of each X chromosome gene locus, and are described as hemizygous for these genes. The Y chromosome is much smaller than the X, and contains a much smaller set of genes, including, but not limited to, those that influence 'maleness', such as the SRY gene for testis determining factor. Dominance rules for sex-linked gene loci are determined by their behavior in the female: because the male has only one allele (except in the case of certain types of Y chromosome aneuploidy), that allele is always expressed regardless of whether it is dominant or recessive.
Epistasis.
Epistasis [""epi" + "stasis" = to sit on top"] is an interaction between alleles at two "different" gene loci that affect a single trait, which may sometimes resemble a dominance interaction between two "different" alleles at the "same" locus. Epistasis modifies the characteristic 9:3:3:1 ratio expected for two non-epistatic genes. For two loci, 14 classes of epistatic interactions are recognized. As an example of recessive epistasis, one gene locus may determine whether a flower pigment is yellow (AA or Aa) or green (aa), while another locus determines whether the pigment is produced (BB or Bb) or not (bb). In a bb plant, the flowers will be white, irrespective of the genotype of the other locus as AA, Aa, or aa. The bb combination is "not" dominant to the A allele: rather, the B gene shows recessive epistasis to the A gene, because the B locus when homozygous for the "recessive" allele (bb) suppresses phenotypic expression of the A locus. In a cross between two AaBb plants, this produces a characteristic 9:3:4 ratio, in this case of yellow : green : white flowers.
In dominant epistasis, one gene locus may determine yellow or green pigment as in the previous example: AA and Aa are yellow, and aa are green. A second locus determines whether a pigment precursor is produced (dd) or not (DD or Dd). Here, in a DD or Dd plant, the flowers will be colorless irrespective of the genotype at the A locus, because of the epistatic effect of the dominant D allele. Thus, in a cross between two AaDd plants, 3/4 of the plants will be colorless, and the yellow and green phenotypes are expressed only in dd plants. This produces a characteristic 12:3:1 ratio of white : yellow : green plants.
Supplementary epistasis occurs when two loci affect the same phenotype. For example, if pigment color is produced by CC or Cc but not cc, and by DD or Dd but not dd, then pigment is not produced in any genotypic combination with either cc "or" dd. That is, "both" loci must have at least one dominant allele to produce the phenotype. This produces a characteristic 9:7 ratio of pigmented to unpigmented plants. Complementary epistasis in contrast produces an unpigmented plant if and only if the genotype is cc "and" dd, and the characteristic ratio is 15:1 between pigmented and unpigmented plants.
Classical genetics considered epistatic interactions between two genes at a time. It is now evident from molecular genetics that all gene loci are involved in complex interactions with many other genes (e.g., metabolic pathways may involve scores of genes), and that this creates epistatic interactions that are much more complex than the classic two-locus models.
Hardy-Weinberg principle (Estimation of carrier frequency).
The frequency of the homozygous state (which is the carrier state for a recessive trait) can be estimated using the Hardy-Weinberg formula: formula_1
This formula applies to a gene with exactly two alleles and relates the frequencies of those alleles in a large population to the frequencies of their three genotypes in that population.
For example, if "p" is the frequency of allele A, and "q" is the frequency of allele a then the terms "p"2, 2"pq", and "q"2 are the frequencies of the genotypes AA, Aa and aa respectively. Since the gene has only two alleles, all alleles must be either A or a and . Now, if A is completely dominant to a then the frequency of the carrier genotype Aa cannot be directly observed (since it has the same traits as the homozygous genotype AA), however it can be estimated from the frequency of the recessive trait in the population, since this is the same as that of the homozygous genotype aa. i.e. the individual allele frequencies can be estimated: , , and from those the frequency of the carrier genotype can be derived: .
This formula relies on a number of assumptions and an accurate estimate of the frequency of the recessive trait. In general, any real-world situation will deviate from these assumptions to some degree, introducing corresponding inaccuracies into the estimate. If the recessive trait is rare, then it will be hard to estimate its frequency accurately, as a very large sample size will be needed.
Molecular mechanisms.
The molecular basis of dominance was unknown to Mendel. It is now understood that a gene locus includes a long series (hundreds to thousands) of bases or nucleotides of deoxyribonucleic acid (DNA) at a particular point on a chromosome. The central dogma of molecular biology states that ""DNA makes RNA makes protein"", that is, that DNA is transcribed to make an RNA copy, and RNA is translated to make a protein. In this process, different alleles at a locus may or may not be transcribed, and if transcribed may be translated to slightly different versions of the same protein (called isoforms). Proteins often function as enzymes that catalyze chemical reactions in the cell, which directly or indirectly produce phenotypes. In any diploid organism, the DNA sequences of the two alleles present at any gene locus may be identical (homozygous) or different (heterozygous). Even if the gene locus is heterozygous at the level of the DNA sequence, the proteins made by each allele may be identical. In the absence of any difference between the protein products, neither allele can be said to be dominant (see "co-dominance", above). Even if the two protein products are slightly different (allozymes), it is likely that they produce the same phenotype with respect to enzyme action, and again neither allele can be said to be dominant.
Loss of function and haplosufficiency.
Dominance typically occurs when one of the two alleles is non-functional at the molecular level, that is, it is not transcribed or else does not produce a functional protein product. This can be the result of a mutation that alters the DNA sequence of the allele. An organism homozygous for the non-functional allele will generally show a distinctive phenotype, due to the absence of the protein product. For example, in humans and other organisms, the unpigmented skin of the albino phenotype results when an individual is homozygous for an allele that encodes a non-functional version of an enzyme needed to produce the skin pigment melanin. It is important to understand that it is not the lack of function that allows the allele to be described as recessive: this is the interaction with the alternative allele in the heterozygote. Three general types of interaction are possible:
Dominant-negative mutations.
Many proteins are normally active in the form of a multimer, an aggregate of multiple copies of the same protein, otherwise known as a homomultimeric protein or homooligomeric protein. In fact, a majority of the 83,000 different enzymes from 9800 different organisms in the BRENDA Enzyme Database represent homooligomers. When the wild-type version of the protein is present along with a mutant version, a mixed multimer can be formed. A mutation that leads to a mutant protein that disrupts the activity of the wild-type protein in the multimer is a dominant-negative mutation.
A dominant-negative mutation may arise in a human somatic cell and provide a proliferative advantage to the mutant cell, leading to its clonal expansion. For instance, a dominant-negative mutation in a gene necessary for the normal process of programmed cell death (Apoptosis) in response to DNA damage can make the cell resistant to apoptosis. This will allow proliferation of the clone even when excessive DNA damage is present. Such dominant-negative mutations occur in the tumor suppressor gene "p53". The P53 wild-type protein is normally present as a four-protein multimer (oligotetramer). Dominant-negative "p53" mutations occur in a number of different types of cancer and pre-cancerous lesions (e.g. brain tumors, breast cancer, oral pre-cancerous lesions and oral cancer).
Dominant-negative mutations also occur in other tumor suppressor genes. For instance two dominant-negative germ line mutations were identified in the Ataxia telangiectasia mutated (ATM) gene which increases susceptibility to breast cancer. Dominant negative mutations of the transcription factor C/EBPα can cause acute myeloid leukemia. Inherited dominant negative mutations can also increase the risk of diseases other than cancer. Dominant-negative mutations in Peroxisome proliferator-activated receptor gamma (PPARγ) are associated with severe insulin resistance, diabetes mellitus and hypertension.
Dominant-negative mutations have also been described in organisms other than humans. In fact, the first study reporting a mutant protein inhibiting the normal function of a wild-type protein in a mixed multimer was with the bacteriophage T4 tail fiber protein GP37. Mutations that produce a truncated protein rather than a full-length mutant protein seem to have the strongest dominant-negative effect in the studies of P53, ATM, C/EBPα, and bacteriophage T4 GP37.
Dominant and recessive genetic diseases in humans.
In humans, many genetic traits or diseases are classified simply as "dominant" or "recessive". Especially with so-called recessive diseases, which are indeed a factor of recessive genes, but can oversimplify the underlying molecular basis and lead to misunderstanding of the nature of dominance. For example, the recessive genetic disease phenylketonuria (PKU) results from any of a large number (>60) of alleles at the gene locus for the enzyme phenylalanine hydroxylase (PAH). Many of these alleles produce little or no PAH, as a result of which the substrate phenylalanine (Phe) and its metabolic byproducts accumulate in the central nervous system and can cause severe intellectual disability if untreated.
The genotypes and phenotypic consequences of interactions among three alleles are shown in the following table:
In unaffected persons homozygous for a standard functional allele (AA), PAH activity is standard (100%), and the concentration of phenylalanine in the blood [Phe] is about 60 uM. In untreated persons homozygous for one of the PKU alleles (BB), PAH activity is close to zero, ten to forty times standard, and the individual manifests PKU.
In the AB heterozygote, PAH activity is only 30% (not 50%) of standard, blood [Phe] is elevated two-fold, and the person does not manifest PKU. Thus, the A allele is dominant to the B allele with respect to PKU, but the B allele is incompletely dominant to the A allele with respect to its molecular effect, determination of PAH activity level (0.3% < 30% Â« 100%). Finally, the A allele is an incomplete dominant to B with respect to as 60 uM < 120 uM Â« 600 uM. Note once more that it is irrelevant to the question of dominance that the recessive allele produces a more extreme [Phe phenotype.
For a third allele C, a CC homozygote produces a very small amount of PAH enzyme, which results in a somewhat elevated level of [Phe] in the blood, a condition called hyperphenylalaninemia, which does not result in intellectual disability.
That is, the dominance relationships of any two alleles may vary according to which aspect of the phenotype is under consideration. It is typically more useful to talk about the phenotypic consequences of the allelic interactions involved in any genotype, rather than to try to force them into dominant and recessive categories.

</doc>
<doc id="68301" url="https://en.wikipedia.org/wiki?curid=68301" title="Hijab">
Hijab

A hijab or (, , or ; , or ) is a veil that covers the head and chest, which is particularly worn by some Muslim women beyond the age of puberty in the presence of adult males outside of their immediate family and non-muslims. It can further refer to any head, face, or body covering worn by Muslim women that conforms to a certain standard of modesty. Hijab can also be used to refer to the seclusion of women from men in the public sphere, or it may embody a metaphysical dimension – "Al-hijab" refers to "the veil which separates man or the world from God".
Most often, it is worn by Muslim women as a symbol of modesty, privacy, and morality. According to the "Encyclopedia of Islam and Muslim World," modesty in the Quran concerns both men's and women's "gaze, gait, garments, and genitalia." The Qur'an admonishes Muslim women to dress modestly. Most Islamic legal systems define this type of modest dressing as covering everything except the face and hands in public. These guidelines (for covering of the entire body except for the hands, the feet and the face) are found in texts of fiqh and hadith developed after the revelation of the Qur'an but, according to some, are derived from the verses (ayahs) referencing hijab in the Qur'an. Many believe that the Qur'an itself does not mandate that women wear hijab.
The term "hijab" in Arabic literally means “a screen or curtain” and is used in the Qur'an to refer to a partition. The Qur'an tells the male believers (Muslims) to talk to the wives of Muhammad behind a curtain. This curtain was the responsibility of the men and not the wives of Muhammad. This leads some to claim that the mandate of the Qur'an to wear hijab applies to the wives of Muhammad, not women generally.
Αlthough hijab is often seen by critics as a tool utilized by men to control and silence women, the practice is understood differently in different contexts.
In Islamic texts.
Quran.
The Quran instructs both Muslim men and women to dress in a modest way, but it doesn't insist on covering the head:
"Tell the believing men to lower their gaze and be modest" (surah 24:30)
The clearest verse on the requirement of the hijab is surah 24:30–31, asking women to draw their "khimār" over their bosoms.
In the following verse, the wives of Muhammad are asked to wear clothes (when they go out), as a measure to distinguish themselves from others, so that they are not harassed. Surah 33:59 reads:
Alternative views.
Some Muslims take a relativist approach to hijab. They believe that the commandment to maintain "modesty" must be interpreted with regard to the surrounding society. What is considered modest or daring in one society might not be considered so in another. It is important, they say, for believers to wear clothing that communicates modesty and reserve.
Along with scriptural arguments, Leila Ahmed argues that head covering should not be compulsory in Islam because the veil predates the revelation of the Qur'an. Head-covering was introduced into Arabia long before Muhammad, primarily through Arab contacts with Syria and Iran, where the hijab was a sign of social status. After all, only a woman who need not work in the fields could afford to remain secluded and veiled.
Ahmed argues for a more liberal approach to hijab. Among her arguments is that while some Qur'anic verses enjoin women in general to "draw their Jilbabs (overgarment or cloak) around them to be recognized as believers and so that no harm will come to them" and "guard their private parts... and drape down "khimar" over their breasts in the presence of unrelated men", they urge modesty. The word "khimar" refers to a piece of cloth that covers the head, or headscarf. While the term "hijab" was originally anything that was used to conceal, it became used to refer to concealing garments worn by women outside the house, specifically the headscarf or khimar.
Other verses do mention separation of men and women.
According to at least three authors (Karen Armstrong, Reza Aslan and Leila Ahmed), the stipulations of the hijab were originally meant only for Muhammad's wives, and were intended to maintain their inviolability. This was because Muhammad conducted all religious and civic affairs in the mosque adjacent to his home:
According to Ahmed: 
They argue that the term "darabat al-hijab" ("taking the veil"), was used synonymously and interchangeably with "becoming Prophet Muhammad's wife", and that during Muhammad's life, no other Muslim woman wore the hijab. Aslan suggests that Muslim women started to wear the hijab to emulate Muhammad's wives, who are revered as "Mothers of the Believers" in Islam, and states "there was no tradition of veiling until around 627 C.E." in the Muslim community.
Another interpretation differing from the traditional states that a veil is not compulsory in front of blind men and men lacking physical desire.
Hadith.
The Arabic word "jilbab" is translated as "cloak" in the following passage. Contemporary "Salafis" insist that the "jilbab" (which is worn over the Kimaar and covers from the head to the toe) worn today is the same garment mentioned in the Qur'an and the "hadith"; other translators have chosen to use less specific terms:
Dress code required by hijab.
Traditionally, Muslims have recognized many different forms of clothing as satisfying the demands of "hijab". Debate focused on how much of the male or female body should be covered. Different scholars adopted different interpretations of the original texts.
Women.
Detailed scholarly attention has focused on prescribing female dress in conformity with hijab. The four major Sunni schools of thought (Hanafi, Shafi'i, Maliki and Hanbali) hold that the entire body of the woman, except her face and hands – though a few clerics say face, hands – must be covered during prayer and in public settings (see Awrah). There are those who allow the feet to be uncovered as well as the hands and face.
It is recommended that women wear clothing that is not form fitting to the body: either modest forms of western clothing (long shirts and skirts), or the more traditional "jilbāb", a high-necked, loose robe that covers the arms and legs. A "khimār" or "shaylah", a scarf or cowl that covers all but the face, is also worn in many different styles. Some scholars encourage covering the face, while some follow the opinion that it is only not obligatory to cover the face and the hands but mustahab (Highly recommended). Other scholars oppose face covering, particularly in the West, where the woman may draw more attention as a result. These garments are very different in cut from most of the traditional forms of "ħijāb", and they are worn worldwide by Muslims.
Many Muslim scholars believe that it is a basic requirement of Islamic law that women keep their hair and bodies covered in the presence of people of the opposite sex other than close family members (those close enough to be forbidden to marry—see "mahram"). These include the Iraqi Shia Marja' (Grand Ayatollah) Ali al-Sistani; the Sunni Permanent Committee for Islamic Research and Issuing Fatwas in Saudi Arabia; and others. According to some interpretations, these requirements extend to non-Muslim women as well. Some believers go so far as to specify exactly which areas of the body must be covered. In some cases, this is everything but the eyes, but most require that women cover everything but the face and hands. In nearly all Muslim cultures, young girls are not required to wear a ħijāb. There is not a single agreed age when a woman should begin wearing a ħijāb—but in many Muslim cultures, puberty is the dividing line.
In private, and in the presence of close relatives ("mahrams"), rules on dress relax. However, in the presence of the husband, most scholars stress the importance of mutual freedom and pleasure of the husband and wife.
Garments.
The "burqa" (also spelled burka) is the garment that covers women most completely: either only the eyes are visible, or nothing at all. Originating in what is now Pakistan, it is more commonly associated with the Afghan chadri. Typically, a "burqa" is composed of many yards of light material pleated around a cap that fits over the top of the head, or a scarf over the face (save the eyes). This type of veil is cultural as limited to the people of that part of the world.
It has become tradition that Muslims in general, and Salafis in particular, believe the Qur'an demands women wear the garments known today as "jilbāb" and "khumūr" (the "khumūr" must be worn underneath the "jilbāb"). However, Qur'an translators and commentators translate the Arabic into English words with a general meaning, such as veils, head-coverings and shawls. Ghamidi argues that verses teach etiquette for male and female interactions, where "khumūr" is mentioned in reference to the clothing of Arab women in the 7th century, but there is no command to actually wear them in any specific way. Hence he considers head-covering a preferable practice but not a directive of the sharia (law).
Men.
Although certain general standards are widely accepted, there has been little interest in narrowly prescribing what constitutes modest dress for Muslim men. Many scholars recommend that men should cover themselves from the navel to the knees. It is also widely accepted that male clothes should not be tight-fitting or "glamorous".
According to some sources, Muslim men should not wear gold jewelry, silk clothing, or adornments that are considered feminine.
Fadwa El Guindi, a prominent Islamic scholar, writes, “Confining the study of the veil, just like the study of women, to the domain of gender in lieu of society and culture narrows the scope in a way that limits cultural understanding and theoretical conceptualization” 
Sartorial hijab as practiced.
In Iran, where wearing the hijab is legally required, women, especially younger ones, have taken to wearing transparent and very loosely worn hijabs.
In Turkey, where the hijab was formerly banned in private and state universities and schools, 11% of women once wore it, though 60% wore traditional non-Islamic headscarves, figures of which are often confused with hijab. However, the ban was lifted from universities in 2011, from government buildings in 2013, and from schools in 2014.
Historical and cultural explanations.
History.
The term "hijab" is never used in the Qur'an to describe an article of clothing. The only verses in the Qur'an that specifically reference women’s clothing, are those promoting modesty, instructing women to guard their private parts and throw a scarf over their bosoms in the presence of men. The contemporary understanding of the hijab dates back to Hadith when the “verse of the hijab” descended upon the community in 627 CE. Now documented in Sura 33: 53 the verse states, “And when you ask wives for something, ask them from behind a partition. That is purer for your hearts and their hearts”. This verse, however, was not addressed to women in general, but exclusively to Muhammad’s wives. As Muhammad’s influence increased, he entertained more and more visitors in the mosque, which was then his home. Often, these visitors stayed the night only feet away from his wives’ apartments. It is commonly understood that this verse was intended to protect his wives from these strangers. During Muhammad’s lifetime no other women in the Ummah (Muslim community) observed the hijab. Instead, the term for donning the veil, "darabat al-hijab", was used interchangeably with “becoming Muhammad’s wife”. As stated by Reza Aslan, “The veil was neither compulsory nor widely adopted until generations after Muhammad’s death, when a large body of male scriptural and legal scholars began using their religious and political authority to regain the dominance they had lost in society as a result of the Prophet’s egalitarian reforms”. Other scholars point out that the Qur'an does not require women to wear veils; rather, it was a social habit picked up with the expansion of Islam. In fact, since it was impractical for working women to wear veils, "A veiled woman silently announced that her husband was rich enough to keep her idle."
Pre-Islamic Veiling Practices.
Veiling did not originate with the advent of Islam. Statuettes depicting veiled priestesses precede all three Abrahamic religions (Christianity, Judaism, and Islam), dating back as far as 2500 BCE. Elite women in ancient Mesopotamia and in the Byzantine, Greek, and Persian empires wore the veil as a sign of respectability and high status. In ancient Mesopotamia, Assyria had explicit sumptuary laws detailing which women must veil and which women must not, depending upon the woman’s class, rank, and occupation in society. Veiling was meant to “differentiate between ‘respectable’ women and those who were publicly available”. Female slaves and unchaste women were explicitly forbidden to veil and suffered harsh penalties if they did so. Veiling was thus a marker of rank and exclusive lifestyle, subtly illustrating upper-class women’s privilege over women in lower classes in the Assyrian community.
Strict seclusion and the veiling of matrons were in place in Roman and Byzantine society as well. Between 550 and 323 B.C.E, prior to Christianity, respectable women in classical Greek society were expected to seclude themselves and wear clothing that concealed them from the eyes of strange men. These customs influenced the later Byzantine empire where proper conduct for girls entailed that they be neither seen nor heard outside their home. Like in Assyrian law, respectable women were expected to veil and low-class women were forbidden from partaking in the practice. In Classical Rome, the Emperor Augustus encouraged his citizens all around the Mediterranean to enter temples "capo velato" literally "with their heads veiled", by which he intended clothing that did not differ much from traditional Saudi clothing for men and women today. Augustus himself appeared like this in propaganda pictures and temple portraits (see the Ara Pacis temple in Rome). The Romans were embedded in a larger Mediterranean/Middle Eastern milieu with roots in Mesopotamia (Iraq) and Egypt, and they transmitted this legacy to both the eastern and western parts of the Roman Empire, which today constitute approximately the Muslim Mediterranean (and parts of the Middle East) and Europe.
By the 5th and 6th centuries, societies of the Mediterranean Middle East were dominated by Christian and some Jewish populations. At the inception of Christianity, Jewish women were veiling the head and face. In Judaic scripture, , and are references in the Old Testament refer to a headcovering for women. Although there is no positive command for women to cover their heads in the Old Testament, there are non-canonical rabbinical writings on "tzniut", meaning "modesty".
There is also a tradition of Christian headcovering for women, rooted in and supported by various early Church Fathers Early Christian art shows women wearing headcoverings. During the ensuing centuries, women wore headcoverings during the meetings of the church, but the style of the covering varied. The practice of head-covering gradually disappeared from most churches over the course of the twentieth century, but still persists in the form of nuns "taking the veil," and many orders of nuns' religious habits resemble the chador, the full-body cloak that leaves only the face exposed, which is worn as a form of hijab by some women, particularly in Iran. Some think that the word "habarah" (a complex cloak and veil traditional in Egypt) itself derives from early Christian and Judaic religious vocabulary.” Scholar Leila Ahmed argues that “Whatever the cultural source or sources, a fierce misogyny was a distinct ingredient of Mediterranean and eventually Christian thought in the centuries immediately preceding the rise of Islam.”
During the period directly preceding the Muslim conquest in 640 CE, the Sassanids ruled in Mesopotamia. Customs of Persian royalty at the time of the first Persian conquest of Mesopotamia continued to be practiced and became even more elaborate under the Sassanids. In addition to acknowledging the monotheistic religion of Zoroastrianism among the upper classes, such customs included large harems of women and, of most note for this article, veiling. Some scholars postulate that the customs of veiling and seclusion of women in early Islam were assimilated from the conquered Persian and Byzantine societies and then later on they were viewed as appropriate expressions of Quranic norms and values.
Thus, successive invasions during the Muslim conquest led to some synthesis in the cultural practices of Greek, Persian, and Mesopotamian empires and the Semitic peoples of the regions. Because Islam identified with the monotheistic religions of the conquered empires, the practice was adopted as an appropriate expression of Qur'anic ideals regarding modesty and piety. Veiling gradually spread to upper-class Arab women, and eventually it became widespread among Muslim women in cities throughout the Middle East. It gradually spread among urban populations, becoming more pervasive under Ottoman rule as a mark of rank and exclusive lifestyle. Women in rural areas were much slower to adopt veiling because the garments interfered with their work in the fields.
The mid-twentieth century saw a resurgence of the hijab in Egypt after a long period of decline as a result of the westernization of Egypt under the rule of Gamal Abdel Nasser. The hijab, veil, often taken to mean suppression of the Islamic woman, began to symbolize a commitment to "the service of the Islamic call help devastated families." The veil became a liberating symbol of being an Islamic woman with a cause for social justice.
Overall, the hijab is meant to highlight the individual’s relationship with Allah. Many scholars believe that the hijab was a source of separation, in which to allow Muhammad’s wives to find oneness with Allah.
Contemporary context.
The mid-1970s marked a period in which college aged Muslim men and women began a movement meant to reunite and rededicate themselves to the Islamic faith. This movement was named the Sahwah, or awakening, and was and sparked a period of heightened religiosity that spread across the east that was evident in every aspect of the believers life through the ways in which they chose to dress themselves. The uniform adopted by the young female pioneers of this movement was named al-Islāmī (Islamic dress) and was made up of an “al-jilbāb—an unfitted, long-sleeved, ankle-length gown in austere solid colors and thick opaque fabric—and al-khimār, a head cover resembling a nun's wimple that covers the hair low to the forehead, comes under the chin to conceal the neck, and falls down over the chest and back”. In addition to the basic garments that were mostly universal within the movement, additional measures of modesty could be taken depending on how conservative the followers wished to be. Some women choose to also utilize a face covering (al-niqāb) that leaves only eye slits for sight, as well as both gloves and socks in order to reveal no visible skin.
Soon this movement expanded outside of the youth realm and became a more widespread Muslim practice. Women viewed this way of dress as a way to both publicly announce their religious beliefs as well as a way to simultaneously reject western influences of dress and culture that were prevalent at the time. Despite many criticisms of the practice of hijab being oppressive and detrimental to women’s equality, many Muslim women view the way of dress to be a positive thing. It is seen as a way to avoid harassment and unwanted sexual advances in public and works to desexualize women in the public sphere in order to instead allow them to enjoy equal rights of complete legal, economic, and political status. This modesty was not only demonstrated by their chosen way of dress but also by their serious demeanor which worked to show their dedication to modesty and Islamic beliefs.
Controversy erupted over the practice. Many people, both men and women from backgrounds of both Islamic and non-Islamic faith questioned the hijab and what it stood for in terms of women and their rights. There was questioning of whether in practice the hijab was truly a female choice or if women were being coerced or pressured into wearing it. Many instances, such as a period of forced veiling for women in Iran, brought these issues to the forefront and generated great debate from both scholars and everyday people.
As the awakening movement gained momentum, its goals matured and shifted from promoting modesty and Islamic identity towards more of a political stance in terms of retaining support for Islamic nationalism and to resist western influences. Today the hijab means many different things for different people. For Islamic women who choose to wear the hijab it allows them to retain their modesty, morals and freedom of choice. They choose to cover because they believe it is liberating and allows them to avoid harassment. Many people (both Muslim and non-Muslim) are against the wearing of the hijab and argue that the hijab causes issues with gender relations, works to silence and repress women both physically and metaphorically, and have many other problems with the practice. This difference in opinions has generated a plethora of discussion on the subject, both emotional and academic, which continues today.
Ever since September 11, 2001, the discussion and discourse on the hijab has intensified. Many nations have attempted to put restrictions on the hijab, which has led to a new wave of rebellion by women who instead turn to covering and wearing the hijab in even greater numbers. Some of the more notable events that have occurred in the recent past can be read about in the further reading section.
Modern practice.
Wearing the hijab in Kazakhstan is not prohibited, but is widely criticized as a foreign custom (the traditional scarf worn by Central Asian married women resemble the bandana, not the hijab), because it was not practiced until the fall of the USSR and the arrival of foreign Islamic missionaries.
Governmental enforcement and bans.
Some governments encourage and even oblige women to wear the hijab, while others have banned it in at least some public settings.
Some Muslims believe hijab covering for women should be compulsory as part of "sharia", i.e. Muslim law. Wearing of the hijab was enforced by the Taliban regime in Afghanistan. The Taliban's Islamic Emirate of Afghanistan required women to cover not only their head but their face as well, because "the face of a woman is a source of corruption" for men not related to them. Today, covering face by niqab is compulsory in many sacred places in the Kingdom of Saudi Arabia.
Turkey, Tunisia, and Tajikistan are Muslim-majority countries where the law prohibits the wearing of hijab in government buildings, schools, and universities. In Tunisia, women were banned from wearing hijab in state offices in 1981 and in the 1980s and 1990s more restrictions were put in place. In 2008 the Turkish government attempted to lift a ban on Muslim headscarves at universities, but were overturned by the country's Constitutional Court. Though in December 2010, the Turkish government ended the headscarf ban in universities.
Iran went from banning hijab in 1936 to making it compulsory in 1979. The tradition of veiling hair in Iranian culture has ancient pre-Islamic origins, but the widespread custom was forcibly ended by Reza Shah's regime in 1936, as it was incompatible with his modernizing ambitions. The police arrested women who wore the veil and would forcibly remove it, and these policies outraged the Shi'a clerics, and ordinary men and women, to whom appearing in public without their cover was tantamount to nakedness. Many women refused to leave the house out of fear of being assaulted by Reza Shah's police. Eventually rules of dress code were relaxed, and after Reza Shah's abdication in 1941 the compulsory element in the policy of unveiling was abandoned. According to Mohammad Reza Shah Pahlavi, between 1941 and 1979, wearing hejab was no longer offensive, but still considered it to be a real hindrance to climbing the social ladder, a badge of backwardness and a marker of class. A headscarf, let alone the chador, prejudiced the chances of advancement in work and society not only of working women but also of men, who were increasingly expected to appear with their wives at social functions. At the time of the overthrow of the Shah's regime after Iranian Revolution of 1979, Ayatollah Ruhollah Khomeini made a speech on the first International Women's Day declaring that women should wear the veil in state ministries. This led to widespread demonstrations in March of 1979 by women all across the country by women opposed to the imposition of the veil. However, legally-imposed veiling gradually took hold: women not covering their hair and body in hijab were first denied the right to enter governmental institutions and facilities, and hijab ultimately became universally mandatory in 1984. Under Penal Code provisions, women who refuse to wear the prescribed hijab will be sentenced to 72 lashes.
Some Iranian women wear their headscarves far back on their heads revealing most of their hair. More conservative types of hijab like kimars and chadors are still widespread in government institutions, mosques, sacred places and conservative areas.
On March 15, 2004, France passed a law banning "symbols or clothes through which students conspicuously display their religious affiliation" in public primary schools, middle schools, and secondary schools. In the Belgian city of Maaseik, "Niqāb" has been banned since 2006. On July 13, 2010, France's lower house of parliament overwhelmingly approved a bill that would ban wearing the Islamic full veil in public. There were 335 votes for the bill and one against in the 557-seat National Assembly.
In 2014 the Islamic State of Iraq and the Levant was reported to have executed several women for not wearing niqab with gloves.
In 2014 the Aceh Legislative Council passed Qanun Acara Jinayat (a sharia-based criminal procedures code) applying Islamic law to everyone in the province, including non-Muslims. This would compel non-Muslims to wear hijab. The bill is under national government review.
Non-governmental enforcement.
Non-governmental enforcement of hijab is found in many parts of the Muslim world.
Successful informal coercion of women by sectors of society to wear hijab has been reported in Gaza where Mujama' al-Islami, the predecessor of Hamas, reportedly used "a mixture of consent and coercion" to "'restore' hijab" on urban educated women in Gaza in the late 1970s and 1980s.
Similar behaviour was displayed by Hamas itself during the First Intifada in Palestine. Though a relatively small movement at this time, Hamas exploited the political vacuum left by perceived failures in strategy by the Palestinian factions to call for a 'return' to Islam as a path to success, a campaign that focused on the role of women. Hamas campaigned for the wearing of the hijab alongside other measures, including insisting women stay at home, segregation from men and the promotion of polygamy. In the course of this campaign women who chose not to wear the hijab were verbally and physically harassed, with the result that the hijab was being worn 'just to avoid problems on the streets'.
In Srinagar, India in 2001 an "acid attack on four young Muslim women ... by an unknown militant outfit followed by swift compliance by women of all ages on the issue of wearing the chadar (head-dress) in public."
Radicals in Gaza have been accused of attacking or threatening to attack the faces of women in an effort to intimidate them from wearing allegedly immodest dress.
World Hijab Day.
World Hijab Day is an annual event that takes place on February 1. The very first World Hijab Day was celebrated in 2013. Founded by Nazma Khan, it is a worldwide event that encourages Muslim and non-Muslim women to wear the hijab, and experience life of a Hijabi woman. This event showcases freedom and traditional aspect of hijab to the women of the 116 participating countries. In short, World Hijab Day is a way for the non-Hijabi woman to experience hijab from the other side.

</doc>
<doc id="68305" url="https://en.wikipedia.org/wiki?curid=68305" title="Chico and the Man">
Chico and the Man

Chico and the Man is an American sitcom which ran on NBC for four seasons, from September 13, 1974, to July 21, 1978. It stars Jack Albertson as Ed Brown (the Man), the cantankerous owner of a run down garage in an East Los Angeles barrio, and (until his suicide late in the third season) Freddie Prinze as Chico Rodriguez, an upbeat, optimistic young Chicano who comes in looking for a job. It was the first U.S. television series set in a Mexican-American neighborhood.
Conception.
Comedians Cheech Marin and Tommy Chong (better known as the comedic duo Cheech & Chong) have stated that series creator James Komack followed the comedians on tour for three months; Chong wrote in his 2009 book "Cheech & Chong: The Unauthorized Autobiography" that Komack based the show on Cheech and Chong skits titled "The Old Man in the Park" and "Pedro and Man" and had acknowledged that fact to Chong after the television series' release. Cheech and Chong have both stated that Komack had originally approached them to star in the show, but they turned down the offer, preferring to stick to films.
Komack told the Associated Press that he first tried working with Cheech and Chong on a show about a Chicano and a Nisei. Komack said he decided to make the show about a young Chicano and a "seventh-generation WASP" after he and the comedy team "couldn't get it together".
Synopsis.
A hard-drinking Anglo widower, Ed stubbornly refuses to fit in with the changing East L.A. neighborhood and has alienated most of the people who live around him. He uses ethnic slurs and berates Chico, a Latino, in an effort to get him to leave when Chico comes looking for a job. Yet Chico sees something in Ed, and sneaks back in at night to clean up the garage and move into an old van that Ed has parked inside. As Ed sees all the effort Chico has put in, he begins to warm to Chico. Over the course of the show, Ed grows to see Chico as family, although Ed denies this on several occasions.
The chemistry between Jack Albertson's "Ed" and Freddie Prinze's "Chico" was a major factor in making the show a hit in its first two seasons. It debuted in the top ten and remained there for the first two seasons.
The show was created by James Komack who produced other successful TV shows such as "The Courtship of Eddie's Father" and "Welcome Back, Kotter". Freddie Prinze was discovered by Komack after he appeared on "The Tonight Show Starring Johnny Carson" in December 1973. Komack thought he would be perfect for the role of Chico Rodriguez.
As the show progressed, Chico's background was revealed as being Mexican on his father's side and Puerto Rican on his mother's side, and (in a nod to Prinze's faux-Hungarian ancestry) "...my grandmother speaks a little Hungarian!" (though Prinze's paternal ancestry was actually German, in his stage-act he would claim his father was Hungarian, thereby allowing him to comically refer to himself as "Hungarican"). Chico was revealed to have spent part of his childhood in Hungary following the death of his mother, being raised by his Aunt Connie (a character who appeared in two other episodes). Chico attempts to explain his situation to Ed by portraying it as the dilemma of his distant cousin in Hungary, torn between the farmer for whom he now works and whom he has grown to love, and another farmer who has offered him a better job. During this scene and this episode, the love between these disparate characters was made clear for the first time, which Chico's cousin Carlos (played by actor Richard Yniguez) notes when he releases Chico from his promise. By the second season, Ed begins to see that he is a part of a bigger world, although he still complains about it. By this time he has found himself a girlfriend by the name of Flora (played by Carole Cook).
The theme song was written and performed by Jose Feliciano.
Freddie Prinze's death.
After struggling with depression and drug use, Freddie Prinze shot himself on January 28, 1977. He was taken off life support and died the following day at the age of 22.
The last episode to star Prinze, "Ed Talks to God", was taped several hours before Prinze's death.
Post-Prinze episodes.
After Prinze's death, the producers considered canceling the show, but opted instead to try replacing the character. To write Chico out of the script, they had the other characters comment that he had gone to visit his father in Mexico. The third season finished out with episodes focusing on the other characters in the show.
Early in the fourth season, a replacement for Chico was introduced. Instead of an adult, the producers brought in twelve-year-old Raul, played by Gabriel Melgar. His first appearance came when Ed and Louie go on a fishing trip to Tijuana and find the Mexican orphan hiding out in their trunk on their return. At the end of this episode, Ed is putting Raul to bed and accidentally calls him Chico. Raul corrects him and Ed remarks that, "You're all Chicos to me." Ed eventually adopts Raul, only to have Raul's overprotective aunt Charo – played by the singer Charo – come from Spain and try to become a part of the "family" as well.
A two-part episode ran in the final season in which Raul discovers Chico's belongings in a closet. Ed catches Raul playing Chico's guitar and Ed smashes it on the van in anger. Raul believes Ed does not love him anymore and runs away to Mexico. Ed goes after him and finally explains to Raul that Chico died, but did not say how, putting a measure of closure on the fate of Chico in the series.
Toward the end of the show's final season, actress Julie Hill was added to the cast as Monica, Ed's attractive 18-year-old adopted niece. She had come to Los Angeles to get into show business, and lived in Chico's old van while awaiting her big break. "Chico and the Man" did not pull in the ratings it did in previous seasons. The show's ratings declined after Prinze's death, and the show was canceled at the end of the fourth season.
Supporting cast.
The show also had a veteran and talented supporting cast. Scatman Crothers portrayed Louie Wilson, Ed's friend and garbage man; Bonnie Boland played Mabel, the mail lady; Isaac Ruiz portrayed Mando, Chico's friend; and Ronny Graham played Rev. Bemis. Also, Della Reese played Della Rogers, Ed's neighbor and landlady.
Notable guest stars.
Other notable guest stars included: 
Additionally, Jeannie Linero appeared in several episodes as one of Chico's more constant girlfriends, nurse Liz Garcia.
Syndication.
"Chico and the Man" was only shown in syndication in few markets and only for a relatively short period. It was briefly re-aired on NBC's morning schedule from May 9 to December 2, 1977. at 12:30p.m./11:30a.m. central time.
TV Land also aired reruns during 2001 as did ION Television in 2007. AmericanLife TV Network also aired this series previously, as well as WGN-TV in Chicago which aired first at 5pm, then later on moved it to 5am.
In Canada, the show previously appeared on Sun TV (CKXT-TV) in Toronto.
From 2005-2009, episodes of the show were available on AOL's now-defunct video website called 'In2TV'.
DVD release.
On September 27, 2005, six episodes of "Chico and the Man" were released on DVD as part of Warner Bros' Television Favorites Compilation and the episodes are as follows:
As of 2016, no full seasons have been released, nor is it known if any seasons will be released, and the Television Favorites DVD is now out of print.

</doc>
<doc id="68306" url="https://en.wikipedia.org/wiki?curid=68306" title="National Liberation Front">
National Liberation Front

National Liberation Front may refer to:
National Liberation Front may also refer to:

</doc>
<doc id="68308" url="https://en.wikipedia.org/wiki?curid=68308" title="Jack Albertson">
Jack Albertson

Jack Albertson (June 16, 1907 – November 25, 1981) was an American character actor who also performed in vaudeville. A comedian, dancer, singer and musician, Albertson is known for his roles as Grandpa Joe in "Willy Wonka & the Chocolate Factory" (1971), Manny Rosen in "The Poseidon Adventure" (1972), Amos Slade in "The Fox and the Hound" (1981) and Ed Brown in the television sitcom "Chico and the Man" (1974–78). For his contributions to the television industry, Albertson was honored with a star on the Hollywood Walk of Fame at 6253 Hollywood Boulevard. He earned the Academy Award for Best Supporting Actor for the "The Subject Was Roses" (1968).
Early life.
Jack Albertson was born on Sunday, June 16, 1909, in Malden, Massachusetts, the son of Russian-born Jewish immigrants Flora (née Craft) and Leopold Albertson. His older sister was actress Mabel Albertson. Albertson's mother, a stock actress, supported the family by working in a shoe factory. Until at least the age of 22, Albertson was known as "Harold Albertson".
Career.
Broadway.
Albertson worked in burlesque as a hoofer (soft shoe dancer) and straight man to Phil Silvers on the "Minsky's Burlesque Circuit". Besides vaudeville and burlesque, he appeared on the stage in many Broadway plays and musicals, including "High Button Shoes", "Top Banana", "The Cradle Will Rock", "Make Mine Manhattan", "Show Boat", "Boy Meets Girl", "Girl Crazy", "Meet the People", "The Sunshine Boys" – for which he received a Tony Award nomination for Best Actor, and "The Subject Was Roses" – for which he won a Tony for Best Supporting Actor.
Film.
Albertson appeared in more than thirty films. He had an early minor role in "Miracle on 34th Street" as a postal worker who redirects dead letters addressed to "Santa Claus" to the courthouse where Kris Kringle is on trial. He won an Academy Award for Best Supporting Actor for his role in the 1968 film "The Subject Was Roses". He later apologized to Jack Wild for winning the award; Wild was also nominated and Albertson expected Wild to win.
Albertson appeared as Charlie Bucket's Grandpa Joe in "Willy Wonka & the Chocolate Factory" (1971), and in "The Poseidon Adventure" (1972), where he played Manny Rosen, husband to Belle, played by Shelley Winters.
Albertson said that his one regret was that he did not reprise his role in the movie version of "The Sunshine Boys". When producer Ray Stark acquired the film rights from Neil Simon in 1973, it was expected that Albertson would play the part, but by the time MGM had bought the rights in 1974 and was preparing to begin filming in February 1975, Albertson was not available because he was appearing on "Chico and the Man" on TV.
Radio.
Albertson was a radio performer early in his career was known for appearing on two programs, "Just Plain Bill" and "The Jack Albertson Comedy Show". Later, he was for a time a regular on the "Milton Berle Show" in the late 1940s.
Television.
Albertson appeared in many television series, such as "Hey, Jeannie!" with Jeannie Carson; the syndicated western series "Frontier Doctor" with Rex Allen; Rod Cameron's syndicated crime drama "State Trooper"; and the 1961–62 drama series "Bus Stop". He guest-starred on the David Janssen crime drama series "Richard Diamond, Private Detective". 
From 1960-61, Albertson was cast in three episodes of "Pete and Gladys", with Harry Morgan and Cara Williams. On January 2, 1961, Albertson was cast as Sampson J. Binton, with DeForest Kelley as Alex Jeffords, in "Listen to the Nightingale", the series finale of "Riverboat", starring Darren McGavin. Albertson had a recurring role as the neighbor Walter Burton in eight episodes of the 1962 ABC sitcom "Room for One More", with Andrew Duggan and Peggy McCay. He had recurring roles in "Ensign O'Toole" (1962–63) and "Run, Buddy, Run" (1966).
Other 1960s series on which Albertson appeared were NBC's sitcom, "Happy" starring Ronnie Burns, and "Glynis", starring Glynis Johns and Keith Andes, which aired for 13 weeks in the fall of 1963. Albertson appeared in two episodes of "The Twilight Zone". In a 1967 episode of "The Andy Griffith Show", he played the n'er-do-well cousin, Bradford J. Taylor, of series character Aunt Bee (Frances Bavier). He co-starred as "The Man" Ed Brown in "Chico and the Man", with Freddie Prinze, for which he earned an Emmy.
Personal life and death.
He resided for many years in West Hollywood, California. In 1978, he was diagnosed with colorectal cancer, but kept this information private and continued to act. Two of his last roles were in the television movies, "My Body, My Child" (1982) and "Grandpa, Will You Run With Me?" (1983), both filmed in 1981 several months before his death, both of which were released posthumously. His final theatrical role was as the ill-tempered hunter, Amos Slade, in Walt Disney's 24th animated feature, "The Fox and the Hound", originally released in the summer of 1981, four months before his death. 
Jack Albertson eventually died on Wednesday, November 25, 1981, at the age of 74, after a three-year battle with colorectal cancer. He was survived by his wife, June (July 23, 1924–January 9, 2015) and his daughter Maura Dhu. He and his elder sister, Mabel Albertson, (who died ten months later from Alzheimer's disease), were cremated and their ashes were scattered in the Pacific Ocean.

</doc>
<doc id="68309" url="https://en.wikipedia.org/wiki?curid=68309" title="Q Public License">
Q Public License

The Q Public License (QPL) is a non-copyleft license, created by Trolltech for its free edition of the Qt. It was used until Qt 3.0, as Trolltech toolkit version 4.0 was released under GPL version 2.
It fails the Debian Free Software Guidelines, used by several Linux distributions, though it qualifies for the Free Software Foundation's Free Software Definition; however, it is not compatible with the FSF's GNU General Public License, meaning that products derived from code under both the GPL and the QPL cannot be redistributed.
History.
KDE, a desktop environment for Linux, is based on Qt. Only the personal edition of Qt was covered by the QPL; the commercial edition, which is functionally equal, is under a pay-per-use license and could not be freely distributed. Meanwhile, the Free Software Foundation and authors of the GPL objected to the QPL as it was a non-copyleft license incompatible with the GPL. As KDE grew in popularity, the free software community urged Trolltech to put Qt under a license (the QPL) that would assure that it would remain free software forever and could be used and developed by commercial third parties. Eventually, under pressure, Trolltech dual-licensed Qt for use under the terms of the GPL or the QPL.
Adoption.
Other projects that have adopted the Q Public License, sometimes with a change in the choice of jurisdiction clause, include:
The Debian project rejects software covered by solely QPL (and not dual licensed with something else like the GPL) because of:
Compliance.
All legal disputes about the license are settled in Oslo, Norway, but it has never been legally contested.

</doc>
<doc id="68311" url="https://en.wikipedia.org/wiki?curid=68311" title="Eurovision Song Contest 1956">
Eurovision Song Contest 1956

The Eurovision Song Contest 1956 was the debut edition of the Eurovision Song Contest, held at the Teatro Kursaal in Lugano, Switzerland on Thursday 24 May. Organised by the European Broadcasting Union, the pan-European music competition was an inspiration of the Italian Sanremo Music Festival. Lohengrin Filipello hosted the first contest which lasted approximately 1 hour and 40 minutes. Seven countries participated, with each of them performing two songs. Two jury members from all participating countries cast their votes in secret, based on which song was their favourite. Lys Assia won the contest for the host country Switzerland with the song "Refrain".
This first edition of the Eurovision Song Contest included several procedures that were not repeated in any subsequent edition: Two songs for each country, secret voting, double voting of one country on behalf of another, optional inclusion of the jury members' own represented country in their voting, only "Grand Prix" title reception for the winner, and a single male presenter to host the show. The other Contests include: One song for each country, scoreboard display, jury panel from each country, disqualification of the juries' own country from their voting, material award, and a single or additional female presenter.
History.
During a meeting in Monaco in 1955, members of the European Broadcasting Union discussed ideas to organise a pan-European music competition, taking inspiration from the Italian Sanremo Music Festival. From that meeting, the concept of the Eurovision Song Contest was born. A decision was reached to hold the first ever contest in the Swiss resort of Lugano the following year.
Location.
The chosen venue for the contest was the Teatro Kursaal in Lugano, a city in the south of Switzerland, in the Italian-speaking canton of Ticino, which borders Italy. The event was also inspired by the Italian music festival, as well as that the contest was hosted in Italian.
Format.
The first programme was hosted by Lohengrin Filipello and lasted approximately 1 hour and 40 minutes. Although it was mainly a radio programme, there were cameras in the studio for the benefit of the few Europeans who possessed a television.
Only solo artists were allowed to enter the contest, and their songs were not to exceed three and a half minutes in length, and were accompanied by a 24-musician orchestra, which was led by Fernando Paggi. The interval act, whistling by the Joyeux Rossignols, had to be extended due to a delay in the voting procedure. It had been strongly recommended that each participating country have a preliminary national song contest.
Voting controversy.
Two jury members from all participating countries travelled to Lugano to cast their vote on the songs in secret, although the jury members from Luxembourg were unable to make it to Lugano. The voting system at this Contest allowed juries to vote for any competing song, including those of their own country. Additionally, the Swiss jury was allowed by the EBU to vote on behalf of the Luxembourg delegation. This system was never repeated.
Lost tapes.
While the contest was shown and recorded for television broadcasting in certain European countries (as television sets were somewhat uncommon still at this time), no copies have survived, with the exception of Lys Assia's repeat performance at the end of the contest. It is one of only two contests to not have survived completely, along with the 1964 contest (of which the tapes were destroyed in a fire).
Participating countries.
Seven countries participated in the first ever contest, each were represented with two songs. Three more countries, Austria, Denmark, and United Kingdom were also expected to take part in the contest, but they missed the submission deadline and therefore could not take part. The BBC's Festival of British Popular Song, which had been intended to choose the United Kingdom entry, was in the end not held until after the Eurovision contest.
Conductors.
Each performance had a conductor who maestro the orchestra. The conductors listed conducted both performances for the indicated countries.
Results.
Except for the winning song, the results have never been published. Simon Barclay's book "The Complete and Independent Guide to the Eurovision Song Contest 2010" includes a table with what appears to be the results, but the author does not give a source and under the chart he writes that "the votes awarded have never been disclosed."
International broadcasts.
The participating national broadcasters sent commentators to the contest, in order to provide coverage of the contest in their own native language. Details of the commentators and the broadcasting station for which they represented are shown in the table below.

</doc>
<doc id="68314" url="https://en.wikipedia.org/wiki?curid=68314" title="Temple name">
Temple name

Temple names are commonly used when naming most Chinese, Korean (Goryeo and Joseon periods), and Vietnamese (such dynasties as Trần, Lý, and Lê) royalty. They should not be confused with era names. Compared to posthumous names, the use of temple names is more exclusive. Both titles were given after death to an emperor or king, but unlike the often elaborate posthumous name, a temple name almost always consists of only two characters:
The "temple" in "temple name" refers to the "grand temple" (太廟), also called "great temple" (大廟) or "ancestral temple" (祖廟), where crown princes and other royalty gathered to worship their ancestors. The ancestral tablets in the grand temple recorded the temple names of the rulers.
At earlier time only rulers performed have temple names, such as Taihao (太昊). Temple names were assigned sporadically from the Han Dynasty and regularly from the Tang Dynasty. Some Han emperors had their temple names permanently removed by their descendants in 190. They are the usual way to refer to emperors from the Tang Dynasty up to (but not including) the Ming Dynasty. For the Ming Dynasty and Qing Dynasty (from 1368), era names were used instead.
In Korea, temple names are used to refer to kings of the early Goryeo (until 1274), and kings and emperors of the Joseon Dynasty. For the Korean Empire (1897–1910), era names should be used, but the temple names are often used instead.
In Vietnam, most rulers are known by their temple names, with the exception of Tây Sơn and Nguyễn Dynasty rulers, who are more well known by their era names.

</doc>
<doc id="68315" url="https://en.wikipedia.org/wiki?curid=68315" title="Protagonist">
Protagonist

The word protagonist () has more than one definition which can be found in the dictionary. It is used notably in stories and forms of literature and culture that contain stories, which would include dramas, novels, operas and films. In those forms the definition may simply be the leading actor, or the principal character in the story. But in addition the word takes on more formalized definitions. For example, the protagonist, while still defined as a leading character, may also be defined as the character whose fate is most closely followed by the reader or audience, and who is opposed by a character known as the antagonist. The antagonist will provide obstacles and complications for the protagonist; the antagonist will create conflict, which will test the protagonist — thus revealing the strengths and weaknesses of their character.
The protagonist should be at the center of the story, should be making the difficult choices and key decisions, and should be experiencing the consequences of those decisions. The protagonist should be propelling the story forward. There are variations in the use of the protagonist. For example, if a story contains a subplot, or is a narrative that is made up of several stories, then there may be a character who is interpreted as the protagonist of each subplot or individual story.
Ancient Greece.
The earliest known examples of protagonist are dated back to Ancient Greece. At first performances involved merely dancing and recitation by the chorus. But then in "Poetics", Aristotle describes how a poet named Thespis introduced the idea of having one actor step out and engage in a dialogue with the chorus. This was the invention of tragedy, which occurred about 536 B.C. Then the poet Aeschylus, in his plays, introduced a second actor, inventing the idea of dialogue between two characters. Sophocles then wrote plays that required a third actor.
Examples.
Euripides' play, "Hippolytus", may be considered to have two protagonists. The protagonist of the first half is Phaedra, until she dies. Then her stepson, the title character, Hippolytus, has the dominant role in the second half.
In Ibsen’s play, "The Master Builder", the protagonist is the architect Halvard Solness. The young woman, Hilda Wangel, whose actions lead to the death of Solness, is the antagonist.
In Shakespeare’s play, "Romeo and Juliet", Romeo is the protagonist. He is actively in pursuit of his relationship with Juliet, and the audience is invested in that story. The character of Tybalt opposes Romeo’s desires, he is the antagonist.
In Shakespeare’s play, "Hamlet", Prince Hamlet, who seeks revenge for the murder of his father, is the protagonist. The antagonist would be the character who most opposes Hamlet, Claudius.
In the novel, "The Catcher in the Rye", the character Holden Caulfield is the protagonist. He is the leading character, and the reader is invested in his story.
Sometimes, a work will have a false protagonist, who may seem to be the protagonist, but then may disappear unexpectedly. The character Marion in Alfred Hitchcock's film "Psycho" (1960) is an example.
A novel that contains a number of narratives, may have a number of protagonists. Alexander Solzhenitsyn's "The First Circle", for example, depicts a variety of characters imprisoned and living in a gulag camp. Leo Tolstoy's "War and Peace", depicts fifteen major characters involved in or affected by a war.

</doc>
<doc id="68316" url="https://en.wikipedia.org/wiki?curid=68316" title="Heat pump">
Heat pump

A heat pump is a device that provides heat energy from a source of heat to a destination called a "heat sink". Heat pumps are designed to move thermal energy opposite to the direction of spontaneous heat flow by absorbing heat from a cold space and releasing it to a warmer one. A heat pump uses some amount of external power to accomplish the work of transferring energy from the heat source to the heat sink.
While air conditioners and freezers are familiar examples of heat pumps, the term "heat pump" is more general and applies to many HVAC (heating, ventilating, and air conditioning) devices used for space heating or space cooling. When a heat pump is used for heating, it employs the same basic refrigeration-type cycle used by an air conditioner or a refrigerator, but in the opposite direction - releasing heat into the conditioned space rather than the surrounding environment. In this use, heat pumps generally draw heat from the cooler external air or from the ground. In heating mode, heat pumps are three to four times more efficient in their use of electric power than simple electrical resistance heaters. Typically installed cost for a heat pump is about 20 times greater than for resistance heaters.
Overview.
In heating, ventilation and air conditioning (HVAC) applications, the term "heat pump" usually refers to easily reversible vapor-compression refrigeration devices optimized for high efficiency in both directions of thermal energy transfer.
Heat spontaneously flows from warmer places to colder spaces. A heat pump can absorb heat from a cold space and release it to a warmer one. "Heat" is not conserved in this process, which requires some amount of external high grade (low-entropy) energy, such as electricity.
Heat pumps are used to provide heating because less high-grade energy is required for their operation than appears in the released heat. Most of the energy for heating comes from the external environment, and only a fraction comes from electricity (or some other high-grade energy source required to run a compressor). In electrically powered heat pumps, the heat transferred can be three or four times larger than the electrical power consumed, giving the system a coefficient of performance (COP) of 3 or 4, as opposed to a COP of 1 for a conventional electrical resistance heater, in which all heat is produced from input electrical energy.
Heat pumps use a refrigerant as an intermediate fluid to absorb heat where it vaporizes, in the evaporator, and then to release heat where the refrigerant condenses, in the condenser. The refrigerant flows through insulated pipes between the evaporator and the condenser, allowing for efficient thermal energy transfer at relatively long distances.
Reversible heat pumps.
Reversible heat pumps work in either thermal direction to provide heating or cooling to the internal space. They employ a reversing valve to reverse the flow of refrigerant from the compressor through the condenser and evaporation coils.
Operating principles.
Mechanical heat pumps exploit the physical properties of a volatile evaporating and condensing fluid known as a refrigerant. The heat pump compresses the refrigerant to make it hotter on the side to be warmed, and releases the pressure at the side where heat is absorbed. 
The working fluid, in its gaseous state, is pressurized and circulated through the system by a compressor. On the discharge side of the compressor, the now hot and highly pressurized vapor is cooled in a heat exchanger, called a condenser, until it condenses into a high pressure, moderate temperature liquid. The condensed refrigerant then passes through a pressure-lowering device also called a metering device. This may be an expansion valve, capillary tube, or possibly a work-extracting device such as a turbine. The low pressure liquid refrigerant then enters another heat exchanger, the evaporator, in which the fluid absorbs heat and boils. The refrigerant then returns to the compressor and the cycle is repeated.
It is essential that the refrigerant reaches a sufficiently high temperature, when compressed, to release heat through the "hot" heat exchanger (the condenser). Similarly, the fluid must reach a sufficiently low temperature when allowed to expand, or else heat cannot flow from the ambient cold region into the fluid in the cold heat exchanger (the evaporator). In particular, the pressure difference must be great enough for the fluid to condense at the hot side and still evaporate in the lower pressure region at the cold side. The greater the temperature difference, the greater the required pressure difference, and consequently the more energy needed to compress the fluid. Thus, as with all heat pumps, the coefficient of performance (amount of thermal energy moved per unit of input work required) decreases with increasing temperature difference.
Insulation is used to reduce the work and energy required to achieve a low enough temperature in the space to be cooled.
To operate in different temperature conditions, different refrigerants are available. Refrigerators, air conditioners, and some heating systems are common applications that use this technology.
Heat transport.
Heat is typically transported through engineered heating or cooling systems by using a flowing gas or liquid. Air is sometimes used, but quickly becomes impractical under many circumstances because it requires large ducts to transfer relatively small amounts of heat. In systems using refrigerant, this working fluid can also be used to transport heat a considerable distance, though this can become impractical because of increased risk of expensive refrigerant leakage. When large amounts of heat are to be transported, water is typically used, often supplemented with antifreeze, corrosion inhibitors, and other additives.
Heat sources/sinks.
A common source or sink for heat in smaller installations is the outside air, as used by an air-source heat pump. A fan is needed to improve heat exchange efficiency.
Larger installations handling more heat, or in tight physical spaces, often use water-source heat pumps. The heat is sourced or rejected in water flow, which can carry much larger amounts of heat through a given pipe or duct cross-section than air flow can carry. The water may be heated at a remote location by boilers, solar energy, or other means. Alternatively when needed, the water may be cooled by using a cooling tower, or discharged into a large body of water, such as a lake, stream or an ocean.
Geothermal heat pumps or ground-source heat pumps use shallow underground heat exchangers as a heat source or sink, and water as the heat transport medium. This is possible because below ground level, the temperature is relatively constant across the seasons, and the earth can provide or absorb a large amount of heat. Ground source heat pumps work in the same way as air-source heat pumps, but exchange heat with the ground via water pumped through pipes in the ground. Ground source heat pumps are more simple and therefore more reliable than air source heat pumps as they do not need fan or defrosting systems and can be housed inside. Although a ground heat exchanger requires a higher initial capital cost, the annual running costs are lower, because well-designed ground source heat pump systems operate more efficiently.
Heat pump installations may be installed alongside an auxiliary conventional heat source such as electrical resistance heaters, or oil or gas combustion. The auxiliary source is installed to meet peak heating loads, or to provide a back-up system.
Applications.
There are millions of domestic installations using common air source electric heat pumps. They are used in climates with moderate space heating and cooling needs (HVAC) and may also provide domestic hot water. The purchase costs are supported in various countries by consumer rebates.
HVAC.
In HVAC applications, a heat pump is typically a vapor-compression refrigeration device that includes a reversing valve and optimized heat exchangers so that the direction of "heat flow" (thermal energy movement) may be reversed. The reversing valve switches the direction of refrigerant through the cycle and therefore the heat pump may deliver either heating or cooling to a building. In cooler climates, the default setting of the reversing valve is heating. The default setting in warmer climates is cooling. Because the two heat exchangers, the condenser and evaporator, must swap functions, they are optimized to perform adequately in both modes. Therefore, the efficiency of a reversible heat pump is typically slightly less than two separately optimized machines.
Plumbing.
In plumbing applications, a heat pump is sometimes used to heat or preheat water for swimming pools or domestic water heaters; the heat energy removed from an air-conditioned space may be recovered for heating water.
District heating.
Commissioned in 2011 this district heating extracts heat from a fjord whose temperature is around 8 °C using 3 systems giving a combined capacity of 14 megawatts to town center residences and businesses. A city ordinance mandates this heating system for many new buildings.
Refrigerants.
Until the 1990s, the refrigerants were often chlorofluorocarbons such as R-12 (dichlorodifluoromethane), one in a class of several refrigerants using the brand name Freon, a trademark of DuPont. Its manufacture was discontinued in 1995 because of the damage that CFCs cause to the ozone layer if released into the atmosphere needed.
One widely adopted replacement refrigerant is the hydrofluorocarbon (HFC) known as R-134a (1,1,1,2-tetrafluoroethane). Heat pumps using R-134a are not as efficient as those using R-12 that they replace (in automotive applications) and therefore, more energy is required to operate systems utilizing R-134a than those using R-12. Other substances such as liquid R-717 ammonia are widely used in large-scale systems, or occasionally the less corrosive but more flammable propane or butane, can also be used.
Since 2001, carbon dioxide, R-744, has increasingly been used, utilizing the transcritical cycle, although it requires much higher working pressures. In residential and commercial applications, the hydrochlorofluorocarbon (HCFC) R-22 is still widely used, however, HFC R-410A does not deplete the ozone layer and is being used more frequently; however, it is a powerful greenhouse gas which contributes to climate change. Hydrogen, helium, nitrogen, or plain air is used in the Stirling cycle, providing the maximum number of options in environmentally friendly gases.
More recent refrigerators use R600A which is isobutane, and does not deplete the ozone and is friendly to the environment.
Dimethyl ether (DME) is also gaining popularity as a refrigerant.
Noise.
Both indoor and outdoor heat pump units contain moving mechanical components which produce noise. In 2013, the CEN started work on standards for protection from noise pollution caused by heat pump outdoor units. Although the CEN/TC 113 Business Plan outset was that "consumers increasingly require a low acoustic power of these units as the users and their neighbours now reject noisy installations", no standards for noise barriers or other means of noise protection were developed by January 2016.
Noise from outdoor units sometimes exceeds noise levels permitted by the legislation. For example, the 2015 data sheet of "Mr Slim" Zubadan Inverter Heat Pump informs whoever reads it, including the pump's owner neighbors, that Mr Slim's outdoor unit generates 52 dB(A) in the heating mode. This is more than permitted by legislation in some countries, for example UK, where this or similar pumps are used. Another example is Poland, where the noise level permitted in residential areas is 40 dB at night, which is more than the UK limit (35 dB), but still makes Mr Slim's outdoor unit 12 dB beyond the limit. In the United States, the allowed nighttime noise level was defined in 1974 as "an average 24-hr exposure limit of 55 A-weighted decibels (dBA) to protect the public from all adverse effects on health and welfare in residential areas (U.S. EPA 1974). This limit is a day–night 24-hr average noise level (LDN), with a 10-dBA penalty applied to nighttime levels between 2200 and 0700 hours to account for sleep disruption and no penalty applied to daytime levels. The 10-dB(A) penalty makes the permitted U.S. nighttime noise level equal to 45 dB(A) which is more than what is accepted in some European countries but less than the noise produced by some heat pumps.
Therefore, it is important to pay special attention to those heat pumps which are advertised as being extremely efficient and generating noise at a very low level, supposedly, at the same time. The simultaneousity of the two conditions being met together can be tested on the example of Toshiba Residential Super Daiseikai G2KVP Inverter Hiwall Heat Pump. The product is advertised as having "extremely high efficiencies with 5.15 and a noise level of only 20 dB in ultra-low fan speed for the RAS-10G2KVP". It is possible to download a brochure by clicking at a pdf at the bottom of the site. The Technical Specifications are given on the last page of the Brochure and one can verify the correctness of the initial commercial information. The detail missing at the beginning is that the value of 20 dB(A) for RAS-10G2KVP only refers to the indoor unit in the quiet mode (42 dB(A) in the high mode) whereas the external unit produces 61 dB(A) in the Heating mode which is not reported in the commercial introduction. The level of 61 dB (A) exceeds the environmental noise limits worldwide.
The location of an outdoor unit in relation to the building wall has a meaning. The unit (1) shown on page 7 of the Heat Pump Product Brochure published by American Standard® Heating&Conditioning is placed close to the center of the house wall, like a musician of the Symphony Orchestra playing a concerto. Shells and walls made of hard material are used behind a sound source if passive sound amplification is necessary. Such a location of the outdoor unit adds some extra dB(A) of noise reflected from the wall. The dB level is not reported in the brochure and the location of the neighbors' house is not shown in the picture, but this type of location should not be used close to a place planned as a quiet place even if the unit is quiet. The heat pump outdoor unit is not a musician performing in front of the audience.
Another feature of ASHP external heat exchangers is their need to stop the fan from time to time for a period of several minutes in order to get rid of frost that accumulates in the outdoor unit in the heating mode. After that the heat pump starts to work again. This part of the work cycle results in two sudden changes of the noise made by the fan. The acoustic effect of such disruption on neighbors is especially powerful in quiet environment where background nighttime noise may be as low as 0 to 10dBA This is included in legislation in France. According to French notion of noise nuisance, the "noise emergence" is the difference between the ambient noise including the disturbing noise and the ambient noise without the disturbing noise. The emergence should be below 3 dB(A) at night (between 10.00 pm and 7.00 am), so the pump in France, once stopped at night, theoretically should not be allowed to switch on again until morning. In addition, the level of ambient noise including the disturbing noise must be below 30 dB(A) in France, which is definitely the condition impossible to be met without an effective sound barrier by most ASHPs which were commercially available by the end of 2015.
However, ASHP outdoor units are still installed in residential areas worldwide without any noise protection, as no recognized standards for heat pump outdoor noise barriers are available yet, as of January 2016.
Performance Considerations.
When comparing the performance of heat pumps, it is best to avoid the word "efficiency", which has a very specific thermodynamic definition. The term coefficient of performance (COP) is used to describe the ratio of useful heat movement per work input. Most vapor-compression heat pumps use electrically powered motors for their work input.
According to the US EPA, geothermal heat pumps can reduce energy consumption up to 44% compared with air-source heat pumps and up to 72% compared with electric resistance heating. Heatpumps in general have a COP of 4.2 to 4.6 which places it behind cogeneration with a COP of 9.
When used for heating a building with an outside temperature of, for example, 10 °C, a typical air-source heat pump (ASHP) has a COP of 3 to 4, whereas an electrical resistance heater has a COP of 1.0. That is, one joule of electrical energy will cause a resistance heater to produce only one joule of useful heat, while under ideal conditions, one joule of electrical energy can cause a heat pump to move three or four joules of heat from a cooler place to a warmer place. Note that an air source heat pump is more efficient in hotter climates than cooler ones, so when the weather is much warmer the unit will perform with a higher COP (as it has a smaller temperature gap to bridge). When there is a wide temperature differential between the hot and cold reservoirs, the COP is lower (worse). In extreme cold weather the COP will go down to 1.0.
On the other hand, ground-source heat pumps (GSHP) benefit from the moderate temperature underground, as the ground acts naturally as a store of thermal energy. Their year-round COP is therefore normally in the range of 2.5 to 5.0.
When there is a high temperature differential (e.g., when an air-source heat pump is used to heat a house with an outside temperature of, say, 0 °C (32 °F)), it takes more work to move the same amount of heat to indoors than on a milder day. Ultimately, due to Carnot efficiency limits, the heat pump's performance will decrease as the outdoor-to-indoor temperature difference increases (outside temperature gets colder), reaching a theoretical limit of 1.0 at −273 °C. In practice, a COP of 1.0 will typically be reached at an outdoor temperature around −18 °C (0 °F) for air source heat pumps.
Also, as the heat pump takes heat out of the air, some moisture in the outdoor air may condense and possibly freeze on the outdoor heat exchanger. The system must periodically melt this ice; this defrosting translates into an additional energy (electricity) expenditure.
When it is extremely cold outside, it is simpler to heat using an alternative heat source (such as an electric resistance heater, oil furnace, or gas furnace) rather than to run an air-source heat pump. Also, avoiding the use of the heat pump during extremely cold weather translates into less wear on the machine's compressor.
The design of the evaporator and condenser heat exchangers is also very important to the overall efficiency of the heat pump. The heat exchange surface areas and the corresponding temperature differential (between the refrigerant and the air stream) directly affect the operating pressures and hence the work the compressor has to do in order to provide the same heating or cooling effect. Generally, the larger the heat exchanger, the lower the temperature differential and the more efficient the system becomes.
Heat exchangers are expensive, requiring drilling for some heat-pump types or large spaces to be efficient, and the heat pump industry generally competes on price rather than efficiency. Heat pumps are already at a price disadvantage when it comes to initial investment (not long-term savings) compared to conventional heating solutions like boilers, so the drive towards more efficient heat pumps and air conditioners is often led by legislative measures on minimum efficiency standards. Electricity rates will also influence the attractiveness of heat pumps.
In cooling mode, a heat pump's operating performance is described in the US as its energy efficiency ratio (EER) or seasonal energy efficiency ratio (SEER), and both measures have units of BTU/(h·W) (1 BTU/(h·W) = 0.293 W/W). A larger EER number indicates better performance. The manufacturer's literature should provide both a COP to describe performance in heating mode, and an EER or SEER to describe performance in cooling mode. Actual performance varies, however, and depends on many factors such as installation details, temperature differences, site elevation, and maintenance.
As with any piece of equipment that depends on coils to transfer heat between air and a fluid, it is important for both the condenser and evaporator coils to be kept clean. If deposits of dust and other debris are allowed to accumulate on the coils, the efficiency of the unit (both in heating and cooling modes) will suffer.
Heat pumps are more "effective" for heating than for cooling an interior space if the temperature differential is held equal. This is because the compressor's input energy is also converted to useful heat when in heating mode, and is discharged along with the transported heat via the condenser to the interior space. But for cooling, the condenser is normally outdoors, and the compressor's dissipated work (waste heat) must also be transported to outdoors using more input energy, rather than being put to a useful purpose. For the same reason, opening a food refrigerator or freezer has the net effect of heating up the room rather than cooling it, because its refrigeration cycle rejects heat to the indoor air. This heat includes the compressor's dissipated work as well as the heat removed from the inside of the appliance.
The COP for a heat pump in a heating or cooling application, with steady-state operation, is:
where
Coefficient of performance (COP) and lift.
The COP increases as the temperature difference, or "lift", decreases between heat source and destination. The COP can be maximized at design time by choosing a heating system requiring only a low final water temperature (e.g. underfloor heating), and by choosing a heat source with a high average temperature (e.g. the ground). Domestic hot water (DHW) and conventional heating radiators require high water temperatures, reducing the COP that can be attained, and affecting the choice of heat pump technology.
One observation is that while current "best practice" heat pumps (ground source system, operating between 0 °C and 35 °C) have a typical COP around 4, no better than 5, the maximum achievable is 8.8 because of fundamental Carnot cycle limits. This means that in the coming decades, the energy efficiency of top-end heat pumps could roughly double. Cranking up efficiency requires the development of a better gas compressor, fitting HVAC machines with larger heat exchangers with slower gas flows, and solving internal lubrication problems resulting from slower gas flow.
Depending on the working fluid, the expansion stage can be important also. Work done by the expanding fluid cools it and is available to replace some of the input power. (An evaporating liquid is cooled by free expansion through a small hole, but an ideal gas is not.)
Types.
Compression vs. absorption.
The two main types of heat pumps are compression and absorption. Compression heat pumps operate on mechanical energy (typically driven by electricity), while absorption heat pumps may also run on heat as an energy source (from electricity or burnable fuels). An absorption heat pump may be fueled by natural gas or LP gas, for example. While the gas utilization efficiency in such a device, which is the ratio of the energy supplied to the energy consumed, may average only 1.5, that is better than a natural gas or LP gas furnace, which can only approach 1.
Heat sources and sinks.
By definition, all heat sources for a heat pump must be colder in temperature than the space to be heated. Most commonly, heat pumps draw heat from the air (outside or inside air) or from the ground (groundwater or soil).
The heat drawn from ground-sourced systems is in most cases stored solar heat, and it should not be confused with direct geothermal heating, though the latter will contribute in some small measure to all heat in the ground. True geothermal heat, when used for heating, requires a circulation pump but no heat pump, since for this technology the ground temperature is higher than that of the space that is to be heated, so the technology relies only upon simple heat convection.
Other heat sources for heat pumps include water; nearby streams and other natural water bodies have been used, and sometimes domestic waste water (via drain water heat recovery) which is often warmer than cold winter ambient temperatures (though still of lower temperature than the space to be heated).
A number of sources have been used for the heat source for heating private and communal buildings.
Air (ASHP).
Air-air heat pumps, that extract heat from outside air and transfer this heat to inside air, are the most common type of heat pumps and the cheapest. These are similar to air conditioners operating in reverse. Air-water heat pumps are otherwise similar to air-air heat pumps, but they transfer the extracted heat into a water heating circuit, floor heating being the most efficient, and they can also transfer heat into a domestic hot water tank for use in showers and hot water taps of the building. However, ground-water heat pumps are more efficient than air-water heat pumps, and therefore they are often the better choice for providing heat for the floor heating and domestic hot water systems.
Air source heat pumps are relatively easy and inexpensive to install and have therefore historically been the most widely used heat pump type. However, they suffer limitations due to their use of the outside air as a heat source. The higher temperature differential during periods of extreme cold leads to declining efficiency. In mild weather, COP may be around 4.0, while at temperatures below around 0 °C (32 °F) an air-source heat pump may still achieve a COP of 2.5. The average COP over seasonal variation is typically 2.5-2.8, with exceptional models able to exceed this in mild climates.
In areas where only fossil fuels are available (e.g. heating oil only; no natural gas pipes available) air source heat pumps could be used as an alternative, supplemental heat source to reduce a building's dependence on fossil fuel. Depending on fuel and electricity prices, using the heat pump for heating may be less expensive than using fossil fuel. A backup fossil-fuel, solar hot water or biomass heat source may still be required for the coldest days.
The heating output of low temperature optimized heat pumps (and hence their energy efficiency) still declines dramatically as the temperature drops, but the threshold at which the decline starts is lower than conventional pumps, as shown in the following table (temperatures are approximate and may vary by manufacturer and model):
Ground (GSHP).
Ground-source heat pumps, also called geothermal heat pumps, typically have higher efficiencies than air-source heat pumps. This is because they draw heat from the ground or groundwater which is at a relatively constant temperature all year round below a depth of about 30 feet (9 m). This means that the temperature differential is lower, leading to higher efficiency. Well maintained ground-source heat pumps typically have COPs of 4.0 at the beginning of the heating season, with lower seasonal COPs of around 3.0 as heat is drawn from the ground. The tradeoff for this improved performance is that a ground-source heat pump is more expensive to install, due to the need for the drilling of boreholes for vertical placement of heat exchanger piping or the digging of trenches for horizontal placement of the piping that carries the heat exchange fluid (water with a little antifreeze).
When compared, groundwater heat pumps are generally more efficient than heat pumps using heat from the soil. Closed loop soil or ground heat exchangers tend to accumulate cold if the ground loop is undersized. This can be a significant problem if nearby ground water is stagnant or the soil lacks thermal conductivity, and the overall system has been designed to be just big enough to handle a "typical worst case" cold spell, or is simply undersized for the load. One way to fix cold accumulation in the ground heat exchanger loop, is to use ground water to cool the floors of the building on hot days, thereby transferring heat from the dwelling into the ground loop. There are several other methods for replenishing a low temperature ground loop; one way is to make large solar collectors, for instance by putting plastic pipes just under the roof, or by putting coils of black polyethylene pipes under glass on the roof, or by piping the tarmac of the parking lot. A further solution is to ensure ground collector arrays are correctly sized, by ensuring soil thermal properties and thermal conductivity are correctly measured and integrated into the design.
Hybrid (HHP).
Hybrid (or twin source) heat pumps: when outdoor air is above 4 to 8 Celsius, (40-50 Fahrenheit, depending on ground water temperature) they use air; when air is colder, they use the ground source. These twin source systems can also store summer heat, by running ground source water through the air exchanger or through the building heater-exchanger, even when the heat pump itself is not running. This has dual advantage: it functions as a low running cost for air cooling, and (if ground water is relatively stagnant) it cranks up the temperature of the ground source, which improves the energy efficiency of the heat pump system by roughly 4% for each degree in temperature rise of the ground source.
Air/water-brine/water heat pump (hybrid heat pump).
The air/water-brine/water heat pump is a hybrid heat pump, developed in Rostock, Germany, that uses only renewable energy sources. Unlike other hybrid systems, which usually combine both conventional and renewable energy sources, it combines air and geothermal heat in one compact device. The air/water-brine/water heat pump has two evaporators — an outside air evaporator and a brine evaporator — both connected to the heat pump cycle. This allows use of the most economical heating source for the current external conditions (for example, air temperature). The unit automatically selects the most efficient operating mode — air or geothermal heat, or both together. The process is controlled by a control unit, which processes the large amounts of data delivered by the complex heating system.
The control unit comprises two controllers, one for the air heat cycle and one for the geothermal circulation, in one device. All components communicate over a common bus to ensure they interact to enhance the efficiency of the hybrid heating system. The German Patent and Trade Mark Office in Munich granted the air/water-brine/water heat pump a patent in 2008, under the title “Heat pump and method for controlling the source inlet temperature to the heat pump”. This hybrid heat pump can be combined with a solar thermal system or with an ice-storage. It trades and is marketed under the name "ThermSelect". In the United Kingdom, "ThermSelect" won the 2013 Commercial Heating Product of the Year award of the HVR Awards for Excellence, organised by "Heating and Ventilating Review", an industry magazine.
Heat distribution.
Heat pumps are only highly efficient when they generate heat at a low temperature differential, ideally around or below . Normal steel plate radiators are not practical, because they would need to be four to six times their current size. Underfloor heating is one ideal solution. When wooden floors or carpets would spoil efficiency, wall heaters (plastic pipes covered with a thick layer of chalk) and piped ceilings can be used. These systems have the disadvantage that they are slow starters, and that they would require extensive renovation in existing buildings.
The alternative is a warm air system.
Such a setup can either complement slower floor heating during warm up, or it can be a quick and economical way to implement a heat pump system into existing buildings. Oversizing the fans and ductwork can reduce the acoustic noise they produce. To efficiently distribute warm water or air from a heat pump, water pipes or air shafts must have significantly larger diameters than in conventional, hotter-source systems, and underfloor heaters should have much more pipes per square meter.
Solid state heat pumps.
Magnetic.
In 1881, the German physicist Emil Warburg put a block of iron into a strong magnetic field and found that it increased very slightly in temperature. Some commercial ventures to implement this technology are underway, claiming to cut energy consumption by 40% compared to current domestic refrigerators. The process works as follows: Powdered gadolinium is moved into a magnetic field, heating the material by 2 to 5 °C (4 to 9 °F). The heat is removed by a circulating fluid. The material is then moved out of the magnetic field, reducing its temperature below its starting temperature.
Thermoelectric.
Solid state heat pumps using the thermoelectric effect have improved over time to the point where they are useful for certain refrigeration tasks. Thermoelectric (Peltier) heat pumps are generally only around 10-15% as efficient as the ideal refrigerator (Carnot cycle), compared with 40–60% achieved by conventional compression cycle systems (reverse Rankine systems using compression/expansion); however, this area of technology is currently the subject of active research in materials science.
A reason why this is popular is because it has a "long lifetime" as there are no moving parts and it does not use potentially hazardous refrigerants.
Thermoacoustic.
Near-solid-state heat pumps using thermoacoustics are commonly used in cryogenic laboratories.
Historical development.
Milestones:

</doc>
<doc id="68318" url="https://en.wikipedia.org/wiki?curid=68318" title="Battle of the Boyne">
Battle of the Boyne

The Battle of the Boyne ( ) was a battle in 1690 between the English King James II, and the Dutch Prince William of Orange, who, with his wife, Mary II (his cousin and James' daughter), had overthrown James in England in 1688. The battle took place across the River Boyne near the town of Drogheda on the east coast of Ireland, and resulted in a victory for William. This turned the tide in James's failed attempt to regain the British crown and ultimately aided in ensuring the continued Protestant ascendancy in Ireland.
The battle took place on 1 July 1690 in the old style (Julian) calendar. This was equivalent to 11 July in the new style (Gregorian) calendar, although today its commemoration is held on 12 July, on which the decisive Battle of Aughrim was fought a year later. William's forces defeated James's army, which consisted mostly of raw recruits. The symbolic importance of this battle has made it one of the best-known battles in the history of the British Isles and a key part of the folklore of the Orange Order. Its commemoration today is principally by the Protestant Orange Institution.
Background.
The battle was the decisive encounter in a war that was primarily about James's attempt to regain the thrones of England and Scotland, resulting from the Invitation to William and William's wife, Mary, to take the throne. It is regarded as a crucial moment in the struggle between Irish Protestant and Catholic interests.
The previous year William had sent the Duke of Schomberg to take charge of the Irish campaign. He was a 75-year-old professional soldier who had accompanied William during the Glorious Revolution. Under his command, affairs had remained static and very little had been accomplished, partly because the English troops, unaccustomed to the climate, suffered severely from fever. William, dissatisfied with the state of affairs in Ireland, decided to take charge in person.
In an Irish context, the war was a sectarian and ethnic conflict, in many ways a re-run of the Irish Confederate Wars of 50 years earlier. For the Jacobites, the war was fought for Irish sovereignty, religious tolerance for Catholicism, and land ownership. The Catholic upper classes had lost almost all their lands after Cromwell's conquest, as well as the right to hold public office, practice their religion, and sit in the Irish Parliament. They saw the Catholic King James as a means of redressing these grievances and securing the autonomy of Ireland from England. To these ends, under Richard Talbot, 1st Earl of Tyrconnel, they had raised an army to restore James after the Glorious Revolution. By 1690, they controlled all of Ireland except for the province of Ulster. Most of James II's troops at the Boyne were Irish Catholics.
The majority of Irish people were Jacobites and supported James II due to his 1687 Declaration of Indulgence or, as it is also known, the Declaration for the Liberty of Conscience, that granted religious freedom to all denominations in England and Scotland and also due to James II's promise to the Irish Parliament of an eventual right to self-determination.
Conversely, for the Williamites, the war was about maintaining Protestant and English rule in Ireland. They feared for their lives and their property if James and his Catholic supporters were to rule Ireland, nor did they trust the promise of tolerance, seeing the Declaration of Indulgence as a ploy to re-establish Catholicism as the sole state religion. In particular, they dreaded a repeat of the Irish Rebellion of 1641, which had been marked by widespread killing. For these reasons, Protestants fought en masse for William of Orange. Many Williamite troops at the Boyne, including their very effective irregular cavalry, were Ulster Protestants, who called themselves "Inniskillingers" and were referred to by contemporaries as "Scots-Irish".
Ironically, historian Derek Brown notes that if the battle is seen as part of the War of the Grand Alliance, Pope Alexander VIII was an ally of William and an enemy to James; the Papal States were part of the Grand Alliance with a shared hostility to the Catholic Louis XIV of France, who at the time was attempting to establish dominance in Europe and to whom James was an ally.
Commanders.
The opposing armies in the battle were led by the Roman Catholic King James II of England, Scotland, and Ireland and opposing him, his nephew and son-in-law, the Protestant King William III ("William of Orange") who had deposed James the previous year. James's supporters controlled much of Ireland and the Irish Parliament. James also enjoyed the support of his cousin, Louis XIV, who did not want to see a hostile monarch on the throne of England. Louis sent 6,000 French troops to Ireland to support the Irish Jacobites. William was already Stadtholder of the Netherlands and was able to call on Dutch and allied troops from Europe as well as England and Scotland.
James was a seasoned officer who had proven his bravery when fighting for his brother – King Charles II – in Europe, notably at the Battle of the Dunes (1658). However, recent historians have noted that he was prone to panicking under pressure and making rash decisions, possibly due to the onset of the dementia which would overtake him completely in later years. William, although a seasoned commander, was hardly one of history's great generals and had yet to win a major battle.
Many of his battles ended in stalemates, prompting at least one modern historian to argue that William lacked an ability to manage armies in the thick of conflict. William's success against the French had been reliant upon tactical manoeuvres and good diplomacy rather than force. His diplomacy had assembled the League of Augsburg, a multi-national coalition formed to resist French aggression in Europe. From William's point of view, his takeover of power in England and the ensuing campaign in Ireland was just another front in the war against King Louis XIV.
James II's subordinate commanders were Richard Talbot, 1st Earl of Tyrconnell, who was Lord Deputy of Ireland and James's most powerful supporter in Ireland; and the French general Lauzun. William's second-in-command was the Duke of Schomberg. Born in Heidelberg, Germany, Schomberg had formerly been a Marshal of France, but, being a Huguenot, was compelled to leave France in 1685 because of the revocation of the Edict of Nantes.
Armies.
The Williamite army at the Boyne was about 36,000 strong, composed of troops from many countries. Around 20,000 troops had been in Ireland since 1689, commanded by Schomberg. William himself arrived with another 16,000 in June 1690. William's troops were generally far better trained and equipped than James's. The best Williamite infantry were from Denmark and the Netherlands, professional soldiers equipped with the latest flintlock muskets. There was also a large contingent of French Huguenot troops fighting with the Williamites. William did not have a high opinion of his English and Scottish troops, with the exception of the Ulster Protestant irregulars who had held Ulster in the previous year. The English and Scottish troops were felt to be politically unreliable, since James had been their legitimate monarch up to a year before. Moreover, they had only been raised recently and had seen little battle action.
The Jacobites were 23,500 strong. James had several regiments of French troops, but most of his manpower was provided by Irish Catholics. The Jacobites' Irish cavalry, who were recruited from among the dispossessed Irish gentry, proved themselves to be high calibre troops during the course of the battle. However, the Irish infantry, predominantly peasants who had been pressed into service, were not trained soldiers. They had been hastily trained, poorly equipped, and only a minority of them had functional muskets. In fact, some of them carried only farm implements such as scythes at the Boyne. On top of that, the Jacobite infantry who actually had firearms were all equipped with the obsolete matchlock musket.
The battle.
William had landed in Carrickfergus in Ulster on 14 June 1690 and marched south to take Dublin. He was heard to remark that 'the place was worth fighting for'. James chose to place his line of defense on the River Boyne, around from Dublin. The Williamites reached the Boyne on 29 June. The day before the battle, William himself had a narrow escape when he was wounded in the shoulder by Jacobite artillery while surveying the fords over which his troops would cross the Boyne.
The battle itself was fought on 1 July OS (11th NS), for control of a ford on the Boyne near Drogheda, about northwest of the hamlet of Oldbridge (and about west-northwest of the modern Boyne River Bridge). William sent about a quarter of his men to cross the river at Roughgrange, about west of Donore and about southwest of Oldbridge. The Duke of Schomberg's son, Meinhardt, led this crossing, which Irish dragoons in picquet under Neil O'Neill unsuccessfully opposed. James, an inexperienced general, thought that he might be outflanked and sent half his troops, along with most of his artillery, to counter this move. What neither side had realised was that there was a deep, swampy ravine at Roughgrange. Because of this ravine, the opposing forces there could not engage each other, but literally sat out the battle. The Williamite forces went on a long detour march which, later in the day, almost saw them cut off the Jacobite retreat at the village of Naul.
At the main ford near Oldbridge, William's infantry, led by the elite Dutch Blue Guards, forced their way across the river, using their superior firepower to slowly drive back the enemy foot soldiers, but were pinned down when the Jacobite cavalry counter-attacked. Having secured the village of Oldbridge, some Williamite infantry tried to hold off successive cavalry attacks with disciplined volley fire, but were scattered and driven into the river, with the exception of the Blue Guards. William's second-in-command, the Duke of Schomberg, and George Walker were killed in this phase of the battle. The Williamites were not able to resume their advance until their own horsemen managed to cross the river and, after being badly mauled, managed to hold off the Jacobite cavalry until they retired and regrouped at Donore, where they once again put up stiff resistance before retiring.
The Jacobites retired in good order. William had a chance to trap them as they retreated across the River Nanny at Duleek, but his troops were held up by a successful rear-guard action. The Dutch secretary of King William, Constantijn Huygens Jr., has given a good description (in Dutch) of the battle and its aftermath, including subsequent cruelties committed by the victorious soldiers.
The casualty figures of the battle were quite low for a battle of such a scale—of the 50,000 or so participants, about 2,000 died. Three-quarters of the dead were Jacobites. William's army had far more wounded. At the time, most casualties of battles tended to be inflicted in the pursuit of an already-beaten enemy; this did not happen at the Boyne, as the counter-attacks of the skilled Jacobite cavalry screened the retreat of the rest of their army, and in addition William was always disinclined to endanger the person of James, since he was the father of his wife, Mary. The Jacobites were badly demoralised by the order to retreat, which lost them the battle. Many of the Irish infantrymen deserted. The Williamites triumphantly marched into Dublin two days after the battle. The Jacobite army abandoned the city and marched to Limerick, behind the River Shannon, where they were unsuccessfully besieged.
Soon after the battle William issued the Declaration of Finglas, offering full pardons to ordinary Jacobite soldiers but not to their leaders. After his defeat, James did not stay in Dublin, but rode with a small escort to Duncannon and returned to exile in France, even though his army left the field relatively unscathed. James's loss of nerve and speedy exit from the battlefield enraged his Irish supporters, who fought on until the Treaty of Limerick in 1691; he was derisively nicknamed "Seamus a' chaca" ("James the shit") in Irish.
There is an oral tradition stating that no battle took place at all, that a symbolic victory was shown by the crossing of the River Boyne and that the total fatalities were a result of Williamite cavalry attacking the local able-bodied men.
It is well documented that Williams' horse on that day was black, despite all Orange Order murals depicting it as white with William holding his sword between the horse's ears to make it resemble a unicorn as a symbol of his "Saviour" status. Depictions of William have been strongly influenced by Benjamin West's 1778 painting "The Battle of the Boyne".
Aftermath.
The battle was overshadowed by the defeat of an Anglo-Dutch fleet by the French two days later at the Battle of Beachy Head, a far more serious event in the short term; only on the continent was the Boyne treated as an important victory. Its importance lay in the fact that it was the first proper victory for the League of Augsburg, the first-ever alliance between the Vatican and Protestant countries. The victory motivated more nations to join the alliance and in effect ended the fear of a French conquest of Europe.
The Boyne also had strategic significance for both England and Ireland. It marked the end of James's hope of regaining his throne by military means and probably assured the triumph of the Glorious Revolution. In Scotland, news of this defeat temporarily silenced the Highlanders supporting the Jacobite Rising, which Bonnie Dundee had led. In Ireland, the Boyne fully assured the Jacobites that they could successfully resist William. But it was a general victory for William, and is still celebrated by the Protestant Orange Order on the Twelfth of July. Ironically, due to the political situation mentioned above, the Pope also hailed the victory of William at the Boyne, ordered the bells of the Vatican to be rung in celebration.
Some Irish Catholics who were taken prisoner after the battle were tortured until they agreed to convert to Protestantism. 
The Treaty of Limerick was very generous to Catholics. It allowed most land owners to keep their land so long as they swore allegiance to William of Orange. It also said that James could take a certain number of his soldiers and go back to France. However, Protestants in England were annoyed with this kind treatment towards the Catholics, especially when they were gaining strength and money. Because of this, penal laws were introduced. These laws included banning Catholics from owning weapons, reducing their land, and prohibiting them from working in the legal profession.
Commemoration.
Originally, Irish Protestants commemorated the Battle of Aughrim on 12 July (old style, equivalent to 22 July new style), symbolising their victory in the Williamite war in Ireland. At Aughrim, which took place a year after the Boyne, the Jacobite army was destroyed, deciding the war in the Williamites' favour. The Boyne, which, in the old Julian calendar, took place on 1 July, was treated as less important, third after Aughrim and the anniversary of the Irish Rebellion of 1641 on 23 October.
In 1752, the Gregorian calendar was adopted in Ireland, which erroneously placed the Boyne on 12 July instead of Aughrim (the correct equivalent date was 11 July, as the difference between the calendars for the year in question, 1690, was not 11 days but only 10 days). However, even after this date, "The Twelfth" still commemorated Aughrim. But after the Orange Order was founded in 1795 amid sectarian violence in Armagh, the focus of parades on 12 July switched to the Battle of the Boyne. Usually the dates before the introduction of the calendar on 14 September 1752 are mapped in English language histories directly onto the Julian dates without shifting them by 10 or 11 days.
Being suspicious of anything with Papist connotations, however, rather than shift the anniversary of the Boyne to the new 1 July or celebrate the new anniversary of Aughrim, the Orangemen continued to march on 12 July which was (erroneously) thought to have marked the battle of the Boyne in New Style dates. Despite this, there are also smaller parades and demonstrations on 1 July, the date which maps the old style date of the Boyne to the new style in the usual manner and which also commemorate the heavy losses of the 36th (Ulster) Division on the first day of the Battle of the Somme in July 1916.
The memory of the battle also has resonance among Irish nationalists. In 1923, IRA members blew up a large monument to the battle on the battlefield site on the Boyne and destroyed a statue of William III in 1929 that stood outside Trinity College, Dublin in the centre of the Irish capital.
"The Twelfth" in Great Britain and Ireland today.
The Battle of the Boyne remains a controversial topic today in Northern Ireland, where some Protestants remember it as the great victory over Catholics that resulted in the sovereignty of Parliament and the "Protestant monarchy".
In recent decades, "The Twelfth" has often been marked by confrontations, as members of the Orange Order attempt to celebrate the date by marching past or through what they see as their traditional route. Some of these areas, however, now have a nationalist majority who object to marches passing through what they see as their areas.
Each side thus dresses up the disputes in terms of the other's alleged attempts to repress them; Nationalists still see Orange Order marches as provocative attempts to "show who is boss", whilst Unionists insist that they have a right to "walk the Queen's highway". Since the start of The Troubles, the celebrations of the battle have been seen as playing a critical role in the awareness of those involved in the unionist/nationalist tensions in Northern Ireland.
The battlefield today.
The site of the Battle of the Boyne sprawls over a wide area west of the town of Drogheda. In the County Development Plan for 2000, Meath County Council rezoned the land at the eastern edge of Oldbridge, at the site of the main Williamite crossing, to residential status. A subsequent planning application for a development of over 700 houses was granted by Meath County Council and this was appealed by local historians to An Bord Pleanala (The Planning Board). In March 2008 after an extremely long appeal process, An Bord Pleanala approved permission for this development to proceed. However, due to the current economic climate in Ireland, no work has yet started on this development.
The current Interpretive Centre dedicated to informing tourists and other visitors about the battle is about to the west of the main crossing point. This facility was redeveloped in 2008 and is now open for tourists. The battle's other main combat areas (at Duleek, Donore and Plattin – along the Jacobite line of retreat) are marked with tourist information signs.
On 4 April 2007 in a sign of improving relations between unionist and nationalist groups, the newly elected First Minister of Northern Ireland, the Reverend Ian Paisley, was invited to visit the battle site by the Taoiseach (Prime Minister) Bertie Ahern later in the year. Following the invitation, Paisley commented that "such a visit would help to demonstrate how far we have come when we can celebrate and learn from the past so the next generation more clearly understands". On 10 May the visit took place, and Paisley presented the Taoiseach with a Jacobite musket in return for Ahern's gift at the St Andrews talks of a walnut bowl made from a tree from the site. A new tree was also planted in the grounds of Oldbridge House by the two politicians to mark the occasion.

</doc>
<doc id="68319" url="https://en.wikipedia.org/wiki?curid=68319" title="Cesar Chavez">
Cesar Chavez

Cesar Chavez (born César Estrada Chávez, ; March 31, 1927April 23, 1993) was an American labor leader and civil rights activist, who, with Dolores Huerta, co-founded the National Farm Workers Association (later the United Farm Workers union, UFW) in 1962. Originally a Mexican American farm worker, Chavez became the best known Latino American civil rights activist, and was strongly promoted by the American labor movement, which was eager to enroll Hispanic members. His public-relations approach to unionism and aggressive but nonviolent tactics made the farm workers' struggle a moral cause with nationwide support. By the late 1970s, his tactics had forced growers to recognize the UFW as the bargaining agent for 50,000 field workers in California and Florida. However, by the mid-1980s membership in the UFW had dwindled to around 15,000.
During his lifetime, Colegio Cesar Chavez was one of the few institutions named in his honor, but after his death he became a major historical icon for the Latino community, with many schools, streets, and parks being named after him. He has since become an icon for organized labor and leftist politics, symbolizing support for workers and for Hispanic empowerment based on grass roots organizing. He is also famous for popularizing the slogan "Sí, se puede" (Spanish for "Yes, one can" or, roughly, "Yes, it can be done"), which was adopted as the 2008 campaign slogan of Barack Obama. His supporters say his work led to numerous improvements for union laborers. Although the UFW faltered a few years after Chavez died in 1993, he became an iconic "folk saint" in the pantheon of Mexican Americans. His birthday, March 31, has become Cesar Chavez Day, a state holiday in California, Colorado, and Texas.
Early life and education.
Chavez was born on March 31, 1927, in Yuma, Arizona, in a Mexican-American family of six children. He was the son of Juana Estrada and Librado Chávez. He had two brothers, Richard (1929–2011) and Librado, and two sisters, Rita and Vicki. He was named after his grandfather, Cesario. Chavez grew up in a small adobe home, the same home in which he was born. His family owned a grocery store and a ranch, but their land was lost during the Great Depression. The family's home was taken away after his father had agreed to clear eighty acres of land in exchange for the deed to the house, an agreement which was subsequently broken. Later, when Chavez's father attempted to purchase the house, he could not pay the interest on the loan and the house was sold back to its original owner. His family then moved to California to become migrant farm workers.
The Chavez family faced many hardships in California. The family would pick peas and lettuce in the winter, cherries and beans in the spring, corn and grapes in the summer, and cotton in the fall. When Chavez was a teenager, he and his older sister Rita would help other farm workers and neighbors by driving those unable to drive to the hospital to see a doctor.
In 1942, Chavez quit school in the seventh grade. It would be his final year of formal schooling, because he did not want his mother to have to work in the fields. Chavez dropped out to become a full-time migrant farm worker. In 1946 he joined the United States Navy and served for two years. Chavez had hoped that he would learn skills in the Navy that would help him later when he returned to civilian life. Later, Chavez described his experience in the military as "the two worst years of my life".
Activism, 1952-1976.
Chavez worked in the fields until 1952, when he became an organizer for the Community Service Organization (CSO), a Latino civil rights group. Father Donald McDonnell who served in Santa Clara County introduced Fred Ross, a community organizer, to Cesar Chavez. Chavez urged Mexican Americans to register and vote, and he traveled throughout California and made speeches in support of workers' rights. He later became CSO's national director in 1958.
Workers' rights.
In 1962, Chavez left the CSO and co-founded the National Farm Workers Association (NFWA) with Dolores Huerta. It was later called the United Farm Workers (UFW).
When Filipino American farm workers initiated the Delano grape strike on September 8, 1965, to protest for higher wages, Chavez eagerly supported them. Six months later, Chavez and the NFWA led a strike of California grape pickers on the historic farmworkers march from Delano to the California state capitol in Sacramento for similar goals. The UFW encouraged all Americans to boycott table grapes as a show of support. The strike lasted five years and attracted national attention. In March 1966, the U.S. Senate Committee on Labor and Public Welfare's Subcommittee on Migratory Labor held hearings in California on the strike. During the hearings, subcommittee member Robert F. Kennedy expressed his support for the striking workers.
These activities led to similar movements in Southern Texas in 1966, where the UFW supported fruit workers in Starr County, Texas, and led a march to Austin, in support of UFW farm workers' rights. In the Midwest, Chavez's movement inspired the founding of two midwestern independent unions: Obreros Unidos in Wisconsin in 1966, and the Farm Labor Organizing Committee (FLOC) in Ohio in 1967. Former UFW organizers would also found the Texas Farm Workers Union in 1975.
In the early 1970s, the UFW organized strikes and boycotts—including the Salad Bowl strike, the largest farm worker strike in U.S. history—to protest for, and later win, higher wages for those farm workers who were working for grape and lettuce growers. He again fasted to draw public attention. UFW organizers believed that a reduction in produce sales by 15% was sufficient to wipe out the profit margin of the boycotted product.
Chavez undertook a number of "spiritual fasts", regarding the act as “a personal spiritual transformation”. In 1968, he fasted for 25 days, promoting the principle of nonviolence. In 1970, Chavez began a fast of "thanksgiving and hope" to prepare for pre-arranged civil disobedience by farm workers. Also in 1972, he fasted in response to Arizona’s passage of legislation that prohibited boycotts and strikes by farm workers during the harvest seasons. These fasts were influenced by the Catholic tradition of penance and by Gandhi’s fasts and emphasis of nonviolence.
Immigration.
The UFW during Chavez's tenure was committed to restricting immigration. Chavez and Dolores Huerta, cofounder and president of the UFW, fought the Bracero Program that existed from 1942 to 1964. Their opposition stemmed from their belief that the program undermined U.S. workers and exploited the migrant workers. Since the Bracero Program ensured a constant supply of cheap immigrant labor for growers, immigrants could not protest any infringement of their rights, lest they be fired and replaced. Their efforts contributed to Congress ending the Bracero Program in 1964. In 1973, the UFW was one of the first labor unions to oppose proposed employer sanctions that would have prohibited hiring illegal aliens. Later during the 1980s, while Chavez was still working alongside Huerta, he was key in getting the amnesty provisions into the 1986 federal immigration act.
On a few occasions, concerns that illegal alien labor would undermine UFW strike campaigns led to a number of controversial events, which the UFW describes as anti-strikebreaking events, but which have also been interpreted as being anti-immigrant. In 1969, Chavez and members of the UFW marched through the Imperial and Coachella Valleys to the border of Mexico to protest growers' use of illegal aliens as strikebreakers. Joining him on the march were Reverend Ralph Abernathy and U.S. Senator Walter Mondale. In its early years, the UFW and Chavez went so far as to report illegal aliens who served as strikebreaking replacement workers (as well as those who refused to unionize) to the Immigration and Naturalization Service.
In 1973, the United Farm Workers set up a "wet line" along the United States-Mexico border to prevent Mexican immigrants from entering the United States illegally and potentially undermining the UFW's unionization efforts. During one such event, in which Chavez was not involved, some UFW members, under the guidance of Chavez's cousin Manuel, physically attacked the strikebreakers after peaceful attempts to persuade them not to cross the border failed.
Legislative campaigns.
Chavez had long preferred grassroots action to legislative work, but in 1974, propelled by the recent election of the pro-union Jerry Brown as governor of California, as well as a costly battle with the Teamsters union over the organizing of farmworkers, Chavez decided to try to work toward legal victories. Once in office Brown's support for the UFW cooled. The UFW decided to organize a 110-mile (180 km) march by a small group of UFW leaders from San Francisco to the E & J Gallo Winery in Modesto. Just a few hundred marchers left San Francisco on February 22, 1975. By the time they reached Modesto on March 1, however, more than 15,000 people had joined the march en route. The success of the Modesto march garnered significant media attention, and helped convince Brown and others that the UFW still had significant popular support.
On June 4, 1975, Governor Brown signed into law the California Agricultural Labor Relations Act (ALRA), which established collective bargaining for farmworkers. The act set up the California Agricultural Labor Relations Board (ALRB) to oversee the process.
In mid-1976, the ALRB ran out of its budgeted money for the year, as a result of a massive amount of work in setting up farmworker elections. The California legislature refused to allocate more money, so the ALRB closed shop for the year. In response, Chavez gathered signatures in order to place Proposition 14 on the ballot, which would guarantee the right of union organizers to visit and recruit farmworkers, even if it meant trespassing on private property controlled by farm owners. The proposition went before California voters in November 1976, but was defeated by a 2-1 margin.
Setbacks and a change of direction, 1976-1988.
As a result of the failure of Proposition 14, Chavez decided that the UFW suffered from disloyalty, poor motivation and lack of communication. He felt that the union needed to turn into a "movement". He took inspiration from the Synanon community of California (which he had visited previously), which had begun as a drug rehabilitation center before turning into a New Age religious organization. Synanon had pioneered what they referred to as "the Game", in which each member would be singled out in turn to receive harsh, profanity-laced criticism from the rest of the community. Chavez instituted "the Game" at UFW, having volunteers, including senior members of the organization, receive verbal abuse from their peers. He also fired many members, whom he accused of disloyalty; in some cases he accused volunteers of being spies for either the Republican Party or the Communists.
In 1977, Chavez attempted to reach out to Filipino-American farmworkers in a way that ended up backfiring. Acting on the advice of former UFW leader Andy Imutan, Chavez met with then-President of the Philippines Ferdinand Marcos in Manila and endorsed the regime, which was seen by human rights advocates and religious leaders as a vicious dictatorship. This caused a further rift within the UFW, which led to Philip Vera Cruz's resignation from the organization.
During this time, Chavez also clashed with other UFW members about policy issues, including the possible creation of local unions for the UFW, which was typical for national unions but which Chavez was firmly against, on the grounds that it detracted from his vision for the UFW as a movement.
By the end of the 1970s, only one member of the UFW's original board of directors remained in place.
In the 1980s, with the UFW declining, Chavez got into real-estate development; some of the development projects he was involved with used non-union construction workers, which "The New Yorker" later termed an "embarassment".
In 1988, Chavez attempted another grape boycott, to protest the exposure of farmworkers to pesticides. Bumper stickers reading "NO GRAPES" and "UVAS NO" (the translation in Spanish) were widespread. However, the boycott failed. As a result, Chavez undertook what was to be his last fast. He fasted for 35 days before being convinced by others to start eating again. He lost 30 pounds during the fast, and it caused health problems that may have contributed to his death.
Personal life.
When Chavez returned home from his service in the military in 1948, he married his high school sweetheart, Helen Fabela. The couple moved to San Jose, California, where they had eight children.
Chavez was a vegan, both because he believed in animal rights and also for his health.
Death.
Chavez died on April 23, 1993, of unspecified natural causes in San Luis, Arizona, in the home of former farm worker and longtime friend Dofla Maria Hau. Chavez was in Arizona helping UFW attorneys defend the union against a lawsuit. Shortly after his death, his widow, Helen Chavez, donated his black nylon union jacket to the National Museum of American History, a branch of the Smithsonian.
Chavez is buried at the National Chavez Center, on the headquarters campus of the United Farm Workers of America (UFW), at 29700 Woodford-Tehachapi Road in the Keene community of unincorporated Kern County, California.
He received belated full military honors from the US Navy at his graveside on April 23, 2015, the 22nd anniversary of his death.
Legacy.
There is a portrait of Chavez in the National Portrait Gallery in Washington, D.C.
In 2003, the United States Postal Service honored Chavez with a postage stamp. 
The American Friends Service Committee (AFSC) nominated him three times for the Nobel Peace Prize.
One of Chavez's grandchildren is the professional golfer Sam Chavez.
Awards and honors.
In 1973, Chavez received the Jefferson Award for Greatest Public Service Benefiting the Disadvantaged.
In 1992, Chavez was awarded the Catholic Church's "Pacem in Terris" Award, named after a 1963 encyclical by Pope John XXIII calling upon all people of good will to secure peace among all nations.
On September 8, 1994, Chavez was presented posthumously with the Presidential Medal of Freedom by President Bill Clinton. The award was received by his widow, Helen Chavez.
On December 6, 2006, California governor Arnold Schwarzenegger and First Lady Maria Shriver inducted Chavez into the California Hall of Fame.
Places and things named after Cesar Chavez.
Across the United States, and especially in California, there have been many parks, streets, schools, libraries, university buildings and other establishments named after Chavez. In addition, the census-designated place of Cesar Chavez, Texas is named after him.
Colegio Cesar Chavez, named after Chavez while he was still alive, was a four-year "college without walls" in Mount Angel, Oregon, intended for the education of Mexican-Americans, that ran from 1973 to 1983.
On May 18, 2011, Navy Secretary Ray Mabus announced that the Navy would be naming the last of 14 Lewis and Clark-class cargo ships after Cesar Chavez. The USNS "Cesar Chavez" was launched on May 5, 2012.
Monuments.
In 2004, the National Chavez Center was opened on the UFW national headquarters campus in Keene by the César E. Chávez Foundation. It currently consists of a visitor center, memorial garden and his grave site. When it is fully completed, the site will include a museum and conference center to explore and share Chavez's work.
On September 14, 2011, the U.S. Department of the Interior added the Nuestra Senora Reina de La Paz ranch to the National Register of Historic Places.
On October 8, 2012, President Barack Obama designated the Cesar E. Chavez National Monument within the National Park system.
California State University San Marcos's Chavez Plaza includes a statue to Chavez. In 2007, The University of Texas at Austin unveiled its own Cesar Chavez statue on campus.
The Consolidated Natural Resources Act of 2008 authorized the National Park Service to conduct a special resource study of sites that are significant to the life of Cesar Chavez and the farm labor movement in the western United States. The study evaluated the significance and suitability of sites significant to Cesar Chavez and the farm labor movement, and the feasibility and appropriateness of a National Park Service role in the management of any of these sites.
Cesar Chavez Day.
Cesar Chavez's birthday, March 31, is a state holiday in California, Colorado, and Texas. It is intended to promote community service in honor of Chavez's life and work. Many, but not all, state government offices, community colleges, and libraries are closed. Many public schools in the three states are also closed. Chavez Day is an optional holiday in Arizona. Although it is not a federal holiday, President Barack Obama proclaimed March 31 "Cesar Chavez Day" in the United States, with Americans being urged to "observe this day with appropriate service, community, and educational programs to honor César Chávez's enduring legacy".
Other commemorations.
The heavily Hispanic city of Laredo, Texas, observes "Cesar Chavez Month" during March. Organized by the local League of United Latin American Citizens, a citizens' march is held in downtown Laredo on the last Saturday morning of March to commemorate Chavez. Among those attending are local politicians and students.
In the Mission District, San Francisco a "Cesar Chavez Holiday Parade" is held on the second weekend of April, in honor of Cesar Chavez. The parade includes traditional Native American dances, union visibility, local music groups, and stalls selling Latino products.
In popular culture.
Chavez was referenced by Stevie Wonder in the song "Black Man" from the album "Songs in the Key of Life" and by Tom Morello in the song "Union Song" from the album "One Man Revolution".
The 2014 American film "César Chávez", starring Michael Peña as Chavez, covered Chavez's life in the 1960s and early 1970s.

</doc>
<doc id="68322" url="https://en.wikipedia.org/wiki?curid=68322" title="Faye Dunaway">
Faye Dunaway

Dorothy Faye Dunaway (born January 14, 1941) is an American actress, best known for her starring roles in films from the 1960s onwards.
Regarded as one of the greatest actresses of her generation, she has won an Academy Award, three Golden Globes, a BAFTA, an Emmy, and was the first-ever recipient of a Leopard Club Award which honors film professionals whose work has left a mark on the collective imagination. In 2011, the government of France made her an Officer of the Order of Arts and Letters.
Dunaway’s career began in the early 1960s on Broadway. She made her screen debut in the 1967 film "The Happening", and rose to fame that same year with the gangster film "Bonnie and Clyde", for which she received her first Academy Award nomination. Her most notable films include the crime caper "The Thomas Crown Affair" (1968), the neo-noir mystery "Chinatown" (1974), for which she earned her second Oscar nomination, the action-drama disaster "The Towering Inferno" (1974), the political thriller "Three Days of the Condor" (1975) and the satirical "Network" (1976), for which she received an Academy Award for Best Actress.
Dunaway's career evolved to more mature and character roles in subsequent years, often in independent films, beginning with her controversial portrayal of Joan Crawford in the 1981 film "Mommie Dearest". Other notable films in which she has starred include the thriller "Eyes of Laura Mars" (1978), the drama "Barfly" (1987), the surrealist comedy-drama "Arizona Dream" (1993) and the black comedy "The Rules of Attraction" (2002).
Early life.
Dunaway was born in Bascom, Florida, the daughter of Grace April (née Smith 1922–2004), a housewife, and John MacDowell Dunaway, Jr. (1920–1984), a career non-commissioned officer in the United States Army. She is of Scots-Irish, English, and German descent. She spent her childhood traveling throughout the United States and Europe.
Dunaway took dance classes, tap, piano and singing, and then studied at Florida State University and University of Florida, and graduated from the Boston University with a degree in theatre. She spent the summer before her senior year in a summer stock company at Harvard's Loeb Drama Center, where one of her co-players was Jane Alexander, the actress and future head of the National Endowment for the Arts. In 1962, at the age of 21, she took acting classes at the American National Theater and Academy. She was spotted by Lloyd Richards while performing in a production of "The Crucible", and was recommended to director Elia Kazan, who was in search of young talent for his Lincoln Center Repertory Company.
Shortly after graduating from Boston University, Dunaway was already appearing on Broadway as a replacement in Robert Bolt's drama "A Man for All Seasons". She subsequently appeared in Arthur Miller's "After the Fall" and the award-winning "Hogan's Goat" by Harvard professor William Alfred. Alfred became her mentor and spiritual advisor. 
Career.
First screen roles and "Bonnie and Clyde "breakthrough.
Dunaway's first screen role was the 1967 "The Happening", which starred Anthony Quinn. That role was followed by a supporting role in the 1967 film "Hurry Sundown", a drama set in the South directed by Otto Preminger and co-starring Michael Caine and Jane Fonda. While she had difficulties with Preminger, her performance was well-received and she was nominated for a Golden Globe Award for Best New Star of the Year. The film itself was a critical and box office flop.
Dunaway was cast as the bank robber Bonnie Parker in the 1967 film "Bonnie and Clyde", opposite Warren Beatty, who played Clyde Barrow in the film, which he also produced. Casting for the role of Bonnie had proved to be difficult; many actresses had been considered for the role, including Jane Fonda, Tuesday Weld, Ann-Margret, Carol Lynley, Leslie Caron, and Natalie Wood. Director Arthur Penn became convinced that Dunaway was the right choice for the role, and managed to convince Beatty.
The film, though controversial, was a smash hit, and elevated Dunaway to stardom. "Newsweek" said Dunaway's performance was "the revelation of the year," and made the comparison that Dunaway was first American actress to "electrify the world's moviegoers" since Marilyn Monroe. The film was nominated for ten awards, including Best Picture and Best Actress for Dunaway, who lost to Katharine Hepburn. But Dunaway won the BAFTA Award for Best Newcomer and was now among the most bankable actresses in Hollywood.
Her role as Parker (along with Beatty's Barrow) was named by the American Film Institute to be one of the greatest villains to ever appear on screen – 32nd in a list of 50.
Before the breakthrough of "Bonnie and Clyde", director John Frankenheimer offered her a role in his new film "The Extraordinary Seaman". The film also starred David Niven and was a comedy adventure set during World War II. The film was screened for critics, who hated it, and the studio withheld general release for two years. Dunaway later wrote that Frankheimer was a "brilliant man," but the film was a "disaster 
"The Thomas Crown Affair" and career setbacks.
Dunaway's starring role in the 1968 caper film "The Thomas Crown Affair," opposite Steve McQueen in the title role, solidified her screen success. McQueen played a millionaire who attempts to pull off the perfect crime, while Dunaway played an insurance investigator who becomes involved with Crown. Eva Marie Saint was considered for the role after Brigitte Bardot rejected it, but the success of "Bonnie and Clyde" convinced McQueen and director Norman Jewison to offer the role to Dunaway. The film was immensely popular, and was famed for a scene where Dunaway and McQueen play a chess game and silently engage in heavy seduction of each other across the board.
With two consecutive successes in "Bonnie and Clyde" and "The Thomas Crown Affair", Dunaway took on a role in an Italian film, "A Place for Lovers" (1969). The film was a romantic tragedy in the vein of "Camille", where Dunaway played a terminally ill fashion designer who has a doomed romance with an Italian race car driver (Marcello Mastroianni). Like "The Extraordinary Seaman", the film was heavily panned by critics; the critic of "The Los Angeles Times" claimed it was the most mediocre film he had seen since 1926.
Her next appearance was in the widescreen Technicolor production "The Arrangement" (1969), produced and directed by Elia Kazan, scripted by Kazan from his novel of the same name. The ambitious movie starring Kirk Douglas, Deborah Kerr, Hume Cronyn, and Richard Boone met with universal critical disparagement, although appreciation of Dunaway was made: "looking so cool and elegant that the sight of her almost pinches the optic nerves." –Vincent Canby, New York Times.
She had a supporting role in Arthur Penn's 1970 revisionist Western "Little Big Man". In a rare comic role, Dunaway played the sexually frustrated wife of a minister who helps raise and seduce a boy raised by Native Americans (played by Dustin Hoffman). The film was one of Dunaway's few commercial successes at this point. After the film was finished, she appeared in the lead role in "The Deadly Trap", directed by Rene Clement, and "Puzzle of a Downfall Child", an experimental drama inspired by the life of model Anne Saint Marie, directed by Jerry Schatzberg. The film failed to generate commercial interest, though it earned for Dunaway a second Golden Globe nomination for Best Actress. The film remained in obscurity over 40 years, until it was revived at the 64th Cannes Film Festival, 2011, in honor of Dunaway. She also played opposite George C. Scott in the Stanley Kramer film "Oklahoma Crude" in 1973.
Career revival with "Chinatown".
Dunaway's career, which had slumped after "The Thomas Crown Affair", only had one or two truly successful films between 1968 and 1973. "Oklahoma Crude" was not a success, but Dunaway's other 1973 film fared much better. Ilya Salkind and Alexander Salkind hired Dunaway to take on the villainous role of Milady de Winter in their all-star adaptation of Alexandre Dumas' "The Three Musketeers". The film starred Michael York, Oliver Reed, Richard Chamberlain, Raquel Welch, and Dunaway in the leading roles. Eventually, the Salkinds and director Richard Lester decided to split the film into two parts: 1973's "The Three Musketeers" and 1974's "The Four Musketeers". Critics and audiences alike praised the film for its action and its comic tone, and it was the first in a line of successful projects for Dunaway.
Director Roman Polanski offered Dunaway the lead role of Evelyn Mulwray in his mystery neo-noir "Chinatown". Although its producer, Robert Evans, wanted Polanski to consider Jane Fonda for the role, arguing that Dunaway had a reputation for temperament, Polanski insisted on using Dunaway. She accepted the challenging and complex role of Mulwray, a shadowy femme fatale who knows more than she is willing to let Detective J.J. Gittes (played by Jack Nicholson) know. 
Dunaway got along well with Nicholson, describing him later as a "soul mate," but her relationship with Polanski did not go as well. He had a reputation for being too dictatorial on a set. During one scene he pulled one of Dunaway's hairs out of her head, without telling her, because it was catching the light. Dunaway was offended, describing his act as "cruel" and left the set furious. Polanski said afterward that he had "never known an actress to take work as seriously as she does." Dunaway admitted later about the incident that "way too much made out of it," adding that she enjoyed working with Polanski, calling him "a great director".
Despite the complications on the set, the film was finished, released to glowing reviews and ultimately became a classic. It made back its budget almost five times, and received 11 Academy Award nominations. Dunaway received a second Best Actress nomination, and also received a Golden Globe nomination and a BAFTA nomination. Upon the release of the film, producer Robert Evans was full of praise for Dunaway, "She has everything—beauty, talent, neurosis. She has something we haven't seen on the screen for a long time. She has witchery. She's a femme fatale." He later said she was "extraordinary" and believed that "no one could’ve played it as well."
Dunaway's third project in 1974 was the all-star disaster epic "The Towering Inferno". She played the role of Paul Newman's girlfriend, who is trapped in a burning skyscraper along with several hundred other people. The film became the highest-grossing film of the year, further cementing Dunaway as a top actress in Hollywood. Also in 1974, Dunaway married Peter Wolf, who was the lead singer of the rock group The J. Geils Band.
In 1975, Dunaway joined Robert Redford in the political thriller "Three Days of the Condor". A significant critical and commercial success, the film continues to be praised. Dunaway's performance was very well regarded. She received another Golden Globe nomination for Best Actress – Motion Picture Drama.
"Network" and the 1970s.
After she finished "Inferno", Dunaway took a break from acting and spent almost a year of turning down projects. She passed on a role in Alfred Hitchcock's final film, the comic thriller "Family Plot", which she later lamented. In 1976, she took a supporting role in the Holocaust drama "Voyage of the Damned". The story was inspired by true events concerning the fate of the MS "St. Louis" ocean liner carrying Jewish refugees from Germany to Cuba in 1939.
That same year, she was offered the Paddy Chayefsky-scripted satire "Network" as the scheming TV executive Diana Christensen, a ruthless woman who will do anything for higher ratings. When a news anchor named Howard Beale (played by Peter Finch) goes mad and rants on the air (the iconic line "I'm as mad as hell and I'm not going to take this anymore!" is featured here), Dunaway's character decides to capitalize on this and builds a television show around him. William Holden's character, who engages in an affair with Diana, eventually sees her soullessness and the soullessness of television.
Dunaway was excited by Chayefsky’s screenplay and eager to play the character of Diana. She saw her as a woman who "was driven, more driven in her career than I was in mine, but I knew what fueled that sort of ambition." She pursued the role over the objections of her husband, Peter Wolf, and her confidant, the playwright William Alfred. Both regarded Diana as too heartless and were concerned, according to Dunaway, "that people would think badly of me, would confuse the character and the actor, and come to believe I was like that." On the other hand, her manager, Sue Mengers, persuaded her to accept the part and even told her she would no longer represent her if she didn’t do the film. Director Sidney Lumet begged her to do the part and Dunaway said yes, believing that Diana was "one of the most important female roles to come along in years." In his memoir, "Making Movies", Lumet stated that Dunaway was a "selfless, devoted, and wonderful actress."
The film, a success in its own day, is frequently discussed today due to its almost prophetic take on the television industry. Dunaway's performance was lauded, with Vincent Canby of "The New York Times" saying that she "in particular, is successful in making touching and funny a woman of psychopathic ambition and lack of feeling." Dunaway's performance in "Network" earned her many awards. She was named Best Actress in the Kansas City Film Critics Awards, and she also received mentions from the New York Film Critics Circle and the National Society of Film Critics. She received her sixth Golden Globe nomination for "Network" and was awarded Best Actress in a Motion Picture – Drama. In early 1977, the Academy Awards nominated "Network" for ten awards, with Dunaway winning in her third Best Actress nomination.
Dunaway did not appear in another film until 1978. Jane Fonda, a friend and earlier co-star in "Hurry Sundown", asked Dunaway to co-star with her in "Julia", a drama based on a work of Lillian Hellman. Fonda, who was to play Hellman, wanted Dunaway to play the title role of Julia, a friend of Hellman's who fought against the Nazis before the Second World War. Dunaway turned Fonda down, wishing "to be quieter somehow" after her Oscar win. She later regretted not taking on the role. Vanessa Redgrave took on the role of Julia and won the Academy Award for Best Supporting Actress. At the same time, Dunaway received an offer from George Cukor to portray Victoria Woodhull, the first female candidate for President of the United States. The script titled "Vicky" was written by James Toback but, following Cukor’s previous film failure, the film never got made. Dunaway, who was eager to do it, felt "it remains one of the tragedies of the business that "Vicky" never became a movie."
She returned to the screen in 1978's "Eyes of Laura Mars", a thriller about a fashion photographer who sees visions of a killer murdering people. "Mars" was a success at the box office and Dunaway received positive reviews for her performance. In 1979, Dunaway took a small role in Franco Zeffirelli's remake of "The Champ" with Jon Voight. It was a chance for her to play the role of a mother, "which was emotionally where I wanted to be in my life."
"Mommie Dearest" and the 1980s.
In 1980, Dunaway accepted a small role in support of Frank Sinatra in "The First Deadly Sin", a thriller which ended up being Sinatra's final starring role. After completing the film, she played the title role in "Evita Peron", a television miniseries based on the life of the famed First Lady of Argentina.
Director Frank Perry, who had earlier directed Dunaway and Stacy Keach in 1971's "Doc", offered Dunaway the role of actress Joan Crawford in the adaptation of Christina Crawford's controversial memoirs, "Mommie Dearest". Christina's book had depicted her adopted mother as an abusive tyrant, who only adopted her four children to promote her acting career, making quite a stir as the first celebrity tell-all book. The film adaptation had been slated to star actress Anne Bancroft as Crawford, but Bancroft pulled out at the last minute, claiming the film was an unfair "hatchet job" on the screen legend Crawford. Dunaway wanted to tell the truth and show what it was like to be a star in Hollywood. After Perry and producer Frank Yablans assured her they didn’t want to make a tabloid version of Crawford’s life, Dunaway accepted the part. Dunaway worked with her makeup man, Lee Harman, for a long time to get the right look. She finally realized it was not only the makeup, but the way Crawford held herself and her face. When Dunaway walked on the set for the first time as the character, some people who had worked with Crawford told her "it was like seeing Joan herself back from the dead."
To play the role, Dunaway researched Crawford's films and met with many of Crawford's friends and co-workers, including George Cukor. Though Christina Crawford’s story was seen as an exploitation book, Dunaway was eager to portray her mother as "a full woman, who she was in all her facets, not just one." She saw Crawford as a woman "who was so needy, and so in need of approval and love." She also felt that Crawford "gave everything to this little girl, and judging by my research, a great deal of love. And then to be so rebuffed and so cooly treated by this little Scandinavian girl. It was understandable to me that Joan did have areas that could erupt into anger and fury." In "Looking for Gatsby", Dunaway revealed that she screamed herself hoarse during the film's infamous "No wire hangers!" tantrum scene. Frank Sinatra drove her to see a throat specialist and shared his own tips on how to preserve her voice. She described filming to James Lipton as "a real nightmare".
The film premiered in September 1981 to lacerating reviews. Roger Ebert, of "The Chicago Sun-Times" opened his by stating, "I can't imagine who would want to subject themselves to this movie," and went on to criticize the film's narrative sense, sensationalism, and the relationship between Joan and Christina Crawford. Though the film was poorly received by the critics, Dunaway's performance received many positive reviews. Janet Maslin, while dismissing the film as incoherent, wrote that Dunaway's performance was "a small miracle" and praised Dunaway's energy and commitment to the role. The frequently harsh Pauline Kael raved about Dunaway's performance, stating that she had reached new heights as an actress and surmised that it would be difficult for Dunaway to top her performance as Crawford. Vincent Canby also praised Dunaway, writing that ""Mommie Dearest" doesn't work very well, but the ferocious intensity of Faye Dunaway's impersonation does, as does the film's point of view, which succeeds in making Joan Crawford into a woman far more complicated, more self-aware and more profoundly disturbed than the mother remembered in Christina Crawford's book." Director Sidney Lumet stated that it was "a brilliant, an extraordinary performance. The courage of that evil that she brings to it, I think that’s just major acting."
After the hostile reaction from critics, the film continued to play in theatres. But after the first month of release, various audiences began to watch it in an ironic light, laughing at Dunaway's performance and ridiculing various campy lines and situations. Audiences flocked to see the film and took Ajax cleaning solution and wire hangers to "participate" in the screenings (similar to the "The Rocky Horror Picture Show" screenings). Paramount Pictures decided to capitalize on the film's reputation as an unintentional comedy, and began to promote it as a camp classic. Dunaway was horrified and upset to find the film now had the tagline of "Meet the biggest MOTHER of them all!", feeling that her work had been reduced to little more than a joke. She refused to promote the film or participate in its release.
Dunaway was named runner-up for the Best Actress award at both the New York Film Critics Circle Awards and the National Society of Film Critics Awards for her work in "Mommie Dearest". Dunaway told interviewer James Lipton that she was uncomfortable with being associated with the "Mommie Dearest" persona, and felt people attributed many of Crawford's diva-like qualities to Dunaway herself. In the early 2000s, Dunaway began to refuse to discuss the film at all. Following the same distinction for her interpretation of Bonnie Parker, the American Film Institute again named a Dunaway interpretation, this of Crawford, to be one of the greatest villainous characters in cinema history – 41st in a list of 50, and named the infamous line, "No wire hangers, ever!" to be one of the most memorable film quotes of all time.
Dunaway enjoyed, briefly (12 previews, 32 performances), a return to Broadway starring in "The Curse of An Aching Heart", by William Alfred. The play opened at the Little Theatre (now Helen Hayes Theatre) on Jan 25, 1982. "The beauteous and appealing star gives a winning performance.." wrote a reviewer for the "New York Daily News", ".. Miss Dunaway's absence from the theater has not dimmed her stage technique. She's usually in command," wrote Frank Rich in the "New York Times".
Dunaway then, in 1982, portrayed Georgie Elgin (the 1954 Academy Award-winning role for Grace Kelly) for television in a reproduction of the Clifford Odets original 1950 play "The Country Girl". During this time, Dunaway moved to England with her partner of several years, the English photographer Terry O'Neill. Being more interested in her married life, she only took on work that was "convenient" for her, and often picked substandard or even mediocre projects to appear in. Laurence Olivier asked her to play the role of Regan in his television adaptation of "King Lear", but she turned him down. Instead, she agreed to do the "The Wicked Lady", which was a commercial and artistic failure.
After "The Wicked Lady", she was intrigued by an offer to play the lead villain in the new superhero film, "Supergirl". She thought the project was a chance for her to play a comedic character. She felt that "the film was really just a send-up, a spoof, and I had a lot of fun with Selena (her character)." She later admitted she was "mad" at the director, Jeannot Szwarc. "Every time I tried to do something funny, he wouldn't let me. He said, 'you have to be the straight person'. I always wanted to do comedy but it's daunting when you've not done it before." The film was a critical and commercial failure.
Also in 1984, Dunaway appeared in a television miniseries, "Ellis Island". She played the role of highly stylish actress Maud Charteris who marries a Senator played by Richard Burton. She received complimentary reviews, and won her second Golden Globe for her work. The following year, she starred in the miniseries, "Christopher Columbus". She appeared in two Agatha Christie adaptations, "Ordeal by Innocence" and "Thirteen at Dinner" (which was made for television). Dunaway said that she struggled to find artistically fulfilling roles during this period in England. She turned down a chance to star on the nighttime soap opera "The Colbys" around this time, as well. Her husband and she attempted to bring the play "Duet for One" to the screen with O'Neill directing and Dunaway in the leading role, but their plans fell through. The film was eventually made in 1986 with Julie Andrews in the lead role.
"Barfly", independent films and stage roles.
In 1987, Dunaway began appearing in independent films. French director Barbet Schroeder gave her star billing alongside Mickey Rourke in the drama "Barfly". The film was produced by the struggling Cannon Films, and the producers had to fight to get the small drama approved. Produced on a budget of $3,000,000, Dunaway and Rourke played seedy alcoholics. The film was a small success at the box office, but received excellent reviews from critics, the best Dunaway had received in over a decade. Dunaway received her sixth Golden Globe nomination for Best Actress.
In 1989, she produced "Cold Sassy Tree". Dunaway played an enchanting dressmaker who lightens up the lives of a young boy (Neil Patrick Harris) and his grandfather (veteran actor Richard Widmark), whom she marries to the town's disapproval. The film aired on TNT, and received decent reviews from critics.
She appeared with Robert Duvall, with whom she had co-starred in "Network," and actress Natasha Richardson in "The Handmaid's Tale" (1990). She received an offer from Serbian director Emir Kusturica to star alongside Johnny Depp and Jerry Lewis in "Arizona Dream," a surreal comedy-drama. Dunaway played the role of Elaine, a somewhat crazy woman who dreams of building a flying machine. The film premiered in France in early 1993 to great acclaim. Dunaway was very proud of the film, and believed that her role could bring her career to higher heights than ever. However, Warner Bros. elected to re-edit Kusturica's film, cutting and changing it. Dunaway was dismayed to find that some of her best scenes were left out of the American version. Warner Bros. released the film in 1994 to positive reviews, but little box office.
Dunaway was cast as the leading lady of a sitcom, "It Had to Be You" with actor Robert Urich. The series did not work, and was cancelled after four episodes had aired. NBC contacted Dunaway and wanted her to take on the role of a female sleuth, more in the vein of "Columbo" than "Murder, She Wrote". As the prospective series was being developed, Dunaway contacted "Columbo" star Peter Falk, wanting his advice on how to approach playing a sleuth character. While discussing the role, Falk told Dunaway about a "Columbo" script that he had written himself. "It's All in the Game" featured a sexy society woman who plays a game of cat-and-mouse with Lt. Columbo in the midst of a murder. Falk had written the script some years prior, saying that he could not find the right actress to take on the role. He offered her the role, and Dunaway accepted immediately. The 1993 TV movie proved a success, nominated for several Golden Globe and Emmy Awards. Dunaway was recognized with the Primetime Emmy Award for Outstanding Guest Actress in a Drama Series, saying it was that moment when she felt like she was truly home.
With the prospective detective show not working out, Dunaway became interested in returning to the stage. She auditioned to replace Glenn Close in the musical "Sunset Boulevard", a stage version of 1950 film of the same name. The composer and producer Andrew Lloyd Webber cast Dunaway in the famed role of Norma Desmond, and Dunaway began rehearsing to take over the LA engagement from Close when Close moved the show to Broadway. Tickets went on sale for Dunaway's engagement, but shortly after the rehearsals started, Webber and his associates announced that Dunaway was unable to sing to their desired standards. They announced that when Close finished her engagement, the show would shut down completely. Dunaway filed a lawsuit, claiming that Webber had damaged her reputation with his claims. The case went to court and a settlement was later reached, but Dunaway and the producers have not discussed it.
After the "Sunset Blvd." debacle, Dunaway appeared with Marlon Brando and Johnny Depp in the romantic comedy "Don Juan DeMarco "(1995). A hit at the box office, the film was praised for its romance and the performances of the three main characters. Three unsuccessful films followed, but Dunaway received a Star on the Hollywood Walk of Fame at 7021 Hollywood Boulevard. She returned to the stage in 1996, playing famed opera singer Maria Callas in the Tony Award winning play "Master Class" by Terrence McNally. Dunaway toured the play through the United States. In 1998, she starred with Angelina Jolie in "Gia", a biographical film about the rise and fall of supermodel Gia Carangi.Playing the small but key role of Carangi's agent, Dunaway was well reviewed and won her third Golden Globe Award.
Recent career.
In 2000, she appeared in James Gray’s "The Yards" as Charlize Theron’s mother, and turned down "Requiem for a Dream". In 2001, she earned a Golden Globe nomination for Best Supporting Actress in a Series, Miniseries or Television Film for her performance in "Running Mates". Dunaway later appeared mostly in television guest roles and small independent movies. In 2002, she played Ian Somerhalder’s rich Xanax-popping mother in Roger Avary's adaptation of Bret Easton Ellis' novel, "The Rules of Attraction". In 2006, Dunaway guest-starred in one episode of the crime drama "" because she was a huge fan of the show. She also appeared on "Touched by an Angel", "Alias" and "Grey's Anatomy". She served as a judge on the 2005 reality show "The Starlet", which sought, "American Idol"-style, to find the next young actress with the potential to become a major star.
In 2008, Dunaway agreed to star in a low-budget Welsh film, "Flick", for a fraction of her usual £1million fee after falling in love with the script. She called the writer and director David Howard personally to accept the part of a one-armed American detective, saying it was "a really original story." The film premiered at the Raindance Film Festival. That same year, she criticized Hollywood’s treatment of older women, saying: "I am furious that they think I'm too old to play the love interest of guys like Jack Nicholson and Clint Eastwood. Why should I play sisters and mothers while guys like Jack and Clint, who are older than me, have on-screen lovers half their age?" Dunaway’s last screen appearance to date was in a Hallmark Channel film, "A Family Thanksgiving" (2010).
Dunaway announced in 2009 that she had secured financing and planned to direct and star in a film version of the McNally play "Master Class", with her son Liam Dunaway O'Neill playing an opera student. The production was plagued by lawsuits and difficulties in financing, but in 2013, she said three-quarters of the film had been shot. However, in June 2014, Dunaway withdrew from the project and HBO announced that Mike Nichols would produce a film of "Master Class" with Meryl Streep as Callas.
In 2011, a photo of Dunaway taken by Jerry Schatzberg in 1970 was chosen as the 64th annual Cannes Film Festival poster backdrop. The festival organizers described it as a "Model of sophistication and timeless elegance, it is an embodiment of the cinematic dream that the Festival de Cannes seeks to maintain." During the festival, Dunaway and Schatzberg appeared at a special screening of "Puzzle of a Downfall Child," earning a standing ovation upon their entrance. In 2013, Dunaway was the first recipient of the Leopard Club Award. She made a rare personal appearance at the Locarno International Film Festival to accept the award.
In 2014, Dunaway was recognized as the guest of honor by the Lumière Film Festival. Organizers praised the "immense contribution she has made to the emergence of the independent American films of the sixties and seventies, and the contribution is of the highest caliber." Her attendance at the festival was described as an "exceptional event." Dunaway received a standing ovation by a crowd of 5,000 and declared in an emotional speech following the tribute she received, "My fans and my friends have supported me in this search for all these years and I thank you from all of my heart and without you I would not be the same Faye Dunaway."
In 2016, after a six-year hiatus, Dunaway returned to the screen with the horror-thriller "The Bye Bye Man".
Personal life.
Dunaway was engaged to Jerry Schatzberg, who directed her in "Puzzle of a Downfall Child", and had a two-year live-in relationship with actor Marcello Mastroianni, her co-star in "A Place for Lovers". In 1974, Dunaway married Peter Wolf, the lead singer of the rock group The J. Geils Band; they divorced in 1979. From 1983 to 1987, she was married to Terry O'Neill, a British photographer. She and O'Neill have one child, Liam O'Neill (born 1980). In 2003, despite Dunaway's earlier indications that she had given birth to Liam, Terry revealed that Liam was adopted.
Dunaway is an adult convert to Roman Catholicism.
In August, 2011, Dunaway was sued for eviction by the landlord of her rent stabilized apartment in Manhattan. The suit alleged that she was not actually residing in the apartment but rather lived in California. Dunaway said that she had not been evicted, but had "chosen to leave because of the state of the apartment, and also because I am spending less and less time in New York."

</doc>
<doc id="68323" url="https://en.wikipedia.org/wiki?curid=68323" title="Susan Sarandon">
Susan Sarandon

Susan Abigail Sarandon (; née Tomalin; born October 4, 1946) is an American actress. She is an Academy Award and BAFTA Award winner who is also known for her social and political activism for a variety of liberal causes. She was appointed a UNICEF Goodwill Ambassador in 1999 and received the Action Against Hunger Humanitarian Award in 2006.
Sarandon began her career in the 1970 film" Joe", before appearing in the soap opera "A World Apart" (1970–71). In 1975, she starred in the cult classic film "The Rocky Horror Picture Show". She was nominated for the Academy Award for Best Actress for "Atlantic City" (1980), "Thelma & Louise" (1991), "Lorenzo's Oil" (1992) and "The Client" (1994), before winning for "Dead Man Walking" (1995). She has also won the BAFTA Award for Best Actress in a Leading Role for "The Client", and the Screen Actors Guild Award for Best Actress for "Dead Man Walking".
She made her Broadway debut in "An Evening with Richard Nixon" in 1972, and went on to receive Drama Desk Award nominations for the Off-Broadway plays, "A Coupla White Chicks Sitting Around Talking" (1979) and "Extremities" (1982). She returned to Broadway in the 2009 revival of "Exit the King".
On television, she is a five-time Emmy Award nominee, including for her guest roles on the sitcoms "Friends" (2001) and "Malcolm in the Middle" (2002), and the TV films "Bernard and Doris" (2007) and "You Don't Know Jack" (2010). Her other films include "Pretty Baby" (1978), "The Hunger" (1983), "The Witches of Eastwick" (1987), "Bull Durham" (1988), "White Palace" (1990), "Little Women" (1994), "Stepmom" (1998), "Igby Goes Down" (2002), "Enchanted" (2007), "The Lovely Bones" (2009), "Arbitrage" (2012) and "Tammy" (2014).
Early life.
Sarandon was born in Jackson Heights, Queens, New York City. She is the eldest of nine children born to Lenora Marie (née Criscione; b. 1923) and Phillip Leslie Tomalin (1917–1999), an advertising executive, television producer, and one-time nightclub singer. She has four brothers: Philip Jr., Terry, Tim and O'Brian and four sisters: Meredith, Bonnie, Amanda and Missy. Her father was of English, Irish, and Welsh ancestry, his English ancestors being from Hackney in London and his Welsh ancestors being from Bridgend. On her mother's side, she is of Italian descent, with ancestors from the regions of Tuscany and Sicily. Sarandon was raised Roman Catholic and attended Roman Catholic schools. She grew up in Edison, New Jersey, where she graduated from Edison High School in 1964. She then attended The Catholic University of America, from 1964 to 1968, and earned a BA in drama and worked with noted drama coach and master teacher, Father Gilbert V. Hartke.
Career.
In 1969, Sarandon went to a casting call for the motion-picture "Joe" with her then husband Chris Sarandon. Although he did not get a part, she was cast in a major role of a disaffected teen who disappears into the seedy underworld (the film was released in the summer of 1970). Between 1970 and 1972, she appeared on the soap operas "A World Apart" and "Search for Tomorrow", playing Patrice Kahlman and Sarah Fairbanks, respectively. In 1975, she appeared in the cult favorite "The Rocky Horror Picture Show". That same year, she also played the female lead in "The Great Waldo Pepper", opposite Robert Redford. Her first controversial film appearance was in "Pretty Baby" in 1978, a prostitution drama directed by Louis Malle. On stage, she received Drama Desk Award nominations for her work in the Off-Broadway plays "A Coupla White Chicks Siting Around Talking" (1979) and "Extremities" (1982).
Sarandon's performance in "Atlantic City" (1980) earned her first Academy Award nomination as Best Actress. In 1983 she co-starred in Tony Scott's "The Hunger", a modern vampire story in which she had a lesbian sex scene with Catherine Deneuve. One of her biggest commercial successes came in 1987 with "The Witches of Eastwick" alongside Jack Nicholson, Cher, and Michelle Pfeiffer. However, Sarandon did not become a "household name" until her A-list breakthrough in the 1988 film "Bull Durham", where she starred opposite Kevin Costner.
Sarandon received four more Academy Award nominations for Best Actress, in "Thelma & Louise" (1991), "Lorenzo's Oil" (1992), and "The Client" (1994), finally winning in 1995 for "Dead Man Walking". She was awarded the Women in Film Crystal Award in 1994.
Additional film performances include "White Palace" (1990), "Little Women" (1994), "Stepmom" (1998), "Anywhere but Here" (1999), "The Banger Sisters" (2002), "Shall We Dance" (2004), "Alfie" (2004), "Romance & Cigarettes" (2005), "Elizabethtown" (2005) and "Enchanted" (2007). Sarandon has appeared in two episodes of "The Simpsons", once as herself ("Bart Has Two Mommies") and as a ballet teacher, "Homer vs. Patty and Selma". She appeared on "Friends", "Malcolm in the Middle", "Mad TV", "Saturday Night Live", "Chappelle's Show", "30 Rock", "Rescue Me" and "Mike & Molly".
Sarandon has contributed the narration to two dozen documentary films, many of which dealt with social and political issues. In addition she has served as the presenter on many installments of the PBS documentary series, "Independent Lens". In 1999 and 2000 she hosted and presented "Mythos", a series of lectures by the late American mythology professor Joseph Campbell. Sarandon also participates as a member of the Jury for the NYICFF, a local New York City Film Festival dedicated to screening films made for children between the ages of 3 and 18.
Sarandon joined the cast of the adaptation of "The Lovely Bones", opposite Rachel Weisz, and appeared with her daughter, Eva Amurri, in "Middle of Nowhere"; both films were made in 2007.
In June 2010 Sarandon joined the cast of the HBO pilot "The Miraculous Year", as Patty Atwood, a Broadway director/choreographer. However, the series was not picked up. In 2012 Sarandon's audiobook performance of Carson McCullers' "The Member of the Wedding" was released at Audible.com.
Sarandon was the voice actor for the character of Granny Rags, an eccentric and sinister old lady, in the stealth/action video game "Dishonored", released in 2012.
Activism.
Sarandon is noted for her active support of progressive and liberal political causes, ranging from donations to organizations such as EMILY's List, to participating in a 1983 delegation to Nicaragua sponsored by MADRE, an organization that promotes "social, environmental and economic justice." Sarandon has expressed support for various human rights causes that are similar philosophically to ideas found among the left-wing supporters.
In 1995, Sarandon was one of many Hollywood actors, directors and writers interviewed for the documentary "The Celluloid Closet," which looked at how Hollywood films have depicted homosexuality. In 1999, she was appointed UNICEF Goodwill Ambassador. In that capacity, she has actively supported the organization's global advocacy, as well as the work of the Canadian UNICEF Committee.
During the 2000 election, Sarandon supported Ralph Nader's run for president, serving as a co-chair of the National Steering Committee of Nader 2000.
During the 2004 election campaign, she withheld support for Nader's bid, being among several "Nader Raiders" who urged Nader to drop out and his voters offer their support for Democratic Party candidate John Kerry. After the 2004 election, Sarandon called for US elections to be monitored by international entities.
Sarandon and Robbins both took an early stance against the 2003 invasion of Iraq, with Sarandon stating that she was firmly against war as a pre-emptive strike. Prior to a 2003 protest sponsored by the United for Peace and Justice coalition, she said that many Americans "do not want to risk their children or the children of Iraq". Sarandon was one of the first to appear in a series of political ads sponsored by TrueMajority, an organization established by Ben & Jerry's Ice Cream founder Ben Cohen. In 2003 she appeared in a "Love is Love is Love" commercial, which promoted the acceptance of gay, lesbian, bisexual and transgender individuals. The next year, in 2004, she served on the advisory committee for 2004 Racism Watch, an activist group. She hosted a section of the Live 8 concert in Edinburgh, Scotland, in 2005. In 2006, she was one of eight women selected to carry in the Olympic flag at the Opening Ceremony of the 2006 Olympic Winter Games, in Turin, Italy.
Along with anti-war activist Cindy Sheehan, Sarandon took part in a 2006 Mother's Day protest, which was sponsored by Code Pink; she has expressed interest in portraying Sheehan in a film. In January 2007, she appeared with Robbins and Jane Fonda at an anti-war rally in Washington, D.C. in support of a Congressional measure to withdraw U.S. forces from Iraq.
In the 2008 U.S. presidential election, Sarandon and Tim Robbins campaigned for John Edwards in the New Hampshire communities of Hampton, Bedford and Dover. When asked at We Vote '08 Kickoff Party "What would Jesus do this primary season", Sarandon said, "I think Jesus would be very supportive of John Edwards."
Sarandon was appointed an FAO Goodwill Ambassador in 2010. "I am proud to help draw everyone’s attention to the very real and dramatic problems of hunger, food insecurity and extreme poverty," she said.
On March 12, 2011, Sarandon spoke before a crowd in Madison, Wisconsin protesting Governor Scott Walker and his Budget Repair Bill. On September 27, 2011, Sarandon spoke to reporters and interested parties at the Occupy Wall Street protest in New York City.
Her use of the term "Nazi" to describe Pope Benedict XVI on October 15, 2011, created controversy, generating complaints from Roman Catholic authorities, and the Anti-Defamation League, which called on Sarandon to apologize. Sarandon's mother Leonora Tomalin is a staunch Republican, a supporter of George W. Bush and the Iraq War.
As a result of her work in the movie, "Dead Man Walking", in which she portrayed Sister Helen Prejean, Sarandon has become an advocate to end the death penalty and mass incarceration. She has joined the team of people fighting to save the life of Richard Glossip, a man who is on death row in Oklahoma. In May 2015, Sarandon launched a campaign with fundraising platform Represent.com to sell T-shirts to help finance the documentary "Deep Run", the story of a poor North Carolina teen undergoing a gender transition. 
In the 2016 U.S. presidential election, she has made public her support for Vermont Senator Bernie Sanders.
On March 28, 2016 in an interview on "All In with Chris Hayes", Sarandon indicated that she and other Sanders supporters might not support Hillary Clinton if Clinton is the Democratic nominee for President. She stated: "You know, some people feel that Donald Trump will bring the revolution immediately. If he gets in, then things will really explode." Hayes inquired as to whether it would be dangerous to allow Trump to become president, to which she replied: "If you think that it's pragmatic to shore up the status quo right now, then you're not in touch with the status quo".
Recognition.
In 2006, Sarandon received the Action Against Hunger Humanitarian Award. She was honored for her work as a UNICEF Goodwill Ambassador, an advocate for victims of hunger and HIV/AIDS and a spokesperson for Heifer International.
Sarandon received the Lifetime Achievement Award at the 2009 Stockholm International Film Festival, was inducted into the New Jersey Hall of Fame in 2010, and received the Outstanding Artistic Life Award for her Outstanding Contribution to World Cinema at the 2011 Shanghai International Film Festival. In 2013, she was invited to inaugurate the 44th International Film Festival of India (IFFI) in Goa. In 2015, Sarandon received the Goldene Kamera international lifetime achievement award.
Personal life.
While in college, she met fellow student Chris Sarandon and the couple married on September 16, 1967. They divorced in 1979, but she retained the surname Sarandon as her stage name. She then had a relationship with Louis Malle, who directed her in "Pretty Baby" and "Atlantic City". Sarandon had a relationship with musician David Bowie around the time they worked together on the film "The Hunger" (1983), which she describes as "a really interesting period." In the mid-1980s Sarandon dated Italian filmmaker Franco Amurri, and gave birth to their daughter, actress Eva Amurri, on March 15, 1985. From 1988 to 2009 Sarandon was in a relationship with actor Tim Robbins, whom she met while they were filming "Bull Durham". They have two sons – Jack Henry (born May 15, 1989) and Miles Guthrie (born May 4, 1992). On March 1, 2014, the documentary "Storied Streets", produced by Sarandon and directed by Jack Henry Robbins was released. The film deals with homelessness across the United States.
In 2006, Sarandon and ten relatives, including her then-partner, Tim Robbins and her son, Miles, travelled to Wales to trace her family's Welsh genealogy. Their journey was documented by the BBC Wales programme, "Coming Home: Susan Sarandon". Much of the same research and content was featured in the American version of "Who Do You Think You Are?". She also received the "Ragusani nel mondo" prize in 2006; her Sicilian roots are in Ragusa, Italy.
Sarandon is the co-owner of New York ping-pong club SPiN, and its Toronto branch SPiN Toronto.
Sarandon split with her long-time partner, Robbins, in 2009. Following the dissolution of her relationship, she soon began a relationship with Jonathan Bricklin, son of Malcolm Bricklin. They operated the SPiN ping-pong lounges together. Sarandon and Bricklin broke up in 2015.
Sarandon is a vegetarian.

</doc>
<doc id="68325" url="https://en.wikipedia.org/wiki?curid=68325" title="Eurovision Song Contest 1957">
Eurovision Song Contest 1957

The Eurovision Song Contest 1957 was the second edition of the annual Eurovision Song Contest. It was held on Sunday 3 March 1957 in Frankfurt-am-Main, West Germany. It was won by the Netherlands with "Net als toen", performed by Corry Brokken. Like the first 1956 edition, this one was still mainly a radio programme, but there was a noticeable increase in the number of people with televisions.
For some time, a rumour had existed that the privilege of hosting the 1957 contest was given to Germany because they had come in second place in 1956 with "Im Wartesaal zum großen Glück" by Walter Andreas Schwarz. In fact, not only were the official 1956 scores withheld, but the rule stating that the winning nation hosts the next year's Eurovision Song Contest had not yet been conceived. It was planned at the time that each participating country would take it in turns to host the event. However, as more countries wished to participate, this became impractical.
Location.
The contest took place in Frankfurt, at the time one of the largest cities in West Germany. The host venue was the Großer Sendesaal des hessischen Rundfunks, a building, music hall and former television studio based in Frankfurt am Main. It was the former headquarters for the Hessischer Rundfunk broadcast. Today it is used as a music hall.
After being devastated in the Second World War during the early 1940s, Frankfurt rebuilt itself well into the 1950s into one of Europe's most prominent financial centres. With investments coming in from both national and international financial institutions, 1957, the year of the contest, already saw the first of Frankfurt's high-rise business buildings.
Format.
In this year's contest the Italian entry lasted for 5:09 minutes, whilst the UK's entry lasted for only 1:52 minutes. It was because of songs like the former that a rule was eventually introduced restricting each song to a maximum of 3 minutes; this rule still applies.
In a change of rules from the previous year's contest, duos were allowed to compete. Danish representatives, Birthe Wilke and Gustav Winckler, were the first of such acts to participate under this rule change. At the end of their performance, the couple exchanged the longest kiss in the contest's history, although only people with televisions could actually see it. This was due to a member of the production staff forgetting to give a pre-arranged sign that the kiss should end.
This was the first year where the juries were contacted by telephone. It was also the first time the Netherlands won the contest. Another notable change was that the national juries could not vote for their own song, a rule which would be continued throughout the contest's subsequent history.
Participating countries.
Belgium, France, Germany, Italy, Luxembourg, Netherlands, and Switzerland make their second appearances following their débuts in 1956. Austria, Denmark, and the United Kingdom made their débuts; these countries had wanted to participate in 1956, but had applied to the European Broadcasting Union after the deadline for song submissions for that year's contest had passed, thus missing it. With those joining in 1957, the total number of countries was ten, three more than in the first ever contest.
Conductors.
Each performance had a conductor who maestro the orchestra.
Returning artists.
The contest saw the return of two artists who had participated in the previous edition of the contest. Corry Brokken for Netherlands; and Lys Assia for Switzerland.
International broadcasts and voting.
The table below shows the order in which votes were cast during the 1957 contest along with the spokesperson who was responsible for announcing the votes for their respective country. Each national broadcaster also sent a commentator to the contest, in order to provide coverage of the contest in their own native language. Details of the commentators and the broadcasting station for which they represented are also included in the table below.

</doc>
<doc id="68326" url="https://en.wikipedia.org/wiki?curid=68326" title="Extended periodic table">
Extended periodic table

An extended periodic table theorizes about elements beyond element 118 (beyond period 7, or row 7). Currently seven periods in the periodic table of chemical elements are known and proven, culminating with atomic number 118.
If further elements with higher atomic numbers than this are discovered, they will be placed in additional periods, laid out (as with the existing periods) to illustrate periodically recurring trends in the properties of the elements concerned. Any additional periods are expected to contain a larger number of elements than the seventh period, as they are calculated to have an additional so-called g-block, containing at least 18 elements with partially filled g-orbitals in each period.
An eight-period table containing this block was suggested by Glenn T. Seaborg in 1969. IUPAC defines an element to exist if its lifetime is longer than 10−14 seconds, which is the time it takes for the nucleus to form an electronic cloud. No elements in this region have been synthesized or discovered in nature. The first element of the g-block may have atomic number 121, and thus would have the systematic name unbiunium. Elements in this region are likely to be highly unstable with respect to radioactive decay, and have extremely short half lives, although element 126 is hypothesized to be within an island of stability that is resistant to fission but not to alpha decay. It is not clear how many elements beyond the expected island of stability are physically possible, whether period 8 is complete, or if there is a period 9.
According to the orbital approximation in quantum mechanical descriptions of atomic structure, the g-block would correspond to elements with partially filled g-orbitals, but spin-orbit coupling effects reduce the validity of the orbital approximation substantially for elements of high atomic number. While Seaborg's version of the extended period had the heavier elements following the pattern set by lighter elements, as it did not take into account relativistic effects, models that take relativistic effects into account do not. Pekka Pyykkö and B. Fricke used computer modeling to calculate the positions of elements up to "Z" = 184 (comprising periods 8, 9, and the beginning of 10), and found that several were displaced from the Madelung rule.
Richard Feynman noted that a simplistic interpretation of the relativistic Dirac equation runs into problems with electron orbitals at "Z" > 1/α ≈ 137 as described in the sections below, suggesting that neutral atoms cannot exist beyond untriseptium, and that a periodic table of elements based on electron orbitals therefore breaks down at this point. On the other hand, a more rigorous analysis calculates the limit to be "Z" ≈ 173.
History.
It is unknown how far the periodic table might extend beyond the known 118 elements. Glenn T. Seaborg suggested that the highest possible element may be under "Z" = 130, while Walter Greiner predicted that there may not be a highest possible element.
All of these hypothetical undiscovered elements are named by the International Union of Pure and Applied Chemistry (IUPAC) systematic element name standard which creates a generic name for use until the element has been discovered, confirmed, and an official name approved. These names are typically not used in the literature, and are referred to by their atomic numbers; hence, element 164 would usually not be called "unhexquadium" (the IUPAC systematic name), but rather "element 164" with symbol "164", "(164)", or "E164".
, synthesis has been attempted for only ununennium, unbinilium, unbibium, unbiquadium, unbihexium, and unbiseptium. (Z = 119, 120, 122, 124, 126, and 127)
At element 118, the orbitals 1s, 2s, 2p, 3s, 3p, 3d, 4s, 4p, 4d, 4f, 5s, 5p, 5d, 5f, 6s, 6p, 6d, 7s and 7p are assumed to be filled, with the remaining orbitals unfilled. A simple extrapolation from the Aufbau principle would predict the eighth row to fill orbitals in the order 8s, 5g, 6f, 7d, 8p; but after element 120, the proximity of the electron shells makes placement in a simple table problematic. Although a simple extrapolation of the periodic table, following Seaborg's original concept, would put the elements after 120 as follows: 121-138 form the g-block superactinoids; 139-152 form the f-block superactinoids, 153-162 would be transition metals; 163-166 p-block metals; 167=halogen; 168=noble gas; 169=alkali metal; 170=alkaline earth metal, Dirac-Fock calculations predict that it will most likely go: 121-140 form the g-block superactinoids; 141-154 form the f-block superactinoids; 155-164 form the transition metals; 165=alkali metal; 166=alkaline earth metal; 167-170 p-block metals; 171=halogen; 172=noble gas.
Not all models show the higher elements following the pattern established by lighter elements. Pekka Pyykkö, for example, used computer modeling to calculate the positions of elements up to Z=172, and found that several were displaced from the Madelung energy-ordering rule. He predicts that the orbital shells will fill up in this order:
He also suggests that period 8 be split into three parts:
Fricke "et al." also predicted the extended periodic table up to 184. This model has been more widely used among scientists and is shown above as the main form of the extended periodic table.
Predicted properties of undiscovered elements.
Element 118 is the last element that has been synthesized. The next two elements, elements 119 and 120, should form an 8s series and be an alkali and alkaline earth metal respectively. Beyond element 120, the superactinide series is expected to begin, when the 8s electrons and the filling 8p1/2, 7d3/2, 6f5/2, and 5g7/2 subshells determine the chemistry of these elements. Complete and accurate CCSD calculations are not available for elements beyond 122 because of the extreme complexity of the situation: the 5g, 6f, and 7d orbitals should have about the same energy level, and in the region of element 160 the 9s, 8p3/2, and 9p1/2 orbitals should also be about equal in energy. This will cause the electron shells to mix so that the block concept no longer applies very well, and will also result in novel chemical properties that will make positioning these elements in a periodic table very difficult. For example, element 164 is expected to mix characteristics of the elements of group 10, 12, 14, and 18.
Chemical and physical properties.
8s elements.
The first two elements of period 8 are expected to be ununennium and unbinilium, elements 119 and 120. Their electron configurations should have the 8s orbital being filled. This orbital is relativistically stabilized and contracted and thus, elements 119 and 120 should be more like caesium and barium than their immediate neighbours above, francium and radium. Another effect of the relativistic contraction of the 8s orbital is that the atomic radii of these two elements should be about the same of those of francium and radium. They should behave like normal alkali and alkaline earth metals, normally forming +1 and +2 oxidation states respectively, but the relativistic destabilization of the 7p3/2 subshell and the relatively low ionization energies of the 7p3/2 electrons should make higher oxidation states like +3 and +4 (respectively) possible as well.
Superactinides.
The superactinide series is expected to contain elements 121 to 155. In the superactinide series, the 7d3/2, 8p1/2, 6f5/2 and 5g7/2 shells should all fill simultaneously: this creates very complicated situations, so much so that complete and accurate CCSD calculations have been done only for elements 121 and 122. The first superactinide, unbiunium (element 121), should be a congener of lanthanum and actinium and should have similar properties to them: its main oxidation state should be +3, although the closeness of the valence subshells' energy levels may permit higher oxidation states, just like in elements 119 and 120. Relativistic stabilization of the 8p subshell should result in a ground-state 8s28p1 valence electron configuration for element 121, in contrast to the ds2 configurations of lanthanum and actinium. Its first ionization energy is predicted to be 429.4 kJ/mol, which would be lower than those of all known elements except for the alkali metals potassium, rubidium, caesium, and francium: this value is even lower than that of the period 8 alkali metal ununennium (463.1 kJ/mol). Similarly, the next superactinide, unbibium (element 122), may be a congener of cerium and thorium, with a main oxidation state of +4, but would have a ground-state 7d18s28p1 valence electron configuration, unlike thorium's 6d27s2 configuration. Hence, its first ionization energy would be smaller than thorium's (Th: 6.54 eV; Ubb: 5.6 eV) because of the greater ease of ionizing unbibium's 8p1/2 electron than thorium's 7s electron.
In the first few superactinides, the binding energies of the added electrons are predicted to be small enough that they can lose all their valence electrons; for example, unbihexium (element 126) could easily form a +8 oxidation state, and even higher oxidation states for the next few elements may be possible. Unbihexium is also predicted to display a variety of other oxidation states: recent calculations have suggested a stable monofluoride UbhF may be possible, resulting from a bonding interaction between the 5g orbital on unbihexium and the 2p orbital on fluorine. Other predicted oxidation states include +2, +4, and +6; +4 is expected to be the most usual oxidation state of unbihexium. The presence of electrons in g-orbitals, which do not exist in the ground state electron configuration of any currently known element, should allow presently unknown hybrid orbitals to form and influence the chemistry of the superactinides in new ways, although the absence of "g" electrons in known elements makes predicting their chemistry more difficult.
In the later superactinides, the oxidation states should become lower. By element 132, the predominant most stable oxidation state will be only +6; this is further reduced to +3 and +4 by element 144, and at the end of the superactinide series it will be only +2 (and possibly even 0) because the 6f shell, which is being filled at that point, is deep inside the electron cloud and the 8s and 8p1/2 electrons are bound too strongly to be chemically active. The 5g shell should be filled at element 144 and the 6f shell at around element 154, and at this region of the superactinides the 8p1/2 electrons are bound so strongly that they are no longer active chemically, so that only a few electrons can participate in chemical reactions. Calculations by Fricke "et al." predict that at element 154, the 6f shell is full and there are no d- or other electron wave functions outside the chemically inactive 8s and 8p1/2 shells. This would cause element 154 to be very unreactive, so that it may exhibit properties similar to those of the noble gases.
Similarly to the lanthanide and actinide contractions, there should be a superactinide contraction in the superactinide series where the ionic radii of the superactinides are smaller than expected. In the lanthanides, the contraction is about 4.4 pm per element; in the actinides, it is about 3 pm per element. The contraction is larger in the lanthanides than in the actinides due to the greater localization of the 4f wave function as compared to the 5f wave function. Comparisons with the wave functions of the outer electrons of the lanthanides, actinides, and superactinides lead to a prediction of a contraction of about 2 pm per element in the superactinides; although this is smaller than the contractions in the lanthanides and actinides, its total effect is larger due to the fact that 32 electrons are filled in the deeply buried 5g and 6f shells, instead of just 14 electrons being filled in the 4f and 5f shells in the lanthanides and actinides respectively.
Pekka Pyykkö divides these superactinides into three series: a 5g series (elements 121 to 138), an 8p1/2 series (elements 139 to 140), and a 6f series (elements 141 to 155), although noting that there would be a great deal of overlapping between energy levels and that the 6f, 7d, or 8p1/2 orbitals could well also be occupied in the early superactinide atoms or ions. He also expects that they would behave more like "superlanthanides", in the sense that the 5g electrons would mostly be chemically inactive, similarly to how only one or two 4f electrons in each lanthanide are ever ionized in chemical compounds. He also predicted that the possible oxidation states of the superactinides might rise very high in the 6f series, to values such as +12 in element 148.
7d transition metals.
The transition metals in period 8 are expected to be elements 156 to 164. Although the 8s and 8p1/2 electrons are bound so strongly in these elements that they should not be able to take part in any chemical reactions, the 9s and 9p1/2 levels are expected to be readily available for hybridization such that these elements will still behave chemically like their lighter homologues in the periodic table, showing the same oxidation states as they do, in contrast to earlier predictions which predicted the period 8 transition metals to have main oxidation states two less than those of their lighter congeners.
The noble metals of this series of transition metals are not expected to be as noble as their lighter homologues, due to the absence of an outer "s" shell for shielding and also because the 7d shell is strongly split into two subshells due to relativistic effects. This causes the first ionization energies of the 7d transition metals to be smaller than those of their lighter congeners.
Calculations predict that the 7d electrons of element 164 (unhexquadium) should participate very readily in chemical reactions, so that unhexquadium should be able to show stable +6 and +4 oxidation states in addition to the normal +2 state in aqueous solutions with strong ligands. Unhexquadium should thus be able to form compounds like Uhq(CO)4, Uhq(PF3)4 (both tetrahedral), and (linear), which is very different behavior from that of lead, which unhexquadium would be a heavier homologue of if not for relativistic effects. Nevertheless, the divalent state would be the main one in aqueous solution, and unhexquadium(II) should behave more similarly to lead than unhexquadium(IV) and unhexquadium(VI).
Unhexquadium should be a soft metal like mercury, and metallic unhexquadium should have a high melting point as it is predicted to bond covalently. It is also expected to be a soft Lewis acid and have Ahrlands softness parameter close to 4 eV. It should also have some similarities to ununoctium as well as to the other group 12 elements. Unhexquadium should be at most moderately reactive, having a first ionization energy that should be around 685 kJ/mol, comparable to that of molybdenum. Due to the lanthanide, actinide, and superactinide contractions, unhexquadium should have an metallic radius of only 158 pm, very close to that of the much lighter magnesium, despite its being expected to have an atomic weight of around 474 u, about 19.5 times as much as that of magnesium. This small radius and high weight cause it to be expected to have an extremely high density of around 46 g·cm−3, over twice that of osmium, currently the most dense element known, at 22.61 g·cm−3; unhexquadium should be the second most dense element in the first 172 elements in the periodic table, with only its neighbour unhextrium (element 163) being more dense (at 47 g·cm−3). Metallic unhexquadium should be quite stable, as the 8s and 8p1/2 electrons are very deeply buried in the electron core and only the 7d electrons are available for bonding. Metallic unhexquadium should have a very large cohesive energy (enthalpy of crystallization) due to its covalent bonds, most probably resulting in a high melting point.
Theoretical interest in the chemistry of unhexquadium is largely motivated by theoretical predictions that it, especially the isotope 482Uhq (with 164 protons and 318 neutrons), would be at the center of a hypothetical second island of stability (the first being centered on 306Ubb).
Elements 165 to 172.
The next eight elements on the periodic table should be the last eight main-group elements before the end of the periodic table at "Z" = 173. Elements 165 (unhexpentium) and 166 (unhexhexium) should behave as normal alkali and alkaline earth metals when in the +1 and +2 oxidation states respectively. The 9s electrons should have ionization energies comparable to those of the 3s electrons of sodium and magnesium, due to relativistic effects causing the 9s electrons to be much more strongly bound than non-relativistic calculations would predict. Elements 165 and 166 should normally exhibit the +1 and +2 oxidation states respectively, although the ionization energies of the 7d electrons are low enough to allow higher oxidation states like +3 and +4 to occur quite commonly.
In elements 167 to 172, the 9p1/2 and 8p3/2 shells will be filled. Their energy eigenvalues are so close together that they behave as one combined "p" shell, similar to the non-relativistic 2p and 3p shells. Thus, the inert pair effect does not occur and the most common oxidation states of elements 167 to 170 should be +3, +4, +5, and +6 respectively. Element 171 (unseptunium) is expected to show some similarities to the halogens, showing various oxidation states ranging from –1 to +7. Its electron affinity should be 3.0 eV, allowing it to form HUsu, analogous to a hydrogen halide. The Usu− ion is expected to be a soft base, comparable to iodide (I−). Element 172 (unseptbium) should be a noble gas with chemical behaviour similar to that of xenon, as their ionization energies should be very similar (Xe, 1170.4 kJ/mol; Usb, 1090.3 kJ/mol). The only main difference between them is that element 172, unlike xenon, is expected to be a liquid or a solid at standard temperature and pressure due to its much higher atomic weight. Unseptbium should be a strong Lewis acid, forming fluorides and oxides, similarly to its lighter congener xenon. Because of this analogy of elements 165–172 to periods 2 and 3, Fricke "et al." considered them to form a ninth period of the periodic table, while the eighth period was taken by them to end at the noble metal element 164. This ninth and final period would be similar to the second and third period in that it should have no transition metals.
Beyond element 172.
Immediately after element 172 (unseptbium), the first noble gas after element 118 (the last period 7 element), it was originally expected that another long transition series like the superactinides should begin, filling the 6g, 7f, 8d, and perhaps 6h shells. These electrons would be very loosely bound, rendering extremely high oxidation states possibly easy to reach. Element 184 (unoctquadium) was significantly targeted in early predictions, as it was originally speculated that 184 would be a proton magic number.
However, these extrapolations are unlikely to be fulfilled, due to the looming end of the periodic table at "Z" = 173.
In element 173 (unsepttrium), the last electron would enter the 6g7/2 subshell.
End of the periodic table.
The number of physically possible elements is unknown. A low estimate is that the periodic table may end soon after the island of stability, which is expected to center on "Z" = 126, as the extension of the periodic and nuclides tables is restricted by the proton and the neutron drip lines; some, such as Walter Greiner, predict that there may not be an end to the periodic table. Other predictions of an end to the periodic table include "Z" = 128 (John Emsley) and "Z" = 155 (Albert Khazan).
Feynmanium and elements above the atomic number 137.
Richard Feynman noted that a simplistic interpretation of the relativistic Dirac equation runs into problems with electron orbitals at "Z" > 1/α ≈ 137 as described in the sections below, suggesting that neutral atoms cannot exist beyond untriseptium, and that a periodic table of elements based on electron orbitals therefore breaks down at this point. On the other hand, a more rigorous analysis calculates the limit to be "Z" ≈ 173.
Bohr model.
The Bohr model exhibits difficulty for atoms with atomic number greater than 137, for the speed of an electron in a 1s electron orbital, "v", is given by
where "Z" is the atomic number, and "α" is the fine structure constant, a measure of the strength of electromagnetic interactions. Under this approximation, any element with an atomic number of greater than 137 would require 1s electrons to be traveling faster than "c", the speed of light. Hence the non-relativistic Bohr model is clearly inaccurate when applied to such an element.
Relativistic Dirac equation.
The relativistic Dirac equation gives the ground state energy as
where "m" is the rest mass of the electron. For "Z" > 137, the wave function of the Dirac ground state is oscillatory, rather than bound, and there is no gap between the positive and negative energy spectra, as in the Klein paradox. More accurate calculations taking into account the effects of the finite size of the nucleus indicate that the binding energy first exceeds 2"mc"2 for "Z" > "Z"cr ≈ 173. For "Z" > "Z"cr, if the innermost orbital (1s) is not filled, the electric field of the nucleus will pull an electron out of the vacuum, resulting in the spontaneous emission of a positron. The precise details of what happens to atoms with "Z" > 173 are not known yet.
Nuclear properties.
The first island of stability is expected to be centered on unbibium-306 (with 122 protons and 184 neutrons), and the second is expected to be centered on unhexquadium-482 (with 164 protons and 318 neutrons). This second island of stability should confer additional stability on elements 152–168.
Calculations according to the Hartree–Fock–Bogoliubov Method using the non-relativistic Skyrme interaction have proposed Z=126 as a closed proton shell. In this region of the periodic table, N=184 and N=196 have been suggested as closed neutron shells. Therefore the isotopes of most interest are 310Ubh and 322Ubh, for these might be considerably longer-lived than other isotopes. Unbihexium, having a magic number of protons, is predicted to be more stable than other elements in this region, and may have nuclear isomers with very long half-lives.
Electron configurations.
The following are the expected electron configurations of elements 119–172.
Attempts to synthesize still undiscovered elements.
Projects to build period 8 elements that have had synthesis attempts were elements 119, 120, 122, 124, 126, and 127. So far, none of these synthesis attempts were successful.
Ununennium.
The synthesis of ununennium was attempted in 1985 by bombarding a target of einsteinium-254 with calcium-48 ions at the superHILAC accelerator at Berkeley, California:
No atoms were identified, leading to a limiting yield of 300 nb.
As of May 2012, plans are under way to attempt to synthesize the isotopes 295Uue and 296Uue by bombarding a target of berkelium with titanium at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany:
Unbinilium.
Attempts to date to synthesize the element using fusion reactions at low excitation energy have met with failure; although, there are reports that the fission of nuclei of unbinilium at very high excitation has been successfully measured, indicating a strong shell effect at Z=120.
In March–April 2007, the synthesis of unbinilium was attempted at the Flerov Laboratory of Nuclear Reactions in Dubna by bombarding a plutonium-244 target with iron-58 ions. Initial analysis revealed that no atoms of element 120 were produced providing a limit of 400 fb for the cross section at the energy studied.
The Russian team are planning to upgrade their facilities before attempting the reaction again.
In April 2007, the team at GSI attempted to create unbinilium using uranium-238 and nickel-64:
No atoms were detected providing a limit of 1.6 pb on the cross section at the energy provided. The GSI repeated the experiment with higher sensitivity in three separate runs from April–May 2007, Jan–March 2008, and Sept–Oct 2008, all with negative results and providing a cross section limit of 90 fb.
In June–July 2010, scientists at the GSI attempted the fusion reaction:
They were unable to detect any atoms but exact details are not currently available.
In August–October 2011, a different team at the GSI using the TASCA facility tried the new reaction:
Results from this experiment are not yet available.
In 2008, the team at GANIL, France, described the results from a new technique which attempts to measure the fission half-life of a compound nucleus at high excitation energy, since the yields are significantly higher than from neutron evaporation channels. It is also a useful method for probing the effects of shell closures on the survivability of compound nuclei in the super-heavy region, which can indicate the exact position of the next proton shell (Z=114, 120, 124, or 126).
The team studied the nuclear fusion reaction between uranium ions and a target of natural nickel:
The results indicated that nuclei of unbinilium were produced at high (~70 MeV) excitation energy which underwent fission with measurable half-lives > 10−18 s. Although very short, the ability to measure such a process indicates a strong shell effect at Z=120. At lower excitation energy (see neutron evaporation), the effect of the shell will be enhanced and ground-state nuclei can be expected to have relatively long half-lives. This result could partially explain the relatively long half-life of 294Uuo measured in experiments at Dubna. Similar experiments have indicated a similar phenomenon at Z=124 (see unbiquadium) but not for flerovium, suggesting that the next proton shell does in fact lie at Z>120.
The team at RIKEN have begun a program utilizing 248Cm targets and have indicated future experiments to probe the possibility of Z=120 being the next magic number using the aforementioned nuclear reactions to form 302Ubn.
Unbibium.
The first attempt to synthesize unbibium was performed in 1972 by Flerov "et al." at JINR, using the hot fusion reaction:
No atoms were detected and a yield limit of 5 mb (5,000,000,000 pb) was measured. Current results (see flerovium) have shown that the sensitivity of this experiment was too low by at least 6 orders of magnitude.
In 2000, the Gesellschaft für Schwerionenforschung (GSI) performed a very similar experiment with much higher sensitivity:
These results indicate that the synthesis of such heavier elements remains a significant challenge and further improvements of beam intensity and experimental efficiency is required. The sensitivity should be increased to 1 fb.
Another unsuccessful attempt to synthesize unbibium was carried out in 1978 at the GSI, where a natural erbium target was bombarded with xenon-136 ions:
The two attempts in the 1970s to synthesize unbibium were caused by research investigating whether superheavy elements could potentially be naturally occurring.
Several experiments have been performed between 2000-2004 at the Flerov laboratory of Nuclear Reactions studying the fission characteristics of the compound nucleus 306Ubb. Two nuclear reactions have been used, namely 248Cm + 58Fe and 242Pu + 64Ni. The results have revealed how nuclei such as this fission predominantly by expelling closed shell nuclei such as 132Sn (Z=50, N=82). It was also found that the yield for the fusion-fission pathway was similar between 48Ca and 58Fe projectiles, indicating a possible future use of 58Fe projectiles in superheavy element formation.
Unbiquadium.
In a series of experiments, scientists at GANIL have attempted to measure the direct and delayed fission of compound nuclei of elements with Z=114, 120, and 124 in order to probe shell effects in this region and to pinpoint the next spherical proton shell. This is because having complete nuclear shells (or, equivalently, having a magic number of protons or neutrons) would confer more stability on the nuclei of such superheavy elements, thus moving closer to the island of stability. In 2006, with full results published in 2008, the team provided results from a reaction involving the bombardment of a natural germanium target with uranium ions:
The team reported that they had been able to identify compound nuclei fissioning with half-lives > 10−18 s. This result suggests a strong stabilizing effect at Z=124 and points to the next proton shell at Z>120, not at Z=114 as previously thought. A compound nucleus is a loose combination of nucleons that have not arranged themselves into nuclear shells yet. It has no internal structure and is held together only by the collision forces between the target and projectile nuclei. It is estimated that it requires around 10−14 s for the nucleons to arrange themselves into nuclear shells, at which point the compound nucleus becomes an nuclide, and this number is used by IUPAC as the minimum half-life a claimed isotope must have to potentially be recognised as being discovered. Thus, the GANIL experiments do not count as a discovery of element 124.
Unbihexium.
The first and only attempt to synthesize unbihexium, which was unsuccessful, was performed in 1971 at CERN by René Bimbot and John M. Alexander using the hot fusion reaction:
A high energy alpha particle was observed and taken as possible evidence for the synthesis of unbihexium. Recent research suggests that this is highly unlikely as the sensitivity of experiments performed in 1971 would have been several orders of magnitude too low according to current understanding.
Unbiseptium.
Unbiseptium has had one failed attempt at synthesis in 1978 at the Darmstadt UNILAC accelerator by bombarding a natural tantalum target with xenon ions:
Possible natural occurrence.
On April 24, 2008, a group led by Amnon Marinov at the Hebrew University of Jerusalem claimed to have found single atoms of unbibium-292 in naturally occurring thorium deposits at an abundance of between 10−11 and 10−12, relative to thorium. The claim of Marinov "et al." was criticized by a part of the scientific community, and Marinov says he has submitted the article to the journals "Nature" and "Nature Physics" but both turned it down without sending it for peer review. The unbibium-292 atoms were claimed to be superdeformed or hyperdeformed isomers, with a half-life of at least 100 million years.
A criticism of the technique, previously used in purportedly identifying lighter thorium isotopes by mass spectrometry, was published in Physical Review C in 2008. A rebuttal by the Marinov group was published in Physical Review C after the published comment.
A repeat of the thorium-experiment using the superior method of Accelerator Mass Spectrometry (AMS) failed to confirm the results, despite a 100-fold better sensitivity. This result throws considerable doubt on the results of the Marinov collaboration with regards to their claims of long-lived isotopes of thorium, roentgenium and unbibium. It is still possible that traces of unbibium might only exist in some thorium samples, although this is unlikely.
It was suggested in 1976 that primordial superheavy elements (mainly livermorium, unbiquadium, unbihexium, and unbiseptium) could be a cause of unexplained radiation damage in minerals. This prompted many researchers to search for it in nature from 1976 to 1983. Some claimed that they had detected alpha particles with the right energies to cause the damage observed, supporting the presence of unbihexium, while some claimed that no unbihexium had been detected.
The possible extent of primordial unbihexium on Earth is uncertain; it might now only exist in traces, or could even have completely decayed by now after having caused the radiation damage long ago.
Cultural references.
Simon Mayo's "Itch" series concentrates on the story of a boy named Itchingham Lofte, who discovers Unbihexium (element 126). It is constantly referred to as '126' in the book, and is (fictionally) extremely radioactive. It is suggested (in fiction) to be named "Lofteinghiam".

</doc>
<doc id="68328" url="https://en.wikipedia.org/wiki?curid=68328" title="Basil Rathbone">
Basil Rathbone

Philip St. John Basil Rathbone, MC (13 June 1892 – 21 July 1967) was a South African Republic-born British actor. He rose to prominence in the United Kingdom as a Shakespearean stage actor and went on to appear in more than 70 films, primarily costume dramas, swashbucklers and, occasionally, horror films. 
Rathbone frequently portrayed suave villains or morally ambiguous characters, such as Mr. Murdstone in "David Copperfield" (1935) and Sir Guy of Gisbourne in "The Adventures of Robin Hood" (1938). His most famous role, however, was heroic — that of Sherlock Holmes in fourteen Hollywood films made between 1939 and 1946 and in a radio series. His later career included roles on Broadway, as well as self-ironic film and television work. He received a Tony Award in 1948 as Best Actor in a Play. He was also nominated for two Academy Awards and won three stars on the Hollywood Walk of Fame.
Early life.
Rathbone was born Philip St. John Basil Rathbone in Johannesburg, to British parents. His mother, Anna Barbara (née George), was a violinist, and his father, Edgar Philip Rathbone, was a mining engineer and scion of the Liverpool Rathbone family. He had two older half-brothers, Harold and Horace, as well as two younger siblings, Beatrice and John. Basil was the great-grandson of the noted Victorian philanthropist, William Rathbone V, and thus a descendant of William Rathbone II. The Rathbones fled to Britain when Basil was three years old after his father was accused by the Boers of being a spy after the Jameson Raid. He was a distant cousin of Major Henry Rathbone, who was present at the assassination of Abraham Lincoln and was seriously wounded trying to stop John Wilkes Booth.
Rathbone attended Repton School in Derbyshire from 1906 –1910, where he particularly excelled at sports. Thereafter, he was briefly employed by the Liverpool and Globe Insurance Companies, to appease his father's wish for him to have a conventional career..
On 22 April 1911, Rathbone made his first appearance on stage at the Theatre Royal, Ipswich, Suffolk, as Hortensio in "The Taming of the Shrew", with his cousin Sir Frank Benson's No. 2 Company, under the direction of Henry Herbert. In October 1912, he went to the United States with Benson's company, playing such parts as Paris in "Romeo and Juliet", Fenton in "The Merry Wives of Windsor", and Silvius in "As You Like It". Returning to Britain, he made his first appearance in London at the Savoy Theatre on 9 July 1914, as Finch in "The Sin of David". That December, he appeared at the Shaftesbury Theatre as the Dauphin in "Henry V". During 1915, he toured with Benson and appeared with him at London's Court Theatre in December as Lysander in "A Midsummer Night's Dream".
The Great War.
At the end of 1915, Rathbone was called up via the Derby Scheme into the British Army as a private with the London Scottish Regiment, joining a regiment that also counted in its ranks his future professional acting contemporaries Claude Rains, Herbert Marshall and Ronald Colman at different points through the conflict. After basic training with the London Scots in early 1916 he received a commission as a lieutenant in the 2/10th Battalion of the King's Liverpool Regiment (Liverpool Scottish), where he served as an intelligence officer and eventually attained the rank of captain. Rathbone's younger brother John was killed in action on 4 June 1918. It was after this that Rathbone convinced his superiors to allow him to scout enemy positions during daylight rather than at night, as was the usual practice to minimize the chance of detection. Rathbone describes it thus in his autobiography "Camouflage suits had been made for us to resemble trees. On our heads were wreaths of freshly plucked foliage, our faces and hands were blackened with burnt cork." As a result of these highly dangerous daylight raids In September 1918, he was awarded the Military Cross for "conspicuous daring and resource on patrol". Richard Van Emden in his book "Famous 1914-18" speculates that this extreme bravery may have been a form of guilt or a need for vengeance following his brother's death.
Two letters written by Rathbone to his family while serving in the war have recently come to light and help to shed light on his mental state at this time.
Career.
During the Summer Festival of 1919, he appeared at Stratford-upon-Avon with the New Shakespeare Company playing Romeo, Cassius, Ferdinand in "The Tempest" and Florizel in "The Winter's Tale"; in October he was at London's Queen's Theatre as the aide-de-camp in "Napoleon", and in February 1920 he was at the Savoy Theatre in the title role in "Peter Ibbetson" with huge success.
During the 1920s, Rathbone appeared regularly in Shakespearean and other roles on the British stage. He began to travel and appeared at the Cort Theatre, New York, in October 1923 in a production of "The Swan" opposite Eva Le Gallienne, which made him a star on Broadway. He toured in the United States in 1925, appearing in San Francisco in May and the Lyceum Theatre, New York, in October. He was in the US again in 1927 and 1930 and again in 1931, when he appeared on stage with Ethel Barrymore. He continued his stage career in Britain, returning late in 1934 to the US, where he appeared with Katharine Cornell in several plays.
Rathbone was once arrested in 1926 along with every other member of the cast of "The Captive", a play in which his character's wife left him for another woman. Though the charges were eventually dropped, Rathbone was very angry about the censorship because he believed that homosexuality needed to be brought into the open.
He commenced his film career in 1925 in "The Masked Bride", appeared in a few silent films, and played the detective Philo Vance in the 1930 film "The Bishop Murder Case", based on the best-selling novel. In the film there is a coincidental reference to Sherlock Holmes. Like George Sanders and Vincent Price after him, Rathbone made a name for himself in the 1930s by playing suave villains in costume dramas and swashbucklers, including "David Copperfield" (1935) as the abusive stepfather Mr. Murdstone; "Anna Karenina" (1935) as her distant husband, Karenin; "The Last Days of Pompeii" (1935) with a masterful portrayal of Pontius Pilate; "Captain Blood" (1935); "A Tale of Two Cities" (1935), as the Marquis St. Evremonde; "The Adventures of Robin Hood" (1938) playing his best-remembered villain, Sir Guy of Gisbourne; "The Adventures of Marco Polo" (1938); and "The Mark of Zorro" (1940) as Captain Esteban Pasquale. He also appeared in several early horror films: "Tower of London" (1939), as Richard III, and "Son of Frankenstein" (1939), portraying the dedicated surgeon Baron Wolf von Frankenstein, son of the monster's creator, and, in 1949, was also the narrator for the segment "The Wind in the Willows" in the animated feature, "The Adventures of Ichabod and Mr. Toad".
He was admired for his athletic cinema swordsmanship (he listed fencing among his favourite recreations). He fought and lost to Errol Flynn in a duel on the beach in "Captain Blood" and in an elaborate fight sequence in "The Adventures of Robin Hood". He was involved in noteworthy sword fights in "Tower of London", "The Mark of Zorro", and "The Court Jester" (1956). Despite his real-life skill, Rathbone won only once onscreen, in "Romeo and Juliet" (1936). Rathbone earned Academy Award nominations for Best Actor in a Supporting Role for his performances as Tybalt in "Romeo and Juliet" (1936) and as King Louis XI in "If I Were King" (1938). In "The Dawn Patrol" (1938), he played one of his few heroic roles in the 1930s, as a Royal Flying Corps (RFC) squadron commander brought to the brink of a nervous breakdown by the strain and guilt of sending his battle-weary pilots off to near-certain death in the skies of 1915 France. Errol Flynn, Rathbone's perennial foe, starred in the film as his successor when Rathbone's character was promoted.
According to Hollywood legend, Rathbone was Margaret Mitchell's first choice to play Rhett Butler in the film version of her novel "Gone with the Wind". The reliability of this story may be suspect, however, as on another occasion Mitchell chose Groucho Marx for the role, apparently in jest. Rathbone actively campaigned for the role, however, but to no avail.
Despite his film success, Rathbone always insisted that he wished to be remembered for his stage career. He said that his favourite role was that of Romeo.
The Sherlock Holmes films.
Rathbone is most widely recognised for his many portrayals of Sherlock Holmes. In a radio interview Rathbone recalled that Twentieth Century-Fox producer and director Gene Markey, lunching with producer-director-actor Gregory Ratoff and 20th Century-Fox mogul Daryl Zanuck at Lucey's Restaurant in Hollywood, proposed a film version of Sir Arthur Conan Doyle's "The Hound of the Baskervilles", and when asked who could possibly play Holmes, Markey incredulously replied, ""Who?!" Basil Rathbone!" The film was so successful that Fox produced a sequel which appeared later in 1939. Interest in Holmes cooled at Fox but Universal Pictures picked up the character and twelve feature films were made between 1941 and 1944 for release until 1947, all of which co-starred Nigel Bruce as Dr. Watson.
The first two films, "The Hound of the Baskervilles" and "The Adventures of Sherlock Holmes" (both produced by Fox in 1939), were set in the late Victorian times of the original stories. The later installments, produced by Universal, beginning with "Sherlock Holmes and the Voice of Terror" (1942), were set in contemporary times. The first three had World War II-related plots.
Concurrent with the films, Rathbone and Bruce reprised their film roles in a radio series, "The New Adventures of Sherlock Holmes", which began in October 1939. Rathbone appeared in the radio series as long as the film series was active, but after the films lapsed in 1946, Rathbone ceded his radio part to Tom Conway. Conway and Bruce carried on with the series for two seasons, until both dropped out in July 1947.
The many Holmes sequels typecast Rathbone, and he was unable to shake himself completely free from the shadow of the Great Detective despite appearing in other film roles. Resenting the typecasting, Rathbone refused to renew his contract at Metro-Goldwyn-Mayer and returned to Broadway. In later years, however, Rathbone willingly made the Holmes association, as in a TV sketch with Milton Berle in the early 1950s, in which he donned the deerstalker cap and Inverness cape. In the 1960s, dressed as Holmes, he appeared in a series of TV commercials for Getz Exterminators ("Getz gets 'em, since 1888!'").
Rathbone also brought Holmes to the stage in a play written by his wife Ouida. Thomas Gomez, who had appeared as a Nazi ringleader in "Sherlock Holmes and the Voice of Terror", played the villainous Professor Moriarty. Nigel Bruce was slated to portray Dr Watson once more but became too ill and the part was played by character actor Jack Raine. Bruce's absence depressed Rathbone, particularly after Bruce died on 8 October 1953, while the play was in rehearsals. The play ran for only three performances.
Later career.
In the 1950s, Rathbone appeared in two spoofs of his earlier swashbuckling villains: "Casanova's Big Night" (1954) opposite Bob Hope and "The Court Jester" (1956) with Danny Kaye. He appeared frequently on TV game shows and continued to appear in major films, including the Humphrey Bogart comedy "We're No Angels" (1955) and John Ford's political drama "The Last Hurrah" (1958).
Rathbone also appeared on Broadway numerous times. In 1948, he won a Tony Award for Best Actor for his performance as the unyielding Dr. Austin Sloper in the original production of "The Heiress", which featured Wendy Hiller as his timid, spinster daughter. He also received accolades for his performance in Archibald Macleish's "J.B.", a modernisation of the Biblical trials of Job.
Through the 1950s and 1960s, he continued to appear in several dignified anthology programmes on television. To support his second wife's lavish tastes, he appeared as a panelist on the television game show "The Name's the Same" (in 1954), and he also took roles in cheap film thrillers of far lesser quality, such as "The Black Sleep" (1956), "Queen of Blood" (1966), "The Ghost in the Invisible Bikini" (1966, with comic Harvey Lembeck joking, "That guy looks like Sherlock Holmes"), "Hillbillys in a Haunted House" (1967, also featuring Lon Chaney Jr and John Carradine), and his last film, a low-budget, Mexican horror film called "Autopsy of a Ghost" (1968).
He is also known for his spoken word recordings, including his interpretation of Clement C. Moore's "The Night Before Christmas". Rathbone's readings of the stories and poems of Edgar Allan Poe are collected together with readings by Vincent Price in Caedmon Audio's "The Edgar Allan Poe Audio Collection" on CD. Rathbone also made many other recordings, of everything from a dramatised version of "Oliver Twist" to a recording of Prokofiev's "Peter and the Wolf" (with Leopold Stokowski conducting) to a dramatised version of Charles Dickens's "A Christmas Carol".
On television he appeared in two musical versions of Dickens's "A Christmas Carol": one in 1954, in which he played Marley's Ghost opposite Fredric March's Scrooge, and the original 1956 live-action version of "The Stingiest Man In Town", in which he starred as a singing Ebenezer Scrooge.
In the 1960s, he also toured with a one-man show titled (like his autobiography) "In and Out of Character". In this show, he recited poetry and Shakespeare as well as giving reminiscences from his life and career (e.g., the humorous, "I could have killed Errol Flynn any time I wanted to!"). As an encore, he recited "221B" a poem written by writer-critic Vincent Starrett, one of the preemiennt members of the Baker Street Irregulars whom Rathbone held in high regard.
Vincent Price and Rathbone appeared together, along with Boris Karloff, in "Tower of London" (1939) and "The Comedy of Terrors" (1964). The latter was the only film to feature the "Big Four" of American International Pictures' horror films: Price, Rathbone, Karloff and Peter Lorre. Rathbone also appeared with Price in the final segment of Roger Corman's 1962 anthology film "Tales of Terror", a loose dramatisation of Poe's "The Facts in the Case of M. Valdemar."
In 1965 Belmont Books issued the anthology "Basil Rathbone Selects Strange Tales", a collection of classic horror stories by Poe, Hawthorne, Bulwer-Lyttton, Charles Dickens, Allston Collins, Le Fanu, and Wilkie Collins. The volume features a cover portrait of Rathbone; however, the back cover's legend "Produced by Lyle Kenyon Engel" indicates the anthology was probably not edited by Rathbone himself. Canadian editor and book packager Engel packaged shows and magazines for other horror movie stars including Boris Karloff.
Basil Rathbone has three stars on the Hollywood Walk of Fame: one for films, at 6549 Hollywood Boulevard; one for radio, at 6300 Hollywood Boulevard; and one for television, at 6915 Hollywood Boulevard in Hollywood.
Personal life.
Rathbone married actress Ethel Marion Foreman in 1914. They had one son, Rodion Rathbone (1915–1996), who had a brief Hollywood career under the name John Rodion. The couple divorced in 1926. In 1924 he was involved in a brief relationship with Eva Le Gallienne. In 1927, he married writer Ouida Bergère; the couple adopted a daughter, Cynthia Rathbone (1939–1969). The American actor Jackson Rathbone is a distant relation (a third cousin, several times removed). Basil Rathbone was a first cousin once-removed of the British campaigning independent MP, Eleanor Rathbone.
During Rathbone's Hollywood career, Ouida Rathbone, who was also her husband's business manager, developed a reputation for hosting elaborate expensive parties in their home, with many prominent and influential people on the guest lists. This trend inspired a joke in "The Ghost Breakers" (1940), a film in which Rathbone does not appear: During a tremendous thunderstorm in New York City, Bob Hope observes that "Basil Rathbone must be throwing a party". Actress Mrs. Patrick Campbell described Rathbone as "two profiles pasted together". As cited in the same autobiography, Mrs. Campbell would later refer to him as, "a folded umbrella taking elocution lessons."
He was the cousin of the eminent actor Frank Benson, to whom he bore a strong resemblance. Benson's elder brother, W. A. S. Benson, was well known in the world of art as one of the pioneers in the revival of English industrial craftsmanship, especially in the field of the metallic arts; and his younger brother, Godfrey Benson, was a Liberal politician.
Death.
Rathbone died suddenly of a heart attack in New York City on 21 July 1967 at age 75. He is interred in a crypt in the "Shrine of Memories" Mausoleum at Ferncliff Cemetery in Hartsdale, New York.

</doc>
<doc id="68332" url="https://en.wikipedia.org/wiki?curid=68332" title="Frank Jarvis">
Frank Jarvis

Frank Washington Jarvis (August 31, 1878 – June 2, 1933) was an American athlete, and the Olympic 100 m champion of 1900.
Jarvis, an AAU champion in the 100 y, was among the pre-race favourites for the 100 m at the 1900 Summer Olympics in Paris, but the hot favourite was American Arthur Duffey, who won the British Championships just prior to the Games.
In the heats, however, Jarvis and another American, Walter Tewksbury, posted times of 10.8, equalling the World Record. All three Americans qualified for the final, complemented by Stan Rowley of Australia. After a close first half of the final race, leading Duffey pulled a muscle, fell, and retired the race, leaving the three others to decide for the victory—Jarvis won.
At the same Olympics, Jarvis also competed in the triple jump and the standing triple jump (with no run-up), but did not achieve top classifications.
After his running career, Jarvis became a lawyer.

</doc>
<doc id="68334" url="https://en.wikipedia.org/wiki?curid=68334" title="Desktop environment">
Desktop environment

In computing, a desktop environment (DE) is an implementation of the desktop metaphor made of a bundle of programs running on top of a computer operating system, which share a common graphical user interface (GUI). The desktop environment was seen mostly on personal computers until the rise of mobile computing. Desktop GUIs help the user to easily access and edit files, while they usually do not provide access to all of the features found in the underlying operating system. Instead, the traditional command-line interface (CLI) is still used when full control over the operating system is required.
A desktop environment typically consists of icons, windows, toolbars, folders, wallpapers and desktop widgets (see Elements of graphical user interfaces and WIMP). A GUI might also provide drag and drop functionality and other features that make the desktop metaphor more complete. A desktop environment aims to be an intuitive way for the user to interact with the computer using concepts which are similar to those used when interacting with the physical world, such as buttons and windows.
While the term "desktop environment" originally described a style of user interfaces following the desktop metaphor, it has also come to describe the programs that realize the metaphor itself. This usage has been popularized by projects such as the Common Desktop Environment, K Desktop Environment, and GNOME.
Implementation.
On a system that offers a desktop environment, a window manager in conjunction with applications written using a widget toolkit are generally responsible for most of what the user sees. The window manager supports the user interactions with the environment, while the toolkit provides developers a software library for applications with a unified look and behavior.
A windowing system of some sort generally interfaces directly with the underlying operating system and libraries. This provides support for graphical hardware, pointing devices, and keyboards. The window manager generally runs on top of this windowing system. While the windowing system may provide some window management functionality, this functionality is still considered to be part of the window manager, which simply happens to have been provided by the windowing system.
Applications that are created with a particular window manager in mind usually make use of a windowing toolkit, generally provided with the operating system or window manager. A windowing toolkit gives applications access to widgets that allow the user to interact graphically with the application in a consistent way.
History and common use.
The first desktop environment was created by Xerox and was sold with the Xerox Alto in the 1970s. The Alto was generally considered by Xerox to be a personal office computer; it failed in the marketplace because of poor marketing and a very high price tag. With the Lisa, Apple introduced a desktop environment on an affordable personal computer, which also failed in the market.
The desktop metaphor was popularized on commercial personal computers by the original Macintosh from Apple in 1984, and was popularized further by Windows from Microsoft since the 1990s. , the most popular desktop environments are descendants of these earlier environments, including the Aero environment used in Windows Vista and Windows 7, and the Aqua environment used in OS X. When compared with the X-based desktop environments available for Unix-like operating systems such as Linux and FreeBSD, the proprietary desktop environments included with Windows and OS X have relatively fixed layouts and static features, with highly integrated "seamless" designs that aim to provide mostly consistent customer experiences across installations.
Microsoft Windows dominates in marketshare among personal computers with a desktop environment. Computers using Unix-like operating systems such as OS X, Chrome OS, Linux, BSD or Solaris are much less common; however, there is a growing market for low-cost Linux PCs using the X Window System or Wayland with a broad choice of desktop environments. Among the more popular of these are Google's Chromebooks and Chromeboxes, Intel's NUC, the Raspberry Pi, etc.
On tablets and smartphones, the situation is the opposite, with Unix-like operating systems dominating the market, including the iOS (BSD-derived), Android, Tizen, Sailfish and Ubuntu (all Linux-derived). Microsoft's Windows phone, Windows RT and Windows 10 are used on a much smaller number of tablets and smartphones. However, the majority of Unix-like operating systems dominant on handheld devices do not use the X11 desktop environments used by other Unix-like operating systems, relying instead on interfaces based on other technologies.
Desktop environments for the X Window System.
On systems running the X Window System (typically Unix-family systems such as GNU/Linux, the BSDs, and formal UNIX distributions), desktop environments are much more dynamic and customizable to meet user needs. In this context, a desktop environment typically consists of several separate components, including a window manager (such as Mutter or KWin), a file manager (such as Files or Dolphin), a set of graphical themes, together with toolkits (such as GTK+ and Qt) and libraries for managing the desktop. All these individual modules can be exchanged and independently configured to suit users, but most desktop environments provide a default configuration that works with minimal user setup.
Some window managerssuch as IceWM, Fluxbox, Openbox, ROX Desktop and Window Makercontain relatively sparse desktop environment elements, such as an integrated spatial file manager, while others like evilwm and wmii do not provide such elements. Not all of the program code that is part of a desktop environment has effects which are directly visible to the user. Some of it may be low-level code. KDE, for example, provides so-called KIO slaves which give the user access to a wide range of virtual devices. These I/O slaves are not available outside the KDE environment.
Initially, CDE was available as a proprietary solution, but was never popular on Linux systems due to cost and licensing restrictions. In 1996 the KDE was announced, followed in 1997 by the announcement of GNOME. Xfce is a smaller project that was also founded in 1996, and focuses on speed and modularity, just like LXDE which was started in 2006. A comparison of X Window System desktop environments demonstrates the differences between environments. GNOME and KDE were usually seen as dominant solutions, and these are still often installed by default on Linux systems. Each of them offers:
In the early 2000s, KDE reached maturity along with GNOME. The Appeal and ToPaZ projects focused on bringing new advances to the next major releases of both KDE and GNOME respectively. Although striving for broadly similar goals, GNOME and KDE do differ in their approach to user ergonomics. KDE encourages applications to integrate and interoperate, is highly customizable, and contains many complex features, all whilst trying to establish sensible defaults. GNOME on the other hand is more prescriptive, and focuses on the finer details of essential tasks and overall simplification. Accordingly, each one attracts a different user and developer community. Technically, there are numerous technologies common to all Unix-like desktop environments, most obviously the X Window System. Accordingly, the freedesktop.org project was established as an informal collaboration zone with the goal being to reduce duplication of effort.
As GNOME and KDE focus on high-performance computers, users of less powerful or older computers often prefer alternative desktop environments specifically created for low-performance systems. Most commonly used lightweight desktop environments include LXDE and Xfce; they both use GTK+, which is the same underlying toolkit GNOME uses. The MATE desktop environment, a fork of GNOME 2, is comparable to Xfce in its use of RAM and processor cycles, but is often considered more as an alternative to other lightweight desktop environments.
For a while, GNOME and KDE enjoyed the status of the most popular Linux desktop environments; later, other desktop environments grew in popularity. In April 2011, GNOME introduced a new interface concept with its version 3, while a popular Linux distribution Ubuntu introduced its own new desktop environment, Unity. Some users preferred to keep the traditional interface concept of GNOME 2, resulting in the creation of MATE as a GNOME 2 fork.
Examples of desktop environments.
The most common desktop environment on personal computers is Microsoft Windows' built-in interface. It was titled Luna in Windows XP and Aero from Windows Vista onward. Also common is Aqua, included with Apple's Mac OS X.
Mainstream desktop environments for Unix-like operating systems use the X Window System, and include KDE, GNOME, Xfce, and LXDE, any of which may be selected by users and are not tied exclusively to the operating system in use.
A number of other desktop environments also exist, including (but not limited to) CDE, EDE, GEM, IRIX Interactive Desktop, Sun's Java Desktop System, Jesktop, Mezzo, Project Looking Glass, ROX Desktop, UDE, Xito, XFast. Moreover, there exists FVWM-Crystal, which consists of a powerful configuration for the FVWM window manager, a theme and further adds, altogether forming a "construction kit" for building up a desktop environment.
X window managers that are meant to be usable stand-alone — without another desktop environment — also include elements reminiscent of those found in typical desktop environments, most prominently Enlightenment. Other examples include OpenBox, Fluxbox, WindowLab, Fvwm, as well as Window Maker and AfterStep, which both feature the NeXTSTEP GUI look and feel.
The Amiga approach to desktop environment was noteworthy: the original Workbench desktop environment in AmigaOS evolved through time to originate an entire family of descendants and alternative desktop solutions. Some of those descendants are the Scalos, the Ambient desktop of MorphOS, and the Wanderer desktop of the AROS open source OS. WindowLab also contains features reminiscent of the Amiga UI. Third-party Directory Opus software, which was originally just a navigational file manager program, evolved to become a complete Amiga desktop replacement called Directory Opus Magellan.
There is the Workplace Shell that runs on IBM OS/2 or eComStation.
The BumpTop project is an experimental desktop environment. Its main objective is to replace the 2D paradigm with a "real-world" 3D implementation, where documents can be freely manipulated across a virtual table.

</doc>
<doc id="68335" url="https://en.wikipedia.org/wiki?curid=68335" title="Anna Nicole Smith">
Anna Nicole Smith

Anna Nicole Smith (born Vickie Lynn Hogan; November 28, 1967 – February 8, 2007) was an American model, actress and television personality. Smith first gained popularity in "Playboy", winning the 1993 Playmate of the Year. She modeled for fashion companies including Guess, H&M, Heatherette, Lane Bryant.
Smith dropped out of high school and was married three years later in 1985. Her highly publicized second marriage to J. Howard Marshall resulted in speculation that she married the octogenarian mainly for his money, which she denied. Following Marshall's death, Smith began a lengthy legal battle over a share of his estate. Her case, "Marshall v. Marshall", reached the U.S. Supreme Court on a question of federal jurisdiction, and again on a question of bankruptcy court authority (now called "Stern v. Marshall"). Smith died on February 8, 2007 in a Hollywood, Florida, hotel room as a result of an overdose of prescription drugs. During the final six months of her life, Smith was the focus of renewed press coverage surrounding the death of her son, Daniel, and the paternity and custody battle over her newborn daughter, Dannielynn.
Early life.
Born Vickie Lynn Hogan in Houston, Texas, and raised in Mexia, Texas, Anna Nicole was the daughter of Donald Eugene Hogan (July 12, 1947 – September 19, 2009) and Virgie Mae (née Tabers; born July 12, 1951), who married on February 22, 1967 and divorced on November 4, 1969. She had five half siblings, Donna Hogan, David Tacker Jr., Donnie Hogan, Amy Hogan and Donald Hart. Anna Nicole was raised by her mother and aunt. Virgie subsequently married Donald R. Hart in 1971. After Virgie married Donald, Anna Nicole changed her name from Vickie Hogan to Nikki Hart.
Anna Nicole attended Durkee Elementary School and Aldine Senior High School in Houston. When she was in the ninth grade, she was sent to live with her mother's younger sister, Kay Beall, in Mexia, Texas. At Mexia High School, Anna Nicole failed her freshman year and dropped out of school during her sophomore year.
While working at Jim's Krispy Fried Chicken in Mexia, Anna Nicole met Billy Wayne Smith, who was a cook at the restaurant; the couple married April 4, 1985.
Modeling career.
In 1992, Smith appeared on the March cover of "Playboy" magazine, with her name given as Vickie Smith. She later appeared as the Playmate of the Month for the May 1992 issue, in a pictorial shot by Stephen Wayda.
Smith next secured a contract to replace supermodel Claudia Schiffer in a Guess jeans ad campaign featuring a series of sultry black-and-white photographs. During the Guess campaign Smith changed her name to Anna Nicole Smith. Guess photographers noticed Smith bore a striking resemblance to bombshell Jayne Mansfield and showcased her in several Mansfield-inspired photo sessions. In 1993 before Christmas, she modeled for the Swedish clothing company H&M. This led to her being pictured on large billboards in Sweden and Norway.
In addition to "Playboy", Smith has appeared on the cover of German "Marie Claire" magazine, photographed by Peter Lindbergh, "New York", "Arena", "FHM", and in editorials for "Vanity Fair", "Harper's Bazaar", Italian "Vogue", "W", "Photo", "The Face".
A photograph of Smith was used by "New York" magazine on the cover of its August 22, 1994, issue titled "White Trash Nation". In the photo she appears squatting in a short skirt with cowboy boots as she eats chips. In October 1994, her lawyer initiated a $5 million lawsuit against the magazine claiming unauthorized use of her photo, and that the article damaged her reputation. Her lawyer stated Smith was under the impression that she was being photographed to embody the "all-American girl look", but they instead wanted more sexy photos. He further stated the photo the magazine used was taken during a break just for fun. The lawsuit was reported to be settled.
Marriage to J. Howard Marshall (1994 - 1995).
While performing at Gigi's, a Houston strip club (later renamed as "Pleasures") in October 1991, Smith met elderly oil tycoon J. Howard Marshall, and they began a relationship. During their two-year affair, he reportedly lavished gifts on her and asked her to marry him several times. She divorced her husband Billy on February 3, 1993, in Houston. On June 27, 1994, 26-year-old Smith and 89-year-old Marshall were married in Houston. This resulted in a great deal of gossip about her marrying him for his money. She reportedly never lived with him, never made love with him, or kissed him on the mouth more than ten times. Smith, however, maintained that she loved her husband, and age did not matter to her. Thirteen months after his marriage to Smith, Marshall died in Houston at age 90, on August 4, 1995.
Inheritance court cases.
Within weeks of J. Howard Marshall's death, one of his sons, E. Pierce Marshall, disputed her claim for half of her late husband's US$1.6 billion estate. She temporarily joined forces with J. Howard's other son, James Howard Marshall III, whom the elder Howard had disowned. Howard III claimed that J. Howard Marshall had verbally promised him a portion of the estate; like Smith, Howard III was also left out of J. Howard's will. The case had gone on for more than a decade, producing a highly publicized court battle in Texas and several judicial decisions that have gone both for and against Smith in that time.
In 1996, Smith filed for bankruptcy in California as a result of a $850,000 judgment against her for sexual harassment of an employee. As any money potentially due to her from the Marshall estate was part of her potential assets, the bankruptcy court involved itself in the matter.
Smith claimed that J. Howard had orally promised her half of his estate if she married him. In September 2000, a Los Angeles bankruptcy judge awarded her $449,754,134. In July 2001, Houston judge Mike Wood affirmed the jury findings in the probate case by ruling that Smith was entitled to nothing. The judge ordered Smith to pay over $1 million in fees and expenses to Pierce's legal team. The conflict between the Texas probate court and California bankruptcy court judgments forced the matter into federal court.
In March 2002, a federal judge vacated the California bankruptcy court's ruling and issued a new ruling but reduced the award to $88 million. In December 2004, a three-judge panel of the U.S. 9th Circuit Court of Appeals reversed the March 2002 decision, on the reasoning that the federal courts lacked jurisdiction to overrule this probate court decision.
The U.S. Supreme Court decided in September 2005 to hear the appeal of that decision. The Bush administration subsequently directed the Solicitor General to intercede on Smith's behalf out of an interest to expand federal court jurisdiction over state probate disputes. After months of waiting, Smith and her stepson Pierce learned of the Supreme Court's decision on May 1, 2006. The justices unanimously decided in favor of Smith; Justice Ruth Bader Ginsburg wrote the majority opinion. The decision did not give Smith a portion of her husband's estate, but affirmed her right to pursue a share of it in federal court. On June 20, 2006, E. Pierce Marshall died at age 67 from an "aggressive infection". Following his death, his widow, Elaine T. Marshall, pursued the case on behalf of his estate. The case was remanded to the 9th Circuit to adjudicate the remaining appellate issues not previously resolved.
After Smith's death, the "New York Times" reported that the case over the Marshall fortune "is likely to continue in the name of Ms. Smith's infant daughter." The current situation is that Anna Nicole Smith's estate will not inherit any of her late husband's estate. Following the decision by the Appeals Court for the Ninth Circuit, lawyers for the estate of Anna Nicole Smith requested the appeal be heard before the entire 9th circuit. However, on May 6, 2010 the appeal was denied. On September 28, 2010, the U.S. Supreme Court again agreed to hear the case.
On June 23, 2011, the U.S. Supreme Court issued a ruling against the estate of Anna Nicole Smith, holding that a bankruptcy court ruling giving her estate a sum of $475 million was decided without jurisdiction (now called "Stern v. Marshall"). A California bankruptcy court awarded Smith part of the estate, but the 9th U.S. Circuit Court of Appeal said that a bankruptcy court could not make a decision on an issue outside bankruptcy law.
The U.S. Supreme Court agreed with the ruling of the 9th Circuit Court of Appeals.
Film and television career.
Despite her success as a model, Smith never found the same recognition or success as an actress. A twenty-six-year-old Smith debuted on the screen in the 1994 screwball comedy film, "The Hudsucker Proxy". She appeared as Za-Za, a flirtatious celebrity who flirts with the lead character, played by Tim Robbins, in a barbershop scene. Smith was next given a larger role as Tanya Peters in "" (1994), which was released seven days after her initial film debut. Her role in the film, that of a pivotal contact to a crime, earned her favorable reviews and the film enjoyed box office success. Despite the publicity for her performance in both films, they each did very little to improve her acting career.
Smith wanted to be taken more seriously as an actress, but Hollywood studios were reluctant. Her persona of a ditzy dumb blonde was compressed heavily in her film roles, which sought only to market her physical assets. In an attempt to earn acting respect, Smith agreed to appear in "To the Limit" (1995), which would be her first starring role. In the film she played Colette Dubois, a retired spy seeking revenge on the murderer of her late husband. Although the film was highly publicized and boasted a lavish budget and script, Smith's performance drew negative reviews and it was an ultimate box office bomb. It offered Smith's first and only venture in a mainstream Hollywood leading role.
By 1996, Smith's acting career had declined considerably. After the failure of her previous motion picture, Hollywood studios began to realize her public popularity did not affect her acting abilities or ticket sales at the box office. She appeared as herself in the 1995 pilot episode of "The Naked Truth". Smith attempted to revitalize her film career with a leading role in "Skyscraper" in 1996. The low-budget, direct-to-video film offered Smith no more than "soft-core exploitation" and her movie career again stalled.
In the late 1990s, Smith focused her acting career on television. She appeared on the variety series "Sin City Spectacular" in 1998. That same year, Smith appeared in the tell-all self-promoting film, "Anna Nicole Smith: Exposed", which was based on several photo sessions during her Playboy career. She appeared as Donna, the friend of Veronica Chase played by Kirstie Alley, on the sitcom "Veronica's Closet" in 1999. Smith guest-starred as Myra Jacobs in a 1999 episode of the surreal series, "Ally McBeal".
In the early 2000s, Smith had very few acting roles. As a result of her rising popularity with tabloids and gossip columnists, Smith was given her own reality show on the E! cable network. "The Anna Nicole Show" premiered on August 4, 2002, achieving the highest cable rating ever issued for a reality show. Coincidentally, the day the series premiered was the seventh anniversary of the death of J. Howard Marshall. The series attempted to focus on the private life of Smith, her boyfriend/attorney Howard K. Stern, her son Daniel, her assistant Kimberly "Kimmie" Walther, her miniature poodle Sugar Pie, her gay interior decorator Bobby Trendy, and her cousin from Texas, Shelly Cloud.
Despite the popularity of the show amongst college students and pop culture fans, the show declined considerably in viewership at the end of its first season. It was, however, renewed for a second season, before being cancelled on June 1, 2003, after two seasons and twenty-seven episodes. E! announced to the press that the series ended because of "creative differences" between the network and Smith, although she acknowledged the series ended because the network had lost interest in both her and the show.
Smith returned to film acting in 2003 with the comedy film "Wasabi Tuna". In the film she played an over-the-top version of herself, whose miniature poodle Sugar Pie is stolen from her on Halloween by a team of drag queens dressed like her. Neither the film nor her performance drew positive reviews. In 2005, she briefly appeared as a spectator at a basketball game in "Be Cool", starring John Travolta. In late 2005 she agreed to play Lucy in the self-produced independent parody film "Illegal Aliens", alongside wrestler Joani "Chyna" Laurer. It attempted to parody several popular television shows from the 1970s and 1980s as well as several film franchises. It would be released direct-to-video on May 1, 2007, three months after her death.
Smith as spokeswoman.
In an interview on "Late Night with Conan O'Brien", Smith was asked what her "Playmate diet" consisted of. She instantly replied, "fried chicken". In October 2003, she became a spokeswoman for TrimSpa, which helped her lose a reported .
In November 2004, she appeared at the American Music Awards to introduce Kanye West and attracted attention because of her slurred speech and behavior. During her live appearance, she threw her arms up and exclaimed, "Like my body?" Smith murmured other comments and alluded to TrimSpa. The incident became comic material for presenters throughout the rest of the program.
The following day, her appearance was featured in the media. Tabloids speculated that Smith was under the influence of pills or some other controlled substance. Her representatives explained that she was in pain due to a series of grueling workouts.
In March 2005, at the first MTV Australia Video Music Awards in Sydney's Luna Park, she did Janet Jackson's wardrobe malfunction by pulling down her dress to reveal both breasts, each covered with the MTV logo.
Smith was also featured in advertisements for the animal rights group PETA. Spoofing Marilyn Monroe's "Diamonds Are a Girl's Best Friend" segment in "Gentlemen Prefer Blondes", a 2004 ad states "Gentlemen prefer fur-free blondes." Due to her support of the anti-fur movement, in particular her criticism of Canadian seal hunting, PETA began a petition in memory of Smith to the Canadian Prime Minister Stephen Harper to end the annual tradition. In another ad the following year, Smith posed with her dogs in a campaign against Iams dog food for their alleged cruelty to animals, as well as the manufacturer Procter and Gamble, and sister company Eukanuba.
Personal life.
Smith was addicted to prescription medications. Psychiatrist Dr. Nathalie Maullin said she met Smith in April 2006 in Cedars-Sinai Medical Center. Maullin said Smith had borderline personality disorder.
Birth of daughter.
Smith announced on June 1, 2006, in a video clip posted on her official website that she was pregnant. "Let me stop all the rumors," she said, while floating on an inflatable raft in a swimming pool. "Yes, I am pregnant. I'm happy, I'm very, very happy about it. Everything's goin' really, really good and I'll be checking in and out periodically on the web, and I'll let you see me as I'm growing."
Though her announcement did not provide any details, in an interview with Larry King on CNN's "Larry King Live" after her daughter's birth and her son's death, Smith's longtime personal attorney Howard K. Stern said that he and Smith had been in a secret relationship for "a very long time" and that, due to the timing of the pregnancy, he was confident that he was the father of the baby. Entertainment photographer Larry Birkhead, steadfastly maintained that he was the baby's father and filed a lawsuit to establish paternity.
Smith's daughter, Dannielynn Birkhead, was born September 7, 2006, at Doctors Hospital in Nassau, Bahamas. The Bahamian birth certificate recorded the father as Howard K. Stern.
A judge in the United States ordered that DNA tests be performed to determine the biological father of Dannielynn. Following Smith's death, Debra Opri, the lawyer for Larry Birkhead, asked for an emergency DNA sample to be taken from her body. Smith's lawyer, Ron Rale objected strongly to this request. The request was denied by a judge, who instead ordered Smith's body preserved until February 20.
According to a story published in the "New York Daily News", Donna Hogan, Smith's younger half-sister, has said that the model froze the sperm of her second husband, Marshall, prior to his death. The newspaper said that Hogan wrote in her unpublished manuscript about her sister, entitled "Train Wreck", that "To her family, she hinted that she had used the old man's frozen sperm, and would be giving birth to Howard Marshall's child". However, the publisher of Hogan's book described the newspaper's claims as a hoax. On February 9, 2007, Zsa Zsa Gabor's husband Frédéric Prinz von Anhalt said that he had had a decade-long affair with Smith and could potentially be the father of her infant girl, Dannielynn. Alexander Denk, a former bodyguard for Anna Nicole Smith, reportedly told the tabloid television program "Extra" that he had had an affair with his former employer, and that it was possible he could be Dannielynn's father.
After Smith's death, "TMZ.com" reported that Smith had been given a prescription for methadone under a false name while she was in her eighth month of pregnancy. The Medical Board of California launched a review into the matter; the prescribing doctor, Sandeep Kapoor, said his treatment was "sound and appropriate."
On April 10, 2007, a Bahamian judge ruled Larry Birkhead, photographer, as the father of Dannielynn. DNA tests had established Birkhead as the father, with 99.99% certainty. Commenting on the revelation, Birkhead stated, "I hate to be the one to tell you this but, I told you so. I'm the father...My baby's going to be coming home pretty soon." Birkhead subsequently applied for an amended birth certificate listing him as the father, which paved the way for him to obtain a passport for the baby to leave with him for the United States. Howard K. Stern did not contest the DNA results or the ruling. Subsequent to the ruling, Birkhead returned to the United States with the baby.
Smith's mother, Virgie Arthur, appealed the ruling but it was later denied and she was ordered to pay costs.
Death of son.
Smith's 20-year-old son Daniel Smith, died on September 10, 2006, in his mother's hospital room while visiting her and his half sister. After the coroner labeled the death "reserved", Smith hired forensic pathologist Cyril Wecht to perform a second autopsy.
His death certificate was issued on September 21, 2006, so that he could be buried. While Smith remained in the Bahamas with Dannielynn and Stern, Daniel's family in the United States, including his father, Billy Smith, gathered with friends on October 7, 2006, in Mexia, Texas, for a memorial service. Daniel was buried at Lake View Cemetery on New Providence, Bahamas, on October 19, 2006, almost six weeks after his death. According to Howard K. Stern, Smith's longtime boyfriend, she was devastated over her son's death. "Anna and Daniel were inseparable. Daniel was without question the most important person in Anna's life," Stern told Florida Circuit Judge Larry Seidlin during his testimony in Smith's body custody trial: "At Daniel's funeral, she had them open the coffin and tried to climb inside. She said that 'if Daniel has to be buried, I want to be buried with him,'" Stern testified. "She was ready to go down with him." Howard K. Stern revealed that "Anna saw herself as both mother and father to Daniel. From the time I met her, everything was for Daniel. I would say that physically, she died last week, but in a lot of ways, emotionally she died when Daniel died," he added.
Dr. Wecht announced on "Larry King Live" that the autopsy he performed showed that Daniel died from a lethal combination of Zoloft, Lexapro and methadone. Although he explained that methadone is used in the treatment of heroin and morphine addiction, Wecht said he had no information to make any conclusion why Daniel was using the drug. On February 8, 2007, Wecht said on Fox News that he still had no information about how Daniel obtained methadone.
Commitment ceremony with Stern.
On September 28, 2006, Smith and Howard K. Stern exchanged their vows and rings in an informal commitment ceremony aboard the catamaran Margaritaville off the coast of the Bahamas. She wore a white dress and carried a bouquet of red roses, while he wore a black suit with white shirt. Although they pledged their love and made a commitment to be there for each other before a Baptist minister, no marriage certificate was issued and the ceremony was not legally binding.
After the ceremony, they landed on the island of Sandy Cay where they had a party and celebrated with champagne and apple cider that had been brought over for the occasion by sailboat.
Regarding the questionable timing of the ceremony, Smith's attorney in Nassau, stated, "They needed a little adrenaline boost because things have been so hectic and devastating in their life recently." The photos of their ceremony were sold through Getty Images to "People" magazine for around $1,000,000.
Residency in the Bahamas.
Smith and Stern were reportedly staying in The Bahamas to avoid paternity testing of her daughter in the United States. In late 2006, Smith was granted permanent resident status in the Bahamas by Immigration Minister Shane Gibson. On February 11, 2007, newspaper photographs were published showing Smith lying clothed in bed in an embrace with Gibson. Opposition politicians in the Bahamas accused the minister of improper behavior. Gibson resigned as a result of the controversy and claimed that the photos, taken by Stern, were innocent.
The basis of Smith's permanent residency status was the claim that she owned a $900,000 mansion, which she said was given to her by a former boyfriend, real estate developer Gaither Ben Thompson of South Carolina. Thompson asserted that he loaned Smith the finances to purchase the property, but that she failed to repay the loan, and was attempting to regain control of the property. Thompson sued to evict Smith from the property in Bahama Court, and received a default judgment against her when she failed to respond to the eviction, or appear in court on November 28, 2006. Ford Shelley, son-in-law of G. Ben Thompson, claimed that methadone was found in Anna's bedroom refrigerator while the mansion was being reclaimed. A photograph provided by TMZ shows a large bottle of methadone along with vials of injectable vitamin B12 (cyanocobalamin) in her refrigerator and diet product Slimfast.
Death and funeral.
On February 8, 2007, Smith was found dead in room 607 at the Seminole Hard Rock Hotel and Casino in Hollywood, Florida. Tasma Brighthaupt, a friend of Smith who was a trained emergency nurse, performed CPR for 15 minutes until her husband, Maurice "Big Moe" Brighthaupt, Smith's friend and bodyguard, took over CPR. He had driven back to the hotel after being notified by his wife of Smith's condition. According to Seminole Police Chief Charlie Tiger, at 1:38 p.m. (EST) Maurice Brighthaupt, who was also a trained paramedic, called the hotel front desk from her sixth-floor room. The front desk in turn called security, who then called 911. At 1:45 p.m. (EST) the bodyguard administered CPR until paramedics arrived and Smith was rushed to Memorial Regional Hospital at 2:10 p.m. (EST) and pronounced dead on arrival at 2:49 p.m. (EST)
A phone call was released to the public on February 13, 2007, involving Seminole police and the local 911 operators, saying, "We need assistance to Room 607 at the Hard Rock. It's in reference to a white female. She's not breathing and not responsive... actually, it's Anna Nicole Smith."
After a seven-week investigation led by Broward County Medical Examiner and Forensic Pathologist Dr. Joshua Perper in combination with the Seminole police and several independent forensic pathologists and toxicologists, Dr. Perper announced that Smith died of "combined drug intoxication" with the sleeping medication chloral hydrate as the "major component." No illegal drugs were found in her system. The official report states that her death was not considered to be due to homicide, suicide, or natural causes. The full investigative report has been made public and can be found online. Additionally, an official copy of the autopsy report was publicly released on March 26, 2007, and can be found online.
Ultimately her death was ruled accidental drug overdose of the sedative chloral hydrate that became increasingly lethal when combined with other prescription drugs in her system, specifically four benzodiazepines: Klonopin (Clonazepam), Ativan (Lorazepam), Serax (Oxazepam), and Valium (Diazepam). Furthermore, she had taken Benadryl (Diphenhydramine) and Topamax (Topiramate), an anticonvulsant AMPA/Kainate antagonist, which likely contributed to the sedative effect of chloral hydrate and the benzodiazepines. Although the individual levels of any of the benzodiazepines in her system would not have been sufficient to cause death, their combination with a high dose of chloral hydrate led to her overdose. The autopsy report indicates that chloral hydrate was the "toxic/lethal" drug, but it is difficult to know whether chloral hydrate ingestion alone would have killed her, since Dr. Perper indicated (in the March 26 press conference) that she had built up a tolerance to the drug and took more than the average person. He indicated that she took about three tablespoons, whereas the normal dosage is between one and two teaspoons. Chloral hydrate, first synthesized in 1832, was the first depressant developed for the specific purpose of inducing sleep. The infamous "Mickey Finn" or "knockout drops" was a solution of alcohol and chloral hydrate that was popular in Victorian England and in that era's literature. When used properly, and without the introduction of alcohol or other depressants, chloral hydrate is effective in easing sleeplessness due to pain or insomnia. But according to Avis (1990), the effective dose and lethal dose of chloral hydrate are so close that the sedative should be considered dangerous. Today, the use of chloral hydrate has declined as other agents, including barbiturates and benzodiazepines, have largely replaced them. Despite rumors of methadone use due to its involvement in Smith's son's death, Dr. Perper found only methadone in her bile, indicating that it could only have been ingested 2–3 days prior to her death and was not a contributing factor. The autopsy report indicates that abscesses on her buttocks (presumably from prior injections of vitamin B12 in the form of cyanocobalamin, as well as human growth hormone), and viral enteritis were contributory causes of death. Tests for influenza A and B were negative.
It was reported that 8 of the 11 drugs in Smith's system, including the chloral hydrate, were prescribed to Howard K. Stern, not Smith. Additionally, two of the prescriptions were written for Alex Katz and one was written for Smith's friend and psychiatrist, Dr. Khristine Elaine Eroshevich. Dr. Perper acknowledged that all 11 prescriptions were written by Dr. Eroshevich herself.
Smith's funeral took place March 2, 2007. Before Smith's body was buried, it began decomposing at a faster-than-normal pace. Possible factors in her more rapid decomposition were the drugs found in her body in the autopsy, the fact that the legal battles delayed her embalming until a week after her death, and the nearly month-long wait for her burial in the warm Bahama weather. This resulted in the family having a closed-casket funeral.
Smith's will in April 2001 named her son Daniel as the sole beneficiary of her estate, specifically excluded other children, and named Howard K. Stern as the executor. It indicated personal property valued at $10,000 and real property valued at $1.8 million (with a $1.1 million mortgage) at the time of death. A petition to probate Smith's will was filed in Los Angeles County Superior Court. The petition to probate lists Larry Birkhead as a party with interest to Anna's estate.
A six-foot-long black granite monument was installed at Smith's grave in the Bahamas in February 2009.

</doc>
<doc id="68336" url="https://en.wikipedia.org/wiki?curid=68336" title="Reggie Walker">
Reggie Walker

Reginald ("Reggie") Edgar Walker (16 March 1889 in Durban – 5 November 1951) was a South African athlete and the 1908 Olympic champion in the 100 metres.
Born in Natal, Walker, the 1907 South African Champion, was not among the big favourites for the 100 metres at the 1908 Summer Olympics. He even had trouble getting to London, as he lacked the necessary finances until a Natal sportswriter collected funds to support Walker's travel. In England, he was coached by Sam Mussabini, later also the coach of Harold Abrahams.
Several of the big names did not qualify for the final, but Walker did. His first round was a relatively easy victory run in 11.0 seconds. In the second round, Walker edged out William W. May of the United States while tying the Olympic record of 10.8 seconds. This qualified him for the final. There he competed against three North Americans, including James Rector of the United States, who had equalled the Olympic Record in both of the qualifier rounds. Walker beat Rector in the final by about a foot and half.
Walker is still the youngest winner of the Olympic 100 metres (at 19 years and 128 days).

</doc>
<doc id="68338" url="https://en.wikipedia.org/wiki?curid=68338" title="Peter Shor">
Peter Shor

Peter Williston Shor (born August 14, 1959) is an American professor of applied mathematics at MIT. He is known for his work on quantum computation, in particular for devising Shor's algorithm, a quantum algorithm for factoring exponentially faster than the best currently-known algorithm running on a classical computer.
Education.
While attending Tamalpais High School, in Mill Valley, California, he placed third in the 1977 USA Mathematical Olympiad. After graduating that year, he won a silver medal at the International Math Olympiad in Yugoslavia (the U.S. team achieved the most points per country that year). He received his B.S. in Mathematics in 1981 for undergraduate work at Caltech, and was a Putnam Fellow in 1978. He earned his Ph.D. in Applied Mathematics from MIT in 1985. His doctoral advisor was F. Thomson Leighton, and his thesis was on probabilistic analysis of bin-packing algorithms.
Career.
After graduating, he spent one year in a post-doctoral position at the University of California at Berkeley, and then accepted a position at Bell Laboratories. It was there he developed Shor's algorithm, for which he was awarded the Rolf Nevanlinna Prize at the 23rd International Congress of Mathematicians in 1998 and the Gödel Prize in 1999.
Shor began his MIT position in 2003. Currently the Henry Adams Morss and Henry Adams Morss, Jr. Professor of Applied Mathematics in the Department of Mathematics at MIT, he also is affiliated with CSAIL and the Center for Theoretical Physics (CTP).
He received a Distinguished Alumni Award from Caltech in 2007.
On October 1, 2011, he was inducted into the American Academy of Arts and Sciences.
Personal life.
He lives in Wellesley, Massachusetts.
External links.
Lectures and panels

</doc>
<doc id="68339" url="https://en.wikipedia.org/wiki?curid=68339" title="IBM Lotus SmartSuite">
IBM Lotus SmartSuite

SmartSuite is an office suite from Lotus Software. The company made versions of its office suite for IBM OS/2 and Microsoft Windows.
Status.
SmartSuite is in maintenance mode, and supported with fixes and fixpacks on Windows 2000 and Windows XP. SmartSuite is not officially supported by IBM on versions of Windows after XP, but it does work well on both the 32-bit and 64-bit versions of Vista and of Windows 7, if the installer and applications are run with XP compatibility mode set for the executable files. IBM has no plans to release an official Windows 7-compatible version of SmartSuite.
In 2007, IBM introduced a new office suite called IBM Lotus Symphony, unrelated to the Lotus Symphony integrated application suite that Lotus previously released.
In July 2012 the price for a user licence of Lotus SmartSuite 9.8 was US-$342.00 when purchased directly through the IBM website.
In May 2013, IBM announced the withdrawal of SmartSuite. Marketing of the product ended in June 2013, followed by all support ceasing in September 2014. IBM has also announced that there will be no replacement for SmartSuite.
Components.
The following applications are included in SmartSuite for Microsoft Windows:
Compatibility.
Most SmartSuite programs are capable of reading and writing the corresponding Microsoft Office files. The Microsoft programs, however, are capable of reading only a few vintage formats of the Lotus programs, such as the older 1-2-3 .wks and .wk1 files. Furthermore, several of the SmartSuite components provide functionality not found in the Microsoft Office suite, for example Lotus FastSite and Lotus SmartCenter.
IBM vs Microsoft.
In his finding of facts for United States v. Microsoft, Judge Jackson determined that because of IBM's marketing of Lotus SmartSuite, and other alternatives to Microsoft products (like World Book electronic encyclopedia instead of Microsoft's Encarta), Microsoft "punished the IBM PC Company with higher prices, a late license for Windows 95, and the withholding of technical and marketing support."
Microsoft did not grant IBM OEM rights for Windows 95 until 15 minutes prior to the release of Windows 95, August 24, 1995. Because of this uncertainty, IBM machines were sold without Windows 95, while Compaq, HP, and other indulgent companies sold machines with Windows 95 from day one.

</doc>
<doc id="68344" url="https://en.wikipedia.org/wiki?curid=68344" title="Bilirubin">
Bilirubin

Bilirubin (formerly referred to as haematoidin) is the yellow breakdown product of normal heme catabolism, caused by the body's clearance of aged red blood cells which contain hemoglobin.
Bilirubin is excreted in bile and urine, and elevated levels may indicate certain diseases. It is responsible for the yellow color of bruises and the yellow discoloration in jaundice. It is also responsible for the brown color of feces, via its conversion to stercobilin, and the background straw-yellow color of urine via its breakdown product, urobilin.
It has also been found in plants.
Chemistry.
Bilirubin consists of an open chain of four pyrrole-like rings (tetrapyrrole). In heme, these four rings are connected into a larger ring, called a porphyrin ring.
Bilirubin can be "conjugated" with a molecule of glucuronic acid which makes it soluble in water (see below). This is an example of glucuronidation.
Bilirubin is very similar to the pigment phycobilin used by certain algae to capture light energy, and to the pigment phytochrome used by plants to sense light. All of these contain an open chain of four pyrrolic rings.
Like these other pigments, some of the double-bonds in bilirubin isomerize when exposed to light. This is used in the phototherapy of jaundiced newborns: the E,Z-isomers of bilirubin formed upon light exposure are more soluble than the unilluminated Z,Z-isomer, as the possibility of intramolecular hydrogen bonding is removed. This allows the excretion of unconjugated bilirubin in bile.
Some textbooks and research articles show the incorrect geometric isomer of bilirubin. The naturally occurring isomer is the Z,Z-isomer.
Function.
Bilirubin is created by the activity of biliverdin reductase on biliverdin, a green tetrapyrrolic bile pigment that is also a product of heme catabolism. Bilirubin, when oxidized, reverts to become biliverdin once again. This cycle, in addition to the demonstration of the potent antioxidant activity of bilirubin, has led to the hypothesis that bilirubin's main physiologic role is as a cellular antioxidant.
Metabolism.
Unconjugated ("indirect").
The measurement of direct bilirubin depends on its reaction with diazosulfanilic acid to create azobilirubin. However, unconjugated bilirubin also reacts slowly with diazosulfanilic acid, so that the measured indirect bilirubin is an underestimate of the true unconjugated concentration.
Conjugated ("direct").
In the liver, bilirubin is conjugated with glucuronic acid by the enzyme glucuronyltransferase, making it soluble in water: the conjugated version is also often called "direct" bilirubin. Much of it goes into the bile and thus out into the small intestine. Though most bile acid is resorbed in the terminal ileum to participate in enterohepatic circulation, conjugated bilirubin is not absorbed and instead passes into the colon.
There, colonic bacteria deconjugate and metabolize the bilirubin into colorless urobilinogen, which can be oxidized to form urobilin and stercobilin: these give stool its characteristic brown color. A trace (~1%) of the urobilinogen is reabsorbed into the enterohepatic circulation to be re-excreted in the bile: some of this is instead processed by the kidneys, coloring the urine yellow.
Although the terms direct and indirect bilirubin are used equivalently with conjugated and unconjugated bilirubin, this is not quantitatively correct, because the direct fraction includes both conjugated bilirubin and δ bilirubin (bilirubin covalently bound to albumin, which appears in serum when hepatic excretion of conjugated bilirubin is impaired in patients with hepatobiliary disease). Furthermore, direct bilirubin tends to overestimate conjugated bilirubin levels due to unconjugated bilirubin that has reacted with diazosulfanilic acid, leading to increased azobilirubin levels (and increased direct bilirubin).
Urine.
Under normal circumstances, a tiny amount of urobilinogen, if any, is excreted in the urine. If the liver's function is impaired or when biliary drainage is blocked, some of the conjugated bilirubin leaks out of the hepatocytes and appears in the urine, turning it dark amber. However, in disorders involving hemolytic anemia, an increased number of red blood cells are broken down, causing an increase in the amount of unconjugated bilirubin in the blood. Because the unconjugated bilirubin is not water-soluble, one will not see an increase in bilirubin in the urine. Because there is no problem with the liver or bile systems, this excess unconjugated bilirubin will go through all of the normal processing mechanisms that occur (e.g., conjugation, excretion in bile, metabolism to urobilinogen, reabsorption) and will show up as an increase in urine urobilinogen. This difference between increased urine bilirubin and increased urine urobilinogen helps to distinguish between various disorders in those systems.
Toxicity.
Unconjugated hyperbilirubinaemia in a newborn can lead to accumulation of bilirubin in certain brain regions (particularly the basal nuclei) with consequent irreversible damage to these areas manifesting as various neurological deficits, seizures, abnormal reflexes and eye movements. This type of neurological injury is known as kernicterus. The spectrum of clinical effect is called bilirubin encephalopathy. The neurotoxicity of neonatal hyperbilirubinemia manifests because the blood–brain barrier has yet to develop fully, and bilirubin can freely pass into the brain interstitium, whereas more developed individuals with increased bilirubin in the blood are protected. Aside from specific chronic medical conditions that may lead to hyperbilirubinaemia, neonates in general are at increased risk since they lack the intestinal bacteria that facilitate the breakdown and excretion of conjugated bilirubin in the feces (this is largely why the feces of a neonate are paler than those of an adult). Instead the conjugated bilirubin is converted back into the unconjugated form by the enzyme β-glucuronidase (in the gut, this enzyme is located in the brush border of the lining intestinal cells) and a large proportion is reabsorbed through the enterohepatic circulation.
Associated health benefits.
Research has indicated that in the absence of liver disease, individuals with high levels of total bilirubin may experience various health benefits exceeding those with lower levels of bilirubin. Studies have found higher levels of bilirubin in elderly individuals are associated with higher functional independence. Studies have also revealed that levels of serum bilirubin are inversely related to risk of certain heart diseases.
Blood tests.
Bilirubin is degraded by light. Blood collection tubes containing blood or (especially) serum to be used in bilirubin assays should be protected from illumination. For adults, blood is typically collected by needle from a vein in the arm. In newborns, blood is often collected from a heelstick, a technique that uses a small, sharp blade to cut the skin on the infant's heel and collect a few drops of blood into a small tube. Non-invasive technology is available in some health care facilities that will measure bilirubin by using an instrument placed on the skin (transcutaneous bilirubin meter)
Bilirubin (in blood) is in one of two forms:
Total bilirubin (TBIL) measures both BU and BC. Total and direct bilirubin levels can be measured from the blood, but indirect bilirubin is calculated from the total and direct bilirubin.
Indirect bilirubin is fat-soluble and direct bilirubin is water-soluble.
Measurement methods.
Originally, the Van den Bergh reaction was used for a qualitative estimate of bilirubin.
This test is performed routinely in most medical laboratories and can be measured by a variety of methods.
Total bilirubin is now often measured by the 2,5-dichlorophenyldiazonium (DPD) method, and direct bilirubin is often measured by the method of Jendrassik and Grof.
Blood levels.
The bilirubin level found in the body reflects the balance between production and excretion. Blood test results should always be interpreted using the reference range provided by the laboratory that performed the test, but typical to 1.9 mg/dLs for adults and µmol/L for new borns:
Hyperbilirubinemia.
Hyperbilirubinemia results from a higher-than-normal level of bilirubin in the blood. For adults, this is any level above 170 μmol/l and for newborns 340 µmol/l and critical hyperbilirubinemia 425 µmol/l.
Mild rises in bilirubin may be caused by:
Moderate rise in bilirubin may be caused by:
Very high levels of bilirubin may be caused by:
Cirrhosis may cause normal, moderately high or high levels of bilirubin, depending on exact features of the cirrhosis
To further elucidate the causes of jaundice or increased bilirubin, it is usually simpler to look at other liver function tests (especially the enzymes alanine transaminase, aspartate transaminase, gamma-glutamyl transpeptidase, alkaline phosphatase), blood film examination (hemolysis, etc.) or evidence of infective hepatitis (e.g., hepatitis A, B, C, delta, E, etc.).
Jaundice.
Jaundice may be noticeable in the sclera of the eyes at levels of about 2 to 3;mg/dl (34 to 51 μmol/l), and in the skin at higher levels.
For conversion, 1 mg/dl = 17.1 µmol/l.
Jaundice is classified depending upon whether the bilirubin is free or conjugated to glucuronic acid into conjugated jaundice or unconjugated jaundice..
Urine tests.
Urine bilirubin may also be clinically significant. Bilirubin is not normally detectable in the urine of healthy people. If the blood level of conjugated bilirubin becomes elevated, e.g. due to liver disease, excess conjugated bilirubin is excreted in the urine, indicating a pathological process. Unconjugated bilirubin is not water-soluble and so is not excreted in the urine. Testing urine for both bilirubin and urobilinogen can help differentiate obstructive liver disease from other causes of jaundice.

</doc>
<doc id="68345" url="https://en.wikipedia.org/wiki?curid=68345" title="X window manager">
X window manager

An X window manager is a window manager which runs on top of the X Window System, a windowing system mainly used on Unix-like systems.
Unlike the Mac OS (Apple Macintosh) and Microsoft Windows platforms (excepting Microsoft Windows explorer.exe shell replacements) which have historically provided a vendor-controlled, fixed set of ways to control how windows and panes display on a screen, and how the user may interact with them, window management for the X Window System was deliberately kept separate from the software providing the graphical display. The user can choose between various third-party window managers, which differ from one another in several ways, including:
How X window managers work.
When a window manager is running, some kinds of interaction between the X server and its clients are redirected through the window manager. In particular, whenever an attempt to show a new window is made, this request is redirected to the window manager, which decides the initial position of the window. Additionally, most modern window managers are reparenting, which usually leads to a banner being placed at the top of the window and a decorative frame being drawn around the window. These two elements are controlled by the window manager rather than the program. Therefore, when the user clicks or drags these elements, it is the window manager that takes the appropriate actions (such as moving or resizing the window).
Window managers are also responsible for icons. Indeed, icons do not exist at the X Window System core protocol level. When the user requests a window to be iconified, the window manager unmaps it (makes it non-visible) and takes the appropriate actions to show an icon in its place. Most modern window managers do not literally show icons to represent iconified windows anymore. Often, an auxiliary toolbar program will allow access to iconified windows.
While the main aim of a window manager is to manage the windows, many window managers have additional features such as handling mouse clicks in the root window, presenting panes and other visual elements, handling some keystrokes (e.g., Alt-F4 may close a window), deciding which application to run at start-up, etc.
Standardized protocols exist to allow normal clients to communicate with the window manager. The original one is Inter-Client Communication Conventions Manual (ICCCM) but this has been superseded by the Extended Window Manager Hints (EWMH).
Types of window managers.
Stacking window managers.
A stacking window manager renders the windows one-by-one onto the screen at specific co-ordinates. If one window's area overlaps another, then the window "on top" overwrites part of the other's visible appearance. This results in the appearance familiar to many users in which windows act a little bit like pieces of paper on a desktop, which can be moved around and allowed to overlap.
In contrast to "compositing" window managers (see below), the lack of separate off-screen buffers can mean increased efficiency, but effects such as translucency are not possible.
Stacking window managers include Amiwm, Blackbox, Enlightenment, Fluxbox, FVWM, IceWM, MWM, Openbox and Window Maker.
Tiling window managers.
A tiling window manager is a window manager with an organization of the screen into mutually non-overlapping frames (hence the name tiling), as opposed to the traditional approach of coordinate-based stacking of objects (windows) that tries to emulate the desk paradigm.
Tiling window managers include awesome, dwm, ion, larswm, ratpoison, Stumpwm, wmii, i3, xmonad, and XWEM.
Compositing window managers.
A compositing window manager may appear to the user similar to a stacking window manager. However, the individual windows are first rendered in individual buffers, and then their images are composited onto the screen buffer; this two-step process means that visual effects (such as shadows, translucency) can be applied. It also means that compositing window managers are inherently more resource-hungry than an equivalently-powerful stacking window manager. For this reason, some window managers for X do not support compositing by default, such as LXDE.[http://askubuntu.com/questions/53745/compositing-in-lubuntu]
Historically, the Amiga in 1985, OSX in 2001 (which in many ways is a window manager for X), Java Looking Glass in 2003, and the Windows Longhorn demo in 2003 (delayed until Vista in 2007) preceded compositing efforts under X11. Compositing window managers for X include: 
Virtual window managers.
A virtual window manager is a window manager that uses virtual screens, whose resolution can be higher than the resolution of one's monitor/display adapter thus resembling a two dimensional virtual desktop with its viewport. This environment is very useful when one wishes to have a large number of windows open at the same time. A number of virtual window managers have been made, including FVWM, Tvtwm, HaZe and others.
Window managers that are extensible.
Some window managers are extensible, or programmable, by user scripts.
In these window managers, users can define new actions or override the default, or reactions to various events, like window size and position changes, window creation and deletion, key and mouse input, timer, etc. They often provide on-the-fly code execution, too.
Some examples of such window managers and the used languages are:

</doc>
<doc id="68348" url="https://en.wikipedia.org/wiki?curid=68348" title="The Big Sleep">
The Big Sleep

The Big Sleep (1939) is a hardboiled crime novel by Raymond Chandler, the first to feature detective Philip Marlowe. The work has been adapted for film twice, once in 1946 and again in 1978. The story is set in Los Angeles, California.
The story is noted for its complexity, with many characters double-crossing one another and many secrets being exposed throughout the narrative. The title is a euphemism for death; it refers to a rumination in the final pages of the book about "sleeping the big sleep".
In 1999, the book was voted ninety-sixth of "Le Monde"s "100 Books of the Century". In 2005, it was included in "Time"s "List of the 100 Best Novels".
Plot.
Private investigator Philip Marlowe is called to the home of the wealthy and elderly General Sternwood, in the month of October. He wants Marlowe to deal with an attempt by a bookseller named Arthur Geiger to blackmail his wild young daughter, Carmen. She had previously been blackmailed by a man named Joe Brody. Sternwood mentions his other, older daughter Vivian is in a loveless marriage with a man named Rusty Regan, who has disappeared. On Marlowe's way out, Vivian wonders if he was hired to find Regan, but Marlowe will not say.
Marlowe investigates Geiger's bookstore and meets Agnes, the clerk. He determines the store is a pornography lending library. He follows Geiger home, stakes out his house, and sees Carmen Sternwood enter. Later, he hears a scream followed by gunshots and two cars speeding away. He rushes in to find Geiger dead and Carmen drugged and naked, in front of an empty camera. He takes her home but when he returns, Geiger's body is gone. He quickly leaves. The next day, the police call him and let him know the Sternwoods's car was found driven off a pier, with their chauffeur dead inside. It appears that he was hit on the head before the car entered the water. The police also ask if Marlowe is looking for Regan.
Marlowe stakes out the bookstore and sees its inventory being moved to Joe Brody's home. Vivian comes to his office and says Carmen is being blackmailed with the nude photos from the previous night. She also mentions gambling at the casino of Eddie Mars and volunteers that Eddie's wife, Mona, ran off with Rusty. Marlowe revisits Geiger's house and finds Carmen trying to get in. They look for the photos, but she plays dumb about the night before. Eddie Mars suddenly enters; he says he is Geiger's landlord and is looking for him. Mars demands to know why Marlowe is there; Marlowe takes no notice and states he is no threat to Mars.
Marlowe goes to Brody's home and finds him with Agnes, the bookstore clerk. He tells them he knows they are taking over the lending library and blackmailing Carmen with the nude photos. Carmen forces her way in with a gun and demands the photos, but Marlowe takes her gun and makes her leave. Marlowe interrogates Brody further and pieces together the story: Geiger was blackmailing Carmen; the family driver, Owen Taylor, didn't like it, so he sneaked in and killed Geiger, then took the film of Carmen. Brody was staking out the house too and pursued the driver, knocked him out, stole the film, and possibly pushed the car off the pier. Suddenly the doorbell rings and Brody is shot dead; Marlowe gives chase and catches Geiger's male lover, who shot Brody thinking he killed Geiger. He had also hidden Geiger's body, so he could remove his own belongings before the police got wind of the murder.
The case is over, but Marlowe is nagged by Regan's disappearance. The police accept that he simply ran off with Mona Mars, since she is also missing, and since Eddie Mars wouldn't risk committing a murder in which he would be the obvious suspect. Mars calls Marlowe to his casino and seems to be nonchalant about everything. Vivian is also there, and Marlowe senses something between her and Mars. He drives her home and she tries to seduce him, but he rejects her advances. When he gets home, he finds Carmen has sneaked into his bed, and he rejects her, too.
A man named Harry Jones, who is Agnes's new partner, approaches Marlowe and offers to sell him the location of Mona Mars. Marlowe plans to meet him later, but Mars's henchman Canino is suspicious of Jones and Agnes's intentions and kills Jones first. Marlowe manages to meet Agnes anyway and receives the information. He goes to the location in Realito, a repair shop with a home in back, but Canino, with the help of Art Huck, the garage man, jumps him and knocks him out. When he awakens, he is tied up, and Mona Mars is there with him. She says she hasn't seen Rusty in months; she only hid out to help Eddie and insists he didn't kill Rusty. She frees him, and he shoots and kills Canino.
The next day, Marlowe visits General Sternwood, who remains curious about Rusty's whereabouts. On the way out, Marlowe returns Carmen's gun to her, and she asks him to teach her how to shoot. They go to an abandoned field, where she tries to kill him, but he has loaded the gun with blanks. Marlowe brings her back and tells Vivian he has guessed the truth: Carmen came on to Rusty and he refused her, so she killed him. Eddie Mars, who had been backing Geiger, helped Vivian conceal it by inventing a story about his wife running off with Rusty and then began blackmailing her himself. Vivian says she did it to protect her father and promises to have Carmen institutionalized.
With the case now over, Marlowe goes to a local bar and orders several double Scotches. While drinking, he begins to think about Mona "Silver-Wig" Mars. He never sees her again.
Background.
"The Big Sleep", like most of Chandler's novels, was written by what he called "cannibalizing" his short stories. Chandler would take stories he had already published in the pulp magazine "Black Mask" and rework them into a coherent story. For "The Big Sleep", the two main stories that formed the core of the novel were "Killer in the Rain" (published in 1935) and "The Curtain" (published in 1936). Although the stories were independent and shared no characters, they had some similarities that made it logical to combine them. In both stories there is a powerful father who is distressed by his wayward daughter. Chandler merged the two fathers into a new character and did the same for the two daughters, resulting in General Sternwood and his wild daughter Carmen. Chandler also borrowed small parts of two other stories, "Finger Man" and "Mandarin's Jade".
As might be expected, all this cannibalizing—especially in a time when cutting and pasting was done by cutting and pasting paper—sometimes produced a plot with a few loose ends. The famously unanswered question in "The Big Sleep" is who killed the chauffeur. When Howard Hawks filmed the novel, his writing team felt perplexed by that question, in response to which Chandler replied that he had no idea. This exemplifies a difference between Chandler's style of crime fiction and that of previous authors. To Chandler, plot stood third in line to atmosphere and characterization. An ending that answered every question while neatly tying every plot thread mattered less to Chandler than interesting characters with believable behavior.
When Chandler merged his stories into a novel, he spent more effort on expanding descriptions of people, places, and Marlowe's thinking than getting every detail of the plot perfectly consistent. In "The Curtain", the description of Mrs. O'Mara's room is just enough to establish the setting: "This room had a white carpet from wall to wall. Ivory drapes of immense height lay tumbled casually on the white carpet inside the many windows. The windows stared towards the dark foot-hills, and the air beyond the glass was dark too. It hadn't started to rain yet, there was a feeling of pressure in the atmosphere." In "The Big Sleep", Chandler expanded this description of the room and used new detail (e.g., the contrast of white and "bled out", the coming rain) to foreshadow the fact that Mrs. Regan (who was Mrs. O'Mara in the original story) is covering up the murder of her husband by her sister and that the coming rain storm will bring more deaths: "The room was too big, the ceiling was too high, the doors were too tall, and the white carpet that went from wall to wall looked like a fresh fall of snow at Lake Arrowhead. There were full-length mirrors and crystal doodads all over the place. The ivory furniture had chromium on it, and the enormous ivory drapes lay tumbled on the white carpet a yard from the windows. The white made the ivory look dirty and the ivory made the white look bled out. The windows stared towards the darkening foothills. It was going to rain soon. There was pressure in the air already." 

</doc>
<doc id="68349" url="https://en.wikipedia.org/wiki?curid=68349" title="HFE hereditary haemochromatosis">
HFE hereditary haemochromatosis

Haemochromatosis (or hemochromatosis) type 1 (also HFE hereditary haemochromatosis or HFE-related hereditary haemochromatosis) is a hereditary disease characterized by excessive intestinal absorption of dietary iron resulting in a pathological increase in total body iron stores. Humans, like most animals, have no means to excrete excess iron. Excess iron accumulates in tissues and organs disrupting their normal function. The most susceptible organs include the liver, adrenal glands, heart, skin, gonads, joints, and the pancreas; patients can present with cirrhosis, polyarthropathy, adrenal insufficiency, heart failure or diabetes. The hereditary form of the disease is most common among those of Northern European ancestry, in particular those of Celtic descent. The disease is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. Most often, the parents of an individual with an autosomal recessive condition each carry one copy of the mutated gene, but do not show signs and symptoms of the condition.
Signs and symptoms.
Haemochromatosis is protean in its manifestations, "i.e.", often presenting with signs or symptoms suggestive of other diagnoses that affect specific organ systems. Many of the signs and symptoms below are uncommon and most patients with the hereditary form of haemochromatosis do not show any overt signs of disease nor do they suffer premature morbidity.
The classic triad of cirrhosis, bronze skin and diabetes is not as common any more because of earlier diagnosis.
The more common clinical manifestations include:
Less common findings including:
Males are usually diagnosed after their forties and fifties, and women several decades later, owing to regular iron loss through menstruation (which ceases in menopause). The severity of clinical disease in the hereditary form varies considerably. There is evidence suggesting that hereditary haemochromatosis patients affected with other liver ailments such as hepatitis or alcoholic liver disease suffer worse liver disease than those with either condition alone. There are also juvenile forms of hereditary haemochromatosis that present in childhood with the same consequences of iron overload.
End-organ damage.
Iron is stored in the liver, the pancreas and the heart. Long-term effects of haemochromatosis on these organs can be very serious, even fatal when untreated. For example, similar to alcoholism, haemochromatosis can cause cirrhosis of the liver. The liver is a primary storage area for iron and will naturally accumulate excess iron. Over time the liver is likely to be damaged by iron overload. Cirrhosis itself may lead to additional and more serious complications, including bleeding from dilated veins in the esophagus (esophageal varices) and stomach (gastric varices) and severe fluid retention in the abdomen (ascites). Toxins may accumulate in the blood and eventually affect mental functioning. This can lead to confusion or even coma (hepatic encephalopathy).
Liver cancer: Cirrhosis and haemochromatosis together will increase the risk of liver cancer. (Nearly one-third of people with haemochromatosis and cirrhosis eventually develop liver cancer.)
Diabetes: The pancreas which also stores iron is very important in the body’s mechanisms for sugar metabolism. Diabetes affects the way the body uses blood sugar (glucose). Diabetes is in turn the leading cause of new blindness in adults and may be involved in kidney failure and cardiovascular disease.
Congestive heart failure: If excess iron in the heart interferes with the its ability to circulate enough blood, a number of problems can occur including death. The condition may be reversible when haemochromatosis is treated and excess iron stores reduced.
Heart arrhythmias: Arrhythmia or abnormal heart rhythms can cause heart palpitations, chest pain and light-headedness and are occasionally life-threatening. This condition can often be reversed with treatment for haemochromatosis.
Pigment changes: Bronze or grey coloration of the skin is caused primarily by increased melanin deposition, with iron deposition playing a lesser role.
Genetics.
The regulation of dietary iron absorption is complex and our understanding is incomplete. One of the better characterized genes responsible for hereditary haemochromatosis is HFE on chromosome 6 which codes for a protein that participates in the regulation of iron absorption. The HFE gene has two common mutations, C282Y and H63D. The C282Y allele is a transition point mutation from guanine to adenine at nucleotide 845 in the HFE gene, resulting in a missense mutation that replaces the cysteine residue at position 282 with a tyrosine amino acid. Heterozygotes for either allele do not manifest clinical iron overload but may display an increased iron uptake. 
Mutations of the HFE gene account for 90% of the cases of non-transfusional iron overload. This gene is closely linked to the HLA-A3 locus. Homozygosity for the C282Y mutation is the most common genotype responsible for clinical iron accumulation, though heterozygosity for C282Y/H63D mutations, so-called compound heterozygotes, results in clinically evident iron overload. There is considerable debate regarding the penetrance—the probability of clinical expression of the trait given the genotype—is for clinical disease in HHC homozygotes. Most, if not all, males homozygous for HFE C282Y will show manifestations of liver dysfunction such as elevated liver-specific enzymes such as serum gamma glutamyltransferase (GGT) by late middle age. Homozygous females can delay the onset of iron accumulation because of iron loss through menstruation. 
Each patient with the susceptible genotype accumulates iron at different rates depending on iron intake, the exact nature of the mutation, and the presence of other insults to the liver such as alcohol and viral disease. As such the degree to which the liver and other organs is affected is highly variable and is dependent on these factors and co-morbidities as well as age at which they are studied for manifestations of disease. Penetrance differs between populations.
Pathophysiology.
Since the regulation of iron metabolism is still poorly understood, a clear model of how haemochromatosis operates is still not available. A working model describes the defect in the HFE gene, where a mutation puts the intestinal absorption of iron into overdrive. Normally, HFE facilitates the binding of transferrin, which is iron's carrier protein in the blood. Transferrin levels are typically elevated at times of iron depletion (low ferritin stimulates the release of transferrin from the liver). When transferrin is high, HFE works to increase the intestinal release of iron into the blood. When HFE is mutated, the intestines perpetually interpret a strong transferrin signal as if the body were deficient in iron. This leads to maximal iron absorption from ingested foods and iron overload in the tissues. However, HFE is only part of the story, since many patients with mutated HFE do not manifest clinical iron overload, and some patients with iron overload have a normal HFE genotype. A possible explanation is the fact that HFE normally plays a role in the production of hepcidin in the liver, a function that is impaired in HFE mutations.
People with abnormal iron regulatory genes do not reduce their absorption of iron in response to increased iron levels in the body. Thus the iron stores of the body increase. As they increase, the iron which is initially stored as ferritin is deposited in organs as haemosiderin and this is toxic to tissue, probably at least partially by inducing oxidative stress. Iron is a pro-oxidant. Thus, haemochromatosis shares common symptomology (e.g., cirrhosis and dyskinetic symptoms) with other "pro-oxidant" diseases such as Wilson's disease, chronic manganese poisoning, and hyperuricaemic syndrome in Dalmatian dogs. The latter also experience "bronzing".
Diagnosis.
The diagnosis of haemochromatosis is often made following the incidental finding on routine blood screening of elevated serum liver enzymes or elevation of the transferrin saturation. Arthropathy with stiff joints, diabetes, or fatigue, may be the presenting complaint.
Blood tests.
Serum transferrin and transferrin saturation are commonly used as screening for haemochromatosis. Transferrin binds iron and is responsible for iron transport in the blood. Measuring transferrin provides a crude measure of iron stores in the body. Fasting transferrin saturation values in excess of 45% for males or 35% in premenopausal women (i.e. 300 ng/L in males and 200 ng/L in females) are recognized as a threshold for further evaluation of haemochromatosis. Transferrin saturation greater than 62% is suggestive of homozygosity for mutations in the HFE gene.
Serum Ferritin: Ferritin, a protein synthesized by the liver is the primary form of iron storage within cells and tissues. Measuring ferritin provides another crude estimate of whole body iron stores though many conditions, particularly inflammation (but also chronic alcohol consumption, non-alcoholic fatty liver disease and others), can elevate serum ferritin - which can account for up to 90% of cases where elevated levels are observed. Normal values for males are 12–300 ng/ml (nanograms per millilitre) and for female, 12–150 ng/ml. Serum ferritin in excess of 1000 nanograms per millilitre of blood is almost always attributable to haemochromatosis.
Other blood tests routinely performed: blood count, renal function, liver enzymes, electrolytes, glucose (and/or an oral glucose tolerance test (OGTT)).
Liver biopsy.
Liver biopsies involve taking a sample of tissue from the liver, using a thin needle. The amount of iron in the sample is then quantified and compared to normal, and evidence of liver damage, especially cirrhosis, measured microscopically. Formerly, this was the only way to confirm a diagnosis of haemochromatosis but measures of transferrin and ferritin along with a history are considered adequate in determining the presence of the malady. Risks of biopsy include bruising, bleeding and infection. Now, when a history and measures of transferrin or ferritin point to haemochromatosis, it is debatable whether a liver biopsy is still necessary to quantify the amount of accumulated iron.
MRI.
MRI-based testing is a non-invasive and accurate alternative to measure liver iron concentrations.
Other imaging.
Clinically the disease may be silent, but characteristic radiological features may point to the diagnosis. The increased iron stores in the organs involved, especially in the liver and pancreas, result in characteristic findings on unenhanced CT and a decreased signal intensity in MRI scans. Haemochromatosis arthropathy includes degenerative osteoarthritis and chondrocalcinosis. The distribution of the arthropathy is distinctive, but not unique, frequently affecting the second and third metacarpophalangeal joints of the hand. The arthropathy can therefore be an early clue as to the diagnosis of haemochromatosis.
Functional testing.
Based on the history, the doctor might consider specific tests to monitor organ dysfunction, such as an echocardiogram for heart failure, or blood glucose monitoring for patients with haemochromatosis diabetes.
Differential diagnosis.
There exist other causes of excess iron accumulation, which have to be considered before haemochromatosis is diagnosed.
Screening.
Standard diagnostic measures for haemochromatosis, transferrin saturation and ferritin tests, are not a part of routine medical testing. Screening for haemochromatosis is recommended if the patient has a parent, child or sibling with the disease.
Routine screening of the general population for hereditary haemochromatosis is generally not done. Mass genetic screening has been evaluated by the U.S. Preventive Services Task Force (USPSTF), among other groups. The USPSTF recommended against genetic screening of the general population for hereditary haemochromatosis because the likelihood of discovering an undiagnosed patient with clinically relevant iron overload is less than 1 in 1,000. Although there is strong evidence that treatment of iron overload can save lives in patients with transfusional iron overload, no clinical study has shown that for asymptomatic carriers of hereditary haemochromatosis treatment with venesection (phlebotomy) provides any clinical benefit. Recently, it has been suggested that patients be screened for iron overload using serum ferritin as a marker: If serum ferritin exceeds 1000 ng/mL, iron overload is very likely the cause.
Treatment.
Phlebotomy.
Early diagnosis is vital as the late effects of iron accumulation can be wholly prevented by periodic phlebotomies (by venesection) comparable in volume to blood donations. Initiation of treatment is recommended when ferritin levels reach 500 milligrams per litre.
Phlebotomy (or bloodletting) is usually done at a weekly interval until ferritin levels are less than 50 milligrams per litre. In order to prevent iron reaccumulation, subsequent phlebotomies are normally carried out approximately once every three to four months for males, and twice a year for females.
Desferrioxamine mesilate.
Where venesection is not possible, long-term administration of desferrioxamine mesilate is useful. Desferrioxamine is an iron-chelating compound, and excretion induced by desferrioxamine is enhanced by administration of Vitamin C. It cannot be used during pregnancy or breast-feeding due to risk of defects in the child.
Epidemiology.
Haemochromatosis is one of the most common heritable genetic conditions in people of northern European extraction with a prevalence of 1 in 200. The disease has a variable penetration and about 1 in 10 people of this demographic carry a mutation in one of the genes regulating iron metabolism, the most common allele being the C282Y allele in the "HFE" gene. The prevalence of mutations in iron metabolism genes varies in different populations. A study of 3,011 unrelated white Australians found that 14% were heterozygous carriers of an HFE mutation, 0.5% were homozygous for an "HFE" mutation, and only 0.25% of the study population had clinically relevant iron overload. Most patients who are homozygous for HFE mutations will not manifest clinically relevant haemochromatosis (see Genetics above). Other populations have a lower prevalence of both the genetic mutation and the clinical disease.
Genetic studies suggest the original haemochromatosis mutation arose in a single person, possibly of Celtic ethnicity, who lived 60–70 generations ago. At that time when dietary iron may have been scarcer than today, the presence of the mutant allele may have provided an evolutionary or natural selection reproductive advantage by maintaining higher iron levels in the blood.
Terminology.
The term "haemochromatosis" is used by different sources in many different ways.
It is often used to imply an association with the HFE gene. For many years, HFE was the only known gene associated with haemochromatosis, and the term "hereditary haemochromatosis" was used to describe haemochromatosis type 1. However, it is now known that there are many different genetic associations with this condition. The older the text, or the more general the audience, the more likely that HFE is implied.
"Haemochromatosis" has also been used in contexts where there had not been a known genetic cause for iron accumulation. In some cases, however, a condition that was thought to be due to diet or environment was later linked to a genetic polymorphism, as in African iron overload.
History.
The disease was first described in 1865 by Armand Trousseau in a report on diabetes in patients presenting with a bronze pigmentation of their skin. Trousseau did not associate diabetes with iron accumulation; the recognition that infiltration of the pancreas with iron might disrupt endocrine function resulting in diabetes was made by Friedrich Daniel von Recklinghausen in 1890.

</doc>
<doc id="68351" url="https://en.wikipedia.org/wiki?curid=68351" title="Pattern">
Pattern

A pattern, apart from the term's use to mean "Template", is a discernible regularity in the world or in a manmade design. As such, the elements of a pattern repeat in a predictable manner. A geometric pattern is a kind of pattern formed of geometric shapes and typically repeating like a wallpaper.
Any of the five senses may directly observe patterns. Conversely, abstract patterns in science, mathematics, or language may be observable only by analysis. Direct observation in practice means seeing visual patterns, which are widespread in nature and in art. Visual patterns in nature are often chaotic, never exactly repeating, and often involve fractals. Natural patterns include spirals, meanders, waves, foams, tilings, cracks, and those created by symmetries of rotation and reflection. Patterns have an underlying mathematical structure; indeed, mathematics can be seen as the search for regularities, and the output of any function is a mathematical pattern. Similarly in the sciences, theories explain and predict regularities in the world.
In art and architecture, decorations or visual motifs may be combined and repeated to form patterns designed to have a chosen effect on the viewer. In computer science, a software design pattern is a known solution to a class of problems in programming. In fashion, the pattern is a template used to create any number of similar garments.
Nature.
Nature provides examples of many kinds of pattern, including symmetries, trees and other structures with a fractal dimension, spirals, meanders, waves, foams, tilings, cracks and stripes.
Symmetry.
Symmetry is widespread in living things. Animals that move usually have bilateral or mirror symmetry as this favours movement. Plants often have radial or rotational symmetry, as do many flowers, as well as animals which are largely static as adults, such as sea anemones. Fivefold symmetry is found in the echinoderms, including starfish, sea urchins, and sea lilies.
Among non-living things, snowflakes have striking sixfold symmetry: each flake is unique, its structure recording the varying conditions during its crystallisation similarly on each of its six arms. Crystals have a highly specific set of possible crystal symmetries; they can be cubic or octahedral, but cannot have fivefold symmetry (unlike quasicrystals).
Spirals.
Spiral patterns are found in the body plans of animals including molluscs such as the nautilus, and in the phyllotaxis of many plants, both of leaves spiralling around stems, and in the multiple spirals found in flowerheads such as the sunflower and fruit structures like the pineapple.
Chaos, flow, meanders.
Chaos theory predicts that while the laws of physics are deterministic, events and patterns in nature never exactly repeat because extremely small differences in starting conditions can lead to widely differing outcomes. Many natural patterns are shaped by this apparent randomness, including vortex streets and other effects of turbulent flow such as meanders in rivers.
Waves, dunes.
Waves are disturbances that carry energy as they move. Mechanical waves propagate through a medium – air or water, making it oscillate as they pass by. Wind waves are surface waves that create the chaotic patterns of the sea. As they pass over sand, such waves create patterns of ripples; similarly, as the wind passes over sand, it creates patterns of dunes.
Bubbles, foam.
Foams obey Plateau's laws, which require films to be smooth and continuous, and to have a constant average curvature. Foam and bubble patterns occur widely in nature, for example in radiolarians, sponge spicules, and the skeletons of silicoflagellates and sea urchins.
Cracks.
Cracks form in materials to relieve stress: with 120 degree joints in elastic materials, but at 90 degrees in inelastic materials. Thus the pattern of cracks indicates whether the material is elastic or not. Cracking patterns are widespread in nature, for example in rocks, mud, tree bark and the glazes of old paintings and ceramics.
Spots, stripes.
Alan Turing, and later the mathematical biologist James D. Murray and other scientists, described a mechanism that spontaneously creates spotted or striped patterns, for example in the skin of mammals or the plumage of birds: a reaction-diffusion system involving two counter-acting chemical mechanisms, one that activates and one that inhibits a development, such as of dark pigment in the skin. These spatiotemporal patterns slowly drift, the animals' appearance changing imperceptibly as Turing predicted.
Art and architecture.
Tilings.
In visual art, pattern consists in regularity which in some way "organizes surfaces or structures in a consistent, regular manner." At its simplest, a pattern in art may be a geometric or other repeating shape in a painting, drawing, tapestry, ceramic tiling or carpet, but a pattern need not necessarily repeat exactly as long as it provides some form or organizing "skeleton" in the artwork. In mathematics, a tessellation is the tiling of a plane using one or more geometric shapes (which mathematicians call tiles), with no overlaps and no gaps.
In architecture.
In architecture, motifs are repeated in various ways to form patterns. Most simply, structures such as windows can be repeated horizontally and vertically (see leading picture). Architects can use and repeat decorative and structural elements such as columns, pediments, and lintels. Repetitions need not be identical; for example, temples in South India have a roughly pyramidal form, where elements of the pattern repeat in a fractal-like way at different sizes.
Science and mathematics.
Mathematics is sometimes called the "Science of Pattern", in the sense of rules that can be applied wherever needed. For example, any sequence of numbers that may be modeled by a mathematical function can be considered a pattern. Mathematics can be taught as a collection of patterns.
Fractals.
Some mathematical rule-patterns can be visualised, and among these are those that explain patterns in nature including the mathematics of symmetry, waves, meanders, and fractals. Fractals are mathematical patterns that are scale invariant. This means that the shape of the pattern does not depend on how closely you look at it. Self-similarity is found in fractals. Examples of natural fractals are coast lines and tree shapes, which repeat their shape regardless of what magnification you view at. While self-similar patterns can appear indefinitely complex, the rules needed to describe or produce their formation can be simple (e.g. Lindenmayer systems describing tree shapes).
In pattern theory, devised by Ulf Grenander, mathematicians attempt to describe the world in terms of patterns. The goal is to lay out the world in a more computationally friendly manner.
In the broadest sense, any regularity that can be explained by a scientific theory is a pattern. As in mathematics, science can be taught as a set of patterns.
Computer science.
In computer science, a software design pattern, in the sense of a template, is a general solution to a problem in programming. A design pattern provides a reusable architectural outline that may speed the development of many computer programs.
Fashion.
In fashion, the pattern is a template, a technical two-dimensional tool used to create any number of identical garments. It can be considered as a means of translating from the drawing to the real garment.

</doc>
<doc id="68353" url="https://en.wikipedia.org/wiki?curid=68353" title="Solar furnace">
Solar furnace

A solar furnace is a structure that uses concentrated solar power to produce high temperatures, usually for industry. Parabolic mirrors or heliostats concentrate light (Insolation) onto a focal point. The temperature at the focal point may reach , and this heat can be used to generate electricity, melt steel, make hydrogen fuel or nanomaterials.
The largest solar furnace is at Odeillo in the Pyrénées-Orientales in France, opened in 1970. It employs an array of plane mirrors to gather sunlight, reflecting it onto a larger curved mirror.
History.
The ancient Greek / Latin term "heliocaminus" literally means "solar furnace" and refers to a glass-enclosed sunroom intentionally designed to become hotter than the outside air temperature.
During the Second Punic War (218 - 202 BC), the Greek scientist Archimedes is said to have repelled the attacking Roman ships by setting them on fire with a "burning glass" that may have been an array of mirrors. An experiment to test this theory was carried out by a group at the Massachusetts Institute of Technology in 2005. It concluded that although the theory was sound for stationary objects, the mirrors would not likely have been able to concentrate sufficient solar energy to set a ship on fire under battle conditions.
The first modern solar furnace is believed to have been built in France in 1949 by Professor Félix Trombe. It is now still in place at Mont Louis, near Odeillo. The Pyrenees were chosen as the site because the area experiences clear skies up to 300 days a year.
Another solar furnace was built in Uzbekistan as a part of a Soviet Union "Sun" Complex Research Facility impulsed by Academician S.A. Asimov.
Uses.
The rays are focused onto an area the size of a cooking pot and can reach , depending on the process installed, for example:
It has been suggested that solar furnaces could be used in space to provide energy for manufacturing purposes. 
Their reliance on sunny weather is a limiting factor as a source of renewable energy on Earth but could be tied to thermal energy storage systems for energy production through these periods and into the night.
Smaller-scale devices.
The solar furnace principle is being used to make inexpensive solar cookers and solar-powered barbecues, and for solar water pasteurization. A prototype Scheffler reflector is being constructed in India for use in a solar crematorium. This 50 m² reflector will generate temperatures of and displace 200–300 kg of firewood used per cremation.

</doc>
<doc id="68360" url="https://en.wikipedia.org/wiki?curid=68360" title="René Lalique">
René Lalique

René Jules Lalique (6 April 1860, Ay, Marne — 1 May 1945, Paris) was a French glass designer known for his creations of glass art, perfume bottles, vases, jewellry, chandeliers, clocks and automobile hood ornaments.
Life.
Lalique's early life was spent learning the methods of design and art he would use in his later life. At the age of two, his family moved to the suburbs of Paris, but traveled to Ay for summer holidays. These trips influenced Lalique' later on in his naturalistic glasswork. With the death of his father two years later, Lalique began working as an apprentice to goldsmith Louis Aucoc in Paris. He died 5 May 1945, Paris. René Lalique was buried in Père Lachaise Cemetery in Paris, France. His granddaughter, Marie Claude-Lalique (b. 1936), was also a glass maker. She died on April 14, 2003 in Fort Myers, Florida.
Education.
In 1872, when he was twelve, he entered the Collège Turgot where he started drawing and sketching. He attended evening classes at the Ecole des arts décoratifs. He worked there from 1874-1876 and subsequently spent two years at the Crystal Palace School of Art Sydenham, London. At the Sydenham Art College, his skills for graphic design were improved, and his naturalistic approach to art was further developed.
Art Nouveau jewellery designer.
When he returned from England, he worked as a freelance artist, designing pieces of jewellery for French jewelers Cartier, Boucheron and others. In 1885, he opened his own business and designed and made his own jewellery and other glass pieces. By 1890, Lalique was recognized as one of France's foremost Art Nouveau jewellery designers; creating innovative pieces for Samuel Bing's new Paris shop, Maison de l'Art Nouveau. He went on to be one of the most famous in his field, his name synonymous with creativity, beauty and quality.
Glass maker.
Lalique was best known for his creations in glass art. In the 1920s, he became noted for his work in the Art Deco style. He was responsible for the walls of lighted glass and elegant coloured glass columns which filled the dining room and "grand salon" of the and the interior fittings, cross, screens, reredos and font of St. Matthew's Church at Millbrook in Jersey (Lalique's "Glass Church"). 
His earlier experiences in Ay were his defining influence in his later work. As a result, many of his jewellery pieces and vases showcase plants, flowers and flowing lines.
Both unique and commercial works of René Lalique are in the collections of a large number of public museums around the world including the Museu Calouste Gulbenkian in Lisbon, the Musée Lalique and the Musée des Arts Décoratifs in France, the Schmuckmuseum Pforzheim in Germany, the Victoria and Albert Museum in London, the Metropolitan Museum and the Corning Museum in New York State, and the Rijksmuseum in Amsterdam.

</doc>
