<doc id="10814" url="https://en.wikipedia.org/wiki?curid=10814" title="Family name">
Family name

A family name (in Western contexts often referred to as a surname or last name) is typically a part of a person's personal name which, according to law or custom, is passed or given to children from one or both of their parents' family names. The use of family names is common in most cultures around the world, with each culture having its own rules as to how these names are formed, passed and used. But the practice is not universal, with some cultures not using family names (See mononym). Also, in most Slavic countries and in Greece, for example, there are different family name forms for male and female members of the family. Issues of family name arise especially on the passing of a name to a new-born child, on the adoption of a common family name on marriage, on renouncing of a family name and on changing of a family name.
Most countries have laws requiring its citizens and those resident within its jurisdiction to have a family name. Traditionally in many European countries for the past few hundred years, it was the custom or law that a woman would on marriage use the surname of her husband and that children of a man would have the father's surname. If a child's paternity was not known, or if the putative father denied paternity, the new-born child would have the surname of the mother. That is still the custom and law in many countries. The surname for children of married parents is usually inherited from the father. In recent years there has been a trend towards equality of treatment in relation to family names with women not being automatically required or expected, some places even forbidden, to take the husband's surname on marriage, and children not automatically being given the father's surname. In this article, "family name" and "surname" both mean the patrilineal (literally, father-line) surname, handed down from or inherited from the father's line or patriline, unless explicitly stated otherwise. Thus, the term "maternal surname" means the "patrilineal" surname which one's mother inherited from either or both of her parents. For a discussion of "matrilineal" ('mother-line') surnames, passing from mothers to daughters, see matrilineal surname.
Overview.
In many cultures (particularly in European and European-influenced cultures in the Americas, Oceania, etc., as well as the Middle East, South Asia, and most African cultures), the family name is normally the last part of a person's personal name. In some other cultures, the family name comes first. The latter is often called the Eastern order because Europeans are most familiar with the examples from East Asia, specifically Japan, China, Korea and Vietnam. The Eastern order is also used in Hungary and in parts of Africa. Since family names are normally written last in European societies (except in Hungary), the term last name is commonly used for "family name", while in Japan (with vertical writing) the family name may be referred to as upper name ().
In English-speaking cultures, family names are often used by children when referring to adults, but it's also used to refer to someone in authority, the elderly, or in a formal setting, and are often used with a title or honorific such as Mr., Mrs., Ms., Miss, Dr, and so on. Generally the given name, first name, forename, or personal name is the one used by friends, family, and other intimates to address an individual. It may also be used by someone who is in some way senior to the person being addressed. This practice also differs between cultures; see T-V distinction.
Research on individual names.
The study of proper names in family names is called onomastics. A one-name study is a collection of vital and other biographical data about all persons worldwide sharing a particular surname.
History.
While given names have been used from the most distant times to identify individuals, the advent of surnames is a relatively recent phenomenon. In Britain, hereditary surnames were adopted in the 13th and 14th centuries, initially by the aristocracy but eventually by everyone. By 1400, most English and some Scottish people used surnames, but many Scottish and Welsh people did not adopt surnames until the 17th century, or even later. Henry VIII (ruled 1509–1547) ordered that marital births be recorded under the surname of the father. In England and cultures derived from there, there has long been a tradition for a woman to change her surname upon marriage from her birth name to her husband's family name. (See Married and maiden names.) The first known instance in the United States of a woman insisting on the use of her birth name was that of Lucy Stone in 1855; and there has been a general increase in the rate of women using their birth name. This has gone through periods of flux, however, and the 1990s saw a decline in the percentage of name retention among women. As of 2006, more than 80% of American women adopted the husband's family name after marriage.
Many cultures have used and continue to use additional descriptive terms in identifying individuals. These terms may indicate personal attributes, location of origin, occupation, parentage, patronage, adoption, or clan affiliation. These descriptors often developed into fixed clan identifications that in turn became family names as we know them today.
In China, according to legend, family names started with Emperor Fu Xi in 2852 BC His administration standardised the naming system in order to facilitate census-taking, and the use of census information. For scientific documentation that matrilineal surnames existed in China before the Shang Dynasty (1600–1046 BC) and that "by the time of the Shang Dynasty they (Chinese surnames) had become patrilineal", see Matrilineality in China. Chinese women do not change their names upon marriage. They can be referred to either as their full birth names or as their husband's last name plus the word for wife. But in the past, women often had no official first name and were referred in official documents by their family name plus the character "Shi" and when married by their husband's surname, their birth surname, and the character "Shi."
In Japan, family names were uncommon except among the aristocracy until the 19th century.
In Ancient Greece, during some periods, formal identification commonly included place of origin.
At other times clan names and patronymics ("son of") were also common, as in Aristides Lysimachu. For example, Alexander the Great was known as "Heracleides" (as a supposed descendant of Heracles) and by the dynastic name "Karanos"/"Caranus", which referred to the founder of the dynasty to which he belonged. In none of these cases, though, were these names considered essential parts of the person's name, nor were they explicitly inherited in the manner that is common in many cultures today.
In the Roman Empire, the bestowal and use of clan and family names waxed and waned with changes in the various subcultures of the realm. ("See Roman naming conventions.") The nomen, which was the gens name, was inherited much like last names are, but their purposes were quite different. In later Europe, last names were developed to distinguish between individuals. The nomen were to identify group kinship. The praenomen was literally the "forename" and was originally used like a first name today. In later times, praenomen became less useful for distinguishing invidiuals as it was often passed down for boys along with the nomen (like an entire culture where "John Smith, Jr." was the norm), and girls, were often given nno praenomen at all or functional names like Major and Minor ("Older" and "Younger") or Maixma, Maio, and Mino ("Biggest," "Middle," "Littlest") or ordinal numbers rather than what we might think of as names: Prima, Secunda, Tertia, Quarta, etc. Around this time, the nomen became followed by one or more additional names called cognomen. It became usual that one of these cognomen was inherited, but as the praenomen and nomen became ever more rigidly used and less useful for identifying individuals, additional personal cognomen were more often used, to the point that the first the praenomen and then the nomen fell out of use entirely. With the gradual influence of Greek/Christian culture throughout the Empire, Christian religious names were sometimes put in front of traditional cognomen, but eventually, people reverted to sungle names. By the time of the fall of the Western Roman Empire in the 5th century, family names were uncommon in the Eastern Roman Empire. In Western Europe, where Germanic culture dominated the aristocracy, family names were almost non-existent. They would not significantly reappear again in Eastern Roman society until the 10th century, apparently influenced by the familial affiliations of the Armenian military aristocracy. The practice of using family names spread through the Eastern Roman Empire and gradually into Western Europe, although it was not until the modern era that family names came to be explicitly inherited as they are today.
In Ireland, the use of surnames has a very old history. Ireland was the first country in Europe to use fixed surnames. As noted in the Annals, the first recorded fixed surname was Ó Cleirigh, which recorded the death of Tigherneach Ua Cleirigh, lord of Aidhne in Co. Galway in the year 916.
In England, the introduction of family names is generally attributed to the preparation of the Domesday Book in 1086, following the Norman conquest. Evidence indicates that surnames were first adopted among the feudal nobility and gentry, and only slowly spread to other parts of society. Some of the early Norman nobility who arrived in England during the Norman conquest differentiated themselves by affixing 'de' (of) before the name of their village in France. This is what is known as a territorial surname, a consequence of feudal landownership. In medieval times in France, such a name indicated lordship, or ownership, of the village. But some early Norman nobles in England chose to drop the French derivations and call themselves instead after their new English holdings.
Modern era.
During the modern era, many cultures around the world adopted family names, particularly for administrative reasons, especially during the age of European expansion and particularly since 1600. Notable examples include the Netherlands (1811), Japan (1870s), Thailand (1920), and Turkey (1934). Nonetheless, their use is not universal: Icelanders, Tibetans, Burmese, Javanese, and many people groups in East Africa do not use family names.
Family names sometimes change or are replaced by non-family-name surnames under political pressure to avoid persecution. Examples are the cases with Chinese Indonesians and Chinese Thais after migration there during the 20th century, or the Jews who fled to different European countries to avoid persecution from the Nazis during World War II.
The United States followed the naming customs and practices of English common law and traditions until recent times. Beginning in the latter half of the 20th century, traditional naming practices, writes one commentator, were recognized as "cominto conflict with current sensitivities about children's and women's rights." Those changes accelerated a shift away from the interests of the parents to a focus on the best interests of the child. The law in this area continues to evolve today mainly in the context of paternity and custody actions.
UN Convention on the Elimination of All Forms of Discrimination Against Women.
In 1979, the United Nations adopted the "Convention on the Elimination of All Forms of Discrimination Against Women" ("CEDAW"), which declared in effect that women and men, and specifically wife and husband, shall have the same rights to choose a ""family name"", as well as a "profession" and an "occupation". For a further description of and treatment of this Convention, see Matriname.
In France, until 1 January 2005, children were required by law to take the surname of their father. Article 311-21 of the French Civil code now permits parents to give their children the family name of either their father, mother, or a hyphenation of both – although no more than two names can be hyphenated. In cases of disagreement, the father's name applies. This brought France into line with a 1978 declaration by the Council of Europe requiring member governments to take measures to adopt equality of rights in the transmission of family names, a measure that was echoed by the United Nations in 1979. Similar measures were adopted by Germany (1976), Sweden (1982), Denmark (1983) and Spain (1999). The European Community has been active in eliminating gender discrimination. Several cases concerning discrimination in family names have reached the courts. "Burghartz v. Switzerland" challenged the lack of an option for husbands to add the wife's surname to his surname, which they had chosen as the family name, when this option was available for women. "Losonci Rose and Rose v. Switzerland" challenged a prohibition on foreign men married to Swiss women keeping their surname if this option was provided in their national law, an option available to women. "Unal Tekeli v. Turkey" challenged prohibitions on women using their surname as the family name, an option only available to men. The Court found all these laws to be in violation of the Convention.
By language.
English-speaking countries.
Most surnames of British origin fall into seven types:
The original meaning of the name may no longer be obvious in modern English (e.g., a "Cooper" is one who makes barrels. In the Americas, the family names of many African-Americans have their origins in slavery ("i.e." slave name). Many of them came to bear the surnames of their former owners. Many freed slaves either created family names themselves or adopted the name of their former master.
In the Middle Ages, when a man from a lower-status family married an only daughter from a higher-status family, he would often adopt the wife's family name. In the 18th and 19th centuries in Britain, bequests were sometimes made contingent upon a man's changing (or hyphenating) his family name, so that the name of the testator continued. It is rare but not unknown for an English-speaking man to take his wife's family name, whether for personal reasons or as a matter of tradition (such as among matrilineal Canadian aboriginal groups, such as the Haida and Gitxsan); it is exceedingly rare but does occur in the United States, where a married couple may choose an entirely new last name by going through a legal change of name. As an alternative, both spouses may adopt a double-barreled name. For instance, when John Smith and Mary Jones marry each other, they may become known as "John Smith-Jones" and "Mary Smith-Jones." A spouse may also opt to use his or her birth name as a middle name. An additional option, although rarely practiced, is the adoption of a last name derived from a blend of the prior names, such as "Simones", which also requires a legal name change. Some couples keep their own last names but give their children hyphenated or combined surnames.
Upon marriage, men in the United States can easily change their surname to that of their wife's or a combination of their two names with the federal government, through the Social Security Administration, but may face difficulty on the state level in some states. In some places, civil rights lawsuits or constitutional amendments changed the law so that men could also easily change their married names (e.g., in British Columbia and California). Québec law permits neither spouse to change surnames.
Spanish-speaking countries.
In medieval times, a patronymic system was used. For example, "Álvaro", the son of "Rodrigo" would be named "Álvaro Rodríguez". His son, "Juan", would not be named "Juan Rodríguez", but "Juan Álvarez". Over time, many of these patronymics became family names and are some of the most common names in the Spanish-speaking world. Other sources of surnames are personal appearance or habit, e.g. "Delgado" ("thin") and "Moreno" (polysemous word, it can mean "brown skinned", "dark skinned", "tanned skinned", "brunette hair" or "black hair"); occupations, e.g. "Molinero" ("miller"), "Zapatero" ("Shoe-maker") and "Guerrero" ("warrior"); and geographic location or ethnicity, e.g. "Alemán" ("German").
In Spain and in Spanish-speaking countries (e.g. Mexico, Puerto Rico, Cuba, Guatemala, Nicaragua, Colombia, El Salvador, Dominican Republic, Peru, Chile, Ecuador, Panama, The Philippines and Venezuela), people traditionally have two family names: the first family name is the paternal one, inherited from the father's paternal family name, while the second family name is the maternal one, inherited from the mother's paternal family name. When speaking or in informal situations only the first one is used, although both are needed for legal purpose. In some instances, when an individual's given name and first family name are too common (such as in José Luis Rodríguez Zapatero and Mario Vargas Llosa), both family names are used (though not necessarily both given names). A person could even take the maternal name for informal situations instead of the paternal name, for personal preferences or if the maternal name is somehow "special" (José Luís Rodríguez Zapatero is known in Spanish as "José Luis Zapatero" or just as "Zapatero"). In Spain, a new law approved in 1999 allows an adult to change the order of his/her family names, and parents can also change the order of their children's family names if they (and the child, if over 12) agree.
Depending on the country, the family names may or may not be linked by the conjunction "y" ("and"), "i" ("and" in Catalonia), "de" ("of"), "del" ("of the", when the following word is masculine) or "de la" ("of the", when the following word is feminine). Sometimes a father transmits his combined family names, thus creating a new one e.g., the paternal surname of the son of "Javier" (given name) "Reyes" (paternal family name) "de la Barrera" (maternal surname) may become the new paternal surname "Reyes de la Barrera". "De" is also the nobiliary particle used with Spanish surnames. This can not be choose by the person, as it is part of the surname, for example "Puente" and "Del Puente" are not the same surname.
Traditionally in most countries, and currently in some Spanish-speaking countries, women, upon marrying, keep their own family names. It is considered impolite towards her family for a woman to change her name. The higher class women of Cuba and Spain traditionally never change their names. In certain rare situations, a woman may be addressed with her paternal surname followed by her husband's paternal surname linked with "de". For example, a woman named "Ana García Díaz", upon marrying "Juan Guerrero Macías", could be called "Ana García de Guerrero". This custom, begun in medieval times, is decaying and only has legal validity in Dominican Republic, Ecuador, Guatemala, Nicaragua, Honduras, Peru, Panama, and to a certain extent in Mexico (where it is optional but becoming obsolete), but is frowned upon by people in Spain, Cuba, and elsewhere. In Peru and the Dominican Republic, women normally conserve all family names after getting married. For example, if "Rosa María Pérez Martínez" marries "Juan Martín De la Cruz Gómez", she will be called "Rosa María Pérez Martínez de De la Cruz", and if the husband dies, she will be called "Rosa María Pérez Martínez Vda. de De la Cruz" (Vda. being the abbreviation for "viuda", "widow" in Spanish). The law in Peru changed some years ago, and all married women can keep their maiden last name if they wish with no alteration.
In Uruguay, since 2013, a couple can choose the order of the surnames for their first-born. After the choice has been made, all their following children will be registered with the same order. If there's no agreement on the order, in the case of heterosexual couples, the father's surname will be placed first and the mother's second, and with homosexual couples, a draw is made to decide the order. Once the order of the surnames has been established, it can not be changed.
In Ecuador, a couple can choose the order of their children's surnames. Most choose the traditional order (e.g., "Guerrero García" in the example above), but some invert the order, putting the mother's paternal surname first and the father's paternal surname last (e.g., "García Guerrero" from the example above). Such inversion, if chosen, must be consistent for all children of the marriage.
In Argentina, normally only one family name, the father's paternal family name, is used and registered as in English-speaking countries. However, it is possible to use both the paternal and maternal name. For example, if "Ana Laura Melachenko" and "Emanuel Darío Guerrero" had a daughter named "Adabel Anahí", her full name could be "Adabel Anahí Guerrero Melachenko". Women, however, do not change their family names upon marriage and continue to use their birth family names instead of their husband's family names. However, some women do choose to use the old Spanish custom of adjoining "de" and her husband's paternal surname to her own name. For example, if Paula Segovia marries Felipe Cossia, she might keep her birth name or become "Paula Segovia de Cossia" or "Paula Cossia".
In Cuba and in Nicaragua, both men and women carry their two family names (first their father's, and second their mother's). Both are equally important and are mandatory for any official document. Married women never change their original family names for their husband's. Even when they migrate to other countries where this is a common practice, many prefer to adhere to their heritage and keep their maiden name.
In Spanish villages in Catalonia, Galicia, and Asturias and in Cuba, people are often known by the name of their dwelling or collective family nickname rather than by their surnames. For example, Remei Pujol i Serra who lives at Ca l'Elvira would be referred to as "Remei de Ca l'Elvira"; and Adela Barreira López who is part of the "Provisores" family would be known as "Adela dos Provisores".
In the Philippines on 21 November 1849, the Spanish Governor General of the Philippine Islands, Narciso Clavería, decreed the systematic distribution of surnames to Filipinos without prior surnames and the universal implementation of the Spanish naming system, thereby producing the Catálogo Alfabético de Apellidos (“Alphabetical Catalogue of Surnames"), which listed permitted surnames with origins in Spanish, Filipino, and Hispanicised Chinese words, names, and numbers. Thus many Spanish-sounding Filipino surnames are not surnames common to the Hispanophone world. Adopting Spanish nobility and colonial administrator surnames was explicitly prohibited.
The colonial authorities implemented this decree because too many (early) Christianized Filipinos assumed religious-instrument and saint names. There soon were too many people surnamed "de los Santos" (“of the Saints”), "de la Cruz" (“of the Cross”), "del Rosario" (“of the Rosary”), "Bautista" (“Baptist”), et cetera, which made it difficult for the Spanish colonists to control the Filipino people, and most importantly, to collect taxes. These extremely common names were banned by the decree unless they had been in use by the family for at least four generations. This Spanish naming custom also countered the native Filipino naming custom wherein siblings assumed different surnames, as practised before the Spanish Conquest of the Philippine Islands. The decree was enforced to different degrees in different regions.
Because of this implementation of Spanish naming customs (given name -paternal surname -maternal surname) in the Philippines, a Spanish surname does not necessarily denote Spanish ancestry.
French-speaking countries.
France 
Belgium 
Canadian 
German-speaking countries.
There are about 1,000,000 different family names in German. German family names most often derive from given names, geographical names, occupational designations, bodily attributes or even traits of character. Hyphenations notwithstanding, they mostly consist of a single word; in those rare cases where the family name is linked to the given names by particles such as "von" or "zu", they usually indicate noble ancestry. Not all noble families used these names (see Riedesel), while some farm families, particularly in Westphalia, used the particle "von" or "zu" followed by their farm or former farm's name as a family name (see "Meyer zu Erpen").
Family names in German-speaking countries are usually positioned last, after all given names. There are exceptions, however: in parts of Austria and Bavaria and the Alemannic-speaking areas, the family name is regularly put in front of the first given name. Also in many – especially rural – parts of Germany, to emphasize family affiliation there is often an inversion in colloquial use, in which the family name becomes a possessive: "Rüters Erich", for example, would be Erich of the Rüter family.
In Germany today, upon marriage, both partners can choose to keep their birth name or choose either partner's name as the common name. In the latter case the partner whose name wasn't chosen can keep his birth name hyphenated to the new name (e.g. "Schmidt" and "Meyer" choose to marry under the name "Meyer". The former "Schmidt" can choose to be called "Meyer", "Schmidt-Meyer" or "Meyer-Schmidt"), but any children will only get the single common name. In the case that both partners keep their birth name they must decide on one of the two family names for all their future children. (German name)
Changing one's family name for reasons other than marriage, divorce or adoption is possible only if the application is approved by the responsible government agency. Permission will usually be granted if:
Otherwise, name changes will normally not be granted.
Portuguese-speaking countries.
In the case of Portuguese naming customs, the main surname (the one used in alphasorting, indexing, abbreviations, and greetings), appears last.
Each person usually has two family names: though the law specifies no order, the first one is usually the maternal family name, whereas the last one is commonly the paternal family name. In Portugal, a person's full name has a minimum legal length of two names (one given name and one family name from either parent) and a maximum of six names (two first names and four surnames — he or she may have up to four surnames in any order desired picked up from the total of his/her parents and grandparents' surnames). The use of any surname outside this lot, or of more than six names, is legally possible, but it requires dealing with bureaucracy. Parents or the person him/herself must explain the claims they have to bearing that surname (a family nickname, a rare surname lost in past generations, or any other reason one may find suitable). In Brazil there is no limit of surnames used.
In ancient times a patronymic was commonly used — surnames like "Gonçalves" ("son of "Gonçalo""), "Fernandes" ("son of "Fernando""), "Nunes" ("son of "Nuno""), "Soares" ("son of "Soeiro""), "Sanches" ("son of "Sancho""), "Henriques" ("son of "Henrique""), "Rodrigues" ("son of "Rodrigo"") which along with many others are still in regular use as very prevalent family names.
In Medieval times, Portuguese nobility started to use one of their estates' names or the name of the town or village they ruled as their surname, just after their patronymic. Soeiro Mendes da Maia bore a name "Soeiro", a patronymic "Mendes" ("son of Hermenegildo – shortened to Mendo") and the name of the town he ruled "Maia". He was often referred to in 12th century documents as "Soeiro Mendes, senhor da Maia", Soeiro Mendes, lord of Maia. Noblewomen also bore patronymics and surnames in the same manner and never bore their husband's surname. First-born males bore their father's surname, other children bore either both or only one of them at their will.
Only during the Early Modern Age, lower-class males started to use at least one surname; married lower-class women usually took up their spouse's surname, since they rarely ever used one beforehand. After the 1755 Lisbon earthquake, Portuguese authorities realized the benefits of enforcing the use and registry of surnames. Henceforth, they became mandatory, although the rules for their use were very liberal.
During the mid-20th century, under French influence and among upper classes, women started to take up their husbands' surname(s). From the 1960s onwards, this usage spread to the common people, again under French influence, this time, however, due to the forceful legal adoption of their husbands' surname which was imposed onto Portuguese immigrant women in France.
From the 1974 Carnation Revolution onwards the adoption of their husbands' surname(s) receded again, and today both the adoption and non-adoption occur, with non-adoption being chosen in the majority of cases in recent years (60%). Also, it is legally possible for the husband to adopt his wife's surname(s), but this practice is rare.
Brazilians usually call people only by their given names, omitting family names, even in many formal situations, as in the press referring to authorities, e.g. "Former President Fernando Henrique", never Former President Cardoso, or even "Former President Lula" ("Lula" was actually his nickname). When formality or a prefix requires a family name, the given name usually precedes the surname, e.g. "João Santos", or "Sr. João Santos".
Dutch-speaking countries.
The Netherlands 
Belgium 
Arabic-speaking Countries.
The given name is always followed by the father's first name, then the father's family surname.
Some surnames have a prefix of "ibn"- meaning son of ("ould"- in Mauritania)
The surnames follow similar rules defining a relation to a clan, family, place etc.
Some Arab countries have differences due to historic rule by the Ottoman Empire or due to being a different minority.
A large number of Arabic last names start with "Al-" which means "The"
Arab States of the Persian Gulf.
Names mainly consist of the person's name followed by the father's first name connected by the word "ibn" or "bin" (meaning "son of"). The last name either refers to the name of the tribe the person belongs to, or to the region, city, or town he/she originates from. In exceptional cases, members of the royal families or ancient tribes mainly, the title (usually H.M./H.E., Prince, or Sheikh) is included in the beginning as a prefix, and the first name can be followed by four names, his father, his grandfather, and great – grandfather, as a representation of the purity of blood and to show the pride one has for his ancestry.
In Arabic-speaking Levantine countries (Jordan, Lebanon, Palestine, Syria) it's common to have family names associated with a certain profession or craft, such as "Al-Haddad"/"Haddad" which means "Blacksmith" or "Al-Najjar"/"Najjar" which means "Carpenter".
Bantu languages.
In several Northeast Bantu languages such as Kamba, Taita and Kikuyu in Kenya the word "wa" (meaning "of") is inserted before the surname, for instance, Mugo wa Kibiru (Kikuyu) and Mekatilili wa Menza (Taita).
By country.
Albania.
A full Albanian name consists of a given name (), patronymic () and family name (), for example "Agron Mark Gjoni". The patronymic is simply the given name of the individual's father, with no suffix added. The family name is typically a noun in the definite form or at the very least ends with a vowel or -j (an approximant close to -i). Many traditional last names end with -aj (previously -anj), which is more prevalent in certain regions of Albania and Kosovo.
Proper names in Albanian are fully declinable like any noun (e.g. "Marinelda", genitive case "i/e Marineldës" "of Marinelda").
Armenia.
Armenian surnames almost always have the ending () transliterated into English as -yan or -ian (spelled -ean (եան) in Western Armenian and pre-Soviet Eastern Armenian, of Ancient Armenian or Iranian origin, presumably meaning "son of"), though names with that ending can also be found among Persians and a few other nationalities. Armenian surnames can derive from a geographic location, profession, noble rank, personal characteristic or personal name of an ancestor. Armenians in the diaspora sometimes adapt their surnames to help assimilation. In Russia, many have changed -yan to -ov (or -ova for women). In Turkey, many have changed the ending to -oğlu (also meaning "son of"). In English and French-speaking countries, many have shortened their name by removing the ending (for example Charles Aznavour). In ancient Armenia, many noble names ended with the locative -t'si (example, Khorenatsi) or -uni (Bagratuni). Several modern Armenian names also have a Turkish suffix which appears before -ian/-yan: -lian denotes a placename; -djian denotes a profession. Some Western Armenian names have a particle Der, while their Eastern counterparts have Ter. This particle indicates an ancestor who was a priest (Armenian priests can choose to marry or remain celibate, but married priests cannot become a bishop). Thus someone named Der Bedrosian (Western) or Ter Petrosian (Eastern) is a descendent of an Armenian priest. The convention is still in use today: the children of a priest named Hagop Sarkisian would be called Der Sarkisian. Other examples of Armenian surnames: Adonts, Sakunts, Vardanyants, Rshtuni.
Azerbaijan.
Traditional Azeri surnames usually end with "-lı", "-lu", (Turkic for 'with' or 'belonging to'), "-oğlu", "-qızı" (Turkic for 'son of' and 'daughter of'), "-zade" (Persian for 'born of'). Azerbaijanis of Iranian descent traditionally use suffixes such as '-pour' or '-zadeh', meaning 'born of' with their father's name. It is, however, more usual for them to use the name of the city in which their ancestors lived (e.g. Tabrizpour for those from Tabriz) or their occupation (e.g. Damirchizadeh for blacksmiths). Also, due to it being a part of the Russian Empire, many last names carry Slavic endings of "-ov" for men and "-ova" for women. 
Bulgaria.
Bulgarian names usually consist of three components – given name, father's name, family name.
Given names have many variations, but the most common names have Christian/Greek (e.g. Maria, Ivan, Christo, Peter, Pavel), Slavic (Ognyan, Miroslav, Tihomir) or Protobulgarian (Krum, Asparukh) (pre-Christian) origin.
Father's names normally consist of the father's first name and the "-ov" (male) or "-ova" (female) or "-ovi" (plural) suffix.
Family names usually also end with the "-ov", "-ev" (male) or "-ova", "-eva" (female) or "-ovi", "-evi" (plural) suffix.
In many cases (depending on the name root) the suffixes can be also "-ski" (male and plural) or "-ska" (female); "-ovski", "-evski" (male and plural) or "-ovska", "-evska" (female); "-in" (male) or "-ina" (female) or "-ini" (plural); etc.
The meaning of the suffixes is similar to the English word "of", expressing membership in/belonging to a family.
For example, the family name Ivanova means a person belonging to the Ivanovi family.
A father's name Petr*ov* means son of Peter.
Regarding the different meaning of the suffixes, "-ov", "-ev"/"-ova", "-eva" are used for expressing relationship to the father and "-in"/"-ina" for relationship to the mother (often for orphans whose father is dead).
Finland.
There are two predominant surname traditions among the Finnish in Finland: the West Finnish and the East Finnish. The surname traditions of Swedish-speaking farmers and fishermen resembles the West Finnish tradition, while Sami and Romani people have traditions of their own.
Until the mid 20th Century, Finland was a predominantly agrarian society, and the names of West Finns were based on their association with a particular area, farm, or homestead, e.g. "Jaakko Jussila" ("Jaakko from the farm of Jussi"). On the other hand, the East Finnish surname tradition dates back to the 13th century. There, the Savonians pursued slash-and-burn agriculture which necessitated moving several times during a person's lifetime. This in turn required the families to have surnames, which were in wide use among the common folk as early as the 13th century. By the mid-16th century, the East Finnish surnames had become hereditary. Typically, the oldest East Finnish surnames were formed from the first names of the patriarchs of the families, e.g. "Ikävalko", "Termonen", "Pentikäinen". In the 16th, 17th, and 18th centuries, new names were most often formed by adding the name of the former or current place of living (e.g. "Puumalainen" < Puumala). In the East Finnish tradition, the females carried the family name of their fathers in female form (e.g. "Puumalatar" < "Puumalainen"). By the 19th century, this practice fell into disuse due to the influence of the West-European surname tradition.
In Western Finland, agrarian names dominated, and the last name of the person was usually given according to the farm or holding they lived on. In 1921, surnames became compulsory for all Finns. At this point, the agrarian names were usually adopted as surnames. A typical feature of such names is the addition of prefixes "Ala-" (Sub-) or "Ylä-" (Up-), giving the location of the holding along a waterway in relation of the main holding. (e.g. "Yli-Ojanperä", "Ala-Verronen")
A third tradition of surnames was introduced in Finland by the Swedish-speaking upper and middle classes, which used typical German and Swedish surnames. By custom, all Finnish-speaking persons who were able to get a position of some status in urban or learned society, discarded their Finnish name, adopting a Swedish, German or (in the case of clergy) Latin surname. In the case of enlisted soldiers, the new name was given regardless of the wishes of the individual.
In the late 19th and early 20th century, the overall modernization process, and especially the political movement of fennicization, caused a movement for adoption of Finnish surnames. At that time, many persons with a Swedish or otherwise foreign surname changed their family name to a Finnish one. The features of nature with endings "-o/ö", "-nen" ("Meriö" < "Meri" "sea", "Nieminen" < "Niemi" "point") are typical of the names of this era, as well as more or less direct translations of Swedish names ("Paasivirta" < "Hällström").
In 21st-century Finland, the use of surnames follows the German model. Every person is legally obligated to have a first and last name. At most, three first names are allowed. The Finnish married couple may adopt the name of either spouse, or either spouse (or both spouses) may decide to use a double name. The parents may choose either surname or the double surname for their children, but all siblings must share the same surname. All persons have the right to change their surname once without any specific reason. A surname that is un-Finnish, contrary to the usages of the Swedish or Finnish languages, or is in use by any person residing in Finland cannot be accepted as the new name, unless valid family reasons or religious or national customs give a reason for waiving this requirement. However, persons may change their surname to any surname that has ever been used by their ancestors if they can prove such claim. Some immigrants have had difficulty naming their children, as they must choose from an approved list based on the family's household language.
In the Finnish language, both the root of the surname and the first name can be modified by consonant gradation regularly when inflected to a case.
Georgia.
Most eastern Georgian surnames end with the suffix of "-shvili", (e.g. Kartveli'shvili) Georgian for "child" or "offspring". Western Georgian surnames most commonly have the suffix "-dze", (e.g. Laba'dze) Georgian for "son". Megrelian surnames usually end in "-ia","ua" or "ava". Other location-specific endings exist: In Svaneti "-iani", meaning "belonging to", or "hailing from", is common. In the eastern Georgian highlands common endings are "uri" and "uli". Some noble family names end in "eli", meaning "of (someplace)".
In Georgian, the surname is not normally used as the polite form of address; instead, the given name is used together with a title. For instance, Nikoloz Kartvelishvili is politely addressed as "bat'ono Nikoloz" "My Lord. Nikoloz".
Greece and Cyprus.
Greek surnames are most commonly patronymics. Occupation, characteristic, or ethnic background and location/origin-based surnames names also occur; they are sometimes supplemented by nicknames.
Commonly, Greek male surnames end in -s, which is the common ending for Greek masculine proper nouns in the nominative case. Exceptionally, some end in -ou, indicating the genitive case of this proper noun for patronymic reasons.
Although surnames are static today, dynamic and changing patronym usage survives in middle names in Greece where the genitive of the father's first name is commonly the middle name.
Because of their codification in the Modern Greek state, surnames have Katharevousa forms even though Katharevousa is no longer the official standard. Thus, the Ancient Greek name Eleutherios forms the Modern Greek proper name Lefteris, and former vernacular practice (prefixing the surname to the proper name) was to call John Eleutherios Leftero-giannis.
Modern practice is to call the same person Giannis Eleftheriou: the proper name is vernacular (and not Ioannis), but the surname is an archaic genitive. However, children are almost always baptised with the archaic form of the name so in official matters the child will be referred to as Ioannis Eleftheriou and not Giannis Eleftheriou.
Female surnames are most often in the Katharevousa genitive case of a male name. This is an innovation of the Modern Greek state; Byzantine practice was to form a feminine counterpart of the male surname (e.g. masculine Palaiologos, Byzantine feminine Palaiologina, Modern feminine Palaiologou).
In the past, women would change their surname when married to that of their husband (again in genitive case) signifying the transfer of "dependence" from the father to the husband. In earlier Modern Greek society, women were named with -aina as a feminine suffix on the husband's first name: "Giorgaina", "Mrs George", "Wife of George". Nowadays, a woman's legal surname does not change upon marriage, though she can use the husband's surname socially. Children usually receive the paternal surname, though in rare cases, if the bride and groom have agreed before the marriage, the children can receive the maternal surname.
Some surnames are prefixed with Papa-, indicating ancestry from a priest, e.g. "Papageorgiou", the "son of a priest named George". Others, like Archi- and Mastro- signify "boss" and "tradesman" respectively.
Prefixes such as Konto-, Makro-, and Chondro- describe body characteristics, such as "short", "tall/long" and "fat". "Gero-" and "Palaio-" signify "old" or "wise".
Other prefixes include Hadji- (Χαντζή- or Χαντζι-) which was an honorific deriving from the Arabic Hadj or pilgrimage, and indicate that the person had made a pilgrimage (in the case of Christians, to Jerusalem) and Kara- which is attributed to the Turkish word for "black" deriving from the Ottoman Empire era. The Turkish suffix -oglou (derived from a patronym, "-oğlu" in Turkish) can also be found. Although they are of course more common among Greece's Muslim minority, they still can be found among the Christian majority, often Greeks or Karamanlides who were pressured to leave Turkey after the Turkish Republic was founded (since Turkish surnames only date to the founding of the Republic, when Atatürk made them compulsory).
Arvanitic surnames also exist; an example is "Tzanavaras" or "Tzavaras", from the Arvanitic word "çanavar" or "çavar" meaning "brave" ("pallikari" in Greek).
Most Greek patronymic suffixes are diminutives, which vary by region. The most common Hellenic patronymic suffixes are:
Others, less common, are:
Either the surname or the given name may come first in different contexts; in newspapers and in informal uses, the order is "given name + surname", while in official documents and forums (tax forms, registrations, military service, school forms), the surname is often listed or said first.
Hungary.
In Hungarian, like Asian languages but unlike most other European ones (see French and German above for exceptions), the family name is placed before the given names. This usage does not apply to non-Hungarian names, for example "Tony Blair" will remain "Tony Blair" when written in Hungarian texts.
Names of Hungarian individuals, however, appear in Western order in English writing.
Iceland.
In Iceland, most people have no family name; a person's last name is most commonly a patronymic, i.e. derived from the father's first name. For example, when a man called "Karl" has a daughter called "Anna" and a son called "Magnús", their full names will typically be "Anna Karlsdóttir" ("Karl's daughter") and "Magnús Karlsson" ("Karl's son"). The name is not changed upon marriage.
India.
India is a country with numerous distinct cultural and linguistic groups. Thus, Indian surnames, where formalized, fall into seven general types.
Surnames are based on:
The convention is to write the first name followed by middle names and surname. It is common to use the father's first name as the middle name or last name even though it is not universal. In some Indian states like Maharashtra, official documents list the family name first, followed by a comma and the given names.
Traditionally, wives take the surname of their husband after marriage. In modern times, in urban areas at least, this practice is not universal and some wives either suffix their husband's surname or do not alter their surnames at all.. In some rural areas, particularly in North India, wives may also take a new first name after their nuptials. Children inherit their surnames from their father.
Jains generally use Jain, Shah, Firodia, Singhal or Gupta as their last names.
Sikhs generally use the words "Singh" ("lion") and "Kaur" ("princess") as surnames added to the otherwise unisex first names of men and women, respectively. It is also common to use a different surname after Singh in which case Singh or Kaur are used as middle names (Montek Singh Ahluwalia, Surinder Kaur Badal). The tenth Guru of Sikhism ordered (Hukamnama) that any man who considered himself a Sikh must use "Singh" in his name and any woman who considered herself a Sikh must use "Kaur" in her name. Other middle names or honorifics that are sometimes used as surnames include Kumar, Dev, Lal, and Chand.
The modern-day spellings of names originated when families translated their surnames to English, with no standardization across the country. Variations are regional, based on how the name was translated from the local language to English in the 18th, 19th or 20th centuries during British rule. Therefore, it is understood in the local traditions that Agrawal and Aggarwal represent the same name derived from Uttar Pradesh and Punjab respectively. Similarly, Tagore derives from Bengal while Thakur is from Hindi-speaking areas. The officially recorded spellings tended to become the standard for that family. In the modern times, some states have attempted standardization, particularly where the surnames were corrupted because of the early British insistence of shortening them for convenience. Thus Bandopadhyay became Banerji, Mukhopadhay became Mukherji, Chattopadhyay became Chatterji, etc. This coupled with various other spelling variations created several surnames based on the original surnames. The West Bengal Government now insists on re-converting all the variations to their original form when the child is enrolled in school.
Some parts of Sri Lanka, Thailand, Nepal, Burma, and Indonesia have similar patronymic customs to those of India.
Indonesia.
Indonesians comprise more than 300 ethnic groups. Not all of these groups traditionally have surnames. Nonetheless, Indonesians are well aware of the custom of family names, which is known as "marga" or "fam", and such names have become a specific kind of identifier. People can tell what a person's heritage is by his or her surname or clan name.
Javanese people are the majority in Indonesia, and most do not have any surname. There are many individuals who have only one name, such as "Suharto" and "Sukarno". These are not only common with the Javanese but also with other Indonesian ethnic groups who do not have the tradition of surnames. If, however, they are Muslims, they might opt to follow Arabic naming customs.
Most Chinese Indonesians substituted their Chinese surnames with Indonesian-sounding surnames due to political pressure from 1965 to 1998 under Suharto's regime.
Ireland, Isle of Man, and Scotland.
Many surnames of Gaelic origin in Ireland and the other Celtic nations, derive from ancestors' names, nicknames, or descriptive names. In the first group can be placed surnames such as "MacMurrough" and "MacCarthy", derived from patronymics, or "O'Brien" and "O'Grady", derived from ancestral names.
Gaelic surnames derived from nicknames include "Ó Dubhda" (from Aedh ua Dubhda—Aedh, the dark one), "O'Doherty" (from "Ó Dochartaigh", "destroyer" or "obtrusive"), "Garvery" ("garbh", "rough" or "nasty"), "Manton" ("mantach", "toothless"), "Bane" ("bán", "white", as in "white hair"), "Finn" ("fionn", "fair", as in "fair hair") and Kennedy ("cennedie", as in "ugly head")
Very few Gaelic surnames are derived from placenames or venerated people/objects. Among those that are included in this small group, several can be shown to be derivations of Gaelic personal names or surnames. One notable exception is "Ó Cuilleáin" or O'Collins (from "cuileann", "holly") as in the Holly Tree, considered one of the most sacred objects of pre-Christian Celtic culture. Another is Walsh (), meaning Welsh.
In areas where certain family names are extremely common, extra names are added that sometimes follow this archaic pattern. In Ireland, for example, where "Murphy" is an exceedingly common name, particular Murphy families or extended families are nicknamed, so that Denis Murphy's family were called "The Weavers" and Denis himself was called "Denis "The Weaver" Murphy". (See also O'Hay.)
For much the same reason, nicknames (e.g. the "Fada Burkes", "the long/tall "Burkes""), father's names (e.g. "John Morrissey Ned") or mother's maiden name ("Kennedy" becoming "Kennedy-Lydon") can become colloquial or legal surnames. The Irish family of de Courcy descends from Anglo-Normans who came to Ireland following the Norman Conquest. (The name is of French derivation, and indicates that the family once held a manor of that name in Normandy.) The de Courcy family was prominent in County Cork from the earliest days of the Norman occupation and subsequently became prominent in Ireland.
In addition to all this, Irish-speaking areas still follow the old tradition of naming themselves after their father, grandfather, great-grandfather and so on. Examples include "Mike Bartly Pat Reilly" ("Mike, son of Bartholomew, son of Pat Reilly"), "John Michel John Oge Pat Breanach" ("John, son of Michael, son of young John, son of Pat Breanach"), "Tom Paddy-Joe Seoige" ("Tom, son of Paddy-Joe Seoige"), and "Mary Bartly Mike Walsh" ("Mary, daughter of Bartly, son of Mike Walsh"). Sometimes, the female line of the family is used, depending on how well the parent is known in the area the person resides in, e.g. "Paddy Mary John" ("Paddy, son of Mary, daughter of John"). A similar tradition continues even in English-speaking areas, especially in rural districts.
Iranian/Persian/Kazan.
Persian last names may be:
Suffixes include: -an (plural suffix), -i ("of"), -zad/-zadeh ("born of"), -pur ("son of"), -nejad ("from the race of"), -nia ("descendant of"), -mand ("having or pertaining to"), -vand ("succeeding"), -far ("holder of"), -doost ("-phile"), -khah ("seeking of"), -mannesh ("having the manner of"), -ian/-yan, -gar and -chi ("whose vocation pertains").
An example is names of geographical locations plus "-i": Irani ("Iranian"), Gilani ("of Gilan province"), Tabrizi ("of the city of Tabriz").
Another example is last names that indicate relation to religious groups such as Zoroastrian (e.g. Goshtaspi, Namiranian, Azargoshasp), Jewish (e.g. Yaghybian Hayyem [Life, Shaul ) or Muslim (e.g. Alavi, Islamnia, Montazeri)
Last names are arbitrary; their holder need not to have any relation with their meaning.
Traditionally in Iran, the wife does not take her husband's surname, although children take the surname of their father. Individual reactions notwithstanding, it is possible to call a married woman by her husband's surname. This is facilitated by the fact that English words "Mrs.", "Miss", "Woman", "Lady" and "Wife (of)" in a polite context are all translated into "خانم" (Khaanom). Context, however, is important: "خانم گلدوست" (Khaanom Goldust) may, for instance, refer to the daughter of Mr. Goldust instead of his wife.
When most of Iranian surnames are used with a name, the name will be ended with a suffix _E or _ie (of) such as Hasan_e roshan (Hasan is name and roshan is surname) that means Hasan of Roshan or Mosa_ie saiidi (Muses of saiidi). The _e is not for surname and it is difficult to say it is a part of surname.
Italy.
Italy has around 350,000 surnames. Most of them derive from the following sources: patronym or ilk (e.g. "Francesco di Marco", "Francis, son of Mark" or "Eduardo de Filippo", "Edward belonging to the family of Philip"), occupation (e.g. "Enzo Ferrari", "Heinz (of the) Blacksmiths"), personal characteristic (e.g. nicknames or pet names like "Dario Forte", "Darius the Strong"), geographic origin (e.g. "Elisabetta Romano", "Elisabeth from Rome") and objects (e.g. "Carlo Sacchi", "Charles Bags"). The two most common Italian family names, "Russo" and "Rossi", mean the same thing, "Red", possibly referring to a hair color that would have been very distinctive in Italy.
Both Western and Eastern orders are used for full names: the given name usually comes first, but the family name may come first in administrative settings; lists are usually indexed according to the last name.
Since 1975, women have kept their own surname when married, but until recently (2000) they could have added the surname of the husband according to the civil code, although it was a very seldom-used practice. In recent years, the husband's surname cannot be used in any official situation. In some unofficial situations, sometimes both surnames are written (the proper first), sometimes separated by "in" (e.g. "Giuseppina Mauri in Crivelli") or, in case of widows, "ved." ("vedova").
Latvia.
Latvian male surnames usually end in "-s", "-š" or "-is" whereas the female versions of the same names end in "-a" or "-e" or "s" in both unmarried and married women. 
Before the emancipation from serfdom (1817 in Courland, 1819 in Vidzeme, 1861 in Latgale) only noblemen, free craftsmen or people living in towns had surnames. Therefore, the oldest Latvian surnames originate from German or Low German, reflecting the dominance of German as an official language in Latvia till the 19th century. Examples: "Meijers/Meijere" (German: "Meier", farm administrator; akin to Mayor), "Millers/Millere" (German: "Müller", miller), "Šmits/Šmite" (German: "Schmidt", smith), "Šulcs/Šulca" (German: "Schulze", constable), "Ulmanis" (German: "Ullmann", a person from Ulm), "Godmanis" (a God-man), "Pētersons" (son of Peter). Some Latvian surnames, mainly from Latgale are of Polish or Belorussian origin by changing the final "-ski/-cki" to "-skis/-ckis", "-czyk" to "-čiks" or "-vich/-wicz" to "-vičs", such as "Sokolovkis/Sokolovska", "Baldunčiks/Baldunčika" or "Ratkevičs/Ratkeviča". 
Most Latvian peasants received their surnames in 1826 (in Vidzeme), in 1835 (in Courland), and in 1866 (in Latgale). Diminutives were the most common form of family names. Examples: "Kalniņš/Kalniņa" (small hill), "Bērziņš/Bērziņa" (small birch). 
Nowadays many Latvians of Russian ethnicity have surnames of Russian or Ukrainian origin, for example "Volkovs/Volkova" or "Antoņenko".
Libya.
Libya's names and surnames have a strong Islamic/Arab nature, with some Turkish influence from Ottoman Empire rule of nearly 400 years.
Amazigh, Touareg and other minorities also have their own name/surname traditions.
Due to its location as a trade route and the different cultures that had their impact on Libya throughout history, one can find names that could have originated in neighboring countries, including clan names from the Arabian Peninsula, and Turkish names derived from military rank or status ("Basha", "Agha").
Lithuania.
Lithuanian names follow the Baltic distinction between male and female suffixes of names, although the details are different. Male surnames usually end in "-a", "-as", "-aitis", "-ys", "-ius", or "-us", whereas the female versions change these suffixes to "-aitė, -ytė, -iūtė", and "-utė" respectively (if unmarried) or "-ienė" (if married). Some Lithuanians have names of Polish or another Slavic origin, which are made to conform to Lithuanian by changing the final "-ski" to "-skas", such as "Sadauskas", with the female version being "-skienė".
Malta.
Different cultures have their impact on the demographics of the Maltese islands, and this is evident in the various surnames Maltese citizens bear nowadays. There are very few "Maltese" surnames per se: the few that originate from Maltese places of origin include "Chircop" (Kirkop), "Lia" (Lija), "Balzan" (Balzan), "Valletta" (Valletta), and "Sciberras" (Xebb ir-Ras Hill, on which Valletta was built). The village of Munxar, Gozo is characterised by the majority of its population having one of two surnames, either "Curmi" or "de Brincat". In Gozo, the surnames "Bajada" and "Farrugia" are also common.
Sicilian and Italian surnames are common due to the close vicinity to Malta. Sicilian Italians were the first to colonise the Maltese islands. Common examples include "Azzopardi", "Bonello", "Cauchi", "Farrugia", "Gauci", "Rizzo", "Schembri", "Tabone", "Vassallo", "Vella".
Common examples include "Depuis", "Montfort", "Monsenuier".
English surnames exist for a number of reasons, but mainly due to migration as well as Malta forming a part of the British Empire in the 19th century and most of the 20th. Common examples include "Bone", "Harding", "Atkins", "Mattocks", "Smith", "Jones", "Woods", "Turner".
Arabic surnames occur in part due to the early presence of the Arabs in Malta. Common examples include "Sammut", "Camilleri", "Zammit", and "Xuereb".
Common surnames of Spanish origin include "Abela", "Galdes", "Herrera", and "Guzman".
Surnames from foreign countries from the Middle Ages include German,
such as "von Brockdorff", "Hyzler", and "Schranz".
Many of the earliest Maltese surnames are Sicilian Greek, e.g. "Cilia", "Calleia", "Brincat", "Cauchi". Much less common are recent surnames from Greece; examples include "Dacoutros", and "Trakosopoulos"
The original Jewish community of Malta and Gozo has left no trace of their presence on the islands since they were expelled in January 1493.
In line with the practice in other Christian, European states, women generally assume their husband's surname after legal marriage, and this is passed on to any children the couple may bear. Some women opt to retain their old name, for professional/personal reasons, or combine their surname with that of their husband.
Mongolia.
Mongolians do not use surnames in the way that most Westerners, Chinese or Japanese do. Since the socialist period, patronymics – then called "ovog", now called "etsgiin ner" – are used instead of a surname. If the father's name is unknown, a matronymic is used. The patro- or matronymic is written before the given name. Therefore, if a man with given name Tsakhia has a son, and gives the son the name Elbegdorj, the son's full name is Tsakhia Elbegdorj. Very frequently, the patronymic is given in genitive case, i.e. Tsakhiagiin Elbegdorj. However, the patronymic is rather insignificant in everyday use and usually just given as an initial – Ts. Elbegdorj. People are normally just referred to and addressed by their given name (Elbegdorj "guai" – Mr. Elbegdorj), and if two people share a common given name, they are usually just kept apart by their initials, not by the full patronymic.
Since 2000, Mongolians have been officially using clan names – "ovog", the same word that had been used for the patronymics before – on their IDs. Many people chose the names of the ancient clans and tribes such Borjigin, Besud, Jalair, etc. Also many extended families chose the names of the native places of their ancestors. Some chose the names of their most ancient known ancestor. Some just decided to pass their own given names (or modifications of their given names) to their descendants as clan names. Some chose other attributes of their lives as surnames. Gürragchaa chose Sansar (Cosmos). Clan names precede the patronymics and given names, e.g. Besud Tsakhiagiin Elbegdorj. These clan names have a significance and are included in Mongolian passports.
Myanmar (Burma).
People from Myanmar or Burmese, have no family names. This, to some, is the only known Asian people having no family names at all. Some of those from Myanmar or Burma, who are familiar with European or American cultures, began to put to their younger generations with a family name – adopted from the notable ancestors. For example, Ms. Aung San Suu Kyi is the daughter of the late Father of Independence General Aung San; Hayma Ne Win, is the daughter of the famous actor Kawleikgyin Ne Win etc.
Pakistan.
Pakistani surnames are basically divided in three categories: Arab naming convention, tribal or caste names and ancestral names.
Family names indicating Arab ancestry, e.g. Shaikh, Siddiqui, Abbasi, Syed, Zaidi, Khawaja, Naqvi, Farooqi, Osmani, Alavi, Hassani, and Husseini.
People claiming Afghan ancestry include those with family names ځاځي dzādzi Durrani, Gardezi, Suri, Yousafzai, Afridi, Mullagori, Mohmand, Khattak, Wazir, Mehsud, Niazi.
Family names indicating Turkish heritage include Mughal,(cheema) Baig or Beg, Pasha, Barlas, and Seljuki.
People claiming Indian ancestry include those with family names Barelwi, Lakhnavi, Delhvi, Bilgrami and Rajput.
People claiming Iranian ancestry include those with family names Agha, Bukhari, Firdausi, Ghazali, Gilani, Hamadani, Isfahani, Kashani, Kermani, Khorasani, Farooqui, Mir, Mirza, Montazeri, Nishapuri, Noorani, Kayani, Qizilbash, Saadi, Sabzvari, Shirazi, Sistani, Suhrawardi, Yazdani, Zahedi, and Zand.
Tribal names include Abro Afaqi, Afridi, Khogyani(Khakwani), Amini, Ashrafkhel, Awan, Bajwa, Baloch, Barakzai, Baranzai, Bhatti, Bhutto, Ranjha, Bijarani, Bizenjo, Brohi, Khetran, Bugti, Butt, Detho, Farooqui, Gabol, Ghaznavi, Ghilzai, Gichki, Gujjar, Jakhrani, Jamali, Jamote, Janjua, Jatoi, Jutt Joyo, Junejo, Karmazkhel, Kayani, Khar, Khattak, Khuhro, Lakhani, Leghari, Lodhi, Magsi, Malik, Mandokhel, Mayo, Marwat, Mengal, Mughal, Palijo, Paracha, Panhwar, Phul, Popalzai, Qureshi & qusmani, Rabbani, Raisani, Rakhshani, Sahi, Swati, Soomro, Sulaimankhel, Talpur, Talwar, Thebo, Yousafzai, and Zamani.
Family names indicating Turkish/ Kurd ancestry, Dogar .
In Pakistan, the official paperwork format regarding personal identity is as follows:
So and so, son of so and so, of such and such tribe or clan and religion and resident of such and such place. For example, Amir Khan s/o Fakeer Khan, tribe Mughal Kayani or Chauhan Rajput, Follower of religion Islam, resident of Village Anywhere, Tehsil Anywhere, District.
A large number of Muslim Rajputs have retained their surnames such as Chauhan, Rathore, Parmar, Janjua, Bargujar, etc.
The Philippines.
Until the middle of the 19th century, there was no standardization of surnames in the Philippines. There were native Filipinos without surnames, others whose surnames deliberately did not match that of their families, as well as those who took certain surnames simply because they had a certain prestige, usually ones dealing with the Roman Catholic religion, such as de los Santos and de la Cruz.
In 1849, Governor-general Narciso Clavería y Zaldúa decreed an end to these arbitrary practices, the result of which was the Catálogo Alfabético de Apellidos ("Alphabetical Inventory of Surnames"). The book contained many words coming from Spanish and the Philippine languages such as Tagalog and many Basque surnames, such as Zuloaga or Aguirre.
In practice, the application of this decree varied from municipality to municipality. Some municipalities received only surnames starting with a particular letter. For example, the majority of residents of the island of Banton in the province of Romblon have surnames starting with F such as Fabicon, Fallarme, Fadrilan, and Ferran. Thus, although perhaps a majority of Filipinos have Spanish surnames, such a surname does not indicate Spanish ancestry. In addition, most Filipinos currently do not use Spanish accented letters in their Spanish derived names. The lack of accents in Filipino Spanish has been attributed to the lack of accents on the predominantly American typewriters after the US gained control of the Philippines.
The vast majority of Filipinos follow a naming system in the American order, which is the reverse of the Spanish naming order. Children take the mother's surname as their middle name, followed by their father's as their surname; for example, a son of Juan de la Cruz and his wife Maria Agbayani may be David Agbayani de la Cruz. Women take the surnames of their husband upon marriage, and consequently lose their maiden middle names; so upon her marriage to David de la Cruz, the full name of Laura Yuchengco Macaraeg would become Laura Macaraeg de la Cruz. Note that their maiden last names automatically become their middle names upon marriage.
There are other sources for surnames. Many Filipinos also have Chinese-derived surnames, which in some cases could indicate Chinese ancestry. Many Hispanicised Chinese numerals and other Hispanicised Chinese words, however, were also among the surnames in the Catálogo Alfabético de Apellidos. For those whose surname may indicate Chinese ancestry, analysis of the surname may help to pinpoint when those ancestors arrived in the Philippines. A hispanicised Chinese surname such as Cojuangco suggests an 18th-century arrival while a Chinese surname such as Lim suggests a relatively recent immigration. Some Chinese surnames such as Tiu-Laurel are composed of the immigrant Chinese ancestor's surname as well as the name of that ancestor's godparent on receiving Christian baptism.
In the predominantly Muslim areas of the southern Philippines, adoption of surnames was influenced by connexions to that religion, its holy places, and prophets. As a result, surnames among Filipino Muslims are largely Arabic-based, and include such surnames as Hassan and Haradji.
There are also Filipinos who, to this day, have no surnames at all, particularly if they come from indigenous cultural communities.
Naming customs in the Philippines.
Prior to the establishment of the Philippines as a US territory during the earlier part of the 20th century, Filipinos usually followed Iberian naming customs. However, upon the promulgation of the Family Code of 1987, Filipinos formalized adopting the American system of using their surnames.
A common Filipino name will consist of the given name (mostly 2 given names are given), the initial letter of the mother's maiden name and finally the father's surname (i.e. Lucy Anne C. de Guzman). Also, women are allowed to retain their maiden name or use both her and her husband's surname, separated by a dash. This is common in feminist circles or when the woman holds a prominent office (e.g. Gloria Macapagal-Arroyo, Miriam Defensor Santiago). In more traditional circles, especially those who belong to the prominent families in the provinces, the custom of the woman being addressed as Mrs. Husband's Full Name is still common.
For widows, who chose to marry again, two norms are in existence. For those who were widowed before the Family Code, the full name of the woman remains while the surname of the deceased husband is attached. That is, Maria Andres, who was widowed by Ignacio Dimaculangan will have the name Maria Andres viuda de Dimaculangan. If she chooses to marry again, this name will still continue to exist while the surname of the new husband is attached. Thus, if Maria marries Rene de los Santos, her new name will be Maria Andres viuda de Dimaculangan de los Santos.
However, a new norm is also in existence. The woman may choose to use her husband's surname to be one of her middle names. Thus, Maria Andres viuda de Dimaculangan de los Santos may also be called Maria A.D. de los Santos.
Children will however automatically inherit their father's surname if they are considered legitimate. If the child is born out of wedlock, the mother will automatically pass her surname to the child, unless the father gives a written acknowledgment of paternity. The father may also choose to give the child both his parents' surnames if he wishes (that is Gustavo Paredes, whose parents are Eulogio Paredes and Juliana Angeles, while having Maria Solis as a wife, may name his child Kevin S. Angeles-Paredes.
In some Tagalog regions, the norm of giving patronyms, or in some cases matronyms, is also accepted. These names are of course not official, since family names in the Philippines are inherited. It is not uncommon to refer to someone as Juan anak ni Pablo (John, the son of Paul) or Juan apo ni Teofilo (John, the grandson of Theophilus).
Poland.
In Poland and most of the former Polish–Lithuanian Commonwealth, surnames first appeared during the late Middle Ages. They initially denoted the differences between various people living in the same town or village and bearing the same name. The conventions were similar to those of English surnames, using occupations, patronymic descent, geographic origins, or personal characteristics. Thus, early surnames indicating occupation include "Karczmarz" ("innkeeper"), "Kowal" ("blacksmith"), "Złotnik" ("gold smith") and "Bednarczyk" ("young cooper"), while those indicating patronymic descent include "Szczepaniak" ("Son of "Szczepan"), "Józefowicz" ("Son of "Józef"), and "Kaźmirkiewicz" ("Son of "Kazimierz""). Similarly, early surnames like "Mazur" ("the one from Mazury") indicated geographic origin, while ones like "Nowak" ("the new one"), "Biały" ("the pale one"), and "Wielgus" ("the big one") indicated personal characteristics.
In the early 16th century, ( the Polish Renaissance), toponymic names became common, especially among the nobility. Initially, the surnames were in a form of "name "z" ("de", "of") ". Later, most surnames were changed to adjective forms, e.g. "Jakub Wiślicki" ("James of Wiślica") and "Zbigniew Oleśnicki" (""Zbigniew" of Oleśnica"), with masculine suffixes "-ski", "-cki", "-dzki" and "-icz" or respective feminine suffixes "-ska", "-cka", "-dzka" and "-icz" on the east of Polish–Lithuanian Commonwealth. Names formed this way are adjectives grammatically, and therefore change their form depending on sex; for example, "Jan Kowalski" and "Maria Kowalska" collectively use the plural "Kowalscy".
Names with masculine suffixes "-ski", "-cki", and "-dzki", and corresponding feminine suffixes "-ska", "-cka", and "-dzka" became associated with noble origin. Many people from lower classes successively changed their surnames to fit this pattern. This produced many "Kowalski"s, "Bednarski"s, "Kaczmarski"s and so on. Today, although most Polish speakers do not know about noble associations of "-ski", "-cki", "-dzki" and "-icz" endings, such names still somehow sound better to them.
A separate class of surnames derive from the names of noble clans. These are used either as separate names or the first part of a double-barrelled name. Thus, persons named "Jan Nieczuja" and "Krzysztof Nieczuja-Machocki" might be related. Similarly, after World War I and World War II, many members of Polish underground organizations adopted their war-time pseudonyms as the first part of their surnames. "Edward Rydz" thus became Marshal of Poland "Edward Śmigły-Rydz" and "Zdzisław Jeziorański" became "Jan Nowak-Jeziorański".
Romania.
In Romania, like in most of Europe, a child inherits his father's family name, and a wife takes her husband's last name. There are, however, exceptions.
Until the 19th century, the names were primarily of the form "name name name". The few exceptions are usually famous people or the nobility (boyars). The name reform introduced around 1850 had the names changed to a western style, most likely imported from France, consisting of a given name followed by a family name.
As such, the name is called "prenume" (French "prénom"), while the family name is called "nume" or, when otherwise ambiguous, "nume de familie" ("family name"). Although not mandatory, middle names are common.
Historically, when the family name reform was introduced in the mid-19th century, the default was to use a patronym, or a matronym when the father was dead or unknown. The typical derivation was to append the suffix "-escu" to the father's name, e.g. "Anghelescu" (""Anghel's" child") and "Petrescu" (""Petre's" child"). (The "-escu" seems to come from Latin "-iscum", thus being cognate with Italian "-esco" and French "-esque".) The other common derivation was to append the suffix "-eanu" to the name of the place of origin, especially when one came from a different region, e.g. "Munteanu" ("from the mountains") and "Moldoveanu" ("from "Moldova""). These uniquely Romanian suffixes strongly identify ancestral nationality.
There are also descriptive family names derived from occupations, nicknames, and events, e.g. "Botezatu" ("baptised"), "Barbu" ("bushy bearded"), "Prodan" ("foster"), "Bălan" ("blond"), "Fieraru" ("smith"), "Croitoru" ("tailor"), "Păcuraru" ("shepherd").
Romanian family names remain the same regardless of the sex of the person.
Although given names appear before family names in most Romanian contexts, official documents invert the order, ostensibly for filing purposes. Correspondingly, Romanians occasionally introduce themselves with their family names first, e.g. a student signing a test paper in school.
Romanians bearing names of non-Romanian origin often adopt Romanianised versions of their ancestral surnames, such as "Jurovschi" for Polish "Żurowski", which preserves the original pronunciation of the surname through transliteration. In some cases, these changes were mandated by the state.
Russia.
A full Russian name consists of personal (given) name, patronymic, and family name (surname).
Most Russian family names originated from patronymics, that is, father's name usually formed by adding the adjective suffix "-ov(a)" or "-ev(a)". Contemporary patronymics, however, have a substantive suffix "-ich" for masculine and the adjective suffix "-na" for feminine.
For example, the proverbial triad of most common Russian surnames follows:
Feminine forms of these surnames have the ending "-a":
Such a pattern of name formation is not unique to Russia or even to the Eastern and Southern Slavs in general; quite common are also names derived from professions, places of origin, and personal characteristics, with various suffixes (e.g. "-in(a)" and "-sky (-skaya)").
Professions:
Places of origin:
Personal characteristics:
A considerable number of "artificial" names exists, for example, those given to seminary graduates; such names were based on Great Feasts of the Orthodox Church or Christian virtues.
Great Orthodox Feasts:
Christian virtues:
Many freed serfs were given surnames after those of their former owners. For example, a serf of the Demidov family might be named "Demidovsky", which translates roughly as "belonging to Demidov" or "one of Demidov's bunch".
Grammatically, Russian family names follow the same rules as other nouns or adjectives (names ending with "-oy", "-aya" are grammatically adjectives), with exceptions: some names do not change in different cases and have the same form in both genders (for example, "Sedykh", "Lata").
Sweden.
In Scandinavia family names often, but certainly not always, originate from a patronymic. Later on, people from the Scandinavian middle classes, particularly artisans and town dwellers, adopted surnames in a similar fashion to that of the gentry. Family names joining two elements from nature such as the Swedish "Bergman" ("mountain man"), "Holmberg" ("island mountain"), "Lindgren" ("linden branch"), "Sandström" ("sand stream") and "Åkerlund" ("field grove") were quite frequent and remain common today.
Turkey.
In Turkey, following the Surname Law imposed in 1934 in the context of Atatürk's Reforms, every family living in Turkey was given a family name. The surname was generally selected by the elderly people of the family and could be any Turkish word (or a permitted word for families belonging to official minority groups).
Some of the most common family names in Turkey are "Yılmaz" ('undaunted'), "Doğan" ('falcon'), "Şahin" ('hawk'), "Yıldırım" ('thunderbolt'), "Şimşek" ('lightning'), "Öztürk" ('purely Turkish').
Patronymic surnames do not necessarily refer to ancestry, or in most cases cannot be traced back historically. The most usual Turkish patronymic suffix is "–oğlu"; "–ov(a)", "–yev(a)" and "–zade" also occur in the surnames of Azeri or other Turkic descendants.
Official minorities like Armenians, Greeks, and Jews have surnames in their own mother languages.
The Armenian families living in Turkey usually have Armenian surnames and generally have the suffix "–yan," "–ian," or, using Turkish spelling, "-can.". Greek descendants usually have Greek surnames which might have Greek suffixes like "–ou, –aki(s), –poulos/poulou, –idis/idou, –iadis/iadou" or prefixes like "papa–".
The Sephardic Jews who were expelled from Spain and settled in Turkey in 1492 have both Jewish/Hebrew surnames, and Spanish surnames, usually indicating their native regions, cities or villages back in Spain, like "De Leon" or "Toledano".
However these minorities increasingly tend to "Turkicize" their surnames or replace their original surnames with Turkish surnames altogether to avoid being recognized and discriminated against.
By region.
Regions of the Sinosphere.
In modern Chinese, Japanese, Korean, and Vietnamese, the family name is placed before the given names, although this order may not be observed in translation. Generally speaking, Chinese, Korean, and Vietnamese names do "not" alter their order in English (Mao Zedong, Kim Jong-il, Ho Chi Minh) and Japanese names do (Kenzaburō Ōe). However, numerous exceptions exist, particularly for people born in English-speaking countries such as Yo-Yo Ma. This is sometimes systematized: in all Olympic events, the athletes of the People's Republic of China list their names in the Chinese ordering, while Chinese athletes representing other countries, such as the USA, use the Western ordering. (In Vietnam, the system is further complicated by the cultural tradition of addressing people by their given name, usually with an honorific. For example, Phan Văn Khải is "properly" addressed as Mr. Khải, even though Phan is his family name.)
Chinese family names have many types of origins, some claiming dates as early as the legendary Yellow Emperor (2nd millennium BC):
In history, some changed their surnames due to a naming taboo (from Zhuang 莊 to Yan 嚴 during the era of Liu Zhuang 劉莊) or as an award by the Emperor (Li was often to senior officers during Tang dynasty).
In modern times, some Chinese adopt an English name in addition to their native given names: e.g., adopted the English name Martin Lee. Particularly in Hong Kong and Singapore, the convention is to write both names together: Martin Lee Chu-ming. Owing to the confusion this can cause, a further convention is sometimes observed of capitalizing the surname: Martin L Chu-ming. Sometimes, however, the Chinese given name is forced into the Western system as a middle name ("Martin Chu-ming Lee"); less often, the English given name is forced into the Chinese system ("Lee Chu-ming Martin").
In Japan, the civil law forces a common surname for every married couple, unless in a case of international marriage. In most cases, women surrender their surnames upon marriage, and use the surnames of their husbands. However, a convention that a man uses his wife's family name if the wife is an only child is sometimes observed. A similar tradition called "ru zhui" (入贅) is common among Chinese when the bride's family is wealthy and has no son but wants the heir to pass on their assets under the same family name. The Chinese character "zhui" (贅) carries a money radical (貝), which implies that this tradition was originally based on financial reasons. All their offspring carry the mother's family name. If the groom is the first born with an obligation to carry his own ancestor's name, a compromise may be reached in that the first male child carries the mother's family name while subsequent offspring carry the father's family name. The tradition is still in use in many Chinese communities outside mainland China, but largely disused in China because of social changes from communism. Due to the economic reform in the past decade, accumulation and inheritance of personal wealth made a come back to the Chinese society. It is unknown if this financially motivated tradition would also come back to mainland China.
In Chinese, Korean, and Singaporean cultures, women keep their own surnames, while the family as a whole is referred to by the surnames of the husbands.
In Hong Kong, some women would be known to the public with the surnames of their husbands preceding their own surnames, such as Anson Chan Fang On Sang. Anson is an English given name, On Sang is the given name in Chinese, Chan is the surname of Anson's husband, and Fang is her own surname. A name change on legal documents is not necessary. In Hong Kong's English publications, her family names would have been presented in small cap letters to resolve ambiguity, e.g. Anson CHAN FANG On Sang in full or simply Anson Chan in short form.
In Macau, some people have their names in Portuguese spelt with some Portuguese style, such as "Carlos do Rosario Tchiang".
Chinese women in Canada, especially Hongkongers in Toronto, would preserve their maiden names before the surnames of their husbands when written in English, for instance Rosa Chan Leung, where Chan is the maiden name, and Leung is the surname of the husband.
In Chinese, Korean, and Vietnamese, surnames are predominantly monosyllabic (written with one character), though a small number of common disyllabic (or written with two characters) surnames exists (e.g. the Chinese name "Ouyang", the Korean name "Jegal" and the Vietnamese name "Phan-Tran").
Many Chinese, Korean, and Vietnamese surnames are of the same origin, but simply pronounced differently and even transliterated differently overseas in Western nations. For example, the common Chinese surnames Chen, Chan, Chin, Cheng and Tan, the Korean surname Jin, as well as the Vietnamese surname Trần are often all the same exact character 陳. The common Korean surname Kim is also the common Chinese surname Jin, and written 金. The common Mandarin surnames Lin or Lim (林) is also one and the same as the common Cantonese or Vietnamese surname "Lam" and Korean family name Lim (written/pronounced as Im in South Korea). Interestingly, there are people with the surname of Hayashi (林) in Japan too. The common Chinese surname 李, translated to English as Lee, is, in Chinese, the same character but transliterated as Li according to pinyin convention. Lee is also a common surname of Koreans, and the character is identical.
Scandinavia.
In Scandinavia, family names often, but certainly not always, originate from a patronymic. In Denmark and Norway, the corresponding ending is "-sen", as in "Karlsen". Names ending with "dotter/datter" (daughter), such as "Olofsdotter", are rare but occurring, and only apply to females. Today, the patronymic names are passed on similarly to family names in other Western countries, and a person's father does not have to be called Karl if he or she has the surname Karlsson. However, in 2006 Denmark reinstated patronymic and matronymic surnames as an option. Thus, parents Karl Larsen and Anna Hansen can name a son Karlssøn or Annasøn and a daughter Karlsdatter or Annasdatter.
Before the 19th century there was the same system in Scandinavia as in Iceland today. Noble families, however, as a rule adopted a family name, which could refer to a presumed or real forefather (e.g. Earl Birger Magnusson "Folkunge" ) or to the family's coat of arms (e.g. King Gustav Eriksson "Vasa"). In many surviving family noble names, such as "Silfversparre" ("silver chevron"; in modern spelling, "Silver-") or "Stiernhielm" ("star-helmet"; in modernized spelling, "stjärnhjälm"), the spelling is obsolete, but since it applies to a name, remains unchanged. (Some names from relatively modern times also use archaic or otherwise aberrant spelling as a stylistic trait; e.g. "-quist" instead of standard "-kvist" "twig" or "-grén" instead of standard "-gren", "branch".)
Later on, people from the Scandinavian middle classes, particularly artisans and town dwellers, adopted names in a similar fashion to that of the nobility. Family names joining two elements from nature such as the Swedish "Bergman" ("mountain man"), "Holmberg" ("island mountain"), "Lindgren" ("linden branch"), "Sandström" ("sand stream") and "Åkerlund" ("field meadow") were quite frequent and remain common today. The same is true for similar Norwegian and Danish names.
Another common practice was to adopt one's place of origin as a middle or surname.
Even more important a driver of change was the need, for administrative purposes, to develop a system under which each individual had a "stable" name from birth to death. In the old days, people would be known by their name, patronymic and the farm they lived at. This last element would change if a person got a new job, bought a new farm, or otherwise came to live somewhere else. (This is part of the origin, in this part of the world, of the custom of women changing their names upon marriage. Originally it indicated, basically, a change of address, and from older times, there are numerous examples of men doing the same thing). The many patronymic names may derive from the fact that people who moved from the country to the cities, also gave up the name of the farm they came from. As a worker, you passed by your father's name, and this name passed on to the next generation as a family name. Einar Gerhardsen, the Norwegian prime minister, used a true patronym, as his father was named Gerhard Olsen (Gerhard, the son of Ola). Gerhardsen passed his own patronym on to his children as a family name. This has been common in many working-class families. The tradition of keeping the farm name as a family name got stronger during the first half of the 20th century in Norway.
These names often indicated the place of residence of the family. For this reason, Denmark and Norway have a very high incidence of last names derived from those of farms, many signified by the suffixes like "-bø", "-rud", "-heim/-um", "-land" or "-set" (these being examples from Norway). In Denmark, the most common suffix is "-gaard" — the modern spelling is "gård" in Danish and can be either "gård" or "gard" in Norwegian, but as in Sweden, archaic spelling persists in surnames. The most well-known example of this kind of surname is probably "Kierkegaard" (combined by the words "kirke/kierke" (= church) and "gaard" (= farm) meaning "the farm located by the Church". It is, however, a common misunderstanding that the name relates to its direct translation: churchyard/cemetery), but many others could be cited. It should also be noted that, since the names in question are derived from the original owners' domiciles, the possession of this kind of name is no longer an indicator of affinity with others who bear it.
In many cases, names were taken from the nature around them. In Norway, for instance, there is an abundance of surnames based on coastal geography, with suffixes like "-strand", "-øy", "-holm", "-vik", "-fjord" or "-nes". Like the names derived from farms, most of these family names reflected the family's place of residence at the time the family name was "fixed", however. A family name such as Swedish "Dahlgren" is derived from "dahl" meaning valley and "gren" meaning branch; or similarly "Upvall" meaning "upper-valley"; It depends on the Scandinavian country, language, and dialect.
Slavic surname formation.
Most Slavic surnames have suffixes which are found in varying degrees over the different nations. Some surnames are not formed in this way, this includes names of non-Slavic origin.
Note: the following list does not take regional spelling variations into account.
Use of feminine name form.
Slavic countries are noted for having masculine and feminine versions for many (but not all) of their names, as already presented in the list above. In most countries the use of a feminine form is obligatory in official documents as well as in other communication, except for foreigners. In some countries only the male form figures in official use (Bosnia and Herzegovina, Croatia, Montenegro, Serbia, Slovenia), but in communication (speech, print) a feminine form is often used.
In Slovenia last name of a female is the same as the male form in official use (identification documents, letters). In speech and descriptive writing (literature, newspapers) a female form of the last name is regularly used.
Feminine forms of names without suffix.
If the name has no suffix, it may or may not have a feminine version. Sometimes it has the ending changed (such as the addition of "-a"). In the Czech Republic and Slovakia, suffixless names, such as those of German origin, are feminized by adding "-ová" (for example, "Schusterová").
Czech Republic and Slovakia.
Names of Czech people consist of given name ("křestní jméno") and surname ("příjmení"). Usage of the second or middle name is not common. Feminine names are usually derived from masculine ones by a suffix "-ová" ("Nováková") or "-á" for names being originally adjectives ("Veselá"), sometimes with a little change of original name's ending ("Sedláčková" from "Sedláček" or "Svobodová" from "Svoboda"). Women usually change their family names when they get married. The family names are usually nouns ("Svoboda", "Král", "Růžička", "Dvořák", "Beneš"), adjectives ("Novotný", "Černý", "Veselý") or past participles of verbs ("Pospíšil"). There are also a couple of names with more complicated origin which are actually complete sentences ("Skočdopole", "Hrejsemnou" or "Vítámvás"). The most common Czech family name is "Novák" / "Nováková".
In addition, many Czechs and some Slovaks have German surnames due to mixing between the ethnic groups over the past thousand years. Deriving women's names from German and other foreign names is often problematic since foreign names do not suit Czech language rules, although most commonly "-ová" is simply added ("Schmidtová"; umlauts are often, but not always, dropped, e.g. "Müllerová"), or the German name is respelled with Czech spelling ("Šmitová"). Hungarian names, which can be found fairly commonly among Slovaks, can also be either left unchanged (Hungarian "Nagy", fem. "Nagyová") or respelled according to Czech/Slovak orthography (masc. "Naď", fem. "Naďová").
South Slavs.
Endings in -ić and -ič.
Surnames of some South Slavic groups such as Serbs, Croats, Montenegrins, and Bosniaks traditionally end with the suffixes "-ić" and "-vić" (often transliterated to English and other western languages as "ic", "ich", "vic" or "vich". The v is added in the case of a name to which "-ić" is appended would otherwise end with a vowel, to avoid double vowels with the "i" in "-ić".) These are a diminutive indicating descent i.e. "son of." In some cases the family name was derived from a profession (e.g. blacksmith – "Kovač" → "Kovačević").
An analogous ending is also common in Slovenia. As the Slovenian language does not have the softer consonant "ć", in Slovene words and names only "č" is used. So that that people from the former Yugoslavia need not change their names, in official documents "ć" is also allowed (as well as "Đ / đ"). Thus, one may have two surname variants, e.g.: Božič, Tomšič (Slovenian origin or assimilated) and Božić, Tomšić (roots from the Serbo-Croat language continuum area). Slovene names ending in -ič do not necessarily have a patrimonial origin.
In general family names in all of these countries follow this pattern with some family names being typically Serbian, some typically Croat and yet others being common throughout the whole linguistic region.
Children usually inherit their fathers' family name. In an older naming convention which was common in Serbia up until the mid-19th century, a person's name would consist of three distinct parts: the person's given name, the patronymic derived from the father's personal name, and the family name, as seen, for example, in the name of the language reformer Vuk Stefanović Karadžić.
Official family names do not have distinct male or female forms, except in Macedonia, though a somewhat archaic unofficial form of adding suffixes to family names to form female form persists, with "-eva", implying "daughter of" or "female descendant of" or "-ka", implying "wife of" or "married to". In Slovenia the feminine form of a surname ("-eva" or "-ova") is regularly used in non-official communication (speech, print), but not for official IDs or other legal documents.
Bosniak Muslim names follow the same formation pattern but are usually derived from proper names of Islamic origin, often combining archaic Islamic or feudal Turkish titles i.e. Mulaomerović, Šabanović, Hadžihafizbegović, etc. Also related to Islamic influence is the prefix "Hadži-" found in some family names. Regardless of religion, this prefix was derived from the honorary title which a distinguished ancestor earned by making a pilgrimage to either Christian or Islamic holy places; Hadžibegić, being a Bosniak Muslim example, and Hadžiantić an Orthodox Christian one.
In Croatia where tribal affiliations persisted longer, Lika, Herzegovina etc., originally a family name, came to signify practically all people living in one area, clan land or holding of the nobles. The Šubić family owned land around the Zrin River in the Central Croatian region of Banovina. The surname became Šubić Zrinski, the most famous being Nikola Šubić Zrinski.
In Montenegro and Herzegovina, family names came to signify all people living within one clan or bratstvo. As there exists a strong tradition of inheriting personal names from grandparents to grandchildren, an additional patronymic usually using suffix "-ov" had to be introduced to make distinctions between two persons bearing the same personal name and the same family name and living within same area. A noted example is Marko Miljanov Popović, i.e. Marko, son of Miljan, from Popović family.
Due to discriminatory laws in the Austro-Hungarian Empire, some Serb families of Vojvodina discarded the suffix "-ić" in an attempt to mask their ethnicity and avoid heavy taxation.
The prefix "Pop-" in Serbian names indicates descent from a priest, for example Gordana Pop Lazić, i.e. descendent of Pop Laza.
Some Serbian family names include prefixes of Turkish origin, such as "Uzun-" meaning tall, or "Kara-", black. Such names were derived from nicknames of family ancestors. A famous example is Karađorđević, descendents of Đorđe Petrović, known as Karađorđe or Black Đorđe.
Endings -ov and -ski.
Among the Bulgarians, another South Slavic people, the typical surname suffix is "-ov" (Ivanov, Kovachev), although other popular suffixes also exist.
In the Republic of Macedonia, the most popular suffix today is "-ski".
Slovenian surnames.
Slovenes have a great variety of surnames, most of them differentiated according to region. Surnames ending in -ič are less frequent than among Croats and Serbs. There are typically Slovenian surnames ending in -ič, such as Blažič, Stanič, Marušič. Many Slovenian surnames, especially in the Slovenian Littoral, end in -čič (Gregorčič, Kocijančič, Miklavčič, etc.), which is uncommon for other South Slavic peoples (except the neighboring Croats, e.g. Kovačić, Jelačić, Kranjčić, etc.). On the other hand, surname endings in -ski and -ov are rare, and are usually of foreign (mostly Czech) origin. One of the most typical Slovene surname endings is -nik (Rupnik, Pučnik, Plečnik, Pogačnik, Podobnik) and other used surname endings are -lin (Pavlin, Mehlin, Ahlin, Ferlin), -ar (Mlakar, Ravnikar, Smrekar Tisnikar) and -lj (Rugelj, Pucelj, Bagatelj, Bricelj). Many Slovenian surnames are linked to Medieval rural settlement patterns. Surnames like Novak (literally, "the new one") or Hribar (from "hrib", hill) were given to the peasants settled in newly established farms, usually in high mountains. Peasant families were also named according to the owner of the land which they cultivated: thus, the surname Kralj (King) or Cesar (Emperor) was given to those working on royal estates, Škof (Bishop) or Vidmar to those working on ecclesiastical lands, etc. Many Slovenian surnames are named after animals (Medved – bear, Volk, Vovk or Vouk – wolf, Golob – pigeon, Lisjak – fox, Orel – eagle, Zajc or Zajec – rabbit, etc.). Many are named after neighbouring peoples: Horvat, Hrovat, or Hrovatin (Croat), Furlan (Friulian), Nemec (German), Lah (Italian), Vogrin, Vogrič or Vogrinčič (Hungarian), Vošnjak (Bosnian), Čeh (Czech), Turk (Turk), or different Slovene regions: Kranjc, Kranjec or Krajnc (from Carniola), Kraševec (from the Kras), Korošec (from Carinthia), Kočevar or Hočevar (from the Gottschee county).
Use of feminine surnames in Slovenia.
In Slovenia last name of a female is the same as the male form in official use (identification documents, letters). In speech and descriptive writing (literature, newspapers) a female form of the last name is regularly used. Examples: Novak (m.) & Novakova (f.), Kralj (m.) & Kraljeva (f.), Mali (m.) ˛& Malijeva (f.) (this is different from the Czech principle, though forexample "mali" in Slovenian also means "small" the last name is not changed grammatically to "mala".) So we have Maja Novak on the ID card and Maja Novakova in communication; Tjaša Mali and Tjaša Malijeva; respectively. Diminutive forms of last names for females are also available: Novakovka, Kraljevka. As for pronunciation, in Slovenian there is some leeway regarding accentuation. Depending on the region or local usage, you may have either Nóvak & Nóvakova or, more frequently, Novák & Novákova. Accent marks are normally not used.
Ukraine and Belarus.
Ukrainian and Belarusian names evolved from the same Old East Slavic and Ruthenian language (western Rus’) origins. Ukrainian and Belarusian names share many characteristics with family names from other Slavic cultures. Most prominent are the shared root words and suffixes. For example, the root "koval" (blacksmith) compares to the Polish "kowal", and the root "bab" (woman) is shared with Polish, Slovakian, and Czech. The suffix "-vych" (son of) corresponds to the South Slavic "-vic", the Russian "-vich", and the Polish "-wicz", while "-sky", "-ski", and "-ska" are shared with both Polish and Russian, and "-ak" with Polish.
However some suffixes are more uniquely characteristic to Ukrainian and Belarusian names, especially: "-chuk" (Western Ukraine), "-enko" (all other Ukraine) (both son of), "-ko" (little "-ka" (little [feminine), "-shyn", and "-uk". See, for example, Mihalko, Ukrainian Presidents Leonid Kravchuk, and Viktor Yushchenko, Belarusian President Alexander Lukashenko, or former Soviet diplomat Andrei Gromyko. Such Ukrainian and Belarusian names can also be found in Russia, Poland, or even other Slavic countries (e.g. Croatian general Zvonimir Červenko), but are due to importation by Ukrainian, Belarusian, or Rusyn ancestors.
Burundi and Rwanda.
In Burundi and Rwanda, most, if not all surnames have God in it, for example Hakizimana (meaning God cures), Nshimirimana (I thank God) or Havyarimana/Habyarimana (God gives birth). But not all surnames end with the suffix -imana. Irakoze is one of these (technically meaning Thank God, though it is hard to translate it correctly in English or probably any other language). Surnames are often different among immediate family members, as parents frequently choose unique surnames for each child, and women keep their maiden names when married. Surnames are placed before given names and frequently written in capital letters, e.g. HAKIZIMANA Jacques.
Horn of Africa.
The patronymic custom in most of the Horn of Africa gives children the father's first name as their surname. The family then gives the child its first name. Middle names are unknown. So, for example, a person's name might be "Bereket Mekonen ". In this case, "Bereket " is the first name and "Mekonen" is the surname, and also the first name of the father.
The paternal grandfather's name is often used if there is a requirement to identify a person further, for example, in school registration. Also, different cultures and tribes use the father's or grandfather's given name as the family's name. For example, some Oromos use Warra Ali to mean families of Ali, where Ali, is either the householder, a father or grandfather.
In Ethiopia, the customs surrounding the bestowal and use of family names is as varied and complex as the cultures to be found there. There are so many cultures, nations or tribes, that currently there can be no one formula whereby to demonstrate a clear pattern of Ethiopian family names. In general, however, Ethiopians use their father's name as a surname in most instances where identification is necessary, sometimes employing both father's and grandfather's names together where exigency dictates.
Many people in Eritrea have Italian surnames, but all of these are owned by Eritreans of Italian descent.
By ethnic group.
Jewish.
Jewish names have historically varied, encompassing throughout the centuries several different traditions. The most usual last name for those of the priest tribe is "Cohen"/"Kahen"/"Kogan"/"Kohen"/"Katz" (a Hebrew acronym of Kohen Tzedek, or righteous Kohen) and for those of the Levites, "Levi"/"Levine". Those who came from Europe usually have "Rosen"("rose"), "Spiel", "Gold", and other German words as their names' prefixes, and "man", "wyn"/"wein"("wine"), "berg"("mountain"), and other German words as their names' suffixes. Most Sephardic Jews adopted Arabic names, like "Azizi" ("you're love"), "Hassan" or added words to their original names, like "Kohenzadeh" ("[she bore a Kohen"). Names like "Johnson" and "Peterson" may be used in Jewish tradition as they too used the father's name as identification. So "Johnson" in Hebrew is "Ben Yochanon", meaning "Yochanon (John)'s son". Many Yemenite Jews' family names are consisting of the place in which their ancestors have come to Yemen (like Sana'a) and an "i" in the end (like the family name "San'ani"), indicating belonging to the place they have originated from.
Assyrian.
The Assyrians (a.k.a. Chaldo-Assyrian) are a distinct ethnic group, descendant largely from the population of ancient Assyria, indigenous to Mesopotamia with deep and long roots in the Middle East, mainly present-day Iraq, northwest Iran, northeast Syria and southeast Turkey.
Surnames come from the Akkadian influenced Eastern Aramaic dialects of the Assyrian (Chaldo-Assyrian) people. Some surnames are connected to East Syrian Rite Christianity, the religion Assyrians currently follow and have followed since the 1st Century AD, with others being of distinctly ancient Assyrian/Mesopotamian origin.
Common surnames include: "Aboona", "Abraham", "Abro", "Agajan", "Agassi", "Aghase", "Akkad", "Akbalit/Akbalut", "Alamasha", "Alawerdy", "Aldawid", "Amo Baba", "Amu", "Antar", "Aprim", "Apshu", "Afarcan", "Arad", "Ashai", "Ashouri", "Ashurian", "Ashur", "Awdishu", "Awikam", "Awishalim", "Awitor", "Awia", "Awrohum", "Aziz", "Azzo", "Baba", "Bacchus", "Badel", "Barkha/Barkho", "Brikha", "Bronit", "Balou", "Barkoo", "Benassi", "Benyamin", "Bidavid", "Bidawid", "Bishu", "Cabani", "Dadashu/Dadasho", "Darmu", "Dinkha", "Daoud", "Dayan/Daian", "Disho", "Duman", "Elia", "Elias", "Enwia", "Eshai", "Farhad", "Gorges/Georgis", "Gewargis", "Hadad/Adad", "Hamsho", "Hasso", "Harshu", "Hormis", "Hosanna", "Hurmis", "Ilshu", "Ilishu", "Ishmael", "Ishai", "Isaac", "Ishaq", "Iskhaq", "Iwassi", "Jabri", "Jelu", "Jendo", "Juna", "Kambar", "Karam", "Karoukian", "Kasri", "Khamo", "Khanbaba", "Khanisho/Khnanisu", "Khnaninia", "Khedroo", "Khoshanu", "Khoshaba", "Malech", "Malek", "Malka", "Malkai", "Malick", "Mamendo", "Matti", "Merza", "Mikhael/Mikhail", "Mnashi", "Nisan", "Nimrod", "Narsai", "Ninweh", "Nineveh", "Nessar", "Odah", "Odisha", "Odisho", "Oraham", "Oshana", "Qateneh", "Raaba", "Rabi", "Rafael", "Ramsin/Rumsin", "Rassam", "Rifkha", "Ronay", "Samo", "Sargis", "Sargon", "Sarkis", "Sarmas", "Sayad", "Semma", "Shabad", "Shamash/Shamasha", "Shamshi", "Sinharib", "Sharrukin", "Shimun", "Shamoon", "Shimon", "Shimonaya", "Shinu", "Shinai", "Sleman", "Shulman", "Sliwoo/Sliwa", "Tematheus", "Thoma", "Thomaya", "Tamraz", "Tiras", "Tiyareh/Tyareh", "Urshan", "Warda", "Warad", "Yacoub", "Yawalaha", "Yalda", "Yatrin", "Yetron", "Yelu", "Yoel", "Yohannan", "Yonan", "Yonadam" "Yoseph", "Yoshu", "Youkhana", "Younan", "Yousif", "Yukhannan", "Zakharia", "Zilkha", "Zimri".
Kurdish.
The majority of Kurds do not hold Kurdish names because the names have been banned in the countries they primarily live in (namely Iran, Turkey and Syria). Kurds in these respective countries tend to hold Turkish, Persian or Arabic names, in the majority of cases, forcefully appointed by the ruling governments. Others hold Arabic names as a result of the influence of Islam and Arab culture.
Kurds holding authentic Kurdish names are generally found in Diaspora or in Iraqi Kurdistan where Kurds are relatively free. Traditionally, Kurdish family names are inherited from the tribes of which the individual or families are members. However, some families inherit the names of the regions they are from.
Common affixes of authentic Kurdish names are "-î" and "-za" also "-a" and "-ê" by two surnames.<br>
e.g.:<br>
Name+1Surname+2Surname<br>
"Male:"
Baran of Mem of Alan
"Female:" 
Berfin of Sarah of Evin
<br>
there are also names with the word "Mal(a)" (of)
e.g.: 
Baran of House of Alan
Berfin of House of Evin
Some common Kurdish last names, which are also the names of their respective tribes, include Baradost, Barzani, Berwari, Berzinji, Chelki, Diri, Doski, Jaf, Mutki, Rami, Rekani, Rozaki, Sindi, and Tovi. Other names include Akreyi, Alan, Amedi, Botani, Hewrami, Mukri, and Serhati.
Traditionally, Kurdish women did not inherit a man's last name. Although still not in practice by many Kurds, this can be more commonly found today.
Tibet.
Tibetan people are often named at birth by the local Buddhist Lama or they may request a name from the Dalai Lama. They do not often use a family name though many have one. They may change their name throughout life if advised by a Buddhist Lama, for example if a different name removes obstacles. The Tibetans who enter monastic life take a name from their ordination Lama, which will be a combination of the Lama's name and a new name for them.
North Caucasian Adyghe family surnames.
In the case of Circassians, especially Adyges and Kabardians, hereditary surnames have been borne by people for thousands of years. All Circassian people belong to a Clan.
Most surnames of Adyge origin fall into six types:
"Shogen" comes from the Christian era, and "Yefendi" and "Mole" come from the Muslim era.
Circassian women, even when they marry, do not change their surnames. By keeping their surnames and passing it on to the next generation, children come to distinguish relatives from the maternal side and respect her family as well as those from their father's side.
On the other hand, children cannot marry someone who bears the same surname as they do, no matter how distantly related.
In the Circassian tradition, the formula for surnames is patterned to mean "daughter of ..."
Abkhaz families follow similar naming patterns reflecting the common roots of the Abkhazian, Adygean and Wubikh peoples.
Circassian family names cannot be derived from women's names or from the name of female ancestors.

</doc>
<doc id="10815" url="https://en.wikipedia.org/wiki?curid=10815" title="Franc">
Franc

The franc (₣) is the name of several currency units. The French franc was the former currency of France until the euro was adopted in 1999 (by law, 2002 de facto). The Swiss franc is a major world currency today due to the prominence of Swiss financial institutions. The name is said to derive from the Latin inscription "francorum rex" (Style of the French sovereign: "King of the Franks") used on early French coins and until the 18th century, or from the French "franc", meaning "free" (and "frank").
The countries that use francs include Switzerland, Liechtenstein, and most of Francophone Africa. Before the introduction of the euro, francs were also used in France, Belgium and Luxembourg, while Andorra and Monaco accepted the French franc as legal tender (Monegasque franc). The franc was also used within the French Empire's colonies, including Algeria and Cambodia. The franc is sometimes italianised or hispanicised as the "franco", for instance in Luccan franco.
One franc is typically divided into 100 centimes. The French franc symbol was an F with a line through it (₣) or, more frequently, only an F. For practical reasons, the banks and the financial markets used the abbreviation FF for the French franc in order to distinguish it from the Belgian franc (FB), the Luxembourgish franc (FL or FLux) etcetera (In the Luxembourgish language, the word for franc is "Frang", plural form "Frangen".)
Origins.
The franc was originally a French gold coin of 3.87 g minted in 1360 on the occasion of the release of King John II ("the good"), held by the English since his capture at the Battle of Poitiers four years earlier. It was equivalent to one "livre tournois" (Tours pound).
French franc.
The French franc was the name of a gold coin issued in France from 1360 until 1380, then a silver coin issued between 1575 and 1641. The franc finally became the national currency from 1795 until 1999 (franc coins and notes were legal tender until 2002). Though abolished as a legal coin by Louis XIII in 1641 in favor of the gold louis and silver écu, the term franc continued to be used in common parlance for the livre tournois. The franc was also minted for many of the former French colonies, such as Morocco, Algeria, French West Africa, and others. Today, after independence, many of these countries continue to use the franc as their standard denomination.
The value of the French franc was locked to the euro at 1 euro = 6.55957 FRF on 31 December 1998, and after the introduction of the euro notes and coins, ceased to be legal tender after 28 February 2002, although they were still exchangeable at banks until 19 February 2012.
CFA and CFP francs.
Fourteen African countries use the franc CFA (in west Africa, "Communauté financière africaine"; in equatorial Africa, "Coopération financière en Afrique centrale"), originally (1945) worth 1.7 French francs and then from 1948, 2 francs (from 1960: 0.02 new franc) but after January 1994 worth only 0.01 French franc. Therefore, from January 1999, 1 CFA franc is equivalent to €0.00152449.
A separate (franc CFP) circulates in France's Pacific territories, worth €0.0084 (formerly 0.055 French franc).
Comorian franc.
In 1981, The Comoros established an arrangement with the French government similar to that of the CFA franc. Originally, 50 Comorian francs were worth 1 French franc. In January 1994, the rate was changed to 75 Comorian francs to the French franc. Since 1999, the currency has been pegged to the euro.
Belgian franc and Luxembourgish franc.
The conquest of most of western Europe by Revolutionary and Napoleonic France led to the franc's wide circulation. Following independence from the Kingdom of the Netherlands, the new Kingdom of Belgium in 1832 adopted its own Belgian franc, equivalent to the French one, followed by Luxembourg adopting the Luxembourgish franc in 1848 and Switzerland in 1850. Newly unified Italy adopted the lira on a similar basis in 1862.
In 1865, France, Belgium, Switzerland and Italy created the Latin Monetary Union (to be joined by Spain and Greece in 1868): each would possess a national currency unit (franc, lira, peseta, drachma) worth 4.5 g of silver or of gold (fine), all freely exchangeable at a rate of 1:1. In the 1870s the gold value was made the fixed standard, a situation which was to continue until 1914.
In 1926 Belgium as well as France experienced depreciation and an abrupt collapse of confidence, leading to the introduction of a new gold currency for international transactions, the "belga" of 5 francs, and the country's withdrawal from the monetary union, which ceased to exist at the end of the year. The 1921 monetary union of Belgium and Luxembourg survived, however, forming the basis for full economic union in 1932.
Like the French franc, the Belgo-Luxemburgish franc ceased to exist on 1 January 1999, when it became fixed at 1 EUR = 40.3399 BEF/LUF, thus a franc was worth €0.024789. Old franc coins and notes lost their legal tender status on 28 February 2002.
1 Luxembourgish franc was equal to 1 Belgian franc. Belgian francs were legal tender inside Luxembourg, and Luxembourgish francs were legal tender in the whole of Belgium. (In reality, Luxembourgish francs were only accepted as means of payment by shops and businesses in the Belgian province of Luxembourg adjacent to the independent Grand Duchy of Luxembourg, this for historical reasons.)
The equivalent name of the Belgian franc in Dutch, Belgium's other official language, was "Belgische Frank". As mentioned before, in Luxembourg the franc was called "Frang" (plural "Frangen").
Swiss franc and Liechtenstein frank.
The Swiss franc (ISO code: CHF or 756), which appreciated significantly against the new European currency from April to September 2000, remains one of the world's strongest currencies, worth today around five-sixths of a euro. The Swiss franc is used in Switzerland and in Liechtenstein. Liechtenstein retains the ability to mint its own currency, the Liechtenstein frank, which it does from time to time for commemorative or emergency purposes.
The name of the country "Swiss Confederation" is found on some of the coins in Latin ("Confoederatio Helvetica"), as Switzerland has four official languages, all of which are used on the notes. The denomination is abbreviated "Fr." on the coins which is the abbreviation in all four languages.
Saar franc.
The Saar franc, linked at par to the French franc, was introduced in the Saar Protectorate in 1948. On 1 January 1957, the territory joined the Federal Republic of Germany, nevertheless, in its new member state of Saarland, the Saar franc continued to be the currency until 6 July 1959.
The name of the Saar franc in German, the main official language in the Protectorate, was "Franken". Coins displaying German inscriptions and the coat of arms of the Protectorate were circulated and used together with French francs. As banknotes, only French franc bills existed.
Countries that use the franc.
Countries currently using the franc.
Countries which formerly used the franc:
Collectivities which use the franc:

</doc>
<doc id="10819" url="https://en.wikipedia.org/wiki?curid=10819" title="Federal Reserve System">
Federal Reserve System

The Federal Reserve Systemalso known as the Federal Reserve or simply as the Fedis the central banking system of the United States. It was created on December 23, 1913, with the enactment of the Federal Reserve Act, largely in response to a series of financial panics, particularly a severe panic in 1907. Over time, the roles and responsibilities of the Federal Reserve System have expanded, and its structure has evolved. Events such as the Great Depression in the 1930s were major factors leading to changes in the system.
The U.S. Congress established three key objectives for monetary policy in the Federal Reserve Act: maximizing employment, stabilizing prices, and moderating long-term interest rates. The first two objectives are sometimes referred to as the Federal Reserve's dual mandate. Its duties have expanded over the years, and also include supervising and regulating banks, maintaining the stability of the financial system and providing financial services to depository institutions, the U.S. government, and foreign official institutions. The Fed conducts research into the economy and releases numerous publications, such as the Beige Book.
The Federal Reserve System's structure is composed of the presidentially appointed Board of Governors or Federal Reserve Board (FRB), partially presidentially appointed Federal Open Market Committee (FOMC), twelve regional Federal Reserve Banks located in major cities throughout the nation, numerous privately owned U.S. member banks, and various advisory councils. The federal government sets the salaries of the Board's seven governors. Nationally chartered commercial banks are required to hold stock in the Federal Reserve Bank of their region, which entitles them to elect some of their board members. The FOMC sets monetary policy and consists of all seven members of the Board of Governors and the twelve regional bank presidents, though only five bank presidents vote at any given time: the president of the New York Fed and four others who rotate through one-year terms. Thus, the Federal Reserve System has both private and public components to serve the interests of the public and private banks. The structure is considered unique among central banks. It is also unusual in that the United States Department of the Treasury, an entity outside of the central bank, creates the currency used. The Federal Reserve System considers itself "an independent central bank because its monetary policy decisions do not have to be approved by the President or anyone else in the executive or legislative branches of government, it does not receive funding appropriated by the Congress, and the terms of the members of the Board of Governors span multiple presidential and congressional terms."
The U.S. Government receives all the system's annual profits, after a statutory dividend of 6% on member banks' capital investment is paid, and an account surplus is maintained. In 2015, the Federal Reserve made a profit of $100.2 billion and transferred $97.7 billion to the U.S. Treasury.
Purpose.
The primary motivation for creating the Federal Reserve System was to address banking panics. Other purposes are stated in the Federal Reserve Act, such as "to furnish an elastic currency, to afford means of rediscounting commercial paper, to establish a more effective supervision of banking in the United States, and for other purposes". Before the founding of the Federal Reserve System, the United States underwent several financial crises. A particularly severe crisis in 1907 led Congress to enact the Federal Reserve Act in 1913. Today the Federal Reserve System has responsibilities in addition to ensuring the stability of the financial system.
Current functions of the Federal Reserve System include:
Addressing the problem of bank panics.
Banking institutions in the United States are required to hold reservesamounts of currency and deposits in other banksequal to only a fraction of the amount of the bank's deposit liabilities owed to customers. This practice is called fractional-reserve banking. As a result, banks usually invest the majority of the funds received from depositors. On rare occasions, too many of the bank's customers will withdraw their savings and the bank will need help from another institution to continue operating; this is called a bank run. Bank runs can lead to a multitude of social and economic problems. The Federal Reserve System was designed as an attempt to prevent or minimize the occurrence of bank runs, and possibly act as a lender of last resort when a bank run does occur. Many economists, following Milton Friedman, believe that the Federal Reserve inappropriately refused to lend money to small banks during the bank runs of 1929.
Check clearing system.
Because some banks refused to clear checks from certain others during times of economic uncertainty, a check-clearing system was created in the Federal Reserve System. It is briefly described in "The Federal Reserve SystemPurposes and Functions" as follows:
Lender of last resort.
In the United States, the Federal Reserve serves as the lender of last resort to those institutions that cannot obtain credit elsewhere and the collapse of which would have serious implications for the economy. It took over this role from the private sector "clearing houses" which operated during the Free Banking Era; whether public or private, the availability of liquidity was intended to prevent bank runs.
Fluctuations.
Through its discount window and credit operations, Reserve Banks provide liquidity to banks to meet short-term needs stemming from seasonal fluctuations in deposits or unexpected withdrawals. Longer term liquidity may also be provided in exceptional circumstances. The rate the Fed charges banks for these loans is called the discount rate (officially the primary credit rate).
By making these loans, the Fed serves as a buffer against unexpected day-to-day fluctuations in reserve demand and supply. This contributes to the effective functioning of the banking system, alleviates pressure in the reserves market and reduces the extent of unexpected movements in the interest rates. For example, on September 16, 2008, the Federal Reserve Board authorized an $85 billion loan to stave off the bankruptcy of international insurance giant American International Group (AIG).
Central bank.
In its role as the central bank of the United States, the Fed serves as a banker's bank and as the government's bank. As the banker's bank, it helps to assure the safety and efficiency of the payments system. As the government's bank, or fiscal agent, the Fed processes a variety of financial transactions involving trillions of dollars. Just as an individual might keep an account at a bank, the U.S. Treasury keeps a checking account with the Federal Reserve, through which incoming federal tax deposits and outgoing government payments are handled. As part of this service relationship, the Fed sells and redeems U.S. government securities such as savings bonds and Treasury bills, notes and bonds. It also issues the nation's coin and paper currency. The U.S. Treasury, through its Bureau of the Mint and Bureau of Engraving and Printing, actually produces the nation's cash supply and, in effect, sells the paper currency to the Federal Reserve Banks at manufacturing cost, and the coins at face value. The Federal Reserve Banks then distribute it to other financial institutions in various ways. During the Fiscal Year 2013, the Bureau of Engraving and Printing delivered 6.6 billion notes at an average cost of 5.0 cents per note.
Federal funds.
Federal funds are the reserve balances (also called Federal Reserve Deposits) that private banks keep at their local Federal Reserve Bank. These balances are the namesake reserves of the Federal Reserve System. The purpose of keeping funds at a Federal Reserve Bank is to have a mechanism for private banks to lend funds to one another. This market for funds plays an important role in the Federal Reserve System as it is what inspired the name of the system and it is what is used as the basis for monetary policy. Monetary policy is put into effect partly by influencing how much interest the private banks charge each other for the lending of these funds.
Federal reserve accounts contain federal reserve credit, which can be converted into federal reserve notes. Private banks maintain their bank reserves in federal reserve accounts.
Bank regulation.
The Federal Reserve regulates private banks. The system was designed out of a compromise between the competing philosophies of privatization and government regulation. In 2006 Donald L. Kohn, vice chairman of the Board of Governors, summarized the history of this compromise:
The balance between private interests and government can also be seen in the structure of the system. Private banks elect members of the board of directors at their regional Federal Reserve Bank while the members of the Board of Governors are selected by the President of the United States and confirmed by the Senate. Private banks give input to the government officials about their economic situation and government officials use this input in Federal Reserve policy decisions.
Government regulation and supervision.
The Federal Banking Agency Audit Act, enacted in 1978 as Public Law 95-320 and 31 U.S.C. section 714 establish that the Board of Governors of the Federal Reserve System and the Federal Reserve banks may be audited by the Government Accountability Office (GAO).
The GAO has authority to audit check-processing, currency storage and shipments, and some regulatory and bank examination functions, however there are restrictions to what the GAO may audit. Under the Federal Banking Agency Audit Act, 31 U.S.C. section 714(b), our audits of the Federal Reserve Board and Federal Reserve banks do not include (1) transactions for or with a foreign central bank or government, or non-private international financing organization; (2) deliberations, decisions, or actions on monetary policy matters; (3) transactions made under the direction of the Federal Open Market Committee; or (4) a part of a discussion or communication among or between members of the Board of Governors and officers and employees of the Federal Reserve System related to items (1), (2), or (3). See Federal Reserve System Audits: Restrictions on GAO's Access (GAO/T-GGD-94-44), statement of Charles A. Bowsher.
The Board of Governors in the Federal Reserve System has a number of supervisory and regulatory responsibilities in the U.S. banking system, but not complete responsibility. A general description of the types of regulation and supervision involved in the U.S. banking system is given by the Federal Reserve:
Regulatory and oversight responsibilities.
The board of directors of each Federal Reserve Bank District also has regulatory and supervisory responsibilities. If the board of directors of a district bank has judged that a member bank is performing or behaving poorly, it will report this to the Board of Governors. This policy is described in United States Code:
National payments system.
The Federal Reserve plays an important role in the U.S. payments system. The twelve Federal Reserve Banks provide banking services to depository institutions and to the federal government. For depository institutions, they maintain accounts and provide various payment services, including collecting checks, electronically transferring funds, and distributing and receiving currency and coin. For the federal government, the Reserve Banks act as fiscal agents, paying Treasury checks; processing electronic payments; and issuing, transferring, and redeeming U.S. government securities.
In the Depository Institutions Deregulation and Monetary Control Act of 1980, Congress reaffirmed that the Federal Reserve should promote an efficient nationwide payments system. The act subjects all depository institutions, not just member commercial banks, to reserve requirements and grants them equal access to Reserve Bank payment services. It also encourages competition between the Reserve Banks and private-sector providers of payment services by requiring the Reserve Banks to charge fees for certain payments services listed in the act and to recover the costs of providing these services over the long run.
The Federal Reserve plays a role in the nation's retail and wholesale payments systems by providing financial services to depository institutions. Retail payments are generally for relatively small-dollar amounts and often involve a depository institution's retail clientsindividuals and smaller businesses. The Reserve Banks' retail services include distributing currency and coin, collecting checks, and electronically transferring funds through the automated clearinghouse system. By contrast, wholesale payments are generally for large-dollar amounts and often involve a depository institution's large corporate customers or counterparties, including other financial institutions. The Reserve Banks' wholesale services include electronically transferring funds through the Fedwire Funds Service and transferring securities issued by the U.S. government, its agencies, and certain other entities through the Fedwire Securities Service. Because of the large amounts of funds that move through the Reserve Banks every day, the System has policies and procedures to limit the risk to the Reserve Banks from a depository institution's failure to make or settle its payments.
Structure.
The Federal Reserve System has a "unique structure that is both public and private" and is described as "independent within the government" rather than "independent of government". The System does not require public funding, and derives its authority and purpose from the Federal Reserve Act, which was passed by Congress in 1913 and is subject to Congressional modification or repeal. The four main components of the Federal Reserve System are (1) the Board of Governors, (2) the Federal Open Market Committee, (3) the twelve regional Federal Reserve Banks, and (4) the member banks throughout the country.
Board of Governors.
The seven-member Board of Governors is a federal agency. It is charged with the overseeing of the 12 District Reserve Banks and setting national monetary policy. It also supervises and regulates the U.S. banking system in general.
Governors are appointed by the President of the United States and confirmed by the Senate for staggered 14-year terms. One term begins every two years, on February 1 of even-numbered years, and members serving a full term cannot be renominated for a second term. "pon the expiration of their terms of office, members of the Board shall continue to serve until their successors are appointed and have qualified." The law provides for the removal of a member of the Board by the President "for cause". The Board is required to make an annual report of operations to the Speaker of the U.S. House of Representatives.
The Chair and Vice Chair of the Board of Governors are appointed by the President from among the sitting Governors. They both serve a four-year term and they can be renominated as many times as the President chooses, until their terms on the Board of Governors expire.
List of members of the Board of Governors.
The current members of the Board of Governors are as follows:
Nominations, confirmations and resignations.
In late December 2011, President Barack Obama nominated Jeremy C. Stein, a Harvard University finance professor and a Democrat, and Jerome H. Powell, formerly of Dillon Read, Bankers Trust and The Carlyle Group and a Republican. Both candidates also have Treasury Department experience in the Obama and George H. W. Bush administrations respectively.
"Obama administration officials regrouped to identify Fed candidates after Peter Diamond, a Nobel Prize-winning economist, withdrew his nomination to the board in June [2011 in the face of Republican opposition. Richard Clarida, a potential nominee who was a Treasury official under George W. Bush, pulled out of consideration in August one account of the December nominations noted. The two other Obama nominees in 2011, Yellen and Raskin, were confirmed in September. One of the vacancies was created in 2011 with the resignation of Kevin Warsh, who took office in 2006 to fill the unexpired term ending January 31, 2018, and resigned his position effective March 31, 2011. In March 2012, U.S. Senator David Vitter (R, LA) said he would oppose Obama's Stein and Powell nominations, dampening near-term hopes for approval. However Senate leaders reached a deal, paving the way for affirmative votes on the two nominees in May 2012 and bringing the board to full strength for the first time since 2006 with Duke's service after term end. Later, on January 6, 2014, the United States Senate confirmed Yellen's nomination to be Chair of the Federal Reserve Board of Governors; she is slated to be the first woman to hold the position and will become Chair on February 1, 2014. Subsequently, President Obama nominated Stanley Fischer to replace Yellen as the Vice Chair.
In April 2014, Stein announced he was leaving to return to Harvard May 28 with four years remaining on his term. At the time of the announcement, the FOMC "already is down three members as it awaits the Senate confirmation of ... Fischer and Lael Brainard, and as Obama has yet to name a replacement for ... Duke. ... Powell is still serving as he awaits his confirmation for a second term."
Allan R. Landon, 65, former president and CEO of the Bank of Hawaii, was nominated in early 2015 by President Barack Obama to the Board.
In July 2015, President Obama nominated University of Michigan economist Kathryn M. Dominguez to fill the second vacancy on the Board. The Senate had not yet acted on Landon's confirmation by the time of the second nomination.
Federal Open Market Committee.
The Federal Open Market Committee (FOMC) consists of 12 members, seven from the Board of Governors and 5 of the regional Federal Reserve Bank presidents. The FOMC oversees and sets policy on open market operations, the principal tool of national monetary policy. These operations affect the amount of Federal Reserve balances available to depository institutions, thereby influencing overall monetary and credit conditions. The FOMC also directs operations undertaken by the Federal Reserve in foreign exchange markets. The FOMC must reach consensus on all decisions. The president of the Federal Reserve Bank of New York is a permanent member of the FOMC; the presidents of the other banks rotate membership at two- and three-year intervals. All Regional Reserve Bank presidents contribute to the committee's assessment of the economy and of policy options, but only the five presidents who are then members of the FOMC vote on policy decisions. The FOMC determines its own internal organization and, by tradition, elects the Chair of the Board of Governors as its chair and the president of the Federal Reserve Bank of New York as its vice chair. Formal meetings typically are held eight times each year in Washington, D.C. Nonvoting Reserve Bank presidents also participate in Committee deliberations and discussion. The FOMC generally meets eight times a year in telephone consultations and other meetings are held when needed.
Federal Advisory Council.
The Federal Advisory Council, composed of twelve representatives of the banking industry, advises the Board on all matters within its jurisdiction.
Federal Reserve Banks.
There are 12 Federal Reserve Banks and they are located in Boston, New York, Philadelphia, Cleveland, Richmond, Atlanta, Chicago, St. Louis, Minneapolis, Kansas City, Dallas, and San Francisco. Each reserve Bank is responsible for member banks located in its district. The size of each district was set based upon the population distribution of the United States when the Federal Reserve Act was passed. Each regional Bank has a president, who is the chief executive officer of their Bank. Each regional Reserve Bank's president is nominated by their Bank's board of directors, but the nomination is contingent upon approval by the Board of Governors. Presidents serve five-year terms and may be reappointed.
Each regional Bank's board consists of nine members. Members are broken down into three classes: A, B, and C. There are three board members in each class. Class A members are chosen by the regional Bank's shareholders, and are intended to represent member banks' interests. Member banks are divided into three categories: large, medium, and small. Each category elects one of the three class A board members. Class B board members are also nominated by the region's member banks, but class B board members are supposed to represent the interests of the public. Lastly, class C board members are nominated by the Board of Governors, and are also intended to represent the interests of the public.
A member bank is a private institution and owns stock in its regional Federal Reserve Bank. All nationally chartered banks hold stock in one of the Federal Reserve Banks. State chartered banks may choose to be members (and hold stock in their regional Federal Reserve bank), upon meeting certain standards. About 38% of U.S. banks are members of their regional Federal Reserve Bank. The amount of stock a member bank must own is equal to 3% of its combined capital and surplus. However, holding stock in a Federal Reserve bank is not like owning stock in a publicly traded company. These stocks cannot be sold or traded, and member banks do not control the Federal Reserve Bank as a result of owning this stock. The charter and organization of each Federal Reserve Bank is established by law and cannot be altered by the member banks. Member banks, do however, elect six of the nine members of the Federal Reserve Banks' boards of directors. From the profits of the Regional Bank of which it is a member, a member bank receives a dividend equal to 6% of their purchased stock. The remainder of the regional Federal Reserve Banks' profits is given over to the United States Treasury Department. In 2009, the Federal Reserve Banks distributed $1.4 billion in dividends to member banks and returned $47 billion to the U.S. Treasury.
Legal status of regional Federal Reserve Banks.
The Federal Reserve Banks have an intermediate legal status, with some features of private corporations and some features of public federal agencies. The United States has an interest in the Federal Reserve Banks as tax-exempt federally created instrumentalities whose profits belong to the federal government, but this interest is not proprietary. In "Lewis v. United States", the United States Court of Appeals for the Ninth Circuit stated that: "The Reserve Banks are not federal instrumentalities for purposes of the FTCA Federal Tort Claims Act, but are independent, privately owned and locally controlled corporations." The opinion went on to say, however, that: "The Reserve Banks have properly been held to be federal instrumentalities for some purposes." Another relevant decision is "Scott v. Federal Reserve Bank of Kansas City", in which the distinction is made between Federal Reserve Banks, which are federally created instrumentalities, and the Board of Governors, which is a federal agency.
Regarding the structural relationship between the twelve Federal Reserve banks and the various commercial (member) banks, political science professor Michael D. Reagan has written that:
Member banks.
According to the website for the Federal Reserve Bank of Richmond, "ore than one-third of U.S. commercial banks are members of the Federal Reserve System. National banks must be members; state chartered banks may join by meeting certain requirements."
Accountability.
The GAO and an outside auditor regularly audit the Board of Governors, the Federal Reserve banks, and individual member banks. Audits do not cover "most of the Fed's monetary policy actions or decisions, including discount window lending (direct loans to financial institutions), open-market operations and any other transactions made under the direction of the Federal Open Market Committee" ...may the GAO audit "dealings with foreign governments and other central banks." Various statutory changes, including the Federal Reserve Transparency Act, have been proposed to broaden the scope of the audits.
As of August 27, 2012, the Federal Reserve Board has been publishing unaudited financial reports for the Federal Reserve banks every quarter. This is an expansion of prior financial reporting practices. Greater transparency is offered with more frequent disclosure and more detail.
November 7, 2008, Bloomberg L.P. News brought a lawsuit against the Board of Governors of the Federal Reserve System to force the Board to reveal the identities of firms for which it has provided guarantees during the Late-2000s financial crisis. Bloomberg, L.P. won at the trial court and the Fed's appeals were rejected at both the United States Court of Appeals for the Second Circuit and the U.S. Supreme Court. The data was released on March 31, 2011.
Monetary policy.
The term "monetary policy" refers to the actions undertaken by a central bank, such as the Federal Reserve, to influence the availability and cost of money and credit to help promote national economic goals. What happens to money and credit affects interest rates (the cost of credit) and the performance of an economy. The Federal Reserve Act of 1913 gave the Federal Reserve authority to set monetary policy in the United States.
Interbank lending.
The Federal Reserve sets monetary policy by influencing the federal funds rate, which is the rate of interbank lending of excess reserves. The rate that banks charge each other for these loans is determined in the interbank market and the Federal Reserve influences this rate through the three "tools" of monetary policy described in the "Tools" section below. The federal funds rate is a short-term interest rate that the FOMC focuses on, which affects the longer-term interest rates throughout the economy. The Federal Reserve summarized its monetary policy in 2005:
Effects on the quantity of reserves that banks used to make loans influence the economy. Policy actions that add reserves to the banking system encourage lending at lower interest rates thus stimulating growth in money, credit, and the economy. Policy actions that absorb reserves work in the opposite direction. The Fed's task is to supply enough reserves to support an adequate amount of money and credit, avoiding the excesses that result in inflation and the shortages that stifle economic growth.
Tools.
There are three main tools of monetary policy that the Federal Reserve uses to influence the amount of reserves in private banks:
Federal funds rate and open market operations.
The Federal Reserve System implements monetary policy largely by targeting the federal funds rate. This is the interest rate that banks charge each other for overnight loans of federal funds, which are the reserves held by banks at the Fed. This rate is actually determined by the market and is not explicitly mandated by the Fed. The Fed therefore tries to align the effective federal funds rate with the targeted rate by adding or subtracting from the money supply through open market operations. The Federal Reserve System usually adjusts the federal funds rate target by 0.25% or 0.50% at a time.
Open market operations allow the Federal Reserve to increase or decrease the amount of money in the banking system as necessary to balance the Federal Reserve's dual mandates. Open market operations are done through the sale and purchase of United States Treasury security, sometimes called "Treasury bills" or more informally "T-bills" or "Treasuries". The Federal Reserve buys Treasury bills from its primary dealers. The purchase of these securities affects the federal funds rate, because primary dealers have accounts at depository institutions.
The Federal Reserve education website describes open market operations as follows:
Repurchase agreements.
To smooth temporary or cyclical changes in the money supply, the desk engages in repurchase agreements (repos) with its primary dealers. Repos are essentially secured, short-term lending by the Fed. On the day of the transaction, the Fed deposits money in a primary dealer's reserve account, and receives the promised securities as collateral. When the transaction matures, the process unwinds: the Fed returns the collateral and charges the primary dealer's reserve account for the principal and accrued interest. The term of the repo (the time between settlement and maturity) can vary from 1 day (called an overnight repo) to 65 days.
Discount rate.
The Federal Reserve System also directly sets the "discount rate", which is the interest rate for "discount window lending", overnight loans that member banks borrow directly from the Fed. This rate is generally set at a rate close to 100 basis points above the target federal funds rate. The idea is to encourage banks to seek alternative funding before using the "discount rate" option. The equivalent operation by the European Central Bank is referred to as the "marginal lending facility".
Both the discount rate and the federal funds rate influence the prime rate, which is usually about 3 percent higher than the federal funds rate.
Reserve requirements.
Another instrument of monetary policy adjustment employed by the Federal Reserve System is the fractional reserve requirement, also known as the required reserve ratio. The required reserve ratio sets the balance that the Federal Reserve System requires a depository institution to hold in the Federal Reserve Banks, which depository institutions trade in the federal funds market discussed above. The required reserve ratio is set by the Board of Governors of the Federal Reserve System. The reserve requirements have changed over time and some history of these changes is published by the Federal Reserve.
As a response to the financial crisis of 2008, the Federal Reserve now makes interest payments on depository institutions' required and excess reserve balances. The payment of interest on excess reserves gives the central bank greater opportunity to address credit market conditions while maintaining the federal funds rate close to the target rate set by the FOMC.
New facilities.
In order to address problems related to the subprime mortgage crisis and United States housing bubble, several new tools have been created. The first new tool, called the Term Auction Facility, was added on December 12, 2007. It was first announced as a temporary tool but there have been suggestions that this new tool may remain in place for a prolonged period of time. Creation of the second new tool, called the Term Securities Lending Facility, was announced on March 11, 2008. The main difference between these two facilities is that the Term Auction Facility is used to inject cash into the banking system whereas the Term Securities Lending Facility is used to inject treasury securities into the banking system. Creation of the third tool, called the Primary Dealer Credit Facility (PDCF), was announced on March 16, 2008. The PDCF was a fundamental change in Federal Reserve policy because now the Fed is able to lend directly to primary dealers, which was previously against Fed policy. The differences between these three new facilities is described by the Federal Reserve:
Some measures taken by the Federal Reserve to address this mortgage crisis have not been used since The Great Depression. The Federal Reserve gives a brief summary of these new facilities:
A fourth facility, the Term Deposit Facility, was announced December 9, 2009, and approved April 30, 2010, with an effective date of June 4, 2010. The Term Deposit Facility allows Reserve Banks to offer term deposits to institutions that are eligible to receive earnings on their balances at Reserve Banks. Term deposits are intended to facilitate the implementation of monetary policy by providing a tool by which the Federal Reserve can manage the aggregate quantity of reserve balances held by depository institutions. Funds placed in term deposits are removed from the accounts of participating institutions for the life of the term deposit and thus drain reserve balances from the banking system.
Term auction facility.
The Term Auction Facility is a program in which the Federal Reserve auctions term funds to depository institutions. The creation of this facility was announced by the Federal Reserve on December 12, 2007, and was done in conjunction with the Bank of Canada, the Bank of England, the European Central Bank, and the Swiss National Bank to address elevated pressures in short-term funding markets. The reason it was created is that banks were not lending funds to one another and banks in need of funds were refusing to go to the discount window. Banks were not lending money to each other because there was a fear that the loans would not be paid back. Banks refused to go to the discount window because it is usually associated with the stigma of bank failure.
It is also described in the "Term Auction Facility FAQ"
Term securities lending facility.
The Term Securities Lending Facility is a 28-day facility that will offer Treasury general collateral to the Federal Reserve Bank of New York's primary dealers in exchange for other program-eligible collateral. It is intended to promote liquidity in the financing markets for Treasury and other collateral and thus to foster the functioning of financial markets more generally. Like the Term Auction Facility, the TSLF was done in conjunction with the Bank of Canada, the Bank of England, the European Central Bank, and the Swiss National Bank. The resource allows dealers to switch debt that is less liquid for U.S. government securities that are easily tradable. It is anticipated by Federal Reserve officials that the primary dealers, which include Goldman Sachs Group. Inc., J.P. Morgan Chase, and Morgan Stanley, will lend the Treasuries on to other firms in return for cash. That will help the dealers finance their balance sheets. The currency swap lines with the European Central Bank and Swiss National Bank were increased.
Primary dealer credit facility.
The Primary Dealer Credit Facility (PDCF) is an overnight loan facility that will provide funding to primary dealers in exchange for a specified range of eligible collateral and is intended to foster the functioning of financial markets more generally. This new facility marks a fundamental change in Federal Reserve policy because now primary dealers can borrow directly from the Fed when this previously was not permitted.
Interest on reserves.
, the Federal Reserve banks will pay interest on reserve balances (required and excess) held by depository institutions. The rate is set at the lowest federal funds rate during the reserve maintenance period of an institution, less 75bp. As of October 23, 2008, the Fed has lowered the spread to a mere 35 bp.
Term deposit facility.
The Term Deposit Facility is a program through which the Federal Reserve Banks will offer interest-bearing term deposits to eligible institutions. By removing "excess deposits" from participating banks, the overall level of reserves available for lending is reduced, which should result in increased market interest rates, acting as a brake on economic activity and inflation. The Federal Reserve has stated that:
The Federal Reserve initially authorized up to five "small-value offerings are designed to ensure the effectiveness of TDF operations and to provide eligible institutions with an opportunity to gain familiarity with term deposit procedures." After three of the offering auctions were successfully completed, it was announced that small-value auctions would continue on an ongoing basis.
The Term Deposit Facility is essentially a tool available to reverse the efforts that have been employed to provide liquidity to the financial markets and to reduce the amount of capital available to the economy. As stated in Bloomberg News:
Chairman Ben S. Bernanke, testifying before House Committee on Financial Services, described the Term Deposit Facility and other facilities to Congress in the following terms:
Asset Backed Commercial Paper Money Market Mutual Fund Liquidity Facility.
The Asset Backed Commercial Paper Money Market Mutual Fund Liquidity Facility (ABCPMMMFLF) was also called the AMLF. The Facility began operations on September 22, 2008, and was closed on February 1, 2010.
All U.S. depository institutions, bank holding companies (parent companies or U.S. broker-dealer affiliates), or U.S. branches and agencies of foreign banks were eligible to borrow under this facility pursuant to the discretion of the FRBB.
Collateral eligible for pledge under the Facility was required to meet the following criteria:
Commercial Paper Funding Facility.
On October 7, 2008, the Federal Reserve further expanded the collateral it will loan against to include commercial paper using the new Commercial Paper Funding Facility (CPFF). The action made the Fed a crucial source of credit for non-financial businesses in addition to commercial banks and investment firms. Fed officials said they'll buy as much of the debt as necessary to get the market functioning again. They refused to say how much that might be, but they noted that around $1.3 trillion worth of commercial paper would qualify. There was $1.61 trillion in outstanding commercial paper, seasonally adjusted, on the market as of October 1, 2008, according to the most recent data from the Fed. That was down from $1.70 trillion in the previous week. Since the summer of 2007, the market has shrunk from more than $2.2 trillion. This program lent out a total $738 billion before it was closed. Forty-five out of 81 of the companies participating in this program were foreign firms. Research shows that Troubled Asset Relief Program (TARP) recipients were twice as likely to participate in the program than other commercial paper issuers who did not take advantage of the TARP bailout. The Fed incurred no losses from the CPFF.
Quantitative policy.
A little-used tool of the Federal Reserve is the "quantitative policy". With that the Federal Reserve actually buys back corporate bonds and mortgage backed securities held by banks or other financial institutions. This in effect puts money back into the financial institutions and allows them to make loans and conduct normal business. The Federal Reserve Board used this policy in the early 1990s when the U.S. economy experienced the savings and loan crisis.
The bursting of the United States housing bubble prompted the Fed to buy mortgage-backed securities for the first time in November 2008. Over six weeks, a total of $1.25 trillion were purchased in order to stabilize the housing market, about one-fifth of all U.S. government-backed mortgages.
History.
Central banking in the United States, 1791-1813.
The first attempt at a national currency was during the American Revolutionary War. In 1775 the Continental Congress, as well as the states, began issuing paper currency, calling the bills "Continentals". The Continentals were backed only by future tax revenue, and were used to help finance the Revolutionary War. Overprinting, as well as British counterfeiting, caused the value of the Continental to diminish quickly. This experience with paper money led the United States to strip the power to issue Bills of Credit (paper money) from a draft of the new Constitution on August 16, 1787, as well as banning such issuance by the various states, and limiting the states' ability to make anything but gold or silver coin legal tender on August 28.
In 1791, the government granted the First Bank of the United States a charter to operate as the U.S. central bank until 1811. The First Bank of the United States came to an end under President Madison because Congress refused to renew its charter. The Second Bank of the United States was established in 1816, and lost its authority to be the central bank of the U.S. twenty years later under President Jackson when its charter expired. Both banks were based upon the Bank of England. Ultimately, a third national bank, known as the Federal Reserve, was established in 1913 and still exists to this day.
First Central Bank, 1791 and Second Central Bank, 1816.
The first U.S. institution with central banking responsibilities was the First Bank of the United States, chartered by Congress and signed into law by President George Washington on February 25, 1791, at the urging of Alexander Hamilton. This was done despite strong opposition from Thomas Jefferson and James Madison, among numerous others. The charter was for twenty years and expired in 1811 under President Madison, because Congress refused to renew it.
In 1816, however, Madison revived it in the form of the Second Bank of the United States. Years later, early renewal of the bank's charter became the primary issue in the reelection of President Andrew Jackson. After Jackson, who was opposed to the central bank, was reelected, he pulled the government's funds out of the bank. Nicholas Biddle, President of the Second Bank of the United States, responded by contracting the money supply to pressure Jackson to renew the bank's charter forcing the country into a recession, which the bank blamed on Jackson's policies. Jackson was the only President to completely pay off the debt. The bank's charter was not renewed in 1836.
From 1837 to 1862, in the Free Banking Era there was no formal central bank.
From 1846 to 1921 an Independent Treasury System ruled.
From 1863 to 1913, a system of national banks was instituted by the 1863 National Banking Act during which series of bank panics, in 1873, 1893, and 1907 occurred
Creation of Third Central Bank, 1907-1913.
The main motivation for the third central banking system came from the Panic of 1907, which caused renewed demands for banking and currency reform. During the last quarter of the 19th century and the beginning of the 20th century the United States economy went through a series of financial panics. According to many economists, the previous national banking system had two main weaknesses: an inelastic currency and a lack of liquidity. In 1908, Congress enacted the Aldrich–Vreeland Act, which provided for an emergency currency and established the National Monetary Commission to study banking and currency reform. The National Monetary Commission returned with recommendations which were repeatedly rejected by Congress. A revision crafted during a secret meeting on Jekyll Island by Senator Aldrich and representatives of the nation's top finance and industrial groups later became the basis of the Federal Reserve Act. The House voted on December 22, 1913, with 298 yeas to 60 nays, and the Senate voted 4325 on December 23, 1913. President Woodrow Wilson signed the bill later that day.
Federal Reserve Act, 1913.
The head of the bipartisan National Monetary Commission was financial expert and Senate Republican leader Nelson Aldrich. Aldrich set up two commissions – one to study the American monetary system in depth and the other, headed by Aldrich himself, to study the European central banking systems and report on them. Aldrich went to Europe opposed to centralized banking, but after viewing Germany's monetary system he came away believing that a centralized bank was better than the government-issued bond system that he had previously supported.
In early November 1910, Aldrich met with five well known members of the New York banking community to devise a central banking bill. Paul Warburg, an attendee of the meeting and longtime advocate of central banking in the U.S., later wrote that Aldrich was "bewildered at all that he had absorbed abroad and he was faced with the difficult task of writing a highly technical bill while being harassed by the daily grind of his parliamentary duties". After ten days of deliberation, the bill, which would later be referred to as the "Aldrich Plan", was agreed upon. It had several key components, including a central bank with a Washington-based headquarters and fifteen branches located throughout the U.S. in geographically strategic locations, and a uniform elastic currency based on gold and commercial paper. Aldrich believed a central banking system with no political involvement was best, but was convinced by Warburg that a plan with no public control was not politically feasible. The compromise involved representation of the public sector on the Board of Directors.
Aldrich's bill met much opposition from politicians. Critics charged Aldrich of being biased due to his close ties to wealthy bankers such as J. P. Morgan and John D. Rockefeller, Jr., Aldrich's son-in-law. Most Republicans favored the Aldrich Plan, but it lacked enough support in Congress to pass because rural and western states viewed it as favoring the "eastern establishment". In contrast, progressive Democrats favored a reserve system owned and operated by the government; they believed that public ownership of the central bank would end Wall Street's control of the American currency supply. Conservative Democrats fought for a privately owned, yet decentralized, reserve system, which would still be free of Wall Street's control.
The original Aldrich Plan was dealt a fatal blow in 1912, when Democrats won the White House and Congress. Nonetheless, President Woodrow Wilson believed that the Aldrich plan would suffice with a few modifications. The plan became the basis for the Federal Reserve Act, which was proposed by Senator Robert Owen in May 1913. The primary difference between the two bills was the transfer of control of the Board of Directors (called the Federal Open Market Committee in the Federal Reserve Act) to the government. The bill passed Congress on December 23, 1913, on a mostly partisan basis, with most Democrats voting "yea" and most Republicans voting "nay".
Federal Reserve era, 1913-present.
Key laws affecting the Federal Reserve have been:
Measurement of economic variables.
The Federal Reserve records and publishes large amounts of data. A few websites where data is published are at the Board of Governors Economic Data and Research page, the Board of Governors statistical releases and historical data page, and at the St. Louis Fed's FRED (Federal Reserve Economic Data) page. The Federal Open Market Committee (FOMC) examines many economic indicators prior to determining monetary policy.
Some criticism involves economic data compiled by the Fed. The Fed sponsors much of the monetary economics research in the U.S., and Lawrence H. White objects that this makes it less likely for researchers to publish findings challenging the status quo.
Net worth of households and nonprofit organizations.
The net worth of households and nonprofit organizations in the United States is published by the Federal Reserve in a report titled "Flow of Funds". At the end of the third quarter of fiscal year 2012, this value was $64.8 trillion. At the end of the first quarter of fiscal year 2014, this value was $95.5 trillion.
Money supply.
The most common measures are named M0 (narrowest), M1, M2, and M3. In the United States they are defined by the Federal Reserve as follows:
The Federal Reserve stopped publishing M3 statistics in March 2006, saying that the data cost a lot to collect but did not provide significantly useful information. The other three money supply measures continue to be provided in detail.
Personal consumption expenditures price index.
The Personal consumption expenditures price index, also referred to as simply the PCE price index, is used as one measure of the value of money. It is a United States-wide indicator of the average increase in prices for all domestic personal consumption. Using a variety of data including United States Consumer Price Index and U.S. Producer Price Index prices, it is derived from the largest component of the Gross Domestic Product in the BEA's National Income and Product Accounts, personal consumption expenditures.
One of the Fed's main roles is to maintain price stability, which means that the Fed's ability to keep a low inflation rate is a long-term measure of their success. Although the Fed is not required to maintain inflation within a specific range, their long run target for the growth of the PCE price index is between 1.5 and 2 percent. There has been debate among policy makers as to whether the Federal Reserve should have a specific inflation targeting policy.
Inflation and the economy.
Most mainstream economists favor a low, steady rate of inflation. Low (as opposed to zero or negative) inflation may reduce the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduce the risk that a liquidity trap prevents monetary policy from stabilizing the economy. The task of keeping the rate of inflation low and stable is usually given to monetary authorities.
Unemployment rate.
One of the stated goals of monetary policy is maximum employment. The unemployment rate statistics are collected by the Bureau of Labor Statistics, and like the PCE price index are used as a barometer of the nation's economic health.
Budget.
The Federal Reserve is self-funded. The vast majority (90%+) of Fed revenues come from open market operations, specifically the interest on the portfolio of Treasury securities as well as "capital gains/losses" that may arise from the buying/selling of the securities and their derivatives as part of Open Market Operations. The balance of revenues come from sales of financial services (check and electronic payment processing) and discount window loans. The Board of Governors (Federal Reserve Board) creates a budget report once per year for Congress. There are two reports with budget information. The one that lists the complete balance statements with income and expenses as well as the net profit or loss is the large report simply titled, "Annual Report". It also includes data about employment throughout the system. The other report, which explains in more detail the expenses of the different aspects of the whole system, is called "Annual Report: Budget Review". These are comprehensive reports with many details and can be found at the Board of Governors' website under the section "Reports to Congress"
Net worth.
Balance sheet.
One of the keys to understanding the Federal Reserve is the Federal Reserve balance sheet (or balance statement). In accordance with Section 11 of the Federal Reserve Act, the Board of Governors of the Federal Reserve System publishes once each week the "Consolidated Statement of Condition of All Federal Reserve Banks" showing the condition of each Federal Reserve bank and a consolidated statement for all Federal Reserve banks. The Board of Governors requires that excess earnings of the Reserve Banks be transferred to the Treasury as interest on Federal Reserve notes.
Below is the balance sheet as of July 6, 2011 (in billions of dollars):
NOTE: The Fed balance sheet shown in this article has assets, liabilities and net equity that do not add up correctly. The Fed balance sheet is missing the item "Reserve Balances with Federal Reserve Banks" which would make the figures balance.
In addition, the balance sheet also indicates which assets are held as collateral against Federal Reserve Notes.
Criticism.
The Federal Reserve System has faced various criticisms since its inception in 1913. Critique of the organization and system has come from sources such as writers, journalists, economists, and financial institutions as well as politicians and various government employees. Criticisms include doubt of efficacy due to what is seen by some as poor historical performance and populist concerns about the debasement of the value of the dollar.

</doc>
<doc id="10821" url="https://en.wikipedia.org/wiki?curid=10821" title="Francium">
Francium

Francium is a chemical element with symbol Fr and atomic number 87. It used to be known as eka-caesium and actinium K. It is the second-least electronegative element, behind only caesium. Francium is a highly radioactive metal that decays into astatine, radium, and radon. As an alkali metal, it has one valence electron.
Bulk francium has never been viewed. Because of the general appearance of the other elements in its periodic table column, it is assumed that francium would appear as a highly reflective metal, if enough could be collected together to be viewed as a bulk solid or liquid. Obtaining such a sample is highly improbable, since the extreme heat of decay (the half-life of its longest-lived isotope is only 22 minutes) would immediately vaporize any viewable quantity of the element.
Francium was discovered by Marguerite Perey in France (from which the element takes its name) in 1939. It was the last element first discovered in nature, rather than by synthesis. Outside the laboratory, francium is extremely rare, with trace amounts found in uranium and thorium ores, where the isotope francium-223 continually forms and decays. As little as 20–30 g (one ounce) exists at any given time throughout the Earth's crust; the other isotopes (except for francium-221) are entirely synthetic. The largest amount produced in the laboratory was a cluster of more than 300,000 atoms.
Characteristics.
Francium is the most unstable of the naturally occurring elements: its most stable isotope, francium-223, has a half-life of only 22 minutes. In contrast, astatine, the second-least stable naturally occurring element, has a half-life of 8.5 hours. All isotopes of francium decay into astatine, radium, or radon. Francium is also less stable than all synthetic elements up to element 105.
Francium is an alkali metal whose chemical properties mostly resemble those of caesium. A heavy element with a single valence electron, it has the highest equivalent weight of any element. Liquid francium—if created—should have a surface tension of 0.05092 N/m at its melting point. Francium's melting point was calculated to be around 27 °C (80 °F, 300 K). The melting point is uncertain because of the element's extreme rarity and radioactivity. Thus, the estimated boiling point value of 677 °C (1250 °F, 950 K) is also uncertain.
Linus Pauling estimated the electronegativity of francium at 0.7 on the Pauling scale, the same as caesium; the value for caesium has since been refined to 0.79, but there are no experimental data to allow a refinement of the value for francium. Francium has a slightly higher ionization energy than caesium, 392.811(4) kJ/mol as opposed to 375.7041(2) kJ/mol for caesium, as would be expected from relativistic effects, and this would imply that caesium is the less electronegative of the two. Francium should also have a higher electron affinity than caesium and the Fr− ion should be more polarizable than the Cs− ion. The CsFr molecule is predicted to have francium at the negative end of the dipole, unlike all known heterodiatomic alkali metal molecules. Francium superoxide (FrO2) is expected to have a more covalent character than its lighter congeners; this is attributed to the 6p electrons in francium being more involved in the francium–oxygen bonding.
Francium coprecipitates with several caesium salts, such as caesium perchlorate, which results in small amounts of francium perchlorate. This coprecipitation can be used to isolate francium, by adapting the radiocaesium coprecipitation method of Glendenin and Nelson. It will additionally coprecipitate with many other caesium salts, including the iodate, the picrate, the tartrate (also rubidium tartrate), the chloroplatinate, and the silicotungstate. It also coprecipitates with silicotungstic acid, and with perchloric acid, without another alkali metal as a carrier, which provides other methods of separation. Nearly all francium salts are water-soluble.
Isotopes.
There are 34 known isotopes of francium ranging in atomic mass from 199 to 232. Francium has seven metastable nuclear isomers. Francium-223 and francium-221 are the only isotopes that occur in nature, though the former is far more common.
Francium-223 is the most stable isotope, with a half-life of 21.8 minutes, and it is highly unlikely that an isotope of francium with a longer half-life will ever be discovered or synthesized. Francium-223 is the fifth product of the actinium decay series as the daughter isotope of actinium-227. Francium-223 then decays into radium-223 by beta decay (1149 keV decay energy), with a minor (0.006%) alpha decay path to astatine-219 (5.4 MeV decay energy).
Francium-221 has a half-life of 4.8 minutes. It is the ninth product of the neptunium decay series as a daughter isotope of actinium-225. Francium-221 then decays into astatine-217 by alpha decay (6.457 MeV decay energy).
The least stable ground state isotope is francium-215, with a half-life of 0.12 μs. (9.54 MeV alpha decay to astatine-211): Its metastable isomer, francium-215m, is less stable still, with a half-life of only 3.5 ns.
Applications.
Due to its instability and rarity, there are no commercial applications for francium. It has been used for research purposes in the fields of chemistry
and of atomic structure. Its use as a potential diagnostic aid for various cancers has also been explored, but this application has been deemed impractical.
Francium's ability to be synthesized, trapped, and cooled, along with its relatively simple atomic structure have made it the subject of specialized spectroscopy experiments. These experiments have led to more specific information regarding energy levels and the coupling constants between subatomic particles. Studies on the light emitted by laser-trapped francium-210 ions have provided accurate data on transitions between atomic energy levels which are fairly similar to those predicted by quantum theory.
History.
As early as 1870, chemists thought that there should be an alkali metal beyond caesium, with an atomic number of 87. It was then referred to by the provisional name "eka-caesium". Research teams attempted to locate and isolate this missing element, and at least four false claims were made that the element had been found before an authentic discovery was made.
Erroneous and incomplete discoveries.
Soviet chemist D. K. Dobroserdov was the first scientist to claim to have found eka-caesium, or francium. In 1925, he observed weak radioactivity in a sample of potassium, another alkali metal, and incorrectly concluded that eka-caesium was contaminating the sample (the radioactivity from the sample was from the naturally occurring potassium radioisotope, potassium-40). He then published a thesis on his predictions of the properties of eka-caesium, in which he named the element "russium" after his home country. Shortly thereafter, Dobroserdov began to focus on his teaching career at the Polytechnic Institute of Odessa, and he did not pursue the element further.
The following year, English chemists Gerald J. F. Druce and Frederick H. Loring analyzed X-ray photographs of manganese(II) sulfate. They observed spectral lines which they presumed to be of eka-caesium. They announced their discovery of element 87 and proposed the name "alkalinium", as it would be the heaviest alkali metal.
In 1930, Fred Allison of the Alabama Polytechnic Institute claimed to have discovered element 87 when analyzing pollucite and lepidolite using his magneto-optical machine. Allison requested that it be named "virginium" after his home state of Virginia, along with the symbols Vi and Vm. In 1934, H.G. MacPherson of UC Berkeley disproved the effectiveness of Allison's device and the validity of this false discovery.
In 1936, Romanian physicist Horia Hulubei and his French colleague Yvette Cauchois also analyzed pollucite, this time using their high-resolution X-ray apparatus. They observed several weak emission lines, which they presumed to be those of element 87. Hulubei and Cauchois reported their discovery and proposed the name "moldavium", along with the symbol Ml, after Moldavia, the Romanian province where Hulubei was born. In 1937, Hulubei's work was criticized by American physicist F. H. Hirsh Jr., who rejected Hulubei's research methods. Hirsh was certain that eka-caesium would not be found in nature, and that Hulubei had instead observed mercury or bismuth X-ray lines. Hulubei insisted that his X-ray apparatus and methods were too accurate to make such a mistake. Because of this, Jean Baptiste Perrin, Nobel Prize winner and Hulubei's mentor, endorsed moldavium as the true eka-caesium over Marguerite Perey's recently discovered francium. Perey took pains to be accurate and detailed in her criticism of Hulubei's work, and finally she was credited as the sole discoverer of element 87. All other previous purported discoveries of element 87 were ruled out due to francium's very limited half-life.
Perey's analysis.
Eka-caesium was discovered in 1939 by Marguerite Perey of the Curie Institute in Paris, when she purified a sample of actinium-227 which had been reported to have a decay energy of 220 keV. Perey noticed decay particles with an energy level below 80 keV. Perey thought this decay activity might have been caused by a previously unidentified decay product, one which was separated during purification, but emerged again out of the pure actinium-227. Various tests eliminated the possibility of the unknown element being thorium, radium, lead, bismuth, or thallium. The new product exhibited chemical properties of an alkali metal (such as coprecipitating with caesium salts), which led Perey to believe that it was element 87, caused by the alpha decay of actinium-227. Perey then attempted to determine the proportion of beta decay to alpha decay in actinium-227. Her first test put the alpha branching at 0.6%, a figure which she later revised to 1%.
Perey named the new isotope "actinium-K" (it is now referred to as francium-223) and in 1946, she proposed the name "catium" for her newly discovered element, as she believed it to be the most electropositive cation of the elements. Irène Joliot-Curie, one of Perey's supervisors, opposed the name due to its connotation of "cat" rather than "cation". Perey then suggested "francium", after France. This name was officially adopted by the International Union of Pure and Applied Chemistry in 1949, becoming the second element after gallium to be named after France. It was assigned the symbol Fa, but this abbreviation was revised to the current Fr shortly thereafter. Francium was the last element discovered in nature, rather than synthesized, following rhenium in 1925. Further research into francium's structure was carried out by, among others, Sylvain Lieberman and his team at CERN in the 1970s and 1980s.
Occurrence.
Natural.
223Fr is the result of the alpha decay of 227Ac and can be found in trace amounts in uranium and thorium minerals. In a given sample of uranium, there is estimated to be only one francium atom for every 1 × 1018 uranium atoms. It is also calculated that there is at most 30 g of francium in the Earth's crust at any given time.
Synthesis.
Francium can be synthesized in the nuclear reaction:
This process, developed by Stony Brook Physics, yields francium isotopes with masses of 209, 210, and 211, which are then isolated by the magneto-optical trap (MOT). The production rate of a particular isotope depends on the energy of the oxygen beam. An 18O beam from the Stony Brook LINAC creates 210Fr in the gold target with the nuclear reaction 197Au + 18O → 210Fr + 5n. The production required some time to develop and understand. It was critical to operate the gold target very close to its melting point and to make sure that its surface was very clean. The nuclear reaction embeds the francium atoms deep in the gold target, and they must be removed efficiently. The atoms quickly diffuse to the surface of the gold target and are released as ions, but this does not happen every time. The francium ions are guided by electrostatic lenses until they land in a surface of hot yttrium and become neutral again. The francium is then injected into a glass bulb. A magnetic field and laser beams cool and confine the atoms. Although the atoms remain in the trap for only about 20 seconds before escaping (or decaying), a steady stream of fresh atoms replaces those lost, keeping the number of trapped atoms roughly constant for minutes or longer. Initially, about 1000 francium atoms were trapped in the experiment. This was gradually improved and the setup is capable of trapping over 300,000 neutral atoms of francium a time. These are neutral metallic atoms in a gaseous unconsolidated state. Enough francium is trapped that a video camera can capture the light given off by the atoms as they fluoresce. The atoms appear as a glowing sphere about 1 millimeter in diameter. This was the first time that anyone had ever seen francium. The researchers can now make extremely sensitive measurements of the light emitted and absorbed by the trapped atoms, providing the first experimental results on various transitions between atomic energy levels in francium. Initial measurements show very good agreement between experimental values and calculations based on quantum theory. Other synthesis methods include bombarding radium with neutrons, and bombarding thorium with protons, deuterons, or helium ions. Francium has not been synthesized in amounts large enough to weigh.

</doc>
<doc id="10822" url="https://en.wikipedia.org/wiki?curid=10822" title="Fermium">
Fermium

Fermium is a synthetic element with symbol Fm and atomic number 100. It is a member of the actinide series. It is the heaviest element that can be formed by neutron bombardment of lighter elements, and hence the last element that can be prepared in macroscopic quantities, although pure fermium metal has not yet been prepared. A total of 19 isotopes are known, with 257Fm being the longest-lived with a half-life of 100.5 days.
It was discovered in the debris of the first hydrogen bomb explosion in 1952, and named after Enrico Fermi, one of the pioneers of nuclear physics. Its chemistry is typical for the late actinides, with a preponderance of the +3 oxidation state but also an accessible +2 oxidation state. Owing to the small amounts of produced fermium and all of its isotopes having relatively short half-lives, there are currently no uses for it outside of basic scientific research.
Discovery.
Fermium was first discovered in the fallout from the 'Ivy Mike' nuclear test (1 November 1952), the first successful test of a hydrogen bomb. Initial examination of the debris from the explosion had shown the production of a new isotope of plutonium, plutonium-244: this could only have formed by the absorption of six neutrons by a uranium-238 nucleus followed by two β− decays. At the time, the absorption of neutrons by a heavy nucleus was thought to be a rare process, but the identification of raised the possibility that still more neutrons could have been absorbed by the uranium nuclei, leading to new elements.
Element 99 (einsteinium) was quickly discovered on filter papers which had been flown through the cloud from the explosion (the same sampling technique that had been used to discover ). It was then identified in December 1952 by Albert Ghiorso and co-workers at the University of California at Berkeley. They discovered the isotope 253Es (half-life 20.5 days) that was made by the capture of 15 neutrons by uranium-238 nuclei – which then underwent seven successive beta decays:
Some 238U atoms, however, could capture another amount of neutrons (most likely, 16 or 17).
The discovery of fermium (Z = 100) required more material, as the yield was expected to be at least an order of magnitude lower than that of element 99, and so contaminated coral from the Enewetak atoll (where the test had taken place) was shipped to the University of California Radiation Laboratory in Berkeley, California, for processing and analysis. About two months after the test, a new component was isolated emitting high-energy α-particles (7.1 MeV) with a half-life of about a day. With such a short half-life, it could only arise from the β− decay of an isotope of einsteinium, and so had to be an isotope of the new element 100: it was quickly identified as 255Fm (t = 20.07(7) hours).
The discovery of the new elements, and the new data on neutron capture, was initially kept secret on the orders of the U.S. military until 1955 due to Cold War tensions. Nevertheless, the Berkeley team were able to prepare elements 99 and 100 by civilian means, through the neutron bombardment of plutonium-239, and published this work in 1954 with the disclaimer that it was not the first studies that had been carried out on the elements. The 'Ivy Mike' studies were declassified and published in 1955.
The Berkeley team had been worried that another group might discover lighter isotopes of element 100 through ion bombardment techniques before they could publish their classified research, and this proved to be the case. A group at the Nobel Institute for Physics in Stockholm independently discovered the element, producing an isotope later confirmed to be 250Fm (t1/2 = 30 minutes) by bombarding a target with oxygen-16 ions, and published their work in May 1954. Nevertheless, the priority of the Berkeley team was generally recognized, and with it the prerogative to name the new element in honour of the recently deceased Enrico Fermi, the developer of the first artificial self-sustained nuclear reactor.
Isotopes.
There are 19 isotopes of fermium listed in NUBASE 2003, with atomic weights of 242 to 260, of which 257Fm is the longest-lived with a half-life of 100.5 days. 253Fm has a half-life of 3 days, while 251Fm of 5.3 h, 252Fm of 25.4 h, 254Fm of 3.2 h, 255Fm of 20.1 h, and 256Fm of 2.6 hours. All the remaining ones have half-lives ranging from 30 minutes to less than a millisecond.
The neutron-capture product of fermium-257, 258Fm, undergoes spontaneous fission with a half-life of just 370(14) microseconds; 259Fm and 260Fm are also unstable with respect to spontaneous fission (t1/2 = 1.5(3) s and 4 ms respectively). This means that neutron capture cannot be used to create nuclides with a mass number greater than 257, unless carried out in a nuclear explosion. As 257Fm is an α-emitter, decaying to 253Cf, and no fermium isotopes undergo beta minus decay (which would produce isotopes of the next element, mendelevium), fermium is also the last element that can be prepared by a neutron-capture process.
Production.
Fermium is produced by the bombardment of lighter actinides with neutrons in a nuclear reactor. Fermium-257 is the heaviest isotope that is obtained via neutron capture, and can only be produced in nanogram quantities. The major source is the 85 MW High Flux Isotope Reactor (HFIR) at the Oak Ridge National Laboratory in Tennessee, USA, which is dedicated to the production of transcurium ("Z" > 96) elements. In a "typical processing campaign" at Oak Ridge, tens of grams of curium are irradiated to produce decigram quantities of californium, milligram quantities of berkelium and einsteinium and picogram quantities of fermium. However, nanogram and microgram quantities of fermium can be prepared for specific experiments. The quantities of fermium produced in 20–200 kiloton thermonuclear explosions is believed to be of the order of milligrams, although it is mixed in with a huge quantity of debris; 40 picograms of 257Fm was recovered from 10 kilograms of debris from the 'Hutch' test (16 July 1969).
After production, the fermium must be separated from other actinides and from lanthanoid fission products. This is usually achieved by ion exchange chromatography, with the standard process using a cation exchanger such as Dowex 50 or TEVA eluted with a solution of ammonium α-hydroxyisobutyrate. Smaller cations form more stable complexes with the α-hydroxyisobutyrate anion, and so are preferentially eluted from the column. A rapid fractional crystallization method has also been described.
Although the most stable isotope of fermium is 257Fm, with a half-life of 100.5 days, most studies are conducted on 255Fm (t1/2 = 20.07(7) hours) as this isotope can be easily isolated as required as the decay product of 255Es (t1/2 = 39.8(12) days).
Synthesis in nuclear explosions.
The analysis of the debris at the 10-megaton "Ivy Mike" nuclear test was a part of long-term project, one of the goals of which was studying the efficiency of production of transuranium elements in high-power nuclear explosions. The motivation for these experiments was as follows: synthesis of such elements from uranium requires multiple neutron capture. The probability of such events increases with the neutron flux, and nuclear explosions are the most powerful neutron sources, providing densities of the order 1023 neutrons/cm2 within a microsecond, i.e. about 1029 neutrons/(cm2·s). In comparison, the flux of the HFIR reactor is 5 neutrons/(cm2·s). A dedicated laboratory was set up right at Enewetak Atoll for preliminary analysis of debris, as some isotopes could have decayed by the time the debris samples reached the U.S. The laboratory was receiving samples for analysis, as soon as possible, from airplanes equipped with paper filters which flew over the atoll after the tests. Whereas it was hoped to discover new chemical elements heavier than fermium, those were not found after a series of megaton explosions conducted between 1954 and 1956 at the atoll.
The atmospheric results were supplemented by the underground test data accumulated in the 1960s at the Nevada Test Site, as it was hoped that powerful explosions conducted in confined space might result in improved yields and heavier isotopes. Apart from traditional uranium charges, combinations of uranium with americium and thorium have been tried, as well as a mixed plutonium-neptunium charge. They were less successful in terms of yield that was attributed to stronger losses of heavy isotopes due to enhanced fission rates in heavy-element charges. Isolation of the products was found to be rather problematic, as the explosions were spreading debris through melting and vaporizing rocks under the great depth of 300–600 meters, and drilling to such depth in order to extract the products was both slow and inefficient in terms of collected volumes.
Among the nine underground tests, which were carried between 1962 and 1969 and codenamed Anacostia (5.2 kilotons, 1962), Kennebec (<5 kilotons, 1963), Par (38, kilotons, 1964), Barbel (<20 kilotons, 1964), Tweed (<20 kilotons, 1965), Cyclamen (13 kilotons, 1966), Kankakee (20-200 kilotons, 1966), Vulcan (25 kilotons, 1966) and Hutch (20-200 kilotons, 1969), the last one was most powerful and had the highest yield of transuranium elements. In the dependence on the atomic mass number, the yield showed a saw-tooth behavior with the lower values for odd isotopes, due to their higher fission rates. The major practical problem of the entire proposal was however collecting the radioactive debris dispersed by the powerful blast. Aircraft filters adsorbed only about 4 of the total amount and collection of tons of corals at Enewetak Atoll increased this fraction by only two orders of magnitude. Extraction of about 500 kilograms of underground rocks 60 days after the Hutch explosion recovered only about 10−7 of the total charge. The amount of transuranium elements in this 500-kg batch was only 30 times higher than in a 0.4 kg rock picked up 7 days after the test. This observation demonstrated the highly nonlinear dependence of the transuranium elements yield on the amount of retrieved radioactive rock. In order to accelerate sample collection after explosion, shafts were drilled at the site not after but before the test, so that explosion would expel radioactive material from the epicenter, through the shafts, to collecting volumes near the surface. This method was tried in the Anacostia and Kennebec tests and instantly provided hundreds kilograms of material, but with actinide concentration 3 times lower than in samples obtained after drilling; whereas such method could have been efficient in scientific studies of short-lived isotopes, it could not improve the overall collection efficiency of the produced actinides.
Although no new elements (apart from einsteinium and fermium) could be detected in the nuclear test debris, and the total yields of transuranium elements were disappointingly low, these tests did provide significantly higher amounts of rare heavy isotopes than previously available in laboratories. So 6 atoms of 257Fm could be recovered after the Hutch detonation. They were then used in the studies of thermal-neutron induced fission of 257Fm and in discovery of a new fermium isotope 258Fm. Also, the rare 250Cm isotope was synthesized in large quantities, which is very difficult to produce in nuclear reactors from its progenitor 249Cm – the half-life of 249Cm (64 minutes) is much too short for months-long reactor irradiations, but is very "long" on the explosion timescale.
Natural occurrence.
Because of the short half-life of all isotopes of fermium, any primordial fermium, that is fermium that could be present on the Earth during its formation, has decayed by now. Synthesis of fermium from naturally occurring actinides uranium and thorium in the Earth crust requires multiple neutron capture, which is an extremely unlikely event. Therefore, most fermium is produced on Earth in scientific laboratories, high-power nuclear reactors, or in nuclear weapons tests, and is present only within a few months from the time of the synthesis. The transuranic elements from americium to fermium did occur naturally in the natural nuclear fission reactor at Oklo, but no longer do so.
Chemistry.
The chemistry of fermium has only been studied in solution using tracer techniques, and no solid compounds have been prepared. Under normal conditions, fermium exists in solution as the Fm3+ ion, which has a hydration number of 16.9 and an acid dissociation constant of 1.6 (p"K"a = 3.8). Fm3+ forms complexes with a wide variety of organic ligands with hard donor atoms such as oxygen, and these complexes are usually more stable than those of the preceding actinides. It also forms anionic complexes with ligands such as chloride or nitrate and, again, these complexes appear to be more stable than those formed by einsteinium or californium. It is believed that the bonding in the complexes of the later actinides is mostly ionic in character: the Fm3+ ion is expected to be smaller than the preceding An3+ ions because of the higher effective nuclear charge of fermium, and hence fermium would be expected to form shorter and stronger metal–ligand bonds.
Fermium(III) can be fairly easily reduced to fermium(II), for example with samarium(II) chloride, with which fermium coprecipitates. The electrode potential has been estimated to be similar to that of the ytterbium(III)/(II) couple, or about −1.15 V with respect to the standard hydrogen electrode, a value which agrees with theoretical calculations. The Fm2+/Fm0 couple has an electrode potential of −2.37(10) V based on polarographic measurements.
Toxicity.
Although few people come in contact with fermium, the International Commission on Radiological Protection has set annual exposure limits for the two most stable isotopes. For fermium-253, the ingestion limit was set at 107 becquerels (1 Bq is equivalent to one decay per second), and the inhalation limit at 105 Bq; for fermium-257, at 105 Bq and 4000 Bq respectively.

</doc>
<doc id="10823" url="https://en.wikipedia.org/wiki?curid=10823" title="Frédéric Chopin">
Frédéric Chopin

[[File:Frédéric Chopin by Bisson, 1849.png|thumb|Photograph of Chopin by Bisson, 
Frédéric François Chopin (; ; 1 March 181017 October 1849), born Fryderyk Franciszek Chopin, was a Polish composer and a virtuoso pianist of the Romantic era, who wrote primarily for the solo piano. He gained and has maintained renown worldwide as one of the leading musicians of his era, whose "poetic genius was based on a professional technique that was without equal in his generation." Chopin was born in what was then the Duchy of Warsaw, and grew up in Warsaw, which after 1815 became part of Congress Poland. A child prodigy, he completed his musical education and composed his earlier works in Warsaw before leaving Poland at the age of 20, less than a month before the outbreak of the November 1830 Uprising.
At the age of 21 he settled in Paris. Thereafter, during the last 18 years of his life, he gave only some 30 public performances, preferring the more intimate atmosphere of the salon. He supported himself by selling his compositions and teaching piano, for which he was in high demand. Chopin formed a friendship with Franz Liszt and was admired by many of his musical contemporaries, including Robert Schumann. In 1835 he obtained French citizenship. After a failed engagement to Maria Wodzińska, from 1837 to 1847 he maintained an often troubled relationship with the French writer George Sand. A brief and unhappy visit to Majorca with Sand in 1838–39 was one of his most productive periods of composition. In his last years, he was financially supported by his admirer Jane Stirling, who also arranged for him to visit Scotland in 1848. Through most of his life, Chopin suffered from poor health. He died in Paris in 1849, probably of tuberculosis.
All of Chopin's compositions include the piano. Most are for solo piano, though he also wrote two piano concertos, a few chamber pieces, and some songs to Polish lyrics. His keyboard style is highly individual and often technically demanding; his own performances were noted for their nuance and sensitivity. Chopin invented the concept of instrumental ballade. His major piano works also include mazurkas, waltzes, nocturnes, polonaises, études, impromptus, scherzos, preludes and sonatas, some published only after his death. Influences on his compositional style include Polish folk music, the classical tradition of J. S. Bach, Mozart and Schubert, the music of all of whom he admired, as well as the Paris salons where he was a frequent guest. His innovations in style, musical form, and harmony, and his association of music with nationalism, were influential throughout and after the late Romantic period.
Chopin's music, his status as one of music's earliest superstars, his association (if only indirect) with political insurrection, his love life and his early death have made him a leading symbol of the Romantic era in the public consciousness. His works remain popular, and he has been the subject of numerous films and biographies of varying degrees of historical accuracy.
Life.
Childhood.
Fryderyk Chopin was born in Żelazowa Wola, 46 kilometres () west of Warsaw, in what was then the Duchy of Warsaw, a Polish state established by Napoleon. The parish baptismal record gives his birthday as 22 February 1810, and cites his given names in the Latin form "Fridericus Franciscus" (in Polish, he was "Fryderyk Franciszek"). However, the composer and his family used the birthdate 1 March, which is now generally accepted as the correct date.
Fryderyk's father, Nicolas Chopin, was a Frenchman from Lorraine who had emigrated to Poland in 1787 at the age of sixteen. Nicolas tutored children of the Polish aristocracy, and in 1806 married Justyna Krzyżanowska, a poor relative of the Skarbeks, one of the families for whom he worked. Fryderyk was baptized on Easter Sunday, 23 April 1810, in the same church where his parents had married, in Brochów. His eighteen-year-old godfather, for whom he was named, was Fryderyk Skarbek, a pupil of Nicolas Chopin. Fryderyk was the couple's second child and only son; he had an elder sister, Ludwika (1807–55), and two younger sisters, Izabela (1811–81) and Emilia (1812–27). Nicolas was devoted to his adopted homeland, and insisted on the use of the Polish language in the household.
In October 1810, six months after Fryderyk's birth, the family moved to Warsaw, where his father acquired a post teaching French at the Warsaw Lyceum, then housed in the Saxon Palace. Fryderyk lived with his family in the Palace grounds. The father played the flute and violin; the mother played the piano and gave lessons to boys in the boarding house that the Chopins kept. Chopin was of slight build, and even in early childhood was prone to illnesses.
Fryderyk may have had some piano instruction from his mother, but his first professional music tutor, from 1816 to 1821, was the Czech pianist Wojciech Żywny. His elder sister Ludwika also took lessons from Żywny, and occasionally played duets with her brother. It quickly became apparent that he was a child prodigy. By the age of seven Fryderyk had begun giving public concerts, and in 1817 he composed two polonaises, in G minor and B-flat major. His next work, a polonaise in A-flat major of 1821, dedicated to Żywny, is his earliest surviving musical manuscript.
In 1817 the Saxon Palace was requisitioned by Warsaw's Russian governor for military use, and the Warsaw Lyceum was reestablished in the Kazimierz Palace (today the rectorate of Warsaw University). Fryderyk and his family moved to a building, which still survives, adjacent to the Kazimierz Palace. During this period, Fryderyk was sometimes invited to the Belweder Palace as playmate to the son of the ruler of Russian Poland, Grand Duke Constantine; he played the piano for the Duke and composed a march for him. Julian Ursyn Niemcewicz, in his dramatic eclogue, ""Nasze Przebiegi"" ("Our Discourses", 1818), attested to "little Chopin's" popularity.
Education.
From September 1823 to 1826, Chopin attended the Warsaw Lyceum, where he received organ lessons from the Czech musician Wilhelm Würfel during his first year. In the autumn of 1826 he began a three-year course under the Silesian composer Józef Elsner at the Warsaw Conservatory, studying music theory, figured bass and composition. Throughout this period he continued to compose and to give recitals in concerts and salons in Warsaw. He was engaged by the inventors of a mechanical organ, the "eolomelodicon", and on this instrument in May 1825 he performed his own improvisation and part of a concerto by Moscheles. The success of this concert led to an invitation to give a similar recital on the instrument before Tsar Alexander I, who was visiting Warsaw; the Tsar presented him with a diamond ring. At a subsequent eolomelodicon concert on 10 June 1825, Chopin performed his Rondo Op. 1. This was the first of his works to be commercially published and earned him his first mention in the foreign press, when the Leipzig "Allgemeine Musikalische Zeitung" praised his "wealth of musical ideas".
During 1824–28 Chopin spent his vacations away from Warsaw, at a number of locales. In 1824 and 1825, at Szafarnia, he was a guest of Dominik Dziewanowski, the father of a schoolmate. Here for the first time he encountered Polish rural folk music. His letters home from Szafarnia (to which he gave the title "The Szafarnia Courier"), written in a very modern and lively Polish, amused his family with their spoofing of the Warsaw newspapers and demonstrated the youngster's literary gift.
In 1827, soon after the death of Chopin's youngest sister Emilia, the family moved from the Warsaw University building, adjacent to the Kazimierz Palace, to lodgings just across the street from the university, in the south annex of the Krasiński Palace on Krakowskie Przedmieście, where Chopin lived until he left Warsaw in 1830. Here his parents continued running their boarding house for male students; the Chopin Family Parlour ("Salonik Chopinów") became a museum in the 20th century. In 1829 the artist Ambroży Mieroszewski executed a set of portraits of Chopin family members, including the first known portrait of the composer.
Four boarders at his parents' apartments became Chopin's intimates: Tytus Woyciechowski, Jan Nepomucen Białobłocki, Jan Matuszyński and Julian Fontana; the latter two would become part of his Paris milieu. He was friendly with members of Warsaw's young artistic and intellectual world, including Fontana, Józef Bohdan Zaleski and Stefan Witwicki. He was also attracted to the singing student Konstancja Gładkowska. In letters to Woyciechowski, he indicated which of his works, and even which of their passages, were influenced by his fascination with her; his letter of 15 May 1830 revealed that the slow movement ("Larghetto") of his Piano Concerto No. 1 (in E minor) was secretly dedicated to her – "It should be like dreaming in beautiful springtime – by moonlight." His final Conservatory report (July 1829) read: "Chopin F., third-year student, exceptional talent, musical genius."
Travel and domestic success.
In September 1828 Chopin, while still a student, visited Berlin with a family friend, zoologist Feliks Jarocki, enjoying operas directed by Gaspare Spontini and attending concerts by Carl Friedrich Zelter, Felix Mendelssohn and other celebrities. On an 1829 return trip to Berlin, he was a guest of Prince Antoni Radziwiłł, governor of the Grand Duchy of Posen—himself an accomplished composer and aspiring cellist. For the prince and his pianist daughter Wanda, he composed his Introduction and Polonaise brillante in C major for cello and piano, Op. 3.
Back in Warsaw that year, Chopin heard Niccolò Paganini play the violin, and composed a set of variations, "Souvenir de Paganini". It may have been this experience which encouraged him to commence writing his first Études, (1829–32), exploring the capacities of his own instrument. On 11 August, three weeks after completing his studies at the Warsaw Conservatory, he made his debut in Vienna. He gave two piano concerts and received many favourable reviews—in addition to some commenting (in Chopin's own words) that he was "too delicate for those accustomed to the piano-bashing of local artists". In one of these concerts, he premiered his Variations on "Là ci darem la mano", Op. 2 (variations on an aria from Mozart's opera "Don Giovanni") for piano and orchestra. He returned to Warsaw in September 1829, where he premiered his Piano Concerto No. 2 in F minor, Op. 21 on 17 March 1830.
Chopin's successes as a composer and performer opened the door to western Europe for him, and on 2 November 1830, he set out, in the words of Zdzisław Jachimecki, "into the wide world, with no very clearly defined aim, forever." With Woyciechowski, he headed for Austria, intending to go on to Italy. Later that month, in Warsaw, the November 1830 Uprising broke out, and Woyciechowski returned to Poland to enlist. Chopin, now alone in Vienna, was nostalgic for his homeland, and wrote to a friend, "I curse the moment of my departure." When in September 1831 he learned, while travelling from Vienna to Paris, that the uprising had been crushed, he expressed his anguish in the pages of his private journal: "Oh God! ... You are there, and yet you do not take vengeance!" Jachimecki ascribes to these events the composer's maturing "into an inspired national bard who intuited the past, present and future of his native Poland."
Paris.
Chopin arrived in Paris in late September 1831; he would never return to Poland, thus becoming one of many expatriates of the Polish Great Emigration. In France he used the French versions of his given names, and after receiving French citizenship in 1835, he travelled on a French passport. However, Chopin remained close to his fellow Poles in exile as friends and confidants and he never felt fully comfortable speaking French. Chopin's biographer Adam Zamoyski writes that he never considered himself to be French, despite his father's French origins, and always saw himself as a Pole.
In Paris, Chopin encountered artists and other distinguished figures, and found many opportunities to exercise his talents and achieve celebrity. During his years in Paris he was to become acquainted with, among many others, Hector Berlioz, Franz Liszt, Ferdinand Hiller, Heinrich Heine, Eugène Delacroix, and Alfred de Vigny. Chopin was also acquainted with the poet Adam Mickiewicz, principal of the Polish Literary Society, some of whose verses he set as songs.
Two Polish friends in Paris were also to play important roles in Chopin's life there. His fellow student at the Warsaw Conservatory, Julian Fontana, had originally tried unsuccessfully to establish himself in England; Albert Grzymała, who in Paris became a wealthy financier and society figure, often acted as Chopin's adviser and "gradually began to fill the role of elder brother in life." Fontana was to become, in the words of Michałowski and Samson, Chopin's "general factotum and copyist".
At the end of 1831, Chopin received the first major endorsement from an outstanding contemporary when Robert Schumann, reviewing the Op. 2 Variations in the "Allgemeine musikalische Zeitung" (his first published article on music), declared: "Hats off, gentlemen! A genius." On 26 February 1832 Chopin gave a debut Paris concert at the Salle Pleyel which drew universal admiration. The critic François-Joseph Fétis wrote in the "Revue et gazette musicale": "Here is a young man who ... taking no model, has found, if not a complete renewal of piano music, ... an abundance of original ideas of a kind to be found nowhere else ..." After this concert, Chopin realized that his essentially intimate keyboard technique was not optimal for large concert spaces. Later that year he was introduced to the wealthy Rothschild banking family, whose patronage also opened doors for him to other private salons (social gatherings of the aristocracy and artistic and literary elite). By the end of 1832 Chopin had established himself among the Parisian musical elite, and had earned the respect of his peers such as Hiller, Liszt, and Berlioz. He no longer depended financially upon his father, and in the winter of 1832 he began earning a handsome income from publishing his works and teaching piano to affluent students from all over Europe. This freed him from the strains of public concert-giving, which he disliked.
Chopin seldom performed publicly in Paris. In later years he generally gave a single annual concert at the Salle Pleyel, a venue that seated three hundred. He played more frequently at salons, but preferred playing at his own Paris apartment for small groups of friends. The musicologist Arthur Hedley has observed that "As a pianist Chopin was unique in acquiring a reputation of the highest order on the basis of a minimum of public appearances—few more than thirty in the course of his lifetime." The list of musicians who took part in some of his concerts provides an indication of the richness of Parisian artistic life during this period. Examples include a concert on 23 March 1833, in which Chopin, Liszt and Hiller performed (on pianos) a concerto by J.S. Bach for three keyboards; and, on 3 March 1838, a concert in which Chopin, his pupil Adolphe Gutmann, Charles-Valentin Alkan, and Alkan's teacher Joseph Zimmermann performed Alkan's arrangement, for eight hands, of two movements from Beethoven's 7th symphony. Chopin was also involved in the composition of Liszt's "Hexameron"; he wrote the sixth (and final) variation on Bellini's theme. Chopin's music soon found success with publishers, and in 1833 he contracted with Maurice Schlesinger, who arranged for it to be published not only in France but, through his family connections, also in Germany and England.
In the spring of 1834, Chopin attended the Lower Rhenish Music Festival in Aix-la-Chapelle with Hiller, and it was there that Chopin met Felix Mendelssohn. After the festival, the three visited Düsseldorf, where Mendelssohn had been appointed musical director. They spent what Mendelssohn described as "a very agreeable day", playing and discussing music at his piano, and met Friedrich Wilhelm Schadow, director of the Academy of Art, and some of his eminent pupils such as Lessing, Bendemann, Hildebrandt and Sohn. In 1835 Chopin went to Carlsbad, where he spent time with his parents; it was the last time he would see them. On his way back to Paris, he met old friends from Warsaw, the Wodzińskis. He had made the acquaintance of their daughter Maria in Poland five years earlier, when she was eleven. This meeting prompted him to stay for two weeks in Dresden, when he had previously intended to return to Paris via Leipzig. The sixteen-year-old girl's portrait of the composer is considered, along with Delacroix's, as among Chopin's best likenesses. In October he finally reached Leipzig, where he met Schumann, Clara Wieck and Felix Mendelssohn, who organised for him a performance of his own oratorio "St. Paul", and who considered him "a perfect musician". In July 1836 Chopin travelled to Marienbad and Dresden to be with the Wodziński family, and in September he proposed to Maria, whose mother Countess Wodzińska approved in principle. Chopin went on to Leipzig, where he presented Schumann with his G minor Ballade. At the end of 1836 he sent Maria an album in which his sister Ludwika had inscribed seven of his songs, and his 1835 Nocturne in C-sharp minor, Op. 27, No. 1. The anodyne thanks he received from Maria proved to be the last letter he was to have from her.
Franz Liszt.
Although it is not known exactly when Chopin first met Liszt after arriving in Paris, on 12 December 1831 he mentioned in a letter to his friend Woyciechowski that "I have met Rossini, Cherubini, Baillot, etc.—also Kalkbrenner. You would not believe how curious I was about Herz, Liszt, Hiller, etc." Liszt was in attendance at Chopin's Parisian debut on 26 February 1832 at the Salle Pleyel, which led him to remark: "The most vigorous applause seemed not to suffice to our enthusiasm in the presence of this talented musician, who revealed a new phase of poetic sentiment combined with such happy innovation in the form of his art."
The two became friends, and for many years lived in close proximity in Paris, Chopin at 38 Rue de la Chaussée-d'Antin, and Liszt at the Hôtel de France on the Rue Lafitte, a few blocks away. They performed together on seven occasions between 1833 and 1841. The first, on 2 April 1833, was at a benefit concert organized by Hector Berlioz for his bankrupt Shakespearean actress wife Harriet Smithson, during which they played George Onslow's "Sonata in F minor" for piano duet. Later joint appearances included a benefit concert for the Benevolent Association of Polish Ladies in Paris. Their last appearance together in public was for a charity concert conducted for the Beethoven Memorial in Bonn, held at the Salle Pleyel and the Paris Conservatory on 25 and 26 April 1841.
Although the two displayed great respect and admiration for each other, their friendship was uneasy and had some qualities of a love-hate relationship. Harold C. Schonberg believes that Chopin displayed a "tinge of jealousy and spite" towards Liszt's virtuosity on the piano, and others have also argued that he had become enchanted with Liszt's theatricality, showmanship and success. Liszt was the dedicatee of Chopin's Op. 10 Études, and his performance of them prompted the composer to write to Hiller, "I should like to rob him of the way he plays my studies." However, Chopin expressed annoyance in 1843 when Liszt performed one of his nocturnes with the addition of numerous intricate embellishments, at which Chopin remarked that he should play the music as written or not play it at all, forcing an apology. Most biographers of Chopin state that after this the two had little to do with each other, although in his letters dated as late as 1848 he still referred to him as "my friend Liszt". Some commentators point to events in the two men's romantic lives which led to a rift between them; there are claims that Liszt had displayed jealousy of his mistress Marie d'Agoult's obsession with Chopin, while others believe that Chopin had become concerned about Liszt's growing relationship with George Sand.
George Sand.
In 1836, at a party hosted by Marie d'Agoult, Chopin met the French author George Sand (born Aurore [Lucile Dupin). Short (under five feet, or 152 cm), dark, big-eyed and a cigar smoker, she initially repelled Chopin, who remarked, "What an unattractive person "la Sand" is. Is she really a woman?" However, by early 1837 Maria Wodzińska's mother had made it clear to Chopin in correspondence that a marriage with her daughter was unlikely to proceed. It is thought that she was influenced by his poor health and possibly also by rumours about his associations with women such as d'Agoult and Sand. Chopin finally placed the letters from Maria and her mother in a package on which he wrote, in Polish, "My tragedy". Sand, in a letter to Grzymała of June 1838, admitted strong feelings for the composer and debated whether to abandon a current affair in order to begin a relationship with Chopin; she asked Grzymała to assess Chopin's relationship with Maria Wodzińska, without realising that the affair, at least from Maria's side, was over.
In June 1837 Chopin visited London incognito in the company of the piano manufacturer Camille Pleyel where he played at a musical soirée at the house of English piano maker James Broadwood. On his return to Paris, his association with Sand began in earnest, and by the end of June 1838 they had become lovers. Sand, who was six years older than the composer, and who had had a series of lovers, wrote at this time: "I must say I was confused and amazed at the effect this little creature had on me ... I have still not recovered from my astonishment, and if I were a proud person I should be feeling humiliated at having been carried away ..." The two spent a miserable winter on Majorca (8 November 1838 to 13 February 1839), where, together with Sand's two children, they had journeyed in the hope of improving the health of Chopin and that of Sand's 15-year-old son Maurice, and also to escape the threats of Sand's former lover Félicien Mallefille. After discovering that the couple were not married, the deeply traditional Catholic people of Majorca became inhospitable, making accommodation difficult to find. This compelled the group to take lodgings in a former Carthusian monastery in Valldemossa, which gave little shelter from the cold winter weather.
On 3 December, Chopin complained about his bad health and the incompetence of the doctors in Majorca: "Three doctors have visited me ... The first said I was dead; the second said I was dying; and the third said I was about to die." He also had problems having his Pleyel piano sent to him. It finally arrived from Paris in December. Chopin wrote to Pleyel in January 1839: "I am sending you my Preludes [(Op. 28)]. I finished them on your little piano, which arrived in the best possible condition in spite of the sea, the bad weather and the Palma customs." Chopin was also able to undertake work on his Ballade No. 2, Op. 38; two Polonaises, Op. 40; and the Scherzo No. 3, Op. 39.
Although this period had been productive, the bad weather had such a detrimental effect on Chopin's health that Sand determined to leave the island. To avoid further customs duties, Sand sold the piano to a local French couple, the Canuts. The group traveled first to Barcelona, then to Marseilles, where they stayed for a few months while Chopin convalesced. In May 1839 they headed for the summer to Sand's estate at Nohant, where they spent most summers until 1846. In autumn they returned to Paris, where Chopin's apartment at 5 rue Tronchet was close to Sand's rented accommodation at the rue Pigalle. He frequently visited Sand in the evenings, but both retained some independence. In 1842 he and Sand moved to the Square d'Orléans, living in adjacent buildings.
At the funeral of the tenor Adolphe Nourrit in Paris in 1839, Chopin made a rare appearance at the organ, playing a transcription of Franz Schubert's "lied" "Die Gestirne". On 26 July 1840 Chopin and Sand were present at the dress rehearsal of Berlioz's "Grande symphonie funèbre et triomphale", composed to commemorate the tenth anniversary of the July Revolution. Chopin was reportedly unimpressed with the composition.
During the summers at Nohant, particularly in the years 1839–43, Chopin found quiet, productive days during which he composed many works, including his Polonaise in A-flat major, Op. 53. Among the visitors to Nohant were Delacroix and the mezzo-soprano Pauline Viardot, whom Chopin had advised on piano technique and composition. Delacroix gives an account of staying at Nohant in a letter of 7 June 1842:
The hosts could not be more pleasant in entertaining me. When we are not all together at dinner, lunch, playing billiards, or walking, each of us stays in his room, reading or lounging around on a couch. Sometimes, through the window which opens on the garden, a gust of music wafts up from Chopin at work. All this mingles with the songs of nightingales and the fragrance of roses.
Decline.
From 1842 onwards, Chopin showed signs of serious illness. After a solo recital in Paris on 21 February 1842, he wrote to Grzymała: "I have to lie in bed all day long, my mouth and tonsils are aching so much." He was forced by illness to decline a written invitation from Alkan to participate in a repeat performance of the Beethoven Seventh Symphony arrangement at Erard's on 1 March 1843. Late in 1844, Charles Hallé visited Chopin and found him "hardly able to move, bent like a half-opened penknife and evidently in great pain", although his spirits returned when he started to play the piano for his visitor. Chopin's health continued to deteriorate, particularly from this time onwards. Modern research suggests that apart from any other illnesses, he may also have suffered from temporal lobe epilepsy.
Chopin's relations with Sand were soured in 1846 by problems involving her daughter Solange and Solange's fiancé, the young fortune-hunting sculptor Auguste Clésinger. The composer frequently took Solange's side in quarrels with her mother; he also faced jealousy from Sand's son Maurice. Chopin was utterly indifferent to Sand's radical political pursuits, while Sand looked on his society friends with disdain. As the composer's illness progressed, Sand had become less of a lover and more of a nurse to Chopin, whom she called her "third child". In letters to third parties, she vented her impatience, referring to him as a "child," a "little angel", a "sufferer" and a "beloved little corpse." In 1847 Sand published her novel "Lucrezia Floriani", whose main characters—a rich actress and a prince in weak health—could be interpreted as Sand and Chopin; the story was uncomplimentary to Chopin, who could not have missed the allusions as he helped Sand correct the printer's galleys. In 1847 he did not visit Nohant, and he quietly ended their ten-year relationship following an angry correspondence which, in Sand's words, made "a strange conclusion to nine years of exclusive friendship." The two would never meet again.
Chopin's output as a composer throughout this period declined in quantity year by year. Whereas in 1841 he had written a dozen works, only six were written in 1842 and six shorter pieces in 1843. In 1844 he wrote only the Op. 58 sonata. 1845 saw the completion of three mazurkas (Op. 59). Although these works were more refined than many of his earlier compositions, Zamoyski opines that "his powers of concentration were failing and his inspiration was beset by anguish, both emotional and intellectual."
Tour of England and Scotland.
Chopin's public popularity as a virtuoso began to wane, as did the number of his pupils, and this, together with the political strife and instability of the time, caused him to struggle financially. In February 1848, with the cellist Auguste Franchomme, he gave his last Paris concert, which included three movements of the Cello Sonata Op. 65.
In April, during the Revolution of 1848 in Paris, he left for London, where he performed at several concerts and at numerous receptions in great houses. This tour was suggested to him by his Scottish pupil Jane Stirling and her elder sister. Stirling also made all the logistical arrangements and provided much of the necessary funding.
In London Chopin took lodgings at Dover Street, where the firm of Broadwood provided him with a grand piano. At his first engagement, on 15 May at Stafford House, the audience included Queen Victoria and Prince Albert. The Prince, who was himself a talented musician, moved close to the keyboard to view Chopin's technique. Broadwood also arranged concerts for him; among those attending were Thackeray and the singer Jenny Lind. Chopin was also sought after for piano lessons, for which he charged the high fee of one guinea (£1.05 in present British currency) per hour, and for private recitals for which the fee was 20 guineas. At a concert on 7 July he shared the platform with Viardot, who sang arrangements of some of his mazurkas to Spanish texts. On 28 August, he played at a concert in Manchester's Concert Hall, sharing the stage with Marietta Alboni and Lorenzo Salvi.
In late summer he was invited by Jane Stirling to visit Scotland, where he stayed at Calder House near Edinburgh and at Johnstone Castle in Renfrewshire, both owned by members of Stirling's family. She clearly had a notion of going beyond mere friendship, and Chopin was obliged to make it clear to her that this could not be so. He wrote at this time to Grzymała "My Scottish ladies are kind, but such bores", and responding to a rumour about his involvement, answered that he was "closer to the grave than the nuptial bed." He gave a public concert in Glasgow on 27 September, and another in Edinburgh, at the Hopetoun Rooms on Queen Street (now Erskine House) on 4 October. In late October 1848, while staying at 10 Warriston Crescent in Edinburgh with the Polish physician Adam Łyszczyński, he wrote out his last will and testament—"a kind of disposition to be made of my stuff in the future, if I should drop dead somewhere", he wrote to Grzymała.
Chopin made his last public appearance on a concert platform at London's Guildhall on 16 November 1848, when, in a final patriotic gesture, he played for the benefit of Polish refugees. By this time he was very seriously ill, weighing under 99 pounds (i.e. less than 45 kg), and his doctors were aware that his sickness was at a terminal stage.
At the end of November, Chopin returned to Paris. He passed the winter in unremitting illness, but gave occasional lessons and was visited by friends, including Delacroix and Franchomme. Occasionally he played, or accompanied the singing of Delfina Potocka, for his friends. During the summer of 1849, his friends found him an apartment in Chaillot, out of the centre of the city, for which the rent was secretly subsidised by an admirer, Princess Obreskoff. Here in June 1849 he was visited by Jenny Lind.
Death and funeral.
With his health further deteriorating, Chopin desired to have a family member with him. In June 1849 his sister Ludwika came to Paris with her husband and daughter, and in September, supported by a loan from Jane Stirling, he took an apartment at Place Vendôme 12. After 15 October, when his condition took a marked turn for the worse, only a handful of his closest friends remained with him, although Viardot remarked sardonically that "all the grand Parisian ladies considered it "de rigueur" to faint in his room."
Some of his friends provided music at his request; among them, Potocka sang and Franchomme played the cello. Chopin requested that his body be opened after death (for fear of being buried alive) and his heart returned to Warsaw where it rests at the Church of the Holy Cross. He also bequeathed his unfinished notes on a piano tuition method, "Projet de méthode", to Alkan for completion. On 17 October, after midnight, the physician leaned over him and asked whether he was suffering greatly. "No longer", he replied. He died a few minutes before two o'clock in the morning. Those present at the deathbed appear to have included his sister Ludwika, Princess Marcelina Czartoryska, Sand's daughter Solange, and his close friend Thomas Albrecht. Later that morning, Solange's husband Clésinger made Chopin's death mask and a cast of his left hand.
Chopin's disease and the cause of his death have since been a matter of discussion. His death certificate gave the cause as tuberculosis, and his physician, Jean Cruveilhier, was then the leading French authority on this disease. Other possibilities have been advanced including cystic fibrosis, cirrhosis and alpha 1-antitrypsin deficiency. However, the attribution of tuberculosis as principal cause of death has not been disproved. Permission for DNA testing, which could put the matter to rest, has been denied by the Polish government.
The funeral, held at the Church of the Madeleine in Paris, was delayed almost two weeks, until 30 October. Entrance was restricted to ticket holders as many people were expected to attend. Over 3,000 people arrived without invitations, from as far as London, Berlin and Vienna, and were excluded.
Mozart's Requiem was sung at the funeral; the soloists were the soprano Jeanne-Anais Castellan, the mezzo-soprano Pauline Viardot, the tenor Alexis Dupont, and the bass Luigi Lablache; Chopin's Preludes No. 4 in E minor and No. 6 in B minor were also played. The organist at the funeral was Louis Lefébure-Wély. The funeral procession to Père Lachaise Cemetery, which included Chopin's sister Ludwika, was led by the aged Prince Adam Czartoryski. The pallbearers included Delacroix, Franchomme, and Camille Pleyel. At the graveside, the "Funeral March" from Chopin's Piano Sonata No. 2 was played, in Reber's instrumentation.
Chopin's tombstone, featuring the muse of music, Euterpe, weeping over a broken lyre, was designed and sculpted by Clésinger. The expenses of the funeral and monument, amounting to 5,000 francs, were covered by Jane Stirling, who also paid for the return of the composer's sister Ludwika to Warsaw. Ludwika took Chopin's heart in an urn, preserved in alcohol, back to Poland in 1850. She also took a collection of two hundred letters from Sand to Chopin; after 1851 these were returned to Sand, who seems to have destroyed them.
Music.
Overview.
Over 230 works of Chopin survive; some compositions from early childhood have been lost. All his known works involve the piano, and only a few range beyond solo piano music, as either piano concertos, songs or chamber music.
Chopin was educated in the tradition of Beethoven, Haydn, Mozart and Clementi; he used Clementi's piano method with his own students. He was also influenced by Hummel's development of virtuoso, yet Mozartian, piano technique. He cited Bach and Mozart as the two most important composers in shaping his musical outlook. Chopin's early works are in the style of the "brilliant" keyboard pieces of his era as exemplified by the works of Ignaz Moscheles, Friedrich Kalkbrenner, and others. Less direct in the earlier period are the influences of Polish folk music and of Italian opera. Much of what became his typical style of ornamentation (for example, his "fioriture") is taken from singing. His melodic lines were increasingly reminiscent of the modes and features of the music of his native country, such as drones.
Chopin took the new salon genre of the nocturne, invented by the Irish composer John Field, to a deeper level of sophistication. He was the first to write ballades and scherzi as individual concert pieces. He essentially established a new genre with his own set of free-standing preludes (Op. 28, published 1839). He exploited the poetic potential of the concept of the concert étude, already being developed in the 1820s and 1830s by Liszt, Clementi and Moscheles, in his two sets of studies (Op. 10 published in 1833, Op. 25 in 1837).
Chopin also endowed popular dance forms with a greater range of melody and expression. Chopin's mazurkas, while originating in the traditional Polish dance (the "mazurek"), differed from the traditional variety in that they were written for the concert hall rather than the dance hall; "it was Chopin who put the mazurka on the European musical map." The series of seven polonaises published in his lifetime (another nine were published posthumously), beginning with the Op. 26 pair (published 1836), set a new standard for music in the form. His waltzes were also written specifically for the salon recital rather than the ballroom and are frequently at rather faster tempos than their dance-floor equivalents.
Titles, opus numbers and editions.
Some of Chopin's well-known pieces have acquired descriptive titles, such as the "Revolutionary" Étude (Op. 10, No. 12), and the "Minute Waltz" (Op. 64, No. 1). However, with the exception of his "Funeral March", the composer never named an instrumental work beyond genre and number, leaving all potential extramusical associations to the listener; the names by which many of his pieces are known were invented by others. There is no evidence to suggest that the "Revolutionary" Étude was written with the failed Polish uprising against Russia in mind; it merely appeared at that time. The "Funeral March", the third movement of his Sonata No. 2 (Op. 35), the one case where he did give a title, was written before the rest of the sonata, but no specific event or death is known to have inspired it.
The last opus number that Chopin himself used was 65, allocated to the Cello Sonata in G minor. He expressed a deathbed wish that all his unpublished manuscripts be destroyed. At the request of the composer's mother and sisters, however, his musical executor Julian Fontana selected 23 unpublished piano pieces and grouped them into eight further opus numbers (Opp. 66–73), published in 1855. In 1857, 17 Polish songs that Chopin wrote at various stages of his life were collected and published as Op. 74, though their order within the opus did not reflect the order of composition.
Works published since 1857 have received alternative catalogue designations instead of opus numbers. The present standard musicological reference for Chopin's works is the Kobylańska Catalogue (usually represented by the initials 'KK'), named for its compiler, the Polish musicologist Krystyna Kobylańska.
Chopin's original publishers included Maurice Schlesinger and Camille Pleyel. His works soon began to appear in popular 19th-century piano anthologies. The first collected edition was by Breitkopf & Härtel (1878–1902). Among modern scholarly editions of Chopin's works are the version under the name of Paderewski published between 1937 and 1966 and the more recent Polish "National Edition", edited by Jan Ekier, both of which contain detailed explanations and discussions regarding choices and sources.
Form and harmony.
Improvisation stands at the centre of Chopin's creative processes. However, this does not imply impulsive rambling: Nicholas Temperley writes that "improvisation is designed for an audience, and its starting-point is that audience's expectations, which include the current conventions of musical form." The works for piano and orchestra, including the two concertos, are held by Temperley to be "merely vehicles for brilliant piano playing ... formally longwinded and extremely conservative". After the piano concertos (which are both early, dating from 1830), Chopin made no attempts at large-scale multi-movement forms, save for his late sonatas for piano and for cello; "instead he achieved near-perfection in pieces of simple general design but subtle and complex cell-structure." Rosen suggests that an important aspect of Chopin's individuality is his flexible handling of the four-bar phrase as a structural unit.
J. Barrie Jones suggests that "amongst the works that Chopin intended for concert use, the four ballades and four scherzos stand supreme", and adds that "the Barcarolle Op. 60 stands apart as an example of Chopin's rich harmonic palette coupled with an Italianate warmth of melody." Temperley opines that these works, which contain "immense variety of mood, thematic material and structural detail", are based on an extended "departure and return" form; "the more the middle section is extended, and the further it departs in key, mood and theme, from the opening idea, the more important and dramatic is the reprise when it at last comes."
Chopin's mazurkas and waltzes are all in straightforward ternary or episodic form, sometimes with a coda. The mazurkas often show more folk features than many of his other works, sometimes including modal scales and harmonies and the use of drone basses. However, some also show unusual sophistication, for example Op. 63 No. 3, which includes a canon at one beat's distance, a great rarity in music.
Chopin's polonaises show a marked advance on those of his Polish predecessors in the form (who included his teachers Zywny and Elsner). As with the traditional polonaise, Chopin's works are in triple time and typically display a martial rhythm in their melodies, accompaniments and cadences. Unlike most of their precursors, they also require a formidable playing technique.
The 21 nocturnes are more structured, and of greater emotional depth, than those of Field (whom Chopin met in 1833). Many of the Chopin nocturnes have middle sections marked by agitated expression (and often making very difficult demands on the performer) which heightens their dramatic character.
Chopin's études are largely in straightforward ternary form. He used them to teach his own technique of piano playing—for instance playing double thirds (Op. 25, No. 6), playing in octaves (Op. 25, No. 10), and playing repeated notes (Op. 10, No.  7).
The preludes, many of which are very brief (some consisting of simple statements and developments of a single theme or figure), were described by Schumann as "the beginnings of studies". Inspired by J.S. Bach's "The Well-Tempered Clavier", Chopin's preludes move up the circle of fifths (rather than Bach's chromatic scale sequence) to create a prelude in each major and minor tonality. The preludes were perhaps not intended to be played as a group, and may even have been used by him and later pianists as generic preludes to others of his pieces, or even to music by other composers, as Kenneth Hamilton suggests: he has noted a recording by Ferruccio Busoni of 1922, in which the Prelude Op. 28 No. 7 is followed by the Étude Op. 10 No. 5.
The two mature piano sonatas (No. 2, Op. 35, written in 1839 and No. 3, Op. 58, written in 1844) are in four movements. In Op. 35, Chopin was able to combine within a formal large musical structure many elements of his virtuosic piano technique—"a kind of dialogue between the public pianism of the brilliant style and the German sonata principle". The last movement, a brief (75-bar) perpetuum mobile in which the hands play in unmodified octave unison throughout, was found shocking and unmusical by contemporaries, including Schumann. The Op. 58 sonata is closer to the German tradition, including many passages of complex counterpoint, "worthy of Brahms" according to the music historians Kornel Michałowski and Jim Samson.
Chopin's harmonic innovations may have arisen partly from his keyboard improvisation technique. Temperley says that in his works "novel harmonic effects frequently result from the combination of ordinary appoggiaturas or passing notes with melodic figures of accompaniment", and cadences are delayed by the use of chords outside the home key (neapolitan sixths and diminished sevenths), or by sudden shifts to remote keys. Chord progressions sometimes anticipate the shifting tonality of later composers such as Claude Debussy, as does Chopin's use of modal harmony.
Technique and performance style.
In 1841, Léon Escudier wrote of a recital given by Chopin that year, "One may say that Chopin is the creator of a school of piano and a school of composition. In truth, nothing equals the lightness, the sweetness with which the composer preludes on the piano; moreover nothing may be compared to his works full of originality, distinction and grace." Chopin refused to conform to a standard method of playing and believed that there was no set technique for playing well. His style was based extensively on his use of very independent finger technique. In his "Projet de méthode" he wrote: "Everything is a matter of knowing good fingering ... we need no less to use the rest of the hand, the wrist, the forearm and the upper arm." He further stated: "One needs only to study a certain position of the hand in relation to the keys to obtain with ease the most beautiful quality of sound, to know how to play short notes and long notes, and attain unlimited dexterity." The consequences of this approach to technique in Chopin's music include the frequent use of the entire range of the keyboard, passages in double octaves and other chord groupings, swiftly repeated notes, the use of grace notes, and the use of contrasting rhythms (four against three, for example) between the hands.
Jonathan Bellman writes that modern concert performance style—set in the "conservatory" tradition of late 19th- and 20th-century music schools, and suitable for large auditoria or recordings—militates against what is known of Chopin's more intimate performance technique. The composer himself said to a pupil that "concerts are never real music, you have to give up the idea of hearing in them all the most beautiful things of art." Contemporary accounts indicate that in performance, Chopin avoided rigid procedures sometimes incorrectly attributed to him, such as "always crescendo to a high note", but that he was concerned with expressive phrasing, rhythmic consistency and sensitive colouring. Berlioz wrote in 1853 that Chopin "has created a kind of chromatic embroidery ... whose effect is so strange and piquant as to be impossible to describe ... virtually nobody but Chopin himself can play this music and give it this unusual turn". Hiller wrote that "What in the hands of others was elegant embellishment, in his hands became a colourful wreath of flowers."
Chopin's music is frequently played with "rubato", "the practice in performance of disregarding strict time, 'robbing' some note-values for expressive effect". There are differing opinions as to how much, and what type, of "rubato" is appropriate for his works. Charles Rosen comments that "most of the written-out indications of rubato in Chopin are to be found in his mazurkas ... It is probable that Chopin used the older form of rubato so important to Mozart ... the melody note in the right hand is delayed until after the note in the bass ... An allied form of this rubato is the arpeggiation of the chords thereby delaying the melody note; according to Chopin's pupil, Karol Mikuli, Chopin was firmly opposed to this practice."
Friederike Müller, a pupil of Chopin, wrote: " playing was always noble and beautiful; his tones sang, whether in full "forte" or softest "piano". He took infinite pains to teach his pupils this "legato", "cantabile" style of playing. His most severe criticism was 'He—or she—does not know how to join two notes together.' He also demanded the strictest adherence to rhythm. He hated all lingering and dragging, misplaced "rubatos", as well as exaggerated "ritardandos" ... and it is precisely in this respect that people make such terrible errors in playing his works."
Polish heritage.
With his mazurkas and polonaises, Chopin has been credited with introducing to music a new sense of nationalism. Schumann, in his 1836 review of the piano concertos, highlighted the composer's strong feelings for his native Poland, writing that "Now that the Poles are in deep mourning the failure of the November 1830 rising, their appeal to us artists is even stronger ... If the mighty autocrat in the north Nicholas I of Russia could know that in Chopin's works, in the simple strains of his mazurkas, there lurks a dangerous enemy, he would place a ban on his music. Chopin's works are cannon buried in flowers!" The biography of Chopin published in 1863 under the name of Franz Liszt (but probably written by Carolyne zu Sayn-Wittgenstein) claims that Chopin "must be ranked first among the first musicians ... individualizing in themselves the poetic sense of an entire nation."
Some modern commentators have argued against exaggerating Chopin's primacy as a "nationalist" or "patriotic" composer. George Golos refers to earlier "nationalist" composers in Central Europe, including Poland's Michał Kleofas Ogiński and Franciszek Lessel, who utilised polonaise and mazurka forms. Barbara Milewski suggests that Chopin's experience of Polish music came more from "urbanised" Warsaw versions than from folk music, and that attempts (by Jachimecki and others) to demonstrate genuine folk music in his works are without basis. Richard Taruskin impugns Schumann's attitude toward Chopin's works as patronizing and comments that Chopin "felt his Polish patriotism deeply and sincerely" but consciously modelled his works on the tradition of Bach, Beethoven, Schubert and Field.
A reconciliation of these views is suggested by William Atwood: "Undoubtedly use of traditional musical forms like the polonaise and mazurka roused nationalistic sentiments and a sense of cohesiveness amongst those Poles scattered across Europe and the New World ... While some sought solace in [them, others found them a source of strength in their continuing struggle for freedom. Although Chopin's music undoubtedly came to him intuitively rather than through any conscious patriotic design, it served all the same to symbolize the will of the Polish people ..."
Classical pianist Yuja Wang describes Chopin's music as "national, yet universal."
Reception and influence.
Jones comments that "Chopin's unique position as a composer, despite the fact that virtually everything he wrote was for the piano, has rarely been questioned." He also notes that Chopin was fortunate to arrive in Paris in 1831—"the artistic environment, the publishers who were willing to print his music, the wealthy and aristocratic who paid what Chopin asked for their lessons"—and these factors, as well as his musical genius, also fuelled his contemporary and later reputation. While his illness and his love-affairs conform to some of the stereotypes of romanticism, the rarity of his public recitals (as opposed to performances at fashionable Paris soirées) led Arthur Hutchings to suggest that "his lack of Byronic flamboyance his aristocratic reclusiveness make him exceptional" among his romantic contemporaries, such as Liszt and Henri Herz.
Chopin's qualities as a pianist and composer were recognized by many of his fellow musicians. Schumann named a piece for him in his suite "Carnaval", and Chopin later dedicated his Ballade No. 2 in F major to Schumann. Elements of Chopin's music can be traced in many of Liszt's later works. Liszt later transcribed for piano six of Chopin's Polish songs. A less fraught friendship was with Alkan, with whom he discussed elements of folk music, and who was deeply affected by Chopin's death.
Two of Chopin's long-standing pupils, Karol Mikuli (1821–1897) and Georges Mathias, were themselves piano teachers and passed on details of his playing to their own students, some of whom (such as Raoul Koczalski) were to make recordings of his music. Other pianists and composers influenced by Chopin's style include Louis Moreau Gottschalk, Édouard Wolff (1816–1880) and Pierre Zimmermann. Debussy dedicated his own 1915 piano Études to the memory of Chopin; he frequently played Chopin's music during his studies at the Paris Conservatoire, and undertook the editing of Chopin's piano music for the publisher Jacques Durand.
Polish composers of the following generation included virtuosi such as Moritz Moszkowski, but, in the opinion of J. Barrie Jones, his "one worthy successor" among his compatriots was Karol Szymanowski (1882–1937). Edvard Grieg, Antonín Dvořák, Isaac Albéniz, Pyotr Ilyich Tchaikovsky and Sergei Rachmaninoff, among others, are regarded by critics as having been influenced by Chopin's use of national modes and idioms. Alexander Scriabin was devoted to the music of Chopin, and his early published works include nineteen mazurkas, as well as numerous études and preludes; his teacher Nikolai Zverev drilled him in Chopin's works to improve his virtuosity as a performer. In the 20th century, composers who paid homage to (or in some cases parodied) the music of Chopin included George Crumb, Bohuslav Martinů, Darius Milhaud,
Igor Stravinsky and Heitor Villa-Lobos.
Chopin's music was used in the 1909 ballet "Chopiniana", choreographed by Michel Fokine and orchestrated by Alexander Glazunov. Sergei Diaghilev commissioned additional orchestrations—from Stravinsky, Anatoly Lyadov, Sergei Taneyev and Nikolai Tcherepnin—for later productions, which used the title "Les Sylphides".
Chopin's music remains very popular and is regularly performed, recorded and broadcast worldwide. The world's oldest monographic music competition, the International Chopin Piano Competition, founded in 1927, is held every five years in Warsaw. The Fryderyk Chopin Institute of Poland lists on its website over eighty societies world-wide devoted to the composer and his music. The Institute site also lists nearly 1,500 performances of Chopin works on YouTube as of January 2014.
Recordings.
The British Library notes that "Chopin's works have been recorded by all the great pianists of the recording era." The earliest recording was an 1895 performance by Paul Pabst of the Nocturne in E major Op. 62 No. 2. The British Library site makes available a number of historic recordings, including some by Alfred Cortot, Ignaz Friedman, Vladimir Horowitz, Benno Moiseiwitsch, Ignacy Jan Paderewski, Arthur Rubinstein, Xaver Scharwenka and many others. A select discography of recordings of Chopin works by pianists representing the various pedagogic traditions stemming from Chopin is given by Methuen-Campbell in his work tracing the lineage and character of those traditions.
Numerous recordings of Chopin's works are available. On the occasion of the composer's bicentenary, the critics of "The New York Times" recommended performances by the following contemporary pianists (among many others): Martha Argerich, Vladimir Ashkenazy, Emanuel Ax, Evgeny Kissin, Murray Perahia, Maurizio Pollini and Krystian Zimerman. The Warsaw Chopin Society organizes the "Grand prix du disque de F. Chopin" for notable Chopin recordings, held every five years.
In literature, stage, film and television.
Chopin has figured extensively in Polish literature, both in serious critical studies of his life and music and in fictional treatments. The earliest manifestation was probably an 1830 sonnet on Chopin by Leon Ulrich. French writers on Chopin (apart from Sand) have included Marcel Proust and André Gide; and he has also featured in works of Gottfried Benn and Boris Pasternak. There are numerous biographies of Chopin in English (see bibliography for some of these).
Possibly the first venture into fictional treatments of Chopin's life was a fanciful operatic version of some of its events. "Chopin" was written by Giacomo Orefice and produced in Milan in 1901. All the music is derived from that of Chopin.
Chopin's life and his relations with George Sand have been fictionalized in numerous films. The 1945 biographical film "A Song to Remember" earned Cornel Wilde an Academy Award nomination as Best Actor for his portrayal of the composer. Other film treatments have included: "La valse de l'adieu" (France, 1928) by Henry Roussel, with Pierre Blanchar as Chopin; "Impromptu" (1991), starring Hugh Grant as Chopin; "La note bleue" (1991); and "" (2002).
Chopin's life was covered in a BBC TV documentary "Chopin – The Women Behind The Music" (2010), and in a 2010 documentary realised by Angelo Bozzolini and Roberto Prosseda for Italian television.
References.
Notes
Citations
Bibliography
External links.
Music scores

</doc>
<doc id="10825" url="https://en.wikipedia.org/wiki?curid=10825" title="Free Democratic Party (Germany)">
Free Democratic Party (Germany)

The Free Democratic Party (, FDP) is a liberal and classical liberal political party in Germany. The FDP is led by Christian Lindner.
The FDP was founded in 1948 by members of the former liberal political parties existing in Germany before World War II, the German Democratic Party and the German People's Party. For most of the Federal Republic's history, it has held the balance of power in the Bundestag. It was a junior coalition partner to either the CDU/CSU (1949–56, 1961–66, 1982–98, and 2009–13) or the Social Democratic Party of Germany (1969–82). However, in the 2013 federal election the FDP failed to win any directly elected seats in the Bundestag, and came up short of the 5 percent threshold to qualify for list representation. The FDP was therefore left without representation in the Bundestag for the first time in its history.
The FDP strongly supports human rights, civil liberties, and internationalism. The party is traditionally considered centre-right, but it has shifted to the centre according to polls in recent years. Since the 1980s, the party has firmly pushed economic liberalism, and has aligned itself closely to the promotion of free markets and privatisation. iIt is a member of the Liberal International and Alliance of Liberals and Democrats for Europe (ALDE).
Currently the FDP is represented in eight state parliaments and in the European Parliament.
History.
Soon after World War II, the Soviet Union forced the creation of political parties. In July 1945 William Kulice and Eugen Schiffer called for the establishment of a pan-German Party, whose constitution the Allies hesitantly approved only in the Soviet occupation zone as the Liberal Democratic Party of Germany. In September 1945, citizens in Hamburg established the Party of Free Democrats (PFD) as a bourgeois Left Party and the first Liberal Party in the Western zones. In the first state elections in Hamburg in October 1946 the party won 18.2 percent of the vote. The FDP secured between 7.8 and 29.9 percent of the 1946 vote in Greater Berlin (East) and Saxony, the only states in Soviet-occupied territories that held free parliamentary elections. However, it had to support the policies of the Socialist Unity Party of Germany (SED) and join the National Front of the GDR as a "bloc party".Following the FDP's success, liberal parties were founded across the states. The FDP won Hesse's 1950 state election with 31.8 percent, the best result in its history, through appealing to East Germans displaced by the war by including them on their ticket.
Founding of the party.
The Democratic Party of Germany (DPD) was established in Rothenburg ob der Tauber on 17 March 1947 as a pan-German Party. Its leaders were Theodor Heuss and Wilhelm Külz. However, the project failed as a result of disputes over Külz's political direction.
The Free Democratic Party was established on 11–12 December 1948 in Heppenheim, in Hesse, as an association of all 13 regional liberal party organizations in the three Western zones of occupation. The proposed name, Liberal Democratic Party (LDP), was rejected by the delegates, who voted 64 to 25 in favour of the name Free Democratic Party (FDP).
The party's first chairman was Theodor Heuss; his deputy was Franz Blücher. The place for the party's foundation was chosen deliberately: it was at the Heppenheim Assembly that the moderate liberals had met in October 1847 before the March Revolution. 
Some regard the "Heppenheim Assembly", which was held at the "Halber Mond" (Half Moon) Hotel on 10 October 1847, as a meeting of leading liberals that was the beginning of the German Revolution of 1848-49.
Up to the 1950s, several of the FDP's regional organizations were to the right of the CDU/CSU, which initially had ideas of some sort of Christian socialism, and even former office-holders of the Third Reich were courted with national, patriotic values.
The FDP was founded on 11 December 1948 through the merger of nine regional liberal parties formed in 1945 from the remnants of the pre-1933 German People's Party (DVP) and the German Democratic Party (DDP), which had been active in the Weimar Republic. The FDP's first Chairman, Theodor Heuss, was formerly a member of the DDP and after the war of the Democratic People's Party (DVP).
1949–69: The reconstruction of Germany.
In the first elections to the Bundestag on 14 August 1949, the FDP won a vote share of 11.9 percent (with 12 direct mandates, particularly in Baden-Württemberg and Hesse), and thus obtained 52 of 402 seats. In September of the same year the FDP chairman Theodor Heuss was elected the first President of the Federal Republic of Germany. In his 1954 re-election, he received the best election result to date of a President with 871 of 1018 votes (85.6 percent) of the Federal Assembly. Adenauer was also elected on the proposal of the new German President with an extremely narrow majority as the first Chancellor. The FDP participated with the CDU/CSU and the DP in Adenauer's coalition cabinet: they had three ministers: Franz Blücher (Vice-Chancellor), Thomas Dehler (Justice) and Eberhard Wildermuth (housing).
On the most important economic, social and German national issues, the FDP agreed with their coalition partners, the CDU/CSU. However, the FDP recommended to the bourgeois voters a secular party that refused the religious schools and the accused the opposition parties of clericalization. The FDP said they were known also as a consistent representative of the market economy, while the CDU was then dominated nominally from the Ahlen Programme, which allowed a Third Way between capitalism and socialism. Ludwig Erhard, the "father" of the social market economy, had his followers in the early years of the Federal Republic in the Union rather than in the FDP.
The FDP voted in parliament at the end of 1950 against the CDU- and SPD- introduced de-nazification process. At their party conference in Munich in 1951 they demanded the release of all "so-called war criminals" and welcomed the establishment of the "Association of German soldiers" of former Wehrmacht and SS members, to advance the integration of the nationalist forces in democracy. The 1953 Naumann-Affair, named after Werner Naumann, identifies old Nazis trying to infiltrate the party, which had many right-wing and nationalist members in Hesse, North Rhine-Westphalia and Lower Saxony. After the British occupation authorities had arrested seven prominent members of the Naumann circle, the FDP federal board installed a commission of inquiry, chaired by Thomas Dehler, which particularly sharply criticized the situation in the North Rhine-Westphalian FDP. In the following years, the right wing lost power, and the extreme right increasingly sought areas of activity outside the FDP. In the 1953 federal election the FDP received 9.5 percent of the party votes, 10.8 percent of the primary vote (with 14 direct mandates, particularly in Hamburg, Lower Saxony, Hesse, Württemberg and Bavaria) and 48 of 487 seats.
In the second term of the Bundestag, the South German Liberal democrats gained influence in the party. Thomas Dehler, a representative of a more left-liberal course took over as party and parliamentary leader. The former Minister of Justice Dehler, who in 1933 suffered persecution by the Nazis, was known for his rhetorical focus. Generally the various regional associations were independent and translated so different from country to country accents in liberal politics. After the FDP had left in early 1956, the coalition with the CDU in North Rhine-Westphalia and made with SPD and center a new state government, were a total of 16 members of parliament, including the four federal ministers from the FDP and founded the short-lived Free People's Party, which then up was involved to the end of the legislature instead of FDP in the Federal Government. The FDP first took it to the opposition.
Only one of the smaller post-war parties, the FDP survived despite many problems. In 1957 federal elections they still reached 7.7 percent of the vote to 1990 and their last direct mandate with which they had held 41 of 497 seats in the Bundestag. However, they still remained in opposition, because the Union won an absolute majority. In the following example, the FDP sat for a nuclear-free zone in Central Europe.
Even before the election Dehler was assigned as party chairman. At the federal party in Berlin at the end January 1957 relieved him Reinhold Maier. Dehler's role as Group Chairman took over after the election of the national set very Erich Mende. Mende was also chairman of the party.
In the 1961 federal elections, it achieved 12.8 percent nationwide, the best result until then, and the FDP entered a coalition with the CDU again. Although it was committed before the election to continuing to sit in any case in a government together with Adenauer, Chancellor Adenauer was again, however, to withdraw under the proviso, after two years. These events led to the FDP being nicknamed the "Umfallerpartei" ("pushover party"). 
In the Spiegel Affair, the FDP withdrew their ministers from the federal government. Although the coalition was renewed again under Adenauer in 1962, the FDP withdrew again on the condition in October 1963. This occurred even under the new Chancellor, Ludwig Erhard. This was for Erich Mende turn the occasion to go into the cabinet: he took the rather unimportant Federal Ministry for All-German Affairs.
In the 1965 federal elections the FDP gained 9.5 percent. The coalition with the CDU in 1966 broke on the subject of tax increases and it was followed by a grand coalition between the CDU and the SPD. The opposition also pioneered a course change to: The former foreign policy and the attitude to the eastern territories were discussed. The new chairman elected delegates in 1968 Walter Scheel, a European-oriented liberals, although it came from the national liberal camp, but with Willi Weyer and Hans-Dietrich Genscher led the new center of the party. This center strove to make the FDP coalition support both major parties. Here, the Liberals approached to by their reorientation in East Germany and politics especially of the SPD.
1969–82: Social changes and crises.
On 21 October 1969 began the period after the election of a Social Liberal coalition with the SPD and the German Chancellor Willy Brandt. Walter Scheel was he who initiated the foreign policy reversal. Despite a very small majority he and Willy Brandt sat by the controversial New Ostpolitik. This policy was within the FDP quite controversial, especially since the entry into the Federal Government defeats in state elections in North Rhine-Westphalia, Lower Saxony and Saarland on 14 June 1970 followed. In Hanover and Saarbrücken, the party left the parliament.
After the federal party congress in Bonn, just a week later supported the policy of the party leadership and Scheel had confirmed in office, founded by Siegfried party rights Zoglmann 11 July 1970 a "non-partisan" organization called the National-Liberal action on the Hohensyburgstraße - to fall with the goal of ending the left-liberal course of the party and Scheel. However, this was not. Zoglmann supported in October 1970 a disapproval resolution of opposition to Treasury Secretary Alexander Möller, Erich Mende, Heinz Starke, and did the same. A little later all three declared their withdrawal from the FDP; Mende and Strong joined the CDU in, Zoglmann later founded the German Union, which does not make it past the status of a splinter party.
The foreign policy and the socio-political changes were made in 1971 by the Freiburg theses, which were as Rowohlt Paperback sold more than 100,000 times, on a theoretical basis, the FDP is committed to "social liberalism" and social reforms. Walter Scheel was first foreign minister and vice chancellor, 1974, he was then second-liberal President and paving the way for inner-party the previous interior minister Hans-Dietrich Genscher free.
From 1969 to 1974 supported the FDP Chancellor Willy Brandt, then she ruled at the Helmut Schmidt page. Already at the end of the 70s did not seem to be sufficient for a coalition the similarities between FDP and SPD, but the CDU / CSU chancellor candidate of Franz Josef Strauss in 1980 left the two parties go again together in the federal election. The FDP, however, saw more and more the differences to the SPD, especially in economic policy. The position on the question of NATO Double-Track Decision Chancellor Schmidt's own SPD had not behind. Also contradictions within the FDP were always greater
1982–98: joined Kohl government, with economic transition and reunification.
On 1 October 1982, FDP elected together with the CDU / CSU parliamentary group of the CDU party chairman Helmut Kohl as the new Chancellor (→ turn (West Germany)). The coalition change had severe internal conflicts result, the FDP then lost about 20 percent of its 86,500 members, as reflected in the general election in 1983 reflected (drop from 10.6 percent to 7.0 percent). The members went mostly to the SPD, the Greens and newly formed splinter parties, such as the left-liberal party Liberal Democrats (LD) across. Under the exiting members was also the former FDP General Secretary and later EU Commissioner Günter Verheugen. At the party convention in November 1982, the Schleswig-Holstein state chairman Uwe Ronneburger challenged Hans-Dietrich Genscher as party chairman. Ronneburger received 186 of the votes - about 40 percent - and was just narrowly defeated by Genscher.
Young FDP members who did not agree with the politics of the FDP youth organization Young Democrats, had founded in 1980 the Young Liberals (JuLis). For a time there were two youth organizations side by side until the JuLis penetrated due to the turn and the new official youth organization of the FDP were. The Young Democrats split from the FDP and were left a party independent youth organization.
At the time of reunification, the FDP's objective was a special economic zone in the former East Germany, but could not prevail against the CDU / CSU, as this would prevent any loss of votes in the five new federal states in the general election in 1990.
In all federal election campaigns since the 1980s, the party sided with the CDU and CSU, the main conservative parties in Germany. Following German reunification in 1990, the FDP merged with the Association of Free Democrats, a grouping of liberals from East Germany and the Liberal Democratic Party of Germany.
During the political upheavals of 1989/1990 originated in the GDR new liberal parties like the FDP East Germany or the German Forum Party. They formed the Liberal Democratic Party, who had previously acted as a block party on the side of the SED and with Manfred Gerlach also the last Council of State of the GDR presented, the Alliance of Free Democrats, (BFD). Within the FDP came in the following years to considerable internal discussions about dealing with the former block party. Even before the reunification of Germany united on a joint congress in Hanover, West German FDP with the parties to the BFD and the former block party NDPD to the first all-German party. Both party factions brought the FDP a great, albeit short-lived, increase in membership. In the first all-German Bundestag elections, the CDU/CSU/FDP center-right coalition was confirmed, the FDP received 11.0 percent of the valid votes (79 seats) and won (in Halle (Saale)) the first direct mandate since 1957.
During the 1990s, the FDP won between 6.2 and 11 percent of the vote in Bundestag elections. It last participated in the federal government by representing the junior partner in the government of Chancellor Helmut Kohl of the CDU.
In 1998, the CDU/CSU - FDP coalition lost the federal election, which ended the FDP's nearly 30 year reign in government coalition. In its 2002 campaign the FDP made an exception to its party policy of siding with the CDU/CSU when it adopted equidistance to the CDU and SPD. From 1998 until 2009 the FDP remained in the opposition until it became part of a new center-right coalition government.
2005 federal election.
In the 2005 general election the party won 9.8 percent of the vote and 61 federal deputies, an unpredicted improvement from prior opinion polls. It is believed that this was partly due to tactical voting by CDU and Christian Social Union of Bavaria (CSU) alliance supporters who hoped for stronger market-oriented economic reforms than the CDU/CSU alliance called for. However, because the CDU did worse than predicted, the FDP and the CDU/CSU alliance were unable to form a coalition government. At other times, for example after the 2002 federal election, a coalition between the FDP and CDU/CSU was impossible primarily because of the weak results of the FDP.
The CDU/CSU parties had achieved the 3rd worst performance in German postwar history with only 35.2 percent of the votes. Therefore, the FDP wasn't able to form a coalition with its preferred partners, the CDU/CSU parties. As a result, the party was considered as a potential member of two other political coalitions, following the election. One possibility was a partnership between the FDP, the Social Democratic Party of Germany (SPD) and the Alliance 90/The Greens, known as a "traffic light coalition", named after the colors of the three parties. This coalition was ruled out, because the FDP considered the Social Democrats and the Greens insufficiently committed to market-oriented economic reform. The other possibility was a CDU-FDP-Green coalition, known as a "Jamaica coalition" because of the colours of the three parties. This coalition wasn't concluded either, since the Greens ruled out participation in any coalition with the CDU/CSU. Instead, the CDU formed a Grand coalition with the SPD, and the FDP entered the opposition. FDP leader Guido Westerwelle became the unofficial leader of the opposition by virtue of the FDP's position as the largest opposition party in the Bundestag.
In the 2009 European parliament elections, the FDP received 11% of the national vote (2,888,084 votes in total) and returned 12 MEPs.
2009 federal election.
In the national vote on 27 September 2009 the FDP increased its share of the vote by 4.8 percentage points to 14.6%, an all-time record so far. This percentage was enough to offset a decline in the CDU/CSU's vote compared to 2005, to create a CDU-FDP governing coalition in the Bundestag with a 53% majority of seats. On election night, party leader Westerwelle said his party would work to ensure that civil liberties were respected and that Germany got an "equitable tax system and better education opportunities".
The party also made gains in the two state elections held at the same time, acquiring sufficient seats for a CDU-FDP coalition in the northernmost state, Schleswig-Holstein, and gaining enough votes in left leaning Brandenburg to clear the 5% hurdle to enter that state's parliament.
However, after reaching its best ever election result in 2009, the FDP's support collapsed. The party’s policy pledges were put on hold by Merkel as the recession of 2009 unfolded and with the onset of the European debt crisis in 2010. By the end of 2010, the party's support had dropped to as low as 5%. The FDP retained their seats in the state elections in North Rhine-Westphalia, which was held six months after the federal election, but out of the seven state elections that have been held since 2009, the FDP have lost all their seats in five of them due to failing to cross the 5% threshold.
Support for the party further eroded amid infighting and an internal rebellion over euro-area bailouts during the debt crisis.
Westerwelle stepped down as party leader in 2011 after the party was wiped out in both Saxony-Anhalt and Rhineland-Palatinate, as well as losing half its seats in Baden-Württemberg. He was replaced on 13 May 2011 by Philipp Rösler. The change in leadership failed to revive the FDP's fortunes, however, and in the next series of state elections, the party lost all its seats in Bremen, Mecklenburg-Vorpommern, and Berlin. In Berlin, the party lost nearly 75% of the support they had had in the previous election.
In March 2012, the FDP lost all their seats in Saarland. However, this was averted in the Schleswig-Holstein state elections, when they achieved 8% of the vote, which was a severe loss of seats but still over the 5% threshold. In the snap elections in North Rhine-Westphalia a week later, the FDP not only crossed the threshold, but also increased its share of the votes to 2 percentage points higher than in the previous state election. This was attributed to the local leadership of Christian Lindner.
2013 federal election.
In the federal elections on 22 September 2013 the FDP came up just short of the 5% threshold. It failed to win any directly elected seats either; it has only won directly elected seats at only one election since 1953, and hasn't won any directly elected seats since 1990. As a result, the FDP will be out of the Bundestag for the first time since 1949.
2014 European election.
In the 2014 European parliament elections, the FDP received 3.36% of the national vote (986,253 votes in total) and returned 3 MEPs.
Ideology.
The FDP adheres to a classical liberal ideology, advocating liberalism in both the economic sphere and social sphere. The current guidelines of the FDP are enshrined in the "Principles of Wiesbaden". A key objective of the FDP is the "strengthening of freedom and individual responsibility".
Throughout its history, the FDP's policies have shifted between emphasis on social liberalism and economic liberalism. Since the 1980s, the FDP has maintained a consistent pro-business stance. The FDP supports strong competition laws and a minimum standard of welfare protection for every citizen. In addition, the FDP endorses changes to social welfare and health care systems with laws that would require every employed citizen to invest in a private social security account. The party supports a bracket income tax system, as opposed to the current 'linear' system, and, in the long term, a flat tax. The FDP aims for the introduction of a citizen's dividend, which collects all the tax-financed social welfare and social security funds of the state.
The FDP supports gay rights; former party leader Guido Westerwelle was openly gay. Yet the party's group in parliament voted against an oppositional motion for gay marriage, in order not to threaten the coalition with the Christian Democrats.
The FDP describes itself as a pro-European party, although the minority national-liberal faction is Eurosceptic. The FDP wants a politically integrated EU with a Common Foreign and Security Policy, but supported a referendum on the Treaty of Lisbon. The FDP advocates the accession of Turkey to the EU, although this would require Turkey to fulfil all criteria.
Election results.
Federal Parliament ("Bundestag").
Below are charts of the results that the Free Democratic Party has secured in each election to the federal Bundestag. Timelines showing the number of seats and percentage of party list votes won are on the right.

</doc>
<doc id="10826" url="https://en.wikipedia.org/wiki?curid=10826" title="Fax">
Fax

Fax (short for facsimile), sometimes called telecopying or telefax (the latter short for telefacsimile), is the telephonic transmission of scanned printed material (both text and images), normally to a telephone number connected to a printer or other output device. The original document is scanned with a fax machine (or a telecopier), which processes the contents (text or images) as a single fixed graphic image, converting it into a bitmap, and then transmitting it through the telephone system in the form of audio-frequency tones. The receiving fax machine interprets the tones and reconstructs the image, printing a paper copy. Early systems used direct conversions of image darkness to audio tone in a continuous or analog manner. Since the 1980s, most machines modulate the transmitted audio frequencies using a digital representation of the page which is compressed to quickly transmit areas which are all-white or all-black.
History.
Wire transmission.
Scottish inventor Alexander Bain worked on chemical mechanical fax type devices and in 1846 was able to reproduce graphic signs in laboratory experiments. He received British patent 9745 on May 27, 1843 for his "Electric Printing Telegraph." Frederick Bakewell made several improvements on Bain's design and demonstrated a telefax machine. The Pantelegraph was invented by the Italian physicist Giovanni Caselli. He introduced the first commercial telefax service between Paris and Lyon in 1865, some 11 years before the invention of the telephone.
In 1881, English inventor Shelford Bidwell constructed the "scanning phototelegraph" that was the first telefax machine to scan any two-dimensional original, not requiring manual plotting or drawing. Around 1900, German physicist Arthur Korn invented the "Bildtelegraph", widespread in continental Europe especially, since a widely noticed transmission of a wanted-person photograph from Paris to London in 1908, used until the wider distribution of the radiofax. Its main competitors were the "Bélinographe" by Édouard Belin first, then since the 1930s the "Hellschreiber", invented in 1929 by German inventor Rudolf Hell, a pioneer in mechanical image scanning and transmission.
The 1888 invention of the telautograph by Elisha Grey marked a further development in fax technology, allowing users to send signatures over long distances, thus allowing the verification of identification or ownership over long distances.
On May 19, 1924, scientists of the AT&T Corporation "by a new process of transmitting pictures by electricity" sent 15 photographs by telephone from Cleveland to New York City, such photos suitable for newspaper reproduction. Previously, photographs had been sent over the radio using this process.
The Western Union "Deskfax" fax machine, announced in 1948, was a compact machine that fit comfortably on a desktop, using special spark printer paper.
Wireless transmission.
As a designer for the Radio Corporation of America (RCA), in 1924, Richard H. Ranger invented the wireless photoradiogram, or transoceanic radio facsimile, the forerunner of today’s "fax" machines. A photograph of President Calvin Coolidge sent from New York to London on November 29, 1924 became the first photo picture reproduced by transoceanic radio facsimile. Commercial use of Ranger’s product began two years later. Also in 1924, Herbert E. Ives of AT&T Corporation transmitted and reconstructed the first color facsimile, using color separations. Around 1952 or so, Finch Facsimile, a highly developed machine, was described in detail in a book; it was never manufactured in quantity.
By the late 1940s, radiofax receivers were sufficiently miniaturized to be fitted beneath the dashboard of Western Union's "Telecar" telegram delivery vehicles.
In the 1960s, the United States Army transmitted the first photograph via satellite facsimile to Puerto Rico from the Deal Test Site using the Courier satellite.
Radio fax is still in limited use today for transmitting weather charts and information to ships at sea.
Telephone transmission.
In 1964, Xerox Corporation introduced (and patented) what many consider to be the first commercialized version of the modern fax machine, under the name (LDX) or Long Distance Xerography. This model was superseded two years later with a unit that would truly set the standard for fax machines for years to come. Up until this point facsimile machines were very expensive and hard to operate. In 1966, Xerox released the Magnafax Telecopier, a smaller, 46-pound facsimile machine. This unit was far easier to operate and could be connected to any standard telephone line. This machine was capable of transmitting a letter-sized document in about six minutes. The first sub-minute, digital fax machine was developed by Dacom, which built on digital data compression technology originally developed at Lockheed for satellite communication.
By the late 1970s, many companies around the world (especially Japan), entered the fax market. Very shortly after a new wave of more compact, faster and efficient fax machines would hit the market. Xerox continued to refine the fax machine for years after their ground-breaking first machine. In later years it would be combined with copier equipment to create the hybrid machines we have today that copy, scan and fax. Some of the lesser known capabilities of the Xerox fax technologies included their Ethernet enabled Fax Services on their 8000 workstations in the early 1980s.
Prior to the introduction of the ubiquitous fax machine, one of the first being the Exxon Qwip in the mid-1970s, facsimile machines worked by optical scanning of a document or drawing spinning on a drum. The reflected light, varying in intensity according to the light and dark areas of the document, was focused on a photocell so that the current in a circuit varied with the amount of light. This current was used to control a tone generator (a modulator), the current determining the frequency of the tone produced. This audio tone was then transmitted using an acoustic coupler (a speaker, in this case) attached to the microphone of a common telephone handset. At the receiving end, a handset’s speaker was attached to an acoustic coupler (a microphone), and a demodulator converted the varying tone into a variable current that controlled the mechanical movement of a pen or pencil to reproduce the image on a blank sheet of paper on an identical drum rotating at the same rate.
Computer facsimile interface.
In 1985, Dr. Hank Magnuski, founder of GammaLink, produced the first computer fax board, called GammaFax.
Fax in the 21st century.
Although businesses usually maintain some kind of fax capability, the technology has faced increasing competition from Internet-based alternatives. In some countries, because electronic signatures on contracts are not yet recognized by law, while faxed contracts with copies of signatures are, fax machines enjoy continuing support in business. In Japan, faxes are still used extensively for cultural and graphemic reasons and are available for sending to both domestic and international recipients from over 81% of all convenience stores nationwide. Convenience-store fax machines commonly print the slightly re-sized content of the sent fax in the electronic confirmation-slip, in A4 paper size.
In many corporate environments, freestanding fax machines have been replaced by fax servers and other computerized systems capable of receiving and storing incoming faxes electronically, and then routing them to users on paper or via an email (which may be secured). Such systems have the advantage of reducing costs by eliminating unnecessary printouts and reducing the number of inbound analog phone lines needed by an office.
The once ubiquitous fax machine has also begun to disappear from the small office and home office environments. Remotely hosted fax-server services are widely available from VoIP and e-mail providers allowing users to send and receive faxes using their existing e-mail accounts without the need for any hardware or dedicated fax lines. Personal computers have also long been able to handle incoming and outgoing faxes using analogue modems or ISDN, eliminating the need for a stand-alone fax machine. These solutions are often ideally suited for users who only very occasionally need to use fax services. There are 17 million fax machines in the US, about one every 4.47 square miles.
Capabilities.
There are several indicators of fax capabilities: Group, class, data transmission rate, and conformance with ITU-T (formerly CCITT) recommendations. Since the 1968 Carterphone decision, most fax machines have been designed to connect to standard PSTN lines and telephone numbers.
Group.
Analog.
Group 1 and 2 faxes are sent in the same manner as a frame of analog television, with each scanned line transmitted as a continuous analog signal. Horizontal resolution depended upon the quality of the scanner, transmission line, and the printer. Analog fax machines are obsolete and no longer manufactured. ITU-T Recommendations T.2 and T.3 were withdrawn as obsolete in July 1996.
Digital.
A major breakthrough in the development of the modern facsimile system was the result of digital technology, where the analog signal from scanners was digitized and then compressed, resulting in the ability to transmit high rates of data across standard phone lines. The first digital fax machine was the Dacom Rapidfax first sold in late 1960s, which incorporated digital data compression technology developed by Lockheed for transmission of images from satellites.
Group 3 and 4 faxes are digital formats, and take advantage of digital compression methods to greatly reduce transmission times.
Fax Over IP (FoIP) can transmit and receive pre-digitized documents at near realtime speeds using ITU-T recommendation T.38 to send digitised images over an IP network using JPEG compression. T.38 is designed to work with VoIP services and often supported by analog telephone adapters used by legacy fax machines that need to connect through a VoIP service. Scanned documents are limited to the amount of time the user takes to load the document in a scanner and for the device to process a digital file. The resolution can vary from as little as 150 DPI to 9600 DPI or more. This type of faxing is not related to the e-mail to fax service that still uses fax modems at least one way.
Class.
Computer modems are often designated by a particular fax class, which indicates how much processing is offloaded from the computer's CPU to the fax modem.
Data transmission rate.
Several different telephone line modulation techniques are used by fax machines. They are negotiated during the fax-modem handshake, and the fax devices will use the highest data rate that both fax devices support, usually a minimum of 14.4 kbit/s for Group 3 fax.
Note that "Super Group 3" faxes use V.34bis modulation that allows a data rate of up to 33.6 kbit/s.
Compression.
As well as specifying the resolution (and allowable physical size of the image being faxed), the ITU-T T.4 recommendation specifies two compression methods for decreasing the amount of data that needs to be transmitted between the fax machines to transfer the image. The two methods defined in T.4 are:
An additional method is specified in T.6:
Later, other compression techniques were added as options to ITU-T recommendation T.30, such as the more efficient JBIG (T.82, T.85) for bi-level content, and JPEG (T.81), T.43, MRC (T.44), and T.45 for grayscale, palette, and colour content. Fax machines can negotiate at the start of the T.30 session to use the best technique implemented on both sides.
Modified Huffman.
Modified Huffman (MH), specified in T.4 as the one-dimensional coding scheme, is a codebook-based run-length encoding scheme optimised to efficiently compress whitespace. As most faxes consist mostly of white space, this minimises the transmission time of most faxes. Each line scanned is compressed independently of its predecessor and successor.
Modified READ.
Modified READ (MR), specified as an optional two-dimensional coding scheme in T.4, encodes the first scanned line using MH. The next line is compared to the first, the differences determined, and then the differences are encoded and transmitted. This is effective as most lines differ little from their predecessor. This is not continued to the end of the fax transmission, but only for a limited number of lines until the process is reset and a new 'first line' encoded with MH is produced. This limited number of lines is to prevent errors propagating throughout the whole fax, as the standard does not provide for error-correction. MR is an optional facility, and some fax machines do not use MR in order to minimise the amount of computation required by the machine. The limited number of lines is two for 'Standard' resolution faxes, and four for 'Fine' resolution faxes.
Modified Modified READ.
The ITU-T T.6 recommendation adds a further compression type of Modified Modified READ (MMR), which simply allows for a greater number of lines to be coded by MR than in T.4. This is because T.6 makes the assumption that the transmission is over a circuit with a low number of line errors such as digital ISDN. In this case, there is no maximum number of lines for which the differences are encoded.
JBIG.
In 1999, ITU-T recommendation T.30 added JBIG (ITU-T T.82) as another lossless bi-level compression algorithm, or more precisely a "fax profile" subset of JBIG (ITU-T T.85). JBIG-compressed pages result in 20% to 50% faster transmission than MMR-compressed pages, and up to 30-times faster transmission if the page includes halftone images.
JBIG performs adaptive compression, that is both the encoder and decoder collect statistical information about the transmitted image from the pixels transmitted so far, in order to predict the probability for each next pixel being either black or white. For each new pixel, JBIG looks at ten nearby, previously transmitted pixels. It counts, how often in the past the next pixel has been black or white in the same neighborhood, and estimates from that the probability distribution of the next pixel. This is fed into an arithmetic coder, which adds only a small fraction of a bit to the output sequence if the more probable pixel is then encountered.
The ITU-T T.85 "fax profile" constrains some optional features of the full JBIG standard, such that codecs do not have to keep data about more than the last three pixel rows of an image in memory at any time. This allows the streaming of "endless" images, where the height of the image may not be known until the last row is transmitted.
ITU-T T.30 allows fax machines to negotiate one of two options of the T.85 "fax profile":
Matsushita Whiteline Skip.
A proprietary compression scheme employed on Panasonic fax machines is Matsushita Whiteline Skip (MWS). It can be overlaid on the other compression schemes, but is operative only when two Panasonic machines are communicating with one another. This system detects the blank scanned areas between lines of text, and then compresses several blank scan lines into the data space of a single character. (JBIG implements a similar technique called "typical prediction", if header flag TPBON is set to 1.)
Typical characteristics.
Group 3 fax machines transfer one or a few printed or handwritten pages per minute in black-and-white (bitonal) at a resolution of 204×98 (normal) or 204×196 (fine) dots per square inch. The transfer rate is 14.4 kbit/s or higher for modems and some fax machines, but fax machines support speeds beginning with 2400 bit/s and typically operate at 9600 bit/s. The transferred image formats are called ITU-T (formerly CCITT) fax group 3 or 4. Group 3 faxes have the suffix codice_1 and the MIME type image/g3fax.
The most basic fax mode transfers black and white colors only. The original page is scanned in a resolution of 1728 pixels/line and 1145 lines/page (for A4). The resulting raw data is compressed using a modified Huffman code optimized for written text, achieving average compression factors of around 20. Typically a page needs 10 s for transmission, instead of about 3 minutes for the same uncompressed raw data of 1728×1145 bits at a speed of 9600 bit/s. The compression method uses a Huffman codebook for run lengths of black and white runs in a single scanned line, and it can also use the fact that two adjacent scanlines are usually quite similar, saving bandwidth by encoding only the differences.
Fax classes denote the way fax programs interact with fax hardware. Available classes include Class 1, Class 2, Class 2.0 and 2.1, and Intel CAS. Many modems support at least class 1 and often either Class 2 or Class 2.0. Which is preferable to use depends on factors such as hardware, software, modem firmware, and expected use.
Printing process.
Fax machines from the 1970s to the 1990s often used direct thermal printers with rolls of thermal paper as their printing technology, but since the mid-1990s there has been a transition towards plain-paper faxes:- thermal transfer printers, inkjet printers and laser printers.
One of the advantages of inkjet printing is that inkjets can affordably print in color; therefore, many of the inkjet-based fax machines claim to have color fax capability. There is a standard called ITU-T30e (formally ITU-T Recommendation T.30 Annex E ) for faxing in color; unfortunately, it is not widely supported, so many of the color fax machines can only fax in color to machines from the same manufacturer.
Stroke speed.
Stroke speed in facsimile systems is the rate at which a fixed line perpendicular to the direction of scanning is crossed in one direction by a scanning or recording spot. Stroke speed is usually expressed as a number of strokes per minute. When the fax system scans in both directions, the stroke speed is twice this number. In most conventional 20th century mechanical systems, the stroke speed is equivalent to drum speed.
Fax paper.
As a precaution, thermal fax paper is typically not accepted in archives or as documentary evidence in some courts of law unless photocopied. This is because the image-forming coating is eradicable and brittle, and it tends to detach from the medium after a long time in storage.
Internet fax.
One popular alternative is to subscribe to an Internet fax service, allowing users to send and receive faxes from their personal computers using an existing email account. No software, fax server or fax machine is needed. Faxes are received as attached TIFF or PDF files, or in proprietary formats that require the use of the service provider's software. Faxes can be sent or retrieved from anywhere at any time that a user can get Internet access. Some services offer secure faxing to comply with stringent HIPAA and Gramm–Leach–Bliley Act requirements to keep medical information and financial information private and secure. Utilizing a fax service provider does not require paper, a dedicated fax line, or consumable resources.
Another alternative to a physical fax machine is to make use of computer software which allows people to send and receive faxes using their own computers, utilizing fax servers and unified messaging. A virtual (email) fax can be printed out and then signed and scanned back to computer before being emailed. Also the sender can attach a digital signature to the document file.
With the surging popularity of mobile phones, virtual fax machines can now be downloaded as applications for Android and iOS. These applications make use of the phone's internal camera to scan fax documents for upload or they can import from various cloud services.

</doc>
<doc id="10827" url="https://en.wikipedia.org/wiki?curid=10827" title="Film crew">
Film crew

A movie crew is a group of people hired by a production company for the purpose of producing a film or motion picture. The crew is distinguished from the "cast" as the "cast" are understood to be the actors who appear in front of the camera or provide voices for characters in the film. The "crew" is also separate from the "producers" as the "producers" are the ones who own a portion of either the film company or the film's intellectual property rights. A film crew is divided into different departments, each of which specializes in a specific aspect of the production. Film crew positions have evolved over the years, spurred by technological change, but many traditional jobs date from the early 20th century and are common across jurisdictions and film-making cultures.
Motion picture projects have three discrete stages: development, production and distribution. Within the production stage there are also three clearly defined sequential phases — pre-production, principal photography and post-production — and many film crew positions are associated with only one or two of the phases. Distinctions are also made between above-the-line personnel (such as the director, the screenwriter and the producers) who begin their involvement during the project's development stage, and the below-the-line "technical" crew involved only with the production stage.
A study of the 100 top-grossing films of each year between 1994 and 2013 found that there were an average of 588 crew credits per film, however, profitable independent films have been made with crews of less than a dozen. 
Television crew positions are derived from those of film crew.
Director.
The director is considered to be a separate entity, not within the film crew's departmental structure.
Production.
"Production" is generally not considered a department as such, but rather as a series of functional groups. These include the film's producers and executive producers such as the production manager, the production coordinator, and their assistants; the various assistant directors; the accounting staff; and sometimes the locations manager and their assistants. 
Additional production credits.
Since the turn of the 21st century, several additional professionals are now routinely listed in the production credits on most major motion pictures.
Camera & lighting.
Grip.
Grips are trained lighting and rigging technicians. Their main responsibility is to work closely with the electrical department to put in the non-electrical components of lighting set-ups required for a shot, such as flags, overheads, and bounces. On the sound stage, they move and adjust major set pieces when something needs to be moved to get a camera into position. In the US and Canada they may belong to the International Alliance of Theatrical Stage Employees.
Art department.
The art department in a major feature film can often number hundreds of people. Usually it is considered to include several sub-departments: the art department proper, with its art director, set designers and draftsmen; set decoration, under the set decorator; props, under the props master; construction, headed by the construction coordinator; scenic, headed by the key scenic artist; and special effects.
Art.
Within the overall art department is a sub-department, also called the art department—which can be confusing. This consists of the people who design the sets and create the graphic art.
Hair and make-up.
Some actors or actresses have personal makeup artists or hair stylists.
Special effects.
This department oversees the mechanical effects—also called practical or physical effects—that create optical illusions during live-action shooting. It is not to be confused with the Visual effects department, which adds photographic effects during filming to be altered later during video editing in the post-production process.
Post-production.
Visual effects.
Visual effects commonly refers to post-production alterations of the film's images. The on set VFX crew works to prepare shots and plates for future visual effects. This may include adding tracking markers, taking and asking for reference plates and helping the Director understand the limitations and ease of certain shots that will effect the future post production. A VFX crew can also work alongside the Special effects department for any on-set optical effects that need physical representation during filming (on camera.)
Animation.
Animation film crews have many of the same roles and departments as live-action films (including directing, production, editing, camera, sound, and so on), but nearly all on-set departments (lighting, electrical, grip, sets, props, costume, hair, makeup, special effects, and stunts) were traditionally replaced with a single animation department made up of various types of animators (character, effects, in-betweeners, cleanup, and so on). In traditional animation, the nature of the medium meant that "everything" was literally flattened into the drawn lines and solid colors that became the characters, making nearly all live-action positions irrelevant. Because animation has traditionally been so labor-intensive and thus expensive, animation films normally have a separate story department in which storyboard artists painstakingly develop scenes to make sure they make sense before they are actually animated.
However, since the turn of the 21st century, modern 3D computer graphics and computer animation have made possible a level of rich detail never seen before. Many animated films now have specialized artists and animators who act as the virtual equivalent of lighting technicians, grips, costume designers, props masters, set decorators, set dressers, and cinematographers. They make artistic decisions strongly similar to those of their live-action counterparts, but implement them in a virtual space that exists only in software rather than on a physical set. There have been major breakthroughs in the simulation of hair since 2005, meaning that hairstylists have been called in since then to consult on a few animation projects.

</doc>
<doc id="10828" url="https://en.wikipedia.org/wiki?curid=10828" title="Fear">
Fear

Fear is a feeling induced by perceived danger or threat that occurs in certain types of organisms, which causes a change in metabolic and organ functions and ultimately a change in behavior, such as fleeing, hiding or freezing from perceived traumatic events. Fear in human beings may occur in response to a specific stimulus occurring in the present, or in anticipation or expectation of a future threat perceived as a risk to body or life. The fear response arises from the perception of danger leading to confrontation with or escape from/avoiding the threat (also known as the fight-or-flight response), which in extreme cases of fear (horror and terror) can be a freeze response or paralysis. 
In humans and animals, fear is modulated by the process of cognition and learning. Thus fear is judged as rational or appropriate and irrational or inappropriate. An irrational fear is called a phobia.
Psychologists such as John B. Watson, Robert Plutchik, and Paul Ekman have suggested that there is only a small set of basic or innate emotions and that fear is one of them. This hypothesized set includes such emotions as acute stress reaction, anger, angst, anxiety, fright, horror, joy, panic and sadness. Fear is closely related to, but should be distinguished from, the emotion anxiety, which occurs as the result of threats that are perceived to be uncontrollable or unavoidable. The fear response serves survival by generating appropriate behavioral responses, so it has been preserved throughout evolution.
Etymology.
The noun "fear" stems from the Middle English words "feer", "fere" and "fer", the Old English "fǣr" for "calamity" or "danger" (and its verb "fǣran", "frighten", but also "revere") and is related to the Proto-Germanic "fērą", "danger", the Proto-Indo-European "*per", "to attempt, try, research, risk". In German the word for "danger" is "Gefahr", in Dutch "gevaar", in Swedish "fara", in Albanian "frikë", and in Latin "perīculum", which is the root for the term in the Romance languages.
As a noun "fear" can be used in three ways with different meanings: In the uncountable form fear is a strong, uncontrollable and unpleasant emotion caused by actual or perceived danger, e.g. "He was struck by fear on seeing the snake." In the countable form, and when used with the indefinite article, a "fear" means a phobia, a sense of fear induced by something or someone, e.g. "Not everybody has the same fears; I have a fear of ants." In an uncountable form it can also mean extreme veneration or awe, as toward a supreme being or deity.
Types.
Top 10 types in the U.S..
In a 2005 Gallup poll (U.S.), a national sample of adolescents between the ages of 13 and 17 were asked what they feared the most. The question was open-ended and participants were able to say whatever they wanted. The top ten fears were, in order: terrorist attacks, spiders, death, being a failure, war, criminal or gang violence, being alone, the future, and nuclear war.
In an estimate of what people fear the most, book author Bill Tancer analyzed the most frequent online queries that involved the phrase, "fear of..." following the assumption that people tend to seek information on the issues that concern them the most. His top ten list of fears published 2008 consisted of flying, heights, clowns, intimacy, death, rejection, people, snakes, failure, and driving.
Common phobias.
According to surveys, some of the most common fears are of demons and ghosts, the existence of evil powers, cockroaches, spiders, snakes, heights, water, enclosed spaces, tunnels, bridges, needles, social rejection, failure, examinations and public speaking.
A person with arachnophobia may panic or feel uneasy around a spider even though most are harmless. Sometimes, even an object resembling a spider can trigger a panic attack in an arachnophobic individual, which is called automatonophobia. 
One of the most common phobias in humans is the glossophobia or the fear of public speaking. People may be comfortable speaking inside a room, but when it becomes public speaking, fear enters in the form of suspicion over whether the words uttered are correct or incorrect, because there are many to judge them. Another common fear can be fear of pain, or of someone damaging a person. Fear of pain in a plausible situation brings flinching, or cringing.
Fear of death.
Death anxiety is multidimensional; it covers "fears related to one's own death, the death of others, fear of the unknown after death, fear of obliteration, and fear of the dying process, which includes fear of a slow death and a painful death".
The Yale philosopher Shelly Kagan examined fear of death in a 2007 Yale open course by examining the following questions: Is fear of death a reasonable appropriate response? What conditions are required and what are appropriate conditions for feeling fear of death? What is meant by fear, and how much fear is appropriate? According to Kagan for fear in general to make sense, three conditions should be met: the object of fear needs to be "something bad", there needs to be a non-negligible chance that the bad state of affairs will happen, and there needs to be some uncertainty about the bad state of affairs. The amount of fear should be appropriate to the size of "the bad". If the 3 conditions aren't met, fear is an inappropriate emotion. He argues, that death does not meet the first two criteria, even if death is a "deprivation of good things" and even if one believes in a painful afterlife. Because death is certain, it also does not meet the third criteria, but he grants that the unpredictability of when one dies "may" be cause to a sense of fear.
In a 2003 study of 167 women and 121 men, aged 65–87, low self-efficacy predicted fear of the unknown after death and fear of dying for women and men better than demographics, social support, and physical health. Fear of death was measured by a "Multidimensional Fear of Death Scale" which included the 8 subscales Fear of Dying, Fear of the Dead, Fear of Being Destroyed, Fear for Significant Others, Fear of the Unknown, Fear of Conscious Death, Fear for the Body After Death, and Fear of Premature Death. In hierarchical multiple regression analysis the most potent predictors of death fears were low "spiritual health efficacy", defined as beliefs relating to one's perceived ability to generate spiritually based faith and inner strength, and low "instrumental efficacy", defined as beliefs relating to one's perceived ability to manage activities of daily living.
Psychologists have tested the hypothesis that fear of death motivates religious commitment, and assurances about an afterlife alleviate the fear and empirical research on this topic has been equivocal. Religiosity can be related to fear of death when the afterlife is portrayed as time of punishment. "Intrinsic religiosity", as opposed to mere "formal religious involvement" has been found to be negatively correlated with death anxiety. In a 1976 study people of various Christian denominations those most firm in their faith, attending religious services weekly were the least afraid of dying. The survey found a negative correlation between fear of death and "religious concern".
In a 2006 study of white, Christian men and women the hypothesis was tested that traditional, church-centered religiousness and de-institutionalized spiritual seeking are ways of approaching fear of death in old age. Both religiousness and spirituality were related to positive psychosocial functioning, but only church-centered religiousness protected subjects against the fear of death.
Fear of the unknown.
Fear of the unknown or irrational fear is caused by negative thinking which arises from anxiety. Many people are scared of the "unknown". The irrational fear can branch out to many areas such as the hereafter, the next ten years, or even tomorrow. In these cases specialists use False Evidence Appearing Real as a definition. Being scared makes people to anticipate and aggravate of what may lie ahead rather than plan and evaluate. E.g. Continuation of scholarly education, most educators perceive this as a risk that may cause them fear and stress and they would rather teach things they've been taught than go and do research. This can lead to habits such as laziness and procrastination. The ambiguity of a situations that tend to be uncertain and unpredictable can cause anxiety, other psychological and physical problems in some populations; especially those who engage it constantly. E.g. War-ridden or Conflict places, Terrorism, Abuse ...etc. Poor parenting that instills fear can also debilitate children's psyche development or personality. E.g. Parents tell their children not to talk to strangers in order to protect them. In school they would be motivated to not show fear in talking with strangers, but to be assertive and also aware of the risks and the environment that it takes place. Ambiguous and mixed messages like this can affect their self-esteem and self-confidence. Researcher's say talking to strangers isn't something to be thwarted but allowed in a parent's presence if required. Developing a sense of equanimity to handle various situations is often advocated as an antidote to irrational fear and essential skill by a number of ancient philosophies.
Causes.
People develop specific fears as a result of learning. This has been studied in psychology as fear conditioning, beginning with John B. Watson's Little Albert experiment in 1920, which was inspired after observing a child with an irrational fear of dogs. In this study, an 11-month-old boy was conditioned to fear a white rat in the laboratory. The fear became generalized to include other white, furry objects, such as a rabbit, dog, and even a ball of cotton.
Fear can be learned by experiencing or watching a frightening traumatic accident. For example, if a child falls into a well and struggles to get out, he or she may develop a fear of wells, heights (acrophobia), enclosed spaces (claustrophobia), or water (aquaphobia). There are studies looking at areas of the brain that are affected in relation to fear. When looking at these areas (such as the amygdala), it was proposed that a person learns to fear regardless of whether they themselves have experienced trauma, or if they have observed the fear in others. In a study completed by Andreas Olsson, Katherine I. Nearing and Elizabeth A. Phelps the amygdala were affected both when subjects observed someone else being submitted to an aversive event, knowing that the same treatment awaited themselves, and when subjects were subsequently placed in a fear-provoking situation. This suggests that fear can develop in both conditions, not just simply from personal history.
Fear is affected by cultural and historical context. For example, in the early 20th century, many Americans feared polio, a disease that cripples the body part it affects, leaving that body part immobilized for the rest of one's life. There are consistent cross-cultural differences in how people respond to fear. Display rules affect how likely people are to show the facial expression of fear and other emotions.
Although many fears are learned, the capacity to fear is part of human nature. Many studies have found that certain fears (e.g. animals, heights) are much more common than others (e.g. flowers, clouds). These fears are also easier to induce in the laboratory. This phenomenon is known as preparedness. Because early humans that were quick to fear dangerous situations were more likely to survive and reproduce, preparedness is theorized to be a genetic effect that is the result of natural selection .
From an evolutionary psychology perspective, different fears may be different adaptations that have been useful in our evolutionary past. They may have developed during different time periods. Some fears, such as fear of heights, may be common to all mammals and developed during the mesozoic period. Other fears, such as fear of snakes, may be common to all simians and developed during the cenozoic time period. Still others, such as fear of mice and insects, may be unique to humans and developed during the paleolithic and neolithic time periods (when mice and insects become important carriers of infectious diseases and harmful for crops and stored foods).
Fear is high only if the observed risk and seriousness both are high, and is low, if risk or seriousness is low.
Symptoms and signs.
Many physiological changes in the body are associated with fear, summarized as the fight-or-flight response. An inborn response for coping with danger, it works by accelerating the breathing rate (hyperventilation), heart rate, constriction of the peripheral blood vessels leading to blushing and vasodilation of the central vessels (pooling), increasing muscle tension including the muscles attached to each hair follicle to contract and causing "goose bumps", or more clinically, piloerection (making a cold person warmer or a frightened animal look more impressive), sweating, increased blood glucose (hyperglycemia), increased serum calcium, increase in white blood cells called neutrophilic leukocytes, alertness leading to sleep disturbance and "butterflies in the stomach" (dyspepsia). This primitive mechanism may help an organism survive by either running away or fighting the danger. With the series of physiological changes, the consciousness realizes an emotion of fear.
In animals.
Often laboratory studies with rats are conducted to examine the acquisition and extinction of conditioned fear responses. In 2004, researchers conditioned rats ("rattus norvegicus") to fear a certain stimulus, through electric shock. The researchers were able to then cause an extinction of this conditioned fear, to a point that no medications or drugs were able to further aid in the extinction process. However the rats did show signs of avoidance learning, not fear, but simply avoiding the area that brought pain to the tests rats. The avoidance learning of rats is seen as a conditioned response, and therefore the behavior can be unconditioned, as supported by the earlier research. 
Species-specific defense reactions (SSDRs) or avoidance learning in nature is the specific tendency to avoid certain threats or stimuli, it is how animals survive in the wild. Humans and animals both share these species-specific defense reactions, such as the flight, fight, which also include pseudo-aggression, fake or intimidating aggression, freeze response to threats, which is controlled by the sympathetic nervous system. These SSDRs are learned very quickly through social interactions between others of the same species, other species, and interaction with the environment. These acquired sets of reactions or responses are not easily forgotten. The animal that survives is the animal that already knows what to fear and how to avoid this threat. An example in humans is the reaction to the sight of a snake, many jump backwards before cognitively realizing what they are jumping away from, and in some cases it is a stick rather than a snake.
As with many functions of the brain, there are various regions of the brain involved in deciphering fear in humans and other nonhuman species. The amygdala communicates both directions between the prefrontal cortex, hypothalamus, the sensory cortex, the hippocampus, thalamus, septum, and the brainstem. The amygdala plays an important role in SSDR, such as the ventral amygdalofugal, which is essential for associative learning, and SSDRs are learned through interaction with the environment and others of the same species. An emotional response is created only after the signals have been relayed between the different regions of the brain, and activating the sympathetic nervous systems; which controls the flight, fight, freeze, fright, and faint response. Often a damaged amygdala can cause impairment in the recognition of fear (like the human case of patient S.M.). This impairment can cause different species to lack the sensation of fear, and often can become overly confident, confronting larger peers, or walking up to predatory creatures.
Robert C. Bolles (1970), a researcher at University of Washington, wanted to understand species-specific defense reactions and avoidance learning among animals, but found that the theories of avoidance learning and the tools that were used to measure this tendency were out of touch with the natural world. He theorized the species-specific defense reaction (SSDR). There are three forms of SSDRs: flight, fight (pseudo-aggression), or freeze. Even domesticated animals have SSDRs, and in those moments it is seen that animals revert to atavistic standards and become "wild" again. Dr. Bolles states that responses are often dependent on the reinforcement of a safety signal, and not the aversive conditioned stimuli. This safety signal can be a source of feedback or even stimulus change. Intrinsic feedback or information coming from within, muscle twitches, increased heart rate, is seen to be more important in SSRDs than extrinsic feedback, stimuli that comes from the external environment. Dr. Bolles found that most creatures have some intrinsic set of fears, to help assure survival of the species. Rats will run away from any shocking event, and pigeons will flap their wings harder when threatened, the wing flapping in pigeons and the scattered running of rats are considered a species-specific defense reaction or behavior. Bolles believed that SSDR are conditioned through pavlovian conditioning, and not operant conditioning; SSDR arise from the association between the environmental stimuli and adverse events. Michael S. Fanselow conducted an experiment, to test some specific defense reactions, he observed that rats in two different shock situations responded differently, based on instinct or defensive topography, rather than contextual information.
Species specific defense responses are created out of fear, and are essential for survival. Rats that lack the gene stathmin show no avoidance learning, or a lack of fear, and will often walk directly up to cats and be eaten. Animals use these SSDR to continue living, to help increase their chance of fitness, by surviving long enough to procreate. Humans and animals alike have created fear to know what should avoided, and this fear can be learned through association with others in the community, or learned through personal experience with a creature, species, or situations that should be avoided. SSDRs are an evolutionary adaptation that has been seen in many species throughout the world including rats, chimpanzees, prairie dogs, and even humans, an adaptation created to help individual creatures survive in a hostile world.
Neurocircuit in mammals.
The brain structure that is the center of most neurobiological events associated with fear is the amygdala, located behind the pituitary gland. The amygdala is part of a circuitry of fear learning. It is essential for proper adaptation to stress and specific modulation of emotional learning memory. In the presence of a threatening stimulus, the amygdala generates the secretion of hormones that influence fear and aggression. Once response to the stimulus in the form of fear or aggression commences, the amygdala may elicit the release of hormones into the body to put the person into a state of alertness, in which they are ready to move, run, fight, etc. This defensive response is generally referred to in physiology as the fight-or-flight response regulated by the hypothalamus, part of the limbic system. Once the person is in safe mode, meaning that there are no longer any potential threats surrounding them, the amygdala will send this information to the medial prefrontal cortex (mPFC) where it is stored for similar future situations, which is known as memory consolidation.
Some of the hormones involved during the state of fight-or-flight include epinephrine, which regulates heart rate and metabolism as well as dilating blood vessels and air passages, norepinephrine increasing heart rate, blood flow to skeletal muscles and the release of glucose from energy stores. and cortisol which increases blood sugar, increases circulating neutrophilic leukocytes, calcium amongst other things.
After a situation which incites fear occurs, the amygdala and hippocampus record the event through synaptic plasticity. The stimulation to the hippocampus will cause the individual to remember many details surrounding the situation. Plasticity and memory formation in the amygdala are generated by activation of the neurons in the region. Experimental data supports the notion that synaptic plasticity of the neurons leading to the lateral amygdala occurs with fear conditioning. In some cases, this forms permanent fear responses such as post-traumatic stress disorder (PTSD) or a phobia. MRI and fMRI scans have shown that the amygdala in individuals diagnosed with such disorders including bipolar or panic disorder is larger and wired for a higher level of fear.
Pathogens can suppress amygdala activity. Rats infected with the toxoplasmosis parasite become less fearful of cats, sometimes even seeking out their urine-marked areas. This behavior often leads to them being eaten by cats. The parasite then reproduces within the body of the cat. There is evidence that the parasite concentrates itself in the amygdala of infected rats. In a separate experiment, rats with lesions in the amygdala did not express fear or anxiety towards unwanted stimuli. These rats pulled on levers supplying food that sometimes sent out electrical shocks. While they learned to avoid pressing on them, they did not distance themselves from these shock-inducing levers.
Several brain structures other than the amygdala have also been observed to be activated when individuals are presented with fearful vs. neutral faces, namely the occipitocerebellar regions including the fusiform gyrus and the inferior parietal / superior temporal gyri. Interestingly, fearful eyes, brows and mouth seem to separately reproduce these brain responses. Scientist from Zurich studies show that the hormone oxytocin related to stress and sex reduces activity in your brain fear center.
Pheromones and why fear can be contagious.
In threatening situations insects, aquatic organisms, birds, reptiles, and mammals emit odorant substances, initially called alarm substances, which are chemical signals now called alarm pheromones ("Schreckstoff" in German). This is to defend themselves and at the same time to inform members of the same species of danger and leads to observable behavior change like freezing, defensive behavior, or dispersion depending on circumstances and species. For example, stressed rats release odorant cues that cause other rats to move away from the source of the signal. Pheromones are synthesized, emitted and perceived by all living organisms studied to date, with the exception of viruses and prions: i.e. in bacteria, prokaryotes, plants, plankton, parasites, insects, invertebrates and vertebrates (aquatic organisms, birds, reptiles, and mammals).
After the discovery of pheromones in 1959, alarm pheromones were first described in 1968 in ants and earthworms, and 4 years later also found in mammals, both mice and rats. Over the next two decades identification and characterization of these pheromones proceeded in all manner of insects and sea animals, including fish, but it was not until 1990 that more insight into mammalian alarm pheromones was gleaned.
Early on, in 1985, a link between odors released by stressed rats and pain perception was discovered: unstressed rats exposed to these odors developed opioid-mediated analgesia. In 1997, researchers found bees became less responsive to pain after they had been stimulated with isoamyl acetate, a chemical smelling of banana, and a component of bee alarm pheromone. The experiment also showed that the bees' fear-induced pain tolerance was mediated by an endorphine.
By using the forced swimming test in rats as a model of fear-induction, the first mammalian "alarm substance" was found.
In 1991, this "alarm substance" was shown to fulfill criteria for pheromones: well-defined behavioral effect, species specificity, minimal influence of experience and control for nonspecific arousal. Rat activity testing with alarm pheromone and their preference/avoidance for odors from cylinders containing the pheromone showed, that the pheromone had very low volatility.
In 1993 a connection between alarm chemosignals in mice and their immune response was found.
Pheromone production in mice was found to be associated with or mediated by the pituitary gland in 1994.
It was not until 2011 that a link between severe pain, neuroinflammation and alarm pheromones release in rats was found: real time RT-PCR analysis of rat brain tissues indicated that shocking the footpad of a rat increased its production of proinflammatory cytokines in deep brain structures, namely of IL-1β, heteronuclear Corticotropin-releasing hormone and c-fos mRNA expressions in both the paraventricular nucleus and the bed nucleus of the stria terminalis, and it increased stress hormone levels in plasma (corticosterone).
In 2004, it was demonstrated that rats’ alarm pheromones had different effects on the “recipient“ rat (the rat perceiving the pheromone) depending which body region they were released from: Pheromone production from the face modified behavior in the recipient rat, e.g. caused sniffing or movement, whereas pheromone secreted from the rat's anal area induced autonomic nervous system stress responses, like an increase in core body temperature. Further experiments showed that when a rat perceived alarm pheromones, it increased its defensive and risk assessment behavior. and its acoustic startle reflex was enhanced.
The neurocircuit for how rats perceive alarm pheromones was shown to be related to hypothalamus, brainstem, and amygdala, all of which are evolutionary ancient structures deep inside or in the case of the brainstem underneath the brain away from the cortex, and involved in the Fight-or-flight response, as is the case in humans.
Alarm pheromone-induced anxiety in rats has been used to evaluate the degree to which anxiolytics can alleviate anxiety in humans. For this the change in the acoustic startle reflex of rats with alarm pheromone-induced anxiety (i.e. reduction of defensiveness) has been measured. Pretreatment of rats with one of five anxiolytics used in clinical medicine was able to reduce their anxiety: namely midazolam, phenelzine (a nonselective monoamine oxidase (MAO) inhibitor), propranolol, a nonselective beta blocker, clonidine, an alpha 2 adrenergic agonist or CP-154,526, a corticotropin-releasing hormone antagonist.
Faulty development of odor discrimination impairs the perception of pheromones and pheromone-related behavior, like aggressive behavior and mating in male rats: The enzyme Mitogen-activated protein kinase 7 (MAPK7) has been implicated in regulating the development of the olfactory bulb and odor discrimination and it is highly expressed in developing rat brains, but absent in most regions of adult rat brains. conditional deletion of the MAPK7gene in mouse neural stem cells impairs several pheromone-mediated behaviors, including aggression and mating in male mice. These behavior impairments were not caused by a reduction in the level of testosterone, by physical immobility, by heightened fear or anxiety or by depression. Using mouse urine as a natural pheromone-containing solution, it has been shown that the impairment was associated with defective detection of related pheromones, and with changes in their inborn preference for pheromones related to sexual and reproductive activities.
Lastly, alleviation of an acute fear response because a friendly peer (or in biological language: an affiliative conspecific) tends and befriends is called "social buffering". The term is in analogy to the 1985 "buffering" hypothesis in psychology, where social support has been proven to mitigate the negative health effects of alarm pheromone mediated distress. The role of a "social pheromone" is suggested by the recent discovery that olfactory signals are responsible in mediating the "social buffering" in male rats. "Social buffering" was also observed to mitigate the conditioned fear responses of honeybees. A bee colony exposed to an environment of high threat of predation did not show increased aggression and aggressive-like gene expression patterns in individual bees, but decreased aggression. That the bees did not simply habituate to threats is suggested by the fact that the disturbed colonies also decreased their foraging.
Biologists have proposed in 2012 that fear pheromones evolved as molecules of "keystone significance", a term coined in analogy to keystone species. Pheromones may determine species compositions, and affect rates of energy and material exchange in an ecological community. Thus pheromones generate structure in a trophic web and play critical roles in maintaining natural systems.
Fear pheromones in humans.
Evidence of chemosensory alarm signals in humans has emerged slowly: Although alarm pheromones have not been physically isolated and their chemical structure has not been identified in man so far, there is evidence for their presence. Androstadienone, for example, a steroidal, endogenous odorant, is a pheromone candidate found in human sweat, axillary hair and plasma. The closely related compound androstenone is involved in communicating dominance, aggression or competition; sex hormone influences on androstenone perception in humans showed high testosterone level related to heightened androstenone sensitivity in men, a high testosterone level related to unhappiness in response to androstenone in men, and a high estradiol level related to disliking of androstenone in women.
A German study from 2006 showed when anxiety-induced versus exercise-induced human sweat from a dozen people was pooled and offered to seven study participants, of five able to olfactorily distinguish exercise-induced sweat from room air, three could also distinguish exercise-induced sweat from anxiety induced sweat. The acoustic startle reflex response to a sound when sensing anxiety sweat was larger than when sensing exercise-induced sweat, as measured by electromyograph analysis of the orbital muscle, which is responsible for the eyeblink component. This showed for the first time that fear chemosignals can modulate the startle reflex in humans without emotional mediation; fear chemosignals primed the recipient's "defensive behavior" prior to the subjects' conscious attention on the acoustic startle reflex level.
In analogy to the social buffering of rats and honeybees in response to chemosignals, induction of empathy by "smelling anxiety" of another person has been found in humans.
A study from 2013 provided brain imaging evidence that human responses to fear chemosignals may be gender-specific. Researchers collected alarm-induced sweat and exercise-induced sweat from donors extracted it, pooled it and presented it to 16 unrelated people undergoing functional brain MRI. While stress-induced sweat from males produced a comparably strong emotional response in both females and males, stress-induced sweat from females produced a markedly stronger arousal in women than in men. Statistical tests pinpointed this gender-specificity to the right amygdala and strongest in the superficial nuclei. Since no significant differences were found in the olfactory bulb, the response to female fear-induced signals is likely based on processing the meaning, i.e. on the emotional level, rather than the strength of chemosensory cues from each gender, i.e. the perceptual level.
An approach-avoidance task was set up where volunteers seeing either an angry or a happy cartoon face on a computer screen pushed away or pulled toward them a joystick as fast as possible. Volunteers smelling anandrostadienone, masked with clove oil scent responded faster, especially to angry faces, than those smelling clove oil only, which was interpreted as anandrostadienone-related activation of the fear system. A potential mechanism of action is, that androstadienone alters the "emotional face processing". Androstadienone is known to influence activity of the fusiform gyrus which is relevant for face recognition.
In culture.
Death.
The fear of the end and its existence is in other words the fear of death. The fear of death ritualized the lives of our ancestors. These rituals were designed to reduce that fear; they helped collect the cultural ideas that we now have in the present. These rituals also helped preserve the cultural ideas. The results and methods of human existence had been changing at the same time that social formation was changing. One can say that the formation of communities happened because people lived in fear. The result of this fear forced people to unite to fight dangers together rather than fight alone.
Religion.
Religions are filled with different fears that humans have had throughout many centuries. The fears aren't just metaphysical (including the problems of life and death) but are also moral. Death is seen as a boundary to another world. That world would always be different depending on how each individual lived their lives. The origins of this intangible fear are not found in the present world. In a sense we can assume that fear was a big influence on things such as morality. This assumption, however, flies in the face of concepts such as Moral Absolutism and Moral Universalism – which would hold that our morals are rooted in either the divine or natural laws of the universe, and would not be generated by any human feeling, thought or emotion.
There is another fear in the Bible that has a different meaning; the fear of God. Fear is used to express a Filial or a slavish passion. In believers the fear of god is "holy awe" or "reverence" of a particular god and the laws of its associated religion.
Manipulation.
Fear may be politically and culturally manipulated to persuade citizenry of ideas which would otherwise be widely rejected or dissuade citizenry from ideas which would otherwise be wildly supported. In contexts of disasters, nation-states manage the fear not only to provide their citizens with an explanation about the event or blaming some minorities, but also to adjust their previous beliefs. The manipulation of fear is done by means of symbolic instruments as terror movies and the administration ideologies that lead to nationalism. After a disaster, the fear is re-channeled in a climate of euphoria based on patriotism. The fear and evilness are inextricably intertwined.
Mirroring fears.
Fear is found in mythology and folklore, and portrayed in books and movies. 
The Story of the Youth Who Went Forth to Learn What Fear Was is a German fairy tale dealing with the topic of not knowing fear.
For example, many stories include characters who fear the antagonist of the plot. One of the important characteristics of historical and mythical heroes across cultures is to be fearless in the face of big and often lethal enemies.
Overcoming.
Pharmaceutical.
A drug treatment for fear conditioning and phobias via the amygdala is the use of glucocorticoids. In one study, glucocorticoid receptors in the central nucleus of the amygdala were disrupted in order to better understand the mechanisms of fear and fear conditioning. The glucocorticoid receptors were inhibited using lentiviral vectors containing Cre-recombinase injected into mice. Results showed that disruption of the glucocorticoid receptors prevented conditioned fear behavior. The mice were subjected to auditory cues which caused them to freeze normally. However, a reduction of freezing was observed in the mice that had inhibited glucocorticoid receptors.
Psychology.
Cognitive behavioral therapy has been successful in helping people overcome fear. Because fear is more complex than just forgetting or deleting memories, an active and successful approach involves people repeatedly confronting their fears. By confronting their fears in a safe manner a person can suppress the fear-triggering memory or stimulus. Known as ‘exposure therapy’, this practice can help cure up to 90% of people, with specific phobias.
Inability to experience.
People who have damage to the amygdala, such as from Urbach–Wiethe disease, are unable to experience fear. This is not debilitating, but a lack of fear can allow someone to get into a dangerous situation they otherwise would have avoided.

</doc>
<doc id="10830" url="https://en.wikipedia.org/wiki?curid=10830" title="Football team">
Football team

A football team is the collective name given to a group of players selected together in the various team sports known as football. 
Such teams could be selected to play in a match against an opposing team, to represent a football club, group, state or nation, an All-star team or even selected as a hypothetical team (such as a Dream Team or Team of the Century) and never play an actual match. 
There are several varieties of football, notably Association football, Gridiron football, Australian rules football, Gaelic football, rugby league, and rugby union. The number of players selected for each team within these varieties and their associated codes can vary substantially. Sometimes, the word "team" is limited to those who play on the field in a match and does not always include other players who may take part as replacements or emergency players. "Football squad" may be used to be inclusive of these support and reserve players.
The term football club is the most commonly used for a sports club which is an organised or incorporated body with a president, committee and a set of rules responsible for ensuring the continued playing existence of one or more teams which are selected for regular competition play (and which may participate in several different divisions or leagues). The oldest football clubs date back to the early 19th century. The words team and club are sometimes used interchangeably by supporters, although they typically refer to the team within the club playing in the highest division or competition.
Variation of player numbers among football codes.
The number of players that take part in the sport simultaneously, thus forming the team are:

</doc>
<doc id="10831" url="https://en.wikipedia.org/wiki?curid=10831" title="F">
F

F (named "ef" ) is the sixth letter in the modern English alphabet and the ISO basic Latin alphabet.
History.
The origin of 'F' is the Semitic letter "vâv" (or "waw") that represented a sound like or . Graphically it originally probably depicted either a hook or a club. It may have been based on a comparable Egyptian hieroglyph such as (transliterated as ḥ(dj)): T3
The Phoenician form of the letter was adopted into Greek as a vowel, "upsilon" (which resembled its descendant 'Y' but was also the ancestor of the Roman letters 'U', 'V', and 'W'); and, with another form, as a consonant, "digamma", which indicated the pronunciation , as in Phoenician. Latin 'F,' despite being pronounced differently, is ultimately descended from digamma and closely resembles it in form.
After sound changes eliminated from spoken Greek, "digamma" was used only as a numeral. However, the Greek alphabet also gave rise to other alphabets, and some of these retained letters descended from digamma. In the Etruscan alphabet, 'F' probably represented , as in Greek, and the Etruscans formed the digraph 'FH' to represent . (At the time these letters were borrowed, there was no Greek letter that represented /f/: the Greek letter phi 'Φ' then represented an aspirated voiceless bilabial plosive , although in Modern Greek it has come to represent .) When the Romans adopted the alphabet, they used 'V' (from Greek "upsilon") not only for the vowel , but also for the corresponding semivowel , leaving 'F' available for . And so out of the various "vav" variants in the Mediterranean world, the letter F entered the Roman alphabet attached to a sound which its antecedents in Greek and Etruscan did not have. The Roman alphabet forms the basis of the alphabet used today for English and many other languages.
The lowercase ' f ' is not related to the visually similar long s, ' ſ ' (or medial s). The use of the "long s" largely died out by the beginning of the 19th century, mostly to prevent confusion with ' f ' when using a short mid-bar (see more at: S).
Use in writing systems.
English.
In the English writing system is used to represent the sound , the voiceless labiodental fricative. It is commonly doubled at the end of words. Exceptionally, it represents the voiced labiodental fricative in the common word "of".
Other languages.
In the writing systems of other languages, commonly represents , or .
Other systems.
The International Phonetic Alphabet uses to represent the voiceless labiodental fricative.
Other uses.
In English-language online slang, "F" (with the pronunciation spelling "eff") is used as an initialism for "fuck". (e.g. "F U", meaning "fuck you"). The "F-word" refers to the word "fuck" itself.
In school grading "F" stands for Fail.

</doc>
<doc id="10834" url="https://en.wikipedia.org/wiki?curid=10834" title="Food preservation">
Food preservation

Food preservation involves preventing the growth of bacteria, fungi (such as yeasts), or other micro-organisms (although some methods work by introducing benign bacteria or fungi to the food), as well as retarding the oxidation of fats that cause rancidity. Food preservation may also include processes that inhibit visual deterioration, such as the enzymatic browning reaction in apples after they are cut during food preparation.
Many processes designed to preserve food will involve a number of food preservation methods. Preserving fruit by turning it into jam, for example, involves boiling (to reduce the fruit’s moisture content and to kill bacteria, etc.), sugaring (to prevent their re-growth) and sealing within an airtight jar (to prevent recontamination). Some traditional methods of preserving food have been shown to have a lower energy input and carbon footprint, when compared to modern methods. However, some methods of food preservation are known to create carcinogens, and in 2015, the International Agency for Research on Cancer of the World Health Organization classified processed meat, i.e. meat that has undergone salting, curing, fermenting, and smoking, as "carcinogenic to humans".
Maintaining or creating nutritional value, texture and flavor is an important aspect of food preservation, although, historically, some methods drastically altered the character of the food being preserved. In many cases these changes have come to be seen as desirable qualities – cheese, yogurt and pickled onions being common examples. 
Traditional techniques.
New techniques of food preservation became available to the home chef from the dawn of agriculture until the Industrial Revolution.
Drying.
Drying is one of the oldest techniques used to hamper the decomposition of food products. As early as 12,000 B.C., Middle Eastern and Oriental cultures were drying foods using the power of the sun. Vegetables and fruit are naturally dried by the sun and wind, but "still houses" were built in areas that did not have enough sunlight to dry things. A fire would be built inside the building to provide the heat to dry the various fruits, vegetables, and herbs.
Cooling.
Cooling preserves foods by slowing down the growth and reproduction of micro-organisms and the action of enzymes that cause food to rot. The introduction of commercial and domestic refrigerators drastically improved the diets of many in the Western world by allowing foods such as fresh fruit, salads and dairy products to be stored safely for longer periods, particularly during warm weather.
Freezing.
Freezing is also one of the most commonly used processes, both commercially and domestically, for preserving a very wide range of foods, including prepared foods that would not have required freezing in their unprepared state. For example, potato waffles are stored in the freezer, but potatoes themselves require only a cool dark place to ensure many months' storage. Cold stores provide large-volume, long-term storage for strategic food stocks held in case of national emergency in many countries.
Boiling.
Boiling liquid food items can kill any existing microbes. Milk and water are often boiled to kill any harmful microbes that may be present in them.
Heating.
Heating to temperatures which are sufficient to kill microorganisms inside the food is a method used with perpetual stews. Milk is also boiled before storing to kill many microorganisms.
Salting.
Salting or curing draws moisture from the meat through a process of osmosis. Meat is cured with salt or sugar, or a combination of the two. Nitrates and nitrites are also often used to cure meat and contribute the characteristic pink color, as well as inhibition of "Clostridium botulinum".
It was a main method of preservation in medieval times and around the 1700s.
Sugaring.
The earliest cultures have used sugar as a preservative, and it was commonplace to store fruit in honey. Similar to pickled foods, sugar cane was brought to Europe through the trade routes. In northern climates without sufficient sun to dry foods, preserves are made by heating the fruit with sugar. "Sugar tends to draw water from the microbes (plasmolysis). This process leaves the microbial cells dehydrated, thus killing them. In this way, the food will remain safe from microbial spoilage." Sugar is used to preserve fruits, either in an anti-microbial syrup with fruit such as apples, pears, peaches, apricots and plums, or in crystallized form where the preserved material is cooked in sugar to the point of crystallization and the resultant product is then stored dry. This method is used for the skins of citrus fruit (candied peel), angelica and ginger.
Also sugaring can be used in jam jellies.
Smoking.
Smoking is used to lengthen the shelf life of perishable food items. This effect is achieved by exposing the food to smoke from burning plant materials such as wood. Smoke deposits a number of pyrolysis products onto the food, including the phenols syringol, guaiacol and catechol. These compounds aid in the drying and preservation of meats and other foods. Most commonly subjected to this method of food preservation are meats and fish that have undergone curing. Fruits and vegetables like paprika, cheeses, spices, and ingredients for making drinks such as malt and tea leaves are also smoked, but mainly for cooking or flavoring them. It is one of the oldest food preservation methods, which probably arose after the development of cooking with fire.
Pickling.
Pickling is a method of preserving food in an edible anti-microbial liquid. Pickling can be broadly classified into two categories: chemical pickling and fermentation pickling.
In chemical pickling, the food is placed in an edible liquid that inhibits or kills bacteria and other micro-organisms. Typical pickling agents include brine (high in salt), vinegar, alcohol, and vegetable oil, especially olive oil but also many other oils. Many chemical pickling processes also involve heating or boiling so that the food being preserved becomes saturated with the pickling agent. Common chemically pickled foods include cucumbers, peppers, corned beef, herring, and eggs, as well as mixed vegetables such as piccalilli.
In fermentation pickling, the food itself produces the preservation agent, typically by a process that produces lactic acid. Fermented pickles include sauerkraut, nukazuke, kimchi, surströmming, and curtido. Some pickled cucumbers are also fermented.
Lye.
Sodium hydroxide (lye) makes food too alkaline for bacterial growth. Lye will saponify fats in the food, which will change its flavor and texture. Lutefisk uses lye in its preparation, as do some olive recipes. Modern recipes for century eggs also call for lye.
Canning.
Canning involves cooking food, sealing it in sterile cans or jars, and boiling the containers to kill or weaken any remaining bacteria as a form of sterilization. It was invented by the French confectioner Nicolas Appert. By 1806, this process was used by the French Navy to preserve meat, fruit, vegetables, and even milk. Although Appert had discovered a new way of preservation, it wasn't understood until 1864 when Louis Pasteur found the relationship between microorganisms, food spoilage, and illness.
Foods have varying degrees of natural protection against spoilage and may require that the final step occur in a pressure cooker. High-acid fruits like strawberries require no preservatives to can and only a short boiling cycle, whereas marginal vegetables such as carrots require longer boiling and addition of other acidic elements. Low-acid foods, such as vegetables and meats, require pressure canning. Food preserved by canning or bottling is at immediate risk of spoilage once the can or bottle has been opened.
Lack of quality control in the canning process may allow ingress of water or micro-organisms. Most such failures are rapidly detected as decomposition within the can causes gas production and the can will swell or burst. However, there have been examples of poor manufacture (underprocessing) and poor hygiene allowing contamination of canned food by the obligate anaerobe "Clostridium botulinum", which produces an acute toxin within the food, leading to severe illness or death. This organism produces no gas or obvious taste and remains undetected by taste or smell. Its toxin is denatured by cooking, however. Cooked mushrooms, handled poorly and then canned, can support the growth of Staphylococcus aureus, which produces a toxin that is not destroyed by canning or subsequent reheating.
Jellying.
Food may be preserved by cooking in a material that solidifies to form a gel. Such materials include gelatin, agar, maize flour, and arrowroot flour. Some foods naturally form a protein gel when cooked, such as eels and elvers, and sipunculid worms, which are a delicacy in Xiamen, in the Fujian province of the People's Republic of China. Jellied eels are a delicacy in the East End of London, where they are eaten with mashed potatoes. Potted meats in aspic (a gel made from gelatine and clarified meat broth) were a common way of serving meat off-cuts in the UK until the 1950s. Many jugged meats are also jellied.
A traditional British way of preserving meat (particularly shrimp) is by setting it in a pot and sealing it with a layer of fat. Also common is potted chicken liver; compare pâté.
Jugging.
Meat can be preserved by jugging. Jugging is the process of stewing the meat (commonly game or fish) in a covered earthenware jug or casserole. The animal to be jugged is usually cut into pieces, placed into a tightly-sealed jug with brine or gravy, and stewed. Red wine and/or the animal's own blood is sometimes added to the cooking liquid. Jugging was a popular method of preserving meat up until the middle of the 20th century.
Burial.
Burial of food can preserve it due to a variety of factors: lack of light, lack of oxygen, cool temperatures, pH level, or desiccants in the soil. Burial may be combined with other methods such as salting or fermentation. Most foods can be preserved in soil that is very dry and salty (thus a desiccant) such as sand, or soil that is frozen.
Many root vegetables are very resistant to spoilage and require no other preservation than storage in cool dark conditions, for example by burial in the ground, such as in a storage clamp. Century eggs are created by placing eggs in alkaline mud (or other alkaline substance), resulting in their "inorganic" fermentation through raised pH instead of spoiling. The fermentation preserves them and breaks down some of the complex, less flavorful proteins and fats into simpler, more flavorful ones. Cabbage was traditionally buried in the fall in northern farms in the U.S. for preservation. Some methods keep it crispy while other methods produce sauerkraut. A similar process is used in the traditional production of kimchi. Sometimes meat is buried under conditions that cause preservation. If buried on hot coals or ashes, the heat can kill pathogens, the dry ash can desiccate, and the earth can block oxygen and further contamination. If buried where the earth is very cold, the earth acts like a refrigerator.
In Orissa, India, it is practical to store rice by burying it underground. This method helps to store for three to six months during the dry season.
Curing.
The earliest form of curing was dehydration. To accelerate this process, salt is usually added. In the culinary world, it was common to choose raw salts from various sources (rock salt, sea salt, etc.). More modern "examples of salts that are used as preservatives include sodium chloride (NaCl), sodium nitrate (NaNO3) and sodium nitrite (NaNO2). Even at mild concentrations (up to 2%), sodium chloride, found in many food products, is capable of neutralizing the antimicrobial character of natural compounds."
Fermentation.
Some foods, such as many cheeses, wines, and beers, use specific micro-organisms that combat spoilage from other less-benign organisms. These micro-organisms keep pathogens in check by creating an environment toxic for themselves and other micro-organisms by producing acid or alcohol. Methods of fermentation include, but are not limited to, starter micro-organisms, salt, hops, controlled (usually cool) temperatures and controlled (usually low) levels of oxygen. These methods are used to create the specific controlled conditions that will support the desirable organisms that produce food fit for human consumption.
Fermentation is the microbial conversion of starch and sugars into alcohol. Not only can fermentation produce alcohol, but it can also be a valuable preservation technique. Fermentation can also make foods more nutritious and palatable. For example, drinking water in the Middle Ages was dangerous because it often contained pathogens that could spread disease. When the water is made into beer, the resulting alcohol kills any bacteria in the water that could make people sick. Additionally, the water now has the nutrients from the barley and other ingredients, and the microorganisms can also produce vitamins as they ferment.
Industrial/modern techniques.
Techniques of food preservation were developed in research laboratories for commercial applications.
Pasteurization.
Pasteurization is a process for preservation of liquid food. It was originally applied to combat the souring of young local wines. Today, the process is mainly applied to dairy products. In this method, milk is heated at about 70 °C for 15 to 30 seconds to kill the bacteria present in it and cooling it quickly to 10 °C to prevent the remaining bacteria from growing. The milk is then stored in sterilized bottles or pouches in cold places. This method was invented by Louis Pasteur, a French chemist, in 1862.
Vacuum packing.
Vacuum-packing stores food in a vacuum environment, usually in an air-tight bag or bottle. The vacuum environment strips bacteria of oxygen needed for survival. Vacuum-packing is commonly used for storing nuts to reduce loss of flavor from oxidization. A major drawback to vacuum packaging, at the consumer level, is that vacuum sealing can deform contents and rob certain foods, such as cheese, of its flavor.
Artificial food additives.
Preservative food additives can be "antimicrobial", which inhibit the growth of bacteria or fungi, including mold, or "antioxidant", such as oxygen absorbers, which inhibit the oxidation of food constituents. Common antimicrobial preservatives include calcium propionate, sodium nitrate, sodium nitrite, sulfites (sulfur dioxide, sodium bisulfite, potassium hydrogen sulfite, etc.) and disodium EDTA. Antioxidants include BHA and BHT. Other preservatives include formaldehyde (usually in solution), glutaraldehyde (kills insects), ethanol, and methylchloroisothiazolinone.
Irradiation.
Irradiation of food is the exposure of food to ionizing radiation. The two types of ionizing radiation used are beta particles (high-energy electrons) and gamma rays (emitted from radioactive sources as cobalt-60 or cesium-137). Treatment effects include killing bacteria, molds, and insect pests, reducing the ripening and spoiling of fruits, and at higher doses inducing sterility. The technology may be compared to pasteurization; it is sometimes called "cold pasteurization", as the product is not heated.
The irradiation process is not directly related to nuclear energy, but does use radioactive isotopes produced in nuclear reactors. Cobalt-60, for example does not occur naturally and can only be produced through neutron bombardment of cobalt-59. Ionizing radiation at high energy levels is hazardous to life (hence its usefulness in sterilisation); for this reason, irradiation facilities have a heavily shielded irradiation room where the process takes place. Radiation safety procedures are used to ensure that neither the workers in such facilities nor the environment receives any radiation dose above administrative limits. Irradiated food does not and cannot become radioactive, and national and international expert bodies have declared food irradiation as wholesome. However, the wholesomeness of consuming such food is disputed by opponents and consumer organizations. National and international expert bodies have declared food irradiation as "wholesome"; organizations of the United Nations, such as the World Health Organization and Food and Agriculture Organization, endorse food irradiation. International legislation on whether food may be irradiated or not varies worldwide from no regulation to full banning. Irradiation may allow lower-quality or contaminated foods to be rendered marketable.
Approximately 500,000 tons of food items are irradiated per year worldwide in over 40 countries. These are mainly spices and condiments with an increasing segment of fresh fruit irradiated for fruit fly quarantine.
Pulsed electric field electroporation.
Pulsed electric field (PEF) electroporation is a method for processing cells by means of brief pulses of a strong electric field. PEF holds potential as a type of low-temperature alternative pasteurization process for sterilizing food products. In PEF processing, a substance is placed between two electrodes, then the pulsed electric field is applied. The electric field enlarges the pores of the cell membranes, which kills the cells and releases their contents. PEF for food processing is a developing technology still being researched. There have been limited industrial applications of PEF processing for the pasteurization of fruit juices. To date, several PEF treated juices are available on the market in Europe. Furthermore, for several years a juice pasteurization application in the US has used PEF.
For cell disintegration purposes especially potato processors show great interest in PEF technology as an efficient alternative for their preheaters. Potato applications are already operational in the US and Canada. There are also commercial PEF potato applications in various countries in Europe, as well as in Australia, India and China.
Modified atmosphere.
Modifying atmosphere is a way to preserve food by operating on the atmosphere around it. Salad crops that are notoriously difficult to preserve are now being packaged in sealed bags with an atmosphere modified to reduce the oxygen (O2) concentration and increase the carbon dioxide (CO2) concentration. There is concern that, although salad vegetables retain their appearance and texture in such conditions, this method of preservation may not retain nutrients, especially vitamins.
There are two methods for preserving grains with carbon dioxide. One method is placing a block of dry ice in the bottom and filling the can with the grain. Another method is purging the container from the bottom by gaseous carbon dioxide from a cylinder or bulk supply vessel.
Carbon dioxide prevents insects and, depending on concentration, mold and oxidation from damaging the grain. Grain stored in this way can remain edible for approximately five years.
Nitrogen gas (N2) at concentrations of 98% or higher is also used effectively to kill insects in the grain through hypoxia. However, carbon dioxide has an advantage in this respect, as it kills organisms through hypercarbia and hypoxia (depending on concentration), but it requires concentrations of above 35%, or so. This makes carbon dioxide preferable for fumigation in situations where a hermetic seal cannot be maintained.
Controlled Atmospheric Storage (CA): "CA storage is a non-chemical process. Oxygen levels in the sealed rooms are reduced, usually by the infusion of nitrogen gas, from the approximate 21 percent in the air we breathe to 1 percent or 2 percent. Temperatures are kept at a constant . Humidity is maintained at 95 percent and carbon dioxide levels are also controlled. Exact conditions in the rooms are set according to the apple variety. Researchers develop specific regimens for each variety to achieve the best quality. Computers help keep conditions constant."
"Eastern Washington, where most of Washington’s apples are grown, has enough warehouse storage for 181 million boxes of fruit, according to a report done in 1997 by managers for the Washington State Department of Agriculture Plant Services Division. The storage capacity study shows that 67 percent of that space —enough for 121,008,000 boxes of apples — is CA storage."
Air-tight storage of grains (sometimes called hermetic storage) relies on the respiration of grain, insects, and fungi that can modify the enclosed atmosphere sufficiently to control insect pests. This is a method of great antiquity, as well as having modern equivalents. The success of the method relies on having the correct mix of sealing, grain moisture, and temperature.
A patented process uses fuel cells to exhaust and automatically maintain the exhaustion of oxygen in a shipping container, containing, for example, fresh fish.
Nonthermal plasma.
This process subjects the surface of food to a "flame" of ionized gas molecules, such as helium or nitrogen. This causes micro-organisms to die off on the surface.
High-pressure food preservation.
High-pressure food preservation or pascalization refers to the use of a food preservation technique that makes use of high pressure. "Pressed inside a vessel exerting or more, food can be processed so that it retains its fresh appearance, flavor, texture and nutrients while disabling harmful microorganisms and slowing spoilage." By 2005, the process was being used for products ranging from orange juice to guacamole to deli meats and widely sold.
Biopreservation.
Biopreservation is the use of natural or controlled microbiota or antimicrobials as a way of preserving food and extending its shelf life. Beneficial bacteria or the fermentation products produced by these bacteria are used in biopreservation to control spoilage and render pathogens inactive in food. It is a benign ecological approach which is gaining increasing attention.
Of special interest are lactic acid bacteria (LAB). Lactic acid bacteria have antagonistic properties that make them particularly useful as biopreservatives. When LABs compete for nutrients, their metabolites often include active antimicrobials such as lactic acid, acetic acid, hydrogen peroxide, and peptide bacteriocins. Some LABs produce the antimicrobial nisin, which is a particularly effective preservative.
These days, LAB bacteriocins are used as an integral part of hurdle technology. Using them in combination with other preservative techniques can effectively control spoilage bacteria and other pathogens, and can inhibit the activities of a wide spectrum of organisms, including inherently resistant Gram-negative bacteria.
Hurdle technology.
Hurdle technology is a method of ensuring that pathogens in food products can be eliminated or controlled by combining more than one approach. These approaches can be thought of as "hurdles" the pathogen has to overcome if it is to remain active in the food. The right combination of hurdles can ensure all pathogens are eliminated or rendered harmless in the final product.
Hurdle technology has been defined by Leistner (2000) as an intelligent combination of hurdles that secures the microbial safety and stability as well as the organoleptic and nutritional quality and the economic viability of food products. The organoleptic quality of the food refers to its sensory properties, that is its look, taste, smell, and texture.
Examples of hurdles in a food system are high temperature during processing, low temperature during storage, increasing the acidity, lowering the water activity or redox potential, and the presence of preservatives or biopreservatives. According to the type of pathogens and how risky they are, the intensity of the hurdles can be adjusted individually to meet consumer preferences in an economical way, without sacrificing the safety of the product.

</doc>
<doc id="10835" url="https://en.wikipedia.org/wiki?curid=10835" title="Frequency modulation">
Frequency modulation

In telecommunications and signal processing, frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. This contrasts with amplitude modulation, in which the amplitude of the carrier wave varies, while the frequency remains constant.
In analog frequency modulation, such as FM radio broadcasting of an audio signal representing voice or music, the instantaneous frequency deviation, the difference between the frequency of the carrier and its center frequency, is proportional to the modulating signal.
Digital data can be encoded and transmitted via FM by shifting the carrier's frequency among a predefined set of frequencies representing digits - for example one frequency can represent a binary 1 and a second can represent binary 0. This modulation technique is known as frequency-shift keying (FSK). FSK is widely used in modems and fax modems, and can also be used to send Morse code. Radioteletype also uses FSK.
Frequency modulation is widely used for FM radio broadcasting. It is also used in telemetry, radar, seismic prospecting, and monitoring newborns for seizures via EEG, two-way radio systems, music synthesis, magnetic tape-recording systems and some video-transmission systems. In radio transmission, an advantage of frequency modulation is that it has a larger signal-to-noise ratio and therefore rejects radio frequency interference better than an equal power amplitude modulation (AM) signal. For this reason, most music is broadcast over FM radio.
Frequency modulation has a close relationship with phase modulation; phase modulation is often used as an intermediate step to achieve frequency modulation. Mathematically both of these are considered a special case of quadrature amplitude modulation (QAM).
Theory.
If the information to be transmitted (i.e., the baseband signal) is formula_1 and the sinusoidal carrier is formula_2, where "fc" is the carrier's base frequency, and "Ac" is the carrier's amplitude, the modulator combines the carrier with the baseband data signal to get the transmitted signal:
In this equation, formula_6 is the "instantaneous frequency" of the oscillator and formula_7 is the "frequency deviation", which represents the maximum shift away from "fc" in one direction, assuming "x""m"("t") is limited to the range ±1.
While most of the energy of the signal is contained within "fc" ± "f"Δ, it can be shown by Fourier analysis that a wider range of frequencies is required to precisely represent an FM signal. The frequency spectrum of an actual FM signal has components extending infinitely, although their amplitude decreases and higher-order components are often neglected in practical design problems.
Sinusoidal baseband signal.
Mathematically, a baseband modulated signal may be approximated by a sinusoidal continuous wave signal with a frequency "fm".This method is also named as Single-tone Modulation.The integral of such a signal is:
In this case, the expression for y(t) above simplifies to:
where the amplitude formula_10 of the modulating sinusoid is represented by the peak deviation formula_7 (see frequency deviation).
The harmonic distribution of a sine wave carrier modulated by such a sinusoidal signal can be represented with Bessel functions; this provides the basis for a mathematical understanding of frequency modulation in the frequency domain.
Modulation index.
As in other modulation systems,the modulation index indicates by how much the modulated variable varies around its unmodulated level. It relates to variations in the carrier frequency:
where formula_13 is the highest frequency component present in the modulating signal "x""m"("t"), and formula_14 is the peak frequency-deviation—i.e. the maximum deviation of the "instantaneous frequency" from the carrier frequency. For a sine wave modulation, the modulation index is seen to be the ratio of the peak frequency deviation of the carrier wave to the frequency of the modulating sine wave.
If formula_15, the modulation is called narrowband FM, and its bandwidth is approximately formula_16.Sometimes modulation index h<0.3 rad is considered as Narrowband FM otherwise Wideband FM.
For digital modulation systems, for example Binary Frequency Shift Keying (BFSK), where a binary signal modulates the carrier, the modulation index is given by:
where formula_18 is the symbol period, and formula_19 is used as the highest frequency of the modulating binary waveform by convention, even though it would be more accurate to say it is the highest "fundamental" of the modulating binary waveform. In the case of digital modulation, the carrier formula_20 is never transmitted. Rather, one of two frequencies is transmitted, either formula_21 or formula_22, depending on the binary state 0 or 1 of the modulation signal.
If formula_23, the modulation is called "wideband FM" and its bandwidth is approximately formula_24. While wideband FM uses more bandwidth, it can improve the signal-to-noise ratio significantly; for example, doubling the value of formula_14, while keeping formula_26 constant, results in an eight-fold improvement in the signal-to-noise ratio. (Compare this with Chirp spread spectrum, which uses extremely wide frequency deviations to achieve processing gains comparable to traditional, better-known spread-spectrum modes).
With a tone-modulated FM wave, if the modulation frequency is held constant and the modulation index is increased, the (non-negligible) bandwidth of the FM signal increases but the spacing between spectra remains the same; some spectral components decrease in strength as others increase. If the frequency deviation is held constant and the modulation frequency increased, the spacing between spectra increases.
Frequency modulation can be classified as narrowband if the change in the carrier frequency is about the same as the signal frequency, or as wideband if the change in the carrier frequency is much higher (modulation index >1) than the signal frequency.
Bessel functions.
For the case of a carrier modulated by a single sine wave, the resulting frequency spectrum can be calculated using Bessel functions of the first kind, as a function of the sideband number and the modulation index. The carrier and sideband amplitudes are illustrated for different modulation indices of FM signals. For particular values of the modulation index, the carrier amplitude becomes zero and all the signal power is in the sidebands.
Since the sidebands are on both sides of the carrier, their count is doubled, and then multiplied by the modulating frequency to find the bandwidth. For example, 3 kHz deviation modulated by a 2.2 kHz audio tone produces a modulation index of 1.36. Suppose that we limit ourselves to only those sidebands that have a relative amplitude of at least 0.01. Then, examining the chart shows this modulation index will produce three sidebands. These three sidebands, when doubled, gives us (6 * 2.2 kHz) or a 13.2 kHz required bandwidth.
Carson's rule.
A rule of thumb, "Carson's rule" states that nearly all (~98 percent) of the power of a frequency-modulated signal lies within a bandwidth formula_27 of:
where formula_29, as defined above, is the peak deviation of the instantaneous frequency formula_30 from the center carrier frequency formula_20 andformula_13 is the highest frequency in the modulating signal.
Condition for application of Carson's rule is only sinusoidal signals.
Noise reduction.
A major advantage of FM in a communications circuit, compared for example with AM, is the possibility of improved Signal-to-noise ratio (SNR). Compared with an optimum AM scheme, FM typically has poorer SNR below a certain signal level called the noise threshold, but above a higher level – the full improvement or full quieting threshold – the SNR is much improved over AM. The improvement depends on modulation level and deviation. For typical voice communications channels, improvements are typically 5-15 dB. FM broadcasting using wider deviation can achieve even greater improvements. Additional techniques, such as pre-emphasis of higher audio frequencies with corresponding de-emphasis in the receiver, are generally used to improve overall SNR in FM circuits. Since FM signals have constant amplitude, FM receivers normally have limiters that remove AM noise, further improving SNR.
Implementation.
Modulation.
FM signals can be generated using either direct or indirect frequency modulation:
Demodulation.
Many FM detector circuits exist. A common method for recovering the information signal is through a Foster-Seeley discriminator. A phase-locked loop can be used as an FM demodulator. "Slope detection" demodulates an FM signal by using a tuned circuit which has its resonant frequency slightly offset from the carrier. As the frequency rises and falls the tuned circuit provides a changing amplitude of response, converting FM to AM. AM receivers may detect some FM transmissions by this means, although it does not provide an efficient means of detection for FM broadcasts.
Applications.
Magnetic tape storage.
FM is also used at intermediate frequencies by analog VCR systems (including VHS) to record the luminance (black and white) portions of the video signal. Commonly, the chrominance component is recorded as a conventional AM signal, using the higher-frequency FM signal as bias. FM is the only feasible method of recording the luminance ("black and white") component of video to (and retrieving video from) magnetic tape without distortion; video signals have a large range of frequency components – from a few hertz to several megahertz, too wide for equalizers to work with due to electronic noise below −60 dB. FM also keeps the tape at saturation level, acting as a form of noise reduction; a limiter can mask variations in playback output, and the FM capture effect removes print-through and pre-echo. A continuous pilot-tone, if added to the signal – as was done on V2000 and many Hi-band formats – can keep mechanical jitter under control and assist timebase correction.
These FM systems are unusual, in that they have a ratio of carrier to maximum modulation frequency of less than two; contrast this with FM audio broadcasting, where the ratio is around 10,000. Consider, for example, a 6-MHz carrier modulated at a 3.5-MHz rate; by Bessel analysis, the first sidebands are on 9.5 and 2.5 MHz and the second sidebands are on 13 MHz and −1 MHz. The result is a reversed-phase sideband on +1 MHz; on demodulation, this results in unwanted output at 6−1 = 5 MHz. The system must be designed so that this unwanted output is reduced to an acceptable level.
Sound.
FM is also used at audio frequencies to synthesize sound. This technique, known as FM synthesis, was popularized by early digital synthesizers and became a standard feature in several generations of personal computer sound cards.
Radio.
Edwin Howard Armstrong (1890–1954) was an American electrical engineer who invented wideband frequency modulation (FM) radio.
He patented the regenerative circuit in 1914, the superheterodyne receiver in 1918 and the super-regenerative circuit in 1922. Armstrong presented his paper, "A Method of Reducing Disturbances in Radio Signaling by a System of Frequency Modulation", (which first described FM radio) before the New York section of the Institute of Radio Engineers on November 6, 1935. The paper was published in 1936.
As the name implies, wideband FM (WFM) requires a wider signal bandwidth than amplitude modulation by an equivalent modulating signal; this also makes the signal more robust against noise and interference. Frequency modulation is also more robust against signal-amplitude-fading phenomena. As a result, FM was chosen as the modulation standard for high frequency, high fidelity radio transmission, hence the term "FM radio" (although for many years the BBC called it "VHF radio" because commercial FM broadcasting uses part of the VHF band—the FM broadcast band). FM receivers employ a special detector for FM signals and exhibit a phenomenon known as the "capture effect", in which the tuner "captures" the stronger of two stations on the same frequency while rejecting the other (compare this with a similar situation on an AM receiver, where both stations can be heard simultaneously). However, frequency drift or a lack of selectivity may cause one station to be overtaken by another on an adjacent channel. Frequency drift was a problem in early (or inexpensive) receivers; inadequate selectivity may affect any tuner.
An FM signal can also be used to carry a stereo signal; this is done with multiplexing and demultiplexing before and after the FM process. The FM modulation and demodulation process is identical in stereo and monaural processes. A high-efficiency radio-frequency switching amplifier can be used to transmit FM signals (and other constant-amplitude signals). For a given signal strength (measured at the receiver antenna), switching amplifiers use less battery power and typically cost less than a linear amplifier. This gives FM another advantage over other modulation methods requiring linear amplifiers, such as AM and QAM.
FM is commonly used at VHF radio frequencies for high-fidelity broadcasts of music and speech. Analog TV sound is also broadcast using FM. Narrowband FM is used for voice communications in commercial and amateur radio settings. In broadcast services, where audio fidelity is important, wideband FM is generally used. In two-way radio, narrowband FM (NBFM) is used to conserve bandwidth for land mobile, marine mobile and other radio services.

</doc>
<doc id="10837" url="https://en.wikipedia.org/wiki?curid=10837" title="Faith and rationality">
Faith and rationality

Faith and rationality are two ideologies that exist in varying degrees of conflict or compatibility. Rationality is based on reason or facts. Faith is belief in inspiration, revelation, or authority. The word "faith" usually refers to a belief that is held with lack of, in spite of or against reason or evidence, while another position holds that it can refer to belief based upon a degree of evidential warrant.
Although the words "faith" and "belief" are sometimes erroneously conflated and used as synonyms, "faith" properly refers to a particular type (or subset) of "belief," as defined above.
Broadly speaking, there are two categories of views regarding the relationship between faith and rationality:
The Catholic Church also has taught that true faith and correct reason can and must work together, and, viewed properly, can never be in conflict with one another, as both have their origin in God, as stated in the Papal encyclical letter issued by Pope John Paul II, "Fides et Ratio" (" Faith and Reason").
Relationship between faith and reason.
From at least the days of the Greek Philosophers, the relationship between faith and reason has been hotly debated. Plato argued that knowledge is simply memory of the eternal. Aristotle set down rules by which knowledge could be discovered by reason.
Rationalists point out that many people hold irrational beliefs, for many reasons. There may be evolutionary causes for irrational beliefs — irrational beliefs may increase our ability to survive and reproduce. Or, according to Pascal's Wager, it may be to our advantage to have faith, because faith may promise infinite rewards, while the rewards of reason are seen by many as finite. One more reason for irrational beliefs can perhaps be explained by operant conditioning. For example, in one study by B. F. Skinner in 1948, pigeons were awarded grain at regular time intervals regardless of their behaviour. The result was that each of pigeons developed their own idiosyncratic response which had become associated with the consequence of receiving grain.
Believers in faith — for example those who believe salvation is possible through faith alone — frequently suggest that everyone holds beliefs arrived at by faith, not reason. The belief that the universe is a sensible place and that our minds allow us to arrive at correct conclusions about it, is a belief we hold through faith. Rationalists contend that this is arrived at because they have observed the world being consistent and sensible, not because they have faith that it is.
Beliefs held "by faith" may be seen existing in a number of relationships to rationality:
Views of the Roman Catholic Church.
St. Thomas Aquinas, the most important doctor of the Catholic Church, was the first to write a full treatment of the relationship, differences, and similarities between faith—an intellectual assent—and reason, predominately in his "Summa Theologica", "De Veritate", and "Summa contra Gentiles".
The Council of Trent's catechism—the "Roman Catechism", written during the Catholic Church's Counter-Reformation to combat Protestantism and Martin Luther's antimetaphysical tendencies.
"Dei Filius" was a dogmatic constitution of the First Vatican Council on the Roman Catholic faith. It was adopted unanimously on 24 April 1870 and was influenced by the philosophical conceptions of Johann Baptist Franzelin, who had written a great deal on the topic of faith and rationality.
Because the Roman Catholic Church does not disparage reason, but rather affirms its veracity and utility, there have been many Catholic scientists over the ages.
Twentieth-century Thomist philosopher Étienne Gilson wrote about faith and reason in his 1922 book "Le Thomisme". His contemporary Jacques Maritain wrote about it in his "The Degrees of Knowledge".
"Fides et Ratio" is an encyclical promulgated by Pope John Paul II on 14 September 1998. It deals with the relationship between faith and reason.
Pope Benedict XVI's 12 September 2006 Regensburg Lecture was about faith and reason.
Lutheran epistemology.
Some have asserted that Martin Luther taught that faith and reason were antithetical in the sense that questions of faith could not be illuminated by reason. Contemporary Lutheran scholarship however has found a different reality in Luther. Luther rather seeks to separate faith and reason in order to honor the separate spheres of knowledge that each understand. Bernhard Lohse for example has demonstrated in his classic work "Fides Und Ratio" that Luther ultimately sought to put the two together. More recently Hans-Peter Großhans has demonstrated that Luther's work on Bibilical Criticism stresses the need for external coherence in right exegetical method. This means that for Luther it is more important that the Bible be reasonable according to the reality outside of the scriptures than that the Bible make sense to itself, that it has internal coherence. The right tool for understanding the world outside of the Bible for Luther is none other than Reason which for Luther denoted science, philosophy, history and empirical observation. Here a differing picture is presented of a Luther who deeply valued both faith and reason, and held them in dialectical partnership. Luther's concern thus in separating them is honoring their different epistemological spheres.
Reformed epistemology.
Faith as underlying rationality.
The view that faith underlies all rationality holds that rationality is dependent on faith for its coherence. Under this view, there is no way to comprehensively "prove" that we are actually seeing what we appear to be seeing, that what we remember actually happened, or that the laws of logic and mathematics are actually real. Instead, all beliefs depend for their coherence on "faith" in our senses, memory, and reason, because the foundations of rationalism cannot be proven by evidence or reason. Rationally, you can not prove anything you see is real, but you can prove that you yourself are real, and rationalist belief would be that you can believe that the world is consistent until something demonstrates inconsistency. This differs from faith based belief, where you believe that your world view is consistent no matter what inconsistencies the world has with your beliefs.
Rationalist point of view.
In this view, there are many beliefs that are held by faith alone, that rational thought would force the mind to reject. As an example, many people believe in the Biblical story of Noah's flood: that the entire Earth was covered by water for forty days. But objected that most plants cannot survive being covered by water for that length of time, a boat of that magnitude could not have been built by wood, and there would be no way for two of every animal to survive on that ship and migrate back to their place of origin. (such as penguins), Although Christian apologists offer answers to these and such issues, under the premise that such responses are insufficient, one must choose between accepting the story on faith and rejecting reason, or rejecting the story by reason and thus rejecting faith.
Within the rationalist point of view, there remains the possibility of multiple rational explanations. For example, considering the biblical story of Noah's flood, one making rational determinations about the probability of the events does so via interpretation of modern evidence. Two observers of the story may provide different plausible explanations for the life of plants, construction of the boat, species living at the time, and migration following the flood. Some see this as meaning that a person is not strictly bound to choose between faith and reason.
Evangelical views.
American biblical scholar Archibald Thomas Robertson stated that the Greek word "pistis" used for faith in the New Testament (over two hundred forty times), and rendered "assurance" in Acts 17:31 (KJV), is "an old verb to furnish, used regularly by Demosthenes for bringing forward evidence." Likewise Tom Price (Oxford Centre for Christian Apologetics) affirms that when the New Testament talks about faith positively it only uses words derived from the Greek root which means "to be persuaded."
In contrast to faith meaning blind trust, in the absence of evidence, even in the teeth of evidence, Alister McGrath quotes Oxford Anglican theologian W. H. Griffith-Thomas, (1861-1924), who states faith is "not blind, but intelligent" and "commences with the conviction of the mind based on adequate evidence...", which McGrath sees as "a good and reliable definition, synthesizing the core elements of the characteristic Christian understanding of faith."
Alvin Plantinga upholds that faith may be the result of evidence testifying to the reliability of the source of truth claims, but although it may involve this, he sees faith as being the result of hearing the truth of the gospel with the internal persuasion by the Holy Spirit moving and enabling him to believe. "Christian belief is produced in the believer by the internal instigation of the Holy Spirit, endorsing the teachings of Scripture, which is itself divinely inspired by the Holy Spirit. The result of the work of the Holy Spirit is faith."
Jewish philosophy.
The 14th Century Jewish philosopher Levi ben Gerson tried to reconcile faith and reason. He wrote, "The Torah cannot prevent us from considering to be true that which our reason urges us to believe." His contemporary Hasdai ben Abraham Crescas argued the contrary view, that reason is weak and faith strong, and that only through faith can we discover the fundamental truth that God is love, that through faith alone can we endure the suffering that is the common lot of God's chosen people.

</doc>
<doc id="10839" url="https://en.wikipedia.org/wiki?curid=10839" title="List of film institutes">
List of film institutes

Some notable institutions celebrating film, including both national film institutes and independent and non-profit organizations. For the purposes of this list, institutions that do not have their own article on Wikipedia are not considered notable.

</doc>
<doc id="10841" url="https://en.wikipedia.org/wiki?curid=10841" title="Forth">
Forth

Forth may refer to:
FORTH may stand for:

</doc>
<doc id="10842" url="https://en.wikipedia.org/wiki?curid=10842" title="F wave">
F wave

In neuroscience, an F wave is the second of two voltage changes observed after electrical stimulation is applied to the skin surface above the distal region of a nerve. F waves are often used to measure nerve conduction velocity, and are particularly useful for evaluating conduction problems in the proximal region of nerves (i.e., portions of nerves near the spinal cord).
It's called F wave because it was initially recorded in the foot muscles.
Overview.
In a typical F wave study, a strong electrical stimulus (supramaximal stimulation) is applied to the skin surface above the distal portion of a nerve so that the impulse travels both distally (towards the muscle fiber) and proximally (back to the motor neurons of the spinal cord). (These directions are also known as orthodromic and antidromic, respectively.) When the "orthodromic" stimulus reaches the muscle fiber, it elicits a strong M-response indicative of muscle contraction. When the "antidromic" stimulus reaches the motor neuron cell bodies, a small portion of the motor neurons backfire and orthodromic wave travels back down the nerve towards the muscle. This reflected stimulus evokes small proportion of the muscle fibers causing a small, second CMAP called the F wave.
Because a different population of anterior horn cells is stimulated with each stimulation, each F wave have a slightly different shape, amplitude and latency.
Properties.
F wave properties include:
F wave measurements.
Several measurements can be done on the F responses, including minimal and maximal latencies, and F wave persistence.
The minimal F wave latency is typically 25-32 ms in the upper extremities, and 45-56 ms in the lower extremities.
F wave persistence is the number of F waves obtained per the number of stimulations, which is normally 80-100% (or above 50%).

</doc>
<doc id="10843" url="https://en.wikipedia.org/wiki?curid=10843" title="Fruit">
Fruit

In botany, a fruit is the seed-bearing structure in flowering plants (also known as angiosperms) formed from the ovary after flowering.
Fruits are the means by which angiosperms disseminate seeds. Edible fruits, in particular, have propagated with the movements of humans and animals in a symbiotic relationship as a means for seed dispersal and nutrition; in fact, humans and many animals have become dependent on fruits as a source of food. Accordingly, fruits account for a substantial fraction of the world's agricultural output, and some (such as the apple and the pomegranate) have acquired extensive cultural and symbolic meanings.
In common language usage, "fruit" normally means the fleshy seed-associated structures of a plant that are sweet or sour, and edible in the raw state, such as apples, bananas, grapes, lemons, oranges, and strawberries. On the other hand, in botanical usage, "fruit" includes many structures that are not commonly called "fruits", such as bean pods, corn kernels, tomatoes, and wheat grains. The section of a fungus that produces spores is also called a fruiting body.
Botanic fruit and culinary fruit.
Many common terms for seeds and fruit do not correspond to the botanical classifications. In culinary terminology, a "fruit" is usually any sweet-tasting plant part, especially a botanical fruit; a "nut" is any hard, oily, and shelled plant product; and a "vegetable" is any savory or less sweet plant product. However, in botany, a "fruit" is the ripened ovary or carpel that contains seeds, a "nut" is a type of fruit and not a seed, and a "seed" is a ripened ovule.
Examples of culinary "vegetables" and nuts that are botanically fruit include corn, cucurbits (e.g., cucumber, pumpkin, and squash), eggplant, legumes (beans, peanuts, and peas), sweet pepper, and tomato. In addition, some spices, such as allspice and chili pepper, are fruits, botanically speaking. In contrast, rhubarb is often referred to as a fruit, because it is used to make sweet desserts such as pies, though only the petiole (leaf stalk) of the rhubarb plant is edible, and edible gymnosperm seeds are often given fruit names, e.g., ginkgo nuts and pine nuts.
Botanically, a cereal grain, such as corn, rice, or wheat, is also a kind of fruit, termed a caryopsis. However, the fruit wall is very thin and is fused to the seed coat, so almost all of the edible grain is actually a seed.
Fruit structure.
The outer, often edible layer, is the "pericarp", formed from the ovary and surrounding the seeds, although in some species other tissues contribute to or form the edible portion. The pericarp may be described in three layers from outer to inner, the "epicarp", "mesocarp" and "endocarp".
Fruit that bears a prominent pointed terminal projection is said to be "beaked".
Fruit development.
A fruit results from maturation of one or more flowers, and the gynoecium of the flower(s) forms all or part of the fruit.
Inside the ovary/ovaries are one or more ovules where the megagametophyte contains the egg cell. After double fertilization, these ovules will become seeds. The ovules are fertilized in a process that starts with pollination, which involves the movement of pollen from the stamens to the stigma of flowers. After pollination, a tube grows from the pollen through the stigma into the ovary to the ovule and two sperm are transferred from the pollen to the megagametophyte. Within the megagametophyte one of the two sperm unites with the egg, forming a zygote, and the second sperm enters the central cell forming the endosperm mother cell, which completes the double fertilization process. Later the zygote will give rise to the embryo of the seed, and the endosperm mother cell will give rise to endosperm, a nutritive tissue used by the embryo.
As the ovules develop into seeds, the ovary begins to ripen and the ovary wall, the "pericarp", may become fleshy (as in berries or drupes), or form a hard outer covering (as in nuts). In some multiseeded fruits, the extent to which the flesh develops is proportional to the number of fertilized ovules. The pericarp is often differentiated into two or three distinct layers called the "exocarp" (outer layer, also called epicarp), "mesocarp" (middle layer), and "endocarp" (inner layer). In some fruits, especially simple fruits derived from an inferior ovary, other parts of the flower (such as the floral tube, including the petals, sepals, and stamens), fuse with the ovary and ripen with it. In other cases, the sepals, petals and/or stamens and style of the flower fall off. When such other floral parts are a significant part of the fruit, it is called an "accessory fruit". Since other parts of the flower may contribute to the structure of the fruit, it is important to study flower structure to understand how a particular fruit forms.
There are three general modes of fruit development:
Plant scientists have grouped fruits into three main groups, simple fruits, aggregate fruits, and composite or multiple fruits. The groupings are not evolutionarily relevant, since many diverse plant taxa may be in the same group, but reflect how the flower organs are arranged and how the fruits develop.
Simple fruit.
Simple fruits can be either dry or fleshy, and result from the ripening of a simple or compound ovary in a flower with only one pistil. Dry fruits may be either dehiscent (they open to discharge seeds), or indehiscent (they do not open to discharge seeds). Types of dry, simple fruits, and examples of each, include:
Fruits in which part or all of the "pericarp" (fruit wall) is fleshy at maturity are "simple fleshy fruits". Types of simple, fleshy, fruits (with examples) include:
An aggregate fruit, or "etaerio", develops from a single flower with numerous simple pistils.
The pome fruits of the family Rosaceae, (including apples, pears, rosehips, and saskatoon berry) are a syncarpous fleshy fruit, a simple fruit, developing from a half-inferior ovary.
Schizocarp fruits form from a syncarpous ovary and do not really dehisce, but rather split into segments with one or more seeds; they include a number of different forms from a wide range of families. Carrot seed is an example.
Aggregate fruit.
Aggregate fruits form from single flowers that have multiple carpels which are not joined together, i.e. each pistil contains one carpel. Each pistil forms a fruitlet, and collectively the fruitlets are called an etaerio. Four types of aggregate fruits include etaerios of achenes, follicles, drupelets, and berries. Ranunculaceae species, including "Clematis" and "Ranunculus" have an etaerio of achenes, "Calotropis" has an etaerio of follicles, and "Rubus" species like raspberry, have an etaerio of drupelets. "Annona" have an etaerio of berries.
The raspberry, whose pistils are termed "drupelets" because each is like a small drupe attached to the receptacle. In some bramble fruits (such as blackberry) the receptacle is elongated and part of the ripe fruit, making the blackberry an "aggregate-accessory" fruit. The strawberry is also an aggregate-accessory fruit, only one in which the seeds are contained in achenes. In all these examples, the fruit develops from a single flower with numerous pistils.
Multiple fruits.
A multiple fruit is one formed from a cluster of flowers (called an "inflorescence"). Each flower produces a fruit, but these mature into a single mass. Examples are the pineapple, fig, mulberry, osage-orange, and breadfruit.
In the photograph on the right, stages of flowering and fruit development in the noni or Indian mulberry ("Morinda citrifolia") can be observed on a single branch. First an inflorescence of white flowers called a head is produced. After fertilization, each flower develops into a drupe, and as the drupes expand, they become "connate" (merge) into a "multiple fleshy fruit" called a "syncarp".
Berries.
Berries are another type of fleshy fruit; they are simple fruit created from a single ovary. The ovary may be compound, with several carpels. Types include (examples follow in the table below):
Accessory fruit.
Some or all of the edible part of accessory fruit is not generated by the ovary. Accessory fruit can be simple, aggregate, or multiple, i.e., they can include one or more pistils and other parts from the same flower, or the pistils and other parts of many flowers.
Seedless fruits.
Seedlessness is an important feature of some fruits of commerce. Commercial cultivars of bananas and pineapples are examples of seedless fruits. Some cultivars of citrus fruits (especially grapefruit, mandarin oranges, navel oranges), satsumas, table grapes, and watermelons are valued for their seedlessness. In some species, seedlessness is the result of "parthenocarpy", where fruits set without fertilization. Parthenocarpic fruit set may or may not require pollination, but most seedless citrus fruits require a stimulus from pollination to produce fruit.
Seedless bananas and grapes are triploids, and seedlessness results from the abortion of the embryonic plant that is produced by fertilization, a phenomenon known as "stenospermocarpy", which requires normal pollination and fertilization.
Seed dissemination.
Variations in fruit structures largely depend on their seeds' mode of dispersal. This dispersal can be achieved by animals, explosive dehiscence, water, or wind.
Some fruits have coats covered with spikes or hooked burrs, either to prevent themselves from being eaten by animals, or to stick to the feathers, hairs, or legs of animals, using them as dispersal agents. Examples include cocklebur and unicorn plant.
The sweet flesh of many fruits is "deliberately" appealing to animals, so that the seeds held within are eaten and "unwittingly" carried away and deposited (i.e., defecated) at a distance from the parent. Likewise, the nutritious, oily kernels of nuts are appealing to rodents (such as squirrels), which hoard them in the soil to avoid starving during the winter, thus giving those seeds that remain uneaten the chance to germinate and grow into a new plant away from their parent.
Other fruits are elongated and flattened out naturally, and so become thin, like wings or helicopter blades, e.g., elm, maple, and tuliptree. This is an evolutionary mechanism to increase dispersal distance away from the parent, via wind. Other wind-dispersed fruit have tiny "parachutes", e.g., dandelion, milkweed, salsify.
Coconut fruits can float thousands of miles in the ocean to spread seeds. Some other fruits that can disperse via water are nipa palm and screw pine.
Some fruits fling seeds substantial distances (up to 100 m in sandbox tree) via explosive dehiscence or other mechanisms, e.g., impatiens and squirting cucumber.
Uses.
Many hundreds of fruits, including fleshy fruits (like apple, kiwifruit, mango,peach, pear, and watermelon) are commercially valuable as human food, eaten both fresh and as jams, marmalade and other preserves. Fruits are also used in manufactured foods (e.g., cakes, cookies, ice cream, muffins, or yogurt) or beverages, such as fruit juices (e.g., apple juice, grape juice, or orange juice) or alcoholic beverages (e.g., brandy, fruit beer, or wine), Fruits are also used for gift giving, e.g., in the form of Fruit Baskets and Fruit Bouquets.
Many "vegetables" in culinary "parlance" are botanical fruits, including bell pepper, cucumber, eggplant, green bean, okra, pumpkin, squash, tomato, and zucchini. Olive fruit is pressed for olive oil. Spices like allspice, black pepper, paprika, and vanilla are derived from berries.
Nutritional value.
Fresh fruits are generally high in fiber, vitamin C, and water.
Regular consumption of fruit is generally associated with reduced risks of several diseases and functional declines associated with aging.
Nonfood uses.
Because fruits have been such a major part of the human diet, various cultures have developed many different uses for fruits they do not depend on for food. For example: 
Safety.
For food safety, the CDC recommends proper fruit handling and preparation to reduce the risk of food contamination and foodborne illness. Fresh fruits and vegetables should be carefully selected; at the store, they should not be damaged or bruised; and pre-cut pieces should be refrigerated or surrounded by ice.
All fruits and vegetables should be rinsed before eating. This recommendation also applies to produce with rinds or skins that are not eaten. It should be done just before preparing or eating to avoid premature spoilage.
Fruits and vegetables should be kept separate from raw foods like meat, poultry, and seafood, as well as from utensils that have come in contact with raw foods. Fruits and vegetables that are not going to be cooked should be thrown away if they have touched raw meat, poultry, seafood, or eggs.
All cut, peeled, or cooked fruits and vegetables should be refrigerated within two hours. After a certain time, harmful bacteria may grow on them and increase the risk of foodborne illness.
Allergies.
Fruit allergies make up about 10 percent of all food related allergies
Storage.
All fruits benefit from proper post harvest care, and in many fruits, the plant hormone ethylene causes ripening. Therefore, maintaining most fruits in an efficient cold chain is optimal for post harvest storage, with the aim of extending and ensuring shelf life.

</doc>
<doc id="10844" url="https://en.wikipedia.org/wiki?curid=10844" title="French materialism">
French materialism

French materialism is the name given to a handful of French 18th-century philosophers during the Age of Enlightenment, many of them clustered around the salon of Baron d'Holbach. Although there are important differences between them, all of them were materialists who believed that the world was made up of a single substance, matter, the motions and properties of which could be used to explain all phenomena. 
Prominent French materialists of the 18th century include:

</doc>
<doc id="10845" url="https://en.wikipedia.org/wiki?curid=10845" title="February">
February

February is the second month of the year in the Julian and Gregorian calendars. It is the shortest month and the only month with fewer than 30 days. The month has 28 days in common years or 29 days in leap years, with the quadrennial 29th day being called the "leap day."
February is the third month of meteorological winter in the Northern Hemisphere. In the Southern Hemisphere, February is the last month of summer (the seasonal equivalent of August in the Northern Hemisphere, in meteorological reckoning).
History.
The Roman month "Februarius" was named after the Latin term "februum", which means "purification", via the purification ritual "Februa" held on February 15 (full moon) in the old lunar Roman calendar. January and February were the last two months to be added to the Roman calendar, since the Romans originally considered winter a monthless period. They were added by Numa Pompilius about 713 BC. February remained the last month of the calendar year until the time of the decemvirs (c. 450 BC), when it became the second month. At certain intervals February was truncated to 23 or 24 days, and a 27-day intercalary month, Intercalaris, was inserted immediately after February to realign the year with the seasons.
Under the reforms that instituted the Julian calendar, Intercalaris was abolished, leap years occurred regularly every fourth year, and in leap years February gained a 29th day. Thereafter, it remained the second month of the calendar year, meaning the order that months are displayed (January, February, March, ..., December) within a year-at-a-glance calendar. Even during the Middle Ages, when the numbered Anno Domini year began on March 25 or December 25, the second month was February whenever all twelve months were displayed in order. The Gregorian calendar reforms made slight changes to the system for determining which years were leap years and thus contained a 29-day February.
Historical names for February include the Old English terms Solmonath (mud month) and Kale-monath (named for cabbage) as well as Charlemagne's designation Hornung. In Finnish, the month is called "helmikuu", meaning "month of the pearl"; when snow melts on tree branches, it forms droplets, and as these freeze again, they are like pearls of ice. In Polish and Ukrainian, respectively, the month is called "luty" or "лютий", meaning the month of ice or hard frost. In Macedonian the month is "sechko" (сечко), meaning month of cutting In Czech, it is called "únor", meaning month of submerging [of river ice. Croatians call the month "veljača", whose meaning is unknown but may come from the word for "greater," a possible reference to the days increasing in length.
In Slovene, February is traditionally called "svečan", related to icicles or Candlemas. This name originates from "sičan", written as "svičan" in the "New Carniolan Almanac" from 1775 and changed to its final form by Franc Metelko in his "New Almanac" from 1824. The name was also spelled "sečan", meaning "the month of cutting down of trees". In 1848, a proposal was put forward in "Kmetijske in rokodelske novice" by the Slovene Society of Ljubljana to call this month "talnik" (related to ice melting), but it did not stick. The idea was proposed by the priest and patriot Blaž Potočnik. Another name of February in Slovene was "vesnar", after the mythological character Vesna.
Pronunciation.
February may be pronounced either as ( or or ). Many people pronounce it as ( rather than ), as if it were spelled "Feb-u-ary". This comes about by analogy with "January" (which ends in "-uary" but not "-ruary"), as well as by a dissimilation effect whereby having two "r"s close to each other causes one to change for ease of pronunciation.
Patterns.
February starts on the same day of the week as both March and November in common years, and as August in leap years. February ends on the same day of the week as October every year and on the same day of the week as January in common years only. February starts on the same day of the week as June of the previous year in all years. February ends on the same day of the week as May of the previous year in common years and August and November of the previous year in leap years. February ends on the same day of the week as July of the following year in years immediately before common years and April and December of the following year in years immediately before leap years. February starts on the same day of the week as May of the following year in leap years and years immediately before leap years. In leap years, it is the only month that ends on the same weekday it began.
Having only 28 days in common years, it is the only month of the year that can pass without a single full moon. This last happened in 1999 and will next happen in 2018.
February is also the only month of the calendar that once every six years and twice every 11 years consecutively, either back into the past or forward into the future, will have four full 7-day weeks. In countries that start their week on a Monday, it occurs as part of a common year starting on Friday, in which February 1st is a Monday and the 28th is a Sunday, this was observed in 2010 and can be traced back 11 years to 1999, 6 years back to 1993, 11 years back to 1982, 11 years back to 1971 and 6 years back to 1965, and will be observed in 2021. In countries that start their week on a Sunday, it occurs in a common year starting on Thursday, with the next occurrence in 2026, and previous occurrences in 2015 (11 years earlier than 2026), 2009 (6 years earlier than 2015), 1998 (11 years earlier than 2009) and 1987 (11 years earlier than 1998). This works unless the pattern is broken by a skipped leap year, but no leap year has been skipped since 1900 and no others will be skipped until 2100.
Observances.
"This list does not necessarily imply either official status nor general observance."
Movable observances, 2016 dates.
Monday closest to January 29 - February 1
First Monday - February 1
First Week of February (first Monday, ending on Sunday) - February 1–7
First Friday - February 5
First Saturday - February 6
First Sunday - February 7
Second Monday - February 8
Second Day of the second week - February 8
Second Tuesday - February 9
Second Saturday - February 13
Second Sunday - February 14
Third Monday' - February 15
Third Thursday - February 18
Third Friday - February 19
Week of February 22 - February 21–27
Last Tuesday - February 23
Last Friday - February 26
Last Saturday - February 27
Last day of February - February 29

</doc>
<doc id="10846" url="https://en.wikipedia.org/wiki?curid=10846" title="February 1">
February 1


</doc>
<doc id="10847" url="https://en.wikipedia.org/wiki?curid=10847" title="First Lady of the United States">
First Lady of the United States

The First Lady of the United States (FLOTUS), is an unofficial title and position traditionally held by the wife of the president, concurrent with his term of office. 
The position of the First Lady is unofficial and carries no official duties. The role of the First Lady has evolved over the centuries. The main role of the First ladies, besides their private role as spouse, has been as host and organizer to the White House. She organizes and attends official ceremonies and functions of state either along with, or in place of, the president. 
The position is largely one of status, and First Ladies have held influence in a range of sectors, from fashion to public opinion on policy. Historically, should a president be unmarried, or the president's wife is unable to act as First Lady, the president usually asks a relative or friend to act as White House hostess. Although the United States Presidents have historically been heterosexual men in conventional marriages, if this were not the case, the president's spouse would still act as primary organizer and host. This possibility and speculation over what the new title of the acting Spouse in office might be have been discussed in the presidential campaigns of Hillary Clinton in 2008 and 2016.
Current First Ladies.
The current First Lady is Michelle Obama. At present, there are four living former first ladies: Rosalynn Carter, wife of Jimmy Carter; Barbara Bush, wife of George H. W. Bush; Hillary Rodham Clinton, wife of Bill Clinton; and Laura Bush, wife of George W. Bush.
Origins of the title.
The use of the title "First Lady" to describe the spouse or hostess of an executive began in the United States. In the early days of the republic, there was not a generally accepted title for the wife of the president. Many early first ladies expressed their own preference for how they were addressed, including the use of such titles as "Lady", "Mrs. President", and "Mrs. Presidentress"; Martha Washington was often referred to as "Lady Washington." One of the earliest uses of the term "First Lady" was applied to her in an 1838 newspaper article that appeared in the St. Johnsbury (VT) Caledonian, the author, "Mrs. Sigourney", discussing how Martha Washington had not changed, even after her husband George became president, wrote that "The first lady of the nation still preserved the habits of early life. Indulging in no indolence, she left the pillow at dawn, and after breakfast, retired to her chamber for an hour for the study of the scriptures and devotion".
Dolley Madison was reportedly referred to as "First Lady" in 1849 at her funeral in a eulogy delivered by President Zachary Taylor; however, no written record of this eulogy exists, nor did any of the newspapers of her day refer to her by that title. Sometime after 1849, the title began being used in Washington, D.C., social circles. One of the earliest known written examples comes from the November 3, 1863, diary entry of William Howard Russell, in which he referred to gossip about "the First Lady in the Land," referring to Mary Todd Lincoln. The title first gained nationwide recognition in 1877, when newspaper journalist Mary C. Ames referred to Lucy Webb Hayes as "the First Lady of the Land" while reporting on the inauguration of Rutherford B. Hayes. The frequent reporting on Lucy Hayes' activities helped spread use of the title outside Washington. A popular 1911 comedic play about Dolley Madison by playwright Charles Nirdlinger, titled "The First Lady in the Land", popularized the title further. By the 1930s it was in wide use. Use of the title later spread from the United States to other nations.
When Edith Wilson took control of her husband's schedule in 1919 after he had a debilitating stroke, one Republican senator labeled her "the Presidentress who had fulfilled the dream of the suffragettes by changing her title from First Lady to Acting First Man."
The wife of the :Vice President of the United States is sometimes referred to as the Second Lady of the United States, but this title is much less common.
Several women who were not presidents' wives have served as First Lady, as when the president was a bachelor or widower, or when the wife of the president was unable to fulfill the duties of the First Lady herself. In these cases, the position has been filled by a female relative or friend of the president, such as Martha Jefferson Randolph during Jefferson's presidency, Emily Donelson and Sarah Yorke Jackson during Jackson's, Mary Elizabeth (Taylor) Bliss during Taylor's, Mary Harrison McKee during Benjamin Harrison's presidency, upon her mother's death, Harriet Lane during Buchanan's, and Rose Cleveland prior to Cleveland's marriage.
Role.
Burns identifies four successive main themes of the First Ladyship: as public woman (1900–1929); as political celebrity (1932–1961); as political activist (1964–1977); and as political interloper (1980–2001).
The position of the First Lady is not an elected one and carries no official duties. Nonetheless, first ladies have held a highly visible position in U.S. government. The role of the First Lady has evolved over the centuries. She is, first and foremost, the hostess of the White House. She organizes and attends official ceremonies and functions of state either along with, or in place of, the president.
Both Martha Washington and Abigail Adams gained fame from the Revolutionary War and were treated as if they were "ladies" of the British royal court. Dolley Madison popularized the First Ladyship by engaging in efforts to assist orphans and women, by dressing in elegant fashions and attracting newspaper coverage, and by risking her life to save iconic treasures during the War of 1812. Madison set the standard for the ladyship and her actions were the model for nearly every First Lady until Eleanor Roosevelt in the 1930s. Plagued by a paralytic illness, President Franklin D. Roosevelt was not free to travel around the country, so Mrs. Roosevelt assumed this role. She authored a weekly newspaper column and hosted a radio show. Jacqueline Kennedy led an effort to redecorate and restore the White House while she was First Lady.
Over the course of the 20th century it became increasingly common for first ladies to select specific causes to promote, usually ones that are not politically divisive. It is common for the First Lady to hire a staff to support these activities. Lady Bird Johnson pioneered environmental protection and beautification; Pat Nixon encouraged volunteerism and traveled extensively abroad; Betty Ford supported women's rights; Rosalynn Carter aided those with mental disabilities; Nancy Reagan founded the Just Say No drug awareness campaign; Barbara Bush promoted literacy; Hillary Clinton sought to reform the healthcare system in the U.S.; and Laura Bush supported women's rights groups and encouraged childhood literacy. Michelle Obama has become identified with supporting military families and tackling childhood obesity.
Clinton was elected a U.S. Senator from New York in 2001 and was the Secretary of State in the Obama administration from 2009 to 2013. Many first ladies, including Jacqueline Kennedy, Nancy Reagan, and Michelle Obama have been significant fashion trendsetters. There is a strong tradition against the First Lady holding outside employment while serving as White House hostess. However, some first ladies have exercised a degree of political influence by virtue of being an important adviser to the president. During Hillary Clinton's campaign for election to the U.S. Senate, the couple's daughter, Chelsea, took over much of the First Lady's role.
Office of the First Lady.
The Office of the First Lady of the United States is accountable to the First Lady for her to carry out her duties as hostess of the White House, and is also in charge of all social and ceremonial events of the White House. The First Lady has her own staff that includes a chief of staff, press secretary, White House Social Secretary, Chief Floral Designer, etc. The Office of the First Lady is an entity of the White House Office, a branch of the Executive Office of the President. When First Lady Hillary Clinton decided to pursue a run for Senator of New York, she set aside her duties as first lady and moved to Chappaqua, New York to establish state residency. She resumed her duties as First Lady after winning her senatorial campaign, and retained her duties as both first lady and U.S. Senator for the seventeen-day overlap before Bill Clinton's term came to an end.
Exhibitions and collections.
Established in 1912, the First Ladies Collection has been one of the most popular attractions at the Smithsonian Institution. The original exhibition opened in 1914 and was one of the first at the Smithsonian to prominently feature women. Originally focused largely on fashion, the exhibition now delves deeper into the contributions of first ladies to the presidency and American society. In 2008, "First Ladies at the Smithsonian" opened at the National Museum of American History as part of its reopening year celebration. That exhibition served as a bridge to the museum's expanded exhibition on first ladies' history that opened on November 19, 2011. "The First Ladies" explores the unofficial but important position of first lady and the ways that different women have shaped the role to make their own contributions to the presidential administrations and the nation. The exhibition features 26 dresses and more than 160 other objects, ranging from those of Martha Washington to Michelle Obama, and includes White House china, personal possessions and other objects from the Smithsonian's unique collection of first ladies' materials.
First Lady and fashion.
Some first ladies have garnered attention for their dress and style. Jacqueline Kennedy, for instance, became a global fashion icon: her style was copied by commercial manufacturers and imitated by many young women, and she was named to the International Best Dressed List Hall of Fame in 1965. Michelle Obama has also received significant attention for her fashion choices: style writer Robin Givhan praised her in "The Daily Beast", arguing that the First Lady's style has helped to enhance the public image of the office.

</doc>
<doc id="10852" url="https://en.wikipedia.org/wiki?curid=10852" title="Frank Herbert">
Frank Herbert

Frank Patrick Herbert, Jr. (October 8, 1920 – February 11, 1986) was an American science fiction writer best known for the novel "Dune" and its five sequels. Though he became famous for science fiction, he was also a newspaper journalist, photographer, short story writer, book reviewer, ecological consultant and lecturer.
The "Dune" saga, set in the distant future and taking place over millennia, deals with complex themes such as human survival and evolution, ecology, and the intersection of religion, politics and power. "Dune" itself is the best-selling science fiction novel of all time and the series is widely considered to be among the classics of the genre.
Biography.
Early life.
Frank Herbert was born on October 8, 1920, in Tacoma, Washington, to Frank Patrick Herbert, Sr. and Eileen (McCarthy) Herbert. Because of a poor home environment, he ran away from home in 1938 to live with an aunt and uncle in Salem, Oregon. He enrolled in high school at Salem High School (now North Salem High School), where he graduated the next year. In 1939 he lied about his age to get his first newspaper job at the "Glendale Star". Herbert then returned to Salem in 1940 where he worked for the "Oregon Statesman" newspaper (now "Statesman Journal") in a variety of positions, including photographer.
He served in the U.S. Navy's Seabees for six months as a photographer during World War II, then he was given a medical discharge. He married Flora Parkinson in San Pedro, California in 1940. They had a daughter, Penny (b. February 16, 1942), but divorced in 1945.
After the war Herbert attended the University of Washington, where he met Beverly Ann Stuart at a creative writing class in 1946. They were the only students who had sold any work for publication; Herbert had sold two pulp adventure stories to magazines, the first to "Esquire" in 1945, and Stuart had sold a story to "Modern Romance" magazine. They married in Seattle, Washington on June 20, 1946 and had two sons, Brian Patrick Herbert (b. June 29, 1947, Seattle, Washington) and Bruce Calvin Herbert (b. June 26, 1951, Santa Rosa, California d. June 15, 1993, San Rafael, California, a professional photographer and gay rights activist).
In 1949 Herbert and his wife moved to California to work on the "Santa Rosa Press-Democrat". Here they befriended the psychologists Ralph and Irene Slattery. The Slatterys introduced Herbert to the work of several thinkers who would influence his writing, including Freud, Jung, Jaspers and Heidegger; they also familiarized Herbert with Zen Buddhism.
Herbert did not graduate from the university; according to his son Brian, he wanted to study only what interested him and so did not complete the required curriculum. He returned to journalism and worked at the "Seattle Star" and the "Oregon Statesman". He was a writer and editor for the "San Francisco Examiner's" "California Living" magazine for a decade.
In a 1973 interview, Herbert stated that he had been reading science fiction "about ten years" before he
began writing in the genre, and he listed his favorite authors as H. G. Wells, Robert A. Heinlein, Poul Anderson and Jack Vance.
Herbert's first science fiction story, "Looking for Something", was published in the April 1952 issue of "Startling Stories", then a monthly edited by Samuel Mines. Three more of his stories appeared in 1954 issues of "Astounding Science Fiction" and "Amazing Stories". His career as a novelist began in 1955 with the serial publication of "Under Pressure" in "Astounding" from November 1955; afterward it was issued as a book by Doubleday, "The Dragon in the Sea". The story explored sanity and madness in the environment of a 21st-century submarine and predicted worldwide conflicts over oil consumption and production. It was a critical success but not a major commercial one. During this time Herbert also worked as a speechwriter for Republican senator Guy Cordon.
"Dune".
Herbert began researching "Dune" in 1959. He was able to devote himself wholeheartedly to his writing career because his wife returned to work full-time as an advertising writer for department stores, becoming the breadwinner during the 1960s. He later told Willis E. McNelly that the novel originated when he was supposed to do a magazine article on sand dunes in the Oregon Dunes near Florence, Oregon. He became too involved and ended up with far more raw material than needed for an article. The article was never written, but instead planted the seed that led to "Dune".
"Dune" took six years of research and writing to complete and it was much longer than commercial science fiction of the time was supposed to run. "Analog" (the renamed "Astounding", still edited by John W. Campbell) published it in two parts comprising eight installments, "Dune World" from December 1963 and "Prophet of Dune" in 1965. It was then rejected by nearly twenty book publishers. One editor prophetically wrote, "I might be making the mistake of the decade, but ..."
Sterling E. Lanier, an editor of Chilton Book Company (known mainly for its auto-repair manuals) had read the Dune serials and offered a $7,500 advance plus future royalties for the rights to publish them as a hardcover book. Herbert rewrote much of his text. "Dune" was soon a critical success. It won the Nebula Award for Best Novel in 1965 and shared the Hugo Award in 1966 with "...And Call Me Conrad" by Roger Zelazny. "Dune" was the first major ecological science fiction novel, embracing a multitude of sweeping, inter-related themes and multiple character viewpoints, a method that ran through all Herbert's mature work.
"Dune" was not immediately a bestseller. By 1968 Herbert had made $20,000 from it, far more than most science fiction novels of the time were generating, but not enough to let him take up full-time writing. However, the publication of "Dune" did open doors for him. He was the "Seattle Post-Intelligencer's" education writer from 1969 to 1972 and lecturer in general studies and interdisciplinary studies at the University of Washington (1970–1972). He worked in Vietnam and Pakistan as social and ecological consultant in 1972. In 1973 he was director-photographer of the television show "The Tillers".
By 1972, Herbert retired from newspaper writing and became a full-time fiction writer. During the 1970s and 1980s, Herbert enjoyed considerable commercial success as an author. He divided his time between homes in Hawaii and Washington's Olympic Peninsula; his home in Port Townsend on the peninsula was intended to be an "ecological demonstration project". During this time he wrote numerous books and pushed ecological and philosophical ideas. He continued his "Dune" saga, following it with "Dune Messiah", "Children of Dune", and "God Emperor of Dune". Other highlights were "The Dosadi Experiment", "The Godmakers", "The White Plague" and the books he wrote in partnership with Bill Ransom: "The Jesus Incident", "The Lazarus Effect", and "The Ascension Factor" which were sequels to "". He also helped launch the career of Terry Brooks with a very positive review of Brooks' first novel, "The Sword of Shannara", in 1977.
Success, family changes, and death.
Herbert's change in fortune was shadowed by tragedy. In 1974, Beverly underwent an operation for cancer. She lived ten more years, but her health was adversely affected by the surgery. During this period, Herbert was the featured speaker at the Octocon II science fiction convention at the El Rancho Tropicana in Santa Rosa, California in October 1978; in 1979, he met anthropologist James Funaro with whom he conceived the Contact Conference. Beverly Herbert died on February 7, 1984, the same year that "Heretics of Dune" was published; in his afterword to 1985's "", Frank Herbert wrote a eulogy for her.
In 1983, British heavy metal band Iron Maiden requested permission from Herbert's publisher to name a song on their album "Piece of Mind" after "Dune", but were told that the author had a strong distaste for their style of music. They instead titled the song "To Tame a Land".
1984 was a tumultuous year in Herbert's life. During this same year of his wife's death, his career took off with the release of David Lynch's film version of "Dune". Despite high expectations, a big-budget production design and an A-list cast, the movie drew mostly poor reviews in the United States. However, despite a disappointing response in the USA, the film was a critical and commercial success in Europe and Japan.
After Beverly's death, Herbert married Theresa Shackleford in 1985, the year he published "Chapterhouse: Dune", which tied up many of the saga's story threads. This would be Herbert's final single work (the anthology "Eye" was published that year, and "Man of Two Worlds" was published in 1986). He died of a massive pulmonary embolism while recovering from surgery for pancreatic cancer on February 11, 1986 in Madison, Wisconsin age 65. He was raised a Catholic but adopted Zen Buddhism as an adult.
Criticism of government.
Herbert was a critic of the Soviet Union and shared many views with controversial Republican senator, Joseph McCarthy, of whom Herbert was also a distant relative and referred to as "Cousin Joe." Herbert was, however, appalled to learn of McCarthy's blacklisting of suspected Communists from working in certain careers and believed that he was endangering essential freedoms of citizens of the United States. Herbert believed that governments lie to protect themselves and that, following the infamous Watergate scandal, President Richard Nixon had unwittingly taught an important lesson in not trusting government.
Ideas and themes.
Frank Herbert used his science fiction novels to explore complex ideas involving philosophy, religion, psychology, politics and ecology, which have caused many of his readers to take an interest in these areas. The underlying thrust of his work was a fascination with the question of human survival and evolution. Herbert has attracted a sometimes fanatical fan base, many of whom have tried to read everything he wrote, fiction or non-fiction, and see Herbert as something of an authority on the subject matters of his books. Indeed, such was the devotion of some of his readers that Herbert was at times asked if he was founding a cult, something he was very much against.
There are a number of key themes in Herbert's work:
Frank Herbert carefully refrained from offering his readers formulaic answers to many of the questions he explored.
Status and influence on science fiction.
"Dune" and the "Dune" saga constitute one of the world's best-selling science fiction series and novels; "Dune" in particular has received widespread critical acclaim, winning the Nebula Award in 1965 and sharing the Hugo Award in 1966, and is frequently considered one of the best science fiction novels ever, if not the best. "Locus" subscribers voted it the all-time best SF novel in 1975, again in 1987, and the best "before 1990" in 1998. According to contemporary Robert A. Heinlein, Herbert's opus was "powerful, convincing, and most ingenious."
"Dune" is considered a landmark novel for a number of reasons:
Herbert wrote more than twenty novels after "Dune" that are regarded as being of variable quality. Books like "The Green Brain", "The Santaroga Barrier" seemed to hark back to the days before "Dune", when a good technological idea was all that was needed to drive a sci-fi novel. And some fans of the "Dune" saga are critical of the follow-up novels as being subpar.
Herbert never again equalled the critical acclaim he received for "Dune". Neither his sequels to "Dune" nor any of his other books won a Hugo or Nebula Award, although almost all of them were "New York Times" Best Sellers. Some felt that "Children of Dune" was almost too literary and too dark to get the recognition it may have deserved; others felt that "The Dosadi Experiment" lacked an epic quality that fans had come to expect.
Largely overlooked because of the concentration on "Dune" was Herbert's 1973 novel, "Hellstrom's Hive", with its minutely worked-out depiction of a human society modeled on social insects, which could be counted a major utopia/dystopia.
Malcolm Edwards in the "Encyclopedia of Science Fiction" wrote:
Much of Herbert's work makes difficult reading. His ideas were genuinely developed concepts, not merely decorative notions, but they were sometimes embodied in excessively complicated plots and articulated in prose which did not always match the level of thinking ... His best novels, however, were the work of a speculative intellect with few rivals in modern science fiction. 
The Science Fiction Hall of Fame inducted Herbert in 2006.
California State University, Fullerton's Pollack Library has several of Herbert's draft manuscripts of "Dune" and other works, with the author's notes, in their Frank Herbert Archives.
Bibliography.
Posthumously published works.
Beginning in 2012, Herbert's estate and WordFire Press have released four previously unpublished novels in e-book and paperback formats: "High-Opp" (2012), "Angels' Fall" (2013), "A Game of Authors" (2013), and "A Thorn in the Bush" (2014).
In recent years, Frank Herbert's son Brian Herbert and author Kevin J. Anderson have added to the "Dune" franchise, using notes left behind by Frank Herbert and discovered over a decade after his death. Brian Herbert and Anderson have written two prequel trilogies ("Prelude to Dune" and "Legends of Dune") exploring the history of the "Dune" universe before the events within "Dune", as well as two post-"Chapterhouse Dune" novels that complete the original series ("Hunters of Dune" and "Sandworms of Dune") based on Frank Herbert's own "Dune 7" outline.

</doc>
<doc id="10853" url="https://en.wikipedia.org/wiki?curid=10853" title="Fictional language">
Fictional language

Fictional languages are constructed languages created as part of a fictional setting, for example in books, movies and video games. Fictional languages are intended to be the languages of a fictional world and are often designed with the intent of giving more depth and an appearance of plausibility to the fictional worlds with which they are associated, and to have their characters communicate in a fashion which is both alien and dislocated.
Some of these languages, e.g., in worlds of fantasy fiction, alternate universes, Earth's future, or alternate history, are presented as distorted versions or dialects of modern English or other natural language, while others are independently designed conlangs.
Purpose.
Fictional languages are separated from artistic languages by both purpose and relative completion: a fictional language often has the least amount of grammar and vocabulary possible, and rarely extends beyond the absolutely necessary. At the same time, some others have developed languages in detail for their own sake, such as J. R. R. Tolkien's Quenya and Sindarin, Star Trek's Klingon language and Avatar's Na'vi language which exist as functioning, usable languages. Here "fictional" can be a misnomer.
By analogy with the word "conlang", the term "conworld" is used to describe these fictional worlds, inhabited by fictional constructed cultures. The conworld influences vocabulary (what words the language will have for flora and fauna, articles of clothing, objects of technology, religious concepts, names of places and tribes, etc.), as well as influencing other factors such as pronouns, or how their cultures view the break-off points between colors or the gender and age of family members.
Professional fictional languages.
Professional fictional languages are those languages created for use in books, movies, television shows, video games, comics, toys, and musical albums (prominent examples of works featuring fictional languages include the Middle-earth and Star Trek universes and the game Myst).
Alien languages.
A notable subgenre of fictional languages are alien languages, the ones that are used or might be used by putative extraterrestrial life forms. Alien languages are subject of both science fiction and scientific research.
Perhaps the most fully developed fictional alien language is the Klingon language of the Star Trek universe - a fully developed constructed language.
The problem of alien language has confronted generations of science fiction writers; some have created fictional languages for their characters to use, while others have circumvented the problem through translation devices or other fantastic technology.
Although this field remains largely confined to science fiction, the possibility of intelligent extraterrestrial life makes the question of alien language a credible topic for scientific and philosophical speculation.
While many cases an alien language is but an element of fictional reality, in a number of science fiction works the core of the plot are linguistic and psychological problems of communication between various alien races.
Internet-based fictional languages.
Internet-based fictional languages are hosted along with their "conworlds" on the Internet, and based at these sites, becoming known to the world through the visitors to these sites; Verdurian, the language of Mark Rosenfelder's Verduria on the planet of Almea, is a flagship Internet-based fictional language. Many other fictional languages and their associated conworlds are created privately by their inventor, known only to the inventor and perhaps a few friends. In this context the term "professional" (used for the first category) as opposed to "amateur" (used for the second and third) refers only to the professionalism of the used medium, and not to the professionalism of the language itself or its creator. In fact, most professional languages are the work of non-linguists, while many amateur languages were in fact created by linguists, and in general the latter are better developed. 

</doc>
