<doc id="8485" url="https://en.wikipedia.org/wiki?curid=8485" title="Diego Maradona">
Diego Maradona

Diego Armando Maradona (, born 30 October 1960) is a retired Argentine professional footballer. He has served as a manager and coach at other clubs as well as the national team of Argentina. Many in the sport, including football writers, former players, current players and football fans, regard Maradona as the greatest football player of all time. He was joint FIFA Player of the 20th Century with Pelé.
An advanced playmaker who operated in the classic number 10 position, Maradona is the only player in football history to set the world record transfer fee twice, first when he transferred to Barcelona for a then world record £5 million, and second, when he transferred to Napoli for another record fee £6.9 million. He played for Argentinos Juniors, Boca Juniors, Barcelona, Napoli, Sevilla and Newell's Old Boys during his club career, and is most famous for his time at Napoli where he won numerous accolades. In his international career with Argentina, he earned 91 caps and scored 34 goals. Maradona's exceptional vision, passing, ball control, dribbling skills, speed, reflexes and thinking time was combined with his small size (he was 5'5", or 1.65m) giving him a low center of gravity which allowed him to be more maneuverable than most other football players; he would often dribble past multiple opposing players on a run. His presence on the pitch had a great effect on his team's general performance, while he would often be singled out by the opposition. A precocious talent, Maradona was given the nickname "El Pibe de Oro" ("The Golden Boy"), a name that stuck with him throughout his career.
Maradona played in four FIFA World Cups, including the 1986 World Cup in Mexico where he captained Argentina and led them to victory over West Germany in the final, and won the Golden Ball as the tournament's best player. In the 1986 World Cup quarter final, he scored both goals in a 2–1 victory over England that entered football history for two different reasons. The first goal was an unpenalized handling foul known as the "Hand of God", while the second goal followed a dribble past five England players, voted "The Goal of the Century" by FIFA.com voters in 2002.
Maradona became coach of Argentina in November 2008. He was in charge of the team at the 2010 FIFA World Cup in South Africa before leaving at the end of the tournament. He coached Dubai-based club Al Wasl in the UAE Pro-League for the 2011–12 season. In August 2013, Maradona joined Argentine Primera D club Deportivo Riestra's staff as "spiritual coach".
Early years.
Diego Maradona was born on 30 October 1960, at the Policlínico (Polyclinic) Evita Hospital in Lanús, Buenos Aires Province, but raised in Villa Fiorito, a shantytown on the southern outskirts of Buenos Aires, Argentina, to a poor family that had moved from Corrientes Province. He was the first son after three daughters. He has two younger brothers, Hugo ("el Turco") and Raúl (Lalo), both of whom were also professional football players. Maradona is of Italian, Spanish, Croatian, Indigenous-Argentinian ancestry. His surname originates from the Spanish region Galicia.
He was the fifth child and first son of Diego Maradona 'Chitoro' and Dalma Salvadora Franco 'Doña Tota' (1930–2011). Both his parents were illegitimate children. His father took the family name of his mother because his father did not recognise him as his own. Maradona's mother was not recognised by her father, Atanancio Ramón Edisto Franco, until she was eighteen years old. Maradona's parents were both born and brought up in the town of Esquina in the north-east province of Corrientes Province, living only two hundred metres from each other on the banks of the Corriente River. In 1950, they left Esquina and settled in Buenos Aires. At age eight, Maradona was spotted by a talent scout while he was playing in his neighbourhood club "Estrella Roja". He became a staple of "Los Cebollitas" (The Little Onions), the junior team of Buenos Aires's Argentinos Juniors. As a 12-year-old ball boy, he amused spectators by showing his wizardry with the ball during the halftime intermissions of first division games. He named Brazilian playmaker Rivelino and Manchester United winger George Best among his inspirations growing up.
Club career.
Argentinos Juniors and Boca Juniors.
On 20 October 1976, Maradona made his professional debut for Argentinos Juniors, ten days before his sixteenth birthday. He entered to the pitch wearing the number 16 jersey, and after the game stated: "That day I felt I had held the sky in my hands". Maradona scored his first goal in the Primera División against Marplatense team San Lorenzo on 14 November 1976, two weeks after turning 16. Maradona spent five years at Argentinos Juniors, from 1976 to 1981, scoring 115 goals in 167 appearances before his US$ 4 million transfer to Boca Juniors. Maradona received offers to join other clubs, including River Plate who offered to make him the club's best paid player. Nevertheless, Maradona expressed his will to be transferred to Boca Juniors, the team he always wanted to play for.
Maradona signed a contract with Boca Juniors on 20 February 1981. He made his debut two days later against Talleres de Córdoba, scoring twice in the club's 4-1 win. On 10 April, Maradona played his first "Superclásico" against River Plate at "La Bombonera". Boca defeated River 3-0 with Maradona scoring a goal after dribbling past Tarantini and Fillol. Despite the distrustful relationship between Maradona and Boca Juniors manager, Silvio Marzolini, Boca had a successful season, winning the league title after securing a point against Racing Club. That would be the only title won by Maradona in the Argentine domestic league.
Barcelona.
After the 1982 World Cup, in June, Maradona was transferred to FC Barcelona in Spain for a then world record fee of £5m ($7.6m). In 1983, under coach César Luis Menotti, Barcelona and Maradona won the Copa del Rey (Spain's annual national cup competition), beating Real Madrid, and the Spanish Super Cup, beating Athletic Bilbao. On 26 June 1983, Barcelona defeated Real Madrid on the road in the world's biggest club game, "El Clásico", a match where Maradona scored and became the first Barcelona player to be applauded by arch rival Real Madrid fans. Maradona dribbled past Madrid goalkeeper Agustín, and as he approached the empty goal he stopped just as Madrid defender Juan José came sliding in a desperate attempt to block the shot and ended up crashing into the post, before Maradona slotted the ball into the net. The manner of the goal led to many inside the stadium start applauding: only Ronaldinho (in November 2005), and Andrés Iniesta (in November 2015), have since been granted such an ovation as Barcelona players from Madrid fans at the Santiago Bernabéu. Due to illness and injury as well as controversial incidents on the field, Maradona had a difficult tenure in Barcelona. First a bout of hepatitis, then a broken ankle in a La Liga game at the Camp Nou in September 1983 caused by an ill-timed tackle by Athletic Bilbao's Andoni Goikoetxea threatened to jeopardize Maradona's career, but after treatment and therapy it was possible for him to be back on the pitch after a recovery period of three months.
The end of the 1983–84 season included a violent and chaotic fight Maradona was directly involved in at the 1984 Copa del Rey final at the Santiago Bernabéu against Athletic Bilbao. After receiving another rough tackle by Goikoetxea which wounded his leg, being taunted with xenophobic insults throughout the match by Bilbao fans, and being provoked by Bilbao's Miguel Sola at full time as Barcelona lost 1–0, Maradona snapped. He aggressively got up, stood inches from Sola's face and the two exchanged words. This started a chain reaction of emotional reactions from both teams. Using expletives, Sola mimicked a gesture from the crowd towards Maradona by using a xenophobic term. Maradona then headbutted Sola, elbowed another Bilbao player in the face, and kneed another player in the head, knocking him out cold. The Bilbao squad surrounded Maradona to exact some retribution with Goikoetxea connecting with a high kick to his chest, before the rest of the Barcelona squad joined in to help Maradona; and from this point on the Barcelona and Bilbao players brawled on the field with Maradona in the center of the action, kicking and punching anyone in a Bilbao shirt.
The mass brawl was played out in front of the Spanish King Juan Carlos and an audience of 100,000 fans inside the stadium, and more than half of Spain watching on television. Sixty people were injured; and this incident effectively sealed Maradona's transfer out of the club in what was his last game in a Barcelona shirt. One Barcelona executive stated: "When I saw those scenes of Maradona fighting and the chaos that followed I realized we couldn't go any further with him." Maradona got into frequent disputes with Barcelona FC executives, especially club president Josep Lluís Núñez, culminating with a demand to be transferred out of Camp Nou in 1984. During his two injury-hit seasons at Barcelona, Maradona scored 38 goals in 58 games. Maradona transferred to Napoli in Italy's Serie A for another world record fee, £6.9m ($10.48m).
Napoli.
Maradona arrived in Naples and was presented to the world media as a Napoli player on 5 July 1984, where he was welcomed by 75,000 fans at his presentation at the Stadio San Paolo. Sports writer David Goldblatt commented; "They fans were convinced that the saviour had arrived." A local newspaper stated that despite the lack of a "mayor, houses, schools, buses, employment and sanitation, none of this matters because we have Maradona." Prior to Maradona's arrival, Italian football was dominated by teams from the north and centre of the country, such as A.C. Milan, Juventus, Inter Milan and A.S. Roma, and no team in the south of the Italian Peninsula had ever won a league title.
At Napoli, Maradona reached the peak of his professional career: he soon inherited the captain's armband from Napoli veteran defender Giuseppe Bruscolotti, and quickly became an adored star among the club's fans; in his time there he elevated the team to the most successful era in its history. Maradona played for Napoli at a period when North-South tensions in Italy were at a peak due to a variety of issues, notably the economic differences between the two. Led by Maradona, Napoli won their first ever Serie A Italian Championship in 1986–87. Goldblatt wrote; "The celebrations were tumultuous. A rolling series of impromptu street parties and festivities broke out contagiously across the city in a round-the-clock carnival which ran for over a week. The world was turned upside down. The Neapolitans held mock funerals for Juventus and Milan, burning their coffins, their death notices announcing 'May 1987, the other Italy has been defeated. A new empire is born.'" Murals of Maradona were painted on the city's ancient buildings, and newborn children were named in his honor. The following season, the team's prolific attacking trio, formed by Maradona, Bruno Giordano, and Careca, was later dubbed the "Ma-Gi-Ca" ("magic") front-line.
Napoli would win their second league title in 1989–90, and finish runners up in the league twice, in 1987–88 and 1988–89. Other honors during the Maradona era at Napoli included the Coppa Italia in 1987, (second place in the Coppa Italia in 1989), the UEFA Cup in 1989 and the Italian Supercup in 1990. Despite primarily playing in a creative role, as an attacking midfielder, Maradona was the top scorer in Serie A in 1987–88, with 15 goals, and is the all-time leading goalscorer for Napoli with 115 goals. When asked who was the toughest player he ever faced, A.C. Milan legend Franco Baresi stated: "Maradona; when he was on form, there was almost no way of stopping him", a view shared by his Milan teammate and fellow all-time great Paolo Maldini, who stated: "The best ever I played against was Maradona."
While Maradona was successful on the field, during his time in Italy his personal problems increased. His cocaine use continued, and he received US $70,000 in fines from his club for missing games and practices, ostensibly because of 'stress'. He faced a scandal there regarding an illegitimate son; and he was also the object of some suspicion over an alleged friendship with the Camorra. Later on, in honor of Maradona and his achievements during his career at Napoli, the No. 10 jersey of Napoli was officially retired.
Sevilla, Newell's Old Boys and Boca Juniors.
After serving a 15-month ban for failing a drug test for cocaine, Maradona left Napoli in disgrace in 1992. Despite interest from Real Madrid of Spain and Olympique Marseille of France, he signed for Sevilla of Spain, where he stayed for one year. In 1993 he played for Newell's Old Boys and in 1995 he returned to Boca Juniors for two years. Maradona also appeared for Tottenham Hotspur in a friendly match against Inter Milan, shortly before the 1986 World Cup. The match was a testimonial for Osvaldo Ardiles, who insisted that his friend Maradona play.
International career.
During his time with the Argentine national team, Maradona scored 34 goals in 91 appearances. He made his full international debut at age 16, against Hungary on 27 February 1977. Maradona was left off the Argentine squad for the 1978 World Cup on home soil by coach Cesar Luis Menotti who felt the 17-year-old was still too young. At age 18, he played the 1979 FIFA World Youth Championship in Japan, and was the star of the tournament, shining in Argentina's 3–1 final win over the Soviet Union. On 2 June 1979, Maradona scored his first senior international goal in a 3–1 win against Scotland at Hampden Park.
Maradona and his compatriot and heir apparent, Lionel Messi, are the only players to win the Golden Ball at both the FIFA U-20 World Cup and FIFA World Cup. Maradona did so in 1979 and 1986, which Messi emulated in 2005 and 2014.
1982 World Cup.
Maradona played his first World Cup tournament in 1982 in his new country of residence, Spain. Argentina played Belgium in the opening game of the 1982 Cup at the Camp Nou in Barcelona. The Catalan crowd was eager to see their new world-record signing Maradona in action, but he did not perform to expectations. Argentina, the defending champions, lost to Belgium 1–0. Although the team convincingly beat both Hungary and El Salvador in Alicante to progress to the second round, there were internal tensions within the team, with the younger, less experienced players at odds with the older, more experienced players. In a team that also included such players as Mario Kempes, Osvaldo Ardiles, Ramón Díaz, Daniel Bertoni, Alberto Tarantini, Ubaldo Fillol and Daniel Passarella, the Argentine side was defeated in the second round by Brazil and by eventual winners Italy. The Italian match is renowned for Maradona being aggressively man-marked by Claudio Gentile, as Italy beat Argentina at the Sarria Stadium in Barcelona 2-1.
Maradona played in all five matches without being substituted, scoring twice against Hungary. He was fouled repeatedly in all five games and particularly in the last one against Brazil at the Sarria; a game that was blighted by poor officiating and violent fouls. With Argentina already down 3-0 to Brazil, Maradona's temper eventually got the better of him and he was sent off with 5 minutes remaining for a serious retaliatory foul against João Batista da Silva.
1986 World Cup.
Maradona captained the Argentine national team to victory in the 1986 World Cup in Mexico, winning the final in the capital of Mexico City against West Germany. Throughout the 1986 World Cup Maradona asserted his dominance and was the most dynamic player of the tournament. He played every minute of every Argentina game, scored 5 goals and made 5 assists, three of those in the opening match against South Korea at the Olimpico Stadium in Mexico City. His first goal of the tournament came against Italy in the second group game in Puebla. Argentina eliminated Uruguay in the first knockout round in Puebla, and this meant that they were to play England at the Azteca Stadium in Mexico City. After scoring two contrasting goals in the 2–1 quarter-final win against England his legend was cemented. The majesty of his second goal and the notoriety of his first led to the French newspaper "L'Equipe" describing Maradona as "half-angel, half-devil". This match was played with the background of the Falklands War between Argentina and the United Kingdom. Replays showed that the first goal was scored by striking the ball with his hand. Maradona was coyly evasive, describing it as "a little with the head of Maradona and a little with the hand of God." It became known as the "Hand of God". Ultimately, on 22 August 2005 Maradona acknowledged on his television show that he had hit the ball with his hand purposely, and no contact with his head was made, and that he immediately knew the goal was illegitimate. This became known as an international fiasco in World Cup history. The goal stood, much to the wrath of the English players.
Maradona's second goal, just four minutes after the hotly disputed hand-goal, was later voted by FIFA as the greatest goal in the history of the World Cup. He received the ball in his own half, swivelled around, and with 11 touches ran more than half the length of the field, dribbling past five English outfield players (Peter Beardsley, Steve Hodge, Peter Reid, Terry Butcher, and Terry Fenwick) before he left goalkeeper Peter Shilton on his backside with a feint, and slotted the ball into the net. This goal was voted "Goal of the Century" in a 2002 online poll conducted by FIFA.
Maradona followed this with two more goals in a semi-final match against Belgium at the Azteca, including another virtuoso dribbling display for the second goal. In the final match, West Germany attempted to contain him by double-marking, but he nevertheless found the space past the West German player Lothar Matthäus to give the final pass to Jorge Burruchaga for the winning goal. Argentina beat West Germany 3–2 in front of 115,000 fans at the Azteca.
During the course of the tournament, Maradona attempted or created more than half of Argentina's shots, embarked on 90 dribbles some three times more than any other player and was fouled 53 times winning his team twice as many free kicks as any player. Maradona scored or assisted 10 of Argentina's 14 goals including the assist for the winning goal in the final, ensuring that he would be remembered as one of the greatest names in football history. By the end of the World Cup, Maradona went on to win the Golden Ball as the best player of the tournament by unanimous vote and was widely regarded to have won the World Cup virtually single-handedly, something that he didn't entirely agree with. In a tribute to him, Azteca Stadium authorities built a statue of him scoring the "Goal of the Century" and placed it at the entrance of the stadium.
1990 World Cup.
Maradona captained Argentina again in the 1990 World Cup in Italy to yet another World Cup Final. An ankle injury affected his overall performance, and he was much less dominant than four years earlier. After losing their opening game to the Cameroon at the San Siro in Milan, Argentina were almost eliminated in the first round, only qualifying in third position from their group. In the round of 16 match against Brazil in Turin, Claudio Caniggia scored the only goal after being set up by Maradona.
In the quarter final, Argentina faced Yugoslavia in Florence, the match ending 0–0 after 120 minutes, and Argentina advancing on penalty kicks, despite Maradona missing one of the penalties in the shootout with a weak shot to the goalkeeper's right. The semifinal against the host nation Italy at Maradona's club stadium in Naples was also resolved on penalties after a 1–1 draw; this time, Maradona was successful with his effort, daringly rolling the ball into the net with an almost exact replica of his missed shot in the previous round. At the final in Rome, Argentina lost 1–0 to West Germany, the only goal being a penalty by Andreas Brehme in the 85th minute after a controversial foul on Rudi Völler.
1994 World Cup.
At the 1994 World Cup in the United States, Maradona played in only two games (both at the Foxboro Stadium near Boston), scoring one goal against Greece, before being sent home after failing a drug test for ephedrine doping. In his autobiography, Maradona argued that the test result was due to his personal trainer giving him the power drink Rip Fuel. His claim was that the U.S. version, unlike the Argentine one, contained the chemical and that, having run out of his Argentine dosage, his trainer unwittingly bought the U.S. formula. FIFA expelled him from USA '94 and Argentina were subsequently eliminated in the second round by Romania in Los Angeles. Maradona has also separately claimed that he had an agreement with FIFA, on which the organization reneged, to allow him to use the drug for weight loss before the competition in order to be able to play. His failed drugs test at the 1994 World Cup signaled the end of his international career, which had lasted 17 years and yielded 34 goals from 91 games.
Playing style.
A classic number 10, Maradona was renowned for his dribbling ability, vision, close ball control, passing and creativity, and is considered one of the most skillful players ever. He had a compact physique, and with his strong legs and low center of gravity he could withstand physical pressure well while running with the ball. Dutch legend Johan Cruyff saw similarities between Maradona and Lionel Messi with the ball seemingly attached to their body when dribbling. His physical strengths were illustrated by his two goals against Belgium in the 1986 World Cup. He was a strategist and a team player, as well as highly technical with the ball. He could manage himself effectively in limited spaces, and would attract defenders only to quickly dash out of the melee (as in the second 1986-goal against England), or give an assist to a free teammate. Being short, but strong, he could hold the ball long enough with a defender on his back to wait for a teammate making a run or to find a gap for a quick shot. He showed leadership qualities on the field and captained Argentina in their World Cup campaigns of 1986, 1990 and 1994.
One of Maradona's trademark moves was dribbling full-speed on the right wing, and on reaching the opponent's goal line, delivering accurate passes to his teammates. Another trademark was the "Rabona," a reverse-cross pass shot behind the leg that holds all the weight. This maneuver led to several assists, such as the powerful cross for Ramón Díaz's header in the 1980 friendly against Switzerland. He was also a dangerous free kick and penalty kick taker.
Maradona was famous for his cunning personality. Inherent within his nickname "El Pibe de Oro" ("Golden Boy") is a sense of mischief, with "pibe" being an anti-establishment rogue, street smart and full of guile. Some critics view his controversial "Hand of God" goal at the 1986 World Cup as a clever maneuver, with one of the opposition players, Glenn Hoddle, admitting that Maradona had disguised it cunningly in flicking his head at the same time as palming the ball. The goal itself has been viewed as an embodiment of the Buenos Aires shanty town Maradona was brought up in and its concept of "viveza criolla" — native cunning. Maradona used his hand in the 1990 World Cup, again without punishment, and this time on his own goal line, to prevent the USSR from scoring. A number of publications have referred to Maradona as the Artful Dodger, the urchin pickpocket expert from Charles Dickens' "Oliver Twist".
Maradona was dominantly left-footed, often using his left foot even when the ball was positioned more suitably for a right-footed connection. His first goal against Belgium in the 1986 World Cup semi-final is a worthy indicator of such; he had run into the inside right channel to receive a pass but let the ball travel across to his left foot, requiring more technical ability. During his run past several England players in the previous round for the "Goal of the Century" he did not use his right foot once, despite spending the whole movement on the right-hand side of the pitch. In the 1990 World Cup second round tie against Brazil, he did use his right foot to set up the winning goal for Caniggia due to two Brazilian markers forcing him into a position that made use of his left foot less practical.
Retirement and honours.
Hounded for years by the press, Maradona once fired a compressed-air rifle at reporters who he claimed were invading his privacy. This quote from former teammate Jorge Valdano summarizes the feelings of many:
In 1990 Konex Foundation from Argentina granted him the Diamond Konex Award, one of the most prestigious culture awards in Argentina, as the most important personality in Sports in the last decade in his country. In 2000, Maradona published his autobiography "Yo Soy El Diego" ("I am "The Diego""), which became a bestseller in his home country. Two years later, Maradona donated the Cuban royalties of his book to "the Cuban people and Fidel."
In 2000, he won FIFA Player of the Century award which was to be decided by votes on their official website, their official magazine and a grand jury. Maradona won the Internet-based poll, garnering 53.6% of the votes against 18.53% for Pelé. In spite of this, and shortly before the ceremony, FIFA added a second award and appointed a "Football Family" committee composed of football journalists that also gave to Pelé the title of best player of the century to make it a draw. Maradona also came fifth in the vote of the IFFHS (International Federation of Football History and Statistics). In 2001, the Argentine Football Association (AFA) asked FIFA for authorization to retire the jersey number 10 for Maradona. FIFA did not grant the request, even though Argentine officials have maintained that FIFA hinted that it would.
Maradona has topped a number of fan polls, including a 2002 FIFA poll in which his second goal against England was chosen as the best goal ever scored in a World Cup; he also won the most votes in a poll to determine the All-Time Ultimate World Cup Team. On 22 March 2010, Maradona was chosen number 1 in The Greatest 10 World Cup players of all time by the London-based newspaper "The Times". Argentinos Juniors named its stadium after Maradona on 26 December 2003. In 2003, Maradona was employed by the Libyan footballer Al-Saadi Gaddafi, the third son of Colonel Muammar Gaddafi, as a "technical consultant", while Al-Saadi was playing for the Italian club, Perugia Calcio, which was in Serie A at the time.
On 22 June 2005, it was announced that Maradona would return to Boca Juniors as a sports vice president in charge of managing the First Division roster (after a disappointing 2004–05 season, which coincided with Boca's centenary). His contract began 1 August 2005, and one of his first recommendations proved to be very effective: advising the club to hire Alfio Basile as the new coach. With Maradona fostering a close relationship with the players, Boca won the 2005 Apertura, the 2006 Clausura, the 2005 Copa Sudamericana and the 2005 Recopa Sudamericana.
On 15 August 2005, Maradona made his debut as host of a talk-variety show on Argentine television, La Noche del 10 ("The Night of the no. 10"). His main guest on opening night was Pelé; the two had a friendly chat, showing no signs of past differences. However, the show also included a cartoon villain with a clear physical resemblance to Pelé. In subsequent evenings, he led the ratings on all occasions but one. Most guests were drawn from the worlds of football and show business, including Ronaldo and Zinedine Zidane, but also included interviews with other notable friends and personalities such as Cuban leader Fidel Castro and boxers Roberto Durán and Mike Tyson. Maradona gave each of his guests a signed Argentina jersey, which Tyson wore when he arrived in Brazil, Argentina's deadliest rivals.
In May 2006, Maradona agreed to take part in UK's Soccer Aid (a program to raise money for Unicef). In September 2006, Maradona, in his famous blue and white number 10, was the captain for Argentina in a three-day World Cup of Indoor Football tournament in Spain. On 26 August 2006, it was announced that Maradona was quitting his position in the club Boca Juniors because of disagreements with the AFA, who selected Basile to be the new coach of the Argentina national football team. In 2008, award-winning Serbian filmmaker Emir Kusturica made a documentary about Maradona's life, entitled "Maradona".
On 1 September 2014, Maradona, along with many current and former footballing stars, took part in the "Match for Peace", which was played at the Stadio Olimpico, in Rome, with the proceeds being donated entirely to charity. Maradona set up a goal for Roberto Baggio during the first half of the match, with a chipped through-ball over the defence with the outside of his left foot. Unusually, both Baggio and Maradona wore the number 10 shirt, despite playing on the same team. On 17 August 2015, Maradona visited Ali Bin Nasser, the Tunisian referee of the Argentina vs England quarter-final match at the 1986 World Cup where Maradona scored his Hand of God, and paid tribute to him by giving him a signed Argentine jersey.
Managerial career.
Club management.
He attempted to work as a coach alongside former Argentinos Juniors midfield team mate Carlos Fren. The pair led Mandiyú of Corrientes (1994) and Racing Club (1995), but with little success. In May 2011 he became manager of Dubai club Al Wasl FC in the United Arab Emirates. Maradona was sacked on 10 July 2012.
International management.
After the resignation of Argentina national football team coach Alfio Basile in 2008, Diego Maradona immediately proposed his candidacy for the vacant role. According to several press sources, his major challengers included Diego Simeone, Carlos Bianchi, Miguel Ángel Russo and Sergio Batista. On 29 October 2008, AFA chairman Julio Grondona confirmed that Maradona would be the head coach of the national team from December 2008. On 19 November 2008, Diego Maradona managed Argentina for the first time when Argentina played against Scotland at Hampden Park in Glasgow which Argentina won 1–0.
After winning his first three matches in charge of the national team, he oversaw a 6–1 defeat to Bolivia, equalling the team's worst ever margin of defeat. With two matches remaining in the qualification tournament for the 2010 World Cup, Argentina was in fifth place and faced the possibility of failing to qualify, but victory in the last two matches secured qualification for the finals. After Argentina's qualification, Maradona used abusive language at the live post-game press conference, telling members of the media to "suck it and keep on sucking it". FIFA responded with a two-month ban on all footballing activity, which expired on 15 January 2010, and a CHF 25,000 fine, with a warning as to his future conduct. The friendly match scheduled to take place at home to the Czech Republic on 15 December, during the period of the ban, was cancelled. The only match Argentina played during Maradona's ban was a friendly away to Catalonia, which Argentina lost 4–2.
At the World Cup finals in June 2010, Argentina started by winning 1–0 against Nigeria, and then defeated South Korea by 4–1, with a hat-trick from Gonzalo Higuain. In the final match of the group stage Argentina won 2–0 against Greece to win their the group and advance to a second round meeting with Mexico. After defeating Mexico 3–1, Argentina was in turn routed by Germany, 4–0 in the quarter finals to go out of the competition. Argentina was ranked 5th in the tournament. After the defeat to Germany Maradona admitted that he was considering his future as Argentina coach, "I may leave tomorrow," he said. On 15 July 2010, the Argentine Football Association said that he would be offered a new 4-year deal that would keep him in charge through to the summer of 2014 when Brazil stages the World Cup, however on 27 July the AFA announced that its board had unanimously decided not to renew his contract. Afterwards on 29 July 2010, Maradona claimed that AFA president Julio Grondona and director of national teams (and his former Argentine national team and FC Sevilla coach) Carlos Bilardo had "lied to" and "betrayed" and effectively sacked him from the role. Saying "they wanted me to continue, but seven of my staff should not go on, if he told me that, it meant he did not want me to keep working".
Personal life.
Family.
Born to a Roman Catholic family, his parents are Diego Maradona Senior and Dalma Salvadora Franco. His father is of Italian and Native Amerindian origin and his mother is of Spanish and Croatian origin. Maradona married long-time fiancée Claudia Villafañe on 7 November 1984 in Buenos Aires, and they had two daughters, Dalma Nerea (born 2 April 1987) and Giannina Dinorah (born 16 May 1989), by whom he became a grandfather in 2009. In his autobiography, Maradona admits he was not always faithful to Claudia, even though he refers to her as the love of his life.
Maradona and Villafañe divorced in 2004. Daughter Dalma has since asserted that the divorce was the best solution for all, as her parents remained on friendly terms. They travelled together to Napoli for a series of homages in June 2005 and were seen together on other occasions, including the Argentina games during 2006 World Cup.
During the divorce proceedings, Maradona admitted he is the father of Diego Sinagra (born in Naples on 20 September 1986). The Italian courts had already ruled so in 1993, after Maradona refused to undergo DNA tests for proving or disproving his paternity. Diego Junior met Maradona for the first time in May 2003 after tricking his way onto a golf course in Italy where Maradona was playing. Sinagra is now a footballer playing in Italy. After the divorce, Claudia embarked on a career as a theatre producer, and Dalma was seeking an acting career; she had expressed her desire to attend the Actor's Studio in Los Angeles.
His younger daughter, Giannina, married Manchester City striker Sergio Agüero, with whom she has a son, Benjamin, born in Madrid on 19 February 2009. In January 2013, Agüero and Giannina separated. His mother, Dalma, died on 19 November 2011. Diego was in Dubai at the time, and desperately tried to fly back in time to see her, but was too late. She was 81 years old. His father, "Don" Diego, died on 25 June 2015; he was 87. His son Diego Fernando, whom he had with his ex long term partner Veronica Ojeda, was born 13 February 2013.
Drug abuse and health issues.
From the mid-1980s until 2004 Diego Maradona was addicted to cocaine. He allegedly began using the drug in Barcelona in 1983. By the time he was playing for Napoli he had a regular addiction, which began to interfere with his ability to play football. Over the years following his retirement his health seriously deteriorated. On 4 January 2000, while vacationing in Punta del Este, Uruguay, Maradona had to be rushed to the emergency room of a local clinic. In a press conference, doctors stated that it was detected heart muscle damage due to "an underlying health issue". It was later known that traces of cocaine were found in his blood and Maradona had to explain the circumstances to the police. After this he left Argentina and went to Cuba in order to follow a drug rehab plan. On 18 April 2004, doctors reported that Maradona had suffered a major myocardial infarction following a cocaine overdose; he was admitted to intensive care in a Buenos Aires hospital. Scores of fans gathered around the clinic. He was taken off the respirator on 23 April and remained in intensive care for several days before being discharged on 29 April. He tried to return to Cuba, where he had spent most of his time in the years leading up to the heart attack, but his family opposed, having filed a judicial petition to exercise his legal guardianship.
Maradona had a tendency to put on weight, and suffered increasingly from obesity (at one point weighing 280 lb (127 kg)) from the end of his playing career until undergoing gastric bypass surgery in a clinic in Cartagena de Indias, Colombia on 6 March 2005. His surgeon said that Maradona would follow a liquid diet for three months in order to return his normal weight. When Maradona resumed public appearances shortly thereafter, he displayed a notably thinner figure. On 29 March 2007, Maradona was readmitted to a hospital in Buenos Aires. He was treated for hepatitis and effects of alcohol abuse, and was released on 11 April, but re-admitted two days later. In the following days there were constant rumors about his health, including three false claims of his death within a month. After transfer to a psychiatric clinic specialising in alcohol-related problems, he was discharged on 7 May. On 8 May 2007, Maradona appeared on Argentine television and stated that he had quit drinking and had not used drugs in two and a half years.
Political views.
Having previously been vocal in his support of neoliberal Argentine President Carlos Menem and his Harvard University-educated economist Domingo Cavallo, Maradona has shown sympathy to left-wing ideologies. He became friends with Cuban leader Fidel Castro while receiving treatment on the island with Castro stating: "Diego is a great friend and very noble, too. There’s also no question he’s a wonderful athlete and has maintained a friendship with Cuba to no material gain of his own.” He has a portrait of Castro tattooed on his left leg and one of Fidel's second in command, fellow Argentine Che Guevara on his right arm. In his autobiography, "El Diego", he dedicated the book to various people, including Castro, he wrote "To Fidel Castro and, through him, all the Cuban people".
Maradona was also a supporter of former Venezuelan President Hugo Chávez. In 2005, he came to Venezuela to meet Chávez, who received him in the Miraflores. After this meeting, Maradona claimed that he had come with the aim of meeting a "great man" ("un grande" in Spanish) but he had met instead a gigantic man ("un gigante" in Spanish, meaning he was more than great). "I believe in Chávez, I am Chavista. Everything Fidel does, everything Chávez does, for me is the best." Maradona was the guest of honor of Chávez at the opening game of the 2007 Copa América held in Venezuela.
He has declared his opposition to what he identifies as imperialism, notably during the 2005 Summit of the Americas in Mar del Plata, Argentina. There he protested George W. Bush's presence in Argentina, wearing a T-shirt labeled "STOP BUSH" (with the "s" in "Bush" being replaced with a swastika) and referring to Bush as "human garbage". In August 2007, Maradona went further, making an appearance on Chávez's weekly television show "Alo Presidente" and saying: "I hate everything that comes from the United States. I hate it with all my strength." In December 2008, Maradona expressed admiration for Bush's successor, President-elect Barack Obama, and held great expectations for him.
With his poor shanty town upbringing, Maradona has cultivated a man of the people persona. During a meeting with Pope John Paul II at the Vatican in 1987 they clashed on the issue of wealth disparity, with Maradona stating: "I argued with him because I was in the Vatican and I saw all these golden ceilings and afterwards I heard the Pope say the Church was worried about the welfare of poor kids. Sell your ceiling then amigo, do something!". In September 2014 Maradona met with Pope Francis in Rome, crediting Francis for inspiring him to return to religion after many years, and stated: "We should all imitate Pope Francis. If each one of us gives something to someone else, no one in the world would be starving".
In December 2007, Maradona presented a signed shirt with a message of support to the people of Iran: it is displayed in the Iranian Ministry of Foreign Affairs' museum. In April 2013, Maradona visited the tomb of Hugo Chávez and urged Venezuelans to elect the late leader's designated successor, Nicolás Maduro, to continue the socialist leader's legacy; "Continue the struggle," Maradona said on television. Maradona attended Maduro's final campaign rally in Caracas, signing footballs and kicking them to the crowd, and presented Maduro with an Argentina jersey. Having visited Chávez's tomb with Maradona, Maduro said; "Speaking with Diego was very emotional because comandante Chávez also loved him very much".
In October 2015, Maradona thanked Queen Elizabeth II and the Houses of Parliament in London for giving him the chance to provide "true justice" as head of an organisation designed to help young children. In a video released on his official Facebook page Maradona confirmed he would accept their nomination for him to become Latin American director for the non-governmental organisation Football for Unity.
Financial problems.
In March 2009 Italian officials announced that Maradona still owed the Italian government €37 million in taxes; €23.5 million of which was accrued interest on his original debt. They reported that thus far, Maradona has paid only €42,000, two luxury watches and a set of earrings.
In popular culture.
The American newspaper "The Houston Chronicle" wrote about Maradona:
In Argentina, Maradona is considered a sports hero to many. He is idolized, receiving the name of "God". On the idolatry that exists in Argentina, former teammate Jorge Valdano said: "At the time that Maradona retired from active football, left traumatized Argentina. Maradona was more than just a great footballer. It was a special compensation factor for a country that in a few years lived several military dictatorships and social frustrations of all kinds". Valdano added that "Maradona offered to the Argentines a way out of their collective frustration, and that's why people love him. There is a divine figure."
Ever since 1986, it is common for Argentines abroad to hear Maradona's name as a token of recognition, even in remote places. The Tartan Army sing a version of the Hokey Cokey in honour of the Hand of God goal against England. In Argentina, Maradona is often talked about in terms reserved for legends. In the Argentine film "El Hijo de la Novia" ("Son of the Bride"), somebody who impersonates a Catholic priest says to a bar patron: "they idolized him and then crucified him". When a friend scolds him for taking the prank too far, the fake priest retorts: "But I was talking about Maradona". He's the subject of the film "El Camino de San Diego", though he himself only appears in archive footage.
Maradona was included in many cameos in the Argentine comic book El Cazador de Aventuras. After the closing of it, the authors started a new short-lived comic book titled "El Die", using Maradona as the main character. Maradona has had several online Flash games that are entirely dedicated to his legacy. In Rosario, Argentina, locals organized the parody religion of the ""Church of Maradona"". The organization reformulates many elements from Christian tradition, such as Christmas or prayers, reflecting instead details from Maradona. It had 200 founding members, and tens of thousands more have become members via the church's official web site.
Many Argentine artists performed songs in tribute to Diego, like: "Maradó" by El Potro Rodrigo, "Maradona" by Andrés Calamaro, "Para siempre Diego" (Diego forever) by Los Ratones Paranoicos, "Para verte gambetear" (For seeing you dribble) by La Guardia Hereje, "Francotirador" (Sniper) by Attaque 77, "Dale Diez" (C'mon Diez) by Julio Lacarra, "Maradona blues" by Charly García, "Santa Maradona" (Saint Maradona) by Mano Negra, "La Vida Tombola" by Manu Chao, "¿Qué es Dios?" (What is God?) by Las Pastillas del Abuelo, "Pelusa" (Fluff) by Los Cafres, among others. There are also films, such as: "Maradona, La Mano de Dios" (Maradona, the Hand of God), "El Camino de San Diego" (Saint Diego's Road), "Amando a Maradona" (Loving Maradona), "Maradona by Kusturica".
By 1982 Maradona had become one of the biggest sports stars in the world and had endorsements with many companies, including Puma and Coca-Cola, earning him $1.5 million per year in endorsements. In 1982 he featured in a World Cup commercial for Coca-Cola, and a Japanese commercial for Puma. In 2010, Maradona appeared in a commercial for the French fashion house Louis Vuitton, indulging in a game of table football with fellow legends Pelé and Zinedine Zidane. Maradona features in the music video to the 2010 World Cup song "Waka Waka" by Shakira, with footage shown of him celebrating Argentina winning the 1986 World Cup.
A 2006 television commercial for Brazilian soft drink Guaraná Antarctica portrayed Maradona as a member of the Brazilian national football team, including wearing the yellow jersey and singing the Brazilian national anthem with Brazilian caps Kaká and Ronaldo. Later on in the commercial he wakes up realizing it was a nightmare after having drunk too much of the drink. This generated some controversy in the Argentine media after its release (although the commercial was not supposed to air on the Argentine market, fans could see it online). Maradona replied that he has no problem in wearing the Brazilian national squad jersey despite Argentina and Brazil having a tense rivalry in football, but that he would refuse to wear the shirt of River Plate, Boca Juniors' traditional rival. There is a documented phenomenon of Brazilians being named in honour of Maradona, an example being footballer Diego Costa.

</doc>
<doc id="8487" url="https://en.wikipedia.org/wiki?curid=8487" title="David Brewster">
David Brewster

Sir David Brewster KH PRSE FRS FSA(Scot) FSSA MICE (11 December 1781 – 10 February 1868) was a Scottish physicist, mathematician, astronomer, inventor, writer, historian of science and university principal.
Most noted for his contributions to the field of optics, he studied the double refraction by compression and discovered the photoelastic effect, which gave birth to the field of optical mineralogy. For his work, William Whewell dubbed him the "Father of modern experimental optics" and "the Johannes Kepler of Optics."
He is well-recognized for being the inventor of the kaleidoscope and an improved version of the stereoscope applied to photography. He called it the "lenticular stereoscope", which was the first portable, 3D viewing device. He also invented the binocular camera, two types of polarimeters, the polyzonal lens and the lighthouse illuminator.
A prominent figure in the popularization of science, he is considered one of the founders of the "British Association", of which he would be elected President in 1849. In addition, he was the editor of the 18-volume "Edinburgh Encyclopædia".
Early life.
David Brewster was born at the Canongate in Jedburgh, Roxburghshire, to Margaret Key (1753–1790) and James Brewster (c. 1735–1815), the rector of Jedburgh Grammar School and a teacher of high reputation. David was the third of six children, two daughters and four sons: James (1777–1847), minister at Craig, Ferryden; David; David; George (1784–1855), minister at Scoonie, Fife; and Patrick (1788–1859), minister at the abbey church, Paisley.
At the age of 12, David was sent to the University of Edinburgh (graduating MA in 1800), being intended for the clergy. He was licensed a minister of the Church of Scotland, but only preached from the pulpit on one occasion. He had already shown a strong inclination for natural science, and this had been fostered by his intimacy with a "self-taught philosopher, astronomer and mathematician", as Sir Walter Scott called him, of great local fame—James Veitch of Inchbonny—a man who was particularly skilful in making telescopes.
Career.
Work on optics.
Though Brewster duly finished his theological studies and was licensed to preach, his other interests distracted him from the duties of his profession. In 1799 fellow-student Henry Brougham persuaded him to study the diffraction of light. The results of his investigations were communicated from time to time in papers to the "Philosophical Transactions" of London and other scientific journals. The fact that other scientists – notably Étienne-Louis Malus and Augustin Fresnel – were pursuing the same investigations contemporaneously in France does not invalidate Brewster's claim to independent discovery, even though in one or two cases the priority must be assigned to others. A lesser-known classmate of his, Thomas Dick, also went on to become a popular astronomical writer.
The most important subjects of his inquiries can be enumerated under the following five headings:
In this line of investigation, the prime importance belongs to the discovery of
These discoveries were promptly recognised. As early as 1807 the degree of LL.D. was conferred upon Brewster by Marischal College, Aberdeen; in 1815 he was elected a Fellow of the Royal Society of London, and received the Copley Medal; in 1818 he received the Rumford Medal of the society; and in 1816 the French Institute awarded him one-half of the prize of three thousand francs for the two most important discoveries in physical science made in Europe during the two preceding years. In 1821, he was made a foreign member of the Royal Swedish Academy of Sciences.
Among the non-scientific public, his fame spread more effectually by his invention in about 1815 of the kaleidoscope, for which there was a great demand in both the United Kingdom, France, and the United States. As a reflection of this fame, Brewster portrait was later printed in some cigar boxes. Brewster chose renowned achromatic lens developer Philip Carpenter as the sole manufacturer of the kaleidoscope in 1817. Although Brewster patented the kaleidoscope in 1817 (GB 4136), a copy of the prototype was shown to London opticians and copied before the patent was granted. As a consequence, the kaleidoscope became produced in large numbers, but yielded no direct financial benefits to Brewster. It proved to be a massive success with two hundred thousand kaleidoscopes sold in London and Paris in just three months.
An instrument of more significance, the stereoscope, which – though of much later date (1849) – along with the kaleidoscope did more than anything else to popularise his name, was not as has often been asserted the invention of Brewster. Sir Charles Wheatstone discovered its principle and applied it as early as 1838 to the construction of a cumbersome but effective instrument, in which the binocular pictures were made to combine by means of mirrors. A dogged rival of Wheatstone's, Brewster was unwilling to credit him with the invention, however, and proposed that the true author of the stereoscope was a Mr. Elliot, a "Teacher of Mathematics" from Edinburgh, who, according to Brewster, had conceived of the principles as early as 1823 and had constructed a lensless and mirrorless prototype in 1839, through which one could view drawn landscape transparencies, since photography had yet to be invented. Brewster's personal contribution was the suggestion to use prisms for uniting the dissimilar pictures; and accordingly the lenticular stereoscope may fairly be said to be his invention.
A much more valuable and practical result of Brewster's optical researches was the improvement of the British lighthouse system. Although Fresnel, who had also the satisfaction of being the first to put it into operation, perfected the dioptric apparatus independently, Brewster was active earlier in the field than Fresnel, describing the dioptric apparatus in 1812. Brewster pressed its adoption on those in authority at least as early as 1820, two years before Fresnel suggested it, and it was finally introduced into lighthouses mainly through Brewster's persistent efforts.
Other work.
Although Brewster's own discoveries were important, they were not his only service to science. He began writing in 1799 as a regular contributor to the "Edinburgh Magazine", of which he acted as editor at the age of twenty. In 1807, he undertook the editorship of the newly projected "Edinburgh Encyclopædia", of which the first part appeared in 1808, and the last not until 1830. The work was strongest in the scientific department, and many of its most valuable articles were from the pen of the editor. At a later period he was one of the leading contributors to the "Encyclopædia Britannica" (seventh and eighth editions) writing, among others, the articles on electricity, hydrodynamics, magnetism, microscope, optics, stereoscope, and voltaic electricity. He was elected a member of the American Antiquarian Society in 1816.
In 1819 Brewster undertook further editorial work by establishing, in conjunction with Robert Jameson (1774–1854), the "Edinburgh Philosophical Journal", which took the place of the "Edinburgh Magazine". The first ten volumes (1819–1824) were published under the joint editorship of Brewster and Jameson, the remaining four volumes (1825–1826) being edited by Jameson alone. After parting company with Jameson, Brewster started the "Edinburgh Journal of Science" in 1824, 16 volumes of which appeared under his editorship during the years 1824–1832, with very many articles from his own pen.
He contributed around three hundred papers to the transactions of various learned societies, and few of his contemporaries wrote as much for the various reviews. In the "North British Review" alone, seventy-five articles of his appeared. A list of his larger separate works will be found below. Special mention, however, must be made of the most important of them all: his biography of Sir Isaac Newton. In 1831 he published a short popular account of the philosopher's life in "Murray's Family Library"; but it was not until 1855 that he was able to issue the much fuller "Memoirs of the Life, Writings and Discoveries of Sir Isaac Newton", a work which embodied the results of more than 20 years' investigation of original manuscripts and other available sources.
Brewster's position as editor brought him into frequent contact with the most eminent scientific men, and he was naturally among the first to recognise the benefit that would accrue from regular communication among those in the field of science. In a review of Charles Babbage's book "Decline of Science in England" in "John Murray's Quarterly Review", he suggested the creation of "an association of our nobility, clergy, gentry and philosophers". This was taken up by various "Declinarians" and found speedy realisation in the British Association for the Advancement of Science. Its first meeting was held at York in 1831; and Brewster, along with Babbage and Sir John Herschel, had the chief part in shaping its constitution.
In the same year in which the British Association held its first meeting, Brewster received the honour of knighthood and the decoration of the Royal Guelphic Order. In 1838, he was appointed principal of the united colleges of St Salvator and St Leonard, University of St Andrews. In 1849, he acted as president of the British Association and was elected one of the eight foreign associates of the Institute of France in succession to J. J. Berzelius; and ten years later, he accepted the office of principal of the University of Edinburgh, the duties of which he discharged until within a few months of his death. In 1855, the government of France made him an Officier de la Légion d'honneur.
He was a close friend of William Henry Fox Talbot, inventor of the calotype process, who sent Brewster early examples of his work. It was Brewster who suggested Talbot only patent his process in England, initiating the development of early photography in Scotland and eventually allowing for the formation of the first photographic society in the world, the Edinburgh Calotype Club, in 1843. Brewster was a prominent member of the club until its dissolution sometime in the mid-1850s; however, his interest in photography continued, and he was elected the first President of the Photographic Society of Scotland when it was founded in 1856.
Of a high-strung and nervous temperament, Brewster was somewhat irritable in matters of controversy; but he was repeatedly subjected to serious provocation. He was a man of highly honourable and fervently religious character. In estimating his place among scientific discoverers, the chief thing to be borne in mind is that his genius was not characteristically mathematical. His method was empirical, and the laws that he established were generally the result of repeated experiment. To the ultimate explanation of the phenomena with which he dealt he contributed nothing, and it is noteworthy although he did not maintain to the end of his life the corpuscular theory he never explicitly adopted the wave theory of light. Few would dispute the verdict of James David Forbes, an editor of the eighth edition of the "Encyclopædia Britannica": "His scientific glory is different in kind from that of Young and Fresnel; but the discoverer of the law of polarization of biaxial crystals, of optical mineralogy, and of double refraction by compression, will always occupy a foremost rank in the intellectual history of the age." In addition to the various works of Brewster already mentioned, the following may be added: "Notes and Introduction to Carlyle's translation of Legendre's Elements of Geometry" (1824); "Treatise on Optics" (1831); " Letters on Natural Magic", addressed to Sir Walter Scott (1832) "The Martyrs of Science, or the Lives of Galileo, Tycho Brahe, and Kepler" (1841); "More Worlds than One" (1854).
In his "Treatise" he demonstrated that vegetal colors were related with the absorption spectra and he described for the first time the red fluorescence of chlorophyll.
Opposition to evolution.
Brewster's Christian beliefs stirred him to respond against the idea of the transmutation of species and the theory of evolution. In 1845 he wrote a highly critical review of the evolutionist work "Vestiges of the Natural History of Creation", in the "North British Review". which he considered to be an insult to Christian revelation and a dangerous example of materialism.
In 1862, he again responded to Darwin's "On the Origin of Species" and published the article "" in "Good Words". He stated that Darwin's book combined both "interesting facts and idle fancies" which made up a "dangerous and degrading speculation". He accepted adaptive changes, but he strongly opposed Darwin's statement about the "primordial form", which he considered an offensive idea to "both the naturalist and the Christian."
Family.
Brewster married twice. His first wife, Juliet Macpherson (c. 1776–1850), was a daughter of James Macpherson (1736–1796), a probable translator of Ossian poems. They married on 31 July 1810 in Edinburgh and had four sons and a daughter:
Brewster married a second time in Nice, on 26 (or 27) March 1857, to Jane Kirk Purnell (b. 1827), the second daughter of Thomas Purnell of Scarborough. Brewster died in 1868, and was buried at Melrose Abbey, next to his first wife and second son. The physics building at Heriot-Watt University is named in his honour.
In popular culture.
Brewster appears as a minor antagonist in the 2015 video game "Assassin's Creed Syndicate" as a scientist working for the Templars. He is assassinated by one of the protagonists, Evie Frye.

</doc>
<doc id="8488" url="https://en.wikipedia.org/wiki?curid=8488" title="Dual-tone multi-frequency signaling">
Dual-tone multi-frequency signaling

Dual-tone multi-frequency signaling (DTMF) is an in-band telecommunication signaling system using the voice-frequency band over telephone lines between telephone equipment and other communications devices and switching centers. DTMF was first developed in the Bell System in the United States, and became known under the trademark Touch-Tone for use in push-button telephones supplied to telephone customers, starting in 1963. DTMF is standardized by ITU-T Recommendation Q.23. It is also known in the UK as "MF4".
The Touch-Tone system using a telephone keypad gradually replaced the use of rotary dial and has become the industry standard for landline and mobile service. Other multi-frequency systems are used for internal signaling within the telephone network.
Multifrequency signaling.
Prior to the development of DTMF, telephone numbers were dialed by users with a loop-disconnect (LD) signaling, more commonly known as pulse dialing (dial pulse, DP) in the U.S. It functions by interrupting the current in the local loop between the telephone exchange and the calling party's telephone at a precise rate with a switch in the telephone that is operated by the rotary dial as it spins back to its rest position after having been rotated to each desired number. The exchange equipment responds to the dial pulses either directly by operating relays, or by storing the number in a digit register recording the dialed number. The physical distance for which this type of dialing was possible was restricted by electrical distortions and was only possible on direct metallic links between end points of a line. Placing calls over longer distances required either operator assistance or provision of special subscriber trunk dialing equipment. Operators used an earlier type of multi-frequency signaling.
Multi-frequency signaling is a group of signaling methods that use a mixture of two pure tone (pure sine wave) sounds. Various MF signaling protocols were devised by the Bell System and CCITT. The earliest of these were for in-band signaling between switching centers, where long-distance telephone operators used a 16-digit keypad to input the next portion of the destination telephone number in order to contact the next downstream long-distance telephone operator. This semi-automated signaling and switching proved successful in both speed and cost effectiveness. Based on this prior success with using MF by specialists to establish long-distance telephone calls, dual-tone multi-frequency signaling was developed for end-user signaling without the assistance of operators.
The DTMF system uses a set of eight audio frequencies transmitted in pairs to represent 16 signals, represented by the ten digits, the letters A to D, and the symbols "#" and "*". As the signals are audible tones in the voice frequency range, they can be transmitted through electrical repeaters and amplifiers, and over radio and microwave links, thus eliminating the need for intermediate operators on long-distance circuits.
AT&T described the product as "a method for pushbutton signaling from customer stations using the voice transmission path." In order to prevent consumer telephones from interfering with the MF-based routing and switching between telephone switching centers, DTMF frequencies differ from all of the pre-existing MF signaling protocols between switching centers: MF/R1, R2, CCS4, CCS5, and others that were later replaced by SS7 digital signaling. DTMF was known throughout the Bell System by the trademark "Touch-Tone". The term was first used by AT&T in commerce on July 5, 1960 and was introduced to the public on November 18, 1963, when the first push-button telephone was made available to the public. It was a registered trademark by AT&T from September 4, 1962 to March 13, 1984. It is standardized by ITU-T Recommendation Q.23. In the UK, it is also known as MF4.
Other vendors of compatible telephone equipment called the Touch-Tone feature "tone dialing" or "DTMF", or used their other trade names such as "Digitone" by Northern Electric Company in Canada.
As a method of in-band signaling, DTMF signals were also used by cable television broadcasters to indicate the start and stop times of local commercial insertion points during station breaks for the benefit of cable companies. Until out-of-band signaling equipment was developed in the 1990s, fast, unacknowledged DTMF tone sequences could be heard during the commercial breaks of cable channels in the United States and elsewhere. Previously, terrestrial television stations used DTMF tones to control remote transmitters.
#, *, A, B, C, and D.
The engineers had envisioned telephones being used to access computers, and automated response systems. They consulted with companies to determine the requirements. This led to the addition of the number sign (#, "pound" or "diamond" in this context, "hash", "square" or "gate" in the UK, and "octothorpe" by the original engineers) and asterisk or "star" (*) keys as well as a group of keys for menu selection: A, B, C and D. In the end, the lettered keys were dropped from most phones, and it was many years before the two symbol keys became widely used for vertical service codes such as *67 in the United States of America and Canada to suppress caller ID.
Public payphones that accept credit cards use these additional codes to send the information from the magnetic strip.
The AUTOVON telephone system of the United States Armed Forces used these signals to assert certain privilege and priority levels when placing telephone calls. Precedence is still a feature of military telephone networks, but using number combinations. For example, entering 93 before a number is a priority call.
Present-day uses of the A, B, C and D signals on telephone networks are few, and are exclusive to network control. For example, the A key is used on some networks to cycle through different carriers at will. The A, B, C and D tones are used in radio phone patch and repeater operations to allow, among other uses, control of the repeater while connected to an active phone line.
The *, #, A, B, C and D keys are still widely used worldwide by amateur radio operators and commercial two-way radio systems for equipment control, repeater control, remote-base operations and some telephone communications systems.
DTMF signaling tones can also be heard at the start or end of some VHS (Video Home System) cassette tapes. Information on the master version of the video tape is encoded in the DTMF tone. The encoded tone provides information to automatic duplication machines, such as format, duration and volume levels, in order to replicate the original video as closely as possible.
DTMF tones are used in some caller ID systems to transfer the caller ID information, but in the United States only Bell 202 modulated FSK signaling is used to transfer the data.
Keypad.
The DTMF telephone keypad is laid out in a 4×4 matrix of push buttons in which each row represents the "low" frequency component and each column represents the "high" frequency component of the DTMF signal. Pressing a key sends a combination of the row and column frequencies. For example, the key "1" produces a superimposition of tones of 697 and 1209 hertz (Hz). Initial pushbutton designs employed levers, so that each button activated two contacts. The tones are decoded by the switching center to determine the keys pressed by the user.
Decoding.
DTMF was originally decoded by tuned filter banks. By the end of the 20th century, digital signal processing became the predominant technology for decoding. DTMF decoding algorithms often use the Goertzel algorithm to detect tones.
Other multiple frequency signals.
National telephone systems define other tones that indicate the status of lines, equipment, or the result of calls. Such call-progress tones are often also composed of multiple frequencies and are standardized in each country. The Bell System defines them in the Precise Tone Plan. However, such signaling systems are not considered to belong to the DTMF system.

</doc>
<doc id="8489" url="https://en.wikipedia.org/wiki?curid=8489" title="Deuterocanonical books">
Deuterocanonical books

Deuterocanonical books is a term used since the 16th century in the Catholic Church and Eastern Christianity to describe certain books and passages of the Christian Old Testament that are not part of the current Hebrew Bible. The term is used in contrast to the protocanonical books, which are contained in the Hebrew Bible. This distinction had previously contributed to debate in the early Church about whether they should be classified as canonical texts. The term is used as a matter of convenience by the Ethiopian Orthodox Tewahedo Church and other Churches to refer to books of their Old Testament which are not part of the Masoretic Text.
The deuterocanonical books are considered canonical by Catholics, Eastern Orthodox, Oriental Orthodox, and the Church of the East, but are considered non-canonical by most Protestants. The word "deuterocanonical" comes from the Greek meaning 'belonging to the second canon'.
The original usage of the term distinguished these scriptures both from those considered "non-canonical" and from those considered "protocanonical". However, some editions of the Bible include text from both deuterocanonical and non-canonical scriptures in a single section designated "Apocrypha". This arrangement can lead to conflation between the otherwise distinct terms "deuterocanonical" and "apocryphal".
History.
Deuterocanonical is a term coined in 1566 by the theologian Sixtus of Siena, who had converted to Catholicism from Judaism, to describe scriptural texts of the Old Testament considered canonical by the Catholic Church, but which are not present in the Hebrew Bible today, and including some texts which had been omitted by some early canon lists, especially in the East.
Their acceptance among early Christians was widespread, though not universal, and the Bible of the early Church always included, with varying degrees of recognition, books now called "deuterocanonical". Some say that their canonicity seems not to have been doubted in the Church until it was challenged by Jews after AD 100, sometimes postulating a hypothetical Council of Jamnia. Regional councils in the West published official canons that included these books as early as the 4th and 5th centuries.
The "Catholic Encyclopedia" states that "At Jerusalem there was a renewal, or at least a survival, of Jewish ideas, the tendency there being distinctly unfavourable to the deuteros. St. Cyril of Jerusalem, while vindicating for the Church the right to fix the Canon, places them among the apocrypha and forbids all books to be read privately which are not read in the churches. In Antioch and Syria the attitude was more favourable. St. Epiphanius of Salamis hesitated about the rank of the deuteros. While he esteemed them, they did not hold the same place as the Hebrew books in his regard. On the other hand, the Oriental versions and Greek manuscripts of the period are more liberal. They have all the deuterocanonicals and, in some cases, certain apocrypha."
"In the Latin Church, all through the Middle Ages, there is evidence of hesitation about the character of the deuterocanonicals. One is favourable, the other unfavourable to their authority and sacredness. Wavering between the two are a number of writers whose veneration for these books is tempered by some perplexity as to their exact standing, and among those is St. Thomas Aquinas. Few are found to unequivocally acknowledge their canonicity. The prevailing attitude of Western medieval authors is substantially that of the Greek Fathers. The chief cause of this phenomenon in the West is to be sought in the influence, direct and indirect, of St. Jerome's depreciating Prologus."
Meanwhile, “the protocanonical books of the Old Testament correspond with those of the Bible of the Hebrews, and the Old Testament as received by Protestants.”
Dead Sea scrolls.
Fragments of three deuterocanonical books have been found among the Dead Sea Scrolls found at Qumran, in addition to several partial copies of "I Enoch" and "Jubilees" from the Ethiopic deuterocanon. "Sirach", whose Hebrew text was already known from the Cairo Geniza, has been found in two scrolls (2QSir or 2Q18, 11QPs_a or 11Q5) in Hebrew. Another Hebrew scroll of "Sirach" has been found in Masada (MasSir). The "Book of Tobit" has been found in Qumran in four scrolls written in Aramaic and in one written in Hebrew. The "Letter of Jeremiah" (or "Baruch" chapter 6) has been found in cave 7 (papyrus 7Q5) in Greek. It has been theorized by recent scholars that the Qumran library (of approximately 1,100 manuscripts found in the eleven caves at Qumran) was not entirely produced at Qumran, but may have included part of the library of the Jerusalem Temple, that may have been hidden in the caves for safekeeping at the time the Temple was destroyed by Romans in 70 AD.
Influence of the Septuagint.
The large majority of Old Testament references in the New Testament are taken from the Koine Greek Septuagint (LXX) —editions of which include the deuterocanonical books, as well as apocrypha —both of which are called collectively ἀναγιγνωσκόμενα "anagignoskomena" (things that are read or "profitable reading"). No two Septuagint codices contain the same apocrypha, and the three earliest manuscripts of the LXX show uncertainty as to which books constitute the complete list of the Apocrypha. Codex Vaticanus (B) lacks 1—4 Maccabees but includes 1 Esdras, while Codex Sinaiticus (Aleph) omits Baruch, but includes 4 Maccabees.
Codex Alexandrinus includes the LXX, and Greek Psalm manuscripts from the fifth century contain three New Testament ‘psalms’: the Magnificat, the Benedictus, the Nunc Dimittis from Luke’s birth narrative, and the conclusion of the hymn that begins with the ‘Gloria in Excelsis.’ Beckwith states that manuscripts of anything like the capacity of Codex Alexandrinus were not used in the first centuries of the Christian era, and believes that the comprehensive codices of the Septuagint, which start appearing in the fourth century AD, are all of Christian origin.
Some deuterocanonical appear to have been written originally in Hebrew, but the original text has long been lost. Archaeological finds, however, discovered some Greek text from the book of Baruch among the Dead Sea scrolls. The Septuagint was widely accepted and used by Greek-speaking Jews in the 1st century, even in the region of Roman Judea, and therefore naturally became the text most widely used by early Christians, who were predominantly Greek speaking.
In the New Testament, Hebrews 11:35 is understood by some as referring to an event that was recorded in one of the deuterocanonical books, 2 Maccabees. For instance, the author of Hebrews references oral tradition which spoke of an Old Testament prophet who was sawn in half in Hebrews 11:37, two verses after the 2nd Maccabees reference. Other New Testament authors such as Paul also reference or quote period literature which was familiar to the audience but that was not included in the deuterocanonical or the protocanonical Old Testament books.
The Jewish historian Josephus speaks of there being 22 books in the canon of the Hebrew Bible, a Jewish tradition reported also by the Christian bishop Athanasius. However, included in Athanasius's list of 22 Old Testament books are Baruch and the Letter of Jeremiah. At the same time, he mentioned that certain other books, including five deuterocanonical books but also the Didache and the Shepherd of Hermas, while not being part of the New Testament canon, "were appointed by the Fathers to be read". He excluded what he called "apocryphal writings" entirely.
In the Roman Catholic Church.
In the Catholic Church, "the first infallible and effectually promulgated pronouncement on the Canon" was that defined by the Council of Trent. Among the minority, in Trent, that showed opposition to these books' inclusion were Cardinals Seripando and Cajetan, the latter an opponent of Luther at Augsburg. However, Trent confirmed the statements of earlier and less authoritative regional councils which also included the deuterocanonical books, such as the Synod of Hippo (393), and the Councils of Carthage of 397. Much later (15th century), the Council of Florence taught the divine inspiration of these books, but "did not formally pass on their canonicity."
According to Baptist minister and blogger, Bill Webster, controversy remains as to the significance of Trent's omission of the Septuagint version of 1 Esdras which Carthage may have ratified. He says that there is ambiguity over the naming of the books of Esdras since the "Canon of Hippo" lists two books of Esdras, thus this could mean 1 Esdras and Ezra-Nehemiah as in the Septuagint or Ezra and Nehemiah as in the Vulgate. However, Augustine of Hippo explains the relation between the two books of Ezra/Esdras and its separation with Chronicles (partly included in the Septuagint 1 Esdras): "...and the two of Ezra, which last look more like a sequel to the continuous regular history which terminates with the books of Kings and Chronicles." 
Philip Schaff says that "the council of Hippo in 393, and the third (according to another reckoning the sixth) council of Carthage in 397, under the influence of Augustine, who attended both, fixed the catholic canon of the Holy Scriptures, including the Apocrypha of the Old Testament, ... This decision of the transmarine church however, was subject to ratification; and the concurrence of the Roman see it received when Innocent I and Gelasius I (A.D. 414) repeated the same index of biblical books. This canon remained undisturbed till the sixteenth century, and was sanctioned by the council of Trent at its fourth session."
The Catholic deuterocanonical scriptural texts are:
Influence of the Vulgate.
Jerome in the Vulgate's prologues describes a canon which excludes the deuterocanonical books, possibly excepting Baruch. In his "Prologues", Jerome mentions all of the deuterocanonical and apocryphal works by name as being apocryphal or "not in the canon" except for "Prayer of Manasses" and "Baruch". He mentions "Baruch" by name in his "Prologue to Jeremiah" and notes that it is neither read nor held among the Hebrews, but does not explicitly call it apocryphal or "not in the canon". The inferior status to which the deuterocanonical books were relegated by authorities like Jerome is seen by some as being due to a rigid conception of canonicity, one demanding that a book, to be entitled to this supreme dignity, must be received by all, must have the sanction of Jewish antiquity, and must moreover be adapted not only to edification, but also to the "confirmation of the doctrine of the Church".
Eventually however, Jerome's Vulgate did include the deuterocanonical books as well as apocrypha. Jerome referenced and quoted from some as scripture despite describing them as "not in the canon". Michael Barber asserts that, although Jerome was once suspicious of the apocrypha, he later viewed them as Scripture. Barber argues that this is clear from Jerome's epistles; he cites Jerome's letter to Eustochium, in which Jerome quotes Sirach 13:2. Elsewhere Jerome apparently also refers to Baruch, the Story of Susannah and Wisdom as scripture.
In his prologue to Judith, without using the word canon, he mentioned that Judith was held to be scriptural by the First Council of Nicaea. In his reply to Rufinus, he affirmed that he was consistent with the choice of the church regarding which version of the deuterocanonical portions of Daniel to use, which the Jews of his day did not include:
Thus Jerome acknowledged the principle by which the canon would be settled —the judgment of the Church, rather than his own judgment or the judgment of Jews; though, concerning translation of Daniel to Greek, he wondered why one should use the version of a translator whom he regarded as heretic and judaizer (Theodotion).
The Vulgate is also important as the touchstone of the canon concerning which parts of books are canonical. When the Council of Trent listed the books included in the canon, it qualified the books as being "entire with all their parts, as they have been used to be read in the Catholic Church, and as they are contained in the old Latin vulgate edition". This decree was clarified somewhat by Pope Pius XI on June 2, 1927, who allowed that the Comma Johanneum was open to dispute, and it was further explicated by Pope Pius XII's "Divino afflante Spiritu".
In Orthodox Christianity.
Outside the Roman Catholic Church, the term deuterocanonical is sometimes used, by way of analogy, to describe books that Eastern Orthodoxy, and Oriental Orthodoxy included in the Old Testament that are not part of the Jewish Tanakh, nor the Protestant Old Testament. Among Orthodox, the term is understood to mean that they were compiled separately from the primary canon, as explained in 2 Esdras, where Esdras is instructed to keep certain books separate and hidden.
Eastern Orthodoxy.
The Eastern Orthodox Churches have traditionally included all the books of the Septuagint in their Old Testaments. The Greeks use the word "Anagignoskomena" (Ἀναγιγνωσκόμενα "readable, worthy to be read") to describe the books of the Greek Septuagint that are not present in the Hebrew Tanakh. When Orthodox theologians use the term "deuterocanonical," it is important to note that the meaning is not identical to the Roman Catholic usage. In Orthodox Christianity, deuterocanonical means that a book is part of the corpus of the Old Testament (i.e. is read during the services) but has secondary authority. In other words, deutero (second) applies to authority or witnessing power, whereas in Roman Catholicism, deutero applies to chronology (the fact that these books were confirmed later), not to authority.
The Eastern Orthodox books of the Old Testament include the deuterocanonical books listed above, plus 3 Maccabees and 1 Esdras (also included in the Clementine Vulgate), while Baruch is divided from the Epistle of Jeremiah, making a total of 49 Old Testament books in contrast with the Protestant 39-book canon.
Like the Roman Catholic deuterocanonical books, these texts are integrated with the rest of the Old Testament, not printed in a separate section.
Other texts printed in Orthodox Bibles are considered of some value (like the additional Psalm 151, and the Prayer of Manasseh) or are included as an appendix (like the Greek 4 Maccabees, and the Slavonic 2 Esdras).
Ethiopian Orthodoxy.
In the Amharic Bible used by the Ethiopian Orthodox Church (an Oriental Orthodox Church), those books of the Old Testament that are still counted as canonical, but not by all other Churches, are often set in a separate section titled ""Deeyutrokanoneekal"" (ዲዩትሮካኖኒካል), which is the same word. The Ethiopian Orthodox Deuterocanon, in addition to the standard set listed above, along with the books of Esdras and "Prayer of Minasse", also includes some books that are still held canonical by only the Ethiopian Church, including Enoch or "Henok" (I Enoch), "Kufale" (Jubilees) and 1, 2 and 3 Meqabyan (which are sometimes wrongly confused with the "Books of Maccabees").
In the Anglican Communion.
There is a great deal of overlap between the Apocrypha section of the original 1611 King James Bible and the Catholic deuterocanon, but the two are distinct. The Apocrypha section of the original 1611 King James Bible includes, in addition to the deuterocanonical books, the following three books, which were not included in the list of the canonical books by the Council of Trent:
These books make up the Apocrypha section of the Clementine Vulgate: 3 Esdras (1 Esdras); 4 Esdras (2 Esdras); and The Prayer of Manasseh, where they are specifically described as "outside of the series of the canon". The 1609 Douai Bible includes them in an appendix, but they have been dropped from recent Catholic translations into English. They are found, along with the deuterocanonical books, in the Apocrypha section of Protestant bibles.
Using the word apocrypha (Greek: hidden away) to describe texts, although not necessarily pejorative, implies to some people that the writings in question should not be included in the canon of the Bible. This classification commingles them with certain non-canonical gospels and New Testament Apocrypha. The "Style Manual for the Society of Biblical Literature" recommends the use of the term "deuterocanonical literature" instead of "Apocrypha" in academic writing.
The Thirty-Nine Articles of Religion of the Church of England, a historical artifact with little bearing on the spirituality, polity, or governance of Churches in the Anglican Communion today, including the Church of England, lists the deuterocanonical books as suitable to be read for "example of life and instruction of manners, but yet doth not apply them to establish any doctrine." The early lectionaries of the Anglican Church (as included in the Book of Common Prayer of 1662) included the deuterocanonical books amongst the cycle of readings, and passages from them were used regularly in services (such as the Kyrie Pantokrator and the Benedicite).
Readings from the deuterocanonical books are now included in most, if not all, of the modern lectionaries in the Anglican Communion, based on the Revised Common Lectionary (in turn based on the post-conciliar Roman Catholic lectionary), though alternative readings from protocanonical books are also provided.
The Jewish position.
Judaism and most Protestant versions of the Bible exclude these books. It is commonly said that Judaism officially excluded the deuterocanonicals and the additional Greek texts listed here from their Scripture in the Council of Jamnia (c. 70–90 AD), but this claim is also disputed.
In Christian churches having their origins in the Protestant Reformation.
Presbyterianism.
The Westminster Confession of Faith, a Calvinist document that serves as a systematic summary of doctrine for the Church of Scotland and Presbyterian churches worldwide, recognizes only the sixty-six books of the Protestant canon as authentic Scripture. Chapter 1, Article 3 of the Confession reads: "The books commonly called Apocrypha, not being of divine inspiration, are no part of the Canon of Scripture; and therefore are of no authority in the Church of God, nor to be any otherwise approved, or made use of, than other human writings."
Reformed churches.
The Belgic Confession, used in Reformed churches, devotes a section (Article 6) to "The difference between the canonical and apocryphal books" and asserts that "All which the Church may read and take instruction from, so far as they agree with the canonical books; but they are far from having such power and efficacy as that we may from their testimony confirm any point of faith or of the Christian religion; much less to detract from the authority of the other sacred books."
New Testament deuterocanonicals.
The term "deuterocanonical" is sometimes used to describe the canonical antilegomena, those books of the New Testament which, like the deuterocanonicals of the Old Testament, were not universally accepted by the early Church. These books may be called the "New Testament deuterocanonicals", which are now included in the 27 books of the New Testament recognized by almost all Christians. The deuterocanonicals of the New Testament are as follows:

</doc>
<doc id="8490" url="https://en.wikipedia.org/wiki?curid=8490" title="Discus throw">
Discus throw

The discus throw () is a track and field event in which an athlete throws a heavy disc—called a discus—in an attempt to mark a farther distance than his or her competitors. It is an ancient sport, as demonstrated by the fifth-century-B.C. Myron statue, "Discobolus". Although not part of the modern pentathlon, it was one of the events of the ancient Greek pentathlon, which can be dated back to at least to 708 BC.
History.
Discus is a routine part of most modern track-and-field meets at all levels and is a sport which is particularly iconic of the Olympic Games. The men's competition has been a part of the modern Summer Olympic Games since the first Olympiad in 1896. Images of discus throwers figured prominently in advertising for early modern Games, such as fundraising stamps for the 1896 games and the main posters for the 1920 and 1948 Summer Olympics.
The discus was re-discovered in Magdeburg, Germany, by Christian Georg Kohlrausch and his students in the 1870s. His work around the discus and the earlier throwing techniques have been published since the 1880.
The first modern athlete to throw the discus while rotating the whole body was František Janda-Suk from Bohemia (present Czech Republic). He invented this technique when studying the position of the famous statue of Discobolus. After only one year of developing the technique he gained the olympic silver in 1900.
The women's competition was added to the Olympic program in the 1928 games, although they had been competing at some national and regional levels previously.
Description.
The discus, the object to be thrown, is a heavy lenticular disc with a weight of and diameter of for the men's event, and a weight of and diameter of for the women's program.
Under IAAF (international) rules, Youth boys (16–17 years) throw the discus, the Junior men (18–19 years) throw the unique discus, and the girls/women of those ages throw the 1 kg discus.
In international competition, men throw the 2 kg discus through to age 49. The discus is thrown by ages 50–59, and men age 60 and beyond throw the discus. Women throw the discus through to age 74. Starting with age 75, women throw the discus.
The typical discus has sides made of plastic, wood, fiberglass, carbon fiber or metal with a metal rim and a metal core to attain the weight. The rim must be smooth, with no roughness or finger holds. A discus with more weight in the rim produces greater angular momentum for any given spin rate, and thus more stability, although it is more difficult to throw. However, a higher rim weight, if thrown correctly, can lead to a farther throw. A solid rubber discus is sometimes used (see in the United States).
To make a throw, the competitor starts in a circle of diameter, which is recessed in a concrete pad by 20 mm. The thrower typically takes an initial stance facing away from the direction of the throw. He then spins anticlockwise (for right-handers) around one and a half times through the circle to build momentum, then releases his/her throw. The discus must land within a 34.92-degree sector. The rules of competition for discus are virtually identical to those of shot put, except that the circle is larger, a stop board is not used and there are no form rules concerning how the discus is to be thrown.
The distance from the front edge of the circle to where the discus has landed is measured, and distances are rounded down to the nearest centimetre. The competitor's best throw from the allocated number of throws, typically three to six, is recorded, and the competitor who legally throws the discus the farthest is declared the winner. Ties are broken by determining which thrower has the longer second-best throw.
The basic motion is a forehanded sidearm movement. The discus is spun off the index finger or the middle finger of the throwing hand. In flight the disc spins clockwise when viewed from above for a right-handed thrower, and anticlockwise for a left-handed thrower. As well as achieving maximum momentum in the discus on throwing, the discus' distance is also determined by the trajectory the thrower imparts, as well as the aerodynamic behavior of the discus. Generally, throws into a moderate headwind achieve the maximum distance. Also, a faster-spinning discus imparts greater gyroscopic stability. The technique of discus throwing is quite difficult to master and needs lots of experience to get right, thus most top throwers are 30 years old or more.
Phases.
The discus technique can be broken down into phases. The purpose is to transfer from the back to the front of the throwing circle while turning through one and half circles. The speed of delivery is high, and speed is built up during the throw (slow to fast). Correct technique involves the build up of torque so that maximum force can be applied to the discus on delivery.
During the wind up, keep weight is evenly distributed between the feet, which are about shoulder distance and not overly active. The wind up sets the tone for the entire throw, the rhythm of the throw is very important.
Focusing on rhythm can bring about the consistency to get in the right positions that many throwers lack. Executing a sound discus throw with solid technique requires perfect balance. This is due to the throw being a linear movement combined with a one and a half rotation and an implement at the end of one arm. Thus, a good discus thrower needs to maintain balance within the circle.
For a right handed thrower, the next stage is to move the weight over the left foot. From this position the right foot is raised, and the athlete 'runs' across the circle. There are various techniques for this stage where the leg swings out to a small or great extent, some athletes turn on their left heel (e.g. Ilke Wylluda) but turning on the ball of the foot is far more common. 
The aim is to land in the 'power position', the right foot should be in the center and the heel should not touch the ground at any point. The left foot should land very quickly after the right. Weight should be mostly over the back foot with as much torque as possible in the body - so the right arm is high and far back - this is very hard to achieve.
power position
The critical stage is the delivery of the discus, from this 'power position' the hips drive through hard, and will be facing the direction of the throw on delivery. Athletes employ various techniques to control the end-point and recover from the throw, such as fixing feet (to pretty much stop dead), or an active reverse spinning onto the left foot (e.g. Virgilijus Alekna).
Sports scientist Richard Ganslen researched the "Aerodynamics of the Discus", reporting the discus will stall at an angle of 29°.
Culture.
The discus throw is the subject of a number of well-known ancient Greek statues and Roman copies such as the Discobolus and Discophoros. The discus throw also appears repeatedly in ancient Greek mythology, featured as a means of manslaughter in the cases of Hyacinth, Crocus, Phocus, and Acrisius, and as a named event in the funeral games of Patroclus.
Discus throwers have been selected as a main motif in numerous collectors' coins. One of the recent samples is the €10 Greek Discus commemorative coin, minted in 2003 to commemorate the 2004 Summer Olympics. On the obverse of the coin a modern athlete is seen in the foreground in a half-turned position, while in the background an ancient discus thrower has been captured in a lively bending motion, with the discus high above his head, creating a vivid representation of the sport.
United States.
In U.S. high school track and field, boys typically throw a discus weighing 1.6 kg (3 lb 9 oz) and the girls throw the 1 kg (2.2 lb) women's discus. Under USATF Youth rules, boys throw the 1 kg discus between the ages of 11-14, and transition to the 1.6 kg discus as 15- to 18-year-olds. Girls throw the 1 kg discus as 11- to 18-year-olds.
Under US high school rules, if a discus hits the surrounding safety cage and is deflected into the sector, it is ruled a foul. In contrast, under IAAF, WMA, NCAA and USATF rules, it is ruled a legal throw. Additionally, under US high school rules, distances thrown are rounded down to the nearest whole inch, rather than the nearest centimetre.
US high school rules allow the use of a solid rubber discus; it is cheaper and easier to learn to throw (due to its more equal distribution of weight, as opposed to the heavy rim weight of the metal rim/core discus), but less durable.
Top 25 performers.
"Accurate as of June 2015".
Season's bests.
As of June 21, 2015

</doc>
<doc id="8492" url="https://en.wikipedia.org/wiki?curid=8492" title="Discrete mathematics">
Discrete mathematics

Discrete mathematics is the study of mathematical structures that are fundamentally discrete rather than continuous. In contrast to real numbers that have the property of varying "smoothly", the objects studied in discrete mathematics – such as integers, graphs, and statements in logic – do not vary smoothly in this way, but have distinct, separated values. Discrete mathematics therefore excludes topics in "continuous mathematics" such as calculus and analysis. Discrete objects can often be enumerated by integers. More formally, discrete mathematics has been characterized as the branch of mathematics dealing with countable sets (sets that have the same cardinality as subsets of the natural numbers, including rational numbers but not real numbers). However, there is no exact definition of the term "discrete mathematics." Indeed, discrete mathematics is described less by what is included than by what is excluded: continuously varying quantities and related notions.
The set of objects studied in discrete mathematics can be finite or infinite. The term finite mathematics is sometimes applied to parts of the field of discrete mathematics that deals with finite sets, particularly those areas relevant to business.
Research in discrete mathematics increased in the latter half of the twentieth century partly due to the development of digital computers which operate in discrete steps and store data in discrete bits. Concepts and notations from discrete mathematics are useful in studying and describing objects and problems in branches of computer science, such as computer algorithms, programming languages, cryptography, automated theorem proving, and software development. Conversely, computer implementations are significant in applying ideas from discrete mathematics to real-world problems, such as in operations research.
Although the main objects of study in discrete mathematics are discrete objects, analytic methods from continuous mathematics are often employed as well.
In university curricula, "Discrete Mathematics" appeared in the 1980s, initially as a computer science support course; its contents were somewhat haphazard at the time. The curriculum has thereafter developed in conjunction with efforts by ACM and MAA into a course that is basically intended to develop mathematical maturity in freshmen; as such it is nowadays a prerequisite for mathematics majors in some universities as well. Some high-school-level discrete mathematics textbooks have appeared as well. At this level, discrete mathematics is sometimes seen as a preparatory course, not unlike precalculus in this respect.
The Fulkerson Prize is awarded for outstanding papers in discrete mathematics.
Grand challenges, past and present.
The history of discrete mathematics has involved a number of challenging problems which have focused attention within areas of the field. In graph theory, much research was motivated by attempts to prove the four color theorem, first stated in 1852, but not proved until 1976 (by Kenneth Appel and Wolfgang Haken, using substantial computer assistance).
In logic, the second problem on David Hilbert's list of open problems presented in 1900 was to prove that the axioms of arithmetic are consistent. Gödel's second incompleteness theorem, proved in 1931, showed that this was not possible – at least not within arithmetic itself. Hilbert's tenth problem was to determine whether a given polynomial Diophantine equation with integer coefficients has an integer solution. In 1970, Yuri Matiyasevich proved that this could not be done.
The need to break German codes in World War II led to advances in cryptography and theoretical computer science, with the first programmable digital electronic computer being developed at England's Bletchley Park with the guidance of Alan Turing and his seminal work, On Computable Numbers. At the same time, military requirements motivated advances in operations research. The Cold War meant that cryptography remained important, with fundamental advances such as public-key cryptography being developed in the following decades. Operations research remained important as a tool in business and project management, with the critical path method being developed in the 1950s. The telecommunication industry has also motivated advances in discrete mathematics, particularly in graph theory and information theory. Formal verification of statements in logic has been necessary for software development of safety-critical systems, and advances in automated theorem proving have been driven by this need.
Computational geometry has been an important part of the computer graphics incorporated into modern video games and computer-aided design tools.
Several fields of discrete mathematics, particularly theoretical computer science, graph theory, and combinatorics, are important in addressing the challenging bioinformatics problems associated with understanding the tree of life.
Currently, one of the most famous open problems in theoretical computer science is the P = NP problem, which involves the relationship between the complexity classes P and NP. The Clay Mathematics Institute has offered a $1 million USD prize for the first correct proof, along with prizes for six other mathematical problems.
Topics in discrete mathematics.
Theoretical computer science.
Theoretical computer science includes areas of discrete mathematics relevant to computing. It draws heavily on graph theory and mathematical logic. Included within theoretical computer science is the study of algorithms for computing mathematical results. Computability studies what can be computed in principle, and has close ties to logic, while complexity studies the time taken by computations. Automata theory and formal language theory are closely related to computability. Petri nets and process algebras are used to model computer systems, and methods from discrete mathematics are used in analyzing VLSI electronic circuits. Computational geometry applies algorithms to geometrical problems, while computer image analysis applies them to representations of images. Theoretical computer science also includes the study of various continuous computational topics.
Information theory.
Information theory involves the quantification of information. Closely related is coding theory which is used to design efficient and reliable data transmission and storage methods. Information theory also includes continuous topics such as: analog signals, analog coding, analog encryption.
Logic.
Logic is the study of the principles of valid reasoning and inference, as well as of consistency, soundness, and completeness. For example, in most systems of logic (but not in intuitionistic logic) Peirce's law ((("P"→"Q")→"P")→"P") is a theorem. For classical logic, it can be easily verified with a truth table. The study of mathematical proof is particularly important in logic, and has applications to automated theorem proving and formal verification of software.
Logical formulas are discrete structures, as are proofs, which form finite trees or, more generally, directed acyclic graph structures (with each inference step combining one or more premise branches to give a single conclusion). The truth values of logical formulas usually form a finite set, generally restricted to two values: "true" and "false", but logic can also be continuous-valued, e.g., fuzzy logic. Concepts such as infinite proof trees or infinite derivation trees have also been studied, e.g. infinitary logic.
Set theory.
Set theory is the branch of mathematics that studies sets, which are collections of objects, such as {blue, white, red} or the (infinite) set of all prime numbers. Partially ordered sets and sets with other relations have applications in several areas.
In discrete mathematics, countable sets (including finite sets) are the main focus. The beginning of set theory as a branch of mathematics is usually marked by Georg Cantor's work distinguishing between different kinds of infinite set, motivated by the study of trigonometric series, and further development of the theory of infinite sets is outside the scope of discrete mathematics. Indeed, contemporary work in descriptive set theory makes extensive use of traditional continuous mathematics.
Combinatorics.
Combinatorics studies the way in which discrete structures can be combined or arranged.
Enumerative combinatorics concentrates on counting the number of certain combinatorial objects - e.g. the twelvefold way provides a unified framework for counting permutations, combinations and partitions.
Analytic combinatorics concerns the enumeration (i.e., determining the number) of combinatorial structures using tools from complex analysis and probability theory. In contrast with enumerative combinatorics which uses explicit combinatorial formulae and generating functions to describe the results, analytic combinatorics aims at obtaining asymptotic formulae.
Design theory is a study of combinatorial designs, which are collections of subsets with certain intersection properties.
Partition theory studies various enumeration and asymptotic problems related to integer partitions, and is closely related to q-series, special functions and orthogonal polynomials. Originally a part of number theory and analysis, partition theory is now considered a part of combinatorics or an independent field.
Order theory is the study of partially ordered sets, both finite and infinite.
Graph theory.
Graph theory, the study of graphs and networks, is often considered part of combinatorics, but has grown large enough and distinct enough, with its own kind of problems, to be regarded as a subject in its own right. Graphs are one of the prime objects of study in discrete mathematics. They are among the most ubiquitous models of both natural and human-made structures. They can model many types of relations and process dynamics in physical, biological and social systems. In computer science, they can represent networks of communication, data organization, computational devices, the flow of computation, etc. In mathematics, they are useful in geometry and certain parts of topology, e.g. knot theory. Algebraic graph theory has close links with group theory. There are also continuous graphs, however for the most part research in graph theory falls within the domain of discrete mathematics.
Probability.
Discrete probability theory deals with events that occur in countable sample spaces. For example, count observations such as the numbers of birds in flocks comprise only natural number values {0, 1, 2, ...}. On the other hand, continuous observations such as the weights of birds comprise real number values and would typically be modeled by a continuous probability distribution such as the normal. Discrete probability distributions can be used to approximate continuous ones and vice versa. For highly constrained situations such as throwing dice or experiments with decks of cards, calculating the probability of events is basically enumerative combinatorics.
Number theory.
Number theory is concerned with the properties of numbers in general, particularly integers. It has applications to cryptography, cryptanalysis, and cryptology, particularly with regard to modular arithmetic, diophantine equations, linear and quadratic congruences, prime numbers and primality testing. Other discrete aspects of number theory include geometry of numbers. In analytic number theory, techniques from continuous mathematics are also used. Topics that go beyond discrete objects include transcendental numbers, diophantine approximation, p-adic analysis and function fields.
Algebra.
Algebraic structures occur as both discrete examples and continuous examples. Discrete algebras include: boolean algebra used in logic gates and programming; relational algebra used in databases; discrete and finite versions of groups, rings and fields are important in algebraic coding theory; discrete semigroups and monoids appear in the theory of formal languages.
Calculus of finite differences, discrete calculus or discrete analysis.
A function defined on an interval of the integers is usually called a sequence. A sequence could be a finite sequence from a data source or an infinite sequence from a discrete dynamical system. Such a discrete function could be defined explicitly by a list (if its domain is finite), or by a formula for its general term, or it could be given implicitly by a recurrence relation or difference equation. Difference equations are similar to a differential equations, but replace differentiation by taking the difference between adjacent terms; they can be used to approximate differential equations or (more often) studied in their own right. Many questions and methods concerning differential equations have counterparts for difference equations. For instance where there are integral transforms in harmonic analysis for studying continuous functions or analog signals, there are discrete transforms for discrete functions or digital signals. As well as the discrete metric there are more general discrete or finite metric spaces and finite topological spaces.
Geometry.
Discrete geometry and combinatorial geometry are about combinatorial properties of "discrete collections" of geometrical objects. A long-standing topic in discrete geometry is tiling of the plane. Computational geometry applies algorithms to geometrical problems.
Topology.
Although topology is the field of mathematics that formalizes and generalizes the intuitive notion of "continuous deformation" of objects, it gives rise to many discrete topics; this can be attributed in part to the focus on topological invariants, which themselves usually take discrete values.
See combinatorial topology, topological graph theory, topological combinatorics, computational topology, discrete topological space, finite topological space, topology (chemistry).
Operations research.
Operations research provides techniques for solving practical problems in business and other fields — problems such as allocating resources to maximize profit, or scheduling project activities to minimize risk. Operations research techniques include linear programming and other areas of optimization, queuing theory, scheduling theory, network theory. Operations research also includes continuous topics such as continuous-time Markov process, continuous-time martingales, process optimization, and continuous and hybrid control theory.
Game theory, decision theory, utility theory, social choice theory.
Decision theory is concerned with identifying the values, uncertainties and other issues relevant in a given decision, its rationality, and the resulting optimal decision.
Utility theory is about measures of the relative economic satisfaction from, or desirability of, consumption of various goods and services.
Social choice theory is about voting. A more puzzle-based approach to voting is ballot theory.
Game theory deals with situations where success depends on the choices of others, which makes choosing the best course of action more complex. There are even continuous games, see differential game. Topics include auction theory and fair division.
Discretization.
Discretization concerns the process of transferring continuous models and equations into discrete counterparts, often for the purposes of making calculations easier by using approximations. Numerical analysis provides an important example.
Discrete analogues of continuous mathematics.
There are many concepts in continuous mathematics which have discrete versions, such as discrete calculus, discrete probability distributions, discrete Fourier transforms, discrete geometry, discrete logarithms, discrete differential geometry, discrete exterior calculus, discrete Morse theory, difference equations, discrete dynamical systems, and discrete vector measures.
In applied mathematics, discrete modelling is the discrete analogue of continuous modelling. In discrete modelling, discrete formulae are fit to data. A common method in this form of modelling is to use recurrence relation.
In algebraic geometry, the concept of a curve can be extended to discrete geometries by taking the spectra of polynomial rings over finite fields to be models of the affine spaces over that field, and letting subvarieties or spectra of other rings provide the curves that lie in that space. Although the space in which the curves appear has a finite number of points, the curves are not so much sets of points as analogues of curves in continuous settings. For example, every point of the form formula_1 for formula_2 a field can be studied either as formula_3, a point, or as the spectrum formula_4 of the local ring at (x-c), a point together with a neighborhood around it. Algebraic varieties also have a well-defined notion of tangent space called the Zariski tangent space, making many features of calculus applicable even in finite settings.
Hybrid discrete and continuous mathematics.
The time scale calculus is a unification of the theory of difference equations with that of differential equations, which has applications to fields requiring simultaneous modelling of discrete and continuous data. Another way of modeling such a situation is the notion of hybrid dynamical system.

</doc>
<doc id="8494" url="https://en.wikipedia.org/wiki?curid=8494" title="DDT">
DDT

DDT (dichlorodiphenyltrichloroethane) is a colorless, crystalline, tasteless and almost odorless organochloride known for its insecticidal properties and environmental impacts. DDT has been formulated in multiple forms, including solutions in xylene or petroleum distillates, emulsifiable concentrates, water-wettable powders, granules, aerosols, smoke candles and charges for vaporizers and lotions.
First synthesized in 1874, DDT's insecticidal action was discovered by the Swiss chemist Paul Hermann Müller in 1939. It was used in the second half of World War II to control malaria and typhus among civilians and troops. After the war, DDT was also used as an agricultural insecticide and its production and use duly increased. Müller was awarded the Nobel Prize in Physiology or Medicine "for his discovery of the high efficiency of DDT as a contact poison against several arthropods" in 1948.
In 1962, Rachel Carson published the book "Silent Spring". It cataloged the environmental impacts of widespread DDT spraying in the United States and questioned the logic of releasing large amounts of potentially dangerous chemicals into the environment without understanding their effects on the environment or human health. The book claimed that DDT and other pesticides had been shown to cause cancer and that their agricultural use was a threat to wildlife, particularly birds. Its publication was a seminal event for the environmental movement and resulted in a large public outcry that eventually led, in 1972, to a ban on its agricultural use in the United States. A worldwide ban on agricultural use was formalized under the Stockholm Convention on Persistent Organic Pollutants, but its limited and still-controversial use in disease vector control continues, because of its effectiveness in reducing malarial infections, balanced by environmental and other health concerns.
Along with the passage of the Endangered Species Act, the United States ban on DDT is cited by scientists as a major factor in the comeback of the bald eagle (the national bird of the United States) and the peregrine falcon from near-extinction in the contiguous United States.
Properties and chemistry.
DDT is similar in structure to the insecticide methoxychlor and the acaricide dicofol. It is highly hydrophobic and nearly insoluble in water but has good solubility in most organic solvents, fats and oils. DDT does not occur naturally. It is produced by the reaction of chloral () with chlorobenzene () in the presence of a sulfuric acid catalyst. DDT has been marketed under trade names including Anofex, Cezarex, Chlorophenothane, Clofenotane, Dicophane, Dinocide, Gesarol, Guesapon, Guesarol, Gyron, Ixodex, Neocid, Neocidol and Zerdane.
Isomers and related compounds.
Commercial DDT is a mixture of several closely–related compounds. The major component (77%) is the "p","p' " isomer (pictured above). The "o","p' " isomer (pictured to the right) is also present in significant amounts (15%). Dichlorodiphenyldichloroethylene (DDE) and dichlorodiphenyldichloroethane (DDD) make up the balance. DDE and DDD are the major metabolites and environmental breakdown products. The term "total DDT" is often used to refer to the sum of all DDT related compounds ("p,p'-"DDT, "o,p'-"DDT, DDE, and DDD) in a sample.
Production and use.
From 1950 to 1980, DDT was extensively used in agriculture — more than 40,000 tonnes each year worldwide — and it has been estimated that a total of 1.8 million tonnes have been produced globally since the 1940s. In the United States, it was manufactured by some 15 companies, including Monsanto, Ciba, Montrose Chemical Company, Pennwalt and Velsicol Chemical Corporation. Production peaked in 1963 at 82,000 tonnes per year. More than 600,000 tonnes (1.35 billion pounds) were applied in the US before the 1972 ban. Usage peaked in 1959 at about 36,000 tonnes.
In 2009, 3,314 tonnes were produced for malaria control and visceral leishmaniasis. India is the only country still manufacturing DDT and is the largest consumer. China ceased production in 2007.
Mechanism of insecticide action.
In insects it opens sodium ion channels in neurons, causing them to fire spontaneously, which leads to spasms and eventual death. Insects with certain mutations in their sodium channel gene are resistant to DDT and similar insecticides. DDT resistance is also conferred by up-regulation of genes expressing cytochrome P450 in some insect species, as greater quantities of some enzymes of this group accelerate the toxin's metabolism into inactive metabolites.
History.
DDT was first synthesized in 1874 by Othmar Zeidler under the supervision of Adolf von Baeyer. It was further described in 1929 in a dissertation by W. Bausch and in two subsequent publications in 1930. The insecticide properties of "multiple chlorinated aliphatic or fat-aromatic alcohols with at least one trichloromethane group" were described in a patent in 1934 by Wolfgang von Leuthold. DDT's insecticidal properties were not, however, discovered until 1939 by the Swiss scientist Paul Hermann Müller, who was awarded the 1948 Nobel Prize in Physiology and Medicine for his efforts.
Use in the 1940s and 1950s.
DDT is the best-known of several chlorine-containing pesticides used in the 1940s and 1950s. With pyrethrum in short supply, DDT was used extensively during World War II by the Allies to control the insect vectors of typhus – nearly eliminating the disease in many parts of Europe. In the South Pacific, it was sprayed aerially for malaria and dengue fever control with spectacular effects. While DDT's chemical and insecticidal properties were important factors in these victories, advances in application equipment coupled with competent organization and sufficient manpower were also crucial to the success of these programs.
In 1945, DDT was made available to farmers as an agricultural insecticide and played a role in the final elimination of malaria in Europe and North America.
In 1955, the World Health Organization commenced a program to eradicate malaria in countries with low to moderate transmission rates worldwide, relying largely on DDT for mosquito control and rapid diagnosis and treatment to reduce transmission. The program eliminated the disease in "Taiwan, much of the Caribbean, the Balkans, parts of northern Africa, the northern region of Australia, and a large swath of the South Pacific" and dramatically reduced mortality in Sri Lanka and India.
However, failure to sustain the program, increasing mosquito tolerance to DDT, and increasing parasite tolerance led to a resurgence. In many areas early successes partially or completely reversed, and in some cases rates of transmission increased. The program succeeded in eliminating malaria only in areas with "high socio-economic status, well-organized healthcare systems, and relatively less intensive or seasonal malaria transmission".
DDT was less effective in tropical regions due to the continuous life cycle of mosquitoes and poor infrastructure. It was not applied at all in sub-Saharan Africa due to these perceived difficulties. Mortality rates in that area never declined to the same dramatic extent, and now constitute the bulk of malarial deaths worldwide, especially following the disease's resurgence as a result of resistance to drug treatments and the spread of the deadly malarial variant caused by "Plasmodium falciparum".
Eradication was abandoned in 1969 and attention instead focused on controlling and treating the disease. Spraying programs (especially using DDT) were curtailed due to concerns over safety and environmental effects, as well as problems in administrative, managerial and financial implementation. Efforts shifted from spraying to the use of bednets impregnated with insecticides and other interventions.
United States ban.
As early as the 1940s, US scientists began expressing concern over possible hazards associated with DDT, and in the 1950s the government began tightening regulations governing its use. These events received little attention. In 1957 the "New York Times" reported an unsuccessful struggle to restrict DDT use in Nassau County, New York, that the issue came to the attention of the popular naturalist-author, Rachel Carson. William Shawn, editor of "The New Yorker", urged her to write a piece on the subject, which developed into her 1962 book "Silent Spring". The book argued that pesticides, including DDT, were poisoning both wildlife and the environment and were endangering human health. "Silent Spring" was a best seller, and public reaction to it launched the modern environmental movement in the United States. The year after it appeared, President John F. Kennedy ordered his Science Advisory Committee to investigate Carson's claims. The committee's report "add up to a fairly thorough-going vindication of Rachel Carson’s Silent Spring thesis," in the words of the journal "Science", and recommended a phaseout of "persistent toxic pesticides". DDT became a prime target of the growing anti-chemical and anti-pesticide movements, and in 1967 a group of scientists and lawyers founded the Environmental Defense Fund (EDF) with the specific goal of enacting a ban on DDT. Victor Yannacone, Charles Wurster, Art Cooley and others in the group had all witnessed bird kills or declines in bird populations and suspected that DDT was the cause. In their campaign against the chemical, EDF petitioned the government for a ban and filed lawsuits. Around this time, toxicologist David Peakall was measuring DDE levels in the eggs of peregrine falcons and California condors and finding that increased levels corresponded with thinner shells.
In response to an EDF suit, the U.S. District Court of Appeals in 1971 ordered the EPA to begin the de-registration procedure for DDT. After an initial six-month review process, William Ruckelshaus, the Agency's first Administrator rejected an immediate suspension of DDT's registration, citing studies from the EPA's internal staff stating that DDT was not an imminent danger. However, these findings were criticized, as they were performed mostly by economic entomologists inherited from the United States Department of Agriculture, who many environmentalists felt were biased towards agribusiness and understated concerns about human health and wildlife. The decision thus created controversy.
The EPA held seven months of hearings in 1971–1972, with scientists giving evidence for and against DDT. In the summer of 1972, Ruckelshaus announced the cancellation of most uses of DDT – exempting public health uses under some conditions. Immediately after the announcement, both EDF and the DDT manufacturers filed suit against EPA. Industry sought to overturn the ban, while EDF wanted a comprehensive ban. The cases were consolidated, and in 1973 the United States Court of Appeals for the District of Columbia Circuit ruled that the EPA had acted properly in banning DDT.
In the same time frame, EPA drafted the Marine Protection, Research and Sanctuaries Act (MPRSA) of 1973, also known as the "Ocean Dumping Act." These regulations banned ocean dumping, except as permitted by EPA under Section 102 of the MPRSA. Seven permits issued by the EPA in 1973 for the period of May 1 to November 1 allowed for the disposal of 84,500 tons of uncontained waste at Site A and 208,500 waste barrels at Site B, of which 55,000 barrels contained chlorinated hydrocarbons. The chlorinated hydrocarbons are suspected to include surplus DDT after it was banned by the EPA five months prior on December 31, 1972. More information on this topic and references can be found at: Marine Protection, Research, and Sanctuaries Act of 1972#Title I - Permit Program.
Some uses of DDT continued under the public health exemption. For example, in June 1979, the California Department of Health Services was permitted to use DDT to suppress flea vectors of bubonic plague. DDT continued to be produced in the United States for foreign markets until 1985, when over 300 tons were exported.
Restrictions on usage.
In the 1970s and 1980s, agricultural use was banned in most developed countries, beginning with Hungary in 1968 followed by Norway and Sweden in 1970, Germany and the US in 1972, but not in the United Kingdom until 1984. By 1991 total bans, including for disease control, were in place in at least 26 countries; for example Cuba in 1970, Singapore in 1984, Chile in 1985 and the Republic of Korea in 1986.
The Stockholm Convention on Persistent Organic Pollutants, which took effect in 2004, outlawed several persistent organic pollutants, and restricted DDT use to vector control. The Convention was ratified by more than 170 countries. Recognizing that total elimination in many malaria-prone countries is currently unfeasible absent affordable/effective alternatives. The convention exempts public health use within World Health Organization (WHO) guidelines from the ban. Resolution 60.18 of the World Health Assembly commits WHO to the Stockholm Convention's aim of reducing and ultimately eliminating DDT. Malaria Foundation International states, "The outcome of the treaty is arguably better than the status quo going into the negotiations. For the first time, there is now an insecticide which is restricted to vector control only, meaning that the selection of resistant mosquitoes will be slower than before."
Despite the worldwide ban, agricultural use continued in India, North Korea, and possibly elsewhere as of 2008. For comparison, treating of cotton during a typical U.S. growing season requires the same amount of chemical as roughly 1,700 homes.
Environmental impact.
DDT is a persistent organic pollutant that is readily adsorbed to soils and sediments, which can act both as sinks and as long-term sources of exposure affecting organisms. Depending on conditions, its soil half life can range from 22 days to 30 years. Routes of loss and degradation include runoff, volatilization, photolysis and aerobic and anaerobic biodegradation. Due to hydrophobic properties, in aquatic ecosystems DDT and its metabolites are absorbed by aquatic organisms and adsorbed on suspended particles, leaving little DDT dissolved in the water. Its breakdown products and metabolites, DDE and DDD, are also persistent and have similar chemical and physical properties. DDT and its breakdown products are transported from warmer areas to the Arctic by the phenomenon of global distillation, where they then accumulate in the region's food web.
Because of its lipophilic properties, DDT can bioaccumulate, especially in predatory birds. DDT, DDE and DDD magnify through the food chain, with apex predators such as raptor birds concentrating more chemicals than other animals in the same environment. They are stored mainly in body fat. DDT and DDE are resistant to metabolism; in humans, their half-lives are 6 and up to 10 years, respectively. In the United States, these chemicals were detected in almost all human blood samples tested by the Centers for Disease Control in 2005, though their levels have sharply declined since most uses were banned. Estimated dietary intake has declined, although FDA food tests commonly detect it.
Marine macroalgae (seaweed) help reduce soil toxicity by up to 80% within six weeks.
Effects on wildlife and eggshell thinning.
DDT is toxic to a wide range of living organisms, including marine animals such as crayfish, daphnids, sea shrimp and many species of fish. DDE caused eggshell thinning and population declines in multiple North American and European bird of prey species. Eggshell thinning lowers the reproductive success rate of certain bird species by causing egg breakage and embryo deaths. DDE-related eggshell thinning is considered a major reason for the decline of the bald eagle, brown pelican, peregrine falcon and osprey. However, birds vary in their sensitivity to these chemicals. Birds of prey, waterfowl and song birds are more susceptible than chickens and related species. DDE appears to be more potent than DDT. Even in 2010, California condors that feed on sea lions at Big Sur that in turn feed in the Palos Verdes Shelf area of the Montrose Chemical Superfund site exhibited continued thin-shell problems. Scientists with the Ventana Wildlife Society and others study and remediate the condors' problems.
The biological thinning mechanism is not entirely understood, but strong evidence indictates that p,p'-DDE inhibits calcium ATPase in the membrane of the shell gland and reduces the transport of calcium carbonate from blood into the eggshell gland. This results in a dose-dependent thickness reduction. Other evidence indicates that o,p'-DDT disrupts female reproductive tract development, later impairing eggshell quality. Multiple mechanisms may be at work, or different mechanisms may operate in different species. Some studies show that although DDE levels have fallen dramatically, eggshell thickness remains 10–12 percent thinner than before DDT was first used.
Human health.
DDT is an endocrine disruptor. It is considered likely to be a human carcinogen although the majority of studies suggest it is not directly genotoxic. DDE acts as a weak androgen receptor antagonist, but not as an estrogen. p,p'-DDT, DDT's main component, has little or no androgenic or estrogenic activity. The minor component o,p'-DDT has weak estrogenic activity.
Acute toxicity.
DDT is classified as "moderately toxic" by the US National Toxicology Program (NTP) and "moderately hazardous" by WHO, based on the rat oral of 113 mg/kg. DDT has on rare occasions been administered orally as a treatment for barbiturate poisoning.
Chronic toxicity.
DDT and DDE, like other organochlorines, have been shown to have xenoestrogenic activity, meaning they are chemically similar enough to estrogens to trigger hormonal responses in animals. This endocrine disrupting activity has been observed in mice and rat toxicological studies. Epidemiological evidence indicates that these effects may be occurring in humans as a result of DDT exposure. EPA states that DDT exposure damages the reproductive system and reduces reproductive success. These effects may cause developmental and reproductive toxicity:
Carcinogenicity.
In 2002, the Centers for Disease Control and Prevention reported, "Overall, in spite of some positive associations for some cancers within certain subgroups of people, there is no clear evidence that exposure to DDT/DDE causes cancer in humans." The NTP classifies it as "reasonably anticipated to be a carcinogen," the International Agency for Research on Cancer classifies it as "probably carcinogenic to humans", and the EPA classifies DDT, DDE and DDD as class B2 "probable" carcinogens. These evaluations are based mainly on animal studies.
A 2005 Lancet review stated that occupational DDT exposure was associated with increased pancreatic cancer risk in 2 case control studies, but another study showed no DDE dose-effect association. Results regarding a possible association with liver cancer and biliary tract cancer are conflicting: workers who did not have direct occupational DDT contact showed increased risk. White men had an increased risk, but not white women or black men.
Results about an association with multiple myeloma, prostate and testicular cancer, endometrial cancer and colorectal cancer have been inconclusive or generally do not support an association.
A 2009 review, whose co-authors included persons engaged in DDT-related litigation, reached broadly similar conclusions, with an equivocal association with testicular cancer. Case–control studies did not support an association with leukemia or lymphoma.
Breast cancer.
The question of whether DDT or DDE are risk factors in breast cancer has not been conclusively answered. Several meta analyses of observational studies have concluded that there is no overall relationship between DDT exposure and breast cancer risk. The United States Institute of Medicine reviewed data on the association of breast cancer with DDT exposure in 2012 and concluded that a causative relationship could neither be proven nor disproven.
A 2007 case control study using archived blood samples found that breast cancer risk was increased 5-fold among women who were born prior to 1931 and who had high serum DDT levels in 1963. Reasoning that DDT use became widespread in 1945 and peaked around 1950, they concluded that the ages of 14-20 were a critical period in which DDT exposure leads to increased risk. This study, which suggests a connection between DDT exposure and breast cancer that would not be picked up by most studies, has received variable commentary in third party reviews. One review suggested that "previous studies that measured exposure in older women may have missed the critical period." A second review suggested a cautious approach to the interpretation of these results given methodological weaknesses in the study design. The National Toxicology Program notes that while the majority of studies have not found a relationship between DDT exposure and breast cancer that positive associations have been seen in a "few studies among women with higher levels of exposure and among certain subgroups of women"
A 2015 case control study identified a link (odds ratio 3.4) between "in-utero" exposure (as estimated from archived maternal blood samples) and breast cancer diagnosis in daughters. The findings "support classification of DDT as an endocrine disruptor, a predictor of breast cancer, and a marker of high risk".
Malaria.
Malaria remains the primary public health challenge in many countries. 2008 WHO estimates were 243 million cases and 863,000 deaths. About 89% of these deaths occur in Africa, mostly to children under age 5. DDT is one of many tools to fight the disease. Its use in this context has been called everything from a "miracle weapon is like Kryptonite to the mosquitoes," to "toxic colonialism".
Before DDT, eliminating mosquito breeding grounds by drainage or poisoning with Paris green or pyrethrum was sometimes successful. In parts of the world with rising living standards, the elimination of malaria was often a collateral benefit of the introduction of window screens and improved sanitation. A variety of usually simultaneous interventions represents best practice. These include antimalarial drugs to prevent or treat infection; improvements in public health infrastructure to diagnose, sequester and treat infected individuals; bednets and other methods intended to keep mosquitoes from biting humans; and vector control strategies such as larvaciding with insecticides, ecological controls such as draining mosquito breeding grounds or introducing fish to eat larvae and indoor residual spraying (IRS) with insecticides, possibly including DDT. IRS involves the treatment of interior walls and ceilings with insecticides. It is particularly effective against mosquitoes, since many species rest on an indoor wall before or after feeding. DDT is one of 12 WHO–approved IRS insecticides.
WHO's anti-malaria campaign of the 1950s and 1960s relied heavily on DDT and the results were promising, though temporary in developing countries. Experts tie malarial resurgence to multiple factors, including poor leadership, management and funding of malaria control programs; poverty; civil unrest; and increased irrigation. The evolution of resistance to first-generation drugs (e.g. chloroquine) and to insecticides exacerbated the situation. Resistance was largely fueled by unrestricted agricultural use. Resistance and the harm both to humans and the environment led many governments to curtail DDT use in vector control and agriculture. In 2006 WHO reversed a longstanding policy against DDT by recommending that it be used as an indoor pesticide in regions where malaria is a major problem.
Once the mainstay of anti-malaria campaigns, as of 2008 only 12 countries used DDT, including India and some southern African states, though the number was expected to rise. and 29 in 1964. Thereafter the program was halted to save money and malaria rebounded to 600,000 cases in 1968 and the first quarter of 1969. The country resumed DDT vector control but the mosquitoes had evolved resistance in the interim, presumably because of continued agricultural use. The program switched to malathion, but despite initial successes, malaria continued its resurgence into the 1980s.
DDT remains on WHO's list of insecticides recommended for IRS. After the appointment of Arata Kochi as head of its anti-malaria division, WHO's policy shifted from recommending IRS only in areas of seasonal or episodic transmission of malaria, to advocating it in areas of continuous, intense transmission. WHO reaffirmed its commitment to phasing out DDT, aiming "to achieve a 30% cut in the application of DDT world-wide by 2014 and its total phase-out by the early 2020s if not sooner" while simultaneously combating malaria. WHO plans to implement alternatives to DDT to achieve this goal.
South Africa continues to use DDT under WHO guidelines. In 1996, the country switched to alternative insecticides and malaria incidence increased dramatically. Returning to DDT and introducing new drugs brought malaria back under control. Malaria cases increased in South America after countries in that continent stopped using DDT. Research data showed a strong negative relationship between DDT residual house sprayings and malaria. In a research from 1993 to 1995, Ecuador increased its use of DDT and achieved a 61% reduction in malaria rates, while each of the other countries that gradually decreased its DDT use had large increases.
Mosquito resistance.
In some areas resistance reduced DDT's effectiveness. WHO guidelines require that absence of resistance must be confirmed before using the chemical. Resistance is largely due to agricultural use, in much greater quantities than required for disease prevention.
Resistance was noted early in spray campaigns. Paul Russell, former head of the Allied Anti-Malaria campaign, observed in 1956 that "resistance has appeared after six or seven years." Resistance has been detected in Sri Lanka, Pakistan, Turkey and Central America and it has largely been replaced by organophosphate or carbamate insecticides, "e.g." malathion or bendiocarb.
In many parts of India, DDT is ineffective. Agricultural uses were banned in 1989 and its anti-malarial use has been declining. Urban use ended. DDT is still manufactured and used. One study concluded that "DDT is still a viable insecticide in indoor residual spraying owing to its effectivity in well supervised spray operation and high excito-repellency factor."
Studies of malaria-vector mosquitoes in KwaZulu-Natal Province, South Africa found susceptibility to 4% DDT (WHO's susceptibility standard), in 63% of the samples, compared to the average of 86.5% in the same species caught in the open. The authors concluded that "Finding DDT resistance in the vector "An. arabiensis", close to the area where we previously reported pyrethroid-resistance in the vector "An. funestus" Giles, indicates an urgent need to develop a strategy of insecticide resistance management for the malaria control programmes of southern Africa."
DDT can still be effective against resistant mosquitoes and the avoidance of DDT-sprayed walls by mosquitoes is an additional benefit of the chemical. For example, a 2007 study reported that resistant mosquitoes avoided treated huts. The researchers argued that DDT was the best pesticide for use in IRS (even though it did not afford the most protection from mosquitoes out of the three test chemicals) because the others pesticides worked primarily by killing or irritating mosquitoes – encouraging the development of resistance. Others argue that the avoidance behavior slows eradication. Unlike other insecticides such as pyrethroids, DDT requires long exposure to accumulate a lethal dose; however its irritant property shortens contact periods. "For these reasons, when comparisons have been made, better malaria control has generally been achieved with pyrethroids than with DDT." In India outdoor sleeping and night duties are common, implying that "the excito-repellent effect of DDT, often reported useful in other countries, actually promotes outdoor transmission." Genomic studies in the model genetic organism "Drosophila melanogaster" revealed that high level DDT resistance is polygenic, involving multiple resistance mechanisms.
Residents' concerns.
IRS is effective if at least 80% of homes and barns in a residential area are sprayed. Lower coverage rates can jeopardize program effectiveness. Many residents resist DDT spraying, objecting to the lingering smell, stains on walls, and the potential exacerbation of problems with other insect pests. Pyrethroid insecticides (e.g. deltamethrin and lambda-cyhalothrin) can overcome some of these issues, increasing participation.
Human exposure.
A 1994 study found that South Africans living in sprayed homes have levels that are several orders of magnitude greater than others. Breast milk from South African mothers contains high levels of DDT and DDE. It is unclear to what extent these levels arise from home spraying vs food residues. Evidence indicates that these levels are associated with infant neurological abnormalities.
Most studies of DDT's human health effects have been conducted in developed countries where DDT is not used and exposure is relatively low.
Illegal diversion to agriculture is also a concern as it is difficult to prevent and its subsequent use on crops is uncontrolled. For example, DDT use is widespread in Indian agriculture, particularly mango production and is reportedly used by librarians to protect books. Other examples include Ethiopia, where DDT intended for malaria control is reportedly used in coffee production, and Ghana where it is used for fishing." The residues in crops at levels unacceptable for export have been an important factor in bans in several tropical countries. Adding to this problem is a lack of skilled personnel and management.
Criticism of restrictions on DDT use.
Critics argue that limitations on DDT use for public health purposes have caused unnecessary morbidity and mortality from vector-borne diseases, with some claims of malaria deaths ranging as high as the hundreds of thousands and millions. Robert Gwadz of the US National Institutes of Health said in 2007, "The ban on DDT may have killed 20 million children." These arguments were rejected as "outrageous" by former WHO scientist Socrates Litsios. May Berenbaum, University of Illinois entomologist, says, "to blame environmentalists who oppose DDT for more deaths than Hitler is worse than irresponsible." Investigative journalist Adam Sarvana and others characterize this notion as a "myth" promoted principally by Roger Bate of the pro-DDT advocacy group Africa Fighting Malaria (AFM).
Criticisms of a DDT "ban" often specifically reference the 1972 United States ban (with the erroneous implication that this constituted a worldwide ban and prohibited use of DDT in vector control). Reference is often made to "Silent Spring," even though Carson never pushed for a DDT ban. John Quiggin and Tim Lambert wrote, "the most striking feature of the claim against Carson is the ease with which it can be refuted."
It has been alleged that donor governments and agencies refused to fund DDT spraying, or made aid contingent upon not using DDT. According to a report in the "British Medical Journal", use of DDT in Mozambique "was stopped several decades ago, because 80% of the country's health budget came from donor funds, and donors refused to allow the use of DDT." Roger Bate asserted, "many countries have been coming under pressure from international health and environment agencies to give up DDT or face losing aid grants: Belize and Bolivia are on record admitting they gave in to pressure on this issue from ."
The US Agency for International Development (USAID) has been the focus of much criticism. While the agency now funds DDT use in some African countries, in the past it did not. When John Stossel accused USAID of not funding DDT because it wasn't "politically correct," Anne Peterson, the agency's assistant administrator for global health, replied that "I believe that the strategies we are using are as effective as spraying with DDT ... So, politically correct or not, I am very confident that what we are doing is the right strategy." USAID's Kent R. Hill stated that the agency had been misrepresented: "USAID strongly supports spraying as a preventative measure for malaria and will support the use of DDT when it is scientifically sound and warranted." The Agency's website states that "USAID has never had a 'policy' as such either 'for' or 'against' DDT for IRS (Indoor residual spraying). The real change in the past two years [2006/07] was a new interest and emphasis on IRS in general – with DDT or any other insecticide – as an effective malaria prevention strategy in tropical Africa." The agency claimed that in many cases alternative malaria control measures were more cost-effective than DDT spraying.
Alternatives.
Insecticides.
Organophosphate and carbamate insecticides, "e.g." malathion and bendiocarb, respectively, are more expensive than DDT per kilogram and are applied at roughly the same dosage. Pyrethroids such as deltamethrin are also more expensive than DDT, but are applied more sparingly (0.02–0.3 g/m2 vs 1–2 g/m2), so the net cost per house is about the same.
Non-chemical vector control.
Before DDT, malaria was successfully eliminated or curtailed in several tropical areas by removing or poisoning mosquito breeding grounds and larva habitats, for example by eliminating standing water. These methods have seen little application in Africa for more than half a century. According to CDC, such methods are not practical in Africa because ""Anopheles gambiae", one of the primary vectors of malaria in Africa, breeds in numerous small pools of water that form due to rainfall ... It is difficult, if not impossible, to predict when and where the breeding sites will form, and to find and treat them before the adults emerge."
The relative effectiveness of IRS versus other malaria control techniques (e.g. bednets or prompt access to anti-malarial drugs) varies and is dependent on local conditions.
A WHO study released in January 2008 found that mass distribution of insecticide-treated mosquito nets and artemisinin–based drugs cut malaria deaths in half in malaria-burdened Rwanda and Ethiopia. IRS with DDT did not play an important role in mortality reduction in these countries.
Vietnam has enjoyed declining malaria cases and a 97% mortality reduction after switching in 1991 from a poorly funded DDT-based campaign to a program based on prompt treatment, bednets and pyrethroid group insecticides.
In Mexico, effective and affordable chemical and non-chemical strategies were so successful that the Mexican DDT manufacturing plant ceased production due to lack of demand.
A review of fourteen studies in sub-Saharan Africa, covering insecticide-treated nets, residual spraying, chemoprophylaxis for children, chemoprophylaxis or intermittent treatment for pregnant women, a hypothetical vaccine and changing front–line drug treatment, found decision making limited by the lack of information on the costs and effects of many interventions, the small number of cost-effectiveness analyses, the lack of evidence on the costs and effects of packages of measures and the problems in generalizing or comparing studies that relate to specific settings and use different methodologies and outcome measures. The two cost-effectiveness estimates of DDT residual spraying examined were not found to provide an accurate estimate of the cost-effectiveness of DDT spraying; the resulting estimates may not be good predictors of cost-effectiveness in current programs.
However, a study in Thailand found the cost per malaria case prevented of DDT spraying (US$1.87) to be 21% greater than the cost per case prevented of lambda-cyhalothrin–treated nets (US$1.54), casting some doubt on the assumption that DDT was the most cost-effective measure. The director of Mexico's malaria control program found similar results, declaring that it was 25% cheaper for Mexico to spray a house with synthetic pyrethroids than with DDT. However, another study in South Africa found generally lower costs for DDT spraying than for impregnated nets.
A more comprehensive approach to measuring cost-effectiveness or efficacy of malarial control would not only measure the cost in dollars, as well as the number of people saved, but would also consider ecological damage and negative human health impacts. One preliminary study found that it is likely that the detriment to human health approaches or exceeds the beneficial reductions in malarial cases, except perhaps in epidemics. It is similar to the earlier study regarding estimated theoretical infant mortality caused by DDT and subject to the criticism also mentioned earlier.
A study in the Solomon Islands found that "although impregnated bed nets cannot entirely replace DDT spraying without substantial increase in incidence, their use permits reduced DDT spraying."
A comparison of four successful programs against malaria in Brazil, India, Eritrea and Vietnam does not endorse any single strategy but instead states, "Common success factors included conducive country conditions, a targeted technical approach using a package of effective tools, data-driven decision-making, active leadership at all levels of government, involvement of communities, decentralized implementation and control of finances, skilled technical and managerial capacity at national and sub-national levels, hands-on technical and programmatic support from partner agencies, and sufficient and flexible financing."
DDT resistant mosquitoes have generally proved susceptible to pyrethroids. Thus far, pyrethroid resistance in "Anopheles" has not been a major problem.

</doc>
<doc id="8495" url="https://en.wikipedia.org/wiki?curid=8495" title="Data set">
Data set

A data set (or dataset) is a collection of data.
Most commonly a data set corresponds to the contents of a single database table, or a single statistical data matrix, where every column of the table represents a particular variable, and each row corresponds to a given member of the data set in question. The data set lists values for each of the variables, such as height and weight of an object, for each member of the data set. Each value is known as a datum. The data set may comprise data for one or more members, corresponding to the number of rows.
The term data set may also be used more loosely, to refer to the data in a collection of closely related tables, corresponding to a particular experiment or event. An example of this type is the data sets collected by space agencies performing experiments with instruments aboard space probes.
History.
Historically, the term originated in the mainframe field, where it had a well-defined meaning, very close to contemporary "computer file".
Properties.
Several characteristics define a data set's structure and properties. These include the number and types of the attributes or variables, and various statistical measures applicable to them, such as standard deviation and kurtosis.
The values may be numbers, such as real numbers or integers, for example representing a person's height in centimeters, but may also be nominal data (i.e., not consisting of numerical values), for example representing a person's ethnicity. More generally, values may be of any of the kinds described as a level of measurement. For each variable, the values are normally all of the same kind. However, there may also be "missing values", which must be indicated in some way.
In statistics, data sets usually come from actual observations obtained by sampling a statistical population, and each row corresponds to the observations on one element of that population. Data sets may further be generated by algorithms for the purpose of testing certain kinds of software. Some modern statistical analysis software such as SPSS still present their data in the classical data set fashion. If data is missing or suspicious an imputation method may be used to complete a data set.
Classic data sets.
Several classic data sets have been used extensively in the statistical literature:

</doc>
<doc id="8496" url="https://en.wikipedia.org/wiki?curid=8496" title="DMA">
DMA

DMA can refer to:

</doc>
<doc id="8498" url="https://en.wikipedia.org/wiki?curid=8498" title="Diagnostic and Statistical Manual of Mental Disorders">
Diagnostic and Statistical Manual of Mental Disorders

The Diagnostic and Statistical Manual of Mental Disorders (DSM), published by the American Psychiatric Association (APA), offers a common language and standard criteria for the classification of mental disorders. It is used, or relied upon, by clinicians, researchers, psychiatric drug regulation agencies, health insurance companies, pharmaceutical companies, the legal system, and policy makers together with alternatives such as the International Statistical Classification of Diseases and Related Health Problems (ICD), produced by the World Health Organization (WHO). The DSM is now in its fifth edition, DSM-5, published on May 18, 2013.
The DSM evolved from systems for collecting census and psychiatric hospital statistics, and from a United States Army manual. Revisions since its first publication in 1952 have incrementally added to the total number of mental disorders, although also removing those no longer considered to be mental disorders.
The ICD is the other commonly used manual for mental disorders. It is distinguished from the DSM in that it covers health as a whole. While the DSM is the official diagnostic system for mental disorders in the US, the ICD is used more widely in Europe and other parts of the world. The DSM-IV-TR (4th. ed.) contains, in Appendix G, an "ICD-9-CM Codes for Selected General Medical Conditions and Medication-Induced Disorders" that allows for comparisons between the DSM and the ICD manuals, which may not systematically match because revisions are not simultaneously coordinated.
While the DSM has been praised for standardizing psychiatric diagnostic categories and criteria, it has also generated controversy and criticism. Critics, including the National Institute of Mental Health, argue that the DSM represents an unscientific and subjective system. There are ongoing issues concerning the validity and reliability of the diagnostic categories; the reliance on superficial symptoms; the use of artificial dividing lines between categories and from "normality"; possible cultural bias; and medicalization of human distress. The publication of the DSM, with tightly guarded copyrights, now makes APA over $5 million a year, historically totaling over $100 million.
Uses and definition.
Many mental health professionals use the manual to determine and help communicate a patient's diagnosis after an evaluation; hospitals, clinics, and insurance companies in the US also generally require a DSM diagnosis for all patients treated. The DSM can be used clinically in this way, and also to categorize patients using diagnostic criteria for research purposes. Studies done on specific disorders often recruit patients whose symptoms match the criteria listed in the DSM for that disorder. An international survey of psychiatrists in 66 countries comparing use of the ICD-10 and DSM-IV found the former was more often used for clinical diagnosis while the latter was more valued for research.
DSM-5, and the abbreviations for all previous editions, are registered trademarks owned by the APA.
History.
The initial impetus for developing a classification of mental disorders in the United States was the need to collect statistical information. The first official attempt was the 1840 census, which used a single category: "idiocy/insanity". Three years later, the American Statistical Association made an official protest to the U.S. House of Representatives, stating that "the most glaring and remarkable errors are found in the statements respecting nosology, prevalence of insanity, blindness, deafness, and dumbness, among the people of this nation", pointing out that in many towns African-Americans were all marked as insane, and calling the statistics essentially useless.
The Association of Medical Superintendents of American Institutions for the Insane was formed in 1844, changing its name in 1892 to the American Medico-Psychological Association, and in 1921 to the present American Psychiatric Association (APA).
Edward Jarvis and later Francis Amasa Walker helped expand the census, from 2 volumes in 1870 to 25 volumes in 1880. Frederick H. Wines was appointed to write a 582-page volume called "Report on the Defective, Dependent, and Delinquent Classes of the Population of the United States, As Returned at the Tenth Census (June 1, 1880)" (published 1888). Wines used seven categories of mental illness: dementia, dipsomania (uncontrollable craving for alcohol), epilepsy, mania, melancholia, monomania and paresis. These categories were also adopted by the Association.
In 1917, together with the National Commission on Mental Hygiene (now Mental Health America), the APA developed a new guide for mental hospitals called the "Statistical Manual for the Use of Institutions for the Insane". This included 22 diagnoses and would be revised several times by the APA over the years. Along with the New York Academy of Medicine, the APA also provided the psychiatric nomenclature subsection of the US general medical guide, the "Standard Classified Nomenclature of Disease", referred to as the "Standard".
DSM-I (1952).
World War II saw the large-scale involvement of US psychiatrists in the selection, processing, assessment, and treatment of soldiers. This moved the focus away from mental institutions and traditional clinical perspectives. A committee headed by psychiatrist Brigadier General William C. Menninger developed a new classification scheme called Medical 203, that was issued in 1943 as a War Department Technical Bulletin under the auspices of the Office of the Surgeon General. The foreword to the DSM-I states the US Navy had itself made some minor revisions but "the Army established a much more sweeping revision, abandoning the basic outline of the Standard and attempting to express present day concepts of mental disturbance. This nomenclature eventually was adopted by all Armed Forces", and "assorted modifications of the Armed Forces nomenclature introduced into many clinics and hospitals by psychiatrists returning from military duty." The Veterans Administration also adopted a slightly modified version of Medical 203.
In 1949, the World Health Organization published the sixth revision of the International Statistical Classification of Diseases (ICD), which included a section on mental disorders for the first time. The foreword to DSM-1 states this "categorized mental disorders in rubrics similar to those of the Armed Forces nomenclature." An APA Committee on Nomenclature and Statistics was empowered to develop a version specifically for use in the United States, to standardize the diverse and confused usage of different documents. In 1950, the APA committee undertook a review and consultation. It circulated an adaptation of Medical 203, the VA system, and the Standard's Nomenclature to approximately 10% of APA members. 46% replied, of which 93% approved, and after some further revisions (resulting in its being called DSM-I), the "Diagnostic and Statistical Manual of Mental Disorders" was approved in 1951 and published in 1952. The structure and conceptual framework were the same as in Medical 203, and many passages of text were identical. The manual was 130 pages long and listed 106 mental disorders. These included several categories of "personality disturbance", generally distinguished from "neurosis" (nervousness, egodystonic).
In 1952, the APA listed homosexuality in the DSM as a sociopathic personality disturbance. "", a large-scale 1962 study of homosexuality by Irving Bieber and other authors, was used to justify inclusion of the disorder as a supposed pathological hidden fear of the opposite sex caused by traumatic parent–child relationships. This view was widely influential in the medical profession. In 1956, however, the psychologist Evelyn Hooker performed a study that compared the happiness and well-adjusted nature of self-identified homosexual men with heterosexual men and found no difference. Her study stunned the medical community and made her a heroine to many gay men and lesbians, but homosexuality remained in the DSM until May 1974.
DSM-II (1968).
In the 1960s, there were many challenges to the concept of mental illness itself. These challenges came from psychiatrists like Thomas Szasz, who argued that mental illness was a myth used to disguise moral conflicts; from sociologists such as Erving Goffman, who said mental illness was merely another example of how society labels and controls non-conformists; from behavioural psychologists who challenged psychiatry's fundamental reliance on unobservable phenomena; and from gay rights activists who criticised the APA's listing of homosexuality as a mental disorder. A study published in "Science" by Rosenhan received much publicity and was viewed as an attack on the efficacy of psychiatric diagnosis.
Although the APA was closely involved in the next significant revision of the mental disorder section of the ICD (version 8 in 1968), it decided to go ahead with a revision of the DSM. It was published in 1968, listed 182 disorders, and was 134 pages long. It was quite similar to the DSM-I. The term "reaction" was dropped, but the term "neurosis" was retained. Both the DSM-I and the DSM-II reflected the predominant psychodynamic psychiatry, although they also included biological perspectives and concepts from Kraepelin's system of classification. Symptoms were not specified in detail for specific disorders. Many were seen as reflections of broad underlying conflicts or maladaptive reactions to life problems, rooted in a distinction between neurosis and psychosis (roughly, anxiety/depression broadly in touch with reality, or hallucinations/delusions appearing disconnected from reality). Sociological and biological knowledge was incorporated, in a model that did not emphasize a clear boundary between normality and abnormality. The idea that personality disorders did not involve emotional distress was discarded.
An influential 1974 paper by Robert Spitzer and Joseph L. Fleiss demonstrated that the second edition of the DSM (DSM-II) was an unreliable diagnostic tool. They found that different practitioners using the DSM-II were rarely in agreement when diagnosing patients with similar problems. In reviewing previous studies of 18 major diagnostic categories, Fleiss and Spitzer concluded that "there are no diagnostic categories for which reliability is uniformly high. Reliability appears to be only satisfactory for three categories: mental deficiency, organic brain syndrome (but not its subtypes), and alcoholism. The level of reliability is no better than fair for psychosis and schizophrenia and is poor for the remaining categories".
Seventh printing of the DSM-II, 1974.
As described by Ronald Bayer, a psychiatrist and gay rights activist, specific protests by gay rights activists against the APA began in 1970, when the organization held its convention in San Francisco. The activists disrupted the conference by interrupting speakers and shouting down and ridiculing psychiatrists who viewed homosexuality as a mental disorder. In 1971, gay rights activist Frank Kameny worked with the Gay Liberation Front collective to demonstrate against the APA's convention. At the 1971 conference, Kameny grabbed the microphone and yelled: "Psychiatry is the enemy incarnate. Psychiatry has waged a relentless war of extermination against us. You may take this as a declaration of war against you."
This activism occurred in the context of a broader anti-psychiatry movement that had come to the fore in the 1960s and was challenging the legitimacy of psychiatric diagnosis. Anti-psychiatry activists protested at the same APA conventions, with some shared slogans and intellectual foundations.
Presented with data from researchers such as Alfred Kinsey and Evelyn Hooker, the seventh printing of the DSM-II, in 1974, no longer listed homosexuality as a category of disorder. After a vote by the APA trustees in 1973, and confirmed by the wider APA membership in 1974, the diagnosis was replaced with the category of "sexual orientation disturbance".
DSM-III (1980).
In 1974, the decision to create a new revision of the DSM was made, and Robert Spitzer was selected as chairman of the task force. The initial impetus was to make the DSM nomenclature consistent with the International Statistical Classification of Diseases and Related Health Problems (ICD), published by the World Health Organization. The revision took on a far wider mandate under the influence and control of Spitzer and his chosen committee members. One goal was to improve the uniformity and validity of psychiatric diagnosis in the wake of a number of critiques, including the famous Rosenhan experiment. There was also a need to standardize diagnostic practices within the US and with other countries after research showed that psychiatric diagnoses differed markedly between Europe and the USA. The establishment of these criteria was an attempt to facilitate the pharmaceutical regulatory process.
The criteria adopted for many of the mental disorders were taken from the Research Diagnostic Criteria (RDC) and Feighner Criteria, which had just been developed by a group of research-orientated psychiatrists based primarily at Washington University in St. Louis and the New York State Psychiatric Institute. Other criteria, and potential new categories of disorder, were established by consensus during meetings of the committee, as chaired by Spitzer. A key aim was to base categorization on colloquial English descriptive language (which would be easier to use by federal administrative offices), rather than assumptions of etiology, although its categorical approach assumed each particular pattern of symptoms in a category reflected a particular underlying pathology (an approach described as "neo-Kraepelinian"). The psychodynamic or physiologic view was abandoned, in favor of a regulatory or legislative model. A new "multiaxial" system attempted to yield a picture more amenable to a statistical population census, rather than just a simple diagnosis. Spitzer argued that "mental disorders are a subset of medical disorders" but the task force decided on the DSM statement: "Each of the mental disorders is conceptualized as a clinically significant behavioral or psychological syndrome." The personality disorders were placed on axis II along with mental retardation.
The first draft of the DSM-III was prepared within a year. Many new categories of disorder were introduced, while some were deleted or changed. A number of the unpublished documents discussing and justifying the changes have recently come to light. Field trials sponsored by the U.S. National Institute of Mental Health (NIMH) were conducted between 1977 and 1979 to test the reliability of the new diagnoses. A controversy emerged regarding deletion of the concept of neurosis, a mainstream of psychoanalytic theory and therapy but seen as vague and unscientific by the DSM task force. Faced with enormous political opposition, the DSM-III was in serious danger of not being approved by the APA Board of Trustees unless "neurosis" was included in some capacity; a political compromise reinserted the term in parentheses after the word "disorder" in some cases. Additionally, the diagnosis of ego-dystonic homosexuality replaced the DSM-II category of "sexual orientation disturbance".
Finally published in 1980, the DSM-III was 494 pages and listed 265 diagnostic categories. It rapidly came into widespread international use and has been termed a revolution or transformation in psychiatry. However, Robert Spitzer later criticized his own work on it in an interview with Adam Curtis, saying it led to the medicalization of 20-30 percent of the population who may not have had any serious mental problems.
When DSM-III was published, the developers made extensive claims about the reliability of the radically new diagnostic system they had devised, which relied on data from special field trials. However, according to a 1994 article by Stuart A. Kirk:
Twenty years after the reliability problem became the central focus of DSM-III, there is still not a single multi-site study showing that DSM (any version) is routinely used with high reliably by regular mental health clinicians. Nor is there any credible evidence that any version of the manual has greatly increased its reliability beyond the previous version. There are important methodological problems that limit the generalisability of most reliability studies. Each reliability study is constrained by the training and supervision of the interviewers, their motivation and commitment to diagnostic accuracy, their prior skill, the homogeneity of the clinical setting in regard to patient mix and base rates, and the methodological rigor achieved by the investigator…
DSM-III-R (1987).
In 1987, the DSM-III-R was published as a revision of the DSM-III, under the direction of Spitzer. Categories were renamed and reorganized, and significant changes in criteria were made. Six categories were deleted while others were added. Controversial diagnoses, such as pre-menstrual dysphoric disorder and masochistic personality disorder, were considered and discarded. "Ego-dystonic homosexuality" was also removed and was largely subsumed under "sexual disorder not otherwise specified", which can include "persistent and marked distress about one's sexual orientation." Altogether, the DSM-III-R contained 292 diagnoses and was 567 pages long. Further efforts were made for the diagnoses to be purely descriptive, although the introductory text stated that for at least some disorders, "particularly the Personality Disorders, the criteria require much more inference on the part of the observer" (p. xxiii).
DSM-IV (1994).
In 1994, DSM-IV was published, listing 297 disorders in 886 pages. The task force was chaired by Allen Frances. A steering committee of 27 people was introduced, including four psychologists. The steering committee created 13 work groups of five to 16 members. Each work group had about 20 advisers The work groups conducted a three-step process: first, each group conducted an extensive literature review of their diagnoses; then, they requested data from researchers, conducting analyses to determine which criteria required change, with instructions to be conservative; finally, they conducted multicenter field trials relating diagnoses to clinical practice. A major change from previous versions was the inclusion of a clinical significance criterion to almost half of all the categories, which required that symptoms cause "clinically significant distress or impairment in social, occupational, or other important areas of functioning". Some personality disorder diagnoses were deleted or moved to the appendix.
DSM-IV-TR (2000).
A "text revision" of the DSM-IV, known as the DSM-IV-TR, was published in 2000. The diagnostic categories and the vast majority of the specific criteria for diagnosis were unchanged. The text sections giving extra information on each diagnosis were updated, as were some of the diagnostic codes to maintain consistency with the ICD. The DSM-IV-TR was organized into a five-part axial system. The first axis incorporated clinical disorders. The second axis covered personality disorders and intellectual disabilities. The remaining axes covered medical, psychosocial, environmental, and childhood factors functionally necessary to provide diagnostic criteria for health care assessments.
The DSM-IV-TR characterizes a mental disorder as "a clinically significant behavioral or psychological syndrome or pattern that occurs in an individual is associated with present distress… or disability… or with a significant increased risk of suffering." It also notes that "no definition adequately specifies precise boundaries for the concept of 'mental disorder'… different situations call for different definitions". It states that "there is no assumption that each category of mental disorder is a completely discrete entity with absolute boundaries dividing it from other mental disorders or from no mental disorder" (APA, 1994 and 2000). There are attempts to adjust the wording for the upcoming DSM-V.
DSM-5 (2013).
The fifth edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM), the DSM-5, was approved by the Board of Trustees of the APA on December 1, 2012. Published on May 18, 2013, the DSM-5 contains extensively revised diagnoses and, in some cases, broadens diagnostic definitions while narrowing definitions in other cases. The DSM-5 is the first major edition of the manual in twenty years.
A significant change in the fifth edition is the deletion of the subtypes of schizophrenia (paranoid, disorganized, catatonic, undifferentiated and residual).
The deletion of the subsets of autistic spectrum disorder (namely, Asperger's Syndrome, classic autism, Rett Syndrome, Childhood Disintegrative Disorder and pervasive developmental disorder not otherwise specified) was also implemented, with specifiers with regard to intensity (mild, moderate and severe). Severity is based on social communication impairments and restricted, repetitive patterns of behaviour, with three levels: 1 (requiring support), 2 (requiring substantial support) and 3 (requiring very substantial support).
During the revision process, the APA website periodically listed several sections of the DSM-5 for review and discussion.
Future revisions and updates (2013 and beyond).
Beginning with the fifth edition, it is intended that diagnostic guidelines revisions will be added more frequently. It is notable that The DSM-5 is identified with Arabic rather than Roman numerals. Incremental updates will be identified with decimals (DSM-5.1, DSM-5.2, etc.). A new edition will be signified by whole number changes (DSM-5, DSM-6, etc.). The change reflects the intent of the APA to respond more quickly when a preponderance of research supports a specific change in the manual. The research base of mental disorders is evolving at different rates for different disorders.
DSM-IV-TR.
Categorization.
The DSM-IV is a categorical classification system. The categories are prototypes, and a patient with a close approximation to the prototype is said to have that disorder. DSM-IV states, "there is no assumption each category of mental disorder is a completely discrete entity with absolute boundaries" but isolated, low-grade and noncriterion (unlisted for a given disorder) symptoms are not given importance. Qualifiers are sometimes used, for example mild, moderate or severe forms of a disorder. For nearly half the disorders, symptoms must be sufficient to cause "clinically significant distress or impairment in social, occupational, or other important areas of functioning", although DSM-IV-TR removed the distress criterion from tic disorders and several of the paraphilias due to their egosyntonic nature. Each category of disorder has a numeric code taken from the ICD coding system, used for health service (including insurance) administrative purposes.
Multi-axial system.
With the advent of the DSM-5 in 2013, the APA eliminated the longstanding multiaxial system for mental disorders.
Previously, the DSM-IV organized each psychiatric diagnosis into five dimensions (axes) relating to different aspects of disorder or disability:
Common Axis I disorders include depression, anxiety disorders, bipolar disorder, ADHD, autism spectrum disorders, anorexia nervosa, bulimia nervosa, and schizophrenia.
Common Axis II disorders include personality disorders: paranoid personality disorder, schizoid personality disorder, schizotypal personality disorder, borderline personality disorder, antisocial personality disorder, narcissistic personality disorder, histrionic personality disorder, avoidant personality disorder, dependent personality disorder, obsessive-compulsive personality disorder; and intellectual disabilities.
Common Axis III disorders include brain injuries and other medical/physical disorders which may aggravate existing diseases or present symptoms similar to other disorders."
Cautions.
The DSM-IV-TR states, because it is produced for the completion of federal legislative mandates, its use by people without clinical training can lead to inappropriate application of its contents. Appropriate use of the diagnostic criteria is said to require extensive clinical training, and its contents "cannot simply be applied in a cookbook fashion". The APA notes diagnostic labels are primarily for use as a "convenient shorthand" among professionals. The DSM advises laypersons should consult the DSM only to obtain information, not to make diagnoses, and people who may have a mental disorder should be referred to psychological counseling or treatment. Further, a shared diagnosis or label may have different causes or require different treatments; for this reason the DSM contains no information regarding treatment or cause. The range of the DSM represents an extensive scope of psychiatric and psychological issues or conditions, and it is not exclusive to what may be considered "illnesses".
Sourcebooks.
The DSM-IV does not specifically cite its sources, but there are four volumes of "sourcebooks" intended to be APA's documentation of the guideline development process and supporting evidence, including literature reviews, data analyses and field trials. The Sourcebooks have been said to provide important insights into the character and quality of the decisions that led to the production of DSM-IV, and hence the scientific credibility of contemporary psychiatric classification.
Criticism.
Reliability and validity concerns.
The revisions of the DSM from the 3rd Edition forward have been mainly concerned with diagnostic reliability—the degree to which different diagnosticians agree on a diagnosis. It was argued that a science of psychiatry can only advance if diagnosis is reliable. If clinicians and researchers frequently disagree about a diagnosis with a patient, then research into the causes and effective treatments of those disorders cannot advance. Hence, diagnostic reliability was a major concern of DSM-III. When the diagnostic reliability problem was thought to be solved, subsequent editions of the DSM were concerned mainly with "tweaking" the diagnostic criteria. Unfortunately, neither the issue of reliability or validity was settled. However, most psychiatric education post DSM-III focused on issues of treatment—especially drug treatment—and less on diagnostic concerns. In fact, Thomas R. Insel, M.D., Director of the NIMH, stated in 2013 that the agency would no longer fund research projects that rely exclusively on DSM criteria due to its lack of validity. Field trials of DSM-5 brought the debate of reliability back into the limelight as some disorders showed poor reliability. For example, major depressive disorder, a common mental illness, had a poor reliability kappa statistic of 0.28, indicating that clinicians frequently disagreed on this diagnosis in the same patients. The most reliable diagnosis was major neurocognitive disorder with a kappa of 0.78.
Superficial symptoms.
By design, the DSM is primarily concerned with the signs and symptoms of mental disorders, rather than the underlying causes. It claims to collect them together based on statistical or clinical patterns. As such, it has been compared to a naturalist's field guide to birds, with similar advantages and disadvantages. The lack of a causative or explanatory basis, however, is not specific to the DSM, but rather reflects a general lack of pathophysiological understanding of psychiatric disorders. As DSM-III chief architect Robert Spitzer and DSM-IV editor Michael First outlined in 2005, "little progress has been made toward understanding the pathophysiological processes and etiology of mental disorders. If anything, the research has shown the situation is even more complex than initially imagined, and we believe not enough is known to structure the classification of psychiatric disorders according to etiology."
The DSM's focus on superficial symptoms is claimed to be largely a result of necessity (assuming such a manual is nevertheless produced), since there is no agreement on a more explanatory classification system. Reviewers note, however, that this approach is undermining research, including in genetics, because it results in the grouping of individuals who have very little in common except superficial criteria as per DSM or ICD diagnosis.
Despite the lack of consensus on underlying causation, advocates for specific psychopathological paradigms have nonetheless faulted the current diagnostic scheme for not incorporating evidence-based models or findings from other areas of science. A recent example is evolutionary psychologists' criticism that the DSM does not differentiate between genuine cognitive malfunctions and those induced by psychological adaptations, a key distinction within evolutionary psychology but one that is widely challenged within general psychology. Another example is the strong operationalist viewpoint, which contends that reliance on operational definitions, as purported by the DSM, necessitates that intuitive concepts like depression be replaced by specific measurable concepts before they are scientifically meaningful. One critic states of psychologists that "Instead of replacing 'metaphysical' terms such as 'desire' and 'purpose', they used it to legitimize them by giving them operational definitions…the initial, quite radical operationalist ideas eventually came to serve as little more than a 'reassurance fetish' (Koch 1992) for mainstream methodological practice."
A 2013 review published in the "European Archives of Psychiatry and Clinical Neuroscience" states "that psychiatry targets the phenomena of consciousness, which, unlike somatic symptoms and signs, cannot be grasped on the analogy with material thing-like objects." As an example of the problem of the superficial characterization of psychiatric signs and symptoms, the authors gave the example of a patient saying they "feel depressed, sad, or down", showing that such a statement could indicate various underlying experiences: "not only depressed mood but also, for instance, irritation, anger, loss of meaning, varieties of fatigue, ambivalence, ruminations of different kinds, hyper-reflectivity, thought pressure, psychological anxiety, varieties of depersonalization, and even voices with negative content, and so forth." The structured interview comes with "danger of over confidence in the face value of the answers, as if a simple 'yes' or 'no' truly confirmed or denied the diagnostic criterion at issue." The authors gave an example: A patient who was being administered the Structured Clinical Interview for the DSM-IV Axis I Disorders denied thought insertion, but during a "conversational, phenomenological interview", a semi-structured interview tailored to the patient, the same patient admitted to experiencing thought insertion, along with a delusional elaboration. The authors suggested 2 reasons for this discrepancy: either the patient did not "recognize his own experience in the rather blunt, implicitly either/or formulation of the structured-interview question", or the experience did not "fully articulate itself" until the patient started talking about his experiences.
Dividing lines.
Despite caveats in the introduction to the DSM, it has long been argued that its system of classification makes unjustified categorical distinctions between disorders and uses arbitrary cut-offs between normal and abnormal. A 2009 psychiatric review noted that attempts to demonstrate natural boundaries between related DSM syndromes, or between a common DSM syndrome and normality, have failed. Some argue that rather than a categorical approach, a fully dimensional, spectrum or complaint-oriented approach would better reflect the evidence.
In addition, it is argued that the current approach based on exceeding a threshold of symptoms does not adequately take into account the context in which a person is living, and to what extent there is internal disorder of an individual versus a psychological response to adverse situations. The DSM does include a step ("Axis IV") for outlining "Psychosocial and environmental factors contributing to the disorder" once someone is diagnosed with that particular disorder.
Because an individual's degree of impairment is often not correlated with symptom counts and can stem from various individual and social factors, the DSM's standard of distress or disability can often produce false positives. On the other hand, individuals who do not meet symptom counts may nevertheless experience comparable distress or disability in their life.
Cultural bias.
Some psychiatrists argue that current diagnostic standards rely on an exaggerated interpretation of neurophysiological findings and so understate the scientific importance of social-psychological variables. Advocating a more culturally sensitive approach to psychology, critics such as Carl Bell and Marcello Maviglia contend that the cultural and ethnic diversity of individuals is often discounted by researchers and service providers. In addition, current diagnostic guidelines have been criticized as having a fundamentally Euro-American outlook. Although these guidelines have been widely implemented, opponents argue that even when a diagnostic criterion set is accepted across different cultures, it does not necessarily indicate that the underlying constructs have any validity within those cultures; even reliable application can only demonstrate consistency, not legitimacy. Cross-cultural psychiatrist Arthur Kleinman contends that the Western bias is ironically illustrated in the introduction of cultural factors to the DSM-IV: the fact that disorders or concepts from non-Western or non-mainstream cultures are described as "culture-bound", whereas standard psychiatric diagnoses are given no cultural qualification whatsoever, is to Kleinman revelatory of an underlying assumption that Western cultural phenomena are universal. Kleinman's negative view toward the culture-bound syndrome is largely shared by other cross-cultural critics, common responses included both disappointment over the large number of documented non-Western mental disorders still left out, and frustration that even those included were often misinterpreted or misrepresented. Many mainstream psychiatrists have also been dissatisfied with these new culture-bound diagnoses, although not for the same reasons. Robert Spitzer, a lead architect of the DSM-III, has held the opinion that the addition of cultural formulations was an attempt to placate cultural critics, and that they lack any scientific motivation or support. Spitzer also posits that the new culture-bound diagnoses are rarely used in practice, maintaining that the standard diagnoses apply regardless of the culture involved. In general, the mainstream psychiatric opinion remains that if a diagnostic category is valid, cross-cultural factors are either irrelevant or are only significant to specific symptom presentations. One of the results was the development of the Azibo Nosology by Daudi Ajani Ya Azibo as an alternative to the DSM to treat African and African American patients.
Medicalization and financial conflicts of interest.
It has also been alleged that the way the categories of the DSM are structured, as well as the substantial expansion of the number of categories, are representative of an increasing medicalization of human nature, which may be attributed to disease mongering by psychiatrists and pharmaceutical companies, the power and influence of the latter having grown dramatically in recent decades. Of the authors who selected and defined the DSM-IV psychiatric disorders, roughly half have had financial relationships with the pharmaceutical industry at one time, raising the prospect of a direct conflict of interest. The same article concludes that the connections between panel members and the drug companies were particularly strong in those diagnoses where drugs are the first line of treatment, such as schizophrenia and mood disorders, where 100% of the panel members had financial ties with the pharmaceutical industry. In 2005, then APA President Steven Sharfstein released a statement in which he conceded that psychiatrists had "allowed the biopsychosocial model to become the bio-bio-bio model".
However, although the number of identified diagnoses has increased by more than 300% (from 106 in DSM-I to 365 in DSM-IV-TR), psychiatrists such as Zimmerman and Spitzer argue it almost entirely represents greater specification of the forms of pathology, thereby allowing better grouping of more similar patients. However, William Glasser refers to the DSM as "phony diagnostic categories", arguing that "it was developed to help psychiatrists – to help them make money". In addition, the publishing of the DSM, with tightly guarded copyrights, has in itself earned over $100 million for the APA.
Clients and survivors.
A client is a person who accesses psychiatric services and may have been given a diagnosis from the DSM, while a survivor self-identifies as a person who has endured a psychiatric intervention and the mental health system (which may have involved involuntary commitment and involuntary treatment). Some individuals are relieved to find that they have a recognized condition that they can apply a name to and this has led to many people self-diagnosing. Others, however, question the accuracy of the diagnosis, or feel they have been given a "label" that invites social stigma and discrimination (the terms "mentalism" and "sanism" have been used to describe such discriminatory treatment).
Diagnoses can become internalized and affect an individual's self-identity, and some psychotherapists have found that the healing process can be inhibited and symptoms can worsen as a result. Some members of the psychiatric survivors movement (more broadly the consumer/survivor/ex-patient movement) actively campaign against their diagnoses, or the assumed implications, and/or against the DSM system in general. Additionally, it has been noted that the DSM often uses definitions and terminology that are inconsistent with a recovery model, and such content can erroneously imply excess psychopathology (e.g. multiple "comorbid" diagnoses) or chronicity.
DSM-5 critiques.
Psychiatrist Allen Frances has been critical of proposed revisions to the DSM-5. In a 2012 "New York Times" editorial, Frances warned that if this DSM version is issued unamended by the APA, it will "medicalize normality and result in a glut of unnecessary and harmful drug prescription." In a December 2, 2012 blog post in "Psychology Today", Frances lists the ten "most potentially harmful changes" to DSM-5:
Frances and others have published debates on what they see as the six most essential questions in psychiatric diagnosis:
In 2011, psychologist Brent Robbins co-authored a national letter for the Society for Humanistic Psychology that has brought thousands into the public debate about the DSM. Approximately 14,000 individuals and mental health professionals have signed a petition in support of the letter. Thirteen other American Psychological Association divisions have endorsed the petition. Robbins has noted that under the new guidelines, certain responses to grief could be labeled as pathological disorders, instead of being recognized as being normal human experiences.

</doc>
<doc id="8500" url="https://en.wikipedia.org/wiki?curid=8500" title="Dar es Salaam">
Dar es Salaam

Dar es Salaam (from ', literally "the residence of peace"; or simply Dar, formerly Mzizima) is the largest city of Tanzania and the largest city in eastern Africa by population, as well as a regionally important economic centre. It is Tanzania's most prominent city in arts, fashion, media, music, film and television. It is Tanzania's leading financial centre with the Dar es Salaam Stock Exchange (DSE) being the country's first and most important stock exchange market. Dar es Salaam is the largest and most populous Swahili speaking city in the world. 
It is the capital of the Dar es Salaam Region administrative province and consists of three boroughs or administrative districts: northern Kinondoni, central Ilala, and southern Temeke. The city is the leading arrival and departure point for most tourists who visit tourism areas in Tanzania like the national parks for safaris and the islands of Zanzibar. The region had a population of 4,364,541 as of the official 2012 census. Although Dar es Salaam lost its status as the nation's capital to Dodoma in 1974 (not completed until 1996), it remains the focus of the permanent central government bureaucracy. 
History.
In the 19th century, Mzizima (Kiswahili for "healthy town") was a coastal fishing village on the periphery of Indian Ocean trade routes. In 1865 or 1866, Sultan Majid bin Said of Zanzibar began building a new city very close to Mzizima and named it Dar es Salaam. The name is commonly translated as "abode/home of peace", based on the Arabic "dar" ("house"), and the Arabic "es salaam" ("of peace"). Dar es Salaam fell into decline after Majid's death in 1870, but was revived in 1887 when the German East Africa Company established a station there. The town's growth was facilitated by its role as the administrative and commercial centre of German East Africa and industrial expansion resulting from the construction of the Central Railway Line in the early 1900s.
German East Africa was captured by the British during World War I and became Tanganyika, with Dar es Salaam the administrative and commercial centre. Under British indirect rule, separate European (e.g., Oyster Bay) and African (e.g., Kariakoo and Ilala) areas developed at a distance from the city centre. The city's population also included a large number of south Asians. After World War II, Dar es Salaam experienced a period of rapid growth.
Political developments, including the formation and growth of the Tanganyika African National Union, led to Tanganyika attaining independence from colonial rule in December 1961. Dar es Salaam continued to serve as its capital, even when in 1964 Tanganyika and Zanzibar merged to form Tanzania. In 1973, however, provisions were made to relocate the capital to Dodoma, a more centrally located city in the interior. The relocation process has not yet been completed, and Dar es Salaam remains Tanzania's primary city.
In 1967, the Tanzanian government declared the "Ujamaa policy", that set Tanzania into a socialist path. The move slowed down the potential growth of the city as the government encouraged people not to move in cities but stay in Ujamaa socialist villages. But by 1980's the Ujamaa policy proved to be a failure into combating increasing poverty, hunger, and delayed development that Tanzania faced. This led to the 1980s liberalization policy that virtually ended socialism and its spirit within the Tanzania's government. The move led to increasing migration of rural dwellers from rural areas into cities with Dar es Salaam becoming the leading city in receiving migrants from rural areas.
Until the late 1990s, Dar es Salaam was not put into same category as Africa's leading cities like Nairobi, Johannesburg, Lagos, or Addis Ababa. But the 2000s decade became the turning point as the city experienced one of Africa's fastest urbanization rates as businesses were opened and prospered, Tanzanian banks headquartered in the city started to run more proper, the Dar es Salaam Stock Exchange expanded, and the Dar es Salaam harbour proved to be the most important in Tanzania and prominent for entrepot trade with landlocked countries like the Democratic Republic of Congo, Rwanda, Burundi, and Zambia. The CBD skyline hosts tall buildings, among them the 35-floor PSPF Tower, finished in 2015, and "the Tanzania" "Port"s "Authority" "(TPA) Tower", currently under construction .
Geography.
Dar es Salaam is located at 6°48' South, 39°17' East (−6.8000, 39.2833), on a natural harbour on the eastern coast of Africa, with sandy beaches in some areas.
Administratively, the Dar es Salaam region is divided into three districts: Ilala, Kinondoni, and Temeke.
Population.
Dar es Salaam is the largest city in Tanzania. With a population increase of 5.6 percent per year from 2002 to 2012, the city is the third fastest growing in Africa (ninth fastest in the world), after Bamako and Lagos. The metro population is expected to reach 5.12 million by 2020 and predicted to be as high as 76 million by the year 2100, making Dar Es Salaam the second largest city on earth (after Lagos), by 2100.
Economy and infrastructure.
Dar es Salaam is Tanzania's most important city for both business and government. The city contains high concentrations of trade and other services and manufacturing compared to other parts of Tanzania, which has about 80 percent of its population in rural areas. Downtown includes small businesses, many of which are run by traders and proprietors whose families originated from the Middle East and Indian sub-continent—areas of the world with which the settlements of the Tanzanian coast have had long-standing trading relations.
The Dar es Salaam CBD made up of Kisutu, Kivukoni, Upanga and Kariakoo areas is Tanzania's largest city CBD. All three areas making up the downtown are found in the Ilala district. Kivukoni has the city's important fish market, the Magogoni fish market. Kivukoni also is the place where the Tanzania's central bank, The Bank of Tanzania is located, so is the Dar es Salaam Stock Exchange. Kisutu has businesses and offices and is the location of Dar es Salaam central railway station, the PSPF Towers and the TPA tower. Kariakoo is the prominent shopping area with streets like Congo Street for clothing shops. Uhuru street is for computer and electronics, Msimbazi for mobile phones.
Dar es Salaam has a problem with slums. According to a United Nations estimate, 70 percent of the city's population lives in informal settlements. The poorer residents crowd into downtown areas or large slums, many without running water or basic services. The more wealthy live in beachside mansions in the city's northern districts.
On a natural harbour on the Indian Ocean, it is the hub of the Tanzanian transportation system as the main railways and several highways originate in or near the city.
Dar es Salaam has had a major construction boom. The PSPF Twin Towers with more than 35 stories is the tallest building in the city and the country. Dar es Salaam has major infrastructural problems, including an outdated transport system and occasional power rationing.
Climate.
Due to close proximity to the equator and the warm Indian Ocean, the city experiences tropical climatic conditions, typified by hot and humid weather throughout much of the year. It has a tropical wet and dry climate (Köppen: Aw). Annual rainfall is approximately , and in a normal year there are two rainy seasons: "the long rains" in April and May and "the short rains" in November and December.
Transportation.
The Julius Nyerere International Airport is the principal airport serving the country. Tanzania Railways operates the Central Line from Dar es Salaam to Kigoma. The TAZARA Railway connects Dar es Salaam to Zambia. 
Most intracity transport is by the dala dala (minibus) or Dar es Salaam commuter rail.
The bus rapid transit system under construction will be operated by the Dar Rapid Transit Agency (DART), a government entity, and is expected to open at the end of 2014. DART is being sponsored by the World Bank.
Dala dala minibuses are involved in many road accidents, accounting for a large percentage of the 4000+ yearly road deaths.
Dala dalas are cheap and often overcrowded. They are operated by a driver and a conductor: the conductor collects the fare and signals the driver to leave. They tend to be overcrowded, with passengers sometimes hanging outside the door.
Port.
The city has the countries busiest port and the Port of Dar es Salaam handles 90% of the countries cargo. Due to huge influx of cargo and the slow pace of expansion a new cargo port 60 km north of Dar es Salaam is proposed at Bagamoyo.
Culture.
Dar es Salaam has heavy traffic during the daytime, but after sunset the area is relatively quiet as much of the city's nightlife is located in more residential districts away from the city's mainly commercial centre.
The sprawling suburbs furthest from the city centre are generally populated by Tanzanians of African descent, with the exception of Oyster Bay, where there is a large population of foreign expatriates. The edges of Dar es Salaam are spreading rapidly, severely taxing the transportation network (which aside from ferries, lacks any kind of mass transit facilities) and raising the prospect of future urban overcrowding.
Food.
Due in part to the growth of the expatriate community and the increasing importance of tourism, the number of international restaurants has risen rapidly. The cityoffers a diversity of cuisine, ranging from traditional Tanzanian Barbecue-style options, such as "Nyama Choma" (Roasted meat—served with rice or ugali) and "Mishkaki" (Shish kebab—usually barbecued and served with salt, hot chili peppers, chapati, fries, and rice on the side), as well as the long-established traditional Indian and Zanzibari cuisine, to options from all corners of the globe, including Arab, Chinese, Thai, Turkish, Italian, and Japanese food. People who prefer neither fast food nor traditional restaurants buy their food from street vendors, who usually sell food at low prices. Samosas ("sambusas") are common street food items within the city, as the area is largely influenced by the foods brought from India.
Music.
The music scene in Dar es Salaam is divided between several styles. The longest standing style is live dance music (muziki wa dansi) bands such as DDC Mlimani Park Orchestra. Taarab which was traditionally strong in Zanzibar has also found a niche. However, it remains small compared both to dance music and "Bongo Flava", a broad category that represents the Tanzanian take on Hip Hop and R&B, which has quickly become the most popular locally produced music. Traditional music, which locally is used to refer to tribal music is still performed but typically only on family oriented occasions such as weddings.
This rap scene is also present.
In the 1970s, the Ministry of National Youth Culture aimed to create a national culture, which stressed the importance of music. Dar es Salaam became the music center in Tanzania, with the local radio exposing new bands and dominating the music and cultural scene. With this ujamaa, or family, mentality governing culture and music a unified people’s culture was created, leading to the rise of hip hop music. Throughout the years, the radio in Dar es Salaam has played a major role in the dissemination of music because many people don’t have television and cassettes are used over CDs.
Tourism.
Dar es Salaam has two of the five museums comprising the National Museum of Tanzania consortium, namely the National Museum proper and the Village Museum. The National Museum is dedicated to the history of Tanzania; most notably, it exhibits some of the bones of "Paranthropus boisei" that were among the findings of Louis Leakey at Olduvai. The Village Museum, located in the outskirts of the city on the road to Bagamoyo, showcases traditional huts from 16 different Tanzanian ethnic groups. There are also examples of traditional cultivations, and traditional music and dance shows are held daily.
Close to the National Museum are also the botanical gardens, with tropical plants and trees.
There are beaches on the Msasani peninsula north of Dar es Salaam and in Kigamboni to the south. Trips to the nearby islands of the Dar es Salaam Marine Reserve are a popular daytrip from the city and a spot for snorkeling, swimming and sunbathing. Bongoyo Island can be reached by boat from the Msasani Slipway.
Art.
Dar es Salaam (and specifically the area of Oyster Bay) is home to the Tingatinga painting style. The Nyumba ya sanaa ("House of Art") is a cultural centre, workshop and shop dedicated to Tanzanian art, showcasing and promoting Tanzanian craftmanship. Prominent Tanzanian sculptor George Lilanga has donated some of his works to the centre, including decorations of the building's main entrance.
Sports.
The National Stadium hosts Dar es Salaam's Young Africans Football Club, Simba Sports Club, Azam F.C. and other Tanzanian football clubs, and international matches.
Dar es Salaam's Mama Africa school, founded in 2003, is known for training some of Africa's finest acrobats.
Newspapers.
Dar has newspapers available, particularly from sellers prowling through stationary traffic at road intersections. English-language ones, with online presences, include "The Citizen" and "The Guardian" and the leading Kiswahili daily, Mwananchi.Business Times is the only financial and economic newspaper in town. It was established in 1988 and became the first ever private newspaper in Tanzania. Business Times also owns Majira, the Kiswahili leading newspaper in Tanzania.
Internet access.
Installation of a trans-Indian Ocean backbone cable in 2009 has, in theory, made Internet access much more readily available in Dar in particular and in East Africa in general. However, roll-out to end-users is slow, partly because of spotty telephone line coverage, partly due to the substantial prices and long contracts demanded for purchase of bandwidth for small ISPs. Mobile-telephone access to the Internet via 3G and 3.75G is still relatively expensive.
Internet cafes are found in the city centre.
The expressed aim of the SEACOM cable is to enable East Africa to develop economically through increased online trading.
Globalization.
Dar es Salaam is the city in Tanzania to which villagers flock for better opportunities. Westerners and Asians are also settling in Dar es Salaam, and the surge of foreigners has put pressure on local officials to develop policies better accommodating the growing diverse population of the city and its suburbs.
Education.
Dar es Salaam is the educational centre of Tanzania. The city is home to educational institutions.
Suburbs.
Dar es Salaam is divided into three districts: Ilala, Kinondoni, and Temeke. All three are governed as municipal councils, and so all of the city's suburbs or wards are affiliated with them.
Kinondoni.
Kinondoni is the most populated amongst the districts, with half of the city's population residing within it. It is also home to high-income suburbs. These include:
Ilala.
Ilala is the administrative district of Dar es Salaam where almost all government offices and ministries are housed. The Central Business District (locally called "Posta") is located in this district. It is the transportation hub of the city, as the Julius Nyerere International Airport, Central Railway Station and Tazara Railway Station are all within the district boundaries. The residential areas are mainly middle to high-income, and some of these are:
Temeke.
Temeke is the industrial district of the city, where the manufacturing centers (heavy and light industry) are located. The Port of Dar es Salaam, which is the largest in the country, is found here. Temeke is believed to have the largest concentration of low-income residents due to industry. Port officials, military and police officers live there.
Sports.
Dar es Salaam is the sports center of Tanzania. Dar es Salaam hosts the second largest stadium in East and Central Africa (National Stadium), which can accommodate up to 60,000 people. The city is home of soccer clubs,the Azam FC, Simba Sports Club (Simba) and Young Africans Sports Club (Yanga) and other teams.
Apart from the National Stadium, Dar es salaam is home to the Uhuru Stadium (used mainly for local tournaments and political gatherings), Karume Memorial Stadium (the home of Tanzania Football Federation (TFF)), the Gymkhana Golf Courses (between the city center and the shores of the Indian Ocean), and also has tennis courts, squash courts, and a Fitness club. Outside the metropolitan districts, there is the Lugalo Military Golf Course (located in the Lugalo Military Barracks).
Notable people.
Mr. Zakaria Maftah was appointed by the former Tanzanian President, the late Mwl.Julius Nyerere after the establishment of Anti-Corruption Squad (ACS) in 1975 - 1990.
Twin towns — sister cities.
Dar es Salaam is twinned with:

</doc>
<doc id="8501" url="https://en.wikipedia.org/wiki?curid=8501" title="Distributed computing">
Distributed computing

Distributed computing is a field of computer science that studies distributed systems. A "distributed system" is a software system in which components located on networked computers communicate and coordinate their actions by passing messages. The components interact with each other in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components. Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to peer-to-peer applications.
A computer program that runs in a distributed system is called a distributed program, and distributed programming is the process of writing such programs. There are many alternatives for the message passing mechanism, including pure HTTP, RPC-like connectors and message queues.
A goal and challenge pursued by some computer scientists and practitioners in distributed systems is location transparency; however, this goal has fallen out of favour in industry, as distributed systems are different from conventional non-distributed systems, and the differences, such as network partitions, partial system failures, and partial upgrades, cannot simply be "papered over" by attempts at "transparency" (see CAP theorem).
"Distributed computing" also refers to the use of distributed systems to solve computational problems. In "distributed computing", a problem is divided into many tasks, each of which is solved by one or more computers, which communicate with each other by message passing.
Introduction.
The word "distributed" in terms such as "distributed system", "distributed programming", and "distributed algorithm" originally referred to computer networks where individual computers were physically distributed within some geographical area. The terms are nowadays used in a much wider sense, even referring to autonomous processes that run on the same physical computer and interact with each other by message passing.
While there is no single definition of a distributed system, the following defining properties are commonly used:
In this article, the computational entities are called "computers" or "nodes".
A distributed system may have a common goal, such as solving a large computational problem. Alternatively, each computer may have its own user with individual needs, and the purpose of the distributed system is to coordinate the use of shared resources or provide communication services to the users.
Other typical properties of distributed systems include the following:
Parallel and distributed computing.
Distributed systems are groups of networked computers, which have the same goal for their work.
The terms "concurrent computing", "parallel computing", and "distributed computing" have a lot of overlap, and no clear distinction exists between them. The same system may be characterized both as "parallel" and "distributed"; the processors in a typical distributed system run concurrently in parallel. Parallel computing may be seen as a particular tightly coupled form of distributed computing, and distributed computing may be seen as a loosely coupled form of parallel computing. Nevertheless, it is possible to roughly classify concurrent systems as "parallel" or "distributed" using the following criteria:
The figure on the right illustrates the difference between distributed and parallel systems. Figure (a) is a schematic view of a typical distributed system; as usual, the system is represented as a network topology in which each node is a computer and each line connecting the nodes is a communication link. Figure (b) shows the same distributed system in more detail: each computer has its own local memory, and information can be exchanged only by passing messages from one node to another by using the available communication links. Figure (c) shows a parallel system in which each processor has a direct access to a shared memory.
The situation is further complicated by the traditional uses of the terms parallel and distributed "algorithm" that do not quite match the above definitions of parallel and distributed "systems" (see below for more detailed discussion). Nevertheless, as a rule of thumb, high-performance parallel computation in a shared-memory multiprocessor uses parallel algorithms while the coordination of a large-scale distributed system uses distributed algorithms.'"
History.
The use of concurrent processes that communicate by message-passing has its roots in operating system architectures studied in the 1960s. The first widespread distributed systems were local-area networks such as Ethernet, which was invented in the 1970s.
ARPANET, the predecessor of the Internet, was introduced in the late 1960s, and ARPANET e-mail was invented in the early 1970s. E-mail became the most successful application of ARPANET, and it is probably the earliest example of a large-scale distributed application. In addition to ARPANET, and its successor, the Internet, other early worldwide computer networks included Usenet and FidoNet from the 1980s, both of which were used to support distributed discussion systems.
The study of distributed computing became its own branch of computer science in the late 1970s and early 1980s. The first conference in the field, Symposium on Principles of Distributed Computing (PODC), dates back to 1982, and its European counterpart International Symposium on Distributed Computing (DISC) was first held in 1985.
Architectures.
Various hardware and software architectures are used for distributed computing. At a lower level, it is necessary to interconnect multiple CPUs with some sort of network, regardless of whether that network is printed onto a circuit board or made up of loosely coupled devices and cables. At a higher level, it is necessary to interconnect processes running on those CPUs with some sort of communication system.
Distributed programming typically falls into one of several basic architectures: client–server, three-tier, "n"-tier, or peer-to-peer; or categories: loose coupling, or tight coupling.
Another basic aspect of distributed computing architecture is the method of communicating and coordinating work among concurrent processes. Through various message passing protocols, processes may communicate directly with one another, typically in a master/slave relationship. Alternatively, a "database-centric" architecture can enable distributed computing to be done without any form of direct inter-process communication, by utilizing a shared database.
Applications.
Reasons for using distributed systems and distributed computing may include:
Ghaemi "et al." define a distributed query as a query "that selects data from databases located at multiple sites in a network" and offer as an SQL example:
Examples.
Examples of distributed systems and applications of distributed computing include the following:
Theoretical foundations.
Models.
Many tasks that we would like to automate by using a computer are of question–answer type: we would like to ask a question and the computer should produce an answer. In theoretical computer science, such tasks are called computational problems. Formally, a computational problem consists of "instances" together with a "solution" for each instance. Instances are questions that we can ask, and solutions are desired answers to these questions.
Theoretical computer science seeks to understand which computational problems can be solved by using a computer (computability theory) and how efficiently (computational complexity theory). Traditionally, it is said that a problem can be solved by using a computer if we can design an algorithm that produces a correct solution for any given instance. Such an algorithm can be implemented as a computer program that runs on a general-purpose computer: the program reads a problem instance from input, performs some computation, and produces the solution as output. Formalisms such as random access machines or universal Turing machines can be used as abstract models of a sequential general-purpose computer executing such an algorithm.
The field of concurrent and distributed computing studies similar questions in the case of either multiple computers, or a computer that executes a network of interacting processes: which computational problems can be solved in such a network and how efficiently? However, it is not at all obvious what is meant by "solving a problem" in the case of a concurrent or distributed system: for example, what is the task of the algorithm designer, and what is the concurrent or distributed equivalent of a sequential general-purpose computer?
The discussion below focuses on the case of multiple computers, although many of the issues are the same for concurrent processes running on a single computer.
Three viewpoints are commonly used:
In the case of distributed algorithms, computational problems are typically related to graphs. Often the graph that describes the structure of the computer network "is" the problem instance. This is illustrated in the following example.
An example.
Consider the computational problem of finding a coloring of a given graph "G". Different fields might take the following approaches:
While the field of parallel algorithms has a different focus than the field of distributed algorithms, there is a lot of interaction between the two fields. For example, the Cole–Vishkin algorithm for graph coloring was originally presented as a parallel algorithm, but the same technique can also be used directly as a distributed algorithm.
Moreover, a parallel algorithm can be implemented either in a parallel system (using shared memory) or in a distributed system (using message passing). The traditional boundary between parallel and distributed algorithms (choose a suitable network vs. run in any given network) does not lie in the same place as the boundary between parallel and distributed systems (shared memory vs. message passing).
Complexity measures.
In parallel algorithms, yet another resource in addition to time and space is the number of computers. Indeed, often there is a trade-off between the running time and the number of computers: the problem can be solved faster if there are more computers running in parallel (see speedup). If a decision problem can be solved in polylogarithmic time by using a polynomial number of processors, then the problem is said to be in the class NC. The class NC can be defined equally well by using the PRAM formalism or Boolean circuits—PRAM machines can simulate Boolean circuits efficiently and vice versa.
In the analysis of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a synchronous system where all nodes operate in a lockstep fashion. During each "communication round", all nodes in parallel (1) receive the latest messages from their neighbours, (2) perform arbitrary local computation, and (3) send new messages to their neighbours. In such systems, a central complexity measure is the number of synchronous communication rounds required to complete the task.
This complexity measure is closely related to the diameter of the network. Let "D" be the diameter of the network. On the one hand, any computable problem can be solved trivially in a synchronous distributed system in approximately 2"D" communication rounds: simply gather all information in one location ("D" rounds), solve the problem, and inform each node about the solution ("D" rounds).
On the other hand, if the running time of the algorithm is much smaller than "D" communication rounds, then the nodes in the network must produce their output without having the possibility to obtain information about distant parts of the network. In other words, the nodes must make globally consistent decisions based on information that is available in their "local neighbourhood". Many distributed algorithms are known with the running time much smaller than "D" rounds, and understanding which problems can be solved by such algorithms is one of the central research questions of the field.
Other commonly used measures are the total number of bits transmitted in the network (cf. communication complexity).
Other problems.
Traditional computational problems take the perspective that we ask a question, a computer (or a distributed system) processes the question for a while, and then produces an answer and stops. However, there are also problems where we do not want the system to ever stop. Examples of such problems include the dining philosophers problem and other similar mutual exclusion problems. In these problems, the distributed system is supposed to continuously coordinate the use of shared resources so that no conflicts or deadlocks occur.
There are also fundamental challenges that are unique to distributed computing. The first example is challenges that are related to "fault-tolerance". Examples of related problems include consensus problems, Byzantine fault tolerance, and self-stabilisation.
A lot of research is also focused on understanding the "asynchronous" nature of distributed systems:
Properties of distributed systems.
So far the focus has been on "designing" a distributed system that solves a given problem. A complementary research problem is "studying" the properties of a given distributed system.
The halting problem is an analogous example from the field of centralised computation: we are given a computer program and the task is to decide whether it halts or runs forever. The halting problem is undecidable in the general case, and naturally understanding the behaviour of a computer network is at least as hard as understanding the behaviour of one computer.
However, there are many interesting special cases that are decidable. In particular, it is possible to reason about the behaviour of a network of finite-state machines. One example is telling whether a given network of interacting (asynchronous and non-deterministic) finite-state machines can reach a deadlock. This problem is PSPACE-complete, i.e., it is decidable, but it is not likely that there is an efficient (centralised, parallel or distributed) algorithm that solves the problem in the case of large networks.
Coordinator election.
"Coordinator election" (sometimes called "leader election") is the process of designating a single process as the organizer of some task distributed among several computers (nodes). Before the task is begun, all network nodes are either unaware which node will serve as the "coordinator" (or leader) of the task, or unable to communicate with the current coordinator. After a coordinator election algorithm has been run, however, each node throughout the network recognizes a particular, unique node as the task coordinator.
The network nodes communicate among themselves in order to decide which of them will get into the "coordinator" state. For that, they need some method in order to break the symmetry among them. For example, if each node has unique and comparable identities, then the nodes can compare their identities, and decide that the node with the highest identity is the coordinator.
The definition of this problem is often attributed to LeLann, who formalized it as a method to create a new token in a token ring network in which the token has been lost.
Coordinator election algorithms are designed to be economical in terms of total bytes transmitted, and time. The algorithm suggested by Gallager, Humblet, and Spira for general undirected graphs has had a strong impact on the design of distributed algorithms in general, and won the Dijkstra Prize for an influential paper in distributed computing.
Many other algorithms were suggested for different kind of network graphs, such as undirected rings, unidirectional rings, complete graphs, grids, directed Euler graphs, and others. A general method that decouples the issue of the graph family from the design of the coordinator election algorithm was suggested by Korach, Kutten, and Moran.
In order to perform coordination, distributed systems employ the concept of coordinators. The coordinator election problem is to choose a process from among a group of processes on different processors in a distributed system to act as the central coordinator. Several central coordinator election algorithms exist.
Bully algorithm.
When using the Bully algorithm, any process sends a message to the current coordinator. If there is no response within a given time limit, the process tries to elect itself as leader.
Chang and Roberts algorithm.
The Chang and Roberts algorithm (or "Ring Algorithm") is a ring-based election algorithm used to find a process with the largest unique identification number.

</doc>
<doc id="8504" url="https://en.wikipedia.org/wiki?curid=8504" title="Dublin">
Dublin

Dublin (, ) is the capital and largest city of Ireland. Dublin is in the province of Leinster on Ireland's east coast, at the mouth of the River Liffey. The city has an urban area population of 1,273,069. The population of the Greater Dublin Area, , was 1,801,040 persons.
Founded as a Viking settlement, the Kingdom of Dublin became Ireland's principal city following the Norman invasion. The city expanded rapidly from the 17th century and was briefly the second largest city in the British Empire before the Acts of Union in 1800. Following the partition of Ireland in 1922, Dublin became the capital of the Irish Free State, later renamed Ireland.
Dublin is administered by a City Council. The city is listed by the Globalization and World Cities Research Network (GaWC) as a global city, with a ranking of "Alpha-", placing it among the top thirty cities in the world. It is a historical and contemporary centre for education, the arts, administration, economy and industry.
History.
Toponymy.
Although the area of Dublin Bay has been inhabited by humans since prehistoric times, the writings of Ptolemy (the Greco-Roman astronomer and cartographer) in about 140 AD provide possibly the earliest reference to a settlement there. He called the settlement "Eblana polis" ().
Dublin celebrated its 'official' millennium in 1988 AD, meaning that the Irish government recognised 988 AD as the year in which the city was settled and that this first settlement would later become the city of Dublin.
The name "Dublin" comes from the Gaelic word "Dublind", early Classical Irish "Dubhlind"/"Duibhlind", "dubh" /d̪uβ/, alt. /d̪uw/, alt /d̪u:/ meaning "black, dark", and "lind" /lʲiɲ[d̪ʲ] "pool", referring to a dark tidal pool where the River Poddle entered the Liffey on the site of the Castle Gardens at the rear of Dublin Castle. In Modern Irish the name is "Duibhlinn", and Irish rhymes from Dublin County show that in Dublin Leinster Irish it was pronounced "Duílinn" /d̪ˠi:lʲiɲ/. The original pronunciation is preserved in the names for the city in other languages such as Old English "Difelin", Old Norse "Dyflin", modern Icelandic "Dyflinn" and modern Manx "Divlyn" as well as Welsh "Dulyn". Other localities in Ireland also bear the name "Duibhlinn", variously anglicized as Devlin, Divlin and Difflin. Historically, scribes using the Gaelic script wrote "bh" with a dot over the "b", rendering Duḃlinn or Duiḃlinn. Those without knowledge of Irish omitted the dot, spelling the name as "Dublin". Variations on the name are also found in traditionally Gaelic-speaking areas (the Gàidhealtachd, cognate with Irish Gaeltacht) of Scotland, such as "An Linne Dhubh" ("the black pool"), which is part of Loch Linnhe.
It is now thought that the Viking settlement was preceded by a Christian ecclesiastical settlement known as "Duibhlinn", from which "Dyflin" took its name. Beginning in the 9th and 10th century, there were two settlements where the modern city stands. The Viking settlement of about 841 was known as "Dyflin", from the Irish "Duibhlinn", and a Gaelic settlement, Áth Cliath ("ford of hurdles") was further up river, at the present day Father Mathew Bridge (also known as Dublin Bridge), at the bottom of Church Street. ', meaning "town of the hurdled ford", is the common name for the city in modern Irish. ' is a place name referring to a fording point of the River Liffey near Father Mathew Bridge. "" was an early Christian monastery, believed to have been in the area of Aungier Street, currently occupied by Whitefriar Street Carmelite Church. There are other towns of the same name, such as "Àth Cliath" in East Ayrshire, Scotland, which is Anglicised as Hurlford.
The subsequent Scandinavian settlement centred on the River Poddle, a tributary of the Liffey in an area now known as Wood Quay. The Dubhlinn was a small lake used to moor ships; the Poddle connected the lake with the Liffey. This lake was covered during the early 18th century as the city grew. The Dubhlinn lay where the Castle Garden is now located, opposite the Chester Beatty Library in Dublin Castle. "Táin Bó Cuailgne" ("The Cattle Raid of Cooley") refers to "Dublind rissa ratter Áth Cliath", meaning "Dublin, which is called Ath Cliath".
Middle Ages.
Dublin was established as a Viking settlement in the 10th century and, despite a number of rebellions by the native
Irish, it remained largely under Viking control until the Norman invasion of Ireland was launched from Wales in 1169. The King of Leinster, Diarmait Mac Murchada, enlisted the help of Strongbow, the Earl of Pembroke, to conquer Dublin. Following Mac Murrough's death, Strongbow declared himself King of Leinster after gaining control of the city. In response to Strongbow's successful invasion, King Henry II of England reaffirmed his sovereignty by mounting a larger invasion in 1171 and pronounced himself Lord of Ireland. Around this time, the county of the City of Dublin was established along with certain liberties adjacent to the city proper. This continued down to 1840 when the barony of Dublin City was separated from the barony of Dublin. Since 2001, both baronies have been redesignated the City of Dublin.
Dublin Castle, which became the centre of Norman power in Ireland, was founded in 1204 as a major defensive work on the orders of King John of England. Following the appointment of the first Lord Mayor of Dublin in 1229, the city expanded and had a population of 8,000 by the end of the 13th century. Dublin prospered as a trade centre, despite an attempt by King Robert I of Scotland to capture the city in 1317. It remained a relatively small walled medieval town during the 14th century and was under constant threat from the surrounding native clans. In 1348, the Black Death, a lethal plague which had ravaged Europe, took hold in Dublin and killed thousands over the following decade.
Dublin was incorporated into the English Crown as the Pale, which was a narrow strip of English settlement along the eastern seaboard. The Tudor conquest of Ireland in the 16th century spelt a new era for
Dublin, with the city enjoying a renewed prominence as the centre of administrative rule in Ireland. Determined to make Dublin a Protestant city, Queen Elizabeth I of England established Trinity College in 1592 as a solely Protestant university and ordered that the Catholic St. Patrick's and Christ Church cathedrals be converted to Protestant.
The city had a population of 21,000 in 1640 before a plague in 1649–51 wiped out almost half of the city's inhabitants. However, the city prospered again soon after as a result of the wool and linen trade with England, reaching a population of over 50,000 in 1700.
Early modern.
As the city continued to prosper during the 18th century, Georgian Dublin became, for a short period, the second largest city of the British Empire and the fifth largest city in Europe, with the population exceeding 130,000. The vast majority of Dublin's most notable architecture dates from this period, such as the Four Courts and the Custom House. Temple Bar and Grafton Street are two of the few remaining areas that were not affected by the wave of Georgian reconstruction and maintained their medieval character.
Dublin grew even more dramatically during the 18th century, with the construction of many famous districts and buildings, such as Merrion Square, Parliament House and the Royal Exchange. The Wide Streets Commission was established in 1757 at the request of Dublin Corporation to govern architectural standards on the layout of streets, bridges and buildings. In 1759, the founding of the Guinness brewery resulted in a considerable economic gain for the city. For much of the time since its foundation, the brewery was Dublin's largest employer.
Late modern and contemporary.
Dublin suffered a period of political and economic decline during the 19th century following the Act of Union of 1800, under which the seat of government was transferred to the Westminster Parliament in London. The city played no major role in the Industrial Revolution, but remained the centre of administration and a transport hub for most of the island. Ireland had no significant sources of coal, the fuel of the time, and Dublin was not a centre of ship manufacturing, the other main driver of industrial development in Britain and Ireland. Belfast developed faster than Dublin during this period on a mixture of international trade, factory-based linen cloth production and shipbuilding.
The Easter Rising of 1916, the Irish War of Independence, and the subsequent Irish Civil War resulted in a significant amount of physical destruction in central Dublin. The Government of the Irish Free State rebuilt the city centre and located the new parliament, the Oireachtas, in Leinster House. Since the beginning of Norman rule in the 12th century, the city has functioned as the capital in varying geopolitical entities: Lordship of Ireland (1171–1541), Kingdom of Ireland (1541–1800), island as part of the United Kingdom of Great Britain and Ireland (1801–1922), and the Irish Republic (1919–1922). Following the partition of Ireland in 1922, it became the capital of the Irish Free State (1922–1937) and now is the capital of Ireland. One of the memorials to commemorate that time is the Garden of Remembrance.
Dublin was also victim to the Northern Irish Troubles. While during this 30 year conflict, violence mainly engulfed Northern Ireland. However, the Provisional IRA drew a lot of support from the Republic, specifically Dublin. This caused a Loyalist paramilitary group the Ulster Volunteer Force to bomb the city. The most notable of atrocities carried out by loyalists during this time was the Dublin and Monaghan bombings in which 34 people died, mainly in Dublin itself.
Since 1997, the landscape of Dublin has changed immensely. The city was at the forefront of Ireland's rapid economic expansion during the Celtic Tiger period, with enormous private sector and state development of housing, transport and business.
Government.
Local.
From 1842, the boundaries of the city were comprehended by the baronies of Dublin City and the Barony of Dublin. In 1930, the boundaries were extended by the Local Government (Dublin) Act. Later, in 1953, the boundaries were again extended by the Local Government Provisional Order Confirmation Act.
Dublin City Council is a unicameral assembly of 63 members elected every five years from Local Election Areas. It is presided over by the Lord Mayor, who is elected for a yearly term and resides in Mansion House. Council meetings occur at Dublin City Hall, while most of its administrative activities are based in the Civic Offices on Wood Quay. The party or coalition of parties, with the majority of seats adjudicates committee members, introduces policies, and appoints the Lord Mayor. The Council passes an annual budget for spending on areas such as housing, traffic management, refuse, drainage, and planning. The Dublin City Manager is responsible for implementing City Council decisions.
National.
As the capital city, Dublin seats the national parliament of Ireland, the Oireachtas. It is composed of the President of Ireland, Seanad Éireann as the upper house, and Dáil Éireann as the lower house. The President resides in Áras an Uachtaráin in the Phoenix Park, while both houses of the Oireachtas meet in Leinster House, a former ducal palace on Kildare Street. It has been the home of the Irish parliament since the creation of the Irish Free State in 1922. The old Irish Houses of Parliament of the Kingdom of Ireland are located in College Green.
Government Buildings house the Department of the Taoiseach, the Council Chamber, the Department of Finance and the Office of the Attorney General. It consists of a main building (completed 1911) with two wings (completed 1921). It was designed by Thomas Manley Dean and Sir Aston Webb as the Royal College of Science. The First Dáil originally met in the Mansion House in 1919. The Irish Free State government took over the two wings of the building to serve as a temporary home for some ministries, while the central building became the College of Technology until 1989. Although both it and Leinster House were intended to be temporary, they became the permanent homes of parliament from then on.
For elections to Dáil Éireann the city is divided into five constituencies: Dublin Central (3 seats), Dublin Bay North (5 seats), Dublin North–West (3 seats), Dublin South–Central (4 seats) and Dublin Bay South (4 seats). Nineteen TD's are elected in total.
Politics.
In the past Dublin city was regarded as a stronghold for Fianna Fáil, however following the Irish local elections, 2004 the party was eclipsed by the centre-left Labour Party. In the 2011 general election the Dublin Region elected 18 Labour Party, 17 Fine Gael, 4 Sinn Féin, 2 Socialist Party, 2 People Before Profit Alliance and 3 Independent TDs. Fianna Fáil lost all but one of its sitting TDs in the region.
Geography.
Landscape.
Dublin is situated at the mouth of the River Liffey and encompasses a land area of approximately 44 sq mi, or 115 km2, in east-central Ireland. It is bordered by a low mountain range to the south and surrounded by flat farmland to the north and west. The
Liffey divides the city in two between the Northside and the Southside. Each of these is further divided by two lesser rivers – the River Tolka running southeast into Dubin Bay, and the River Dodder running northeast to the mouth of the Liffey. Two further water bodies – the Grand Canal on the southside and the Royal Canal on the northside – ring the inner city on their way from the west and the River Shannon.
The River Liffey bends at Leixlip from a northeasterly route to a predominantly eastward direction, and this point also marks the transition to urban development from more agricultural land usage.
Cultural divide.
A north-south division did traditionally exist, with the River Liffey as the divider. The Northside was generally seen as working class, while the Southside was seen as middle to upper-middle class. The divide was punctuated by examples of Dublin "sub-culture" stereotypes, with upper-middle class constituents seen as tending towards an accent and demeanour synonymous with the Southside, and working-class Dubliners seen as tending towards characteristics associated with Northside and inner-city areas. Dublin's economic divide was also previously an east-west as well as a north-south. There were also social divisions evident between the coastal suburbs in the east of the city, including those on the Northside, and the newer developments further to the west.
Climate.
Similar to much of the rest of northwestern Europe, Dublin experiences a maritime climate ("Cfb") with cool summers, mild winters, and a lack of temperature extremes. The average maximum January temperature is , while the average maximum July temperature is . On average, the sunniest months are May and June, while the wettest month is October with of rain, and the driest month is February with . Rainfall is evenly distributed throughout the year.
Ringsend in the south of the city records the least amount of rainfall in Ireland, with an average annual precipitation of , with the average annual precipitation in the city centre being . The main precipitation in winter is rain; however snow showers do occur between November and March. Hail is more common than snow. The city experiences long summer days and short winter days. Strong Atlantic winds are most common in autumn. These winds can affect Dublin, but due to its easterly location it is least affected compared to other parts of the country. However, in winter, easterly winds render the city colder and more prone to snow showers.
Quarters.
Dublin city is divided into several quarters or districts.
Medieval Quarter
This is the oldest part of the city, which includes Dublin Castle, Christ Church and St Patrick's Cathedral along with the old city walls. It was part of the Dubh Linn settlement, this area became the home for the Vikings in Dublin.
Georgian Quarter
Dublin is renowned for its Georgian architecture. It boasts some of the world's finest Georgian buildings. It starts at St Stephen's Green and Trinity College up to the canal. Merrion Square, Saint Stephen's Green and Fitzwilliam Square are examples of this style of architecture.
Docklands Quarter
This area is Dublin Docklands which includes "Silicon Docks", Dublin's Tech Quarter located in the Grand Canal Dock area. Global giants such as Google, Facebook, Accenture and Twitter are based there. It used to be a derelict part of the city, but has undergone revitalisation with the development of offices and apartments.
Cultural Quarter
Temple Bar is at the heart of Dublin's social and cultural life. It was once derelict but was then revitalized in the 1990s.
Creative Quarter
It is the newest district, created in 2012. It covers the area from South William Street to George's Street, and from Lower Stephen's Street to Exchequer Street. Its a hub of design, creativity and innovation.
Places of interest.
Landmarks.
Dublin has many landmarks and monuments dating back hundreds of years. One of the oldest is Dublin Castle, which was first founded as a major defensive work on the orders of King John of England in 1204, shortly after the Norman invasion of Ireland in 1169, when it was commanded that a castle be built with strong walls and good ditches for the defence of the city, the administration of justice, and the protection of the King's treasure. Largely complete by 1230, the castle was of typical Norman courtyard design, with a central square without a keep, bounded on all sides by tall defensive walls and protected at each corner by a circular tower. Sited to the south-east of Norman Dublin, the castle formed one corner of the outer perimeter of the city, using the River Poddle as a natural means of defence.
One of Dublin's newest monuments is the Spire of Dublin, or officially titled "Monument of Light". It is a conical spire made of stainless steel and is located on O'Connell Street. It replaces Nelson's Pillar and is intended to mark Dublin's place in the 21st century. The spire was designed by Ian Ritchie Architects, who sought an "Elegant and dynamic simplicity bridging art and technology". During the day it maintains its steel look, but at dusk the monument appears to merge into the sky. The base of the monument is lit and the top is illuminated to provide a beacon in the night sky across the city.
Many people visit Trinity College, Dublin to see the Book of Kells in the library there. The Book of Kells is an illustrated manuscript created by Irish monks circa. 800 AD. The Ha'penny Bridge; an old iron footbridge over the River Liffey is one of the most photographed sights in Dublin and is considered to be one of Dublin's most iconic landmarks.
Other popular landmarks and monuments include the Mansion House, the Anna Livia monument, the Molly Malone statue, Christ Church Cathedral, St Patrick's Cathedral, Saint Francis Xavier Church on Upper Gardiner Street near Mountjoy Square, The Custom House, and Áras an Uachtaráin. The Poolbeg Towers are also iconic features of Dublin and are visible in many spots around the city.
Parks.
Dublin has more green spaces per square kilometre than any other European capital city, with 97% of city residents living within 300 metres of a park area. The city council provides of public green space per 1,000 people and 255 playing fields. The council also plants approximately 5,000 trees annually and manages over of parks.
There are many park areas around the city, including the Phoenix Park, Herbert Park and St Stephen's Green. The Phoenix Park is about west of the city centre, north of the River Liffey. Its perimeter wall encloses , making it one of the largest walled city parks in Europe. It includes large areas of grassland and tree-lined avenues, and since the 17th century has been home to a herd of wild Fallow deer. The residence of the President of Ireland (Áras an Uachtaráin), which was built in 1751, is located in the park. The park is also home to Dublin Zoo, the official residence of the United States Ambassador, and Ashtown Castle. Music concerts have also been performed in the park by many singers and musicians.
St Stephen's Green is adjacent to one of Dublin's main shopping streets, Grafton Street, and to a shopping centre named for it, while on its surrounding streets are the offices of a number of public bodies and the city terminus of one of Dublin's Luas tram lines. Saint Anne's Park is a public park and recreational facility, shared between Raheny and Clontarf, both suburbs on the North Side of Dublin.
The park, the second largest municipal park in Dublin, is part of a former estate assembled by members of the Guinness family, beginning with Benjamin Lee Guinness in 1835 (the largest municipal park is nearby (North) Bull Island, also shared between Clontarf and Raheny).
Economy.
The Dublin region is the economic centre of Ireland, and was at the forefront of the country's rapid economic expansion during the Celtic Tiger period. In 2009, Dublin was listed as the fourth richest city in the world by purchasing power and 10th richest by personal income. According to "Mercer's 2011 Worldwide Cost of Living Survey", Dublin is the 13th most expensive city in the European Union (down from 10th in 2010) and the 58th most expensive place to live in the world (down from 42nd in 2010). , approximately 800,000 people were employed in the Greater Dublin Area, of whom around 600,000 were employed in the services sector and 200,000 in the industrial sector.
Many of Dublin's traditional industries, such as food processing, textile manufacturing, brewing, and distilling have gradually declined, although Guinness has been brewed at the St. James's Gate Brewery since 1759. Economic improvements in the 1990s have attracted a large number of global pharmaceutical, information and communications technology companies to the city and Greater Dublin Area. Companies such as Microsoft, Google, Amazon, eBay, PayPal, Yahoo!, Facebook, Twitter, Accenture and Pfizer now have European headquarters and/or operational bases in the city.
Financial services have also become important to the city since the establishment of Dublin's International Financial Services Centre in 1987, which is globally recognised as a leading location for a range of internationally traded financial services. More than 500 operations are approved to trade in under the IFSC programme. The centre is host to half of the world's top 50 banks and to half of the top 20 insurance companies. Many international firms have established major headquarters in the city, such as Citibank and Commerzbank. The Irish Stock Exchange (ISEQ), Internet Neutral Exchange (INEX) and Irish Enterprise Exchange (IEX) are also located in Dublin. The economic boom led to a sharp increase in construction, with large redevelopment projects in the Dublin Docklands and Spencer Dock. Completed projects include the Convention Centre, the 3Arena, and the Bord Gáis Energy Theatre and Silicon Docks.
Transport.
Road.
The road network in Ireland is primarily focused on Dublin. The M50 motorway, a semi-ring road which runs around the south, west and north of the city, connects important national primary routes to the rest of the country. In 2008, the West-Link toll bridge was replaced by the eFlow barrier-free tolling system, with a three-tiered charge system based on electronic tags and car pre-registration. The toll is currently €2.10 for vehicles with a pre-paid tag, €2.60 for vehicles whose number plates have been registered with eFlow, and €3.10 for unregistered vehicles.
The first phase of a proposed eastern bypass for the city is the Dublin Port Tunnel, which officially opened in 2006 to mainly cater for heavy vehicles. The tunnel connects Dublin Port and the M1 motorway close to Dublin Airport. The city is also surrounded by an inner and outer orbital route. The inner orbital route runs approximately around the heart of the Georgian city and the outer orbital route runs primarily along the natural circle formed by Dublin's two canals, the Grand Canal and the Royal Canal, as well as the North and South Circular Roads.
Dublin is served by an extensive network of nearly 200 bus routes which serve all areas of the city and suburbs. The majority of these are controlled by Dublin Bus, but a number of smaller companies also operate. Fares are generally calculated on a stage system based on distance travelled. There are several different levels of fares, which apply on most services. A "Real Time Passenger Information" system was introduced at Dublin Bus bus stops in 2012. Electronically displayed signs relay information about the time of the next bus' arrival based on its GPS determined position. The National Transport Authority is responsible for integration of bus and rail services in Dublin and has been involved in introducing a pre-paid smart card, called a Leap card, which can be used on Dublin's public transport services.
Rail and tram.
Heuston and Connolly stations are the two main railway stations in Dublin. Operated by Iarnród Éireann, the Dublin Suburban Rail network consists of five railway lines serving the Greater Dublin Area and commuter towns such as Drogheda and Dundalk in County Louth. One of these lines is the electrified Dublin Area Rapid Transit (DART) line, which runs primarily along the coast of Dublin, comprising a total of 31 stations, from Malahide and Howth southwards as far as Greystones in County Wicklow. Commuter rail operates on the other four lines using Irish Rail diesel multiple units. In 2013, passengers for DART and Dublin Suburban lines were 16 million and 11.7 million, respectively (around 75% of all Irish Rail passengers).
The Luas is a light rail system, run by Veolia Transport, has been operating since 2004 and now carries over 30 million passengers annually. The network consists of two tram lines; the Red Line links the Docklands and city centre with the south-western suburbs, while the Green Line connects the city centre with suburbs to the south of the city and together comprise a total 54 stations and of track. Construction of a 6 km extension to the Green Line, bringing it to the north of the city, commenced in June 2013.
Proposed multibillion-euro projects such as the Dublin Metro and the DART Underground will also be considered.
Rail and ferry.
Dublin Connolly is connected by bus to Dublin Port and ferries run by Irish Ferries and Stena Line to Holyhead for connecting trains on the North Wales Coast Line to Chester, Crewe and London Euston.
Dublin Connolly to Dublin Port can be reached by walking beside the tram lines around the corner from Amiens Street, Dublin into Store Street or by Luas one stop to Busáras where Dublin Bus operates a service to the Ferry Terminal, or Dublin Bus route 53 or to take a taxi.
Airport.
Dublin Airport is operated by the Dublin Airport Authority and is located north of Dublin City in the administrative county of Fingal. It is the headquarters of Ireland's flag carrier Aer Lingus, low-cost carrier Ryanair, and regional airlines Stobart Air and CityJet. The airport offers an extensive short and medium haul network, as well as domestic services to many regional airports in Ireland. There are also extensive Long Haul services to the United States, Canada and the Middle East. Dublin Airport is the busiest airport in Ireland, followed by Cork and Shannon. Construction of a second terminal began in 2007 and was officially opened on 19 November 2010.
Dublin Airport currently ranks as the 18th busiest airport in Europe recording over 25 million passengers during 2015, and has been showing a very strong growth in passenger numbers in recent years, particularly in long haul routes. Dublin is now ranked 6th in Europe as a hub for transatlantic passengers, with 158 flights a week to the US, ahead of much bigger airports such as Istanbul and Rome.
Cycling.
Dublin City Council began installing cycle lanes and tracks throughout the city in the 1990s, and the city has over of specific on- and off-road tracks for cyclists. In 2011, the city was ranked 9th of major world cities on the "Copenhagenize Index of Bicycle-Friendly Cities".
Dublinbikes is a self-service bicycle rental scheme which has been in operation in Dublin since 2009. Sponsored by JCDecaux, the scheme consists of 550 French-made unisex bicycles stationed at 44 terminals throughout the city centre. Users must make a subscription for either an annual Long Term Hire Card costing €20 or a 3 Day Ticket costing €2. The first 30 minutes of use is free, but after that a service charge depending on the extra length of use applies. Dublinbikes now has over 58,000 subscribers and there are plans to dramatically expand the service across the city and its suburbs to provide for up to 5,000 bicycles and approximately 300 terminals.
The 2011 Census revealed that 5.9 percent of commuters in Dublin cycled. A 2013 report by Dublin City Council on traffic flows crossing the canals in and out of the city found that just under 10% of all traffic was made up of cyclists, representing an increase of 14.1% over 2012 and a 87.2% increase over 2006 levels and is attributed to measures, such as, the Dublinbikes bike rental scheme, the provision of cycle lanes, public awareness campaigns to promote cycling and the introduction of the 30kph city centre speed limit.
Higher education.
Dublin is the primary centre of education in Ireland, it is home to three universities, Dublin Institute of Technology and many other higher education institutions. There are 20 third-level institutes in the city and in surrounding towns and suburbs.
Dublin was European Capital of Science in 2012. The University of Dublin is the oldest university in Ireland dating from the 16th century, and is located in the city centre. Its sole constituent college, Trinity College, was established by Royal Charter in 1592 under Elizabeth I and was closed to Roman Catholics until Catholic Emancipation. The Catholic hierarchy then banned Roman Catholics from attending it until 1970. It is situated in the city centre, on College Green, and has 15,000 students.
The National University of Ireland (NUI) has its seat in Dublin, which is also the location of the associated "constituent university" of University College Dublin (UCD), has over 30,000 students. UCD's main campus is at Belfield, about from the city centre in the southeastern suburbs.
With a continuous history dating back to 1887, Dublin's principal institution for technological education and research Dublin Institute of Technology (DIT) with over 23,000 students. Dublin Institute of Technology specialises in engineering, architecture, sciences, health, digital media, hospitality and business but also offers many art, design, music and humanities programmes. DIT currently has campuses, buildings and research facilities at multiple locations in central Dublin, it has commenced consolidation to a new city-centre campus in Grangegorman.
Dublin City University (DCU), formerly known as the National Institute for Higher Education (NIHE), specialises in business, engineering, science, and communication courses. It has around 10,000 students, and is located about from the city centre in the northern suburbs.
The Royal College of Surgeons in Ireland (RCSI) is a medical school which is a recognised college of the NUI, it is situated at St. Stephen's Green in the city centre.
The National University of Ireland, Maynooth, another constituent of the NUI, is in neighbouring Co. Kildare, about from the city centre. The Institute of European Affairs is also in Dublin.
Portobello College has its degrees conferred through the University of Wales. Dublin Business School (DBS) is Ireland's largest private third level institution with over 9,000 students located on Aungier Street.
The National College of Art and Design (NCAD) supports training and research in art, design and media. The National College of Ireland (NCI) is also based in Dublin. The Economic and Social Research Institute, a social science research institute, is based on Sir John Rogerson's Quay, Dublin 2.
The Irish public administration and management training centre has its base in Dublin, the Institute of Public Administration provides a range of undergraduate and post graduate awards via the National University of Ireland and in some instances, Queen's University Belfast. There are also smaller specialised colleges, including Griffith College Dublin, The Gaiety School of Acting and the New Media Technology College.
Outside of the city, the towns of Tallaght in South Dublin and Dún Laoghaire in Dún Laoghaire–Rathdown have regional colleges:
The Institute of Technology, Tallaght has full and part-time courses in a wide range of technical subjects and the Dún Laoghaire Institute of Art, Design and Technology (IADT) supports training and research in art, design, business, psychology and media technology.
The western suburb of Blanchardstown offers childcare and sports management courses along with languages and technical subjects at the Institute of Technology, Blanchardstown.
Demographics.
The City of Dublin is the area administered by Dublin City Council, but the term "Dublin" normally refers to the contiguous urban area which includes parts of the adjacent local authority areas of Dún Laoghaire–Rathdown, Fingal and South Dublin. Together, the four areas form the traditional County Dublin. This area is sometimes known as the Dublin Region. The population of the administrative area controlled by the City Council was 525,383 in the 2011 census, while the population of the urban area was 1,110,627. The County Dublin population was 1,273,069 and that of the Greater Dublin Area 1,804,156. The area's population is expanding rapidly, and it is estimated by the Central Statistics Office that it will reach 2.1 million by 2020.
Since the late 1990s, Dublin has experienced a significant level of net immigration, with the greatest numbers coming from the European Union, especially the United Kingdom, Poland and Lithuania. There is also a considerable number of immigrants from outside Europe, particularly from India, Pakistan, China and Nigeria. Dublin is home to a greater proportion of new arrivals than any other part of the country. Sixty percent of Ireland's Asian population lives in Dublin. Over 15% of Dublin's population was foreign-born in 2006.
The capital attracts the largest proportion of non-Catholic migrants from other countries. Increased secularization in Ireland has prompted a drop in regular Catholic church attendance in Dublin from over 90 percent in the mid-1970s down to 14 percent according to a 2011 survey.
Culture.
The arts.
Dublin has a world-famous literary history, having produced many prominent literary figures, including Nobel laureates William Butler Yeats, George Bernard Shaw and Samuel Beckett. Other influential writers and playwrights include Oscar Wilde, Jonathan Swift and the creator of Dracula, Bram Stoker. It is arguably most famous as the location of the greatest works of James Joyce, including "Ulysses", which is set in Dublin and full of topical detail. "Dubliners" is a collection of short stories by Joyce about incidents and typical characters of the city during the early 20th century. Other renowned writers include J. M. Synge, Seán O'Casey, Brendan Behan, Maeve Binchy, and Roddy Doyle. Ireland's biggest libraries and literary museums are found in Dublin, including the National Print Museum of Ireland and National Library of Ireland. In July 2010, Dublin was named as a UNESCO City of Literature, joining Edinburgh, Melbourne and Iowa City with the permanent title.
There are several theatres within the city centre, and various world famous actors have emerged from the Dublin theatrical scene, including Noel Purcell, Sir Michael Gambon, Brendan Gleeson, Stephen Rea, Colin Farrell, Colm Meaney and Gabriel Byrne. The best known theatres include the Gaiety, Abbey, Olympia, Gate, and Grand Canal. The Gaiety specialises in musical and operatic productions, and is popular for opening its doors after the evening theatre production to host a variety of live music, dancing, and films. The Abbey was founded in 1904 by a group that included Yeats with the aim of promoting indigenous literary talent. It went on to provide a breakthrough for some of the city's most famous writers, such as Synge, Yeats himself and George Bernard Shaw. The Gate was founded in 1928 to promote European and American Avant Garde works. The Grand Canal Theatre is a new 2,111 capacity theatre which opened in March 2010 in the Grand Canal Dock.
Apart from being the focus of the country's literature and theatre, Dublin is also the focal point for much of Irish art and the Irish artistic scene. The Book of Kells, a world-famous manuscript produced by Celtic Monks in AD 800 and an example of Insular art, is on display in Trinity College. The Chester Beatty Library houses the famous collection of manuscripts, miniature paintings, prints, drawings, rare books and decorative arts assembled by American mining millionaire (and honorary Irish citizen) Sir Alfred Chester Beatty (1875–1968). The collections date from 2700 BC onwards and are drawn from Asia, the Middle East, North Africa and Europe.
In addition public art galleries are found across the city, including the Irish Museum of Modern Art, the National Gallery, the Hugh Lane Municipal Gallery, the Douglas Hyde Gallery, the Project Arts Centre and the Royal Hibernian Academy. In recent years Dublin has become host to a thriving contemporary art scene. Some of the leading private galleries include Green on Red Gallery, Kerlin Gallery, Kevin Kavangh Gallery and Mother's Tankstation, each of which focuses on facilitating innovative, challenging and engaging contemporary visual art practice.
Three branches of the National Museum of Ireland are located in Dublin: Archaeology in Kildare Street, Decorative Arts and History in Collins Barracks and Natural History in Merrion Street. The same area is also home to many smaller museums such as Number 29 on Fitzwilliam Street and the Little Museum of Dublin on St. Stephen's Green. Dublin is home to the National College of Art and Design, which dates from 1746, and Dublin Institute of Design, founded in 1991. Dublinia is a living history attraction showcasing the Viking and Medieval history of the city.
Dublin has long been a city with a strong underground arts scene. Temple Bar was the home of many artists in the 1980s, and spaces such as the Project Arts Centre were hubs for collectives and new exhibitions. "The Guardian" noted that Dublin's independent and underground arts flourished during the economic recession of 2010. Dublin also has many acclaimed dramatic, musical and operatic companies, including Festival Productions, Lyric Opera Productions, the Pioneers' Musical & Dramatic Society, the Glasnevin Musical Society, Second Age Theatre Company, Opera Theatre Company and Opera Ireland. Ireland is well known for its love of baroque music, which is highly acclaimed at Trinity College.
Dublin was shortlisted to be World Design Capital 2014. Taoiseach Enda Kenny was quoted to say that Dublin "would be an ideal candidate to host the World Design Capital in 2014".
Entertainment.
Dublin has a vibrant nightlife and is reputedly one of Europe's most youthful cities, with an estimate of 50% of citizens being younger than 25. There are many pubs across the city centre, with the area around St. Stephen's Green and Grafton Street, especially Harcourt Street, Camden Street, Wexford Street and Leeson Street, having the most popular nightclubs and pubs.
The best known area for nightlife is Temple Bar, south of the River Liffey. The area has become popular among tourists, including stag and hen parties from Britain. It was developed as Dublin's cultural quarter and does retain this spirit as a centre for small arts productions, photographic and artists' studios, and in the form of street performers and small music venues. However, it has been criticised as overpriced, false and dirty by Lonely Planet. In 2014, Temple Bar was listed by the Huffington Post as one of the ten most disappointing destinations in the world. The areas around Leeson Street, Harcourt Street, South William Street and Camden/George's Street are popular nightlife spots for locals.
Live music is popularly played on streets and at venues throughout Dublin, and the city has produced several musicians and groups of international success, including The Dubliners, Thin Lizzy, The Boomtown Rats, U2, Sinéad O'Connor, Boyzone, Westlife and Jedward. The two best known cinemas in the city centre are the Savoy Cinema and the Cineworld Cinema, both north of the Liffey. Alternative and special-interest cinema can be found in the Irish Film Institute in Temple Bar, in the Screen Cinema on D'Olier Street and in the Lighthouse Cinema in Smithfield. Large modern multiscreen cinemas are located across suburban Dublin. The 3Arena venue in the Dublin Docklands has played host to many world-renowned performers.
Shopping.
Dublin is a popular shopping destination for both locals and tourists. The city has numerous shopping districts, particularly around Grafton Street and Henry Street. The city centre is also the location of large department stores, most notably Arnotts, Brown Thomas and Clerys (until June 2015 when it closed down).
The city retains a thriving market culture, despite new shopping developments and the loss of some traditional market sites. Amongst several historic locations, Moore Street remains one of the city's oldest trading districts. There has also been a significant growth in local farmers' markets and other markets. In 2007, Dublin Food Co-op relocated to a larger warehouse in The Liberties area, where it is home to many market and community events. Suburban Dublin has several modern retail centres, including Dundrum Town Centre, Blanchardstown Centre, the Square in Tallaght, Liffey Valley Shopping Centre in Clondalkin, Omni Shopping Centre in Santry, Nutgrove Shopping Centre in Rathfarnham, and Pavilions Shopping Centre in Swords.
Media.
Dublin is the centre of both media and communications in Ireland, with many newspapers, radio stations, television stations and telephone companies based there. RTÉ is Ireland's national state broadcaster, and is based in Donnybrook. Fair City is RTÉ's soap opera, located in the fictional Dublin suburb of "Carraigstown". TV3 Media, UTV Ireland, Setanta Sports, MTV Ireland and Sky News are also based in the city. The headquarters of An Post and telecommunications companies such as Eircom, as well as mobile operators Meteor, Vodafone and 3 are all located there. Dublin is also the headquarters of important national newspapers such as "The Irish Times" and "Irish Independent", as well as local newspapers such as "The Evening Herald".
As well as being home to RTÉ Radio, Dublin also hosts the national radio networks Today FM and Newstalk, and numerous local stations. Commercial radio stations based in the city include 4fm (94.9 MHz), Dublin's 98FM (98.1 MHz), Radio Nova 100FM (100.3 MHz), Q102 (102.2 MHz), SPIN 1038 (103.8 MHz), FM104 (104.4 MHz), TXFM (105.2 MHz) and Sunshine 106.8 (106.8 MHz). There are also numerous community and special interest stations, including Dublin City FM (103.2 MHz), Dublin South FM (93.9 MHz), Liffey Sound FM (96.4 MHz), Near FM (90.3 MHz), Phoenix FM (92.5 MHz), Raidió na Life (106.4 MHz) and West Dublin Access Radio (96.0 MHz).
Sport.
GAA.
Croke Park is the largest sport stadium in Ireland. The headquarters of the Gaelic Athletic Association, it has a capacity of 84,500. It is the fourth largest stadium in Europe after Nou Camp in Barcelona, Wembley Stadium in London and Santiago Bernabéu Stadium in Madrid. It hosts the premier Gaelic football and hurling games, international rules football and irregularly other sporting and non-sporting events including concerts. During the redevelopment of Lansdowne Road it played host to the Irish Rugby Union Team and Republic of Ireland national football team as well as hosting the Heineken Cup rugby 2008–09 semi-final between Munster and Leinster which set a world record attendance for a club rugby match. The Dublin GAA team plays most of their home league hurling games at Parnell Park.
Rugby.
I.R.F.U. Stadium Lansdowne Road was laid out in 1874. This was the venue for home games of both the Irish Rugby Union Team and the Republic of Ireland national football team. A joint venture between the Irish Rugby Football Union, the FAI and the Government, saw it redeveloped into a new state-of-the-art 50,000 seat Aviva Stadium, which opened in May 2010. Aviva Stadium hosted the 2011 UEFA Europa League Final. Rugby union team Leinster Rugby play their competitive home games in the RDS Arena & the Aviva Stadium while Donnybrook Stadium hosts their friendlies and A games, Ireland A and Women, Leinster Schools and Youths and the home club games of All Ireland League clubs Old Wesley and Bective Rangers. County Dublin is home for 13 of the senior rugby union clubs in Ireland including 5 of the 10 sides in the top division 1A.
Football.
County Dublin is home to six League of Ireland association clubs; Bohemian F.C., Shamrock Rovers, St Patrick's Athletic, University College Dublin, Shelbourne and newly elected side Cabinteely. Current FAI Cup Champions are St Patrick's Athletic. The first Irish side to reach the group stages of a European competition (2011–12 UEFA Europa League group stage) are Shamrock Rovers who play at Tallaght Stadium in South Dublin. Bohemian F.C play at Dalymount Park which is the oldest football stadium in the country, having played host to the Ireland football team from 1904 to 1990. St Patrick's Athletic play at Richmond Park, University College Dublin play their home games at the UCD Bowl in Dún Laoghaire–Rathdown, while Shelbourne is based at Tolka Park.Cabinteely will play at Stradbrook Road. Tolka Park, Dalymount Park, UCD Bowl and Tallaght Stadium, along with the Carlisle Grounds in Bray, hosted all Group 3 games in the intermediary round of the 2011 UEFA Regions' Cup.
Other.
The Dublin Marathon has been run since 1980 on the last Monday in October. The Women's Mini Marathon has been run since 1983 on the first Monday in June, which is also a bank holiday in Ireland. It is said to be the largest all female event of its kind in the world.
The Dublin area has several race courses including Shelbourne Park and Leopardstown. The Dublin Horse Show takes place at the RDS, which hosted the Show Jumping World Championships in 1982. The national boxing arena is located in The National Stadium on the South Circular Road. The National Basketball Arena is located in Tallaght, is the home of the Irish basketball team, is the venue for the basketball league finals and has also hosted boxing and wrestling events. The National Aquatic Centre in Blanchardstown is Ireland's largest indoor water leisure facility. Dublin has two ODI Cricket grounds in Castle Avenue, Clontarf and Malahide Cricket Club and College Park has Test status and played host to Ireland's only Test cricket match to date, a women's match against Pakistan in 2000. There are also Gaelic Handball, hockey and athletics stadia, most notably Morton Stadium in Santry, which held the athletics events of the 2003 Special Olympics.
Irish language.
There are 10,469 students in the Dublin region attending the 31 gaelscoileanna (Irish-language primary schools) and 8 gaelcholáistí (Irish-language secondary schools). Dublin has the highest number of Irish-medium schools in the country. There may be also up to another 10,000 Gaeltacht speakers living in Dublin. Two Irish language radio stations Raidió Na Life and RTÉ Raidió na Gaeltachta both have studios in the city, and the online and DAB station Raidió Rí-Rá broadcasts from studios in the city. Many other radio stations in the city broadcast at least an hour of Irish language programming per week. Many Irish language agencies are also located in the capital. Conradh na Gaeilge offers language classes, has a book shop and is a regular meeting place for different groups. The closest Gaeltacht to Dublin is the County Meath Gaeltacht of Ráth Cairn and Baile Ghib which is away.
Twin cities.
Dublin is twinned with the following places:
The city is also in talks to twin with Rio de Janeiro, and Mexican city Guadalajara.

</doc>
<doc id="8506" url="https://en.wikipedia.org/wiki?curid=8506" title="DirectX">
DirectX

Microsoft DirectX is a collection of application programming interfaces (APIs) for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms. Originally, the names of these APIs all began with Direct, such as Direct3D, DirectDraw, DirectMusic, DirectPlay, DirectSound, and so forth. The name Direct"X" was coined as shorthand term for all of these APIs (the X standing in for the particular API names) and soon became the name of the collection. When Microsoft later set out to develop a gaming console, the X was used as the basis of the name Xbox to indicate that the console was based on DirectX technology. The X initial has been carried forward in the naming of APIs designed for the Xbox such as XInput and the Cross-platform Audio Creation Tool (XACT), while the DirectX pattern has been continued for Windows APIs such as Direct2D and DirectWrite.
Direct3D (the 3D graphics API within DirectX) is widely used in the development of video games for Microsoft Windows, Sega Dreamcast, Microsoft Xbox, Microsoft Xbox 360, and Microsoft Xbox One. Direct3D is also used by other software applications for visualization and graphics tasks such as CAD/CAM engineering. As Direct3D is the most widely publicized component of DirectX, it is common to see the names "DirectX" and "Direct3D" used interchangeably.
The DirectX software development kit (SDK) consists of runtime libraries in redistributable binary form, along with accompanying documentation and headers for use in coding. Originally, the runtimes were only installed by games or explicitly by the user. Windows 95 did not launch with DirectX, but DirectX was included with Windows 95 OEM Service Release 2. Windows 98 and Windows NT 4.0 both shipped with DirectX, as has every version of Windows released since. The SDK is available as a free download. While the runtimes are proprietary, closed-source software, source code is provided for most of the SDK samples. Starting with the release of Windows 8 Developer Preview, DirectX SDK has been integrated into Windows SDK.
Development history.
In late 1994, Microsoft was ready to release Windows 95, its next operating system. An important factor in the value consumers would place on it was the programs that would be able to run on it. Three Microsoft employees—Craig Eisler, Alex St. John, and Eric Engstrom—were concerned because programmers tended to see Microsoft's previous operating system, MS-DOS, as a better platform for game programming, meaning few games would be developed for Windows 95 and the operating system would not be as much of a success. This was compounded by negative reception surrounding the Windows port of "The Lion King". The game used WinG, which crashed on Compaq Presarios that came shipped with it following a partnership between Compaq and Disney, as the Cirrus Logic display drivers used by the Presarios were not thoroughly tested with the API.
DOS allowed direct access to video cards, keyboards, mice, sound devices, and all other parts of the system, while Windows 95 - with its protected memory model - restricted access to all of these, working on a much more standardized model. Microsoft needed a quick solution for programmers; the operating system was only months away from being released. Eisler (development lead), St. John, and Engstrom (program manager) worked together to fix this problem, with a solution that they eventually named DirectX.
The first version of DirectX was released in September 1995 as the Windows Games SDK. It was the Win32 replacement for the DCI and WinG APIs for Windows 3.1. DirectX allowed all versions of Microsoft Windows, starting with Windows 95, to incorporate high-performance multimedia. Eisler wrote about the frenzy to build DirectX 1 through 5 in his blog.
Initial adoption of DirectX by game developers was slow. There were fears that DirectX could be replaced as WinG had been, there was a performance penalty in using Windows over DOS, and there were many die-hard DOS programmers.
DirectX 2.0 became a component of Windows itself with the releases of Windows 95 OSR2 and Windows NT 4.0 in mid-1996. Since Windows 95 was itself still new and few games had been released for it, Microsoft engaged in heavy promotion of DirectX to developers who were generally distrustful of Microsoft's ability to build a gaming platform in Windows. Alex St. John, the evangelist for DirectX, staged an elaborate event at the 1996 Computer Game Developers Conference which game developer Jay Barnson described as a Roman theme, including real lions, togas, and something resembling an indoor carnival. It was at this event that Microsoft first introduced Direct3D and DirectPlay, and demonstrated multiplayer "MechWarrior 2" being played over the Internet.
The DirectX team faced the challenging task of testing each DirectX release against an array of computer hardware and software. A variety of different graphics cards, audio cards, motherboards, CPUs, input devices, games, and other multimedia applications were tested with each beta and final release. The DirectX team also built and distributed tests that allowed the hardware industry to confirm that new hardware designs and driver releases would be compatible with DirectX.
Prior to DirectX, Microsoft had included OpenGL on their Windows NT platform. At the time, OpenGL required "high-end" hardware and was focused on engineering and CAD uses. Direct3D was intended to be a lightweight partner to OpenGL, focused on game use. As 3D gaming grew, OpenGL developed to include better support for programming techniques for interactive multimedia applications like games, giving developers choice between using OpenGL or Direct3D as the 3D graphics API for their applications. At that point a "battle" began between supporters of the cross-platform OpenGL and the Windows-only Direct3D. Incidentally, OpenGL was supported at Microsoft by the DirectX team. If a developer chose to use OpenGL 3D graphics API, the other APIs of DirectX are often combined with OpenGL in computer games because OpenGL does not include all of DirectX's functionality (such as sound or joystick support).
In a console-specific version, DirectX was used as a basis for Microsoft's Xbox, Xbox 360 and Xbox One console API. The API was developed jointly between Microsoft and Nvidia, who developed the custom graphics hardware used by the original Xbox. The Xbox API was similar to DirectX version 8.1, but is non-updateable like other console technologies. The Xbox was code named DirectXbox, but this was shortened to Xbox for its commercial name.
In 2002, Microsoft released DirectX 9 with support for the use of much longer shader programs than before with pixel and vertex shader version 2.0. Microsoft has continued to update the DirectX suite since then, introducing Shader Model 3.0 in DirectX 9.0c, released in August 2004.
As of April 2005, DirectShow was removed from DirectX and moved to the Microsoft Platform SDK instead.
DirectX has been confirmed to be present in Microsoft's Windows Phone 8.
Logos.
The original logo resembled a deformed radiation warning symbol. Controversially, the original name for the DirectX project was the "Manhattan Project", a reference to the US nuclear weapons initiative. Alex St. John, head of Microsoft DirectX evangelism at the time, claims that the connotation of the ultimate outcome of the Manhattan Project (the nuclear bombing of Japan) is intentional, and that DirectX and its sister project, the Xbox (which shares a similar logo), were meant to displace Japanese videogame-makers from their dominance of the video-game industry. However, Microsoft publicly denies this account, instead claiming that the logo is merely an artistic design.
Components.
DirectX is composed of multiple APIs:
Microsoft has deprecated, but still supports, these DirectX components:
DirectX functionality is provided in the form of COM-style objects and interfaces. Additionally, while not DirectX components themselves, managed objects have been built on top of some parts of DirectX, such as Managed Direct3D and the XNA graphics library on top of Direct3D 9.
Versions.
DirectX 10.
A major update to DirectX API, DirectX 10 ships with and is only available with Windows Vista and later; previous versions of Windows such as Windows XP are not able to run DirectX 10-exclusive applications. Rather, programs that are run on a Windows XP system with DirectX 10 hardware simply resort to the DirectX 9.0c code path, the latest available for Windows XP computers.
Changes for DirectX 10 were extensive. Many former parts of DirectX API were deprecated in the latest DirectX SDK and are preserved for compatibility only: DirectInput was deprecated in favor of XInput, DirectSound was deprecated in favor of the Cross-platform Audio Creation Tool system (XACT) and additionally lost support for hardware accelerated audio, since the Vista audio stack renders sound in software on the CPU. The DirectPlay DPLAY.DLL was also removed and was replaced with dplayx.dll; games that rely on this DLL must duplicate it and rename it to dplay.dll.
In order to achieve backwards compatibility, DirectX in Windows Vista contains several versions of Direct3D:
Direct3D 10.1 is an incremental update of Direct3D 10.0 which shipped with, and required, Windows Vista Service Pack 1. This release mainly sets a few more image quality standards for graphics vendors, while giving developers more control over image quality. It also adds support for cube map arrays, separate blend modes per-MRT, coverage mask export from a pixel shader, ability to run pixel shader per sample, access to multi-sampled depth buffers and requires that the video card supports Shader Model 4.1 or higher and 32-bit floating-point operations. Direct3D 10.1 still fully supports Direct3D 10 hardware, but in order to utilize all of the new features, updated hardware is required.
DirectX 11.
Microsoft unveiled DirectX 11 at the Gamefest 08 event in Seattle, with the major scheduled features including GPGPU support (DirectCompute), and Direct3D 11 with tessellation support and improved multi-threading support to assist video game developers in developing games that better utilize multi-core processors. Direct3D 11 runs on Windows Vista, Windows 7, Windows 8 and Windows 10. Parts of the new API such as multi-threaded resource handling can be supported on Direct3D 9/10/10.1-class hardware. Hardware tessellation and Shader Model 5.0 require Direct3D 11 supporting hardware. Microsoft has since released the Direct3D 11 Technical Preview. Direct3D 11 is a strict superset of Direct3D 10.1 — all hardware and API features of version 10.1 are retained, and new features are added only when necessary for exposing new functionality. This helps to keep backwards compatibility with previous versions of DirectX.
Microsoft released the Final Platform Update for Windows Vista on October 27, 2009, which was 5 days after the initial release of Windows 7 (launched with Direct3D 11 as a base standard).
DirectX 11.1 is included in Windows 8. It supports WDDM 1.2 for increased performance, features improved integration of Direct2D (now at version 1.1), Direct3D, and DirectCompute, and includes DirectXMath, XAudio2, and XInput libraries from the XNA framework. It also features stereoscopic 3D support for gaming and video. DirectX 11.1 was also partially backported to Windows 7, via the Windows 7 platform update.
DirectX 11.2 is included in Windows 8.1 (including the RT version) and Windows Server 2012 R2. It added some new features to Direct2D like geometry realizations. It also added swap chain composition, which allows some elements of the scene to be rendered at lower resolutions and then composited via hardware overlay with other parts rendered at higher resolution.
DirectX 11.X is a superset of DirectX 11.2 running on the Xbox One. It actually includes some features, such as draw bundles, that were later announced as part of DirectX 12.
DirectX 11.3 was announced along with DirectX 12 at GDC and will be released in 2015. It is meant to complement DirectX 12 as a higher-level alternative.
DirectX 12.
DirectX 12 was announced by Microsoft at GDC on March 20, 2014, and was officially launched alongside Windows 10 on July 29, 2015. DirectX 12 APIs are also expected to feature on the Xbox One and Windows Phone. The version of DirectX that runs on the Xbox One, DirectX 11.X, already includes a subset of the features in DirectX 12. Microsoft has stated that the performance improvements of DirectX 12 on the Xbox One will not be as substantial as that on the PC.
The primary feature highlight for the new release of DirectX was the introduction of advanced low-level programming APIs for Direct3D 12 which can reduce driver overhead. Developers are now able to implement their own command lists and buffers to the GPU, allowing for more efficient resource utilisation through parallel computation. Lead developer Max McMullen, stated that the main goal of Direct3D 12 is to achieve "console-level efficiency on phone, tablet and PC". The release of Direct3D 12 comes alongside other initiatives for low-overhead graphics APIs including AMD's Mantle for AMD graphics cards, Apple's Metal for iOS and OS X and Khronos Group's cross-platform Vulkan.
Multiadapter support will feature in DirectX 12 allowing developers to utilise multiple GPUs on a system simultaneously, multi-GPU support was previously dependent on vendor implementations such as AMD CrossFireX or NVIDIA SLI.
DirectX 12 will be essentially supported on all Fermi and later Nvidia GPUs, on AMD's GCN-based chips and on Intel's Haswell and later processors' graphics units.
At SIGGRAPH 2014, Intel released a demo showing a computer generated asteroid field, in which DirectX 12 was claimed to be 50%-70% more efficient than DirectX 11 in rendering speed and CPU power consumption.
"Ashes of the Singularity" was the first publicly available game to utilise DirectX 12. Testing by "Ars Technica" in August 2015 revealed slight performance regressions in DirectX 12 over DirectX 11 mode for the Nvidia GeForce 980 Ti, whereas the AMD Radeon R9 290x achieved consistent performance improvements of up to 70% under DirectX 12, in some scenarios the AMD outperformed the more powerful Nvidia under DirectX 12. The performance discrepancies may be due to poor Nvidia driver optimisations for DirectX 12, or even hardware limitations of the card which was optimised for DirectX 11 serial execution, however the exact cause remains unclear.
Release history.
The version number as reported by Microsoft's DxDiag tool (version 4.09.0000.0900 and higher) use the x.xx.xxxx.xxxx format for version numbers. However, the DirectX and Windows XP MSDN page claims that the registry always has been in the x.xx.xx.xxxx format. Put another way, when the above table lists a version as '4.09.00.0904' Microsoft's DxDiag tool may have it as '4.09.0000.0904'.
Compatibility.
Various releases of Windows have included and supported various versions of DirectX, allowing newer versions of the operating system to continue running applications designed for earlier versions of DirectX until those versions can be gradually phased out in favor of newer APIs, drivers, and hardware.
APIs such as Direct3D and DirectSound need to interact with hardware, and they do this through a device driver. Hardware manufacturers have to write these drivers for a particular DirectX version's device driver interface (or DDI), and test each individual piece of hardware to make them DirectX compatible. Some hardware devices have only DirectX compatible drivers (in other words, one must install DirectX in order to use that hardware). Early versions of DirectX included an up-to-date library of all of the DirectX compatible drivers currently available. This practice was stopped however, in favor of the web-based Windows Update driver-update system, which allowed users to download only the drivers relevant to their hardware, rather than the entire library.
Prior to DirectX 10, DirectX runtime was designed to be "backward compatible" with older drivers, meaning that newer versions of the APIs were designed to interoperate with older drivers written against a previous version's DDI. The application programmer had to query the available hardware capabilities using a complex system of "cap bits" each tied to a particular hardware feature. Direct3D 7 and earlier would work on any version of the DDI, Direct3D 8 requires a minimum DDI level of 6 and Direct3D 9 requires a minimum DDI level of 7.
However, the Direct3D 10 runtime in Windows Vista cannot run on older hardware drivers due to the significantly updated DDI, which requires a unified feature set and abandons the use of "cap bits".
Direct3D 10.1 introduces "feature levels" 10_0 and 10_1, which allow use of only the hardware features defined in the specified version of Direct3D API. Direct3D 11 adds level 11_0 and "10 Level 9" - a subset of the Direct3D 10 API designed to run on Direct3D 9 hardware, which has three feature levels (9_1, 9_2 and 9_3) grouped by common capabilities of "low", "med" and "high-end" video cards; the runtime directly uses Direct3D 9 DDI provided in all WDDM drivers. Feature level 11_1 has been introduced with Direct3D 11.1.
.NET Framework.
In 2002, Microsoft released a version of DirectX compatible with the Microsoft .NET Framework, thus allowing programmers to take advantage of DirectX functionality from within .NET applications using compatible languages such as managed C++ or the use of the C# programming language. This API was known as "Managed DirectX" (or MDX for short), and claimed to operate at 98% of performance of the underlying native DirectX APIs. In December 2005, February 2006, April 2006, and August 2006, Microsoft released successive updates to this library, culminating in a beta version called Managed DirectX 2.0. While Managed DirectX 2.0 consolidated functionality that had previously been scattered over multiple assemblies into a single assembly, thus simplifying dependencies on it for software developers, development on this version has subsequently been discontinued, and it is no longer supported. The Managed DirectX 2.0 library expired on October 5, 2006.
During the GDC 2006, Microsoft presented the XNA Framework, a new managed version of DirectX (similar but not identical to Managed DirectX) that is intended to assist development of games by making it easier to integrate DirectX, High Level Shader Language (HLSL) and other tools in one package. It also supports the execution of managed code on the Xbox 360. The XNA Game Studio Express RTM was made available on December 11, 2006, as a free download for Windows XP. Unlike the DirectX runtime, Managed DirectX, XNA Framework or the Xbox 360 APIs (XInput, XACT etc.) have not shipped as part of Windows. Developers are expected to redistribute the runtime components along with their games or applications.
No Microsoft product including the latest XNA releases provides DirectX 10 support for the .NET Framework.
The other approach for DirectX in managed languages is to use third-party libraries like:
Alternatives.
There are alternatives to the DirectX family of APIs, with OpenGL, its successor Vulkan and Mantle having the most features comparable to Direct3D. Examples of other APIs include SDL, Allegro, OpenMAX, OpenML, OpenAL, OpenCL, FMOD, SFML etc. Many of these libraries are cross-platform or have open codebases. There are also alternative implementations that aim to provide the same API, such as the one in Wine. Furthermore, the developers of ReactOS are trying to reimplement DirectX under the name "ReactX".

</doc>
<doc id="8508" url="https://en.wikipedia.org/wiki?curid=8508" title="Slalom skiing">
Slalom skiing

Slalom is an alpine skiing and alpine snowboarding discipline, involving skiing between poles or gates. These are spaced more closely than those in giant slalom, super giant slalom and downhill, necessitating quicker and shorter turns. Internationally, the sport is contested at the FIS Alpine World Ski Championships, and at the Winter Olympic Games.
The term may also refer to waterskiing on one ski.
History.
The word "slalom" is from the Morgedal/Seljord dialect of Norwegian slalåm: "sla," meaning slightly inclining hillside, and "låm," meaning track after skis. The inventors of modern skiing classified their trails according to their difficulty. "Slalåm" was a trail used in Telemark by boys and girls not yet able to try themselves on the more challenging runs. "Ufsilåm" was a trail with one obstacle ("ufse") like a jump, a fence, a difficult turn, a gorge, a cliff (often more than high) and more. "Uvyrdslåm" was a trail with several obstacles. A Norwegian military downhill competition in 1767 included racing downhill among trees "without falling or breaking skis". Sondre Norheim and other skiers from Telemark practiced "uvyrdslåm" or "disrespectful/reckless downhill" were they raced downhill in difficult and untested terrain (i.e., off piste). The 1866 "ski race" in Oslo was a combined cross-country, jumping and slalom competition. In the slalom participants were allowed use poles for breaking and steering, and they were given points for style (appropriate skier posture). During the late 1800s Norwegian skiers participated in all branches (jumping, slalom, and cross-country) often with the same pair of skis. Slalom and variants of slalom were often referred to as hill races. Around 1900 hill races are abandoned in the Oslo championships at Huseby and Holmenkollen. Mathias Zdarsky's development of the Lilienfeld binding helped change hill races into a specialty of the Alps region. 
The rules for the modern slalom were developed by Arnold Lunn in 1922 for the British National Ski Championships, and adopted for alpine skiing at the 1936 Winter Olympics. Under these rules gates were marked by pairs of flags rather than single ones, were arranged so that the racers had to use a variety of turn lengths to negotiate them, and scoring was on the basis of time alone, not time and style.
Course.
A course is constructed by laying out a series of gates, formed by alternating pairs of red and blue poles. The skier must pass between the two poles forming the gate, with the tips of both skis and the skier's feet passing between the poles. A course has 55 to 75 gates for men and 40 to 60 for women. The vertical drop for a men's course is and slightly less for women. The gates are arranged in a variety of configurations to challenge the competitor.
Because the offsets are relatively small in slalom, ski racers take a fairly direct line and often knock the poles out of the way as they pass, which is known as blocking. (The main blocking technique in modern slalom is cross-blocking, in which the skier takes such a tight line and angulates so strongly that he or she is able to block the gate with the outside hand.) In modern slalom, a variety of protective equipment is used such as shin pads, hand guards, helmets and face guards.
Clearing the gates.
Traditionally, bamboo poles were used for gates, the rigidity of which forced skiers to maneuver their entire body around each gate. The early 1980s, rigid poles were replaced by hard plastic poles, hinged at the base with a universal joint designed and patented by Peter Laehy and Stefan Dag in Aspen, CO. USA. Patent # 4,270,873. The hinged gates require, according to FIS rules, only that the skis and boots of the skier go around each gate. By 1989 most of the top technical skiers in the world had adopted the cross-block technique.
The new gates allow a more direct path down a slalom course through the process of cross-blocking or shinning the gates. Cross-blocking is a technique in which the legs go around the gate with the upper body inclined toward, or even across, the gate; in this case the racer's outside pole and shinguards hit the gate, knocking it down and out of the way. Cross-blocking is done by pushing the gate down with the arms, hands, or shins.
Equipment.
With the innovation of shaped skis around the turn of the 21st century, equipment used for slalom in international competition changed drastically. World Cup skiers commonly skied on slalom skis at a length of in the 1980s and 1990s but by the 2002 Winter Olympics in Salt Lake City, the majority of competitors were using skis measuring or less.
The downside of the shorter skis was that athletes found that recoveries were more difficult with a smaller platform underfoot. Over concern for the safety of athletes, the FIS began to set minimum ski lengths for international slalom competition. The minimum was initially set at for men and for women, but was increased to for men and for women for the 2003-2004 season.
American Bode Miller hastened the shift to the shorter, more radical sidecut skis when he achieved unexpected success after becoming the first Junior Olympic athlete to adopt the equipment in giant slalom and super G in 1996. A few years later, the technology was adapted to slalom skis as well.

</doc>
<doc id="8518" url="https://en.wikipedia.org/wiki?curid=8518" title="Dachshund">
Dachshund

The dachshund ( or or ) is a short-legged, long-bodied, hound-type dog breed.
The standard size dachshund was developed to scent, chase, and flush out badgers and other burrow-dwelling animals, while the miniature dachshund was bred to hunt smaller prey such as rabbits. In the United States, they have also been used to track wounded deer and hunt prairie dogs.
Dachshunds also participate in conformation shows, field trials and many other events organized through pure bred dog organizations such as the American Kennel Club (AKC). According to the AKC, the dachshund remains one of the top 10 dog breeds in the United States.
Etymology.
The name "dachshund" is of German origin and literally means "badger dog", from "Dachs" ("badger") and "Hund" ("hound, dog"). The pronunciation varies widely in English: variations of the first and second syllables include , and , , . Although "dachshund" is a German word, in modern German they are more commonly known by the name Dackel or, among hunters, Teckel. The German word is pronounced .
Because of their long, narrow build, they are often nicknamed wiener dog or sausage dog.
Classification.
While classified in the hound group or scent hound group in the United States and Great Britain, the breed actually has its own group in the countries which belong to the Fédération Cynologique Internationale (World Canine Federation). Many dachshunds, especially the wire-haired subtype, may exhibit behavior and appearance that are similar to that of the terrier group of dogs. An argument can be made for the scent (or hound) group classification because the breed was developed to use scent to trail and hunt animals, and probably descended from the Saint Hubert Hound like many modern scent hound breed such as bloodhounds and Basset Hounds; but with the persistent personality and love for digging that probably developed from the terrier, it can also be argued that they could belong in the terrier, or "earth dog", group.
Characteristics.
Appearance.
A typical dachshund is long-bodied and muscular with short, stubby legs. Its front paws are unusually large and paddle-shaped for extreme digging. It has skin that is loose enough not to tear while tunneling in tight burrows to chase prey. The dachshund has a deep chest that provides increased lung capacity for stamina when hunting prey underground. Its snout is long with an increased nose area that absorbs odors.
Coat and color.
There are three dachshund coat varieties: smooth coat (short hair), longhaired, and wirehaired. Longhaired dachshunds have a silky coat and short featherings on legs and ears. Wirehaired dachshunds are the least common coat variety in the US (it is the most common in Germany) and the most recent coat to appear in breeding standards.
Dachshunds have a wide variety of colors and patterns. Their base coloration can be single-colored (either red or cream), tan pointed (black and tan, chocolate and tan, blue and tan, or Isabella and tan), and in wirehaired dogs, a color referred to as wildboar. Patterns such as dapple (merle), sable, brindle and piebald also can occur on any of the base colors. Dachshunds in the same litter may be born in different coat colors depending on the genetic makeup of the parents. The dominant color in the breed is red, followed by black and tan. Tan pointed dogs have tan (or cream) markings over the eyes, ears, paws, and tail. The reds range from coppers to deep rusts, with or without somewhat common black hairs peppered along the back, face and ear edges, lending much character and an almost burnished appearance; this is referred to among breeders and enthusiasts as an "overlay" or "sabling". Sabling should not be confused with a more unusual coat color referred to as sable. At a distance, a sable dachshund looks somewhat like a black and tan dog. Upon closer examination, however, one can observe that along the top of the dog's body, each hair is actually banded with red at the base near the skin transitioning to mostly black along the length of the strand. An additional striking coat marking is the brindle pattern. "Brindle" refers to dark stripes over a solid background—usually red. If a dachshund is brindled on a dark coat and has tan points, it will have brindling on the tan points only. Even one single, lone stripe of brindle is a brindle. If a dachshund has one single spot of dapple, it is a dapple.
The Dachshund Club of America (DCA) and the American Kennel Club (AKC) consider both the piebald pattern and the double dapple (double merle) pattern to be nonstandard. However, both types continue to be shown and sometimes even win in the conformation ring.
Dogs that are double-dappled have the merle pattern of a dapple, but with distinct white patches that occur when the dapple gene expresses itself twice in the same area of the coat. The DCA excluded the wording "double-dapple" from the standard in 2007 and now strictly use the wording "dapple" as the double dapple gene is commonly responsible for blindness and deafness.
Size.
Dachshunds come in three sizes: standard, miniature, and "kaninchen" (German for "rabbit"). Although the standard and miniature sizes are recognized almost universally, the rabbit size is not recognized by clubs in the United States and the United Kingdom. The rabbit size is recognized by the Fédération Cynologique Internationale (World Canine Federation) (FCI), which contain kennel clubs from 83 countries all over the world. An increasingly common size for family pets falls between the miniature and the standard size, frequently referred to as "tweenies," not an official classification.
A full-grown standard dachshund averages to , while the miniature variety normally weighs less than . The kaninchen weighs to . According to kennel club standards, the miniature (and kaninchen, where recognized) differs from the full-size only by size and weight, thus offspring from miniature parents must never weigh more than the miniature standard to be considered a miniature as well. While many kennel club size divisions use weight for classification, such as the American Kennel Club, other kennel club standards determine the difference between the miniature and standard by chest circumference; some kennel clubs, such as in Germany, even measure chest circumference in addition to height and weight.
H. L. Mencken said that "A dachshund is a half-dog high and a dog-and-a-half long," although they have been referred to as "two dogs long". This characteristic has led them to be quite a recognizable breed, and they are featured in many a joke and cartoon, particularly "The Far Side" by Gary Larson.
Eye color.
Light-colored dachshunds can sport amber, light brown, or green eyes; however, kennel club standards state that the darker the eye color, the better. They can also have eyes of two different colors; however, this is only found in dapple and double dapple dachshunds. Dachshunds can have a blue and a brown eye. Blue eyes, partially blue eyes, or a blue eye and a brown eye are called "wall" coloring, and are considered a non-desirable trait in kennel club standards. Dappled eyes are also possible.
Wall-eye is permissible according to DCA standards. Piebald-patterned dachshunds will never have blue in their eyes, unless the dapple pattern is present.
Temperament.
Dachshunds are playful, but as hunting dogs can be quite stubborn, and are known for their propensity for chasing small animals, birds, and tennis balls with great determination and ferocity. Many dachshunds are stubborn, making them a challenge to train.
Dachshunds are statistically more aggressive to both strangers and other dogs. Despite this, they are rated in the intelligence of dogs as an average working dog with a persistent ability to follow trained commands 50% of the time or more. They rank 49th in Stanley Coren's "Intelligence of Dogs", being of average working and obedience intelligence.
They can have a loud bark. Some bark quite a lot and may need training to stop, while others will not bark much at all. Dachshunds are known for their devotion and loyalty to their owners, though they can be standoffish towards strangers. If left alone, many dachshunds will whine until they have companionship. Like many dogs if left alone too frequently, some dachshunds are prone to separation anxiety and may chew objects in the house to relieve stress.
Dachshunds are burrowers by nature and are likely to burrow in blankets and other items around the house, when bored or tired.
Dachshunds can be difficult to housebreak, and patience and consistency is often needed in this endeavor.
According to the American Kennel Club's breed standards, "the dachshund is clever, lively and courageous to the point of rashness, persevering in above and below ground work, with all the senses well-developed. Any display of shyness is a serious fault." Their temperament and body language give the impression that they do not know or care about their relatively small size. Like many small hunting dogs, they will challenge a larger dog. Indulged dachshunds may become snappy or extremely obstinate.
Many dachshunds do not like unfamiliar people, and many will growl or bark at them. Although the dachshund is generally an energetic dog, some are sedate. This dog's behavior is such that it is not the dog for everyone. A bored, untrained dachshund will become destructive. If raised improperly and not socialized at a young age, dachshunds can become aggressive or fearful. They require a caring, loving owner who understands their need for entertainment and exercise.
Dachshunds may not be the best pets for small children. Like any dog, dachshunds need a proper introduction at a young age. Well trained dachshunds and well behaved children usually get along fine. Otherwise, they may be aggressive and bite an unfamiliar child, especially one that moves quickly around them or teases them. However, many dachshunds are very tolerant and loyal to children within their family, but these children should be mindful of the vulnerability of the breed's back.
A 2008 University of Pennsylvania study of 6,000 dog owners who were interviewed indicated that dogs of smaller breeds were more likely to be "genetically predisposed towards aggressive behaviour". Dachshunds were rated the most aggressive, with 20% having bitten strangers, as well as high rates of attacks on other dogs and their owners. The study noted that attacks by small dogs were unlikely to cause serious injuries and because of this were probably under-reported.
Health.
The breed is prone to spinal problems, especially intervertebral disk disease (IVDD), due in part to an extremely long spinal column and short rib cage. The risk of injury may be worsened by obesity, jumping, rough handling, or intense exercise, which place greater strain on the vertebrae. About 20–25% of Dachshunds will develop IVDD.
Treatment consists of combinations of crate confinement and courses of anti-inflammatory medications (steroids and non-steroidal anti-inflammatory drugs like carprofen and meloxicam), or chronic pain medications, like tramadol. Serious cases may require surgery to remove the troublesome disk contents. A dog may need the aid of a cart to get around if paralysis occurs.
A new minimally invasive procedure called "percutaneous laser disk ablation" has been developed at the Oklahoma State University Veterinary Hospital. Originally, the procedure was used in clinical trials only on dachshunds that had suffered previous back incidents. Since dachshunds are prone to back issues, the goal is to expand this treatment to dogs in a normal population.
In addition to back problems, the breed is also prone to patellar luxation which is where the kneecap can become dislodged. Dachshunds may also be affected by Osteogenesis imperfecta (brittle bone disease). The condition seems to be mainly limited to wire-haired Dachshunds, with 17% being carriers. A genetic test is available to allow breeders to avoid breeding carriers to carriers. In such pairings, each puppy will have a 25% chance of being affected.
In some double dapples, there are varying degrees of vision and hearing loss, including reduced or absent eyes. Not all double dapples have problems with their eyes and/or ears, which may include degrees of hearing loss, full deafness, malformed ears, congenital eye defects, reduced or absent eyes, partial or full blindness, or varying degrees of both vision and hearing problems; but heightened problems can occur due to the genetic process in which two dapple genes cross, particularly in certain breeding lines. Dapple genes, which are dominant genes, are considered "dilution" genes, meaning whatever color the dog would have originally carried is lightened, or diluted, randomly; two dominant "dilution" genes can cancel each other out, or "cross", removing all color and producing a white recessive gene, essentially a white mutation. When this happens genetically within the eyes or ears, this white mutation can be lethal to their development, causing hearing or vision problems.
Other dachshund health problems include hereditary epilepsy, granulomatous meningoencephalitis, dental issues, Cushing's syndrome, thyroid and autoimmune problems, various allergies and atopies, and various eye conditions including cataracts, glaucoma, progressive retinal atrophy, corneal ulcers, nonucerative corneal disease, sudden acquired retinal degeneration, and cherry eye. Dachshunds are also 2.5 times more likely than other breeds of dogs to develop patent ductus arteriosus, a congenital heart defect. Dilute color dogs (Blue, Isabella, and Fawn) are very susceptible to Color Dilution Alopecia, a skin disorder that can result in hair loss and extreme sensitivity to sun. Since the occurrence and severity of these health problems is largely hereditary, breeders are working to eliminate these.
Inbreeding depression.
Factors influencing the litter size of puppies and the proportion of stillborn puppies per litter were analyzed in normally sized German dachshunds. The records analyzed contained data on 42,855 litters. It was found that as the inbreeding coefficient increased, litter size decreased and the percentage of stillborn puppies increased, thus indicating inbreeding depression. It was also found that young and older dams had smaller litter sizes and more stillborn puppies than middle-aged dams.
History.
Some writers and dachshund experts have theorized that the early roots of the dachshund go back to ancient Egypt, where engravings were made featuring short-legged hunting dogs. Recent discoveries by the American University in Cairo of mummified dachshund-like dogs from ancient Egyptian burial urns may lend credibility to this theory. In its modern incarnation, the dachshund is a creation of German breeders and includes elements of German, French, and English hounds and terriers. Dachshunds have been kept by royal courts all over Europe, including that of Queen Victoria, who was particularly enamored of the breed. They were originally bred for hunting badgers by trailing scent.
The first verifiable references to the dachshund, originally named the "Dachs Kriecher" ("badger crawler") or "Dachs Krieger" ("badger warrior"), came from books written in the early 18th century. Prior to that, there exist references to "badger dogs" and "hole dogs", but these likely refer to purposes rather than to specific breeds. The original German dachshunds were larger than the modern full-size variety, weighing between , and originally came in straight-legged and crook-legged varieties (the modern dachshund is descended from the latter). Though the breed is famous for its use in exterminating badgers and badger-baiting, dachshunds were also commonly used for rabbit and fox hunting, for locating wounded deer, and in packs were known to hunt game as large as wild boar and as fierce as the wolverine.
There are huge differences of opinion as to when dachshunds were specifically bred for their purpose of badger hunting, as the American Kennel Club states the dachshund was bred in the 15th century, while the Dachshund Club of America states that foresters bred the dogs in the 18th or 19th century.
Double-dapple dachshunds, which are prone to eye disease, blindness, or hearing problems, are generally believed to have been introduced to the United States between 1879 and 1885.
The flap-down ears and famous curved tail of the dachshund have deliberately been bred into the dog. In the case of the ears, this is to keep grass seeds, dirt, and other matter from entering the ear canal. The curved tail is dual-purposed: to be seen more easily in long grass and, in the case of burrowing dachshunds, to help haul the dog out if it becomes stuck in a burrow.
The smooth-haired dachshund, the oldest style, may be a cross between the German Shorthaired Pointer, a Pinscher, and a Bracke (a type of bloodhound), or to have been produced by crossing a short Bruno Jura Hound with a pinscher. Others believe it was a cross from a miniature French pointer and a pinscher; others claim that it was developed from the St. Hubert Hound, also a bloodhound, in the 18th century, and still others believe that they were descended from Basset Hounds, based upon their scent abilities and general appearance.
The exact origins of the dachshund are therefore unknown. According to William Loeffler, from " The American Book of the Dog (1891)", in the chapter on dachshunds: "The origin of the Dachshund is in doubt, our best authorities disagreeing as to the beginning of the breed." What can be agreed on, however, is that the short-haired dachshund gave rise to both the long-haired and the wire-haired varieties.
There are two theories about how the standard longhair dachshund came about. One theory is that smooth Dachshunds would occasionally produce puppies which had slightly longer hair than their parents. By selectively breeding these animals, breeders eventually produced a dog which consistently produced longhair offspring, and the longhair dachshund was born. Another theory is that the standard longhair dachshund was developed by breeding smooth dachshunds with various land and water spaniels. The long-haired dachshund may be a cross among any of the small dog breeds in the spaniel group, including the German Stoberhund, and the smooth-haired dachshund.
The wire-haired dachshund, the last to develop, was bred in the late 19th century. There is a possibility the wire-haired dachshund was a cross between the smooth dachshund and various hard-coated terriers and wire-haired pinschers, such as the Schnauzer, the Dandie Dinmont Terrier, the German Wirehaired Pointer, or perhaps the Scottish Terrier.
Symbol of Germany.
Dachshunds have traditionally been viewed as a symbol of Germany. Political cartoonists commonly used the image of the dachshund to ridicule Germany. During World War I the dachshunds' popularity in the United States plummeted because of this association. As a result, they were often called "liberty hounds" by their owners similar to "liberty cabbage" becoming a term for sauerkraut mostly in North America. The stigma of the association was revived to a lesser extent during World War II, though it was comparatively short-lived. Kaiser Wilhelm II and German Field Marshal Erwin Rommel were known for keeping dachshunds.
Due to the association of the breed with Germany, as well as its popularity among dog keepers in Munich, the dachshund was chosen to be the first official mascot for the 1972 Summer Olympics in Munich, with the name Waldi.
Sports.
Some people train and enter their dachshund to compete in dachshund races, such as the Wiener Nationals. Several races across the United States routinely draw several thousand attendees, including races in Germantown, Tennessee; Bossier City, Louisiana; Buda, Texas; Davis, California; Phoenix, Arizona; Los Alamitos, California; Findlay, Ohio; Milwaukee, Wisconsin; Oklahoma City, Oklahoma; Kansas City, Kansas; Palo Alto, California; and Shakopee, Minnesota. There is also an annual dachshund run in Kennywood, located in Pittsburgh, Pennsylvania, called the Wiener 100, and in Huntington, West Virginia called the Dachshund Dash.
Despite the popularity of these events, the Dachshund Club of America opposes "wiener racing", as many greyhound tracks use the events to draw large crowds to their facilities. The DCA is also worried about potential injuries to dogs, due to their predisposition to back injuries. Another favorite sport is earthdog trials, in which dachshunds enter tunnels with dead ends and obstacles attempting to locate an artificial bait or live but caged and protected rats.
"Dackel" versus "Teckel".
In Germany, dachshunds are widely called "Dackel" (both singular and plural). Among hunters, they are mainly referred to as "Teckel". There are kennels which specialize in breeding hunting dachshunds, the so-called "jagdliche Leistungszucht" ("hunting performance breed") or "Gebrauchshundezucht" ("working dog breed"), as opposed to breeding family dogs. Therefore, it is sometimes believed that "Teckel" is either a name for the hunting breed or a mark for passing the test for a trained hunting dog (called "VGP", "Verband-Gebrauchsprüfung") in Germany. It is not.
Popularity.
Dachshunds are one of the most popular dogs in the United States, ranking 10th in the 2012 AKC registration statistics. They are popular with urban and apartment dwellers, ranking among the top ten most popular breeds in 76 of 190 major US cities surveyed by the AKC.
One will find varying degrees of organized local dachshund clubs in most major American cities, including New York, New Orleans, Portland, Los Angeles, and Chicago.

</doc>
<doc id="8519" url="https://en.wikipedia.org/wiki?curid=8519" title="Data structure">
Data structure

In computer science, a data structure is a particular way of organizing data in a computer so that it can be used efficiently. Data structures can implement one or more particular abstract data types (ADT), which specify the operations that can be performed on a data structure and the computational complexity of those operations. In comparison, a data structure is a concrete implementation of the specification provided by an ADT.
Different kinds of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks. For example, relational databases commonly use B-tree indexes for data retrieval, while compiler implementations usually use hash tables to look up identifiers.
Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data structures are key to designing efficient algorithms. Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Data structures can be used to organize the storage and retrieval of information stored in both main memory and in secondary memory.
Overview.
Data structures are generally based on the ability of a computer to fetch and store data at any place in its memory, specified by a pointer—a bit string, representing a memory address, that can be itself stored in memory and manipulated by the program. Thus, the array and record data structures are based on computing the addresses of data items with arithmetic operations; while the linked data structures are based on storing addresses of data items within the structure itself. Many data structures use both principles, sometimes combined in non-trivial ways (as in XOR linking).
The implementation of a data structure usually requires writing a set of procedures that create and manipulate instances of that structure. The efficiency of a data structure cannot be analyzed separately from those operations. This observation motivates the theoretical concept of an abstract data type, a data structure that is defined indirectly by the operations that may be performed on it, and the mathematical properties of those operations (including their space and time cost).
Examples.
There are numerous types of data structures, generally built upon simpler primitive data types:
Language support.
Most assembly languages and some low-level languages, such as BCPL (Basic Combined Programming Language), lack built-in support for data structures. On the other hand, many high-level programming languages and some higher-level assembly languages, such as MASM, have special syntax or other built-in support for certain data structures, such as records and arrays. For example, the C and Pascal languages support structs and records, respectively, in addition to vectors (one-dimensional arrays) and multi-dimensional arrays.
Most programming languages feature some sort of library mechanism that allows data structure implementations to be reused by different programs. Modern languages usually come with standard libraries that implement the most common data structures. Examples are the C++ Standard Template Library, the Java Collections Framework, and Microsoft's .NET Framework.
Modern languages also generally support modular programming, the separation between the interface of a library module and its implementation. Some provide opaque data types that allow clients to hide implementation details. Object-oriented programming languages, such as C++, Java and Smalltalk may use classes for this purpose.
Many known data structures have concurrent versions that allow multiple computing threads to access the data structure simultaneously.

</doc>
<doc id="8520" url="https://en.wikipedia.org/wiki?curid=8520" title="Dmitri Shostakovich">
Dmitri Shostakovich

Dmitri Dmitriyevich Shostakovich (, ; 25 September 19069 August 1975) was a Soviet composer and pianist, and a prominent figure of 20th-century music.
Shostakovich achieved fame in the Soviet Union under the patronage of Soviet chief of staff Mikhail Tukhachevsky, but later had a complex and difficult relationship with the government. Nevertheless, he received accolades and state awards and served in the Supreme Soviet of the RSFSR (1947–1962) and the Supreme Soviet of the Soviet Union (from 1962 until his death).
A poly-stylist, Shostakovich developed a hybrid voice, combining a variety of different musical techniques into his music. Shostakovich's music is characterized by sharp contrasts, elements of the grotesque, and ambivalent tonality; the composer was also heavily influenced by the neo-classical style pioneered by Igor Stravinsky, and (especially in his symphonies) by the post-Romanticism associated with Gustav Mahler.
Shostakovich's orchestral works include 15 symphonies and six concerti. His chamber output includes 15 string quartets, a piano quintet, two piano trios, and two pieces for string octet. His piano works include two solo sonatas, an early set of preludes, and a later set of 24 preludes and fugues. Other works include three operas, several song cycles, ballets, and a substantial quantity of film music; especially well known is "The Second Waltz", Op. 99, music to the film "" (1955–1956), as well as the Suites composed for "The Gadfly".
Biography.
Early life.
Their son, Dmitri Dmitriyevich Shostakovich, displayed significant musical talent after he began piano lessons with his mother at the age of nine. On several occasions, he displayed a remarkable ability to remember what his mother had played at the previous lesson, and would get "caught in the act" of playing the previous lesson's music while pretending to read different music placed in front of him. In 1918, he wrote a funeral march in memory of two leaders of the Kadet party, murdered by Bolshevik sailors.
In 1919, at the age of thirteen, he was allowed to enter the Petrograd Conservatory, then headed by Alexander Glazunov, who monitored Shostakovich's progress closely and promoted him. Shostakovich studied piano with Leonid Nikolayev after a year in the class of Elena Rozanova, composition with Maximilian Steinberg, and counterpoint and fugue with Nikolay Sokolov, with whom he became friends. Shostakovich also attended Alexander Ossovsky's history of music classes. Steinberg tried to guide Shostakovich in the path of the great Russian composers, but was disappointed to see him 'wasting' his talent and imitating Igor Stravinsky and Sergei Prokofiev. He also suffered for his perceived lack of political zeal, and initially failed his exam in Marxist methodology in 1926. His first major musical achievement was the First Symphony (premiered 1926), written as his graduation piece at the age of nineteen.
Early career.
After graduation, Shostakovich initially embarked on a dual career as concert pianist and composer, but his dry style of playing was often unappreciated (his American biographer, Laurel Fay, comments on his "emotional restraint" and "riveting rhythmic drive"). He nevertheless won an "honorable mention" at the First International Chopin Piano Competition in Warsaw in 1927. He explained the disappointment at the competition to suffering from appendicitis and the jury being all-Polish. He later had his appendix removed in April 1927. After the competition Shostakovich met the conductor Bruno Walter, who was so impressed by the composer's First Symphony that he conducted it at its Berlin premiere later that year. Leopold Stokowski was equally impressed and gave the work its U.S. premiere the following year in Philadelphia and also made the work's first recording.
Thereafter, Shostakovich concentrated on composition and soon limited his performances primarily to those of his own works. In 1927 he wrote his Second Symphony (subtitled "To October"), a patriotic piece with a great pro-Soviet choral finale. Due to its experimental nature, as with the subsequent Third Symphony, the pieces were not critically acclaimed with the enthusiasm granted to the First.
The year 1927 also marked the beginning of Shostakovich's relationship with Ivan Sollertinsky, who remained his closest friend until the latter's death in 1944. Sollertinsky introduced the composer to the music of Gustav Mahler, which had a strong influence on his music from the Fourth Symphony onwards.
While writing the Second Symphony, Shostakovich also began work on his satirical opera "The Nose", based on the story by Gogol. In June 1929, the opera was given a concert performance, against Shostakovich's own wishes, and was ferociously attacked by the Russian Association of Proletarian Musicians (RAPM). Its stage premiere on 18 January 1930 opened to generally poor reviews and widespread incomprehension amongst musicians.
In the late 1920s and early 1930s, Shostakovich worked at TRAM, a proletarian youth theatre. Although he did little work in this post, it shielded him from ideological attack. Much of this period was spent writing his opera, "Lady Macbeth of the Mtsensk District", which was first performed in 1934. It was immediately successful, on both popular and official levels. It was described as "the result of the general success of Socialist construction, of the correct policy of the Party", and as an opera that "could have been written only by a Soviet composer brought up in the best tradition of Soviet culture".
Shostakovich married his first wife, Nina Varzar, in 1932. Initial difficulties led to a divorce in 1935, but the couple soon remarried when Nina became pregnant with their first child.
First denunciation.
In 1936, Shostakovich fell from official favour. The year began with a series of attacks on him in "Pravda", in particular an article entitled, "Muddle Instead of Music". Shostakovich was away on a concert tour in Arkhangelsk when he heard news of the first "Pravda" article. Two days before the article was published on the evening of 28 January, a friend had advised Shostakovich to attend the Bolshoi Theatre production of "Lady Macbeth". When he arrived, he saw that Joseph Stalin and the Politburo were there. In letters written to his friend Ivan Sollertinsky, Shostakovich recounted the horror with which he watched as Stalin shuddered every time the brass and percussion played too loudly. Equally horrifying was the way Stalin and his companions laughed at the love-making scene between Sergei and Katerina. Eyewitness accounts testify that Shostakovich was "white as a sheet" when he went to take his bow after the third act.
The article condemned "Lady Macbeth" as formalist, "coarse, primitive and vulgar". Consequently, commissions began to fall off, and his income fell by about three quarters. Even Soviet music critics who had praised the opera were forced to recant in print, saying they "failed to detect the shortcomings of "Lady Macbeth" as pointed out by "Pravda"". Shortly after the "Muddle Instead of Music" article, "Pravda" published another, "Ballet Falsehood," that criticized Shostakovich’s ballet "The Limpid Stream". Shostakovich did not expect this second article because the general public and press already accepted this music as "democratic" – that is, tuneful and accessible. However, "Pravda" criticized "The Limpid Stream" for incorrectly displaying peasant life on the collective farm.
More widely, 1936 marked the beginning of the Great Terror, in which many of the composer's friends and relatives were imprisoned or killed. These included his patron Marshal Tukhachevsky (shot months after his arrest); his brother-in-law Vsevolod Frederiks (a distinguished physicist, who was eventually released but died before he got home); his close friend Nikolai Zhilyayev (a musicologist who had taught Tukhachevsky; shot shortly after his arrest); his mother-in-law, the astronomer Sofiya Mikhaylovna Varzar (sent to a camp in Karaganda); his friend the Marxist writer Galina Serebryakova (20 years in camps); his uncle Maxim Kostrykin (died); and his colleagues Boris Kornilov and Adrian Piotrovsky (executed). His only consolation in this period was the birth of his daughter Galina in 1936; his son Maxim was born two years later.
Withdrawal of the Fourth Symphony.
The publication of the "Pravda" editorials coincided with the composition of Shostakovich's Fourth Symphony. The work marked a great shift in style for the composer due to the substantial influence of Gustav Mahler and a number of Western-style elements. The symphony gave Shostakovich compositional trouble, as he attempted to reform his style into a new idiom. The composer was well into the work when the fatal articles appeared. Despite this, Shostakovich continued to compose the symphony and planned a premiere at the end of 1936. Rehearsals began that December, but after a number of rehearsals Shostakovich, for reasons still debated today, decided to withdraw the symphony from the public. A number of his friends and colleagues, such as Isaak Glikman, have suggested that it was in fact an official ban which Shostakovich was persuaded to present as a voluntary withdrawal. Whatever the case, it seems possible that this action saved the composer's life: during this time Shostakovich feared for himself and his family. Yet Shostakovich did not repudiate the work; it retained its designation as his Fourth Symphony. A piano reduction was published in 1946, and the work was finally premiered in 1961, well after Stalin's death.
During 1936 and 1937, in order to maintain as low a profile as possible between the Fourth and Fifth symphonies, Shostakovich mainly composed film music, a genre favored by Stalin and lacking in dangerous personal expression.
"A Soviet artist's creative response to just criticism".
The composer's response to his denunciation was the Fifth Symphony of 1937, which was musically more conservative than his earlier works. Premiering on 21 November 1937 in Leningrad, it was a phenomenal success. The Fifth drove many to tears and welling emotions. Later, Shostakovich wrote in his supposed memoirs, "Testimony": "I'll never believe that a man who understood nothing could feel the Fifth Symphony. Of course they understood, they understood what was happening around them and they understood what the Fifth was about."
The success put Shostakovich in good standing once again. Music critics and the authorities alike, including those who had earlier accused Shostakovich of formalism, claimed that he had learned from his mistakes and had become a true Soviet artist. The composer Dmitry Kabalevsky, who had been among those who disassociated himself from Shostakovich when the "Pravda" article was published, praised the Fifth Symphony and congratulated Shostakovich for "not having given in to the seductive temptations of his previous 'erroneous' ways."
It was also at this time that Shostakovich composed the first of his string quartets. His chamber works allowed him to experiment and express ideas which would have been unacceptable in his more public symphonic pieces. In September 1937, he began to teach composition at the Leningrad Conservatory, which provided some financial security but interfered with his own creative work.
Second World War.
In 1939, before the Soviet forces attempted to invade Finland, the Party Secretary of Leningrad Andrei Zhdanov commissioned a celebratory piece from Shostakovich, entitled "Suite on Finnish Themes" to be performed as the marching bands of the Red Army would be parading through the Finnish capital Helsinki. The Winter War was a bitter experience for the Red Army, the parade never happened, and Shostakovich would never lay claim to the authorship of this work. It was not performed until 2001.
After the outbreak of war between the Soviet Union and Germany in 1941, Shostakovich initially remained in Leningrad. He tried to enlist for the military but was turned away because of his poor eyesight. To compensate, Shostakovich became a volunteer for the Leningrad Conservatory’s firefighter brigade and delivered a radio broadcast to the Soviet people "". The photograph for which he posed was published in newspapers throughout the country.
But his greatest and most famous wartime contribution was the Seventh Symphony. The composer wrote the first three movements in Leningrad and completed the work in Kuibyshev (now Samara) where he and his family had been evacuated. Whether or not Shostakovich really conceived the idea of the symphony with the siege of Leningrad in mind, it was officially claimed as a representation of the people of Leningrad’s brave resistance to the German invaders and an authentic piece of patriotic art at a time when morale needed boosting. The symphony was first premiered by the Bolshoi Theatre orchestra in Kuibyshev and was soon performed abroad in London and the United States. However, the most compelling performance was the Leningrad premiere by the Radio Orchestra in the besieged city. The orchestra had only fourteen musicians left, so the conductor Karl Eliasberg had to recruit anyone who could play a musical instrument to perform the symphony.
In spring 1943, the family moved to Moscow. At the time of the Eighth Symphony's premiere, the tide had turned for the Red Army. Therefore, the public, and most importantly the authorities, wanted another triumphant piece from the composer. Instead, they got the Eighth Symphony, perhaps the ultimate in sombre and violent expression within Shostakovich's output. In order to preserve the image of Shostakovich (a vital bridge to the people of the Union and to the West), the government assigned the name "Stalingrad" to the symphony, giving it the appearance of a mourning of the dead in the bloody Battle of Stalingrad. However, the symphony did not escape criticism. Shostakovich is reported to have said: "When the Eighth was performed, it was openly declared counter-revolutionary and anti-Soviet. They said, 'Why did Shostakovich write an optimistic symphony at the beginning of the war and a tragic one now? At the beginning we were retreating and now we're attacking, destroying the Fascists. And Shostakovich is acting tragic, that means he's on the side of the fascists.'" The work was unofficially but effectively banned until 1956.
The Ninth Symphony (1945), in contrast, was much lighter in tone. Gavriil Popov wrote that it was "splendid in its joie de vivre, gaiety, brilliance, and pungency!! By 1946, however, it was the subject of criticism. Israel Nestyev asked whether it was the right time for "a light and amusing interlude between Shostakovich's significant creations, a temporary rejection of great, serious problems for the sake of playful, filigree-trimmed trifles." The New York World-Telegram of 27 July 1946 was similarly dismissive: "The Russian composer should not have expressed his feelings about the defeat of Nazism in such a childish manner". Shostakovich continued to compose chamber music, notably his Second Piano Trio (Op. 67), dedicated to the memory of Sollertinsky, with a bittersweet, Jewish-themed "totentanz" finale.
Second denunciation.
In 1948, Shostakovich, along with many other composers, was again denounced for formalism in the Zhdanov decree. Andrei Zhdanov, Chairman of the RSFSR Supreme Soviet, accused Shostakovich and other composers (such as Sergei Prokofiev and Aram Khachaturian) for writing inappropriate and formalist music. This was part of an ongoing anti-formalism campaign intended to root out all Western compositional influence as well as any perceived "non-Russian" output. The conference resulted in the publication of the Central Committee’s Decree "On V. Muradeli’s opera "The Great Friendship"," which was targeted towards all Soviet composers and demanded that they only write "proletarian" music, or music for the masses. The accused composers, including Shostakovich, were summoned to make public apologies in front of the committee. Most of Shostakovich's works were banned, and his family had privileges withdrawn. Yuri Lyubimov says that at this time "he waited for his arrest at night out on the landing by the lift, so that at least his family wouldn't be disturbed."
The consequences of the decree for composers were harsh. Shostakovich was among those who were dismissed from the Conservatoire altogether. For Shostakovich, the loss of money was perhaps the largest blow. Others still in the Conservatory experienced an atmosphere that was thick with suspicion. No one wanted their work to be understood as formalist, so many resorted to accusing their colleagues of writing or performing anti-proletarian music.
In the next few years, he composed three categories of work: film music to pay the rent, official works aimed at securing official rehabilitation, and serious works "for the desk drawer". The latter included the Violin Concerto No. 1 and the song cycle "From Jewish Folk Poetry." The cycle was written at a time when the post-war anti-Semitic campaign was already under way, with widespread arrests including of I. Dobrushin and Yiditsky, the compilers of the book from which Shostakovich took his texts.
The restrictions on Shostakovich's music and living arrangements were eased in 1949, when Stalin decided that the Soviets needed to send artistic representatives to the Cultural and Scientific Congress for World Peace in New York City, and that Shostakovich should be amongst them. For Shostakovich, it was a humiliating experience culminating in a New York press conference where he was expected to read a prepared speech. Nicolas Nabokov, who was present in the audience, witnessed Shostakovich starting to read "in a nervous and shaky voice" before he had to break off "and the speech was continued in English by a suave radio baritone". Fully aware that Shostakovich was not free to speak his mind, Nabokov publicly asked the composer whether he supported the then recent denunciation of Stravinsky's music in the Soviet Union. Shostakovich, who was a great admirer of Stravinsky and had been influenced by his music, had no alternative but to answer in the affirmative. Nabokov did not hesitate to publish that this demonstrated that Shostakovich was "not a free man, but an obedient tool of his government." Shostakovich never forgave Nabokov for this public humiliation. That same year Shostakovich was obliged to compose the cantata "Song of the Forests," which praised Stalin as the "great gardener." In 1951 the composer was made a deputy to the Supreme Soviet of RSFSR.
Stalin's death in 1953 was the biggest step towards Shostakovich's rehabilitation as a creative artist, which was marked by his Tenth Symphony. It features a number of musical quotations and codes (notably the DSCH and Elmira motifs, Elmira Nazirova being a pianist and composer who had studied under Shostakovich in the year prior to his dismissal from the Moscow Conservatoire), the meaning of which is still debated, whilst the savage second movement, according to "Testimony", is intended as a musical portrait of Stalin himself. The Symphony ranks alongside the Fifth and Seventh as one of his most popular works. 1953 also saw a stream of premieres of the "desk drawer" works.
During the forties and fifties, Shostakovich had close relationships with two of his pupils: Galina Ustvolskaya and Elmira Nazirova. In the background to all this remained Shostakovich's first, open marriage to Nina Varzar until her death in 1954. He taught Ustvolskaya from 1937 to 1947. The nature of their relationship is far from clear: Mstislav Rostropovich described it as "tender". Ustvolskaya rejected a proposal of marriage from him after Nina's death. Shostakovich's daughter, Galina, recalled her father consulting her and Maxim about the possibility of Ustvolskaya becoming their stepmother. Ustvolskaya's friend, Viktor Suslin, said that she had been "deeply disappointed" in Shostakovich by the time of her graduation in 1947. The relationship with Nazirova seems to have been one-sided, expressed largely through his letters to her, and can be dated to around 1953 to 1956. He married his second wife, Komsomol activist Margarita Kainova, in 1956; the couple proved ill-matched, and divorced three years later.
In 1954, Shostakovich wrote the Festive Overture, opus 96, that was used as the theme music for the 1980 Summer Olympics. In addition his '"Theme from the film "Pirogov", Opus 76a: Finale" was played as the cauldron was lit at the 2004 Summer Olympics in Athens, Greece.
In 1959, Shostakovich appeared on stage in Moscow at the end of a concert performance of his Fifth Symphony, congratulating Leonard Bernstein and the New York Philharmonic Orchestra for their performance (part of a concert tour of the Soviet Union). Later that year, Bernstein and the New York Philharmonic recorded the symphony in Boston for Columbia Records.
Joining the Party.
The year 1960 marked another turning point in Shostakovich's life: he joined the Communist Party. The government wanted to appoint him General Secretary of the Composers' Union, but in order to hold that position he was required to attain Party membership. It was understood that Nikita Khrushchev, the First Secretary of the Communist Party from 1958 to 1964, was looking for support from the leading ranks of the intelligentsia in an effort to create a better relationship with the Soviet Union’s artists. This event has been interpreted variously as a show of commitment, a mark of cowardice, the result of political pressure, or as his free decision. On the one hand, the apparat was undoubtedly less repressive than it had been before Stalin's death. On the other, his son recalled that the event reduced Shostakovich to tears, and he later told his wife Irina that he had been blackmailed. Lev Lebedinsky has said that the composer was suicidal. Once he joined the Party, several articles denouncing individualism in music were published in "Pravda" under his name, though he did not actually write them. In addition, in joining the party, Shostakovich was also committing himself to finally writing the homage to Lenin that he had promised before. His Twelfth Symphony, which portrays the Bolshevik Revolution and was completed in 1961, was dedicated to Vladimir Lenin and called "The Year 1917." Around this time, his health also began to deteriorate.
Shostakovich's musical response to these personal crises was the Eighth String Quartet, composed in only three days. He subtitled the piece, "To the victims of fascism and war", ostensibly in memory of the Dresden fire bombing that took place in 1945. Yet, like the Tenth Symphony, this quartet incorporates quotations from several of his past works and his musical monogram: Shostakovich confessed to his friend Isaak Glikman "I started thinking that if some day I die, nobody is likely to write a work in memory of me, so I had better write one myself." Several of Shostakovich's colleagues, including Natalya Vovsi-Mikhoels and the cellist Valentin Berlinsky, were also aware of the Eighth Quartet's biographical intent.
In 1962 he married for the third time, to Irina Supinskaya. In a letter to Glikman, he wrote "her only defect is that she is 27 years old. In all other respects she is splendid: clever, cheerful, straightforward and very likeable." According to Galina Vishnevskaya, who knew the Shostakoviches well, this marriage was a very happy one: "It was with her that Dmitri Dmitriyevich finally came to know domestic peace... Surely, she prolonged his life by several years." In November he made his only venture into conducting, conducting a couple of his own works in Gorky; otherwise he declined to conduct, citing nerves and ill health as his reasons.
That year saw Shostakovich again turn to the subject of anti-Semitism in his Thirteenth Symphony (subtitled "Babi Yar"). The symphony sets a number of poems by Yevgeny Yevtushenko, the first of which commemorates a massacre of Ukrainian Jews during the Second World War. Opinions are divided how great a risk this was: the poem had been published in Soviet media, and was not banned, but it remained controversial. After the symphony's premiere, Yevtushenko was forced to add a stanza to his poem which said that Russians and Ukrainians had died alongside the Jews at Babi Yar.
In 1965 Shostakovich raised his voice in defense of poet Joseph Brodsky, who was sentenced to five years of exile and hard labor. Shostakovich co-signed protests together with Yevtushenko and fellow Soviet artists Kornei Chukovsky, Anna Akhmatova, Samuil Marshak, and the French philosopher Jean-Paul Sartre. After the protests the sentence was commuted, and Brodsky returned to Leningrad.
Later life.
In 1964 Shostakovich composed the music for the Russian film "Hamlet", which was favourably reviewed by the "New York Times": "But the lack of this aural stimulation – of Shakespeare's eloquent words – is recompensed in some measure by a splendid and stirring musical score by Dmitri Shostakovich. This has great dignity and depth, and at times an appropriate wildness or becoming levity".
In later life, Shostakovich suffered from chronic ill health, but he resisted giving up cigarettes and vodka. Beginning in 1958 he suffered from a debilitating condition that particularly affected his right hand, eventually forcing him to give up piano playing; in 1965 it was diagnosed as poliomyelitis. He also suffered heart attacks the following year and again in 1971, and several falls in which he broke both his legs; in 1967 he wrote in a letter:
"Target achieved so far: 75% (right leg broken, left leg broken, right hand defective). All I need to do now is wreck the left hand and then 100% of my extremities will be out of order."
A preoccupation with his own mortality permeates Shostakovich's later works, among them the later quartets and the Fourteenth Symphony of 1969 (a song cycle based on a number of poems on the theme of death). This piece also finds Shostakovich at his most extreme with musical language, with twelve-tone themes and dense polyphony used throughout. Shostakovich dedicated this score to his close friend Benjamin Britten, who conducted its Western premiere at the 1970 Aldeburgh Festival. The Fifteenth Symphony of 1971 is, by contrast, melodic and retrospective in nature, quoting Wagner, Rossini and the composer's own Fourth Symphony.
Shostakovich died of lung cancer on 9 August 1975 and after a civic funeral was interred in the Novodevichy Cemetery, Moscow. Even before his death he had been commemorated with the naming of the Shostakovich Peninsula on Alexander Island, Antarctica.
He was survived by his third wife, Irina; his daughter, Galina; and his son, Maxim, a pianist and conductor who was the dedicatee and first performer of some of his father's works. Shostakovich himself left behind several recordings of his own piano works, while other noted interpreters of his music include his friends Emil Gilels, Mstislav Rostropovich, Tatiana Nikolayeva, Maria Yudina, David Oistrakh, and members of the Beethoven Quartet.
His last work was his Viola Sonata, which was first performed on 28 December 1975, four months after his death.
Shostakovich's musical influence on later composers outside the former Soviet Union has been relatively slight, although Alfred Schnittke took up his eclecticism, and his contrasts between the dynamic and the static, and some of André Previn's music shows clear links to Shostakovich's style of orchestration. His influence can also be seen in some Nordic composers, such as Lars-Erik Larsson. Many of his Russian contemporaries, and his pupils at the Leningrad Conservatory, however, were strongly influenced by his style (including German Okunev, Boris Tishchenko, whose 5th Symphony of 1978 is dedicated to Shostakovich's memory, Sergei Slonimsky, and others). Shostakovich's conservative idiom has grown increasingly popular with audiences both within and beyond Russia, as the avant-garde has declined in influence and debate about his political views has developed.
Music.
Overview.
Shostakovich's works are broadly tonal and in the Romantic tradition, but with elements of atonality and chromaticism. In some of his later works (e.g., the Twelfth Quartet), he made use of tone rows. His output is dominated by his cycles of symphonies and string quartets, each totaling fifteen works. The symphonies are distributed fairly evenly throughout his career, while the quartets are concentrated towards the latter part. Among the most popular are the Fifth and Seventh Symphonies and the Eighth and Fifteenth Quartets. Other works include the operas "Lady Macbeth of Mtsensk", "The Nose" and the unfinished "The Gamblers" based on the comedy of Nikolai Gogol; six concertos (two each for piano, violin and cello); two piano trios; and a large quantity of film music.
Shostakovich's music shows the influence of many of the composers he most admired: Bach in his fugues and passacaglias; Beethoven in the late quartets; Mahler in the symphonies and Berg in his use of musical codes and quotations. Among Russian composers, he particularly admired Modest Mussorgsky, whose operas "Boris Godunov" and "Khovanshchina" he re-orchestrated; Mussorgsky's influence is most prominent in the wintry scenes of "Lady Macbeth" and the Eleventh Symphony, as well as in his satirical works such as "Rayok". Prokofiev's influence is most apparent in the earlier piano works, such as the first sonata and first concerto. The influence of Russian church and folk music is very evident in his works for unaccompanied choir of the 1950s.
Shostakovich's relationship with Stravinsky was profoundly ambivalent; as he wrote to Glikman, "Stravinsky the composer I worship. Stravinsky the thinker I despise." He was particularly enamoured of the Symphony of Psalms, presenting a copy of his own piano version of it to Stravinsky when the latter visited the USSR in 1962. (The meeting of the two composers was not very successful, however; observers commented on Shostakovich's extreme nervousness and Stravinsky's "cruelty" to him.)
Many commentators have noted the disjunction between the experimental works before the 1936 denunciation and the more conservative ones that followed; the composer told Flora Litvinova, "without 'Party guidance' ... I would have displayed more brilliance, used more sarcasm, I could have revealed my ideas openly instead of having to resort to camouflage." Articles published by Shostakovich in 1934 and 1935 cited Berg, Schoenberg, Krenek, Hindemith, "and especially Stravinsky" among his influences. Key works of the earlier period are the First Symphony, which combined the academicism of the conservatory with his progressive inclinations; "The Nose" ("The most uncompromisingly modernist of all his stage-works"); "Lady Macbeth." which precipitated the denunciation; and the Fourth Symphony, described in Grove's Dictionary as "a colossal synthesis of Shostakovich's musical development to date". The Fourth Symphony was also the first in which the influence of Mahler came to the fore, prefiguring the route Shostakovich was to take to secure his rehabilitation, while he himself admitted that the preceding two were his least successful.
In the years after 1936, Shostakovich's symphonic works were outwardly musically conservative, regardless of any subversive political content. During this time he turned increasingly to chamber works, a field that permitted the composer to explore different and often darker ideas without inviting external scrutiny. While his chamber works were largely tonal, they gave Shostakovich an outlet for sombre reflection not welcomed in his more public works. This is most apparent in the late chamber works, which portray what is described in Grove's Dictionary as a "world of purgatorial numbness"; in some of these he included the use of tone rows, although he treated these as melodic themes rather than serially. Vocal works are also a prominent feature of his late output, setting texts often concerned with love, death and art.
Jewish themes.
Even before the Stalinist anti-Semitic campaigns in the late 1940s and early 1950s, Shostakovich showed an interest in Jewish themes. He was intrigued by Jewish music’s "ability to build a jolly melody on sad intonations". Examples of works that included Jewish themes are the Fourth String Quartet (1949), the First Violin Concerto (1948), and the "Four Monologues on Pushkin Poems" (1952), as well as the Piano Trio in E minor (1944). He was further inspired to write with Jewish themes when he examined Moisei Beregovski’s thesis on the theme of Jewish folk music in 1946.
In 1948, Shostakovich acquired a book of Jewish folk songs, and from this he composed the song cycle "From Jewish Poetry". He initially wrote eight songs that were meant to represent the hardships of being Jewish in the Soviet Union. However in order to disguise this, Shostakovich ended up adding three more songs meant to demonstrate the great life Jews had under the Soviet regime. Despite his efforts to hide the real meaning in the work, the Union of Composers refused to approve his music in 1949 under the pressure of the anti-Semitism that gripped the country. "From Jewish Poetry" could not be performed until after Stalin’s death in March 1953, along with all the other works that were forbidden.
Posthumous publications.
In 2004, the musicologist Olga Digonskaya discovered a trove of Shostakovich manuscripts at the Glinka State Central Museum of Musical Culture, Moscow. In a cardboard file were some "300 pages of musical sketches, pieces and scores" in the hand of Shostakovich. "A composer friend bribed Shostakovich's housemaid to regularly deliver the contents of Shostakovich's office waste bin to him, instead of taking it to the garbage. Some of those cast-offs eventually found their way into the Glinka. ... The Glinka archive 'contained a huge number of pieces and compositions which were completely unknown or could be traced quite indirectly,' Digonskaya said."
Among these were Shostakovich's piano and vocal sketches for a prologue to an opera, "Orango" (1932). They have been orchestrated by the British composer Gerard McBurney and this work was premiered in December 2011 by the Los Angeles Philharmonic.
Criticism.
According to Shostakovich scholar Gerard McBurney, opinion is divided on whether his music is "of visionary power and originality, as some maintain, or, as others think, derivative, trashy, empty and second-hand". William Walton, his British contemporary, described him as "the greatest composer of the 20th century". Musicologist David Fanning concludes in Grove's Dictionary that, "Amid the conflicting pressures of official requirements, the mass suffering of his fellow countrymen, and his personal ideals of humanitarian and public service, he succeeded in forging a musical language of colossal emotional power."
Some modern composers have been critical. Pierre Boulez dismissed Shostakovich's music as "the second, or even third of Mahler". The Romanian composer and Webern disciple Philip Gershkovich called Shostakovich "a hack in a trance". A related complaint is that Shostakovich's style is vulgar and strident: Stravinsky wrote of "Lady Macbeth": "brutally hammering ... and monotonous". English composer and musicologist Robin Holloway described his music as "battleship-grey in melody and harmony, factory-functional in structure; in content all rhetoric and coercion."
In the 1980s, the Finnish conductor and composer Esa-Pekka Salonen was critical of Shostakovich and refused to conduct his music. For instance, he said in 1987:
Shostakovich is in many ways a polar counter-force for Stravinsky. [...] When I have said that the 7th symphony of Shostakovich is a dull and unpleasant composition, people have responded: "Yes, yes, but think of the background of that symphony." Such an attitude does no good to anyone.
However, Salonen has since performed and recorded several of Shostakovich's works, including the Piano Concertos Nos. 1 and 2 (1999), the Violin Concerto No. 1 (2010), the Prologue to "Orango" and the Symphony No. 4 (2012).
It is certainly true that Shostakovich borrows extensively from the material and styles both of earlier composers and of popular music; the vulgarity of "low" music is a notable influence on this "greatest of eclectics". McBurney traces this to the avant-garde artistic circles of the early Soviet period in which Shostakovich moved early in his career, and argues that these borrowings were a deliberate technique to allow him to create "patterns of contrast, repetition, exaggeration" that gave his music the large-scale structure it required.
Personality.
Shostakovich was in many ways an obsessive man: according to his daughter he was "obsessed with cleanliness"; he synchronised the clocks in his apartment; he regularly sent cards to himself to test how well the postal service was working. Elizabeth Wilson's "Shostakovich: A Life Remembered" (1994 edition) indexes 26 references to his nervousness. Mikhail Druskin remembers that even as a young man the composer was "fragile and nervously agile". Yuri Lyubimov comments, "The fact that he was more vulnerable and receptive than other people was no doubt an important feature of his genius". In later life, Krzysztof Meyer recalled, "his face was a bag of tics and grimaces".
In his lighter moods, sport was one of his main recreations, although he preferred spectating or umpiring to participating (he was a qualified football referee). His favourite football club was Zenit Leningrad, which he would watch regularly. He also enjoyed playing card games, particularly patience.
He was fond of satirical writers such as Gogol, Chekhov and Mikhail Zoshchenko. The influence of the latter in particular is evident in his letters, which include wry parodies of Soviet officialese. Zoshchenko himself noted the contradictions in the composer's character: "he is ... frail, fragile, withdrawn, an infinitely direct, pure child ... he is also hard, acid, extremely intelligent, strong perhaps, despotic and not altogether good-natured (although cerebrally good-natured)".
He was diffident by nature: Flora Litvinova has said he was "completely incapable of saying 'No' to anybody." This meant he was easily persuaded to sign official statements, including a denunciation of Andrei Sakharov in 1973; on the other hand he was willing to try to help constituents in his capacities as chairman of the Composers' Union and Deputy to the Supreme Soviet. Oleg Prokofiev commented that "he tried to help so many people that ... less and less attention was paid to his pleas." When asked if he believed in God, Shostakovich said "No, and I am very sorry about it."
Orthodoxy and revisionism.
Shostakovich's response to official criticism and, what is more important, the question of whether he used music as a kind of covert dissidence is a matter of dispute. He outwardly conformed to government policies and positions, reading speeches and putting his name to articles expressing the government line. But it is evident he disliked many aspects of the regime, as confirmed by his family, his letters to Isaak Glikman, and the satirical cantata "Rayok", which ridiculed the "anti-formalist" campaign and was kept hidden until after his death. He was a close friend of Marshal of the Soviet Union Mikhail Tukhachevsky, who was executed in 1937 during the Great Purge.
It is also uncertain to what extent Shostakovich expressed his opposition to the state in his music. The revisionist view was put forth by Solomon Volkov in the 1979 book "Testimony", which was claimed to be Shostakovich's memoirs dictated to Volkov. The book alleged that many of the composer's works contained coded anti-government messages, that would place Shostakovich in a tradition of Russian artists outwitting censorship that goes back at least to the early 19th century poet Alexander Pushkin. It is known that he incorporated many quotations and motifs in his work, most notably his signature DSCH theme. His longtime collaborator Yevgeny Mravinsky said that "Shostakovich very often explained his intentions with very specific images and connotations."
The revisionist perspective has subsequently been supported by his children, Maxim and Galina, and many Russian musicians. Volkov has further argued, both in "Testimony" and in "Shostakovich and Stalin", that Shostakovich adopted the role of the "yurodivy" or holy fool in his relations with the government. Other prominent revisionists are Ian MacDonald, whose book "The New Shostakovich" put forward further revisionist interpretations of his music, and Elizabeth Wilson, whose "Shostakovich: A Life Remembered" provides testimony from many of the composer's acquaintances.
Musicians and scholars including Laurel Fay and Richard Taruskin contest the authenticity and debate the significance of "Testimony", alleging that Volkov compiled it from a combination of recycled articles, gossip, and possibly some information direct from the composer. Fay documents these allegations in her 2002 article 'Volkov's "Testimony" reconsidered', showing that the only pages of the original "Testimony" manuscript that Shostakovich had signed and verified are word-for-word reproductions of earlier interviews given by the composer, none of which are controversial. (Against this, it has been pointed out by Allan B. Ho and Dmitry Feofanov that at least two of the signed pages contain controversial material: for instance, "on the first page of chapter 3, where [Shostakovich notes that the plaque that reads 'In this house lived ' should also say 'And in this house his wife was brutally murdered'.")
Recorded legacy.
In May 1958, during a visit to Paris, Shostakovich recorded his two piano concertos with André Cluytens, as well as some short piano works. These were issued by EMI on an LP, reissued by Seraphim Records on LP, and eventually digitally remastered and released on CD. Shostakovich recorded the two concertos in stereo in Moscow for Melodiya. Shostakovich also played the piano solos in recordings of the Cello Sonata, Op. 40 with cellist Daniil Shafran and also with Mstislav Rostropovich; the Violin Sonata, Op. 134, with violinist David Oistrakh; and the Piano Trio, Op. 67 with violinist David Oistrakh and cellist Miloš Sádlo. There is also a short sound film of Shostakovich as soloist in a 1930s concert performance of the closing moments of his first piano concerto. A colour film of Shostakovich supervising one of his operas, from his last year, was also made. A major achievement was the recording of the original, unexpurgated score for Lady Macbeth of Mtsensk by EMI. There was at least one recording of the cleaned up version, Katerina Ismailova that Shostakovich had made to satisfy Soviet censorship. But when conductor Mstislav Rostropovich and his wife, soprano Galina Vishnevskaya were finally allowed to emigrate to the West, the composer begged them to record the full original score, which they did in 1979. It features Vishnevskaya as Katerina, Nicolai Gedda as Sergei, Dimiter Petkov as Boris Ismailov and a brilliant supporting cast under Rostropovich's direction.

</doc>
<doc id="8521" url="https://en.wikipedia.org/wiki?curid=8521" title="Doom (1993 video game)">
Doom (1993 video game)

Doom (typeset as DOOM in official documents) is a 1993 science fiction horror-themed first-person shooter (FPS) video game by id Software. It is considered one of the most significant and influential titles in the video game industry, for having ushered in the popularity of the first-person shooter genre. The original game was divided into three nine-level episodes and was distributed via shareware and mail order. The Ultimate Doom, an updated release of the original game featuring a fourth episode, was released in 1995 and sold at retail.
In "Doom", players assume the role of an unnamed space marine, who became popularly known as "Doomguy", fighting his way through hordes of invading demons from Hell. With one third of the game, nine levels, distributed as shareware, "Doom" was played by an estimated 15–20 million people within two years of its release, popularizing the mode of gameplay and spawning a gaming subculture. In addition to popularizing the FPS genre, it pioneered immersive 3D graphics, networked multiplayer gaming, and support for customized additions and modifications via packaged files in a data archive known as "WADs". As a sign of its effect on the industry, first-person shooter games from the genre's boom in the 1990s, helped in no small part by the game's release, became known simply as ""Doom" clones". Its graphic violence, as well as satanic imagery, made "Doom" the subject of controversy.
The "Doom" franchise was later continued with the follow-up "" (1994) and numerous expansion packs, including "Master Levels for Doom II" (1995), and "Final Doom" (1996). Originally released for PC DOS, the games have later been ported to numerous other platforms. Once the game's source code was released in 1997, it spawned even more adaptations, as fans further ported the code to countless devices. The series started to lose mainstream appeal as the technology of the "Doom" game engine was surpassed in the mid-1990s, although fans have continued making WADs, speedruns, and modifications to the original. The franchise again received popular attention in 2004 with the release of "Doom 3", a retelling of the original game using new technology, and an associated 2005 "Doom" motion picture. "Doom 4" was announced as in production in 2008 and was later retitled simply as "Doom".
Plot.
"Doom", a science fiction/horror themed video game, has a background which is given in the game's instruction manual; the rest of the story is advanced with short messages displayed between each section of the game (called "episodes"), the action as the player character progresses through the levels, and some visual cues.
The player takes the role of an unnamed space marine ("Doomguy") who has been punitively posted to Mars after assaulting his commanding officer, who ordered his unit to fire on civilians. The Martian space marine base acts as security for the Union Aerospace Corporation, a multi-planetary conglomerate, which is performing secret experiments with teleportation by creating gateways between the two moons of Mars, Phobos and Deimos. Mars is considered by space marines to be the dullest assignment imaginable. This all changes when the UAC experiments go horribly wrong. Computer systems on Phobos malfunction, Deimos disappears entirely, and "something fragging evil" starts pouring out of the gateway, killing or possessing all UAC personnel.
Responding to a frantic distress call from the overrun scientists, the Martian marine unit is quickly sent by ship from Mars to Phobos to investigate, where the player character is left to guard the perimeter with only a pistol while the rest of the group proceeds inside. The marine hears assorted radio messages, gunfire, and screams, followed by silence: "Seems your buddies are dead." The player cannot navigate the ship off of Phobos alone and sees that the only way out is to fight through the Phobos complex.
As the last man standing, the player character's mission is to fight through the entire onslaught of demonic enemies by himself in order to keep them from attacking Earth. "Knee-Deep in the Dead", the first episode and the only one in the shareware version, is set in the high-tech military bases, power plants, computer centers and geological anomalies on Phobos. It ends with the player character entering the teleporter leading to Deimos, only to be overwhelmed by monsters.
In the second episode, "The Shores of Hell", the marine has successfully teleported to Deimos. He fights his way through installations on Deimos, similar to those on Phobos, but warped and distorted from the demon invasion and interwoven with beastly architecture. After defeating the titanic Cyberdemon, the marine discovers the truth about the vanished moon: it is floating above Hell.
The third episode, called "Inferno", begins after the marine climbs off Deimos to the surface. The marine fights his way through Hell and defeats the Spider Mastermind that planned the invasion. Then a hidden doorway back to Earth opens for the hero, who has "proven too tough for Hell to contain". However, a burning city and a rabbit's head impaled on a stake (named in "The Ultimate Doom" as the marine's pet rabbit, Daisy) show that the demons have invaded Earth, setting the stage for "". The retcons the events of "Doom" as an alien invasion of the Mars moon bases.
In "The Ultimate Doom" expansion, in the fourth episode "Thy Flesh Consumed", it tells that the marine fought valiantly against the hordes of demons that the Spider Mastermind sent through that hidden doorway but ultimately the forces of Hell prevailed in the invasion of Earth. The locales of "Thy Flesh Consumed" are varied, including a mix of high-tech bases and demonic temples, though the atmosphere appears to be Earth.
Gameplay.
Being a first-person shooter, "Doom" is experienced through the eyes of the main character. This character is not named throughout the game. The game's designer, John Romero, has pointed out that this is so the player feels more involved in the game: "There was never a name for the DOOM marine because it's supposed to be you." At its core, the gameplay is similar to classic shooter games, presenting the player with the challenge of surviving while shooting every enemy in sight, but with its pseudo-3D first-person perspective giving environments a spatial representation that has a major effect on the level design and gameplay experience.
In order for the game to be completed, the marine must fight through Phobos, Deimos, and then Hell itself, each presented as an episode containing eight distinct levels, along with an optional ninth hidden level for each one. "The Ultimate Doom", the retail store version of the game, adds a fourth episode, "Thy Flesh Consumed." Set between the end of "Doom" and before "Doom II" and featuring the first contribution of Tim Willits to the Doom franchise, the fourth episode was designed for expert Doom players seeking a major challenge (being considerably more difficult than the original episodes).
The objective of each level is simply to locate the exit room that leads to the next area, marked with an exit sign and/or a special kind of door, while surviving all hazards on the way. Among the obstacles are demonic monsters, pits of toxic or radioactive slime, ceilings that lower and crush anything below them, and locked doors which require a keycard, skull-shaped key device, or a remote switch to be located. The levels are sometimes labyrinthine and feature plenty of items such as additional ammo, health increases and other "power-ups" along the way, as well as the occasional secret areas which are not immediately obvious as a reward for players who explore more carefully. To ease navigation through the levels, a full screen automap is available and shows the areas explored to that point. Many versions of "Doom" (and its sequels) include secret levels which are accessed by the player discovering alternate exits, often hidden behind secret doors, hidden passageways, or in areas which are difficult to reach. Despite carrying masses of high-tech weaponry, the main character can still run at blistering speeds.
"Doom" is notable for the weapons arsenal available to the marine, which became prototypical for first-person shooters. The player character starts armed only with a pistol, and fists in case the ammunition runs out, but larger weapons can be picked up: these are a chainsaw, a shotgun, a chaingun, a rocket launcher, a plasma rifle, and finally the immensely powerful BFG 9000. There is a wide array of power-ups, such as a backpack that increases the player character's ammunition-carrying capacity, armor, first aid kits to restore health, the berserk pack which both restores health and causes the player's punching attack to deal enormous damage, supernatural blue orbs (named "soul spheres" in the manuals) that boost the player character's health up to a maximum of 200%, nightvision, computer maps (which show every area of the level), partial invisibility, and protective suits that allow the player to survive in toxic acids.
The enemy monsters in "Doom" make up the central gameplay element. The player character faces them in large numbers, with the number generally increased when the higher of the game's five difficulty levels is chosen when starting a new game. There are ten types of monsters, including possessed undead humans as well as demons, all which vary in many ways. The monsters have very simple behavior, consisting of either walking toward their opponent, or attacking by throwing fireballs, biting, and scratching. They will fight each other if one monster is accidentally harmed by another (though most monsters are not harmed by the ranged attacks of their own kind).
Aside from the single player game mode, "Doom" features two multiplayer modes playable over a network: "cooperative", in which two to four players team up, and "deathmatch", in which two to four players play against each other. Online multiplayer was eventually made available through the DWANGO service.
Development.
The development of "Doom" started in 1992, when John D. Carmack developed a new 3D game engine, the Doom engine, while the rest of the id Software team finished the "Wolfenstein 3D" prequel, "Spear of Destiny". When the game design phase began in late 1992, the main thematic influences were the science fiction action film "Aliens" and the horror film "Evil Dead II". The title of the game was picked by John Carmack: "There is a scene in "The Color of Money" where Tom Cruise shows up at a pool hall with a custom pool cue in a case. 'What do you have in there?' asks someone. 'Doom.' replied Cruise with a cocky grin. That, and the resulting carnage, was how I viewed us springing the game on the industry."
Designer Tom Hall wrote an elaborate design document called the "Doom Bible", according to which the game would feature a detailed storyline, multiple player characters, and a number of interactive features. However, many of his ideas were discarded during development in favor of simpler design primarily advocated by John Carmack, resulting in Hall in the end being forced to resign due to not contributing effectively in the direction the rest of the team was going. Most of the level design that ended up in the final game is that of John Romero and Sandy Petersen. The graphics, by Adrian Carmack, Kevin Cloud and Gregor Punchatz, were modelled in various ways: although much was drawn or painted, several of the monsters were built from sculptures in clay or latex, and some of the weapons are toy guns from Toys "R" Us. A heavy metal-ambient soundtrack was supplied by Bobby Prince.
Engine technology.
"Doom"s primary distinguishing feature at the time of its release was its relatively realistic 3D graphics. The advance from id Software's previous game "Wolfenstein 3D" was enabled by several new features in the "Doom" engine, including height differences (all rooms in "Wolfenstein 3D" have the same height), full texture mapping of all surfaces (in "Wolfenstein 3D", floors and ceilings are flat colors) and varying light levels and custom palettes (all areas in "Wolfenstein 3D" are fully lit at the same brightness). The latter contributed to "Doom"s visual authenticity, atmosphere and gameplay, as the use of darkness to frighten or confuse the player was nearly unheard of in games released prior to "Doom"; palette modifications were used to enhance effects such as the berserk power-up which tints the player's vision red.
In contrast to the static levels of "Wolfenstein 3D", those in "Doom" are highly dynamic: platforms can lower and rise, floors can rise sequentially to form staircases, and bridges can rise and fall. The immersive environments were enhanced further by the stereo sound system, which made it possible to roughly determine the direction and distance of a sound effect. The player is kept on guard by the grunts and growls of monsters, and receives occasional clues to finding secret areas in the form of sounds of hidden doors opening remotely. As in "Wolfenstein 3D", enemies can also become aware of the player's presence by hearing distant gunshots.
John Carmack had to make use of several tricks for these features to run smoothly on home computers of 1993. Most significantly, the "Doom" engine and levels are not truly three-dimensional; they are internally represented on a single plane, with height differences stored separately as displacements (a similar technique is still used in many games to create expansive outdoor environments). This allows a two point perspective projection, with several design limitations: for example, it is not possible in the "Doom" engine to create one room over another room in a level. However, thanks to its two-dimensional property, the environment can be rendered very quickly, using a binary space partitioning method. Another benefit was the clarity of the automap, as that could be rendered with 2D vectors without any risk of overlapping. Additionally, the BSP tree technology created by Bruce Naylor was used.
Another important feature of the "Doom" engine is its modular data files, which allow most of the game's content to be replaced by loading custom WAD files. "Wolfenstein 3D" was not designed to be expandable, but fans had nevertheless figured out how to create their own levels for it, and "Doom" was designed to further extend the possibilities. The ability to create custom scenarios contributed significantly to the game's popularity (see the section on WADs, below).
Release.
The development of "Doom" was surrounded by much anticipation. The large number of posts in Internet newsgroups about "Doom" led to the SPISPOPD joke, to which a nod was given in the game in the form of a cheat code. In addition to news, rumors and screenshots, unauthorized leaked alpha versions also circulated online. Many years later these alpha versions were sanctioned by id Software because of historical interest; they reveal how the game progressed from its early design stages. The first public version of "Doom" was uploaded to Software Creations BBS and an FTP server at the University of Wisconsin–Madison on December 10, 1993.
"Doom" was released as shareware, with people encouraged to distribute it further. Although most users did not purchase the registered version, over one million copies have been sold, and the popularity helped the sales of later games in the "Doom" series that were not released as shareware. In 1995, "The Ultimate Doom" (version 1.9, including Episode IV) was released, making this the first time that "Doom" was sold commercially in stores.
In a press release dated January 1, 1993, id Software had written that they expected "Doom" to be "the number one cause of decreased productivity in businesses around the world." This prediction came true at least in part: "Doom" became a major problem at workplaces, both occupying the time of employees and clogging computer networks with traffic caused by deathmatches. Intel, Lotus Development and Carnegie Mellon University are among many organizations reported to form policies specifically disallowing "Doom"-playing during work hours. At the Microsoft campus, "Doom" was by one account equal to a "religious phenomenon".
In late 1995, "Doom" was estimated to be installed on more computers worldwide than Microsoft's new operating system Windows 95, despite million-dollar advertising campaigns for the latter. The game's popularity prompted Bill Gates to briefly consider buying id Software. This led Microsoft to develop a Windows 95 port of "Doom" to promote the operating system as a gaming platform. The development team in this effort was led by then-employee Gabe Newell. One Windows 95 promotional video had Bill Gates digitally superimposed into the game. The 1995 release of Microsoft Excel 95 included a "Doom-esque" secret level as an Easter egg containing portraits of the programmers among other things.
The game was made available on Steam on August 3, 2007, running on the DOSBox DOS emulator.
Expansions and ports.
The popularity of "Doom" led to the development of expansion packs and alternate versions based on the same game engine, including "The Ultimate Doom" (1995), "Final Doom" (1996), and "Doom 64" (1997). "Doom" became a "killer app" that all capable consoles and operating systems were expected to have, and versions of "Doom" have subsequently been released for the following systems: DOS, OS/2, Microsoft Windows, Linux, Amiga, Apple Macintosh, Super NES, Genesis 32X, PlayStation, Game Boy Advance, iOS, Symbian OS, RISC OS, Atari Jaguar, Sega Saturn, Tapwave Zodiac, 3DO, Xbox, and Xbox 360 (via Xbox Live Arcade). Some of these were bestsellers even many years after initial release. In 2013, a version of "Doom" was ported to the Commodore VIC-20, a vintage 1980 introductory home computer having only 3,583 bytes of BASIC RAM, an 8 bit 6502A processor with rudimentary graphics, no sprites, and just 8 colors.
WADs.
The ability for others to create custom levels and otherwise modify the game, in the form of custom WAD files (short for "Where's All the Data?"), turned out to be a particularly popular aspect of "Doom". Gaining the first large mod-making community, "Doom" affected the culture surrounding first-person shooters, and also the industry. Several future professional game designers started their careers making "Doom" WADs as a hobby, among them Tim Willits, who later became the lead designer at id Software.
The first level editors appeared in early 1994, and additional tools have been created that allow most aspects of the game to be edited. Although the majority of WADs contain one or several custom levels mostly in the style of the original game, others implement new monsters and other resources, and heavily alter the gameplay; several popular movies, television series, other video games and other brands from popular culture have been turned into "Doom" WADs by fans, including "Aliens", "Star Wars", "The X-Files", "Teenage Mutant Ninja Turtles","The Simpsons", "South Park", "Sailor Moon", "Dragon Ball Z", "Red Faction", "The Thing", "Pokémon", "Beavis and Butt-head", "Batman", and "Sonic the Hedgehog". Some works, like the "Theme Doom Patch", combined enemies from several films, such as "Aliens", "Predator", and "The Terminator". Some add-on files were also made that changed the sounds made by the various characters and weapons.
Around 1994 and 1995, WADs were primarily distributed online over bulletin board systems or sold in collections on compact discs in computer shops, sometimes bundled with editing guide books. FTP servers became the primary method in later years. A few WADs have been released commercially, including the "Master Levels for Doom II", which was released in 1995 along with "Maximum Doom", a CD containing 1,830 WADs that had been downloaded from the Internet. Several thousand WADs have been created in total: the "idgames" FTP archive contains over 18,000 files, and this represents only a fraction of the complete output of "Doom" fans. Third party programs were also written to handle the loading of various WADs, since the game is a DOS game and all commands had to be entered on the command line to run. A typical launcher would allow the player to select which files to load from a menu, making it much easier to start. In 1995, WizardWorks Software released the "D!Zone" pack featuring hundreds of levels for "Doom" and "Doom II". "D!Zone" was reviewed in "Dragon" by Jay & Dee; Jay gave the pack 1 out of 5 stars, while Dee gave the pack 1½ stars.
Reception.
"Doom" was widely praised in the gaming press and is broadly considered to be one of the most important and influential titles in gaming history. Upon release, "GamesMaster" gave it a 90% rating. "Dragon" gave it five stars, praising the improvements over "Wolfenstein 3D", the "fast-moving arcade shoot 'em up" gameplay, and network play. "Edge" gave it a 7/10 rating, criticizing the "fairly simple 3D perspective maze adventure/shoot 'em up" gameplay but praising the graphics and levels.
In 1996, "Computer Gaming World" ranked it as the fifth best video game of all time. In 2001, "Doom" was voted the number one game of all time in a poll among over 100 game developers and journalists conducted by GameSpy. In 2003, IGN ranked it as the 44th top video game of all time and also called it ""the" breakthrough game of 1993", adding: "Its arsenal of powerful guns (namely the shotgun and BFG), intense level of gore and perfect balance of adrenaline-soaked action and exploration kept this gamer riveted for years." "PC Gamer" proclaimed "Doom" the most influential game of all time in its ten-year anniversary issue in April 2004. In 2004, readers of "Retro Gamer" voted "Doom" as the ninth top retro game, with the editors commenting: "Only a handful of games can claim that they’ve changed the gaming world, and "Doom" is perhaps the most qualified of them all." In 2005, IGN ranked it as the 39th top game. On March 12, 2007, "The New York Times" reported that "Doom" was named to a list of the ten most important video games of all time, the so called game canon. The Library of Congress took up this video game preservation proposal and began with the games from this list.
In 2009, GameTrailers ranked "Doom" as number one "breakthrough PC game". That same year, "Game Informer" put "Doom" sixth on their list of the games of all time, stating that it gave "the genre the kick start it needed to rule the gaming landscape two decades later." "Game Informer" staff also put it sixth on their 2001 list of the 100 best games ever. In 2012, "Time" named it one of the 100 greatest video games of all time as "it established the look and feel of later shooters as surely as Xerox PARC established the rules of the virtual desktop," adding that "its impact also owes a lot to the gonzo horror sensibility of its designers, including John Romero, who showed a bracing lack of restraint in their deployment of gore and Satanic iconography." Including "Doom" on the list of the greatest games of all time, GameSpot wrote that "despite its numerous appearances in other formats and on other media, longtime fans will forever remember the original 1993 release of "Doom" as the beginning of a true revolution in action gaming."
A common criticism of "Doom" was that it was not a true 3D game, since the game engine did not allow corridors and rooms to be stacked on top of one another (room-over-room), and instead relied on graphical trickery to make it appear that the player character and enemies were moving along differing elevations.
The game was ported to numerous console gaming platforms both domestically and abroad where it maintained its popularity, receiving generally favorable critical reception.
Controversies.
"Doom" was notorious for its high levels of graphic violence and satanic imagery, which generated controversy from a broad range of groups. "Doom" for the Genesis 32X was among one of the first video games to be given an M for Mature rating from the Entertainment Software Rating Board due to its violent gore and nature. Yahoo! Games listed it as one of the top ten most controversial games of all time. It was criticized by religious organizations for its diabolic undertones and was dubbed a "mass murder simulator" by critic and Killology Research Group founder David Grossman. "Doom" prompted fears that the then-emerging virtual reality technology could be used to simulate extremely realistic killing.
The game again sparked controversy throughout a period of school shootings in the United States when it was found that Eric Harris and Dylan Klebold, who committed the Columbine High School massacre on April 20, 1999, were avid players of the game. While planning for the massacre, Harris said in his journal that the killing would be "like playing "Doom"", and "it'll be like the LA riots, the Oklahoma bombing, WWII, Vietnam, "Duke Nukem" and "Doom" all mixed together", and that his shotgun was "straight out of the game". A rumor spread afterwards that Harris had designed a "Doom" level that looked like the high school, populated with representations of Harris's classmates and teachers, and that Harris practiced for his role in the shootings by playing the level over and over. Although Harris did design "Doom" levels, which later became known as the 'Harris levels', none have been found to be based on Columbine High School.
While "Doom" and other violent video games have been blamed for nationally covered school shootings, 2008 research featured by Greater Good Science Center shows that the two are not closely related. Harvard medical school researchers Cheryl Olson and Lawrence Kutner found that violent video games did not correlate to school shootings. The U.S. Secret Service and Department of Education analyzed 37 incidents of school violence and sought to develop a profile of school shooters, they discovered that the most common traits among shooters were that they were male and had histories of depression and attempted suicide. While many of the killers—like the vast majority of young teenage boys—did play video games, this study did not find a relationship between game play and school shootings. In fact, only one eighth of the shooters showed any special interest in violent video games; far less than the number of shooters who seemed attracted to books and movies with violent content.
Excess internet usage.
When "Doom" came out, complaints soon started from internet node managers about excess load on their servers caused by "Doom" inter-player communication packages, and to some server managers' antivirus software was added an "Antidoom" package that blocked "Doom"-related packages and sent a "Doom" "end this game" code to any "Doom" players detected.
Legacy.
"Doom" franchise.
"Doom" has appeared in several forms in addition to video games, including a "Doom" comic book, four novels by Dafydd Ab Hugh and Brad Linaweaver (loosely based on events and locations in the games), a and a live-action film starring Karl Urban and The Rock released in 2005. The game's development and impact on popular culture is also the subject of the book "" by David Kushner.
The "Doom" series remained dormant between 1997 and 2000, when "Doom 3" was announced. A retelling of the original "Doom" using entirely new graphics technology, "Doom 3" was hyped to provide as large a leap in realism and interactivity as the original game and helped renew interest in the franchise when it was released in 2004. After the "Doom 4" project development was scrapped in 2013, id's Tim Willits said that the next game in the "Doom" series was still the team's focus, but it has not been confirmed to be titled "Doom 4". It was renamed to simply "Doom" in 2014.
Clones.
"Doom" was influential and dozens of new first-person shooter titles appeared following "Doom" release, and they were often referred to as ""Doom" clones" rather than "first-person shooters". The term ""Doom" clone" was used to describe the style of gameplay in "Doom"-like games. While the term was initially popular, it was, after 1996, gradually replaced by "first-person shooter", and the phrase "first-person shooter" had firmly superseded ""Doom" clone" around 1998. Some of these were certainly "clones", hastily assembled and quickly forgotten, while others explored new grounds of the genre and were highly acclaimed. Many of the games closely imitated features in "Doom" such as the selection of weapons and cheat codes. "Doom" principal rivals were Apogee's "Rise of the Triad" and Looking Glass Studios' "System Shock". The popularity of "Star Wars"-themed WADs is rumored to have been the factor that prompted LucasArts to create their first-person shooter "Dark Forces".
The "Doom" game engine was licensed by id Software to several other companies, who released their own games using the technology, including "Heretic", "", "Strife: Quest for the Sigil", and "Hacx: Twitch 'n Kill". A "Doom"-based game called "Chex Quest" was released in 1996 by Ralston Foods as a promotion to increase cereal sales, and the United States Marine Corps released "Marine Doom".
When 3D Realms released "Duke Nukem 3D" in 1996, a tongue-in-cheek science fiction shooter based on Ken Silverman's technologically similar "Build" engine, id Software was nearly finished developing "Quake", its next-generation game, which mirrored "Doom"s success for much of the remainder of the 1990s and reduced interest in its predecessor.
Community.
In addition to the thrilling nature of the single-player game, the deathmatch mode was an important factor in the game's popularity. "Doom" was not the first first-person shooter with a deathmatch mode; "Maze War", an FPS released in 1974, was running multiplayer deathmatch over ethernet on Xerox computers by 1977. The widespread distribution of PC systems and the violence in "Doom" made deathmatching particularly attractive. Two-player multiplayer was possible over a phone line by using a modem, or by linking two PCs with a null-modem cable. Because of its widespread distribution, "Doom" hence became the game that introduced deathmatching to a large audience and was also the first game to use the term "deathmatch".
Although the popularity of the "Doom" games dropped with the release of more modern first-person shooters, the game still retains a strong fan base that continues to this day by playing competitively and creating WADs, and "Doom"-related news is still tracked at multiple websites such as Doomworld. Interest in "Doom" was renewed in 1997, when the source code for the "Doom" engine was released (it was also placed under the GNU General Public License on October 3, 1999). Fans then began porting the game to various operating systems, even to previously unsupported platforms such as the Dreamcast. As for the PC, over 50 different "Doom" source ports have been developed. New features such as OpenGL rendering and scripting allow WADs to alter the gameplay more radically.
Devoted players have spent years creating speedruns for "Doom", competing for the quickest completion times and sharing knowledge about routes through the levels and how to exploit bugs in the "Doom" engine for shortcuts. Achievements include the completion of both "Doom" and "Doom II" on the "Ultra-Violence" difficulty setting in less than 30 minutes each. In addition, a few players have also managed to complete "Doom II" in a single run on the difficulty setting "Nightmare!", on which monsters are more aggressive, launch faster projectiles (or, in the case of the Pinky Demon, simply move faster), and respawn roughly 30 seconds after they have been killed (level designer John Romero characterized the idea of such a run as "having to be impossible"). Movies of most of these runs are available from the COMPET-N website.
Online co-op and deathmatch play are still continued on fan created services.
In 2011, a modification for "Doom" was released with the intent of replicating the design style of the original game.

</doc>
<doc id="8522" url="https://en.wikipedia.org/wiki?curid=8522" title="Denver">
Denver

Denver (officially, The City and County of Denver) () is the capital and most populous municipality of the U.S. state of Colorado. , Denver is also the most populous county in Colorado. Denver is located in the South Platte River Valley on the western edge of the High Plains just east of the Front Range of the Rocky Mountains. The Denver downtown district is located immediately east of the confluence of Cherry Creek with the South Platte River, approximately east of the foothills of the Rocky Mountains. Denver is nicknamed the "Mile-High City" because its official elevation is exactly one mile () above sea level, making it one of the highest major cities in the United States. The 105th meridian west of Greenwich, the longitudinal reference for the Mountain Time Zone, passes directly through Denver Union Station.
Denver is ranked as a Beta- world city by the Globalization and World Cities Research Network. With a 2015 estimated population of 682,545, Denver ranks as the 21st-most populous U.S. city. The 10-county Denver-Aurora-Lakewood, CO Metropolitan Statistical Area had an estimated 2015 population of 2,814,330 and ranked as the 19th most populous U.S. metropolitan statistical area. The 12-city Denver-Aurora, CO Combined Statistical Area had an estimated 2015 population of 3,418,876, which ranks as the 16th most populous U.S. metropolitan area. Denver is the most populous city of the 18-county Front Range Urban Corridor, an oblong urban region stretching across two states with an estimated 2015 population of 4,757,713. Denver is the most populous city within a radius and the most populous city in the Mountain West and the third-most populous city in the Southwestern United States after Phoenix, Arizona and El Paso, Texas. Its metropolitan population is the second-largest in the Southwest after that of Phoenix. Denver ranks No. 1 on U.S. News & World Report's list of the 2016 Best Places to Live in the USA.
History.
Denver City was founded in November 1858 as a mining town during the Pike's Peak Gold Rush in western Kansas Territory. That summer, a group of gold prospectors from Lawrence, Kansas, had arrived and established Montana City on the banks of the South Platte River. This was the first settlement in what was later to become the city of Denver. The site faded quickly, however, and by the summer of 1859 it was abandoned in favor of Auraria (named after the gold mining town of Auraria, Georgia), and St. Charles City.
On November 22, 1858, General William Larimer, a land speculator from eastern Kansas Territory, placed cottonwood logs to stake a claim on the bluff overlooking the confluence of the South Platte River and Cherry Creek, across the creek from the existing mining settlement of Auraria, and on the site of the existing townsite of St. Charles. Larimer named the town site Denver City to curry favor with Kansas Territorial Governor James W. Denver. Larimer hoped that the town's name would help make it the county seat of Arapaho County, but unknown to him Governor Denver had already resigned from office. The location was accessible to existing trails and was across the South Platte River from the site of seasonal encampments of the Cheyenne and Arapaho. The site of these first towns is now the site of Confluence Park near downtown Denver. Larimer, along with associates in the St. Charles City Land Company, sold parcels in the town to merchants and miners, with the intention of creating a major city that would cater to new emigrants. Denver City was a frontier town, with an economy based on servicing local miners with gambling, saloons, livestock and goods trading. In the early years, land parcels were often traded for grubstakes or gambled away by miners in Auraria. In May 1859, Denver City residents donated 53 lots to the Leavenworth & Pike's Peak Express in order to secure the region's first overland wagon route. Offering daily service for "passengers, mail, freight, and gold," the Express reached Denver on a trail that trimmed westward travel time from twelve days to six. In 1863, Western Union furthered Denver's dominance of the region by choosing the city for its regional terminus.
The Colorado Territory was created on February 28, 1861, Arapahoe County was formed on November 1, 1861, and Denver City was incorporated on November 7, 1861. Denver City served as the Arapahoe County Seat from 1861 until consolidation in 1902. In 1867, Denver City became the Territorial Capital. With its new-found importance, Denver City shortened its name to Denver. On August 1, 1876, Colorado was admitted to the Union.
Although by the close of the 1860s, Denver residents could look with pride at their success establishing a vibrant supply and service center, the decision to route the nation's first transcontinental railroad through Cheyenne, rather than Denver, threatened the prosperity of the young town. A daunting 100 miles away, citizens mobilized to build a railroad to connect Denver to the transcontinental railroad. Spearheaded by visionary leaders including Territorial Governor John Evans, David Moffat, and Walter Cheesman, fundraising began. Within three days, $300,000 had been raised, and citizens were optimistic. Fundraising stalled before enough was raised, forcing these visionary leaders to take control of the debt-ridden railroad. Despite challenges, on June 24, 1870, citizens cheered as the Denver Pacific completed the link to the transcontinental railroad, ushering in a new age of prosperity for Denver.
Finally linked to the rest of the nation by rail, Denver prospered as a service and supply center. The young city grew during these years, attracting millionaires with their mansions, as well as the poverty and crime of a rapidly growing city. Denver citizens were proud when the rich chose Denver and were thrilled that Horace Tabor, the Leadville mining millionaire, built an impressive business block at 16th and Larimer as well as the elegant Tabor Grand Opera House. Luxurious hotels, including the much-loved Brown Palace Hotel, soon followed, as well as splendid homes for millionaires like the Croke, Patterson, Campbell Mansion at 11th and Pennsylvania and the now-demolished Moffat Mansion at 8th and Grant. Intent on transforming Denver into one of the world's great cities, leaders wooed industry and enticed laborers to work in these factories. Soon, in addition to the elite and a large middle class, Denver had a growing population of German, Italian, and Chinese laborers, soon followed by African-Americans and Spanish-surname workers. Unprepared for this influx, the Silver Crash of 1893 unsettled political, social, and economic balances, laying the foundation for ethnic bigotry, such as the Red Scare and the rise of the Ku Klux Klan, as well as corruption and crime.
Between 1880 and 1895 the city experienced a huge rise in corruption, as crime bosses, such as Soapy Smith, worked side by side with elected officials and the police to control elections, gambling, and the bunko gangs. The city also experienced a depression in 1893 after the crash of silver prices. In 1887, the precursor to the international charity United Way was formed in Denver by local religious leaders who raised funds and coordinated various charities to help Denver's poor. By 1890, Denver had grown to be the second-largest city west of Omaha, Nebraska. In 1900, whites represented 96.8% of Denver's population.
Between the 1880s and 1930s, Denver's floriculture industry developed and thrived. This period became known locally as the Carnation Gold Rush.
In 1901, the Colorado General Assembly voted to split Arapahoe County into three parts: a new consolidated City and County of Denver, a new Adams County, and the remainder of the Arapahoe County to be renamed South Arapahoe County. A ruling by the Colorado Supreme Court, subsequent legislation, and a referendum delayed the creation of the City and County of Denver until November 15, 1902.
Denver has hosted the Democratic National Convention twice, during the years of 1908, and again in 2008, taking the opportunity to promote the city's status on the national, political, and socioeconomic stage.
Early in the 20th century, Denver, like many other cities, was home to a pioneering Brass Era car company. The Colburn Automobile Company made cars copied from the contemporary Renault.
From 1953 to 1989, the Rocky Flats Plant, a DOE nuclear weapon facility formerly located about 15 miles from Denver, produced fissile plutonium "pits" for nuclear warheads. A major fire at the facility in 1957, as well as leakage from nuclear waste stored at the site between 1958 and 1968, resulted in the contamination of some parts of Denver, to varying degrees, with plutonium-239, a harmful radioactive substance with a half-life of 24,200 years. A study by the Jefferson County health director, Dr. Carl Johnson, in 1981 linked the contamination to an increase in birth defects and cancer incidence in central Denver and nearer Rocky Flats. Later studies confirmed many of his findings. Plutonium contamination was still present outside the former plant site , and presents risks to building the envisioned Jefferson Parkway, which would complete Denver's automotive beltway.
Denver was selected in 1970 to host the 1976 Winter Olympics to coincide with Colorado's centennial celebration, but in November 1972 Colorado voters struck down ballot initiatives allocating public funds to pay for the high costs of the games, which were subsequently moved to Innsbruck, Austria. The notoriety of becoming the only city ever to decline to host an Olympiad after being selected has made subsequent bids difficult. The movement against hosting the games was based largely on environmental issues and was led by State Representative Richard Lamm, who was subsequently elected to three terms (1975–87) as Colorado governor. Denver explored a potential bid for the 2022 Winter Olympics, but no bid will be submitted.
In 2010, Denver adopted a comprehensive update of its zoning code. The new zoning was developed to guide development as envisioned in adopted plans such as Blueprint Denver, Transit Oriented Development Strategic Plan, Greenprint Denver, and the Strategic Transportation Plan.
Denver has also been known historically as the "Queen City of the Plains" and the "Queen City of the West", because of its important role in the agricultural industry of the high-plains region in eastern Colorado and along the foothills of the Colorado Front Range. Several US Navy ships have been named USS "Denver" in honor of the city.
Geography.
Denver is located in the center of the Front Range Urban Corridor, between the Rocky Mountains to the west and the High Plains to the east. Denver's topography consists of plains in the city center with hilly areas to the north, west and south. According to the United States Census Bureau the city has a total area of , of which is land and (1.1%) is water. The City and County of Denver is surrounded by only three other counties: Adams County to the north and east, Arapahoe County to the south and east, and Jefferson County to the west.
Although Denver's nickname is the "Mile-High City" because its official elevation is one mile above sea level, defined by the elevation of the spot of a benchmark on the steps of the State Capitol building, the elevation of the entire city ranges from . According to Geographic Names Information System (GNIS) and the National Elevation Dataset, the city's elevation is , which is reflected on various websites such as that of the National Weather Service.
Neighborhoods.
As of January 2013, the City and County of Denver has defined 78 official neighborhoods that the city and community groups use for planning and administration. Although the city's delineation of the neighborhood boundaries is somewhat arbitrary, it corresponds roughly to the definitions used by residents. These "neighborhoods" should not be confused with cities or suburbs, which may be separate entities within the metro area.
The character of the neighborhoods varies significantly from one to another and includes everything from large skyscrapers to houses from the late 19th century to modern, suburban style developments. Generally, the neighborhoods closest to the city center are denser, older and contain more brick building material. Many neighborhoods away from the city center were developed after World War II, and are built with more modern materials and style. Some of the neighborhoods even farther from the city center, or recently redeveloped parcels anywhere in the city have either very suburban characteristics or are new urbanist developments that attempt to recreate the feel of older neighborhoods. Most neighborhoods contain parks or other features that are the focal point for the neighborhood.
Denver does not have larger area designations, unlike the City of Chicago, which has larger areas that house the neighborhoods (IE: Northwest Side). Denver residents use the terms "north" "south" "east" and "west".
Denver also has a number of neighborhoods not reflected in the administrative boundaries. These neighborhoods may reflect the way people in an area identify themselves or they might reflect how others, such as real estate developers, have defined those areas. Well-known non-administrative neighborhoods include the historic and trendy LoDo (short for "Lower Downtown"), part of the city's Union Station neighborhood; Uptown, straddling North Capitol Hill and City Park West; Curtis Park, part of the Five Points neighborhood; Alamo Placita, the northern part of the Speer neighborhood; Park Hill, a successful example of intentional racial integration; and Golden Triangle, in the Civic Center.
Climate.
Denver lies within the semi-arid, continental climate zone (Köppen climate classification "BSk"). It has four distinct seasons and receives a modest amount of precipitation spread through the year. Due to its inland location on the High Plains, at the foot of the Rocky Mountains, Denver, like all cities along the eastern edge of the Rocky Mountains, is subject to sudden changes in weather. The climate is very sunny, averaging 3,106 hours of sunshine a year. July is the warmest month, with a daily average temperature of . Summers range from mild to hot with occasional afternoon thunderstorms and high temperatures reaching on 38 days annually, and occasionally . December, the coldest month of the year, has a daily average temperature of . Winters range from mild to occasional bitter cold, consisting of periods of snow and very low temperatures alternating with periods of relatively milder weather. In winter, highs can reach up to , but can also sometimes be below . Snowfall is common throughout the late fall, winter and early spring, averaging for 1981–2010. The average window for measurable (≥) snow is October 17 through April 27 although measurable snowfall has fallen in Denver as early as September 4 and as late as June 3. Extremes in temperature range from on January 9, 1875 up to as recently as June 25 and 26, 2012. Tornadoes are rare in Denver, though one notable exception was an F3 tornado that struck 4.4 miles south of downtown on June 15, 1988. However, the eastern suburbs of Denver, and the city's east-northeastern extension which is the Denver International Airport, can see a few small tornadoes in the spring and summer months, especially during June in the Denver Convergence Vorticity Zone (DCVZ). The DCVZ, also known as the Denver Cyclone, is a variable vortex of storm-forming air flow usually found north and east of downtown, and which often includes the airport. Heavy weather from the DCVZ can disrupt airport operations. In a study looking at hail events in areas with a population of at least 50,000, Denver was found to be ranked 10th most prone to hail storms in the continental United States.
Based on 30-year averages obtained from NOAA's National Climatic Data Center for the months of December, January and February, Weather Channel ranked Denver the 18th coldest major U.S. city .
Demographics.
As of the 2010 census, the population of the City and County of Denver was 600,158, making it the 24th most populous U.S. city. The Denver-Aurora-Lakewood, CO Metropolitan Statistical Area had an estimated 2013 population of 2,697,476 and ranked as the 21st most populous U.S. metropolitan statistical area, and the larger Denver-Aurora-Boulder Combined Statistical Area had an estimated 2013 population of 3,277,309 and ranked as the 16th most populous U.S. metropolitan area. Denver is the most populous city within a radius centered in the city and of magnitude. Denverites is a term used for residents of Denver.
According to the 2010 census, the City and County of Denver contains 600,158 people and 285,797 households. The population density is 3,698 inhabitants per square mile (1,428/km²) including the airport. There are 285,797 housing units at an average density of 1,751 per square mile (676/km²). However, the average density throughout most Denver neighborhoods tends to be higher. Without the 80249 zip code (47.3 sq mi, 8,407 residents) near the airport, the average density increases to around 5,470 per square mile.
According to the 2010 United States Census, the racial composition of Denver was as follows:
Approximately 70.3% of the population (over five years old) spoke only English at home. An additional 23.5% of the population spoke Spanish at home. In terms of ancestry, 31.2% were Mexican, 14.6% of the population were of German ancestry, 9.7% were of Irish ancestry, 8.9% were of English ancestry, and 4.0% were of Italian ancestry.
There are 250,906 households, of which 23.2% have children under the age of 18 living with them, 34.7% are married couples living together, 10.8% have a female householder with no husband present, and 50.1% are non-families. 39.3% of all households are made up of individuals and 9.4% have someone living alone who is 65 years of age or older. The average household size is 2.27 and the average family size is 3.14.
Age distribution is 22.0% under the age of 18, 10.7% from 18 to 24, 36.1% from 25 to 44, 20.0% from 45 to 64, and 11.3% who are 65 years of age or older. The median age is 33 years. For every 100 females there are 102.1 males.
The median household income is $45,438, and the median family income is $48,195. Males have a median income of $36,232 versus $33,768 for females. The per capita income for the city is $24,101. 19.1% of the population and 14.6% of families are below the poverty line. Out of the total population, 25.3% of those under the age of 18 and 13.7% of those 65 and older are living below the poverty line.
Languages.
, 72.28% (386,815) of Denver residents aged five and older spoke only English at home, while 21.42% (114,635) spoke Spanish, 0.85% (4,550) Vietnamese, 0.57% (3,073) African languages, 0.53% (2,845) Russian, 0.50% (2,681) Chinese, 0.47% (2,527) French, and German by 0.46% (2,465) of the population over the age of five. In total, 27.72% (148,335) of Denver's population age five and older spoke a language other than English.
Economy.
The Denver MSA has a gross metropolitan product of $157.6 billion in 2010, making it the 18th largest metro economy in the United States. Denver's economy is based partially on its geographic position and its connection to some of the major transportation systems of the country. Because Denver is the largest city within , it has become a natural location for storage and distribution of goods and services to the Mountain States, Southwest states, as well as all western states. Another benefit for distribution is that Denver is nearly equidistant from large cities of the Midwest, such as Chicago and St. Louis and some large cities of the West Coast, such as Los Angeles and San Francisco.
Over the years, the city has been home to other large corporations in the central United States, making Denver a key trade point for the country. Several well-known companies originated in or have relocated to Denver. William Ainsworth opened the Denver Instrument Company in 1895 to make analytical balances for gold assayers. Its factory is now in Arvada. AIMCO (NYSE: AIV)—the largest owner and operator of apartment communities in the United States, with approximately 870 communities comprising nearly 136,000 units in 44 states—is headquartered in Denver, employing approximately 3,500 people. Also Samsonite Corp., the world's largest luggage manufacturer, began in Denver in 1910 as Shwayder Trunk Manufacturing Company, but Samsonite closed its NE Denver factory in 2001, and moved its headquarters to Massachusetts after a change of ownership in 2006. The Mountain States Telephone & Telegraph Company, founded in Denver in 1911, is now a part of telecommunications giant CenturyLink.
MediaNews Group purchased the "Denver Post" in 1987; the company is based in Denver. The Gates Corporation, the world's largest producer of automotive belts and hoses, was established in S. Denver in 1919. Russell Stover Candies Inc. made its first chocolate candy in Denver in 1923, but moved to Kansas City in 1969. The Wright & McGill Company has been making its Eagle Claw brand of fishing gear in NE Denver since 1925. The original Frontier Airlines began operations at Denver's old Stapleton International Airport in 1950. Frontier was reincarnated at DIA in 1994. Scott's Liquid Gold, Inc., has been making furniture polish in Denver since 1954. Village Inn restaurants began as a single pancake house in Denver in 1958. Big O Tires, LLC, of Centennial opened its first franchise in 1962 in Denver. The Shane Company sold its first diamond jewelry in 1971 in Denver. Johns Manville Corp., a manufacturer of insulation and roofing products, relocated its headquarters to Denver from New York in 1972. CH2M HILL Inc., an engineering and construction firm, relocated from Oregon to the Denver Technological Center in 1980. The Ball Corporation sold its glass business in Indiana in the 1990s and moved to suburban Broomfield. Ball has several operations in greater Denver.
Molson Coors Brewing Company established its U.S. headquarters in Denver in 2005. Its subsidiary and regional wholesale distributor, Coors Distributing Company, is in NW Denver. The Newmont Mining Corporation, the 2nd largest gold producer in North America and one of the largest in the world, is headquartered in Denver.
Large Denver-area employers that have headquarters elsewhere include Lockheed Martin Corp., United Airlines, Kroger Co. and Xcel Energy, Inc. MapQuest, an online site for maps, directions and business listings, is headquartered in Denver's LODO district.
Geography also allows Denver to have a considerable government presence, with many federal agencies based or having offices in the Denver area. Along with federal agencies come many companies based on US defense and space projects, and more jobs are brought to the city by virtue of its being the capital of the state of Colorado. The Denver area is home to the former nuclear weapons plant Rocky Flats, the Denver Federal Center, Byron G. Rogers Federal Building and United States Courthouse, the Denver Mint, and the National Renewable Energy Laboratory.
In 2005, a $310.7 million expansion for the Colorado Convention Center was completed, doubling its size. The hope was that the center's expansion would elevate the city to one of the top 10 cities in the nation for holding a convention.
Denver's position near the mineral-rich Rocky Mountains encouraged mining and energy companies to spring up in the area. In the early days of the city, gold and silver booms and busts played a large role in the economic success of the city. In the 1970s and early 1980s, the energy crisis in America and resulting high oil prices created an energy boom in Denver captured in the soap opera "Dynasty". Denver was built up considerably during this time with the construction of many new downtown skyscrapers. When the price of oil dropped from $34 a barrel in 1981 to $9 a barrel in 1986, the Denver economy dropped with it, leaving almost 15,000 oil industry workers in the area unemployed (including former mayor and current governor John Hickenlooper, a former geologist), and the highest office vacancy rate in the nation (30%). Since then, the industry has recovered and there remain 700 employed petroleum engineers in the region. Advances is hydraulic fracturing has made the DJ Basin of Colorado into an accessible and lucrative oil play. Energy and mining are still important in Denver's economy today, with companies such as EnCana, Halliburton, Smith International, Rio Tinto Group, Newmont Mining, Noble Energy, and Anadarko headquartered or having significant operations in the area.
Denver's west-central geographic location in the Mountain Time Zone (UTC−7) also benefits the telecommunications industry by allowing communication with both North American coasts, South America, Europe, and Asia in the same business day. Denver's location on the 105th meridian at over one mile (1.6 km) in elevation also enables it to be the largest city in the U.S. to offer a "one-bounce" real-time satellite uplink to six continents in the same business day. Qwest Communications, Dish Network Corporation, Starz-Encore, DIRECTV, and Comcast are a few of the many telecommunications companies with operations in the Denver area. These and other high-tech companies had a boom in Denver in the mid to late 1990s. Denver had one of the lowest unemployment rates in the nation at 3.8% in October 2007. As of April 2015, the unemployment rate for the Denver-Aurora-Broomfield MSA is 4.2%. The Downtown region has seen increased real estate investment with the construction of several new skyscrapers set to be completed in 2010–2013.
Denver has also enjoyed success as a pioneer in the fast casual restaurant industry, with many popular national chain restaurants founded and based in Denver. Chipotle Mexican Grill, Quizno's, and Smashburger were founded and headquartered in Denver. Qdoba Mexican Grill, Noodles & Company, and Good Times Burgers & Frozen Custard originated in Denver, but have moved their headquarters to the nearby suburbs of Wheat Ridge, Broomfield, and Golden.
In 2015, Denver ranked No. 1 on "Forbes"' list of the Best Places for Business and Careers.
Culture and contemporary life.
Apollo Hall opened quickly after the city's founding in 1859 and staged many plays for eager settlers. In the 1880s Horace Tabor built Denver's first Opera House. After the start of the 20th century, city leaders embarked on a city beautification program that created many of the city's parks, parkways, museums, and the Municipal Auditorium, which was home to the 1908 Democratic National Convention and is now known as the Ellie Caulkins Opera House. Denver and the metropolitan areas around it continued to support culture. In 1988, voters in the Denver Metropolitan Area approved the Scientific and Cultural Facilities Tax (commonly known as SCFD), a 1 cent sales tax that contributes money to various cultural and scientific facilities and organizations throughout the Metro area. The tax was renewed by voters in 1994 and 2004 and allows the SCFD to operate until 2018.
Denver is home to many nationally recognized museums, including a new wing for the Denver Art Museum by world-renowned architect Daniel Libeskind, the second largest Performing Arts Center in the nation after Lincoln Center in New York City and bustling neighborhoods such as LoDo, filled with art galleries, restaurants, bars and clubs. That is part of the reason why Denver was recently recognized for the third year in a row as the best city for singles. Denver's neighborhoods also continue their influx of diverse people and businesses while the city's cultural institutions grow and prosper. The city acquired the estate of abstract expressionist painter Clyfford Still in 2004 and built a museum to exhibit his works near the Denver Art Museum.
The Denver Museum of Nature and Science currently holds an aquamarine specimen valued at over one million dollars, as well as specimens of the state mineral, rhodochrosite. Every September the Denver Mart, located at 451 E. 58th Avenue hosts a gem and mineral show. The state history museum, History Colorado Center, opened in April 2012. It features hands-on and interactive exhibits, artifacts and programs about Colorado history. It was named in 2013 by "True West Magazine" as one of the top-ten "must see" history museums in the country. History Colorado's Byers-Evans House Museum and the Molly Brown House are nearby.
Denver has numerous art districts around the city, including Denver's Art District on Santa Fe and the River North Art District (RiNo).
While Denver may not be as recognized for historical musical prominence as some other American cities, it still manages to have a very active pop, jazz, jam, folk, and classical music scene, which has nurtured several artists and genres to regional, national, and even international attention. Of particular note is Denver's importance in the folk scene of the 1960s and 1970s. Well-known folk artists such as Bob Dylan, Judy Collins and John Denver lived in Denver at various points during this time, and performed at local clubs. Also, three members of the widely popular group Earth, Wind, and Fire are from Denver. More recent Denver-based artists include The Lumineers, Air Dubai, The Fray, Flobots, Cephalic Carnage, Axe Murder Boyz, Deuce Mob, and Five Iron Frenzy.
Because of its proximity to the mountains and generally sunny weather, Denver has gained a reputation as being a very active, outdoor-oriented city. Many Denver residents spend the weekends in the mountains; skiing in the winter and hiking, climbing, kayaking, and camping in the summer.
Denver and surrounding cities are home to a large number of local and national breweries. Many restaurants in the region have on-site breweries, and some of the larger brewers offer tours, including Coors and New Belgium Brewing Company. The city also welcomes visitors from around the world when it hosts the annual Great American Beer Festival each fall.
Denver used to be a major trading center for beef and livestock when ranchers would drive (or later transport) cattle to the Denver Union Stockyards for sale. As a celebration of that history, for more than a century Denver has hosted the annual National Western Stock Show, attracting as many as 10,000 animals and 700,000 attendees. The show is held every January at the National Western Complex northeast of downtown.
Denver has one of the country's largest populations of Mexican Americans and hosts four large Mexican American celebrations: Cinco de Mayo (with over 500,000 attendees), in May, El Grito de la Independencia, in September, the annual Lowrider show, and the Dia De Los Muertos art shows/events in North Denver's Highland neighborhood, and the Lincoln Park neighborhood in the original section of West Denver.
Denver is also famous for its dedication to New Mexican cuisine and the chile. It's best known for its green and red chile sauce, Colorado burrito, Southwest (Denver) omelette, breakfast burrito, chiles rellenos, and tamales. Denver is also well known for other types of food such as Rocky Mountain oysters, rainbow trout, and the Denver sandwich.
The Dragon Boat Festival in July, Moon Festival in September and Chinese New Year are annual events in Denver for the Chinese and Asian residents. Chinese hot pot (huo guo) and Korean BBQ restaurants have been growing in popularity. The Denver area has 2 Chinese newspapers, the Chinese American Post and the Colorado Chinese News.
Denver is the setting for "The Bill Engvall Show", and of MTV's "The Real World". It was also the setting for the prime time drama "Dynasty" from 1981 to 1989 (although the show was mostly filmed in Los Angeles). From 1998 to 2002 the city's Alameda East Veterinary Hospital was home to the Animal Planet series "Emergency Vets", which spun off three one-off documentary specials and the current Animal Planet series "E-Vet Interns". The city is also the setting for the Disney Channel Original TV Show, "Good Luck Charlie".
Sports.
Denver is home to a variety of sports teams and is one of the U.S. cities with teams from four major sports (the Denver metro area is the smallest metropolitan area to have a team in all four major sports). The Denver Broncos of the National Football League have drawn crowds of over 70,000 since their origins in the early 1960s, and continue to draw fans today to their current home Sports Authority Field at Mile High. The Broncos have sold out every home game (except for strike-replacement games) since 1970. The Broncos have advanced to eight Super Bowls and won back-to-back titles in 1998 and 1999, and won again in 2015.
The Colorado Rockies were created as an expansion franchise in 1993 and Coors Field opened in 1995. The Rockies advanced to the playoffs that year, but were eliminated in the first round. In 2007, they advanced to the playoffs as a wild-card entrant, won the NL Championship Series, and brought the World Series to Denver for the first time but were swept in four games by the Boston Red Sox.
Denver is also home to the Colorado Avalanche, a National Hockey League team that relocated from Quebec City in 1995. While in Denver, they have won two Stanley Cups in 1996 and in 2001, and they play at Pepsi Center. The Denver Nuggets of the National Basketball Association also play at the Pepsi Center. The Major League Soccer team Colorado Rapids play in Dick's Sporting Goods Park, an 18,000 seat soccer-specific stadium opened for the 2007 MLS season, located in the Denver suburb of Commerce City. The Rapids won the MLS Cup in 2010. 
Denver has several additional professional teams. In 2006 Denver established a Major League Lacrosse team, the Denver Outlaws. They play in Sports Authority Field at Mile High. In 2006, the Denver Outlaws won the Western Conference Championship. The Colorado Mammoth of the National Lacrosse League play at the Pepsi Center. The Denver PRO Rugby team plays at Infinity Park.
Denver submitted the winning bid to host the 1976 Winter Olympics, but subsequently withdrew, giving it the dubious distinction of being the only city to back out after winning a bid to host the Olympics. Denver and Colorado Springs hosted the 1962 World Ice Hockey Championships.
Parks and recreation.
, Denver had over 200 parks, from small mini-parks all over the city to the giant City Park. Denver also has 29 recreation centers providing places and programming for resident's recreation and relaxation.
Many of Denver's parks were acquired from state lands in the late 19th and early 20th centuries. This coincided with the City Beautiful movement, and Denver mayor Robert Speer (1904–12 and 1916–18) set out to expand and beautify the city's parks. Reinhard Schuetze was the city's first landscape architect, and he brought his German-educated landscaping genius to Washington Park, Cheesman Park, and City Park among others. Speer used Schuetze as well as other landscape architects such as Frederick Law Olmsted, Jr. and Saco Rienk DeBoer to design not only parks such as Civic Center Park, but many city parkways and tree-lawns. All of this greenery was fed with South Platte River water diverted through the city ditch.
In addition to the parks within Denver itself, the city acquired land for mountain parks starting in the 1911s. Over the years, Denver has acquired, built and maintained approximately of mountain parks, including Red Rocks Park, which is known for its scenery and musical history revolving around the unique Red Rocks Amphitheatre. Denver also owns the mountain on which the Winter Park Resort ski area is operated in Grand County, west of Denver. City parks are important places for both Denverites and visitors, inciting controversy with every change. Denver continues to grow its park system with the development of many new parks along the Platte River through the city, and with Central Park and Bluff Lake Nature Center in the Stapleton neighborhood redevelopment. All of these parks are important gathering places for residents and allow what was once a dry plain to be lush, active, and green. Denver is also home to a large network of public community gardens, most of which are managed by Denver Urban Gardens, a non-profit organization.
Since 1974, Denver and the surrounding jurisdictions have rehabilitated the urban South Platte River and its tributaries for recreational use by hikers and cyclists. The main stem of the South Platte River Greenway runs along the South Platte from Chatfield Reservoir into Adams County in the north. The Greenway project is recognized as one of the best urban reclamation projects in the U.S., winning, for example, the Silver Medal Rudy Bruner Award for Urban Excellence in 2001.
In its 2013 ParkScore ranking, The Trust for Public Land, a national land conservation organization, reported that Denver had the 17th best park system among the 50 most populous U.S. cities.
Government.
Denver is a consolidated city-county with a mayor elected on a nonpartisan ballot, a 13-member city council and an auditor. The Denver City Council is elected from 11 districts with two at-large council-members and is responsible for passing and changing all laws, resolutions, and ordinances, usually after a public hearing, and can also call for misconduct investigations of Denver's departmental officials. All elected officials have four-year terms, with a maximum of three terms. The current mayor is Michael Hancock.
Denver has a strong mayor/weak city council government. The mayor can approve or veto any ordinances or resolutions approved by the council, makes sure all contracts with the city are kept and performed, signs all bonds and contracts, is responsible for the city budget, and can appoint people to various city departments, organizations, and commissions. However, the council can override the mayor's veto with a nine out of thirteen member vote, and the city budget must be approved and can be changed by a simple majority vote of the council. The auditor checks all expenditures and may refuse to allow specific ones, usually based on financial reasons.
The Denver Department of Safety oversees three branches: the Denver Police Department, Denver Fire Department, and Denver Sheriff Department. The Denver County Court is an integrated Colorado County Court and Municipal Court and is managed by Denver instead of the state.
Politics.
While Denver elections are non-partisan, Democrats have long held the majority sway on Denver politics with most officials elected citywide having Democratic Party affiliation. In federal elections, Denverites also tend to vote for Democratic candidates, voting for the Democratic Presidential nominee in every election since 1960 (excluding 1980 and 1972). The office of Denver's Mayor has been occupied by a Democrat since the municipal general election of 1963. Denver is represented at the federal level by congresswoman Diana DeGette, a Democrat representing Colorado's 1st congressional district, which includes all of Denver and parts of Arapahoe County.
Benjamin F. Stapleton was the mayor of Denver, Colorado, for two periods, the first from 1923 to 1931 and the second from 1935 to 1947. Stapleton was responsible for many civic improvements during his term, notably during his second stint as mayor when he had access to funds and manpower from the New Deal. During this time, the park system was considerably expanded and the Civic Center completed. His signature project was the construction of Denver Municipal Airport, which began in 1929 amidst heavy criticism. It was later renamed Stapleton International Airport in his honor. Today, the airport no longer stands, but has been replaced by a neighborhood also named Stapleton. Stapleton Street continues to bear his name.
During the 1960s and 1970s, Denver was one of the epicenters of the Chicano Movement. The boxer-turned-activist Rodolfo "Corky" Gonzales formed an organization called the Crusade for Justice, which battled police brutality, fought for bilingual education, and, most notably, hosted the First National Chicano Youth Liberation Conference in March 1969.
In recent years, Denver has taken a stance on helping people who are or become homeless, particularly under the administrations of mayors John Hickenlooper and Wellington Webb. At a rate of 19 homeless per 10,000 residents in 2011 as compared to 50 or more per 10,000 residents for the four metro areas with the highest rate of homelessness, Denver's homeless population and rate of homeless are both considerably lower than many other major cities. However, residents of the city streets suffer Denver winters - which, although mild and dry much of the time, can have brief periods of extremely cold temperatures and snow.
In 2005, Denver became the first major city in the U.S. to vote to make the private possession of less than an ounce of marijuana legal for adults 21 and older. The city voted 53.5 percent in favor of the marijuana legalization measure, which, as then-mayor John Hickenlooper pointed out, was without effect, because the city cannot usurp state law, which at that time treated marijuana possession in much the same way as a speeding ticket, with fines of up to $100 and no jail time. Denver passed an initiative in the fourth quarter of 2007 requiring the mayor to appoint an 11-member review panel to monitor the city's compliance with the 2005 ordinance. In 2012, Colorado Amendment 64 was signed into law by Governor John Hickenlooper and at the beginning of 2014 Colorado became the first state to allow the sale of marijuana for recreational use.
Former Denver mayor John Hickenlooper was a member of the Mayors Against Illegal Guns Coalition, an organization formed in 2006 and co-chaired by New York City mayor Michael Bloomberg and Boston mayor Thomas Menino.
Denver hosted the 2008 Democratic National Convention, which was the centennial of the city's first hosting of the landmark 1908 convention. It also hosted the G7 (now G8) summit between June 20 and 22 in 1997 and the 2000 National Convention of the Green Party.
On October 31, 2011 it was announced that The University of Denver in Denver was selected as the host of the first of three 2012 presidential debates to be held on October 3, 2012.
Taxes.
The City and County of Denver levies an Occupational Privilege Tax (OPT or Head Tax) on employers and employees.
Education.
Denver Public Schools (DPS) is the public school system in Denver. It currently educates about 73,000 students in 73 elementary schools, 15 K-8 schools, 17 middle schools, 14 high schools, and 19 charter schools. The first school of what is now DPS was a log cabin that opened in 1859 on the corner of 12th Street between Market and Larimer Streets. The district boundaries are coextensive with the city limits. The Cherry Creek School District serves some areas with Denver postal addresses that are outside the city limits.
Denver's many colleges and universities range in age and study programs. Three major public schools constitute the Auraria Campus, University of Colorado Denver, Metropolitan State University of Denver, and Community College of Denver. The private University of Denver was the first institution of higher learning in the city and was founded in 1864. Other prominent Denver higher education institutions include Johnson & Wales University, Catholic (Jesuit) Regis University and the city has Roman Catholic and Jewish institutions, as well as a health sciences school. In addition to those schools within the city, there are a number of schools located throughout the surrounding metro area.
Media.
The Denver Metropolitan Area is served by a variety of media outlets in print, radio, television, and the Internet.
Television stations.
Denver is the 16th-largest market in the country for television, according to the 2009–2010 rankings from Nielsen Media Research.
Radio stations.
Denver is also served by over 40 AM and FM radio stations, covering a wide variety of formats and styles. Denver-Boulder radio is the No. 19 market in the United States, according to the Spring 2011 Arbitron ranking (up from No. 20 in Fall 2009).
For a list of radio stations, see Radio Stations in Colorado
Print.
After a continued rivalry between Denver's two main newspapers, the "Denver Post" and "Rocky Mountain News", the papers merged operations in 2001 under a Joint Operating Agreement which formed the Denver Newspaper Agency until February 2009 when E. W. Scripps Company, the owner of the Rocky Mountain News closed the paper. There are also several alternative or localized newspapers published in Denver, including the "Westword" and "Out Front Colorado". Denver is home to multiple regional magazines such as "5280", which takes its name from the city's mile-high () elevation.
Transportation.
City streets.
Most of Denver has a straightforward street grid oriented to the four cardinal directions. Blocks are usually identified in hundreds from the median streets, identified as "00", which are Broadway (the east–west median, running north–south) and Ellsworth Avenue (the north–south median, running east–west). Colfax Avenue, a major east–west artery through Denver, is 15 blocks (1500) north of the median. Avenues north of Ellsworth are numbered (with the exception of Colfax Avenue and several others, such as Martin Luther King, Jr. Blvd and Montview Blvd.), while avenues south of Ellsworth are named.
There is also an older downtown grid system that was designed to be parallel to the confluence of the South Platte River and Cherry Creek. Most of the streets downtown and in LoDo run northeast–southwest and northwest–southeast. This system has an unplanned benefit for snow removal; if the streets were in a normal N–S/E–W grid, only the N–S streets would receive sunlight. With the grid oriented to the diagonal directions, the NW–SE streets receive sunlight to melt snow in the morning and the NE–SW streets receive it in the afternoon. This idea was from Henry Brown the founder of the Brown Palace Hotel. There is now a plaque across the street from the Brown Palace Hotel which honors this idea. The NW–SE streets are numbered, while the NE–SW streets are named. The named streets start at the intersection of Colfax Avenue and Broadway with the block-long Cheyenne Place. The numbered streets start underneath the Colfax and I-25 viaducts. There are 27 named and 44 numbered streets on this grid. There are also a few vestiges of the old grid system in the normal grid, such as Park Avenue, Morrison Road, and Speer Boulevard. Larimer Street, named after William Larimer, Jr., the founder of Denver, which is located in the heart of LoDo, is the oldest street in Denver.
All roads in the downtown grid system are streets (e.g. 16th Street, Stout Street). Roads outside that system that travel east/west are given the suffix "avenue" and those that head north and south are given the "street" suffix (e.g. Colfax Avenue, Lincoln Street). Boulevards are higher capacity streets and travel any direction (more commonly north and south). Smaller roads are sometimes referred to as places, drives (though not all drives are smaller capacity roads, some are major thoroughfares) or courts. Most streets outside the area between Broadway and Colorado Boulevard are organized alphabetically from the city's center.
Many Denver streets have bicycle lanes, and there are over 850 miles of paved, off-road, bike paths in Denver parks and along bodies of water, like Cherry Creek and the South Platte. This allows for a significant portion of Denver's population to be bicycle commuters and has led to Denver being known as a bicycle friendly city. In addition to the many bike paths, Denver launched B-Cycle – a city-wide bicycle sharing program – in late April 2010. The B-Cycle network was the largest in the United States at the time of its launch, boasting 400 bicycles.
The Denver Boot, a car-disabling device was first used in Denver.
Cycling.
The League of American Bicyclists has rated Colorado as the sixth most bicycle-friendly state in the nation for the year 2014. This is due in large part to Front Range cities like Boulder, Fort Collins and Denver placing an emphasis on legislation, programs and infrastructure developments that promote cycling as a mode of transportation. Walk score has rated Denver as the third most bicycle-friendly large city in the United States.
Many Denver streets have bicycle lanes, and there are over 850 miles of paved, off-road, bike paths in Denver parks and along bodies of water, like Cherry Creek and the South Platte. This allows for a significant portion of Denver's population to be bicycle commuters and has led to Denver being known as a bicycle friendly city. According to data from the 2011 American Community Survey, Denver ranks 6th among US cities with populations over 400,000 in terms of the percentage of workers who commute by bicycle at 2.2% of commuters. In addition to the many bike paths, Denver launched B-Cycle – a city-wide bicycle sharing program – in late April 2010. The B-Cycle network was the largest in the United States at the time of its launch, boasting 400 bicycles. Through the acquisition of new grants, the program has continued to expand each year, adding dozens of new stations, hundreds of bikes, and by beginning service during the winter months.
Walkability.
A 2011 study by Walk Score ranked Denver sixteenth most walkable of fifty largest U.S. cities.
Freeways and highways.
Denver is primarily served by the interstate freeways I-25 and I-70. The intersection of the two interstates is referred to locally as "the mousetrap", because when viewed from the air, the junction (and subsequent vehicles) resemble mice in a large trap.
Denver also has a nearly complete beltway known as "the 470's". These are SH 470 (also known as C-470), a freeway in the southwest Metro area, and two toll highways, E-470 (from southeast to northeast) and Northwest Parkway (from terminus of E-470 to US 36). SH 470 was originally intended to be I-470 and built with federal highway funds, but the funding was redirected to complete conversion of downtown Denver's 16th Street to a pedestrian mall. As a result, construction was delayed until 1980 after state and local legislation was passed. I-470 was also once called "The Silver Stake Highway", from Gov. Lamm's declared intention to drive a silver stake through it and kill it.
A highway expansion and transit project for the southern I-25 corridor, dubbed T-REX (Transportation Expansion Project), was completed on November 17, 2006. The project installed wider and additional highway lanes, and improved highway access and drainage. The project also includes a light rail line that traverses from downtown to the south end of the metro area at Lincoln Avenue. The project spanned almost along the highway with an additional line traveling parallel to part of I-225, stopping just short of Parker Road.
Metro Denver highway conditions can be accessed on the Colorado Department of Transportation website Traffic Conditions.
Mass transportation.
Mass transportation throughout the Denver metropolitan area is managed and coordinated by the Regional Transportation District (RTD). RTD currently operates more than 1,000 buses serving over 10,000 bus stops in 38 municipal jurisdictions in eight counties around the Denver and Boulder metropolitan areas. Additionally, RTD operates six light rail lines, the C, D, E, F, W, and H with a total of of track, serving 36 stations. FasTracks is a light rail/bus/rail expansion project approved by voters in 2004 which will serve neighboring suburbs and communities. The W line, or West line, opened in April 2013 serving Golden/Federal Center. Currently, RTD is expanding the rail through Aurora along I-225 and building a commuter line along I-70 to connect Downtown with Stapleton and the Denver International Airport.
CDOT runs a bus system named Bustang that offers weekday service between Union Station in Denver, Glenwood Springs, Colorado Springs, and Fort Collins.
Greyhound Lines, the intercity bus operator, has a major hub in Denver, with routes to New York City, Portland, Reno, Las Vegas, and their headquarters, Dallas. Subsidiary Autobuses Americanos provides service to El Paso. Allied bus operators Black Hills Trailways, and Burlington Trailways provide service to Billings, Omaha, Indianapolis, and Alamosa.
Amtrak, the national passenger rail system, provides service to Denver, operating its "California Zephyr" daily in both directions between Chicago and Emeryville, California, across the bay from San Francisco. Amtrak Thruway service operated by private bus companies links the Denver station with Rocky Mountain points.
At Albuquerque, New Mexico, Denver Thruway connections are made daily with the Amtrak "Southwest Chief". Additionally, the Ski Train operated on the former Denver & Rio Grande Western Railroad, which took passengers between Denver and the Winter Park Ski Resort, but it is no longer in service. The Ski Train made its final run to Winter Park on March 29, 2009.
Denver's early years as a major train hub of the west are still very visible today. Trains stop in Denver at historic Union Station, where travelers can access RTD's 16th Street Free MallRide or use light rail to tour the city. Union Station will also serve as the main juncture for rail travel in the metro area, at the completion of FasTracks.
Airports.
Denver International Airport (IATA: DEN, ICAO: KDEN), commonly known as DIA, serves as the primary airport for a large region surrounding Denver. DIA is located east-northeast of the Colorado State Capitol. DIA is the tenth busiest airport in the world and ranks fourth in the United States, with 51,245,334 passengers passing through it in 2008. It covers more than , making it the largest airport by land area in the United States and larger than the island of Manhattan. Denver serves as a major hub for United Airlines, is the headquarters for Frontier Airlines, and is the fastest-growing focus city for Southwest Airlines.
Three general aviation airports serve the Denver area. Rocky Mountain Metropolitan Airport (KBJC) is north-northwest, Centennial Airport (KAPA) is south-southeast, and Front Range Airport (KFTG) is located east of the state capitol.
In the past, Denver has been home to several other airports that are no longer operational. Stapleton International Airport was closed in 1995 when it was replaced by DIA. Lowry Air Force Base was a military flight training facility that ceased flight operations in 1966, with the base finally being closed in 1994. It is currently being used for residential purposes. Buckley Air Force Base, a former Air National Guard base, is currently the only military facility in the Denver-Metro area.
Sister cities.
Denver's relationship with Brest, France, began in 1948, making it the second-oldest sister city in the United States. Since then, Denver has established relationships with additional sister cities, and currently has a total of ten partnerships:
In addition to these, the Denver Regional Council of Governments (consisting of the city and 51 other local governments) has established a "sister city" relationship with the Baghdad Governorate, one of Iraq's eighteen provinces.

</doc>
<doc id="8524" url="https://en.wikipedia.org/wiki?curid=8524" title="Deuterium">
Deuterium

Deuterium (symbol ' or ', also known as heavy hydrogen) is one of two stable isotopes of hydrogen. The nucleus of deuterium, called a deuteron, contains one proton and one neutron, whereas the far more common hydrogen isotope, protium, has no neutron in the nucleus. Deuterium has a natural abundance in Earth's oceans of about one atom in of hydrogen. Thus deuterium accounts for approximately 0.0156% (or on a mass basis 0.0312%) of all the naturally occurring hydrogen in the oceans, while the most common isotope (hydrogen-1 or protium) accounts for more than 99.98%. The abundance of deuterium changes slightly from one kind of natural water to another (see Vienna Standard Mean Ocean Water).
The deuterium isotope's name is formed from the Greek "deuteros" meaning "second", to denote the two particles composing the nucleus. Deuterium was discovered and named in 1931 by Harold Urey, earning him a Nobel Prize in 1934. This was followed by the discovery of the neutron in 1932, which made the nuclear structure of deuterium obvious. Soon after deuterium's discovery, Urey and others produced samples of "heavy water" in which the deuterium content had been highly concentrated.
Deuterium is destroyed in the interiors of stars faster than it is produced. Other natural processes are thought to produce only an insignificant amount of deuterium. Theoretically nearly all deuterium found in nature was produced in the Big Bang 13.8 billion years ago, as the basic or primordial ratio of hydrogen-1 (protium) to deuterium (about 26 atoms of deuterium per million hydrogen atoms) has its origin from that time. This is the ratio found in the gas giant planets, such as Jupiter (see references 2,3 and 4). However, other astronomical bodies are found to have different ratios of deuterium to hydrogen-1. This is thought to be as a result of natural isotope separation processes that occur from solar heating of ices in comets. Like the water-cycle in Earth's weather, such heating processes may enrich deuterium with respect to protium. The analysis of deuterium/protium ratios in comets found results very similar to the mean ratio in Earth's oceans (156 atoms of deuterium per million hydrogens). This reinforces theories that much of Earth's ocean water is of cometary origin. The deuterium/protium ratio of the comet 67P/Churyumov-Gerasimenko, as measured by the Rosetta space probe, is about three times that of earth water. This figure is the highest yet measured in a comet.
Deuterium/protium ratios thus continue to be an active topic of research in both astronomy and climatology.
Differences between deuterium and common hydrogen (protium).
Chemical symbol.
Deuterium is frequently represented by the chemical symbol D. Since it is an isotope of hydrogen with mass number 2, it is also represented by . IUPAC allows both D and , although is preferred. A distinct chemical symbol is used for convenience because of the isotope's common use in various scientific processes. Also, its large mass difference with protium (1H) (deuterium has a mass of , compared to the mean hydrogen atomic weight of , and protium's mass of ) confers non-negligible chemical dissimilarities with protium-containing compounds, whereas the isotope weight ratios within other chemical elements are largely insignificant in this regard.
Spectroscopy.
In quantum mechanics the energy levels of electrons in atoms depend on the reduced mass of the system of electron and nucleus. For the hydrogen atom, the role of reduced mass is most simply seen in the Bohr model of the atom, where the reduced mass appears in a simple calculation of the Rydberg constant and Rydberg equation, but the reduced mass also appears in the Schrödinger equation, and the Dirac equation for calculating atomic energy levels.
The reduced mass of the system in these equations is close to the mass of a single electron, but differs from it by a small amount about equal to the ratio of mass of the electron to the atomic nucleus. For hydrogen, this amount is about 1837/1836, or 1.000545, and for deuterium it is even smaller: 3671/3670, or 1.0002725. The energies of spectroscopic lines for deuterium and light-hydrogen (hydrogen-1) therefore differ by the ratios of these two numbers, which is 1.000272. The wavelengths of all deuterium spectroscopic lines are shorter than the corresponding lines of light hydrogen, by a factor of 1.000272. In astronomical observation, this corresponds to a blue Doppler shift of 0.000272 times the speed of light, or 81.6 km/s.
The differences are much more pronounced in vibrational spectroscopy such as infrared spectroscopy and Raman spectroscopy, and in rotational spectra such as microwave spectroscopy because the reduced mass of the deuterium is markedly higher than that of protium.
Deuterium and Big Bang nucleosynthesis.
Deuterium is thought to have played an important role in setting the number and ratios of the elements that were formed in the Big Bang. Combining thermodynamics and the changes brought about by cosmic expansion, one can calculate the fraction of protons and neutrons based on the temperature at the point that the universe cooled enough to allow formation of nuclei. This calculation indicates seven protons for every neutron at the beginning of nucleogenesis, a ratio that would remain stable even after nucleogenesis was over. This fraction was in favor of protons initially, primarily because the lower mass of the proton favored their production. As the universe expanded, it cooled. Free neutrons and protons are less stable than helium nuclei, and the protons and neutrons had a strong energetic reason to form helium-4. However, forming helium-4 requires the intermediate step of forming deuterium.
Through much of the few minutes after the big bang during which nucleosynthesis could have occurred, the temperature was high enough that the mean energy per particle was greater than the binding energy of weakly bound deuterium; therefore any deuterium that was formed was immediately destroyed. This situation is known as the deuterium bottleneck. The bottleneck delayed formation of any helium-4 until the universe became cool enough to form deuterium (at about a temperature equivalent to 100 keV). At this point, there was a sudden burst of element formation (first deuterium, which immediately fused to helium). However, very shortly thereafter, at twenty minutes after the Big Bang, the universe became too cool for any further nuclear fusion and nucleosynthesis to occur. At this point, the elemental abundances were nearly fixed, with the only change as some of the radioactive products of big bang nucleosynthesis (such as tritium) decay. The deuterium bottleneck in the formation of helium, together with the lack of stable ways for helium to combine with hydrogen or with itself (there are no stable nuclei with mass numbers of five or eight) meant that insignificant carbon, or any elements heavier than carbon, formed in the Big Bang. These elements thus required formation in stars. At the same time, the failure of much nucleogenesis during the Big Bang ensured that there would be plenty of hydrogen in the later universe available to form long-lived stars, such as our Sun.
Abundance.
Deuterium occurs in trace amounts naturally as deuterium gas, written 2 or D2, but most natural occurrence in the universe is bonded with a typical atom, a gas called hydrogen deuteride (HD or ).
The existence of deuterium on Earth, elsewhere in the solar system (as confirmed by planetary probes), and in the spectra of stars, is also an important datum in cosmology. Gamma radiation from ordinary nuclear fusion dissociates deuterium into protons and neutrons, and there are no known natural processes other than the Big Bang nucleosynthesis, which might have produced deuterium at anything close to the observed natural abundance of deuterium (deuterium is produced by the rare cluster decay, and occasional absorption of naturally occurring neutrons by light hydrogen, but these are trivial sources). There is thought to be little deuterium in the interior of the Sun and other stars, as at temperatures there nuclear fusion reactions that consume deuterium happen much faster than the proton-proton reaction that creates deuterium. However, deuterium persists in the outer solar atmosphere at roughly the same concentration as in Jupiter, and this has probably been unchanged since the origin of the Solar System. The natural abundance of deuterium seems to be a very similar fraction of hydrogen, wherever hydrogen is found, unless there are obvious processes at work that concentrate it.
The existence of deuterium at a low but constant primordial fraction in all hydrogen is another one of the arguments in favor of the Big Bang theory over the Steady State theory of the universe. The observed ratios of hydrogen to helium to deuterium in the universe are difficult to explain except with a Big Bang model. It is estimated that the abundances of deuterium have not evolved significantly since their production about . Measurements of Milky Way galactic deuterium from ultraviolet spectral analysis show a ratio of as much as 23 atoms of deuterium per million hydrogen atoms in undisturbed gas clouds, which is only 15% below the WMAP estimated primordial ratio of about 27 atoms per million from the Big Bang. This has been interpreted to mean that less deuterium has been destroyed in star formation in our galaxy than expected, or perhaps deuterium has been replenished by a large in-fall of primordial hydrogen from outside the galaxy. In space a few hundred light years from the Sun, deuterium abundance is only 15 atoms per million, but this value is presumably influenced by differential adsorption of deuterium onto carbon dust grains in interstellar space.
The abundance of deuterium in the atmosphere of Jupiter has been directly measured by the Galileo space probe as 26 atoms per million hydrogen atoms. ISO-SWS observations find 22 atoms per million hydrogen atoms in Jupiter. and this abundance is thought to represent close to the primordial solar system ratio. This is about 17% of the terrestrial deuterium-to-hydrogen ratio of 156 deuterium atoms per million hydrogen atoms.
Cometary bodies such as Comet Hale Bopp and Halley's Comet have been measured to contain relatively more deuterium (about 200 atoms D per million hydrogens), ratios which are enriched with respect to the presumed protosolar nebula ratio, probably due to heating, and which are similar to the ratios found in Earth seawater. The recent measurement of deuterium amounts of 161 atoms D per million hydrogen in Comet 103P/Hartley (a former Kuiper belt object), a ratio almost exactly that in Earth's oceans, emphasizes the theory that Earth's surface water may be largely comet-derived. Most recently the deuterium/protium (D/H) ratio of 67P/Churyumov-Gerasimenko as measured by Rosetta is about three times that of earth water, a figure that is high. This has caused renewed interest in suggestions that Earth's water may be partly of asteroidal origin.
Deuterium has also observed to be concentrated over the mean solar abundance in other terrestrial planets, in particular Mars and Venus.
Production.
Deuterium is produced for industrial, scientific and military purposes, by starting with ordinary water—a small fraction of which is naturally-occurring heavy water—and then separating out the heavy water by the Girdler sulfide process, distillation, or other methods.
In theory, deuterium for heavy water could be created in a nuclear reactor, but separation from ordinary water is the cheapest bulk production process.
The world's leading supplier of deuterium was Atomic Energy of Canada Limited, in Canada, until 1997, when the last heavy water plant was shut down. Canada uses heavy water as a neutron moderator for the operation of the CANDU reactor design.
Properties.
Physical properties.
The physical properties of deuterium compounds can exhibit significant kinetic isotope effects and other physical and chemical property differences from the hydrogen analogs. D2O, for example, is more viscous than H2O. Chemically, there are differences in bond energy and length for compounds of heavy hydrogen isotopes compared to normal hydrogen, which are larger than the isotopic differences in any other element. Bonds involving deuterium and tritium are somewhat stronger than the corresponding bonds in hydrogen, and these differences are enough to cause significant changes in biological reactions.
Deuterium can replace the normal hydrogen in water molecules to form heavy water (D2O), which is about 10.6% denser than normal water (so that ice made from it sinks in ordinary water). Heavy water is slightly toxic in eukaryotic animals, with 25% substitution of the body water causing cell division problems and sterility, and 50% substitution causing death by cytotoxic syndrome (bone marrow failure and gastrointestinal lining failure). Prokaryotic organisms, however, can survive and grow in pure heavy water, though they develop slowly. Despite this toxicity, consumption of heavy water under normal circumstances does not pose a health threat to humans. It is estimated that a person might drink 4.8 liters of heavy water without serious consequences. Small doses of heavy water (a few grams in humans, containing an amount of deuterium comparable to that normally present in the body) are routinely used as harmless metabolic tracers in humans and animals.
Quantum properties.
The deuteron has spin +1 ("triplet") and is thus a boson. The NMR frequency of deuterium is significantly different from common light hydrogen. Infrared spectroscopy also easily differentiates many deuterated compounds, due to the large difference in IR absorption frequency seen in the vibration of a chemical bond containing deuterium, versus light hydrogen. The two stable isotopes of hydrogen can also be distinguished by using mass spectrometry.
The triplet deuteron nucleon is barely bound at EB = , so all the higher energy states are not bound. The singlet deuteron is a virtual state, with a negative binding energy of . There is no such stable particle, but this virtual particle transiently exists during neutron-proton inelastic scattering, accounting for the unusually large neutron scattering cross-section of the proton.
Nuclear properties (the deuteron).
Deuteron mass and radius.
The nucleus of deuterium is called a deuteron. It has a mass of The charge radius of the deuteron is 
Spin and energy.
Deuterium is one of only five stable nuclides with an odd number of protons and an odd number of neutrons. (, , , , ; also, the long-lived radioactive nuclides , , , occur naturally.) Most odd-odd nuclei are unstable with respect to beta decay, because the decay products are even-even, and are therefore more strongly bound, due to nuclear pairing effects. Deuterium, however, benefits from having its proton and neutron coupled to a spin-1 state, which gives a stronger nuclear attraction; the corresponding spin-1 state does not exist in the two-neutron or two-proton system, due to the Pauli exclusion principle which would require one or the other identical particle with the same spin to have some other different quantum number, such as orbital angular momentum. But orbital angular momentum of either particle gives a lower binding energy for the system, primarily due to increasing distance of the particles in the steep gradient of the nuclear force. In both cases, this causes the diproton and dineutron nucleus to be unstable.
The proton and neutron making up deuterium can be dissociated through neutral current interactions with neutrinos. The cross section for this interaction is comparatively large, and deuterium was successfully used as a neutrino target in the Sudbury Neutrino Observatory experiment.
Isospin singlet state of the deuteron.
Due to the similarity in mass and nuclear properties between the proton and neutron, they are sometimes considered as two symmetric types of the same object, a nucleon. While only the proton has an electric charge, this is often negligible due to the weakness of the electromagnetic interaction relative to the strong nuclear interaction. The symmetry relating the proton and neutron is known as isospin and denoted "I" (or sometimes "T").
Isospin is an SU(2) symmetry, like ordinary spin, so is completely analogous to it. The proton and neutron form an isospin doublet, with a "down" state (↓) being a neutron, and an "up" state (↑) being a proton.
A pair of nucleons can either be in an antisymmetric state of isospin called singlet, or in a symmetric state called triplet. In terms of the "down" state and "up" state, the singlet is
This is a nucleus with one proton and one neutron, i.e. a deuterium nucleus. The triplet is
and thus consists of three types of nuclei, which are supposed to be symmetric: a deuterium nucleus (actually a highly excited state of it), a nucleus with two protons, and a nucleus with two neutrons. The latter two nuclei are not stable or nearly stable, and therefore so is this type of deuterium (meaning that it is indeed a highly excited state of deuterium).
Approximated wavefunction of the deuteron.
The deuteron wavefunction must be antisymmetric if the isospin representation is used (since a proton and a neutron are not identical particles, the wavefunction
need not be antisymmetric in general). Apart from their isospin, the two nucleons also have spin and spatial distributions of their wavefunction. The latter is symmetric if the deuteron is symmetric under parity (i.e. have an "even" or "positive" parity), and antisymmetric if the deuteron is antisymmetric under parity (i.e. have an "odd" or "negative" parity). The parity is fully determined by the total orbital angular momentum of the two nucleons: if it is even then the parity is even (positive), and if it is odd then the parity is odd (negative).
The deuteron, being an isospin singlet, is antisymmetric under nucleons exchange due to isospin, and therefore must be symmetric under the double exchange of their spin and location. Therefore, it can be in either of the following two different states:
In the first case the deuteron is a spin triplet, so that its total spin "s" is 1. It also has an even parity and therefore even orbital angular momentum "l" ; The lower its orbital angular momentum, the lower its energy. Therefore, the lowest possible energy state has , .
In the second case the deuteron is a spin singlet, so that its total spin "s" is 0. It also has an odd parity and therefore odd orbital angular momentum "l". Therefore, the lowest possible energy state has , .
Since gives a stronger nuclear attraction, the deuterium ground state is in the , state.
The same considerations lead to the possible states of an isospin triplet having , or , . Thus the state of lowest energy has , , higher than that of the isospin singlet.
The analysis just given is in fact only approximate, both because isospin is not an exact symmetry, and more importantly because the strong nuclear interaction between the two nucleons is related to angular momentum in spin-orbit interaction that mixes different "s" and "l" states. That is, "s" and "l" are not constant in time (they do not commute with the Hamiltonian), and over time a state such as , may become a state of , . Parity is still constant in time so these do not mix with odd "l" states (such as , ). Therefore, the quantum state of the deuterium is a superposition (a linear combination) of the , state and the , state, even though the first component is much bigger. Since the total angular momentum "j" is also a good quantum number (it is a constant in time), both components must have the same "j", and therefore . This is the total spin of the deuterium nucleus.
To summarize, the deuterium nucleus is antisymmetric in terms of isospin, and has spin 1 and even (+1) parity. The relative angular momentum of its nucleons "l" is not well defined, and the deuteron is a superposition of mostly with some .
Magnetic and electric multipoles.
In order to find theoretically the deuterium magnetic dipole moment µ, one uses the formula for a nuclear magnetic moment
with
g(l) and g(s) are g-factors of the nucleons.
Since the proton and neutron have different values for g(l) and g(s), one must separate their contributions. Each gets half of the deuterium orbital angular momentum formula_5 and spin formula_6. One arrives at
where subscripts p and n stand for the proton and neutron, and .
By using the same identities as here and using the value , we arrive at the following result, in nuclear magneton units
For the , state (), we obtain
For the , state (), we obtain
The measured value of the deuterium magnetic dipole moment, is , which is 97.5% of the value obtained by simply adding moments of the proton and neutron. This suggests that the state of the deuterium is indeed to a good approximation , state, which occurs with both nucleons spinning in the same direction, but their magnetic moments subtracting because of the neutron's negative moment.
But the slightly lower experimental number than that which results from simple addition of proton and (negative) neutron moments shows that deuterium is actually a linear combination of mostly , state with a slight admixture of , state.
The electric dipole is zero as usual.
The measured electric quadrupole of the deuterium is . While the order of magnitude is reasonable, since the deuterium radius is of order of 1 femtometer (see below) and its electric charge is e, the above model does not suffice for its computation. More specifically, the electric quadrupole does not get a contribution from the "l" =0 state (which is the dominant one) and does get a contribution from a term mixing the "l" =0 and the "l" =2 states, because the electric quadrupole operator does not commute with angular momentum.
The latter contribution is dominant in the absence of a pure contribution, but cannot be calculated without knowing the exact spatial form of the nucleons wavefunction inside the deuterium.
Higher magnetic and electric multipole moments cannot be calculated by the above model, for similar reasons.
Applications.
Deuterium has a number of commercial and scientific uses. These include:
Nuclear reactors.
Deuterium is used in heavy water moderated fission reactors, usually as liquid D2O, to slow neutrons without the high neutron absorption of ordinary hydrogen. This is a common commercial use for larger amounts of deuterium.
In research reactors, liquid D2 is used in cold sources to moderate neutrons to very low energies and wavelengths appropriate for scattering experiments.
Experimentally, deuterium is the most common nuclide used in nuclear fusion reactor designs, especially in combination with tritium, because of the large reaction rate (or nuclear cross section) and high energy yield of the D–T reaction. There is an even higher-yield D–Helium-3 fusion reaction, though the breakeven point of D– is higher than that of most other fusion reactions; together with the scarcity of , this makes it implausible as a practical power source until at least D–T and D–D fusion reactions have been performed on a commercial scale. However, commercial nuclear fusion is not yet an accomplished technology.
NMR spectroscopy.
Deuterium is most commonly used in hydrogen nuclear magnetic resonance spectroscopy (proton NMR) in the following way. NMR ordinarily requires compounds of interest to be analyzed as dissolved in solution. Because of deuterium's nuclear spin properties which differ from the light hydrogen usually present in organic molecules, NMR spectra of hydrogen/protium are highly differentiable from that of deuterium, and in practice deuterium is not "seen" by an NMR instrument tuned for light-hydrogen. Deuterated solvents (including heavy water, but also compounds like deuterated chloroform, CDCl3) are therefore routinely used in NMR spectroscopy, in order to allow only the light-hydrogen spectra of the compound of interest to be measured, without solvent-signal interference.
Nuclear magnetic resonance spectroscopy can also be used to obtain information about the deteron's environment in isotopically labelled samples (Deuterium NMR). For example, the flexibility in the tail, which is a long hydrocarbon chains, in deuterium-labelled lipid molecules can be quantified using solid state deuterium NMR.
Deuterium NMR spectra are especially informative in the solid state because of its relatively small quadrupole moment in comparison with those of bigger quadrupolar nuclei such as chlorine-35, for example.
Tracing.
In chemistry, biochemistry and environmental sciences, deuterium is used as a non-radioactive, stable isotopic tracer, for example, in the doubly labeled water test. In chemical reactions and metabolic pathways, deuterium behaves somewhat similarly to ordinary hydrogen (with a few chemical differences, as noted). It can be distinguished from ordinary hydrogen most easily by its mass, using mass spectrometry or infrared spectrometry. Deuterium can be detected by femtosecond infrared spectroscopy, since the mass difference drastically affects the frequency of molecular vibrations; deuterium-carbon bond vibrations are found in locations free of other signals.
Measurements of small variations in the natural abundances of deuterium, along with those of the stable heavy oxygen isotopes 17O and 18O, are of importance in hydrology, to trace the geographic origin of Earth's waters. The heavy isotopes of hydrogen and oxygen in rainwater (so-called meteoric water) are enriched as a function of the environmental temperature of the region in which the precipitation falls (and thus enrichment is related to mean latitude). The relative enrichment of the heavy isotopes in rainwater (as referenced to mean ocean water), when plotted against temperature falls predictably along a line called the global meteoric water line (GMWL). This plot allows samples of precipitation-originated water to be identified along with general information about the climate in which it originated. Evaporative and other processes in bodies of water, and also ground water processes, also differentially alter the ratios of heavy hydrogen and oxygen isotopes in fresh and salt waters, in characteristic and often regionally distinctive ways. The ratio of concentration of 2H to 1H is usually indicated with a delta as δ2H and the geographic patterns of these values are plotted in maps termed as isoscapes. Stable isotope are incorporated into plants and animals and an analysis of the ratios in a migrant bird or insect can help suggest a rough guide to their origins.
Contrast properties.
Neutron scattering techniques particularly profit from availability of deuterated samples: The H and D cross sections are very distinct and different in sign, which allows contrast variation in such experiments. Further, a nuisance problem of ordinary hydrogen is its large incoherent neutron cross section, which is nil for D. The substitution of deuterium atoms for hydrogen atoms thus reduces scattering noise.
Hydrogen is an important and major component in all materials of organic chemistry and life science, but it barely interacts with X-rays. As hydrogen (and deuterium) interact strongly with neutrons, neutron scattering techniques, together with a modern deuteration facility, fills a niche in many studies of macromolecules in biology and many other areas.
Nuclear weapons.
This is discussed below. It is notable that although most stars, including the Sun, generate energy over most of their lives by fusing hydrogen into heavier elements, such fusion of light hydrogen (protium) has never been successful in the conditions attainable on Earth. Thus, all artificial fusion, including the hydrogen fusion that occurs in so-called hydrogen bombs, requires heavy hydrogen (either tritium or deuterium, or both) in order for the process to work.
Suggested neurological effects of natural abundance variation.
The natural deuterium content of water has been suggested from preliminary correlative epidemiology to influence the incidence of affective disorder-related pathophysiology and major depression, which might be mediated by the serotonergic mechanisms.
History.
Suspicion of lighter element isotopes.
The existence of nonradioactive isotopes of lighter elements had been suspected in studies of neon as early as 1913, and proven by mass spectrometry of light elements in 1920. The prevailing theory at the time, however, was that the isotopes were due to the existence of differing numbers of "nuclear electrons" in different atoms of an element. It was expected that hydrogen, with a measured average atomic mass very close to , the known mass of the proton, always had a nucleus composed of a single proton (a known particle), and therefore could not contain any nuclear electrons without losing its charge entirely. Thus, hydrogen could have no heavy isotopes.
Deuterium detected.
It was first detected spectroscopically in late 1931 by Harold Urey, a chemist at Columbia University. Urey's collaborator, Ferdinand Brickwedde, distilled five liters of cryogenically produced liquid hydrogen to of liquid, using the low-temperature physics laboratory that had recently been established at the National Bureau of Standards in Washington, D.C. (now the National Institute of Standards and Technology). The technique had previously been used to isolate heavy isotopes of neon. The cryogenic boiloff technique concentrated the fraction of the mass-2 isotope of hydrogen to a degree that made its spectroscopic identification unambiguous.
Naming of the isotope and Nobel Prize.
Urey created the names protium, deuterium, and tritium in an article published in 1934. The name is based in part on advice from G. N. Lewis who had proposed the name "deutium". The name is derived from the Greek deuteros (second), and the nucleus to be called "deuteron" or "deuton". Isotopes and new elements were traditionally given the name that their discoverer decided. Some British chemists, like Ernest Rutherford, wanted the isotope to be called "diplogen", from the Greek diploos (double), and the nucleus to be called diplon.
The amount inferred for normal abundance of this heavy isotope of hydrogen was so small (only about 1 atom in 6400 hydrogen atoms in ocean water (156 deuteriums per million hydrogens)) that it had not noticeably affected previous measurements of (average) hydrogen atomic mass. This explained why it hadn't been experimentally suspected before. Urey was able to concentrate water to show partial enrichment of deuterium. Lewis had prepared the first samples of pure heavy water in 1933. The discovery of deuterium, coming before the discovery of the neutron in 1932, was an experimental shock to theory, but when the neutron was reported, making deuterium's existence more explainable, deuterium won Urey the Nobel Prize in chemistry in 1934. Lewis was embittered by being passed over for this recognition given to his former student.
"Heavy water" experiments in World War II.
Shortly before the war, Hans von Halban and Lew Kowarski moved their research on neutron moderation from France to England, smuggling the entire global supply of heavy water (which had been made in Norway) across in twenty-six steel drums.
During World War II, Nazi Germany was known to be conducting experiments using heavy water as moderator for a nuclear reactor design. Such experiments were a source of concern because they might allow them to produce plutonium for an atomic bomb. Ultimately it led to the Allied operation called the "Norwegian heavy water sabotage", the purpose of which was to destroy the Vemork deuterium production/enrichment facility in Norway. At the time this was considered important to the potential progress of the war.
After World War II ended, the Allies discovered that Germany was not putting as much serious effort into the program as had been previously thought. They had been unable to sustain a chain reaction. The Germans had completed only a small, partly built experimental reactor (which had been hidden away). By the end of the war, the Germans did not even have a fifth of the amount of heavy water needed to run the reactor, partially due to the Norwegian heavy water sabotage operation. However, even had the Germans succeeded in getting a reactor operational (as the U.S. did with a graphite reactor in late 1942), they would still have been at least several years away from development of an atomic bomb with maximal effort. The engineering process, even with maximal effort and funding, required about two and a half years (from first critical reactor to bomb) in both the U.S. and U.S.S.R, for example.
Deuterium in thermonuclear weapons.
The 62-ton Ivy Mike device built by the United States and exploded on 1 November 1952, was the first fully successful "hydrogen bomb" or thermonuclear bomb. In this context, it was the first bomb in which most of the energy released came from nuclear reaction stages that followed the primary nuclear fission stage of the atomic bomb. The Ivy Mike bomb was a factory-like building, rather than a deliverable weapon. At its center, a very large cylindrical, insulated vacuum flask or cryostat, held cryogenic liquid deuterium in a volume of about 1000 liters (160 kilograms in mass, if this volume had been completely filled). Then, a conventional atomic bomb (the "primary") at one end of the bomb was used to create the conditions of extreme temperature and pressure that were needed to set off the thermonuclear reaction.
Within a few years, so-called "dry" hydrogen bombs were developed that did not need cryogenic hydrogen. Released information suggests that all thermonuclear weapons built since then contain chemical compounds of deuterium and lithium in their secondary stages. The material that contains the deuterium is mostly lithium deuteride, with the lithium consisting of the isotope lithium-6. When the lithium-6 is bombarded with fast neutrons from the atomic bomb, tritium (hydrogen-3) is produced, and then the deuterium and the tritium quickly engage in thermonuclear fusion, releasing abundant energy, helium-4, and even more free neutrons.
Data for elemental deuterium.
Formula: D2 or 2
Data at approximately for D2 (triple point):
Anti-deuterium.
An antideuteron is the antimatter counterpart of the nucleus of deuterium, consisting of an antiproton and an antineutron. The antideuteron was first produced in 1965 at the Proton Synchrotron at CERN and the Alternating Gradient Synchrotron at Brookhaven National Laboratory. A complete atom, with a positron orbiting the nucleus, would be called "antideuterium", but as of 2005 antideuterium has not yet been created. The proposed symbol for antideuterium is , that is, D with an overbar.

</doc>
<doc id="8525" url="https://en.wikipedia.org/wiki?curid=8525" title="Digital signal processing">
Digital signal processing

Digital signal processing (DSP) is the numerical manipulation of signals, usually with the intention to measure, filter, produce or compress continuous analog signals. It is characterized by the use of digital signals to represent these signals as discrete time, discrete frequency, or other discrete domain signals in the form of a sequence of numbers or symbols to permit the digital processing of these signals.
Theoretical analyses and derivations are typically performed on discrete-time signal models, created by the abstract process of sampling. Numerical methods require a digital signal, such as those produced by an analog-to-digital converter (ADC). The processed result might be a frequency spectrum or a set of statistics. But often it is another digital signal that is converted back to analog form by a digital-to-analog converter (DAC). Even if that whole sequence is more complex than analog processing and has a discrete value range, the application of computational power to signal processing allows for many advantages over analog processing in many applications, such as error detection and correction in transmission as well as data compression.
Digital signal processing and analog signal processing are subfields of signal processing. DSP applications include audio and speech signal processing, sonar and radar signal processing, sensor array processing, spectral estimation, statistical signal processing, digital image processing, signal processing for communications, control of systems, biomedical signal processing, seismic data processing, among others. DSP algorithms have long been run on standard computers, as well as on specialized processors called digital signal processors, and on purpose-built hardware such as application-specific integrated circuit (ASICs). Currently, there are additional technologies used for digital signal processing including more powerful general purpose microprocessors, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors, among others.
Digital signal processing can involve linear or nonlinear operations. Nonlinear signal processing is closely related to nonlinear system identification and can be implemented in the time, frequency, and spatio-temporal domains.
Signal sampling.
The increasing use of computers has resulted in the increased use of, and need for, digital signal processing. To digitally analyze and manipulate an analog signal, it must be digitized with an analog-to-digital converter. Sampling is usually carried out in two stages, discretization and quantization. In the discretization stage, the space of signals is partitioned into equivalence classes and quantization is carried out by replacing the signal with representative signal of the corresponding equivalence class. In the quantization stage, the representative signal values are approximated by values from a finite set.
The Nyquist–Shannon sampling theorem states that a signal can be exactly reconstructed from its samples if the sampling frequency is greater than twice the highest frequency of the signal, but this requires an infinite number of samples. In practice, the sampling frequency is often significantly higher than twice that required by the signal's limited bandwidth.
Some (continuous-time) periodic signals become non-periodic after sampling, and some non-periodic signals become periodic after sampling. In general, for a periodic signal with period "T" to be periodic (with period "N") after sampling with sampling interval "Ts", the following must be satisfied:
where "k is an integer.
DSP domains.
In DSP, engineers usually study digital signals in one of the following domains: time domain (one-dimensional signals), spatial domain (multidimensional signals), frequency domain, and wavelet domains. They choose the domain in which to process a signal by making an informed assumption (or by trying different possibilities) as to which domain best represents the essential characteristics of the signal. A sequence of samples from a measuring device produces a temporal or spatial domain representation, whereas a discrete Fourier transform produces the frequency domain information, that is, the frequency spectrum. Autocorrelation is defined as the cross-correlation of the signal with itself over varying intervals of time or space.
Time and space domains.
The most common processing approach in the time or space domain is enhancement of the input signal through a method called filtering. Digital filtering generally consists of some linear transformation of a number of surrounding samples around the current sample of the input or output signal. There are various ways to characterize filters; for example:
A filter can be represented by a block diagram, which can then be used to derive a sample processing algorithm to implement the filter with hardware instructions. A filter may also be described as a difference equation, a collection of zeroes and poles or, if it is an FIR filter, an impulse response or step response.
The output of a linear digital filter to any given input may be calculated by convolving the input signal with the impulse response.
Frequency domain.
Signals are converted from time or space domain to the frequency domain usually through the Fourier transform. The Fourier transform converts the signal information to a magnitude and phase component of each frequency. Often the Fourier transform is converted to the power spectrum, which is the magnitude of each frequency component squared.
The most common purpose for analysis of signals in the frequency domain is analysis of signal properties. The engineer can study the spectrum to determine which frequencies are present in the input signal and which are missing.
In addition to frequency information, phase information is often needed. This can be obtained from the Fourier transform. With some applications, how the phase varies with frequency can be a significant consideration.
Filtering, particularly in non-realtime work can also be achieved by converting to the frequency domain, applying the filter and then converting back to the time domain. This is a fast, O(n log n) operation, and can give essentially any filter shape including excellent approximations to brickwall filters.
There are some commonly used frequency domain transformations. For example, the cepstrum converts a signal to the frequency domain through Fourier transform, takes the logarithm, then applies another Fourier transform. This emphasizes the harmonic structure of the original spectrum.
Frequency domain analysis is also called "spectrum-" or "spectral analysis".
Z-plane analysis.
Whereas analog filters are usually analyzed in terms of transfer functions in the s plane using Laplace transforms, digital filters are analyzed in the z plane in terms of Z-transforms. A digital filter may be described in the z plane by its characteristic collection of zeroes and poles. The z plane provides a means for mapping digital frequency (samples/second) to real and imaginary z components, where formula_2 for continuous periodic signals and formula_3 (formula_4 is the digital frequency). This is useful for providing a visualization of the frequency response of a digital system or signal.
Wavelet.
In numerical analysis and functional analysis, a discrete wavelet transform (DWT) is any wavelet transform for which the wavelets are discretely sampled. As with other wavelet transforms, a key advantage it has over Fourier transforms is temporal resolution: it captures both frequency "and" location information (location in time).
Applications.
The main applications of DSP are audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, radar, sonar, financial signal processing, seismology and biomedicine. Specific examples are speech compression and transmission in digital mobile phones, room correction of sound in hi-fi and sound reinforcement applications, weather forecasting, economic forecasting, seismic data processing, analysis and control of industrial processes, medical imaging such as CAT scans and MRI, MP3 compression, computer graphics, image manipulation, hi-fi loudspeaker crossovers and equalization, and audio effects for use with electric guitar amplifiers.
Implementation.
Depending on the requirements of the application, digital signal processing tasks can be implemented on general purpose computers.
Often when the processing requirement is not real-time, processing is economically done with an existing general-purpose computer and the signal data (either input or output) exists in data files. This is essentially no different from any other data processing, except DSP mathematical techniques (such as the FFT) are used, and the sampled data is usually assumed to be uniformly sampled in time or space. For example: processing digital photographs with software such as "Photoshop".
However, when the application requirement is real-time, DSP is often implemented using specialized microprocessors such as the DSP56000, the TMS320, or the SHARC. These often process data using fixed-point arithmetic, though some more powerful versions use floating point. For faster applications FPGAs might be used.
Beginning in 2007, multicore implementations of DSPs have started to emerge from companies including Freescale and Stream Processors, Inc. For faster applications with vast usage, ASICs might be designed specifically. For slow applications, a traditional slower processor such as a microcontroller may be adequate. Also a growing number of DSP applications are now being implemented on embedded systems using powerful PCs with multi-core processors.

</doc>
