<doc id="9841" url="https://en.wikipedia.org/wiki?curid=9841" title="Expressive aphasia">
Expressive aphasia

Expressive aphasia (non-fluent aphasia) is characterized by the loss of the ability to produce language (spoken or written). A person with expressive aphasia will exhibit effortful speech. Speech may only include important content words and leave out insignificant words, like "the". This is known as "telegraphic speech". The person may still be understood, but sentences will not be grammatical. In very severe forms of Expressive Aphasia, a person may only speak using single word utterances. It is one subset of a larger family of disorders known collectively as aphasia. Expressive aphasia differs from dysarthria, which is typified by a patient's inability to properly move the muscles of the tongue and mouth to produce speech. Expressive aphasia also differs from apraxia of speech which is a motor disorder characterized by an inability to create and sequence motor plans for speech. Comprehension is typically only mildly to moderately impaired in expressive aphasia due to difficulty understanding complex grammar. This contrasts with receptive aphasia, which is distinguished by a patient's inability to comprehend language or speak with appropriately meaningful words. Expressive aphasia is also known as Broca's aphasia in clinical neuropsychology and agrammatic aphasia in cognitive neuropsychology and is caused by acquired damage to the anterior regions of the brain, including (but not limited to) the left posterior inferior frontal gyrus or inferior frontal operculum, also described as Broca's area (Brodmann area 44 and Brodmann area 45) Expressive aphasia is also a symptom of some migraine attacks.
Signs and symptoms.
Broca's aphasia is a type of expressive aphasia because speech production is halting and effortful. Damage is typically in the anterior portion of the left hemisphere. Typically, writing is at least as severely impaired as speech. Persons with Broca's aphasia are usually aware of their communication deficits, and are more prone to depression and sometimes catastrophic reactions that are patients with other forms of aphasia. Intonation and stress patterns are deficient. Language is reduced to disjointed words, and sentence construction is poor, omitting function words and inflections (bound morphemes). A person with expressive aphasia might say ""Son ... University ... Smart ... Good ... Good ... ""Content words (nouns, verbs) may be used in speech, but sentences are difficult to produce due to problems with grammar, resulting in "telegraphic speech." In its more severe form, spoken utterances may be reduced to single words. "The prosody of those with Broca's aphasia is compromised by shortened length of utterances and the presence of self-repairs and disfluencies."
For example, in the following passage, a Broca's aphasic patient is trying to explain how he came to the hospital for dental surgery:
Patients who communicated with sign language before the onset of the aphasia experience analogous symptoms.
Severity of expressive aphasia varies among patients. In the most extreme cases, patients may be able to produce only a single word. The most famous case of this was Paul Broca's patient Leborgne, nicknamed "Tan", after the only syllable he could say. Even in such cases, over-learned and rote-learned speech patterns may be retained—for instance, some patients can count from one to ten, but cannot produce the same numbers in ordinary conversation.
Meanwhile, in general, word comprehension is preserved; making most Broca's aphasia patients receptive language functional. Individuals with Broca's aphasia understand most of the everyday conversation around them, but higher-level deficits in receptive language can also occur. Individuals with Broca's aphasia can often respond to simple questions. 
For more complex sentences, with many steps interpretation dependent on syntax and phrase structure is substantially impaired. This can be demonstrated by using phrases with unusual structures. A typical Broca's aphasic patient will misinterpret "the man is bitten by the dog" by switching the subject and object. Note this element is a problem with receptive language, not expressive language, and is one reason why the problem is referred to as agrammatic aphasia. Because patients with Broca's aphasia have good receptive language, their reading skills are also functional.
Patients who recover go on to say that they knew what they wanted to say but could not express themselves. Residual deficits will often be seen.
Agrammatic aphasiacs tend to be sensitive to word order, relying instead on pragmatics in order to understand others. For example, they may understand a sentence such as “The teenagers arrested the cop” to actually mean “The cop arrested the teenagers”. This is due to the understood meaning to be more realistic and more likely to happen. Because of this trouble with understanding, there is a mental leap that is often made in order to attempt comprehension. It is possible that people with agrammatic aphasia rely on a heuristic based on the canonical word order of English. Typically, the noun phrase preceding the verb takes on the role of the agent, or the noun that does the verb. Additionally, the noun phrase following a preposition such as ‘by’ is also assigned the role of agent, and thus follows the same thought process. Relying on this heuristic helps to understand reversible active sentences.
For example, only 75% of agrammatic aphasiacs would comprehend the reversible active sentence, “The actor applauded the dancer” accurately, due to the atypical scenario that the sentence describes. Reversible passive sentences such as “The actor was applauded by the dancer” are even more complex and difficult to comprehend, and were only found to be accurately understood by 50% of tested agrammatic aphasiacs in one study. Some researchers hypothesize that Broca’s aphasiacs struggle with such types of sentence processing due to damage to a specific sentence processing mechanism that connects an antecedent with its trace. Broca’s aphasicas also have been found to struggle in the integration of syntactic structure of a sentence with semantic information. This can perhaps be attributed to the a timing problem where lexical items are retrieved too slowly to integrate with sentence structure.
Overlap with receptive aphasia.
In addition to difficulty expressing oneself, sufferers of expressive aphasia are also noted to commonly have trouble with comprehension in certain linguistic areas. This agrammatism overlaps with receptive aphasia, but can be seen in patients of expressive aphasia without being diagnosed as having receptive aphasia too. The most well-noted of these are object-relative clauses, object Wh- questions, and topicalized structures (placing the topic at the beginning of the sentence). These three concepts all share phrasal movement, which can cause words to lose their thematic roles when they change order in the sentence. This is often not an issue for people without agrammatic aphasias, but many aphasics rely very heavily on word order to understand roles that words play within the sentence.
Causes.
The most common cause of expressive aphasia is stroke. A stroke is caused by hypoperfusion (lack of oxygen) to an area of the brain, which is commonly caused by thrombosis or embolism. Some form of aphasia occurs in 34 to 38% of stroke patients. Expressive aphasia occurs in approximately 12% of new cases of aphasia caused by stroke. In most cases, expressive aphasia is caused by a stroke in Broca's area or the surrounding vicinity. However, cases of expressive aphasia have been seen in patients with strokes in other areas of the brain. Patients with classic symptoms of expressive aphasia in general have more acute brain lesions, whereas patients with larger, widespread lesions exhibit a variety of symptoms that may be classified as global aphasia or left unclassified.
Expressive aphasia can also be caused by trauma to the brain, tumor, cerebral hemorrhage by extradural hematoma.
Understanding lateralization of brain function is important for understanding what areas of the brain cause expressive aphasia when damaged. In the past, it has been believed that the area for language production differs between left and right-handed individuals. If this were true, damage to the homologous region of Broca's area in the right hemisphere should cause aphasia in a left-handed individual. More recent studies have shown that even left-handed individuals typically have language functions only in the left hemisphere. However, left-handed individuals are more likely to have a dominance of language in the right hemisphere.
Diagnosis.
Expressive aphasia is also a classification of non-fluent aphasia, as opposed to fluent aphasia. Diagnosis is done on a case by case basis, as lesions often affect surrounding cortex and deficits are not well conserved between patients.
In order to diagnose a patient who is suffering from Broca’s aphasia, there are certain commonly used tests and procedures. The Boston Diagnostic Aphasia Examination (BDAE), the Western Aphasia Battery (WAB) and the Porch Index of Speech Ability (PISA) are all evaluations created for the purpose of identifying aphasia and the class of the condition the patient is experiencing. More routine processes for diagnosis include MRI scans and questions. The ability to name common objects, maintain casual conversation, proper word use, answering questions concerning a subject the patient read or heard, word and sentence repetition skills and general reading and writing proficiency are all determiners of possible expressive aphasia. Testing swallowing can also aid in diagnosing this impairment, as can the ability to use alternative and augmentative (AAC) speech, which is a form of communication specifically used by those suffering from physical or mental disabilities that impair the production of spoken or written language.
Treatment.
Currently, there is no standard treatment for expressive aphasia. Most aphasia treatment is individualized based on a patient's condition and needs as assessed by a speech language pathologist. The majority of patients go through a period of spontaneous recovery following brain injury in which they regain a great deal of language function. In the months following injury or stroke, most patients receive traditional treatment for a few hours per day. Among other exercises, patients practice the repetition of words and phrases. Mechanisms are also taught in traditional treatment to compensate for lost language function such as drawing and using phrases that are easier to pronounce. Emphasis is placed on establishing a basis for communication with family and caregivers in everyday life. The following treatments are currently being studied to determine the best possible method for treating aphasia.
As a client, you may have the option of individual or group treatment. Group treatment tends to go under the radar but has been seen to have advantageoous outcomes. Some types of group treatments include becoming a part of a supportive peer environment, family counseling, maintenance groups, support groups and treatment groups. These are important to consider because depression can be very common with Aphasia. It is important to keep your mental and emotional health strong, and by allowing yourself all of this support, we can ensure this.
Singing and Melodic Intonation Therapy.
Melodic Intonation Therapy was inspired by the observation that individuals with non-fluent aphasia sometimes can sing words or phrases that they normally cannot speak."Melodic Intonation Therapy was begun as an attempt to use the intact melodic/prosodic processing skills of the right hemisphere in those with aphasia to help cue retrieval words and expressive language." It is believed that this is because singing capabilities are stored in the right hemisphere of the brain, which is likely to remain unaffected after a stroke in the left hemisphere. However, recent evidence demonstrates that the capability of individuals with aphasia to sing entire pieces of text may actually result from rhythmic features and the familiarity with the lyrics.
The goal of Melodic Intonation Therapy is to utilize singing to access the language-capable regions in the right hemisphere and use these regions to compensate for lost function in the left hemisphere. Because it was assumed that patients are better at singing phrases than speaking them, the natural musical component of speech was used to engage the patients' ability to voice phrases. Contrary to this assumption, a clinical study revealed that singing and rhythmic speech may be similarly effective in the treatment of non-fluent aphasia and apraxia of speech. Moreover, evidence from randomized controlled trials is still needed to confirm that Melodic Intonation Therapy is suitable to improve propositional utterances and speech intelligibility in individuals with (chronic) non-fluent aphasia and apraxia of speech.
Melodic Intonation Therapy appears to work particularly well in patients who have had a unilateral, left hemisphere stroke, show poor articulation, nonfluent or severely restricted speech output, can produce some intelligible words while singing, moderately well preserved auditory comprehension, good motivation and emotional stability. MIT therapy on average lasts for 1.5 hours per day for five days per week. At the lowest level of therapy, simple words and phrases (such as "water" and "I love you") are broken down into a series of high- and low-pitch syllables. With increased treatment, longer phrases are taught and less support is provided by the therapist. Patients are taught to say phrases using the natural melodic component of speaking and continuous voicing is emphasized. The patient is also instructed to use the left hand to tap the syllables of the phrase while the phrases are spoken. Tapping is assumed to trigger the rhythmic component of speaking to utilize the right hemisphere.
The efficacy of singing has been proven in one patient with aphasia who was a trained musician; in this patient, singing had an advantage over rhythmic speech. However, the advantage of singing over rhythmic speech was not observed in 10 patients without any musical background. FMRI studies have shown that Melodic Intonation Therapy uses both sides of the brain to recover lost function, as opposed to traditional therapies that utilize only the left hemisphere. Furthermore, it has been seen that, in MIT, individuals with small lesions in the left hemisphere seem to recover by activation of the left hemisphere perilesional cortex, while, in individuals with larger left-hemisphere lesions, there is a recruitment of the use of language-capable regions in the right hemisphere. The interpretation of these results is still a matter of debate. For example, it remains unclear whether changes in neural activity in the right hemisphere result from singing or from the intensive use of common phrases, such as "thank you," "how are you?" or "I am fine." This type of phrases falls into the category of formulaic language and is known to be supported by neural networks of the intact right hemisphere.
Melodic Intonation Therapy is used by music therapists, board-certified professionals that use music as a therapeutic tool to effect certain non-musical outcomes in their patients. Speech language pathologists can also use this therapy for individuals who have had a left hemisphere stroke and non-fluent aphasias such as Broca’s or even apraxia of speech. Candidates will have good auditory comprehension, poor repetition and articulation skills, and good emotional stability and memory.
Constraint-induced therapy.
Constraint-induced aphasia therapy (CIAT) is based on similar principles as constraint-induced movement therapy developed by Dr. Edward Taub at the University of Alabama at Birmingham. Constraint-induced movement therapy is based on the idea that a person with an impairment (physical or communicative) develops a "learned nonuse" by compensating for the lost function with other means such as using an unaffected limb by a paralyzed individual or drawing by a patient with aphasia. In constraint-induced movement therapy, the alternative limb is constrained with a glove or sling and the patient is forced to use the affected limb. In constraint-induced aphasia therapy, the interaction is guided by communicative need in a language game context, picture cards, barriers making it impossible to see other players' cards, and other materials, so that patients are encouraged ("constrained") to use the remaining verbal abilities to succeed in the communication game.
Two important principles of constraint-induced aphasia therapy are that treatment is very intense, with sessions lasting for up to 6 hours over the course of 10 days and that language is used in a communication context in which it is closely linked to (nonverbal) actions. These principles are motivated by neuroscience insights about learning at the level of nerve cells (synaptic plasticity) and the coupling between cortical systems for language and action in the human brain. Constraint-induced therapy contrasts sharply with traditional therapy by the strong belief that mechanisms to compensate for lost language function should not be used unless absolutely necessary, even in everyday life.
It is believed that CIAT works by the mechanism of increased neuroplasticity. By constraining an individual to use only speech, it is believed that the brain can reestablish old neural pathways and recruit new neural pathways to compensate for lost function.
The greatest advantage of CIAT has been seen in its treatment of chronic aphasia (lasting over 1 year). Studies of CIAT have shown that further improvement is possible even after a patient has reached a "plateau" period of recovery. It has also been proven that the benefits of CIAT are retained long term. However, improvements only seem to be made while a patient is undergoing intense therapy. A recent breakthrough has been achieved by combining constraint-induced aphasia therapy with drug treatment, which led to an amplification of therapy benefits.
Pharmacotherapy.
In addition to active speech therapy, pharmaceuticals have also been considered as a useful treatment for expressive aphasia. This area of study is relatively new and much research continues to be conducted.
The following drugs have been suggested for use in treating aphasia and their efficacy has been studied in control studies.
The most effect has been shown by piracetam and amphetamine, which may increase cerebral plasticity and result in an increased capability to improve language function. It has been seen that piracetam is most effective when treatment is begun immediately following stroke. When used in chronic cases it has been much less efficient.
Bromocriptine has been shown by some studies to increase verbal fluency and word retrieval with therapy than with just therapy alone. Furthermore, its use seems to be restricted to non-fluent aphasia.
Donepezil has shown a potential for helping chronic aphasia.
No study has established irrefutable evidence that any drug is an effective treatment for aphasia therapy. Furthermore, no study has shown any drug to be specific for language recovery. Comparison between the recovery of language function and other motor function using any drug has shown that improvement is due to a global increase plasticity of neural networks. Pharmaceutical therapy remains an important area of study in aphasia treatment.
Transcranial magnetic stimulation.
In transcranial magnetic stimulation (TMS), magnetic fields are used to create electrical currents in specified cortical regions. The procedure is a painless and noninvasive method of stimulating the cortex. TMS works by suppressing the inhibition process in certain areas of the brain. By suppressing the inhibition of neurons by external factors, the targeted area of the brain may be reactivated and thereby recruited to compensate for lost function. Research has shown that patients can show increased object naming ability with regular transcranial magnetic stimulation than patients in therapy without TMS. Furthermore, this improvement has been proven to be permanent and remains upon the completion of TMS therapy. However, some patients fail to show any significant improvement from TMS which indicates the need for further research of this treatment.
Treatment of underlying forms (TUF).
Described as the linguistic approach to the treatment of expressive aphasia, treatment begins by emphasizing and educating patients on the thematic roles of words within sentences. Sentences that are usually problematic will be reworded into active-voiced, declarative phrasings of their non-canonical counterparts. The simpler sentence phrasings are then transformed into variations that are more difficult to interpret. For example, many sufferers of expressive aphasia struggle with Wh- sentences. "What" and "who" questions are problematic sentences that this treatment method attempts to improve, and they are also two interrogative particles that are strongly related to each other because they reorder arguments from the declarative counterparts. For instance, therapists have used sentences like, "Who is the boy helping?" and "What is the boy fixing?" because both verbs are transitive- they require two arguments in the form of a subject and a direct object, but not necessarily an indirect object. In addition, certain question particles are linked together based on how the reworded sentence is formed. Training "who" sentences increased the generalizations of non-trained "who" sentences as well as untrained "what" sentences, and vice versa. Likewise, "where" and "when" question types are very closely linked. "What" and "who" questions alter placement of arguments, and "where" and "when" sentences move adjunct phrases. Training is in the style of: "The man parked the car in the driveway. What did the man park in the driveway?" Sentence training goes on in this manner for more domains, such as clefts and sentence voice.
Results: Patients’ use of sentence types used in the TUF treatment will improve, subjects will generalize sentences of similar category to those used for treatment in TUF, and results are applied to real-world conversations with others. Generalization of sentence types used can be improved when the treatment progresses in the order of more complex sentences to more elementary sentences. Treatment has been shown to affect on-line (real-time) processing of trained sentences and these results can be tracked using fMRI mappings. Training of Wh- sentences has led improvements in three main areas of discourse for aphasics: increased average length of utterances, higher proportions of grammatical sentences, and larger ratios of numbers of verbs to nouns produced. Patients also showed improvements in verb argument structure productions and assigned thematic roles to words in utterances with more accuracy. In terms of on-line sentence processing, patients having undergone this treatment discriminate between anomalous and non-anomalous sentences with more accuracy than control groups and are closer to levels of normalcy than patients not having participated in this treatment.
Mechanisms of recovery.
Mechanisms for recovery differ from patient to patient. Some mechanisms for recovery occur spontaneously after damage to the brain, whereas others are caused by the effects of language therapy. FMRI studies have shown that recovery can be partially attributed to the activation of tissue around the damaged area and the recruitment of new neurons in these areas to compensate for the lost function. Recovery may also be caused in very acute lesions by a return of blood flow and function to damaged tissue that has not died around an injured area. It has been stated by some researchers that the recruitment and recovery of neurons in the left hemisphere opposed to the recruitment of similar neurons in the right hemisphere is superior for long-term recovery and continued rehabilitation. It is thought that, because the right hemisphere is not intended for full language function, using the right hemisphere as a mechanism of recovery is effectively a "dead-end" and can lead only to partial recovery.
It has been proven that, among all types of therapies, one of the most important factors and best predictors for a successful outcome is the intensity of the therapy. By comparing the length and intensity of various methods of therapies, it was proven that intensity is a better predictor of recovery than the method of therapy used.
Speech entrainment: a potential new treatment.
In a 2012 study from the University of South Carolina's Arnold School of Public Health, researchers found that some stroke victims with speech loss from Broca's aphasia can speak fluently through the use of "speech entrainment". In the experiment of 13 people with Broca's aphasia, each subject was prompted with an auditory and visual stimulus of a series of sentences. The visual stimulus was a video shown on an iPod of someone speaking each sentence in time with an audio recording of each sentence. The result of this audio-visual stimulation was amazing: the patients, some who had Broca's aphasia for multiple decades, were able to mimic the movements of the mouth in real time and speak fluently. Though there are various methods of treatment for Broca's aphasia as stated on this page, speech entrainment provides a potential future therapeutic method that produces drastic results simply not seen in any other method of treatment.
Prognosis.
In most individuals with expressive aphasia, the majority of recovery is seen within the first year following a stroke or injury. The majority of this improvement is seen in the first four weeks in therapy following a stroke and slows thereafter. However, this timeline will vary depending upon the type of stroke experienced by the patient. Patients who experienced an ischemic stroke may recover in the days and weeks following the stroke, and then experience a plateau and gradual slowing of recovery. On the other hand, patients who experienced a hemorrhagic stroke experience a slower recovery in the first 4–8 weeks, followed by a faster recovery which eventually stabilizes.
When compared to patients with the most common types of aphasia, patients with expressive aphasia tend to show the most improvement within the first year. This may be due to an expressive aphasiac's awareness and greater insight of their impairment (unlike in receptive aphasia), which motivates him/her to progress in treatment. Studies have also found that prognosis of expressive aphasia correlates strongly with the initial severity of impairment. Those with the greatest initial disability tend to show the greatest improvement among test groups. Within the first year, the diagnosis of patients with expressive aphasia may change to anomic aphasia. Likewise, patients diagnosed with global aphasia may be re-diagnosed with expressive aphasia upon improvement. Typically, little improvement is seen after the first year following a stroke. However, it has been seen that continued recovery is possible years after a stroke with effective treatment using methods such as constraint-induced aphasia therapy. Depression, anxiety, and social withdrawal are all factors which have been proven to negatively affect a patient's chance of recovery. Due to frustration from the inability to express themselves, sufferers of expressive aphasia can become clinically depressed. This creates further impairment because the left hemisphere in depressed individuals functions at lower levels of activity than people without depression. This further complicates issues because the decreased functionality of the two conditions can combine to create even lower levels of activity than in either of the two conditions alone. The strategy for aiding individuals in this condition is to deal with the depression first. Once the depression is alleviated, or at least under control, the patient is better able to focus on treatments that target the aphasia than if the order of treatments was reversed.
Location and size of the brain lesion may also play a role in the prognosis of aphasia. It has been seen in receptive aphasia that larger lesions correlate to slower recovery. It has also been seen that patients with aphasia caused by sub cortical lesions have a better chance of recovery than those with aphasia due to cortical stroke. Other factors that may affect recovery are age, education, social support, and handedness (how one's brain is organized).
History.
Expressive aphasia was first identified by the French neurologist Paul Broca. By examining the brains of deceased individuals having acquired expressive aphasia in life, he concluded that language ability is localized in the ventroposterior region of the frontal lobe. One of the most important aspects of Paul Broca's discovery was the observation that the loss of proper speech in expressive aphasia is due to the brain's loss of ability to produce language, as opposed to the mouth's loss of ability to produce words.
The discoveries of Paul Broca were made during the same period of time as the German Neurologist Carl Wernicke, who was also studying brains of aphasiacs post-mortem and identified the region now known as Wernicke's area. Discoveries of both men contributed to the concept of localization, which states that specific brain functions are all localized to a specific area of the brain. While both men made significant contributions to the field of aphasia, it was Carl Wernicke who realized the difference between patients with aphasia that could not produce language and those that could not comprehend language (the essential difference between expressive and receptive aphasia).
Society and culture.
The protagonist of Stephen King's novel "Duma Key" exhibited symptoms of a condition similar to receptive aphasia after suffering brain damage in an industrial accident. When trying to recall some words, he would frequently substitute a synonym of a similar-sounding word, such as trying to say "char" but instead saying "burn" (a synonym of "char") and "friend" (a synonym of "chum").
The character Toggle in Garry Trudeau's cartoon strip "Doonesbury" suffers from expressive aphasia.
The character Saxifrage Russell suffers Broca's aphasia due to a stroke suffered while being rescued from interrogators in Kim Stanley Robinson's novel "Green Mars".
The character Hodor in George R. R. Martin's A Song of Ice and Fire may have suffered a form of Broca's aphasia. Throughout the novels, Hodor is only able to say the single word "Hodor." The characters of the novels associate the word with him and use it as his name despite it not being the name that he was born with. "Martin doesn't provide any details regarding whether Hodor suffered a traumatic brain injury as a child. But his symptoms are consistent with this type of disorder." The character in the TV series also carries a scar on his temple which would be the correct location for a lesion in Broca's area.
Similar to the above, the character Emmeryn in Nintendo's Fire Emblem: Awakening shows signs of this condition after a presumably traumatic injury, along with what seems to be amnesia.

</doc>
<doc id="9843" url="https://en.wikipedia.org/wiki?curid=9843" title="Ephesus">
Ephesus

Ephesus (; "Ephesos"; ; ultimately from Hittite "Apasa") was an ancient Greek city on the coast of Ionia, three kilometres southwest of present-day Selçuk in İzmir Province, Turkey. It was built in the 10th century BC on the site of the former Arzawan capital by Attic and Ionian Greek colonists. During the Classical Greek era it was one of the twelve cities of the Ionian League. The city flourished after it came under the control of the Roman Republic in 129 BC. According to estimates, Ephesus had a population of 33,600 to 56,000 people in the Roman period, making it the third largest city of Roman Asia Minor after Sardis and Alexandria Troas.
The city was famed for the Temple of Artemis (completed around 550 BC), one of the Seven Wonders of the Ancient World. In 268 AD, the Temple was destroyed or damaged in a raid by the Goths. It may have been rebuilt or repaired but this is uncertain, as its later history is not clear. Emperor Constantine the Great rebuilt much of the city and erected new public baths. Following the Edict of Thessalonica from Emperor Theodosius I, what remained of the temple was destroyed in 401 AD by a mob led by St. John Chrysostom. The town was partially destroyed by an earthquake in 614 AD. The city's importance as a commercial center declined as the harbor was slowly silted up by the Küçükmenderes River.
Ephesus was one of the seven churches of Asia that are cited in the Book of Revelation. The Gospel of John may have been written here. The city was the site of several 5th century Christian Councils (see Council of Ephesus). It is also the site of a large gladiators' graveyard. The ruins of Ephesus are a favourite international and local tourist attraction, partly owing to their easy access from Adnan Menderes Airport.
History.
Neolithic age.
The area surrounding Ephesus was already inhabited during the Neolithic Age (about 6000 BC), as was revealed by excavations at the nearby "höyük" (artificial mounds known as tells) of Arvalya and Cukurici.
Bronze Age.
Excavations in recent years have unearthed settlements from the early Bronze Age at Ayasuluk Hill. According to Hittite sources, the capital of the Kingdom of Arzawa (another independent state in Western and Southern Anatolia/Asia Minor) was Apasa (or "Abasa"). Some scholars suggest that this is the later Greek Ephesus. In 1954, a burial ground from the Mycenaean era (1500–1400 BC) with ceramic pots was discovered close to the ruins of the basilica of St. John. This was the period of the Mycenaean Expansion when the "Achaioi" (as they were called by Homer) settled in Asia Minor during the 14th and 13th centuries BC. Scholars believe that Ephesus was founded on the settlement of Apasa (or "Abasa"), a Bronze Age city noted in 14th century BC Hittite sources as being under the rule of the Ahhiyawans, most probably the name of the Achaeans used in Hittite sources.
Period of Greek migrations.
Ephesus was founded as an Attic-Ionian colony in the 10th century BC on the Ayasuluk Hill, three kilometers () from the centre of ancient Ephesus (as attested by excavations at the Seljuk castle during the 1990s). The mythical founder of the city was a prince of Athens named Androklos, who had to leave his country after the death of his father, King Kadros. According to the legend, he founded Ephesus on the place where the oracle of Delphi became reality ("A fish and a boar will show you the way"). Androklos drove away most of the native Carian and Lelegian inhabitants of the city and united his people with the remainder. He was a successful warrior, and as a king he was able to join the twelve cities of Ionia together into the Ionian League. During his reign the city began to prosper. He died in a battle against the Carians when he came to the aid of Priene, another city of the Ionian League. Androklos and his dog are depicted on the Hadrian temple frieze, dating from the 2nd century. Later, Greek historians such as Pausanias, Strabo and Herodotos and the poet Kallinos reassigned the city's mythological foundation to Ephos, queen of the Amazons.
The Greek goddess Artemis and the great Anatolian goddess Kybele were identified together as "Artemis of Ephesus". The many-breasted "Lady of Ephesus", identified with Artemis, was venerated in the Temple of Artemis, one of the Seven Wonders of the World and the largest building of the ancient world according to Pausanias (4.31.8). Pausanias mentions that the temple was built by Ephesus, son of the river god Caystrus, before the arrival of the Ionians. Of this structure, scarcely a trace remains.
Archaic period.
About 650 BC, Ephesus was attacked by the Cimmerians who razed the city, including the temple of Artemis. After the Cimmerians had been driven away, the city was ruled by a series of tyrants. Following a revolt by the people, Ephesus was ruled by a council. The city prospered again under a new rule, producing a number of important historical figures such as the elegiac poet Callinus and the iambic poet Hipponax, the philosopher Heraclitus, the great painter Parrhasius and later the grammarian Zenodotos and physicians Soranus and Rufus.
About 560 BC, Ephesus was conquered by the Lydians under king Croesus, who, though a harsh ruler, treated the inhabitants with respect and even became the main contributor to the reconstruction of the temple of Artemis. His signature has been found on the base of one of the columns of the temple (now on display in the British Museum). Croesus made the populations of the different settlements around Ephesus regroup ("synoikismos") in the vicinity of the Temple of Artemis, enlarging the city.
Later in the same century, the Lydians under Croesus invaded Persia. The Ionians refused a peace offer from Cyrus the Great, siding with the Lydians instead. After the Persians defeated Croesus, the Ionians offered to make peace, but Cyrus insisted that they surrender and become part of the empire. They were defeated by the Persian army commander Harpagos in 547 BC. The Persians then incorporated the Greek cities of Asia Minor into the Achaemenid Empire. Those cities were then ruled by satraps.
Ephesus has intrigued archaeologists because for the Archaic Period there is no definite location for the settlement. There are numerous sites to suggest the movement of a settlement between the Bronze Age and the Roman period, but the silting up of the natural harbours as well as the movement of the Kayster River meant that the location never remained the same.
Classical period.
Ephesus continued to prosper, but when taxes were raised under Cambyses II and Darius, the Ephesians participated in the Ionian Revolt against Persian rule in the Battle of Ephesus (498 BC), an event which instigated the Greco-Persian wars. In 479 BC, the Ionians, together with Athens, were able to oust the Persians from the shores of Asia Minor. In 478 BC, the Ionian cities with Athens entered into the Delian League against the Persians. Ephesus did not contribute ships but gave financial support.
During the Peloponnesian War, Ephesus was first allied to Athens but in a later phase, called the Decelean War, or the Ionian War, sided with Sparta, which also had received the support of the Persians. As a result, rule over the cities of Ionia was ceded again to Persia.
These wars did not greatly affect daily life in Ephesus. The Ephesians were surprisingly modern in their social relations: they allowed strangers to integrate; education was valued; through the cult of Artemis, the city became a bastion of women's rights – Ephesus even had female artists. In later times, Pliny the Elder mentioned having seen at Ephesus a representation of the goddess Diana by Timarata, the daughter of a painter.
In 356 BC the temple of Artemis was burnt down, according to legend, by a lunatic called Herostratus. The inhabitants of Ephesus at once set about restoring the temple and even planned a larger and grander one than the original.
Hellenistic period.
When Alexander the Great defeated the Persian forces at the Battle of Granicus in 334 BC, the Greek cities of Asia Minor were liberated. The pro-Persian tyrant Syrpax and his family were stoned to death, and Alexander was greeted warmly when he entered Ephesus in triumph. When Alexander saw that the temple of Artemis was not yet finished, he proposed to finance it and have his name inscribed on the front. But the inhabitants of Ephesus demurred, claiming that it was not fitting for one god to build a temple to another. After Alexander's death in 323 BC, Ephesus in 290 BC came under the rule of one of Alexander's generals, Lysimachus.
As the river Cayster (Grk. name Κάϋστρος) silted up the harbor, the resulting marshes caused malaria and many deaths among the inhabitants. The people of Ephesus were forced to move to a new settlement two kilometres () further on, when the king flooded the old city by blocking the sewers. This settlement was officially called Arsinoea ( or Ἀρσινοΐα) after the king's second wife, Arsinoe II of Egypt. After Lysimachus had destroyed the nearby cities of Lebedos and Colophon in 292 BC, he relocated their inhabitants to the new city.
Ephesus revolted after the treacherous death of Agathocles, giving the Hellenistic king of Syria and Mesopotamia Seleucus I Nicator an opportunity for removing and killing Lysimachus, his last rival, at the Battle of Corupedium in 281 BC. After the death of Lysimachus the town again was named Ephesus.
Thus Ephesus became part of the Seleucid Empire. After the murder of king Antiochus II Theos and his Egyptian wife, pharaoh Ptolemy III invaded the Seleucid Empire and the Egyptian fleet swept the coast of Asia Minor. Ephesus came under Egyptian rule between 263 and 197 BC.
When the Seleucid king Antiochus III the Great tried to regain the Greek cities of Asia Minor, he came into conflict with Rome. After a series of battles, he was defeated by Scipio Asiaticus at the Battle of Magnesia in 190 BC. As a result, Ephesus came under the rule of the Attalid king of Pergamon Eumenes II (197–133 BC). When his grandson Attalus III died without male children of his own, he left his kingdom to the Roman Republic.
Roman period.
Ephesus, a territory that was traditionally Greek to the core, became a subject of the Roman Republic. The city felt the Roman influence at once. Taxes rose considerably, and the treasures of the city were systematically plundered. In 88 BC Ephesus welcomed Archelaus, a general of Mithridates the Great, king of Pontus, when he conquered Asia (the Roman name for western Asia Minor). This led to the Asiatic Vespers, the slaughter of 80,000 Roman citizens in Asia, or any person who spoke with a Latin accent. Many had lived in Ephesus. But when they saw how badly the people of Chios had been treated by Zenobius, a general of Mithridates, they refused entry to his army. Zenobius was invited into the city to visit Philopoemen, the father of Monime, the favorite wife of Mithridates, and the overseer of Ephesus. As the people expected nothing good of him, they threw him into prison and murdered him. Mithridates took revenge and inflicted terrible punishments. However, the Greek cities were given freedom and several substantial rights. Ephesus became, for a short time, self-governing. When Mithridates was defeated in the First Mithridatic War by the Roman consul Lucius Cornelius Sulla, Ephesus came back under Roman rule in 86 BC. Sulla imposed a huge indemnity, along with five years of back taxes, which left Asian cities heavily in debt for a long time to come.
When Augustus became emperor in 27 BC, he made Ephesus the capital of proconsular Asia (which covered western Asia Minor) instead of Pergamum. Ephesus then entered an era of prosperity, becoming both the seat of the governor and a major center of commerce. According to Strabo, it was second in importance and size only to Rome.
Until recently the population of Ephesus in Roman times was estimated to number up to 225,000 people. More recent scholarship regards these estimates as unrealistic. Such a large estimate would require population densities only possible in modern times, or extensive settlement outside the city walls. This would have been impossible at Ephesus because of the mountain ranges, coastline and quarries which surrounded the city.
The wall of Lysimachus has been estimated to enclose an area of . Not all of this area was inhabited due to public buildings and spaces in the centre and the steep slope of the Bülbül Dağı mountain, which was enclosed by the wall. Jerome Murphy-O'Connor uses an estimate of for the inhabited land. Using an average population density of 400 to 500 per hectare, he calculates that Ephesus would have had a population between 138,000 and 172,500, with a preference for the higher figure. J. W. Hanson estimates the inhabited space to be smaller at . He argues that population densities of 150 or 250 people per hectare are more realistic, which gives a range of 33,600 to 56,000 inhabitants. Even with these much lower population estimates, Ephesus was one of the largest cities of Roman Asia Minor, ranking it as the largest city after Sardis and Alexandria Troas.
The city was famed for the Temple of Artemis (Diana), the Library of Celsus, and a theater which was capable of holding 25,000 spectators. This open-air theatre was used initially for drama, but during later Roman times gladiatorial combats were also held on its stage; the first archaeological evidence of a gladiator graveyard was found in May 2007. Ephesus also had several major bath complexes, built at various times while the city was under Roman rule. The city had one of the most advanced aqueduct systems in the ancient world, with multiple aqueducts of various sizes to supply different areas of the city, including four major aqueducts. They fed a number of water mills, one of which has been identified as a sawmill for marble.
The city and temple were destroyed by the Goths in 263 AD. This marked the decline of the city's splendour.
Byzantine era (395–1308).
The emperor Constantine I rebuilt much of the city and erected a new public bath. Ephesus remained the most important city of the Byzantine Empire in Asia after Constantinople in the 5th and 6th centuries. Emperor Flavius Arcadius raised the level of the street between the theatre and the harbour. The basilica of St. John was built during the reign of emperor Justinian I in the 6th century.
The city was partially destroyed by an earthquake in 614.
The importance of the city as a commercial centre declined as the harbour was slowly silted up by the river (today, Küçük Menderes) despite repeated dredging during the city's history. (Today, the harbour is 5 kilometres inland). The loss of its harbour caused Ephesus to lose its access to the Aegean Sea, which was important for trade. People started leaving the lowland of the city for the surrounding hills. The ruins of the temples were used as building blocks for new homes. Marble sculptures were ground to powder to make lime for plaster.
Sackings by the Arabs first in the year 654–655 by caliph Muawiyah I, and later in 700 and 716 hastened the decline further.
When the Seljuk Turks conquered Ephesus in 1090, it was a small village. The Byzantines resumed control in 1097 and changed the name of the town to Hagios Theologos. They kept control of the region until 1308. Crusaders passing through were surprised that there was only a small village, called Ayasalouk, where they had expected a bustling city with a large seaport. Even the temple of Artemis was completely forgotten by the local population. The Crusaders of the Second Crusade fought the Seljuks just outside the town in December 1147.
Ottoman era.
The town surrendered, on October 24, 1304, to Sasa Bey, a Turkish warlord of the Menteşoğulları principality. Nevertheless, contrary to the terms of the surrender the Turks pillaged the church of Saint John and deported most of the local population to Thyrea, Greece when a revolt seemed probable. During these events many of the remaining inhabitants were massacred.
Shortly afterwards, Ephesus was ceded to the Aydinid principality that stationed a powerful navy in the harbour of Ayasuluğ (the present-day Selçuk, next to Ephesus). Ayasoluk became an important harbour, from which the navy organised raids to the surrounding regions.
The town knew again a short period of prosperity during the 14th century under these new Seljuk rulers. They added important architectural works such as the İsa Bey Mosque, caravansaries and Turkish bathhouses (hamam).
Ephesians were incorporated as vassals into the Ottoman Empire for the first time in 1390. The Central Asian warlord Tamerlane defeated the Ottomans in Anatolia in 1402, and the Ottoman sultan Bayezid I died in captivity. The region was restored to the Anatolian beyliks. After a period of unrest, the region was again incorporated into the Ottoman Empire in 1425.
Ephesus was completely abandoned by the 15th century. Nearby Ayasuluğ was renamed Selçuk in 1914.
Ephesus and Christianity.
Ephesus was an important centre for Early Christianity from the AD 50s. From AD 52–54, the apostle Paul lived in Ephesus, working with the congregation and apparently organizing missionary activity into the hinterlands. Initially, according to the Acts of the Apostles, Paul attended the Jewish synagogue in Ephesus, but after three months he became frustrated with the stubbornness or hardness of heart of some of the Jews, and moved his base to the school of Tyrannus (). The Jamieson-Fausset-Brown Bible Commentary reminds readers that the unbelief of "some" () implies that "others, probably a large number, believed" and therefore there must have been a community of Jewish Christians in Ephesus. Paul introduced about twelve men to the 'baptism with the Holy Spirit' who had previously only experienced the baptism of John the Baptist (), and later became embroiled in a dispute with some artisans whose livelihood depended on selling statuettes of Artemis () in the Temple of Artemis (). Between 53 and 57 AD Paul wrote the letter 1 Corinthians from Ephesus (possibly from the 'Paul tower' near the harbour, where he was imprisoned for a short time). Later, Paul wrote the Epistle to the Ephesians while he was in prison in Rome (around 62 AD).
Roman Asia was associated with John, one of the chief apostles, and the Gospel of John might have been written in Ephesus, "c" 90–100. Ephesus was one of the seven cities addressed in the Book of Revelation (), indicating that the church at Ephesus was strong.
Two decades later, the church at Ephesus was still important enough to be addressed by a letter written by Bishop Ignatius of Antioch to the Ephesians in the early 2nd century AD, that begins with, "Ignatius, who is also called Theophorus, to the Church which is at Ephesus, in Asia, deservedly most happy, being blessed in the greatness and fullness of God the Father, and predestinated before the beginning of time, that it should be always for an enduring and unchangeable glory" ("Letter to the Ephesians"). The church at Ephesus had given their support for Ignatius, who was taken to Rome for execution.
A legend, which was first mentioned by Epiphanius of Salamis in the 4th century AD, purported that Mary may have spent the last years of her life in Ephesus. The Ephesians derived the argument from John's presence in the city, and Jesus’ instructions to John to take care of Mary after his death. Epiphanius, however, was keen to point out that, while the Bible says John was leaving for Asia, it does not say specifically that Mary went with him. He later stated that she was buried in Jerusalem. Since the 19th century, The House of the Virgin Mary, about from Selçuk, has been considered to have been the last home of Mary, mother of Jesus in the Roman Catholic tradition, based on the visions of Sister Anne Catherine Emmerich. It is a popular place of Catholic pilgrimage which has been visited by three recent popes.
The Church of Mary near the harbour of Ephesus was the setting for the Third Ecumenical Council in 431, which resulted in the condemnation of Nestorius. A Second Council of Ephesus was held in 449, but its controversial acts were never approved by the Catholics. It came to be called the Robber Council of Ephesus or Robber Synod of Latrocinium by its opponents.
Main sites.
Ephesus contains the largest collection of Roman ruins in the eastern Mediterranean. Only an estimated 15% has been excavated. The ruins that are visible give some idea of the city's original splendour, and the names associated with the ruins are evocative of its former life. The theatre dominates the view down Harbour Street, which leads to the silted-up harbour.
The Library of Celsus, the façade of which has been carefully reconstructed from all original pieces, was originally built c. 125 AD in memory of Tiberius Julius Celsus Polemaeanus, an Ancient Greek who served as governor of Roman Asia (105–107) in the Roman Empire. Celsus paid for the construction of the library with his own personal wealth and is buried in a sarcophagus beneath it. The library was mostly built by his son Gaius Julius Aquila and once held nearly 12,000 scrolls. Designed with an exaggerated entrance — so as to enhance its perceived size, speculate many historians — the building faces east so that the reading rooms could make best use of the morning light.
A part of the site, Basilica of St. John, was built in the 6th century AD, under emperor Justinian I, over the supposed site of the apostle's tomb. It is now surrounded by Selçuk.
The Temple of Artemis, one of the Seven Wonders of the Ancient World, once stood 418' by 239' with over 100 marble pillars each 56' high. The temple earned the city the title "Servant of the Goddess". Pliny tells us that the magnificent structure took 120 years to build but is now represented only by one inconspicuous column, revealed during an archaeological excavation by the British Museum in the 1870s. Some fragments of the frieze (which are insufficient to suggest the form of the original) and other small finds were removed – some to London and some to the Archaeological Museum, Istanbul.
The Odeon was a small roofed theater constructed by Vedius Antonius and his wife around 150 AD. It was a small salon for plays and concerts, seating about 1,500 people. There were 22 stairs in the theatre. The upper part of the theatre was decorated with red granite pillars in the Corinthian style. The entrances were at both sides of the stage and reached by a few steps.
The Temple of Hadrian dates from the 2nd century but underwent repairs in the 4th century and has been reerected from the surviving architectural fragments. The reliefs in the upper sections are casts, the originals now being exhibited in the Ephesus Archaeological Museum. A number of figures are depicted in the reliefs, including the emperor Theodosius I with his wife and eldest son. The temple was depicted on the reverse of the Turkish 20 million lira banknote of 2001–2005 and of the 20 new lira banknote of 2005–2009.Announcement on the Withdrawal of E8 New Turkish Lira Banknotes from Circulation, 8 May 2007. – Retrieved on 20 April 2009.</ref>
The Temple of the Sebastoi (sometimes called the Temple of Domitian), dedicated to the Flavian dynasty, was one of the largest temples in the city. It was erected on a pseudodipteral plan with 8 × 13 columns. The temple and its statue are some of the few remains connected with Domitian.
At an estimated 24,000 seating capacity, the 'Theatre' is believed to be the largest outdoor theatre in the ancient world.
The Tomb/Fountain of Pollio was erected in 97 AD in honour of C. Sextilius Pollio, who constructed the Marnas aqueduct, by Offilius Proculus. It has a concave façade.
There were two agoras, one for commercial and one for state business.
Seven sleepers.
Ephesus is believed to be the city of the Seven Sleepers. The story of the Seven Sleepers, who are considered saints by Catholics and Orthodox Christians and whose story is also mentioned in the Qur'an, tells that they were persecuted because of their belief in God and that they slept in a cave near Ephesus for centuries.
Archaeology.
The history of archaeological research in Ephesus stretches back to 1863, when British architect John Turtle Wood, sponsored by the British Museum, began to search for the Artemision. In 1869 he discovered the pavement of the temple, but since further expected discoveries were not made the excavations stopped in 1874. In 1895 German archaeologist Otto Benndorf, financed by a 10,000 guilder donation made by Austrian Karl Mautner Ritter von Markhof, resumed excavations. In 1898 Benndorf founded the Austrian Archaeological Institute, which plays a leading role in Ephesus today.
Finds from the site are exhibited notably in the Ephesos Museum in Vienna, the Ephesus Archaeological Museum in Selçuk and in the British Museum.

</doc>
<doc id="9845" url="https://en.wikipedia.org/wiki?curid=9845" title="JavaScript">
JavaScript

JavaScript () is a high-level, dynamic, untyped, and interpreted programming language. It has been standardized in the ECMAScript language specification. Alongside HTML and CSS, it is one of the three core technologies of World Wide Web content production; the majority of websites employ it and it is supported by all modern Web browsers without plug-ins. JavaScript is prototype-based with first-class functions, making it a multi-paradigm language, supporting object-oriented, imperative, and functional programming styles. It has an API for working with text, arrays, dates and regular expressions, but does not include any I/O, such as networking, storage, or graphics facilities, relying for these upon the host environment in which it is embedded.
Despite some naming, syntactic, and standard library similarities, JavaScript and Java are otherwise unrelated and have very different semantics. The syntax of JavaScript is actually derived from C, while the semantics and design are influenced by the Self and Scheme programming languages.
JavaScript is also used in environments that are not Web-based, such as PDF documents, site-specific browsers, and desktop widgets. Newer and faster JavaScript virtual machines (VMs) and platforms built upon them have also increased the popularity of JavaScript for server-side Web applications. On the client side, JavaScript has been traditionally implemented as an interpreted language, but more recent browsers perform just-in-time compilation. It is also used in game development, the creation of desktop and mobile applications, and server-side network programming with runtime environments such as Node.js.
History.
Beginnings at Netscape.
JavaScript was originally developed in 10 days in May 1995 by Brendan Eich, while he was working for Netscape Communications Corporation. Indeed, while competing with Microsoft for user adoption of Web technologies and platforms, Netscape considered their client-server offering a distributed OS with a portable version of Sun Microsystems's Java providing an environment in which applets could be run. Because Java was a competitor of C++ and aimed at professional programmers, Netscape also wanted a lightweight interpreted language that would complement Java by appealing to nonprofessional programmers, like Microsoft's Visual Basic (see JavaScript and Java).
Although it was developed under the name Mocha, the language was officially called LiveScript when it first shipped in beta releases of Netscape Navigator 2.0 in September 1995, but it was renamed JavaScript when it was deployed in the Netscape browser version 2.0B3.
The change of name from LiveScript to JavaScript roughly coincided with Netscape adding support for Java technology in its Netscape Navigator Web browser. The final choice of name caused confusion, giving the impression that the language was a spin-off of the Java programming language, and the choice has been characterized as a marketing ploy by Netscape to give JavaScript the cachet of what was then the hot new Web programming language.
There is a common misconception that the JavaScript language was influenced by an earlier Web page scripting language developed by Nombas named C-- (not to be confused with the later C-- created in 1997). Brendan Eich, however, had never heard of C-- before he created LiveScript. Nombas did pitch their embedded Web page scripting to Netscape, though Web page scripting was not a new concept, as shown by ViolaWWW. Nombas later switched to offering JavaScript instead of C-- in their ScriptEase product and was part of the TC39 group that standardized ECMAScript.
Server-side JavaScript.
Netscape introduced an implementation of the language for server-side scripting with Netscape Enterprise Server in December, 1995, soon after releasing JavaScript for browsers.
Since the mid-2000s, there has been a resurgence of server-side JavaScript implementations, such as Node.js.
Adoption by Microsoft.
Microsoft Windows script technologies including VBScript and JScript were released in 1996. JScript, a reverse-engineered implementation of Netscape's JavaScript, was released on July 16, 1996 and was part of Internet Explorer 3, as well as being available server-side in Internet Information Server. IE3 also included Microsoft's first support for Cascading Style Sheets and various extensions to HTML, but in each case the implementation was noticeably different to that found in Netscape Navigator at the time. These differences made it difficult for designers and programmers to make a single website work well in both browsers leading to the use of 'best viewed in Netscape' and 'best viewed in Internet Explorer' logos that characterised these early years of the browser wars. JavaScript began to acquire a reputation for being one of the roadblocks to a cross-platform and standards-driven Web. Some developers took on the difficult task of trying to make their sites work in both major browsers, but many could not afford the time. With the release of Internet Explorer 4, Microsoft introduced the concept of Dynamic HTML, but the differences in language implementations and the different and proprietary Document Object Models remained, and were obstacles to widespread take-up of JavaScript on the Web.
Standardization.
In November 1996, Netscape announced that it had submitted JavaScript to Ecma International for consideration as an industry standard, and subsequent work resulted in the standardized version named ECMAScript. In June 1997, Ecma International published the first edition of the ECMA-262 specification. In June 1998, some modifications were made to adapt it to the ISO/IEC-16262 standard, and the second edition was released. The third edition of ECMA-262 was published on December 1999.
Development of the fourth edition of the ECMAScript standard was never completed. The fifth edition was released in December 2009. The current edition of the ECMAScript standard is 6, released in June 2015.
Later developments.
JavaScript has become one of the most popular programming languages on the Web. Initially, however, many professional programmers denigrated the language because its target audience consisted of Web authors and other such "amateurs", among other reasons. The advent of Ajax returned JavaScript to the spotlight and brought more professional programming attention. The result was a proliferation of comprehensive frameworks and libraries, improved JavaScript programming practices, and increased usage of JavaScript outside Web browsers, as seen by the proliferation of server-side JavaScript platforms.
In January 2009, the CommonJS project was founded with the goal of specifying a common standard library mainly for JavaScript development outside the browser.
With the rise of the single-page application and JavaScript-heavy sites, it is increasingly being used as a compile target for source-to-source compilers from both dynamic languages and static languages. In particular, Emscripten and highly optimized JIT compilers, in tandem with asm.js that is friendly to ahead-of-time compilers (AOT) like OdinMonkey, have enabled C and C++ programs to be compiled into JavaScript and execute at near-native speeds, causing JavaScript to be considered the "assembly language of the Web", according to its creator and others.
Trademark.
"JavaScript" is a trademark of Oracle Corporation. It is used under license for technology invented and implemented by Netscape Communications and current entities such as the Mozilla Foundation.
Features.
The following features are common to all conforming ECMAScript implementations, unless explicitly specified otherwise.
Imperative and structured.
JavaScript supports much of the structured programming syntax from C (e.g., if statements, while loops, switch statements, do while loops, etc.). One partial exception is scoping: JavaScript originally had only function scoping with var. ECMAScript 2015 adds a let keyword for block scoping, meaning JavaScript now has both function and block scoping. Like C, JavaScript makes a distinction between expressions and statements. One syntactic difference from C is automatic semicolon insertion, which allows the semicolons that would normally terminate statements to be omitted.
Prototype-based (Object-oriented).
JavaScript is almost entirely object-based. In JavaScript, an object is an associative array, augmented with a prototype (see below); each string key provides the name for an object property, and there are two syntactical ways to specify such a name: dot notation (obj.x = 10) and bracket notation (obj['x'] = 10). A property may be added, rebound, or deleted at run-time. Most properties of an object (and any property that belongs to an object's prototype inheritance chain) can be enumerated using a for...in loop.
JavaScript has a small number of built-in objects, including and .
Functional.
A function is first-class; a function is considered to be an object. As such, a function may have properties and methods, such as .call() and .bind(). A "nested" function is a function defined within another function. It is created each time the outer function is invoked. In addition, each nested function forms a lexical closure: The lexical scope of the outer function (including any constant, local variable, or argument value) becomes part of the internal state of each inner function object, even after execution of the outer function concludes. JavaScript also supports anonymous functions.
Delegative.
JavaScript supports implicit and explicit delegation.
Vendor-specific extensions.
JavaScript is officially managed by Mozilla Foundation, and new language features are added periodically. However, only some JavaScript engines support these new features:
Syntax.
Simple examples.
Variables in JavaScript can be defined using the var keyword:
<syntaxhighlight lang="javascript">
var x; // defines the variable x, the special value “undefined” (not to be confused with an undefined value) is assigned to it by default
var y = 2; // defines the variable y and assigns the value of 2 to it
</syntaxhighlight>
Note the comments in the example above, both of which were preceded with two forward slashes.
There is no built-in I/O functionality in JavaScript; the run-time environment provides that. The ECMAScript specification in edition 5.1 mentions:
… indeed, there are no provisions in this specification for input of external data or output of computed results.
However, most runtime environments have a console object that can be used to print output. Here is a minimalist Hello World program:
<syntaxhighlight lang="javascript">
console.log("Hello World!");
</syntaxhighlight>
A simple recursive function:
<syntaxhighlight lang="javascript">
function factorial(n) {
</syntaxhighlight>
Anonymous function (or lambda) syntax and closure example:
<syntaxhighlight lang="javascript">
var displayClosure = function() {
var inc = displayClosure();
inc(); // returns 1
inc(); // returns 2
inc(); // returns 3
</syntaxhighlight>
Variadic function demonstration (arguments is a special variable).
<syntaxhighlight lang="javascript">
var sum = function() {
sum(1, 2, 3); // returns 6
</syntaxhighlight>
Immediately-invoked function expressions allow functions to pass around variables under their own closures.
<syntaxhighlight lang="JavaScript">
var v;
v = 1;
var getValue = (function(v) {
})(v);
v = 2;
getValue(); // 1
</syntaxhighlight>
More advanced example.
This sample code displays various JavaScript features.
<syntaxhighlight lang="javascript">
/* Finds the lowest common multiple (LCM) of two numbers */
function LCMCalculator(x, y) { // constructor function
// The prototype of object instances created by a constructor is
// that constructor's "prototype" property.
LCMCalculator.prototype = { // object literal
The following output should be displayed in the browser window.
<syntaxhighlight lang="html4strict">
LCMCalculator: a = 28, b = 56, gcd = 28, lcm = 56
LCMCalculator: a = 21, b = 56, gcd = 7, lcm = 168
LCMCalculator: a = 25, b = 55, gcd = 5, lcm = 275
LCMCalculator: a = 22, b = 58, gcd = 2, lcm = 638
</syntaxhighlight>
Use in Web pages.
The most common use of JavaScript is to add client-side behavior to HTML pages, a.k.a. Dynamic HTML (DHTML). Scripts are embedded in or included from HTML pages and interact with the Document Object Model (DOM) of the page. Some simple examples of this usage are:
Because JavaScript code can run locally in a user's browser (rather than on a remote server), the browser can respond to user actions quickly, making an application more responsive. Furthermore, JavaScript code can detect user actions that HTML alone cannot, such as individual keystrokes. Applications such as Gmail take advantage of this: much of the user-interface logic is written in JavaScript, and JavaScript dispatches requests for information (such as the content of an e-mail message) to the server. The wider trend of Ajax programming similarly exploits this strength.
A JavaScript engine (also known as "JavaScript interpreter" or "JavaScript implementation") is an interpreter that interprets JavaScript source code and executes the script accordingly. The first JavaScript engine was created by Brendan Eich at Netscape Communications Corporation, for the Netscape Navigator Web browser. The engine, code-named SpiderMonkey, is implemented in C. It has since been updated (in JavaScript 1.5) to conform to ECMA-262 Edition 3. The Rhino engine, created primarily by Norris Boyd (formerly of Netscape; now at Google) is a JavaScript implementation in Java. Rhino, like SpiderMonkey, is ECMA-262 Edition 3 compliant.
A Web browser is by far the most common host environment for JavaScript. Web browsers typically create "host objects" to represent the Document Object Model (DOM) in JavaScript. The Web server is another common host environment. A JavaScript Web server would typically expose host objects representing HTTP request and response objects, which a JavaScript program could then interrogate and manipulate to dynamically generate Web pages.
Because JavaScript is the only language that the most popular browsers share support for, it has become a target language for many frameworks in other languages, even though JavaScript was never intended to be such a language. Despite the performance limitations inherent to its dynamic nature, the increasing speed of JavaScript engines has made the language a surprisingly feasible compilation target.
Example script.
Below is a minimal example of a standards-conforming Web page containing JavaScript (using HTML 5 syntax) and the DOM:
<syntaxhighlight lang="html5">
<!DOCTYPE html>
<html>
<meta charset="utf-8">
<title>Minimal Example</title>
<body>
This is JavaScript
<script>
</script>
<noscript>Your browser either does not support JavaScript, or has it turned off.</noscript>
</body>
</html>
</syntaxhighlight>
Compatibility considerations.
Because JavaScript runs in widely varying environments, an important part of testing and debugging is to test and verify that the JavaScript works across multiple browsers.
The DOM interfaces for manipulating Web pages are not part of the ECMAScript standard, or of JavaScript itself. Officially, the DOM interfaces are defined by a separate standardization effort by the W3C; in practice, browser implementations differ from the standards and from each other, and not all browsers execute JavaScript.
To deal with these differences, JavaScript authors can attempt to write standards-compliant code that will also be executed correctly by most browsers; failing that, they can write code that checks for the presence of certain browser features and behaves differently if they are not available. In some cases, two browsers may both implement a feature but with different behavior, and authors may find it practical to detect what browser is running and change their script's behavior to match. Programmers may also use libraries or toolkits that take browser differences into account.
Furthermore, scripts may not work for some users. For example, a user may:
To support these users, Web authors can try to create pages that degrade gracefully on user agents (browsers) that do not support the page's JavaScript. In particular, the page should remain usable albeit without the extra features that the JavaScript would have added. An alternative approach that many find preferable is to first author content using basic technologies that work in all browsers, then enhance the content for users that have JavaScript enabled. This is known as progressive enhancement.
Security.
JavaScript and the DOM provide the potential for malicious authors to deliver scripts to run on a client computer via the Web. Browser authors contain this risk using two restrictions. First, scripts run in a sandbox in which they can only perform Web-related actions, not general-purpose programming tasks like creating files. Second, scripts are constrained by the same origin policy: scripts from one Web site do not have access to information such as usernames, passwords, or cookies sent to another site. Most JavaScript-related security bugs are breaches of either the same origin policy or the sandbox.
There are subsets of general JavaScript — ADsafe, Secure ECMA Script (SES) — that provide greater level of security, especially on code created by third parties (such as advertisements). Caja is another project for safe embedding and isolation of third-party JavaScript and HTML.
Content Security Policy is the main intended method of ensuring that only trusted code is executed on a Web page.
Cross-site vulnerabilities.
A common JavaScript-related security problem is cross-site scripting, or XSS, a violation of the same-origin policy. XSS vulnerabilities occur when an attacker is able to cause a target Web site, such as an online banking website, to include a malicious script in the webpage presented to a victim. The script in this example can then access the banking application with the privileges of the victim, potentially disclosing secret information or transferring money without the victim's authorization. A solution to XSS vulnerabilities is to use "HTML escaping" whenever displaying untrusted data.
Some browsers include partial protection against "reflected" XSS attacks, in which the attacker provides a URL including malicious script. However, even users of those browsers are vulnerable to other XSS attacks, such as those where the malicious code is stored in a database. Only correct design of Web applications on the server side can fully prevent XSS.
XSS vulnerabilities can also occur because of implementation mistakes by browser authors.
Another cross-site vulnerability is cross-site request forgery or CSRF. In CSRF, code on an attacker's site tricks the victim's browser into taking actions the user didn't intend at a target site (like transferring money at a bank). It works because, if the target site relies only on cookies to authenticate requests, then requests initiated by code on the attacker's site will carry the same legitimate login credentials as requests initiated by the user. In general, the solution to CSRF is to require an authentication value in a hidden form field, and not only in the cookies, to authenticate any request that might have lasting effects. Checking the HTTP Referrer header can also help.
"JavaScript hijacking" is a type of CSRF attack in which a <script> tag on an attacker's site exploits a page on the victim's site that returns private information such as JSON or JavaScript. Possible solutions include:
Misplaced trust in the client.
Developers of client-server applications must recognize that untrusted clients may be under the control of attackers. The application author cannot assume that his JavaScript code will run as intended (or at all) because any secret embedded in the code could be extracted by a determined adversary. Some implications are:
Browser and plugin coding errors.
JavaScript provides an interface to a wide range of browser capabilities, some of which may have flaws such as buffer overflows. These flaws can allow attackers to write scripts that would run any code they wish on the user's system. This code is not by any means limited to another JavaScript application. For example, a buffer overrun exploit can allow an attacker to gain access to the operating system's API with superuser privileges.
These flaws have affected major browsers including Firefox, Internet Explorer, and Safari.
Plugins, such as video players, Adobe Flash, and the wide range of ActiveX controls enabled by default in Microsoft Internet Explorer, may also have flaws exploitable via JavaScript (such flaws have been exploited in the past).
In Windows Vista, Microsoft has attempted to contain the risks of bugs such as buffer overflows by running the Internet Explorer process with limited privileges. Google Chrome similarly confines its page renderers to their own "sandbox".
Sandbox implementation errors.
Web browsers are capable of running JavaScript outside the sandbox, with the privileges necessary to, for example, create or delete files. Of course, such privileges aren't meant to be granted to code from the Web.
Incorrectly granting privileges to JavaScript from the Web has played a role in vulnerabilities in both Internet Explorer and Firefox. In Windows XP Service Pack 2, Microsoft demoted JScript's privileges in Internet Explorer.
Microsoft Windows allows JavaScript source files on a computer's hard drive to be launched as general-purpose, non-sandboxed programs (see: Windows Script Host). This makes JavaScript (like VBScript) a theoretically viable vector for a Trojan horse, although JavaScript Trojan horses are uncommon in practice.
Uses outside Web pages.
In addition to Web browsers and servers, JavaScript interpreters are embedded in a number of tools. Each of these applications provides its own object model that provides access to the host environment. The core JavaScript language remains mostly the same in each application.
Development tools.
Within JavaScript, access to a debugger becomes invaluable when developing large, non-trivial programs. Because there can be implementation differences between the various browsers (particularly within the Document Object Model), it is useful to have access to a debugger for each of the browsers that a Web application targets.
Script debuggers are integrated within Internet Explorer, Firefox, Safari, Google Chrome, Opera and Node.js
In addition to the native Internet Explorer Developer Tools, three debuggers are available for Internet Explorer: Microsoft Visual Studio is the richest of the three, closely followed by Microsoft Script Editor (a component of Microsoft Office), and finally the free Microsoft Script Debugger that is far more basic than the other two. The free Microsoft Visual Web Developer Express provides a limited version of the JavaScript debugging functionality in Microsoft Visual Studio. Internet Explorer has included developer tools since version 8 (reached by pressing the F12 key).
In comparison to Internet Explorer, Firefox has a more comprehensive set of developer tools, which include a debugger as well. Old versions of Firefox without these tools used a Firefox addon called Firebug, or the older Venkman debugger. Also, WebKit's Web Inspector includes a JavaScript debugger, which is used in Safari. A modified version called Blink DevTools is used in Google Chrome. Node.js has node-inspector, an interactive debugger that integrates with the Blink DevTools, available in Google Chrome. Last but not least, Opera includes a set of tools called Dragonfly.
In addition to the native computer software, there are "online JavaScript IDEs", debugging aids are themselves written in JavaScript and built to run on the Web. An example is the program JSLint, developed by Douglas Crockford who has written extensively on the language. JSLint scans JavaScript code for conformance to a set of standards and guidelines. Many libraries for JavaScript, such as three.js, provide links to demonstration code that can be edited by users. They are also used as a pedagogical tool by institutions such as Khan Academy to allow students to experience writing code in an environment where they can see the output of their programs, without needing any setup beyond a Web browser.
Version history.
JavaScript was initially developed in 1996 for use in the Netscape Navigator browser. In the same year Microsoft released an implementation for Internet Explorer. This implementation was called JScript due to trademark issues. In 1997 the first standardized version of the language was released under the name ECMAScript.
The following table is based on information from multiple sources.
Related languages and features.
JSON, or JavaScript Object Notation, is a general-purpose data interchange format that is defined as a subset of JavaScript's object literal syntax. Like much of JavaScript (regexps and anonymous functions as 1st class elements, closures, flexible classes, 'use strict'), JSON, except for replacing Perl's key-value operator '=>' by an RFC 822 inspired ':', is syntactically pure Perl.
jQuery is a popular JavaScript library designed to simplify DOM-oriented client-side HTML scripting along with offering cross-browser compatibility because various browsers respond differently to certain vanilla JavaScript code.
Underscore.js is a utility JavaScript library for data manipulation that is used in both client-side and server-side network applications.
Mozilla browsers currently support LiveConnect, a feature that allows JavaScript and Java to intercommunicate on the Web. However, Mozilla-specific support for LiveConnect is scheduled to be phased out in the future in favor of passing on the LiveConnect handling via NPAPI to the Java 1.6+ plug-in (not yet supported on the Mac ). Most browser inspection tools, such as Firebug in Firefox, include JavaScript interpreters that can act on the visible page's DOM.
asm.js is a subset of JavaScript that can be run in any JavaScript engine or run faster in an ahead-of-time (AOT) compiling engine.
JSFuck is an esoteric programming language. Programs are written using only six different characters, but are still valid JavaScript code.
p5.js is an object oriented JavaScript library designed for artists and designers. It is based on the ideas of the Processing project but is for the web. 
Use as an intermediate language.
As JavaScript is the most widely supported client-side language that can run within a Web browser, it has become an intermediate language for other languages to target. This has included both newly created languages and ports of existing languages.
Some of these include:
As JavaScript has unusual limitations – such as no separate integer type, using floating point – languages that compile to JavaScript commonly have slightly different behavior than in other environments.
JavaScript and Java.
A common misconception is that JavaScript is similar or closely related to Java. It is true that both have a C-like syntax (the C language being their most immediate common ancestor language). They also are both typically sandboxed (when used inside a browser), and JavaScript was designed with Java's syntax and standard library in mind. In particular, all Java keywords were reserved in original JavaScript, JavaScript's standard library follows Java's naming conventions, and JavaScript's Math and Date objects are based on classes from Java 1.0, but the similarities end there.
The differences between the two languages are more prominent than their similarities. Java has static typing, while JavaScript's typing is dynamic. Java is loaded from compiled bytecode, while JavaScript is loaded as human-readable source code. Java's objects are class-based, while JavaScript's are prototype-based. Finally, Java did not support functional programming until Java 8, while JavaScript has done so from the beginning, being influenced by Scheme.

</doc>
<doc id="9846" url="https://en.wikipedia.org/wiki?curid=9846" title="Elbing (disambiguation)">
Elbing (disambiguation)

Elbing is the German name of Elbląg, a city in northern Poland which until 1945 was a German city in the province of East Prussia.
Elbing may also refer to:

</doc>
<doc id="9855" url="https://en.wikipedia.org/wiki?curid=9855" title="Exile">
Exile

Exile means to be away from one's home (i.e. city, state or country), while either being explicitly refused permission to return and/or being threatened with imprisonment or death upon return. It can be a form of punishment and solitude.
It is common to distinguish between internal exile, i.e., forced resettlement within the country of residence, and external exile, deportation outside the country of residence. Although most commonly used to describe an individual situation, the term is also used for groups (especially ethnic or national groups), or for an entire government. Terms such as diaspora and refugee describe group exile, both voluntary and forced, and government in exile describes a government of a country that has been forced to relocate and argue its legitimacy from outside that country.
Exile can also be a self-imposed departure from one's homeland. Self-exile is often depicted as a form of protest by the person that claims it, to avoid persecution or legal matters (such as tax or criminal allegations), an act of shame or repentance, or isolating oneself to be able to devote time to a particular pursuit.
Article 9 of the Universal Declaration of Human Rights states that "No one shall be subjected to arbitrary arrest, detention or exile."
For individuals.
Exiled heads of state.
In some cases the deposed head of state is allowed to go into exile following a coup or other change of government, allowing a more peaceful transition to take place or to escape justice. Examples include:
Exile of a prophet.
Baha'u'llah, the Messenger or Manifestation of the Baha'i Faith, was exiled from His homeland in Tehran to Baghdad in 1853. Also, after a stay in the region of Iraq He was banished to Constantinople in 1863 for fear of His growing influence in the region. Moreover, He was banished again to Adrianople in December 1863 and finally exiled to Akka in the present day Israel in 1868.
Avoiding tax or legal matters.
A wealthy citizen who departs from a former abode for a lower tax jurisdiction (a "tax haven") in order to reduce his/her tax burden is termed a "tax exile". Creative people such as authors and musicians who achieve sudden wealth sometimes find themselves among this group. Examples include the British-Canadian writer Arthur Hailey, who moved to the Bahamas to avoid taxes following the runaway success of his novels "Hotel" and "Airport", and the English rock band the Rolling Stones who, in the spring of 1971 owed more in taxes than they could pay and left Britain before the government could seize their assets. Members of the band all moved to France for a period of time where they recorded music for the album that came to be called "Exile on Main Street", the Main Street of the title referring the French Riviera. In 2012, Eduardo Saverin, one of the founders of Facebook, made headlines by renouncing his U.S. Citizenship before his company's IPO. The dual Brazilian/U.S. citizen's decision to move to Singapore and renounce his citizenship spurred a bill in the U.S. Senate, the Ex-PATRIOT Act, which would have forced such wealthy "tax exiles" to pay a special tax in order to re-enter the United States.
In some cases a person voluntarily lives in exile to avoid legal issues, such as litigation or criminal prosecution. An example of this was Asil Nadir, who fled to the Turkish Republic of Northern Cyprus for 17 years rather than face prosecution in connection with the failed £1.7 bn company Polly Peck in the United Kingdom.
Avoiding violence or persecution, or in the aftermath of war.
Examples include:
For groups, nations and governments.
Nation in exile.
When large groups, or occasionally a whole people or nation is exiled, it can be said that this nation is in "exile", or Diaspora. Nations that have been in exile for substantial periods include the Jews, who were deported by Babylonian king Nebuchadnezzar II in 586 BCE and again following the destruction of the second Temple in Jerusalem in the year 70 CE. Many Jewish prayers include a yearning to return to Jerusalem and the Jewish homeland.
After the partitions of Poland in the late 18th century, and following the uprisings (like Kościuszko Uprising, November Uprising and January Uprising) against the partitioning powers (Russian Empire, Prussia and Austro-Hungary), many Poles have chosen – or been forced – to go into exile, forming large diasporas (known as Polonia), especially in France and the United States. The entire population of Crimean Tatars (200,000) that remained in their homeland Crimea was exiled on 18 May 1944 to Central Asia as a form of ethnic cleansing and collective punishment on false accusations. At Diego Garcia, between 1967 and 1973 the British Government forcibly removed some 2,000 Chagossian resident islanders to make way for a military base today jointly operated by the US and UK.
Since the Cuban Revolution over one million Cubans have left Cuba. Most of these self-identify as exiles as their motivation for leaving the island is political in nature. It is to be noted that at the time of the Cuban Revolution, Cuba only had a population of 6.5 million, and was not a country that had a history of significant emigration, it being the sixth largest recipient of immigrants in the world as of 1958. Most of the exiles' children also consider themselves to be Cuban exiles. It is to be noted that under Cuban law, children of Cubans born abroad are considered Cuban Citizens.
Government in exile.
During a foreign occupation or after a coup d'état, a "government in exile" of a such afflicted country may be established abroad. One of the most well-known instances of this is the Polish government-in-exile, a government in exile that commanded Polish armed forces operating outside Poland after German occupation during World War II. Other examples include the Free French Forces government of Charles De Gaulle of the same time, and the Central Tibetan Administration, commonly known as the Tibetan government-in-exile, and headed by the 14th Dalai Lama.
Exile in drama, literature, movie, and the arts.
Drama.
Exile is an early motif in ancient Greek tragedy: To wander away from the city-state (the home) is to be exposed without the protection of government (laws), friends and family. In the ancient Greek world, this was seen as a fate worse than death. The motif reaches its peak on the play Medea, originally written by Euripides around the time of Hesiod, and rooting in the very old oral traditions of Greek mythology. Euripedes’ Medea has remained the most frequently performed Greek tragedy through the 20th century.
Art.
After Medea was abandoned by Jason and had become a murderess out of revenge, she fled to Athens and married king Aigeus there, and became the stepmother of the hero Theseus. Due to a conflict with him, she must leave the Polis and go away into exile. John William Waterhouse (1849–1917), the English Pre-Raphaelite painter’s famous picture "Jason and Medea" shows a key moment before, when Medea tries to poison Theseus.
Literature.
In ancient Rome, the Roman Senate had have the power to declare the exile to individuals, families or even entire regions. One of the Roman victims was the poet Ovid, who lived during the reign of Augustus. He was forced to leave Rome and move away to the city of Tomis on the Black Sea, now Constanta. There he wrote his famous work "Tristia" (Sorrows) about his bitter feelings in exile.
Another, at least in a temporary exile, was Dante.
The German language writer of novels, Franz Kafka, called "the Dante of the twentieth century" by the poet W. H. Auden, describes the exile of Karl Rossmann in the posthumously published novel "Amerika".
During the period of National Socialism in the first few years after 1933 many Jews, as well as a significant part of German artists and intellectuals fled into exile, such as the authors Klaus Mann and Anna Seghers. So Germany’s own exile literature emerged and received worldwide credit.Klaus Mann finished his novel "Der Vulkan" ("The Volcano. A Novel Among Emigrants") in 1939, describing the German exile scene, "to bring the rich, scattered and murky experience of exile into epic form ",as he wrote in his literary balance sheet. At the same place and in the same year, Anna Seghers published her famous novel "Das siebte Kreuz" ("The Seventh Cross", published in the United States in 1942). Her painful story was produced as a movie in 1944 by MGM starring Spencer Tracy. "The Seventh Cross" is one of the very few depictions of Nazi concentration camps, in either literature or the cinema.

</doc>
<doc id="9857" url="https://en.wikipedia.org/wiki?curid=9857" title="Elbląg">
Elbląg

Elbląg () is a city in northern Poland on the eastern edge of the Żuławy region with 124,257 inhabitants (December 31, 2011). It is the capital of Elbląg County and has been assigned (since 1999) to the Warmian-Masurian Voivodeship. Previously it was the capital of Elbląg Voivodeship (1975–1998) and a county seat within Gdańsk Voivodeship (1945–1975).
Geographical location.
Elbląg is located about south-east of Gdańsk and south-west of Kaliningrad.
The city is a port on the river Elbląg, which flows into the Vistula Lagoon about to the north, thus giving the city access to the Baltic Sea via the Russian-controlled Strait of Baltiysk. The Old Town () is located on the river Elbląg connecting Lake Drużno to the Vistula Lagoon, about from the lagoon and from Gdańsk.
Modern city.
The German Elbing was almost totally destroyed at the end of World War II. The city became the Polish Elbląg after the war, when the area was ceded to Poland under border changes promulgated at the Potsdam Conference. Parts of the inner city were gradually rebuilt, and around 2000 rebuilding was begun in a style emulating the previous architecture, in many cases over the same foundations and utilizing old bricks and portions of the same walls. The western bank part of the old city is now completely gone.
The modern city adjoins about half the length of the river between Lake Drużno and Elbląg Bay ("Zatoka Elbląska", an arm of the Vistula Lagoon), and spreads out on both banks, though mainly on the eastern side. To the east is the Elbląg Upland ("Wysoczyzna Elbląska"), a dome pushed up by glacial compression, 390 km2 in diameter and high at its greatest elevation. It gives the appearance of ridges and parkland.
Views to the west show flat fields extending to the horizon; this part of the Vistula Delta ("Żuławy Wiślane") is used mainly for agricultural purposes. To the south are the marshes and swamps of Drużno. The Elbląg River has been left in a more natural state through the city, but elsewhere it is a controlled channel with branches. One of them, the Jagielonski Channel ("Kanał Jagieloński"), leads to the Nogat River, along which navigation to Gdańsk is common. The Elbląg Canal ("Kanał Elbląski") connecting Lake Drużno with Drwęca River and Lake Jeziorak is a popular tourist site.
Elbląg is not a deep-water port. The draft of vessels using its waterways must be no greater than by law. The turning area at Elbląg is diameter and a pilot is required for large vessels. Deep water vessels cannot manoeuvre; in that sense, Elbląg has become a subsidiary port of Gdańsk. Traffic of smaller vessels at Elbląg is within the river and very marginal, while larger vessels cannot reach the open Baltic Sea because the channel, once built in East-Prussia to go through the peninsula, has belonged to Russia since 1945. The river has become almost stagnant and its banks are overgrown with waterlilies and tulies. The city features three quay complexes, movable cranes, and railways. One of its specialities is heavy machinery.
Names.
Etymology.
"Elbląg" is the Polish derivative of the German name "Elbing", which was assigned by the Teutonic Knights to the citadel and subsequent town placed by them in 1237 next to the river. The purpose of the citadel was to prevent the Old Prussian settlement of Truso from being reoccupied, as the German crusaders were at war with the pagan Prussians. The citadel was named after the river, itself of uncertain etymology. One traditional etymology connects it to the name of the Helveconae, a Germanic tribe mentioned in Ancient Greek and Latin sources, but the etymology or language of the tribal name is not known.
Historical names.
Early sources: river "Ilfing" (890), "Castrum de Elbingo quod a nomine fluminis Elbingum appellavit" (1237 — Peter of Dusburg, Chronicon terrae Prussiae), "in Elbingo" (1239), "in Elbing" (1242), "in Elbinge ... fluvium Elbinc" (1246, city charter), "de Elbingo" (1250), "in Elbyngo" (1258), "vitra Elbingum" (1263), "Elvingo" (1293), "in Elbingo" (1300), "in Elvingo" (1389), "czum Elbinge" (1392), "czu Elbing" (1403), "Elwing" (1410), "czum Elwinge" (1412), "Elbing" (1414–1438), "Elbyang" (before 1454), "Elbing" (1508), "ku Elbiągowi" (1634), "w Elblągu" (1661), "w Elblągu" (1661).
History.
Old Prussian Truso.
The settlement was first mentioned as "Ilfing" in "", an Anglo-Saxon chronicle written in King Alfred's reign using information from a Viking who had visited the area.
During the Middle Ages, the Old Prussian settlement of Truso was located on Lake Drużno, near the current site of Elbląg in historical Pogesania; the settlement burned down in the 10th century. Early in the 13th century the Teutonic Knights conquered the region, built a castle, and founded Elbing on the lake, with a population mostly from Lübeck (today the lake, now much smaller, no longer reaches the city). After the defeat of the Teutonic Knights and the destruction of the castle by the inhabitants, the city successively came under the sovereignty of the Polish crown (1466), the Kingdom of Prussia (1772), and Germany (1871). Elbing was heavily damaged in World War II, and its German citizens were expelled upon the war's end. The city became part of Poland in 1945 and was repopulated with Polish citizens.
The seaport of Truso was first mentioned ca. 890 by Wulfstan of Hedeby, an Anglo-Saxon sailor, travelling on the south coast of the Baltic Sea at the behest of King Alfred the Great of England. The exact location of Truso was not known for a long time, as the seashore has significantly changed, but most historians trace the settlement inside or near to modern Elbląg on Lake Drużno. Truso was located at territory already known to the Roman Empire and earlier.
It was an important seaport serving the Vistula River bay on the early medieval Baltic Sea trade routes which led from Birka in the north to the island of Gotland and to Visby in the Baltic Sea. From there, traders continued further south to Carnuntum along the Amber Road. The ancient Amber Road led further southwest and southeast to the Black Sea and eventually to Asia. The east-west trade route went from Truso, along the Baltic Sea to Jutland, and from there inland by river to Hedeby, a large trading center in Jutland. The main goods of Truso were amber, furs, and slaves.
Archaeological finds in 1897 and diggings in the 1920s placed Truso at Gut Hansdorf. A large burial field was also found at Elbing. Recent Polish diggings have found burned beams and ashes and thousand-year-old artifacts in an area of about 20 hectares. Many of these artifacts are now displayed at the Elbing Museum.
Prussian Crusade.
Attempts to conquer Prussian land began in 997, when Bolesław I Chrobry, at the urging of the Pope, sent a contingent of soldiers and a missionary (Adalbert of Prague) to the pagan Prussians, a non-Slavic people, on a crusade of conquest and conversion. The crusade encompassed much of the Baltic Sea coast, including Danzig (present day Gdańsk), and other areas of the coast up to Sambia. Starting in 1209 additional crusades were called for by Konrad of Masovia, who mainly sought to conquer Prussian territory, rather than actually convert the indigenous Prussians. Despite heroic efforts, Old Prussian sovereignty would eventually collapse after a succession of wars instigated by Pope Honorius III and his frequent calls for crusade.
Before the Prussians and their neighbors to the west, the Pomeranians, were finally brought to heel, Polish rulers and the Duchy of Masovia, both by then Christianised peoples, would be continually frustrated in their attempts at northern expansion. Aside from minor border raids, major campaigns against the Prussians would be launched in 1219, 1220, and 1222. After a particularly sound defeat by Prussian forces in 1223, Polish forces in Chełmno, the seat of Christian of Oliva and the Duchy of Masovia, were forced onto the defensive.
In 1226 Duke Konrad I of Masovia summoned the Teutonic Knights for assistance; by 1230 they had secured Chełmno (Culm) and begun claiming conquered territories for themselves under the authority of the Holy Roman Empire, although these claims were rejected by the Poles, whose ambition had been to conquer Prussia all along. The Teutonic Order's strategy was to move down the Vistula and secure the delta, establishing a barrier between the Prussians and Danzig. The victorious Teutonic Knights built a castle at Elbing, near, if not on top of, the destroyed Prussian town of Truso.
The Chronicon terrae Prussiae describes the conflict in the vicinity of Lake Drusen (now Drużno) shortly before the founding of Elbing:
Truso did not disappear suddenly to be replaced with the citadel and town of Elbing during the Prussian Crusade. It had already burned down in the tenth century, with the population dispersed in the area.
Foundation of Elbing.
The Chronicon terrae Prussiae describes the founding of Elbing under the leadership of Hermann Balk. After building two ships, the Pilgerim (Pilgrim) and the Vridelant (Friedland), with the assistance of Margrave Henry III of Margraviate of Meissen, the Teutonic Knights used them to clear the Vistula Lagoon ("Frisches Haff") and the Vistula Spit of Prussians:
Apparently the river was in Pomesania, which the knights had just finished clearing, but the bay was in Pogesania. The first Elbing was placed in Pogesania:
Both landings were amphibious operations conducted from the ships. The "Chronicon" relates that they were in use for many years and then were sunk in Lake Drusen. In 1238 the Dominican Order was invited to build a monastery on a grant of land. Pomesania was not secured, however, and from 1240-1242 the order began building a brick castle on the south side of the settlement, where archaeologists now believe Truso had been. It may be significant that Elbing's first industry was the same as Truso's had been: manufacture of amber and bone artifacts for export. In 1243 William of Modena created the Diocese of Pomesania and three others. They were at first only ideological constructs, but the tides of time turned them into reality in that same century.
The foundation of Elbing was perhaps not the end of the Old Prussian story in the region. In 1825 a manuscript listing a vocabulary of the Baltic Old Prussian language, named the Elbing-Prussian Dictionary (), or more commonly in English just Elbing Vocabulary, was found among some manuscripts from a merchant's house. It contained 802 words in a dialect now termed Pomesanian with their equivalents in an early form of German.
The origin of the vocabulary remains unknown. Its format is like that of modern travel dictionaries; i.e., it may have been used by German speakers to communicate with Old Prussians, but the specific circumstances are only speculative. The manuscript became the Codex Neumannianus. It disappeared after a British bombing raid destroyed the library at Elbing but before then facsimiles had been made. The date of the MSS was estimated at ca. 1400, but it was a copy. There is no evidence concerning the provenance of the original, except that it must have been in Pomesanian.
Hanseatic Elbing.
In 1246 the town was granted a constitution under Lübeck law, used in maritime circumstances, instead of Magdeburg rights common in other cities in Central Europe. This decision of the Order was in keeping with its general strategy of espousing the trade association that in 1358 would become the Hanseatic League. The Order seized on this association early and used it to establish bases throughout the Baltic. The Order's involvement in the League was somewhat contradictory. In whatever cities they founded the ultimate authority was the commander of the town, who kept office in the citadel, typically used as a prison. Lübeck law, on the other hand, provided for self-government of the town.
Membership in the Hanseatic League meant having important trading contacts with England, Flanders, France, and the Netherlands. The city received numerous merchant privileges from the rulers of England, Poland, Pomerania, and the Teutonic Order. For instance, the privilege of the Old Town (, ) was upgraded in 1343, while in 1393 it was granted an emporium privilege for grains, metals, and forest products.
Except for the citadel and churches, Elbing at the time was more of a small village by modern standards. Its area was . It featured a wharf, a marketplace and five streets, as well as a number of churches. The castle was completed in 1251. In 1288 fire destroyed the entire settlement except for the churches, which were of brick. A new circuit wall was started immediately. From 1315 to 1340 Elbląg was rebuilt. A separate settlement called New Town () was founded ca. 1337 and received Lübeck rights in 1347. In 1349 the Black Death struck the town, toward the end of the European plague. After the population recovered it continued building up the city and in 1364 a crane was built for the port.
The German-language "Elbinger Rechtsbuch", written in Elbing, Prussia documented among other laws for the first time Polish common law. The German-language Polish laws are based on the Sachsenspiegel and were written down to aid the judges. It is thus the oldest source for documented Polish common law and is in Polish referred to as the "Księga Elbląska" (Book of Elbląg). It was written down in the second half of the 13th century.
Kingdom of Poland.
In 1440 several western and eastern Prussian towns formed the Prussian Confederation, which led the revolt of Prussia against the rule of the Teutonic Knights in 1454. The burghers destroyed the Teutonic Order castle. For assistance against the Order, the Confederation asked for help from King Casimir IV of Poland; Casimir's subsequent claiming of Prussia led to the Thirteen Years' War.
After the Section of Prussians and Polish victory over the Teutonic Order, the city became part of the autonomous province of Royal Prussia under the suzerainty of the Polish crown in the Second Peace of Thorn. The city was known to the Polish crown by its Polish name Elbląg.
With the creation of the Polish-Lithuanian Commonwealth in 1569, the city was brought under direct control of the Polish crown.
With the 16th century Protestant Reformation the burghers became Lutherans and the first Lutheran Gymnasium was established in Elbląg in 1535.
From 1579 Elbing/Elbląg had close trade relations with England, to which the city accorded free trade. English, Scottish, and Irish merchants settled in the city. They formed the Scottish Reformed Church of Elbląg and became Elbing citizens, aiding Lutheran Sweden in the Thirty Years' War. The rivalry of nearby Danzig interrupted trading links several times. By 1618 Elbląg had left the Hanseatic League owing to its close business dealings with England.
Famous inhabitants of the city at that time included native sons Hans von Bodeck and Samuel Hartlib. During the Thirty Years' War, Swedish Chancellor Axel Oxenstierna brought the Moravian Brethren refugee John Amos Comenius to Elbląg for six years (1642–48). In 1642 Johann Stobäus, who composed with Johann Eccard, published the " Preussische Fest-Lieder", a number of evangelical Prussian songs. In 1646 the city recorder Daniel Barholz noted that the city council employed "Bernsteindreher", or "Paternostermacher", licensed and guilded amber craftsmen who worked on prayer beads, rosaries, and many other items made of amber. Members of the Barholz family became mayors and councillors.
During the Thirty Years' War, the Vistula Lagoon was the main southern Baltic base of King Gustavus Adolphus of Sweden, who was hailed as the protector of the Protestants. By 1660 the Vistula Lagoon had gone to Elector Frederick William of Brandenburg-Prussia, but was returned in 1700.
The poet Christian Wernicke was born in 1661 in Elbing, while Gottfried Achenwall became famous for his teachings in natural law and human rights law.
In 1700-1710 it was occupied by Swedish troops.
In 1709 it was besieged, taken by storm on February 2, 1710 by Russian troops with support of Prussian artillery. The city was handed over to Polish King Augustus II in 1712.
The Imperial cartographer Johann Friedrich Endersch completed a map of Warmia () in 1755 and also made a copper etching of the galley named "The City of Elbląg" () .
During the War of the Polish Succession in 1734, Elbing/Elbląg and Danzig were placed under military occupation by Russia and Saxony. The town came again under occupation by Russia from 1758-1762 during the Seven Years' War.
Hohenzollern Prussia.
During the First Partition of Poland in 1772, resulting in the re-unification of Prussia, the city state was annexed by King Frederick the Great of the Kingdom of Prussia. Elbing became part of the new Prussian Province of West Prussia in 1773. In the 1815 provincial reorganization following the Napoleonic Wars, Elbing and its hinterland were included within Regierungsbezirk Danzig in West Prussia.
Elbing industrialized under the sovereignty of the Hohenzollern kings in Berlin. In 1828 the first steamship was built by Ignatz Grunau. In 1837 Ferdinand Schichau started the Schichau-Werke company in Elbing as well as another shipyard in Danzig later on. Schichau constructed the "Borussia", the first screw-vessel in Germany. Schichau-Werke built hydraulic machinery, ships, steam engines, and torpedoes. After the inauguration of the railway to Königsberg in 1853, Elbing's industry began to grow. Schichau worked together with his son-in-law Carl H. Zise, who continued the industrial complex after Schichau's death. Schichau erected large complexes for his many thousands of workers.
Georg Steenke, an engineer from Königsberg, connected Elbing near the Baltic Sea with the southern part of Prussia by building the Oberländischer Kanal (Elbląg Canal).
Elbing became part of the Prussian-led German Empire in 1871 during the unification of Germany. As Elbing became an industrial city, the Social Democratic Party of Germany (SPD) frequently received the majority of votes; in the 1912 Reichstag elections the SPD received 51% of the vote. After World War I, most of West Prussia became part of the Second Polish Republic. Elbing was joined to German East Prussia, and was separated from Weimar Germany by the Polish Corridor.
Mormons started filming the church records of Elbing's citizens in "Kirchenbücher". Records dating from 1577 to 1890 are available.
Third Reich.
During the Nazi German era (1933–1945), three subcamps of the Stutthof concentration camp were located near the town: "Elbing", "Elbing (Org. Todt)", and "Elbing (Schinau)". These were closed and many of the German inhabitants of Elbing forced to flee as the Soviet Red Army approached the city toward the end of World War II (see Evacuation of East Prussia). Laid under siege since January 23, 1945, about 65% of the city infrastructure was destroyed, including most of the historical city center. The town was captured by the Soviet Red Army during the night of February 9/10, 1945. During the first days of the fighting most of the population of approximately 100,000 persons fled, except of about 20,000. After the end of war, in spring 1945, the region together with the town of Elbing became part of Poland as a result of the Potsdam Conference.
Almost all Germans who remained or returned were expelled by the Poles during the following months.
History after 1945.
After the expulsion of most of the German population, the city was repopulated and given the Polish name "Elbląg". Of the new inhabitants, 98% were Poles expelled from Polish areas annexed by the Soviet Union, or Polish peasants from central Poland. Parts of the damaged historical city center were completely demolished, with the bricks being used to rebuild Warsaw and Gdańsk. The Communist authorities had originally planned that the Old Town, utterly destroyed during the fightings since January 23, 1945, would be built over with blocks of flats; however, economic difficulties thwarted this effort. Two churches were reconstructed and the remaining ruins of the old town were torn down in the 1960s.
Along with Tricity and Szczecin, Elbląg was the scene of rioting in the coastal cities in 1970 (see also Polish 1970 protests). Since 1990 the German minority population has had a modest resurgence, with the Elbinger Deutsche Minderheit Organization counting around 450 members in 2000.
Restoration of the Old Town began after 1989. Since the beginning of the restoration, an extensive archaeological programme has been carried out. Most of the city's heritage was destroyed during the construction of basements in the 19th century or during World War II, but the backyards and latrines of the houses remained largely unchanged, and have provided information on the city's history. In some instances, private investors have incorporated parts of preserved stonework into new architecture. By 2006, approximately 75% of the Old Town had been reconstructed. The city museum presents many pieces of art and items of everyday use, including the only 15th century binoculars preserved in Europe.
Elbląng is home to the Elbrewery, Poland's largest brewery, which belongs to the Żywiec Group.
Population.
Note that the above table is based on primary, possibly biased, sources.
Tourist attractions.
Until World War II there were many Gothic, renaissance and baroque houses in Elbląg's Old Town; some of them are reconstructed. Other preserved buildings are:
Politics.
Elbląg constituency.
Members of Parliament (Sejm) elected from Elbląg constituency
International relations.
Twin towns - Sister cities.
Elbląg is twinned with:

</doc>
<doc id="9860" url="https://en.wikipedia.org/wiki?curid=9860" title="ESR">
ESR

ESR may refer to:

</doc>
<doc id="9862" url="https://en.wikipedia.org/wiki?curid=9862" title="Europe of Democracies and Diversities">
Europe of Democracies and Diversities

Europe of Democracies and Diversities (EDD) was a Eurosceptic political group with seats in the European Parliament between 1999 and 2004. Following the 2004 European elections, the group reformed as Independence/Democracy (IND/DEM).

</doc>
<doc id="9864" url="https://en.wikipedia.org/wiki?curid=9864" title="European Free Alliance">
European Free Alliance

The European Free Alliance (EFA) is a European political party.
It consists of various regionalist political parties in Europe advocating either full political independence and sovereignty, or some form of devolution or self-governance for their country or region. The alliance has generally limited its membership to progressive parties, therefore only a minority among European regionalist parties are members of the EFA.
Since 1999 the EFA and the European Green Party (EGP) have joined forces within The Greens–European Free Alliance (Greens/EFA) group in the European Parliament, albeit some EFA members have joined other groups from time to time.
The EFA's youth wing is the European Free Alliance Youth (EFAY), founded in 2000.
History.
Since the 1979 election, regionalists have been represented in the European Parliament. Four regionalist parties obtained seats in that election: the Scottish National Party (SNP), the Flemish People's Union (VU), the Brussels-based Democratic Front of Francophones (FDF) and the South Tyrolean People's Party (SVP). The SNP, although being predominantly social-democratic, joined the European Progressive Democrats, a conservative group led by the French Gaullist Rally for the Republic. The VU and the FDF joined the heterogeneous Technical Group of Independents, while the SVP joined the European People's Party.
In 1981 six parties (VU, the Frisian National Party, Independent Fianna Fáil, the Party of German-speaking Belgians, the Party for the Organization of a Free Brittany and the Alsace-Lorraine National Association), plus three observers (the Union of the Corsican People, the Occitan Party and the Democratic Convergence of Catalonia, CDC), joined forces to form the European Free Alliance. Regionalist MEPs continued, however, to sit in different groups in the European Parliament: the SNP in the Gaullist-dominated European Democratic Alliance; the VU, the Sardinian Action Party (PSd'Az) and Basque Solidarity (EA) in the Rainbow Group, together with Green parties; the SVP in the European People's Party group; the CDC with the Liberal Democrats; and Batasuna among Non-Inscrits.
Only after the 1989 European Parliament election did EFA members form a united group, called Rainbow like its green predecessor. It consisted of three Italian MEPs (two for Lega Lombarda and one for the PSd'Az), two Spanish MEPs (one each for the PNV and the Andalusian Party, PA), one Belgian MEP (for VU), one French MEP (Union of the Corsican People, UPC), one British MEP (SNP) and one independent MEP from Ireland. They were joined by 4 MEPs from the Danish left-wing Eurosceptic People's Movement against the EU, while the other regionalist parties, including the SVP, Batasuna and the Convergence and Union of Catalonia (CiU) declined to join.
In the 1994 European Parliament election the regionalists lost many seats. Moreover, the EFA had suspended its major affiliate, Lega Nord, for having joined forces in government with the post-fascist National Alliance. Also, the PNV chose to switch to the European People's Party (EPP). The three remaining EFA MEPs (representing the SNP, the VU and the Canarian Coalition) formed a group with the French "Énergie Radicale" list and the Italian Pannella List: the European Radical Alliance.
Following the 1999 European Parliament election, in which EFA parties did quite well, EFA elected MEPs formed a joint group with the European Green Party, under the name The Greens–European Free Alliance (Greens/EFA). In the event the EFA supplied ten members: two each from the Scottish SNP, the Welsh Plaid Cymru, and the Flemish VU, and one each from the Basque PNV and EA, the Andalusian PA and the Galician Nationalist Bloc (BNG).
In the 2004 European Parliament election, the EFA, which had formally become a European political party, was reduced to four MEPs: two from the SNP (Ian Hudghton and Alyn Smith), one from Plaid Cymru (Jill Evans) and one from the Republican Left of Catalonia (ERC; Bernat Joan i Marí, replaced at the mid-term by MEP Mikel Irujo of the Basque EA). They were joined by two associate members: Tatjana Ždanoka of For Human Rights in United Latvia (PCTVL) and László Tőkés, an independent MEP and former member of the Democratic Union of Hungarians in Romania (UMDR). Co-operation between the EFA and the Greens continued.
Following the 2008 revision of the EU Regulation that governs European political parties allowing the creation of European foundations affiliated to European political parties, the EFA established its official foundation/think tank, the Centre Maurits Coppieters (CMC), in September 2007.
In the 2009 European Parliament election, six MEPs were returned for the EFA: two from the SNP (Ian Hudghton and Alyn Smith), one from Plaid Cymru (Jill Evans), one from the Party of the Corsican Nation (PNC; François Alfonsi), one from the ERC (Oriol Junqueras i Vies), and Tatjana Ždanoka, an individual member of the EFA from Latvia. After the election, the New Flemish Alliance (N-VA) also joined the EFA. The EFA subgroup thus counted seven MEPs.
In the 2014 European Parliament election, EFA-affiliated parties returned twelve seats to the Parliament: four for the N-VA, two for the SNP, two for "L'Esquerra pel Dret a Decidir" (an electoral list primarily composed of the ERC), one for "Los Pueblos Deciden" (an electoral list maily comprising EH Bildu, a Basque coalition including EA), one for "Primavera Europea" (an electoral list comprising the Valencian Nationalist Bloc, BNV, and the Aragonese Union, ChA), one from Plaid Cymru, and one from the Latvian Russian Union (LKS). Due to ideological divergences with the Flemish Greens, the N-VA defected to the European Conservatives and Reformists (ECR) group and the EH Bildu MEP joined the European United Left–Nordic Green Left (GUE/NGL) group: the EFA representation within the Greens/EFA group was thus of seven MEPs.
Ideology.
In the Brussels declaration of 2000 the EFA codified its political principles. The EFA stands for "a Europe of Free Peoples based on the principle of subsidiarity, which believe in solidarity with each other and the peoples of the world." The EFA sees itself as an alliance of stateless peoples, which are striving towards independence, autonomy, recognition or wanting a proper voice in Europe. It supports European integration on basis of the subsidiarity-principle. It believes also that Europe should move away from further centralisation and works towards the formation of a "Europe of regions". It believes that regions should have more power in Europe, for instance participating in the Council of the European Union, when matters within their competence are discussed. It also wants to protect the linguistic and cultural diversity within the EU.
The EFA broadly stands on the left-wing of the political spectrum. The Brussels declaration emphasises the protection of human rights, sustainable development and social justice. In 2007 the EFA congress in Bilbao added several progressive principles to the declaration, including a commitment to fight against racism, antisemitism, discrimination, xenophobia and islamophobia, and a commitment to get full citizenship for immigrants, including voting rights.
EFA members are generally progressive, although there are some notable exceptions as the conservative New Flemish Alliance, Bavaria Party, Schleswig Party and Future of Åland, the Christian-democratic Slovene Union, the centre-right Liga Veneta Repubblica and the far-right South Tyrolean Freedom.
Organisation.
The main organs of the EFA organisation are the General Assembly, the Bureau and the Secretariat.
General Assembly.
In the General Assembly, the supreme council of the EFA, every member party has one vote.
Bureau and Secretariat.
The Bureau takes care of daily affairs. It is chaired by François Alfonsi (Party of the Corsican Nation), president of the EFA, while Jordi Solé (Republican Left of Catalonia) is secretary-general and Lorena Lopez de Lacalle (Basque Solidarity) treasurer and vice-president. The Bureau is completed by other nine vice-presidents: Gustave Alirol (Occitan Party), Olrik Bouma (Frisian National Party), Fabrizio Comencini (Liga Veneta Repubblica), Eric Defoort (New Flemish Alliance), Jill Evans (Plaid Cymru),
Ian Hudghton (Scottish National Party), Davyth Hicks (Mebyon Kernow), Axel Jonsson (Future of Åland) and Ana Miranda (Galician Nationalist Bloc).
Member parties.
This is a list of EFA member parties.
Full members.
Before becoming a member party, an organization needs to have been an observer of the EFA for at least one year. Only one member party per region is allowed. If a second party from a region wants to join the EFA, the first party needs to agree, at which point these two parties will then form a common delegation with one vote. The EFA also recognises friends of the EFA, a special status for regionalist parties outside of the European Union.

</doc>
<doc id="9865" url="https://en.wikipedia.org/wiki?curid=9865" title="Alliance of Liberals and Democrats for Europe Party">
Alliance of Liberals and Democrats for Europe Party

The Alliance of Liberals and Democrats for Europe Party (ALDE Party) is a European political party mainly active in the European Union, composed of 60 national-level liberal parties from across Europe. Until 10 November 2012, the party was known as European Liberal Democrat and Reform Party (ELDR). The ALDE Party is affiliated with the Liberal International.
Having developed from a loose confederation of national political parties in the 1970s, the ALDE Party is a recognised European political party incorporated as a non-profTiit association under Belgian law.
, ALDE is represented in European Union institutions, with 70 MEPs and 5 members of the European Commission. Of the 28 EU member states, there are seven with ALDE-affiliated Prime Ministers: Xavier Bettel (DP) in Luxembourg, Charles Michel (MR) in Belgium, Taavi Rõivas (RE) in Estonia, Miro Cerar (SMC) in Slovenia, Juha Sipilä (KESK) in Finland, Mark Rutte (VVD) in the Netherlands and Lars Løkke Rasmussen (Venstre) in Denmark. Liberals are also in government in three other EU member states: Croatia, Czech Republic and Lithuania.
Since 20 July 2004, the ALDE Party is politically represented in the European Parliament by the Alliance of Liberals and Democrats for Europe (ALDE) parliamentary group, formed in conjunction with the European Democratic Party (EDP). The ALDE parliamentary group is led by Guy Verhofstadt, a former Prime Minister of Belgium. Prior to the 2004 European election the party was attached to the European Liberal Democrat and Reform Party (ELDR) Group.
ALDE's think tank is the European Liberal Forum. The youth wing of ALDE is the European Liberal Youth (LYMEC), which is predominantly based upon youth and student liberal organisations but contains also a small number of individual members. LYMEC is led by Vedrana Gujic (HNS, Croatia), who was elected for a two-year term as LYMEC President in May 2014, and counts 200,000 members.
Structure.
Bureau.
The day-to-day management of the ALDE Party is handled by the Bureau, the members of which are:
History of pan-European liberalism.
Pan-European liberalism has a long history dating back to the foundation of Liberal International in April 1947. In March 1976, the Federation of Liberal and Democrat Parties in Europe was established. The founding parties of the federation were the Free Democratic Party of Germany, Radical Party of France, Liberal Party of Denmark, Italian Liberal Party, Dutch People's Party for Freedom and Democracy and Democratic Party of Luxembourg. Observer members joining later in 1976 were the Danish Social Liberal Party, French Radical Party of the Left and Independent Republicans, British Liberal Party, and Italian Republican Party. The federation gradually evolved into the European Liberal Democrat and Reform Party (ELDR) with a matching group in the European Parliament, the European Liberal Democrat and Reform Party Group.
At an extraordinary Congress in Brussels held on 30 April 2004 the day before the enlargement of the European Union, the ELDR Party incorporated itself under Belgian law and became a European political party.
The ELDR Party allied with the European Democratic Party in 2004 to form the Alliance of Liberals and Democrats for Europe (ALDE), with a matching ALDE Group in the European Parliament. The ELDR Party adopted its current name on 10 November 2012 in order to match the pan-European alliance and parliamentary group.
European Commissioners.
ALDE Member Parties contribute 5 out of the 28 members of the European Commission:

</doc>
<doc id="9866" url="https://en.wikipedia.org/wiki?curid=9866" title="European People's Party Group">
European People's Party Group

The European People's Party group (EPP Group) is the political group in the European Parliament consisting of deputies (MEPs) from the member parties of the European People's Party (EPP). In this respect, there is a distinction between the European People's Party (an umbrella party of centre-right national political parties from across Europe) and the EPP Group (which only exists in the European Parliament). The group comprises politicians of Christian democratic and conservative orientation.
The European People's Party was officially founded as a European political party in 1976. However, the European People's Party group in the European Parliament has existed in one form or another since June 1953, from the Common Assembly of the European Coal and Steel Community. This makes it one of the oldest EU political groups. Its size has given it influence in all the EU's institutions. It has been the largest political group in the European Parliament since 1999. In the European Council, 14 out of 28 Heads of State and Government belong to the EPP family and in the European Commission, 13 out of 28 Commissioners come from EPP parties.
History.
The Common Assembly of the European Coal and Steel Community (the predecessor of the present day European Parliament) first met on 10 September 1952 and the first Christian Democratic group was unofficially formed the next day, with Maan Sassen as President. The group held 38 of the 78 seats, two short of an absolute majority. On 16 June 1953 the Common Assembly passed a resolution enabling the official formation of political groups, and on 23 June 1953 the constituent declaration of the group was published and the group was officially formed.
The Christian Democrat group was the biggest group at formation, but as time wore on it lost support and was the second-biggest group by the time of the 1979 elections. As the European Community expanded into the European Union, the dominant centre-right parties in the new member states were not necessarily Christian democratic, and the EPP (European People's Party, the pan-continental political party founded in 1976 which all group members are now affiliated to) feared being sidelined. To counter this, the EPP expanded its remit to cover the centre-right regardless of tradition and pursued a policy of integrating conservative parties.
This policy lead to Greek New Democracy and Spanish People's Party MEPs joining the EPP Group. The British and Danish Conservatives tried to maintain a group of their own called the "European Democrats" (ED), but lack of support and the problems inherent in maintaining a small group forced ED's collapse in the 1990s, and its members crossed the floor to join the EPP Group. The parties of these MEPs also became full members of the EPP (with the exception of the British Conservatives who did not join the Party) and this consolidation process of the European centre-right throughout the 1990s with the acquisition of members from the Italian party Forza Italia. However, the consolidation was not unalloyed and a split emerged with the Eurosceptic MEPs who congregated in a subgroup within the group, also called the "European Democrats" (ED).
Nevertheless, the consolidation held through the 1990s, assisted by the group being renamed to the "European People's Party – European Democrats" (EPP-ED Group), and after the 1999 European elections the EPP-ED reclaimed its position as the largest group in the Parliament from the PES Group.
Size was not enough, however: the group did not have a majority. It continued therefore to engage in the "Grand Coalition" (a coalition with the PES Group, or occasionally the Liberals) to generate the majorities required by the cooperation procedure under the Single European Act. This coalition has held, although occasionally the group adopts a government-opposition dynamic with the other groups, notably during the budget crisis when it opposed the PES and brought about the resignation of the Santer Commission.
Meanwhile, the parties in the European Democrats subgroup were growing restless and finally left following the 2009 elections, when the Czech Civic Democrats and British Conservatives formed their own right-wing European Conservatives and Reformists (ECR) group on 22 June 2009, abolishing the European Democrats subgroup from that date. The EPP-ED Group reverted to its original name – the EPP Group – immediately.
In the 7th European Parliament the EPP Group remains the largest parliamentary group with 275 MEPs. It is currently the only political group in the European parliament to fully represent its corresponding European political party, i.e. the European People's Party. The United Kingdom is now the only EU member state not to have representation in the EPP Group.
Membership at formation.
The 38 members in the group on 11 September 1952 were as follows:
Structure.
Organisation.
The EPP Group is governed by a collective (referred to as the "Presidency") that allocates tasks. The Presidency consists of the Group Chair and a maximum of ten Vice-Chairs, including the Treasurer. The day-to-day running of the EPP Group is performed by its secretariat in the European Parliament, led by its Secretary-General. The Group runs its own think-tank, the European Ideas Network, which brings together opinion-formers from across Europe to discuss issues facing the European Union from a centre-right perspective.
The EPP Group Presidency includes:
The chairs of the group and its predecessors from 1952 to 18 September 2008 are as follows:
Membership.
The national parties that have Members of the EPP Group are as follows:
Activities.
In the news.
Activities performed by the group in the period between June 2004 and June 2008 include monitoring elections in Palestine and the Ukraine; encouraging transeuropean rail travel, telecoms deregulation, energy security, a common energy policy, the accession of Bulgaria and Romania to the Union, partial reform of the CAP and attempts to tackle illegal immigration; denouncing Russian involvement in South Ossetia; supporting the Constitution Treaty and the Lisbon Treaty; debating globalisation, relations with China, and Taiwan; backing plans to outlaw Holocaust denial; nominating Anna Politkovskaya for the 2007 Sakharov Prize; expelling Daniel Hannan from the Group; the discussion about whether ED MEPs should remain within EPP-ED or form a group of their own; criticisms of the group's approach to tackle low turnout for the 2009 elections and the group's use of the two-President arrangement.
Parliamentary activity profile.
The debates and votes in the European Parliament are tracked by its website and categorized by the groups that participate in them and the rule of procedure that they fall into. The results give a profile for each group by category and the total indicates the group's level of participation in Parliamentary debates. The activity profile for each group for the period 1 August 2004 to 1 August 2008 in the Sixth Parliament is given on the diagram on the right. The group is denoted in blue.
The website shows the group as participating in 659 motions, making it the third most active group during the period.
Publications.
The group produces many publications, which can be found on its website. Documents produced in 2008 cover subjects such as dialogue with the Orthodox Church, study days, its strategy for 2008-09, Euro-Mediterranean relations, and the Treaty of Lisbon. It also publishes a yearbook and irregularly publishes a presentation, a two-page summary of the group.
Academic analysis.
Along with the other political groups, the group has been analysed by academics on its positions regarding various issues. Those positions are summarised in this article. That article characterizes the group as a three-quarter male group that, prior to ED's departure, was only 80% cohesive and split between centre-right Europhiles (the larger EPP subgroup) and right-wing Eurosceptics (the smaller ED subgroup). That article characterized the group as a whole as ambiguous on hypothetical EU taxes, against taxation, Green issues, social liberal issues (LGBT rights, abortion, euthanasia) and full Turkish accession to the European Union, and for a deeper Federal Europe, deregulation, the Common Foreign and Security Policy and controlling migration into the EU.

</doc>
<doc id="9867" url="https://en.wikipedia.org/wiki?curid=9867" title="European United Left–Nordic Green Left">
European United Left–Nordic Green Left

European United Left/Nordic Green Left (GUE/NGL) is a left-wing political group in the European Parliament, established in 1995. The group comprises political parties of mostly socialist and communist orientation.
Position.
According to its 1994 constituent declaration, the group is opposed to the present European Union political structure, but committed to integration. That declaration sets out three aims for the construction of another European Union: the total change of institutions to make them "fully democratic"; breaking with "neo-liberal monetarist policies"; and a policy of co-development and equitable cooperation. The group wants to disband the North Atlantic Treaty Organisation (NATO) and "strengthen the Organization for Security and Co-operation in Europe" (OSCE).
The group is ambiguous between reformism and revolution, leaving it up to each party to decide on the manner they deem best suited to achieve these aims. As such, it has simultaneously positioned itself as "insiders" within the European institutions, enabling it to influence the decisions made by co-decision, and as "outsiders" by its willingness to seek "another Union" which would abolish the Maastricht Treaty.
Organisation.
The GUE/NGL is a confederal group: it is composed of MEPs from national parties. Those national parties must share common political objectives with the group, as specified in the group's constituent declaration. Nevertheless, those national parties, not the group, retain control of their MEPs. Thus, the Group may be divided on certain issues.
Members of the group meet regularly to prepare for meetings, debate on policies and vote on resolutions. The group also publishes reports on various topics.
Member parties.
MEPs may be full or associate members.
National parties may be full or associate members.
History.
In 1995, the enlargement of the European Union led to the creation of the Nordic Green Left group of parties. The Nordic Green Left merged with the Confederal Group of the European United Left (GUE) on 6 January 1995, forming the Confederal Group of the European United Left/Nordic Green Left. The NGL suffix was added to the name of the expanded group on insistence of Swedish and Finnish MEPs. The group initially consisted of MEPs from the Finnish Left Alliance, Swedish Left Party, the Danish Socialist People's Party, United Left of Spain (including the Spanish Communist Party), Synaspismós of Greece, the French Communist Party, Portuguese Communist Party, the Communist Party of Greece, and the Communist Refoundation Party of Italy.
In 1999, the German Party of Democratic Socialism (PDS) and the Greek Democratic Social Movement (DIKKI) joined as full members, while the five MEPs elected from the list of the French Trotskyist alliance LO-LCR joined as associate members.
In 2002, four MEPs from the French Citizen and Republican Movement also joined the group.
In 2004, no MEPs were elected from LO-LCR and DIKKI was dissolved. MEPs from the Portuguese Left Bloc, Sinn Féin both from the Republic of Ireland and Northern Ireland, the Progressive Party of Working People (AKEL) of Cyprus, and the Communist Party of Bohemia and Moravia joined the group.

</doc>
<doc id="9868" url="https://en.wikipedia.org/wiki?curid=9868" title="European Democrats">
European Democrats

The European Democrats was a loose association of conservative political parties in Europe. It was a political group in the European Parliament from 1979 until 1992, when it became a subgroup of European People's Party–European Democrats (EPP-ED). It continues to exist as a political group in the Parliamentary Assembly of the Council of Europe.
European Democrats in the European Parliament.
1979-1992.
The European Democratic Group (ED) was formed on 17 July 1979 by British Conservative, Danish Conservative and other MEPs after their success in the 1979 elections. It supplanted the earlier European Conservative Group.
In the late seventies and early eighties, the ED was the third-largest group in the Parliament.
However, the group saw its membership fall sharply in the late 1980s, as many centre-right members moved to the rival European People's Party (EPP), dominated by the German CDU and the ideology of Christian democracy in general. The ED had been somewhat further from the political centre and less pro-European than the EPP. Largely isolated, even hardline eurosceptics like Margaret Thatcher conceded that the British Conservatives could not be effectively heard from such a peripheral group.
1992-1999.
On 1 May 1992, the ED (now largely composed of UK Conservative Party members) dissolved, and its remaining members were accorded "associated party" status in the EPP group; that is, being part of the parliamentary group without retaining actual membership in the EPP Europarty organisation. This was considered essential for the Conservatives, as the EPP was generally seen as quite favourable to European integration, a stance at odds with their core ideology. The Conservatives' relationship to the EPP would become a sore point in the following years, particularly for the eurosceptic general membership in Britain. Then-Tory leader William Hague hoped to put the issue to rest by negotiating a new arrangement in 1999 by which the parliamentary group would rebrand itself as the European People's Party–European Democrats (EPP-ED), with the "European Democrat" nomenclature returning after a seven-year hiatus. This was intended to nominally underscore the Conservatives' status apart from the rest of EPP, and it was hoped that with the coming enlargement of the European Union numerous newly involved right-wing parties, averse to the EPP proper for its perceived European federalism, would be willing to instead enter the ED subgroup, growing the overall alignment.
1999-2009.
The arrangement proved to do little to appease opposition. Hague's successor, Iain Duncan Smith, made a concerted drive at one point to resurrect the European Democratic Group, but backed off when it became clear that Conservative MEPs would not move voluntarily. The hope that multiple Central and European parties would join ED also proved to be dubious, as only the Czech Civic Democratic Party took up the offer, with the remainder joining EPP proper or other groups such as Union for Europe of the Nations (UEN) or Independence and Democracy. Meanwhile, the ED remained a more eurosceptic subgroup within the broader EPP-ED bloc that contributed slightly more than 10% of its total MEPs. It resisted the trend of incorporating as a European political party.
During the 2005 Conservative leadership contest, eventual winner David Cameron pledged to withdraw the Conservatives from the EPP-ED group, while opponent David Davis argued in a letter to the editor of the Daily Telegraph that the current ED arrangement allowed the Conservatives to maintain suitable distance from EPP while still having influence in the largest parliamentary grouping. Conservative/EPP-ED MEP Martin Callanan responded in that paper the following day:
The Czech Civic Democratic Party (ODS), the Polish party Law and Justice (PiS) and the Rally For France party were among the first to discuss forming a breakaway group under the Movement for European Reform. Sir Reg Empey, Leader of the Ulster Unionist Party (UUP) has committed his party thereunto Its position would be that the European Union should exist, but as a looser supranational organisation than at present, making the group less eurosceptic than the Union for Europe of the Nations and the Independence and Democracy. Some members from the above parties founded a new organization, the Alliance for an Open Europe, in the midst of this debate, with broadly similar objectives.
Cameron initially intended to form the new group in 2006, though this aspiration had to be cancelled due to their main prospective partners, the ODS and PiS, being unable or unwilling to break away from their then-groupings; the new grouping was put on hiatus until the European Parliament election, 2009. By then, new factors—including the collapse of the Union for Europe of the Nations (UEN) group—made conditions for forming a new political grouping much more favourable. On 22 June 2009, the founder members of the European Conservatives and Reformists, all signatories of the Prague Declaration announced that they were to leave the EPP-ED, and in virtue of that fact, the European Democrats movement. This announcement ended the 30-year existence of the European Democrats in the European Parliament.
Former member parties.
The following political parties were associated with the European Democrats at some point:
European Democrats in PACE (Parliamentary Assembly of the Council of Europe).
The European Democrat Group in the Parliamentary Assembly of the Council of Europe was originally founded as the Group of Independent Representatives in 1970 by British and Scandinavian members of PACE, having about 35-40 members from the UK, Ireland, Norway, Denmark, Turkey, Sweden and Switzerland. It adopted its current name in September 1980.

</doc>
<doc id="9869" url="https://en.wikipedia.org/wiki?curid=9869" title="Epistle to the Ephesians">
Epistle to the Ephesians

The Epistle to the Ephesians, also called the Letter to the Ephesians and often shortened to Ephesians, is the tenth book of the New Testament. Its authorship has traditionally been credited to Paul the Apostle but, starting in 1792, this has been challenged as Deutero-Pauline, that is, written in Paul's name by a later author strongly influenced by Paul's thought.
Themes.
The main theme of Ephesians is “the Church, which is the Body of Christ.”
The Church is to maintain the unity in practice which Christ has brought about positionally. According to New Testament scholar Daniel Wallace, the theme may be stated pragmatically as “Christians, get along with each other! Maintain the unity practically which Christ has effected positionally by his death.”
Another major theme in Ephesians is the keeping of Christ's body (that is, the Church) pure and holy. 
From Ephesians 4:17–6:20 the author of the Epistle to the Ephesians gives practical advice in how to live a holy, pure, and Christ-inspired lifestyle. Many devotional thoughts and sermons that are addressed to the practically minded individual have been drawn from this section of the New Testament, due to its nature as being good for application studies.
Composition.
According to tradition, the Apostle Paul wrote the letter while he was in prison in Rome (around AD 62). This would be about the same time as the Epistle to the Colossians (which in many points it resembles) and the Epistle to Philemon. However many critical scholars have questioned the authorship of the letter and suggest that it may have been written between AD 80 and 100.
Authenticity.
The first verse in the letter, according to the late manuscripts used in most English translations, reads, "Paul, an apostle of Christ Jesus by the will of God, To the saints in Ephesus, the faithful in Christ Jesus." ( NIV). Hence, the letter identifies Paul as its author, and these manuscripts designate the Ephesian church as its recipient. Ephesians is found in the two earliest canons, and many of the early Church Fathers (including Clement of Rome, Ignatius, Hermas, and Polycarp) support Paul's authorship. However, there are a few problems with this traditional position, including:
There are four main theories in biblical scholarship that address the question of Pauline authorship.
The lack of any internal references to Ephesus in the early manuscripts may have led Marcion, a second-century heretic who created the first New Testament canon, to believe that the letter was actually addressed to the church at Laodicea, for details see Epistle to the Laodiceans. The view is not uncommon in later traditions either, considering that the content of the letter seems to suggest a similar socio-critical context to the Laodicean church mentioned in the Revelation of John.
Place, date, and purpose of the writing of the letter.
"This was probably a circular letter to be read in more than one place...Most likely, the author did not know the readers personally (see 1:15, 3:2–4, and 6:23–24). According to Acts, Paul spent better than two years in Ephesus and was emotionally attached to the believers there. If this letter were to Ephesus, one would expect it to have more of the warmth evidenced in Philippians...We may safely assume the letter was a general letter to Gentile believers in southwestern Asia Minor and that it became identified with Ephesus as the most important city between Rome and Antioch." (NIV application commentary; Klyne Snodgrass; p. 21)
If Paul was the author of the letter, then it was probably written from Rome during Paul's first imprisonment (; ; ), and probably soon after his arrival there in the year 62, four years after he had parted with the Ephesian elders at Miletus. However, scholars who dispute Paul's authorship date the letter to between 70–80 AD. In the latter case, the possible location of the authorship could have been within the church of Ephesus itself. Ignatius of Antioch himself seemed to be very well versed in the epistle to the Ephesians, and mirrors many of his own thoughts in his own epistle to the Ephesians.
The major theme of the letter is the unity and reconciliation of the whole of creation through the agency of the Church and, in particular, its foundation in Christ as part of the will of the Father.
In the Epistle to the Romans, Paul writes from the point of view of the demonstration of the righteousness of God — his covenant faithfulness and saving justice — in the gospel; the author of Ephesians writes from the perspective of union with Christ, who is the head of the true church.
Outline.
Ephesians contains:
Founding of the church at Ephesus.
Paul's first and hurried visit for the space of three months to Ephesus is recorded in . The work he began on this occasion was carried forward by Apollos and Aquila and Priscilla. On his second visit early in the following year, he remained at Ephesus "three years," for he found it was the key to the western provinces of Asia Minor. Here "a great door and effectual" was opened to him, and the church was established and strengthened by his diligent labours there. From Ephesus the gospel spread abroad "almost throughout all Asia." The word "mightily grew and prevailed" despite all the opposition and persecution he encountered.
On his last journey to Jerusalem, the apostle landed at Miletus and, summoning together the elders of the church from Ephesus, delivered to them a farewell charge, expecting to see them no more.
The following parallels between this epistle and the Milesian charge may be traced:
Purpose.
The purpose of the epistle, and to whom it was written, are matters of much speculation. It was regarded by C.H. Dodd as the "crown of Paulinism." In general, it is born out of its particular socio-historical context and the situational context of both the author and the audience. Originating in the circumstance of a multicultural church (primarily Jewish and Hellenistic), the author addressed issues appropriate to the diverse religious and cultural backgrounds present in the community.
Paul exhorts the church repeatedly to embrace a specific view of salvation, which he then explicates. It seems most likely that Paul's Christology of sacrifice is the manner in which he intends to effect an environment of peace within the church. In short: "If Christ was sacrificed for your sake, be like him and be in submission to one another." Paul addresses hostility, division, and self-interest more than any other topic in the letter, leading many scholars to believe that his primary concern was not doctrinal, but behavioral.
Some theologians, such as Frank Charles Thompson, agree the main theme of Ephesians is in response to the newly converted Jews who often separated themselves from their Gentile brethren. The unity of the church, especially between Jew and Gentile believers, is the keynote of the book. This is shown by the recurrence of such words and phrases as:
Together: made alive together; raised up together, sitting together; built together.
One, indicating unity: one new man, one body, one Spirit, one hope, one Lord, one faith, one baptism, one God and Father of all.
The Pauline theme of unity based on a sacrificial Christology may also be noted in the epistle to the Philippians.
Interpretations.
Ephesians is notable for its domestic code treatment in , covering husband-wife, parent-child, and master-slave relationships. In , wives are urged to submit to their husbands, and husbands to love their wives "as Christ loved the Church." Christian Egalitarian theologians, such as Katharine Bushnell and Jesse Penn-Lewis, interpret these commands in the context of the preceding verse, for all Christians to "submit to one another." Thus, it is two-way, mutual submission of both husbands to wives and wives to husbands. But according to Peter O'Brien, Professor Emeritus at Moore Theological College, this would be the only instance of this meaning of submission in the whole New Testament, indeed in any extant comparable Greek texts; by O'Brien's account, the word simply does not connote mutuality. Dallas Theological Seminary professor Daniel Wallace understands it to be an extension of on being filled by the Holy Spirit.
In the context leading up to the American Civil War (1861–65), on master-slave relationships was one of the Bible verses used by Confederate slaveholders in support of a slaveholding position.

</doc>
<doc id="9872" url="https://en.wikipedia.org/wiki?curid=9872" title="Electric bus (disambiguation)">
Electric bus (disambiguation)

Electric bus is a bus powered by electric energy. "Electric bus" can also refer to:

</doc>
<doc id="9875" url="https://en.wikipedia.org/wiki?curid=9875" title="Exploit (computer security)">
Exploit (computer security)

An exploit (from the English verb "to exploit", meaning "using something to one’s own advantage") is a piece of software, a chunk of data, or a sequence of commands that takes advantage of a bug or vulnerability in order to cause unintended or unanticipated behavior to occur on computer software, hardware, or something electronic (usually computerized). Such behavior frequently includes things like gaining control of a computer system, allowing privilege escalation, or a denial-of-service attack.
Classification.
There are several methods of classifying exploits. The most common is by how the exploit contacts the vulnerable software. A "remote exploit" works over a network and exploits the security vulnerability without any prior access to the vulnerable system. A "local exploit" requires prior access to the vulnerable system and usually increases the privileges of the person running the exploit past those granted by the system administrator. Exploits against client applications also exist, usually consisting of modified servers that send an exploit if accessed with a client application. Exploits against client applications may also require some interaction with the user and thus may be used in combination with the social engineering method. Another classification is by the action against the vulnerable system; unauthorized data access, arbitrary code execution, and denial of service are examples. Many exploits are designed to provide superuser-level access to a computer system. However, it is also possible to use several exploits, first to gain low-level access, then to escalate privileges repeatedly until one reaches root. Normally a single exploit can only take advantage of a specific software vulnerability. Often, when an exploit is published, the vulnerability is fixed through a patch and the exploit becomes obsolete until newer versions of the software become available. This is the reason why some black hat hackers do not publish their exploits but keep them private to themselves or other hackers. Such exploits are referred to as "zero day exploits" and to obtain access to such exploits is the primary desire of unskilled attackers, often nicknamed script kiddies.
Types.
Exploits are commonly categorized and named by these criteria:
Pivoting.
Pivoting refers to a method used by penetration testers that uses the compromised system to attack other systems on the same network to avoid restrictions such as firewall configurations, which may prohibit direct access to all machines. For example, if an attacker compromises a web server on a corporate network, the attacker can then use the compromised web server to attack other systems on the network. These types of attacks are often called multi-layered attacks. Pivoting is also known as "island hopping".
Pivoting can further be distinguished into proxy pivoting and VPN pivoting:
Typically, the proxy or VPN applications enabling pivoting are executed on the target computer as the payload (software) of an exploit.

</doc>
<doc id="9877" url="https://en.wikipedia.org/wiki?curid=9877" title="Erg">
Erg

The erg is a unit of energy and work equal to 10−7 joules. It originated in the centimetre–gram–second (CGS) system of units. It has the symbol "erg". The erg is not an SI unit. Its name is derived from "ergon" (’έργον) a Greek word meaning "work or task".
An erg is the amount of work done by a force of one dyne exerted for a distance of one centimeter. In the CGS base units, it is equal to one gram centimeter-squared per second-squared (g·cm2/s2). It is thus equal to 10−7 joules or 100 nanojoules (nJ) in SI units. An erg is approximately the amount of work done (or energy consumed) by one common house fly performing one "push up", the leg-bending dip that brings its mouth to the surface on which it stands and back up.
1 erg = 10−7 J = 100 nJ
1 erg = 10−10sn·m = 100 psn·m = 100 picosthène-metres
1 erg = 624.15 GeV = 
1 erg = 1 dyne cm = 1 g·cm2/s2
History.
In 1864, Rudolf Clausius proposed the Greek word ("") "ergon" for the unit of energy, work and heat. In 1873, a committee of the British Association for the Advancement of Science, including British physicists James Clerk Maxwell and William Thomson defined the C.G.S. System of Units, and recommended the name "erg" or "ergon" for the C.G.S. unit of energy.
In 1922, William Draper Harkins proposed the name micri-erg as a convenient unit to measure the surface energy of molecules in surface chemistry. It would equate to 10−14 erg, the equivalent to 10−21 joule.

</doc>
<doc id="9878" url="https://en.wikipedia.org/wiki?curid=9878" title="Everway">
Everway

Everway is a fantasy role-playing game first published by Wizards of the Coast under their Alter Ego brand in the mid-1990s. Its lead designer was Jonathan Tweet. Marketed as a "Visionary Roleplaying Game", it has often been characterized as an innovative piece with a limited commercial success. Wizards later abandoned the line, and Rubicon Games purchased it, and published several supplements. The line was sold again to Gaslight Press in February 2001.
The game has a fantasy setting of the multiverse type, with many different worlds, some of which differed from generic fantasy. It appears to have been heavily influenced by divinatory tarot, the four classical elements of ancient Greece, and mythologies from around the world.
Everway was first with implementing, in a commercial game, several new concepts including much more picture-based/visual source material and character creation than usual. Like other works by Jonathan Tweet, the rules are very simple and flexible. It is also one of a few diceless role-playing games. Although the Fortune Deck works as a randomizer, the results obtained by it are entirely arbitrary and subjective, and the GM's absolute power over the game is further emphasized by the three resolution systems: Karma (the higher character ability wins, modified by situation), Drama (the GM decides what happens, by what they think most appropriate), and Fortune (more or less the same as the above, with interpretation flavored by a card draw). The original edition contained the "Fortune" deck of thirty-six cards, used for "divination" and action-resolution, as well as ninety "Vision" cards used as source material. Each Vision card depicts a fantastic scene of some sort and is backed with a series of leading questions such as, "What does this person most enjoy?" or "What's the worst thing that could happen in this situation?" The game's box also had three books of source material and game-playing tips: a Player's Guide, Game Master's Guide, and Guide to the Fortune Deck.
The Fortune cards were illustrated by Scott Kirschner and Jeff Miracola.
Setting.
The official setting for Everway revolves around heroes with the power of "spherewalking," traveling between worlds called "spheres." Spheres typically consist of many "realms." The city of Everway is located in a realm called Roundwander, in the sphere called Fourcorner. Roundwander is the only realm in Fourcorner that is described. There is some detail on the sphere's main city, Everway, which contains a stone pyramid, a set of family-oriented guilds, and various exotic events related to the city's position as an inter-dimensional trading center. Several dozen other spheres are described as one-sentence blurbs, a few as page-long summaries, and one in detail as the setting for a sample adventure, "Journey to Stonekeep." The theme is strongly fantasy-oriented as opposed to science fictional, with advanced technology explicitly forbidden in the character creation rules. The authors gave significant thought to anthropology by describing how the people of various spheres live, including many similarities across cultures. Some of these common features are entirely realistic (language, art), and others plainly related to the game's fantasy elements (magic, knowledge of the Fortune Deck). Nearly all spheres are inhabited by humans, with mostly realistic physics.
Character creation.
Character design is abstract and simple by most role-playing games' standards. Each character begins with twenty points to divide between four Element scores roughly equivalent to statistics for Strength (Fire), Perception (Water), Intelligence (Air) and Endurance (Earth). Scores range from 1 (pathetic) to 3 (average) to 10 (godlike), so a generic hero would have scores of 5. Each Element also has a specialty for which a character can get a 1-point bonus; e.g., a 5-Air hero with an Air specialty of "Writing" could write as though their Air score were 6. As a general rule a statistic of N is twice as capable as a level of N-1, where this makes sense. (A 5-Fire, 5-Earth hero can typically defeat two 4-Fire, 5-Earth enemies, or handily defeat a 3-Fire, 5-Earth character in foot race, but cannot necessarily run twice as fast even though speed is governed by Fire.)
Each character also has Powers representing unusual abilities. These cost from 0 to 3 or more points depending on whether they should be considered Frequent, Major (or even "Twice Major", for especially powerful abilities that significantly affect gameplay) and/or Versatile. For instance, a "Cat Familiar," a slightly intelligent cat, is arguably worth 2 points for being Frequent (usually around and often useful) and Versatile (able to scout, carry messages, and fight). A "Winning Smile" that makes the hero likable is worth 0 points because of its trivial effect, while a "Charming Song" that inspires one emotion when played might be useful enough to count as Frequent (1 point). There is no strict rule for deciding what a Power is worth. Each hero can have one 0-point Power for free; additional Powers that would otherwise cost 0 points instead cost 1.
Magic is also abstract. A hero wanting access to magic, as opposed to a few specific Powers, must design their own magic system. This is done by choosing an Element for its basis, which affects its theme; e.g., Air is associated with speech and intellect and would be suitable for a system of spoken spells gained through study. The new Magic statistic has a 1–10 rating and point cost, and can be no higher than the Element on what it is based. The game's rules suggest listing examples of what the magic system can do at each power level, working these out with the GM. It is suggested that most characters do not need magic and that it is not suitable for new players.
Finally, each hero has personality traits based on the game's Fortune and Vision cards. Players are to choose one or more Vision cards and base a backstory on them, and to have three Fortune cards representing a Virtue, Fault, and Fate (a challenge they will face). These three cards can change to represent new phases in the hero's life. There is a list of suggested Motives for why the hero is adventuring, such as "Adversity" or "Wanderlust", but this feature has no gameplay effect.
Equipment such as weaponry is handled completely abstractly, with no specific rules for item cost, carrying capacity, or combat statistics. However, a particularly powerful piece of equipment—for example, a cloak that renders its wearer invisible for a brief period—may be treated as a Power that the hero must spend their initial element points on.
The Fortune Deck.
To decide what happens, the GM considers the rules of Karma (characters' statistics and Powers), Drama (the needs of the plot), and Fortune, the result of a card drawn from the Fortune Deck. Many of these cards are based on the "Major Arcana" of tarot divination, such as "The Fool" and "Death", but the deck includes original cards such as "Drowning in Armor" and "Law." As with the Tarot deck there is symbolic art and each card has two complementary meanings when upright or reversed (while face up). The meanings are printed on the cards (e.g., "Protective Measures Turn Dangerous" vs. "True Prudence" for "Drowning in Armor") and explained more fully in the game's books. The rules are flexible about how often the GM should consult the Fortune Deck, whether the cards should be shown to players, and how much influence the draw should have—it is entirely acceptable for the GM to never use the deck at all, if she so desires. Though cards sometimes have obvious interpretations for the context in which they are drawn, the rules explain that sometimes they are best read simply as "a positive (or negative) result."
Although the Fortune Deck resembles (and can be used as) a fortune-telling device, Everway treats the Deck only as a storytelling device and an element of the fictional setting. It does not in any way endorse "real" fortune-telling or other supernatural concepts.

</doc>
<doc id="9883" url="https://en.wikipedia.org/wiki?curid=9883" title="Eurocard (printed circuit board)">
Eurocard (printed circuit board)

Eurocard is a European standard format for PCB cards that can be plugged together into a standardized subrack. The subrack consists of a series of slotted card guides on the top and bottom, into which the cards are slid so they stand on end, like books on a shelf. At the "back" of each card is one or more connectors, which plug into mating connectors on a backplane that closes the rear of the subrack.
Dimensions.
As the cards are assumed to be installed in a vertical orientation, the usual meanings of height and width are transposed: A card might be 233.35 mm "high", but only 20 mm "wide". Height is measured in rack units, "U", with 1 U being . This dimension refers to the subrack in which the card is to be mounted, rather than the card itself. 
Enclosure heights are multiples of 3U, with the cards always shorter than the enclosure. Two common heights are 3U (a 100 mm card in a subrack) and 6U (a 233.35 mm card in a high subrack). As two 3U cards are shorter than a 6U card (by 33.35 mm), it is possible to install two 3U cards in one slot of a 6U subrack, with a mid-height structure for proper support. 
Card widths are specified in horizontal pitch units "HP", with 1 HP being .
Card depths start at and increase in increments. The most common today is , but standard hardware is available for depths of , , , , , and .
Standards and architecture.
The Eurocard mechanical architecture was defined originally under IEC-60297-3. Today, the most widely recognized standards for this mechanical structure are IEEE 1101.1, IEEE 1101.10 (also known commonly as "dot ten") and IEEE 1101.11. IEEE 1101.10 covers the additional mechanical and electromagnetic interference features required for VITA 1.1-1997(R2002), which is the VME64 Extensions standard, as well as PICMG 2.0 (R3.0), which is the CompactPCI specification.
The IEEE 1101.11 standard covers rear plug-in units that are also called rear transition modules or RTMs.
The Eurocard is a mechanical system and does not define the specific connector to be used or the signals that are assigned to connector contacts.
The connector systems that are commonly used with Eurocard architectures include the original DIN 41612 connector that is also standardized as IEC 60603.2. This is the connector that is used for the VMEbus standard, which was IEEE 1014. The connector known as the 5-row DIN, which is used for the VME64 Extensions standard is IEC 61076-4-113. The VME64 Extension architecture defined by VITA 1.1-1997 (R2002).
Another popular computer architecture that utilizes the 6U-160 Eurocard is CompactPCI and CompactPCI Express. These are defined by PICMG 2.0R3 and PICMG Exp0 R1 respectively. Other computer architectures that utilize the Eurocard system are VME eXtensions for Instrumentation (VXI), PCI eXtensions for Instrumentation (PXI), and PXI Express.
A computer architecture that used the 6U-220 Eurocard format was Multibus-II, which was IEEE 1296.
Because the Eurocard system provided for so many modular card sizes and because connector manufacturers have continued to create new connectors that are compatible with this system, it is a popular mechanical standard that is also used for innumerable "one-off" applications.
Conduction-cooled Eurocards are used in military and aerospace applications. They are defined by the IEEE 1101.2-1992 (2001) standard.
The Eurocard standard is also the basis of the "Eurorack" format for modular electronic music synthesizers, popularized by Doepfer and other manufacturers.

</doc>
<doc id="9890" url="https://en.wikipedia.org/wiki?curid=9890" title="Electron counting">
Electron counting

Electron counting is a formalism used for classifying compounds and for explaining or predicting electronic structure and bonding. Many rules in chemistry rely on electron-counting:
Atoms that do not obey their rule are called "electron-deficient" when they have too few electrons to achieve a "noble gas configuration", or "hypervalent" when they have too many electrons. Since these compounds tend to be more reactive than compounds that obey their rule, electron counting is an important tool for identifying the reactivity of molecules.
Counting rules.
Two methods of electron counting are popular and both give the same result. 
Electrons donated by common fragments.
"Special cases".
The numbers of electrons "donated" by some ligands depends on the geometry of the metal-ligand ensemble. Perhaps the most famous example of this complication is the M–NO entity. When this grouping is linear, the NO ligand is considered to be a three-electron ligand. When the M–NO subunit is strongly bent at N, the NO is treated as a pseudohalide and is thus a one electron (in the neutral counting approach). The situation is not very different from the "η"3 versus the "η"1 allyl. Another unusual ligand from the electron counting perspective is sulfur dioxide. 
Examples of electron counting.
These examples show the methods of electron counting, they are a "formalism", and don't have anything to do with "real life" chemical transformations. Most of the 'fragments' mentioned above do not exist as such; they cannot be kept in a bottle: e.g. the neutral C, the tetraanionic C, the neutral Ti, and the tetracationic Ti are not "free" species, they are always bound to something, for neutral C, it is commonly found in graphite, charcoal, diamond (sharing electrons with the neighboring carbons), as for Ti which can be found as its metal (where it shares its electrons with neighboring Ti atoms), C4− and Ti4+ 'exist' only with appropriate counterions (with which they probably share electrons). So these formalisms are only used to predict stabilities or properties of compounds!

</doc>
<doc id="9891" url="https://en.wikipedia.org/wiki?curid=9891" title="Entropy">
Entropy

In thermodynamics, entropy (usual symbol S) is a measure of the number of specific realizations or microstates that may realize a thermodynamic system in a defined state specified by macroscopic variables. Most understand entropy as a measure of molecular disorder within a macroscopic system. The second law of thermodynamics states that an isolated system's entropy never decreases. Such a system spontaneously evolves towards thermodynamic equilibrium, the state with maximum entropy. Non-isolated systems may lose entropy, provided they increase their environment's entropy by that increment. Since entropy is a state function, the change in entropy of a system is constant for any process with known initial and final states. This applies whether the process is reversible or irreversible. However, irreversible processes increase the combined entropy of the system and its environment.
The change in entropy (ΔS) of a system was originally defined for a thermodynamically reversible process as
where is the absolute temperature of the system, dividing an incremental reversible transfer of heat into that system (). (If heat is transferred out the sign would be reversed giving a decrease in entropy of the system.) The above definition is sometimes called the macroscopic definition of entropy because it can be used without regard to any microscopic description of the contents of a system. The concept of entropy has been found to be generally useful and has several other formulations. Entropy was discovered when it was noticed to be a quantity that behaves as a function of state, as a consequence of the second law of thermodynamics.
Entropy is an extensive property. It has the dimension of energy divided by temperature, which has a unit of joules per kelvin (J K−1) in the International System of Units (or kg m2 s−2 K−1 in terms of base units). But the entropy of a pure substance is usually given as an intensive property — either entropy per unit mass (SI unit: J K−1 kg−1) or entropy per unit amount of substance (SI unit: J K−1 mol−1).
The "absolute" entropy ("S" rather than Δ"S") was defined later, using either statistical mechanics or the third law of thermodynamics.
In the modern microscopic interpretation of entropy in statistical mechanics, entropy is the amount of additional information needed to specify the exact physical state of a system, given its thermodynamic specification. Understanding the role of thermodynamic entropy in various processes requires an understanding of how and why that information changes as the system evolves from its initial to its final condition. It is often said that entropy is an expression of the disorder, or randomness of a system, or of our lack of information about it. The second law is now often seen as an expression of the fundamental postulate of statistical mechanics through the modern definition of entropy.
History.
The French mathematician Lazare Carnot proposed in his 1803 paper "Fundamental Principles of Equilibrium and Movement" that in any machine the accelerations and shocks of the moving parts represent losses of "moment of activity". In other words, in any natural process there exists an inherent tendency towards the dissipation of useful energy. Building on this work, in 1824 Lazare's son Sadi Carnot published "Reflections on the Motive Power of Fire" which posited that in all heat-engines, whenever "caloric" (what is now known as heat) falls through a temperature difference, work or motive power can be produced from the actions of its fall from a hot to cold body. He made the analogy with that of how water falls in a water wheel. This was an early insight into the second law of thermodynamics. Carnot based his views of heat partially on the early 18th century "Newtonian hypothesis" that both heat and light were types of indestructible forms of matter, which are attracted and repelled by other matter, and partially on the contemporary views of Count Rumford who showed (1789) that heat could be created by friction as when cannon bores are machined. Carnot reasoned that if the body of the working substance, such as a body of steam, is returned to its original state at the end of a complete engine cycle, that "no change occurs in the condition of the working body".
The first law of thermodynamics, deduced from the heat-friction experiments of James Joule in 1843, expresses the concept of energy, and its conservation in all processes; the first law, however, is unable to quantify the effects of friction and dissipation.
In the 1850s and 1860s, German physicist Rudolf Clausius objected to the supposition that no change occurs in the working body, and gave this "change" a mathematical interpretation by questioning the nature of the inherent loss of usable heat when work is done, e.g. heat produced by friction. Clausius described entropy as the "transformation-content", i.e. dissipative energy use, of a thermodynamic system or working body of chemical species during a change of state. This was in contrast to earlier views, based on the theories of Isaac Newton, that heat was an indestructible particle that had mass.
Later, scientists such as Ludwig Boltzmann, Josiah Willard Gibbs, and James Clerk Maxwell gave entropy a statistical basis. In 1877 Boltzmann visualized a probabilistic way to measure the entropy of an ensemble of ideal gas particles, in which he defined entropy to be proportional to the logarithm of the number of microstates such a gas could occupy. Henceforth, the essential problem in statistical thermodynamics, i.e. according to Erwin Schrödinger, has been to determine the distribution of a given amount of energy E over N identical systems.
Carathéodory linked entropy with a mathematical definition of irreversibility, in terms of trajectories and integrability.
Definitions and descriptions.
There are two related definitions of entropy: the thermodynamic definition and the statistical mechanics definition. Historically, the classical thermodynamics definition developed first. In the classical thermodynamics viewpoint, the system is composed of very large numbers of constituents (atoms, molecules) and the state of the system is described by the average thermodynamic properties of those constituents; the details of the system's constituents are not directly considered, but their behavior is described by macroscopically averaged properties, e.g. temperature, pressure, entropy, heat capacity. The early classical definition of the properties of the system assumed equilibrium. The classical thermodynamic definition of entropy has more recently been extended into the area of non-equilibrium thermodynamics. Later, the thermodynamic properties, including entropy, were given an alternative definition in terms of the statistics of the motions of the microscopic constituents of a system — modeled at first classically, e.g. Newtonian particles constituting a gas, and later quantum-mechanically (photons, phonons, spins, etc.). The statistical mechanics description of the behavior of a system is necessary as the definition of the properties of a system using classical thermodynamics become an increasingly unreliable method of predicting the final state of a system that is subject to some process.
Function of state.
There are many thermodynamic properties that are functions of state. This means that at a particular thermodynamic state (which should not be confused with the microscopic state of a system), these properties have a certain value. Often, if two properties of the system are determined, then the state is determined and the other properties' values can also be determined. For instance, a quantity of gas at a particular temperature and pressure has its state fixed by those values, and has a particular volume that is determined by those values. As another instance, a system composed of a pure substance of a single phase at a particular uniform temperature and pressure is determined (and is thus a particular state) and is at not only a particular volume but also at a particular entropy. The fact that entropy is a function of state is one reason it is useful. In the Carnot cycle, the working fluid returns to the same state it had at the start of the cycle, hence the line integral of any state function, such as entropy, over the cycle is zero.
Reversible process.
Entropy is defined for a reversible process and for a system that, at all times, can be treated as being at a uniform state and thus at a uniform temperature. Reversibility is an ideal that some real processes approximate and that is often presented in study exercises. For a reversible process, entropy behaves as a conserved quantity and no change occurs in total entropy. More specifically, total entropy is conserved in a reversible process and not conserved in an irreversible process. One has to be careful about system boundaries. For example, in the Carnot cycle, while the heat flow from the hot reservoir to the cold reservoir represents an increase in entropy, the work output, if reversibly and perfectly stored in some energy storage mechanism, represents a decrease in entropy that could be used to operate the heat engine in reverse and return to the previous state, thus the "total" entropy change is still zero at all times if the entire process is reversible. Any process that does not meet the requirements of a reversible process must be treated as an irreversible process, which is usually a complex task. An irreversible process increases entropy.
Heat "transfer" situations require two or more non-isolated systems in thermal contact. In irreversible heat transfer, heat energy is irreversibly transferred from the higher temperature system to the lower temperature system, and the combined entropy of the systems increases. Each system, by definition, must have its own absolute temperature applicable within all areas in each respective system in order to calculate the entropy transfer. Thus, when a system at higher temperature transfers heat to a system of lower temperature , the former loses entropy and the latter gains entropy . Since , it follows that , whence there is a net gain in the combined entropy.
Carnot cycle.
The concept of entropy arose from Rudolf Clausius's study of the Carnot cycle. In a Carnot cycle, heat is absorbed at temperature from a 'hot' reservoir (an isothermal process), and given up as heat to a 'cold' reservoir (isothermal process) at . According to Carnot's principle, work can only be produced by the system when there is a temperature difference, and the work should be some function of the difference in temperature and the heat absorbed (). Carnot did not distinguish between and , since he was using the incorrect hypothesis that caloric theory was valid, and hence heat was conserved (the incorrect assumption that and were equal) when, in fact, is greater than . Through the efforts of Clausius and Kelvin, it is now known that the maximum work that a system can produce is the product of the Carnot efficiency and the heat absorbed from the hot reservoir:
In order to derive the Carnot efficiency, (a number less than one), Kelvin had to evaluate the ratio of the work output to the heat absorbed during the isothermal expansion with the help of the Carnot-Clapeyron equation which contained an unknown function, known as the Carnot function. The possibility that the Carnot function could be the temperature as measured from a zero temperature, was suggested by Joule in a letter to Kelvin. This allowed Kelvin to establish his absolute temperature scale. It is also known that the work produced by the system is the difference between the heat absorbed from the hot reservoir and the heat given up to the cold reservoir:
Since the latter is valid over the entire cycle, this gave Clausius the hint that at each stage of the cycle, work and heat would not be equal, but rather their difference would be a state function that would vanish upon completion of the cycle. The state function was called the internal energy and it became the first law of thermodynamics.
Now equating () and () gives
or
This implies that there is a function of state which is conserved over a complete cycle of the Carnot cycle. Clausius called this state function "entropy". One can see that entropy was discovered through mathematics rather than through laboratory results. It is a mathematical construct and has no easy physical analogy. This makes the concept somewhat obscure or abstract, akin to how the concept of energy arose.
Clausius then asked what would happen if there should be less work produced by the system than that predicted by Carnot's principle. The right-hand side of the first equation would be the upper bound of the work output by the system, which would now be converted into an inequality
When the second equation is used to express the work as a difference in heats, we get
So more heat is given up to the cold reservoir than in the Carnot cycle. If we denote the entropies by for the two states, then the above inequality can be written as a decrease in the entropy
In other words, the entropy that leaves the system is greater than the entropy that enters the system, implying that some irreversible process prevents the cycle from outputting the maximum amount of work as predicted by the Carnot equation.
The Carnot cycle and efficiency are useful because they define the upper bound of the possible work output and the efficiency of any classical thermodynamic system. Other cycles, such as the Otto cycle, Diesel cycle and Brayton cycle, can be analyzed from the standpoint of the Carnot cycle. Any machine or process that is claimed to produce an efficiency greater than the Carnot efficiency is not viable because it violates the second law of thermodynamics. For very small numbers of particles in the system, statistical thermodynamics must be used. The efficiency of devices such as photovoltaic cells require an analysis from the standpoint of quantum mechanics.
Classical thermodynamics.
The thermodynamic definition of entropy was developed in the early 1850s by Rudolf Clausius and essentially describes how to measure the entropy of an isolated system in thermodynamic equilibrium with its parts. Clausius created the term entropy as an extensive thermodynamic variable that was shown to be useful in characterizing the Carnot cycle. Heat transfer along the isotherm steps of the Carnot cycle was found to be proportional to the temperature of a system (known as its absolute temperature). This relationship was expressed in increments of entropy equal to the ratio of incremental heat transfer divided by temperature, which was found to vary in the thermodynamic cycle but eventually return to the same value at the end of every cycle. Thus it was found to be a function of state, specifically a thermodynamic state of the system. Clausius wrote that he "intentionally formed the word Entropy as similar as possible to the word Energy", basing the term on the Greek ἡ τροπή "tropē", "transformation".
While Clausius based his definition on a reversible process, there are also irreversible processes that change entropy. Following the second law of thermodynamics, entropy of an isolated system always increases. The difference between an isolated system and closed system is that heat may "not" flow to and from an isolated system, but heat flow to and from a closed system is possible. Nevertheless, for both closed and isolated systems, and indeed, also in open systems, irreversible thermodynamics processes may occur.
According to the Clausius equality, for a reversible cyclic process:
formula_9
This means the line integral formula_10 is path-independent.
So we can define a state function "S" called entropy, which satisfies
formula_11
To find the entropy difference between any two states of a system, the integral must be evaluated for some reversible path between the initial and final states. Since entropy is a state function, the entropy change of the system for an irreversible path will be the same as for a reversible path between the same two states. However, the entropy change of the surroundings will be different.
We can only obtain the change of entropy by integrating the above formula. To obtain the absolute value of the entropy, we need the third law of thermodynamics, which states that "S" = 0 at absolute zero for perfect crystals.
From a macroscopic perspective, in classical thermodynamics the entropy is interpreted as a state function of a thermodynamic system: that is, a property depending only on the current state of the system, independent of how that state came to be achieved. In any process where the system gives up energy Δ"E", and its entropy falls by Δ"S", a quantity at least "T"R Δ"S" of that energy must be given up to the system's surroundings as unusable heat ("T"R is the temperature of the system's external surroundings). Otherwise the process will not go forward. In classical thermodynamics, the entropy of a system is defined only if it is in thermodynamic equilibrium.
Statistical mechanics.
The statistical definition was developed by Ludwig Boltzmann in the 1870s by analyzing the statistical behavior of the microscopic components of the system. Boltzmann showed that this definition of entropy was equivalent to the thermodynamic entropy to within a constant number which has since been known as Boltzmann's constant. In summary, the thermodynamic definition of entropy provides the experimental definition of entropy, while the statistical definition of entropy extends the concept, providing an explanation and a deeper understanding of its nature.
The interpretation of entropy in statistical mechanics is the measure of uncertainty, or "mixedupness" in the phrase of Gibbs, which remains about a system after its observable macroscopic properties, such as temperature, pressure and volume, have been taken into account. For a given set of macroscopic variables, the entropy measures the degree to which the probability of the system is spread out over different possible microstates. In contrast to the macrostate, which characterizes plainly observable average quantities, a microstate specifies all molecular details about the system including the position and velocity of every molecule. The more such states available to the system with appreciable probability, the greater the entropy. In statistical mechanics, entropy is a measure of the number of ways in which a system may be arranged, often taken to be a measure of "disorder" (the higher the entropy, the higher the disorder). This definition describes the entropy as being proportional to the natural logarithm of the number of possible microscopic configurations of the individual atoms and molecules of the system (microstates) which could give rise to the observed macroscopic state (macrostate) of the system. The constant of proportionality is the Boltzmann constant.
Specifically, entropy is a logarithmic measure of the number of states with significant probability of being occupied:
where "k"B is the Boltzmann constant, equal to .
The summation is over all the possible microstates of the system, and "pi" is the probability that the system is in the "i"-th microstate. This definition assumes that the basis set of states has been picked so that there is no information on their relative phases. In a different basis set, the more general expression is
where formula_14 is the density matrix, formula_15 is trace (linear algebra) and formula_16 is the matrix logarithm.
This density matrix formulation is not needed in cases of thermal equilibrium so long as the basis states are chosen to be energy eigenstates. For most practical purposes, this can be taken as the fundamental definition of entropy since all other formulas for "S" can be mathematically derived from it, but not vice versa.
In what has been called "the fundamental assumption of statistical thermodynamics" or "the fundamental postulate in statistical mechanics", the occupation of any microstate is assumed to be equally probable (i.e. "P""i" = 1/Ω, where Ω is the number of microstates); this assumption is usually justified for an isolated system in equilibrium. Then the previous equation reduces to
In thermodynamics, such a system is one in which the volume, number of molecules, and internal energy are fixed (the microcanonical ensemble).
The most general interpretation of entropy is as a measure of our uncertainty about a system. The equilibrium state of a system maximizes the entropy because we have lost all information about the initial conditions except for the conserved variables; maximizing the entropy maximizes our ignorance about the details of the system. This uncertainty is not of the everyday subjective kind, but rather the uncertainty inherent to the experimental method and interpretative model.
The interpretative model has a central role in determining entropy. The qualifier "for a given set of macroscopic variables" above has deep implications: if two observers use different sets of macroscopic variables, they will observe different entropies. For example, if observer A uses the variables "U", "V" and "W", and observer B uses "U", "V", "W", "X", then, by changing "X", observer B can cause an effect that looks like a violation of the second law of thermodynamics to observer A. In other words: the set of macroscopic variables one chooses must include everything that may change in the experiment, otherwise one might see decreasing entropy!
Entropy can be defined for any Markov processes with reversible dynamics and the detailed balance property.
In Boltzmann's 1896 "Lectures on Gas Theory", he showed that this expression gives a measure of entropy for systems of atoms and molecules in the gas phase, thus providing a measure for the entropy of classical thermodynamics.
Entropy of a system.
Entropy is the above-mentioned unexpected and, to some, obscure integral that arises directly from the Carnot cycle. It is reversible heat divided by temperature. It is also, remarkably, a fundamental and very useful function of state.
In a thermodynamic system, pressure, density, and temperature tend to become uniform over time because this equilibrium state has higher probability (more possible combinations of microstates) than any other; see statistical mechanics. As an example, for a glass of ice water in air at room temperature, the difference in temperature between a warm room (the surroundings) and cold glass of ice and water (the system and not part of the room), begins to be equalized as portions of the thermal energy from the warm surroundings spread to the cooler system of ice and water. Over time the temperature of the glass and its contents and the temperature of the room become equal. The entropy of the room has decreased as some of its energy has been dispersed to the ice and water. However, as calculated in the example, the entropy of the system of ice and water has increased more than the entropy of the surrounding room has decreased. In an isolated system such as the room and ice water taken together, the dispersal of energy from warmer to cooler always results in a net increase in entropy. Thus, when the "universe" of the room and ice water system has reached a temperature equilibrium, the entropy change from the initial state is at a maximum. The entropy of the thermodynamic system is a measure of how far the equalization has progressed.
Thermodynamic entropy is a non-conserved state function that is of great importance in the sciences of physics and chemistry. Historically, the concept of entropy evolved in order to explain why some processes (permitted by conservation laws) occur spontaneously while their time reversals (also permitted by conservation laws) do not; systems tend to progress in the direction of increasing entropy. For isolated systems, entropy never decreases. This fact has several important consequences in science: first, it prohibits "perpetual motion" machines; and second, it implies the arrow of entropy has the same direction as the arrow of time. Increases in entropy correspond to irreversible changes in a system, because some energy is expended as waste heat, limiting the amount of work a system can do.
Unlike many other functions of state, entropy cannot be directly observed but must be calculated. Entropy can be calculated for a substance as the standard molar entropy from absolute zero (also known as absolute entropy) or as a difference in entropy from some other reference state which is defined as zero entropy. Entropy has the dimension of energy divided by temperature, which has a unit of joules per kelvin (J/K) in the International System of Units. While these are the same units as heat capacity, the two concepts are distinct. Entropy is not a conserved quantity: for example, in an isolated system with non-uniform temperature, heat might irreversibly flow and the temperature become more uniform such that entropy increases. The second law of thermodynamics, states that a closed system has entropy which may increase or otherwise remain constant. Chemical reactions cause changes in entropy and entropy plays an important role in determining in which direction a chemical reaction spontaneously proceeds.
One dictionary definition of entropy is that it is "a measure of thermal energy per unit temperature that is not available for useful work". For instance, a substance at uniform temperature is at maximum entropy and cannot drive a heat engine. A substance at non-uniform temperature is at a lower entropy (than if the heat distribution is allowed to even out) and some of the thermal energy can drive a heat engine.
A special case of entropy increase, the entropy of mixing, occurs when two or more different substances are mixed. If the substances are at the same temperature and pressure, there will be no net exchange of heat or work – the entropy change will be entirely due to the mixing of the different substances. At a statistical mechanical level, this results due to the change in available volume per particle with mixing.
Second law of thermodynamics.
The second law of thermodynamics requires that, in general, the total entropy of any system will not decrease other than by increasing the entropy of some other system. Hence, in a system isolated from its environment, the entropy of that system will tend not to decrease. It follows that heat will not flow from a colder body to a hotter body without the application of work (the imposition of order) to the colder body. Secondly, it is impossible for any device operating on a cycle to produce net work from a single temperature reservoir; the production of net work requires flow of heat from a hotter reservoir to a colder reservoir, or a single expanding reservoir undergoing adiabatic cooling, which performs adiabatic work. As a result, there is no possibility of a perpetual motion system. It follows that a reduction in the increase of entropy in a specified process, such as a chemical reaction, means that it is energetically more efficient.
It follows from the second law of thermodynamics that the entropy of a system that is not isolated may decrease. An air conditioner, for example, may cool the air in a room, thus reducing the entropy of the air of that system. The heat expelled from the room (the system), which the air conditioner transports and discharges to the outside air, will always make a bigger contribution to the entropy of the environment than will the decrease of the entropy of the air of that system. Thus, the total of entropy of the room plus the entropy of the environment increases, in agreement with the second law of thermodynamics.
In mechanics, the second law in conjunction with the fundamental thermodynamic relation places limits on a system's ability to do useful work. The entropy change of a system at temperature "T" absorbing an infinitesimal amount of heat δ"q"
in a reversible way, is given by "δq/T". More explicitly, an energy "TR S" is not available to do useful work, where "TR" is the temperature of the coldest accessible reservoir or heat sink external to the system. For further discussion, see "Exergy".
Statistical mechanics demonstrates that entropy is governed by probability, thus allowing for a decrease in disorder even in an isolated system. Although this is possible, such an event has a small probability of occurring, making it unlikely.
Applications.
The fundamental thermodynamic relation.
The entropy of a system depends on its internal energy and its external parameters, such as its volume. In the thermodynamic limit, this fact leads to an equation relating the change in the internal energy "U" to changes in the entropy and the external parameters. This relation is known as the "fundamental thermodynamic relation". If external pressure "P" bears on the volume "V" as the only external parameter, this relation is:
Since both internal energy and entropy are monotonic functions of temperature "T", implying that the internal energy is fixed when one specifies the entropy and the volume, this relation is valid even if the change from one state of thermal equilibrium to another with infinitesimally larger entropy and volume happens in a non-quasistatic way (so during this change the system may be very far out of thermal equilibrium and then the entropy, pressure and temperature may not exist).
The fundamental thermodynamic relation implies many thermodynamic identities that are valid in general, independent of the microscopic details of the system. Important examples are the Maxwell relations and the relations between heat capacities.
Entropy in chemical thermodynamics.
Thermodynamic entropy is central in chemical thermodynamics, enabling changes to be quantified and the outcome of reactions predicted. The second law of thermodynamics states that entropy in an isolated system – the combination of a subsystem under study and its surroundings – increases during all spontaneous chemical and physical processes. The Clausius equation of δ"q"rev/"T" = Δ"S" introduces the measurement of entropy change, Δ"S". Entropy change describes the direction and quantifies the magnitude of simple changes such as heat transfer between systems – always from hotter to cooler spontaneously.
The thermodynamic entropy therefore has the dimension of energy divided by temperature, and the unit joule per kelvin (J/K) in the International System of Units (SI).
Thermodynamic entropy is an extensive property, meaning that it scales with the size or extent of a system. In many processes it is useful to specify the entropy as an intensive property independent of the size, as a specific entropy characteristic of the type of system studied. Specific entropy may be expressed relative to a unit of mass, typically the kilogram (unit: ). Alternatively, in chemistry, it is also referred to one mole of substance, in which case it is called the "molar entropy" with a unit of .
Thus, when one mole of substance at about is warmed by its surroundings to , the sum of the incremental values of "q"rev/"T" constitute each element's or compound's standard molar entropy, an indicator of the amount of energy stored by a substance at . Entropy change also measures the mixing of substances as a summation of their relative quantities in the final mixture.
Entropy is equally essential in predicting the extent and direction of complex chemical reactions. For such applications, Δ"S" must be incorporated in an expression that includes both the system and its surroundings, Δ"S"universe = Δ"S"surroundings + Δ"S" system. This expression becomes, via some steps, the Gibbs free energy equation for reactants and products in the system: Δ"G" Gibbs free energy change of the system = Δ"H" enthalpy change −"T" Δ"S" entropy change.
Entropy balance equation for open systems.
In chemical engineering, the principles of thermodynamics are commonly applied to "open systems", i.e. those in which heat, work, and mass flow across the system boundary. Flows of both heat (formula_19) and work, i.e. formula_20 (shaft work) and "P(dV/dt)" (pressure-volume work), across the system boundaries, in general cause changes in the entropy of the system. Transfer as heat entails entropy transfer formula_21 where "T" is the absolute thermodynamic temperature of the system at the point of the heat flow. If there are mass flows across the system boundaries, they will also influence the total entropy of the system. This account, in terms of heat and work, is valid only for cases in which the work and heat transfers are by paths physically distinct from the paths of entry and exit of matter from the system.
To derive a generalized entropy balanced equation, we start with the general balance equation for the change in any extensive quantity Θ in a thermodynamic system, a quantity that may be either conserved, such as energy, or non-conserved, such as entropy. The basic generic balance expression states that dΘ/dt, i.e. the rate of change of Θ in the system, equals the rate at which Θ enters the system at the boundaries, minus the rate at which Θ leaves the system across the system boundaries, plus the rate at which Θ is generated within the system. For an open thermodynamic system in which heat and work are transferred by paths separate from the paths for transfer of matter, using this generic balance equation, with respect to the rate of change with time "t" of the extensive quantity entropy "S", the entropy balance equation is:
where
Note, also, that if there are multiple heat flows, the term formula_27 will be replaced by formula_28 where formula_29 is the heat flow and formula_30 is the temperature at the "jth" heat flow port into the system.
Entropy change formulas for simple processes.
For certain simple transformations in systems of constant composition, the entropy changes are given by simple formulas.
Isothermal expansion or compression of an ideal gas.
For the expansion (or compression) of an ideal gas from an initial volume formula_31 and pressure formula_32 to a final volume formula_33 and pressure formula_34 at any constant temperature, the change in entropy is given by:
Here formula_36 is the number of moles of gas and formula_37 is the ideal gas constant. These equations also apply for expansion into a finite vacuum or a throttling process, where the temperature, internal energy and enthalpy for an ideal gas remain constant.
Cooling and heating.
For heating or cooling of any system (gas, liquid or solid) at constant pressure from an initial temperature formula_38 to a final temperature formula_39, the entropy change is
provided that the constant-pressure molar heat capacity (or specific heat) CP is constant and that no phase transition occurs in this temperature interval.
Similarly at constant volume, the entropy change is
where the constant-volume heat capacity Cv is constant and there is no phase change.
At low temperatures near absolute zero, heat capacities of solids quickly drop off to near zero, so the assumption of constant heat capacity does not apply.
Since entropy is a state function, the entropy change of any process in which temperature and volume both vary is the same as for a path divided into two steps - heating at constant volume and expansion at constant temperature. For an ideal gas, the total entropy change is
Similarly if the temperature and pressure of an ideal gas both vary,
Phase transitions.
Reversible phase transitions occur at constant temperature and pressure. The reversible heat is the enthalpy change for the transition, and the entropy change is the enthalpy change divided by the thermodynamic temperature. For fusion (melting) of a solid to a liquid at the melting point "T"m, the entropy of fusion is
Similarly, for vaporization of a liquid to a gas at the boiling point "T"b, the entropy of vaporization is
Approaches to understanding entropy.
As a fundamental aspect of thermodynamics and physics, several different approaches to entropy beyond that of Clausius and Boltzmann are valid.
Standard textbook definitions.
The following is a list of additional definitions of entropy from a collection of textbooks:
In Boltzmann's definition, entropy is a measure of the number of possible microscopic states (or microstates) of a system in thermodynamic equilibrium. Consistent with the Boltzmann definition, the second law of thermodynamics needs to be re-worded as such that entropy increases over time, though the underlying principle remains the same.
Order and disorder.
Entropy has often been loosely associated with the amount of order or disorder, or of chaos, in a thermodynamic system. The traditional qualitative description of entropy is that it refers to changes in the status quo of the system and is a measure of "molecular disorder" and the amount of wasted energy in a dynamical energy transformation from one state or form to another. In this direction, several recent authors have derived exact entropy formulas to account for and measure disorder and order in atomic and molecular assemblies. One of the simpler entropy order/disorder formulas is that derived in 1984 by thermodynamic physicist Peter Landsberg, based on a combination of thermodynamics and information theory arguments. He argues that when constraints operate on a system, such that it is prevented from entering one or more of its possible or permitted states, as contrasted with its forbidden states, the measure of the total amount of "disorder" in the system is given by:
Similarly, the total amount of "order" in the system is given by:
In which "CD" is the "disorder" capacity of the system, which is the entropy of the parts contained in the permitted ensemble, "CI" is the "information" capacity of the system, an expression similar to Shannon's channel capacity, and "CO" is the "order" capacity of the system.
Energy dispersal.
The concept of entropy can be described qualitatively as a measure of energy dispersal at a specific temperature. Similar terms have been in use from early in the history of classical thermodynamics, and with the development of statistical thermodynamics and quantum theory, entropy changes have been described in terms of the mixing or "spreading" of the total energy of each constituent of a system over its particular quantized energy levels.
Ambiguities in the terms "disorder" and "chaos", which usually have meanings directly opposed to equilibrium, contribute to widespread confusion and hamper comprehension of entropy for most students. As the second law of thermodynamics shows, in an isolated system internal portions at different temperatures will tend to adjust to a single uniform temperature and thus produce equilibrium. A recently developed educational approach avoids ambiguous terms and describes such spreading out of energy as dispersal, which leads to loss of the differentials required for work even though the total energy remains constant in accordance with the first law of thermodynamics (compare discussion in next section). Physical chemist Peter Atkins, for example, who previously wrote of dispersal leading to a disordered state, now writes that "spontaneous changes are always accompanied by a dispersal of energy".
Relating entropy to energy "usefulness".
Following on from the above, it is possible (in a thermal context) to regard entropy as an indicator or measure of the "effectiveness" or "usefulness" of a particular quantity of energy. This is because energy supplied at a high temperature (i.e. with low entropy) tends to be more useful than the same amount of energy available at room temperature. Mixing a hot parcel of a fluid with a cold one produces a parcel of intermediate temperature, in which the overall increase in entropy represents a "loss" which can never be replaced.
Thus, the fact that the entropy of the universe is steadily increasing, means that its total energy is becoming less useful: eventually, this will lead to the "heat death of the Universe".
Entropy and adiabatic accessibility.
A definition of entropy based entirely on the relation of adiabatic accessibility between equilibrium states was given by E.H.Lieb and J. Yngvason in 1999. This approach has several predecessors, including the pioneering work of Constantin Carathéodory from 1909 and the monograph by R. Giles from 1964. In the setting of Lieb and Yngvason one starts by picking, for a unit amount of the substance under consideration, two reference states formula_48 and formula_49 such that the latter is adiabatically accessible from the former but not vice versa. Defining the entropies of the reference states to be 0 and 1 respectively the entropy of a state formula_50 is defined as the largest number formula_51 such that formula_50 is adiabatically accessible from a composite state consisting of an amount formula_51 in the state formula_49 and a complementary amount, formula_55, in the state formula_48. A simple but important result within this setting is that entropy is uniquely determined, apart from a choice of unit and an additive constant for each chemical element, by the following properties: It is monotonic with respect to the relation of adiabatic accessibility, additive on composite systems, and extensive under scaling.
Entropy in quantum mechanics.
In quantum statistical mechanics, the concept of entropy was developed by John von Neumann and is generally referred to as "von Neumann entropy",
where ρ is the density matrix and Tr is the trace operator.
This upholds the correspondence principle, because in the classical limit, when the phases between the basis states used for the classical probabilities are purely random, this expression is equivalent to the familiar classical definition of entropy,
i.e. in such a basis the density matrix is diagonal.
Von Neumann established a rigorous mathematical framework for quantum mechanics with his work "Mathematische Grundlagen der Quantenmechanik". He provided in this work a theory of measurement, where the usual notion of wave function collapse is described as an irreversible process (the so-called von Neumann or projective measurement). Using this concept, in conjunction with the density matrix he extended the classical concept of entropy into the quantum domain.
Information theory.
When viewed in terms of information theory, the entropy state function is simply the amount of information (in the Shannon sense) that would be needed to specify the full microstate of the system. This is left unspecified by the macroscopic description.
In information theory, "entropy" is the measure of the amount of information that is missing before reception and is sometimes referred to as "Shannon entropy". Shannon entropy is a broad and general concept which finds applications in information theory as well as thermodynamics. It was originally devised by Claude Shannon in 1948 to study the amount of information in a transmitted message. The definition of the information entropy is, however, quite general, and is expressed in terms of a discrete set of probabilities "pi so that
In the case of transmitted messages, these probabilities were the probabilities that a particular message was actually transmitted, and the entropy of the message system was a measure of the average amount of information in a message. For the case of equal probabilities (i.e. each message is equally probable), the Shannon entropy (in bits) is just the number of yes/no questions needed to determine the content of the message.
The question of the link between information entropy and thermodynamic entropy is a debated topic. While most authors argue that there is a link between the two, a few argue that they have nothing to do with each other.
The expressions for the two entropies are similar. If "W" is the number of microstates that can yield a given macrostate, and each microstate has the same "A priori" probability, then that probability is "p=1/W". The Shannon entropy (in nats) will be:
and if entropy is measured in units of "k" per nat, then the entropy is given by:
which is the famous Boltzmann entropy formula when "k" is Boltzmann's constant, which may be interpreted as the thermodynamic entropy per nat. There are many ways of demonstrating the equivalence of "information entropy" and "physics entropy", that is, the equivalence of "Shannon entropy" and "Boltzmann entropy". Nevertheless, some authors argue for dropping the word entropy for the "H" function of information theory and using Shannon's other term "uncertainty" instead.
Interdisciplinary applications of entropy.
Although the concept of entropy was originally a thermodynamic construct, it has been adapted in other fields of study, including information theory, psychodynamics, thermoeconomics/ecological economics, and evolution.
For instance, an entropic argument has been recently proposed for explaining the preference of cave spiders in choosing a suitable area for laying their eggs.
The arrow of time.
Entropy is the only quantity in the physical sciences that seems to imply a particular direction of progress, sometimes called an arrow of time. As time progresses, the second law of thermodynamics states that the entropy of an isolated system never decreases. Hence, from this perspective, entropy measurement is thought of as a kind of clock.
Cosmology.
Since a finite universe is an isolated system, the Second Law of Thermodynamics states that its total entropy is constantly increasing. It has been speculated, since the 19th century, that the universe is fated to a heat death in which all the energy ends up as a homogeneous distribution of thermal energy, so that no more work can be extracted from any source.
If the universe can be considered to have generally increasing entropy, then – as Sir Roger Penrose has pointed out – gravity plays an important role in the increase because gravity causes dispersed matter to accumulate into stars, which collapse eventually into black holes. The entropy of a black hole is proportional to the surface area of the black hole's event horizon. Jacob Bekenstein and Stephen Hawking have shown that black holes have the maximum possible entropy of any object of equal size. This makes them likely end points of all entropy-increasing processes, if they are totally effective matter and energy traps. However, the escape of energy from black holes might be possible due to quantum activity, see Hawking radiation. Hawking has recently changed his stance on some details, in a paper which largely redefined the event horizons of black holes.
The role of entropy in cosmology remains a controversial subject since the time of Ludwig Boltzmann. Recent work has cast some doubt on the heat death hypothesis and the applicability of any simple thermodynamic model to the universe in general. Although entropy does increase in the model of an expanding universe, the maximum possible entropy rises much more rapidly, moving the universe further from the heat death with time, not closer. This results in an "entropy gap" pushing the system further away from the posited heat death equilibrium. Other complicating factors, such as the energy density of the vacuum and macroscopic quantum effects, are difficult to reconcile with thermodynamical models, making any predictions of large-scale thermodynamics extremely difficult.
The entropy gap is widely believed to have been originally opened up by the early rapid exponential expansion of the universe.
Economics.
Romanian American economist Nicholas Georgescu-Roegen, a progenitor in economics and a paradigm founder of ecological economics, made extensive use of the entropy concept in his magnum opus on "The Entropy Law and the Economic Process". Due to Georgescu-Roegen's work, the laws of thermodynamics now form an integral part of the ecological economics school. Although his work was blemished somewhat by mistakes, a full chapter on the economics of Georgescu-Roegen has approvingly been included in one elementary physics textbook on the historical development of thermodynamics.
In economics, Georgescu-Roegen's work has generated the term 'entropy pessimism'. Since the 1990s, leading ecological economist and steady-state theorist Herman Daly — a student of Georgescu-Roegen — has been the economists profession's most influential proponent of the entropy pessimism position.

</doc>
<doc id="9892" url="https://en.wikipedia.org/wiki?curid=9892" title="Expert">
Expert

An expert () is "somebody who obtains results that are vastly superior to those obtained by the majority of the population". Alternatively, an expert is someone widely recognized as a reliable source of technique or skill whose faculty for judging or deciding rightly, justly, or wisely is accorded authority and status by peers or the public in a specific well-distinguished domain. An expert, more generally, is a person with extensive knowledge or ability based on research, experience, or occupation and in a particular area of study. Experts are called in for advice on their respective subject, but they do not always agree on the particulars of a field of study. An expert can be believed, by virtue of credential, training, education, profession, publication or experience, to have special knowledge of a subject beyond that of the average person, sufficient that others may officially (and legally) rely upon the individual's opinion. Historically, an expert was referred to as a sage (Sophos). The individual was usually a profound thinker distinguished for wisdom and sound judgment.
Experts have a prolonged or intense experience through practice and education in a particular field. In specific fields, the definition of expert is well established by consensus and therefore it is not always necessary for individuals to have a professional or academic qualification for them to be accepted as an expert. In this respect, a shepherd with 50 years of experience tending flocks would be widely recognized as having complete expertise in the use and training of sheep dogs and the care of sheep. Another example from computer science is that an expert system may be taught by a human and thereafter considered an expert, often outperforming human beings at particular tasks. In law, an expert witness must be recognized by argument and authority.
Research in this area attempts to understand the relation between expert knowledge, skills and personal characteristics and exceptional performance. Some researchers have investigated the cognitive structures and processes of experts. The fundamental aim of this research is to describe what it is that experts know and how they use their knowledge to achieve performance that most people assume requires extreme or extraordinary ability. Studies have investigated the factors that enable experts to be fast and accurate.
Expertise.
Expertise characteristics, skills and knowledge of a person (that is, expert) or of a system, which distinguish experts from novices and less experienced people. In many domains there are objective measures of performance capable of distinguishing experts from novices: expert chess players will almost always win games against recreational chess players; expert medical specialists are more likely to diagnose a disease correctly; etc.
The word Expertise is used to refer also to Expert Determination, where an expert is invited to decide a disputed issue. The decision may be binding or advisory, according to the agreement between the parties in dispute.
Academic views on expertise.
There are broadly two academic approaches to the understanding and study of expertise. The first understands expertise as an emergent property of communities of practice. In this view expertise is socially constructed; tools for thinking and scripts for action are jointly constructed within social groups enabling that group jointly to define and acquire expertise in some domain.
In the second view expertise is a characteristic of individuals and is a consequence of the human capacity for extensive adaptation to physical and social environments. Many accounts of the development of expertise emphasize that it comes about through long periods of deliberate practice. In many domains of expertise estimates of 10 years' experience deliberate practice are common. Recent research on expertise emphasizes the nurture side of the nature and nurture argument. Some factors not fitting the nature-nurture dichotomy are biological but not genetic, such as starting age, handedness, and season of birth.
In the field of education there is a potential "expert blind spot" in newly practicing educators who are experts in their content area. This is based on the "expert blind spot hypothesis" researched by Mitchell Nathan and Andrew Petrosino (2003: 906). Newly practicing educators with advanced subject-area expertise of an educational content area tend to use the formalities and analysis methods of their particular area of expertise as a major guiding factor of student instruction and knowledge development, rather than being guided by student learning and developmental needs that are prevalent among novice learners.
The blind spot metaphor refers to the physiological blind spot in human vision in which perceptions of surroundings and circumstances are strongly impacted by their expectations. Beginning practicing educators tend to overlook the importance of novice levels of prior knowledge and other factors involved in adjusting and adapting pedagogy for learner understanding. This expert blind spot is in part due to an assumption that novices’ cognitive schemata are less elaborate, interconnected, and accessible than experts’ and that their pedagogical reasoning skills are less well developed (Borko & Livingston, 1989: 474). Essential knowledge of subject matter for practicing educators consists of overlapping knowledge domains: subject matter knowledge and pedagogical content matter (Borko, Eisenhart, Brown, Underhill, Jones, & Agard, 1992: 195). Pedagogical content matter consists of an understanding of how to represent certain concepts in ways appropriate to the learner contexts, including abilities and interests. The expert blind spot is a pedagogical phenomenon that is typically overcome through educators’ experience with instructing learners over time.
Historical views on expertise.
In line with the socially constructed view of expertise, expertise can also be understood as a form of power; that is, experts have the ability to influence others as a result of their defined social status. By a similar token, a fear of experts can arise from fear of an intellectual elite's power. In earlier periods of history, simply being able to read made one part of an intellectual elite. The introduction of the printing press in Europe during the fifteenth century and the diffusion of printed matter contributed to higher literacy rates and wider access to the once-rarefied knowledge of academia. The subsequent spread of education and learning changed society, and initiated an era of widespread education whose elite would now instead be those who produced the written content itself for consumption, in education and all other spheres.
Plato's "Noble Lie", concerns expertise. Plato did not believe most people were clever enough to look after their own and society's best interest, so the few clever people of the world needed to lead the rest of the flock. Therefore, the idea was born that only the elite should know the truth in its complete form and the rulers, Plato said, must tell the people of the city "the noble lie" to keep them passive and content, without the risk of upheaval and unrest.
In contemporary society, doctors and scientists, for example, are considered to be experts in that they hold a body of dominant knowledge that is, on the whole, inaccessible to the layman (Fuller: 2005: 141). However, this inaccessibility and perhaps even mystery that surrounds expertise does not cause the layman to disregard the opinion of the experts on account of the unknown. Instead, the complete opposite occurs whereby members of the public believe in and highly value the opinion of medical professionals or of scientific discoveries (Fuller: 2005: 144), despite not understanding it.
Research related to expertise.
According to Danyal a number of computational models have been developed in cognitive science to explain the development from novice to expert. In particular, Herbert A. Simon and Kevin Gilmartin proposed a model of learning in chess called MAPP (Memory-Aided Pattern Recognizer). Based on simulations, they estimated that about 50,000 chunks (units of memory) are necessary to become an expert, and hence the many years needed to reach this level. More recently, the CHREST model (Chunk Hierarchy and REtrieval STructures) has simulated in detail a number of phenomena in chess expertise (eye movements, performance in a variety of memory tasks, development from novice to expert) and in other domains.
An important feature of expert performance seems to be the way in which experts are able to rapidly retrieve complex configurations of information from long-term memory. They recognize situations because they have meaning. It is perhaps this central concern with meaning and how it attaches to situations which provides an important link between the individual and social approaches to the development of expertise. Work on "Skilled Memory and Expertise" by Anders Ericsson and James J. Staszewski confronts the paradox of expertise and claims that people not only acquire content knowledge as they practice cognitive skills, they also develop mechanisms that enable them to use a large and familiar knowledge base efficiently.
Work on expert systems (computer software designed to provide an answer to a problem, or clarify uncertainties where normally one or more human experts would need to be consulted) typically is grounded on the premise that expertise is based on acquired repertoires of rules and frameworks for decision making which can be elicited as the basis for computer supported judgment and decision-making. However, there is increasing evidence that expertise does not work in this fashion. Rather, experts recognize situations based on experience of many prior situations. They are in consequence able to make rapid decisions in complex and dynamic situations.
In a critique of the expert systems literature suggest:
Skilled Memory Theory.
The role of long term memory in the skilled memory effect was first articulated by Chase and Simon in their classic studies of chess expertise. They asserted that organized patterns of information stored in long term memory (chunks) mediated experts' rapid encoding and superior retention. Their study revealed that all subjects retrieved about the same number of chunks, but the size of the chunks varied with subjects' prior experience. Experts' chunks contained more individual pieces than those of novices. This research did not investigate how experts find, distinguish, and retrieve the right chunks from the vast number they hold without a lengthy search of long term memory.
Skilled memory enables experts to rapidly encode, store, and retrieve information within the domain of their expertise and thereby circumvent the capacity limitations that typically constrain novice performance. For example, it explains experts' ability to recall large amounts of material displayed for only brief study intervals, provided that the material comes from their domain of expertise. When unfamiliar material (not from their domain of expertise) is presented to experts, their recall is no better than that of novices.
The first principle of skilled memory, the "meaningful encoding principle," states that experts exploit prior knowledge to durably encode information needed to perform a familiar task successfully. Experts form more elaborate and accessible memory representations than novices. The elaborate semantic memory network creates meaningful memory codes that create multiple potential cues and avenues for retrieval.
The second principle, the "retrieval structure principle" states that experts develop memory mechanisms called retrieval structures to facilitate the retrieval of information stored in long term memory. These mechanisms operate in a fashion consistent with the meaningful encoding principle to provide cues that can later be regenerated to retrieve the stored information efficiently without a lengthy search.
The third principle, the "speed up principle" states that long term memory encoding and retrieval operations speed up with practice, so that their speed and accuracy approach the speed and accuracy of short term memory storage and retrieval.
Examples of skilled memory research described within the Ericcson and Stasewski study include:
Expertise in problem solving.
Much of the research regarding expertise involves the studies of how experts and novices differ in solving problems (Chi, M. T. H., Glasser R., & Rees, E.,1982). Mathematics (Sweller, J., Mawer, R. F., & Ward, M. R., 1983) and physics (Chi, Feltovich, & Glaser, 1981) are common domains for these studies.
One of the most cited works in this area, Chi et al. (1981), examines how experts (PhD students in physics) and novices (undergraduate students that completed one semester of mechanics) categorize and represent physics problems. They found that novices sort problems into categories based upon surface features (e.g., keywords in the problem statement or visual configurations of the objects depicted). Experts, however, categorize problems based upon their deep structures (i.e., the main physics principle used to solve the problem).
Their findings also suggest that while the schemas of both novices and experts are activated by the same features of a problem statement, the experts’ schemas contain more procedural knowledge which aid in determining which principle to apply, and novices’ schemas contain mostly declarative knowledge which do not aid in determining methods for solution.
Germain's Expertise Scale.
Relative to a specific field, an expert has:
Marie-Line Germain (Germain, 2006) developed a psychometric measure of perception of employee expertise called the Generalized Expertise Measure (GEM). She defined a behavioral dimension in experts, in addition to the dimensions suggested by Swanson and Holton (2001). Her 16-item scale contains objective expertise items and subjective expertise items. Objective items were named Evidence-Based items. Subjective items (the remaining 11 items from the measure below) were named Self-Enhancement items because of their behavioral component.
(Condensed from Germain, 2006).
Rhetoric.
Scholars in rhetoric have also turned their attention to the concept of the expert. Considered an appeal to ethos or "the personal character of the speaker", established expertise allows a speaker to make statements regarding special topics of which the audience may be ignorant. In other words, the expert enjoys the deference of the audience’s judgment and can appeal to authority where a non-expert cannot.
In The rhetoric of expertise, E. Johanna Hartelius defines two basic modes of expertise: autonomous and attributed expertise. While an autonomous expert can "possess expert knowledge without recognition from other people," attributed expertise is "a performance that may or may not indicate genuine knowledge." With these two categories, Hartelius isolates the rhetorical problems faced by experts: just as someone with autonomous expertise may not possess the skill to persuade people to hold their points of view, someone with merely attributed expertise may be persuasive but lack the actual knowledge pertaining to a given subject. The problem faced by audiences follows from the problem facing experts: when faced with competing claims of expertise, what resources do non-experts have to evaluate claims put before them?
Hartelius and other scholars have also noted the challenges that projects such as Wikipedia pose to how experts have traditionally constructed their authority. In "Wikipedia and the Emergence of Dialogic Expertise", she highlights Wikipedia as an example of the "dialogic expertise" made possible by collaborative digital spaces. Predicated upon the notion that "truth emerges from dialogue", Wikipedia challenges traditional expertise both because anyone can edit it and because no single person, regardless of their credentials, can end a discussion by fiat. In other words, the community, rather than single individuals, direct the course of discussion. The production of knowledge, then, as a process of dialogue and argumentation, becomes an inherently rhetorical activity.
Building on Hartelius, Damien Pfister developed the concept of "networked expertise". Noting that Wikipedia employs a "many to many" rather than a "one to one" model of communication, he notes how expertise likewise shifts to become a quality of a group rather than an individual. With the information traditionally associated with individual experts now stored within a text produced by a collective, knowing about something is less important than knowing how to find something. As he puts it, "With the internet, the historical power of subject matter expertise is eroded: the archival nature of the Web means that what and how to information is readily available." The rhetorical authority previously afforded to subject matter expertise, then, is given to those with the procedural knowledge of how to find information called for by a situation.
Contrasts and comparisons.
Associated terms.
An expert differs from the specialist in that a specialist has to "be able to solve" a problem and an expert has to "know its solution". The opposite of an expert is generally known as a layperson, while someone who occupies a middle grade of understanding is generally known as a technician and often employed to assist experts. A person may well be an expert in one field and a layperson in many other fields. The concepts of experts and expertise are debated within the field of epistemology under the general heading of expert knowledge. In contrast, the opposite of a specialist would be a generalist or polymath.
The term is widely used informally, with people being described as 'experts' in order to bolster the relative value of their opinion, when no objective criteria for their expertise is available. The term crank is likewise used to disparage opinions. Academic elitism arises when experts become convinced that only their opinion is useful, sometimes on matters beyond their personal expertise.
In contrast to an expert, a novice (known colloquially as a newbie or 'greenhorn') is any person that is new to any science or field of study or activity or social cause and who is undergoing training in order to meet normal requirements of being regarded a mature and equal participant.
"Expert" is also being mistakenly interchanged with the term "authority" in new media. An expert can be an authority if through relationships to people and technology, that expert is allowed to control access to his expertise. However, a person who merely wields authority is not by right an expert. In new media, users are being misled by the term "authority". Many sites and search engines such as Google and Technorati use the term "authority" to denote the link value and traffic to a particular topic. However, this authority only measures populist information. It in no way assures that the author of that site or blog is an expert.
Developmental characteristics.
Some characteristics of the development of an expert have been found to include
Use in literature.
Mark Twain defined an expert as "an ordinary fellow from another town". Will Rogers described an expert as "A man fifty miles from home with a briefcase." Danish scientist and Nobel laureate Niels Bohr defined an expert as "A person that has made every possible mistake within his or her field.". Malcolm Gladwell describes expertise as a matter of practicing the correct way for a total of around 10,000 hours.

</doc>
<doc id="9895" url="https://en.wikipedia.org/wiki?curid=9895" title="Economy of Afghanistan">
Economy of Afghanistan

The economy of Afghanistan has improved significantly since 2002 due to the infusion of billions of dollars in international assistance and investments, as well as remittances from Afghan expatriates.The help that came from expatriates and outside investments saw this significant increase when there was more political reliability after the fall of the many terrorist groups in the early 2000s such as the Taliban. The recent improvement is also due to dramatic improvements in agricultural production and the end of a four-year drought in most of the country.
The government of Afghanistan claims that the country holds up to $3 trillion in proven untapped mineral deposits, which could make it one of the richest mining regions on earth. However, due to the conflicts, it remains one of the least developed countries in the world, ranking 175th on the United Nations' Human Development Index. The nation's GDP stands at about $34 billion with an exchange rate of $19.85 billion, and the GDP per capita is about $1,150.
About 35% of its population is unemployed and 36% live below the national poverty line, suffering from shortages of housing, clean drinking water, and electricity. The Karzai administration along with international donors have remained committed to improving access to these basic necessities by prioritizing infrastructure development, education, housing development, jobs programs, medical care, and economic reform.
Economic history.
Historically, there has been a lack of information and reliable statistics about Afghanistan's economy. In the early modern period under the rule of kings Abdur Rahman Khan (1880–1901) and Habibullah Khan (1901–1919), a great deal of Afghan commerce was centrally controlled by the Afghan government. The Afghan monarchs were eager to develop the stature of government and the country's military capability, and so attempted to raise money by the imposition of state monopolies on the sale of commodities and high taxes. This slowed the long-term development of Afghanistan during that period. Western technologies and manufacturing methods were slowly introduced during these eras at the command of the Afghan ruler, but in general only according to the logistical requirements of the growing army. An emphasis was placed on the manufacture of weapons and other military materiel. This process was in the hands of a small number of western experts invited to Kabul by the Afghan kings. Otherwise, it was not possible for outsiders, particularly westerners, to set up large-scale enterprises in Afghanistan during that period.
The first prominent plan to develop Afghanistan's economy in modern times was the Helmand Valley Authority project, modelled on the Tennessee Valley Authority in the United States, which was expected to be of primary economic importance. The country began facing severe economic hardships during the 1970s when neighboring Pakistan, under Zulfikar Ali Bhutto, began closing the Pakistan-Afghanistan border crossings. This move resulted in Afghanistan increasing political and economic ties with its northern neighbor, the powerful Soviet Union of that time.
The 1979 Soviet invasion and ensuing civil war destroyed much of the country's limited infrastructure, and disrupted normal patterns of economic activity (See "Democratic Republic of Afghanistan#Economy"). Eventually, Afghanistan went from a traditional economy to a centrally planned economy up until 2002 when it was replaced by a free market economy. Gross domestic product has fallen substantially since the 1980s due to disruption of trade and transport as well as loss of labor and capital. Continuing internal strife severely hampered domestic efforts to rebuild the nation or provide ways for the international community to help.
According to the International Monetary Fund, the Afghan economy grew 20% in the fiscal year ending in March 2004, after expanding 30% in the previous 12 months. The growth is attributed to international aid and to the end of droughts. An estimated $4.4 billion of aid entered the nation from 2002 to 2004. A GDP of $4 billion in fiscal year 2003 was recalculated by the IMF to $6.1 billion, after adding proceeds from opium products. Mean graduate pay was $0.56 per man-hour in 2010.
Agriculture and livestock.
The Afghan economy has always been agricultural, despite the fact that only 12% of its total land is arable and about 6% is currently cultivated. Agriculture production is constrained by an almost total dependence on erratic winter snows and spring rains for water. As of 2007, the country's fruit and nut exports were at $113 million per year, but according to an estimate could grow to more than $800 million per year in 10 years given sufficient investment. Afghanistan is known for producing some of the finest fruits and vegetables, especially pomegranates, apricots, grapes, melons, and mulberries. Several provinces in the north of the country (i.e. Badghis and Samangan) are famous for pistachio cultivation but the area currently lacks proper marketing and processing plants. It is claimed that some Indian companies buy Afghan pistachios for a very low price, process them in India and sell to western countries as Indian products. However, the Afghan government is planning to build storage facilities for pistachios since receiving bumper crops in 2010. The Bamyan Province in central Afghanistan is known for growing superior potatoes, which on an average produces 140,000 to 170,000 tonnes.
Wheat and cereal production is Afghanistan's traditional agricultural mainstay. National wheat production in 2010 was 4,532 MT. The overall agricultural production dramatically declined following four years of drought as well as the sustained fighting and instability in rural areas. Soviet efforts to disrupt production in resistance-dominated areas also contributed to this decline. Furthermore, since 2002 more than 4 million refugees returned to Afghanistan. Many of these former refugees are now involved in the farming industry. Some studies indicate that agricultural production and livestock numbers may only be sufficient to feed about half of the country's population. Shortages are exacerbated by the country's limited transportation network, which is currently being rebuilt. A report by the Food and Agriculture Organization (FAO) states that Afghanistan was nearing self-sufficiency in grain production.
The availability of land suitable for grazing has traditionally made animal husbandry an important part of the economy. There are two main types of animal husbandry: sedentary, practiced by farmers who raise both animals and crops; and nomadic, practiced by animal herders known as Kuchis. Natural pastures cover some but are being overgrazed. The northern regions around Mazar-i-Sharif and Maymanah were the home range for about six million karakul sheep in the late 1990s. Most flocks move to the highlands in the summer to pastures in the north. Oxen are the primary draft power and farmers often share animals for plowing. Poultry are traditionally kept in many houses, mostly in rural households.
Much of Afghanistan's livestock was removed from the country by early waves of refugees who fled to neighboring Pakistan and Iran. In 2001, the livestock population in Afghanistan had declined by about 40% since 1998. In 2002, this figure was estimated to have declined further to 60%. An FAO survey done in the northern regions in spring 2002 showed that in four provinces (Balkh, Jowzjan, Sar-e Pol, and Faryab), there was a loss of about 84% of cattle from 1997 to 2002 and around 80% of sheep and goat. The majority of Afghans traditionally raise sheep instead of goats because goat meat is not popular in Afghanistan. After 2002, the Afghan ministry of agriculture and livestock with assistance from USAID have been helping to regrow livestock numbers throughout the country. This was done by providing Afghan villagers training and animals to start with. The Agriculture Minister Mohammad Asef Rahimi stated that over the past decade arable land had increased from 2.1 million hectares to 8.1 million hectares, wheat production from 5.1 million tonnes to 2.3 million tonnes, nurseries from 75,000 hectares to 119,000 hectares and grape production from 364,000 tonnes to 615,000 tonnes. Almond production jumped from 19,000 to 56,000 tonnes and cotton from 20,000 to 45,000 tonnes, with the saffron yield reaching 2,000 kilograms.
Fishing.
The country has plenty of water reserves and suitable climate for fish farming. Fishing takes place in the lakes and rivers, particularly in the Kabul River around the Jalalabad area. Fish constitute a smaller part of the Afghan diet today because fish farmers are unable to produce enough fish to keep up with the demands of customers. Using explosives for fishing, called dynamite fishing, became popular in the 1980s and is still practiced by some even though it is illegal today. The annual catch was about 900 tons in 2003. Most fish and seafood is imported from neighboring Pakistan, Iran, the United Arab Emirates and other countries. In recent years, USAID has helped many Afghans in establishing fish farms across the country. There are about 300 fish farms throughout the country and the largest one is at the Qargha, which supplies fish eggs to the other fish farms.
Forestry.
Afghanistan's timber has been greatly depleted, and since the mid-1980s, only about 3% of the land area has been forested, mainly in the east. Significant stands of trees have been destroyed by the ravages of the war. Exploitation has been hampered by lack of power and access roads. Moreover, the distribution of the forest is uneven, and most of the remaining woodland is only found in the Kunar, Nuristan and the Paktia regions in the east of the country.
The natural forests in Afghanistan are mainly of two types: dense forests of oak trees, walnut trees, and many other species of nuts that grow in the southeast, and on the northern and northeastern slopes of the Sulaiman ranges; and sparsely distributed short trees and shrubs on all other slopes of the Hindu Kush. The dense forests of the southeast cover only 2.7% of the country. Roundwood production in 2003 was 3,148,000 cubic metres, with 44% used for fuel.
The destruction of the forests to create agricultural land, logging, forest fires, plant diseases, and insect pests are all causes of the reduction in forest coverage. Illegal logging and clear-cutting by timber smugglers have exacerbated this destructive process. There is currently a ban on cutting new timber in Afghanistan. Prior to 2001 and under Taliban rule, massive deforestation of the country side was permitted and Afghans moved large quantities of logs into storage centers for profit, where the trees wait for processing on an individual tree by tree request.
Trade and industry.
The current trade between Afghanistan and other countries is at US$5 billion a year. In 1996, legal exports (excluding opium) were estimated at $80 million and imports estimated at $150 million per year. Since the collapse of the Taliban government in 2001, new trade relations are emerging with the United States, Pakistan, Iran, Turkmenistan, the EU, Japan, Uzbekistan, India and other countries. Trade between Afghanistan and the U.S. is beginning to grow at a fast pace, reaching up to approximately $500 million per year. Afghan handwoven rugs are one of the most popular products exported from the country. Other products include hand crafted antique replicas as well as leather and furs.
Afghanistan is endowed with a wealth of natural resources, including extensive deposits of natural gas, petroleum, coal, marble, gold, copper, chromite, talc, barites, sulfur, lead, zinc, iron ore, salt, precious and semi-precious stones, and many rare earth elements. In 2006, a U.S. Geological Survey estimated that Afghanistan has as much as of natural gas, of oil and condensate reserves. According to a 2007 assessment, Afghanistan has significant amounts of undiscovered non-fuel mineral resources. Geologists also found indications of abundant deposits of colored stones and gemstones, including emerald, ruby, sapphire, garnet, lapis, kunzite, spinel, tourmaline and peridot.
In 2010, U.S. Pentagon officials along with American geologists have revealed the discovery of nearly $1 trillion in untapped mineral deposits in Afghanistan. A memo from the Pentagon stated that Afghanistan could become the "Saudi Arabia of lithium". Some believe, including Afghan President Hamid Karzai, that the untapped minerals are worth at least $3 trillion.
Another US Geological Survey estimate from September 2011 showed that the Khanashin carbonatites in the Helmand Province of the country have an estimated 1 million metric tonnes of rare earth elements. Regina Dubey, Acting Director for the Department of Defence "Task Force for Business and Stability Operations (TFBSO)" stated that "this is just one more piece of evidence that Afghanistan's mineral sector has a bright future."
Afghanistan signed a copper deal with China (Metallurgical Corp. of China Ltd.) in 2008, which is to a large-scale project that involves the investment of $2.8 billion by China and an annual income of about $400 million to the Afghan government. The country's Ainak copper mine, located in Logar province, is one of the biggest in the world and is expected to provide jobs to 20,000 Afghans. It is estimated to hold at least 11 million tonnes or US$33 billion worth of copper.
Experts believe that the production of copper could begin within two to three years and the iron ore in five to seven years as of 2010. The country's other recently announced treasure is the Hajigak iron ore mine, located 130 miles west of Kabul and is believed to hold an estimated 1.8 billion to 2 billion metric tons of the mineral used to make steel. AFISCO, an Indian consortium of seven companies, led by the Steel Authority of India Limited (SAIL), and Canada's Kilo Goldmines Ltd are expected to jointly invest $14.6 billion in developing the Hajigak iron mine. The country has several coal mines but need to be modernized.
Afghanistan's important resource in the past has been natural gas, which was first tapped in 1967. During the 1980s, gas sales accounted for $300 million a year in export revenues (56% of the total). 90% of these exports went to the Soviet Union to pay for imports and debts. However, during the withdrawal of Soviet troops in 1989, Afghanistan's natural gas fields were capped to prevent sabotage by the Mujahideen. Gas production has dropped from a high of 8.2 million cubic metres per day in the 1980s to a low of about 600,000 cubic meters in 2001. After the formation of the new Karzai administration, production of natural gas has been restored again.
A locally owned company, Azizi Hotak General Trading Group, is currently the main supplier of diesel fuel, gasoline, jet fuel and LPG in Afghanistan. In December 2011, Afghanistan signed an oil exploration contract with China National Petroleum Corporation (CNPC) for the development of three oil fields along the Amu Darya river. The state will have its first oil refineries within the next three years, after which it will receive very little of the profits from the sale of the oil and natural gas. CNPC began Afghan oil production in late October 2012, with extracting 1.5 million barrels of oil annually.
Trade in goods smuggled into Pakistan once constituted a major source of revenue for Afghanistan. Many of the goods that were smuggled into Pakistan have originally entered Afghanistan from Pakistan, where they fell under the 1965 Afghanistan–Pakistan Transit Trade Agreement. This permitted goods bound for Afghanistan to transit through Pakistani seaports free of duty. Once in Afghanistan, the goods were often immediately smuggled back into Pakistan over the porous border that the two countries share, often with the help of corrupt officials. Additionally, items declared as Afghanistan-bound were often prematurely offloaded from trucks and smuggled into Pakistani markets without paying requisite duty fees. This resulted in the creation of a thriving black market, with much of the illegal trading occurring openly, as was common in Peshawar's bustling Karkhano Market, which was widely regarded as a smuggler's bazaar.
In Pakistan clamped down in 2003 on the types of goods permitted duty-free transit, and introducing stringent measures and labels to prevent smuggling. re-routing of goods through Iran from the Persian Gulf increased significantly. The pre-2003 smuggling trade provided undocumented jobs to tens of thousands of Afghans and Pakistanis, but also helped fuel the "black" economy, often intertwined with the drug cartels, of both countries.
Afghanistan and Pakistan recently signed into law a new Afghanistan–Pakistan Transit Trade Agreement (APTTA), which allows their shipping trucks to transit goods within both nations. This revised US-sponsored APTTA agreement also allows Afghan trucks to transport exports to India via Pakistan up to the Wagah crossing point. Secondary to concerns regarding smuggling, Pakistani officials insisted that while Afghan exports destined for India can be transited across Pakistani territory, Indian goods cannot in turn be exported to Afghanistan across Pakistani territory. Instead, Afghan trucks offloaded at Wagah may return to Afghanistan loaded only with Pakistani, rather than Indian, goods in an attempt to curb smuggling.
According to Afghanistan's Chamber of Commerce and Industries deputy head, Khan Jan Alokozai, about 500 shipping containers of trade goods enter Afghanistan via the Torkham and Wesh-Chaman border crossings on a daily basis. Other major trade routes in Afghanistan are via the crossing borders in Zaranj, Islam Qala, Hairatan, Shir Khan Bandar, and Towraghondi.
Economic development and recovery.
Afghanistan embarked on a modest economic development program in the 1930s. The government founded banks; introduced paper money; established a university; expanded primary, secondary, and technical schools; and sent students abroad for education. In 1952 it created the Helmand Valley Authority to manage the economic development of the Helmand and Arghandab valleys through irrigation and land development, a scheme which remains one of the country's most important capital resources.
In 1956, the government promulgated the first in a long series of ambitious development plans. By the late 1970s, these had achieved only mixed results due to flaws in the planning process as well as inadequate funding and a shortage of the skilled managers and technicians needed for implementation.
Da Afghanistan Bank serves as the central bank of the nation and the "Afghani" (AFN) is the national currency, with an exchange rate of about 68.5 Afghanis to 1 US dollar. There are over 16 different banks operating in the country, including Afghanistan International Bank, Kabul Bank, Azizi Bank, Pashtany Bank, Standard Chartered Bank, First Micro Finance Bank, and others. A new law on private investment provides three to seven-year tax holidays to eligible companies and a four-year exemption from exports tariffs and duties. According to a UN report in 2007, Afghanistan has received over $3.3 billion from its expatriate community in 2006. UN officials familiar with the issue said remittances to Afghanistan could have been more if the banking regulations are more convenient. Additionally, improvements to the business-enabling environment have resulted in more than $1.5 billion in telecom investment and created more than 100,000 jobs since 2003.
Afghanistan is a member of SAARC, ECO, OIC, and has an observer status in the Shanghai Cooperation Organisation (SCO). It seeks to complete the so-called "New Silk Road" trade project, which is aimed to connecting South Asia with Central Asia and the Middle East. This way Afghanistan will be able to collect large fees from trade passing through the country, including from the Trans-Afghanistan Pipeline. Foreign Minister Zalmai Rassoul stated that his nation's "goal is to achieve an Afghan economy whose growth is based on trade, private enterprise and investment". Experts believe that this will revolutionize the economy of the region.
The capital of Kabul symbolizes the spirits of all Afghans and international cooperation, sets at the heart of this highly resourceful region, with great potential to turn into a business hub. After 2002, the new geo-political dynamics and its subsequent business opportunities, rapid urban population growth and emergence of high unemployment, triggered the planning of urban extension towards the immediate north of Kabul, in the form of a new city.
In 2006, President Hamid Karzai established an independent board for the development of Kabul New City. The board brought together key stakeholders, including relevant government agencies, representation from private sector, urban specialists and economists, with cooperation from the government of Japan and French private sector, to prepare a master plan for the city in the context of Greater Kabul. The master plan and its implementation strategy for 2025 were endorsed by the Afghan Cabinet in early 2009. The initiative turned into one of the biggest commercially viable national development project of the country, expected to be led by the private sector.
As part of an attempt to modernize the city and boost the economy, a number of new high rise buildings are under construction by various developers. An initial concept design called the City of Light Development, envisioned by Hisham N. Ashkouri, for the development and the implementation of a privately based investment enterprise was proposed for a multi-function commercial, historic and cultural development within the limits of the Old City of Kabul, along the southern side of the Kabul River and along Jade Meywand Avenue. Some of the national development projects include New Kabul City next to the capital, Ghazi Amanullah Khan City east of Jalalabad, and Aino Mena in Kandahar. Similar development projects are also taking place in Herat in the west, Mazar-e-Sharif in the north and in other cities.
In the last decade, companies such as The Coca-Cola Company and PepsiCo launched or re-launched operations in Kabul. In addition, a number of local mineral water and juice plants, including factories of other products, were built. This not only promotes foreign investment but also makes the country less dependent on imports from neighboring countries and helps provide employment opportunity to many Afghans. Watan Group is a company based in Afghanistan that provides telecommunications, logistics and security services.
Tourism.
Tourism in Afghanistan was at its peak in 1977. Many tourists from around the world came to visit Afghanistan, including from neighboring Iran, Turkey and Pakistan, the Soviet Union, Europe, North America and other places. All this ended with the start of the April 1978 Saur Revolution. It is expected that once the security situation is normal, Afghanistan will become a major tourist destination. Most westerners feel that Afghanistan is too dangerous for them to tour but the Afghan expatriates and those particularly from the Muslim world do not see it that dangerous.
The country has three international airports, including the Kabul International Airport, Kandahar International Airport and Herat International Airport. Mazar-i-Sharif Airport and Ghazni Airport are also being upgraded to become international in the coming years. The city of Kabul has many guest houses and hotels, including the Hotel Inter-Continental Kabul, Safi Landmark Hotel, and at least one 5-star Serena Hotel. A Marriott is under construction next to the U.S. Embassy.
Tourist sites within the country include:
National accounts.
"The majority of the following informatin is taken from, or adapted from The World Factbook"
GDP: purchasing power parity $33.55 billion, with an exchange rate at $19.85 billion (2011 est.)
GDP - real growth rate: 
GDP - per capita: purchasing power parity - $1,000 (2011 est.)
GDP - composition by sector:
note: data excludes opium production
Population below poverty line:
Household income or consumption by percentage share:
Inflation rate (consumer prices): 13.8% (2011 est.)
Natural gas - production: 220 million m³ (2001)
Natural gas - consumption: 220 million m³ (2001)
Natural gas - proved reserves: 15.7 trillion cubic feet (2006 est.)
Agriculture - products: opium poppies, wheat, fruits, nuts, karakul pelts
Exports: $376 million (2012 est.)
<br>"country comparison to the world:" 164
Exports - commodities: opium, fruits and nuts, handwoven carpets, wool, cotton, hides and pelts, and gemstone
Exports - partners: Pakistan 48%, India 19%, Russia 9%, Iran 5% (FY11/12 est.)
Imports: $6.39 billion (2012 est.)
Imports - commodities: machinery and other capital goods, food, textiles, petroleum products
Imports - partners: Pakistan 13.7%, Russia 12.6%, Uzbekistan 11.5%, Iran 9.1% (FY11/12 est.)
Debt - external: $1.28 to $2.3 billion total (2011)
Current account balance: -$743.9 million (2011 est.)
<br>"country comparison to the world:" 132
Currency: Afghani (AFN)
Exchange rates: afghanis (AFA) per US dollar - 62 = $1
Fiscal year: 21 March - 21 March

</doc>
<doc id="9896" url="https://en.wikipedia.org/wiki?curid=9896" title="Elf">
Elf

An elf (plural: "elves") is a type of supernatural being in Germanic mythology and folklore. Reconstructing the early concept of an elf depends almost entirely on texts in Old English or relating to Norse mythology. Later evidence for elves appears in diverse sources such as medical texts, prayers, ballads, and folktales.
Recent scholars have emphasised, in the words of Ármann Jakobsson, that
However, some generalisations are possible. In medieval Germanic-speaking cultures, elves seem generally to have been thought of as a group of beings with magical powers and supernatural beauty, ambivalent towards everyday people and capable of either helping or hindering them. However, the precise character of beliefs in elves across the Germanic-speaking world has varied considerably across time, space, and different cultures. In Old Norse mythological texts, elves seem at least at times to be counted among the pagan gods; in medieval German texts they seem more consistently monstrous and harmful.
Elves are prominently associated with sexual threats, seducing people and causing them harm. For example, a number of early modern ballads in the British Isles and Scandinavia, originating in the medieval period, describe human encounters with elves.
In English literature of the Elizabethan era, elves became conflated with the fairies of Romance culture, so that the two terms began to be used interchangeably. German Romanticist writers were influenced by this notion of the 'elf', and reimported the English word "elf" in that context into the German language. In Scandinavia, probably through a process of euphemism, elves often came to be conflated with the beings called the huldra or huldufólk. Meanwhile, German folklore has tended to see the conflation of elves with dwarfs.
The "Christmas elves" of contemporary popular culture are of relatively recent tradition, popularized during the late nineteenth-century in the United States. Elves entered the twentieth-century high fantasy genre in the wake of works published by authors such as J. R. R. Tolkien, for which, see Elf (Middle-earth).
Etymology.
The English word "elf" is from the Old English word most often attested as "ælf" (whose plural would have been *"ælfe"). Although this word took a variety of forms in different Old English dialects, these converged on the form "elf" during the Middle English period. During the Old English period, separate forms were used for female elves (such as "ælfen", putatively from common Germanic *"ɑlβ(i)innjō"), but during the Middle English period the word "elf" came routinely to include female beings.
The main medieval Germanic cognates of "elf" are Old Norse "alfr", plural "alfar", and Old High German "alp", plural "alpî", "elpî" (alongside the feminine "elbe"). These words must come from Common Germanic, the ancestor-language of English, German, and the Scandinavian languages: the Common Germanic forms must have been *"ɑlβi-z" and "ɑlβɑ-z".
Germanic "*ɑlβi-z~*ɑlβɑ-z" is generally agreed to be cognate with the Latin "albus" ('(matt) white'), Old Irish "ailbhín" (‘flock’); Albanian "elb" (‘barley’); and Germanic words for ‘swan’ such as Modern Icelandic "álpt". These all come from an Indo-European base "*albh-", and seem to be connected by whiteness. The Germanic word presumably originally meant 'white person', perhaps as a euphemism. Jakob Grimm thought that whiteness implied positive moral connotations, and, noting Snorri Sturluson's "ljósálfar", suggested that elves were divinities of light. This is not necessarily the case, however. For example, Alaric Hall, noting that the cognates suggest matt white or soft white, has instead tentatively suggested that later evidence associating both elves and whiteness with beauty may indicate that it was this beauty that gave elves their name. Compare descriptions such as ‘swan white’ to describe the beauty of fair complexion. Norse cultural values view masculinity as an ideal of beauty, which the Alfr personifies. For example, the Norse Eddas similarly celebrate the male beauty of Baldr. Icelandic Sagas celebrate the beauty of the cliff giants (bergrisi), and certain warrior kings that descend from them. Modern Scandinavian folklore celebrates the male beauty of the Fossegrim and the Huldrekarl/Huldrekall, nature spirits comparable to nymphs, but masculine men. By contrast, British cultural values tend to downplay male beauty and only emphasize femininity as an ideal of beauty. For example, angels are unambiguously masculine in ancient biblical texts, yet because of their beauty, modern British artists often depict angels as feminine. Ultimately, beauty and luminosity are identical. In the Norse Eddas, the radiant beauty of Baldr is the light of the daylight itself. Likewise, in medieval British poetry, the supernatural beauty of biblical Judith is described as ‘elf shining’ (ælfscinu), a magical beauty that shines an aura of light.
A completely different etymology, making "elf" cognate with the "Rbhus", semi-divine craftsmen in Indian mythology, was also suggested by Kuhn, in 1855. In this case, *ɑlβi-z connotes the meaning, ‘skillful, inventive, clever’, and is cognate with Latin "labor", in the sense of ‘creative work’. While often mentioned, this etymology is not widely accepted. Notable is the association of both Old Norse "Alfr" and Sanskrit "Rbhu" with the solar corona and sun rays.
Elves in names.
Throughout the medieval Germanic languages, "elf" was one of the nouns that was used in personal names, almost invariably as a first element. These names may have been influenced by Celtic names beginning in "Albio-" such as "Albiorix".
Personal names provide the only evidence for "elf" in Gothic, which must have had the word "*albs" (plural "*albeis"). The most famous such name is "Alboin". Old English names in "elf"- include the cognate of "Alboin" Ælfwine ("elf-friend", m.), Ælfric ("elf-powerful", m.), Ælfweard (m.) and Ælfwaru (f.) ("elf-guardian"). The only widespread survivor of these in modern English is Alfred (Old English "Ælfrēd", "elf-advice"). German examples are "Alberich", "Alphart" and "Alphere" (father of Walter of Aquitaine) and Icelandic examples include "Álfhildur". It is generally agreed that these names indicate that elves were positively regarded in early Germanic culture. Other words for supernatural beings in personal names almost all denote pagan gods, suggesting that elves were in a similar category of beings.
In later Old Icelandic, "alfr" ("elf") and the personal name which in Common Germanic had been *"Aþa(l)wulfaz" both coincidentally became "álfr~Álfr". This seems to have led people to associate legendary heroes called Álfr with the elves.
Elves appear in some place-names, though it is hard to be sure how many as a variety of other words, including personal names, can appear similar to "elf". The clearest English example is "Elveden" ("elves' hill", Suffolk); other examples may be "Eldon Hill" ("Elves' hill", Derbyshire); and "Alden Valley" ("elves' valley", Lancashire). These seem to associate elves fairly consistently with woods and valleys.
Relationship to Christian cosmologies.
Almost all surviving textual sources about elves were produced by Christians—whether Anglo-Saxon monks, medieval Icelandic poets, early modern ballad-singers, nineteenth-century folklore collectors, or even early twentieth-century fantasy authors. As with the Irish "Aos Sí", beliefs in elves have, therefore, been a part of Christian cultures throughout their recorded history and there is a complex relationship between ideas about elves and mainstream Christian thought.
Historically, people have taken three main approaches to integrating elves into Christian cosmology (though of course there are no rigid distinctions between these):
Elves in medieval texts and post-medieval folk-belief.
Our earliest substantial evidence for elf-beliefs comes in medieval texts from Anglo-Saxon England and high medieval Iceland, with a scatter of texts from the German-speaking world. Some general themes are apparent: elves were human(-like); were once pagan divinities of some kind; and were dangerous: they could cause harm to people or livestock, or might seduce people into sexual relationships with them.
After the Middle Ages, the word "elf" tended to be replaced by other terms, becoming archaic, dialectal, or surviving only in fossilised terms.
Medieval English-language sources.
Old English.
The earliest surviving manuscripts mentioning elves are from Anglo-Saxon England. Here elves are most often attested in Old English glosses which translate Latin words for nymphs, and in medical texts which attest to elves afflicting humans and livestock with illnesses: apparently mostly sharp, internal pains and mental disorders. The most famous of the medical texts is the metrical charm "Wið færstice" ('against a stabbing pain'), from the tenth-century compilation "Lacnunga", but most of the attestations are in the tenth-century "Bald's Leechbook" and "Leechbook III".
Because of elves' association with illness, in the second half of the twentieth century, most scholars imagined that elves in the Anglo-Saxon tradition were small, invisible, demonic beings, causing illness with arrows. Scholars, but not the primary texts, labelled the illnesses elves caused as "elf-shot" This was encouraged by the idea that "elf-shot" is depicted in the Eadwine Psalter, in an image which became well known in this connection. However, this is now thought to be a misunderstanding: the image proves to be a conventional illustration of God's arrows and of Christian demons.
But there is good evidence that elves were associated with the succuba-like "mære" and could cause illness, recent scholarship suggests Anglo-Saxon elves, like elves in later evidence from Britain and Scandinavia or the Irish Aos Sí, were like people. Like words for gods and men, the word "elf" is used in personal names where words for monsters and demons are not. Just as "álfar" are associated with "Æsir" in Old Norse, "Wið færstice" associates elves with "ēse"; whatever this word meant by the tenth century, etymologically it denoted pagan gods. In Old English, the plural "ylfe" (attested in "Beowulf") is grammatically an ethnonym (a word for an ethnic group).
While they may still have been thought to cause disease with weapons, elves are more clearly associated in Old English with a kind of magic denoted by Old English "sīden" and "sīdsa", cognate with Old Norse "seiðr", and also paralleled in the Old Irish "Serglige Con Culainn". This fits well with the use of Old English "ælf" and its feminine derivative "ælbinne" to gloss words for nymphs and with the word "ælfscȳne", which meant 'elf-beautiful' and is attested describing seductively beautiful women.
Middle English.
Later in medieval English evidence, while still appearing as causes of harm and danger, elves appear more clearly as human-like beings, and increasingly as females rather than males, which may reflect developments in elf-beliefs during the medieval period. They became associated with medieval romance traditions of fairies and particularly with the idea of a Fairy Queen. Sexual allure becomes increasingly prominent in the source material. Elves are also associated with the arcane wisdom of alchemy.
By the end of the medieval period, "elf" was increasingly being supplanted by the French loan-word "fairy", as in Geoffrey Chaucer's satirical "Sir Thopas" where the title character sets out in quest of the 'elf-queen', who dwells in the 'countree of the Faerie'.
Post-medieval folk belief in Britain.
Despite the decline in references to elves in England, beliefs in elves remained prominent in early modern Scotland, where elves appear in English-language sources in the early modern Scottish witchcraft trials. These produced many depositions by people who believed themselves to have been given healing powers or to know of people or animals made sick by elves. The similarities with Old English material, and particularly "Wið færstice", are close. Elves were viewed as being supernaturally powerful people who lived invisibly alongside everyday rural people.
The noun "elf-shot" is first attested in a Scots poem, 'Rowlis Cursing' from around 1500, where 'elf schot' is listed among a range of curses to be inflicted on some chicken-thieves. It may not always have denoted an actual projectile as there is evidence that 'shot' could mean 'a sharp pain', but it and terms like "elf-arrow(head)" are sometimes used of neolithic arrow-heads, apparently thought to have been made by elves, and in a few witchcraft trials people attest that these were used in healing rituals, and occasionally alleged to be used by witches (and perhaps elves) to injure people and cattle. Compare with the following excerpt from a 1749–50 ode by William Collins:
Old Norse texts.
Evidence for elf-beliefs in medieval Scandinavia outside Iceland is very sparse, but the Icelandic evidence is uniquely rich.
Mythological texts.
For a long time, views about elves in Old Norse mythology were defined by Snorri Sturluson's Prose Edda, which talks about "svartálfar", "dökkálfar" and "ljósálfar". However, these words are only attested in the Prose Edda and texts based on it, and it is now agreed that they reflect traditions of dwarves, demons, and angels, partly showing Snorri's 'paganisation' of a Christian cosmology learned from the "Elucidarius".
Scholars of Old Norse mythology now focus on references to elves in Old Norse poetry, particularly the Elder Edda. The only character explicitly identified as an elf in classical Eddaic poetry, if any, is Völundr, the protagonist of "Völundarkviða". However, elves are frequently mentioned in the alliterating formulaic collocation "Æsir ok Álfar" ('Æsir and elves') and its variants. This shows a strong tradition of associating elves with the Æsir, or sometimes even of not distinguishing between the two groups. The collocation is paralleled in the Old English poem "Wið færstice"; in the Germanic personal name system; and in Skaldic verse the word "elf" is used in the same way as words for gods. Sigvatr Þórðarson’s skaldic travelogue "Austrfaravísur", composed around 1020, mentions an "álfablót" (‘elves' sacrifice’) in Edskogen in what is now southern Sweden. There does not seem to have been any clear-cut distinction between humans and gods; like the Æsir, then, elves were presumably thought of as being human(-like) and existing in opposition to the giants. Many commentators have also (or instead) argued for conceptual overlap between elves and dwarves in Old Norse mythology, which may fit with trends in the medieval German evidence.
There are hints that Freyr was associated with elves, particularly that "Álfheimr" (literally 'elf-world') is mentioned as being given to Freyr in "Grímnismál". Because Snorri Sturluson identified Freyr as one of the Vanir when that word is rare in Eddaic verse, very rare in Skaldic verse, and is not generally thought to appear in other Germanic languages, it has long been suggested that "álfar" and "Vanir" are, more or less, different words for the same group of beings, and even that Snorri invented the "Vanir". However, this is not uniformly accepted.
A kenning for the sun, "álfröðull", is of uncertain meaning but is to some suggestive of a close link between the elves' and the sun.
Although the relevant words are of slightly uncertain meaning, it seems fairly clear that Völundr is described as one of the elves in "Völundarkviða". As his most prominent deed in the poem is to rape Böðvildr, the poem associates elves with being a sexual threat to maidens. The same idea is present in two post-classical Eddaic poems, which are also influenced by romance or Breton "lais", "Kötludraumur" and "Gullkársljóð" and in later traditions in Scandinavia and beyond, so may be an early attestation of a prominent tradition. Elves also appear in a couple of verse spells, including the Bergen rune-charm from among the Bryggen inscriptions.
Other sources.
The appearance of elves in sagas is closely defined by genre. 'In the more realistic Sagas of Icelanders, Bishops' Sagas, and "Sturlunga saga", "álfar" are rare. When seen, they are distant.' These texts include a fleeting mention of elves seen out riding in 1168 (in "Sturlunga saga"); mention of an "álfablót" in "Kormáks saga"; and the existence of the euphemism "ganga álfrek" ('go to drive away the elves') for 'going for a poo' in "Eyrbyggja saga".
The Kings' sagas include a rather elliptical account of an early Swedish king being worshipped after his death and being called Ólafr Geirstaðaálfr ('Ólafr the elf of Geirstaðir') and the elf as a demon at the beginning of "Norna-Gests þáttr", which is a portion of the "Greatest Saga of Olaf Tryggvason".
The Legendary sagas tend to focus on elves as legendary ancestors or on heroes' sexual relations with elf-women. Mention of the land of Álfheimr is found in "Heimskringla" while "The Saga of Thorstein, Viking's Son" recounts a line of local kings who ruled over Álfheim, who since they had elven blood were said to be more beautiful than most men. According to "Hrólfs saga kraka", Hrolfr Kraki's half-sister Skuld was the half-elven child of King Helgi and an elf-woman ("álfkona"). Skuld was skilled in witchcraft ("seiðr"). Accounts of Skuld in earlier sources, however, do not include this material. The "Þiðreks saga" version of the Nibelungen (Niflungar) describes Högni as the son of a human queen and an elf, but no such lineage is reported in the Eddas, "Völsunga saga", or the "Nibelungenlied". The relatively few mentions of elves in the Chivalric sagas tend even to be whimsical.
Both Continental Scandinavia and Iceland have a scattering of mentions of elves in medical texts, most of them with Low German connections.
Post-medieval developments.
Although the term "elf" was sustained in some Scandinavian traditions, during and after the medieval period it largely disappears in favour either of euphemisms for the same beings or different beliefs entirely, such as "huldufólk" ('hidden people', Icelandic), "huldra" ('hidden people', Norwegian and Swedish, along with terms like "skogsfru" and "skogsrå"), "vetter", "nisse" (Denmark, along with "bjærgfolk") and "tomte" (Sweden).
Medieval and early modern German texts.
Old High German "alp" is attested only in a small number of glosses and is defined by the "Althochdeutsches Wörterbuch" as a 'nature-god or -demon, equated with the Fauns of Classical mytholology ... regarded as eerie, ferocious beings ... As the nightmare he messes around with women'. There is also evidence associating elves with illness, specifically epilepsy, and in the word "Alpdruck" ('elf-oppression') with the nightmare.
Accordingly, elves appear in Middle German most often associated with deception or bewildering people 'in a phrase that occurs so often it would appear to be proverbial: "die elben/der alp trieget mich" (the elves/elf is/are deceiving me)' and are often associated with the mare. Elves appear as a threatening, even demonic, force widely in later medieval prayers. The most famous is the fourteenth-century "Münchener Nachtsegen", a prayer to be said at night, which includes the lines:
In early modern sources, the German "alp" is also described as "cheating" or "deceiving" (, ) its victims. In the early modern period, elves are attested in north Germany doing the evil bidding of witches; Martin Luther believed his mother to have been afflicted in this way.
Elves in German tradition also show the seductive side apparent in English and Scandinavian material, however. Most famously, the early thirteenth-century Heinrich von Morungen's fifth "Minnesang" begins 'Von den elben virt entsehen vil manic man | Sô bin ich von grôzer lieber entsên' ('full many a man is bewitched by elves | thus I too am bewitched by great love'). As in earlier English, "elbe" is attested translating words for nymphs.
As in Old Norse, however, there are few characters identified as elves. It seems likely that elves were to a significant extent conflated with dwarves (). Some dwarfs that appear in German heroic poetry have been seen as relating to elves, especially when the dwarf's name is "Alberich", which etymologically means 'elf-powerful'; Jacob Grimm thought that the name echoed the notion of the king of the nation of elves or dwarfs. The Alberich in the epic "Ortnit" is a dwarf of childlike-stature who turns out to be the real father of the titular hero, having raped his mother. This incubus motif recurs in the "Þiðreks saga" version of the parentage of Hagen (ON Högni), who was the product of his mother Oda being impregnated by an elf (ON álfr) while she lay in bed; "Þiðreks saga" was translated from a lost German text. The "Alberich" who aids Ortnit is paralleled by the French Auberon, who aids Huon de Bordeaux and whose name derives from "Alberich". Auberon entered English literature through Lord Berner's translation of the "chanson de geste" around 1540, then as "Oberon", the king of elves and fairies in Shakespeare's "A Midsummer Night's Dream" (see below).
As the apparent convergence with "Gezwerc" suggests, the word "alp" declined in use in German after the medieval period, though it still occurs in some fossilised uses, most prominently the word for 'nightmare', "Alptraum" ('elf dream'). Variations of the German elf in later folklore include the moss people and the weisse frauen ('white women'). As in English, however, twentieth-century fantasy fiction has helped to reinvigorate the term.
Early modern ballads.
Elves have a prominent place in a number of closely related ballads which must have originated in the Middle Ages but are first attested in the early modern period, many in Karen Brahes Folio, a Danish manuscript from the 1570s. They circulated widely in Scandinavia and northern Britain. Because they were learned by heart, they sometimes mention elves when that term had become archaic in everyday usage, and have played a major role in transmitting traditional ideas about elves in post-medieval cultures. Some of the early modern ballads, indeed, are still quite widely known, whether through school syllabuses or modern folk music. They therefore give people an unusual degree of access to ideas of elves in older traditional culture.
The ballads are characterised by sexual encounters between everyday people and human(-like) beings referred to in at least some variants as elves (the same characters also appear as mermen, dwarves, and other kinds of supernatural beings). The elves pose a threat to the everyday community by trying to lure people to into the elves' world. Much the most popular example is "Elveskud" and its many variants (paralleled in English as "Clerk Colvill"), where a woman from the elf-world tries to tempt a young knight to join her in dancing, or simply to live among the elves; sometimes he refuses and sometimes he accepts, but in either case he dies, tragically. As in "Elveskud", sometimes the everyday person is a man and the elf a woman, as also in "Elvehøj" (much the same story as "Elveskud" but with a happy ending), "Herr Magnus og Bjærgtrolden", "Herr Tønne af Alsø", "Herr Bøsmer i elvehjem", or the Northern British "Thomas the Rhymer". Sometimes the everyday person is a woman and the elf is a man, as in the northern British "Tam Lin", "The Elfin Knight", and "Lady Isabel and the Elf-Knight", in which the Elf-Knight bears away Isabel to murder her, or the Scandinavian "Harpans kraft". In "The Queen of Elfland's Nourice", a woman is abducted to be a wet-nurse to the elf-queen's baby, but promised that she may return home once the child is weaned.
Post-medieval conceptions of elves.
Early modern Europe saw the emergence for the first time of a distinctive elite culture, while the Reformation encouraged new scepticism and opposition to traditional beliefs, while subsequently Romanticism encouraged their fetishisation by intellectual elites. The effects of this on writing about elves are most apparent in England and Germany, with developments in each country influencing the other. In Scandinavia, the Romantic movement was also prominent, and literary writing was the main context for continued use of the word "elf "except in fossilised words for illnesses. However, oral traditions about beings like elves remained prominent in Scandinavia into the early twentieth century.
England and Germany.
From around the Late Middle Ages, the word "elf" began to be used in English as a term loosely synonymous with the French loan-word "fairy"; in elite culture, at least, it also became associated with diminutive supernatural beings like Puck, hobgoblins, Robin Goodfellow, the English and Scots brownie, and the Northumbrian English hob. In Elizabethan England, Edmund Spenser's "Faerie Queene" (1590-) used 'fairy' and 'elf' interchangeably of human-sized beings, but they are complex imaginary and allegorical figures; his aetiology of the 'Elfe' and 'Elfin kynd' as being made and quickened by Prometheus is entirely his invention.
William Shakespeare also imagined elves as little people. He apparently considered elves and fairies to be the same race. In a speech in "Romeo and Juliet" (1592) an 'elf-lock' (tangled hair) is not caused by an elf as such, but Queen Mab, who is referred to as 'the fairies' midwife'. In "A Midsummer Night's Dream", the elves are almost as small as insects. The influence of Shakespeare and Michael Drayton made the use of "elf" and "fairy" for very small beings the norm, and had a lasting effect seen in fairy tales about elves collected in the modern period.
Early modern English notions of elves became influential in eighteenth-century Germany. The Modern German "Elf" (m) and "Elfe" (f) was introduced as a loan from English in the 1740s and was prominent in Christoph Martin Wieland's 1764 translation of "A Midsummer Night's Dream".
As German Romanticism got underway and writers started to seek authentic folklore, Jacob Grimm rejected "Elf" as a recent Anglicism, and promoted the reuse of the old form "Elb" (plural "Elbe" or "Elben"). In the same vein, Johann Gottfried Herder translated the Danish ballad "Elveskud" in his 1778 collection of folk songs, "", as " ('The Erl-king's Daughter'; it appears that Herder introduced the term "Erlkönig" into German through a mis-Germanisation of the Danish word for "elf"). This in turn inspired Goethe's poem "Der Erlkönig". Goethe's poem then took on a life of its own, inspiring the Romantic concept of the Erlking, which was influential on literary images of elves from the nineteenth century on.
English and German literary traditions both influenced the British Victorian image of elves, which appeared in illustrations as tiny men and women with pointed ears and stocking caps. An example is Andrew Lang's fairy tale "Princess Nobody" (1884), illustrated by Richard Doyle, where fairies are tiny people with butterfly wings, whereas elves are tiny people with red stocking caps. These conceptions remained prominent in twentieth-century children's literature, for example Enid Blyton's The Faraway Tree series, and were influenced by German Romantic literature. Accordingly, in the Brothers Grimm fairy tale "Die Wichtelmänner" (literally 'the little men'), the title protagonists are two tiny naked men who help a shoemaker in his work. Even though "Wichtelmänner" are akin to beings such as kobolds, dwarves and brownies, the tale was translated into English by Margaret Hunt in 1884 as "The Elves and the Shoemaker". This shows how the meanings of "elf" had changed, and was in itself influential: the usage is echoed, for example, in the house-elf of J. K. Rowling's Harry Potter stories. In his turn, J. R. R. Tolkien recommended using the older German form "Elb" in his "Guide to the Names in The Lord of the Rings" (1967) and "Elb, Elben" was consequently introduced in the 1972 German translation of "The Lord of the Rings", having a role in repopularising the form in German.
Scandinavia.
In Scandinavian folklore, an "elf" is called "elver" in Danish, "alv" in Norwegian, "alv" (as a learned borrowing from Old Norse) or "älva" in Swedish, and "álfur" in Icelandic. After the medieval period, these terms were generally less prominent than alternatives like "huldufólk" ('hidden people', Icelandic), "huldra" ('hidden people', Norwegian and Swedish, along with terms like "skogsfru" and "skogsrå"), "vetter", "nisse" (Denmark) and "tomte" (Sweden): the Norwegian expressions seldom appear in genuine folklore, for example.
In Denmark and Sweden, the elves appear as beings distinct from the "vetter", even though the border between them is diffuse. The insect-winged fairies in Celtic mythology are often called "älvor" in modern Swedish or "alfer" in Danish, although the more formal translation is "feer". In a similar vein, the "alf" found in the fairy tale "The Elf of the Rose" by Danish author Hans Christian Andersen is so tiny that he can have a rose blossom for home, and has 'wings that reached from his shoulders to his feet'. Yet Andersen also wrote about "elvere" in "The Elfin Hill". The elves in this story are more alike those of traditional Danish folklore, who were beautiful females, living in hills and boulders, capable of dancing a man to death. Like the "huldra" in Norway and Sweden, they are hollow when seen from the back.
The elves of Norse mythology have survived into folklore mainly as females, living in hills and mounds of stones. The Swedish "älvor", (sing. "älva") were stunningly beautiful girls who lived in the forest with an elven king. In Romantic art and literature, elves are typically pictured as fair-haired, white-clad, and (like most creatures in the Scandinavian folklore) nasty when offended. In folk-stories, they often play the role of disease-spirits. The most common, though also most harmless case was various irritating skin rashes, which were called "älvablåst" (elven blow) and could be cured by a forceful counter-blow (a handy pair of bellows was most useful for this purpose). "Skålgropar", a particular kind of petroglyph found in Scandinavia, were known in older times as "älvkvarnar" (elven mills), pointing to their believed usage. One could appease the elves by offering them a treat (preferably butter) placed into an elven mill.
In order to protect themselves and their livestock against malevolent elves, Scandinavians could use a so-called Elf cross ("Alfkors", "Älvkors" or "Ellakors"), which was carved into buildings or other objects. It existed in two shapes, one was a pentagram and it was still frequently used in early 20th-century Sweden as painted or carved onto doors, walls and household utensils in order to protect against elves. The second form was an ordinary cross carved onto a round or oblong silver plate. This second kind of elf cross was worn as a pendant in a necklace and in order to have sufficient magic it had to be forged during three evenings with silver from nine different sources of inherited silver. In some locations it also had to be on the altar of a church for three consecutive Sundays.
The elves could be seen dancing over meadows, particularly at night and on misty mornings. They left a circle where they had danced, which were called "älvdanser" (elf dances) or "älvringar" (elf circles), and to urinate in one was thought to cause venereal diseases. Typically, elf circles were fairy rings consisting of a ring of small mushrooms, but there was also another kind of elf circle:
If a human watched the dance of the elves, he would discover that even though only a few hours seemed to have passed, many years had passed in the real world. Humans being invited or lured to the elf dance is a common motif transferred from older Scandinavian ballads.
Elves were not exclusively young and beautiful. In the Swedish folktale "Little Rosa and Long Leda", an elvish woman ("älvakvinna") arrives in the end and saves the heroine, Little Rose, on condition that the king's cattle no longer graze on her hill. She is described as a beautiful old woman and by her aspect people saw that she belonged to the "subterraneans".
In Iceland, expression of belief in the cognate huldufólk or 'hidden people', the elves that dwell in rock formations, is still relatively common. Even when Icelanders do not explicitly express their belief, they are often reluctant to express disbelief. A 2006 and 2007 study on superstition by the University of Iceland’s Faculty of Social Sciences revealed that many would not rule out the existence of elves and ghosts, a result similar to a 1974 survey by Erlendur Haraldsson. The lead researcher, Terry Gunnell stated: 'Icelanders seem much more open to phenomena like dreaming the future, forebodings, ghosts and elves than other nations'.
Modern popular culture.
With industrialisation and mass education, traditional folklore about elves waned, but as the phenomenon of popular culture emerged, elves were reimagined, in large part on the basis of Romantic literary depictions and associated medievalism.
Christmas elf.
As American Christmas traditions crystallized in the nineteenth century, the 1823 poem 'A Visit from St. Nicholas' (widely known as '’Twas the Night before Christmas') characterized St Nicholas himself as 'a right jolly old elf' (line 45), but it was the little helpers that were later attributed to him to whom the name stuck. Thus in the USA, Canada, the United Kingdom, and Ireland the modern children's folklore of Santa Claus typically includes green-clad elves with pointy ears, long noses, and pointy hats as Santa's helpers or hired workers. They make the toys in a workshop located in the North Pole. In this portrayal, elves slightly resemble nimble and delicate versions of the elves in English folktakes in the Victorian period from which they derived. The role of elves as Santa's helpers has continued to be popular, as evidenced by the success of the popular Christmas movie "Elf".
Fantasy fiction.
The fantasy genre in the twentieth century grew out of nineteenth-century Romanticism, in which nineteenth-century scholars such as Andrew Lang and the Grimm brothers collected 'fairy-stories' from folklore and in some cases retold them freely.
A pioneering work of the fantasy genre was "The King of Elfland's Daughter", a 1924 novel by Lord Dunsany. Elves played a central role in Tolkien's legendarium, notably "The Silmarillion" and "The Lord of the Rings"; this legendarium was enormously influential on subsequent fantasy writing. Tolkien's writing has such popularity that in the 1960s and afterwards, elves speaking an elvish language similar to those in Tolkien's novels (like Quenya, and Sindarin) became staple non-human characters in high fantasy works and in fantasy role-playing games. Post-Tolkien fantasy elves (popularized by the "Dungeons & Dragons" role-playing game) tend to be more beautiful and wiser than humans, with sharper senses and perceptions. They are said to be gifted in magic, mentally sharp and lovers of nature, art, and song. They are often skilled archers. A hallmark of many fantasy elves is their pointed ears.
In works where elves are the main characters, such as "The Silmarillion" or Wendy and Richard Pini’s comic book series "Elfquest", elves exhibit a similar range of behaviour to a human cast, distinguished largely by their superhuman physical powers. However, where narratives are more human-centered, as in "The Lord of the Rings", elves tend to sustain their role as powerful, sometimes threatening, outsiders.

</doc>
<doc id="9897" url="https://en.wikipedia.org/wiki?curid=9897" title="Evil">
Evil

Evil, in a general context, is the absence or opposite of that which is described as being good. Often, evil is used to denote profound immorality. In certain religious contexts, evil has been described as a supernatural force. Definitions of evil vary, as does the analysis of its motives. However, elements that are commonly associated with evil involve unbalanced behavior involving expediency, selfishness, ignorance, or neglect.
In cultures with an Abrahamic religious influence, evil is usually perceived as the dualistic antagonistic opposite of good, in which good should prevail and evil should be defeated. In cultures with Buddhist spiritual influence, both good and evil are perceived as part of an antagonistic duality that itself must be overcome through achieving "Śūnyatā" meaning emptiness in the sense of recognition of good and evil being two opposing principles but not a reality, emptying the duality of them, and achieving a oneness.
The philosophical question of whether morality is absolute, relative, or illusory leads to questions about the nature of evil, with views falling into one of four opposed camps: moral absolutism, amoralism, moral relativism, and moral universalism.
While the term is applied to events and conditions without agency, the forms of evil addressed in this article presume an evildoer or doers.
Etymology.
The modern English word "evil" (Old English ) and its cognates such as the German and Dutch are widely considered to come from a Proto-Germanic reconstructed form of "*ubilaz", comparable to the Hittite "huwapp-" ultimately from the Proto-Indo-European form and suffixed zero-grade form . Other later Germanic forms include Middle English , Old Frisian (adjective and noun), Old Saxon , Old High German , and Gothic .
The root meaning of the word is of obscure origin though shown to be akin to modern German "Das Übel" (although "evil" is normally translated as "Das Böse") with the basic idea of transgressing.
Chinese moral philosophy.
As with Buddhism below, in Confucianism or Taoism, there is no direct analogue to the way "good and evil" are opposed although reference to "demonic influence" is common in Chinese folk religion. Confucianism's primary concern is with correct social relationships and the behavior appropriate to the learned or superior man. Thus "evil" would correspond to wrong behavior. Still less does it map into Taoism, in spite of the centrality of dualism in that system, but the opposite of the cardinal virtues of Taoism, compassion, moderation, and humility can be inferred to be the analogue of evil in it.
Western philosophy.
Spinoza.
Benedict de Spinoza states
Spinoza assumes a quasi-mathematical style and states these further propositions which he purports to prove or demonstrate from the above definitions in part IV of his "Ethics" :
Nietzsche.
Friedrich Nietzsche, in a rejection of the Judeo-Christian morality, addresses this in two works "Beyond Good and Evil" and "On the Genealogy of Morals" where he essentially says that the natural functional non-good has been socially transformed into the religious concept of evil by the slave mentality of the weak and oppressed masses who resent their masters (the strong).
Psychology.
Carl Jung.
Carl Jung, in his book "Answer to Job" and elsewhere, depicted evil as the "dark side of the Devil". People tend to believe evil is something external to them, because they project their shadow onto others. Jung interpreted the story of Jesus as an account of God facing his own shadow.
Philip Zimbardo.
In 2007, Philip Zimbardo suggested that people may act in evil ways as a result of a collective identity. This hypothesis, based on his previous experience from the Stanford prison experiment, was published in the book "The Lucifer Effect: Understanding How Good People Turn Evil".
Religion.
Bahá'í Faith.
The Bahá'í Faith asserts that evil is non-existent and that it is a concept for the lacking of good, just as cold is the state of no heat, darkness is the state of no light, forgetfulness the lacking of memory, ignorance the lacking of knowledge. All of these are states of lacking and have no real existence.
Thus, evil does not exist, and is relative to man. `Abdu'l-Bahá, son of the founder of the religion, in Some Answered Questions states:
"Nevertheless a doubt occurs to the mind—that is, scorpions and serpents are poisonous. Are they good or evil, for they are existing beings? Yes, a scorpion is evil in relation to man; a serpent is evil in relation to man; but in relation to themselves they are not evil, for their poison is their weapon, and by their sting they defend themselves."
Thus, evil is more of an intellectual concept than a true reality. Since God is good, and upon creating creation he confirmed it by saying it is Good (Genesis 1:31) evil cannot have a true reality.
Buddhism.
The primal duality in Buddhism is between suffering and enlightenment, so the good vs. evil splitting has no direct analogue in it. One may infer however from the general teachings of the Buddha that the catalogued causes of suffering are what correspond in this belief system to 'evil.
Practically this can refer to 1) the three selfish emotions—desire, hate and delusion; and 2) to their expression in physical and verbal actions. See "ten unvirtuous actions in Buddhism". Specifically, "evil" means whatever harms or obstructs the causes for happiness in this life, a better rebirth, liberation from samsara, and the true and complete enlightenment of a buddha (samyaksambodhi).
"What is evil? Killing is evil, lying is evil, slandering is evil, abuse is evil, gossip is evil: envy is evil, hatred is evil, to cling to false doctrine is evil; all these things are evil. And what is the root of evil? Desire is the root of evil, illusion is the root of evil." Gautama Siddhartha, the founder of Buddhism, 563-483 B.C.
Hinduism.
In Hinduism the concept of Dharma or righteousness clearly divides the world into good and evil, and clearly explains that wars have to be waged sometimes to establish and protect Dharma, this war is called Dharmayuddha. This division of good and evil is of major importance in both the Hindu epics of Ramayana and Mahabharata. However, the main emphasis in Hinduism is on bad action, rather than bad people. The Hindu holy text, the Bhagavad Gita, speaks of the balance of good and evil. When this balance goes off, divine incarnations come to help to restore this balance.
Sikhism.
In adherence to the core principle of spiritual evolution, the Sikh idea of evil changes depending on one's position on the path to liberation. At the beginning stages of spiritual growth, good and evil may seem neatly separated. However, once one's spirit evolves to the point where it sees most clearly, the idea of evil vanishes and the truth is revealed. In his writings Guru Arjan explains that, because God is the source of all things, what we believe to be evil must too come from God. And because God is ultimately a source of absolute good, nothing truly evil can originate from God.
Nevertheless, Sikhism, like many other religions, does incorporate a list of "vices" from which suffering, corruption, and abject negativity arise. These are known as the Five Thieves, called such due to their propensity to cloud the mind and lead one astray from the prosecution of righteous action. These are:
One who gives in to the temptations of the Five Thieves is known as "Manmukh", or someone who lives selfishly and without virtue. Inversely, the "Gurmukh, who thrive in their reverence toward divine knowledge, rise above vice via the practice of the high virtues of Sikhism. These are:
Islam.
There is no concept of absolute evil in Islam, as a fundamental universal principle that is independent from and equal with good in a dualistic sense. Within Islam, it is considered essential to believe that all comes from Allah, whether it is perceived as good or bad by individuals; and things that are perceived as "evil" or "bad" are either natural events (natural disasters or illnesses) or caused by humanity's free will to disobey Allah's orders. See Devil (Islam).
According to the Ahmadiyya understanding of Islam, evil does not have a positive existence in itself and is merely the lack of good, just as darkness is the result of lack of light.
Judaism.
In Judaism, evil is not real, it is per se not part of God's creation, but comes into existence through man's bad actions. Human beings are responsible for their choices. However Jews and non-Jews have the free will to choose good (life in olam haba) or bad (death in heaven). (Deuteronomy 28:20) Judaism stresses obedience to God's 613 commandments of the Written Torah (see also Tanakh) and the collective body of Jewish religious laws expounded in the Oral Torah and Shulchan Aruch (see also Mishnah and the Talmud). In Judaism, there is no prejudice in one's becoming good or evil at time of birth, since full responsibility comes with Bar and Bat Mitzvah, when Jewish boys become 13, and girls become 12 years old.
Christianity.
Evil according to a Christian worldview is any action, thought or attitude that is contrary to the character or will of God. This is shown through the law given in both the Old and New Testament. There is no moral action given in the Bible that is contrary to God's character or God's will. Therefore, evil in a Christian world view is contrasted by and in conflict with God's character or God's will. This evil shows itself through deviation from the character or will of God.
Christian theology draws its concept of evil from the Old and New Testaments. The Christian Bible exercises “the dominant influence upon ideas about God and evil in the Western world.” In the Old Testament, evil is understood to be an opposition to God as well as something unsuitable or inferior such as the leader of the fallen angels Satan In the New Testament the Greek word "poneros" is used to indicate unsuitability, while "kakos" is used to refer to opposition to God in the human realm. Officially, the Catholic Church extracts its understanding of evil from its canonical antiquity and the Dominican theologian, Thomas Aquinas, who in "Summa Theologica" defines evil as the absence or privation of good. French-American theologian Henri Blocher describes evil, when viewed as a theological concept, as an "unjustifiable reality. In common parlance, evil is 'something' that occurs in experience that "ought not to be"."
In Mormonism, mortal life is viewed as a test of faith, where one's choices are central to the Plan of Salvation. See Agency (LDS Church). Evil is that which keeps one from discovering the nature of God. It is believed that one must choose not to be evil to return to God.
Christian Science believes that evil arises from a misunderstanding of the goodness of nature, which is understood as being inherently perfect if viewed from the correct (spiritual) perspective. Misunderstanding God's reality leads to incorrect choices, which are termed evil. This has led to the rejection of any separate power being the source of evil, or of God as being the source of evil; instead, the appearance of evil is the result of a mistaken concept of good. Christian Scientists argue that even the most "evil" person does not pursue evil for its own sake, but from the mistaken viewpoint that he or she will achieve some kind of good thereby.
Zoroastrianism.
In the originally Persian religion of Zoroastrianism, the world is a battle ground between the god Ahura Mazda (also called Ormazd) and the malignant spirit Angra Mainyu (also called Ahriman). The final resolution of the struggle between good and evil was supposed to occur on a day of Judgement, in which all beings that have lived will be led across a bridge of fire, and those who are evil will be cast down forever. In afghan belief, angels and saints are beings sent to help us achieve the path towards goodness.
Philosophical questions.
Universality.
A fundamental question is whether there is a universal, transcendent definition of evil, or whether evil is determined by one's social or cultural background. C. S. Lewis, in "The Abolition of Man", maintained that there are certain acts that are universally considered evil, such as rape and murder. However the numerous instances in which rape or murder is morally affected by social context call this into question. Up until the mid-19th century, the United States — along with many other countries — practiced forms of slavery. As is often the case, those transgressing moral boundaries stood to profit from that exercise. Arguably, slavery has always been the same and objectively evil, but men with a motivation to transgress will justify that action.
The Nazis, during World War II, considered genocide to be acceptable, as did the Hutu Interahamwe in the Rwandan genocide. One might point out, though, that the actual perpetrators of those atrocities probably avoided calling their actions genocide, since the objective meaning of any act accurately described by that word is to wrongfully kill a selected group of people, which is an action that at least their victims will understand to be evil. Universalists consider evil independent of culture, and wholly related to acts or intents. Thus, while the ideological leaders of Nazism and the Hutu Interhamwe accepted (and considered it moral) to commit genocide, the belief in genocide as "fundamentally" or "universally" evil holds that those who instigated this genocide are actually evil. Other universalists might argue that although the commission of an evil act is always evil, those who perpetrate may not be wholly evil or wholly good entities. To say that someone who has stolen a candy bar, for instance, becomes wholly evil is a rather untenable position. However, universalists might also argue that a person can choose a decidedly evil or a decidedly good life career, and genocidal dictatorship plainly falls on the side of the former.
Views on the nature of evil tend to fall into one of four opposed camps:
Plato wrote that there are relatively few ways to do good, but there are countless ways to do evil, which can therefore have a much greater impact on our lives, and the lives of other beings capable of suffering.
Usefulness as a term.
One school of thought that holds that no "person" is evil, and that only "acts" may be properly considered evil. Psychologist and mediator Marshall Rosenberg claims that the root of violence is the very concept of "evil" or "badness". When we label someone as bad or evil, Rosenberg claims, it invokes the desire to punish or inflict pain. It also makes it easy for us to turn off our feelings towards the person we are harming. He cites the use of language in Nazi Germany as being a key to how the German people were able to do things to other human beings that they normally would not do. He links the concept of evil to our judicial system, which seeks to create justice via punishment — "punitive justice" — punishing acts that are seen as bad or wrong.He contrasts this approach with what he found in cultures where the idea of evil was non-existent. In such cultures when someone harms another person, they are believed to be out of harmony with themselves and their community, are seen as sick or ill and measures are taken to restore them to a sense of harmonious relations with themselves and others.
Psychologist Albert Ellis agrees, in his school of psychology called Rational Emotive Behavioral Therapy, or REBT. He says the root of anger, and the desire to harm someone, is almost always related to variations of implicit or explicit philosophical beliefs about other human beings. He further claims that without holding variants of those covert or overt belief and assumptions, the tendency to resort to violence in most cases is less likely.
American psychiatrist M. Scott Peck on the other hand, describes evil as "militant ignorance". The original Judeo-Christian concept of "sin" is as a process that leads one to "miss the mark" and not achieve perfection. Peck argues that while most people are conscious of this at least on some level, those that are evil actively and militantly refuse this consciousness. Peck describes evil as a malignant type of self-righteousness which results in a projection of evil onto selected specific innocent victims (often children or other people in relatively powerless positions). Peck considers those he calls evil to be attempting to escape and hide from their own conscience (through self-deception) and views this as being quite distinct from the apparent absence of conscience evident in sociopaths.
According to Peck, an evil person:
He also considers certain institutions may be evil, as his discussion of the My Lai Massacre and its attempted coverup illustrate. By this definition, acts of criminal and state terrorism would also be considered evil.
Necessary evil.
Martin Luther argued that there are cases where a little evil is a positive good. He wrote, "Seek out the society of your boon companions, drink, play, talk bawdy, and amuse yourself. One must sometimes commit a sin out of hate and contempt for the Devil, so as not to give him the chance to make one scrupulous over mere nothings... ."
According to certain schools of political philosophy, leaders should be indifferent to good or evil, taking actions based only upon practicality; this approach to politics was put forth by Niccolò Machiavelli, a 16th-century Florentine writer who advised politicians "...it is far safer to be feared than loved."
The international relations theories of realism and neorealism, sometimes called "realpolitik" advise politicians to explicitly ban absolute moral and ethical considerations from international politics, and to focus on self-interest, political survival, and power politics, which they hold to be more accurate in explaining a world they view as explicitly amoral and dangerous. Political realists usually justify their perspectives by laying claim to a "higher moral duty" specific to political leaders, under which the greatest evil is seen to be the failure of the state to protect itself and its citizens. Machiavelli wrote: "...there will be traits considered good that, if followed, will lead to ruin, while other traits, considered vices which if practiced achieve security and well being for the Prince."
Anton LaVey, founder of the Church of Satan, was a materialist and claimed that evil is actually good. He was responding to the common practice of describing sexuality or disbelief as evil, and his claim was that when the word "evil" is used to describe the natural pleasures and instincts of men and women, or the skepticism of an inquiring mind, the things called evil are really good.
References.
Notes
Further reading

</doc>
<doc id="9901" url="https://en.wikipedia.org/wiki?curid=9901" title="Epistle to the Hebrews">
Epistle to the Hebrews

Epistle to the Hebrews, or Letter to the Hebrews, or in the Greek manuscripts, simply To the Hebrews ( Πρὸς Έβραίους) is a text of the New Testament. In some versions of the Bible, its author refers to it as a "word of exhortation", using the same term used in to describe a sermon. In the Modern Literal Version the direct translation into English gives the phrase "word of encouragement". Since the earliest days of the Church, its authorship and canonicity have been debated. 
The text is traditionally attributed to Paul the Apostle, but doubt on Pauline authorship is reported already by Eusebius, and modern biblical scholarship considers its authorship unknown, perhaps written in deliberate imitation of the style of Paul.
Scholars of Greek consider its writing to be more polished and eloquent than any other book of the New Testament. The book has earned the reputation of being a masterpiece. It also has been described as an intricate New Testament book. Scholars believe it was written for Jewish Christians who lived in Jerusalem. Its purpose was to exhort Christians to persevere in the face of persecution. The theme of the epistle is the doctrine of the person of Christ and his role as mediator between God and humanity.
The epistle opens with an exaltation of Jesus as "the radiance of God's glory, the express image of his being, and upholding all things by his powerful word". The epistle presents Jesus with the titles "pioneer" or "forerunner", "Son" and "Son of God", "priest" and "high priest".
The epistle casts Jesus as both exalted Son and high priest, a unique dual Christology.
Composition.
Hebrews uses Old Testament quotations interpreted in light of first century rabbinical Judaism. New Testament and Second Temple Judaism scholar Eric Mason argues that the conceptual background of the priestly Christology of the Epistle to the Hebrews closely parallels presentations of the messianic priest and Melchizedek in the Qumran scrolls. In both Hebrews and Qumran a priestly figure is discussed in the context of a Davidic figure; in both cases a divine decree appoints the priests to their eschatological duty; both priestly figures offer an eschatological sacrifice of atonement. Although the author of Hebrews was not directly influenced by Qumran's "Messiah of Aaron", these and other conceptions did provide "a precedent... to conceive Jesus similarly as a priest making atonement and eternal intercession in the heavenly sanctuary".
Authorship.
By the end of the first century there was not a consensus over the author’s identity. Clement of Rome, Barnabas, the Apostle Paul, and other names were proposed. Others later suggested Luke the Evangelist, Apollos and Priscilla as possible authors.
Though no author is named, the original King James Version of the Bible titled the work "The Epistle of Paul the Apostle to the Hebrews". However, the KJV's attribution to Paul was only a guess, and not a very good one according to the majority of recent scholarship. Its vastly different style, different theological focus, different spiritual experience—all are believed to make Paul's authorship of Hebrews increasingly indefensible. At present, neither modern scholarship nor church teaching ascribes Hebrews to Paul.
Because of its anonymity, it had some trouble being accepted as part of the Christian canon, being classed with the Antilegomena. Eventually it was accepted as scripture because of its sound theology, eloquent presentation, and other intrinsic factors. In antiquity, certain circles began to ascribe it to Paul in an attempt to provide the anonymous work an explicit apostolic pedigree.
In the 4th century, Jerome and Augustine of Hippo supported Paul's authorship: the Church largely agreed to include Hebrews as the fourteenth letter of Paul, and affirmed this authorship until the Reformation. Scholars argued that in the 13th Chapter of Hebrews, Timothy is referred to as a companion. Timothy was Paul's missionary companion in the same way Jesus sent disciples out in pairs of two. Also, the writer states that he wrote the letter from "Italy", which also at the time fits Paul. The difference in style is explained as simply an adjustment to a distinct audience, to the Jewish Christians who were being persecuted and pressured to go back to traditional Judaism.
Many scholars now believe that the author was one of Paul's pupils or associates, citing stylistic differences between Hebrews and the other Pauline epistles. Recent scholarship has favored the idea that the author was probably a leader of a predominantly Jewish congregation to whom he or she was writing.
Believing the author to have been Priscilla, Hoppin posits that the name was omitted either to suppress its female authorship, or to protect the letter itself from suppression.
Also convinced that Priscilla was the author of Hebrews, Gilbert Bilezikian, professor of biblical studies at Wheaton College, remarks on "the conspiracy of anonymity in the ancient church," and reasons: "The lack of any firm data concerning the identity of the author in the extant writings of the church suggests a deliberate blackout more than a case of collective loss of memory."
A.J. Gordon ascribes the authorship of "Hebrews" to Priscilla, writing that "It is evident that the Holy Spirit made this woman Priscilla a teacher of teachers". Originally proposed by Adolf von Harnack in 1900, Harnack’s reasoning won the support of prominent Bible scholars of the early twentieth century. Harnack believes the letter was written in Rome—not to the Church, but to the inner circle. In setting forth his evidence for Priscillan authorship, he finds it amazing that the name of the author was blotted out by the earliest tradition. Citing , he says it was written by a person of "high standing and apostolic teacher of equal rank with Timothy". If Luke, Clemens, Barnabas, or Apollos had written it, Harnack believes their names would not have been obliterated.
Donald Guthrie’s commentary "The Letter to the Hebrews" (1983) mentions Priscilla by name as a suggested author.
However, the author's use of the masculine gender participle when referring to himself in Hebrews 11:32 ("And what shall I more say? for the time would fail me to tell of Gideon, and of Barak, and of Samson, and of Jephtha; of David also, and Samuel, and of the prophets") makes it less likely it could be Priscilla or any other woman. 
In the 3rd century, Origen wrote of the letter, "In the epistle entitled "To The Hebrews" the diction does not exhibit the characteristic roughness of speech or phraseology admitted by the Apostle himself, the construction of the sentences is closer to the Greek usage, as anyone capable of recognising differences of style would agree. On the other hand the matter of the epistle is wonderful, and quite equal to the Apostle's acknowledged writings: the truth of this would be admitted by anyone who has read the Apostle carefully...If I were asked my personal opinion, I would say that the matter is the Apostle's but the phraseology and construction are those of someone who remembered the Apostle's teaching and wrote his own interpretation of what his master had said. So if any church regards this epistle as Paul's, it should be commended for so doing, for the primitive Church had every justification for handing it down as his. Who wrote the epistle is known to God alone: the accounts that have reached us suggest that it was either Clement, who became Bishop of Rome, or Luke, who wrote the gospel and the Acts." Further, "Men of old have handed it down as Paul's, but who wrote the Epistle God only knows".
Date.
The use of tabernacle terminology in Hebrews has been used to date the epistle before the destruction of the temple, the idea being that knowing about the destruction of both Jerusalem and the temple would have influenced the development of the author's overall argument. Therefore, the most probable date for its composition is the second half of the year 63 or the beginning of 64, according to the Catholic Encyclopedia.
Audience.
Traditional scholars have argued the letter's audience was Jewish Christians, as early as the end of the 2nd century (hence its title, "The Epistle to the Hebrews"). Other scholars have suggested that Hebrews is part of an internal New Testament debate between the extreme Judaizers (who argued that non-Jews must convert to Judaism before they can receive the Holy Spirit of Jesus' new covenant) versus the extreme Antinomians (who argued that Jews must reject God's commandments and that Jewish law was no longer in effect). James and Paul represent the moderates of each faction, respectively, and Peter served as moderator. The Epistle emphasizes that non-Jewish followers of Jesus do not need to convert to Judaism to share in all of God's promises to Jews. American Baptist theologian Edgar Goodspeed claims, "But the writer's Judaism is not actual and objective, but literary and academic, manifestly gained from the reading of the Septuagint Greek version of the Jewish scriptures, and his polished Greek style would be a strange vehicle for a message to Aramaic-speaking Jews or Christians of Jewish blood".
It sets before the Jew the claims of Christianity—to bring the Jew to the full realization of the relation of Judaism to Christianity, to make clear that Christ has fulfilled those temporary and provisional institutions, and has thus abolished them. This view is commonly referred to as Supersessionism.
Some had stopped assembling together, and this was possibly due to persecution. 
Purpose for writing.
Those to whom Hebrews is written seem to have begun to doubt whether Jesus could really be the Messiah for whom they were waiting, because they believed the Messiah prophesied in the Hebrew Scriptures was to come as a militant king and destroy the enemies of his people. Jesus, however, came as a mere man who was arrested by the Jewish leaders and who suffered and even died under Roman crucifixion. And although he was seen resurrected, he still left the earth and his people, who now face persecution rather than victory. The book of Hebrews solves this problem by arguing that the Hebrew Scriptures also foretold that the Messiah would be a priest (although of a different sort than the traditional Levitical priests) and Jesus came to fulfill this role, as a sacrificial offering to God, to atone for sins. His role of a king is yet to come, and so those who follow him should be patient and not be surprised that they suffer for now.
Some scholars today believe the document was written to prevent apostasy. Some have interpreted apostasy to mean a number of different things, such as a group of Christians in one sect leaving for another more conservative sect, one of which the author disapproves. Some have seen apostasy as a move from the Christian assembly to pagan ritual. In light of a possibly Jewish-Christian audience, the apostasy in this sense may be in regard to Jewish-Christians leaving the Christian assembly to return to the Jewish synagogue. The author writes, "Let us hold fast to our confession".
The book could be argued to affirm special creation. It affirms that God by His Son, Jesus Christ, made the worlds. "God...hath in these last days spoken unto us by his Son...by whom also he made the worlds". The epistle also states that the worlds themselves do not provide the evidence of how God formed them. "Through faith we understand that the worlds were framed by the word of God, so that things which are seen were not made of things which do appear".
Style.
Hebrews is a very consciously "literary" document. The purity of its Greek was noted by Clement of Alexandria, according to Eusebius ("Historia Eccl. ", VI, xiv), and Origen of Alexandria asserted that every competent judge must recognize a great difference between this epistle and those of Paul (Eusebius, VI, xxv).
This letter consists of two strands: an expositional or doctrinal strand, and a hortatory or strongly urging strand which punctuates the exposition parenthetically at key points as warnings to the readers. 
Hebrews does not fit the form of a traditional Hellenistic epistle, lacking a proper prescript. Modern scholars generally believe this book was originally a sermon or homily, although possibly modified after it was delivered to include the travel plans, greetings and closing. 
Hebrews contains many references to the Old Testament—specifically to its Septuagint text.
Christology.
From "The Interpreter's Bible" 1955
“We may sum up our author’s Christology negatively by saying that he has nothing to do with the older Hebrew messianic hopes of a coming Son of David, who would be a divinely empowered human leader to bring in the kingdom of God on earth; and that while he still employs the figure of a militant, apocalyptic king ... who will come again..., this is not of the essence of his thought about Christ.<br>
“Positively, our author presents Christ as divine in nature, and solves any possible objection to a divine being who participates in human experience, especially in the experience of death, by the priestly analogy. He seems quite unconscious of the logical difficulties of his position proceeding from the assumption that Christ is both divine and human, at least human in experience although hardly in nature. ” TIB XI p. 588
External links.
Online translations of the Epistle to the Hebrews:
Related articles:

</doc>
<doc id="9902" url="https://en.wikipedia.org/wiki?curid=9902" title="Esther">
Esther

Esther (; ), born Hadassah, is the eponymous heroine of the Book of Esther.
According to the Hebrew Bible, Esther was a Jewish queen of the Persian king Ahasuerus. Ahasuerus is traditionally identified with Xerxes I during the time of the Achaemenid empire. Her story is the basis for the celebration of Purim in Jewish tradition.
In the Bible.
King Ahasuerus (Xerxes I) held a 180-day feast in Susa (Shoushan). While in "high spirits" from the wine, he ordered his queen, Vashti, to appear before him and his guests to display her beauty. But when the attendants delivered the king's command to Queen Vashti, she refused to come. Furious at her refusal to obey, the king asked his wise men what should be done. One of them said that all the women in the empire would hear that "The King Ahasuerus commanded Vashti the queen to be brought in before him, but she came not." Then these women would despise their husbands, which would cause many problems in the kingdom. Therefore it would be prudent to depose Vashti.
Many beautiful maidens were then brought before the king in order that he might choose a successor to the unruly Vashti. The King chose Esther, an orphan daughter of a Benjamite named Abihail. Esther was originally named Hadassah, meaning myrtle. She had spent her life among the Jewish exiles in Persia, where she lived under the protection of her cousin Mordecai. When Cyrus gave permission for the exiles to return unto Jerusalem, she stayed with Mordecai.
Mordecai was the son of Jair, a Benjamite, who had been carried into captivity together with Jeconiah by Nebuchadnezzar, King of Babylon. Mordecai became chief minister of Ahasuerus and lived in the Persian capital of Susa. One day, while sitting at the gate of the king's palace, Mordecai overheard a plot of two eunuchs, Bigthan and Teresh, to kill the king. Having informed the king through Esther of the conspiracy, Mordecai brought about the execution of the two conspirators, and the event was recorded in the royal chronicles.
The grand vizier, Haman the Agagite, commanded Mordecai to do obeisance to him. Upon Mordecai's refusal to prostrate himself, Haman informed the king that the Jews were a useless and turbulent people and inclined to disloyalty, and he promised to pay 10,000 silver talents into the royal treasury for the permission to pillage and exterminate this alien race. The king then issued a proclamation ordering the confiscation of Jewish property and a general extermination of all the Jews within the empire.
Mordecai tore his robes and put ash on his head (signs of mourning or grieving) on hearing this news. Sheltered in the harem, Esther was unaware of the decree until Mordecai advised her of it through Hathach, one of the king's chamberlains. He informed her that she should not think that she would escape simply because she was in the palace. At the request of Esther, Mordecai instituted at Susa a general fast for three days.
Esther could not approach the king without being summoned, on pain of death, and the king had not summoned her in thirty days, implying that she may have fallen out of favor. Nevertheless, at the end of the three days, Esther dressed in her royal apparel and went before the king. When the king asked her what her request was, she invited the king and Haman to come to a banquet she had prepared. At the banquet they accepted her invitation to dine with her again on the following day. Haman, carried away by the joy that this honour gave him, issued orders for the erection of a gallows on which he purposed to hang the hated Mordecai.
But that night the king, being sleepless, ordered the chronicles of the nation to be read to him. Recalling that Mordecai had never been rewarded for his service in revealing the plot of the eunuchs, he asked Haman, the next day, to suggest a suitable reward for one "whom the king desired to honour". Thinking it was himself that the king had in mind, Haman suggested the use of the king's apparel and insignia. These the king ordered to be bestowed on Mordecai.
Only at the second dinner party, when the king was sufficiently beguiled by her charms, did Esther reveal for the first time her identity as a Jew, and accused Haman of the plot to destroy her and her people. The king ordered that Haman should be hanged on the gallows prepared for Mordecai, and, confiscating his property, bestowed it upon the intended victim. The king then appointed Mordecai as his prime minister, and issued a decree authorizing the Jews to defend themselves.
Purim.
The Jews established an annual feast, the feast of Purim, in memory of their deliverance. Haman set the date of Adar 13 to commence his campaign against the Jews. This determined the date of the festival of Purim.
Origin and meaning of the name Esther.
It has been conjectured that the name Esther is derived from a reconstructed Median word "astra" meaning myrtle.
An alternative view is that "Esther" is derived from the theonym Ishtar. The Book of Daniel provides accounts of Jews in exile being assigned names relating to Babylonian gods and "Mordecai" is understood to mean servant of Marduk, a Babylonian god. "Esther" may have been a different Hebrew interpretation from the Proto-Semitic root "star/'morning/evening star'", which descended with the /th/ into the Ugaritic "Athtiratu" and Arabian "Athtar". The derivation must then have been secondary for the initial ayin to be confused with an aleph (both represented by vowels in Akkadian), and the second consonant descended as a /s/ (like in the Aramaic "asthr" "bright star"), rather than a /sh/ as in Hebrew and most commonly in Akkadian.
Wilson, who identified Ahasuerus with Xerxes I and Vashti with Amestris, suggested that both "Amestris" and "Esther" derived from Akkadian "Ammi-Ishtar" or "Ummi-Ishtar". Hoschander alternatively suggested "Ishtar-udda-sha" ("Ishtar is her light") as the origin with the possibility of "-udda-sha" being connected with the similarly sounding Hebrew name Hadassah. These names however remain unattested in sources, and come from the original Babylonian Empire from 2000 BCE, not the Chaldean Empire or Persian Empire of the Book of Esther.
The Targum connects the name with the Persian word for "star", "ستاره" "setareh", explaining that Esther was so named for being as beautiful as the Morning Star.
In the Talmud (Tractate Yoma 29a), Esther is compared to the "morning star", and is considered the subject of Psalm 22, because its introduction is a "song for the morning star".
Interpretations.
Dianne Tidball argues that while Vashti is a "feminist icon", Esther is a post-feminist icon.
Abraham Kuyper notes some "disagreeable aspects" to her character: that she should not have agreed to take Vashti's place, that she refrained from saving her nation until her own life was threatened, and that she carries out bloodthirsty vengeance.
The tale opens with Esther as beautiful and obedient, but also a relatively passive figure. During the course of the story, she evolves into someone who takes a decisive role in her own future and that of her people. According to Sidnie White Crawford, "Esther's position in a male court mirrors that of the Jews in a Gentile world, with the threat of danger ever present below the seemingly calm surface." Esther is related to Daniel in that both represent a "type" for Jews living in Diaspora, and hoping to live a successful life in an alien environment.
Esther as rhetorical model.
Since she used only rhetoric to convince the king to save her people, Esther has been interpreted as a model for a successful rhetoric of marginalized groups persuading those who have power over them. According to Susan Zaeske, the story of Esther is a "rhetoric of exile and empowerment that, for millennia, has notably shaped the discourse of marginalized peoples such as Jews, women, African Americans.” 
Zaeske argues that Esther speaks not only for women but for a multi-gender oppressed group and does it in such a way that “depicts rhetorical dynamics, not only of Jews living in a foreign court, but also of women coping in a society intensely hostile to their gender.” In this way, Esther’s rhetoric has been interpreted not as strictly feminist rhetoric or strictly Jewish rhetoric but rhetoric of intersectional exiled or marginalized groups.
Persian culture.
Given the great historical link between Persian and Jewish history, modern day Persian Jews are called "Esther's Children". A building alleged to be the Tomb of Esther and Mordecai is located in Hamadan, Iran, although the village of Kfar Bar'am in northern Israel also claims to be the burial place of Queen Esther.
Depictions of Esther.
There are several paintings depicting Esther, including one by Millais.
Canonicity in Christianity.
The status of Esther as a canonical book of the Bible has historically been under dispute. For example, in the first several centuries of Christianity, Esther does not appear in the lists of books produced by Melito, Athanasius, Cyril, Gregory of Nazianzus, and others. Additionally, no copies of Esther were found at Qumran in the contents of the Dead Sea Scrolls. Nevertheless, by the fourth century CE, the majority of Western churches accepted Esther as a part of their Bibles.
Esther is also commemorated as a matriarch in the Calendar of Saints of the Lutheran Church–Missouri Synod on May 24. She is also recognized as a saint in the Eastern Orthodox and Coptic Orthodox Churches.

</doc>
<doc id="9903" url="https://en.wikipedia.org/wiki?curid=9903" title="Entamoeba">
Entamoeba

Entamoeba is a genus of Amoebozoa found as internal parasites or commensals of animals.
In 1875, Fedor Lösch described the first proven case of amoebic dysentery in St. Petersburg, Russia. He referred to the amoeba he observed microscopically as 'Amoeba coli'; however it is not clear whether he was using this as a descriptive term or intended it as a formal taxonomic name. The genus "Entamoeba" was defined by Casagrandi and Barbagallo for the species "Entamoeba coli", which is known to be a commensal organism. Lösch's organism was renamed "Entamoeba histolytica" by Fritz Schaudinn in 1903; he later died, in 1906, from a self-inflicted infection when studying this amoeba. For a time during the first half of the 20th century the entire genus "Entamoeba" was transferred to "Endamoeba", a genus of amoebas infecting invertebrates about which little is known. This move was reversed by the International Commission on Zoological Nomenclature in the late 1950s, and "Entamoeba" has stayed 'stable' ever since.
Species.
Several species are found in humans and animals. "Entamoeba histolytica" is the pathogen responsible for invasive 'amoebiasis' (which includes amoebic dysentery and amoebic liver abscesses). Others such as "Entamoeba coli" (not to be confused with "Escherichia coli") and "Entamoeba dispar" are harmless. With the exception of "Entamoeba gingivalis", which lives in the mouth, and "E. moshkovskii", which is frequently isolated from river and lake sediments, all "Entamoeba" species are found in the intestines of the animals they infect. "Entamoeba invadens" is a species that can cause a disease similar to "E. histolytica" but in reptiles. In contrast to other species, "E. invadens" forms cysts in vitro in the absence of bacteria and is used as a model system to study this aspect of the life cycle. Many other species of "Entamoeba" have been described and it is likely that many others remain to be found.
Structure.
"Entamoeba" cells are small, with a single nucleus and typically a single lobose pseudopod taking the form of a clear anterior bulge. They have a simple life cycle. The trophozoite (feeding-dividing form) is approximately 10-20 μm in diameter and feeds primarily on bacteria. It divides by simple binary fission to form two smaller daughter cells. Almost all species form cysts, the stage involved in transmission (the exception is "Entamoeba gingivalis"). Depending on the species, these can have one, four or eight nuclei and are variable in size; these characteristics help in species identification.
Classification.
"Entamoeba" belongs to the Archamoebae, which like many other anaerobic eukaryotes lack mitochondria. This group also includes "Endolimax" and "Iodamoeba", which also live in animal intestines and are similar in appearance to "Entamoeba", although this may partly be due to convergence. Also in this group are the free-living amoebo-flagellates of the genus "Mastigamoeba" and related genera. Certain other genera of symbiotic amoebae, such as "Endamoeba", might prove to be synonyms of "Entamoeba" but this is still unclear.
Culture.
Fission.
Studying "Entamoeba invadens", David Biron of the Weizmann Institute of Science and coworkers found that about one third of the cells are unable to separate unaided and recruit a neighboring amoeba (dubbed the "midwife") to complete the fission. He writes:
They also reported a similar behavior in "Dictyostelium".
Since "E. histolytica" does not form cysts in the absence of bacteria, "E. invadens" has become used as a model for encystation studies as it will form cysts under axenic growth conditions, which simplifies analysis. After inducing encystation in "E. invadens", DNA replication increases initially and then slows down. On completion of encystation, predominantly tetra-nucleate cysts are formed along with some uni-, bi- and tri-nucleate cysts.
Differentiation and cell biology.
Uni-nucleated trophozoites convert into cysts in a process called encystation. The number of nuclei in the cyst varies from 1 to 8 among species and is one of the characteristics used to tell species apart. Of the species already mentioned, "Entamoeba coli" forms cysts with 8 nuclei while the others form tetra-nucleated cysts. Since "E. histolytica" does not form cysts "in vitro" in the absence of bacteria, it is not possible to study the differentiation process in detail in that species. Instead the differentiation process is studied using "E. invadens", a reptilian parasite that causes a very simiilar disease to "E. histolytica" and which can be induced to encyst "in vitro". Until recently there was no genetic transfection vector available for this organism and detailed study at the cellular level was not possible. However, recently a transfection vector was developed and the transfection conditions for "E. invadens" were optimised which should enhance the research possibilities at the molecular level of the differentiation process.
Meiosis.
In sexually reproducing eukaryotes, homologous recombination (HR) ordinarily occurs during meiosis. The meiosis-specific recombinase, Dmc1, is required for efficient meiotic HR, and Dmc1 is expressed in "E. histolytica". The purified Dmc1 from "E. histolytica" forms presynaptic filaments and catalyzes ATP-dependent homologous DNA pairing and DNA strand exchange over at least several thousand base pairs. The DNA pairing and strand exchange reactions are enhanced by the eukaryotic meiosis-specific recombination accessory factor (heterodimer) Hop2-Mnd1. These processes are central to meiotic recombination, suggesting that "E. histolytica" undergoes meiosis.
Studies of "E. invadens" found that, during the conversion from the tetraploid uninucleate trophozoite to the tetranucleate cyst, homologous recombination is enhanced. Expression of genes with functions related to the major steps of meiotic recombination also increased during encystations. These findings in "E. invadens", combined with evidence from studies of "E. histolytica" indicate the presence of meiosis in the "Entamoeba".

</doc>
<doc id="9904" url="https://en.wikipedia.org/wiki?curid=9904" title="England national football team">
England national football team

The England national football team represents England in international football and is controlled by The Football Association, the governing body for football in England. England are one of the two oldest national teams in football; alongside Scotland, whom they played in the world's first international football match in 1872. England's home ground is Wembley Stadium, London, and the current team manager is Roy Hodgson.
Although part of the United Kingdom, England has always had a representative side that plays in major professional tournaments, though not in the Olympic Games, as the IOC has always recognised United Kingdom representative sides.
England contest the FIFA World Cup and UEFA European Championship, which alternate biennially. England won the World Cup in 1966, when they hosted the finals, defeating West Germany 4–2 in extra time in the final. Their best performance since has been a semi-final appearance in 1990. England have never won the UEFA European Football Championship – their best performances being semi-final appearances at the 1968 and 1996 Championships, the latter of which they hosted.
History.
The England national football team is the joint-oldest in the world; it was formed at the same time as Scotland. A representative match between England and Scotland was played on 5 March 1870, having been organised by the Football Association. A return fixture was organised by representatives of Scottish football teams on 30 November 1872.
This match, played at Hamilton Crescent in Scotland, is viewed as the first official international football match, because the two teams were independently selected and operated, rather than being the work of a single football association. Over the next forty years, England played exclusively with the other three Home Nations—Scotland, Wales and Ireland—in the British Home Championship.
To begin with, England had no permanent home stadium. They joined FIFA in 1906 and played their first ever games against countries other than the Home Nations on a tour of Central Europe in 1908. Wembley Stadium was opened in 1923 and became their home ground. The relationship between England and FIFA became strained, and this resulted in their departure from FIFA in 1928, before they rejoined in 1946. As a result, they did not compete in a World Cup until 1950, in which they were beaten in a 1–0 defeat by the United States, failing to get past the first round in one of the most embarrassing defeats in the team's history.
Their first ever defeat on home soil to a foreign team was an 0–2 loss to the Republic of Ireland, on 21 September 1949 at Goodison Park. A 6–3 loss in 1953 to Hungary, was their second defeat by a foreign team at Wembley. In the return match in Budapest, Hungary won 7–1. This still stands as England's worst ever defeat. After the game, a bewildered Syd Owen said, "it was like playing men from outer space". In the 1954 FIFA World Cup, England reached the quarter-finals for the first time, and lost 4–2 to reigning champions Uruguay.
Although Walter Winterbottom was appointed as England's first ever full-time manager in 1946, the team was still picked by a committee until Alf Ramsey took over in 1963. The 1966 FIFA World Cup was hosted in England and Ramsey guided England to victory with a 4–2 win against West Germany after extra time in the final, during which Geoff Hurst famously scored a hat-trick. In UEFA Euro 1968, the team reached the semi-finals for the first time, being eliminated by Yugoslavia.
England qualified for the 1970 FIFA World Cup in Mexico as reigning champions, and reached the quarter-finals, where they were knocked out by West Germany. England had been 2–0 up, but were eventually beaten 3–2 after extra time. They failed in qualification for the 1974, leading to Ramsey's dismissal, and 1978 FIFA World Cups. Under Ron Greenwood, they managed to qualify for the 1982 FIFA World Cup in Spain (the first time competitively since 1962); despite not losing a game, they were eliminated in the second group stage.
The team under Bobby Robson fared better as England reached the quarter-finals of the 1986 FIFA World Cup, losing 2–1 to Argentina in a game made famous by two goals by Maradona for very contrasting reasons, before losing every match in UEFA Euro 1988. They next went on to achieve their second best result in the 1990 FIFA World Cup by finishing fourth – losing again to West Germany in an semi-final finishing 1–1 after extra time, then 3–4 in England's first penalty shoot-out.
Despite losing to Italy in the third place play-off, the members of the England team were given bronze medals identical to the Italians’. The England team of 1990 were welcomed home as heroes and thousands of people lined the streets, for a spectacular open-top bus parade. However, the team did not win any matches in UEFA Euro 1992, drawing with tournament winners Denmark, and later with France, before being eliminated by host nation Sweden.
The 1990s saw four England managers, each in the role for a relatively brief period. Graham Taylor was Robson's successor, but resigned after England failed to qualify for the 1994 FIFA World Cup. At UEFA Euro 1996, held in England, Terry Venables led England, equalling their best performance at an European Championship, reaching the semifinals as they did in 1968.
He resigned following investigations into his financial activities. His successor, Glenn Hoddle, similarly left the job for non-footballing reasons after just one international tournament – the 1998 FIFA World Cup — in which England were eliminated in the second round again by Argentina and again on penalties (after a 2–2 draw). Following Hoddle's departure, Kevin Keegan took England to UEFA Euro 2000, but performances were disappointing and he resigned shortly afterwards.
Sven-Göran Eriksson took charge of the team between 2001 and 2006, and was the first non–English manager of England. Despite controversial press coverage of his personal life, Eriksson was consistently popular with the majority of fans. He guided England to the quarter-finals of the 2002 FIFA World Cup, UEFA Euro 2004, and the 2006 FIFA World Cup. He lost only five competitive matches during his tenure, and England rose to an No.4 world ranking under his guidance. His contract was extended by the Football Association by two years, to include UEFA Euro 2008. However, it was terminated by them at the 2006 FIFA World Cup's conclusion.
Steve McClaren was then appointed as head coach, and was sacked unanimously by The Football Association on 22 November 2007, after failing to get the team to Euro 2008. The following month, he was replaced by an second foreign manager, Italian Fabio Capello, whose experience included stints at Juventus and Real Madrid.
England won all but one of their qualifying games for the 2010 FIFA World Cup, but at the tournament itself, England drew their opening two games; this led to questions about the team's spirit, tactics and ability to handle pressure. They progressed to the next round, where they were beaten 4–1 by Germany, their heaviest defeat in an World Cup.
In February 2012, Capello resigned from his role as England manager, following a disagreement with the FA over their request to remove John Terry from team captaincy after accusations of racial abuse concerning the player. Following this, there was media speculation that Harry Redknapp would take the job. However, on 1 May 2012, Roy Hodgson was announced as the new manager, just six weeks before UEFA Euro 2012. England managed to finish top of their group, winning two and drawing one of their fixtures, but exited the Championships in the quarter-finals via a penalty shoot-out, this time to Italy.
In the 2014 FIFA World Cup, England were eliminated at the group stage for the first time since the 1958 World Cup, and the first time at a major tournament since Euro 2000. England's points total of one from three matches was its worst ever in the World Cup, obtaining one point from drawing against Costa Rica in their last match. England qualified for UEFA Euro 2016, with 10 wins from 10 qualifying matches.
Team image.
Media coverage.
All England matches are broadcast with full commentary on BBC Radio 5 Live. From the 2008–09 season until the 2017–18 season, England's home and away qualifiers, and friendlies both home and away are broadcast live on ITV (often with the exception of STV, the ITV affiliate in central and northern Scotland). England's away qualifiers for the 2010 World Cup were shown on Setanta Sports until that company's collapse. As a result of Setanta Sports's demise, England's World Cup qualifier in Ukraine on 10 October 2009 was shown in the United Kingdom on a pay-per-view basis via the internet only. This one-off event was the first time an England game had been screened in such a way. The number of subscribers, paying between £4.99 and £11.99 each, was estimated at between 250,000 and 300,000 and the total number of viewers at around 500,000.
Colours.
England's traditional home colours are white shirts, navy blue shorts and white or black socks. The team has periodically worn an all-white kit.
Although England's first away kits were blue, England's traditional away colours are red shirts, white shorts and red socks. In 1996, England's away kit was changed to grey shirts, shorts and socks. This kit was only worn three times, including against Germany in the semi-final of Euro 96 but the deviation from the traditional red was unpopular with supporters and the England away kit remained red until 2011, when a navy blue away kit was introduced. The away kit is also sometimes worn during home matches, when a new edition has been released to promote it.
England have occasionally had a third kit. At the 1970 World Cup England wore a third kit with pale blue shirts, shorts and socks against Czechoslovakia. They had a kit similar to Brazil's, with yellow shirts, yellow socks and blue shorts which they wore in the summer of 1973. For the World Cup in 1986 England had a third kit of pale blue, imitating that worn in Mexico sixteen years before and England retained pale blue third kits until 1992, but they were rarely used.
Umbro first agreed to manufacture the kit in 1954 and since then has supplied most of the kits, the exceptions being from 1959-1965 with Bukta and 1974-1984 with Admiral. Nike purchased Umbro in 2008 and took over as kit supplier in 2013 following their sale of the Umbro brand.
Logo.
The motif of the England national football team has three lions "passant guardant", the emblem of King Richard I, who reigned from 1189 to 1199. The lions, often blue, have had minor changes to colour and appearance. Initially topped by a crown, this was removed in 1949 when the FA was given an official coat of arms by the College of Arms; this introduced ten Tudor roses, one for each of the regional branches of the FA. Since 2003, England top their logo with a star to recognise their World Cup win in 1966; this was first embroidered onto the left sleeve of the home kit, and a year later was moved to its current position, first on the away shirt.
Home stadium.
For the first fifty years of their existence, England played their home matches all around the country. They initially used cricket grounds before later moving on to football clubs' stadiums. The original Empire Stadium was built in Wembley, London, for the British Empire Exhibition.
England played their first match at the stadium in 1924 against Scotland and for the next 27 years Wembley was used as a venue for matches against Scotland only. The stadium later became known simply as Wembley Stadium and it became England's permanent home stadium during the 1950s. In October 2000, the stadium closed its doors, ending with a defeat.
This stadium was demolished during the period of 2002–2003, and work began to completely rebuild it. During this time, England played at a number of different venues across the country, though by the time of the 2006 FIFA World Cup qualification, this had largely settled down to having Manchester United's Old Trafford stadium as the primary venue, with Newcastle United's St. James' Park used on occasions when Old Trafford was unavailable.
They returned to the new Wembley Stadium in March 2007. The stadium is now owned by the Football Association, via its subsidiary Wembley National Stadium Limited.
Players.
Current squad.
The following players were in the squad for the friendly matches against Germany on 26 March and the Netherlands on 29 March 2016.
"Caps and goals updated as of 29 March 2016 after the match against the Netherlands."
Recent call ups.
The following players have also been called up to the England squad within the last twelve months.
Notes:
Records.
Most capped players.
"Updated 17 November 2015."
"Players in bold are still active at club level.
Players with an equal number of caps are ranked in chronological order of reaching the milestone.
Top goalscorers.
Goalscorers with an equal number of goals are ranked with the highest to lowest goals per game ratio.
Competitive record.
FIFA World Cup.
England first appeared at the 1950 FIFA World Cup and have appeared in 14 FIFA World Cups, they are tied for sixth-best in terms of number of wins alongside France and Spain. The national team is one of eight national teams to have won at least one FIFA World Cup title. The England team won their first and only World Cup title in 1966. The tournament was played on home soil and England defeated Germany 4–2 in the final. In 1990, England finished in fourth place, losing 2–1 to host nation Italy in the third place play-off after losing on penalties to champions Germany in the semi-final. The team has also reached the quarter-final on two recent occasions in 2002 and 2006. Previously, they reached this stage in 1954, 1962, 1970 and 1986.
England failed to qualify for the World Cup in 1974, 1978 and 1994. The team's earliest exit in the competition itself was its elimination in the first round in 1950, 1958 and most recently in the 2014 FIFA World Cup, after being defeated in both their opening two matches for the first time, versus Italy and Uruguay in Group D. In 1950, four teams remained after the first round, in 1958 eight teams remained and in 2014 sixteen teams remained. In 2010, England suffered its most resounding World Cup defeat (4–1 to Germany) in the Round of 16, after drawing with the United States and Algeria and defeating Slovenia 1–0 in the group stage.
UEFA European Championship.
England is quite a successful nation at the UEFA European Football Championship, having finished in third place in 1968 and reached the semi-final in 1996. England hosted Euro 96 and have appeared in eight UEFA European Championship Finals tournaments, tied for ninth-best. The team has also reached the quarter-final on two recent occasions in 2004 and 2012. The team's worst result in the competition was a first-round elimination in 1980, 1988, 1992 and 2000. The team did not enter in 1960, and they failed to qualify in 1964, 1972, 1976, 1984, and 2008.
Honours.
Major:
Regional:
Minor:
Other:
Unofficial:

</doc>
<doc id="9907" url="https://en.wikipedia.org/wiki?curid=9907" title="Eureka, Missouri">
Eureka, Missouri

Eureka is a city located in St. Louis County, Missouri, United States between the cities of St. Louis and Pacific along Interstate 44. As of the 2010 census, the city had a population of 10,189. Since 1971, Eureka has been known as the home of the amusement park Six Flags St. Louis (formerly Six Flags Over Mid-America). Local news coverage for the town and some of its neighbors is provided by the "Tri County Journal", the "Eureka Pacific Current NewsMagazine", and the "Washington Missourian". The city is west of the former Times Beach, the site of dioxin contamination in the 1980s; the area was depopulated, cleaned up, and reopened as Route 66 State Park.
History.
The village of Eureka was platted in 1858 along the route of the Pacific Railroad. By 1890, the village consisted of about 100 homes. According to the Eureka Chamber of Commerce, railroad workers while clearing way for the track and the next railroad camp saw Eureka, level land with little to clear, and declared, "Eureka!" Greek meaning "I have found it." Thus, Eureka was founded. In 1898, Eureka became home to the St. Louis Children's Industrial Farm, established to give children from St. Louis tenement neighborhoods a chance to experience life in a rural setting. It later became Camp Wyman (now part of Wyman Center) and is one of the oldest camps in the United States. Eureka was incorporated as a fourth-class city on April 7, 1954.
City of Allenton.
The railroad town of Allenton is a former community on U.S. Route 66 located (now) at the junction of Interstate 44 and Business Loop 44 in western St. Louis County. In 1985, it was annexed by the city of Eureka. The town is currently rural, with adjacent farmland and forested Ozark ridges. This community was declared blighted by St. Louis County in 1973.
Geography.
According to the United States Census Bureau, the city has a total area of , of which, is land and is water.
Demographics.
2010 census.
As of the 2010 census, there were 10,189 people, 3,474 households, and 2,758 families residing in the city. The population density was . There were 3,683 housing units at an average density of . The racial makeup of the city was 94.9% White, 0.8% African American, 0.2% Native American, 1.9% Asian, 0.1% Pacific Islander, 0.3% from other races, and 1.7% from two or more races. Hispanic or Latino of any race were 2.0% of the population.
There were 3,474 households of which 46.9% had children under the age of 18 living with them, 66.2% were married couples living together, 9.3% had a female householder with no husband present, 3.9% had a male householder with no wife present, and 20.6% were non-families. 17.2% of all households were made up of individuals and 5.9% had someone living alone who was 65 years of age or older. The average household size was 2.87 and the average family size was 3.27.
The median age in the city was 37.1 years. 30.9% of residents were under the age of 18; 6% were between the ages of 18 and 24; 26.6% were from 25 to 44; 26.7% were from 45 to 64; and 9.6% were 65 years of age or older. The gender makeup of the city was 49.6% male and 50.4% female.
2000 census.
As of the 2000 census, there were 7,676 people in the city, organized into 2,487 households and two families. Its population density was 763.7 people per square mile (294.9/km²). There were 2,622 housing units at an average density of 260.9 per square mile (100.7/km²). The racial makeup of the city was 97.38% White, 0.82% Asian, 0.57% Black or African American, 0.20% Native American, no Pacific Islanders, 0.26% from other races, and 0.77% from two or more races. 1.22% of the population were Hispanic or Latino of any race.
There were 2,487 households out of which half have children under the age of 18 living with them, 71.6% were married couples living together, 8.2% had a female householder with no husband present, and 17.0% were non-families. 13.8% of all households were made up of individuals and 4.3% had someone living alone who was 65 years of age or older. The average household size was 2.98 and the average family size was 3.30.
In the city, the population was spread out with 31.9% under the age of 18, 5.7% from 18 to 24, 34.4% from 25 to 44, 19.5% from 45 to 64, and 8.5% 65 years of age or older. The median age was 34 years. For every 100 females, there were 94.9 males. For every 100 females age 18 and over, there were 89.6 males.
The median income for a household in the city was $74,301, and the median income for a family was $80,625. Males had a median income of $51,799 compared to $33,269 for females. The per-capita income for the city was $27,553. 2.2% of the population and 1.3% of families were below the poverty line. Out of the total population, 3.1% of those under the age of 18 and 5.9% of those 65 and older were living below the poverty line.

</doc>
<doc id="9908" url="https://en.wikipedia.org/wiki?curid=9908" title="Equation of state">
Equation of state

In physics and thermodynamics, an equation of state is a relation between state variables. More specifically, an equation of state is a thermodynamic equation describing the state of matter under a given set of physical conditions. It is a constitutive equation which provides a mathematical relationship between two or more state functions associated with the matter, such as its temperature, pressure, volume, or internal energy. Equations of state are useful in describing the properties of fluids, mixtures of fluids, solids, and even the interior of stars.
Overview.
The most prominent use of an equation of state is to correlate densities of gases and liquids to temperatures and pressures. One of the simplest equations of state for this purpose is the ideal gas law, which is roughly accurate for weakly polar gases at low pressures and moderate temperatures. However, this equation becomes increasingly inaccurate at higher pressures and lower temperatures, and fails to predict condensation from a gas to a liquid. Therefore, a number of more accurate equations of state have been developed for gases and liquids. At present, there is no single equation of state that accurately predicts the properties of all substances under all conditions.
Measurements of equation-of-state parameters, especially at high pressures, can be made using lasers.
In addition, there are also equations of state describing solids, including the transition of solids from one crystalline state to another. There are equations that model the interior of stars, including neutron stars, dense matter (quark–gluon plasmas) and radiation fields. A related concept is the perfect fluid equation of state used in cosmology.
In practical context, the equations of state are instrumental for PVT calculation in process engineering problems and especially in petroleum gas/liquid equilibrium calculations. A successful PVT model based on a fitting equation of state can be helpful to determine the state of the flow regime, the parameters for handling the reservoir fluids, piping and sizing.
Historical.
Boyle's law (1662).
Boyle's Law was perhaps the first expression of an equation of state. In 1662, the noted Irish physicist and chemist Robert Boyle performed a series of experiments employing a J-shaped glass tube, which was sealed on one end. Mercury was added to the tube, trapping a fixed quantity of air in the short, sealed end of the tube. Then the volume of gas was carefully measured as additional mercury was added to the tube. The pressure of the gas could be determined by the difference between the mercury level in the short end of the tube and that in the long, open end. Through these experiments, Boyle noted that the gas volume varied inversely with the pressure. In mathematical form, this can be stated as:
The above relationship has also been attributed to Edme Mariotte and is sometimes referred to as Mariotte's law. However, Mariotte's work was not published until 1676.
Charles's law or Law of Charles and Gay-Lussac (1787).
In 1787 the French physicist Jacques Charles found that oxygen, nitrogen, hydrogen, carbon dioxide, and air expand to the same extent over the same 80 kelvin interval. Later, in 1802, Joseph Louis Gay-Lussac published results of similar experiments, indicating a linear relationship between volume and temperature:
Dalton's law of partial pressures (1801).
Dalton's Law of partial pressure states that the pressure of a mixture of gases is equal to the sum of the pressures of all of the constituent gases alone.
Mathematically, this can be represented for "n" species as:
The ideal gas law (1834).
In 1834 Émile Clapeyron combined Boyle's Law and Charles' law into the first statement of the "ideal gas law". Initially the law was formulated as "pVm" = "R"("TC" + 267) (with temperature expressed in degrees Celsius), where "R" is the gas constant. However, later work revealed that the number should actually be closer to 273.2, and then the Celsius scale was defined with 0 °C = 273.15 K, giving:
Van der Waals equation of state (1873).
In 1873, J. D. van der Waals introduced the first equation of state derived by the assumption of a finite volume occupied by the constituent molecules. His new formula revolutionized the study of equations of state, and was most famously continued via the Redlich–Kwong equation of state and the Soave modification of Redlich-Kwong.
Major equations of state.
For a given amount of substance contained in a system, the temperature, volume, and pressure are not independent quantities; they are connected by a relationship of the general form:
In the following equations the variables are defined as follows. Any consistent set of units may be used, although SI units are preferred. Absolute temperature refers to use of the Kelvin (K) or Rankine (°R) temperature scales, with zero being absolute zero.
Classical ideal gas law.
The classical ideal gas law may be written:
In the form shown above, the equation of state is thus
formula_17.
If the calorically perfect gas approximation is used, then the ideal gas law may also be expressed as follows
where formula_19 is the density, formula_20 is the adiabatic index (ratio of specific heats), formula_21 is the internal energy per unit mass (the "specific internal energy"), formula_22 is the specific heat at constant volume, and formula_23 is the specific heat at constant pressure.
Cubic equations of state.
Cubic equations of state are called such because they can be rewritten as a cubic function of Vm.
Van der Waals equation of state.
The Van der Waals equation of state may be written:
where formula_25 is molar volume. The substance-specific constants formula_26 and formula_27 can be calculated from the critical properties formula_28 and formula_29 (noting that formula_29 is the molar volume at the critical point) as:
Also written as
Proposed in 1873, the van der Waals equation of state was one of the first to perform markedly better than the ideal gas law. In this landmark equation formula_26 is called the attraction parameter and formula_27 the repulsion parameter or the effective molecular volume. While the equation is definitely superior to the ideal gas law and does predict the formation of a liquid phase, the agreement with experimental data is limited for conditions where the liquid forms. While the van der Waals equation is commonly referenced in text-books and papers for historical reasons, it is now obsolete. Other modern equations of only slightly greater complexity are much more accurate.
The van der Waals equation may be considered as the ideal gas law, "improved" due to two independent reasons:
With the reduced state variables, i.e. Vr=Vm/Vc, Pr=P/Pc and Tr=T/Tc, the reduced form of the Van der Waals equation can be formulated:
The benefit of this form is that for given Tr and Pr, the reduced volume of the liquid and gas can be calculated directly using Cardano's method for the reduced cubic form:
For Pr<1 and Tr<1, the system is in a state of vapor–liquid equilibrium. The reduced cubic equation of state yields in that case 3 solutions. The largest and the lowest solution are the gas and liquid reduced volume.
Redlich-Kwong equation of state.
Introduced in 1949, the Redlich-Kwong equation of state was a considerable improvement over other equations of the time. It is still of interest primarily due to its relatively simple form. While superior to the van der Waals equation of state, it performs poorly with respect to the liquid phase and thus cannot be used for accurately calculating vapor–liquid equilibria. However, it can be used in conjunction with separate liquid-phase correlations for this purpose.
The Redlich-Kwong equation is adequate for calculation of gas phase properties when the ratio of the pressure to the critical pressure (reduced pressure) is less than about one-half of the ratio of the temperature to the critical temperature (reduced temperature):
Soave modification of Redlich-Kwong.
Where ω is the acentric factor for the species.
This formulation for formula_56 is due to Graboski and Daubert. The original formulation from Soave is:
for hydrogen:
We can also write it in the polynomial form, with:
then we have:
where formula_62 is the universal gas constant and Z=PV/(RT) is the compressibility factor.
In 1972 G. Soave replaced the 1/√("T") term of the Redlich-Kwong equation with a function α(T,ω) involving the temperature and the acentric factor (the resulting equation is also known as the Soave-Redlich-Kwong equation). The α function was devised to fit the vapor pressure data of hydrocarbons and the equation does fairly well for these materials.
Note especially that this replacement changes the definition of "a" slightly, as the formula_63 is now to the second power.
Peng–Robinson equation of state.
In polynomial form:
where formula_73 is the acentric factor of the species, formula_62 is the universal gas constant and Z=PV/(RT) is compressibility factor.
The Peng–Robinson equation was developed in 1976 at The University of Alberta by Ding-Yu Peng and Donald Robinson in order to satisfy the following goals:
For the most part the Peng–Robinson equation exhibits performance similar to the Soave equation, although it is generally superior in predicting the liquid densities of many materials, especially nonpolar ones. The departure functions of the Peng–Robinson equation are given on a separate article.
Peng–Robinson-Stryjek-Vera equations of state.
PRSV1.
A modification to the attraction term in the Peng–Robinson equation of state published by Stryjek and Vera in 1986 (PRSV) significantly improved the model's accuracy by introducing an adjustable pure component parameter and by modifying the polynomial fit of the acentric factor.
The modification is:
where formula_77 is an adjustable pure component parameter. Stryjek and Vera published pure component parameters for many compounds of industrial interest in their original journal article. At reduced temperatures above 0.7, they recommend to set formula_78 and simply use formula_79. For alcohols and water the value of formula_80 may be used up to the critical temperature and set to zero at higher temperatures.
PRSV2.
A subsequent modification published in 1986 (PRSV2) further improved the model's accuracy by introducing two additional pure component parameters to the previous attraction term modification.
The modification is:
where formula_77, formula_84, and formula_85 are adjustable pure component parameters.
PRSV2 is particularly advantageous for VLE calculations. While PRSV1 does offer an advantage over the Peng–Robinson model for describing thermodynamic behavior, it is still not accurate enough, in general, for phase equilibrium calculations. The highly non-linear behavior of phase-equilibrium calculation methods tends to amplify what would otherwise be acceptably small errors. It is therefore recommended that PRSV2 be used for equilibrium calculations when applying these models to a design. However, once the equilibrium state has been determined, the phase specific thermodynamic values at equilibrium may be determined by one of several simpler models with a reasonable degree of accuracy.
One thing to note is that in the PRSV equation, the parameter fit is done in a particular temperature range which is usually below the critical temperature. Above the critical temperature, the PRSV alpha function tends to diverge and become arbitrarily large instead of tending towards 0. Because of this, alternate equations for alpha should be employed above the critical point. This is especially important for systems containing hydrogen which is often found at temperatures far above its critical point. Several alternate formulations have been proposed. Some well known ones are by Twu et all or by Mathias and Copeman.
Elliott, Suresh, Donohue equation of state.
The Elliott, Suresh, and Donohue (ESD) equation of state was proposed in 1990. The equation seeks to correct a shortcoming in the Peng–Robinson EOS in that there was an inaccuracy in the van der Waals repulsive term. The EOS accounts for the effect of the shape of a non-polar molecule and can be extended to polymers with the addition of an extra term (not shown). The EOS itself was developed through modeling computer simulations and should capture the essential physics of the size, shape, and hydrogen bonding.
where:
and
where
The characteristic size parameter is related to the shape parameter formula_89 through
where
Noting the relationships between Boltzmann's constant and the Universal gas constant, and observing that the number of molecules can be expressed in terms of Avogadro's number and the molar mass, the reduced number density formula_93 can be expressed in terms of the molar volume as
The shape parameter formula_104 appearing in the Attraction term and the term formula_105 are given by
where formula_108 is the depth of the square-well potential and is given by
The model can be extended to associating components and mixtures of nonassociating components. Details are in the paper by J.R. Elliott, Jr. "et al." (1990).
Non-cubic equations of state.
Dieterici equation of state.
where "a" is associated with the interaction between molecules and "b" takes into account the finite size of the molecules, similar to the Van der Waals equation.
The reduced coordinates are:
Virial equations of state.
Virial equation of state.
Although usually not the most convenient equation of state, the virial equation is important because it can be derived directly from statistical mechanics. This equation is also called the Kamerlingh Onnes equation. If appropriate assumptions are made about the mathematical form of intermolecular forces, theoretical expressions can be developed for each of the coefficients. In this case "B" corresponds to interactions between pairs of molecules, "C" to triplets, and so on. Accuracy can be increased indefinitely by considering higher order terms. The coefficients "B", "C", "D", etc. are functions of temperature only.
It can also be used to work out the Boyle Temperature (the temperature at which B = 0 and ideal gas laws apply) from a and b from the Van der Waals equation of state, if you use the value for B shown below:
The BWR equation of state.
where
Values of the various parameters for 15 substances can be found in 
Multiparameter equations of state.
Helmholtz Function form.
Multiparameter equations of state (MEOS) can be used to represent pure fluids with high accuracy, in both the liquid and gaseous states. MEOS's represent the Helmholtz function of the fluid as the sum of ideal gas and residual terms. Both terms are explicit in reduced temperature and reduced density - thus:
formula_125
Where:
formula_126
The reduced density and temperature are typically, though not always, the critical values for the pure fluid.
Other thermodynamic functions can be derived from the MEOS by using appropriate derivatives of the Helmholtz function; hence, because integration of the MEOS is not required, there are few restrictions as to the functional form of the ideal or residual terms.
Typical MEOS use upwards of 50 fluid specific parameters, but are able to represent the fluid's properties with high accuracy. MEOS are available currently for about 50 of the most common industrial fluids including refrigerants. Mixture models also exist.
Other equations of state of interest.
Stiffened equation of state.
When considering water under very high pressures (typical applications are underwater nuclear explosions, sonic shock lithotripsy, and sonoluminescence) the stiffened equation of state is often used:
where formula_128 is the internal energy per unit mass, formula_129 is an empirically determined constant typically taken to be about 6.1, and formula_130 is another constant, representing the molecular attraction between water molecules. The magnitude of the correction is about 2 gigapascals (20,000 atmospheres).
The equation is stated in this form because the speed of sound in water is given by formula_131.
Thus water behaves as though it is an ideal gas that is "already" under about 20,000 atmospheres (2 GPa) pressure, and explains why water is commonly assumed to be incompressible: when the external pressure changes from 1 atmosphere to 2 atmospheres (100 kPa to 200 kPa), the water behaves as an ideal gas would when changing from 20,001 to 20,002 atmospheres (2000.1 MPa to 2000.2 MPa).
This equation mispredicts the specific heat capacity of water but few simple alternatives are available for severely nonisentropic processes such as strong shocks.
Ultrarelativistic equation of state.
An ultrarelativistic fluid has equation of state
where formula_41 is the pressure, formula_134 is the mass density, and formula_135 is the speed of sound.
Ideal Bose equation of state.
The equation of state for an ideal Bose gas is
where α is an exponent specific to the system (e.g. in the absence of a potential field,
α=3/2), "z" is exp("μ"/"kT") where "μ" is the chemical potential, Li is the 
polylogarithm, ζ is the Riemann zeta function, and "T""c" is the
critical temperature at which a Bose–Einstein condensate begins to form.
Jones-Wilkins-Lee equation of state for explosives (JWL-equation).
The equation of state from Jones-Wilkins-Lee is used to describe the detonation products of explosives.
The ratio formula_138 is defined by using formula_139 = density of the explosive (solid part) and formula_140 = density of the detonation products. The parameters formula_141, formula_142, formula_143, formula_144 and formula_145 are given by several references. In addition, the initial density (solid part) formula_146, speed of detonation formula_147, Chapman–Jouguet pressure formula_148 and the chemical energy of the explosive formula_149 are given in such references. These parameters are obtained by fitting the JWL-EOS to experimental results. Typical parameters for some explosives are listed in the table below.
Equations of state for solids and liquids.
Common abbreviations: formula_150

</doc>
<doc id="9910" url="https://en.wikipedia.org/wiki?curid=9910" title="Ecclesiastes">
Ecclesiastes

Ecclesiastes (; Greek: Ἐκκλησιαστής, "Ekklesiastes", , "Qoheleth", "Koheleth") is one of 24 books of the Tanakh or Hebrew Bible, where it is classified as one of the "Ketuvim" (or "Writings"). It is among the canonical Wisdom Books in the Old Testament of most denominations of Christianity. The title "Ecclesiastes" is a Latin transliteration of the Greek translation of the Hebrew Koheleth (meaning "Gatherer", but traditionally translated as "Teacher" or "Preacher"), the pseudonym used by the author of the book.
This anonymous work was probably composed in the last part of the 3rd century BC. The author, introducing himself as "son of David, king in Jerusalem" (i.e., Solomon) discusses the meaning of life and the best way to live. He proclaims all the actions of man to be inherently "hevel", meaning "vain" or "futile", ("mere breath"), as both wise and foolish end in death. Koheleth clearly endorses wisdom as a means for a well-lived earthly life. In light of this senselessness, one should enjoy the simple pleasures of daily life, such as eating, drinking, and taking enjoyment in one's work, which are gifts from the hand of God. The book concludes with the injunction: "Fear God, and keep his commandments; for that is the whole duty of everyone" (12:13).
Ecclesiastes has had a deep influence on Western literature. It contains several phrases that have resonated in British and American culture, such as "nothing new under the sun," "a time to be born and a time to die," and "vanity of vanities; all is vanity." Abraham Lincoln quoted Ecclesiastes 1:4 in his address to the reconvening Congress on December 1, 1862 during the darkest hours of the American Civil War: "One generation passeth away, and another generation cometh: but the earth abideth for ever...Our strife pertains to ourselves – to the passing generations of men; and it can without convulsion be hushed forever with the passing of one generation." American novelist Thomas Wolfe wrote: "f all I have ever seen or learned, that book seems to me the noblest, the wisest, and the most powerful expression of man's life upon this earth—and also the highest flower of poetry, eloquence, and truth. I am not given to dogmatic judgments in the matter of literary creation, but if I had to make one I could say that Ecclesiastes is the greatest single piece of writing I have ever known, and the wisdom expressed in it the most lasting and profound."
Structure.
Ecclesiastes is presented as an autobiography of "Koheleth." Koheleth's story is framed by voice of the narrator, who refers to Koheleth in the third person, praises his wisdom, but reminds the reader that wisdom has its limitations and is not man's main concern. Koheleth reports what he planned, did, experienced and thought. His journey to knowledge is, in the end, incomplete. The reader is not only to hear Koheleth's wisdom, but to observe his journey towards understanding and acceptance of life's frustrations and uncertainties: the journey itself is important.
Few of the many attempts to uncover an underlying structure to Ecclesiastes have met with widespread acceptance; among them, the following is one of the more influential:
Verse 1:1 is a superscription, the ancient equivalent of a title page: it introduces the book as "the words of Koheleth, son of David, king in Jerusalem."
Most, though not all, modern commentators regard the epilogue (12:9–14) as an addition by a later scribe. Some have identified certain other statements as further additions intended to make the book more religiously orthodox (e.g., the affirmations of God's justice and the need for piety).
Summary.
The ten-verse introduction in verses 1:2–11 are the words of the frame narrator; they set the mood for what is to follow: Koheleth's message is that all is meaningless.
After the introduction come the words of Koheleth. As king he has experienced everything and done everything, but nothing is ultimately reliable. Death levels all. The only good is to partake of life in the present, for enjoyment is from the hand of God. Everything is ordered in time and people are subject to time in contrast to God's eternal character. The world is filled with injustice, which only God will adjudicate. God and humans do not belong in the same realm and it is therefore necessary to have a right attitude before God. People should enjoy, but should not be greedy; no-one knows what is good for humanity; righteousness and wisdom escape us. Koheleth reflects on the limits of human power: all people face death, and death is better than life, but we should enjoy life when we can. The world is full of risk: he gives advice on living with risk, both political and economic. Mortals should take pleasure when they can, for a time may come when no one can. Koheleth's words finish with imagery of nature languishing and humanity marching to the grave.
The frame narrator returns with an epilogue: the words of the wise are hard, but they are applied as the shepherd applies goads and pricks to his flock. The original ending of the book was probably the words: "The end of the matter" (12:13:) but the text we have continues: "Fear God" (a phrase used often in Koheleth's speech) "and keep his commandments" (which he never uses), "for God will bring every deed to judgement."
Composition.
Title, date and author.
The book takes its name from the Greek "ekklesiastes", a translation of the title by which the central figure refers to himself: "Koheleth", meaning something like "one who convenes or addresses an assembly". According to rabbinic tradition, Ecclesiastes was written by Solomon in his old age. (An alternative tradition that "Hezekiah and his colleagues wrote Isaiah, Proverbs, the Song of Songs and Ecclesiastes" probably means simply that the book was edited under Hezekiah.) Nevertheless, critical scholars have long rejected the idea of a pre-exilic origin. The presence of Persian loan-words and Aramaisms points to a date no earlier than about 450 BCE, while the latest possible date for its composition is 180 BCE, when another Jewish writer, Ben Sira, quotes from it. The dispute as to whether Ecclesiastes belongs to the Persian or the Hellenistic periods (i.e., the earlier or later part of this period) revolves around the degree of Hellenization (influence of Greek culture and thought) present in the book. Scholars arguing for a Persian date (c. 450–330 BCE) hold that there is a complete lack of Greek influence; those who argue for a Hellenistic date (c. 330–180 BCE) argue that it shows internal evidence of Greek thought and social setting.
Also unresolved is whether the author and narrator of Koheleth are one and the same person. Some scholars have argued that the third-person narrative structure is an artificial literary device along the lines of Uncle Remus, although the description of the Teacher in 12:8–14 seems to favour a historical person whose thoughts are presented by the narrator. The question, however, has no theological importance, and one scholar (Roland Murphy) has commented that Koheleth himself would have regarded the time and ingenuity put into interpreting his book as "one more example of the futility of human effort".
Genre and setting.
Ecclesiastes has taken its literary form from the Middle Eastern tradition of the fictional autobiography, in which a character, often a king, relates his experiences and draws lessons from them, often self-critical: Koheleth likewise identifies himself as a king, speaks of his search for wisdom, relates his conclusions, and recognises his limitations. It belongs to the category of wisdom literature, the body of biblical writings which give advice on life, together with reflections on its problems and meanings—other examples include the Book of Job, Proverbs, and some of the Psalms. Ecclesiastes differs from the other biblical Wisdom books in being deeply skeptical of the usefulness of Wisdom itself. Ecclesiastes in turn influenced the deuterocanonical works, Wisdom of Solomon and Sirach, both of which contain vocal rejections of the Ecclesiastical philosophy of futility.
Wisdom was a popular genre in the ancient world, where it was cultivated in scribal circles and directed towards young men who would take up careers in high officialdom and royal courts; there is strong evidence that some of these books, or at least sayings and teachings, were translated into Hebrew and influenced the Book of Proverbs, and the author of Ecclesiastes was probably familiar with examples from Egypt and Mesopotamia. He may also have been influenced by Greek philosophy, specifically the schools of Stoicism, which held that all things are fated, and Epicureanism, which held that happiness was best pursued through the quiet cultivation of life's simpler pleasures.
Canonicity.
The presence of Ecclesiastes in the Bible is something of a puzzle, as the common themes of the Hebrew canon—a God who reveals and redeems, who elects and cares for a chosen people—are absent from it, which gives it tone that Koheleth had lost his faith in his old age. The problem to understand the book has been there from the earliest recorded discussions (the hypothetical Council of Jamnia in the 1st century CE). One argument advanced then was that the name of Solomon carried enough authority to ensure its inclusion, but other works which appeared with Solomon's name were excluded despite being more orthodox than Ecclesiastes. Another was that the words of the epilogue, in which the reader is told to fear God and keep his commands, made it orthodox; but all later attempts to find anything in the rest of the book which would reflect this orthodoxy have failed. A modern suggestion has been to treat the book as a dialogue in which different statements belong to different voices, with Koheleth himself answering and refuting unorthodox opinions, but there are no explicit markers for this in the book, as there are, for example in the Book of Job. Yet another suggestion is that Ecclesiastes is simply the most extreme example of a tradition of skepticism, but none of the proposed examples match Ecclesiastes for a sustained denial of faith and doubt in the goodness of God. "In short, we do not know why or how this book found its way into such esteemed company," summarizes Martin A. Shields in his 2006 book "The End of Wisdom: A Reappraisal of the Historical and Canonical Function of Ecclesiastes"
Themes.
Scholars disagree about the themes of Ecclesiastes. Is it positive and life-affirming or deeply pessimistic? Is Koheleth coherent or incoherent, insightful or confused, orthodox or heterodox? Is the ultimate message of the book to copy Koheleth, the wise man, or to avoid his errors? Some passages of Ecclesiastes seem to contradict other portions of the Old Testament, and even itself. One suggestion for resolving the contradictions is to read the book as the record of Koheleth's quest for knowledge: opposing judgments (e.g., "the dead are better off than the living" (4:2) vs. "a living dog is better off than a dead lion" (9:4)) are therefore provisional, and it is only at the conclusion that the verdict is delivered (11–12:7). On this reading, Koheleth's sayings are goads, designed to provoke dialogue and reflection in his readers, rather than to reach premature and self-assured conclusions.
The subjects of Ecclesiastes are the pain and frustration engendered by observing and meditating on the distortions and inequities pervading the world, the uselessness of human deeds, and the limitations of wisdom and righteousness. The phrase "under the sun" appears thirty times in connection with these observations; all this coexists with a firm belief in God, whose power, justice and unpredictability are sovereign. History and nature move in cycles, so that all events are predetermined and unchangeable, and life has no meaning or purpose: the wise man and the man who does not study wisdom will both die and be forgotten: man should be reverent ("Fear God"), but in this life it is best to simply enjoy God's gifts.
Traditional Judaism.
In traditional Judaism, Ecclesiastes is read either on Shemini Atzeret (by Yemenites, Italians, some Sepharadim, and the mediaeval French Jewish rite) or on the Shabbat of the Intermediate Days of Sukkot (by Ashkenazim). If there is no Intermediate Sabbath of Sukkot, even the Ashkenazim read it on Shemini Atzeret (or, for Ashkenazim in the Land of Israel, on the first Shabbat of Sukkot). It is read on Sukkot as a reminder to not get too caught up in the festivities of the holiday, as well as to carry over the happiness of Sukkot to the rest of the year by telling the listeners that, without God, life is meaningless. When the listeners take this to heart, then true happiness can be achieved throughout the year.
The final poem of Koheleth () has been interpreted in the Targum, Talmud and Midrash, and by the rabbis Rashi, Rashbam and ibn Ezra, as an allegory of old age.
Catholicism.
Like most of the Bible, Ecclesiastes has been cited in the writings of past and current Catholic Church leaders. For example, doctors of the Church have cited Ecclesiastes. St. Augustine of Hippo cited Ecclesiastes in Book XX of "City of God". St. Jerome wrote a commentary on Ecclesiastes. St. Thomas Aquinas cited Ecclesiastes ("The number of fools is infinite.") in his "Summa Theologica".
The book continues to be cited by recent popes, including Pope John Paul II and Pope Francis. Pope John Paul II, in his general audience of October 20, 2004, called the author of Ecclesiastes "an ancient biblical sage" whose description of death "makes frantic clinging to earthly things completely pointless." Pope Francis cited Ecclesiastes on his address on September 9, 2014. Speaking of vain people, he said, "How many Christians live for appearances? Their life seems like a soap bubble."
Atheism.
Atheists often name Ecclesiastes as their favorite book of the Bible. The antitheist author Christopher Hitchens, who considered George Orwell an atheist, wrote approvingly of Orwell's use of Ecclesiastes at his funeral. The atheist biologist Richard Dawkins called the King James Bible translation of Ecclesiastes "one of the glories of English literature." Other atheists that have voiced support for Ecclesiastes include Greta Christina, Hemant Mehta, Dale McGowan, and Pippa Evans.
References in Literature.
The opening of Sonnet 59 of William Shakespeare references Ecclesiastes 1:9-10.

</doc>
<doc id="9911" url="https://en.wikipedia.org/wiki?curid=9911" title="Ezekiel">
Ezekiel

Ezekiel (; , "Y'ḥez'qel", ), meaning "May God strengthen him", "God will strengthen" (from , "ḥazaq", , literally "to fasten upon", figuratively "strong", and , "el", , literally "God", and so figuratively "The Almighty") is the central protagonist of the Book of Ezekiel in the Hebrew Bible.
In Judaism, Christianity, Islam and the Bahá'í Faith, Ezekiel is acknowledged as a Hebrew prophet. In Judaism and Christianity, he is also viewed as the author of the Book of Ezekiel that reveals prophecies regarding the destruction of Jerusalem, the restoration to the land of Israel and the "Millennial Temple" visions, or the Third Temple.
Life.
The author of the Book of Ezekiel presents himself as Ezekiel, the son of Buzzi, born into a priesthood (Kohen) lineage of the patrilineal line of Ithamar, and resident of Anathoth. Apart from identifying himself, the author gives a chronology for the first divine encounter which he will present. He states that it happened "in the thirtieth year", which may be a reference to his age at the time. In such a case, the approximate year of birth is 622 BC. He also dates the event 5 years after the exile of King of Judah Jehoiachin by the Babylonians, a recurring dating pattern throughout the book. Josephus claims that under at the request of Nebuchadnezzar II, Babylonian armies exiled three thousand Jews from Judah, after deposing King Jehoiachin in 598 BC.
The book of Ezekiel was written by the Great Assembly (Knesset Hagedolah) because a prophet was not allowed to write down the prophecies while being outside of Israel.
Living in Babylon.
According to the Bible, Ezekiel and his wife lived on the bank of the Chebar River, in Tel Abib ("Mound of the Deluge") where exiles from Judah came to seek his prophetic insights. There is no mention of him having any offspring. Only that his wife died rather young, in the ninth year of exile, when Ezekiel was 34 years of age.
Prophetic career.
Ezekiel describes his calling to be a prophet by going into great detail about his encounter with God and four living creatures or Cherubim with four wheels that stayed beside the creatures. For the next five years he incessantly prophesied and acted out the destruction of Jerusalem and its temple, which was met with some opposition. However, Ezekiel and his contemporaries like Jeremiah, another prophet who was living in Jerusalem at that time, witnessed the fulfillment of their prophecies when Jerusalem was finally sacked by the Babylonians. The date of the sacking, 587 BC, is confirmed by Babylonian cuneiform records discovered by archeologists. Ezekiel was 50 years old when he began to have visions of a new Temple. He served as a prophet for at least 22 years. Ezekiel last experienced an encounter with God in April 570 BC. His time of death has not been recorded.
World views.
Jewish tradition.
Ezekiel, like Jeremiah, is said by Talmud and Midrash to have been a descendant of Joshua by his marriage with the proselyte Rahab. Some statements found in rabbinic literaturez posit that Ezekiel was the son of Jeremiah, who was (also) called "Buzi" because he was despised by the Jews.
Ezekiel was said to be already active as a prophet while in the Land of Israel, and he retained this gift when he was exiled with Jehoiachin and the nobles of the country to Babylon.
Rava states in the Babylonian Talmud that although Ezekiel describes the appearance of the throne of God (Merkabah), this is not because he had seen more than the prophet Isaiah, but rather because the latter was more accustomed to such visions; for the relation of the two prophets is that of a courtier to a peasant, the latter of whom would always describe a royal court more floridly than the former, to whom such things would be familiar. Ezekiel, like all the other prophets, has beheld only a blurred reflection of the divine majesty, just as a poor mirror reflects objects only imperfectly.
According to the midrash "Canticles Rabbah", it was Ezekiel whom the three pious men, Hananiah, Mishael, and Azariah (also called Shadrach, Meshach, and Abednego in the Bible) asked for advice as to whether they should resist Nebuchadnezzar's command and choose death by fire rather than worship his idol. At first God revealed to the prophet that they could not hope for a miraculous rescue; whereupon the prophet was greatly grieved, since these three men constituted the "remnant of Judah". But after they had left the house of the prophet, fully determined to sacrifice their lives to God, Ezekiel received this revelation: "Thou dost believe indeed that I will abandon them. That shall not happen; but do thou let them carry out their intention according to their pious dictates, and tell them nothing".
Christianity.
Ezekiel is commemorated as a saint in the liturgical calendar of the Eastern Orthodox Church—and those Eastern Catholic Churches which follow the Byzantine Rite—on July 23 (for those churches which use the traditional Julian Calendar, July 23 falls on August 5 of the modern Gregorian Calendar). Ezekiel is commemorated on August 28 on the Calendar of Saints of the Armenian Apostolic Church, and on April 10 in the Roman Martyrology.
Certain Lutheran churches also celebrate his commemoration on July 20.
The Church Fathers interpret Ezekiel's vision of the human likeness upon the sapphire throne () as a prophecy of the Incarnation of the Logos from the Theotokos (Virgin Mary), who in many ancient church hymns is called the "living Throne of God".
Ezekiel's statement about the "closed gate" () is understood as another prophecy of the Incarnation: the "gate" signifying the Virgin Mary and the "prince" referring to Jesus. This is one of the readings at Vespers on Great Feasts of the Theotokos in the Eastern Orthodox and Byzantine Catholic Churches. This imagery is also found in the traditional Catholic Christmas hymn "Gaudete" and in a saying by Saint Bonaventure, quoted by Alphonsus Maria de' Liguori: "No one can enter Heaven unless by Mary, as though through a door." The imagery provides the basis for the concept that God gave Mary to mankind as the "Gate of Heaven" (thence the dedication of churches and convents to the Porta Coeli), an idea also laid out in the "Salve Regina" (Hail Holy Queen) prayer.
According to Matthew Henry a Bible commentator who flourished in the 17th century, Ezekiel is also believed to have been known as Nazaratus Assyrius, a teacher to Pythagoras. However, James Ussher, in his writings of the Ussher chronology, republished as "The Annals of the World" claims that this is a mistake, basing his opinion on the writings of Clemens Alexandrinus. However, Sir William Smith, in his "Bible Dictionary," points out that John Selden, among others, consider it a possibility. In the book "Pythagoras: Greek philosopher" it states; "Nazaratus, the Assyrian, one of Pythagoras' masters, was supposed to be the prophet Ezekiel, and Thomas Stanley's "Life of Pythagoras" says that Ezekiel and Pythagoras flourished together.
Mormonism.
Since 1830, The Church of Jesus Christ of Latter-day Saints has identified the Book of Mormon with the "record of the stick of Ephraim" () while the stick of Judah is identified with the Bible.
Islamic tradition.
Ezekiel is recognized as a prophet in Islamic tradition. Although not mentioned in the Qur'an by the name, all Muslim scholars, both classical and modern have included Ezekiel in lists of the prophets of Islam.
The Qur'an mentions a prophet called Zul-Kifl. This prophet is sometimes identified with Ezekiel although Zul-Kifl's identity is disputed. Carsten Niebuhr, in his "Reisebeschreibung nach Arabian", says he visited Al Kifl in Iraq, midway between Najaf and Hilla and said "Kifl" was the Arabic form of "Ezekiel". He further explained in his book that Ezekiel's Tomb was present in Al Kifl and that the Jews came to it on pilgrimage. The name "Zul-Kifl" would mean "One of double", as "Zul" in Arabic means "double". Some Islamic scholars have likened Ezekiel's mission to the description of Dhul-Kifl. When the exile, monarchy, and state were annihilated, a political and national life was no longer possible. In the absence of a worldly foundation it became necessary to build a spiritual one and Ezekiel performed this mission by observing the signs of the time and deducing his doctrines from them. In conformity with the two parts of his book, his personality and his preaching are alike twofold, and the title "Zul-Kifl" means "the one of double" Aside from the possible identification of Zul-Kifl with Ezekiel, Muslims have viewed Ezekiel as a prophet, regardless of his identification with Zul-Kifl. 
Ezekiel appears in all Muslim collections of "Stories of the Prophets". Muslim exegesis further lists Ezekiel's father as Buzi ("Budhi") and Ezekiel is given the title "ibn al-adjus", denoting "son of the old", as his parents are supposed to have been very old when he was born. A tradition, which resembles that of Hannah and Samuel in the Hebrew Bible, states that Ezekiel's mother prayed to God in old age for the birth of an offspring and was given Ezekiel as a gift from God.
Tomb.
The tomb of Ezekiel is a structure located in modern-day south Iraq near Kefil, believed to be the final resting place of Ezekiel. It has been a place of pilgrimage to both Muslims and Jews alike. After the Jewish exodus from Iraq, Jewish activity in the tomb ceased although a disused synagogue remains in place.

</doc>
<doc id="9914" url="https://en.wikipedia.org/wiki?curid=9914" title="Executable and Linkable Format">
Executable and Linkable Format

In computing, the Executable and Linkable Format (ELF, formerly called Extensible Linking Format) is a common standard file format for executables, object code, shared libraries, and core dumps. First published in the System V Release 4 (SVR4) Application Binary Interface (ABI) specification, and later in the Tool Interface Standard, it was quickly accepted among different vendors of Unix systems. In 1999 it was chosen as the standard binary file format for Unix and Unix-like systems on x86 by the 86open project.
ELF is flexible and extensible by design, and it is not bound to any particular processor or architecture. This has allowed it to be adopted by many different operating systems on many different platforms.
File layout.
Each ELF file is made up of one ELF header, followed by file data. The file data can include:
The segments contain information that is necessary for runtime execution of the file, while sections contain important data for linking and relocation. Any byte in the entire file can be owned by at most one section, and there can be orphan bytes which are not owned by any section.
File header.
The ELF header defines whether 32- or 64-bit addresses are to be used. The header itself contains three fields that are affected by this setting and offset other fields that follow them. The 64-bit header is 64 bytes long.
Program Header.
The program header table tells the system how to create a process image. It is found at file offset e_phoff, and consists of e_phnum entries, each with size e_phentsize. For 32-bit ELF, each entry is structured as:
Applications.
The ELF format has replaced older executable formats in various environments.
It has replaced a.out and COFF formats in Unix-like operating systems:
ELF has also seen some adoption in non-Unix operating systems, such as:
Some game consoles also use ELF:
Other operating systems running on PowerPC using ELF:
Some operating systems for mobile phones and mobile devices use ELF:
Some phones can run ELF files through the use of a patch that adds assembly code to the main firmware, which is a feature known as "ELFPack" in the underground modding culture. The ELF file format is also used with the Atmel AVR (8-bit), AVR32 and with Texas Instruments MSP430 microcontroller architectures. Some implementations of Open Firmware can also load ELF files, most notably Apple's implementation used in almost all PowerPC machines the company produced.
Specifications.
The Linux Standard Base (LSB) supplements some of the above specifications for architectures in which it is specified. For example, that is the case for the System V ABI, AMD64 Supplement.
86open.
86open was a project to form consensus on a common binary file format for Unix and Unix-like operating systems on the common PC compatible x86 architecture, in order to encourage software developers to port to the architecture. The initial idea was to standardize on a small subset of Spec 1170, a predecessor of the Single UNIX Specification, and the GNU C Library (glibc) to enable unmodified binaries to run on the x86 UNIX-like operating systems. The project was originally designated "Spec 150".
The format eventually chosen was ELF, specifically the Linux implementation of ELF, after it had turned out to be a "de facto" standard supported by all involved vendors and operating systems.
The group started email discussions in 1997 and first met together at the Santa Cruz Operation offices on August 22, 1997.
The steering committee was Marc Ewing, Dion Johnson, Evan Leibovitch, Bruce Perens, Andrew Roach, Bryan Sparks and Linus Torvalds. Other people on the project were Keith Bostic, Chuck Cranor, Michael Davidson, Chris G. Demetriou, Ulrich Drepper, Don Dugger, Steve Ginzburg, Jon "maddog" Hall, Ron Holt, Jordan Hubbard, Dave Jensen, Kean Johnston, Andrew Josey, Robert Lipe, Bela Lubkin, Tim Marsland, Greg Page, Ronald Joe Record, Tim Ruckle, Joel Silverstein, Chia-pi Tien and Erik Troan. Operating systems and companies represented were BeOS, BSDI, FreeBSD, Intel, Linux, NetBSD, SCO and SunSoft, Inc..
The project progressed and in mid-1998, SCO began developing lxrun, an open-source compatibility layer capable of running Linux binaries on OpenServer, UnixWare, and Solaris. SCO announced official support of lxrun at LinuxWorld in March 1999. Sun Microsystems began officially supporting lxrun for Solaris in early 1999, and has since moved to integrated support of the Linux binary format via Solaris Containers for Linux Applications.
With the BSDs having long supported Linux binaries (through a compatibility layer) and the main x86 Unix vendors having added support for the format, the project decided that Linux ELF was the format chosen by the industry and "declare itself dissolved" on July 25, 1999.
FatELF: Universal Binaries for Linux.
FatELF is an ELF binary-format extension which adds Fat binary capabilities. It is aimed for Linux and other Unix-like operating systems. Additionally to the CPU architecture abstraction (byte order, word size, CPU instruction set etc.), there is the potential advantage of software-platform abstraction e.g. binaries which support multiple kernel ABI versions.
A proof-of-concept Ubuntu 9.04 image (VM image of Ubuntu 9.04 with Fat Binary support) and development tools are available. As of 2014, support for FatELF is not integrated in the Linux kernel mainline.

</doc>
<doc id="9917" url="https://en.wikipedia.org/wiki?curid=9917" title="Explorers program">
Explorers program

The Explorers program is a United States space exploration program that provides flight opportunities for physics, geophysics, heliophysics, and astrophysics investigations from space. Over 90 space missions have been launched since 1958, and it is still active. Starting with Explorer 6, it has been operated by NASA, with regular collaboration with a variety of other institutions, including many international partners.
History.
The Explorers program was the United States's first successful attempt to launch an artificial satellite. It began as a U.S. Army proposal (Project Orbiter) to place a scientific satellite into orbit during the International Geophysical Year; however, that proposal was rejected in favor of the U.S. Navy's Project Vanguard. The Explorers program was later reestablished to catch up with the Soviet Union after that nation's launch of Sputnik 1 on October 4, 1957. ("See:" Sputnik crisis) Explorer 1 was launched on January 31, 1958. Besides being the first U.S. satellite, it is known for discovering the Van Allen radiation belt.
The Explorers program was transferred to NASA, which continued to use the name for an ongoing series of relatively small space missions, typically an artificial satellite with a specific science focus. Over the years, NASA has launched a series of Explorers spacecraft carrying a wide variety of scientific investigations.
Explorers satellites have made many important discoveries on: Earth's magnetosphere and the shape of its gravity field; the solar wind; properties of micrometeoroids raining down on the Earth; ultraviolet, cosmic, and X-rays from the Solar System and universe beyond; ionospheric physics; Solar plasma; solar energetic particles; and atmospheric physics. These missions have also investigated air density, radio astronomy, geodesy, and gamma ray astronomy. Various space telescopes have made a variety of discoveries, including the first known Earth Trojan asteroid.
The Explorers Program Office at Goddard Space Flight Center in Greenbelt, Maryland, provides management of the many operational scientific exploration missions in the program. The missions are characterized by relatively moderate costs and small to medium-sized missions that are capable of being built, tested, and launched in a short time interval compared to larger observatories.
Explorers categories have included MIDEX (Medium Explorer), SMEX (Small Explorer), UNEX (University-Class Explorer), and others. A subprogram called Missions of Opportunity (MO) has funded instruments on non-NASA missions.
Launchers used for these missions include Jupiter C (Juno I), Juno II, various Thor rockets such as the Thor-Able, Scout, various Delta and Delta II rockets of the Delta rocket family, and Pegasus.
Mission types.
Medium-Class Explorers (MIDEX).
The Medium-Class Explorer (MIDEX) program is an effort within NASA to fund space exploration missions that cost no more than .
Small Explorers (SMEX).
The Small Explorer (SMEX) program is an effort within NASA to fund space exploration missions that cost no more than . started in 1989. The first set of three SMEX missions were launched between 1992 and 1998. The second set of two missions were launched in 1998 and 1999. These missions were managed by the Small Explorer Project Office at NASA's Goddard Space Flight Center (GSFC). In early 1999, that office was closed and with the announcement of opportunity for the third set of SMEX missions NASA converted the program so that each mission was managed by its Principal Investigator, with oversight by the GSFC Explorers Project.
University-Class Explorers (UNEX).
Investigations characterized by definition, development, mission operations, and data analysis costs not to exceed $15.0M (real year dollars) total cost to NASA. UNEX missions will be launched by a variety of low cost methods.
Missions of Opportunity (MO).
The Missions of Opportunity (MO) program provides funding for science instruments or hardware components of onboard non-NASA space missions. MO missions have a total NASA cost of under $55 million.
Spacecraft by year.
Explorers name numbers can be found in the NSSDC master catalog, typically assigned to each spacecraft in a mission. These numbers were not officially assigned until after 1975.
Miscellaneous.
Many missions are proposed, but not selected. For example in 2011, the Explorers program received 22 full missions solicitations, 20 Missions of Opportunity, and 8 USPI. Missions of Opportunity (MO) are small collaborative missions with spacecraft not operated by NASA, such as an additional instrument. Examples of this include Astro-H, CINDI, TWINS, and HETE-2. Sometimes mission are only partially developed but must be stopped for financial, technological, or bureaucratic reasons. Some missions failed upon reaching orbit including WIRE and TERRIERS.
Examples of missions that were not developed or cancelled were: 
Examples of recent missions conclusions, sometimes cancelled due to budget constraints:
Launch graph.
Roughly the number of launches per decade: 

</doc>
<doc id="9920" url="https://en.wikipedia.org/wiki?curid=9920" title="Electronic oscillator">
Electronic oscillator

An electronic oscillator is an electronic circuit that produces a periodic, oscillating electronic signal, often a sine wave or a square wave. Oscillators convert direct current (DC) from a power supply to an alternating current (AC) signal. They are widely used in many electronic devices. Common examples of signals generated by oscillators include signals broadcast by radio and television transmitters, clock signals that regulate computers and quartz clocks, and the sounds produced by electronic beepers and video games.
Oscillators are often characterized by the frequency of their output signal:
Oscillators designed to produce a high-power AC output from a DC supply are usually called inverters.
There are two main types of electronic oscillator: the linear or harmonic oscillator and the nonlinear or relaxation oscillator.
Harmonic oscillator.
The harmonic, or "linear", oscillator produces a sinusoidal output. There are two types:
Feedback oscillator.
The most common form of linear oscillator is an electronic amplifier such as a transistor or op amp connected in a feedback loop with its output fed back into its input through a frequency selective electronic filter to provide positive feedback. When the power supply to the amplifier is first switched on, electronic noise in the circuit provides a non-zero signal to get oscillations started. The noise travels around the loop and is amplified and filtered until very quickly it converges on a sine wave at a single frequency.
Feedback oscillator circuits can be classified according to the type of frequency selective filter they use in the feedback loop:
Negative resistance oscillator.
In addition to the feedback oscillators described above, which use two-port amplifying active elements such as transistors and op amps, linear oscillators can also be built using one-port (two terminal) devices with negative resistance, such as magnetron tubes, tunnel diodes, lambda diodes and Gunn diodes. Negative resistance oscillators are usually used at high frequencies in the microwave range and above, since at these frequencies feedback oscillators perform poorly due to excessive phase shift in the feedback path.
In negative resistance oscillators, a resonant circuit, such as an LC circuit, crystal, or cavity resonator, is connected across a device with negative differential resistance, and a DC bias voltage is applied to supply energy. A resonant circuit by itself is "almost" an oscillator; it can store energy in the form of electronic oscillations if excited, but because it has electrical resistance and other losses the oscillations are damped and decay to zero. The negative resistance of the active device cancels the (positive) internal loss resistance in the resonator, in effect creating a resonator with no damping, which generates spontaneous continuous oscillations at its resonant frequency.
The negative resistance oscillator model is not limited to one-port devices like diodes; feedback oscillator circuits with two-port amplifying devices such as transistors and tubes also have negative resistance. At high frequencies, transistors and FETs do not need a feedback loop, but with certain loads applied to one port can become unstable at the other port and show negative resistance due to internal feedback, causing them to oscillate. So high frequency oscillators in general are designed using negative resistance techniques.
Some of the many harmonic oscillator circuits are listed below:
Relaxation oscillator.
A nonlinear or relaxation oscillator produces a non-sinusoidal output, such as a square, sawtooth or triangle wave. It consists of an energy-storing element (a capacitor or, more rarely, an inductor) and a nonlinear switching device (a latch, Schmitt trigger, or negative resistance element) connected in a feedback loop. The switching device periodically charges and discharges the energy stored in the storage element thus causing abrupt changes in the output waveform.
Square-wave relaxation oscillators are used to provide the clock signal for sequential logic circuits such as timers and counters, although crystal oscillators are often preferred for their greater stability. Triangle wave or sawtooth oscillators are used in the timebase circuits that generate the horizontal deflection signals for cathode ray tubes in analogue oscilloscopes and television sets. They are also used in voltage controlled oscillators (VCOs), inverters and switching power supplies, dual slope analog to digital converters (ADCs), and in function generators to generate square and triangle waves for testing equipment. In general, relaxation oscillators are used at lower frequencies and have poorer frequency stability than linear oscillators.
Ring oscillators are built of a ring of active delay stages. Generally the ring has an odd number of inverting stages, so that there is no single stable state for the internal ring voltages. Instead, a single transition propagates endlessly around the ring.
Some of the more common relaxation oscillator circuits are listed below:
Voltage-controlled oscillator (VCO).
An oscillator can be designed so that the oscillation frequency can be varied over some range by an input voltage or current. These voltage controlled oscillators are widely used in phase-locked loops, in which the oscillator's frequency can be locked to the frequency of another oscillator. These are ubiquitous in modern communications circuits, used in filters, modulators, demodulators, and forming the basis of frequency synthesizer circuits which are used to tune radios and televisions.
Radio frequency VCOs are usually made by adding a varactor diode to the tuned circuit or resonator in an oscillator circuit. Changing the DC voltage across the varactor changes its capacitance, which changes the resonant frequency of the tuned circuit. Voltage controlled relaxation oscillators can be constructed by charging and discharging the energy storage capacitor with a voltage controlled current source. Increasing the input voltage increases the rate of charging the capacitor, decreasing the time between switching events.
History.
One of the first electronic oscillators was an oscillating arc built by Elihu Thomson in 1892. Thomson's oscillator placed an LC tuned circuit in parallel with the arc, used metal electrodes, and included a magnetic blowout. Independently in the same year, George Francis Fitzgerald realized that if the damping resistance in a resonant circuit could be made zero or negative, it would produce oscillations, and tried unsuccessfully to build a negative resistance oscillator with a dynamo, what would now be called a parametric oscillator. The arc oscillator was rediscovered and popularized by William Duddell in 1900. Electric arcs were used to provide illumination in the 19th century, but the arc current was unstable and they often produced hissing, humming or howling sounds. Duddell, a student at London Technical College, investigated this effect. He attached an LC circuit to the electrodes of an arc lamp, and the negative resistance of the arc excited audio frequency oscillations in the tuned circuit at its resonant frequency. Some of the energy was radiated as sound waves by the arc, producing a musical tone. To demonstrate his oscillator before the London Institute of Electrical Engineers, Duddell wired a series of tuned circuits to the arc and played a tune, ""God Save The Queen"". Duddell wasn't able to generate frequencies above the audio range with his "singing arc", but in 1902 Danish physicists Valdemar Poulsen and P. O. Pederson were able to increase the frequency produced into the radio range, inventing the Poulsen arc radio transmitter, the first continuous wave radio transmitter, which was used through the 1920s.
The vacuum tube feedback oscillator was invented around 1912, when it was discovered that feedback ("regeneration") in the recently invented audion vacuum tube could produce oscillations. At least six researchers independently made this discovery and can be said to have some role in the invention. In the summer of 1912, Edwin Armstrong observed oscillations in audion radio receiver circuits and went on to use positive feedback in his invention of the regenerative receiver. German Alexander Meissner independently discovered positive feedback and invented oscillators in March 1913. Irving Langmuir at General Electric observed feedback in 1913. Fritz Lowenstein may have preceded the others with a crude oscillator in late 1911. In Britain, H. J. Round patented amplifying and oscillating circuits in 1913. In August 1912, Lee De Forest, the inventor of the audion, had also observed oscillations in his amplifiers, but he didn't understand its significance and tried to eliminate it until he read Armstrong's patents in 1914, which he promptly challenged. Armstrong and De Forest fought a protracted legal battle over the rights to the "regenerative" oscillator circuit which has been called "the most complicated patent litigation in the history of radio". De Forest ultimately won before the Supreme Court in 1934 on technical grounds, but most sources regard Armstrong's claim as the stronger one.
The first and most widely used relaxation oscillator circuit, the astable multivibrator, was invented in 1917 by French engineers Henri Abraham and Eugene Bloch. They called their cross-coupled, dual vacuum tube circuit a "multivibrateur" because the square-wave signal it produced was rich in harmonics, compared to the sinusoidal signal of other vacuum tube oscillators.
Vacuum tube feedback oscillators became the basis of radio transmission by 1920. However the triode vacuum tube oscillator performed poorly above 300 MHz because of interelectrode capacitance. To reach higher frequencies, new "transit time" (velocity modulation) vacuum tubes were developed, in which electrons traveled in "bunches" through the tube. The first of these was the Barkhausen-Kurz oscillator (1920), the first tube to produce power in the UHF range. The most important and widely used were the klystron (R. and S. Varian, 1937) and the cavity magnetron (J. Randall and H. Boot, 1940).
Mathematical conditions for feedback oscillations, now called the Barkhausen criterion, were derived by Heinrich Georg Barkhausen in 1921. The first analysis of a nonlinear electronic oscillator model, the Van der Pol oscillator, was done by Balthasar van der Pol in 1927. He showed that the stability of the oscillations (limit cycles) in actual oscillators was due to the nonlinearity of the amplifying device. He originated the term "relaxation oscillation" and was first to distinguish between linear and relaxation oscillators. Further advances in mathematical analysis of oscillation were made by Hendrik Wade Bode and Harry Nyquist in the 1930s. In 1969 K. Kurokawa derived necessary and sufficient conditions for oscillation in negative resistance circuits, which form the basis of modern microwave oscillator design.

</doc>
<doc id="9922" url="https://en.wikipedia.org/wiki?curid=9922" title="Societas Europaea">
Societas Europaea

A societas Europaea ( SE; Latin: "European society" or "company"; plural: societates Europaeae) is a public company registered in accordance with the corporate law of the European Union (EU), introduced in 2004 with the "Council Regulation on the Statute for a European Company". Such a company may more easily transfer to, or merge with companies in, other member states.
2,525 registrations have been reported as of March 2016, including the following nine components (18%) of the Euro Stoxx 50 stock market index of leading Euro Area companies (excluding the SE designation): Airbus Group, Allianz, BASF, E.ON, Fresenius, LVMH Moët Hennessy Louis Vuitton, SAP, Schneider Electric and Unibail-Rodamco.
National law continues to supplement the basic rules in the Regulation on formation and mergers. The European Company Regulation is complemented by an Employee Involvement Directive that sets rules for participation by employees on the company's board of directors. There is also a statute allowing European Cooperative Societies.
Main provisions.
Formation.
The Statute provides four ways of forming a European limited company: merger, formation of a holding company, formation of a joint subsidiary, or conversion of a public limited company previously formed under national law. Formation by merger is available only to public limited companies from different member states. Formation of an SE holding company is available to public and private limited companies with their registered offices in different member states or having subsidiaries or branches in member states other than that of their registered office. Formation of a joint subsidiary is available under the same circumstances to any legal entities governed by public or private law.
See "The European Company all over Europe" De Gruyter Recht - Berlin for a general overview of the European process.
SEs can be created in the following ways:
Minimum capital.
The SE must have a minimum subscribed capital of €120,000 as per article 4(2) of the directive, subject to the provision that where a member state requires a larger capital for companies exercising certain types of activities, the same requirement will also apply to an SE with its registered office in that member state (article 4(3)).
Registered office.
The registered office of the SE designated in the statutes must be the place where it has its central administration, that is to say its true centre of operations. The SE may transfer its registered office within the Community without dissolving the company in one member state in order to form a new one in another member state; however, such a transfer is subject to the provisions of 8 which require, inter alia, the drawing up of a transfer proposal, a report justifying the legal and economic aspects of the transfer and the issuing, by the competent authority in the member state in which the SE is registered, of a certificate attesting to the completion of the required acts and formalities.
Laws applicable.
The order of precedence of the laws applicable to the SE is clarified.
Registration and liquidation.
The registration and completion of the liquidation of an SE must be disclosed for information purposes in the Official Journal of the European Communities. Every SE must be registered in the State where it has its registered office, in a register designated by the law of that State.
Statutes.
The Statutes of the SE must provide as governing bodies the general meeting of shareholders and either a management board and a supervisory board (two-tier system) or an administrative board (single-tier system).
Under the two-tier system the SE is managed by a management board. The member or members of the management board have the power to represent the company in dealings with third parties and in legal proceedings. They are appointed and removed by the supervisory board. No person may be a member of both the management board and the supervisory board of the same company at the same time. But the supervisory board may appoint one of its members to exercise the functions of a member of the management board in the event of absence through holidays. During such a period the function of the person concerned as a member of the supervisory board shall be suspended.
Under the single-tier system, the SE is managed by an administrative board. The member or members of the administrative board have the power to represent the company in dealings with third parties and in legal proceedings. Under the single-tier system the administrative board may delegate the power of management to one or more of its members.
The following operations require the authorization of the supervisory board or the deliberation of the administrative board:
Annual accounts.
The SE must draw up annual accounts comprising the balance sheet, the profit and loss account, and the notes to the accounts, and an annual report giving a fair view of the company's business and of its position; consolidated accounts may also be required.
Taxation.
In tax matters, the SE is treated the same as any other multinational, i.e., it is subject to the tax regime of the national legislation applicable to the company and its subsidiaries. SEs are subject to taxes and charges in all member states where their administrative centres are situated. Thus, their tax status is not perfect as there is still no adequate harmonization at European level.
Winding-up.
Winding-up, liquidation, insolvency, and suspension of payments are in large measure to be governed by national law. When an SE transfers its registered office outside the Community, or in any other manner no longer complies with requirements of article 7, the member state must take appropriate measures to ensure compliance or take necessary measures to ensure that the SE is liquidated.
Status of the legislation and implementation.
Council Regulation (EC) No 2157/2001 of 8 October 2001 on the Statute for a European company (SE).
Council Directive 2001/86/EC of 8 October 2001 supplementing the Statute for a European company with regard to the involvement of employees.
See also: Europa's collection of press releases, regulations, directives and FAQs on the European Company Statute.
United Kingdom.
UK Statutory Instrument 2004 No. 2326. The European Public Limited-Liability Company Regulations 2004 came into force on 8 October and gave effect to the European Company Statute Regulation (Council Regulation EC no.2157/2001), which gives the framework for a new form of company, the European Public Limited-Liability Company or Societas Europaea (SE). The regulations are available in full text on the HMSO website.
UK Statutory Instrument 2004 no. 2407. The European Public Limited-Liability Company (Fees) Regulations 2004 also came into force on 8 October 2004. An explanatory memorandum on the Fees Regulations describe them as setting out "the fees payable in connection with the services and facilities provided by the DTI in respect of a new form of company, the European Public Limited-Liability Company or 'Societas Europaea' (SE)."
Employee participation.
The regulation is complemented by the Council Directive supplementing the Statute for a European Company with regard to the involvement of employees (informally "Council Directive on Employee Participation"), adopted 8 October 2001. The directive establishes rules on worker involvement in the management of the SE.
EU member states differ in the degree of worker involvement in corporate management. In Germany, most large corporations are required to allow employees to elect a certain percentage of seats on the supervisory board. Other member states, such as the UK, have no such requirement, and furthermore in these states such practices are largely unknown and considered a threat to the rights of management.
These differing traditions of worker involvement have held back the adoption of the Statute for over a decade. States without worker involvement provisions were afraid that the SE might lead to having such provisions being imposed on their companies; and states with those provisions were afraid they might lead to those provisions being circumvented.
A compromise, contained in the Directive, was worked out as follows: worker involvement provisions in the SE will be decided upon by negotiations between employees and management before the creation of the SE. If agreement cannot be reached, provisions contained in the Directive will apply. The Directive provides for worker involvement in the SE if a minimum percentage of employees from the entities coming together to form the SE enjoyed worker involvement provisions. The Directive permits member states to not implement these default worker involvement provisions in their national law, but then an SE cannot be created in that member state if the provisions in the Directive would apply and negotiations between workers and management are unsuccessful.
Definition.
Definition of employee participation: it does not mean participation in day-to-day decisions, which are a matter for the management, but participation in the supervision and strategic development of the company.
Employment contracts and pensions.
Employment contracts and pensions are not covered by the Directive. With regard to occupational pension schemes, the SE is covered by the provisions laid down in the proposal for a directive on institutions for occupational schemes, presented by the Commission in October 2000, in particular in connection with the possibility of introducing a single pension scheme for all their employees in the European Union.
Development.
Two approaches have been attempted to solve the problems cited above. One approach is to harmonize the company law of the member states. This approach has had some successes, but after thirty years only limited progress has been made. It is difficult to harmonize widely different regulatory systems, especially when they reflect different national attitudes to issues such as worker involvement in the management of the company.
The other approach is to construct a whole new system of EU company law, that co-exists with the individual company laws of the member states. Companies would have the choice of operating either under national regulations or under the EU-wide system. However, this approach has been only somewhat more effective than the harmonization approach: while states are not as concerned about having foreign traditions of corporate governance imposed on their companies, which the harmonization approach could well entail; they also wish to ensure that the EU-wide system would be palatable to the traditions of their national companies, so that they will not be put at a disadvantage compared to the other member states.
The European Company Statute represents a step in this direction, albeit a limited one. While it establishes some common EU rules on the SE, these rules are incomplete, and the holes in the rules are to be filled in using the law of the member state in which the SE is registered. This has been due to the difficulties of agreeing on common European rules on these issues.
Registrations.
In terms of registrations, the Czech Republic is vastly overrepresented, accounting for 79% of all "societates Europaeae" as of December 2015. 9 of the 50 constituents of the Euro Stoxx 50 stock market index of leading Euro Area companies are as of December 2015 "societates Europaeae".
Annual registrations by member state are presented in the following chart:
Registrations of new "societates" are to be published in the Official Journal of the European Union. There is no official union-wide register of "societates", as they are registered in the nation in which their corporate seats are located. "worker-participation.eu" does however maintain a database of current and planned registrations. Examples of companies include:

</doc>
<doc id="9924" url="https://en.wikipedia.org/wiki?curid=9924" title="Electronic mixer">
Electronic mixer

An electronic mixer is a device that combines two or more electrical or electronic signals into one or two composite output signals. There are two basic circuits that both use the term "mixer", but they are very different types of circuits: additive mixers and multiplicative mixers.
Simple additive mixers use Kirchhoff's circuit laws to add the currents of two or more signals together, and this terminology ("mixer") is only used in the realm of audio electronics where audio mixers are used to add together audio signals such as voice signals, music signals, and sound effects.
Multiplicative mixers multiply together two time-varying input signals instantaneously (instant-by-instant). If the two input signals are both sinusoids of specified frequencies f1 and f2, then the output of the mixer will contain two new sinsoids that have the sum f1 + f2 frequency and the difference frequency absolute value |f1 - f2|.
Note: Any nonlinear electronic block driven by two signals with frequencies f1 and f2 would generate intermodulation (mixing) products. A multiplier (which is a nonlinear device) will generate ideally only the sum and difference frequencies, whereas an arbitrary nonlinear block would generate also signals at e.g. 2·f1-3·f2, etc. Therefore, normal nonlinear amplifiers or just single diodes have been used as mixers, instead of a more complex multiplier. A multiplier has usually the advantage of rejecting - at least partly - undesired higher-order intermodulations and larger conversion gain.
Additive mixers.
Additive mixers add two or more signals, giving out a composite signal that contains the frequency components of each of the source signals. The simplest additive mixers are simple resistor networks, and thus purely passive, while more complex matrix mixers employ active components such as buffer amplifiers for impedance matching and better isolation.
Multiplicative mixers.
Ideal multiplicative mixers produce an output signal equal to the product of the two input signals. Multiplicative mixers are often used in conjunction with an oscillator in the communications field to modulate signal frequencies. Multiplicative mixers can be coupled with a filter to either up-convert or down-convert an input signal frequency, but they are more commonly used to down-convert to a lower frequency to allow for simpler filter designs, as done in superheterodyne receivers. In many typical circuits, the single output signal actually contains multiple waveforms, namely those at the sum and difference of the two input frequencies and harmonic waveforms. The output signal may be obtained by removing the other signal components with a filter. ("see" intermediate frequency)
Multiplicative mixers have been implemented in a wide variety of ways. The most popular are Gilbert cell mixers, diode mixers, diode ring mixers (ring modulation) and switching mixers. Diode mixers take advantage of the non-linearity of diode devices to produce the desired multiplication in the squared term. It is a very inefficient method as most of the power output is in other unwanted terms which need filtering out. Inexpensive AM radios still use diode mixers.
Electronic mixers are usually made with transistors and/or diodes arranged in a balanced circuit or even a double-balanced circuit. These are readily manufactured by using the technology of either monolithic integrated circuits or hybrid integrated circuits. These are designed for a wide variety of frequency ranges, and they are mass produced to tight tolerances by the hundreds of thousands, making them relatively cheap components.
These double-balanced mixers are very widely used in microwave communication systems, satellite communication systems, and ultrahigh frequency (UHF) communications transmitters and receivers, and in radar systems transmitters and receivers.
"Gilbert cell" mixers are just an arrangement of transistors that multiplies the two signals. The switching mixers (below) pass more power and usually insert less distortion.
"switching mixers" use arrays of field effect transistors or (in older days) vacuum tubes. These are used as electronic switches, to permit the signal to go one direction, then the other. They are controlled by the signal being mixed. They are especially popular with digitally controlled radios.

</doc>
<doc id="9925" url="https://en.wikipedia.org/wiki?curid=9925" title="Eubulides">
Eubulides

Eubulides (; fl. 4th century BCE) of Miletus was a philosopher of the Megarian school, and a pupil of Euclid of Megara. He is famous for his paradoxes.
Life.
Eubulides was a pupil of Euclid of Megara, the founder of the Megarian school. He was a contemporary of Aristotle, against whom he wrote with great bitterness. He taught logic to Demosthenes, and he is also said to have taught Apollonius Cronus, the teacher of Diodorus Cronus, and the historian Euphantus. He may have been the author of a book about Diogenes of Sinope.
Paradoxes of Eubulides.
Eubulides is most famous for inventing the forms of seven famous paradoxes, some of which, however, are also ascribed to Diodorus Cronus:
The first paradox (the Liar) is probably the most famous, and is similar to the famous paradox of Epimenides the Cretan. The second, third and fourth paradoxes are variants of a single paradox and relate to the problem of what it means to "know" something and the identity of objects involved in an affirmation (compare the masked man fallacy). The fifth and sixth paradoxes are also a single paradox and is usually thought to relate to the vagueness of language. The final paradox attacks presumptions involved in a proposition, and is related to the syllogistic fallacy.
These paradoxes were very well known in ancient times, some are alluded to by Eubulides' contemporary Aristotle and even partially by Plato. Aulus Gellius mentions how the discussion of such paradoxes was considered (for him) after-dinner entertainment at the Saturnalia, but Seneca, on the other hand, considered them a waste of time: "Not to know them does no harm, and mastering them does no good."

</doc>
