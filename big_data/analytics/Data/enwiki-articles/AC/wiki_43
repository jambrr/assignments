<doc id="15076" url="https://en.wikipedia.org/wiki?curid=15076" title="International Data Encryption Algorithm">
International Data Encryption Algorithm

In cryptography, the International Data Encryption Algorithm (IDEA), originally called Improved Proposed Encryption Standard (IPES), is a symmetric-key block cipher designed by James Massey of ETH Zurich and Xuejia Lai and was first described in 1991. The algorithm was intended as a replacement for the Data Encryption Standard (DES). IDEA is a minor revision of an earlier cipher, Proposed Encryption Standard (PES).
The cipher was designed under a research contract with the Hasler Foundation, which became part of Ascom-Tech AG. The cipher was patented in a number of countries but was freely available for non-commercial use. The name "IDEA" is also a trademark. The last patents expired in 2012, and IDEA is now patent-free and thus completely free for all uses.
IDEA was used in Pretty Good Privacy (PGP) v2.0, and was incorporated after the original cipher used in v1.0, BassOmatic, was found to be insecure. IDEA is an optional algorithm in the OpenPGP standard.
Operation.
IDEA operates on 64-bit blocks using a 128-bit key, and consists of a series of eight identical transformations (a "round", see the illustration) and an output transformation (the "half-round"). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups — modular addition and multiplication, and bitwise eXclusive OR (XOR) — which are algebraically "incompatible" in some sense. In more detail, these operators, which all deal with 16-bit quantities, are:
After the eight rounds comes a final “half round”, the output transformation illustrated below (the swap of the middle two values cancels out the swap at the end of the last round, so that there is no net swap):
Structure.
The overall structure of IDEA follows the Lai-Massey scheme. XOR is used for both subtraction and addition. IDEA uses a key-dependent half-round function. To work with 16 bit words (meaning four inputs instead of two for the 64 bit block size), IDEA uses the Lai-Massey scheme twice in parallel, with the two parallel round functions being interwoven with each other. To ensure sufficient diffusion, two of the sub-blocks are swapped after each round.
Key schedule.
Each round uses six 16-bit sub-keys, while the half-round uses four, a total of 52 for 8.5 rounds. The first eight sub-keys are extracted directly from the key, with K1 from the first round being the lower sixteen bits; further groups of eight keys are created by rotating the main key left 25 bits between each group of eight. This means that it is rotated less than once per round, on average, for a total of six rotations.
Decryption.
Decryption works like encryption, but the order of the round keys is inverted and the subkeys for the odd rounds are inversed. For instance, the values of subkeys K1 - K4 are replaced by the inverse of K49 - K52 for the respective group operation, K5 and K6 of each group should be replaced by K47 and K48 for decryption.
Security.
The designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. , the best attack which applied to all keys could break IDEA reduced to 6 rounds (the full IDEA cipher uses 8.5 rounds). Note that a "break" is any attack which requires less than 2128 operations; the 6-round attack requires 264 known plaintexts and 2126.8 operations.
Bruce Schneier thought highly of IDEA in 1996, writing, "In my opinion, it is the best and most secure block algorithm available to the public at this time." ("Applied Cryptography", 2nd ed.) However, by 1999 he was no longer recommending IDEA due to the availability of faster algorithms, some progress in its cryptanalysis, and the issue of patents.
In 2011 full 8.5-round IDEA was broken using a meet-in-the-middle attack. Independently in 2012, full 8.5 round IDEA was broken using a narrow-bicliques attack, with a reduction of cryptographic strength of about two bits, similar to the effect of the previous bicliques attack on AES.
Weak keys.
The very simple key schedule makes IDEA subject to a class of weak keys; some keys containing a large number of 0 bits produce weak encryption. These are of little concern in practice, being sufficiently rare that they are unnecessary to avoid explicitly when generating keys randomly. A simple fix was proposed: exclusive-ORing each subkey with a 16-bit constant, such as codice_1.
Larger classes of weak keys were found in 2002.
This is still of negligible probability to be a concern to a randomly chosen key, and some of the problems are fixed by the constant XOR proposed earlier, but the paper is not certain if all of them are. A more comprehensive redesign of the IDEA key schedule may be desirable.
Availability.
A patent application for IDEA was first filed in Switzerland (CH A 1690/90) on May 18, 1990, then an international patent application was filed under the Patent Cooperation Treaty on May 16, 1991. Patents were eventually granted in Austria, France, Germany, Italy, the Netherlands, Spain, Sweden, Switzerland, the United Kingdom, (, filed May 16, 1991, issued June 22, 1994 and expired May 16, 2011), the United States (, issued May 25, 1993 and expired January 7, 2012) and Japan (JP 3225440) (expired May 16, 2011).
MediaCrypt AG is now offering a successor to IDEA and focuses on its new cipher (official release on May 2005) IDEA NXT, which was previously called FOX.

</doc>
<doc id="15077" url="https://en.wikipedia.org/wiki?curid=15077" title="Indoor rower">
Indoor rower

An indoor rower, or rowing machine, is a machine used to simulate the action of watercraft rowing for the purpose of exercise or training for rowing. Indoor rowing has become established as a sport in its own right. The term also refers to a participant in this sport.
Modern indoor rowers are often known as ergometers (colloquially erg or ergo), an ergometer being a device which measures the amount of work performed. The indoor rower is calibrated to measure the amount of energy the rower is using through their use of the equipment.
History.
Chabrias, an Athenian admiral of the 4th century BC, introduced the first rowing machines as supplemental military training devices. "To train inexperienced oarsmen, Chabrias built wooden rowing frames on shore where beginners could learn technique and timing before they went on board ship." 
Early rowing machines are known to have existed from the mid-1800s, a US patent being issued to W.B. Curtis in 1872 for a particular hydraulic based damper design. Machines using linear pneumatic resistance were common around 1900—one of the most popular was the Narragansett hydraulic rower, manufactured in Rhode Island from around 1900–1960. However they did not simulate actual rowing very accurately nor measure power output. 
In the 1950s and 1960s, coaches in many countries began using specially made rowing machines for training and improved power measurement. One original design incorporated a large, heavy, solid iron flywheel with a mechanical friction brake, developed by John Harrison of Leichhardt Rowing Club in Sydney, later to become a professor of mechanical engineering at the University of New South Wales. Harrison, a dual Australian champion beach sprinter who went on to row in the coxless four at the 1956 Melbourne Olympics, had been introduced to rowing after a chance meeting with one of the fathers of modern athletic physiological training and testing, and the coach of the Leichhardt "Guinea Pigs", Professor Frank Cotton. Professor Cotton had produced a rudimentary friction-based machine for evaluating potential rowers by exhausting them, without any pretence of accurately measuring power output. Harrison realised the importance of using a small braking area with a non-absorbent braking material, combined with a large flywheel. The advantage of this design (produced by Ted Curtain Engineering, Curtain being a fellow Guinea Pig) was the virtual elimination of factors able to interfere with accurate results—for instance ambient humidity or temperature. The Harrison-Cotton machine represents the very first piece of equipment able to accurately quantify human power output; power calculation within an accuracy range as achieved by his machine of less than 1% remains an impressive result today. The friction brake was adjusted according to a rower's weight to give an accurate appraisal of boat-moving ability (drag on a boat is proportional to weight). Inferior copies of Harrison's machine were produced in several countries utilising a smaller flywheel and leather straps—unfortunately the leather straps were sensitive to humidity, and the relatively large braking area made results far less accurate than Harrison's machine. The weight correction factor tended to make them unpopular among rowers of the time. Harrison, arguably the father of modern athletic power evaluation, died in February 2012.
In the 1970s, the Gjessing-Nilson ergometer from Norway used a friction brake mechanism with industrial strapping applied over the broad rim of the flywheel. Weights hanging from the strap ensured that an adjustable and predictable friction could be calculated. The cord from the handle mechanism ran over a helical pulley with varying radius, thereby adjusting the gearing and speed of the handle in a similar way to the changing mechanical gearing of the oar through the stroke, derived from changes in oar angle and other factors. This machine was for many years the internationally accepted standard for measurement.
The first air resistance ergometers were introduced around 1980 by Repco. 
The Concept2 ergometer was introduced in 1980 by the Dreissigacker brothers. The first, the Model A, was a fixed-frame sliding-seat design using a bicycle wheel with fins attached for air resistance. The Model B, introduced in 1986, introduced a solid cast flywheel (now enclosed by a cage) and the first digital performance monitor, which proved revolutionary. This machine's capability of accurate calibration combined with easy transportability spawned the sport of competitive indoor rowing, and revolutionised training and selection procedures for watercraft rowing. The later Models C (1993) and D (2003) became some of the best-selling fitness equipment pieces of all time.
Design summary.
All rowing-machine designs consist of an energy damper or braking mechanism connected to a chain and/or handle. A foot stretcher (where rowers places their feet) is attached to the same mounting as the energy damper. Most include a rail which either the seat or the mechanism slide upon. Different machines have a variety of layouts and damping mechanisms, each of which have certain advantages and disadvantages.
Machines with a digital display calculate the user's power by measuring the speed of the flywheel during the stroke and then recording the rate at which it decelerates during the recovery. Using this and the known moment of inertia of the flywheel, the computer is able to calculate speed, power, distance and energy usage. Some ergometers can be connected to a personal computer using software, and data on individual exercise sessions can be collected and analysed. In addition, some software packages allows users to connect multiple ergometers either directly or over the internet for virtual races and workouts.
Motion type.
There are three possible designs to allow the foot stretcher (with flywheel) and handle to move relatively nearer and apart from each other.
The first option is the most common, with the foot stretcher and flywheel both fixed, with only the seat sliding on a rail. This is generally analogous to the seat sliding on rails in the boat. Commonly called a 'Fixed head' ergometer.
The second option is where both the seat and the foot stretcher slide on a rail. This is analogous to both the seat sliding on the boat, and the boat sliding relative to the rower, on the water. The relative movement of seat and flywheel are similar to the result of the rower moving at steadier average speed while the boat's speed varies much more relative to the rower. Commonly called a 'Floating head' ergometer.
The third option has the seat fixed. Only the foot stretcher slides backward and away from the rower.
In addition, some indoor rowers include a pivoting handle or handles (as opposed to a simple chain) in order to more completely simulate the action of rowing or sculling. Such machines are known as "rowing simulators".
Damper type.
Piston resistance comes from hydraulic cylinders that are attached to the handles of the rowing machine. The length of the rower handles on this class of rower is typically adjustable, however, during the row the handle length is fixed which in turn fixes the trajectory that the hands must take on the stroke and return, thus making the stroke less accurate than is possible on the other types of resistance models where it is possible to emulate the difference in hand height on the stroke and return. Furthermore, many models in this class have a fixed seat position that eliminates the leg drive which is the foundation of competitive on water rowing technique. Because of the compact size of the pistons and mechanical simplicity of design, these models are typically not as large or as expensive as the others types.
Braked flywheel resistance models comprise magnetic, air and water resistance rowers. These machines are mechanically similar since all three types use a handle connected to a flywheel by rope, chain, or strap to provide resistance to the user – the types differ only in braking mechanism. Because the handle is attached to the resistance source by rope or similarly flexible media, the trajectory of the hands in the vertical plane is free making it possible for the rower to emulate the hand height difference between the stroke and the return. Most of these models have the characteristic sliding seat typical of competitive on-the-water boats.
Rowing machines with monitors calculate performance using an algorithm unique to the individual manufacturer; it will be affected by the type of resistance used and other factors.
Exercise.
Indoor rowing primarily works the cardiovascular systems with typical workouts consisting of steady pieces of 20–40 minutes, although the standard trial distance for record attempts is 2000 m, which can take from five and a half minutes (best elite rowers) to nine minutes or more. Like other forms of cardio focused exercise, interval training is also commonly used in indoor rowing. While cardio-focused, rowing also stresses many muscle groups throughout the body anaerobically, thus rowing is often referred to as a strength-endurance sport.
Unlike high impact exercises, which can damage knees and the connective tissues of the lower body, rowing's most common injury site is the lower back. Proper technique is a necessity for staying injury free, with a focus on both mechanics and breathing, as correct rhythm, exhaling on the drive and inhaling on the recovery, is a stabilizing force for the upper body. Non-rowers commonly overemphasize the muscles of the upper body, while correct technique uses the large muscle of the thighs to drive much of the stroke. Also, good technique requires that the angle of the upper body is never too far forward, nor too far back, both of which jeopardize the lower back and compression injuries on the knees and hip flexor muscles.
In addition to the high levels of fitness attained, rowing is an intense calorie-burning exercise. Although rowers with less ability and training will burn fewer calories, the ergometer is an excellent tool for use in a weight-loss program.
The standard measurement of speed on an ergometer is generally known as the "split", or the amount of time in minutes and seconds required to travel at the current pace — a split of 2:00 represents a speed of two minutes per 500 metres, or about . The split does not necessarily correspond to how many strokes the rower takes (the "rating") since strokes can vary in power.
Ergometer testing.
Ergometer tests are used by rowing coaches to evaluate rowers and is part of athlete selection for many senior and junior national rowing teams. During a test, rowers will row a set distance and try to clock the fastest time possible, or a set time and try to row the longest distance possible. The most common distances for erg tests are 2000, 5000, 6000 or 10000 metres. The most common times for erg tests are 3 min, 5 min, 20 min, 30 min, and 1 hour. Results of these tests are an objective measure of an athlete's fitness; however, weight, technique and team coordination also impact performance in a boat, thus assembling a crew based purely on erg scores is not an optimal strategy. In fact it is not unheard of for teams that are considerably faster on the ergometer to be beaten on the water.
Rowing technique.
Rowing technique on the erg broadly follows the same pattern as that of a normal rowing stroke on water, but with minor modifications: it is not necessary to "tap down" at the finish, since there are no blades to extract from water; but many who also row on water do this anyway. Sometimes an exaggerated finish, pulling the hands further up the chest than would be possible on water, is used.
Rowing on an ergometer requires four basics phases to complete one stroke; the catch, the drive, the finish and the recovery. The catch is the initial part of the stroke. The drive is where the power from the rower is generated while the finish is the final part of the stroke. Then, the recovery is the initial phase to begin taking a new stroke. The phases repeat until a time duration or a distance is completed.
Catch.
Knees are bent with the shins in a vertical position. The back should be roughly parallel to the thigh without hyperflexion (leaning forward too far). The arms and shoulders should be extended forward and relaxed. The arms should be level.
Drive.
The drive is initiated by the extension of the legs; the body remains in the catch posture at this point of the drive. As the legs continue to full extension, the rower engages the core to begin the motion of the body levering backward, adding to the work of the legs. When the legs are flat, the rower begins to pull the handle toward the chest with their arms while keeping their arms straight and parallel to the floor.
Finish (or release).
The legs are at full extension and flat. The shoulders are slightly behind the pelvis, and the arms are in full contraction with the elbows bent and hands against the chest below the nipples. The back of the rower is still maintained in an upright posture and wrists should be flat.
Recovery.
The recovery is a slow slide back to the initial part of the stroke, it gives the rower time to recover from the previous stroke. During the recovery the actions are in reverse order of the drive. The arms are fully extended so that they are straight. The torso is engaged to move forward back over the pelvis. Weight transfers from the back of the seat to the front of the seat at this time. When the hands come over the knees, the legs contract back towards the foot stretcher. Slowly the back becomes more parallel to the thighs until the recovery becomes the catch.
Competitions.
A large number of indoor rowing competitions are held all over the world, including the indoor rowing world championships (also known as CRASH-B Sprints) held in Boston, Massachusetts, United States in February and the British Indoor Rowing Championships held in Birmingham, England in November; both are rowed on Concept2s. The core event for most competitions is the individual 2000-m; less common are the mile (e.g., Evesham), the 2500-m (e.g., Basingstoke—also the original distance of the CRASH-B Sprints). Many competitions also include a sprint event (100m-500m) and sometimes team relay events. The machines used are consistent although the resistance may be adjusted. The resistance adjustment does not affect the energy measurement so a result on one machine can be fairly compared with results on other machines regardless of resistance level.
Most competitions are organized into categories based on sex, age, and weight class. While the fastest times are generally achieved by rowers between 20 and 40 years old, teenagers and rowers over 90 are common at competitions. There is a nexus between performance on-water and performance on the ergometer, with open events at the World Championships often being dominated by elite on-water rowers. Former men's Olympic single scull champions Pertti Karppinen and Rob Waddell and five-time Gold Medalist Sir Steven Redgrave have all won world championships or set world records in indoor rowing.
In addition to live venue competitions, many erg racers compete by internet, either offline by posting scores to challenges, or live online races facilitated by computer connection. Online Challenges sponsored by Concept2 include the annual ultra-rowing challenge, the Virtual Team Challenge.

</doc>
<doc id="15078" url="https://en.wikipedia.org/wiki?curid=15078" title="Internetwork Packet Exchange">
Internetwork Packet Exchange

Internetwork Packet Exchange (IPX) is the network layer protocol in the IPX/SPX protocol suite. IPX is derived from Xerox Network Systems' IDP. It may act as a transport layer protocol as well.
The IPX/SPX protocol suite was very popular through the late 1980s into the mid-1990s because it was used by the Novell NetWare network operating system. Because of Novell Netware popularity the IPX became a prominent internetworking protocol.
A big advantage of IPX was a small memory footprint of the IPX driver, which was vital for MS-DOS and Microsoft Windows up to the version Windows 95 because of limited size of the conventional memory. Another IPX advantage is an easy configuration of the client computers. However, IPX does not scale well for large networks such as the Internet, and as such, IPX usage decreased as the boom of the Internet made TCP/IP nearly universal. Computers and networks can run multiple network protocols, so almost all IPX sites will be running TCP/IP as well to allow for Internet connectivity. It has also been possible to run Novell products without IPX for some time, as they have supported both IPX and TCP/IP since NetWare reached version 5 in late 1998.
Description.
A big advantage of IPX protocol is its little or no need for configuration. In the time when protocols for dynamic host configuration did not exist and the BOOTP protocol for centralized assigning addresses was not common, the IPX network could be configured almost automatically. A client computer uses the MAC address of its network card as the node address, and learns the network number from the server or router. Network number is derived from MAC address of the server.
A small IPX network administrator had to care only
IPX packet structure.
Each IPX packet begins with a header with the following structure:
The Packet Type values:
IPX addressing.
An IPX address has the following structure:
Network number.
The network number allows to address (and communicate with) the IPX nodes which do not belong to the same network or "cabling system". The cabling system is a network in which a data link layer protocol can be used for communication. To allow communication between different networks, they must be connected with IPX routers. A set of interconnected networks is called an internetwork. Any Novell Netware server may serve as an IPX router. Novell also supplied stand-alone routers. Multiprotocol routers of other vendors often support IPX routing. Using different frame formats in one cabling system is possible, but it works similarly as if separate cabling systems were used (i.e. different network numbers must be used for different frame formats even in the same cabling system and a router must be to allow communication between nodes using different frame formats in the same cabling system).
Node number.
The node number is used to address an individual computer (or more exactly, a network interface) in the network. Client stations use its network interface card MAC address as the node number.
The value FF:FF:FF:FF:FF:FF may be used as a node number in a destination address to broadcast a packet to "all nodes in the current network".
Socket number.
The socket number serves to select a process or application in the destination node.
The presence of a socket number in the IPX address allows the IPX to act as a transport layer protocol, comparable with the User Datagram Protocol (UDP) in the Internet protocol suite.
Comparison with IP.
The IPX network number is conceptually identical to the network part of the IP address (the parts with netmask bits set to 1); the node number has the same meaning as the bits of IP address with netmask bits set to 0. The difference is that the boundary between network and node part of address in IP is variable, while in IPX it is fixed. As the node address is usually identical to the MAC address of the network adapter, the Address Resolution Protocol is not needed in IPX.
For routing, the entries in the IPX routing table are similar to IP routing tables; routing is done by network address, and for each network address a network:node of the next router is specified in a similar fashion an IP address/netmask is specified in IP routing tables.
There are 3 routing protocols available for IPX networks: In early IPX networks a version of Routing Information Protocol (RIP) was the only available protocol to exchange routing information. Unlike RIP for IP, it uses delay time as the main metric, retaining the hop count as a secondary metric. Since NetWare 3, the NetWare Link Services Protocol (NSLP) based on IS-IS is available which is more suitable for larger networks. Cisco routers implement an IPX version of EIGRP protocol as well.
Frame formats.
IPX can be transmitted over Ethernet using one of the following 4 frame formats or encapsulation types:
In non-Ethernet networks only 802.2 and SNAP frame types are available.

</doc>
<doc id="15079" url="https://en.wikipedia.org/wiki?curid=15079" title="International human rights instruments">
International human rights instruments

International human rights instruments are treaties and other international documents relevant to international human rights law and the protection of human rights in general. They can be classified into two categories: "declarations", adopted by bodies such as the United Nations General Assembly, which are not legally binding although they may be politically so as soft law; and "conventions", which are legally binding instruments concluded under international law. International treaties and even declarations can, over time, obtain the status of customary international law.
International human rights instruments can be divided further into "global instruments", to which any state in the world can be a party, and "regional instruments", which are restricted to states in a particular region of the world.
Most conventions establish mechanisms to oversee their implementation. In some cases these mechanisms have relatively little power, and are often ignored by member states; in other cases these mechanisms have great political and legal authority, and their decisions are almost always implemented. Examples of the first case include the UN treaty committees, while the best exemplar of the second case is the European Court of Human Rights.
Mechanisms also vary as to the degree of individual access to them. Under some conventions – e.g. the European Convention on Human Rights – individuals or states are permitted, subject to certain conditions, to take individual cases to the enforcement mechanisms; under most, however (e.g. the UN conventions), individual access is contingent on the acceptance of that right by the relevant state party, either by a declaration at the time of ratification or accession, or through ratification of or accession to an optional protocol to the convention. This is part of the evolution of international law over the last several decades. It has moved from a body of laws governing states to recognizing the importance of individuals and their rights within the international legal framework.
The Universal Declaration of Human Rights, the International Covenant on Civil and Political Rights, and the International Covenant on Economic, Social and Cultural Rights are sometimes referred to as the "international bill of rights".

</doc>
<doc id="15080" url="https://en.wikipedia.org/wiki?curid=15080" title="Indian removal">
Indian removal

Indian removal was a policy of the United States government in the 19th century whereby Native Americans were forcibly removed from their ancestral homelands in the eastern United States to lands west of the Mississippi River, thereafter known as Indian Territory. That policy has been characterized by some scholars as part of a long-term genocide of Native Americans by European settlers to North America in the colonial period and citizens of the United States until the mid-20th century. The policy traced its direct origins to the administration of James Monroe, though it addressed conflicts between whites and Native Americans that had been occurring since the 17th century, and were getting worse by the early 19th century as white settlers were increasingly pushing west. The Indian Removal Act was the key act that enforced Indian removal, and was signed into law by President Andrew Jackson on May 28, 1830.
The Revolutionary background.
Some of the American Revolutionary thinkers and leaders viewed the American Indians not as a single people, but as nations in their own right, and developed early policies for the new United States to interact with the Indian nations:
Benjamin Franklin.
Benjamin Franklin, in his "Proposed Articles of Confederation" (presented to the Continental Congress on May 10, 1775) for the nation about to take birth, called for a "perpetual Alliance" with the Indians, especially with the Six Nations of the Iroquois Confederacy.
Thomas Jefferson.
Thomas Jefferson, in his Notes on the State of Virginia (1785), defended American Indian culture and marveled at how the tribes of Virginia "never submitted themselves to any laws, any coercive power, any shadow of government" due to their "moral sense of right and wrong". 
He would later write, "I believe the Indian then to be in body and mind equal to the whiteman". His desire was for the Native Americans to intermix with European Americans and to become one people. 
To achieve that end, President Jefferson would - in addition to offering U.S. citizenship to some of the Indian nations - propose lending credit to them for trade with the expectation they would be unable to honor their debts and thereby the United States would acquire their land.
George Washington.
President George Washington, while addressing the Seneca nation in 1790, publicly pledged to uphold their “just rights” and described the pre-Constitutional defrauding of the Indians out of their land as “evil”.
In March and April of 1792, Washington met with 50 tribal chiefs in Philadelphia – including the Iroquois – to discuss closer friendship between them and the United States.
Later that same year, Washington stressed the need for building peace, trust, and commerce with America's Indian neighbors:
I cannot dismiss the subject of Indian affairs without again recommending to your consideration the expediency of more adequate provision for giving energy to the laws throughout our interior frontier, and for restraining the commission of outrages upon the Indians; without which all pacific plans must prove nugatory. To enable, by competent rewards, the employment of qualified and trusty persons to reside among them, as agents, would also contribute to the preservation of peace and good neighbourhood. If, in addition to these expedients, an eligible plan could be devised for promoting civilization among the friendly tribes, and for carrying on trade with them, upon a scale equal to their wants, and under regulations calculated to protect them from imposition and extortion, its influence in cementing their interests with our’s could not but be considerable.
In 1795, in his Seventh Message to Congress, Washington expressed that if the US government wanted peace with the Indians, then it must give peace to them, and that if the US wanted raids by Indians to stop, then raids by American "frontier inhabitants" must also stop.
Early Congressional Acts.
The new Congress passed the Northwest Ordinance of 1787, which would, for years to come, serve broadly as a precedent for the manner in which the United States' territorial expansion would occur, called for the protection of Indians' "property, rights, and liberty":
The U.S. Constitution of 1787 (Article I, Section 8) calls for regulating commerce with the Indian tribes, and makes their importance to Congress equal to that of the states and foreign governments.
In 1790, Congress passed the Indian Nonintercourse Act (renewed and amended in 1793, 1796, 1799, 1802, and 1834) to protect and codify the Indians’ land rights.
The above acts and sentiments stood in contrast with those of President Andrew Jackson in the 1830s:
Jeffersonian policy.
As president, Thomas Jefferson developed far reaching Indian policy that had two primary goals. The security of the fledgling United States was paramount so Jefferson wanted to assure the Native nations were tightly bound to the United States and not other foreign nations. Secondly he wanted "to civilize" them into agricultural or more urbanized lifestyles. These goals would be achieved through trade and treaties.
He encouraged American policy to allow Native Americans to remain east of the Mississippi as long as they became assimilated or "civilized". As President, Jefferson made sustained efforts to win the friendship and cooperation of many Native American nations. He repeatedly articulated his aspirations for a united nation of both Whites and Indians, such as the following from a letter to the Seneca spiritual leader Handsome Lake dated November 3, 1802:
Go on then, brother, in the great reformation you have undertaken... In all your enterprises for the good of your people, you may count with confidence on the aid and protection of the United States, and on the sincerity and zeal with which I am myself animated in the furthering of this humane work. You are our brethren of the same land; we wish your prosperity as brethren should do. Farewell.
Jefferson's personal nonsectarian religiosity appears to show in his references to the Great Spirit, as in the following letter to the Choctaw nation dated December 17, 1803:
I am glad, brothers, you are willing to go and visit some other parts of our country... we thank the Great Spirit who took care of you on the ocean, and brought you safe and in good health to the seat of our great Council; and we hope His care will accompany and protect you, on your journey and return home; and that He will preserve and prosper your nation in all its just pursuits.
President Jefferson also sought full U.S. citizenship for those Indian nations which desired it, including the Cherokee. In his Eighth Annual Message to Congress on November 8, 1808, he presented to the nation a vision of White and Indian unity:
With our Indian neighbors the public peace has been steadily maintained... And, generally, from a conviction that we consider them as part of ourselves, and cherish with sincerity their rights and interests, the attachment of the Indian tribes is gaining strength daily... and will amply requite us for the justice and friendship practiced towards them... of the two great divisions of the Cherokee nation have now under consideration to solicit the citizenship of the United States, and to be identified with us in laws and government, in such progressive manner as we shall think best.
Years after the Jefferson presidency, in 1817 the U.S. government would again offer citizenship to the Cherokee who lived east of the Mississippi River, along with 640 acres per family.
As other writings illustrate, his general compassion for the Indians at times gave way to impatience with nations which responded unfavorably to his communications with them, and to his frustration with the limited success of his efforts. His intention was to change their lifestyle from hunter-gatherer to farming, largely through "the decrease of game rendering their subsistence by hunting insufficient". Jefferson expected that the switch to agriculture would make them dependent on White Americans for trade goods and therefore more likely to give up their land in exchange. In an 1803 letter to William Henry Harrison, Jefferson wrote:
When they withdraw themselves to the culture of a small piece of land, they will perceive how useless to them are their extensive forests, and will be willing to pare them off from time to time in exchange for necessaries for their farms and families. To promote this disposition to exchange lands, which they have to spare and we want, for necessaries, which we have to spare and they want, we shall push our trading uses, and be glad to see the good and influential individuals among them run in debt, because we observe that when these debts get beyond what the individuals can pay, they become willing to lop them off by a cession of lands. At our trading houses, too, we mean to sell so low as merely to repay us cost and charges, so as neither to lessen or enlarge our capital. This is what private traders cannot do, for they must gain; they will consequently retire from the competition, and we shall thus get clear of this pest without giving offence or umbrage to the Indians. In this way our settlements will gradually circumscribe and approach the Indians, and they will in time either incorporate with us as citizens of the United States, or remove beyond the Mississippi. The former is certainly the termination of their history most happy for themselves; but, in the whole course of this, it is essential to cultivate their love. As to their fear, we presume that our strength and their weakness is now so visible that they must see we have only to shut our hand to crush them, and that all our liberalities to them proceed from motives of pure humanity only. Should any tribe be foolhardy enough to take up the hatchet at any time, the seizing the whole country of that tribe, and driving them across the Mississippi, as the only condition of peace, would be an example to others, and a furtherance of our final consolidation. 
However, elsewhere in the same letter, Jefferson spoke of protecting the Indians from injustices perpetrated by Whites:
Our system is to live in perpetual peace with the Indians, to cultivate an affectionate attachment from them, by everything just and liberal which we can do for them within... reason, and by giving them effectual protection against wrongs from our own people.
Native American land was sometimes purchased, either via a treaty or under duress. The idea of land exchange, that is, Native Americans would give up their land east of the Mississippi in exchange for a similar amount of territory west of the river, was first proposed by Jefferson in 1803 and was first incorporated into treaties in 1817. The Indian Removal Act of 1830 incorporated this concept.
Calhoun's plan.
Under President James Monroe, Secretary of War John C. Calhoun devised the first plans for Indian removal. By late 1824, Monroe approved Calhoun's plans and in a special message to the Senate on January 27, 1825, requested the creation of the Arkansas Territory and Indian Territory. The Indians east of the Mississippi were to voluntarily exchange their lands for lands west of the river. The Senate accepted Monroe's request and asked Calhoun to draft a bill, which was killed in the House of Representatives by the Georgia delegation. President John Quincy Adams assumed the Calhoun–Monroe policy and was determined to remove the Indians by non-forceful means, but Georgia refused to submit to Adams' request and forced Adams to make a treaty with Creeks and Cherokees granting Georgia what it wanted. When Andrew Jackson became the president from the newly organized Democratic Party, he agreed that the Indians should be forced to exchange eastern lands for western lands.
Indian Removal Act.
When Andrew Jackson became president of the United States in 1829, his government took a hard line. Jackson abandoned the policy of his predecessors of treating different Indian groups as separate nations. Instead, he aggressively pursued plans against all Indian tribes which claimed constitutional sovereignty and independence from state laws, and which were based east of the Mississippi River. They were to be removed to reservations in Indian Territory west of the Mississippi (now Oklahoma), where their laws could be sovereign without any state interference. At Jackson's request, the United States Congress opened a debate on an Indian Removal Bill. After fierce disagreements the Senate passed the measure 28–19, the House 102–97. Jackson signed the legislation into law May 30, 1830.
In 1830, the majority of the "Five Civilized Tribes"—the Chickasaw, Choctaw, Creek, Seminole, and Cherokee—were living east of the Mississippi as they had for thousands of years. The Indian Removal Act of 1830 implemented the U.S. government policy towards the Indian populations, which called for moving Native American tribes living east of the Mississippi River to lands west of the river. While it did not authorize the forced removal of the indigenous tribes, it authorized the President to negotiate land exchange treaties with tribes located in lands of the United States.
Choctaw.
On September 27, 1830, the Choctaw signed the Treaty of Dancing Rabbit Creek and by concession, became the first Native American tribe to be removed. The agreement represented one of the largest transfers of land that was signed between the U.S. Government and Native Americans without being instigated by warfare. By the treaty, the Choctaw signed away their remaining traditional homelands, opening them up for European-American settlement in Mississippi Territory. When the Choctaw reached Little Rock, a Choctaw chief referred to the trek as a "trail of tears and death".
Alexis de Tocqueville, the French philosopher, witnessed the Choctaw removals while in Memphis, Tennessee, in 1831,
Cherokee.
While the Indian Removal Act made the move of the tribes voluntary, it was often abused by government officials. The best-known example is the Treaty of New Echota. It was negotiated and signed by a small faction of Cherokee tribal members, not the tribal leadership, on December 29, 1835. It resulted in the forced relocation of the tribe in 1838. An estimated 4,000 Cherokee died in the march, now known as the Trail of Tears. Missionary organizer Jeremiah Evarts urged the Cherokee Nation to take their case to the U.S. Supreme Court. The Marshall court ruled that while Native American tribes were sovereign nations ("Cherokee Nation v. Georgia", 1831), state laws had no force on tribal lands ("Worcester v. Georgia", 1832).
In spite of this acculturation, many white settlers and land speculators simply desired the land. Some claimed their presence was a threat to peace and security. Some U.S. states, like Georgia in 1830, passed a law which prohibited whites from living on Native American territory after March 31, 1831, without a license from the state. This law was written to justify removing white missionaries who were helping the Native Americans resist removal.
Seminole.
In 1835, the Seminole refused to leave their lands in Florida, leading to the Second Seminole War. Osceola led the Seminole in their fight against removal. Based in the Everglades of Florida, Osceola and his band used surprise attacks to defeat the U.S. Army in many battles. In 1837, Osceola was seized by deceit upon the orders of U.S. General Thomas Jesup when Osceola came under a flag of truce to negotiate peace. Osceola died in prison of illness. The war would end up costing the U.S. over 1,500 deaths and cost the government $20 million. Some Seminole traveled deeper into the Everglades, while others moved west. Removal continued out west and numerous wars ensued over land.
Muscogee (Creek).
In the aftermath of the Treaty of Fort Jackson and the Treaty of Washington, the Muscogee were confined to a small strip of land in present-day east central Alabama. Following the Indian Removal Act, in 1832 the Creek National Council signed the Treaty of Cusseta, ceding their remaining lands east of the Mississippi to the U.S., and accepting relocation to the Indian Territory. Most Muscogee were removed to Indian Territory during the Trail of Tears in 1834, although some remained behind.
Chickasaw.
Unlike other tribes who exchanged land grants, the Chickasaw were to receive mostly financial compensation of $3 million from the United States for their lands east of the Mississippi River.
In 1836, the Chickasaw had reached an agreement that purchased land from the previously removed Choctaw after a bitter five-year debate. They paid the Choctaw $530,000 for the westernmost part of Choctaw land. The first group of Chickasaw moved in 1837. The $3,000,000 that the U.S. owed the Chickasaw went unpaid for nearly 30 years.
Aftermath.
As a result, the five tribes were resettled in the new Indian Territory in modern-day Oklahoma and parts of Kansas. Some indigenous nations resisted forced migration more forcefully. Those few who stayed behind eventually formed tribal groups including the Eastern Band Cherokee, based in North Carolina, the Mississippi Band of Choctaw Indians, the Seminole Tribe of Florida, and the Creeks in Atmore, Alabama.
Southern removals.
"Many figures have been rounded."
The North.
Tribes in the Old Northwest were far smaller and more fragmented than the Five Civilized Tribes, so the treaty and emigration process was more piecemeal. Bands of Shawnee, Ottawa, Potawatomi, Sauk, and Meskwaki (Fox) signed treaties and relocated to the Indian Territory. In 1832, a Sauk leader named Black Hawk led a band of Sauk and Fox back to their lands in Illinois. In the Black Hawk War, the U.S. Army and Illinois militia defeated Black Hawk and his warriors, resulting in the Sauk and Fox being relocated into what would become modern-day Iowa.
The Iroquois were also supposed to be part of Indian removal, and the Treaty of Buffalo Creek arranged for them to be removed to land in Wisconsin and Kansas. However, the land company that was to purchase the land for the territories reneged on their deal, and subsequent treaties in 1842 and 1857 gave back most of the Iroquois' reservations untouched. Only the Buffalo Creek Reservation was ever dissolved as part of the removal program; a small portion was purchased back over a century later to build a casino.
Jackson's reputation.
Andrew Jackson's reputation took a blow for his treatment of the Indians. Historians who admire Jackson's strong presidential leadership, such as Arthur Schlesinger, Jr., would skip over the Indian question with a footnote. In 1969 Francis Paul Prucha argued that Jackson's removal of the Five Civilized Tribes from the very hostile white environment in the Old South to Oklahoma probably saved their very existence. In the 1970s, however, Jackson came under sharp attack from writers on the left, such as Michael Paul Rogin and Howard Zinn, chiefly on this issue. In the 21st century, his reputation has improved somewhat. Paul R. Bartrop and Steven Leonard Jacobs argue that Jackson's policies did not meet the criterion for genocide or cultural genocide. Jackson historian Steve Inskeep reports:
Further reading.
University of Oklahoma Press, 2002. ISBN 978-0-8061-3432-1 (2002 edition).

</doc>
<doc id="15081" url="https://en.wikipedia.org/wiki?curid=15081" title="Green Party (Ireland)">
Green Party (Ireland)

The Green Party () is a green party in Ireland that operates in both the Republic of Ireland and Northern Ireland. It was founded as the Ecology Party of Ireland in 1981 by Dublin teacher Christopher Fettes. The party became the Green Alliance in 1983 and in 1987 was renamed to its current title in English. Its leader is Eamon Ryan, its deputy leader is Catherine Martin and its chairman is Roderic O'Gorman.
Green Party candidates have been elected to all levels of representation; local, Dáil and European Parliament, and in 2007 the party gained its first representation in the Northern Ireland Assembly, the Green Party in Northern Ireland having become a region of the party the previous year.
The Greens became part of the Irish government for the first time following the Irish general election, 2007, having agreed upon a programme for government in coalition with Fianna Fáil and the Progressive Democrats. In the wake of the Irish financial crisis, the party lost a significant amount of its support and came under pressure to withdraw its support for the administration. In January 2011 the party withdrew from government, after passing legislation for European Union and International Monetary Fund financial support for the Republic's bank bailout, and a dispute with Fianna Fáil over the appointment of cabinet ministers. In the February 2011 election, the party suffered a wipeout, losing all six of its TDs. Following the 2011 Seanad Éireann election, the party no longer had any representatives in the Oireachtas. However, in the February 2016 election, the Green Party returned to the Dáil with two seats, becoming the first Irish party to lose all seats at an election and win seats after that. Following this, Grace O'Sullivan was elected to the Seanad on the 26th of April that year.
It has one representative in the Northern Ireland Assembly.
History.
The party's first electoral outing was when seven candidates contested the November 1982 general election under the "Ecology Party" banner, winning 0.2% of the vote. Following a name change, they contested the 1984 European Parliament elections, with their party founder winning 1.9% in the Dublin constituency. The following year they won their first election when Marcus Counihan was elected to Killarney Urban District Council during the 1985 local elections. The party nationally ran 34 candidates and won 0.6% of the vote.
The party continued to struggle until the general election of 1989 when the (again renamed) party won its first seat in parliament (the Dáil), when Roger Garland was elected in Dublin South. In the 1994 European Parliament election Patricia McKenna topped the poll for the Dublin Constituency and Nuala Ahern won a seat in Leinster. They retained their seats in 1999 although the party lost five councillors in local elections held that year despite an increase in their vote. In the general election of 1997 the party gained a seat when John Gormley won a Dáil seat in Dublin South–East.
At the general election of 2002 it made a breakthrough, getting six Teachtaí Dála (TDs) elected to the Dáil with 4% of the national vote. However, in the election to the European Parliament of June 2004, the party lost both of the European Parliament seats. In the 2004 local elections at county level it increased its number of councillors from 8 to 18 out of 883 and at town council level its number of councillors increased from 5 to 14 out of 744. While in government, the vast majority of its seats were lost at the 2009 council elections, including its entire traditional Dublin base, where – with the exception of a Town Council Seat in Balbriggan – it held no council seats in Dublin and only three County Council seats in total.
In the 2014 local elections, the party gained nine seats for a total of twelve. The party was successful in the four Dublin area councils.
It has about fifteen hundred members.
Organisation.
The National Executive Committee is the organising committee of the party. It comprises the party leader Eamon Ryan, deputy leader Catherine Martin, Chair Roderic O'Gorman, Young Greens representative, Treasurer and ten members elected annually at the party convention.
Leadership.
The party did not have a national leader until 2001. At a special "Leadership Convention" in Kilkenny on 6 October 2001, Trevor Sargent was elected the first official leader of the Green Party. He was re-elected to this position in 2003 and again in 2005. The party's constitution requires that a leadership election be held within six months of a general election.
Sargent resigned the leadership in the wake of the general election to the 30th Dáil. During the campaign, Sargent had promised that he would not lead the party into Government with Fianna Fáil. In the election outcome the party retained 6 Dáil seats, making them the most likely partner for Fianna Fáil. Sargent and the party negotiated a coalition government and at the 12 June 2007 membership meeting to approve the agreement, he announced his resignation as leader.
In the subsequent leadership election, John Gormley became the new leader on 17 July 2007, defeating Patricia McKenna by 478 votes to 263. Mary White was subsequently elected as the deputy Leader. John Gormley served as Minister for the Environment, Heritage and Local Government from July 2007 until the Green Party's decision to exit Government in December 2010.
Following the election defeat of 2011, John Gormley announced his intention not to seek another term as Green Party leader. Eamon Ryan was elected as the new party leader, over party colleagues Phil Kearney and Cllr Malcolm Noonan in a postal ballot election of party members in May 2011. Monaghan based former councillor Catherine Martin defeated Down based Dr John Barry and former Senator Mark Dearey to the post of Deputy Leader on 11 June 2011 during the party's annual convention.
The Green Party had six seats in the Irish parliament but lost them all in the 2011 general election. Party Chairman Dan Boyle and Déirdre de Búrca were nominated by the Taoiseach to Seanad Éireann after the formation of the Fianna Fáil–PD–Green Party government in 2007 and Niall Ó Brolcháin elected in December 2009. De Búrca resigned in February 2010, and was replaced by Mark Dearey. Neither Dan Boyle or Niall O'Brolchain were re-elected to Seanad Éireann in the Seanad election of 2011, leaving the Green Party without Oireachtas representation until the elections of 2016, where they regained 2 Dáil seats.
Irish and European politics.
The Green Party is an all-island party, with a region in each of the Republic of Ireland and Northern Ireland. The Green Party in Northern Ireland voted to become a region of the Green Party in Ireland in 2005 at its annual convention, and again in a postal ballot in March 2006.) Brian Wilson, formerly a councillor for the Alliance Party, won the Green Party's first seat in the Northern Ireland Assembly in the 2007 election. Steven Agnew held that seat in the 2011 election.
The Irish Green Party is a member of the European Green Party. Though it previously held a more eurosceptic stance than is usually articulated by most other green parties in Europe, in 2009 the party backed the Lisbon Treaty with support from two thirds of the party.
2007 Dáil election.
Although the party's share of first preference votes increased by some 22% from 3.84% to 4.69% nationally in the 2007 general election, held on 24 May 2007, the party failed to increase the number of TDs returned. Mary White won a seat for the first time in Carlow-Kilkenny; however, Dan Boyle lost his seat in Cork South–Central leaving the party with the same number of TDs as before.
Those elected were:
In government.
The Green Party entered government with Fianna Fáil and the Progressive Democrats on 14 June 2007, gaining two senior ministers John Gormley, Minister for the Environment, Heritage and Local Government and Eamon Ryan, Minister for Communications, Energy and Natural Resources. Trevor Sargent was named the junior minister for Minister of State for Food and Horticulture, however Sargent later resigned the position in 2010. On 23 March 2010, the Green Party gained two new junior ministries. Ciaran Cuffe was appointed as Minister for Horticulture, Sustainable Travel, Planning and Heritage. Mary White was appointed as Minister for Equality, Human Rights and Integration.
The Green Party had approached the 2007 General Election in the Republic on an independent platform, ruling out no coalition partners while expressing its preference for an alternative to the incumbent coalition. The results of the election ruled out the possibility of a Fine Gael/Labour/Green government without support from a combination of the Progressive Democrats, Sinn Féin and various independents (77 seats) leaving it 7 seats short of a majority. Fine Gael ruled out a potential coalition arrangement with Sinn Féin opening the way for Green Party negotiations with Fianna Fáil.
Negotiations for government.
Before the negotiations began Ciarán Cuffe wrote on his blog that "a deal with Fianna Fáil would be a deal with the devil... and Green Party would be decimated as a Party". The negotiations were undertaken by Dan Boyle, Donall Geoghegan (the party's general secretary) and the at that time party Chair John Gormley. The Green Party walked out after 6 days in what Donall Geoghegan later said was due to there not being "enough in deal to allow Green Party to continue". The negotiations restarted on 11 June with a draft programme for government being agreed one day later, which under party rules needed 66% of members to endorse it at a special convention.
On 13 June 2007, Green members in the Mansion House, Dublin, voted 86% in favour (441 to 67; with 2 spoilt votes) of entering coalition with Fianna Fáil. The following day, the six Green Party TDs voted for the re-election of Bertie Ahern as Taoiseach.
This was the first time the Green Party had entered government in Ireland.
Criticisms.
Before their entry into government, the Green Party were vocal supporters of the Shell to Sea movement, the campaign to reroute the M3 motorway away from Tara and (to a lesser extent) the campaign to end United States military use of Shannon airport. Since the Green Party entered government, there were no substantive changes in government policy on these issues, which meant that Eamon Ryan oversaw the Corrib gas project while he was in office. The Green Party made an inquiry into the irregularities surrounding the project (see Corrib gas controversy) a precondition of government at their last annual conference but changed their stance during post-election negotiations with Fianna Fáil. The County Mayo branch of the party still supports efforts to relocate the refinery to an alternative location.
2008 budget.
The 2008 budget, announced on 6 December 2007, did not include a carbon levy on fuels such as petrol, diesel and home heating oil, which the Green Party had sought before the election. A carbon levy was however introduced in the 2010 Budget. The 2008 budget did include a separate carbon budget announced by Gormley, which introduced new energy efficiency tax credit, a ban on incandescent bulbs from January 2009, a tax scheme incentivising commuters' purchases of bicycles and a new scale of vehicle registration tax based on carbon emissions.
Treaty of Lisbon.
In 2007, the Green Party launched an internal debate on the party's stance on the Treaty of Lisbon. At a special convention on 19 January 2008 to consider whether or not to support what would become the Twenty-eighth Amendment of the Constitution of Ireland, the party voted 63.5% in favour of supporting the Lisbon Treaty fell short of the party's two-third majority requirement for policy issues. As a result, the Green Party did not participate in the referendum debate, although individual members were involved on different sides 
Following the Irish Government's negotiation with EU member states of additional legal guarantees and assurances, and the subsequent adoption by Dáil and Seanad Éireann of the Twenty-eighth Amendment of the Constitution Bill (2009), the Green Party held another special convention meeting in Dublin on 18 July 2009 to decide its position on the second Lisbon referendum. At the meeting precisely two thirds of party members present voted to campaign for a Yes in the referendum. This was the first time in the party's history that it campaigned in favour of a European treaty.
Resignations in 2010.
In 2010, Déirdre de Búrca, one of two Green Party Senators nominated by Taoiseach Bertie Ahern in 2007, resigned from the party and her seat, in part due to the party's inability to secure her a job in the European Commission. On 23 February 2010, Trevor Sargent, one of six Green Party TDs, and former leader of the party from 2001 to 2007, resigned as Minister of State for Food and Horticulture due to allegations over contacting Gardaí about a criminal case involving a constituent.
Withdrawal from government.
On 23 January 2011, the Green Party met with Taoiseach Brian Cowen following his resignation as leader of coalition partner Fianna Fáil the previous afternoon. The Green Party then announced it was withdrawing from governing the country and took its place on the opposition benches with immediate effect. Green Party leader John Gormley said at a press conference announcing the withdrawal: 
The party had two ministers: Minister for the Environment, Heritage and Local Government John Gormley and Minister for Communications, Energy and Natural Resources Eamon Ryan. These were reassigned to Fianna Fáil ministers Éamon Ó Cuív and Pat Carey respectively. Green Ministers of State Ciarán Cuffe and Mary White also resigned from their roles.
Government record.
In almost four years in Government, from 2007–2011, the party were said to have succeeded in, among other areas, the passage of civil partnership legislation granting significant rights to same-sex couples, the introduction of major planning reform, a major increase in renewable energy output, and a nationwide scheme of home insulation retrofitting.
2011 elections.
The party suffered a wipeout at the 2011 general election in the Republic, with all of its six TDs losing their seats, including those of former Ministers John Gormley and Eamon Ryan. Three out of their six incumbent TDs lost their deposits. The party's share of the vote fell below 2%, meaning that they could not reclaim election expenses, and their lack of parliamentary representation led to the ending of state funding for the party.
The candidates in the 2011 Seanad election were Dan Boyle and Niall Ó Brolcháin, but neither were elected, and as a result for the first time since 1989, the Greens have no representatives in the Oireachtas.
Eamon Ryan was elected as party leader on 27 May 2011, succeeding John Gormley. Catherine Martin, a former Carrickmacross town councillor, was later appointed deputy leader, while Ciaran Cuffe and Mark Dearey were also placed on the party's front bench.
2014 local and European elections.
In the 2014 European Election the party received 4.9% of the vote nationally (an increase of 3% on the 2009 result). Despite a very close race between Eamon Ryan and Nessa Childers for the final seat in Dublin, no Green candidate was elected.
In the 2014 local elections in the Republic the party received 1.6% of the vote nationally. 12 candidates were elected to County Councils, compared to 3 previously.

</doc>
<doc id="15085" url="https://en.wikipedia.org/wiki?curid=15085" title="Iconoclasm">
Iconoclasm

Iconoclasm is the destruction of religious icons and other images or monuments for religious or political motives. Over time, the word, usually in the adjectival form, has also come to refer to aggressive statements or actions against any well-established status quo. It is a frequent component of major political or religious changes. The term does not generally encompass the specific destruction of images of a ruler after his death or overthrow ("damnatio memoriae").
People who engage in or support iconoclasm are called "iconoclasts", a term that has come to be applied figuratively to any individual who challenges "cherished beliefs or venerated institutions on the grounds that they are erroneous or pernicious". Conversely, one who reveres or venerates religious images is called (by iconoclasts) an "iconolater"; in a Byzantine context, such a person is called an "iconodule" or "iconophile".
Iconoclasm may be carried out by people of a different religion, but is often the result of sectarian disputes between factions of the same religion. In Christianity, iconoclasm has generally been motivated by people who adopt a literal interpretation of the Ten Commandments, which forbid the making and worshipping of "graven images or any likeness of anything". The Church Fathers identified Jews and Judaism with heresy. They saw deviations from Orthodox Christianity and opposition to the veneration of images as heresies that were essentially "Jewish in spirit". The degree of iconoclasm among Christian branches greatly varies. Islam, in general, tends to be more iconoclastic than Christianity, with Sunni Islam being more iconoclastic than Shia Islam.
Religious iconoclasm.
Ancient era.
In the Bronze age the most significant episode of iconoclasm in Egypt was during the Amarna Period, when Akhenaten, based in his new capital of Akhetaten, instituted a campaign of intolerance towards the traditional gods and many temples and monuments were destroyed.
"In rebellion against the old religion and the powerful priests of Amun, Akhenaten ordered the eradication of all of Egypt's traditional gods. He sent royal officials to chisel out and destroy every reference to Amun and the names of other deities on tombs, temple walls, and cartouches to instill in the people that the Aten was the one true god."
"For Egypt, the greatest horror was the destruction or abduction of the cult images. In the eyes of the Israelites, the erection of images meant the destruction of divine presence; in the eyes of the Egyptians, this same effect was attained by the destruction of images. In Egypt, iconoclasm was the most terrible religious crime; in Israel, it was idolatry. In this respect Osarseph alias Akhenaten, the iconoclast, and the Golden Calf, the paragon of idolatry, correspond to each other inversely, and it is strange that Aaron could so easily avoid the role of the religious criminal. It is more than probable that these traditions evolved under mutual influence. In this respect, Moses and Akhenaten became, after all, closely related."
Byzantine era.
Although widespread use of Christian iconography only began as Christianity increasingly spread among gentiles after the legalization of Christianity by Roman Emperor Constantine (c. 312 AD), scattered expressions of opposition to the use of images were reported (e.g. Spanish Synod of Elvira). The period after the reign of Byzantine Emperor Justinian (527–565) evidently saw a huge increase in the use of images, both in volume and quality, and a gathering aniconic reaction.
In the Eastern Roman (Byzantine) Empire, government-led iconoclasm began with Byzantine Emperor Leo III, following what seems to have been a long period of rising opposition to the use or misuse of images. The religious conflict created political and economic divisions in Byzantine society. It was generally supported by the Eastern, poorer, non-Greek peoples of the Empire who had to deal frequently with raids from the new Muslim Empire. On the other hand, the wealthier Greeks of Constantinople, and also the peoples of the Balkan and Italian provinces, strongly opposed iconoclasm.
Within the Byzantine Empire the government had probably been adopting Christian images more frequently. One notable change came in 695, when Justinian II's government added a full-face image of Christ on the obverse of imperial gold coins. The change caused the Caliph Abd al-Malik to stop his earlier adoption of Byzantine coin types. He started a purely Islamic coinage with lettering only. A letter by the patriarch Germanus written before 726 to two Iconoclast bishops says that "now whole towns and multitudes of people are in considerable agitation over this matter" but there is little written evidence of the debate.
... we declare that we defend free from any innovations all the written and unwritten ecclesiastical traditions that have been entrusted to us. One of these is the production of representational art; this is quite in harmony with the history of the spread of the gospel, as it provides confirmation that the becoming man of the Word of God was real and not just imaginary, and as it brings us a similar benefit. For, things that mutually illustrate one another undoubtedly possess one another's message.
Views in Byzantine iconoclasm.
Accounts of iconoclast arguments are largely found in iconodule writings. To understand iconoclastic arguments, one must note the main points:
The chief theological opponents of iconoclasm were the monks Mansur (John of Damascus), who, living in Muslim territory as advisor to the Caliph of Damascus, was far enough away from the Byzantine emperor to evade retribution, and Theodore the Studite, abbot of the Stoudios monastery in Constantinople. John declared that he did not venerate matter, "but rather the creator of matter". However he also declared, "But I also venerate the matter through which salvation came to me, as if filled with divine energy and grace". He includes in this latter category the ink in which the gospels were written as well as the paint of images, the wood of the Cross, and the body and blood of Jesus.
The iconodule response to iconoclasm included:
Protestant Reformation.
Some of the Protestant reformers, in particular Andreas Karlstadt, Huldrych Zwingli and John Calvin, encouraged the removal of religious images by invoking the Decalogue's prohibition of idolatry and the manufacture of graven (sculpted) images of God. As a result, individuals attacked statues and images. However, in most cases, civil authorities removed images in an orderly manner in the newly reformed Protestant cities and territories of Europe.
Significant iconoclastic riots took place in Zurich (in 1523), Copenhagen (1530), Münster (1534), Geneva (1535), Augsburg (1537), Scotland (1559), Rouen (1560) and Saintes and La Rochelle (1562). The Seventeen Provinces (now the Netherlands, Belgium and parts of Northern France) were disrupted by widespread Protestant iconoclasm in the summer of 1566. This is called the "Beeldenstorm" and began with the destruction of the statuary of the Monastery of Saint Lawrence in Steenvoorde after a ""Hagenpreek"", or field sermon, by Sebastiaan Matte.
Hundreds of other attacks included the sacking of the Monastery of Saint Anthony after a sermon by Jacob de Buysere. The "Beeldenstorm" marked the start of the revolution against the Spanish forces and the Catholic Church.
The Iconoclast belief was causing havoc throughout Europe, and in 1523, specifically due to the Swiss reformer Huldrych Zwingli, a vast number of his followers viewed themselves as being involved in a spiritual community that in matters of faith should obey neither the visible Church nor lay authorities. According to author R.W Scribner: 
Lord what work was here! What clattering of glasses! What beating down of walls! What tearing up of monuments! What pulling down of seats! What wresting out of irons and brass from the windows! What defacing of arms! What demolishing of curious stonework! What tooting and piping upon organ pipes! And what a hideous triumph in the market-place before all the country, when all the mangled organ pipes, vestments, both copes and surplices, together with the leaden cross which had newly been sawn down from the Green-yard pulpit and the service-books and singing books that could be carried to the fire in the public market-place were heaped together.'
William Dowsing was commissioned and salaried by the government to tour the towns and villages of East Anglia to destroy images in churches. His detailed record of his trail of destruction through Suffolk and Cambridgeshire survives:
Protestant Christianity was not uniformly hostile to the use of religious images. Martin Luther, initially hostile, came round to the view that Christians should be free to use religious images as long as they did not worship them in place of God. Lutheran scholar Jeremiah Ohl writes: -->
Muslim iconoclasm.
Within Muslim history, the act of removing idols from the Ka'ba in Mecca is considered by all believers to be of great symbolic and historical importance.
In general, Muslim societies have avoided the depiction of living beings (animals and humans) within such sacred spaces as mosques and madrasahs. This opposition to figural representation is based not on the Qur'an, but on traditions contained within the Hadith. The prohibition of figuration has not always extended to the secular sphere, and a robust tradition of figural representation exists within Muslim art.
However, western authors have tended to perceive "a long, culturally determined, and unchanging tradition of violent iconoclastic acts" within Islamic society.
Recent events.
Certain Muslim denominations continue to pursue iconoclastic agendas. There has been much controversy within Islam over the recent and apparently on-going destruction of historic sites by Saudi Arabian authorities, prompted by the fear they could become the subject of "idolatry".
During the Tuareg rebellion of 2012, the radical Islamist militia Ansar Dine destroyed various Sufi shrines from the 15th and 16th centuries in the city of Timbuktu, Mali.
The Islamic State of Iraq and the Levant has carried out iconoclastic attacks such as the destruction of Shia mosques and shrines. Notable incidents include the Mosque of the Prophet Yunus (Jonah) and the Shrine to Seth in Mosul.
Political and revolutionary iconoclasm.
"Damnatio memoriae".
Revolutions and changes of regime, whether through uprising of the local population, foreign invasion, or a combination of both, are often accompanied by the public destruction of statues and monuments identified with the previous regime. This may also be known as "damnatio memoriae", the ancient Roman practice of official obliteration of the memory of a specific individual. Stricter definitions of "iconoclasm" exclude both types of action, reserving the term for religious or more widely cultural destruction. In many cases, such as Revolutionary Russia or Ancient Egypt, this distinction can be hard to make.
Among Roman emperors and other political figures subject to decrees of damnatio memoriae were Sejanus, Publius Septimius Geta, and Domitian.
Iconoclasm in the French Revolution.
Throughout the radical phase of the French Revolution, iconoclasm was supported by members of the government as well as the citizenry. Numerous monuments, religious works, and other historically significant pieces were destroyed in an attempt to eradicate any memory of the Old Regime. At the same time, the republican government felt responsible to preserve these works for their historical, aesthetic, and cultural value. One way the republican government succeeded in their paradoxical mission of preserving and destroying symbols of the Old Regime was through the development of museums.
During the Revolution, a statue of King Louis XV in the Paris square which until then bore his name, was pulled down and destroyed. This was a prelude to the guillotining of his successor Louis XVI in the same site, renamed "Place de la Révolution" (at present Place de la Concorde).
The statue of Napoleon on the column at Place Vendôme, Paris was also the target of iconoclasm several times: destroyed after the Bourbon Restoration, restored by Louis-Philippe, destroyed during the Paris Commune and restored by Adolphe Thiers.
Demolition of Hindu temples.
During Muslim conquest.
Records from the campaign recorded in the "Chach Nama" record temple demolitions during the early 8th century when the Umayyad governor of Damascus, al-Hajjaj ibn Yusuf, mobilized an expedition of 6000 cavalry under Muhammad bin Qasim in 712.
The historian, Upendra Thakur records the persecution of Hindus and Buddhists:
Sultan Sikandar Butshikan of Kashmir (1389–1413) ordered the breaking of all "golden and silver images". The "Firishta" states, "After the emigration of the Bramins, Sikundur ordered all the temples in Kashmeer to be thrown down. Having broken all the images in Kashmeer, (Sikandar) acquired the title of 'Destroyer of Idols'".
In 725 Junayad, the governor of Sind, sent his armies to destroy the second Somnath. In 1024, the temple was again destroyed by Mahmud of Ghazni, who raided the temple from across the Thar Desert. The temple was rebuilt by Bhoja of the Paramara dynasty of Malwa and Bhima of the Solanki dynasty of Patan between 1026-42. The wooden structure was replaced by Kumarpal (r. 1143–72), who rebuilt the temple out of stone.
In 1451 AD, the temple was once again destroyed by Mahmud Begda, the Sultan of Gujarat. In 1701 AD, the temple was once again destroyed by Mughal Emperor Aurangzeb. Aurangzeb built a mosque on the site of the Somnath temple, using some columns from the temple, whose Hindu sculptural motifs remained visible.
Mahmud of Ghazni was an Afghan Sultan who invaded the Indian subcontinent during the early 11th century. His campaigns across the gangetic plains are often cited for their iconoclastic plundering and destruction of temples such as those at Mathura and he looked upon their destruction as an act of ""jihad"". He sacked the second Somnath Temple in 1026, and looted it of gems and precious stones and the famous Shiva lingam of the temple was destroyed.
Historical records compiled by Muslim historian Maulana Hakim Saiyid Abdul Hai attest to the iconoclasm of Qutb-ud-din Aybak. The first mosque built in Delhi, the "Quwwat al-Islam" was built after the demolition of the Hindu temple built previously by Prithvi Raj and certain parts of the temple were left outside the mosque proper. This pattern of iconoclasm was common during his reign, although an argument goes that such iconoclasm was motivated more by politics than by religion.
Another ruler of the sultanate, Shams-ud-din Iltutmish, conquered and subjugated the Hindu pilgrimage site Varanasi in the 11th century and he continued the destruction of Hindu temples and idols that had begun during the first attack in 1194.
No aspect of Aurangzeb's reign is more cited—or more controversial—than the numerous desecrations and even the destruction of Hindu temples. During his reign, tens of thousands of temples were desecrated: their facades and interiors were defaced and their murtis (divine images) looted. In many cases, temples were destroyed entirely; in numerous instances mosques were built on their foundations, sometimes using the same stones. Among the temples Aurangzeb destroyed were two that are most sacred to Hindus, in Varanasi and Mathura. In both cases, he had large mosques built on the sites.
The Kesava Deo temple in Mathura, marked the place that Hindus believe was the birthplace of Shri Krishna. In 1661 Aurangzeb ordered the demolition of the temple, and constructed the Katra Masjid mosque. Traces of the ancient Hindu temple can be seen from the back of the mosque. Aurangzeb also destroyed what was the most famous temple in Varanasi – the Vishwanath Temple.
The temple had changed its location over the years, and in 1585 Akbar had authorized its location at Gyan Vapi. Aurangzeb ordered its demolition in 1669 and constructed a mosque on the site, whose minarets stand 71 metres above the Ganges. Traces of the old temple can be seen behind the mosque. Centuries later, emotional debate about these wanton acts of cultural desecration continues. Aurangzeb also destroyed the Somnath temple in 1706.
Hindu nationalists claim that Mughals destroyed the Ram Mandir in Ayodhya, located at the birthplace of Rama, and built the Babri Masjid on the holy site, which has since been a source of tension between the Hindu and Muslim communities.
Writer Fernand Braudel wrote in "A History of Civilizations" (Penguin 1988/1963, pp. 232–236), Islamic rule in India as a "colonial experiment" was "extremely violent", and "the Muslims could not rule the country except by systematic terror. Cruelty was the norm – burnings, summary executions, crucifixions or impalements, inventive tortures. Hindu temples were destroyed to make way for mosques. On occasion there were forced conversions. If ever there were an uprising, it was instantly and savagely repressed: houses were burned, the countryside was laid waste, men were slaughtered and women were taken as slaves."
C. K. Kareem also notes that Tippu Sultan issued an edict for the destruction of Hindu temples in Kerala.
In a two-volume book by Sita Ram Goel, Arun Shourie, Harsh Narain, Jay Dubashi and Ram Swarup, Hindu Temples – What Happened to Them, includes a list of 2000 mosques that it is claimed were built on Hindu temples in the first volume, which it is asserted is based primarily on the books of Muslim historians of the period or the inscriptions of the mosques. The second volume excerpts from medieval histories and chronicles and from inscriptions concerning the destruction of Hindu, Jain, and Buddhist temples. The authors claim that the material presented in this book are only the tip of an iceberg.
During Goa inquisitions.
Diago de Boarda, a priest, and his advisor Vicar General, Miguel Vaz, had made a 41-point plan for torturing Hindus. Under this plan Viceroy Antano de Noronha issued in 1566, an order applicable to the entire area under Portuguese rule:
I hereby order that in any area owned by my master, the king, nobody should construct a Hindu temple and such temples already constructed should not be repaired without my permission. If this order is transgressed, such temples shall be, destroyed and the goods in them shall be used to meet expenses of holy deeds, as punishment of such transgression.
In 1567 the campaign of destroying temples in Bardez met with success. At the end of it 300 Hindu temples were destroyed. In 1583 Hindu temples at Assolna and Cuncolim were destroyed through army action.
"The fathers of the Church forbade the Hindus under terrible penalties the use of their own sacred books, and prevented them from all exercise of their religion. They destroyed their temples, and so harassed and interfered with the people that they abandoned the city in large numbers, refusing to remain any longer in a place where they had no liberty, and were liable to imprisonment, torture and death if they worshipped after their own fashion the gods of their fathers". wrote Filippo Sassetti, who was in India from 1578 to 1588.
An order was issued in June 1684 eliminating the Konkani language and making it compulsory to speak Portuguese language. Following that law all the symbols of non-Christian sects were destroyed and the books written in local languages were burnt.
Contemporary iconoclasm against Hindu temples and monuments.
In India.
On December 6, 1992, a large crowd of Hindu Karsevaks (volunteers) entirely destroyed the 16th-century Babri mosque in Ayodhya, Uttar Pradesh, India, in an attempt to reclaim the land known as Ram Janmabhoomi. The demolition occurred after a religious ceremony turned violent and resulted in several months of intercommunal rioting between India's Hindu and Muslim communities, causing the death of at least 2,000 people most of which were Muslims.
In June 2010, during rioting in Sangli, people threw stones inside a Ganesh mandal.
The 2010 Deganga riots began on 6 September when mobs resorted to arson and violence over a disputed structure at Deganga, Kartikpur and Beliaghata under the Deganga police station area. The violence began late in the evening and continued throughout the night into the next morning. The violence finally calmed down on 9 September after hundreds of business establishments and residences were looted, destroyed and burnt, dozens of people were severely injured and several places of worship desecrated and vandalized.
In June 2011 at Asansol Market area, a Hindu temple, under construction led by Bastim Bazaar Sarbojanin Durga Puja Committee was and approved by ADM on 12 April 2011, was attacked by an Islamic mob.
In Bangladesh.
In Bangladesh atrocities including targeted attacks against temples and open theft of Hindu property have increased sharply in recent years after the Jamat-e-Islami joined the coalition government led by the Bangladesh National Party. Hindu temples in Bangladesh have also been vandalised.
On the February 6, 2010, Sonargaon temple in Narayanganj district of Bangladesh was destroyed by Islamic fanatics.
In Pakistan.
Several Hindu temples have been destroyed in Pakistan. A notable incident was the destruction of the Ramna Kali Mandir in former East Pakistan. The temple was bulldozed by the Pakistani Army on March 27, 1971. The Dhakeshwari Temple was severely damaged during the Indo-Pakistani War of 1971, and over half of the temple's buildings were destroyed. In a major disrespect of the religion, the main worship hall was taken over by the Pakistan Army and used as an ammunitions storage area. Several of the temple custodians were tortured and killed by the Army though most, including the Head Priest, fled first to their ancestral villages and then to India and therefore escaped death.
In 2006 the last Hindu temple in Lahore was destroyed to pave the way for construction of a multi-story commercial building. The temple was demolished after officials of the Evacuee Property Trust Board concealed facts from the board chairman about the nature of the building. When reporters from Pakistan-based newspaper "Dawn" tried to cover the incident, they were accosted by the henchmen of the property developer, who denied that a Hindu temple existed at the site.
Several political parties in Pakistan have objected to this move, such as the Pakistan People's Party and the Pakistani Muslim League-N. The move has also evoked strong condemnation in India from minority bodies and political parties, including the Bharatiya Janata Party (BJP), the Congress Party, as well as Muslim advocacy political parties such as the All India Muslim Majlis-e-Mushawarat. A firm of lawyers representing the Hindu minority has approached the Lahore High Court seeking a directive to the builders to stop the construction of the commercial plaza and reconstruct the temple at the site. The petitioners maintain that the demolition violates section 295 of the Pakistan Penal Code prohibiting the demolition of places of worship.
On June 29, 2005, following the arrest of an illiterate Christian janitor on allegations of allegedly burning Qur'an pages, a mob of between 300 and 500 Muslims destroyed a Hindu temple and houses belonging to Christian and Hindu families in Nowshera. Under the terms of a deal negotiated between Islamic religious leaders and the Hindu/Christian communities, Pakistani police later released all previously arrested perpetrators without charge.
In Malaysia.
Between April to May 2006, several Hindu temples were demolished by city hall authorities in the country, accompanied by violence against Hindus. On April 21, 2006, the Malaimel Sri Selva Kaliamman Temple in Kuala Lumpur was reduced to rubble after the city hall sent in bulldozers. Many Hindu advocacy groups have protested what they allege is a systematic plan of temple cleansing in Malaysia. The official reason given by the Malaysian government has been that the temples were built "illegally". However, several of the temples are centuries old. On May 11, 2006, armed city hall officers from Kuala Lumpur forcefully demolished part of a 60-year-old suburban temple that serves more than 1,000 Hindus.
In Saudi Arabia.
On March 24, 2005, Saudi authorities destroyed religious items found in a raid on a makeshift Hindu shrine found in an apartment in Riyadh.
In Fiji.
In Fiji according to official reports, attacks on Hindu institutions increased by 14% compared to 2004. This intolerance of Hindus has found expression in anti-Hindu speeches and destruction of temples, the two most common forms of immediate and direct violence against Hindus. Between 2001 and April 2005, one hundred cases of temple attacks have been registered with the police. The alarming increase of temple destruction has spread fear and intimidation among the Hindu minorities and has hastened immigration to neighboring Australia and New Zealand. Organized religious institutions, such as the Methodist Church of Fiji, have repeatedly called for the creation of a theocratic Christian State and have propagated anti-Hindu sentiment. State favoritism of Christianity, and systematic attacks on temples, are some of the greatest threats faced by Fijian Hindus. Despite the creation of a human rights commission, the plight of Hindus in Fiji continues to be precarious.
Chinese "anti-foreignism".
There had been a number of anti-Buddhist campaigns in Chinese history, and temples and Buddhist images were destroyed. One of the most notable of these campaigns is the Great Anti-Buddhist Persecution of the Tang dynasty.
During the 1926 Northern Expedition in Guangxi, Kuomintang General Bai Chongxi led his troops in destroying Buddhist temples and smashing Buddhist images, turning the temples into schools and Kuomintang party headquarters. It was reported that almost all of the viharas in Guangxi were destroyed. The monks were removed.
Bai led a wave of anti-foreignism in Guangxi, attacking American, European, and other foreigners and missionaries, and generally making the province unsafe for foreigners. Westerners fled from the province and some Chinese Christians were also attacked as imperialist agents.
The three goals of the movement were anti-foreignism, anti-imperialism and anti-religion. Bai led the anti-religious movement against superstition. Huang Shaohong, also a Kuomintang member of the New Guangxi clique, supported Bai's campaign. The anti-religious campaign was agreed upon by all Guangxi Kuomintang members.
Other examples.
Other examples of political destruction of images include:

</doc>
<doc id="15086" url="https://en.wikipedia.org/wiki?curid=15086" title="IWW (disambiguation)">
IWW (disambiguation)

IWW may refer to:

</doc>
<doc id="15087" url="https://en.wikipedia.org/wiki?curid=15087" title="Imbolc">
Imbolc

Imbolc or Imbolg (pronounced ), also called (Saint) Brigid's Day (, , ), is a Gaelic festival marking the beginning of spring. Most commonly it is held on 1 February, or about halfway between the winter solstice and the spring equinox. Historically, it was widely observed throughout Ireland, Scotland and the Isle of Man. It is one of the four Gaelic seasonal festivals—along with Beltane, Lughnasadh and Samhain—and corresponds to the Welsh "Gŵyl Fair y Canhwyllau". Christians observe it as the feast day of Saint Brigid, especially in Ireland.
Imbolc is mentioned in some of the earliest Irish literature and there is evidence it has been an important date since ancient times. It is believed that it was originally a pagan festival associated with the goddess Brigid and that it was Christianized as a festival of Saint Brigid, who is thought to be a Christianization of the goddess. At Imbolc, Brigid's crosses were made and a doll-like figure of Brigid, called a "Brídeóg", would be paraded from house-to-house. Brigid was said to visit one's home at Imbolc. To receive her blessings, people would make a bed for Brigid and leave her food and drink, while items of clothing would be left outside for her to bless. Brigid was also invoked to protect homes and livestock. Special feasts were had, holy wells were visited and it was also a time for divination.
Although many of its customs died out in the 20th century, it is still observed and in some places it has been revived as a cultural event. Since the latter 20th century, Celtic neopagans and Wiccans have observed Imbolc, or something based on it, as a religious holiday.
Etymology.
The etymology of Imbolc/Imbolg is unclear. The most common explanation is that is comes from the Old Irish "i mbolc" (Modern Irish "i mbolg"), meaning "in the belly", and refers to the pregnancy of ewes. Another possible origin is the Old Irish "imb-fholc", "to wash/cleanse oneself", referring to a ritual cleansing. Eric P. Hamp derives it from a Proto-Indo-European root meaning both "milk" and "cleansing". Professor Alan Ward derives it from the Proto-Celtic "*embibolgon", "budding". The 10th century Cormac's Glossary derives it from "oimelc", "ewe milk", but many scholars see this as a folk etymology. Nevertheless, some Neopagans have adopted "Oimelc" as a name for the festival.
Since Imbolc is immediately followed (on 2 February) by Candlemas (Irish "Lá Fhéile Muire na gCoinneal" "feast day of Mary of the Candles", Welsh "Gŵyl Fair y Canhwyllau"), Irish "Imbolc" is sometimes translated into English as "Candlemas"; e.g. "iar n-imbulc, ba garb a ngeilt" translated as "after Candlemas, rough was their herding".
Prehistory.
The date of Imbolc is thought to have been significant in Ireland since the Neolithic period. This is based on the alignment of some Megalithic monuments. For example, at the Mound of the Hostages on the Hill of Tara, the inner chamber is aligned with the rising sun on the dates of Imbolc and Samhain.
Historic Imbolc customs.
In Gaelic Ireland, Imbolc was the "feis" or festival marking the beginning of spring, during which great feasts were held. It is attested in some of the earliest Old Irish literature, from the 10th century onward. It was one of four Gaelic seasonal festivals: Samhain (~1 November), Imbolc (~1 February), Beltane (~1 May) and Lughnasadh (~1 August).
From the 18th century to the mid 20th century, many accounts of Imbolc/St Brigid's Day were recorded by folklorists and other writers. They tell us how it was celebrated then, and shed light on how it may have been celebrated in the past.
Imbolc has traditionally been celebrated on 1 February. However, because the day was deemed to begin and end at sunset, the celebrations would start on what is now 31 January. It has also been argued that the timing of the festival was originally more fluid and based on seasonal changes. It has been associated with the onset of the lambing season—which could vary by as much as two weeks before or after 1 February—and the blooming of blackthorn.
The holiday was a festival of the hearth and home, and a celebration of the lengthening days and the early signs of spring. Celebrations often involved hearthfires, special foods, divination or watching for omens, candles or a bonfire if the weather permitted. Fire and purification were an important part of the festival. The lighting of candles and fires represented the return of warmth and the increasing power of the Sun over the coming months. A spring cleaning was also customary.
Holy wells were visited at Imbolc, and at the other Gaelic festivals of Beltane and Lughnasa. Visitors to holy wells would pray for health while walking 'sunwise' around the well. They would then leave offerings; typically coins or clooties (see clootie well). Water from the well was used to bless the home, family members, livestock and fields.
Donald Alexander Mackenzie also recorded that offerings were made "to earth and sea". The offering could be milk poured into the ground or porridge poured into the water, as a libation.
Brigid.
Imbolc is strongly associated with Saint Brigid (Old Irish: "Brigit", modern Irish: "Bríd", modern Scottish Gaelic: "Brìghde" or "Brìd", anglicised "Bridget"). Saint Brigid is thought to have been based on Brigid, a Gaelic goddess. The festival, which celebrates the onset of spring, is thought to be linked with Brigid in her role as a fertility goddess.
On Imbolc Eve, Brigid was said to visit virtuous households and bless the inhabitants. As Brigid represented the light half of the year, and the power that will bring people from the dark season of winter into spring, her presence was very important at this time of year.
Families would have a special meal or supper on Imbolc Eve. This typically included food such as colcannon, sowans, dumplings, barmbrack and/or bannocks. Often, some of the food and drink would be set aside for Brigid.
Brigid would be symbolically invited into the house and a bed would often be made for her. In the north of Ireland a family member, representing Brigid, would circle the home three times carrying rushes. They would then knock the door three times, asking to be let in. On the third attempt they are welcomed in, the meal is had, and the rushes are then made into a bed or crosses. In 18th century Mann, the custom was to stand at the door with a bundle of rushes and say "Brede, Brede, come to my house tonight. Open the door for Brede and let Brede come in". The rushes were then strewn on the floor as a carpet or bed for Brigid. In the 19th century, some old Manx women would make a bed for Brigid in the barn with food, ale, and a candle on a table. In the Hebrides in the late 18th century, a bed of hay would be made for Brigid and someone would then call out three times: ""a Bhríd, a Bhríd, thig a stigh as gabh do leabaidh"" ("Bríd Bríd, come in; thy bed is ready"). A white wand, usually made of birch, would be set by the bed. It represented the wand that Brigid was said to use to make the vegetation start growing again. In the 19th century, women in the Hebrides would dance while holding a large cloth and calling out ""Bridean, Bridean, thig an nall 's dean do leabaidh"" ("Bríd Bríd, come over and make your bed"). However, by this time the bed itself was rarely made.
Before going to bed, people would leave items of clothing or strips of cloth outside for Brigid to bless. Ashes from the fire would be raked smooth and, in the morning, they would look for some kind of mark on the ashes as a sign that Brigid had visited. The clothes or strips of cloth would be brought inside, and believed to now have powers of healing and protection.
In Ireland and Scotland, a representation of Brigid would be paraded around the community by girls and young women. Sometimes the representative was a girl, but usually it was a doll-like figure known as a "Brídeóg" (also called a 'Breedhoge' or 'Biddy'). It would be made from rushes or reeds and clad in bits of cloth, shells and/or flowers. In the Hebrides of Scotland, a bright shell or crystal called the "reul-iuil Bríde" (guiding star of Brigid) was set on its chest. The girls would carry it in procession while singing a hymn to Brigid. All wore white with their hair unbound as a symbol of purity and youth. They visited every house in the area, where they received either food or more decoration for the Brídeóg. Afterwards, they feasted in a house with the Brídeóg set in a place of honour, and put it to bed with lullabies. When the meal was done, the local young men humbly asked for admission, made obeisance to the Brídeóg, and joined the girls in dancing and merrymaking. In many parts, only unwed girls could carry the Brídeóg, but in some places both boys and girls carried it. In the late 17th century, Catholic families in the Hebrides would make a bed for the Brídeóg out of a basket. Up until the mid-20th century, children in Ireland still went house-to-house asking for pennies for "poor Biddy", or money for the poor. In County Kerry, men in white robes went from house to house singing.
In Ireland, Brigid's crosses ("pictured on the right") were made at Imbolc. A Brigid's cross usually consists of rushes woven into a square or equilateral cross, although three-armed crosses have also been recorded. They were often hung over doors, windows and stables to welcome Brigid and protect the buildings from fire and lightning. The crosses were generally left there until the next Imbolc. In western Connacht, people would make a "Crios Bríde" (Bríd's girdle); a great ring of rushes with a cross woven in the middle. Young boys would carry it around the village, inviting people to step through it and so be blessed.
Today, some people still make Brigid's crosses and Brídeógs or visit holy wells dedicated to St Brigid on 1 February.
Weather divination.
Imbolc was traditionally a time of weather divination, and the old tradition of watching to see if serpents or badgers came from their winter dens may be a forerunner of the North American Groundhog Day. A Scottish Gaelic proverb about the day is:
<poem>"Thig an nathair as an toll"
"Là donn Brìde,"
"Ged robh trì troighean dhen t-sneachd"
"Air leac an làir."
The serpent will come from the hole
On the brown Day of Bríde,
Though there should be three feet of snow
On the flat surface of the ground.</poem>
Imbolc was believed to be when the Cailleach—the divine hag of Gaelic tradition—gathers her firewood for the rest of the winter. Legend has it that if she wishes to make the winter last a good while longer, she will make sure the weather on Imbolc is bright and sunny, so she can gather plenty of firewood. Therefore, people would be relieved if Imbolc is a day of foul weather, as it means the Cailleach is asleep and winter is almost over. At Imbolc on the Isle of Man, where she is known as "Caillagh ny Groamagh", the Cailleach is said to take the form of a gigantic bird carrying sticks in her beak.
Neopaganism.
Imbolc or Imbolc-based festivals are held by some Neopagans. As there are many kinds of Neopaganism, their Imbolc celebrations can be very different despite the shared name. Some try to emulate the historic festival as much as possible. Other Neopagans base their celebrations on many sources, with historic accounts of Imbolc being only one of them.
Neopagans usually celebrate Imbolc on 1 February in the Northern Hemisphere and 1 August in the Southern Hemisphere. Some Neopagans celebrate it at the astronomical midpoint between the winter solstice and spring equinox (or the full moon nearest this point). In the Northern Hemisphere, this is usually on the 3rd or 4th of February. Other Neopagans celebrate Imbolc when the primroses, dandelions, and other spring flowers emerge.
Celtic Reconstructionist.
Celtic Reconstructionists strive to reconstruct the pre-Christian religions of the Celts. Their religious practices are based on research and historical accounts, but may be modified slightly to suit modern life. They avoid syncretism (i.e. combining practises from different cultures). They usually celebrate the festival when the first stirrings of spring are felt, or on the full moon nearest this. Many use traditional songs and rites from sources such as "The Silver Bough" and "The Carmina Gadelica". It is a time of honouring the Goddess Brigid, and many of her dedicants choose this time of year for rituals to her.
Wicca and NeoDruidry.
Wiccans and Neo-Druids celebrate something based on Imbolc as one of the eight Sabbats in their Wheel of the Year, following Midwinter and preceding Ostara. In Wicca, Imbolc is commonly associated with the goddess Brigid and as such it is sometimes seen as a "women's holiday" with specific rites only for female members of a coven. Among Dianic Wiccans, Imbolc is the traditional time for initiations.
External links.
Modern events

</doc>
<doc id="15088" url="https://en.wikipedia.org/wiki?curid=15088" title="Isaiah">
Isaiah

Isaiah ( or ;
The exact relationship between the Book of Isaiah and any such historical Isaiah is complicated. One widespread view sees parts of the first half of the book (chapters 1–39) as originating with the historical prophet, interspersed with prose commentaries written in the time of King Josiah a hundred years later; with the remainder of the book dating from immediately before and immediately after the end of the exile in Babylon, almost two centuries after the time of the original prophet.
Jews and Christians consider the Book of Isaiah a part of their Biblical canon; he is the first listed (although not the earliest) of the "Nevi'im Aharonim", the latter prophets. Muslims consider Isaiah a prophet mentioned in Muslim exegesis of canonical scriptures.
Biography.
The first verse of the Book of Isaiah states that Isaiah prophesied during the reigns of Uzziah (or Azariah), Jotham, Ahaz and Hezekiah, the kings of Judah (). Uzziah's reign was 52 years in the middle of the 8th century BCE, and Isaiah must have begun his ministry a few years before Uzziah's death, probably in the 740s BCE. Isaiah lived until the fourteenth year of Hezekiah's reign (who died 698 BCE), and may have been contemporary for some years with Manasseh. Thus Isaiah may have prophesied for as long as 64 years.
According to some modern interpretations Isaiah's wife was called "the prophetess" (), either because she was endowed with the prophetic gift, like Deborah () and Huldah (), or simply because she was the "wife of the prophet" (as he is named, for instance in ). Another interpretation, holds that it was simply an honorary title is likely. They had two sons, naming one She'ar-Ya'shuv, meaning "A remnant shall return" () and the younger, Maher-Shalal-Hash-Baz, meaning, "Spoil quickly, plunder speedily." () The book of Isaiah, along with the book of Jeremiah, is distinctive in the Hebrew bible for its direct portrayal of the "wrath of the Lord" as presented, for example, in Isaiah 9:19 stating, "Through the wrath of the Lord of hosts is the land darkened, and the people shall be as the fuel of the fire." However, according to traditional Christian view "the prophetess" was a reference not to Isaiah's wife but to the Theotokos and the names given in reference to Christ, with the verse then being seen as a prophecy of the Incarnation.
In early youth, Isaiah may have been moved by the invasion of Israel by the Assyrian monarch Tiglath-Pileser III (); and again, twenty years later, when he had already entered his office, by the invasion of Tiglath-Pileser and his career of conquest. Ahaz, king of Judah, at this crisis refused to co-operate with the kings of Israel and Syria in opposition to the Assyrians, and was on that account attacked and defeated by Rezin of Damascus and Pekah of Israel (; ). Humbled, Ahaz sided with Assyria and sought the aid of Tiglath-Pileser against Israel and Syria. The consequence was that Rezin and Pekah were conquered and many of the people carried captive to Assyria (, ; ).
Soon after this, Shalmaneser V determined to subdue the kingdom of Israel, Samaria was taken and destroyed (722 BCE). So long as Ahaz reigned, the kingdom of Judah was unmolested by the Assyrian power; but on his accession to the throne, Hezekiah, who was encouraged to rebel "against the king of Assyria" (), entered into an alliance with the king of Egypt (). This led the king of Assyria to threaten the king of Judah, and at length to invade the land. Sennacherib (701 BC) led a powerful army into Judah. Hezekiah was reduced to despair, and submitted to the Assyrians (). But after a brief interval war broke out again. Again Sennacherib led an army into Judah, one detachment of which threatened Jerusalem (; ). Isaiah on that occasion encouraged Hezekiah to resist the Assyrians (), whereupon Sennacherib sent a threatening letter to Hezekiah, which he "spread before the LORD" ().
According to the account in 2 Kings 19 (and its derivative account in 2 Chronicles 32) the judgment of God now fell on the Assyrian army and wiped out 185,000 of its men. "Like Xerxes in Greece, Sennacherib never recovered from the shock of the disaster in Judah. He made no more expeditions against either the Southern Levant or Egypt."
The remaining years of Hezekiah's reign were peaceful (). Isaiah probably lived to its close, and possibly into the reign of Manasseh, but the time and manner of his death are not specified in either the Bible or other primary sources. The Talmud 49b says that he suffered martyrdom by being sawn in two under the orders of Manasseh.
Some writers assert that Isaiah was a vegetarian, on the basis of passages in the Book of Isaiah that extol nonviolence and reverence for life, such as Isaiah 1:11, 11:6-9, 65:25, and 66:3. Some of these writers refer to "the vegetarian Isaiah", "the notorious vegetarian Isaiah", and "Isaiah, the vegetarian prophet".
In Christianity.
Gregory of Nyssa (c. 335–395), believed that the Prophet Isaiah "knew more perfectly than all others the mystery of the religion of the Gospel". Jerome (c. 342–420) also lauds the Prophet Isaiah, saying, "He was more of an Evangelist than a Prophet, because he described all of the Mysteries of the Church of Christ so vividly that you would assume he was not prophesying about the future, but rather was composing a history of past events." Of specific note are the songs of the Suffering Servant which Christians say are a direct prophetic revelation of the nature, purpose and detail of the death of Jesus Christ.
The Book of Isaiah is quoted many times by New Testament writers. Ten of those references are about the Suffering Servant, how he will suffer and die to save many from their sins, be buried in a rich man's tomb, be a light to the Gentiles. The Gospel of John even says that Isaiah "saw Jesus’ glory and spoke about him."
In Islam.
Although Isaiah is not mentioned by name in the Quran or the Hadith, Muslim sources have accepted him as a prophet. Some Muslim scholars, such as Ibn Kathir and Kisa'i, reproduced Jewish traditions, transmitted through early Jewish converts to Islam, regarding Isaiah. Such Old Testament stories, which are confirmed by the Quran and prophetic hadith, is referred to as Ycol , and are considered strong enough to be used as evidence in Islamic law. Isaiah is mentioned as a prophet in Ibn Kathir's "Story of Prophet Isaiah", and the modern writers Muhammad Asad and Abdullah Yusuf Ali accepted Isaiah as a true Hebrew prophet, who preached to the Israelites following the death of King David.
Isaiah is well known in Muslim exegesis and literature, notably for his predictions of the coming of Jesus and Muhammad. Isaiah's narrative in Muslim literature can be divided into three sections. The first establishes Isaiah as a prophet of Israel during the reign of Hezekiah; the second relates Isaiah's actions during the siege of Jerusalem by Sennacherib; and the third warns the nation of coming doom.
Muslim exegesis preserves a tradition parallel to the Hebrew Bible, which states that Hezekiah was king in Jerusalem during Isaiah's time. Hezekiah heard and obeyed Isaiah's advice, but could not quell the turbulence in Israel. This tradition maintains that Hezekiah was a righteous man and that the turbulence worsened after him. After the death of the king, Isaiah told the people to not forsake God, and he warned Israel to cease from its persistent sin and disobedience. Muslim tradition maintains that the unrighteous of Israel in their anger sought to kill Isaiah. In a death that resembles that attributed to Isaiah in "Lives of the Prophets", Muslim exegesis recounts that Isaiah was martyred by Israelites by being sawn in two.
In the Baha'i Faith.
Isaiah is considered a lesser prophet in the Baha'i Faith. Abdul-Baha mentions prophecies by Isaiah which refer to a man called the Branch as applying to Baha'ullah.
Rabbinic literature.
According to the Rabbinic literature, Isaiah was a descendant of the royal house of Judah and Tamar (Sotah 10b). He was the son of Amoz (not to be confused with Prophet Amos), who was the brother of King Amaziah of Judah. (Talmud tractate Megillah 15a).

</doc>
<doc id="15089" url="https://en.wikipedia.org/wiki?curid=15089" title="Interpreted language">
Interpreted language

An interpreted language is a programming language for which most of its implementations execute instructions directly, without previously compiling a program into machine-language instructions. The interpreter executes the program directly, translating each statement into a sequence of one or more subroutines already compiled into machine code.
The terms "interpreted language" and "compiled language" are not well defined because, in theory, any programming language can be either interpreted or compiled. In modern programming language implementation it is increasingly popular for a platform to provide both options.
Interpreted languages can also be contrasted with machine languages. Functionally, both execution and interpretation mean the same thing — fetching the next instruction/statement from the program and executing it. Although interpreted byte code is additionally identical to machine code in form and has an assembler representation, the term "interpreted" is practically reserved for "software processed" languages (by virtual machine or emulator) on top of the native (i.e. hardware) processor.
In principle, programs in many languages may be compiled or interpreted, emulated or executed natively, so this designation is applied solely based on common implementation practice, rather than representing an essential property of a language.
Many languages have been implemented using both compilers and interpreters, including BASIC, C, Lisp, Pascal, and Python. Java and C# are compiled into bytecode, the virtual machine-friendly interpreted language. Lisp implementations can freely mix interpreted and compiled code.
Historical background of interpreted/compiled.
In the early days of computing, language design was heavily influenced by the decision to use compiling or interpreting as a mode of execution. For example, Smalltalk (1980), which was designed to be interpreted at run-time, allows generic objects to dynamically interact with each other.
Initially, interpreted languages were compiled line-by-line; that is, each line was compiled as it was about to be executed, and if a loop or subroutine caused certain lines to be executed multiple times, they would be recompiled every time. This has become much less common. Most so-called interpreted languages use an intermediate representation, which combines compiling and interpreting.
Examples include: 
The intermediate representation can be compiled once and for all (as in Java), each time before execution (as in Perl or Ruby), or each time a change in the source is detected before execution (as in Python).
Advantages of interpreting a language.
Interpreting a language gives implementations some additional flexibility over compiled implementations. Features that are often easier to implement in interpreters than in compilers include (but are not limited to):
Disadvantages of interpreted languages.
Disadvantages of interpreted languages are:
List of frequently used interpreted languages.
Languages usually compiled to a bytecode.
Many interpreted languages are first compiled to bytecode. Ѕometimes, bytecode can also be compiled to a native binary using an AOT compiler or executed natively, by hardware processor.

</doc>
<doc id="15095" url="https://en.wikipedia.org/wiki?curid=15095" title="Intifada">
Intifada

Intifada ( "") is an Arabic word literally meaning, as a noun, "tremor", "shivering", "shuddering". It is derived from an Arabic term "nafada" meaning "to shake", "shake off", "get rid of", as a dog might shrug off water, or as one might shake off sleep, or dirt from one's sandals, and is a key concept in contemporary Arabic usage referring to a legitimate uprising against oppression. It is often rendered into English as "uprising", "resistance", or "rebellion". In the Palestinian context, with which it is particularly associated, the word refers to attempts to "shake off" the Israeli occupation of the Palestinian territories in the First and Second Intifadas, where it was originally chosen to connote "aggressive nonviolent resistance", a meaning it bore among Palestinian students in struggles in the 1980s and which they adopted as less confrontational than terms in earlier militant rhetoric since it bore no nuance of violence.
Intifada may be used to refer to these events:

</doc>
<doc id="15097" url="https://en.wikipedia.org/wiki?curid=15097" title="Ionosphere">
Ionosphere

The ionosphere () is a region of Earth's upper atmosphere, from about to altitude, and includes the thermosphere and parts of the mesosphere and exosphere. It is ionized by solar radiation, plays an important part in atmospheric electricity and forms the inner edge of the magnetosphere. It has practical importance because, among other functions, it influences radio propagation to distant places on the Earth.
Geophysics.
The ionosphere is a shell of electrons and electrically charged atoms and molecules that surrounds the Earth, stretching from a height of about to more than . It owes its existence primarily to ultraviolet radiation from the Sun.
The lowest part of the Earth's atmosphere, the troposphere extends from the surface to about . Above is the stratosphere, followed by the mesosphere. In the stratosphere incoming solar radiation creates the ozone layer. At heights of above , in the thermosphere, the atmosphere is so thin that free electrons can exist for short periods of time before they are captured by a nearby positive ion. The number of these free electrons is sufficient to affect radio propagation. This portion of the atmosphere is "ionized" and contains a plasma which is referred to as the ionosphere. In a plasma, the negative free electrons and the positive ions are attracted to each other by the electrostatic force, but they are too energetic to stay fixed together in an electrically neutral molecule.
Ultraviolet (UV), X-ray and shorter wavelengths of solar radiation are "ionizing," since photons at these frequencies contain sufficient energy to dislodge an electron from a neutral gas atom or molecule upon absorption. In this process the light electron obtains a high velocity so that the temperature of the created electronic gas is much higher (of the order of thousand K) than the one of ions and neutrals. The reverse process to ionization is recombination, in which a free electron is "captured" by a positive ion. Recombination occurs spontaneously, and causes the emission of a photon carrying away the energy produced upon recombination. As gas density increases at lower altitudes, the recombination process prevails, since the gas molecules and ions are closer together. The balance between these two processes determines the quantity of ionization present.
Ionization depends primarily on the Sun and its activity. The amount of ionization in the ionosphere varies greatly with the amount of radiation received from the Sun. Thus there is a diurnal (time of day) effect and a seasonal effect. The local winter hemisphere is tipped away from the Sun, thus there is less received solar radiation. The activity of the Sun is associated with the sunspot cycle, with more radiation occurring with more sunspots. Radiation received also varies with geographical location (polar, auroral zones, mid-latitudes, and equatorial regions). There are also mechanisms that disturb the ionosphere and decrease the ionization. There are disturbances such as solar flares and the associated release of charged particles into the solar wind which reaches the Earth and interacts with its geomagnetic field.
The ionospheric layers.
At night the F layer is the only layer of significant ionization present, while the ionization in the E and D layers is extremely low. During the day, the D and E layers become much more heavily ionized, as does the F layer, which develops an additional, weaker region of ionisation known as the F1 layer. The F2 layer persists by day and night and is the region mainly responsible for the refraction of radio waves.
D layer.
The D layer is the innermost layer, to above the surface of the Earth. Ionization here is due to Lyman series-alpha hydrogen radiation at a wavelength of 121.5 nanometre (nm) ionizing nitric oxide (NO). In addition, high solar activity can generate hard X-rays (wavelength ) that ionize N2 and O2. Recombination rates are high in the D layer, so there are many more neutral air molecules than ions. Medium frequency (MF) and lower high frequency (HF) radio waves are significantly reduced in strength within the D layer, as the passing radio waves cause electrons to move, which then collide with the neutral molecules, giving up their energy. The lower frequencies move the electrons farther, with a greater chance of collisions. This is the main reason for absorption of HF radio waves, particularly at 10 MHz and below, with progressively less absorption at higher frequencies. This effect peaks around noon and is reduced at night due to a decrease in the D layer's thickness; only a small part remains due to cosmic rays. A common example of the D layer in action is the disappearance of distant AM broadcast band stations in the daytime.
During solar proton events, ionization can reach unusually high levels in the D-region over high and polar latitudes. Such very rare events are known as Polar Cap Absorption (or PCA) events, because the increased ionization significantly enhances the absorption of radio signals passing through the region. In fact, absorption levels can increase by many tens of dB during intense events, which is enough to absorb most (if not all) transpolar HF radio signal transmissions. Such events typically last less than 24 to 48 hours.
E layer.
The E layer is the middle layer, to above the surface of the Earth. Ionization is due to soft X-ray (1–10 nm) and far ultraviolet (UV) solar radiation ionization of molecular oxygen (O₂). Normally, at oblique incidence, this layer can only reflect radio waves having frequencies lower than about 10 MHz and may contribute a bit to absorption on frequencies above. However, during intense Sporadic E events, the Es layer can reflect frequencies up to 50 MHz and higher. The vertical structure of the E layer is primarily determined by the competing effects of ionization and recombination. At night the E layer weakens because the primary source of ionization is no longer present. After sunset an increase in the height of the E layer maximum increases the range to which radio waves can travel by reflection from the layer.
This region is also known as the Kennelly–Heaviside layer or simply the Heaviside layer. Its existence was predicted in 1902 independently and almost simultaneously by the American electrical engineer Arthur Edwin Kennelly (1861–1939) and the British physicist Oliver Heaviside (1850–1925). However, it was not until 1924 that its existence was detected by Edward V. Appleton and Miles Barnett.
Es.
The Es layer (sporadic E-layer) is characterized by small, thin clouds of intense ionization, which can support reflection of radio waves, rarely up to 225 MHz. Sporadic-E events may last for just a few minutes to several hours. Sporadic E propagation makes VHF-operating radio amateurs very excited, as propagation paths that are generally unreachable can open up. There are multiple causes of sporadic-E that are still being pursued by researchers. This propagation occurs most frequently during the summer months when high signal levels may be reached. The skip distances are generally around . Distances for one hop propagation can be anywhere from to . Double-hop reception over is possible.
F layer.
The F layer or region, also known as the Appleton-Barnett layer, extends from about to more than above the surface of Earth. It is the densest point of the ionosphere, which implies signals penetrating this layer will escape into space. At higher altitudes, the number of oxygen ions decreases and lighter ions such as hydrogen and helium become dominant; this layer is the topside ionosphere. There, extreme ultraviolet (UV, 10–100 nm) solar radiation ionizes atomic oxygen. The F layer consists of one layer at night, but during the day, a deformation often forms in the profile that is labeled F₁. The F₂ layer remains by day and night responsible for most skywave propagation of radio waves, facilitating high frequency (HF, or shortwave) radio communications over long distances.
From 1972 to 1975 NASA launched the AEROS and AEROS B satellites to study the F region.
Ionospheric model.
An ionospheric model is a mathematical description of the ionosphere as a function of location, altitude, day of year, phase of the sunspot cycle and geomagnetic activity. Geophysically, the state of the ionospheric plasma may be described by four parameters: "electron density, electron and ion temperature" and, since several species of ions are present, "ionic composition". Radio propagation depends uniquely on electron density.
Models are usually expressed as computer programs. The model may be based on basic physics of the interactions of the ions and electrons with the neutral atmosphere and sunlight, or it may be a statistical description based on a large number of observations or a combination of physics and observations. One of the most widely used models is the International Reference Ionosphere (IRI), which is based on data and specifies the four parameters just mentioned. The IRI is an international project sponsored by the Committee on Space Research (COSPAR) and the International Union of Radio Science (URSI). The major data sources are the worldwide network of ionosondes, the powerful incoherent scatter radars (Jicamarca, Arecibo, Millstone Hill, Malvern, St. Santin), the ISIS and Alouette topside sounders, and in situ instruments on several satellites and rockets. IRI is updated yearly. IRI is more accurate in describing the variation of the electron density from bottom of the ionosphere to the altitude of maximum density than in describing the total electron content (TEC) .Since 1999 this model is "International Standard" for the terrestrial ionosphere (standard TS16457).
Persistent anomalies to the idealized model.
Ionograms allow deducing, via computation, the true shape of the different layers. Nonhomogeneous structure of the electron/ion-plasma produces rough echo traces, seen predominantly at night and at higher latitudes, and during disturbed conditions.
Winter anomaly.
At mid-latitudes, the F2 layer daytime ion production is higher in the summer, as expected, since the Sun shines more directly on the Earth. However, there are seasonal changes in the molecular-to-atomic ratio of the neutral atmosphere that cause the summer ion loss rate to be even higher. The result is that the increase in the summertime loss overwhelms the increase in summertime production, and total F2 ionization is actually lower in the local summer months. This effect is known as the winter anomaly. The anomaly is always present in the northern hemisphere, but is usually absent in the southern hemisphere during periods of low solar activity.
Equatorial anomaly.
Within approximately ± 20 degrees of the "magnetic equator", is the "equatorial anomaly". It is the occurrence of a trough in the ionization in the F2 layer at the equator and crests at about 17 degrees in magnetic latitude. The Earth's magnetic field lines are horizontal at the magnetic equator. Solar heating and tidal oscillations in the lower ionosphere move plasma up and across the magnetic field lines. This sets up a sheet of electric current in the E region which, with the horizontal magnetic field, forces ionization up into the F layer, concentrating at ± 20 degrees from the magnetic equator. This phenomenon is known as the "equatorial fountain".
Equatorial electrojet.
The worldwide solar-driven wind results in the so-called Sq (solar quiet) current system in the E region of the Earth's ionosphere (ionospheric dynamo region) ( – altitude). Resulting from this current is an electrostatic field directed E-W (dawn-dusk) in the equatorial day side of the ionosphere. At the magnetic dip equator, where the geomagnetic field is horizontal, this electric field results in an enhanced eastward current flow within ± 3 degrees of the magnetic equator, known as the equatorial electrojet.
Ephemeral ionospheric perturbations.
X-rays: sudden ionospheric disturbances (SID).
When the Sun is active, strong solar flares can occur that will hit the sunlit side of Earth with hard X-rays. The X-rays will penetrate to the D-region, releasing electrons that will rapidly increase absorption, causing a high frequency (3–30 MHz) radio blackout. During this time very low frequency (3–30 kHz) signals will be reflected by the D layer instead of the E layer, where the increased atmospheric density will usually increase the absorption of the wave and thus dampen it. As soon as the X-rays end, the sudden ionospheric disturbance (SID) or radio black-out ends as the electrons in the D-region recombine rapidly and signal strengths return to normal.
Protons: polar cap absorption (PCA).
Associated with solar flares is a release of high-energy protons. These particles can hit the Earth within 15 minutes to 2 hours of the solar flare. The protons spiral around and down the magnetic field lines of the Earth and penetrate into the atmosphere near the magnetic poles increasing the ionization of the D and E layers. PCA's typically last anywhere from about an hour to several days, with an average of around 24 to 36 hours.
Geomagnetic storms.
A geomagnetic storm is a temporary intense disturbance of the Earth's magnetosphere.
Lightning.
Lightning can cause ionospheric perturbations in the D-region in one of two ways. The first is through VLF (very low frequency) radio waves launched into the magnetosphere. These so-called "whistler" mode waves can interact with radiation belt particles and cause them to precipitate onto the ionosphere, adding ionization to the D-region. These disturbances are called "lightning-induced electron precipitation" (LEP) events.
Additional ionization can also occur from direct heating/ionization as a result of huge motions of charge in lightning strikes. These events are called early/fast.
In 1925, C. T. R. Wilson proposed a mechanism by which electrical discharge from lightning storms could propagate upwards from clouds to the ionosphere. Around the same time, Robert Watson-Watt, working at the Radio Research Station in Slough, UK, suggested that the ionospheric sporadic E layer (Es) appeared to be enhanced as a result of lightning but that more work was needed. In 2005, C. Davis and C. Johnson, working at the Rutherford Appleton Laboratory in Oxfordshire, UK, demonstrated that the Es layer was indeed enhanced as a result of lightning activity. Their subsequent research has focused on the mechanism by which this process can occur.
Applications.
Radio communication.
DX communication, popular among amateur radio enthusiasts, is a term given to communication over great distances. Thanks to the property of ionized atmospheric gases to refract high frequency (HF, or shortwave) radio waves, the ionosphere can be utilized to "bounce" a transmitted signal down to ground. Transcontinental HF-connections rely on up to 5 bounces, or hops. Such communications played an important role during World War II. Karl Rawer's most sophisticated prediction method took account of several (zig-zag) paths, attenuation in the D-region and predicted the 11-year solar cycle by a method due to Wolfgang Gleißberg.
Mechanism of refraction.
When a radio wave reaches the ionosphere, the electric field in the wave forces the electrons in the ionosphere into oscillation at the same frequency as the radio wave. Some of the radio-frequency energy is given up to this resonant oscillation. The oscillating electrons will then either be lost to recombination or will re-radiate the original wave energy. Total refraction can occur when the collision frequency of the ionosphere is less than the radio frequency, and if the electron density in the ionosphere is great enough.
The critical frequency is the limiting frequency at or below which a radio wave is reflected by an ionospheric layer at vertical incidence. If the transmitted frequency is higher than the plasma frequency of the ionosphere, then the electrons cannot respond fast enough, and they are not able to re-radiate the signal. It is calculated as shown below:
where N = electron density per m3 and fcritical is in Hz.
The Maximum Usable Frequency (MUF) is defined as the upper frequency limit that can be used for transmission between two points at a specified time.
where formula_3 = angle of attack, the angle of the wave relative to the horizon, and sin is the sine function.
The cutoff frequency is the frequency below which a radio wave fails to penetrate a layer of the ionosphere at the incidence angle required for transmission between two specified points by refraction from the layer.
Other applications.
The open system electrodynamic tether, which uses the ionosphere, is being researched. The space tether uses plasma contactors and the ionosphere as parts of a circuit to extract energy from the Earth's magnetic field by electromagnetic induction.
Measurements.
Overview.
Scientists also are exploring the structure of the ionosphere by a wide variety of methods, including passive observations of optical and radio emissions generated in the ionosphere, bouncing radio waves of different frequencies from it, incoherent scatter radars such as the EISCAT, Sondre Stromfjord, Millstone Hill, Arecibo, and Jicamarca radars, coherent scatter radars such as the Super Dual Auroral Radar Network (SuperDARN) radars, and using special receivers to detect how the reflected waves have changed from the transmitted waves.
A variety of experiments, such as HAARP (High Frequency Active Auroral Research Program), involve high power radio transmitters to modify the properties of the ionosphere. These investigations focus on studying the properties and behavior of ionospheric plasma, with particular emphasis on being able to understand and use it to enhance communications and surveillance systems for both civilian and military purposes. HAARP was started in 1993 as a proposed twenty-year experiment, and is currently active near Gakona, Alaska.
The SuperDARN radar project researches the high- and mid-latitudes using coherent backscatter of radio waves in the 8 to 20 MHz range. Coherent backscatter is similar to Bragg scattering in crystals and involves the constructive interference of scattering from ionospheric density irregularities. The project involves more than 11 different countries and multiple radars in both hemispheres.
Scientists are also examining the ionosphere by the changes to radio waves, from satellites and stars, passing through it. The Arecibo radio telescope located in Puerto Rico, was originally intended to study Earth's ionosphere.
Ionograms.
Ionograms show the virtual heights and critical frequencies of the ionospheric layers and which are measured by an ionosonde. An ionosonde sweeps a range of frequencies, usually from 0.1 to 30 MHz, transmitting at vertical incidence to the ionosphere. As the frequency increases, each wave is refracted less by the ionization in the layer, and so each penetrates further before it is reflected. Eventually, a frequency is reached that enables the wave to penetrate the layer without being reflected. For ordinary mode waves, this occurs when the transmitted frequency just exceeds the peak plasma, or critical, frequency of the layer. Tracings of the reflected high frequency radio pulses are known as ionograms. Reduction rules are given in: "URSI Handbook of Ionogram Interpretation and Reduction", edited by William Roy Piggott and Karl Rawer, Elsevier Amsterdam, 1961 (translations into Chinese, French, Japanese and Russian are available).
Incoherent scatter radars.
Incoherent scatter radars operate above the critical frequencies. Therefore, the technique allows to probe the ionosphere, unlike ionosondes, also above the electron density peaks. The thermal fluctuations of the electron density scattering the transmitted signals lack coherence, which gave the technique its name. Their power spectrum contains information not only on the density, but also on the ion and electron temperatures, ion masses and drift velocities.
Solar flux.
Solar flux is a measurement of the intensity of solar radio emissions at a frequency of 2800 MHz made using a radio telescope located in Dominion Radio Astrophysical Observatory, Penticton, British Columbia, Canada. Known also as the 10.7 cm flux (the wavelength of the radio signals at 2800 MHz), this solar radio emission has been shown to be proportional to sunspot activity. However, the level of the Sun's ultraviolet and X-ray emissions is primarily responsible for causing ionization in the Earth's upper atmosphere. We now have data from the GOES spacecraft that measures the background X-ray flux from the Sun, a parameter more closely related to the ionization levels in the ionosphere.
Ionospheres of other planets and moons.
Objects in the Solar System that have appreciable atmospheres (i.e., all of the major planets and many of the larger moons) generally produce ionospheres. Planets known to have ionospheres include Venus,
Uranus, Mars and Jupiter.
The atmosphere of Titan includes an ionosphere that ranges from about to in altitude and contains carbon compounds.
History.
As early as 1839, the German mathematician and physicist Carl Friedrich Gauss postulated that an electrically conducting region of the atmosphere could account for observed variations of Earth's magnetic field. Sixty years later, Guglielmo Marconi received the first trans-Atlantic radio signal on December 12, 1901, in St. John's, Newfoundland (now in Canada) using a kite-supported antenna for reception. The transmitting station in Poldhu, Cornwall, used a spark-gap transmitter to produce a signal with a frequency of approximately 500 kHz and a power of 100 times more than any radio signal previously produced. The message received was three dits, the Morse code for the letter S. To reach Newfoundland the signal would have to bounce off the ionosphere twice. Dr. Jack Belrose has contested this, however, based on theoretical and experimental work. However, Marconi did achieve transatlantic wireless communications in Glace Bay, Nova Scotia, one year later.
In 1902, Oliver Heaviside proposed the existence of the "Kennelly–Heaviside layer" of the ionosphere which bears his name. Heaviside's proposal included means by which radio signals are transmitted around the Earth's curvature. Heaviside's proposal, coupled with Planck's law of black body radiation, may have hampered the growth of radio astronomy for the detection of electromagnetic waves from celestial bodies until 1932 (and the development of high-frequency radio transceivers). Also in 1902, Arthur Edwin Kennelly discovered some of the ionosphere's radio-electrical properties.
In 1912, the U.S. Congress imposed the Radio Act of 1912 on amateur radio operators, limiting their operations to frequencies above 1.5 MHz (wavelength 200 meters or smaller). The government thought those frequencies were useless. This led to the discovery of HF radio propagation via the ionosphere in 1923.
In 1926, Scottish physicist Robert Watson-Watt introduced the term "ionosphere" in a letter published only in 1969 in "Nature":
Edward V. Appleton was awarded a Nobel Prize in 1947 for his confirmation in 1927 of the existence of the ionosphere. Lloyd Berkner first measured the height and density of the ionosphere. This permitted the first complete theory of short-wave radio propagation. Maurice V. Wilkes and J. A. Ratcliffe researched the topic of radio propagation of very long radio waves in the ionosphere. Vitaly Ginzburg has developed a theory of electromagnetic wave propagation in plasmas such as the ionosphere.
In 1962, the Canadian satellite Alouette 1 was launched to study the ionosphere. Following its success were Alouette 2 in 1965 and the two ISIS satellites in 1969 and 1971, further AEROS-A and -B in 1972 and 1975, all for measuring the ionosphere.

</doc>
<doc id="15100" url="https://en.wikipedia.org/wiki?curid=15100" title="Interlingua">
Interlingua

Interlingua (; ISO 639 language codes "ia", "ina") is an international auxiliary language (IAL), developed between 1937 and 1951 by the International Auxiliary Language Association (IALA). It ranks among the top most widely used IALs (along with Esperanto and Ido), and is the most widely used naturalistic IAL: in other words, its vocabulary, grammar and other characteristics are derived from natural languages. Interlingua was developed to combine a simple, mostly regular grammar with a vocabulary common to the widest possible range of languages, making it unusually easy to learn, at least for those whose native languages were sources of Interlingua's vocabulary and grammar. Conversely, it is used as a rapid introduction to many natural languages.
Interlingua literature maintains that (written) Interlingua is comprehensible to the hundreds of millions of people who speak a Romance language, though it is actively spoken by only a few hundred.
The name Interlingua comes from the Latin words "inter", meaning between, and "lingua", meaning tongue or language. These morphemes are identical in Interlingua. Thus, Interlingua would be "between language", or "intermediary language".
Rationale.
The expansive movements of science, technology, trade, diplomacy, and the arts, combined with the historical dominance of the Greek and Latin languages have resulted in a large common vocabulary among European languages. With Interlingua, an objective procedure is used to extract and standardize the most widespread word or words for a concept found in a set of "control languages": English, French, Italian, Spanish and Portuguese, with German and Russian as secondary references. Words from any language are eligible for inclusion, so long as their internationality is shown by their presence in these control languages. Hence, Interlingua includes such diverse word forms as Japanese "geisha" and "samurai", Arabic "califa", Guugu Yimithirr "gangurru" (Interlingua: kanguru), and Finnish "sauna".
Interlingua combines this pre-existing vocabulary with a minimal grammar based on the control languages. People with a good knowledge of a Romance language, or a smattering of a Romance language plus a good knowledge of the "international scientific vocabulary" can frequently understand it immediately on reading or hearing it. Educated speakers of English also enjoy this easy comprehension. The immediate comprehension of Interlingua, in turn, makes it unusually easy to learn. Speakers of other languages can also learn to speak and write Interlingua in a short time, thanks to its simple grammar and regular word formation using a small number of roots and affixes.
Once learned, Interlingua can be used to learn other related languages quickly and easily, and in some studies, even to understand them immediately. Research with Swedish students has shown that, after learning Interlingua, they can translate elementary texts from Italian, Portuguese, and Spanish. In one 1974 study, an Interlingua class translated a Spanish text that students who had taken 150 hours of Spanish found too difficult to understand. Gopsill has suggested that Interlingua's freedom from irregularities allowed the students to grasp the mechanisms of language quickly.
Words in Interlingua retain their original form from the source language; they are altered as little as possible to fit Interlingua's phonotactics. Each word retains its original spelling, pronunciation, and meanings. For this reason, Interlingua is frequently termed a "naturalistic" IAL.
When compared to natural languages, Interlingua most resembles Spanish.
History.
The American heiress Alice Vanderbilt Morris (1874–1950) became interested in linguistics and the international auxiliary language movement in the early 1920s, and in 1924, Morris and her husband, Dave Hennen Morris, established the non-profit International Auxiliary Language Association (IALA) in New York City. Their aim was to place the study of IALs on a scientific basis. Morris developed the research program of IALA in consultation with Edward Sapir, William Edward Collinson, and Otto Jespersen.
International Auxiliary Language Association.
The IALA became a major supporter of mainstream American linguistics, funding, for example, numerous studies by Sapir, Collinson, and Morris Swadesh in the 1930s and 1940s. Alice Morris edited several of these studies and provided much of IALA's financial support. IALA also received support from such prestigious groups as the Carnegie Corporation, the Ford Foundation, the Research Corporation, and the Rockefeller Foundation.
In its early years, IALA concerned itself with three tasks: finding other organizations around the world with similar goals; building a library of books about languages and interlinguistics; and comparing extant IALs, including Esperanto, Esperanto II, Ido, Peano’s Interlingua (Latino sine flexione), Novial, and Interlingue (Occidental). In pursuit of the last goal, it conducted parallel studies of these languages, with comparative studies of national languages, under the direction of scholars at American and European universities. It also arranged conferences with proponents of these IALs, who debated features and goals of their respective languages. With a "concession rule" that required participants to make a certain number of concessions, early debates at IALA sometimes grew from heated to explosive.
At the Second International Interlanguage Congress, held in Geneva in 1931, IALA began to break new ground; 27 recognized linguists signed a testimonial of support for IALA's research program. An additional eight added their signatures at the third congress, convened in Rome in 1933. That same year, Professor Herbert N. Shenton and Dr. Edward L. Thorndike became influential in IALA's work by authoring key studies in the interlinguistic field.
The first steps towards the finalization of Interlingua were taken in 1937, when a committee of 24 eminent linguists from 19 universities published "Some Criteria for an International Language and Commentary". However, the outbreak of World War II in 1939 cut short the intended biannual meetings of the committee.
Development of a new language.
Originally, the association had not set out to create its own language. Its goal was to identify which auxiliary language already available was best suited for international communication, and how to promote it most effectively. However, after ten years of research, more and more members of IALA concluded that none of the existing interlanguages were up to the task. By 1937, the members had made the decision to create a new language, to the surprise of the world's interlanguage community.
To that point, much of the debate had been equivocal on the decision to use naturalistic (e.g., Peano’s Interlingua, Novial and Occidental) or systematic (e.g., Esperanto and Ido) words. During the war years, proponents of a naturalistic interlanguage won out. The first support was Dr. Thorndike's paper; the second was a concession by proponents of the systematic languages that thousands of words were already present in many – or even a majority – of the European languages. Their argument was that systematic derivation of words was a Procrustian bed, forcing the learner to unlearn and re-memorize a new derivation scheme when a usable vocabulary was already available. This finally convinced supporters of the systematic languages, and IALA from that point assumed the position that a naturalistic language would be best.
At the outbreak of World War II, IALA's research activities were moved from Liverpool to New York, where E. Clark Stillman established a new research staff. Stillman, with the assistance of Dr. Alexander Gode, developed a "prototyping" technique – an objective methodology for selecting and standardizing vocabulary based on a comparison of "control languages".
In 1943 Stillman left for war work and Gode became Acting Director of Research. IALA began to develop models of the proposed language, the first of which were presented in Morris's "General Report" in 1945.
From 1946 to 1948, renowned French linguist André Martinet was Director of Research. During this period IALA continued to develop models and conducted polling to determine the optimal form of the final language. In 1946, IALA sent an extensive survey to more than 3,000 language teachers and related professionals on three continents.
Four models were canvassed:
The results of the survey were striking. The two more schematic models were rejected – K overwhelmingly. Of the two naturalistic models, M received somewhat more support than P. IALA decided on a compromise between P and M, with certain elements of C.
Martinet took up a position at Columbia University in 1948, and Gode took on the last phase of Interlingua's development. The vocabulary and grammar of Interlingua were first presented in 1951, when IALA published the finalized "" and the 27,000-word "Interlingua–English Dictionary" (IED). In 1954, IALA published an introductory manual entitled "Interlingua a Prime Vista" ("Interlingua at First Sight").
Interestingly, the Interlingua presented by the IALA is very close to Peano’s Interlingua (Latino sine flexione), both in its grammar and especially in its vocabulary. Accordingly, the very name "Interlingua" was kept, yet a distinct abbreviation was adopted: IA instead of IL.
Success, decline, and resurgence.
An early practical application of Interlingua was the scientific newsletter "Spectroscopia Molecular", published from 1952 to 1980. In 1954, Interlingua was used at the Second World Cardiological Congress in Washington, D.C. for both written summaries and oral interpretation. Within a few years, it found similar use at nine further medical congresses. Between the mid-1950s and the late 1970s, some thirty scientific and especially medical journals provided article summaries in Interlingua. Science Service, the publisher of "Science Newsletter" at the time, published a monthly column in Interlingua from the early 1950s until Gode's death in 1970. In 1967, the powerful International Organization for Standardization, which normalizes terminology, voted almost unanimously to adopt Interlingua as the basis for its dictionaries.
The IALA closed its doors in 1953 but was not formally dissolved until 1956 or later. Its role in promoting Interlingua was largely taken on by Science Service, which hired Gode as head of its newly formed Interlingua Division. Hugh E. Blair, Gode's close friend and colleague, became his assistant. A successor organization, the Interlingua Institute, was founded in 1970 to promote Interlingua in the US and Canada. The new institute supported the work of other linguistic organizations, made considerable scholarly contributions and produced Interlingua summaries for scholarly and medical publications. One of its largest achievements was two immense volumes on phytopathology produced by the American Phytopathological Society in 1976 and 1977.
Interlingua had attracted many former adherents of other international-language projects, notably Occidental and Ido. The former Occidentalist Ric Berger founded The Union Mundial pro Interlingua (UMI) in 1955, and by the late 1950s, interest in Interlingua in Europe had already begun to overtake that in North America.
Beginning in the 1980s UMI has held international conferences every two years (typical attendance at the earlier meetings was 50 to 100) and launched a publishing programme that eventually produced over 100 volumes. Other Interlingua-language works were published by university presses in Sweden and Italy, and in the 1990s, Brazil and Switzerland. Several Scandinavian schools undertook projects that used Interlingua as a means of teaching the international scientific and intellectual vocabulary.
In 2000, the Interlingua Institute was dissolved amid funding disputes with the UMI; the American Interlingua Society, established the following year, succeeded the institute and responded to new interest emerging in Mexico.
In the Soviet bloc.
Interlingua was spoken and promoted in the Soviet bloc, despite attempts to suppress the language. In the German Democratic Republic, government officials confiscated the letters and magazines that the UMI sent to Walter Rädler, the Interlingua representative there.
In Czechoslovakia, Július Tomin published his first article on Interlingua in the Slovak magazine "Príroda a spoločnosť" (Nature and Society) in 1971, after which he received several anonymous threatening letters. He went on to become the Czech Interlingua representative, teach Interlingua in the school system, and publish a series of articles and books.
Interlingua today.
Today, interest in Interlingua has expanded from the scientific community to the general public. Individuals, governments, and private companies use Interlingua for learning and instruction, travel, online publishing, and communication across language barriers. Interlingua is promoted internationally by the Union Mundial pro Interlingua. Periodicals and books are produced by many national organizations, such as the Societate American pro Interlingua, the Svenska Sällskapet för Interlingua, and the Union Brazilian pro Interlingua.
Samples.
From an essay by Alexander Gode:
Community.
It is not certain how many people have an active knowledge of Interlingua. As noted above, Interlingua is the most widely spoken naturalistic auxiliary language.
Interlingua's greatest advantage is that it is the most widely "understood" international auxiliary language by virtue of its naturalistic (as opposed to schematic) grammar and vocabulary, allowing those familiar with a Romance language, and educated speakers of English, to read and understand it without prior study.
Interlingua has active speakers on all continents, especially in South America and in Eastern and Northern Europe, most notably Scandinavia; also in Russia and Ukraine. In Africa, Interlingua has official representation in the Republic of the Congo. There are copious Interlingua web pages, including editions of Wikipedia and Wiktionary, and a number of periodicals, including "Panorama in Interlingua" from the Union Mundial pro Interlingua (UMI) and magazines of the national societies allied with it. There are several active mailing lists, and Interlingua is also in use in certain Usenet newsgroups, particularly in the europa.* hierarchy. Interlingua is presented on CDs, radio, and television. In recent years, samples of Interlingua have also been seen in music and anime.
Interlingua is taught in many high schools and universities, sometimes as a means of teaching other languages quickly, presenting interlinguistics, or introducing the international vocabulary. The University of Granada in Spain, for example, offers an Interlingua course in collaboration with the Centro de Formación Continua.
Every two years, the UMI organizes an international conference in a different country. In the year between, the Scandinavian Interlingua societies co-organize a conference in Sweden. National organizations such as the Union Brazilian pro Interlingua also organize regular conferences.
Phonology and orthography.
Phonology.
Interlingua is primarily a written language, and the pronunciation is not entirely settled. The sounds in parentheses are not used by all speakers.
Interlingua alphabet.
Interlingua uses the 26 letters of the ISO basic Latin alphabet with no diacritics. The alphabet, pronunciation in IPA & letter name in Interlingua are:
Orthography and pronunciation.
Interlingua has a largely phonemic orthography. For the most part, consonants are pronounced as in English, while the vowels are like Spanish. Double consonants are pronounced as single. Interlingua has five falling diphthongs, , and , although and are rare.
Stress.
The "general rule" is that stress falls on the vowel before the last consonant (e.g., "lingua", 'language', "esser", 'to be', "requirimento", 'requirement'), and where that is not possible, on the first vowel ("via", 'way', "io crea", 'I create'). There are a few exceptions, and the following rules account for most of them:
Speakers may pronounce all words according to the general rule mentioned above. For example, "kilometro" is acceptable, although "kilometro" is more common.
Loanwords.
Unassimilated foreign loanwords, or borrowed words, are pronounced and spelled as in their language of origin. Their spelling may contain diacritics, or accent marks. If the diacritics do not affect pronunciation, they are removed.
Phonotactics.
Interlingua has no explicitly defined phonotactics. However, the prototyping procedure for determining Interlingua words, which strives for internationality, should in general lead naturally to words that are easy for most learners to pronounce. In the process of forming new words, an ending cannot always be added without a modification of some kind in between. A good example is the plural "-s", which is always preceded by a vowel to prevent the occurrence of a hard-to-pronounce consonant cluster at the end. If the singular does not end in a vowel, the final "-s" becomes "-es."
Vocabulary.
Words in Interlingua may be taken from any language, as long as their internationality is verified by their presence in seven "control" languages: Spanish, Portuguese, Italian, French, and English, with German and Russian acting as secondary controls. These are the most widely spoken Romance, Germanic, and Slavic languages, respectively. Because of their close relationship, Spanish and Portuguese are treated as one unit. The largest number of Interlingua words are of Latin origin, with the Greek and Germanic languages providing the second and third largest number. The remainder of the vocabulary originates in Slavic and non-Indo-European languages.
Eligibility.
A word, that is a form with meaning, is eligible for the Interlingua vocabulary if it is verified by at least three of the four primary control languages. Either secondary control language can substitute for a primary language. Any word of Indo-European origin found in a control language can contribute to the eligibility of an international word. In some cases, the archaic or "potential" presence of a word can contribute to its eligibility.
A word can be potentially present in a language when a derivative is present, but the word itself is not. English "proximity", for example, gives support to Interlingua "proxime", meaning 'near, close'. This counts as long as one or more control languages actually have this basic root word, which the Romance languages all do. Potentiality also occurs when a concept is represented as a compound or derivative in a control language, the morphemes that make it up are themselves international, and the combination adequately conveys the meaning of the larger word. An example is Italian "fiammifero" (lit. flamebearer), meaning "match, lucifer", which leads to Interlingua "flammifero", or "match". This word is thus said to be potentially present in the other languages although they may represent the meaning with a single morpheme.
Words do not enter the Interlingua vocabulary solely because cognates exist in a sufficient number of languages. If their meanings have become different over time, they are considered different words for the purpose of Interlingua eligibility. If they still have one or more meanings in common, however, the word can enter Interlingua with this smaller set of meanings.
If this procedure did not produce an international word, the word for a concept was originally taken from Latin (see below). This only occurred with a few grammatical particles.
Form.
The form of an Interlingua word is considered an "international prototype" with respect to the other words. On the one hand, it should be neutral, free from characteristics peculiar to one language. On the other hand, it should maximally capture the characteristics common to all contributing languages. As a result, it can be transformed into any of the contributing variants using only these language-specific characteristics. If the word has any derivatives that occur in the source languages with appropriate parallel meanings, then their morphological connection must remain intact; for example, the Interlingua word for 'time' is spelled "tempore" and not "*tempus" or "*tempo" in order to match it with its derived adjectives, such as "temporal".
The language-specific characteristics are closely related to the sound laws of the individual languages; the resulting words are often close or even identical to the most recent form common to the contributing words. This sometimes corresponds with that of Vulgar Latin. At other times, it is much more recent or even contemporary. It is never older than the classical period.
An illustration.
The French "œil", Italian "occhio", Spanish "ojo", and Portuguese "olho" appear quite different, but they descend from a historical form "oculus". German "Auge", Dutch "oog" and English "eye" (cf. Czech and Polish "oko", Ukrainian "око" "(óko)") are related to this form in that all three descend from Proto-Indo-European "*okʷ". In addition, international derivatives like "ocular" and "oculista" occur in all of Interlingua's control languages. Each of these forms contributes to the eligibility of the Interlingua word. German and English base words do not influence the form of the Interlingua word, because their Indo-European connection is considered too remote. Instead, the remaining base words and especially the derivatives determine the form "oculo" found in Interlingua.
Notes on Interlingua vocabulary.
New words can be derived internally – that is, from existing Interlingua words – or extracted from the control languages in the manner of the original vocabulary. Internal word-building, though freer than in the control languages, is more limited than in schematic languages.
Originally, a word was taken from Latin if the usual procedure did not produce a sufficiently international word. More recently, modern alternatives have become generally accepted. For example, the southern Romance "comprar", meaning 'to buy', has replaced "emer", because the latter occurs only in derivatives in the control languages. Similarly, the modern form "troppo", 'too' or 'too much', has replaced "nimis", and "ma" 'but' has largely replaced "sed".
Grammar.
Interlingua has been developed to omit any grammatical feature that is absent from any one primary control language. Thus, Interlingua has no noun–adjective agreement by gender, case, or number (cf. Spanish and Portuguese "gatas negras" or Italian "gatte nere", 'black female cats'), because this is absent from English, and it has no progressive verb tenses (English "I am reading"), because they are absent from French. Conversely, Interlingua distinguishes singular nouns from plural nouns because all the control languages do. With respect to the secondary control languages, Interlingua has articles, unlike Russian.
The definite article "le" is invariable, as in English. Nouns have no grammatical gender. Plurals are formed by adding "-s", or "-es" after a final consonant. Personal pronouns take one form for the subject and one for the direct object and reflexive. In the third person, the reflexive is always "se". Most adverbs are derived regularly from adjectives by adding "-mente", or "-amente" after a "-c". An adverb can be formed from any adjective in this way.
Verbs take the same form for all persons ("io vive, tu vive, illa vive", 'I live', 'you live', 'she lives'). The indicative ("pare", 'appear', 'appears') is the same as the imperative ("pare!" 'appear!'), and there is no subjunctive. Three common verbs usually take short forms in the present tense: "es" for 'is', 'am', 'are;' "ha" for 'has', 'have;' and "va" for 'go', 'goes'. A few irregular verb forms are available, but rarely used.
There are four simple tenses (present, past, future, and conditional), three compound tenses (past, future, and conditional), and the passive voice. The compound structures employ an auxiliary plus the infinitive or the past participle (e.g., "Ille ha arrivate", 'He has arrived'). Simple and compound tenses can be combined in various ways to express more complex tenses (e.g., "Nos haberea morite", 'We would have died').
Word order is subject–verb–object, except that a direct object pronoun or reflexive pronoun comes before the verb ("Io les vide", 'I see them'). Adjectives may precede or follow the nouns they modify, but they most often follow it. The position of adverbs is flexible, though constrained by common sense.
The grammar of Interlingua has been described as similar to that of the Romance languages, but greatly simplified, primarily under the influence of English. More recently, Interlingua's grammar has been likened to the simple grammars of Japanese and particularly Chinese.
Criticisms and controversies.
Some opponents argue that, being based on a few European languages, Interlingua is best suited for speakers of European languages. Others contend that Interlingua has spelling irregularities that, while internationally recognizable in written form, increase the time needed to fully learn the language, especially for those unfamiliar with Indo-European languages. A related point of criticism is that Interlingua's credential as being Standard Average European is too weak outside the Romance languages. Some opponents see the Germanic, Slavic, and Celtic languages, in particular, as having little influence.
Proponents argue that Interlingua's source languages include not only Romance languages but English, German, and Russian as well. Moreover, the source languages are widely spoken internationally, and large numbers of their words also appear in other languages – still more when derivative forms and loan translations are included. Tests had shown that if a larger number of source languages were used, the results would be about the same. So, IALA selected a much simpler extraction procedure for Interlingua with little adverse effect on its internationality.
Flags and symbols.
As with Esperanto, there have been proposals for a flag of Interlingua; the proposal by Czech translator Karel Podrazil is recognized by multilingual sites. It consists of a white four-pointed star extending to the edges of the flag and dividing it into an upper blue and lower red half. The star is symbolic of the four cardinal directions, and the two halves symbolize Romance and non-Romance speakers of Interlingua who understand each other.
Another symbol of Interlingua is a globe surrounded by twelve stars on a black or blue background, echoing the twelve stars of the Flag of Europe (because the source languages of Interlingua are purely European). Novial [ Wikipedia] marks Interlingua with the Flag of Europe itself.

</doc>
<doc id="15102" url="https://en.wikipedia.org/wiki?curid=15102" title="Isle of Wight">
Isle of Wight

The Isle of Wight is a county and the largest and second most populous island in England. It is located in the English Channel, about off the coast of Hampshire, separated from mainland Great Britain by the Solent. The island has several resorts that have been holiday destinations since Victorian times.
Until 1995, like Jersey and Guernsey, the island had a Governor.
Home to the poets Swinburne and Tennyson and to Queen Victoria, who built her much-loved summer residence and final home Osborne House at East Cowes, the island has a maritime and industrial tradition including boat building, sail making, the manufacture of flying boats, the world's first hovercraft, and the testing and development of Britain's space rockets. The Isle hosts annual festivals including the Bestival and the Isle of Wight Festival, which, in 1970, was the largest rock music event ever held. The island has well-conserved wildlife and some of the richest cliffs and quarries for dinosaur fossils in Europe.
The Isle of Wight was owned by a Norman family until 1293 and was earlier a kingdom in its own right. It was part of Hampshire until 1890 when it became an independent administrative county. It continued to shared a Lord Lieutenant with Hampshire until 1974, when it was reconstituted as a non-metropolitan ceremonial county, giving it its own Lord Lieutenant. Apart from a shared police force, there is now no formal administrative link between the Isle of Wight and Hampshire. In the 1970s, there was a political movement seeking the status of Crown Dependency and thus independence from the UK.
The quickest public transport link to the mainland is to and from Southsea (Portsmouth) by hovercraft, while five ferry services shuttle across the Solent from Southampton, Lymington and Portsmouth.
History.
Neolithic.
There are theories that, during the Neolithic era, Bouldnor was a busy seaport that supported trade with the Middle East, as wheat was present there 8,000 years ago, hundreds of years before wheat was grown anywhere in Europe.
Bronze and Iron Age.
The Isle of Wight is first mentioned in writing in "Geography" by Ptolemy. Bronze Age Britain had large reserves of tin in the areas of Cornwall and Devon and tin is necessary to smelt bronze. At that time the sea level was much lower and carts of tin were brought across the Solent at low tide for export, possibly on the Ferriby Boats. Anthony Snodgrass suggests that a shortage of tin, as a part of the Bronze Age Collapse and trade disruptions in the Mediterranean around 1300 BC, forced metalworkers to seek an alternative to bronze. During Iron Age Britain,the Late Iron Age, the Isle of Wight would appear to have been occupied by the Celtic tribe, the Durotriges - as attested by finds of their coins, for example, the South Wight Hoard, and the Shalfleet Hoard. South eastern Britain experienced significant Continental immigration that is reflected in the genetic makeup of the current residents. As the Iron Age began the value of tin likely dropped sharply and this likely greatly changed the economy of the Isle of Wight. Trade however continued as evidenced by the remarkable local abundance of European Iron Age coins.
Roman period.
Caesar reported that the Belgae took the Isle of Wight about 85 BC and named it Ictus (or Vectis). The Roman historian Suetonius mentions that the entire island was captured by the commander Vespasian, who later became emperor.
The remains of at least five Roman villas have been found on the island, including one near Gurnard which is submerged. First century exports were principally hides, slaves, hunting dogs, grain, cattle, silver, gold, and iron. Ferriby Boats and later Blackfriars Ships likely were important to the local economy.
Jutish and Saxon era.
In or about the 6th Century, the island became the Jutish kingdom of Wihtwara. Its first rulers were said to be Wihtgar (who may have been fictitious) and Stuf. In 661 when it was invaded by Wulfhere of Mercia and forcibly converted to Christianity. When he left for Mercia the islanders reverted to paganism.
In AD 685 it was invaded by Caedwalla of Wessex and can be considered to have become part of Wessex. The resistance to the invasion was led by the local King Arwald and after he was defeated and slain, at Caedwalla's insistence, Wight became the last part of the English lands to convert to Christianity in AD 686. After Alfred the Great (who reigned 871 - 899) made the West Saxon kings the kings of all England, it then became administratively part of England. The island became part of the shire of Hampshire and was divided into hundreds as was the norm. From this time the island suffered especially from Viking predations. Alfred the Great's navy defeated the Danes in 871 after they had "ravaged Devon and the Isle of Wight".
Later middle ages.
The Norman Conquest created the position of Lord of the Isle of Wight. Carisbrooke Priory and the fort of Carisbrooke Castle were founded. The island did not come under full control of the Crown until it was sold by the dying last Norman Lord, Lady Isabella de Fortibus, to Edward I in 1293.
In 1374, the Castilian fleet, led by Fernán Sánchez de Tovar, the 1st Lord of Belves, sacked and burned the island.
The Lordship thereafter became a royal appointment. It is sometimes said that there was a brief interruption when Henry de Beauchamp, 1st Duke of Warwick was in 1444 crowned King of the Isle of Wight with King Henry VI assisting in person at the ceremony, placing the crown on his head. With no male heir, the regal title supposedly expired on the death of Henry de Beauchamp in 1446. But there is no good evidence for this story, and it is considered baseless.
The French landed an invasion force on the island on 21 July 1545 but were rapidly repulsed by local militia. English ships were engaged in battle with the French navy, and it was two days earlier, on 19 July, that the Mary Rose was sunk.
Early modern period.
Henry VIII, who developed the Royal Navy and its permanent base at Portsmouth, fortified the island at Yarmouth, Cowes, East Cowes, and Sandown.
During the English Civil War King Charles fled to the Isle of Wight, believing he would receive sympathy from the governor, Robert Hammond. Hammond was appalled, and imprisoned the king in Carisbrooke Castle. Charles had originally intended to flee to Jersey, but became lost in the New Forest and missed the boat.
During the Seven Years' War, the island was used as a staging post for British troops departing on expeditions against the French coast such as the Raid on Rochefort. During 1759 with a planned French invasion imminent, a large force of soldiers was kept there so they could be moved at speed to any destination on the Southern English coast. The French called off their invasion following the Battle of Quiberon Bay. A later French invasion plan involved a landing on the Isle of Wight.
Modern history.
Queen Victoria made Osborne House on the Isle of Wight her summer home for many years and, as a result, it became a major holiday resort for fashionable Victorians including Alfred, Lord Tennyson, Julia Margaret Cameron, Charles Dickens (who wrote much of David Copperfield there) as well as the French painter Berthe Morisot and members of European royalty.
Queen Victoria died at Osborne House on 22 January 1901, aged 81.
During her reign, the world's first radio station was set up by Marconi in 1897 at the Needles Battery, at the western tip of the island.
During the Second World War the island was frequently bombed. With its proximity to France the island had a number of observation stations and transmitters. It was the starting-point for one of the earlier Operation Pluto pipelines to feed fuel to the Normandy landings.
The Needles battery was used as the site for testing and development of the Black Arrow and Black Knight space rockets, subsequently launched from Woomera, Australia.
The Isle of Wight Festival was a very large rock festival that took place near Afton Down, West Wight in 1970, following two smaller concerts in 1968 and 1969. The 1970 show was notable both for being one of the last public performances by Jimi Hendrix and for the number of attendees reaching, by many estimates, 600,000. The festival was revived in 2002 in a different format and is now an annual event.
Physical geography and wildlife.
The Isle of Wight is roughly diamond-shaped and covers an area of 380 km2, nearly 150 sq.miles. Slightly more than half of the island, mainly in the west, is designated as the Isle of Wight Area of Outstanding Natural Beauty. The island has 258 km2 of farmland, 52 km2 of developed areas, and 57 miles of coastline. The landscape of the island is diverse, leading to its oft-quoted description of "England in Miniature". West Wight is predominantly rural, with dramatic coastlines dominated by the chalk downland ridge, running across the whole island and ending in the Needles stacks—perhaps the most photographed place on the Isle of Wight. The south western quarter is commonly referred to as the Back of the Wight because it has a unique social and historical background. The highest point on the island is St Boniface Down, at , which is a marilyn.
The rest of the island's landscape also has great diversity, with perhaps the most notable habitats being the soft cliffs and sea ledges, which are scenic features and important for wildlife, and are internationally protected. The River Medina flows north into the Solent, whilst the other main river, the Eastern Yar flows roughly north-east, emerging at Bembridge Harbour at the eastern end of the island. There is another river in the west of the island called the Western Yar, flowing the short distance from Freshwater Bay to a relatively large estuary at Yarmouth.
The south coast of the island borders the English Channel. Without man's intervention the sea might well have split the island into three; at the west end where a bank of pebbles separates Freshwater Bay from the marshy backwaters of the Western Yar east of Freshwater, and at the east end where a thin strip of land separates Sandown Bay from the marshy basin of the Eastern Yar, east of Sandown. Yarmouth itself was effectively an island, only connected to the rest of the island by a regularly breached neck of land immediately east of the town.
The Isle of Wight is one of the few places in England where the red squirrel is flourishing, with a stable population (Brownsea Island is another), and unlike most of England, no grey squirrels are to be found on the island. There are occasional sightings of deer at large in the wild on the island. Rare and protected species such as the dormouse and many rare bats can be found. The Glanville Fritillary butterfly's distribution in the United Kingdom is largely restricted to the edges of the crumbling cliffs of the Isle of Wight.
A competition in 2002 named the Pyramidal Orchid as the Isle of Wight's county flower.
The island has one of the most important areas in Europe for dinosaur fossils. The eroding cliffs often reveal previously hidden remains particularly along the region known as the Back of the Wight.
Climate.
The Isle of Wight has a milder sub-climate than other areas of the UK, which makes it a holiday destination, particularly the resorts in the south east of the island. It also has a longer growing season. The mean temperature is 13 degrees Celsius averaged over the year, and is 18 degrees in July and August. The microclimate of places such as Lower Ventnor is influenced by their sheltered position under the cliffs. The Isle of Wight is also sunnier than parts of the UK, with 1800–2100 hours of sunshine a year. Some years have almost no snow in winter, and only a few days of hard frost.
Geology.
The Isle of Wight is made up of a wide variety of different rock types dating from early Cretaceous times (around 127 million years ago) to the middle of the Palaeogene (around 30 million years ago). The northern half of the island is mainly made up of Tertiary clays, with the southern half formed of Cretaceous rocks (the chalk that forms the central east-west downs, as well as Upper and Lower Greensands and Wealden strata).
All the rocks found on the island are sedimentary such as limestone, mudstone and sandstone. Rocks on the island are very rich in fossils and many of these can be seen exposed on the beaches as the cliffs erode. Lignitic coal is present in small quantities in seams on the cliffs and shore at Whitecliff Bay and fossilised molluscs have been found there.
Dinosaur bones and footprints can be seen in and on the rocks exposed around the island's beaches, especially at Yaverland and Compton Bay. As a result, the isle has been nicknamed "Dinosaur Island".
Along the northern coast of the island there is a rich source of fossilised shellfish, crocodiles, turtles and mammal bones. The youngest of these date back to around 30 million years ago.
The geological structure is dominated by a large monocline which causes the marked change in age of strata from the northern younger Tertiary beds to the older Cretaceous beds of the south. This gives rise to a dip of almost 90 degrees in the chalk beds, seen best at the Needles.
The area was affected by sea level changes during the repeated Quaternary glaciations. Probably about 125,000 years ago, during the Ipswichian interglacial, the Isle of Wight became separated from the mainland.
Politics.
With a single Member of Parliament and 132,731 permanent residents in 2001, it is the most populous parliamentary constituency in the United Kingdom (more than 50% above the average of English constituencies). Parliament has passed Section 11, Clause 6(1) of the Parliamentary Voting System and Constituencies Act 2011 to alter this.
The Isle of Wight is a ceremonial and non-metropolitan county. Since the abolition of its two borough councils in 1995 and the restructuring of the county council as the Isle of Wight Council, it has been a unitary county.
As a constituency of the House of Commons, it is traditionally a battleground between the Conservatives and the Liberal Democrats. The current Member of Parliament Andrew Turner is a Conservative, and his predecessor Dr Peter Brand was a Liberal Democrat.
The Isle of Wight Council election of 2013 saw the Conservative Party lose the majority which they had held since 2005 to the Island Independents. Independent councillors currently hold 20 of the 40 seats in the council.
There have been small regionalist movements: the Vectis National Party and the Isle of Wight Party; but they have attracted little support in elections.
Culture.
Language and dialect.
The accent of the Isle of Wight is similar to the traditional dialect of Hampshire, featuring the dropping of some consonants and an emphasis on longer vowels. It is similar to the West Country dialects heard in SW England, but less removed in sound from the Estuary English of the SE. As with many other traditional southern English regional dialects and accents, a strong island accent is not now commonly heard, and, as speakers tend to be older, this decline is likely to continue.
The island has its own local and regional words. Some words, such as "nipper/nips" (a young male person), are still commonly used and are shared with neighbouring areas of the mainland. A few are unique to the island, for example "overner" (a mainlander who has settled on the island), "caulkhead" (someone born on the island and born from long-established island stock) and "grockle" (a tourist/visitor). Other words are more obscure and now used mainly for comic emphasis, such as "mallishag" (meaning "caterpillar"). Some other words are "gurt" meaning "large", "nammit" (a mid-morning snack) and "gallybagger" ("scarecrow").
Identity.
There has been and still is some confusion between the identities of the Isle of Wight as a separate county and, as it once was, a part of the nearby county of Hampshire. At least one mainstream newspaper article as recently as 2008 refers to the "Isle of Wight in Hampshire". Prior to 1890, the Isle of Wight was normally regarded and was administered as a part of Hampshire. With the formation of the Isle of Wight County Council in 1890, the distinct identity became officially established: see also "Politics of the Isle of Wight". In January 2009, the new Flag of the Isle of Wight, the first general flag for the county, was accepted by the Flag Institute. Denizens of the Isle of Wight are sometimes referred to as 'Vectensians', 'Vectians' or "caulkheads".
Sport.
Cycling.
The Isle of Wight is well known for its cycling, with it reaching the top ten in Lonely Planet Best in Travel Guide (2010) for cycling locations. The island is also host to events such as the Isle of Wight Randonnée and the Isle of Wight Cycling Festival, which are hosted annually. There are cycling clubs such as Vectis Roads Cycling Club, which hosts mainly time trials on the island, including an annual 3 Day Time Trial Festival on a bank holiday weekend in May.
Rowing.
There are rowing clubs at Newport, Ryde and Shanklin.
In June 1998 a group of ladies from the Isle of Wight made history by becoming the first team of ladies to row around the island in a fixed seat Solent Galley. They completed their trip in 10 hours and twenty minutes. Their team photo is on show in Ryde Rowing Club.
Rowers from Ryde Rowing Club have rowed around the island on a number of other occasions the first being 1880. The 4s record was set 16 August 1995 at 7 hours and 57 minutes by a Ryde crew.
Two rowers from Southampton ARC (Chris Bennett and Roger Slaymaker) set the 2 man record in July 2003 at 8 hours and 34 minutes and in 2006 Gus McKechnie of Coalporters rowing club completed a clockwise row as part of a 4s crew making him the only person to have rowed around both ways.
The route around the island is some 60+ miles usually anti clockwise and involves even in good conditions a number of notable obstacles including the Needles Rocks and the overfalls at St Catherines point. Start and finish points were traditionally Ryde Rowing club however other start points have been chosen in recent years that give tidal advantages.
Sailing.
Cowes is a centre for sailing, playing host to several racing regattas. Cowes Week is the longest-running regular regatta in the world, with over 1,000 yachts and 8,500 competitors taking part in over 50 classes of yacht racing.
In 1851 the first America's Cup race took place around the island. Other major sailing events hosted in Cowes include the Fastnet race, the Round the Island Race, the Admiral's Cup, and the Commodore's Cup.
Trampolining.
There are two main trampoline clubs on the island, in Freshwater and Newport, competing at regional, national and international grades.
Marathon.
The Isle of Wight Marathon is the United Kingdom's oldest continuously held marathon, having been run every year since 1957. Since 2013 the course has started in Cowes, passing through Gurnard, Rew Street, Porchfield, Shalfleet, Yarmouth, Afton, Willmingham, Thorley, Wellow, Shalfleet, Porchfield, and Northwood before finishing back in Cowes. It is an undulating course with a total climb of 1,043 feet.
Speedway.
The island was home to the Isle of Wight Islanders speedway team until 2014, who competed in the sport's third division, the National League. The club was founded in 1996, with a first-night attendance of 1,740.Speedway is now back for season 2016
Ice hockey.
The island is home to the Wightlink Raiders, an ice hockey team based at Ryde Arena. They compete in the 1st Tier of the English National Ice Hockey League, the 3rd Division in the country. There is an amateur team the Vectis Tigers of the 2nd Tier English National Ice Hockey League, and four youth teams including the Isle of Wight Wildcats, all based at Ryde Arena.
Hockey.
Following an amalgamation of the hockey clubs on the Isle of Wight in 2011, The Isle of Wight Hockey Club now runs two men's senior teams and two ladies' senior teams. These teams compete at a range of levels in the Hampshire open leagues. There is a junior set up who compete in competitions in the U12 and U14 age group.
Football.
The now-disbanded Ryde Sports F.C. founded in 1888 became one of the eight founder members of the Hampshire League in 1896. There are several non-league clubs such as Newport (IW) F.C. There is an Isle of Wight Saturday Football League with three divisions, and a rugby union club, plus various other sporting teams. Beach football is particularly prevalent on the island and has several of the nation's premier clubs with almost all of the England Beach Soccer team made up from players from the island. Many of the stadiums are used when the island hosts the Island Games as it has done twice.
Cricket.
The Isle of Wight is the 39th official county in English cricket, and the Isle of Wight Cricket Board organise an internal cricket league between various local clubs. Ventnor Cricket Club compete in the Southern Premier League, and have won the Second Division several times in recent years. There is a new County Ground near Newport, which held its first match on 6 September 2008. As of November 2010, the Isle of Wight Cricket Board have been in discussion with the Minor Counties Cricket Association and the England and Wales Cricket Board regarding proposals to enter a side in the Minor Counties tournaments. The island has recently produced some notable cricketers, such as Danny Briggs, who plays county cricket for Hampshire County Cricket Club and is a member of the England Lions. Hampshire have played a number of first-class matches on the island, at J Samuel White's Ground (originally built and owned by J. Samuel White Shipbuilders) and the Victoria Recreation Ground.
Island Games.
The Isle of Wight competes in the biennial Island Games, which it hosted in 1993 and again in 2011 with events taking place across the island.
Motor Scooter.
The annual Isle of Wight International Scooter Rally convenes on August Bank Holiday, having begun in 1980. This gathering is one of the biggest scooter rallies in the world, now attracting between four and seven thousand participants.
Music.
The Isle of Wight is home to the Isle of Wight Festival and Bestival. In 1970, with Jimi Hendrix headlining, the festival attracted an audience of 700,000, despite the island itself having a population of roughly 100,000. The Isle of Wight is the home of the band The Bees. They perform at smaller concerts on the island. The band Trixie's Big Red Motorbike as well as three of the founding members of Level 42 (Mark King, Boon Gould and Phil Gould) came from the Isle of Wight. The Isle of Wight has hosted a one-day festival called 'Summer Madness'. It started in 2009 when Madness headlined it; in 2010 Paul Weller headlined. In January 2011 it was reported that the promoter of Summer Madness was insolvent. The Isle Of Wight is also home to 'Platform One: College Of Music', which offers a national BTEC diploma level 2 & level 3 in music as part of Chichester College.
Economy.
This is a table of the trend in regional gross value added by the Isle of Wight economy at current basic prices by the "Office for National Statistics" with figures in millions of pounds.
Industry and agriculture.
The largest industry on the Isle of Wight is tourism, but the island has a strong agricultural heritage, including sheep and dairy farming and the growing of arable crops. Traditional agricultural commodities are more difficult to market off the island because of transport costs, but island farmers have managed successfully to exploit some specialist markets. The high price of these products overcomes the transport costs. One of the most successful agricultural sectors at present is the growing of crops under cover, particularly salad crops, including tomatoes and cucumbers. The Isle of Wight has a longer growing season than much of the United Kingdom and this favours such crops. Garlic has been successfully grown in Newchurch for many years, and is even exported to France. This has led to the establishment of an annual Garlic Festival at Newchurch, which is one of the largest events of the island's annual calendar. The favourable climate has led to the success of vineyards, including one of the oldest in the British Isles, at Adgestone near Sandown. Lavender is grown for its oil. The largest sector of agriculture has been dairying, but due to low milk prices, and strict UK legislation for UK milk producers, the dairy industry has declined. There were nearly one-hundred and fifty dairy producers of various sizes in the mid-eighties, but this has now dwindled down to just twenty-four. Due to modern farming practices, the island has noted increased levels of pesticide poisoning in local farmers and other local residents living near crops and vineyards.
The making of sailcloth, boats and other connected maritime industry has long been associated with the island, although this has somewhat diminished in recent years. Cowes is still home to various small marine-related companies such as boat-builders.
Although they have reduced the extent of the plants and workforce, including the sale of the main site, GKN operates what was once the British Hovercraft Corporation a subsidiary of, and known latterly, when manufacturing focus changed, as Westland Aircraft. Prior to its purchase by Westland, it was the independent company known as Saunders-Roe. It remains one of the most notable historic firms, having produced many of the flying boats, and the world's first hovercraft.
The island's major manufacturing activity today is in composite materials, used by boat-builders and the wind turbine manufacturer Vestas, which has a wind turbine blade factory and testing facilities in Newport and East Cowes.
Bembridge Airfield is the home of Britten-Norman, manufacturers of the Islander and Trislander aircraft. This is shortly to become the site of the European assembly line for Cirrus light aircraft. The Norman Aeroplane Company is a smaller aircraft manufacturing company operating in Sandown. There are have been three other aircraft manufacturers that built planes on the island.
In 2005, Northern Petroleum began exploratory drilling for oil, with its Sandhills-2 borehole at Porchfield but ceased operations in October that year, after failing to find significant reserves.
Breweries.
There are three breweries on the island. Goddards Brewery in Ryde opened in 1993. David Yates, who was head brewer of the Island Brewery, started brewing as Yates Brewery at the Inn at St Lawrence in 2000. The Island Brewery, located in Shalfleet, was formed in 2010 by Tom Minshull to complement the existing family run drinks wholesale business.
Ventnor Brewery, which closed in 2009, was the last incarnation of Burt's Brewery, which had been brewing on the island since the 1840s in Ventnor. Until the 1960s most pubs were owned by Mews Brewery sited in Newport near the old railway station, but it closed and the pubs taken over by Strong's and then by Whitbread. By some accounts Mews beer was apt to be rather cloudy and dark. They pioneered the use of cans in the 19th century for export to British India. The old brewery was derelict for many years but was then severely damaged in a spectacular fire.
Services.
Tourism and heritage.
The heritage of the island is a major asset, which has for many years kept its economy going. Holidays focused on natural heritage, including both wildlife and geology, are becoming a growing alternative to the traditional British seaside holiday, which went into decline in the second half of the 20th century, due to the increased affordability of air travel to alternative destinations.
Tourism is still the largest industry on the island. In 1999, the 130,000 island residents were host to 2.7 million visitors. Of these, 1.5 million stayed overnight, and 1.2 million visits were day visits. Only 150,000 of these visitors were international visitors. Between 1993 and 2000, visits increased at a rate of 3% per year, on average.
At the turn of the 19th century the island had ten pleasure piers including two at Ryde and a "chain pier" at Seaview. The Victoria Pier in Cowes succeeded the earlier Royal Pier but was itself removed in 1960. The piers at Ryde, Seaview, Sandown, Shanklin and Ventnor originally served a coastal steamer service that operated from Southsea on the mainland. The piers at Seaview, Shanklin, Ventnor and Alum Bay were all destroyed by storms during the last century. Today only the railway pier at Ryde and the piers at Sandown, Totland Bay (currently closed to the public) and Yarmouth survive. Blackgang Chine is arguably the oldest theme park in the UK, and one of the oldest in the world.
As well as more traditional tourist attractions, the island is often host to walking holidays or cycling holidays through the attractive scenery. Almost every town and village on the island plays host to hotels, hostels and camping sites. Out of the peak summer season, the island is still an important destination for coach tours from other parts of the United Kingdom and an annual walking festival has attracted considerable interest. The Isle of Wight Coastal Path follows the coastline as far as possible, deviating onto roads where the route is impassable closer to the sea.
A major contribution to the local economy comes from sailing and marine-related tourism.
Summer Camp at Camp Beaumont is an attraction at the old Bembridge School site.
Transport.
The Isle of Wight has a total of of roadway. Major roads run between the main island towns, with smaller roads connecting villages. It is one of the few counties in the UK not to have a motorway, although there is a dual carriageway from Coppins Bridge in Newport towards the north of Newport near the island's hospital and prison.
A comprehensive bus network operated by Southern Vectis links most island settlements, with Newport as the central hub.
The island's location off the mainland means that longer-distance transport involves a ferry journey. Car ferry and passenger services are run between the island and the mainland by Wightlink and Red Funnel as well as a hovercraft operated by Hovertravel.
The Island formerly had its own railway network of over 55 miles, but only one line remains in regular use. The Island Line is part of the United Kingdom's National Rail network, running a little under from Ryde to Shanklin. The line was opened by the Isle of Wight Railway in 1864, and from 1996 to 2007 was run by the smallest train operating company on the network, Island Line Trains. It is notable for utilising ex-London Underground rolling stock. Branching off the Island Line at Smallbrook Junction is the heritage Isle of Wight Steam Railway, which runs for 5½ miles () to the outskirts of Wootton.
There are currently two airfields for general aviation, Isle of Wight Airport at Sandown and Bembridge Airport.
The island has over of cycleways, much of which can be enjoyed by families off-road. Major Trails are 
Media.
The Isle of Wight's main local newspaper the "Isle of Wight County Press", is published most Fridays.
Local, Commercial, Vectis Radio covers the Isle of Wight across the world as the islands online Radio Station; since 2010 Broadcasting from The Riverside Centre Newport.
The island has one local commercial radio station and also falls within the coverage area of a number of local stations on the near mainland. Isle of Wight Radio has broadcast in the medium-wave band since 1990 and on 107.0 MHz (with three smaller transmitters on 102.0 MHz) FM since 1998, as well as streaming on the Internet.
The island's not-for-profit community radio station opened in 2007, Angel Radio began broadcasting on 91.5 MHz from studios in Cowes from a transmitter near Newport. On 1 February 2009, Wight FM began broadcasting as an Internet radio station. It closed down six months later.
Online news sources for the Isle of Wight include "On the Wight" and "The Isle of Wight Chronicle". "The Chronicle" was originally a best selling island paper in the 1950s.
The island has an online 24/7 breaking news source in the form of the "Island Echo", which was founded in May 2012.
The island has had community television stations in the past, first TV12 and then Solent TV from 2002 until its closure on 24 May 2007. iWight.TV is a local internet video news channel.
The Isle of Wight is part of the BBC South region and the ITV Meridian region.
Important broadcasting facilities on Isle of Wight are Chillerton Down transmitting station, whose mast is the tallest structure on Isle of Wight and Rowridge transmitting station.
Prisons.
The geography of the island, and its location near the densely populated south of England, led to it hosting three prisons: Albany, Camp Hill and Parkhurst, all located outside Newport near the main road to Cowes. Albany and Parkhurst were among the few Category A prisons in the UK until they were downgraded in the 1990s. The downgrading of Parkhurst was precipitated by a major escape: three prisoners (two murderers and a blackmailer) made their way out of the prison on 3 January 1995 for four days of freedom before being recaptured. Parkhurst especially enjoyed notoriety as one of the toughest jails in the United Kingdom and housed many notable inmates, including the Yorkshire Ripper Peter Sutcliffe, New Zealand drug lord Terry Clark and the Kray twins.
Camp Hill is located to the west of, and adjacent to, Albany and Parkhurst, on the very edge of Parkhurst Forest, having been converted first to a borstal and later to a Category C prison. It was built on the site of an army camp (both Albany and Parkhurst were barracks); there is a small estate of tree-lined roads with onetime officers' quarters (now privately owned) to the south and east. Camp Hill closed as a prison in March 2013.
The management of all three prisons was merged into a single administration, under the name of HMP Isle of Wight in April 2009.
Education.
There are sixty-nine Local Education Authority-maintained schools on the Isle of Wight, and two independent schools. As a rural community, many of these schools are small, with average numbers of pupils lower than in many urban areas. There are currently primary schools, middle schools and high schools. However, education reforms have led to plans for closures (for full details on these see Education reforms on the Isle of Wight). The Isle of Wight College, is located on the outskirts of Newport.
From September 2010, there was a transition period from the "3-tier system" of primary, middle and high schools. Some schools have now closed their doors, such as Chale C.E. Primary School. Other schools have become "federated", such as Brading C.E. Primary School and St Helen's Primary School. Christ the King College started as a "middle school" but has now been converted into a secondary school and sixth form.
As of September 2011, there are 5 new secondary schools with an age range of 11 to 18 years which have replaced the island's High Schools (as a part of the previous 3-tier system).
Notable residents.
Notable residents have included:
Overseas names.
The Isle of Wight has given its names to many parts of former colonies, most notably Isle of Wight County in Virginia founded by settlers from the island in the 17th century. Its county seat is a town named Isle of Wight.
Other notable examples include:

</doc>
<doc id="15107" url="https://en.wikipedia.org/wiki?curid=15107" title="Internet Control Message Protocol">
Internet Control Message Protocol

The Internet Control Message Protocol (ICMP) is one of the main protocols of the internet protocol suite. It is used by network devices, like routers, to send error messages indicating, for example, that a requested service is not available or that a host or router could not be reached. ICMP can also be used to relay query messages. It is assigned protocol number 1.
ICMP differs from transport protocols such as TCP and UDP in that it is not typically used to exchange data between systems, nor is it regularly employed by end-user network applications (with the exception of some diagnostic tools like ping and traceroute).
Technical details.
The Internet Control Message Protocol is part of the Internet Protocol Suite, as defined in RFC 792. ICMP messages are typically used for diagnostic or control purposes or generated in response to errors in IP operations (as specified in RFC 1122). ICMP errors are directed to the source IP address of the originating packet.
For example, every device (such as an intermediate router) forwarding an IP datagram first decrements the time to live (TTL) field in the IP header by one. If the resulting TTL is 0, the packet is discarded and an ICMP Time To Live exceeded in transit message is sent to the datagram's source address.
Although ICMP messages are contained within standard IP packets, ICMP messages are usually processed as a special case, distinguished from normal IP processing, rather than processed as a normal sub-protocol of IP. In many cases, it is necessary to inspect the contents of the ICMP message and deliver the appropriate error message to the application responsible for transmission of the IP packet that prompted the sending of the ICMP message.
Many commonly used network utilities are based on ICMP messages. The traceroute command can be implemented by transmitting IP datagrams with specially set IP TTL header fields, and looking for ICMP Time to live exceeded in transit (above) and "Destination unreachable" messages generated in response. The related ping utility is implemented using the ICMP "Echo request" and "Echo reply" messages.
ICMP segment structure.
Header.
The ICMP header starts after the IPv4 header and is identified by IP protocol number '1'. 
All ICMP packets have an 8-byte header and variable-sized data section. The first 4 bytes of the header have fixed format, while the last 4 bytes depend on the type/code of that ICMP packet.
Data.
ICMP error messages contain a data section that includes the entire IPv4 header, plus the first eight bytes of data from the IPv4 packet that caused the error message. The ICMP packet is then encapsulated in a new IPv4 packet. This data is used by the host to match the message to the appropriate process. If a higher level protocol uses port numbers, they are assumed to be in the first 64 data bits of the original datagram's data.
The variable size of the ICMP packet data section has been exploited. In the well-known "Ping of death", large or fragmented ping packets are used for denial-of-service attacks. ICMP can also be used to create covert channels for communication. These channels are known as ICMP tunnels.
Control messages.
Source quench.
"Source Quench" requests that the sender decrease the rate of messages sent to a router or host. This message may be generated if a router or host does not have sufficient buffer space to process the request, or may occur if the router or host buffer is approaching its limit.
Data is sent at a very high speed from a host or from several hosts at the same time to a particular router on a network. Although a router has buffering capabilities, the buffering is limited to within a specified range. The router cannot queue any more data than the capacity of the limited buffering space. Thus if the queue gets filled up, incoming data is discarded until the queue is no longer full. But as no acknowledgement mechanism is present in the network layer, the client does not know whether the data has reached the destination successfully. Hence some remedial measures should be taken by the network layer to avoid these kind of situations. These measures are referred to as source quench. In a source quench mechanism, the router sees that the incoming data rate is much faster than the outgoing data rate, and sends an ICMP message to the clients, informing them that they should slow down their data transfer speeds or wait for a certain amount of time before attempting to send more data. When a client receives this message, it will automatically slow down the outgoing data rate or wait for a sufficient amount of time, which enables the router to empty the queue. Thus the source quench ICMP message acts as flow control in the network layer.
Since research suggested that "ICMP Source Quench an ineffective (and unfair) antidote for congestion", routers' creation of source quench messages was deprecated in 1995 by RFC 1812. Furthermore, forwarding of and any kind of reaction to (flow control actions) source quench messages was deprecated from 2012 by RFC 6633.
Where:
Redirect.
"Redirect" requests data packets be sent on an alternative route. ICMP Redirect is a mechanism for routers to convey routing information to hosts. The message informs a host to update its routing information (to send packets on an alternative route). If a host tries to send data through a router (R1) and R1 sends the data on another router (R2) and a direct path from the host to R2 is available (that is, the host and R2 are on the same Ethernet segment), then R1 will send a redirect message to inform the host that the best route for the destination is via R2. The host should then send packets for the destination directly to R2. The router will still send the original datagram to the intended destination. However, if the datagram contains routing information, this message will not be sent even if a better route is available. RFC 1122 states that redirects should only be sent by gateways and should not be sent by Internet hosts.
Where:
Time exceeded.
"Time Exceeded" is generated by a gateway to inform the source of a discarded datagram due to the time to live field reaching zero. A time exceeded message may also be sent by a host if it fails to reassemble a fragmented datagram within its time limit.
Time exceeded messages are used by the traceroute utility to identify gateways on the path between two hosts.
Where:
Timestamp.
"Timestamp" is used for time synchronization. The originating timestamp is set to the time (in milliseconds since midnight) the sender last touched the packet. The receive and transmit timestamps are not used.
Where:
Timestamp reply.
"Timestamp Reply" replies to a "Timestamp" message. It consists of the originating timestamp sent by the sender of the "Timestamp" as well as a receive timestamp indicating when the "Timestamp" was received and a transmit timestamp indicating when the "Timestamp reply" was sent.
Where:
Address mask request.
"Address mask request" is normally sent by a host to a router in order to obtain an appropriate subnet mask.
Recipients should reply to this message with an "Address mask reply" message.
Where:
ICMP Address Mask Request may be used as a part of reconnaissance attack to gather information on the target network, therefore ICMP Address Mask Reply is disabled by default on Cisco IOS.
Address mask reply.
"Address mask reply" is used to reply to an address mask request message with an appropriate subnet mask.
Where:
Destination unreachable.
"Destination unreachable" is generated by the host or its inbound gateway to inform the client that the destination is unreachable for some reason. A Destination Unreachable message may be generated as a result of a TCP, UDP or another ICMP transmission. Unreachable TCP ports notably respond with TCP RST rather than a Destination Unreachable type 3 as might be expected.
The error will not be generated if the original datagram has a multicast destination address. Reasons for this message may include: the physical connection to the host does not exist (distance is infinite); the indicated protocol or port is not active; the data must be fragmented but the 'don't fragment' flag is on.
Where:

</doc>
<doc id="15108" url="https://en.wikipedia.org/wiki?curid=15108" title="ICMP">
ICMP

ICMP may refer to:

</doc>
<doc id="15109" url="https://en.wikipedia.org/wiki?curid=15109" title="Inverse limit">
Inverse limit

In mathematics, the inverse limit (also called the projective limit or limit) is a construction that allows one to "glue together" several related objects, the precise manner of the gluing process being specified by morphisms between the objects. Inverse limits can be defined in any category.
Formal definition.
Algebraic objects.
We start with the definition of an inverse system (or projective system) of groups and homomorphisms. Let ("I", ≤) be a directed poset (not all authors require "I" to be directed). Let ("A""i")"i"∈"I" be a family of groups and suppose we have a family of homomorphisms "f""ij": "A""j" → "A""i" for all "i" ≤ "j" (note the order), called bonding maps, with the following properties:
Then the pair (("A""i")"i"∈"I", ("f""ij")"i"≤ "j"∈"I") is called an inverse system of groups and morphisms over "I", and the morphisms "f""ij" are called the transition morphisms of the system.
We define the inverse limit of the inverse system (("A""i")"i"∈"I", ("f""ij")"i"≤ "j"∈"I") as a particular subgroup of the direct product of the "A""i"'s:
The inverse limit, "A", comes equipped with "natural projections" π"i": "A" → "A""i" which pick out the "i"th component of the direct product for each "i" in "I". The inverse limit and the natural projections satisfy a universal property described in the next section.
This same construction may be carried out if the "A""i"'s are sets, semigroups, topological spaces, rings, modules (over a fixed ring), algebras (over a fixed ring), etc., and the homomorphisms are morphisms in the corresponding category. The inverse limit will also belong to that category.
General definition.
The inverse limit can be defined abstractly in an arbitrary category by means of a universal property. Let ("X""i", "f""ij") be an inverse system of objects and morphisms in a category "C" (same definition as above). The inverse limit of this system is an object "X" in "C" together with morphisms π"i": "X" → "X""i" (called "projections") satisfying π"i" = "f""ij" o π"j" for all "i" ≤ "j". The pair ("X", π"i") must be universal in the sense that for any other such pair ("Y", ψ"i") (i.e. ψ"i": "Y" → "X""i" with ψ"i" = "f""ij" o ψ"j" for all "i" ≤ "j") there exists a unique morphism "u": "Y" → "X" such that the diagram
commutes for all "i" ≤ "j", for which it suffices to show that ψ"i" = π"i" o "u" for all "i". The inverse limit is often denoted
with the inverse system ("X""i", "f""ij") being understood. 
In some categories, the inverse limit does not exist. If it does, however, it is unique in a strong sense: given any other inverse limit "X"′ there exists a "unique" isomorphism "X"′ → "X" commuting with the projection maps.
We note that an inverse system in a category "C" admits an alternative description in terms of functors. Any partially ordered set "I" can be considered as a small category where the morphisms consist of arrows "i" → "j" if and only if "i" ≤ "j". An inverse system is then just a contravariant functor "I" → "C". And the inverse limit functor
formula_3 is a covariant functor.
Derived functors of the inverse limit.
For an abelian category "C", the inverse limit functor
is left exact. If "I" is ordered (not simply partially ordered) and countable, and "C" is the category Ab of abelian groups, the Mittag-Leffler condition is a condition on the transition morphisms "f""ij" that ensures the exactness of formula_7. Specifically, Eilenberg constructed a functor
(pronounced "lim one") such that if ("A""i", "f""ij"), ("B""i", "g""ij"), and ("C""i", "h""ij") are three projective systems of abelian groups, and
is a short exact sequence of inverse systems, then
is an exact sequence in Ab.
Mittag-Leffler condition.
If the ranges of the morphisms of an inverse system of abelian groups ("A""i", "f""ij") are "stationary", that is, for every "k" there exists "j" ≥ "k" such that for all "i" ≥ "j" :formula_11 one says that the system satisfies the Mittag-Leffler condition. This condition implies that formula_12 
The name "Mittag-Leffler" for this condition was given by Bourbaki in their chapter on uniform structures for a similar result about inverse limits of complete Hausdorff uniform spaces. Mittag-Leffler used a similar argument in the proof of Mittag-Leffler's theorem.
The following situations are examples where the Mittag-Leffler condition is satisfied: 
An example where formula_13 is non-zero is obtained by taking "I" to be the non-negative integers, letting "A""i" = "p""i"Z, "B""i" = Z, and "C""i" = "B""i" / "A""i" = Z/"p""i"Z. Then
where Z"p" denotes the p-adic integers.
Further results.
More generally, if "C" is an arbitrary abelian category that has enough injectives, then so does "C""I", and the right derived functors of the inverse limit functor can thus be defined. The "n"th right derived functor is denoted
In the case where "C" satisfies Grothendieck's axiom (AB4*), Jan-Erik Roos generalized the functor lim1 on Ab"I" to series of functors limn such that
It was thought for almost 40 years that Roos had proved (in "Sur les foncteurs dérivés de lim. Applications. ") that lim1 "A""i" = 0 for ("A""i", "f""ij") an inverse system with surjective transition morphisms and "I" the set of non-negative integers (such inverse systems are often called "Mittag-Leffler sequences"). However, in 2002, Amnon Neeman and Pierre Deligne constructed an example of such a system in a category satisfying (AB4) (in addition to (AB4*)) with lim1 "A""i" ≠ 0. Roos has since shown (in "Derived functors of inverse limits revisited") that his result is correct if "C" has a set of generators (in addition to satisfying (AB3) and (AB4*)).
Barry Mitchell has shown (in "The cohomological dimension of a directed set") that if "I" has cardinality formula_17 (the "d"th infinite cardinal), then "R""n"lim is zero for all "n" ≥ "d" + 2. This applies to the "I"-indexed diagrams in the category of "R"-modules, with "R" a commutative ring; it is not necessarily true in an arbitrary abelian category (see Roos' "Derived functors of inverse limits revisited" for examples of abelian categories in which lim"n", on diagrams indexed by a countable set, is nonzero for "n" > 1).
Related concepts and generalizations.
The categorical dual of an inverse limit is a direct limit (or inductive limit). More general concepts are the limits and colimits of category theory. The terminology is somewhat confusing: inverse limits are limits, while direct limits are colimits.

</doc>
<doc id="15111" url="https://en.wikipedia.org/wiki?curid=15111" title="Interplanetary spaceflight">
Interplanetary spaceflight

Interplanetary spaceflight or interplanetary travel is travel between planets, usually within a single planetary system. In practice, spaceflights of this type are confined to travel between the planets of the Solar System.
Current achievements in interplanetary travel.
Remotely guided space probes have flown by all of the planets of the Solar System from Mercury to Neptune, with the New Horizons probe having flown by the dwarf planet Pluto and the Dawn spacecraft currently orbiting the dwarf planet Ceres. The most distant spacecraft, Voyager 1, has left the Solar System, while Pioneer 10, Pioneer 11 and Voyager 2 are on course to leave it.
In general, planetary orbiters and landers return much more detailed and comprehensive information than fly-by missions. Space probes have been placed into orbit around all the five planets known to the ancients: first Mars (Mariner 9, 1971), then Venus (Venera 9, 1975; but landings on Venus and atmospheric probes were performed even earlier), Jupiter (Galileo, 1995), Saturn (Cassini/Huygens, 2004), and most recently Mercury (MESSENGER, March 2011), and have returned data about these bodies and their natural satellites.
The NEAR Shoemaker mission in 2000 orbited the large near-Earth asteroid 433 Eros, and was even successfully landed there, though it had not been designed with this maneuver in mind. The Japanese ion-drive spacecraft Hayabusa in 2005 also orbited the small near-Earth asteroid 25143 Itokawa, landing on it briefly and returning grains of its surface material to Earth. Another powerful ion-drive mission, Dawn, has orbited the large asteroid Vesta (July 2011–September 2012) and later moved on to the dwarf planet Ceres, arriving in March 2015.
Remotely controlled landers such as Viking, Pathfinder and the two Mars Exploration Rovers have landed on the surface of Mars and several Venera and Vega spacecraft have landed on the surface of Venus. The Huygens probe successfully landed on Saturn's moon, Titan.
No manned missions have been sent to any planet of the Solar System. NASA's Apollo program, however, landed twelve people on the Moon and returned them to Earth. The American Vision for Space Exploration, originally introduced by President George W. Bush and put into practice through the Constellation program, had as a long-term goal to eventually send human astronauts to Mars. However, on February 1, 2010, President Barack Obama proposed cancelling the program in Fiscal Year 2011. An earlier project which received some significant planning by NASA included a manned fly-by of Venus in the Manned Venus Flyby mission, but was cancelled when the Apollo Applications Program was terminated due to NASA budget cuts in the late 1960s.
Reasons for interplanetary travel.
The costs and risk of interplanetary travel receive a lot of publicity — spectacular examples include the malfunctions or complete failures of unmanned probes such as Mars 96, Deep Space 2 and Beagle 2 (the article List of Solar System probes gives a full list).
Many astronomers, geologists and biologists believe that exploration of the Solar System provides knowledge that could not be gained by observations from Earth's surface or from orbit around Earth. But they disagree about whether manned missions make a useful scientific contribution — some think robotic probes are cheaper and safer, while others argue that either astronauts advised by Earth-based scientists, or spacefaring scientists advised by Earth-based scientists, can respond more flexibly and intelligently to new or unexpected features of the region they are exploring.
Those who pay for such missions (primarily in the public sector) are more likely to be interested in benefits for themselves or for the human race as a whole. So far the only benefits of this type have been "spin-off" technologies which were developed for space missions and then were found to be at least as useful in other activities (NASA publicizes spin-offs from its activities).
Other practical motivations for interplanetary travel are more speculative, because our current technologies are not yet advanced enough to support test projects. But science fiction writers have a fairly good track record in predicting future technologies — for example geosynchronous communications satellites (Arthur C. Clarke) and many aspects of computer technology (Mack Reynolds).
Many science fiction stories (notably Ben Bova's Grand Tour stories) feature detailed descriptions of how people could extract minerals from asteroids and energy from sources including orbital solar panels (unhampered by clouds) and the very strong magnetic field of Jupiter. Some point out that such techniques may be the only way to provide rising standards of living without being stopped by pollution or by depletion of Earth's resources (for example peak oil).
Finally, colonizing other parts of the Solar System would prevent the whole human species from being exterminated by any one of a number of possible events (see Human extinction). One of these possible events is an asteroid impact like the one which may have resulted in the Cretaceous–Paleogene extinction event. Although various Spaceguard projects monitor the Solar System for objects that might come dangerously close to Earth, current asteroid deflection strategies are crude and untested. To make the task more difficult, carbonaceous chondrites are rather sooty and therefore very hard to detect. Although carbonaceous chondrites are thought to be rare, some are very large and the suspected "dinosaur-killer" may have been a carbonaceous chondrite.
Some scientists, including members of the Space Studies Institute, argue that the vast majority of mankind eventually will live in space and will benefit from doing this.
Economical travel techniques.
One of the main challenges in interplanetary travel is producing the very large velocity changes necessary to travel from one body to another in the Solar System.
Due to the Sun's gravitational pull, a spacecraft moving farther from the Sun will slow down, while a spacecraft moving closer will speed up. Also, since any two planets are at different distances from the Sun, the planet from which the spacecraft starts is moving around the Sun at a different speed than the planet to which the spacecraft is travelling (in accordance with Kepler's Third Law). Because of these facts, a spacecraft desiring to transfer to a planet closer to the Sun must decrease its speed with respect to the Sun by a large amount in order to intercept it, while a spacecraft traveling to a planet farther out from the Sun must increase its speed substantially. Then, if additionally the spacecraft wishes to enter into orbit around the destination planet (instead of just flying by it), it must match the planet's orbital speed around the Sun, usually requiring another large velocity change.
Simply doing this by brute force – accelerating in the shortest route to the destination and then matching the planet's speed – would require an extremely large amount of fuel. And the fuel required for producing these velocity changes has to be launched along with the payload, and therefore even more fuel is needed to put both the spacecraft and the fuel required for its interplanetary journey into orbit. Thus, several techniques have been devised to reduce the fuel requirements of interplanetary travel.
As an example of the velocity changes involved, a spacecraft travelling from low Earth orbit to Mars using a simple trajectory must first undergo a change in speed (also known as a delta-v), in this case an increase, of about 3.8 km/s. Then, after intercepting Mars, it must change its speed by another 2.3 km/s in order to match Mars' orbital speed around the Sun and enter an orbit around it. For comparison, launching a spacecraft into low Earth orbit requires a change in speed of about 9.5 km/s.
Hohmann transfers.
For many years economical interplanetary travel meant using the Hohmann transfer orbit. Hohmann demonstrated that the lowest energy route between any two orbits is an elliptical "orbit" which forms a tangent to the starting and destination orbits. Once the spacecraft arrives, a second application of thrust will re-circularize the orbit at the new location. In the case of planetary transfers this means directing the spacecraft, originally in an orbit almost identical to Earth's, so that the aphelion of the transfer orbit is on the far side of the Sun near the orbit of the other planet. A spacecraft traveling from Earth to Mars via this method will arrive near Mars orbit in approximately 8.5 months, but because the orbital velocity is greater when closer to the center of mass (i.e. the Sun) and slower when farther from the center, the spacecraft will be traveling quite slowly and a small application of thrust is all that is needed to put it into a circular orbit around Mars. If the manoeuver is timed properly, Mars will be "arriving" under the spacecraft when this happens.
The Hohmann transfer applies to any two orbits, not just those with planets involved. For instance it is the most common way to transfer satellites into geostationary orbit, after first being "parked" in low Earth orbit. However, the Hohmann transfer takes an amount of time similar to ½ of the orbital period of the outer orbit, so in the case of the outer planets this is many years – too long to wait. It is also based on the assumption that the points at both ends are massless, as in the case when transferring between two orbits around Earth for instance. With a planet at the destination end of the transfer, calculations become considerably more difficult.
Gravitational slingshot.
The gravitational slingshot technique uses the gravity of planets and moons to change the speed and direction of a spacecraft without using fuel. In typical example, a spacecraft is sent to a distant planet on a path that is much faster than what the Hohmann transfer would call for. This would typically mean that it would arrive at the planet's orbit and continue past it. However, if there is a planet between the departure point and the target, it can be used to bend the path toward the target, and in many cases the overall travel time is greatly reduced. A prime example of this are the two crafts of the Voyager program, which used slingshot effects to change trajectories several times in the outer Solar System. It is difficult to use this method for journeys in the inner part of the Solar System, although it is possible to use other nearby planets such as Venus or even the Moon as slingshots in journeys to the outer planets.
This maneuver can only change an object's velocity relative to a third, uninvolved object, – possibly the “centre of mass” or the Sun. There is no change in the velocities of the two objects involved in the maneuver relative to each other. The Sun cannot be used in a gravitational slingshot because it is stationary compared to rest of the Solar System, which orbits the Sun. It may be used to send a spaceship or probe into the galaxy because the Sun revolves around the center of the Milky Way.
Powered slingshot.
A powered slingshot is the use of a rocket engine at or around closest approach to a body (periapsis). The use at this point multiplies up the effect of the delta-v, and gives a bigger effect than at other times.
Fuzzy orbits.
Computers did not exist when Hohmann transfer orbits were first proposed (1925) and were slow, expensive and unreliable when gravitational slingshots were developed (1959). Recent advances in computing have made it possible to exploit many more features of the gravity fields of astronomical bodies and thus calculate even lower-cost trajectories. Paths have been calculated which link the Lagrange points of the various planets into the so-called Interplanetary Transport Network. Such "fuzzy orbits" use significantly less energy than Hohmann transfers but are often much slower. They may not offer much advantage for manned missions or for research missions, but may be useful for high-volume transport of low-value commodities if humanity develops a space-based economy.
Aerobraking.
Aerobraking uses the atmosphere of the target planet to slow down. It was first used on the Apollo program where the returning spacecraft did not enter Earth orbit
but instead used a S-shaped vertical descent profile (starting with an initially steep descent, followed by a leveling out, followed by a slight climb, followed by a return to a positive rate of descent continuing to splash-down in the ocean) through Earth's atmosphere to reduce its speed until the parachute system could be deployed enabling a safe landing. Aerobraking does not require a thick atmosphere – for example most Mars landers use the technique, and Mars' atmosphere is only about 1% as thick as Earth's.
Aerobraking converts the spacecraft's kinetic energy into heat, so it requires a heatshield to prevent the craft from burning up. As a result, aerobraking is only helpful in cases where the fuel needed to transport the heatshield to the planet is less than the fuel that would be required to brake an unshielded craft by firing its engines.
Improved propulsion technologies.
Several technologies have been proposed which both save fuel and provide significantly faster travel than Hohmann transfers. Most are still just theoretical, but the Deep Space 1 mission was a very successful test of an ion drive. These improved technologies focus on one or more of:
Besides making travel faster, such improvements would allow greater design "safety margins" by reducing the imperative to make spacecraft lighter.
Improved rocket concepts.
All rocket concepts are limited by the rocket equation, which sets the characteristic velocity available as a function of exhaust velocity and mass ratio, of initial ("M"0, including fuel) to final ("M"1, fuel depleted) mass. The main consequence is that mission velocities of more than a few times the velocity of the rocket motor exhaust (with respect to the vehicle) rapidly become impractical.
Nuclear thermal and solar thermal rockets.
In a nuclear thermal rocket or solar thermal rocket a working fluid, usually hydrogen, is heated to a high temperature, and then expands through a rocket nozzle to create thrust. The energy replaces the chemical energy of the reactive chemicals in a traditional rocket engine. Due to the low molecular mass and hence high thermal velocity of hydrogen these engines are at least twice as fuel efficient as chemical engines, even after including the weight of the reactor.
The US Atomic Energy Commission and NASA tested a few designs from 1959 to 1968. The NASA designs were conceived as replacements for the upper stages of the Saturn V launch vehicle, but the tests revealed reliability problems, mainly caused by the vibration and heating involved in running the engines at such high thrust levels. Political and environmental considerations make it unlikely such an engine will be used in the foreseeable future, since nuclear thermal rockets would be most useful at or near the Earth's surface and the consequences of a malfunction could be disastrous. Fission based thermal rocket concepts produce lower exhaust velocities than the electric and plasma concepts described below, and are less suitable except for applications requiring high thrust-to-weight ratio, as in planetary escape.
Electric propulsion.
Electric propulsion systems use an external source such as a nuclear reactor or solar cells to generate electricity, which is then used to accelerate a chemically inert propellant to speeds far higher than achieved in a chemical rocket. Such drives produce feeble thrust, and are therefore unsuitable for quick maneuvers or for launching from the surface of a planet. But they are so economical in their use of
reaction mass that they can keep firing continuously for days or weeks, while chemical rockets use up reaction mass so quickly that they can only fire for seconds or minutes. Even a trip to the Moon is long enough for an electric propulsion system to outrun a chemical rocket – the Apollo missions took 3 days in each direction.
NASA's Deep Space One was a very successful test of a prototype ion drive, which fired for a total of 678 days and enabled the probe to run down Comet Borrelly, a feat which would have been impossible for a chemical rocket. Dawn, the first NASA operational (i.e., non-technology demonstration) mission to use an ion drive for its primary propulsion, is currently on track to explore and orbit the large main-belt asteroids 1 Ceres and 4 Vesta. A more ambitious, nuclear-powered version was intended for an unmanned Jupiter mission, the Jupiter Icy Moons Orbiter (JIMO), originally planned for launch sometime in the next decade. Due to a shift in priorities at NASA that favored manned space missions, the project lost funding in 2005. A similar mission is currently under discussion as the US component of a joint NASA/ESA program for the exploration of Europa and Ganymede.
A NASA multi-center Technology Applications Assessment Team led from the Johnson Spaceflight Center, has as of January 2011 described "Nautilus-X", a concept study for a multi-mission space exploration vehicle useful for missions beyond low Earth orbit (LEO), of up to 24 months duration for a crew of up to six. Although Nautilus-X is adaptable to a variety of mission-specific propulsion units of various low-thrust, high specific impulse (Isp) designs, nuclear ion-electric drive is shown for illustrative purposes. It is intended for integration and checkout at the International Space Station (ISS), and would be suitable for deep-space missions from the ISS to and beyond the Moon, including Earth/Moon L1, Sun/Earth L2, near-Earth asteroidal, and Mars orbital destinations. It incorporates a reduced-g centrifuge providing artificial gravity for crew health to ameliorate the effects of long-term 0g exposure, and the capability to mitigate the space radiation environment.
Fission powered rockets.
The electric propulsion missions already flown, or currently scheduled, have used solar electric power, limiting their capability to operate far from the Sun, and also limiting their peak acceleration due to the mass of the electric power source. Nuclear-electric or plasma engines, operating for long periods at low thrust and powered by fission reactors, can reach speeds much greater than chemically powered vehicles.
Fusion rockets.
Fusion rockets, powered by nuclear fusion reactions, would "burn" such light element fuels as deuterium, tritium, or 3He. Because fusion yields about 1% of the mass of the nuclear fuel as released energy, it is energetically more favorable than fission, which releases only about 0.1% of the fuel's mass-energy. However, either fission or fusion technologies can in principle achieve velocities far higher than needed for Solar System exploration, and fusion energy still awaits practical demonstration on Earth.
One proposal using a fusion rocket was Project Daedalus. Another fairly detailed vehicle system, designed and optimized for crewed Solar System exploration, "Discovery II", based on the D3He reaction but using hydrogen as reaction mass, has been described by a team from NASA's Glenn Research Center. It achieves characteristic velocities of >300 km/s with an acceleration of ~1.7•10−3 "g", with a ship initial mass of ~1700 metric tons, and payload fraction above 10%.
Solar sails.
Solar sails rely on the fact that light reflected from a surface exerts pressure on the surface. The radiation pressure is small and decreases by the square of the distance from the Sun, but unlike rockets, solar sails require no fuel. Although the thrust is small, it continues as long as the Sun shines and the sail is deployed.
The original concept relied only on radiation from the Sun – for example in Arthur C. Clarke's 1965 story "Sunjammer". More recent light sail designs propose to boost the thrust by aiming ground-based lasers or masers at the sail. Ground-based lasers or masers can also help a light-sail spacecraft to "decelerate": the sail splits into an outer and inner section, the outer section is pushed forward and its shape is changed mechanically to focus reflected radiation on the inner portion, and the radiation focused on the inner section acts as a brake.
Although most articles about light sails focus on interstellar travel, there have been several proposals for their use within the Solar System.
Currently, the only spacecraft to use a solar sail as the main method of propulsion is IKAROS which was launched by JAXA on May 21, 2010. It has since been successfully deployed, and shown to be producing acceleration as expected. Many ordinary spacecraft and satellites also use solar collectors, temperature-control panels and Sun shades as light sails, to make minor corrections to their attitude and orbit without using fuel. A few have even had small purpose-built solar sails for this use (for example Eurostar E3000 geostationary communications satellites built by EADS Astrium).
Cyclers.
It is possible to put stations or spacecraft on orbits that cycle between different planets, for example a Mars cycler would synchronously cycle between Mars and Earth, with very little propellant usage to maintain the trajectory. Cyclers are conceptually a good idea, because massive radiation shields, life support and other equipment only need to be put onto the cycler trajectory once. A cycler could combine several roles: habitat (for example it could spin to produce an "artificial gravity" effect); mothership (providing life support for the crews of smaller spacecraft which hitch a ride on it). Cyclers could also possibly make excellent cargo ships for resupply of a colony.
Space elevator.
A space elevator is a theoretical structure that would transport material from a planet's surface into orbit. The idea is that, once the expensive job of building the elevator is complete, an indefinite number of loads can be transported into orbit at minimal cost. Even the simplest designs avoid the vicious circle of rocket launches from the surface, wherein the fuel needed to travel the last 10% of the distance into orbit must be lifted all the way from the surface, requiring even more fuel, and so on. More sophisticated space elevator designs reduce the energy cost per trip by using counterweights, and the most ambitious schemes aim to balance loads going up and down and thus make the energy cost close to zero. Space elevators have also sometimes been referred to as "beanstalks", "space bridges", "space lifts", "space ladders" and "orbital towers".
A terrestrial space elevator is beyond our current technology, although a lunar space elevator could theoretically be built using existing materials.
Skyhook.
A skyhook is a theoretical class of orbiting tether propulsion intended to lift payloads to high altitudes and speeds. Proposals for skyhooks include designs that employ tethers spinning at hypersonic speed for catching high speed payloads or high altitude aircraft and placing them in orbit. In addition, it has been suggested that the rotating skyhook is "not engineeringly feasible using presently available materials".
Using non-terrestrial resources.
Current space vehicles attempt to launch with all their fuel (propellants and energy supplies) on board that they will need for their entire journey, and current space structures are lifted from the Earth's surface. Non-terrestrial sources of energy and materials are mostly a lot further away, but most would not require lifting out of a strong gravity field and therefore should be much cheaper to use in space in the long term.
The most important non-terrestrial resource is energy, because it can be used to transform non-terrestrial materials into useful forms (some of which may also produce energy). At least two fundamental non-terrestrial energy sources have been proposed: solar-powered energy generation (unhampered by clouds), either directly by solar cells or indirectly by focusing solar radiation on boilers which produce steam to drive generators; and electrodynamic tethers which generate electricity from the powerful magnetic fields of some planets (Jupiter has a very powerful magnetic field).
Water ice would be very useful and is widespread on the moons of Jupiter and Saturn:
Oxygen is a common constituent of the moon's crust, and is probably abundant in most other bodies in the Solar System. Non-terrestrial oxygen would be valuable as a source of water ice only if an adequate source of hydrogen can be found. Possible uses include:
Unfortunately hydrogen, along with other volatiles like carbon and nitrogen, are much less abundant than oxygen in the inner Solar System.
Scientists expect to find a vast range of organic compounds in some of the planets, moons and comets of the outer Solar System, and the range of possible uses is even wider. For example methane can be used as a fuel (burned with non-terrestrial oxygen), or as a feedstock for petrochemical processes such as making plastics. And ammonia could be a valuable feedstock for producing fertilizers to be used in the vegetable gardens of orbital and planetary bases, reducing the need to lift food to them from Earth.
Even unprocessed rock may be useful as rocket propellant if mass drivers are employed.
Exotic propulsion.
See the spacecraft propulsion article for a discussion of a number of other technologies that could, in the medium to longer term, be the basis of interplanetary missions. Unlike the situation with interstellar travel, the barriers to fast interplanetary travel involve engineering and economics rather than any basic physics.
Design requirements for manned interplanetary travel.
Life support.
Life support systems must be capable of supporting human life for weeks, months or even years. A breathable atmosphere of at least 35 kPa (5psi) must be maintained, with adequate amounts of oxygen, nitrogen, and controlled levels of carbon dioxide, trace gases and water vapor.
In October 2015, the NASA Office of Inspector General issued a health hazards report related to human spaceflight, including a human mission to Mars.
Radiation.
Once a vehicle leaves low Earth orbit and the protection of Earth's magnetosphere, it enters the Van Allen radiation belt, a region of high radiation. Once through there the radiation drops to lower levels, with a constant background of high energy cosmic rays which pose a health threat. These are dangerous over periods of years to decades.
Scientists of Russian Academy of Sciences are searching for methods of reducing the risk of radiation-induced cancer in preparation for the mission to Mars. They consider as one of the options a life support system generating drinking water with low content of deuterium (a stable isotope of hydrogen) to be consumed by the crew members. Preliminary investigations have shown that deuterium-depleted water features certain anti-cancer effects. Hence, deuterium-free drinking water is considered to have the potential of lowering the risk of cancer caused by extreme radiation exposure of the Martian crew.
In addition, coronal mass ejections from the Sun are highly dangerous, and are fatal within a very short timescale to humans unless they are protected by massive shielding.
Reliability.
Any major failure to a spacecraft en route is likely to be fatal, and even a minor one could have dangerous results if not repaired quickly, something difficult to accomplish in open space. The crew of the Apollo 13 mission survived despite an explosion caused by a faulty oxygen tank (1970); the crews of Soyuz 11 (1971), the Space Shuttles Challenger (1986) and Columbia (2003) were killed by malfunctions of their vessels' components.
Launch windows.
For astrodynamics reasons, cheap spacecraft travel to other planets is only practical within certain time windows. Outside these windows the planets are essentially inaccessible from Earth with current technology. This constrains flights and prevents rescue in an emergency.

</doc>
<doc id="15112" url="https://en.wikipedia.org/wiki?curid=15112" title="Interference (wave propagation)">
Interference (wave propagation)

In physics, interference is a phenomenon in which two waves superpose to form a resultant wave of greater, lower, or the same amplitude. Interference usually refers to the interaction of waves that are correlated or coherent with each other, either because they come from the same source or because they have the same or nearly the same frequency. Interference effects can be observed with all types of waves, for example, light, radio, acoustic, surface water waves or matter waves.
Mechanism.
The principle of superposition of waves states that when two or more propagating waves of same type are incident on the same point, the total displacement at that point is equal to the pointwise sum of the displacements of the individual waves. If a crest of a wave meets a crest of another wave of the same frequency at the same point, then the magnitude of the displacement is the sum of the individual magnitudes – this is constructive interference. If a crest of one wave meets a trough of another wave then the magnitude of the displacements is equal to the difference in the individual magnitudes – this is known as destructive interference.
Constructive interference occurs when the phase difference between the waves is a multiple of 2π, whereas destructive interference occurs when the difference is an odd multiple of π. If the difference between the phases is intermediate between these two extremes, then the magnitude of the displacement of the summed waves lies between the minimum and maximum values.
Consider, for example, what happens when two identical stones are dropped into a still pool of water at different locations. Each stone generates a circular wave propagating outwards from the point where the stone was dropped. When the two waves overlap, the net displacement at a particular point is the sum of the displacements of the individual waves. At some points, these will be in phase, and will produce a maximum displacement. In other places, the waves will be in anti-phase, and there will be no net displacement at these points. Thus, parts of the surface will be stationary—these are seen in the figure above and to the right as stationary blue-green lines radiating from the center.
Between two plane waves.
A simple form of interference pattern is obtained if two plane waves of the same frequency intersect at an angle. 
Interference is essentially an energy redistribution process. The energy which is lost at the destructive interference is regained at the constructive interference.
One wave is travelling horizontally, and the other is travelling downwards at an angle θ to the first wave. Assuming that the two waves are in phase at the point B, then the relative phase changes along the "x"-axis. The phase difference at the point A is given by
It can be seen that the two waves are in phase when
and are half a cycle out of phase when
Constructive interference occurs when the waves are in phase, and destructive interference when they are half a cycle out of phase. Thus, an interference fringe pattern is produced, where the separation of the maxima is
and is known as the fringe spacing. The fringe spacing increases with increase in wavelength, and with decreasing angle .
The fringes are observed wherever the two waves overlap and the fringe spacing is uniform throughout.
Between two spherical waves.
A point source produces a spherical wave. If the light from two point sources overlaps, the interference pattern maps out the way in which the phase difference between the two waves varies in space. This depends on the wavelength and on the separation of the point sources. The figure to the right shows interference between two spherical waves. The wavelength increases from top to bottom, and the distance between the sources increases from left to right.
When the plane of observation is far enough away, the fringe pattern will be a series of almost straight lines, since the waves will then be almost planar.
Multiple beams.
Interference occurs when several waves are added together provided that the phase differences between them remain constant over the observation time.
It is sometimes desirable for several waves of the same frequency and amplitude to sum to zero (that is, interfere destructively, cancel). This is the principle behind, for example, 3-phase power and the diffraction grating. In both of these cases, the result is achieved by uniform spacing of the phases.
It is easy to see that a set of waves will cancel if they have the same amplitude and their phases are spaced equally in angle. Using phasors, each wave can be represented as formula_5 for formula_6 waves from formula_7 to formula_8, where
To show that
one merely assumes the converse, then multiplies both sides by formula_11
The Fabry–Pérot interferometer uses interference between multiple reflections.
A diffraction grating can be considered to be a multiple-beam interferometer, since the peaks which it produces are generated by interference between the light transmitted by each of the elements in the grating; see interference vs. diffraction for further discussion.
Optical interference.
Because the frequency of light waves (~1014 Hz) is too high to be detected by currently available detectors, it is possible to observe only the intensity of an optical interference pattern. The intensity of the light at a given point is proportional to the square of the average amplitude of the wave. This can be expressed mathematically as follows. The displacement of the two waves at a point is:
where represents the magnitude of the displacement, represents the phase and represents the angular frequency.
The displacement of the summed waves is
The intensity of the light at is given by
This can be expressed in terms of the intensities of the individual waves as
Thus, the interference pattern maps out the difference in phase between the two waves, with maxima occurring when the phase difference is a multiple of 2π. If the two beams are of equal intensity, the maxima are four times as bright as the individual beams, and the minima have zero intensity.
The two waves must have the same polarization to give rise to interference fringes since it is not possible for waves of different polarizations to cancel one another out or add together. Instead, when waves of different polarization are added together, they give rise to a wave of a different polarization state.
Light source requirements.
The discussion above assumes that the waves which interfere with one another are monochromatic, i.e. have a single frequency—this requires that they are infinite in time. This is not, however, either practical or necessary. Two identical waves of finite duration whose frequency is fixed over that period will give rise to an interference pattern while they overlap. Two identical waves which consist of a narrow spectrum of frequency waves of finite duration, will give a series of fringe patterns of slightly differing spacings, and provided the spread of spacings is significantly less than the average fringe spacing, a fringe pattern will again be observed during the time when the two waves overlap.
Conventional light sources emit waves of differing frequencies and at different times from different points in the source. If the light is split into two waves and then re-combined, each individual light wave may generate an interference pattern with its other half, but the individual fringe patterns generated will have different phases and spacings, and normally no overall fringe pattern will be observable. However, single-element light sources, such as sodium- or mercury-vapor lamps have emission lines with quite narrow frequency spectra. When these are spatially and colour filtered, and then split into two waves, they can be superimposed to generate interference fringes. All interferometry prior to the invention of the laser was done using such sources and had a wide range of successful applications.
A laser beam generally approximates much more closely to a monochromatic source, and it is much more straightforward to generate interference fringes using a laser. The ease with which interference fringes can be observed with a laser beam can sometimes cause problems in that stray reflections may give spurious interference fringes which can result in errors.
Normally, a single laser beam is used in interferometry, though interference has been observed using two independent lasers whose frequencies were sufficiently matched to satisfy the phase requirements.
Optical arrangements.
To generate interference fringes, light from the source has to be divided into two waves which have then to be re-combined. Traditionally, interferometers have been classified as either amplitude-division or wavefront-division systems.
In an amplitude-division system, a beam splitter is used to divide the light into two beams travelling in different directions, which are then superimposed to produce the interference pattern. The Michelson interferometer and the Mach-Zehnder interferometer are examples of amplitude-division systems.
In wavefront-division systems, the wave is divided in space—examples are Young's double slit interferometer and Lloyd's mirror.
Interference can also be seen in everyday phenomena such as iridescence and structural coloration. For example, the colours seen in a soap bubble arise from interference of light reflecting off the front and back surfaces of the thin soap film. Depending on the thickness of the film, different colours interfere constructively and destructively.
Applications.
Optical interferometry.
Interferometry has played an important role in the advancement of physics, and also has a wide range of applications in physical and engineering measurement.
Thomas Young's double slit interferometer in 1803 demonstrated interference fringes when two small holes were illuminated by light from another small hole which was illuminated by sunlight. Young was able to estimate the wavelength of different colours in the spectrum from the spacing of the fringes. The experiment played a major role in the general acceptance of the wave theory of light. 
In quantum mechanics, this experiment is considered to demonstrate the inseparability of the wave and particle natures of light and other quantum particles (wave–particle duality). Richard Feynman was fond of saying that all of quantum mechanics can be gleaned from carefully thinking through the implications of this single experiment.
The results of the Michelson–Morley experiment, are generally considered to be the first strong evidence against the theory of a luminiferous aether and in favor of special relativity.
Interferometry has been used in defining and calibrating length standards. When the metre was defined as the distance between two marks on a platinum-iridium bar, Michelson and Benoît used interferometry to measure the wavelength of the red cadmium line in the new standard, and also showed that it could be used as a length standard. Sixty years later, in 1960, the metre in the new SI system was defined to be equal to 1,650,763.73 wavelengths of the orange-red emission line in the electromagnetic spectrum of the krypton-86 atom in a vacuum. This definition was replaced in 1983 by defining the metre as the distance travelled by light in vacuum during a specific time interval. Interferometry is still fundamental in establishing the calibration chain in length measurement.
Interferometry is used in the calibration of slip gauges (called gauge blocks in the US) and in coordinate-measuring machines. It is also used in the testing of optical components.
Radio interferometry.
In 1946, a technique called astronomical interferometry was developed. Astronomical radio interferometers usually consist either of arrays of parabolic dishes or two-dimensional arrays of omni-directional antennas. All of the telescopes in the array are widely separated and are usually connected together using coaxial cable, waveguide, optical fiber, or other type of transmission line. Interferometry increases the total signal collected, but its primary purpose is to vastly increase the resolution through a process called Aperture synthesis. This technique works by superposing (interfering) the signal waves from the different telescopes on the principle that waves that coincide with the same phase will add to each other while two waves that have opposite phases will cancel each other out. This creates a combined telescope that is equivalent in resolution (though not in sensitivity) to a single antenna whose diameter is equal to the spacing of the antennas furthest apart in the array.
Acoustic interferometry.
An acoustic interferometer is an instrument for measuring the physical characteristics of sound wave in a gas or liquid. It may be used to measure velocity, wavelength, absorption, or impedance. A vibrating crystal creates the ultrasonic waves that are radiated into the medium. The waves strike a reflector placed parallel to the crystal. The waves are then reflected back to the source and measured.
Quantum interference.
If a system is in state formula_17, its wavefunction is described in Dirac or bra–ket notation as:
where the formula_19s specify the different quantum "alternatives" available (technically, they form an eigenvector basis) and the formula_20 are the probability amplitude coefficients, which are complex numbers.
The probability of observing the system making a transition or quantum leap from state formula_17 to a new state formula_22 is the square of the modulus of the scalar or inner product of the two states:
where formula_25 (as defined above) and similarly formula_26 are the coefficients of the final state of the system. * is the complex conjugate so that formula_27, etc.
Now let's consider the situation classically and imagine that the system transited from formula_28 to formula_29 via an intermediate state formula_30. Then we would "classically" expect the probability of the two-step transition to be the sum of all the possible intermediate steps. So we would have
The classical and quantum derivations for the transition probability differ by the presence, in the quantum case, of the extra terms formula_33; these extra quantum terms represent "interference" between the different formula_34 intermediate "alternatives". These are consequently known as the quantum interference terms, or cross terms. This is a purely quantum effect and is a consequence of the non-additivity of the probabilities of quantum alternatives.
The interference terms vanish, via the mechanism of quantum decoherence, if the intermediate state formula_19 is measured or coupled with the environment.

</doc>
<doc id="15114" url="https://en.wikipedia.org/wiki?curid=15114" title="Indictable offence">
Indictable offence

In many common law jurisdictions (e.g. England and Wales, Ireland, Canada, Hong Kong, India, Australia, New Zealand), an indictable offence is an offence which can only be tried on an indictment after a preliminary hearing to determine whether there is a "prima facie" case to answer or by a grand jury (in contrast to a summary offence). In the United States, a crime of similar severity and rules is called a felony, which also requires an indictment.
England and Wales.
In relation to England and Wales, the expression "indictable offence" means an offence which, if committed by an adult, is triable on indictment, whether it is exclusively so triable or triable either way; and the term "indictable", in its application to offences, is to be construed accordingly. In this definition, references to the way or ways in which an offence is triable are to be construed without regard to the effect, if any, of section 22 of the Magistrates' Courts Act 1980 on the mode of trial in a particular case.
An either way offence allows the defendant to elect between trial by jury on indictment in the Crown Court and summary trial in a magistrates' court. However, the election may be overruled by the magistrates' court if the facts suggest that the sentencing powers of a magistrates' court would be inadequate to reflect the seriousness of the offence. 
In relation to some indictable offences, for example criminal damage, only summary trial is available unless the damage caused exceeds £5,000. 
A youth court has jurisdiction to try all indictable offences with the exception of homicide and certain firearms offences, and will normally do so provided that the available sentencing power of two years detention is adequate to punish the offender if found guilty.
History
See section 64 of the Criminal Law Act 1977. 
Grand juries were abolished in 1933.
Offences triable only on indictment.
Some offences such as murder and rape are considered so serious that they can only be tried on indictment at the Crown Court where the widest range of sentencing powers is available to the judge.
The expression indictable-only offence was defined by section 51(1) of the Crime and Disorder Act 1998, as originally enacted, as an offence triable only on indictment. Sections 51 and 52 of, and Schedule 3 to, that Act abolished committal proceedings for such offences and made other provisions in relation to them.
When the accused is charged with an indictable only offence, he or she will be tried in the Crown Court. The rules are different in England and Wales in respect of those under 18 years of age.
See also section 14(a) of the Criminal Law Act 1977.
New Zealand.
Similarly in New Zealand, a rape or murder charge will be tried at the High Court, while less serious offences such as theft, will be tried at the District Court. However, the District Court can hold both jury and summary trials.
Canada.
For differences between indictable offences and summary offences see summary offences.

</doc>
<doc id="15116" url="https://en.wikipedia.org/wiki?curid=15116" title="Inter Milan">
Inter Milan

F.C. Internazionale Milano, commonly referred to as Internazionale () or simply Inter, and colloquially known as Inter Milan or Inter Milano outside of Italy, is a professional Italian football club based in Milan, Lombardy. The club have played continuously in the top tier of the Italian football league system since its debut in 1909.
Inter have won 30 domestic trophies, including eighteen league titles, seven Coppa Italia and five Supercoppa Italiana. From 2006 to 2010, the club won five successive league titles, equalling the all-time record. They have won the Champions League three times: two back-to-back in 1964 and 1965 and then another in 2010. Their latest win completed an unprecedented Italian seasonal treble, with Inter winning the Coppa Italia and the Scudetto the same year. The club has also won three UEFA Cups, two Intercontinental Cups and one FIFA Club World Cup.
Inter's home games are played at the San Siro stadium, also known as the "Stadio Giuseppe Meazza". The stadium, which is shared with rivals A.C. Milan, is the largest in Italian football, with a total capacity of 80,018. The local team A.C. Milan are considered among their biggest rivals, and matches between the two teams, known as the Derby della Madonnina, are one of the most followed derbies in football. As of 2010, Inter is the second-most supported team in Italy, and the sixth most-supported team in Europe. The club is one of the most valuable in Italian and world football. It was a founding member of the now-defunct G-14 group of Europe's leading football clubs.
History.
Foundation and early years (1908–1960).
The club was founded on 9 March 1908 as "Football Club Internazionale", following the schism with the Milan Cricket and Football Club (now A.C. Milan). The name of the club derives from the wish of its founding members to accept foreign players as well as Italians.
The club won its very first championship in 1910 and its second in 1920. The captain and coach of the first championship winning team was Virgilio Fossati, who was later killed in battle while serving in the Italian army during World War I.
In 1922 Inter remained in the top league after winning two play-offs. Six years later, during the Fascist era, the club was forced to merge with the "Unione Sportiva Milanese" and was renamed "Società Sportiva Ambrosiana". The team wore white jerseys around this time with a red cross emblazoned on it. The jersey's design was inspired by the flag and coat of arms of the city of Milan. In 1929 the club's president, Oreste Simonotti, changed the club's name to "Associazione Sportiva Ambrosiana". However, supporters continued to call the team "Inter", and in 1931 new president Pozzani caved in to shareholder pressure and changed the name to "Associazione Sportiva Ambrosiana-Inter".
Their first Coppa Italia (Italian Cup) was won in 1938–39, led by the iconic Giuseppe Meazza, after whom the San Siro stadium is officially named. A fifth championship followed in 1940, despite Meazza incurring an injury. After the end of World War II the club regained its original name, winning its sixth championship in 1953 and its seventh in 1954.
Grande Inter (1960–1968).
In 1960, manager Helenio Herrera joined Inter from Barcelona, bringing with him his midfield general Luis Suárez, who won the European Footballer of the Year in the same year for his role in Barcelona's La Liga/Fairs Cup double. He would transform Inter into one of the greatest teams in Europe. He modified a 5–3–2 tactic known as the ""Verrou"" ("door bolt") to include larger flexibility for counterattacks. The "catenaccio" system was invented by an Austrian coach named Karl Rappan. Rappan's original system was implemented with four fixed defenders, playing a strict man-to-man marking system, plus a playmaker in the middle of the field who plays the ball together with two midfield wings. Herrera would modify it by adding a fifth defenders, the sweeper or libero behind the two centre backs. The sweeper or libero who acted as the free man would deal with any attackers who went through the two centre backs. Inter finished third in the Serie A in his first season, second the next year and first in his third season. Then followed a back-to-back European Cup victory in 1964 and 1965, earning him the title ""il Mago"" ("the Wizard"). The code of Herrera's team was the fullbacks Tarcisio Burgnich and Giacinto Facchetti, Armando Picchi the sweeper, Suárez the playmaker, Jair the winger, Mario Corso the left midfielder, and Sandro Mazzola, who played on the inside-right.
In 1964, Inter reached the European Cup Final by beating Borussia Dortmund in the semifinal and FK Partizan in the quarter-final. In the final, they met Real Madrid, a team that had reached seven out of the nine finals to date. Mazzola scored two goals in a 3–1 victory, and then the team won the Intercontinental Cup against Independiente. A year later, Inter repeated the feat by beating two-time winner Benfica in the final held at home, from a Jair goal, and then again beat Independiente in the Intercontinental Cup.
In 1967, with Jair gone and Suárez injured, Inter lost the European Cup Final 2–1 to Celtic. During that year the club changed its name to "Football Club Internazionale Milano".
After Helenio Herrera era (1968–1990).
Following the golden era of the 1960s, Inter managed to win their eleventh league title in 1971 and their twelfth in 1980. Inter were defeated for the second time in five years in the final of the European Cup, going down 0–2 to Johan Cruyff's Ajax in 1972. During the 1970s and the 1980s, Inter also added two to its Coppa Italia tally, in 1977–78 and 1981–82.
Led by the German duo of Andreas Brehme and Lothar Matthäus, and Argentine Ramón Díaz, Inter captured the 1989 Serie A championship. Fellow German Jürgen Klinsmann and the Supercoppa Italiana were added the following season but to little avail, as Inter were unable to defend their title.
Mixed fortunes (1990–2004).
The 1990s was a period of disappointment. While their great rivals Milan and Juventus were achieving success both domestically and in Europe, Inter were left behind, with repeated mediocre results in the domestic league standings, their worst coming in 1993–94 when they finished just one point out of the relegation zone. Nevertheless, they achieved some European success with three UEFA Cup victories in 1991, 1994 and 1998.
With Massimo Moratti's takeover from Ernesto Pellegrini in 1995, Inter twice broke the world record transfer fee in this period (£19.5 million for Ronaldo from Barcelona in 1997 and £31 million for Christian Vieri from Lazio two years later). However, the 1990s remained a decade of disappointment, and is the only decade in Inter's history in which they did not win a single Italian Serie A championship. For Inter fans, it was difficult to find who in particular was to blame for the troubled times and this led to some icy relations between them and the president, the managers and even some individual players.
Moratti later became a target of the fans, especially when he sacked the much-loved coach Luigi Simoni after only a few games into the 1998–99 season, after having just received Italian manager of the year award 1998 the day before being dismissed. That season, Inter failed to qualify for any European competition for the first time in almost ten years, finishing in eighth place.
The following season, Moratti appointed former Juventus manager Marcello Lippi, and signed players such as Angelo Peruzzi and Laurent Blanc together with other former Juventus players Vieri and Vladimir Jugović. The team came close to their first domestic success since 1989 when they reached the Coppa Italia final only to be defeated by Lazio.
During the following season, another disaster struck. Inter impressed in the Supercoppa Italiana match against Lazio and took the lead through new signing Robbie Keane and Hakan Şükür—however, they lost 4–3. They were eliminated in the preliminary round of the Champions League by Swedish club Helsingborgs IF, Álvaro Recoba missing a crucial late penalty. Lippi was sacked after only a single game of the new season following Inter's first ever Serie A defeat to Reggina. Marco Tardelli, chosen to replace Lippi, failed to improve results, and is remembered by Inter fans as the manager that lost 6–0 the city derby to Milan in the 2000–01 season. Other members of the Inter "family" during this period that suffered were the likes of Vieri and Fabio Cannavaro, both of whom had their restaurants in Milan vandalised after defeats against the "Rossoneri".
In 2002, not only did Inter manage to make it to the UEFA Cup semi-finals, they were also only 45 minutes away from capturing the Scudetto, when they needed to maintain a one-goal advantage away at over Lazio. Inter were 2–1 up after only 24 minutes. Lazio equalised during first half injury time and then scored two more goals in the second half to clinch victory that eventually saw Juventus win the championship. The next season, Inter finished as league runners-up and also managed to make it to the 2002–03 Champions League semi-finals against Milan, losing on the away goals rule.
Resurrection and recent history (2004–2008).
Revival (2004–2008).
On 1 July 2004, Inter appointed former Lazio boss Roberto Mancini as its new head coach. In his first season, the team collected 72 points from 18 wins, 18 draws and only two losses, as well as winning the Coppa Italia and later the Supercoppa Italiana. On 11 May 2006, Inter retained their Coppa Italia title once again after defeating Roma with a 4–1 aggregate victory (a 1–1 scoreline in Rome and a 3–1 win at the San Siro).
Inter were awarded the 2005–06 Serie A championship after points were stripped from Juventus and Milan due to the match fixing scandal that year. During the following season, Inter went on a record-breaking run of 17 consecutive victories in Serie A, starting on 25 September 2006 with a 4–1 home victory over Livorno, and ending on 28 February 2007, after a 1–1 draw at home to Udinese. On 22 April 2007, Inter won their second consecutive "Scudetto"—and first on the field since 1989—when they defeated Siena 2–1 at Stadio Artemio Franchi. Italian World Cup-winning defender Marco Materazzi scored both goals.
Inter started the 2007–08 season with the goal of winning both Serie A and Champions League. The team started well in the league, topping the table from the first round of matches, and also managed to qualify for the Champions League knockout stage. However, a late collapse, leading to a 2–0 defeat with ten men away to Liverpool on 19 February in the Champions League, threw into question manager Roberto Mancini's future at Inter, and domestic form took a sharp turn of fortune with the team failing to win in the three following Serie A games. After being eliminated by Liverpool in the Champions League, Mancini then announced his intention to leave his job, only to change his mind the following day. On the final day of the 2007–08 Serie A season, Inter played Parma away, and two goals from Zlatan Ibrahimović sealed their third consecutive championship. Mancini, however, was sacked soon after due to his previous announcement to leave the club.
Recent history (2008–present).
On 2 June 2008, Inter appointed former Porto and Chelsea boss José Mourinho as new head coach. In his first season, the "Nerazzurri" won a Suppercoppa Italiana and a fourth consecutive title, though falling in the Champions League in the first knockout round for a third-straight year, losing to eventual finalist Manchester United. In winning the league title for the fourth consecutive time, Inter joined Torino and Juventus as the only teams to do this and the first to accomplish this feat in the last 60 years.
Inter enjoyed more luck in the 2009–10 Champions League, defeating reigning champions Barcelona in the semi-final, and then defeating Bayern Munich 2–0 in the final with two goals from Diego Milito. Inter also won the 2009–10 Serie A title by two points over Roma, and the 2010 Coppa Italia by defeating the same side 1–0 in the final. This made Inter the first Italian team to win Treble, but at the end of the season, Mourinho left the club manage Real Madrid; he was replaced by Rafael Benítez.
On 21 August 2010, Inter defeated Roma 3–1 and won the 2010 Supercoppa Italiana, their fourth trophy of the year. In December 2010, they claimed the FIFA Club World Cup for the first time after a 3–0 win against TP Mazembe in the final. Inter thus completed "Quintuple", becoming the fourth team in the world to do so, after Liverpool in 2001, Al-Ahly in 2006 and Barcelona in 2009. However, after this win, on 23 December 2010, due to his poor performance in Serie A and separated by 13 points from the leader Milan (although Inter played two games less, because of the FIFA Club World Cup appointment), the team announced Benítez's departure. He was replaced by Leonardo the following day.
Leonardo started with 30 points from 12 games, with an average of 2.5 points per game, better than his predecessors Benítez and Mourinho. On 6 March 2011, Leonardo set a new Italian Serie A record by collecting 33 points in 13 games; the previous record was 32 points in 13 games made by Fabio Capello in the 2004–05 season. Leonardo led the club to the quarter-finals of the Champions League before losing to Schalke 04, and leading them to Coppa Italia title. At the end of the season, however, he resigned and was followed by not-so-successful new managers Gian Piero Gasperini, Claudio Ranieri and Andrea Stramaccioni.
On 1 August 2012, Moratti sold a minority interests of Inter Milan to a Chinese consortium led by Kenneth Huang. On the same day, Inter announced an agreement was formed with China Railway Construction Corporation Limited for a new stadium project. On 30 June 2013, Moratti's Internazionale Holding S.r.l. held 98.2% shares of F.C. Internazionale Milano S.p.A.; the deal with the Chinese apparently collapsed.
On 15 October 2013, an Indonesian consortium (International Sports Capital HK Ltd.) led by Erick Thohir, Handy Soetedjo and Rosan Roeslani, signed an agreement to acquire 70% of Inter shares from Internazionale Holding S.r.l. by contributing the capital increases of Inter triggered by a net loss of €79,881,808. Immediately after the deal, Moratti's Internazionale Holding S.r.l. still retained 29.5% of the shares of F.C. Internazionale Milano S.p.A. Thohir also co-owns Major League Soccer (MLS) club D.C. United and Indonesia Super League (ISL) club Persib Bandung ; on 2 December 2013, Inter and D.C. United then formally announced a strategic partnership and in January 2016 Inter and Persib then formally announced a strategic partnership. After the deal, the shares of Inter was owned by a chain of holding companies, namely International Sports Capital S.p.A. of Italy, International Sports Capital HK Limited and Asian Sports Ventures HK Limited of Hong Kong.
Colours and badge.
One of the founders of Inter, a painter named Giorgio Muggiani, was responsible for the design of the first Inter logo in 1908. The first design incorporated the letters "FCIM" in the centre of a series of circles that formed the badge of the club. The basic elements of the design have remained constant even as finer details have been modified over the years. Starting at the 1999–00 season, the original club crest was reduced in size, to give place for the addition of the club's name and foundation year at the upper and lower part of the logo respectively.
In 2007, the logo was returned to the pre-1999–2000 era. It was given a more modern look with smaller Scudetto star and lighter color scheme. This version was used until July 2014, when the club decided to undertake a rebranding. The most significant difference between the current and the previous logo is the omission of the star from other media except match kits.
Since its founding in 1908, Inter have worn black and blue stripes. It is rumoured that black was chosen to represent night and blue was chosen to represent the sky. Aside from a short period during World War II, Inter continued to wear the black and blue stripes, earning them the nickname "Nerazzurri".
For a period of time, however, Inter was forced to abandon their black and blue uniforms. In 1928, Inter's name and philosophy made the ruling Fascist Party uneasy. As a result, during the same year the 20-year-old club was merged with "Unione Sportiva Milanese". The new club was named "Società Sportiva Ambrosiana" after the patron saint of Milan. The flag of Milan (the red cross on white background) replaced the traditional black and blue. After World War II, when the Fascists had fallen from power, the club reverted to their original name and colours. In 2008, Inter celebrated their centenary with a red cross on their away shirt. The cross is reminiscent of the flag of their city, and they continue to use the pattern on their third kit.
Animals are often used to represent football clubs in Italy—the grass snake, called "Il biscione" or "Serpente", represents Inter. The snake is an important symbol for the city of Milan, appearing often in Milanese heraldry as a coiled viper with a man in its jaws. The symbol is famous for its presence on the coat of arms of the House of Sforza (which ruled over Italy from Milan during the Renaissance period), the city of Milan, the historical Duchy of Milan (a 400-year state of the Holy Roman Empire) and Insubria (a historical region the city of Milan falls within). For the 2010–11 season, Inter's away kit featured the serpent.
Stadium.
The team's stadium is the 80,018 seat San Siro, officially known as the "Stadio Giuseppe Meazza" after the former player who represented both Milan and Inter. The more commonly used name, "San Siro", is the name of the district where it is located. San Siro has been the home of Milan since 1926, when it was privately built by funding from Milan's president at the time, Piero Pirelli. Construction was performed by 120 workers, and took 13 and a half months to complete. The stadium was owned by the club until it was sold to the city council in 1935, and since 1947 it has been shared with Inter, when they were accepted as joint tenant.
The first game played at the stadium was on 19 September 1926, when Inter beat Milan 6–3 in a friendly match. Milan played its first league game in San Siro on 19 September 1926, losing 1–2 to Sampierdarenese. From an initial capacity of 35,000 spectators, the stadium has undergone several major renovations, most recently in preparation for the 1990 FIFA World Cup when its capacity was set to 85,700, all covered with a polycarbonate roof. In the summer of 2008, its capacity was reduced to 80,018 to meet the new standards set by UEFA.
Based on the English model for stadiums, San Siro is specifically designed for football matches, as opposed to many multi-purpose stadiums used in Serie A. It is therefore renowned in Italy for its fantastic atmosphere during matches owing to the closeness of the stands to the pitch. The frequent use of flares by supporters contributes to the atmosphere, but the practice has occasionally also caused problems.
Supporters and rivalries.
Inter is one of the most supported clubs in Italy, according to an August 2007 research by Italian newspaper "La Repubblica." Historically, the largest section of Inter fans from the city of Milan were the middle-class bourgeoisie Milanese, while Milan fans were typically working-class.
The traditional ultras group of Inter is "Boys San"; they hold a significant place in the history of the ultras scene in general due to the fact that they are one of the oldest, being founded in 1969. Politically, the ultras of Inter are usually considered right-wing and they have good relationships with the Lazio ultras. As well as the main group of "Boys San", there are four more significant groups: "Viking", "Irriducibili", "Ultras", and "Brianza Alcoolica".
Inter's most vocal fans are known to gather in the Curva Nord, or north curve of the Giuseppe Meazza stadium. This longstanding tradition has led to the Curva Nord being synonymous with the club's most die-hard supporters, who unfurl banners and wave flags in support of their team.
Inter have several rivalries, two of which are highly significant in Italian football; firstly, they participate in the intra city "Derby della Madonnina" with Milan; the rivalry has existed ever since Inter splintered off from Milan in 1908. The name of the derby refers to the Blessed Virgin Mary, whose statue atop the Milan Cathedral is one of the city's main attractions. The match usually creates a lively atmosphere, with numerous (often humorous or offensive) banners unfolded before the match. Flares are commonly present, but they also led to the abandonment of the second leg of the 2004–05 Champions League quarter-final matchup between Milan and Inter on 12 April after a flare thrown from the crowd by an Inter supporter struck Milan keeper Dida on the shoulder.
The other most significant rivalry is with Juventus; the two participate in the "Derby d'Italia". Up until the 2006 Italian football scandal, which saw Juventus relegated, the two were the only Italian clubs to have never played below Serie A. In recent years, post-Calciopoli, Inter have developed a rivalry with Roma, having finished runners-up to Inter in all but one of Inter's five Scudetto winning seasons between 2005 and 2010. The two sides have also contested in 5 Coppa Italia finals and four Supercoppa Italiana finals since 2006. Other clubs, like Atalanta and Napoli, are also considered amongst their rivals.
Their supporters collectively go by "Interisti," or "Nerazzurri."
Players.
Retired numbers.
3 – Giacinto Facchetti, left back, 1960–1978 "(posthumous honour)". The number was retired on 8 September 2006. The last player to wear the shirt was Argentinian center back Nicolás Burdisso, who took on the number 16 shirt for the rest of the season.
4 – Javier Zanetti, defensive midfielder, played 858 games for Inter between 1995 and his retirement in the summer of 2014. Club president Erick Thohir confirmed that Zanetti's number 4 was to be retired out of respect.
Presidents and managers.
Presidential history.
Below is a list of Inter presidents from 1908 until the present day.
Managerial history.
Below is a list of Inter coaches from 1909 until the present day.
Honours.
Inter have won 30 domestic trophies, including the league 18 times, the Coppa Italia seven and the Supercoppa Italiana five. From 2006 to 2010, the club won five successive league titles, equalling the all-time record. They have won the Champions League three times: two back-to-back in 1964 and 1965 and then another in 2010; the last completed an unprecedented Italian treble with the Coppa Italia and the "Scudetto". The club has also won three UEFA Cups, two Intercontinental Cups and one FIFA Club World Cup.
Club statistics and records.
Javier Zanetti holds the records for both total appearances and Serie A appearances for Inter, with 838 official games played in total and 600 in Serie A (as of 14 March 2013).
Giuseppe Meazza is Inter's all-time top goalscorer, with 284 goals in 408 games. Behind him, in second place, is Alessandro Altobelli with 209 goals in 466 games, and Roberto Boninsegna in third place, with 171 goals over 281 games.
Helenio Herrera had the longest reign as Inter coach, with nine years (eight consecutive) in charge, and is the most successful coach in Inter history with three "Scudetti", two European Cups, and two Intercontinental Cup wins. José Mourinho, who was appointed on 2 June 2008, and completed his first season in Italy by winning the Serie A league title and the Supercoppa Italiana, in the second season he won the first "treble" in Italian history, the Serie A league title, Coppa Italia and the UEFA Champions League in the season 2009–2010.
Corporate.
F.C. Internazionale Milano S.p.A. was described as one of the financial "black-holes" among the Italian clubs, which was heavily depends on the financial contribution from the owner Massimo Moratti and later Erick Thohir. In June 2006, the shirt sponsor and the minority shareholder of the club, Pirelli, sold 15.26% shares of the club to Moratti family, for €13.5 million. The tyre manufacturer retained 4.2%. However, due to several capital increases of Inter, such as a reversed merger with an intermediate holding company, Inter Capital Srl in 2006, which held 89% shares of Inter and €70 million capitals at that time, or issues new shares for €70.8 million in June 2007, €99.9 million in December 2007, €86.6 million in 2008, €70 million in 2009, €40 million in 2010 and 2011, €35 million in 2012 or allowing Thoir subscribed €75 million new shares of Inter in 2013, Pirelli became the third largest shareholders of just 0.5%, as of 31 December 2014. Inter also received direct capital contribution from the shareholders to cover loss which was excluded from issuing shares. ()
Right before the takeover of Thohir, the consolidated balance sheets of "Internazionale Holding S.r.l." showed the whole companies group had a bank debt of €156.688 million, including the bank debt of a subsidiary "Inter Brand Srl", as well as the club itself, to Istituto per il Credito Sportivo, for €15.674 million on the balance sheet at end of 2012–13 financial year. In 2006 Inter sold its brand to the new subsidiary, "Inter Brand S.r.l.", a special purpose entity with a shares capital of €40 million, for €158 million (the deal made Internazionale make a net loss of just €31 million in a separate financial statement). At the same time the subsidiary secured a €120 million loan from Banca Antonveneta, which would be repaid in installments until 30 June 2016; In September 2011 Inter secured a loan from the institute by mortgaging the sponsorship of Pirelli of 2012–13 and 2013–14 season, for €24.8 million, in an interest rate of 3 months Euribor + 1.95% spread. In June 2014 new Inter Group secured €230 million loan from Goldman Sachs and UniCredit at a new interest rate of 3 months Euribor + 5.5% spread, as well as setting up a new subsidiary to be the debt carrier: "Inter Media and Comunication S.r.l.". €200 million of which would be utilized in debt refinancing of the group. The €230million loan, €1 million (plus interests) would be due on 30 June 2015, €45 million (plus interests) would be repaid in 15 installments from 30 September 2015 to 31 March 2019, as well as €184 million (plus interests) would be due on 30 June 2019. In ownership side, the Hong Kong-based International Sports Capital HK Limited, had pledged the shares of Italy-based International Sports Capital S.p.A. (the direct holding company of Inter) to CPPIB Credit Investments for €170 million in 2015.
Considering revenue alone, Inter surpassed city rivals in Deloitte Football Money League for the first time, in the 2008–09 season, to rank in 9th place, one place behind Juventus in 8th place. (Milan in 10th place.) In the 2009–10 season, Inter remained in 9th place, surpassing Juventus (10th) but Milan re-took the leading role as the 7th. Inter became the 8th in 2010–11, but was still one place behind Milan. Since 2011, Inter fell to 11th in 2011–12, 15th in 2012–13 and 17th in 2013–14 season. In 2008–09 season, Revenue percentages were divided up between matchday (14%, €28.2 million), broadcasting (59%, €115.7 million, +7%, +€8 million) and commercial (27%, €52.6 million, +43%). Kit sponsors Nike and Pirelli contributed €18.1 million and €9.3 million respectively to commercial revenues, while broadcasting revenues were boosted €1.6 million (6%) by Champions League distribution. in 2009–10 season the revenue was boosted by the sales of Ibrahimović, the treble and the release clause of coach José Mourinho. For the 2010–11 season, Serie A clubs started negotiating club TV rights collectively rather than individually. This was predicted to result in lower broadcasting revenues for Inter, with smaller clubs gaining from the loss. Eventually the result included an extraordinary income of €13 million from RAI. Deloitte expressed the idea that issues in Italian football, particularly matchday revenue issues were holding Inter back compared to other European giants, and developing their own stadia would result in Serie A clubs being more competitive on the world stage.
However, combining revenue and cost, in the 2006–07 season they had a net loss of €206 million (€112 million extraordinary basis, due the abolish of non-standard accounting practice of the special amortization fund), followed by €148 million in the 2007–08 season, €154 million in 2008–09 season, €69 million in the 2009–10 season, €87 million in the 2010–11 season, €77 million in the 2011–12 season.
In 2015 Inter and Roma were the only two Italian clubs that were sanctioned by the UEFA due to their breaking of UEFA Financial Fair Play Regulations. As a probation to avoid further sanction, Inter agreed to have a three-year aggregate break-even from 2015 to 2018, with the 2015–16 season being allowed to have a net loss of a maximum of €30 million, followed by break-even in the 2016–17 season. Inter was also fined €6 million plus an additional €14 million in probation. Inter also made a financial trick in the transfer market, in which Stevan Jovetić and Miranda were signed by Inter on a temporary deal plus an obligation to sign outright in 2017, making their cost less in the loan period. Moreover, despite heavily invested in new signings, namely Geoffrey Kondogbia and Ivan Perišić that potentially increased the cost in amortization, Inter also sold Mateo Kovačić for €29 million, making a windfall profit.

</doc>
<doc id="15120" url="https://en.wikipedia.org/wiki?curid=15120" title="Interferon">
Interferon

Interferons (IFNs) are a group of signaling proteins made and released by host cells in response to the presence of several pathogens, such as viruses, bacteria, parasites, and also tumor cells. In a typical scenario, a virus-infected cell will release interferons causing nearby cells to heighten their anti-viral defenses.
IFNs belong to the large class of proteins known as cytokines, molecules used for communication between cells to trigger the protective defenses of the immune system that help eradicate pathogens. Interferons are named for their ability to "interfere" with viral replication by protecting cells from virus infections. IFNs also have various other functions: they activate immune cells, such as natural killer cells and macrophages; they increase host defenses by up-regulating antigen presentation by virtue of increasing the expression of major histocompatibility complex (MHC) antigens. Certain symptoms of infections, such as fever, muscle pain and "flu-like symptoms", are also caused by the production of IFNs and other cytokines.
More than twenty distinct IFN genes and proteins have been identified in animals, including humans. They are typically divided among three classes: Type I IFN, Type II IFN, and Type III IFN. IFNs belonging to all three classes are important for fighting viral infections and for the regulation of the immune system.
Types of interferon.
Based on the type of receptor through which they signal, human interferons have been classified into three major types.
In general, type I and II interferons are responsible for regulating and activating the immune response. Expression of type I and III IFNs can be induced in virtually all cell types upon recognition of viral components, especially nucleic acids, by cytoplasmic and endosomal receptors, whereas type II interferon is induced by cytokines such as IL-12, and its expression is restricted to immune cells such as T cells and NK cells.
Function.
All interferons share several common effects: they are antiviral agents and they modulate functions of the immune system. Administration of Type I IFN has been shown experimentally to inhibit tumor growth in animals, but the beneficial action in human tumors has not been widely documented. 
A virus-infected cell releases viral particles that can infect nearby cells. However, the infected cell can prepare neighboring cells against a potential infection by the virus by releasing interferons. In response to interferon, cells produce large amounts of an enzyme known as protein kinase R (PKR). This enzyme phosphorylates a protein known as eIF-2 in response to new viral infections; the phosphorylated eIF-2 forms an inactive complex with another protein, called eIF2B, to reduce protein synthesis within the cell. Another cellular enzyme, RNAse L—also induced by interferon action—destroys RNA within the cells to further reduce protein synthesis of both viral and host genes. Inhibited protein synthesis destroys both the virus and infected host cells. In addition, interferons induce production of hundreds of other proteins—known collectively as interferon-stimulated genes (ISGs)—that have roles in combating viruses and other actions produced by interferon.
They also limit viral spread by increasing p53 activity, which kills virus-infected cells by promoting apoptosis. The effect of IFN on p53 is also linked to its protective role against certain cancers.
Another function of interferons is to upregulate major histocompatibility complex molecules, MHC I and MHC II, and increase immunoproteasome activity. Higher MHC I expression increases presentation of viral peptides to cytotoxic T cells, while the immunoproteasome processes viral peptides for loading onto the MHC I molecule, thereby increasing the recognition and killing of infected cells. Higher MHC II expression increases presentation of viral peptides to helper T cells; these cells release cytokines (such as more interferons and interleukins, among others) that signal to and co-ordinate the activity of other immune cells.
Interferons, such as interferon gamma, directly activate other immune cells, such as macrophages and natural killer cells.
Induction of interferons.
Production of interferons occurs mainly in response to microbes, such as viruses and bacteria, and their products. Binding of molecules uniquely found in microbes—viral glycoproteins, viral RNA, bacterial endotoxin (lipopolysaccharide), bacterial flagella, CpG motifs—by pattern recognition receptors, such as membrane bound Toll like receptors or the cytoplasmic receptors RIG-I or MDA5, can trigger release of IFNs.
Toll Like Receptor 3 (TLR3) is important for inducing interferons in response to the presence of double-stranded RNA viruses; the ligand for this receptor is double-stranded RNA (dsRNA). After binding dsRNA, this receptor activates the transcription factors IRF3 and NF-κB, which are important for initiating synthesis of many inflammatory proteins. RNA interference technology tools such as siRNA or vector-based reagents can either silence or stimulate interferon pathways. Release of IFN from cells (specifically IFN-γ in lymphoid cells) is also induced by mitogens. Other cytokines, such as interleukin 1, interleukin 2, interleukin-12, tumor necrosis factor and colony-stimulating factor, can also enhance interferon production.
Downstream signaling.
By interacting with their specific receptors, IFNs activate "signal transducer and activator of transcription" (STAT) complexes; STATs are a family of transcription factors that regulate the expression of certain immune system genes. Some STATs are activated by both type I and type II IFNs. However each IFN type can also activate unique STATs.
STAT activation initiates the most well-defined cell signaling pathway for all IFNs, the classical Janus kinase-STAT (JAK-STAT) signaling pathway. In this pathway, JAKs associate with IFN receptors and, following receptor engagement with IFN, phosphorylate both STAT1 and STAT2. As a result, an IFN-stimulated gene factor 3 (ISGF3) complex forms—this contains STAT1, STAT2 and a third transcription factor called IRF9—and moves into the cell nucleus. Inside the nucleus, the ISGF3 complex binds to specific nucleotide sequences called "IFN-stimulated response elements" (ISREs) in the promoters of certain genes, known as IFN stimulated genes ISGs. Binding of ISGF3 and other transcriptional complexes activated by IFN signaling to these specific regulatory elements induces transcription of those genes. A collection of known ISGs is available on Interferome, a curated online database of ISGs (www.interferome.org); Additionally, STAT homodimers or heterodimers form from different combinations of STAT-1, -3, -4, -5, or -6 during IFN signaling; these dimers initiate gene transcription by binding to IFN-activated site (GAS) elements in gene promoters. Type I IFNs can induce expression of genes with either ISRE or GAS elements, but gene induction by type II IFN can occur only in the presence of a GAS element.
In addition to the JAK-STAT pathway, IFNs can activate several other signaling cascades. For instance, both type I and type II IFNs activate a member of the CRK family of adaptor proteins called CRKL, a nuclear adaptor for STAT5 that also regulates signaling through the C3G/Rap1 pathway. Type I IFNs further activate "p38 mitogen-activated protein kinase" (MAP kinase) to induce gene transcription. Antiviral and antiproliferative effects specific to type I IFNs result from p38 MAP kinase signaling. The "phosphatidylinositol 3-kinase" (PI3K) signaling pathway is also regulated by both type I and type II IFNs. PI3K activates P70-S6 Kinase 1, an enzyme that increases protein synthesis and cell proliferation; phosphorylates of ribosomal protein s6, which is involved in protein synthesis; and phosphorylates a translational repressor protein called "eukaryotic translation-initiation factor 4E-binding protein 1" (EIF4EBP1) in order to deactivate it.
Virus resistance to interferons.
Many viruses have evolved mechanisms to resist interferon activity. They circumvent the IFN response by blocking downstream signaling events that occur after the cytokine binds to its receptor, by preventing further IFN production, and by inhibiting the functions of proteins that are induced by IFN. Viruses that inhibit IFN signaling include Japanese Encephalitis Virus (JEV), dengue type 2 virus (DEN-2) and viruses of the herpesvirus family, such as human cytomegalovirus (HCMV) and Kaposi's sarcoma-associated herpesvirus (KSHV or HHV8). Viral proteins proven to affect IFN signaling include EBV nuclear antigen 1 (EBNA1) and EBV nuclear antigen 2 (EBNA-2) from Epstein-Barr virus, the large T antigen of Polyomavirus, the E7 protein of Human papillomavirus (HPV), and the B18R protein of vaccinia virus. Reducing IFN-α activity may prevent signaling via STAT1, STAT2, or IRF9 (as with JEV infection) or through the JAK-STAT pathway (as with DEN-2 infection). Several poxviruses encode soluble IFN receptor homologs—like the B18R protein of the vaccinia virus—that bind to and prevent IFN interacting with its cellular receptor, impeding communication between this cytokine and its target cells. Some viruses can encode proteins that bind to double-stranded RNA (dsRNA) to prevent the activity of RNA-dependent protein kinases; this is the mechanism reovirus adopts using its sigma 3 (σ3) protein, and vaccinia virus employs using the gene product of its E3L gene, p25. The ability of interferon to induce protein production from interferon stimulated genes (ISGs) can also be affected. Production of protein kinase R, for example, can be disrupted in cells infected with JEV Some viruses escape the anti-viral activities of interferons by gene (and thus protein) mutation. The H5N1 influenza virus, also known as bird flu, has resistance to interferon and other anti-viral cytokines that is attributed to a single amino acid change in its Non-Structural Protein 1 (NS1), although the precise mechanism of how this confers immunity is unclear.
Interferon therapy.
Diseases.
Interferon beta-1a and interferon beta-1b are used to treat and control multiple sclerosis, an autoimmune disorder. This treatment is effective for reducing attacks in relapsing-remitting multiple sclerosis and slowing disease progression and activity in secondary progressive multiple sclerosis.
Interferon therapy is used (in combination with chemotherapy and radiation) as a treatment for some cancers. This treatment can be used in hematological malignancy; leukemia and lymphomas including hairy cell leukemia, chronic myeloid leukemia, nodular lymphoma, and cutaneous T-cell lymphoma. Patients with recurrent melanomas receive recombinant IFN-α2b. 
Both hepatitis B and hepatitis C are treated with IFN-α, often in combination with other antiviral drugs. Some of those treated with interferon have a sustained virological response and can eliminate hepatitis virus. The most harmful strain—hepatitis C genotype I virus—can be treated with a 60-80% success rate with the current standard-of-care treatment of interferon-α, ribavirin and recently approved protease inhibitors such as Telaprevir (Incivek) May 2011, Boceprevir (Victrelis) May 2011 or the nucleotide analog polymerase inhibitor Sofosbuvir (Sovaldi) December 2013. Biopsies of patients given the treatment show reductions in liver damage and cirrhosis. Some evidence shows giving interferon immediately following infection can prevent chronic hepatitis C, although diagnosis early in infection is difficult since physical symptoms are sparse in early hepatitis C infection. Control of chronic hepatitis C by IFN is associated with reduced hepatocellular carcinoma.
Interferon treatment was evaluated in individuals suffering from herpes simplex virus epithelial keratitis. Topical interferon therapy was shown to be an effective treatment, especially with higher concentrations. Interferon, either used alone or in combination with debridement, appears to be as effective as a nucleoside antiviral agent. The combination of interferon and another nucleoside antiviral agent may speed the healing process.
When used in the systemic therapy, IFNs are mostly administered by an intramuscular injection. The injection of IFNs in the muscle or under skin is generally well tolerated. The most frequent adverse effects are flu-like symptoms: increased body temperature, feeling ill, fatigue, headache, muscle pain, convulsion, dizziness, hair thinning, and depression. Erythema, pain and hardness on the spot of injection are also frequently observed. IFN therapy causes immunosuppression, in particular through neutropenia and can result in some infections manifesting in unusual ways.
Drug formulations.
Several different types of interferons are now approved for use in humans. For example, in January 2001, the Food and Drug Administration (FDA) approved the use of PEGylated interferon-alpha in the USA; in this formulation, PEGylated interferon-alpha-2b ("Pegintron"), polyethylene glycol is linked to the interferon molecule to make the interferon last longer in the body. Approval for PEGylated interferon-alpha-2a ("Pegasys") followed in October 2002. These PEGylated drugs are injected once weekly, rather than administering two or three times per week, as is necessary for conventional interferon-alpha. When used with the antiviral drug ribavirin, PEGylated interferon is effective in treatment of hepatitis C; at least 75% of people with hepatitis C genotypes 2 or 3 benefit from interferon treatment, although this is effective in less than 50% of people infected with genotype 1 (the more common form of hepatitis C virus in both the U.S. and Western Europe). Interferon-containing regimens may also include protease inhibitors such as boceprevir and telaprevir.
History.
Interferons were first described in 1957 by Alick Isaacs and Jean Lindenmann at the National Institute for Medical Research in London; the discovery was a result of their studies of viral interference. Viral interference refers to the inhibition of virus growth caused by previous exposure of cells to an active or a heat-inactivated virus. Isaacs and Lindenmann were working with a system that involved the inhibition of the growth of live influenza virus in chicken embryo chorioallantoic membranes by heat-inactivated influenza virus. Their experiments revealed that this interference was mediated by a protein released by cells in the heat-inactivated influenza virus-treated membranes. They published their results in 1957 naming the antiviral factor they had discovered "interferon". The findings of Isaacs and Lindenmann have been widely confirmed and corroborated in the literature.
Furthermore, others may have made observations on interferons before the 1957 publication of Isaacs and Lindenmann. For example, during research to produce a more efficient vaccine for smallpox, Yasu-ichi Nagano and Yasuhiko Kojima—two Japanese virologists working at the Institute for Infectious Diseases at the University of Tokyo—noticed inhibition of viral growth in an area of rabbit-skin or testis previously inoculated with UV-inactivated virus. They hypothesised that some "viral inhibitory factor" was present in the tissues infected with virus and attempted to isolate and characterize this factor from tissue homogenates. Independently, Monto Ho, in John Enders's lab, observed in 1957 that attenuated poliovirus conferred a species specific anti-viral effect in human amniotic cell cultures. They described these observations in a 1959 publication, naming the responsible factor "viral inhibitory factor" (VIF). It took another fifteen to twenty years, using somatic cell genetics, to show that the interferon action gene and interferon gene reside in different human chromosomes. The purification of human beta interferon did not occur until 1977. Chris Y.H. Tan and his co-workers purified and produced biologically active, radio-labeled human beta interferon by superinducing the interferon gene in fibroblast cells, and they showed its active site contains tyrosine residues. Tan's laboratory isolated sufficient amounts of human beta interferon to perform the first amino acid, sugar composition and N-terminal analyses. They showed that human beta interferon was an unusually hydrophobic glycoprotein. This explained the large loss of interferon activity when preparations were transferred from test tube to test tube or from vessel to vessel during purification. The analyses showed the reality of interferon activity by chemical verification. The purification of human alpha interferon was not reported until 1978. A series of publications from the laboratories of Sidney Pestka and Alan Waldman between 1978 and 1981, describe the purification of the type I interferons IFN-α and IFN-β. By the early 1980s, genes for these interferons had been cloned, adding further definitive proof that interferons were responsible for interfering with viral replication. Gene cloning also confirmed that IFN-α was encoded by a family of many related genes. The type II IFN (IFN-γ) gene was also isolated around this time.
Interferon was scarce and expensive until 1980, when the interferon gene was inserted into bacteria using recombinant DNA technology, allowing mass cultivation and purification from bacterial cultures or derived from yeasts. Interferon can also be produced by recombinant mammalian cells.
Before the early 1970s, large scale production of human interferon had been pioneered by Kari Cantell. He produced large amounts of human alpha interferon from large quantities of human white blood cells collected by the Finnish Blood Bank. Large amounts of human beta interferon were made by superinducing the beta interferon gene in human fibroblast cells.
Cantell's and Tan's methods of making large amounts of natural interferon were critical for chemical characterisation, clinical trials and the preparation of small amounts of interferon messenger RNA to clone the human alpha and beta interferon genes. The superinduced human beta interferon messenger RNA was prepared by Tan's lab for Cetus corp. to clone the human beta interferon gene in bacteria and the recombinant interferon was developed as 'betaseron' and approved for the treatment of MS. Superinduction of the human beta interferon gene was also used by Israeli scientists to manufacture human beta interferon.

</doc>
<doc id="15123" url="https://en.wikipedia.org/wiki?curid=15123" title="Israeli settlement">
Israeli settlement

Israeli settlements are Jewish Israeli civilian communities built on lands occupied by Israel since the 1967 Six-Day War. Such settlements currently exist in the West Bank, East Jerusalem, and in the Golan Heights. Settlements previously existed in the Sinai Peninsula and Gaza Strip until Israel evacuated the Sinai settlements following the 1979 Israel-Egypt peace agreement and from the Gaza Strip in 2005 under Israel's unilateral disengagement plan. Israel dismantled 18 settlements in the Sinai Peninsula in 1982, and all 21 in the Gaza Strip and 4 in the West Bank in 2005, but continues to both expand its settlements and settle new areas in the West Bank, despite pressure to desist from the international community. According to the Israeli investigative reporter Uri Blau, settlements are massively funded by private tax-exempt U.S. NGOs, to the tune of $220 million for 2009-2013 alone, suggesting that the U.S. is indirectly subsidizing their creation.
The international community considers the settlements in occupied territory to be illegal, and the United Nations has repeatedly upheld the view that Israel's construction of settlements constitutes a violation of the Fourth Geneva Convention. Israeli neighborhoods in East Jerusalem and communities in the Golan Heights, the latter of which has been annexed by Israel, are also considered settlements by the international community, which does not recognise Israel's annexations of these territories.
The International Court of Justice also says these settlements are illegal in a 2004 advisory opinion. In April 2012, UN secretary general Ban Ki-Moon, in response to moves by Israel to legalise Israeli outposts, reiterated that all settlement activity is illegal, and "runs contrary to Israel's obligations under the Road Map and repeated Quartet calls for the parties to refrain from provocations." Similar criticism was advanced by the EU and the US. Israel disputes the position of the international community and the legal arguments that were used to declare the settlements illegal.
The presence and ongoing expansion of existing settlements by Israel and the construction of settlement outposts is frequently criticized as an obstacle to the peace process by the Palestinians, and third parties such as the OIC, the United Nations, Russia, the United Kingdom, France, the European Union, and the United States have echoed those criticisms.
Settlement has an economic dimension, much of it driven by the significantly lower costs of housing in Jewish settlements compared to the cost of housing and living in Israel. Government spending per citizen in the Jewish settlements is double that spent per Israeli citizen in Tel Aviv and Jerusalem, while government spending for settlers in isolated areas is three times the Israeli national average. Most of the spending goes to the security of the citizens living there. On 30 June 2014, according to the Yesha Council, 382,031 Jewish settlers lived in the 121 officially recognised settlements in the West Bank, over 300,000 Israelis lived in settlements in East Jerusalem and over 20,000 lived in settlements in the Golan Heights. In January 2015 the Israeli Interior Ministry gave figures of 389,250 Israelis living in the West Bank and a further 375,000 Israelis living in East Jerusalem. Settlements range in character from farming communities and frontier villages to urban suburbs and neighborhoods. The four largest settlements, Modi'in Illit, Ma'ale Adumim, Beitar Illit and Ariel, have achieved city status. Ariel has 18,000 residents, while the rest have around 37,000 to 55,500 each. A number of Palestinians reside in settlements in East Jerusalem.
History.
1967 War.
The 1967 Six-Day War left Israel in control of 
Settlement policy.
As early as 1967, Israeli settlement policy was started by the Labor government of Levi Eshkol. The basis for Israeli settlement in the West Bank became the Allon Plan, named after its inventor Yigal Allon. It implied Israeli annexation of major parts of the Israeli-occupied territories, especially East Jerusalem, Gush Etzion and the Jordan Valley. Yigal Allon became Levi Eshkol's successor as Prime Minister in 1969. The settlement policy of the next government, led by Yitzhak Rabin, was also derived from the Allon Plan.
The first settlement was Kfar Etzion, in the southern West Bank, although that location was outside the Allon Plan. Many settlements began as Nahal settlements. They were established as military outposts and later expanded and populated with civilian inhabitants.
The Likud government of Menahem Begin, from 1977, was more supportive to settlement in other parts of the West Bank, by organizations like Gush Emunim and the Jewish Agency/World Zionist Organization, and intensified the settlement activities. In a government statement, Likud declared that the entire historic Land of Israel is the inalienable heritage of the Jewish people, and that no part of the West Bank should be handed over to foreign rule. Ariel Sharon declared in the same year (1977) that there was a plan to settle 2 million Jews in the West Bank by 2000. The government abrogated the prohibition from purchasing occupied land by Israelis; the ""Drobles Plan"", a plan for large-scale settlement in the West Bank meant to prevent a Palestinian state under the pretext of security became the framework for its policy. The "Drobles Plan" from the World Zionist Organization, dated October 1978 and named ""Master Plan for the Development of Settlements in Judea and Samaria, 1979-1983"", was written by the Jewish Agency director and former Knesset member Matityahu Drobles. In January 1981, the government adopted a follow up-plan from Drobles, dated September 1980 and named ""The current state of the settlements in Judea and Samaria"", with more details about settlement strategy and policy.
Since 1967, government-funded settlement projects in the West Bank are implemented by the "Settlement Division" of the World Zionist Organization. Though formally a non-governmental organization, it is funded by the Israeli government and leases lands from the Civil Administration to settle in the West Bank. It is authorized to create settlements in the West Bank on lands licensed to it by the Civil Administration. Traditionally, the "Settlement Division" has been under the responsibility of the Agriculture Ministry. Since the Olso Accords, it was always housed within the Prime Minister's Office (PMO). In 2007, it was moved back to the Agriculture Ministry. In 2009, the Netanyahu Government decided to subject all settlement activities to additional approval of the Prime Minister and the Defense Minister. In 2011, Netanyahu sought to move the Settlement Division again under the direct control of (his own) PMO, and to curtail Defense Minister Ehud Barak's authority.
At the presentation of the Oslo II Accord on 5 October 1995 in the Knesset, PM Yitzhak Rabin expounded the Israeli settlement policy in connection with the permanent solution to the conflict. Israel wanted ""a Palestinian entity, less than a state, which will be a home to most of the Palestinian residents living in the Gaza Strip and the West Bank"". It wanted to keep settlements beyond the Green Line including Ma'ale Adumim and Givat Ze'ev in East Jerusalem. Blocs of settlements should be established in the West Bank. Rabin promised not to return to the 4 June 1967 lines.
In June 1997, the Likud government of Benjamin Netanyahu presented its "Allon Plus Plan". This plan holds the retention of some 60% of the West Bank, including the "Greater Jerusalem" area with the settlements Gush Etzion and Ma'aleh Adumim, other large concentrations of settlements in the West Bank, the entire Jordan Valley, a "security area", and a network of Israeli-only bypass roads.
In the Road map for peace of 2002, which was never implemented, the establishment of a Palestinian state was acknowledged. Outposts would be dismantled. However, many new outposts appeared instead, few were removed. Israel's settlement policy remained unchanged. Settlements in East Jerusalem and remaining West Bank were expanded.
While according to official Israeli policy no new settlements were built, at least some hundred unauthorized outposts were established since 2002 with state funding in the 60% of the West Bank that was not under Palestinian administrative control and the population growth of settlers did not diminish.
In 2005, all 21 settlements in the Gaza Strip and four in the northern West Bank were forcibly evacuated as part of Israeli disengagement from the Gaza Strip, known to some in Israel as "the Expulsion". However, the disengagement was more than compensated by transfers to the West Bank.
After the failure of the "Roadmap", several new plans emerged to settle in major parts of the West Bank. In 2011, Haaretz revealed the Civil Administration's ""Blue Line""-plan, written in January 2011, which aims to increase Israeli "state-ownership" of West Bank lands ("state lands") and settlement in strategic areas like the Jordan Valley and the Palestinian northern Dead Sea area. In March 2012, it was revealed that the Civil Administration over the years covertly allotted 10% of the West Bank for further settlement. Provisional names for future new settlements or settlement expansions were already assigned. The plan includes many Palestinian built-up sites in the Areas A and B.
Geography and municipal status.
Some settlements are self-contained cities with a stable population in the tens of thousands, infrastructure, and all other features of permanence. Examples are Beitar Illit (a city of close to 45,000 residents), Ma'ale Adumim, Modi'in Illit, and Ariel (almost 20,000 residents). Some are towns with a local council status with populations of 2,000–20,0000, such as Alfei Menashe, Eli, Elkana, Efrat and Kiryat Arba. There are also clusters of villages governed by a local elected committee and regional councils that are responsible for municipal services. Examples are Kfar Adumim, Neve Daniel, Kfar Tapuach and Ateret. Kibbutzim and moshavim in the territories include Argaman, Gilgal, Niran and Yitav. Jewish neighborhoods have been built on the outskirts of Arab neighborhoods, for example in Hebron. In Jerusalem, there are urban neighborhoods where Jews and Arabs live together: the Muslim Quarter, Silwan, Abu Tor, Sheikh Jarrah and Shimon HaTzadik.
Under the Oslo Accords, the West Bank was divided into three separate parts designated as Area A, Area B and Area C. Leaving aside the position of East Jerusalem, all of the settlements are in Area C which comprises about 60% of the West Bank.
Resettlement of former Jewish communities.
Some settlements were established on sites where Jewish communities had existed during the British Mandate of Palestine.
Other communities: Shimon HaTzadik, Neve Yaakov and Atarot which in post-1967 was rebuilt as an industrial zone.
Demographics.
At the end of 2010, 534,224 Jewish Israeli lived in the West Bank, including East Jerusalem. 314,132 of them lived in the in 121 authorised settlements and 102 unauthorised settlement outposts on the West Bank, 198,629 were living in East Jerusalem, and almost 20,000 lived in settlements in the Golan Heights. 
In 2011, 328,423 Israeli Jews were living on the West Bank, excluding Jerusalem, and the Jewish population in the Golan Heights exceeded 20,000. 
For the year 2012, the Jewish population in the West Bank settlements excluding East Jerusalem was expected to rise to 350,000.
In May 2014, the Israeli Housing Minister Uri Ariel, who himself lives in the West Bank settlement of Kfar Adumim, put the settler population at up to 750,000: 400,000 in the West Bank and up to 350,000 in East Jerusalem. He stated: "I think that in five years there will be 550,000 or 600,000 Jews in Judea and Samaria, rather than 400,000 (now)".
Note: due to change of definition, the number of settlements in the West Bank decreased in 1997 from 138 to 121 (outposts not included).
Based on various sources, population dispersal can be estimated as follows:
In addition to internal migration, in large though declining numbers, the settlements absorb annually about 1000 new immigrants from outside Israel. In the 1990s, the annual settler population growth was more than three times the annual population growth in Israel. Population growth has continued in the 2000s. According to the BBC, the settlements in the West Bank have been growing at a rate of 5–6% since 2001.
The establishment of settlements in the Palestinian territories is linked to the displacement of the Palestinian populations as evidenced by a 1979 Security Council Commission which established a link between Israeli settlements and the displacement of the local population. The commission also found that those who remained were under consistent pressure to leave to make room for further settlers who were being encouraged into the area. In conclusion the commission stated that settlement in the Palestinian territories was causing "profound and irreversible changes of a geographic and demographic nature".
Administration and local government.
West Bank.
The Israeli settlements in the West Bank make up what Israel calls the "Judea and Samaria Area". Since December 2007, approval by both the Israeli Prime Minister and Israeli Defense Minister of all settlement activities (including planning) in the West Bank is required. Authority for planning and construction is held by the Israel Defense Forces Civil Administration.
The area consists of four cities, thirteen local councils and six regional councils.
The Yesha Council (, "Moatzat Yesha", a Hebrew acronym for Judea, Samaria and Gaza) is the umbrella organization of municipal councils in the West Bank.
The actual buildings of the Israeli settlements cover only 1 percent of the West Bank, but their jurisdiction and their regional councils extend to about 42 percent of the West Bank, according to the Israeli NGO B'Tselem. Yesha Council chairman Dani Dayan disputes the figures and claims that the settlements only control 9.2 percent of the West Bank.
Between 2001 and 2007 more than 10,000 Israeli settlement units were built, while 91 permits were issued for Palestinian construction, and 1,663 Palestinian structures were demolished in Area C.
West Bank Palestinians have their cases tried in Israel's military courts while Jewish Israeli settlers living in the same occupied territory are tried in civil courts. The arrangement has been described as "de facto segregation" by the UN Committee on the Elimination of Racial Discrimination.
A bill to formally extend Israeli law to the Israeli settlements in the West Bank was rejected in 2012.
On 31 August 2014, Israel announced it was appropriating 400 hectares of land in the West Bank to eventually house 1,000 Israel families. The appropriation was described as the largest in more than 30 years. According to reports on Israel Radio, the development is a response to the 2014 kidnapping and murder of Israeli teenagers.
East Jerusalem.
East Jerusalem is defined in the Jerusalem Law as part of Israel and its capital, Jerusalem. As such it is administered as part of the city and its district, the Jerusalem District. Pre-1967 residents of East Jerusalem and their descendants have residency status in the city but many have refused Israeli citizenship. Thus, the Israeli government maintains an administrative distinction between Israeli citizens and non-citizens in East Jerusalem, but the Jerusalem municipality does not.
Golan Heights.
The Golan Heights is administered under Israeli civil law as the Golan sub-district, a part of the North District. Israel makes no legal or administrative distinction between pre-1967 communities in the Golan Heights (mainly Druze) and the post-1967 settlements.
Sinai Peninsula.
After the capture of the Sinai Peninsula from Egypt in the 1967 Six-Day War, settlements were established along the Gulf of Aqaba and in the northeast, just below the Gaza Strip. It had plans to expand the settlement of Yamit into a city with a population of 200,000, though the actual population of Yamit did not exceed 3,000. The Sinai Peninsula was returned to Egypt in stages beginning in 1979 as part of the Egypt–Israel Peace Treaty. As required by the treaty, Israel evacuated the civilian population, which took place in 1982. Some evacuation was done forcefully in some instances, such as the evacuation of Yamit.
Gaza Strip.
Before Israel's unilateral disengagement plan in which the Israeli settlements were evacuated, there were in the Gaza Strip under the administration of the Hof Aza Regional Council. The land was allocated in such a way that each Israeli settler disposed of 400 times the land available to the Palestinian refugees, and 20 times the volume of water allowed to the peasant farmers of the Strip.
Legal status.
The consensus view in the international community is that the existence of Israeli settlements in the West Bank including East Jerusalem and the Golan Heights is in violation of international law. The Fourth Geneva Convention includes statements such as "the Occupying Power shall not deport or transfer parts of its own civilian population into the territory it occupies".
At present, the view of the international community, as reflected in numerous UN resolutions, regards the building and existence of Israeli settlements in the West Bank, East Jerusalem and the Golan Heights as a violation of international law. UN Security Council Resolution 446 refers to the Fourth Geneva Convention as the applicable international legal instrument, and calls upon Israel to desist from transferring its own population into the territories or changing their demographic makeup. The reconvened Conference of the High Contracting Parties to the Geneva Conventions has declared the settlements illegal as has the primary judicial organ of the UN, the International Court of Justice.
The position of successive Israeli governments is that all authorized settlements are entirely legal and consistent with international law. In practice, Israel does not accept that the Fourth Geneva Convention applies "de jure", but has stated that on humanitarian issues it will govern itself "de facto" by its provisions, without specifying which these are. The scholar and jurist Eugene Rostow has disputed the illegality of authorized settlements.
Under Israeli law, West Bank settlements must meet specific criteria to be legal. In 2009, there were approximately 100 small communities that did not meet these criteria and are referred to as illegal outposts.
In 2014 twelve EU countries warned businesses against involving themselves in the settlements. According to the warnings, economic activities relating to the settlements involve legal and economic risks stemming from the fact that the settlements are built on occupied land not recognized as Israel's.
Illegality arguments.
After the Six-Day War, in 1967, Theodor Meron, legal counsel to the Israeli Foreign Ministry stated in a legal opinion to the Prime Minister,
"My conclusion is that civilian settlement in the administered territories contravenes the explicit provisions of the Fourth Geneva Convention."
This legal opinion was sent to Prime Minister Levi Eshkol. However, it was not made public at the time. The Labor cabinet allowed settlements despite the warning. This paved the way for future settlement growth. In 2007, Meron stated that "I believe that I would have given the same opinion today."
In 1978, the Legal Adviser of the Department of State of the United States reached the same conclusion.
The International Court of Justice, in its advisory opinion, has since ruled that Israel is in breach of international law by establishing settlements in Occupied Palestinian Territory, including East Jerusalem. The Court maintains that Israel cannot rely on its right of self-defense or necessity to impose a regime that violates international law. The Court also ruled that Israel violates basic human rights by impeding liberty of movement and the inhabitants' right to work, health, education and an adequate standard of living.
International intergovernmental organizations such as the Conference of the High Contracting Parties to the Fourth Geneva Convention, major organs of the United Nations, the European Union, and Canada, also regard the settlements as a violation of international law. The Committee on the Elimination of Racial Discrimination wrote that "The status of the settlements was clearly inconsistent with Article 3 of the Convention, which, as noted in the Committee's General Recommendation XIX, prohibited all forms of racial segregation in all countries. There is a consensus among publicists that the prohibition of racial discrimination, irrespective of territories, is an imperative norm of international law." Amnesty International, and Human Rights Watch have also characterized the settlements as a violation of international law.
In late January 2013 a report drafted by three justices, presided over by Christine Chanet, and issued by the United Nations Human Rights Council declared that Jewish settlements constituted a creeping annexation based on multiple violations of the Geneva Conventions and international law, and stated that if Palestine ratified the Rome Accord, Israel could be tried for "gross violations of human rights law and serious violations of international humanitarian law.' A spokesman for Israel's Foreign Ministry declared the report ‘unfortunate' and accused the UN's Human Rights Council of a "systematically one-sided and biased approach towards Israel." 
According to Talia Sasson, the High Court of Justice in Israel, with a variety of different justices sitting, has repeatedly stated for more than 4 decades that Israel's presence in the West Bank is in violation of international law.
Legality arguments.
Four prominent jurists cited the concept of the "sovereignty vacuum" in the immediate aftermath of the Six-Day War to describe the legal status of the West Bank and Gaza: Yehuda Zvi Blum in 1968, Elihu Lauterpacht in 1968, Julius Stone in 1969 and 1981, and Stephen M. Schwebel in 1970. Eugene V. Rostow also argued in 1979 that the occupied territories' legal status was undetermined.
Professor Ben Saul took exception to this view, arguing that Article 49(6) can be read to include voluntary or assisted transfers, as indeed it was in the advisory opinion of the International Court of Justice which had expressed this interpretation in the Israeli Wall Advisory Opinion (2003).
Israel maintains that a temporary use of land and buildings for various purposes is permissible under a plea of military necessity and that the settlements fulfilled security needs. Israel argues that its settlement policy is consistent with international law, including the Fourth Geneva Convention, while recognising that some settlements have been constructed illegally on private land. The Israeli Supreme Court has ruled that the power of the Civil Administration and the Military Commander in the occupied territories is limited by the entrenched customary rules of public international law as codified in the Hague Regulations and Geneva Convention IV. In 1998 the Israeli Minister of Foreign Affairs produced "The International Criminal Court Background Paper". It concludesInternational law has long recognised that there are crimes of such severity they should be considered "international crimes." Such crimes have been established in treaties such as the Genocide Convention and the Geneva Conventions... The following are Israel's primary issues of concern with the rules of the ICC: The inclusion of settlement activity as a "war crime" is a cynical attempt to abuse the Court for political ends. The implication that the transfer of civilian population to occupied territories can be classified as a crime equal in gravity to attacks on civilian population centres or mass murder is preposterous and has no basis in international law.
A UN conference held in Rome in 1998, where Israel was one of seven countries to vote against the Rome Statute to establish the International Criminal Court. Israel was opposed to a provision that included as a war crime the transfer of civilian populations into territory the government occupies. Israel has signed the statute, but not ratified the treaty.
Land ownership.
By Israeli law, privately owned land can not be part of a settlement, unless the land in question has been confiscated for military purposes. In 2006 Peace Now acquired a report, which it claims was leaked from the Israeli Government's Civil Administration, indicating that up to 40 percent of the land Israel plans to retain in the West Bank is privately owned by Palestinians. Peace Now called this a violation of Israeli law. Peace Now published a comprehensive report about settlements on private lands. In the wake of a legal battle, Peace Now lowered the figure to 32 percent, which the Civil Administration also denied. "The Washington Post" reported that "The 38-page report offers what appears to be a comprehensive argument against the Israeli government's contention that it avoids building on private land, drawing on the state's own data to make the case."
In February 2008, the Civil Administration stated that the land on which more than a third of West Bank settlements was built had been expropriated by the IDF for "security purposes." The unauthorized seizure of private Palestinian land was defined by the Civil Administration itself as 'theft.' According to B'Tselem, more than 42 percent of the West Bank are under control of the Israeli settlements, 21 percent of which was seized from private Palestinian owners, much of it in violation of the 1979 Israeli Supreme Court decision.
In 1979, the government decided to extend settlements or build new ones only on "state lands".
A secret database, drafted by a retired senior officer, "Baruch Spiegel", on orders from former defense minister Shaul Mofaz, found that some settlements deemed legal by Israel were illegal outposts, and that large portions of Ofra, Elon Moreh and Beit El were built on private Palestinian land. The "Spiegel report" was revealed by Haaretz in 2009. Many settlements are largely built on private lands, without approval of the Israeli Government.Haaretz, Uri Blau, "Secret Israeli database reveals full extent of illegal settlement". 30 January 2009. <br >The published document (in Hebrew): http://www.fmep.org/analysis/reference/israeli-defense-ministry-database-on-illegal-construcion-in-the-territories. Part of it was translated in english by Yesh Din: ""Spiegel Database" of West Bank settlements and outposts developed by the Israeli Ministry of Defense".</ref> According to Israel, the bulk of the land was vacant, was leased from the state, or bought fairly from Palestinian landowners.
Invoking the Absentee Property Law to transfer, sell or lease property in East Jerusalem owned by Palestinians who live elsewhere without compensation has been criticized both inside and outside of Israel. Opponents of the settlements claim that "vacant" land belonged to Arabs who fled or collectively to an entire village, a practice that developed under Ottoman rule. B'Tselem charged that Israel is using the absence of modern legal documents for the communal land as a legal basis for expropriating it. These "abandoned lands" are sometimes laundered through a series of fraudulent sales.
According to Amira Hass, one of the techniques used by Israel to expropriate Palestinian land is to place desired areas under a 'military firing zone' classification, and then issue orders for the evacuation of Palestinians from the villages in that range, while allowing contiguous Jewish settlements to remain unaffected.
Effects on Palestinian human rights.
Amnesty International argues that Israel's settlement policy is discriminatory and a violation of Palestinian human rights. B'Tselem claims that Israeli travel restrictions impact on Palestinian freedom of movement and Palestinian human rights have been violated in Hebron due to the presence of the settlers within the city. According to B'Tselem, over fifty percent of West Bank land expropriated from Palestinians has been used to establish settlements and create reserves of land for their future expansion. The seized lands mainly benefit the settlements and Palestinians cannot use them. The roads built by Israel in the West Bank to serve the settlements are closed to Palestinian vehicles' and act as a barrier often between villages and the lands on which they subsist.
Human Rights Watch and other human rights observer volunteer regularly file reports on "settler violence," referring to stoning and shooting incidents involving Israeli settlers. Israel's withdrawal from Gaza and Hebron have led to violent settler protests and disputes over land and resources. Meron Benvenisti described the settlement enterprise as a "commercial real estate project that conscripts Zionist rhetoric for profit."
The construction of the Israeli West Bank barrier has been criticized as an infringement on Palestinian human and land rights. The United Nations Office for the Coordination of Humanitarian Affairs estimated that 10% of the West Bank would fall on the Israeli side of the barrier.
In July 2012, the UN Human Rights Council decided to set up a probe into Jewish settlements. The report of the independent international fact-finding mission which investigated the "implications of the Israeli settlements on the civil, political, economic, social and cultural rights of the Palestinian people throughout the Occupied Palestinian Territory" was published in February 2013.
Economy.
Goods produced in Israeli settlements are able to stay competitive on the global market, in part because of massive state subsidies they receive from the Israeli government. Farmers and producers are given state assistance, while companies that set up in the territories receive tax breaks and direct government subsidies. An Israeli government fund has also been established to help companies pay customs penalties. Palestinian officials estimate that settlers sell goods worth some $500 million to the Palestinian market. Israel has built 16 industrial zones, containing roughly 1000 industrial plants, in the West Bank and East Jerusalem on acreage that consumes large parts of the territory planned for a future Palestinian state. According to Jodi Rudoren these installations both entrench the occupation and provide work for Palestinians, even those opposed to it. The 16 parks are located at Shaked, Beka'ot, Baran, Karnei Shomron, Emmanuel, Barkan, Ariel, Shilo, Halamish, Ma'ale Efraim, Sha'ar Binyamin, Atarot, Mishor Adumim, Gush Etzion, Kiryat Arba and Metarim (2001).
Export to EU.
According to Israeli government estimates, $230 million worth of settler goods including fruit, vegetables, cosmetics, textiles and toys are exported to the EU each year, accounting for approximately 2% of all Israeli exports to Europe. A 2013 report of Profundo revealed that at least 38 Dutch companies imported settlement products.
European Union law requires a distinction to be made between goods originating in Israel and those from the occupied territories. The former benefit from preferential custom treatment according to the EU-Israel Association Agreement (2000); the latter don't, having been explicitly excluded from the agreement. In practice, however, settler goods often avoid mandatory customs through being labelled as originating in Israel, while European customs authorities commonly fail to complete obligatory postal code checks of products to ensure they have not originated in the occupied territories.
In 2009, the United Kingdom's Department for the Environment, Food and Rural Affairs issued new guidelines concerning labelling of goods imported from the West Bank. The new guidelines require labelling to clarify whether West Bank products originate from settlements or from the Palestinian economy. Israel's foreign ministry said that the UK was "catering to the demands of those whose ultimate goal is the boycott of Israeli products"; but this was denied by the UK government, who said that the aim of the new regulations was to allow consumers to choose for themselves what produce they buy. Denmark has similar legislation requiring food products from settlements in the occupied territories to be accurately labelled.
Palestinian economy and resources.
A Palestinian report argued in 2011 that settlements have a detrimental effect on the Palestinian economy, equivalent to about 85% of the nominal gross domestic product of Palestine, and that the "occupation enterprise" allows the state of Israel and commercial firms to profit from Palestinian natural resources and tourist potential. A 2013 report published by the World Bank analysed the impact that the limited access to Area C lands and resources had on the Palestinian economy. While settlements represent a single axis of control, it is the largest with 68% of the Area C lands reserved for the settlements. The report goes on to calculate that access to the lands and resources of Area C, including the territory in and around settlements, would increase the Palestinian GDP by some $3.5 billion (or 35%) per year.
The Israeli Supreme Court has ruled that Israeli companies are entitled to exploit the West Bank's natural resources for economic gain, and that international law must be "adapted" to the "reality on the ground" of long-term occupation.
Palestinian labour.
Due to the availability of jobs offering twice the prevailing salary of the West Bank (), as well as high unemployment, tens of thousands of Palestinians work in Israeli settlements. According to the Manufacturers Association of Israel, some 22,000 Palestinians were employed in construction, agriculture, manufacturing and service industries. An Al-Quds University study in 2011 found that 82% of Palestinian workers said they would prefer to not work in Israeli settlements if they had alternative employment in the West Bank.
Palestinians have been highly involved in the construction of settlements in the West Bank. In 2013, the Palestinian Central Bureau of Statistics released their survey showing that the number of Palestinian workers who are employed by the Jewish settlements increased from 16,000 to 20,000 in the first quarter. The survey also found that Palestinians who work in Israel and the settlements are paid more than twice their salary compared to what they receive from Palestinian employers.
In 2008, Kav LaOved charged that Palestinians who work in Israeli settlements are not granted basic protections of Israeli labor law. Instead, they are employed under Jordanian labor law, which does not require minimum wage, payment for overtime and other social rights. In 2007, the Supreme Court of Israel ruled that Israeli labor law does apply to Palestinians working in West Bank settlements and applying different rules in the same work place constituted discrimination. The ruling allowed Palestinian workers to file lawsuits in Israeli courts. In 2008, the average sum claimed by such lawsuits stood at 100,000 shekels.
According to Palestinian Center for Policy and Survey Research, 63% of Palestinians opposed PA plans to prosecute Palestinians who work in the settlements. However, 72% of Palestinians support a boycott of the products they sell. Although the Palestinian Authority has criminalized working in the settlements, the director-general at the Palestinian Ministry of Labor, Samer Salameh, described the situation in February 2014 as being "caught between two fires". He said "We strongly discourage work in the settlements, since the entire enterprise is illegal and illegitimate...but given the high unemployment rate and the lack of alternatives, we do not enforce the law that criminalizes work in the settlements."
Violence.
Israeli settler violence.
Gush Emunim Underground was a militant organization that operated in 1979–1984. The organization planned attacks on Palestinian officials and the Dome of the Rock. In 1994, Baruch Goldstein of Hebron, a member of Kach carried out the Cave of the Patriarchs massacre, killing 29 Muslim worshipers and injuring 125. The attack was widely condemned by the Israeli government and Jewish community. The Palestinian leadership has accused Israel of "encouraging and enabling" settler violence in a bid to provoke Palestinian riots and violence in retaliation. Violence perpetrated by Israeli settlers against Palestinians constitutes terrorism according to the U.S. Department of State, and former IDF Head of Central Command Avi Mizrahi stated that such violence constitutes "terror."
In mid-2008, a UN report recorded 222 acts of Israeli settler violence against Palestinians and IDF troops compared with 291 in 2007. This trend reportedly increased in 2009. Maj-Gen Shamni said that the number had risen from a few dozen individuals to hundreds, and called it "a very grave phenomenon." In 2008–2009, the defense establishment adopted a harder line against the extremists. This group responded with a tactic dubbed "price tagging," vandalizing Palestinian property whenever police or soldiers were sent in to dismantle outposts. From January through to September 2013, 276 attacks by settlers against Palestinians were recorded.
Leading religious figures in the West Bank have harshly criticized these tactics. Rabbi Menachem Froman of Tekoa said that "Targeting Palestinians and their property is a shocking thing, (...) It's an act of hurting humanity. (...) This builds a wall of fire between Jews and Arabs." Other rabbis have been accused of inciting violence against non-Jews. In response to settler violence, the Israeli government said that it would increase law enforcement and cut off aid to illegal outposts. Some settlers are thought to lash out at Palestinians because they are "easy victims." The United Nations accused Israel of failing to intervene and arrest settlers suspected of violence. In 2008, Haaretz wrote that "Israeli society has become accustomed to seeing lawbreaking settlers receive special treatment and no other group could similarly attack Israeli law enforcement agencies without being severely punished."
In September 2011, settlers vandalized a mosque and an army base. They slashed tires and cut cables of 12 army vehicles and sprayed graffiti. In November 2011, the United Nations Office for Coordination of Human Affairs (OCHA) in the Palestinian territories published a report on settler violence that showed a significant rise compared to 2009 and 2010. The report covered physical violence and property damage such as uprooted olive trees, damaged tractors and slaughtered sheep. The report states that 90% of complaints filed by Palestinians have been closed without charge.
According to EU reports, Israel has created an "atmosphere of impunity" for Jewish attackers, which is seen as tantamount to tacit approval by the state. In the West Bank, Jews and Palestinians live under two different legal regimes and it is difficult for Palestinians to lodge complaints, which must be filed in Hebrew in Israeli settlements.
The 27 ministers of foreign affairs of the European Union published a report in May 2012 strongly denouncing policies of the State of Israel in the West Bank and denouncing "continuous settler violence and deliberate provocations against Palestinian civilians." The report by all EU ministers called "on the government of Israel to bring the perpetrators to justice and to comply with its obligations under international law."
In July 2014, a day after the burial of three murdered Israeli teens. Khdeir, a 16-year-old Palestinian, was forced into a car by 3 Israeli settlers on an East Jerusalem street. His family immediately reported the fact to Israeli Police who located his charred body a few hours later at Givat Shaul in the Jerusalem Forest. Preliminary results from the autopsy suggested that he was beaten and burnt while still alive. The murder suspects explained the attack as a response to the June abduction and murder of three Israeli teens. The murders contributed to a breakout of hostilities in the 2014 Israel–Gaza conflict.
In July 2015, a similar incident occurred where Israeli settlers made an arson attack on two Palestinian houses, one of which was empty; however, the other was occupied, resulting in the burning to death of a Palestinian infant; the four other members of his family were evacuated to the hospital suffering serious injuries. These two incidents received condemnation from the United States, European Union and even the IDF. The European Union criticized Israel for "failing to protect the Palestinian population".
Olive trees.
While the Economy of the Palestinian territories has shown signs of growth, the International Committee of the Red Cross reported that Palestinian olive farming has suffered. According to the ICRC, 10,000 olive trees were cut down or burned by settlers in 2007-2010. Foreign ministry spokesman Yigal Palmor said the report ignored official PA data showing that the economic situation of Palestinians had improved substantially, citing Mahmoud Abbas's comment to "The Washington Post" in May 2009, where he said "in the West Bank, we have a good reality, the people are living a normal life."
"Haaretz" blamed the violence during the olive harvest on a handful of extremists. In 2010, trees belonging to both Jews and Arabs were cut down, poisoned or torched. In the first two weeks of the harvest, 500 trees owned by Palestinians and 100 trees owned by Jews had been vandalized. In October 2013, 100 trees were cut down.
Violent attacks on olive trees seem to be facilitated by the apparently systematic refusal of the Israeli authorities to allow Palestinians to visit their own groves, some times for years, especially in cases where the groves are deemed to be too close to settlements.
Pro-Palestinian activist violence.
Pro-Palestinian activists who hold regular protests near the settlements have been accused of stone-throwing, physical assault and provocation. In 2008, Avshalom Peled, head of the Israel Police's Hebron district, called "left-wing" activity in the city dangerous and provocative, and accused activists of antagonizing the settlers in the hope of getting a reaction.
Palestinian violence against settlers.
Settlers are targeted by Palestinian armed groups who, according to Human Rights Watch, say that settlers are a legitimate target because they have forfeited their civilian status by residing in settlements that are illegal under international humanitarian law. Both Human Rights Watch and B'tselem rejected this argument on the basis that the legal status of the settlements has no effect the civilian status of their residents. Human Rights Watch said "prohibition against intentional attacks against civilians is absolute". B'tselem said "The settlers constitute a distinctly civilian population, which is entitled to all the protections granted civilians by international law. The Israeli security forces' use of land in the settlements or the membership of some settlers in the Israeli security forces does not affect the status of the other residents living among them, and certainly does not make them proper targets of attack."
Fatal attacks on settlers have included firing of rockets and mortars and drive-by shootings, also targeting infants and children. Violent incidents include the murder of Shalhevet Pass, a ten-month-old baby shot by a Palestinian sniper in Hebron, and the murder of two teenagers on 8 May 2001, whose bodies were hidden in a cave near Tekoa. In the Bat Ayin axe attack, children in Bat Ayin were attacked by a Palestinian wielding an axe and a knife. A 13-year-old boy was killed and another was seriously wounded. Rabbi Meir Hai, a father of seven, was killed in a drive-by shooting. In August 2011, five members of one family were killed in their beds. The victims were the father Ehud (Udi) Fogel, the mother Ruth Fogel, and three of their six children—Yoav, 11, Elad, 4, and Hadas, the youngest, a three-month-old infant. According to David Ha'ivri, and as reported by multiple sources, the infant was decapitated.
Environmental issues.
Municipal Environmental Associations of Judea and Samaria, an environmental awareness group, was established by the settlers to address sewage treatment problems and cooperate with the Palestinian Authority on environmental issues. According to a "Haaretz" study, settlers account for 10% of the population in the West Bank but produce 25% of the sewage output. Beit Duqqu and Qalqilyah have accused settlers of polluting their farmland and villagers claim children have become ill after swimming in a local stream. Legal action was taken against 14 settlements by the Israeli Ministry of the Environment. The Palestinian Authority has also been criticized by environmentalists for not doing more to prevent water pollution. Settlers and Palestinians share the mountain aquifer as a water source, and both generate sewage and industrial effluents that endanger the aquifer. Friends of the Earth Middle East claimed that sewage treatment was inadequate in both sectors. Sewage from Palestinian sources was estimated at 46 million cubic meters a year, and sources from settler sources at 15 million cubic meters a year. A 2004 study found that sewage was not sufficiently treated in many settlements, while sewage from Palestinian villages and cities flowed into unlined cesspits, streams and the open environment with no treatment at all.
In a 2007 study, the Israel Nature and Parks Authority and Israeli Ministry of Environmental Protection, found that Palestinian towns and cities produced 56 million cubic meters of sewage per year, 94 percent discharged without adequate treatment, while Israeli sources produced 17.5 million cubic meters per year, 31.5 percent without adequate treatment.
According to Palestinian environmentalists, the settlers operate industrial and manufacturing plants that can create pollution as many do not conform to Israeli standards. In 2005, an old quarry between Kedumim and Nablus was slated for conversion into an industrial waste dump. Pollution experts warned that the dump would threaten Palestinian water sources.
Impact on Palestinian demographics.
The Consortium for Applied Research on International Migration (CARIM) has reported in their 2011 migration profile for Palestine that the reasons for individuals to leave the country are similar to those of other countries in the region and they attribute less importance to the specific political situation of the occupied Palestinian territory. Human Rights Watch in 2010 reported that Israeli settlement policies have had the effect of "forcing residents to leave their communities".
In 2008, Condoleezza Rice suggested sending Palestinian refugees to South America, which might reduce pressure on Israel to withdraw from the settlements. Sushil P. Seth speculates that Israelis seem to feel that increasing settlements will force many Palestinians to flee to other countries and that the remainder will be forced to live under Israeli terms. Speaking anonymously with regard to Israeli policies in the South Hebron Hills, a UN expert said that the Israeli crackdown on alternative energy infrastructures like solar panels is part of a deliberate strategy in Area C.
"From December 2010 to April 2011, we saw a systematic targeting of the water infrastructure in Hebron, Bethlehem and the Jordan valley. Now, in the last couple of months, they are targeting electricity. Two villages in the area have had their electrical poles demolished. There is this systematic effort by the civil administration targeting all Palestinian infrastructure in Hebron. They are hoping that by making it miserable enough, they Palestinians will pick up and leave."
Educational institutions.
Ariel University, formerly the College of Judea and Samaria, is the major Israeli institution of higher education in the West Bank. With close to 13,000 students, it is Israel's largest public college. The college was accredited in 1994 and awards bachelor's degrees in arts, sciences, technology, architecture and physical therapy. The school's current temporary status is that of a "university institution" conferred by the Israel Defense Forces, but it remains without university accreditation.
500 Arabs begin studies in Ariel saying 'There's no racism here'.
Teacher training colleges include Herzog College in Alon Shvut and Orot Israel College in Elkana. Ohalo College is located in Katzrin, in the Golan Heights. Curricula at these institutions are overseen by the Council for Higher Education in Judea and Samaria (CHE-JS).
In March 2012, The Shomron Regional Council was awarded the Israeli Ministry of Education's first prize National Education Award in recognizing its excellence in investing substantial resources in the educational system. The Shomron Regional Council achieved the highest marks in all parameters (9.28 / 10). Gershon Mesika, the head of the regional council, declared that the award was a certificate of honour of its educators and the settlement youth who proved their quality and excellence.
Strategic significance.
In 1983 an Israeli government plan entitled "Master Plan and Development Plan for Settlement in Samaria and Judea" envisaged placing a "maximally large Jewish population" in priority areas to accomplish incorporation of the West Bank in the Israeli "national system". According to Ariel Sharon, strategic settlement locations would work to preclude the formation of a Palestinian state.
Palestinians argue that the policy of settlements constitutes an effort to preempt or sabotage a peace treaty that includes Palestinian sovereignty, and claim that the presence of settlements harm the ability to have a viable and contiguous state. This was also the view of the Israeli Vice Prime Minister Haim Ramon in 2008, saying "the pressure to enlarge Ofra and other settlements does not stem from a housing shortage, but rather is an attempt to undermine any chance of reaching an agreement with the Palestinians ..."
The Israel Foreign Ministry asserts that some settlements are legitimate, as they took shape when there was no operative diplomatic arrangement, and thus they did not violate any agreement. Based on this, they assert that:
Dismantling of settlements.
An early evacuation took place in 1982 as part of the Egypt–Israel Peace Treaty, when Israel was required to evacuate its settlers from the 18 Sinai settlements. Arab parties to the conflict had demanded the dismantlement of the settlements as a condition for peace with Israel. The evacuation was carried out with force in some instances, for example in Yamit. The settlements were demolished, as it was feared that settlers might try to return to their homes after the evacuation.
Israel's unilateral disengagement plan took place in 2005. It involved the evacuation of settlements in the Gaza Strip and part of the West Bank, including all 21 settlements in Gaza and four in the West Bank, while retaining control over Gaza's borders, coastline, and airspace. Most of these settlements had existed since the early 1980s, some were over 30 years old; the total population involved was more than 10,000. There was significant opposition to the plan among parts of the Israeli public, and especially those living in the territories. George W. Bush said that a permanent peace deal would have to reflect "demographic realities" in the West Bank regarding Israel's settlements.
Within the former settlements, almost all buildings were demolished by Israel, with the exception of certain government and religious structures, which were completely emptied. Under an international arrangement, productive greenhouses were left to assist the Palestinian economy but these were destroyed within hours by Palestinian looters. Following the withdrawal, many of the former synagogues were torched and destroyed by Palestinians. The Palestinian leadership "maintained" that the synagogues were "symbols of Israeli occupation." Kofi Annan, the Secretary-General of the United Nations at the time, said the Palestinian Authority had a "moral responsibility to protect the synagogues as places with religious significance."
Some believe that settlements need not necessarily be dismantled and evacuated, even if Israel withdraws from the territory where they stand, as they can remain under Palestinian rule. These ideas have been expressed both by left-wing Israelis, and by Palestinians who advocate the two-state solution, and by extreme Israeli right-wingers and settlers who object to any dismantling and claim links to the land that are stronger than the political boundaries of the state of Israel.
The Israeli government has often threatened to dismantle outposts. Some have actually been dismantled, occasionally with use of force; this led to settler violence.
Palestinian statehood bid of 2011.
American refusal to declare the settlements illegal was said to be the determining factor in the 2011 attempt to declare Palestinian statehood at the United Nations, the so-called Palestine 194 initiative.
Israel announced additional settlements in response to the Palestinian diplomatic initiative and Germany responded by moving to stop deliveries to Israel of submarines capable of carrying nuclear weapons.
Finally in 2012, several European states switched to either abstain or vote for statehold in response to continued settlement construction. Israel approved further settlements in response to the vote, which brought further worldwide condemnation.
Impact on peace process.
The settlements have been a source of tension between Israel and the U.S. Jimmy Carter regarded the settlements as illegal and tactically unwise. Ronald Reagan stated that they were legal but an obstacle to negotiations. In 1991, the U.S. delayed a subsidized loan to pressure Israel on the subject of settlement-building in the Jerusalem-Bethlehem corridor. In 2005, U.S. declared support for "the retention by Israel of major Israeli population centers as an outcome of negotiations," reflecting the statement by George W. Bush that a permanent peace treaty would have to reflect "demographic realities" in the West Bank. In June 2009, Barack Obama said that the United States "does not accept the legitimacy of continued Israeli settlements."
Palestinians claim that Israel has undermined the Oslo accords and peace process by continuing to expand the settlements. Settlements in the Sinai Peninsula were evacuated and razed in the wake of the peace agreement with Egypt. The 27 ministers of foreign affairs of the European Union published a report in May 2012 strongly denouncing policies of the State of Israel in the West Bank and finding that Israeli settlements in the West Bank are illegal and "threaten to make a two-state solution impossible.""/> In the framework of the Oslo I Accord of 1993 between the Israeli government and the Palestine Liberation Organization (PLO), a modus vivendi was reached whereby both parties agreed to postpone a final solution on the destination of the settlements to the permanent status negotiations (Article V.3). Israel claims that settlements thereby were not prohibited, since there is no explicit interim provision prohibiting continued settlement construction, the agreement does register an undertaking by both sides, namely that "Neither side shall initiate or take any step that will change the status of the West Bank and the Gaza Strip pending the outcome of the permanent status negotiations" (Article XXX1 (7)), which has been interpreted as, not forbidding settlements, but imposing severe restrictions on new settlement building after that date. Melanie Jacques argued in this context that even 'agreements between Israel and the Palestinians which would allow settlements in the OPT, or simply tolerate them pending a settlement of the conflict, violate the Fourth Geneva Convention.'
Final status proposals have called for retaining long-established communities along the Green Line and transferring the same amount of land in Israel to the Palestinian state. The Clinton administration proposed that Israel keep some settlements in the West Bank, especially those in large blocs near the pre-1967 borders of Israel, with the Palestinians receiving concessions of land in other parts of the country. Both Clinton and Tony Blair pointed out the need for territorial and diplomatic compromise based on the validity of some of the claims of both sides.
Fayed Mustafa, Palestinian ambassador to Russia, called for the return of Palestinian territories to Egypt and Jordan if talks failed.
As Minister of Defense, Ehud Barak approved a plan requiring security commitments in exchange for withdrawal from the West Bank. Barak also expressed readiness to cede parts of East Jerusalem and put the holy sites in the city under a "special regime."
On 14 June 2009, Israeli Prime Minister Benjamin Netanyahu, as an answer to U.S. President Barack Obama's speech in Cairo, delivered a speech setting out his principles for a Palestinian-Israeli peace, among others, he alleged "... we have no intention of building new settlements or of expropriating additional land for existing settlements." In March 2010, the Netanyahu government announced plans for building 1,600 housing units in Ramat Shlomo across the Green Line in East Jerusalem during U.S. Vice President Joe Biden's visit to Israel causing a diplomatic row.
On 6 September 2010, Jordanian King Abdullah II and Syrian President Bashar al-Assad said that Israel would need to withdraw from all of the lands occupied in 1967 in order to achieve peace with the Palestinians.
Bradley Burston has said that a negotiated or unilateral withdraw from most of the settlements in the West Bank is gaining traction in Israel.
In November 2010, the United States offered to "fight against efforts to delegitimize Israel" and provide extra arms to Israel in exchange for a continuation of the settlement freeze and a final peace agreement, but failed to come to an agreement with the Israelis on the exact terms.
In December 2010, the United States criticised efforts by the Palestinian Authority to impose borders for the two states through the United Nations rather than through direct negotiations between the two sides. In February 2011, it vetoed a draft resolution to condemn all Jewish settlements established in the occupied Palestinian territory since 1967 as illegal. The resolution, which was supported by all other Security Council members and co-sponsored by nearly 120 nations, would have demanded that "Israel, as the occupying power, immediately and completely ceases all settlement activities in the occupied Palestinian territory, including East Jerusalem and that it fully respect its legal obligations in this regard." The U.S. representative said that while it agreed that the settlements were illegal, the resolution would harm chances for negotiations. Israel's deputy Foreign Minister, Daniel Ayalon, said that the "UN serves as a rubber stamp for the Arab countries and, as such, the General Assembly has an automatic majority," and that the vote "proved that the United States is the only country capable of advancing the peace process and the only righteous one speaking the truth: that direct talks between Israel and the Palestinians are required." Palestinian negotiators, however, have refused to resume direct talks until Israel ceases all settlement activity.
In November 2009, Israeli Prime Minister Netanyahu issued a 10-month settlement freeze in the West Bank in an attempt to restart negotiations with the Palestinians. The freeze did not apply to building in Jerusalem in areas across the green line, housing already under construction and existing construction described as "essential for normal life in the settlements" such as synagogues, schools, kindergartens and public buildings. The Palestinians refused to negotiate without a complete halt to construction. In the face of pressure from the United States and most world powers supporting the demand by the Palestinian Authority that Israel desist from settlement project in 2010, Israel's ambassador to the UN Meron Reuben said Israel would only stop settlement construction after a peace agreement is concluded, and expressed concern were Arab countries to press for UN recognition of a Palestinian state before such an accord. He cited Israel's dismantlement of settlements in both the Sinai which took place after a peace agreement, and its unilateral dismantlement of settlements in the Gaza Strip. He presumed that settlements would stop being built were Palestinians to establish a state in a given area.
Proposals for land swap.
The Clinton Parameters, a 2000 peace proposal by then U.S. President Bill Clinton, included a plan on which the Palestinian State was to include 94–96% of the West Bank, and around 80% of the settlers were to be under Israeli sovereignty, and in exchange for that, Israel will concede some territory (so called 'Territory Exchange' or 'Land Swap') within the Green Line (1967 borders). The swap would consist of 1–3% of Israeli territory, such that the final borders of the West Bank part of the Palestinian state would include 97% of the land of the original borders.
In 2010, Palestinian Authority President Mahmoud Abbas said that the Palestinians and Israel have agreed on the principle of a land swap. The issue of the ratio of land Israel would give to the Palestinians in exchange for keeping settlement blocs is an issue of dispute, with the Palestinians demanding that the ratio be 1:1, and Israel insisting that other factors be considered as well.
Under any peace deal with the Palestinians, Israel intends to keep the major settlement blocs close to its borders, which contain over 80% of the settlers. Prime Ministers Yitzhak Rabin, Ariel Sharon, and Benjamin Netanyahu have all stated Israel's intent to keep such blocs under any peace agreement. U.S. President George W. Bush acknowledged that such areas should be annexed to Israel in a 2004 letter to Prime Minister Sharon.
The European Union position is that any annexation of settlements should be done as part of mutually agreed land swaps, which would see the Palestinians controlling territory equivalent to the territory captured in 1967. The EU says that it will not recognise any changes to the 1967 borders without an agreement between the parties.
Israeli Foreign Minister Avigdor Lieberman has proposed a plan which would see settlement blocs annexed to Israel in exchange for heavily Arab areas inside Israel as part of a population exchange.
According to Mitchell G. Bard: "Ultimately, Israel may decide to unilaterally disengage from the West Bank and determine which settlements it will incorporate within the borders it delineates. Israel would prefer, however, to negotiate a peace treaty with the Palestinians that would specify which Jewish communities will remain intact within the mutually agreed border of Israel, and which will need to be evacuated. Israel will undoubtedly insist that some or all of the "consensus" blocs become part of Israel".
Proposal of dual citizenship.
A number of proposals for the granting of Palestinian citizenship or residential permits to Jewish settlers in return for the removal of Israeli military installations from the West Bank have been fielded by such individuals as Arafat, Ibrahim Sarsur and Ahmed Qurei.
Israeli Minister Moshe Ya'alon said in April 2010 that ""just as Arabs live in Israel, so, too, should Jews be able to live in Palestine." ... "If we are talking about coexistence and peace, why the insistence that the territory they receive be ethnically cleansed of Jews?"".
The idea has been expressed by both advocates of the two-state solution and supporters of the settlers and conservative or fundamentalist currents in Israeli Judaism that, while objecting to any withdrawal, claim stronger links to the land than to the state of Israel.
Settlement expansion.
On 19 June 2011, Haaretz reported that the Israeli cabinet voted to revoke Defense Minister Ehud Barak's authority to veto new settlement construction in the West Bank, by transferring this authority from the Agriculture Ministry, headed by Barak ally Orit Noked, to the Prime Minister's office.
In 2009, newly elected Prime Minister Benjamin Netanyahu said: "I have no intention of building new settlements in the West Bank... But like all the governments there have been until now, I will have to meet the needs of natural growth in the population. I will not be able to choke the settlements." On 15 October 2009, he said the settlement row with the United States had been resolved.
In April 2012, four illegal outposts were retroactively legalized by the Israeli government. In June 2012, the Netanyahu government announced a plan to build 851 homes in five settlements: 300 units in Beit El and 551 units in other settlements.
Amid peace negotiations that showed little signs of progress, Israel issued on 3 November 2013, tenders for 1,700 new homes for Jewish settlers. The plots were offered in nine settlements in areas Israel says it intends to keep in any peace deal with the Palestinians. On 12 November, Peace Now revealed that the "Construction and Housing Ministry" had issued tenders for 24,000 more settler homes in the West Bank, including 4,000 in East Jerusalem. 2,500 units were planned in Ma'aleh Adumim, some 9,000 in the Gush Etzion Region, and circa 12,000 in the Binyamin Region, including 1,200 homes in the E1 area in addition to 3,000 homes in previously frozen E1 projects. Circa 15,000 homes of the 24,000 plan would be east of the West Bank Barrier and create the first new settlement blocs for two decades, and the first blocs ever outside the Barrier, far inside the West Bank.
As stated before, the Israeli government (as of 2015) has a program of residential subsidies in which Israeli settlers receive about double that given to Israelis in Tel Aviv and Jerusalem. As well, settlers in isolated areas receive three times the Israeli national average. From the beginning of 2009 to the end of 2013, the Israeli settlement population as a whole increased by a rate of over 4% per year. A "New York Times" article in 2015 stated that said building had been "at the heart of mounting European criticism of Israel."

</doc>
<doc id="15125" url="https://en.wikipedia.org/wiki?curid=15125" title="Irrealism (the arts)">
Irrealism (the arts)

Irrealism is a term that has been used by various writers in the fields of philosophy, literature, and art to denote specific modes of unreality and/or the problems in concretely defining reality. While in philosophy the term specifically refers to a position put forward by the American philosopher Nelson Goodman, in literature and art it refers to a variety of writers and movements. If the term has nonetheless retained a certain consistency in its use across these fields and would-be movements, it perhaps reflects the word’s position in general English usage: though the standard dictionary definition of "irreal" gives it the same meaning as "unreal", "irreal" is very rarely used in comparison with "unreal". Thus, it has generally been used to describe something which, while unreal, is so in a very specific or unusual fashion, usually one emphasizing not just the "not real," but some form of estrangement from our generally accepted sense of reality.
Irrealism in Literature.
In literature, the term irrealism was first used extensively in the United States in the 1970s to describe the post-realist "new fiction" of writers such as Donald Barthelme or John Barth. More generally, it described the notion that all forms of writing could only "offer particular versions of reality rather than actual descriptions of it," and that a story need not offer a clear resolution at its end. John Gardner, in "The Art of Fiction", cites in this context the work of Barthelme and its "seemingly limitless ability to manipulate techniques as modes of apprehension [which apprehend nothing." Though Barth, in a 1974 interview, stated, "irrealism—not antirealism or unrealism, but irrealism—is all that I would confidently predict is likely to characterize the prose fiction of the 1970s," this did not prove to be the case. Instead writing in the United States quickly returned to its realist orthodoxy and the term irrealism fell into disuse.
In recent years, however, the term has been revived in an attempt to describe and categorize, in literary and philosophical terms, how it is that the work of an irrealist writer differs from the work of writers in other, non-realistic genres (e.g., the fantasy of J.R.R. Tolkien, the magical realism of Gabriel García Márquez) and what the significance of this difference is. This can be seen in Dean Swinford's essay "Defining irrealism: scientific development and allegorical possibility".[http://cafeirreal.alicewhittenburg.com/review1a.htm] Approaching the issue from a structuralist and narratological point of view, he has defined irrealism as a "peculiar mode of postmodern allegory" that has resulted from modernity’s fragmentation and dismantling of the well-ordered and coherent medieval system of symbol and allegory. Thus a lion, when presented in a given context in medieval literature, could only be interpreted in a single, approved way. Contemporary literary theory, however, denies the attribution of such fixed meanings. According to Swinford, this change can be attributed in part to the fact that "science and technical culture have changed perceptions of the natural world, have significantly changed the natural world itself, thereby altering the vocabulary of symbols applicable to epistemological and allegorical attempts to understand it." Thus irreal works such as Italo Calvino's "Cosmicomics" and Jorge Luis Borges' "Ficciones" can be seen as an attempt to find a new allegorical language to explain our changed perceptions of the world that have been brought about by our scientific and technical culture, especially concepts such as quantum physics or the theory of relativity. "The Irrealist work, then, operates within a given system," writes Swinford, "and attests to its plausibility, despite the fact that this system, and the world it represents, is often a mutation, an aberration."
The online journal "The Cafe Irreal" on the other hand, has defined irrealism as being a type of existentialist literature in which the means are continually and absurdly rebelling against the ends that we have determined for them. An example of this would be Franz Kafka's story "The Metamorphosis", in which the salesman Gregor Samsa's plans for supporting his family and rising up in rank by hard work and determination are suddenly thrown topsy-turvy by his sudden and inexplicable transformation into a man-sized insect. Such fiction is said to emphasize the fact that human consciousness, being finite in nature, can never make complete sense of, or successfully order, a universe that is infinite in its aspects and possibilities. Which is to say: as much as we might try to order our world with a certain set of norms and goals (which we consider our real world), the paradox of a finite consciousness in an infinite universe creates a zone of irreality ("that which is beyond the real") that offsets, opposes, or threatens the real world of the human subject. Irrealist writing often highlights this irreality, and our strange fascination with it, by combining the unease we feel because the real world doesn't conform to our desires with the narrative quality of the dream state (where reality is constantly and inexplicably being undermined); it is thus said to communicate directly, "by feeling rather than articulation, the uncertainties inherent in human existence or, to put it another way... the irreconcilability between human aspiration and human reality." [http://cafeirreal.alicewhittenburg.com/what_is_irr.htm If the irreal story can be considered an allegory, then, it would be an allegory that is "so many pointers to an unknown meaning," in which the meaning is felt more than it is articulated or systematically analyzed.
Irrealism in Art.
Various writers have addressed the question of Irrealism in Art. Many salient observations on Irrealism in Art are found in Nelson Goodman's "Languages of Art". Goodman himself produced some multimedia shows, one of which inspired by hockey and is entitled "Hockey Seen: A Nightmare in Three Periods and Sudden Death".
Garret Rowlan, writing in "The Cafe Irreal", writes that the malaise present in the work of the Italian artist Giorgio de Chirico, "which recalls Kafka, has to do with the sense of another world lurking, hovering like the long shadows that dominate de Chirico's paintings, which frequently depict a landscape at twilight's uncertain hour. Malaise and mystery are all by-products of the interaction of the real and the unreal, the rub and contact of two worlds caught on irrealism's shimmering surface." [http://cafeirreal.alicewhittenburg.com/review4a.htm]
The writer Dean Swinford, whose concept of irrealism was described at length in the section "Irrealism in Literature", wrote that the artist Remedios Varos, in her painting "The Juggler", "creates a personal allegorical system which relies on the predetermined symbols of Christian and classical iconography. But these are quickly refigured into a personal system informed by the scientific and organized like a machine...in the Irreal work, allegory operates according to an altered, but constant and orderly iconographic system."
Artist Tristan Tondino has made a number of claims about Irrealism. Most of his claims are found in his paintings, many of which are Lettrist Abstractions. "There is no specific style to Irrealist Art. It is the result of awareness that every human act is the result of the limitations of the world of the actor." 
In Australia, the art journal "the art life" has recently detected the presence of a "New Irrealism" among the painters of that country, which is described as being an "approach to painting that is decidedly low key, deploying its effects without histrionic showmanship, while creating an eerie other world of ghostly images and abstract washes." What exactly constituted the "old" irrealism, they do not say.
Irrealist Art, Film and Music Edition.
Irrealist Art Edition is a publishing company created in the 90s by contemporary plastic artist Frédéric Iriarte. Together with the Estonian poet, writer and art critic Ilmar Laaban, they developed their concept of Irrealism through several essays, exhibitions, projects, manifest and a book, "Irréalisation". Irrealist Art Edition ISBN 91-630-2304-0
Irrealism in music.
Some hardcore bands in Italy have claimed to be irrealist.

</doc>
<doc id="15127" url="https://en.wikipedia.org/wiki?curid=15127" title="Internet humor">
Internet humor

The Internet has long been a resource for the circulation of humorous ideas and jokes. Countless web-sites are devoted to the collection of Internet humor, and every day e-mail crosses the world, containing the text of humorous articles, or jokes about current events.
"Internet humor" is distinguishable from "Humor on the Internet" through the concept of ownership. There are definite examples of humor restricted by copyright law on the internet; examples include the Dilbert cartoons of Scott Adams or the newspaper columns of Dave Barry. "Internet humor" is regarded as that which belongs to the public domain.
Internet humor may also be regarded as humor that specifically relies on characteristics belonging to the Internet, such as "geek" or "hacker" humor (i.e., humor that would not exist if not for the Internet), some of which can be considered ironic. 
Examples include the IETF's April Fools's Day RFCs.
Generally, this type of semi-institutionalized humor starts as a specific group's in-joke, and grows until it reaches a significant portion of Internet users, gaining popularity, "rules" and mythos.
The concept of authorship with regard to Internet humor is very difficult to define. Frequently a "list" type joke may get started but within a few generations of distribution it evolves beyond recognition. A classic example is the well-known "you have two cows" joke — after circulating in other media throughout the 1980s, it seems to have first appeared on the Internet in 1993 with simple descriptions of communism, capitalism, and socialism. However, it was later expanded to include all forms of government, regional variations, philosophical systems, and even art movements. Attempting to define an "author" of the joke hence becomes impossible, and it becomes a publicly owned resource, simply because no one could validly claim legitimate ownership.
Though the Internet has allowed the global explosion of collectively authored comedy, its precursors existed on bulletin boards, corporate messaging systems, and even through such low-tech mechanisms as the facsimile since at least the 1970s.
Daily jokes.
The internet now has many resources where new jokes are available each day. There are literally hundreds of web pages whose authors will post a new joke or perhaps many jokes on a daily basis. Many internet users will visit the same site for their daily dose of humor. Emails containing a new joke can be subscribed to in many cases.
The growing popularity of blogs has contributed to this. There are now many weblogs which have the sole purpose of posting new jokes regularly. Weblog readers often comment on jokes they find particularly original and amusing.
Internet forum humor.
Internet forum humor somewhat differs from general Internet humor. 
Varying from different communities, Internet forum humor often involves image macros, Internet memes, random objects and people, false news stories and sarcasm.

</doc>
<doc id="15129" url="https://en.wikipedia.org/wiki?curid=15129" title="You have two cows">
You have two cows

"You have two cows" refers to a form of political satire involving variations of a scenario, where what occurs to the eponymous cows is used to demonstrate how certain political systems function.
History.
Jokes of this type attracted the attention of a scholar in the USA as early as 1944. An article in "The Modern Language Journal" lists the following classical ones:
Bill Sherk mentions that such lists circulated throughout the United States since around 1936 under the title "Parable of the Isms". A column in "The Chicago Daily Tribune" in 1938 attributes a version involving socialism, communism, fascism and New Dealism to an address by Silas Strawn to the Economic Club of Chicago on 29 November 1935.
Notable usages.
Jokes of this genre formed the base of a monologue by comedian Pat Paulsen on "The Smothers Brothers Comedy Hour" in the late 1960s. Satirising the satire, he appended this comment to capitalism: "...Then put both of them in your wife's name and declare bankruptcy." This material was later used as an element of his satirical US presidential campaign in 1968, and was included on his 1968 comedy album "Pat Paulsen for President".
Richard M Steers and Luciara Nardon in their book about global economy use the "two cows" metaphor to illustrate the concept of cultural differences. They write that jokes of the kind:
– are considered funny because they are realistic caricatures of various cultures, and the pervasiveness of such jokes stems from the significant cultural differences. Steers and Nardon also state that others believe such jokes present cultural stereotypes and must be viewed with caution.

</doc>
<doc id="15134" url="https://en.wikipedia.org/wiki?curid=15134" title="Lightbulb joke">
Lightbulb joke

A lightbulb joke is a joke that asks how many people of a certain group are needed to change, replace, or screw in a light bulb. Generally, the punch line answer highlights a stereotype of the target group. There are numerous versions of the lightbulb joke satirizing a wide range of cultures, beliefs and occupations.
Early versions of the joke, popular in the late 1960s and the 1970s, were used to insult the intelligence of Poles ("Polish jokes"). For instance:
Although lightbulb jokes tend to be derogatory in tone ("e.g.", "How many drummers..." / "Four: one to hold the light bulb and three to drink until the room spins"), the people targeted by them may take pride in the stereotypes expressed and are often themselves the jokes' originators. Lightbulb jokes applied to subgroups can be used to ease tensions between them.
Variations.
Many versions of the joke are puns on the words "change" or "screw":
or
Lightbulb jokes may be responses to current events, particularly those related to energy and political power.
For example, the lightbulb may not be changed at all due to ongoing power outages.
"The Village Voice" held a $200 lightbulb joke contest around the time of the Iran hostage crisis, with the winning joke being:

</doc>
<doc id="15144" url="https://en.wikipedia.org/wiki?curid=15144" title="International Electrotechnical Commission">
International Electrotechnical Commission

The International Electrotechnical Commission (IEC; in French: "Commission électrotechnique internationale") is a non-profit, non-governmental international standards organization that prepares and publishes International Standards for all electrical, electronic and related technologies – collectively known as "electrotechnology". IEC standards cover a vast range of technologies from power generation, transmission and distribution to home appliances and office equipment, semiconductors, fibre optics, batteries, solar energy, nanotechnology and marine energy as well as many others. The IEC also manages three global conformity assessment systems that certify whether equipment, system or components conform to its International Standards.
The IEC charter embraces all electrotechnologies including energy production and distribution, electronics, magnetics and electromagnetics, electroacoustics, multimedia, telecommunication and medical technology, as well as associated general disciplines such as terminology and symbols, electromagnetic compatibility (by its Advisory Committee on Electromagnetic Compatibility, ACEC), measurement and performance, dependability, design and development, safety and the environment.
History.
The IEC held its inaugural meeting on 26 June 1906, following discussions between the British Institution of Electrical Engineers, the American Institute of Electrical Engineers, and others, which began at the 1900 Paris International Electrical Congress, and continued with Colonel R. E. B. Crompton playing a key role.
The IEC was instrumental in developing and distributing standards for units of measurement, particularly Gauss, Hertz, and Weber. It also first proposed a system of standards, the Giorgi System, which ultimately became the SI, or Système International d’unités (in English, the International System of Units).
In 1938, it published a multilingual international vocabulary to unify terminology relating to electrical, electronic and related technologies. This effort continues, and the International Electrotechnical Vocabulary (the on-line version of which is known as the "Electropedia") remains an important work in the electrical and electronic industries.
The CISPR ("Comité International Spécial des Perturbations Radioélectriques") – in English, the International Special Committee on Radio Interference – is one of the groups founded by the IEC.
Currently, 82 countries are members while another 82 participate in the Affiliate Country Programme, which is not a form of membership but is designed to help industrializing countries get involved with the IEC. Originally located in London, the commission moved to its current headquarters in Geneva in 1948. It has regional centres in Asia-Pacific (Singapore), Latin America (São Paulo, Brazil) and North America (Boston, United States).
Today, the IEC is the world's leading international organization in its field, and its standards are adopted as national standards by its members. The work is done by some 10,000 electrical and electronics experts from industry, government, academia, test labs and others with an interest in the subject.
IEC standards.
IEC standards have numbers in the range 60000–79999 and their titles take a form such as "IEC 60417: Graphical symbols for use on equipment". The numbers of older IEC standards were converted in 1997 by adding 60000, for example IEC 27 became IEC 60027.
The IEC cooperates closely with the International Organization for Standardization (ISO) and the International Telecommunication Union (ITU). In addition, it works with several major standards development organizations, including the IEEE with which it signed a cooperation agreement in 2002, which was amended in 2008 to include joint development work.
Standards developed jointly with ISO such as "ISO/IEC 26300, Open Document Format for Office Applications (OpenDocument) v1.0" carry the acronym of both organizations. The use of the ISO/IEC prefix covers publications from ISO/IEC Joint Technical Committee 1 - Information Technology, as well as conformity assessment standards developed by ISO CASCO and IEC CAB (Conformity Assessment Board). Other standards developed in cooperation between IEC and ISO are assigned numbers in the 80000 series, such as IEC 82045-1.
The 60000 series of standards are also found preceded by EN to indicate the IEC standards harmonized as European standards; for example IEC 60034 would be EN 60034.
IEC standards are also being adopted as harmonized standards by other certifying bodies such as BSI (United Kingdom), CSA (Canada), UL & ANSI/INCITS (United States), SABS (South Africa), SAI (Australia), SPC/GB (China) and DIN (Germany). IEC standards harmonized by other certifying bodies generally have some noted differences from the original IEC standard.
Membership and participation.
The IEC is made up of members, called national committees, and each NC represents its nation's electrotechnical interests in the IEC. This includes manufacturers, providers, distributors and vendors, consumers and users, all levels of governmental agencies, professional societies and trade associations as well as standards developers from national standards bodies. National committees are constituted in different ways. Some NCs are public sector only, some are a combination of public and private sector, and some are private sector only. About 90% of those who prepare IEC standards work in industry.
IEC Member countries include:
In 2001 and in response to calls from the WTO to open itself to more developing nations, the IEC launched the Affiliate Country Programme to encourage developing nations to become involved in the Commission's work or to use its International Standards. Countries signing a pledge to participate in the work and to encourage the use of IEC Standards in national standards and regulations are granted access to a limited number of technical committee documents for the purposes of commenting. In addition, they can select a limited number of IEC Standards for their national standards' library. Countries as of 2011 participating in the Affiliate Country Programme are:

</doc>
<doc id="15145" url="https://en.wikipedia.org/wiki?curid=15145" title="ISO 9660">
ISO 9660

ISO 9660 is a file system standard published by the International Organization for Standardization (ISO) for optical disc media.
It aims at supporting different computer operating systems such as Windows, classic Mac OS, and Unix-like systems, so that data may be exchanged.
History.
ISO 9660 traces its roots to the High Sierra Format file system. High Sierra arranged file information in a dense, sequential layout to minimize nonsequential access by using a hierarchical (eight levels of directories deep) tree file system arrangement, similar to UNIX and FAT. To facilitate cross platform compatibility, it defined a minimal set of common file attributes (directory or ordinary file and time of recording) and name attributes (name, extension, and version), and used a separate system use area where future optional extensions for each file may be specified.
High Sierra was adopted in December 1986 (with changes) as an international standard by Ecma International as ECMA-119 and submitted for fast tracking to the ISO, where it was eventually accepted as ISO 9660:1988.
In 2013, ISO published Amendment 1 to the ISO 9660 standard, introducing new data structures and relaxed file name rules intended to "bring harmonization between ISO 9660 and widely used 'Joliet Specification'."
Specifications.
Overall structure.
The following is the rough overall structure of the ISO 9660 file system:
The System Area, the first 32,768 data bytes of the disk (16 sectors of 2,048 bytes each), is unused by ISO 9660 and therefore available for other uses. For example, a CD-ROM may contain an alternative file system descriptor in this area, as it is often used by hybrid CDs to offer Mac OS-specific content.
All multi-byte values are stored twice, in little-endian and big-endian format, either one-after-another in what the specification calls "both-byte orders", or in duplicated data structures such as the path table. As the structures have been designed with unaligned members, this "both endian" encoding does however not help implementors as the data structures need to be read byte-wise to convert them to properly aligned data.
Volume descriptor set.
The data area begins with a set of one or more "volume descriptors", terminated with a "volume descriptor set terminator". Collectively the "volume descriptor set" acts as a header for the data area, describing its content (similar to the BIOS parameter block used by FAT and NTFS formatted disks).
The "volume descriptor set terminator" is simply a particular type of "volume descriptor" with the purpose of marking the end of this set of structures.
Volume descriptor.
Each volume descriptor is 2048 bytes in size, fitting perfectly into a single Mode 1 or Mode 2 Form 1 sector. They have the following structure:
The data field of a volume descriptor may be subdivided into several fields, with the exact content depending on the type.
Standard volume descriptor types are the following:
An ISO 9660 compliant disk contains at least one "Primary Volume Descriptor" describing the file system and a "Volume Descriptor Set Terminator" for indicating the end of the descriptor sequence.
The Primary Volume Descriptor provides information about the volume, characteristics and metadata, including a root directory record that indicates in which sector the root directory is located. Other fields contain the description or name of the volume, and information about who created it and with which application. The size of the logical blocks which the file system uses to segment the volume is also stored in a field inside the primary volume descriptor, as well as the amount of space occupied by the volume (measured in number of logical blocks).
In addition to the Primary Volume Descriptor(s), "Supplementary Volume Descriptors" or "Enhanced Volume Descriptors" may be present.
Supplementary Volume Descriptors describe the same volume as the Primary Volume Descriptor does, and are normally used for providing additional code page support when the standard code tables are insufficient. The standard specifies that ISO 2022 is used for managing code sets that are wider than 8 bytes, and that ISO 2375 escape sequences are used to identify each particular code page used. Consequently, ISO 9660 supports international single-byte and multi-byte character sets, provided they fit into the framework of the referenced standards. However, ISO 9660 does not specify any code pages that are guaranteed to be supported: all use of code tables other than those defined in the standard itself are subject to agreement between the originator and the recipient of the volume.
Enhanced Volume Descriptors were introduced in ISO 9660, Amendment 1. They relax some of the requirements of the other volume descriptors and the directory records referenced by them: for example, the directory depth can exceed eight, file identifiers need not contain '.' or file version number, the length of a file and directory identifier is maximized to 207.
Redundant copies of each volume descriptor can also be included in case the first copy of the descriptor becomes corrupt.
Directories and files.
Directory entries are stored following the location of the root directory entry, where evaluation of filenames is begun. Both directories and files are stored as extents, which are sequential series of sectors.
Files and directories are differentiated only by a file attribute that indicates its nature (similar to Unix). The attributes of a file are stored in the directory entry that describes the file, and optionally in the extended attribute record.
To locate a file, the directory names in the file's path can be checked sequentially, going to the location of each directory to obtain the location of the subsequent subdirectory. However, a file can also be located through the path table provided by the file system. This path table stores information about each directory, its parent and its location on disk. Since the path table is stored in a contiguous region, it can be searched much faster than jumping to the particular locations of each directory in the file's path, thus reducing seek time.
The standard specifies three nested levels of interchange (paraphrased from section 10):
Additional restrictions in the body of the standard: The depth of the directory hierarchy must not exceed 8 (root directory being at level 1), and the path length of any file must not exceed 255. (section 6.8.2.1).
The standard also specifies the following name restrictions (sections 7.5 and 7.6):
Some CD authoring applications allow the user to use almost any character. While, strictly speaking, this does not conform to the ISO 9660 standard, most operating systems which can read ISO 9660 file systems have no problem with out-of-spec names. However, the names could appear wrong to the user.
Path tables.
Path tables summarize the directory structure of the relevant directory hierarchy, providing only the directory identifier, the location of the extent in which the directory is recorded, the length of any extended attributes associated with the directory, and the index of its parent directory path table entry.
Limitations.
Directory depth limit.
The restrictions on filename length (8 characters plus 3 character extension for interchange level 1) and directory depth (8 levels, including the root directory) are a more serious limitation of the ISO 9660 file system.
The Rock Ridge extension works around the 8 directory depth limit by folding paths. In practice however, few drivers and OSes care about the directory depth, so this rule is often ignored.
In addition to the restrictions mentioned above, a CD-ROM producer may choose one of the lower Levels of Interchange specified in chapter 10 of the standard, and further restrict file name length from 30 characters to only 8+3 in file identifiers, and 8 in directory identifiers in order to promote interchangeability with implementations that do not implement the full standard. (This is sometimes mistakenly interpreted as a restriction in the ISO 9660 standard itself.)
The 2/4 GiB file size limit.
All numbers in ISO 9660 file systems except the single byte value used for the GMT offset are unsigned numbers. As the length of a file's extent on disk is stored in a 32 bit value, it allows for a maximum length of just over 4.2 GB (more precisely, one byte less than 4 GiB). (Note: Some older operating systems may handle such values incorrectly (i.e., signed instead of unsigned), which would make it impossible to access files larger than 2 GB in size. The latter holds true also for operating systems without large file support.)
Based on this, it is often assumed that a file on an ISO 9660 formatted disc cannot be larger than 232-1 in size, as the file's size is stored in an unsigned 32 bit value, for which 232-1 is the maximum.
It is, however, possible to circumvent this limitation by using the multi-extent (fragmentation) feature of ISO 9660 Level 3 to create ISO 9660 filesystems and single files up to 8 TB. With this, files larger than 4 GB can be split up into multiple extents (sequential series of sectors), each not exceeding the 4 GB limit.
For example, the free software such as InfraRecorder, ImgBurn and mkisofs as well as Roxio Toast are able to create ISO 9660 filesystems that use multi-extent files to store files larger than 4 GB on appropriate media such as recordable DVDs.
Empirical tests with a 4.2 GB fragmented file on a DVD media have shown that Microsoft Windows XP supports this, while Mac OS X (as of 10.4.8) does not handle this case properly. In the case of Mac OS X, the driver appears not to support file fragmentation at all (i.e. it only supports ISO 9660 Level 2 but not Level 3). Linux supports multiple extents. FreeBSD only shows and reads the last extent of a multi-extent file.
Limit on number of directories.
Another limitation, less well known, is the number of directories. The ISO image has a structure called "path table". For each directory in the image, the path table provides the number of its parent directory entry. The problem is that the parent directory number is a 16-bit number, limiting its range from 1 to 65,535. The content of each directory is written also in a different place, making the path table redundant, and suitable only for fast searching.
Some operating systems (e.g., Windows) use the path table, while others (e.g., Linux) do not. If an ISO image or disk consists of more than 65,535 directories, it will be readable in Linux, while in early Windows versions all files from the additional directories will be visible, but show up as empty (zero length). Current Windows versions appear to handle this correctly.
Some software tools can have problems managing the path table if the directory limit is exceeded. A popular application using ISO format, "mkisofs", aborts if there is a path table overflow. Nero Burning ROM (for Windows) and Pinnacle Instant CD/DVD do not check whether the problem occurs, and will produce an invalid ISO file or disk without warning. The tool isovfy cannot easily report this problem.
Extensions and improvements.
There are several extensions to ISO 9660 that relax some of its limitations. 
For operating systems which do not support any extensions, a name translation file TRANS.TBL must be used. It should be located in every directory, including the root directory. This is now obsolete, since few such operating systems are in use today .
The ISO 13490 standard is an extension to the ISO 9660 format that adds support for multiple sessions on a disc. Since ISO 9660 is by design a read-only, pre-mastered file system, all the data has to be written in one go or "session" to the medium. Once written, there is no provision for altering the stored content. ISO 13490 was created to allow adding more files to a writeable disc such as CD-R in multiple sessions.
The ISO 13346/ECMA-167 standard was designed in conjunction to the ISO 13490 standard to address most of the shortcomings of ISO 9660, and a subset of it evolved into the UDF format, which was adopted for DVDs.
JIS X 0606:1998, also known as ISO 9660:1999, is a Japanese Industrial Standard draft created by the Japanese National Body (JTC1 N4222) in order to make some improvements and remove some limitations from the original ISO 9660 standard. This draft was submitted in 1998, but it has not been ratified as an ISO standard yet. Some of its changes includes the removal of some restrictions imposed by the original standard by extending the maximum file name length to 207 characters, removing the eight-level maximum directory nesting limit, and removing the special meaning of the dot character in filenames. Some operating systems allow these relaxations as well when reading optical discs. Several disc authoring tools (such as Nero Burning ROM, mkisofs and ImgBurn) support a so-called "ISO 9660:1999" mode (sometimes called "ISO 9660 v2" or "ISO 9660 Level 4" mode) that removes restrictions following the guidelines in the ISO 9660:1999 draft.
Disc images.
ISO 9660 file system images (ISO images) are a common way to electronically transfer the contents of CD-ROMs. They often have the filename extension codice_1 (codice_2 is less common, but also in use) and are commonly referred to as "ISOs".
Operating system support.
Most operating systems support reading of ISO 9660 formatted discs, and most new versions support the extensions such as Rock Ridge and Joliet. Operating systems that do not support the extensions usually show the basic (non-extended) features of a plain ISO 9660 disc.
Operating systems that support ISO 9660 and its extensions include the following:

</doc>
<doc id="15146" url="https://en.wikipedia.org/wiki?curid=15146" title="Ice skating">
Ice skating

Ice skating is the act moving on ice by using ice skates. It can be done for a variety of reasons, including exercise, leisure, traveling, and various sports. Ice skating occurs both on specially prepared ice surfaces (arenas, tracks, parks), both indoors and outdoors, as well as on naturally occurring bodies of frozen water, such as ponds, lakes and rivers.
History.
Early history of ice skating.
A study by Federico Formenti of the University of Oxford suggests that the earliest ice skating happened in southern Finland more than 3,000 years ago. Originally, skates were merely sharpened, flattened bone strapped to the bottom of the foot. Skaters did not actually skate on the ice, but rather glided on top of it. True skating emerged when a steel blade with sharpened edges was used. Skates now cut into the ice instead of gliding on top of it. Adding edges to ice skates was invented by the Dutch in the 13th or 14th century. These ice skates were made of steel, with sharpened edges on the bottom to aid movement. The construction of modern ice skates has stayed largely the same since then. In the Netherlands, ice skating was considered proper for all classes of people, as shown in many pictures by the Old Masters. 
Ice skating was also practised in China during the Song dynasty, and became popular among the ruling family of the Qing dynasty.
Rising popularity and first lubes.
Ice skating was brought to England from the Netherlands, where James II was briefly exiled in the 17th century. When he returned to England, this "new" sport was introduced to the British aristocracy, and was soon enjoyed by people from all walks of life.
The first organized skating club was the Edinburgh Skating Club, formed in the 1740s, (some claim the club was established as early as 1642).
An early contemporary reference to the Club appeared in the second edition (1783) of the Encyclopædia Britannica:
From this description and others, it is apparent that the form of skating practiced by club members was indeed an early form of figure skating rather than speed skating. For admission to the club, candidates had to pass a skating test where they performed a complete circle on either foot (e.g., a figure eight), and then jumped over first one hat, then two and three, placed over each other on the ice.
On the Continent, participation in ice skating was limited to members of the upper classes. Emperor Rudolf II of the Holy Roman Empire enjoyed ice skating so much, he had a large ice carnival constructed in his court in order to popularise the sport. King Louis XVI of France brought ice skating to Paris during his reign. Madame de Pompadour, Napoleon I, Napoleon III, and the House of Stuart were, among others, royal and upper class fans of ice skating.
The next skating club to be established was in London and was not founded until 1830. By the mid-19th century, ice skating was a popular pastime among the British upper and middle-classes, (Queen Victoria got to know her future husband, Prince Albert, through a series of ice skating trips.) and early attempts at the construction of artificial ice rinks were made during the 'rink mania' of 1841-44. As the technology for the maintenance of natural ice did not exist, these early rinks used a substitute consisting of a mixture of hog's lard and various salts. An item in the 8 May 1844 issue of Littell's "Living Age" headed "The Glaciarium" reported that "This establishment, which has been removed to Grafton street East' Tottenham Court Road, was opened on Monday afternoon. The area of artificial ice is extremely convenient for such as may be desirous of engaging in the graceful and manly pastime of skating".
Emergence as a sport.
Skating became popular as a recreation, a means of transport and spectator sport in The Fens in England for people from all walks of life. Racing was the preserve of workers, most of them agricultural labourers. It is not known when the first skating matches were held, but by the early nineteenth century racing was well established and the results of matches were reported in the press. Skating as a sport developed on the lakes of Scotland and the canals of the Netherlands. In the 13th and 14th centuries wood was substituted for bone in skate blades, and in 1572 the first iron skates were manufactured. When the waters froze, skating matches were held in towns and villages all over the Fens. In these local matches men (or sometimes women or children) would compete for prizes of money, clothing or food.
The winners of local matches were invited to take part in the grand or championship matches in which skaters from across the Fens would compete for cash prizes in front of crowds of thousands. The championship matches took the form of a Welsh main or "last man standing" contest. The competitors, 16 or sometimes 32, were paired off in heats and the winner of each heat went through to the next round. A course of 660 yards was measured out on the ice, and a barrel with a flag on it placed at either end. For a one-and-a-half mile race the skaters completed two rounds of the course, with three barrel turns.
In the Fens skates were called pattens, fen runners, or Whittlesey runners. The footstock was made of beechwood. A screw at the back was screwed into the heel of the boot, and three small spikes at the front kept the skate steady. There were holes in the footstock for leather straps to fasten it to the foot. The metal blades were slightly higher at the back than the front. In the 1890s fen skaters started to race in Norwegian style skates.
On Saturday 1 February 1879 a number of professional ice skaters from Cambridgeshire and Huntingdonshire met in the Guildhall, Cambridge, to set up the National Skating Association, the first national ice skating body in the world. The founding committee consisted of several landowners, a vicar, a fellow of Trinity College, a magistrate, two Members of Parliament, the mayor of Cambridge, the Lord Lieutenant of Cambridge, journalist James Drake Digby, the president of Cambridge University Skating Club, and Neville Goodman, a fellow of Peterhouse College (and son of Potto Brown’s milling partner, Joseph Goodman). The newly formed Association held their first one-and-a-half-mile British professional championship at Thorney in December 1879.
Figure skating.
The first instructional book concerning ice skating was published in London in 1772. The book, written by a British artillery lieutenant, Robert Jones, describes basic figure skating forms such as circles and figure eights. The book was written solely for men, as women did not normally ice skate in the late 18th century. It was with the publication of this manual that ice skating split into its two main disciplines, speed skating and figure skating.
The founder of modern figure skating as it is known today was Jackson Haines, an American. He was the first skater to incorporate ballet and dance movements into his skating, as opposed to focusing on tracing patterns on the ice. Haines also invented the sit spin and developed a shorter, curved blade for figure skating that allowed for easier turns. He was also the first to wear blades that were permanently attached to the boot.
For a time, the stiff and rigid British figure skating forms dominated in America, trumping Haines's more artistic way of skating. Haines instead attempted to spread his innovations in ice skating style in Europe, gaining success in such countries as Sweden and Austria. His style was still opposed by both his American colleagues as well as skaters from Victorian England, who continued to advocate a stiffer and more restrained style of skating. Haines continued to add new dance elements to his routines, and astounded a crowd in Vienna in the winter of 1868. Many in the audience expressed wonder at how a normal man could move over the ice in such a manner. Haines's performance led to the establishment of the Vienna School, which continued to develop Haines's artistic style.
The International Skating Union was founded in 1892 as the first international ice skating organization in Scheveningen, in the Netherlands. The Union created the first codified set of figure skating rules and governed international competition in speed and figure skating. The first Championship, known as the Championship of the Internationale Eislauf-Vereingung, was held in Saint Petersburg in 1896. The event had four competitors and was won by Gilbert Fuchs.
Physical mechanics of skating.
A skate can slide over ice because the ice molecules at the surface cannot properly bond with the molecules of the mass of ice beneath and thus are free to move like molecules of liquid water. These molecules remain in a semiliquid state, providing lubrication.
It had long been believed that ice is slippery because the pressure of an object in contact with it causes a thin layer to melt. The hypothesis was that the blade of an ice skate, exerting pressure on the ice, melts a thin layer, providing lubrication between the ice and the blade. This explanation, called "pressure melting", originated in the 19th century. This, however, did not account for skating on ice temperatures lower than −3.5 °C, whereas skaters often skate on lower-temperature ice. In the 20th century, an alternative explanation, called "friction heating", was proposed, whereby friction of the material was causing the ice layer melting. However, this theory also failed to explain skating at low temperature. In fact, neither explanation explained why ice is slippery when standing still even at below-zero temperatures.
Safety.
Skating depends on the roughness of the ice, the design of the ice skate, and the skill and experience of the skater. While serious injury is rare, a number of short track skaters have been paralysed after a fall when they hit the boarding. Falling can be fatal if a helmet is not worn to protect against serious head trauma. Accidents are rare but most common with collisions, hockey games, or pair skating.
The second, and more serious, danger is falling through the ice into the freezing water underneath when skating outdoors on a frozen body of water. Death can occur due to shock, hypothermia or drowning. It is often difficult or impossible for skaters to climb out of the water back onto the ice due to the ice repeatedly breaking, the skater being weighed down by skates and thick winter clothing, or the skater becoming disoriented under water. The skater may even not be able to find the hole through which they fell. This may result in drowning or hypothermia, but the rapid cooling can also create a state in which someone can be revived up to hours after having fallen in the water. For safety, it is recommended that skaters should never skate alone or in darkness and that they should bring nails or ice-claws when they are skating on a lake or river to allow them to get a grip on the ice and pull themselves out of the water if they fall through the ice.
Communal games on ice.
A number of recreational skating games can be played on ice.

</doc>
<doc id="15147" url="https://en.wikipedia.org/wiki?curid=15147" title="International Olympic Committee">
International Olympic Committee

The International Olympic Committee (IOC; French: Comité international olympique, CIO) is an international, non-profit, non-governmental organization based in Lausanne, Switzerland, created by Pierre de Coubertin, on 23 June 1894 with Demetrios Vikelas as its first president. Today its membership consists of 100 active members, 32 honorary members, and 1 honour member. The IOC is the supreme authority of the worldwide modern Olympic movement.
The IOC organises the modern Olympic Games and Youth Olympic Games, held in summer and winter, every four years. The first Summer Olympics organised by the IOC was held in Athens, Greece, in 1896; the first Winter Olympics was in Chamonix, France, in 1924. Until 1992, both Summer and Winter Olympics were held in the same year. After that year, however, the IOC shifted the Winter Olympics to the even years between Summer Games, to help space the planning of the two events from one another, and improve the financial balance of the IOC, which receives greater income on Olympic years. The first Summer Youth Olympics were in Singapore in 2010 and the first Winter Youth Olympics were held in Innsbruck in 2012.
Mission and role.
The stated mission of the International Olympic Committee (IOC) is to promote Olympic throughout the world and to lead the Olympic Movement.
Organization.
The IOC Session.
The IOC Session is the general meeting of the members of the IOC, held once a year in which each member has one vote. It is the IOC’s supreme organ and its decisions are final.
Extraordinary Sessions may be convened by the President or upon the written request of at least one third of the members.
Among others, the powers of the Session are:
Honours.
In addition to the Olympic medals for competitors, the IOC awards a number of other honours:
IOC members.
For most of its existence, the IOC was controlled by members who were selected by other members. Countries that had hosted the Games were allowed two members. When named, they did not become the representatives of their respective countries to the IOC, but rather the opposite, IOC members in their respective countries.
Cessation of membership.
The membership of IOC members ceases in the following circumstances:
International federations recognised by IOC.
There are currently 72 sport federations recognised by IOC. These are:
Olympic marketing.
In the early 1980s, the Olympics were highly dependent on revenues from a single source – its contracts with US television companies for the broadcasts of the Olympic Games. Upon his election as President of the IOC in 1980, Juan Antonio Samaranch recognised this vulnerability and in consultation with Horst Dassler, a leading member of the Adidas family, the decision to launch a global marketing programme for the IOC was made. Samaranch appointed Canadian IOC member Richard Pound to lead the initiative as Chairman of the "New Sources of Finance Commission".
In 1982 the IOC drafted ISL Marketing a Swiss sports marketing company, to develop a global marketing programme for the Olympic Movement. ISL successfully developed the programme but was replaced by Meridian Management, a company partly owned by the IOC in the early 1990s.
In 1989, one of the staff members at ISL Marketing, Michael Payne, moved to the IOC and became the organisation's first marketing director. However ISL and subsequently Meridian, continued in the established role as the IOC's sales and marketing agents until 2002. In 2002 the IOC terminated the relationship with Meridian and took its marketing programme in-house under the Direction of Timo Lumme, the IOC's managing director of IOC Television and Marketing Services. During his 17 years with the IOC, in collaboration with ISL Marketing and subsequently Meridian Management, Payne made major contributions to the creation of a multibillion-dollar sponsorship marketing programme for the organisation which, along with improvements in TV marketing and improved financial management, helped to restore the IOC's financial viability.
Revenue.
The Olympic Movement generates revenue through five major programmes. The International Olympic Committee (IOC) manages broadcast partnerships and The Olympic Partner (TOP) worldwide sponsorship programme. The Organising Committees for the Olympic Games (OCOGs) manage domestic sponsorship, ticketing and licensing programmes within the host country under the direction of the IOC. The Olympic Movement generated a total of more than US$4 billion, €2.5 billion in revenue during the Olympic quadrennium from 2001 to 2004.
Revenue distribution.
The IOC distributes some of Olympic marketing revenue to organisations throughout the Olympic Movement to support the staging of the Olympic Games and to promote the worldwide development of sport. The IOC retains approximately 10% of Olympic marketing revenue for the operational and administrative costs of governing the Olympic Movement.
The Organising Committees for the Olympic Games (OCOGs).
The IOC provides The Olympic Partner (TOP) programme contributions and Olympic broadcast revenue to the OCOGs to support the staging of the Olympic Games and Olympic Winter Games:
National Olympic Committees (NOCs).
The NOCs receive financial support for the training and development of Olympic teams, Olympic athletes and Olympic hopefuls. The IOC distributes TOP programme revenue to each of the NOCs throughout the world. The IOC also contributes Olympic broadcast revenue to Olympic Solidarity, an IOC organisation that provides financial support to NOCs with the greatest need.
The continued success of the TOP programme and Olympic broadcast agreements has enabled the IOC to provide increased support for the NOCs with each Olympic quadrennium. The IOC provided approximately US$318.5 million to NOCs for the 2001–2004 quadrennium.
International Olympic Sports Federations (IFs).
The IOC is now the largest single revenue source for the majority of IFs, with its contributions of Olympic broadcast revenue that assist the IFs in the development of their respective sports worldwide. The IOC provides financial support from Olympic broadcast revenue to the 28 IFs of Olympic summer sports and the seven IFs of Olympic winter sports after the completion of the Olympic Games and the Olympic Winter Games, respectively.
The continually increasing value of Olympic broadcast partnership has enabled the IOC to deliver substantially increased financial support to the IFs with each successive Games. The seven winter sports IFs shared US$85.8 million, €75 million in Salt Lake 2002 broadcast revenue. The contribution to the 28 summer sports IFs from Athens 2004 broadcast revenue has not yet been determined, but the contribution is expected to mark a significant increase over the US$190 million, €150 million that the IOC provided to the summer IFs following Sydney 2000.
Other organisations.
The IOC contributes Olympic marketing revenue to the programmes of various recognised international sports organisations, including the International Paralympic Committee, and the World Anti-Doping Agency (WADA).
Controversies.
1976 Winter Olympics (Denver, Colorado).
The cities of Denver, Colorado, United States; Sion, Switzerland; Tampere, Finland; and Vancouver (with the Garibaldi mountains), Canada, made bids for the Games.
The games were originally awarded to Denver on May 12, 1970, but a 300% rise in costs and worries about environmental impact led to Colorado voters' rejection on November 7, 1972, by a 3 to 2 margin, of a $5 million bond issue to finance the games with public funds.
Denver officially withdrew on November 15, and the IOC then offered the games to Whistler, British Columbia, Canada, but they too declined owing to a change of government following elections. Whistler would go on to be associated with neighbouring Vancouver's successful bid for the 2010 games.
Salt Lake City, Utah, a 1972 Winter Olympics final candidate who would eventually host the 2002 Winter Olympics, offered itself as a potential host after the withdrawal of Denver. The IOC, still reeling from the Denver rejection, declined and selected Innsbruck to host the 1976 Winter Olympics, which had hosted the 1964 Winter Olympics games twelve years earlier, on February 5, 1973.
Salt Lake bid scandal.
A scandal broke on 10 December 1998, when Swiss IOC member Marc Hodler, head of the coordination committee overseeing the organisation of the 2002 games, announced that several members of the IOC had taken bribes. Soon four independent investigations were underway: by the IOC, the USOC, the SLOC, and the United States Department of Justice.
Before any of the investigations could even get under way both Welch and Johnson resigned their posts as the head of the SLOC. Many others soon followed. The Department of Justice filed charges against the two: fifteen charges of bribery and fraud. Johnson and Welch were eventually acquitted of all criminal charges in December 2003.
As a result of the investigation ten members of the IOC were expelled and another ten were sanctioned. This was the first expulsion or sanction for corruption in the more than a century the IOC had existed. Although nothing strictly illegal had been done, it was felt that the acceptance of the gifts was morally dubious. Stricter rules were adopted for future bids and caps were put into place as to how much IOC members could accept from bid cities. Additionally new term and age limits were put into place for IOC membership, and fifteen former Olympic athletes were added to the committee.
Other controversies: 2006–2013.
In 2006, a report ordered by the Nagano region's governor said the Japanese city provided millions of dollars in an "illegitimate and excessive level of hospitality" to IOC members, including $4.4 million spent on entertainment alone.
International groups attempted to pressure the IOC to reject Beijing's bid in protest of the state of human rights in the People's Republic of China. One Chinese dissident who expressed similar sentiments was arrested and sentenced to two years in prison for calling on the IOC to do just that at the same time that IOC inspectors were touring the city. Amnesty International expressed concern in 2006 regarding the Olympic Games to be held in China in 2008, likewise expressing concerns over the human rights situation. The second principle in the Fundamental Principles of Olympism, Olympic Charter states that "The goal of Olympism is to place sport at the service of the harmonious development of man, with a view to promoting a peaceful society concerned with the preservation of human dignity." Amnesty International considers the policies and practices of the People's Republic as failing to meet that principle, and urged the IOC to press China to immediately enact human rights reform.
In August 2008, the IOC issued DMCA take down notices on Tibetan Protest videos of the Beijing Olympics hosted on YouTube. YouTube and the Electronic Frontier Foundation (EFF) both pushed back against the IOC, which then withdrew their complaint.
In 2010, the International Olympic Committee was nominated for the Public Eye Awards. This award seeks to present "shame-on-you-awards to the nastiest corporate players of the year".
Before the start of the 2012 Olympic Games, the IOC decided not to hold a minute of silence to honor the 11 Israeli Olympians who were killed 40 years prior in the Munich Massacre. Jacques Rogge, the then-IOC President, said it would be "inappropriate" to do so. Speaking of the decision, Israeli Olympian Shaul Ladany, who had survived the Munich Massacre, commented: "I do not understand. I do not understand, and I do not accept it".
In February 2013, the IOC did not include wrestling as one of its core Olympic sports for the Summer Olympic program for the 2020 Olympics. This decision was poorly received by the sporting and wrestling community. Wrestling will still be part of the program at the 2016 Summer Olympics in Rio de Janeiro. This decision was later overturned, and wrestling will be a part of the 2020 Olympic Games in Tokyo.
References.
Notes
Further reading

</doc>
<doc id="15150" url="https://en.wikipedia.org/wiki?curid=15150" title="Integrated circuit">
Integrated circuit

An integrated circuit or monolithic integrated circuit (also referred to as an IC, a chip, or a microchip) is a set of electronic circuits on one small plate ("chip") of semiconductor material, normally silicon. This can be made much smaller than a discrete circuit made from independent electronic components. ICs can be made very compact, having up to several billion transistors and other electronic components in an area the size of a human fingernail. The width of each conducting line in a circuit can be made smaller as the technology advances; in 2008 it dropped below 100 nanometers, and was reduced to 14 nanometers in 2014.
ICs were made possible by experimental discoveries showing that semiconductor devices could perform the functions of vacuum tubes and by mid-20th-century technology advancements in semiconductor device fabrication. The integration of large numbers of tiny transistors into a small chip was an enormous improvement over the manual assembly of circuits using discrete electronic components. The integrated circuit's mass production capability, reliability and building-block approach to circuit design ensured the rapid adoption of standardized integrated circuits in place of designs using discrete transistors.
ICs have two main advantages over discrete circuits: cost and performance. Cost is low because the chips, with all their components, are printed as a unit by photolithography rather than being constructed one transistor at a time. Furthermore, packaged ICs use much less material than discrete circuits. Performance is high because the IC's components switch quickly and consume little power (compared to their discrete counterparts) as a result of the small size and close proximity of the components. As of 2012, typical chip areas range from a few square millimeters to around 450 mm2, with up to 9 million transistors per mm2.
Integrated circuits are used in virtually all electronic equipment today and have revolutionized the world of electronics. Computers, mobile phones, and other digital home appliances are now inextricable parts of the structure of modern societies, made possible by the low cost of ICs.
Terminology.
An "integrated circuit" is defined as: A circuit in which all or some of the circuit elements are inseparably associated and electrically interconnected so that it is considered to be indivisible for the purposes of construction and commerce. Circuits meeting this definition can be constructed using many different technologies, including thin-film transistor, thick film technology, or hybrid integrated circuit. However, in general usage "integrated circuit" has come to refer to the single-piece circuit construction originally known as a "monolithic integrated circuit".
Invention.
Early developments of the integrated circuit go back to 1949, when German engineer Werner Jacobi (Siemens AG) filed a patent for an integrated-circuit-like semiconductor amplifying device showing five transistors on a common substrate in a 3-stage amplifier arrangement. Jacobi disclosed small and cheap hearing aids as typical industrial applications of his patent. An immediate commercial use of his patent has not been reported.
The idea of the integrated circuit was conceived by Geoffrey W.A. Dummer (1909–2002), a radar scientist working for the Royal Radar Establishment of the British Ministry of Defence. Dummer presented the idea to the public at the Symposium on Progress in Quality Electronic Components in Washington, D.C. on 7 May 1952. He gave many symposia publicly to propagate his ideas, and unsuccessfully attempted to build such a circuit in 1956.
A precursor idea to the IC was to create small ceramic squares (wafers), each containing a single miniaturized component. Components could then be integrated and wired into a bidimensional or tridimensional compact grid. This idea, which seemed very promising in 1957, was proposed to the US Army by Jack Kilby and led to the short-lived Micromodule Program (similar to 1951's Project Tinkertoy). However, as the project was gaining momentum, Kilby came up with a new, revolutionary design: the IC.
Newly employed by Texas Instruments, Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958. In his patent application of 6 February 1959, Kilby described his new device as "a body of semiconductor material … wherein all the components of the electronic circuit are completely integrated." The first customer for the new invention was the US Air Force.
Kilby won the 2000 Nobel Prize in Physics for his part in the invention of the integrated circuit. His work was named an IEEE Milestone in 2009.
Half a year after Kilby, Robert Noyce at Fairchild Semiconductor developed his own idea of an integrated circuit that solved many practical problems Kilby's had not. Noyce's design was made of silicon, whereas Kilby's chip was made of germanium. Noyce credited Kurt Lehovec of Sprague Electric for the "principle of p–n junction isolation" caused by the action of a biased p–n junction (the diode) as a key concept behind the IC.
Fairchild Semiconductor was also home of the first silicon-gate IC technology with self-aligned gates, the basis of all modern CMOS computer chips. The technology was developed by Italian physicist Federico Faggin in 1968, who later joined Intel in order to develop the very first single-chip Central Processing Unit (CPU) (Intel 4004), for which he received the National Medal of Technology and Innovation in 2010.
Generations.
In the early days of simple integrated circuits, the technology's large scale limited each chip to only a few transistors, and the low degree of integration meant the design process was relatively simple. Manufacturing yields were also quite low by today's standards. As the technology progressed, millions, then billions of transistors could be placed on one chip, and good designs required thorough planning, giving rise to new design methods.
SSI, MSI and LSI.
The first integrated circuits contained only a few transistors. Early digital circuits containing tens of transistors provided a few logic gates, and early linear ICs such as the Plessey SL201 or the Philips TAA320 had as few as two transistors. The number of transistors in an integrated circuit has increased dramatically since then. The term "large scale integration" (LSI) was first used by IBM scientist Rolf Landauer when describing the theoretical concept; that term gave rise to the terms "small-scale integration" (SSI), "medium-scale integration" (MSI), "very-large-scale integration" (VLSI), and "ultra-large-scale integration" (ULSI). The early integrated circuits were SSI.
SSI circuits were crucial to early aerospace projects, and aerospace projects helped inspire development of the technology. Both the Minuteman missile and Apollo program needed lightweight digital computers for their inertial guidance systems. Although the Apollo guidance computer led and motivated integrated-circuit technology, it was the Minuteman missile that forced it into mass-production. The Minuteman missile program and various other Navy programs accounted for the total $4 million integrated circuit market in 1962, and by 1968, U.S. Government space and defense spending still accounted for 37% of the $312 million total production. The demand by the U.S. Government supported the nascent integrated circuit market until costs fell enough to allow firms to penetrate the industrial, and eventually, the consumer markets. The average price per integrated circuit dropped from $50.00 in 1962 to $2.33 in 1968. Integrated circuits began to appear in consumer products by the turn of the decade, a typical application being FM inter-carrier sound processing in television receivers.
The first MOS chips were small-scale integrated chips for NASA satellites.
The next step in the development of integrated circuits, taken in the late 1960s, introduced devices which contained hundreds of transistors on each chip, called "medium-scale integration" (MSI).
In 1964, Frank Wanlass demonstrated a single-chip 16-bit shift register he designed, with an incredible (at the time) 120 transistors on a single chip.
MSI devices were attractive economically because while they cost little more to produce than SSI devices, they allowed more complex systems to be produced using smaller circuit boards, less assembly work (because of fewer separate components), and a number of other advantages.
Further development, driven by the same economic factors, led to "large-scale integration" (LSI) in the mid-1970s, with tens of thousands of transistors per chip.
SSI and MSI devices often were manufactured by masks created by hand-cutting Rubylith. An engineer would inspect and verify the completeness of each mask.
LSI devices contain so many transistors, interconnecting wires, and other features that it is considered impossible for a human to check the masks or even do the original design entirely by hand. The engineer depends on computer programs and other hardware aids to do most of this work.
Integrated circuits such as 1K-bit RAMs, calculator chips, and the first microprocessors, that began to be manufactured in moderate quantities in the early 1970s, had under 4000 transistors. True LSI circuits, approaching 10,000 transistors, began to be produced around 1974, for computer main memories and second-generation microprocessors.
VLSI.
The final step in the development process, starting in the 1980s and continuing through the present, was "very-large-scale integration" (VLSI). The development started with hundreds of thousands of transistors in the early 1980s, and continues beyond several billion transistors as of 2009.
Multiple developments were required to achieve this increased density. Manufacturers moved to smaller design rules and cleaner fabrication facilities, so that they could make chips with more transistors and maintain adequate yield. The path of process improvements was summarized by the International Technology Roadmap for Semiconductors (ITRS). Design tools improved enough to make it practical to finish these designs in a reasonable time. The more energy-efficient CMOS replaced NMOS and PMOS, avoiding a prohibitive increase in power consumption.
In 1986 the first one-megabit RAM chips were introduced, containing more than one million transistors. Microprocessor chips passed the million-transistor mark in 1989 and the billion-transistor mark in 2005. The trend continues largely unabated, with chips introduced in 2007 containing tens of billions of memory transistors.
ULSI, WSI, SOC and 3D-IC.
To reflect further growth of the complexity, the term "ULSI" that stands for "ultra-large-scale integration" was proposed for chips of more than 1 million transistors.
Wafer-scale integration (WSI) is a means of building very large integrated circuits that uses an entire silicon wafer to produce a single "super-chip". Through a combination of large size and reduced packaging, WSI could lead to dramatically reduced costs for some systems, notably massively parallel supercomputers. The name is taken from the term Very-Large-Scale Integration, the current state of the art when WSI was being developed.
A system-on-a-chip (SoC or SOC) is an integrated circuit in which all the components needed for a computer or other system are included on a single chip. The design of such a device can be complex and costly, and building disparate components on a single piece of silicon may compromise the efficiency of some elements. However, these drawbacks are offset by lower manufacturing and assembly costs and by a greatly reduced power budget: because signals among the components are kept on-die, much less power is required (see Packaging).
A three-dimensional integrated circuit (3D-IC) has two or more layers of active electronic components that are integrated both vertically and horizontally into a single circuit. Communication between layers uses on-die signaling, so power consumption is much lower than in equivalent separate circuits. Judicious use of short vertical wires can substantially reduce overall wire length for faster operation.
Advances in integrated circuits.
ICs have consistently migrated to smaller feature sizes over the years, allowing more circuitry to be packed on each chip. This increased capacity per unit area can be used to decrease cost or increase functionality—see Moore's law which, in its modern interpretation, states that the number of transistors in an integrated circuit doubles every two years. In general, as the feature size shrinks, almost everything improves—the cost per transistor and the switching power consumption per transistor go down, and the speed goes up -- see Dennard scaling. However, ICs with nanometer-scale devices are not without their problems, principal among which is leakage current (see subthreshold leakage for a discussion of this), although innovations in high-κ dielectrics aim to solve these problems. Since these speed and power consumption gains are apparent to the end user, there is fierce competition among the manufacturers to use finer geometries. This process, and the expected progress over the next few years, is described by the International Technology Roadmap for Semiconductors (ITRS).
Among the most advanced integrated circuits are the microprocessors or "cores", which control everything from computers and cellular phones to digital microwave ovens. Digital memory chips and application-specific integrated circuits (ASICs) are examples of other families of integrated circuits that are important to the modern information society. While the cost of designing and developing a complex integrated circuit is quite high, when spread across typically millions of production units the individual IC cost is minimized. The performance of ICs is high because the small size allows short traces which in turn allows low power logic (such as CMOS) to be used at fast switching speeds.
In current research projects, integrated circuits are also developed for sensoric applications in medical implants or other bioelectronic devices. Special sealing techniques have to be applied in such biogenic environments to avoid corrosion or biodegradation of the exposed semiconductor materials. As one of the few materials well established in CMOS technology, titanium nitride (TiN) turned out as exceptionally stable and well suited for electrode applications in medical implants.
Classification.
Integrated circuits can be classified into analog, digital and mixed signal (both analog and digital on the same chip).
Digital integrated circuits can contain anywhere from one to millions of logic gates, flip-flops, multiplexers, and other circuits in a few square millimeters. The small size of these circuits allows high speed, low power dissipation, and reduced manufacturing cost compared with board-level integration. These digital ICs, typically microprocessors, DSPs, and microcontrollers, work using binary mathematics to process "one" and "zero" signals.
Analog ICs, such as sensors, power management circuits, and operational amplifiers, work by processing continuous signals. They perform functions like amplification, active filtering, demodulation, and mixing. Analog ICs ease the burden on circuit designers by having expertly designed analog circuits available instead of designing a difficult analog circuit from scratch.
ICs can also combine analog and digital circuits on a single chip to create functions such as A/D converters and D/A converters. Such mixed-signal circuits offer smaller size and lower cost, but must carefully account for signal interference.
Modern electronic component distributors
often further sub-categorize the huge variety of integrated circuits now available:
Manufacturing.
Fabrication.
The semiconductors of the periodic table of the chemical elements were identified as the most likely materials for a "solid-state vacuum tube". Starting with copper oxide, proceeding to germanium, then silicon, the materials were systematically studied in the 1940s and 1950s. Today, monocrystalline silicon is the main substrate used for ICs although some III-V compounds of the periodic table such as gallium arsenide are used for specialized applications like LEDs, lasers, solar cells and the highest-speed integrated circuits. It took decades to perfect methods of creating crystals without defects in the crystalline structure of the semiconducting material.
Semiconductor ICs are fabricated in a planar process which includes three key process steps imaging, deposition and etching. The main process steps are supplemented by doping and cleaning.
Mono-crystal silicon wafers (or for special applications, silicon on sapphire or gallium arsenide wafers) are used as the "substrate". Photolithography is used to mark different areas of the substrate to be doped or to have polysilicon, insulators or metal (typically aluminium) tracks deposited on them.
Since a CMOS device only draws current on the "transition" between logic states, CMOS devices consume much less current than bipolar devices.
A random access memory is the most regular type of integrated circuit; the highest density devices are thus memories; but even a microprocessor will have memory on the chip. (See the regular array structure at the bottom of the first image.) Although the structures are intricate – with widths which have been shrinking for decades – the layers remain much thinner than the device widths. The layers of material are fabricated much like a photographic process, although light waves in the visible spectrum cannot be used to "expose" a layer of material, as they would be too large for the features. Thus photons of higher frequencies (typically ultraviolet) are used to create the patterns for each layer. Because each feature is so small, electron microscopes are essential tools for a process engineer who might be debugging a fabrication process.
Each device is tested before packaging using automated test equipment (ATE), in a process known as wafer testing, or wafer probing. The wafer is then cut into rectangular blocks, each of which is called a "die". Each good die (plural "dice", "dies", or "die") is then connected into a package using aluminium (or gold) bond wires which are thermosonically bonded to "pads", usually found around the edge of the die. . Thermosonic bonding was first introduced by A. Coucoulas which provided a reliable means of forming these vital electrical connections to the outside world. After packaging, the devices go through final testing on the same or similar ATE used during wafer probing. Industrial CT scanning can also be used. Test cost can account for over 25% of the cost of fabrication on lower-cost products, but can be negligible on low-yielding, larger, or higher-cost devices.
As of 2005, a fabrication facility (commonly known as a "semiconductor fab") costs over US$1 billion to construct. The cost of a fabrication facility rises over time (Rock's law) because much of the operation is automated. Today, the most advanced processes employ the following techniques:
Packaging.
The earliest integrated circuits were packaged in ceramic flat packs, which continued to be used by the military for their reliability and small size for many years. Commercial circuit packaging quickly moved to the dual in-line package (DIP), first in ceramic and later in plastic. In the 1980s pin counts of VLSI circuits exceeded the practical limit for DIP packaging, leading to pin grid array (PGA) and leadless chip carrier (LCC) packages. Surface mount packaging appeared in the early 1980s and became popular in the late 1980s, using finer lead pitch with leads formed as either gull-wing or J-lead, as exemplified by small-outline integrated circuit – a carrier which occupies an area about 30–50% less than an equivalent DIP, with a typical thickness that is 70% less. This package has "gull wing" leads protruding from the two long sides and a lead spacing of 0.050 inches.
In the late 1990s, plastic quad flat pack (PQFP) and thin small-outline package (TSOP) packages became the most common for high pin count devices, though PGA packages are still often used for high-end microprocessors. Intel and AMD are currently transitioning from PGA packages on high-end microprocessors to land grid array (LGA) packages.
Ball grid array (BGA) packages have existed since the 1970s. Flip-chip Ball Grid Array packages, which allow for much higher pin count than other package types, were developed in the 1990s. In an FCBGA package the die is mounted upside-down (flipped) and connects to the package balls via a package substrate that is similar to a printed-circuit board rather than by wires. FCBGA packages allow an array of input-output signals (called Area-I/O) to be distributed over the entire die rather than being confined to the die periphery.
Traces out of the die, through the package, and into the printed circuit board have very different electrical properties, compared to on-chip signals. They require special design techniques and need much more electric power than signals confined to the chip itself.
When multiple dies are put in one package, it is called SiP, for "System In Package". When multiple dies are combined on a small substrate, often ceramic, it's called an MCM, or Multi-Chip Module. The distinction between a big MCM and a small printed circuit board is sometimes fuzzy.
Chip labeling and manufacture date.
Most integrated circuits large enough to include identifying information include four common sections: the manufacturer's name or logo, the part number, a part production batch number and serial number, and a four-digit code that identifies when the chip was manufactured. Extremely small surface mount technology parts often bear only a number used in a manufacturer's lookup table to find the chip characteristics.
The manufacturing date is commonly represented as a two-digit year followed by a two-digit week code, such that a part bearing the code 8341 was manufactured in week 41 of 1983, or approximately in October 1983.
Intellectual property.
The possibility of copying by photographing each layer of an integrated circuit and preparing photomasks for its production on the basis of the photographs obtained is the main reason for the introduction of legislation for the protection of layout-designs.The Semiconductor Chip Protection Act (SCPA) of 1984 established a new type of intellectual property protection for mask works that are fixed in semiconductor chips. It did so by amending title 17 of the United States chapter 9
A diplomatic conference was held at Washington, D.C., in 1989, which adopted a Treaty on Intellectual Property in Respect of Integrated Circuits (IPIC Treaty).
The Treaty on Intellectual Property in respect of Integrated Circuits, also called Washington Treaty or IPIC Treaty (signed at Washington on 26 May 1989) is currently not in force, but was partially integrated into the TRIPS agreement.
National laws protecting IC layout designs have been adopted in a number of countries.
Other developments.
In the 1980s, programmable logic devices were developed. These devices contain circuits whose logical function and connectivity can be programmed by the user, rather than being fixed by the integrated circuit manufacturer. This allows a single chip to be programmed to implement different LSI-type functions such as logic gates, adders and registers. Current devices called field-programmable gate arrays can now implement tens of thousands of LSI circuits in parallel and operate up to 1.5 GHz.
The techniques perfected by the integrated circuits industry over the last three decades have been used to create very small mechanical devices driven by electricity using a technology known as microelectromechanical systems. These devices are used in a variety of commercial and military applications. Example commercial applications include DLP projectors, inkjet printers, and accelerometers and MEMS gyroscopes used to deploy automobile airbags.
As of 2014, the vast majority of all transistors are fabricated in a single layer on one side of a chip of silicon in a flat 2-dimensional planar process.
Researchers have produced prototypes of several promising alternatives, such as:
In the past, radios could not be fabricated in the same low-cost processes as microprocessors. But since 1998, a large number of radio chips have been developed using CMOS processes. Examples include Intel's DECT cordless phone, or Atheros's 802.11 card.
Future developments seem to follow the multi-core multi-microprocessor paradigm, already used by the Intel and AMD dual-core processors. Rapport Inc. and IBM started shipping the KC256 in 2006, a 256-core microprocessor. Intel, as recently as February–August 2011, unveiled a prototype, "not for commercial sale" chip that bears 80 cores. Each core is capable of handling its own task independently of the others. This is in response to the heat-versus-speed limit that is about to be reached using existing transistor technology (see: thermal design power). This design provides a new challenge to chip programming. Parallel programming languages such as the open-source X10 programming language are designed to assist with this task.
Since the early 2000s, the integration of optical functionality (optical computing) into silicon chips has been actively pursued in both academic research and in industry resulting in the successful commercialization of silicon based integrated optical transceivers combining optical devices (modulators, detectors, routing) with CMOS based electronics.
Silicon labelling and graffiti.
To allow identification during production most silicon chips will have a serial number in one corner. It is also common to add the manufacturer's logo. Ever since ICs were created, some chip designers have used the silicon surface area for surreptitious, non-functional images or words. These are sometimes referred to as chip art, silicon art, silicon graffiti or silicon doodling.
External links.
General
Patents
Integrated circuit die manufacturing

</doc>
<doc id="15154" url="https://en.wikipedia.org/wiki?curid=15154" title="IBM 3270">
IBM 3270

The IBM 3270 is a class of block oriented computer terminal (sometimes called "display devices") introduced by IBM in 1971 normally used to communicate with IBM mainframes. The 3270 was the successor to the IBM 2260 display terminal. Due to the text colour on the original models, these terminals are informally known as "green screen" terminals. Unlike a character-oriented terminal, the 3270 minimizes the number of I/O interrupts required by transferring large blocks of data known as data streams, and uses a high speed proprietary communications interface, using coaxial cable.
Although IBM no longer manufactures 3270 terminals, the IBM 3270 protocol is still commonly used via terminal emulation to access mainframe-based applications. Accordingly, such applications are sometimes referred to as "green screen applications". The use of 3270 is slowly diminishing as more and more mainframe applications acquire Web interfaces, although some Web applications merely use the technique of "screen scraping" to capture old screens and transfer the data to modern front-ends.
Principles.
The 3270 series was designed to connect with mainframe computers, often at a remote location, using the technology then available in the early 1970s. Two of the major design goals of 3270s are minimizing the amount of data transmitted, and minimizing the frequency of interrupts to the mainframe.
3270 devices are "clustered", with one or more displays or printers connected to a "control unit" (the 3275 and 3276 included an integrated control unit). Originally devices were connected to the control unit over coaxial cable; later token ring, twisted pair, or Ethernet connections were available. A "local" control unit attaches directly to the channel of a nearby mainframe. A "remote" control unit is connected to a communications line by a modem. Remote 3270 controllers are frequently "multi-dropped", with multiple control units on a line.
In a data stream, both text and control (or formatting functions) are interspersed allowing an entire screen to be "painted" as a single output operation. The concept of formatting in these devices allows the screen to be divided into fields (clusters of contiguous character cells) for which numerous field attributes (colour, highlighting, character set, protection from modification) can be set. A field attribute occupies a physical location on the screen that also determines the beginning and end of a field.
Using a technique known as "read modified", a single transmission back to the mainframe can contain the changes from any number of formatted fields that have been modified, but without sending any unmodified fields or static data. This technique enhances the terminal throughput of the CPU, and minimizes the data transmitted. Some users familiar with character interrupt-driven terminal interfaces find this technique unusual. There is also a "read buffer" capability that transfers the entire content of the 3270-screen buffer including field attributes. This is mainly used for debugging purposes to preserve the application program screen contents while replacing it, temporarily, with debugging information.
Early 3270s offered three types of keyboards. The "typewriter keyboard" came in both a 66 key version, with no programmed function (PF) keys, and a 78 key version with twelve. Both versions had two "program attention" (PA) keys. The "data entry keyboard" had five PF keys and two PA keys. The "operator console keyboard" had twelve PF keys and two PA keys. Later 3270s had twenty-four PF keys and three PA keys. When one of these keys is pressed, it will cause its control unit to generate an I/O interrupt to the host computer and present a special code identifying which key was pressed. Application program functions such as termination, page-up, page-down, or help can be invoked by a single key press, thereby reducing the load on very busy processors.
In this way, the CPU is not interrupted at every keystroke, a scheme that allowed an early 3033 mainframe with only 16 MB to support up to 17,500 3270 terminals under CICS. On the other hand, vi-like behaviour was not possible. (But end-user responsiveness was arguably more predictable with 3270, something users appreciated.) For the same reason, a porting of Lotus 1-2-3 to mainframes with 3279 screens did not meet with success because its programmers were not able to properly adapt the spreadsheet's user interface to a "screen at a time" rather than "character at a time" device.
Applications.
Following its introduction the 3270 and compatibles were by far the most commonly used terminals on IBM System/370 and successor systems. IBM and third-party software that included an interactive component took for granted the presence of 3270 terminals and provided a set of ISPF panels and supporting programs.
The "Program Development Facility" (PDF) and XEDIT editors for MVS and VM/SP (ISPF/PDF was available for VM, but little used) respectively make extensive use of 3270 features. 
The modified data tag is well suited to converting formatted, structured punched card input onto the 3270 display device. With the appropriate programming, any batch program that uses formatted, structured card input can be layered onto a 3270 terminal.
IBM's OfficeVision office productivity software enjoyed great success with 3270 interaction because of its design understanding. And for many years the PROFS calendar was the most commonly displayed screen on office terminals around the world.
Imperial Chemical Industries (ICI) Mond Division's Works Records System, the first known shared public spreadsheet, used the 3270 successfully for what was, in effect, a high powered version of today's spreadsheets with additional functions. It remained in continual use for 27 years up until 2001 and, despite its lack of a GUI, cells can be defined anywhere on the screen (not necessarily in rows or columns) and can be instantly re-configured for length, content and formulas as required. It is interesting to note that ICI's online, fully interactive system pre-dated PC spreadsheets by quite a few years and allows multiple users to use the spreadsheets at the same time, similar to today's Web based shared spreadsheets.
A version of the WordPerfect word processor ported to System/370 was designed for the 3270 architecture.
3270 and The Web (and HTTP) are similar in that both follow a thin client client-server architecture whereby they, the clients, are given primary responsibility for managing presentation and user input. This minimizes host interactions while still facilitating server-based information retrieval and processing.
With the arrival of the web, application development has in many ways returned to the 3270 approach. In the 3270 era, all application functionality was provided centrally. With the advent of the PC, the idea was to invoke central systems only when absolutely unavoidable, and to do all application processing with local software on the personal computer. Now in the web era (and with wikis in particular), the application again is strongly centrally controlled, with only technical functionality distributed to the PC.
In the early 1990s a popular solution to link PCs with the mainframes was the Irma board, an expansion card that plugged into a PC and connected to the controller through a coaxial cable. IRMA also allows file transfers between the PC and the mainframe.
Third parties.
One of the first groups to write and provide an operating system for the 3270 and its early predecessors was the University of Michigan who created the Michigan Terminal System in order for the hardware to be useful outside of the manufacturer. MTS was the default OS for many years, and was still used at Michigan well into the 1990s.
Many manufacturers, such as Hewlett Packard, Memorex, ITT Courier and Teletype/AT&T created 3270 compatible terminals, or adapted ASCII terminals such as the HP 2640 series to have a similar block-mode capability that would transmit a screen at a time, with some form validation capability. Modern applications are sometimes built upon legacy 3270 applications, using software utilities to capture (screen scraping) screens and transfer the data to web pages or GUI interfaces.
Models.
The IBM 3270 display terminal subsystem consisted of displays, printers and controllers.
Optional features for the 3275 and 3277 were the "selector-pen" or light pen, ASCII rather than EBCDIC character set, an audible alarm, and a keylock for the keyboard. A "keyboard numeric lock" was available would lock the keyboard if the operator attempted to enter non-numeric data into a field defined as numeric. Later an "Operator Identification Card Reader" was added which could read information encoded on a magnetic stripe card.
Displays.
A version of the IBM PC called the 3270 PC, released in October 1983, included 3270 terminal emulation. Later, the 3270 PC/G (graphics) and 3270 PC/GX (extended graphics) followed.
Controllers.
By 1994 the "3174 Establishment Controller" supported features such as attachment to multiple hosts via token ring, Ethernet, or X.25 in addition to the standard channel attach or SDLC, and terminal attachment via twisted pair, token ring or Ethernet in addition to co-ax. They also supported attachment of asynchronous ASCII terminals, printers, and plotters alongside 3270 devices.
Manufacture.
The IBM 3270 display terminal subsystem was designed and developed by IBM's Kingston, NY, laboratory (which later closed during in the mid-1990s). The printers were developed by the Endicott, NY, laboratory. As the subsystem expanded, the 3276 display-controller was developed by the Fujisawa, Japan, laboratory, and later the Yamato laboratory; and the 3279 colour display and 3287 colour printer by the Hursley, UK, laboratory. The subsystem products were manufactured in Kingston (displays and controllers), Endicott (printers), and Greenock, Scotland, UK, (most products) and shipped to users in U.S. and worldwide. 3278 terminals continued to be manufactured in Hortolandia, near Campinas, Brazil as far as late 1980s, having its internals redesigned by a local engineering team using modern CMOS technology, while retaining its external look and feel.
Telnet 3270.
Telnet 3270, or tn3270 describes both the process of sending and receiving 3270 data streams using the Telnet protocol and the software that emulates a 3270 class terminal that communicates using that process. tn3270 allows a 3270 terminal emulator to communicate over a TCP/IP network instead of an SNA network. Telnet 3270 can be used for either terminal or print connections. Standard telnet clients cannot be used as a substitute for tn3270 clients, as they use fundamentally different techniques for exchanging data.
Technical Information.
3270 character set.
The following table shows the 3275/3277/3284/3286 character set for US English EBCDIC. Lower case characters display or print as uppercase. NL, EM, DUP, and FM control characters display and print as 5, 9, *, and ; characters, respectively, except by the printer when WCC or CCC bits 2 and 3 = '00'b, in which case NL and EM serve their control function and do not print. Optional characters were available for US ASCII, and UK, French, German, and Italian EBCDIC. 
Data stream.
Data sent to the 3270 consists of "commands" and "orders". Commands instruct the 3270 control unit to perform some action on a specified device, such a read or write. Orders are sent as part of the data stream to control the format of the device buffer.
The following description applies to the 3271, 3272, and 3275 control units. Later models of 3270 have additional capabilities.
Write Control Character.
The data sent by Write or Erase/Write consists of the command code itself followed by a "Write Control Character" (WCC) optionally followed by a buffer containing orders or data (or both). The WCC controls the operation of the device. Bits may start printer operation and specify a print format. Other bit settings will sound the audible alarm if installed, unlock the keyboard to allow operator entry, or reset all the Modified Data Tags in the device buffer.
Orders.
Orders consist of the order code byte followed by zero to three bytes of variable information.
Attributes.
The original 3277 and 3275 displays used an 8-bit field attribute byte of which five bits were used.
Later models included "base colour" support for four colours. "In base color mode, the protection and intensity bits are used in combination to select among four colors: normally white, red, blue, and green; the protection bits retain their protection functions as well as determining color." Still later models used "extended attributes" to add support for seven colours, blinking, reverse video, underscoring, field outlining, field validation, and programmed symbols. In addition, later models added character attributes, which could establish, e.g., color for individual characters without starting a new field or taking up a screen position.
Buffer addressing.
3270 displays and printers had a buffer containing one byte for every screen position. For example, a 3277 model 2 featured a screen size of 24 rows of 80 columns for a buffer size of 1920 bytes. Bytes were addressed from zero to the screen size minus one, in this example 1919. "There is a fixed relationship between each ... buffer storage location and its position on the display screen." Most orders started operation at the "current" buffer address, and executing an order or writing data would update this address. The buffer address could be set directly using the "Set Buffer Address (SBA)" order, often followed by "Start Field". For a device with a 1920 character display a twelve bit address was sufficient. Later 3270s with larger screen sizes used fourteen or sixteen bits.
Addresses were encoded in orders in two bytes. For twelve bit addresses the high order two bits of each byte were normally set to form valid EBCDIC (or ASCII) characters. For example, address 0 was coded as X'4040', or space-space, address 1919 was coded as X'5D7F', or ". Programmers hand coding panels usually kept the table of addresses from the 3270 Component Description or the 3270 Reference Card handy. For fourteen and sixteen bit address the address used contiguous bits in two bytes.
Example.
The following data stream writes an attribute in row 24, column 1, writes the (protected) characters '> ' in row 24, columns 2 and 3, and creates an unprotected field on row 24 from columns 5-79. Because the buffer wraps around an attribute is placed on row 24, column 80 to terminate the input field. This data stream would normally be written using an Erase/Write command which would set undefined positions on the screen to '00'x. Values are given in hexadecimal.

</doc>
