<doc id="56517" url="https://en.wikipedia.org/wiki?curid=56517" title="Raymond Smullyan">
Raymond Smullyan

Raymond Merrill Smullyan (; born May 25, 1919) is an American mathematician, concert pianist, logician, Taoist philosopher, and magician.
Born in Far Rockaway, New York, his first career was stage magic. He then earned a BSc from the University of Chicago in 1955 and his Ph.D. from Princeton University in 1959. He is one of many logicians to have studied under Alonzo Church.
Life.
Born in Far Rockaway, New York, he showed musical talent, winning a gold medal in a piano competition when he was aged 12. The following year, his family moved to Manhattan and he attended Theodore Roosevelt High School in The Bronx as this school offered courses suited to his musical talents, but he left to study on his own as the school did not offer similar courses in mathematics. He attended several colleges, studying mathematics and music.
While a Ph.D. student, Smullyan published a paper in the 1957 "Journal of Symbolic Logic" showing that Gödelian incompleteness held for formal systems considerably more elementary than that of Gödel's 1931 landmark paper. The contemporary understanding of Gödel's theorem dates from this paper. Smullyan later made a compelling case that much of the fascination with Gödel's theorem should be directed at Tarski's theorem, which is much easier to prove and equally disturbing philosophically.
Smullyan is the author of many books on recreational mathematics and recreational logic. Most notably, one is titled "What Is the Name of This Book?" ISBN 0139550623.
He was a professor of philosophy at Lehman College and the Graduate Center, City University of New York, and at Indiana University. He is also an amateur astronomer, using a six inch reflecting telescope for which he ground the mirror.
Logic problems.
Many of his logic problems are extensions of classic puzzles. Knights and Knaves involves knights (who always tell the truth) and knaves (who always lie). This is based on a story of two doors and two guards, one who lies and one who tells the truth. One door leads to heaven and one to hell, and the puzzle is to find out which door leads to heaven by asking one of the guards a question. One way to do this is to ask "Which door would the other guard say leads to hell?". This idea was famously used in the 1986 film "Labyrinth".
In more complex puzzles, he introduces characters who may lie or tell the truth (referred to as "normals"), and furthermore instead of answering "yes" or "no", use words which mean "yes" or "no", but the reader does not know which word means which. The puzzle known as "the hardest logic puzzle ever" is based on these characters and themes. In his Transylvania puzzles, half of the inhabitants are insane, and believe only false things, whereas the other half are sane and believe only true things. In addition, humans always tell the truth, and vampires always lie. For example, an insane vampire will believe a false thing (2 + 2 is not 4) but will then lie about it, and say that it is false. A sane vampire knows 2 + 2 is 4, but will lie and say it is not. And "mutatis mutandis" for humans. Thus everything said by a sane human or an insane vampire is true, while everything said by an insane human or a sane vampire is false.
His book "Forever Undecided" popularizes Gödel's incompleteness theorems by phrasing them in terms of reasoners and their beliefs, rather than formal systems and what can be proved in them. For example, if a native of a knight/knave island says to a sufficiently self-aware reasoner, "You will never believe that I am a knight", the reasoner cannot believe either that the native is a knight or that he is a knave without becoming inconsistent (i.e., holding two contradictory beliefs). The equivalent theorem is that for any formal system S, there exists a mathematical statement that can be interpreted as "This statement is not provable in formal system S". If the system S is consistent, neither the statement nor its opposite will be provable in it. See also Doxastic logic.
Inspector Craig is a frequent character in Smullyan's "puzzle-novellas." He is generally called into a scene of a crime that has a solution that is mathematical in nature. Then, through a series of increasingly harder challenges, he (and the reader) begin to understand the principles in question. Finally the novella culminates in Inspector Craig (and the reader) solving the crime, utilizing the mathematical and logical principles learned. Inspector Craig generally does not learn the formal theory in question, and Smullyan usually reserves a few chapters after the Inspector Craig adventure to illuminate the analogy for the reader. Inspector Craig gets his name from William Craig.
His book "To Mock a Mockingbird" (1985) is a recreational introduction to the subject of combinatory logic.
Apart from writing about and teaching logic, Smullyan has recently released a recording of his favorite classical piano pieces by composers such as Bach, Scarlatti, and Schubert. Some recordings are available on the Piano Society website, along with the video "Rambles, Reflections, Music and Readings". He has also written an autobiography titled "Some Interesting Memories: A Paradoxical Life" (ISBN 1-888710-10-1).
In 2001, documentary filmmaker Tao Ruspoli made a film about Smullyan called "".
Philosophy.
Smullyan has written several books about Taoist philosophy, which he believes neatly solves most or all traditional philosophical problems as well as integrating mathematics, logic, and philosophy into a cohesive whole.

</doc>
<doc id="56518" url="https://en.wikipedia.org/wiki?curid=56518" title="Wilderness area">
Wilderness area

A wilderness area is a region where the land is in a natural state; where impacts from human activities are minimal—that is, as a wilderness. It might also be called a "wild" or "natural" area. Especially in wealthier, industrialized nations, it has a specific legal meaning as well: as land where development is prohibited by law. Many nations have designated Wilderness Areas, including Australia, Canada, New Zealand, South Africa and the United States.
The WILD Foundation states that wilderness areas have two dimensions: they must be biologically intact and legally protected. The World Conservation Union (IUCN) classifies wilderness at two levels, Ia (Strict Nature Preserves) and Ib (Wilderness areas). 
Most scientists and conservationists agree that no place on earth is completely untouched by humanity, either due to past occupation by indigenous people, or through global processes such as climate change. Activities on the margins of specific wilderness areas, such as fire suppression and the interruption of animal migration, also affect the interior of wildernesses.
Wilderness areas by country.
Finland.
There are twelve wilderness areas in the Sami native region in northern Finnish Lapland. They are intended both to preserve the wilderness character of the areas and further the traditional livelihood of the Sami people. This means e.g. that reindeer husbandry, hunting and taking wood for use in the household is permitted. As population is very sparse, this is generally no big threat to the nature. Large scale reindeer husbandry has influence on the ecosystem, but no change is introduced by the act on wilderness areas. The World Commission on Protected Areas (WCPA) classifies the areas as "VI Protected area with sustainable use of natural resources".
France.
Since 1861, The French Waters and Forests Military Agency (Administration des Eaux et Forêts) put a strong protection on what was called the « artistic reserve » in Fontainebleau State Forest. With a total of 1 097 hectares, it is known to be the first World nature reserve.
Then in the 1950s, Integral Biological Reserves (Réserves Biologiques Intégrales, RBI) are dedicated to man free ecosystem evolution, on the contrary of Managed Biological reserves (Réserves Biologiques Dirigées, RBD) where a specific management is applied to conserve vulnerable species or threatened habitats.
Integral Biological Reserves occurs in French State Forests or City Forests and are therefore managed nowadays by the National Forests Office. In such reserves, all harvests coupe are forbidden excepted exotic species elimination or track safety works to avoid fallen tree risk to visitors (already existing tracks in or on the edge of the reserve).
At the end of 2014, there were 60 Integral Biological Reserves in French State Forests for a total area of 111 082 hectares and 10 in City Forests for a total of 2 835 hectares.
New Zealand.
There are seven wilderness areas in New Zealand as defined by the National Parks Act 1980 and the Conservation Act 1987 that fall well within the IUCN definition. Wilderness areas cannot have any human intervention and can only have indigenous species re-introduced into the area if it is compatible with conservation management strategies.
United States.
In the United States, a Wilderness Area is an area of federal land set aside by an act of Congress. Human activities in wilderness areas are restricted to scientific study and non-mechanized recreation; horses are permitted but motorized vehicles and equipment are not.
Western Australia.
In Western Australia, a Wilderness Area is an area that has a wilderness quality rating of 12 or greater and meets a minimum size threshold of 8,000 hectares in temperate areas or 20,000 hectares in arid and tropical areas. A wilderness area is gazetted under section 62(1)(a) of the Conservation and Land Management Act 1984 by the Minister on any land that is vested in the Conservation Commission of Western Australia.
International.
For a comprehensive review of wilderness areas by country, reference "A Handbook on International Wilderness Law and Policy" (Cyril F. Kormos, ed).

</doc>
<doc id="56519" url="https://en.wikipedia.org/wiki?curid=56519" title="Riding (country subdivision)">
Riding (country subdivision)

A riding is an administrative jurisdiction or electoral district, particularly in several current or former Commonwealth countries.
Etymology.
The word "riding" is descended from late Old English *"þriðing" or *"þriding" (recorded only in Latin contexts or forms, e.g., "trehing", "treding", "trithing", with Latin initial "t" here representing the Old English letter thorn). It came into Old English as a loanword from Old Norse "þriðjungr", meaning a third part (especially of a county), cf. farthing. The modern form "riding" was the result of initial "th" being absorbed in the final "th" or "t" of the words "north", "south", "east" and "west", by which it was normally preceded.
A common misconception holds that the term arose from some association between the size of the district and the distance that can be covered or encircled on horseback in a certain amount of time (cf. the Walking Purchase).
Scandinavia.
Ridings are originally Scandinavian institutions.
In Iceland the third part of a "thing" which corresponded roughly to an English county was called "þrithjungr". The island of Gotland and the Swedish province Närke were also divided into "þrithjungar" instead of hundreds.
In Norway (excluding Iceland) the "þrithjungr" seems to have been an ecclesiastical division.
England.
Yorkshire.
The ancient county of Yorkshire had three ridings, 
North, West and East, originally each subdivided into wapentakes.
The Yorkshire ridings were in many ways treated as separate administrative counties, having had separate quarter sessions and also separate lieutenancies since the Restoration. This practice was followed by the Local Government Act 1888, which made each of the three ridings an administrative county with an elected county council. These county councils, along with the ancient lieutenancies, were abolished in 1974 under the Local Government Act 1972.
A local government area East Riding of Yorkshire was created in 1996, but this does not cover the entire area of the former East Riding and includes areas from the historical West Riding.
According to the 12th century compilation known as the "Leges Edwardi Confessoris", the riding was the third part of a county ("provincia"); to it causes were brought which could not be determined in the wapentake, and a matter which could not be determined in the riding was brought into the court of the shire.
There is abundant evidence that riding courts were held after the Norman Conquest. A charter which Henry I granted to the Church of St Peters at York mentions "wapentacmot, tridingmot" and "shiresmot" (-mot designates popular assemblies), and exemptions from suit to the thriding or riding may be noticed frequently in the charters of the Norman kings. As yet, however, the jurisdiction and functions of these courts have not been ascertained. It seems probable from the silence of the records that they had already fallen into disuse early in the 13th century.
Although no longer having any administrative role the ridings of Yorkshire still play a part as cultural entities – they are used for the names of a number of groups and organisations and some people in Yorkshire associate themselves with one riding or another (see West Riding of Yorkshire#Current usage and Yorkshire Ridings Society). Winifred Holtby's 1936 novel "South Riding" and its adaptations were set in a fictional fourth riding. The title of the novel trilogy "Red Riding" by David Peace, set in Yorkshire, is a play on the word.
Elsewhere.
The Parts of Lindsey, one of the Parts of Lincolnshire, also possessed ridings, in this case the North, West, and South ridings.
Ireland.
County Tipperary in Ireland was divided in 1838 into two ridings, Tipperary North Riding and Tipperary South Riding – the divisions remained as local government counties, but were renamed simply 'North Tipperary' and 'South Tipperary' in 2002. They ceased to exist with the 2014 reforms of local government.
County Cork was divided into East and West Ridings in 1823. The ridings still exist for judicial purposes, and Garda (police) divisions are based on them. County Cork is divided for some purposes into the two ridings, with county councillors for the ridings meeting separately to perform certain functions. County Galway was also divided into east and west ridings.
Canada.
The term was used in 19th century Canada to refer to subdivisions of counties.
In Canadian politics, "riding" is a colloquial term for a constituency or electoral district. Officially, "electoral district" is generally used, although government documents sometimes use the colloquial term. In colloquial Canadian French, a riding is known as "comté", i.e., "county", as the electoral districts in Quebec were historically identical to its counties; the official French term is "circonscription".
The Canadian use of "riding" is derived from the English local government term, which was widely used in Canada in the 19th century. Most Canadian counties never had sufficient population to justify administrative subdivisions. Nonetheless, it was common, especially in Ontario, to divide counties with sufficient population into multiple electoral districts, which thus became known as "ridings" in official documents. The term was used in the legal description of the electoral districts of Canada West, which were grandfathered, by means of a schedule to the new constitution, as the electoral districts for the first elections to the new Canadian House of Commons, immediately following Confederation. Soon after Confederation, the urban population grew (and more importantly, most city dwellers gained the franchise after property ownership was no longer required to gain the vote). Rural constituencies therefore became geographically larger through the 20th century and generally encompassed one or more counties each, and the word "riding" was then used to refer to any electoral division.
The local association for a political party, which legally is known as an "electoral district association", is often referred to as a riding association.
Australia.
The term was used in Australia as a division of some Shire Councils, similar to a Ward in City, Borough, Town and many Shire councils.
New Zealand.
Ridings existed in rural New Zealand in the late 19th and early to mid 20th century as part of larger county councils in the area. For example, The Taranaki County Council was divided into three separate ridings: Moa (south), Omata (west) and Waitara (east).
As use of the automobile became more popular with the improvement of roads, combined with the concurrent trend of 
urban drift (c. 1950s), the ridings were either merged back into their parent councils or separated off into county councils in their own right. The Taranaki Country Council's three ridings eventually split, with the Omata Riding remaining part of the Taranaki County Council, the Moa riding merging with the Inglewood Borough Council and the Waitara Riding becoming part of the Clifton County Council.
In 1989 these were again merged reorganised into district and/or city councils. For example, the above three all merged with the New Plymouth Council and Waitara Borough Councils to form the New Plymouth District Council.
Examples:
See also.
The term farthing is analogous for quarters of a county. Gloucestershire was once divided into Farthings. In Tolkien's fictional world of Middle-earth, the Shire is divided into four Farthings, into the Fourth Age.

</doc>
<doc id="56520" url="https://en.wikipedia.org/wiki?curid=56520" title="Conservation easement">
Conservation easement

In the United States, a conservation easement (also called conservation covenant, conservation restriction or conservation servitude) is a power invested in a qualified private land conservation organization (often called a "land trust") or government (municipal, county, state or federal) to constrain, as to a specified land area, the exercise of rights otherwise held by a landowner so as to achieve certain conservation purposes. It is an interest in real property established by agreement between a landowner and land trust or unit of government. The conservation easement "runs with the land," meaning it is applicable to both present and future owners of the land. As with other real property interests, the grant of conservation easement is recorded in the local land records; the grant becomes a part of the chain of title for the property.
The conservation easement's purposes will vary depending on the character of the particular property, the goals of the land trust or government unit, and the needs of the landowners. For example, an easement’s purposes (often called "conservation objectives") might include any one or more of the following:
The conservation easement’s administrative terms for advancing the conservation objectives also vary but typically forbid or substantially constrain subdivision and other real estate development. 
The most distinguishing feature of the conservation easement as a conservation tool is that it enables users to achieve specific conservation objectives on the land while keeping the land in the ownership and control of landowners for uses consistent with the conservation objectives. 
The decision to place a conservation easement on a property is strictly a voluntary one whether the easement is sold or donated. The restrictions of the easement, once set in place, are perpetual (and potentially reduce the resale value of the associated property). Appraisals of the value of the easement, and financial arrangements between the parties (land owner and land trust), generally are kept private.
The landowner who grants a conservation easement continues to privately own and manage the land and may receive significant state and federal tax advantages for having donated and/or sold the conservation easement. Perhaps more importantly, the landowner has contributed to the public good by preserving the conservation values associated with their land for future generations. In accepting the conservation easement, the easement holder has a responsibility to monitor future uses of the land to ensure compliance with the terms of the easement and to enforce the terms if a violation occurs.
Although a conservation easement prohibits certain uses by the landowner, such an easement does not make the land public. On the contrary, many conservation easements confer no use of the land either to the easement holder or to the public. Furthermore, many conservation easements reserve to the landowner specific uses which if not reserved would be prohibited. Some conservation easements confer specific uses to the easement holder or to the public. These details are spelled out in the legal document that creates the conservation easement.
Income tax deductions.
Landowners in the United States who donate a "qualifying" conservation easement to a "qualified" land protection organization under the regulations set forth in 170(h) of the Internal Revenue Code may be eligible for a federal income tax deduction equal to the value of their donation. The value of the easement donation, as determined by a qualified appraiser, equals the difference between the fair market value of the property before and after the easement takes effect. 
To qualify for this income tax deduction, the easement must be: a) perpetual; b) held by a qualified governmental or non-profit organization; and, c) serve a valid "conservation purpose", meaning the property must have an appreciable natural, scenic, historic, scientific, recreational, or open space value. As a result of legislation signed by President George W. Bush on August 17, 2006 (H.R. 4 The Pensions Protection Act of 2006), in 2006 and 2007, conservation easement donors were able to deduct the value of their gift at the rate of 50% of their adjusted gross income (AGI) per year. Further, landowners with 50% or more of their income from agriculture were able to deduct the donation at a rate of 100% of their AGI. Any amount of the donation remaining after the first year could be carried forward for fifteen additional years (allowing a maximum of sixteen years within which the deduction may be utilized), or until the amount of the deduction has been used up, whichever comes first. With the passage of the Farm Bill in the summer of 2008 these expanded federal income tax incentives were extended such that they also apply to all conservation easements donated in 2008 and 2009 and then this provision was extended again to apply to donations in 2010 and 2011. The provision has since expired and currently for 2012, conservation easement donations may only be deducted at the rate of 30% of the donor's AGI and after the first year the donor has a five year carryforward.
Income tax credits (states).
Land conservation advocates have long tried to enact additional tax incentives for landowners to donate easements, above the federal charitable deduction (and state tax deduction in states that conform to federal tax process). There has been discussion of creating a federal income tax credit for easement donors since around 1980. However, no federal tax credit has been enacted. States, however, have moved ahead to grant credits that can be used to pay state income tax to donors of qualified conservation easements. In 1983, North Carolina became the first state to establish such a program.
Attorney Philip Tabas of The Nature Conservancy promoted the state tax credit idea widely in the 1990s. In 1999 four state legislatures enacted state tax credit programs (Virginia, Delaware, Colorado, and Connecticut, in that order). South Carolina and California followed in 2000. Several other states have followed since. 
For landowners with little income subject to state taxation, a tax credit is a hollow reward for reducing the value of real property by donating a conservation easement. To respond to this, Colorado conservationists made their state tax credit transferable in 2000—that is, the donor/landowner can sell her/his credit to other parties; the buyers then use the purchased tax credit to pay their Colorado income tax. This is appealing to buyers because the credit is sold at a discount from face value. Virginia followed by enacting transferability in 2002. Delegate Bill Howell (now Speaker of the Virginia House of Delegates) introduced HB1322, which had been suggested to him by conservationists Charles Davenport and Phil Hocker. HB1322 was enacted, effective retroactively to 1Jan2002. Other states have followed since. However, "caps" on the amount of credit an easement can generate, and other restrictions, limit the scope of the different state tax credit programs in varying manners.
In the states where credit for conservation land donations is transferable, free markets have arisen. Brokers assist landowners with excess credit to contact buyers, and the brokers often handle payments and paperwork to protect the principals, and to ensure that transfers are fully reported to the state tax authorities. The federal and state tax treatment of profits from sale and use of transferable tax credit have been the subject of extensive discussion and the issuance of several guidance documents by the Internal Revenue Service.
The New Mexico state income tax credit was originated in 2003.581 New transferability legislation, effective January 1, 2008, applies retroactively to conservation easements effected from January 1, 2004.
The Virginia transferable credit program is far the largest among the States in dollar value of property conserved. By the end of 2010, $2,512,000,000 of property value had been donated as easements in Virginia for which tax credit was claimed. The qualifying easements cover over of Virginia landscape. The Virginia program now (2011) grants about $110 million of new tax credit each year. The credit allowance is 40% of the appraised value of the easement donation, so this equates to $275 million of property value donated per year for protection of wildlife habitat, farmland and woodland, and scenic open space—in perpetuity. The other state tax credit programs are smaller in dollar measurement, but are very significant in the area and the conservation values that they cause to be protected. The concept of state tax credit action (in the absence of a federal tax credit) that Philip Tabas and The Nature Conservancy promoted in the 1990s has borne remarkable fruit, and continues to expand today.
Estate tax reductions and exclusions.
For landowners who will leave sizable estates upon their death, the most important financial impact of a conservation easement may be a significant reduction in estate taxes. Estate taxes often make it difficult for heirs to keep land intact and in the family because of high estate tax rates and high development value of land. It may be necessary to subdivide or sell land for development in order to pay these taxes which may not be the desire of the landowner or their heirs. A conservation easement can often provide significant help with this problem in three important ways:
In Pennsylvania, conservation restrictions on land included in the estate can reduce the inheritance tax owed.
State and property tax incentives.
Some states (Colorado, Virginia, Maryland, and North Carolina) offer a state income tax incentive and many states offer property tax incentives to conservation easement donors. In Pennsylvania, conservation restrictions on land included in the estate can reduce the inheritance tax owed.
Purchase of Agricultural Conservation Easement programs.
In 1974, Suffolk County in New York enacted the first PACE (also known as purchase of development rights or PDR) program. King County in Washington and the states of Maryland, Massachusetts, and Connecticut quickly followed suit. As of 2003, the PACE program operates in 23 states, including 19 statewide and more than 45 local programs.

</doc>
<doc id="56522" url="https://en.wikipedia.org/wiki?curid=56522" title="Right-wing politics">
Right-wing politics

Right-wing politics hold that some forms of social stratification or social inequality are inevitable, natural, normal, or desirable, typically defending this position on the basis of natural law, economics or tradition. Hierarchy and inequality may be viewed as natural results of traditional social differences or from competition in market economies.
The political terms "Right" and "Left" were first used during the French Revolution (1789–99), and referred to seating arrangements in the French parliament; those who sat to the right of the chair of the parliamentary president were broadly supportive of the institutions of the monarchist "Ancien Régime". The original Right in France was formed as a reaction against the Left, and comprised those politicians supporting hierarchy, tradition, and clericalism. The use of the expression "la droite" ("the right") became prominent in France after the restoration of the monarchy in 1815, when "le droit" was applied the Ultra-royalists. The people of English-speaking countries did not apply the terms "right" and "left" to their own politics until the 20th Century.
From the 1830s to the 1880s, there was a shift in the Western world of social class structure and the economy, moving away from nobility and aristocracy towards capitalism. This general economic shift toward capitalism affected centre right movements such as the British Conservative Party, which responded by becoming supportive of capitalism.
Although the right-wing originated with traditional conservatives, monarchists and reactionaries, the term right-wing has been applied to extreme movements including fascists, Nazis, and racial supremacists.
In the United States "right-wing" has quite a different history and meaning. For the most part the American right wing is an integral part of the conservative movement in the U.S. The right has been a major—and often dominant—factor in American politics since about 1981 (the beginning of the Reagan Era).
History.
The political term "right-wing" was first used during the French Revolution, when liberal deputies of the Third Estate generally sat to the left of the president's chair, a custom that began in the Estates General of 1789. The nobility, members of the Second Estate, generally sat to the right. In the successive legislative assemblies, monarchists who supported the Ancien Régime were commonly referred to as rightists because they sat on the right side. A major figure on the right was Joseph de Maistre, who argued for an authoritarian form of conservatism. Throughout the 19th century, the main line dividing Left and Right in France was between supporters of the republic (often secularists) and supporters of the monarchy (often Catholics). On the right, the Legitimists and Ultra-royalists held counter-revolutionary views, while the Orléanists hoped to create a constitutional monarchy under their preferred branch of the royal family, a brief reality after the 1830 July Revolution. The centre-right Gaullists in post-World War II France advocated considerable social spending on education and infrastructure development, as well as extensive economic regulation, but limited the wealth redistribution measures characteristic of social democracy.
In British politics, the terms 'right' and 'left' came into common use for the first time in the late 1930s in debates over the Spanish Civil War.
The Right has gone through five distinct historical stages: (i) the reactionary right sought a return to aristocracy and established religion; (ii) the moderate right distrusted intellectuals and sought limited government; (iii) the radical right favored a romantic and aggressive nationalism; (iv) the extreme right proposed anti-immigration policies and implicit racism; and (v) the neo-liberal right sought to combine a market economy and economic deregulation with the traditional Right-wing beliefs in patriotism, élitism, and law and order.
Positions.
The meaning of right-wing "varies across societies, historical epochs, and political systems and ideologies." According to "The Concise Oxford Dictionary of Politics", in liberal democracies, the political Right opposes socialism and social democracy. Right-wing parties include conservatives, Christian democrats, classical liberals, nationalists and, on the far Right, racists and fascists.
Roger Eatwell and Neal O'Sullivan divide the Right into five types: 'reactionary', 'moderate', 'radical', 'extreme', and 'new'. Chip Berlet argues that each of these "styles of thought" are "responses to the left", including liberalism and socialism, which have arisen since the 1789 French Revolution. The 'reactionary right' looks toward the past and is "aristocratic, religious and authoritarian". The 'moderate right', typified by the writings of Edmund Burke, is tolerant of change, provided it is gradual, and accepts some aspects of liberalism, including the rule of law and capitalism, although it sees radical "laissez-faire" and individualism as harmful to society. Often the moderate right promotes nationalism and social welfare policies. 'Radical right' is a term developed after World War II to describe groups and ideologies such as McCarthyism, the John Birch Society, Thatcherism, and the Republikaner Party. Eatwell stresses that this use has "major typological problems" and that the term "has also been applied to clearly democratic developments." The radical right includes right-wing populism and various other subtypes. Eatwell argues that the 'extreme right' has four traits: "1) anti-democracy; 2) nationalism; 3) racism; and 4) the strong state". The 'New Right' consists of the liberal conservatives, who stress small government, free markets, and individual initiative.
Other authors make a distinction between the centre-right and the far right. Parties of the centre-right generally support liberal democracy, capitalism, the market economy (though they may accept government regulation to control monopolies), private property rights, and a limited welfare state (for example government provision of education and medical care). They support conservatism and economic liberalism, and oppose socialism and communism. The phrase "far right", by contrast, is used to describe those who favor an absolutist government, which uses the power of the state to support the dominant ethnic group or religion and often to criminalize other ethnic groups or religions. Typical examples of leaders to whom the "far right" label is often applied are Francisco Franco in Spain and Augusto Pinochet in Chile. The US Department of Homeland Security defines right-wing extremism as hate groups who target racial, ethnic or religious minorities and may be dedicated to a single issue. The phrase is also used to describe support for ethnic nationalism.
Social stratification.
Right-wing politics involves in varying degrees the rejection of some egalitarian objectives of left-wing politics, claiming either that social or economic inequality is natural and inevitable or that it is beneficial to society.
Right-wing ideologies and movements support social order. The original French right-wing was called "the party of order" and held that France needed a strong political leader to keep order. British conservative scholar R. J. White, who rejects egalitarianism, wrote: "Men are equal before God and the laws, but unequal in all else; hierarchy is the order of nature, and privilege is the reward of honourable service". American conservative Russell Kirk also rejected egalitarianism as imposing sameness, stating: "Men are created different; and a government that ignores this law becomes an unjust government for it sacrifices nobility to mediocrity". He took as one of the "canons" of conservatism the principle that "civilized society requires orders and classes".
Right libertarians reject collective or state-imposed equality as undermining reward for personal merit, initiative, and enterprise. In their view, it is unjust, limits personal freedom, and leads to social uniformity and mediocrity.
Anti-communism.
The original use of "right-wing" in reference to communism had the conservatives on the Right, the liberals in the center, and the communists on the Left. Both the conservatives and the liberals were strongly anti-communist. As time went on, however, conservatives accused liberals of being "soft on communism" and using freedom of speech and freedom of religion as a cover for their hidden communist sympathies. The history of the use of the term "right-wing" to mean anti-communist is a complicated one.
Early Marxist movements were at odds with the traditional monarchies that ruled over much of the European continent at the time. Many European monarchies outlawed the public expression of communist views, and the Communist Manifesto, which began "A spectre is haunting Europe," stated that monarchs feared for their thrones. Advocacy of communism was illegal in the Russian Empire, the German Empire and Austria-Hungary, the three most powerful monarchies in continental Europe prior to World War I. Many Monarchists (except Constitutional Monarchists) viewed inequality in wealth and political power as resulting from a divine natural order. The struggle between monarchists and communists was often described as a struggle between the Right and the Left.
By World War I however, in most European monarchies, the Divine Right of Kings had become discredited and replaced by liberal and nationalist movements. Most European monarchs became figureheads; elected governments held the real power. The most conservative European monarchy, the Russian Empire, was replaced by the communist Soviet Union. The Russian Revolution inspired a series of other communist revolutions across Europe in the years 1917–1922. Many of these, such as the German Revolution, were defeated by nationalist and monarchist military units. In this period, nationalism began to be considered right-wing, especially when it opposed the internationalism of the communists.
The 1920s and 1930s saw the fading of traditional right-wing politics. The mantle of conservative anti-communism was taken up by the rising fascist movements on the one hand, and by American-inspired liberal conservatives on the other. When communist groups and political parties began appearing around the world, as in the Republic of China in the 1920s, their opponents were usually colonial authorities, and the term right-wing came to be applied to colonialism.
After World War II, communism became a global phenomenon, and anti-communism became an integral part of the domestic and foreign policies of the United States and its NATO allies. Conservatism in the post-war era abandoned its monarchist and aristocratic roots, focusing instead on patriotism, religion, and nationalism. Throughout the Cold War, colonial governments in Asia, Africa, and Latin America turned to the United States for political and economic support. Communists were also enemies of capitalism, portraying Wall Street as the oppressor of the masses. The United States made anti-communism the top priority of its foreign policy, and many American conservatives sought to combat what they saw as communist influence at home. This led to the adoption of a number of domestic policies that are collectively known under the term "McCarthyism". While both liberals and conservatives were anti-communist, the followers of Senator McCarthy were called right-wing, and those on the Right called liberals who favored free speech, even for communists, leftist.
Economics.
In France after the French Revolution, the Right fought against the rising power of those who had grown rich through commerce, and sought to preserve the rights of the hereditary nobility. They were uncomfortable with capitalism, with the Enlightenment, with individualism, and with industrialism and fought to retain traditional social hierarchies and institutions. In Europe's history, there have been strong collectivist right-wing movements, such as in the social Catholic Right that has exhibited hostility to all forms of liberalism, including economic liberalism, and has historically advocated for paternalist class harmony involving an organic-hierarchical society where workers are protected while hierarchy of classes remain.
In the 19th century, the Right had shifted to support the newly rich in some European countries, particularly England, and instead of favouring the nobility over industrialists, favoured capitalists over the working class. Other right-wing currents on the Continent, such as Carlism in Spain and nationalist movements in France, Germany, and Russia, remained hostile to capitalism and industrialism. There are, however, still a few right-wing movements today, notably the French Nouvelle Droite, CasaPound, and American paleoconservatives, that are often in opposition to capitalist ethics and the effects they have on society as a whole, which they see as infringing upon or causing the decay of social traditions or hierarchies that they see as essential for social order.
In modern times, "right-wing" is sometimes used to describe laissez-faire capitalism. In Europe, capitalists formed alliances with the Right during their conflicts with workers after 1848. In France, the Right's support of capitalism can be traced to the late 19th century. The so-called neoliberal Right, popularized by Ronald Reagan and Margaret Thatcher, combines support for free markets, privatisation, and deregulation with traditional right-wing support for social conformity. Right-wing libertarianism (sometimes known as libertarian conservatism or conservative libertarianism) supports a decentralized economy based on economic freedom, and holds property rights, free markets and free trade to be the most important kinds of freedom. Russell Kirk believed that freedom and property rights were interlinked. Anthony Gregory has written that right-wing libertarianism, "can refer to any number of varying and at times mutually exclusive political orientations." He holds that the issue is not right or left but "whether a person sees the state as a major hazard or just another institution to be reformed and directed toward a political goal."
Conservative authoritarians and those on the far right have supported fascism and corporatism.
Nationalism.
In France, nationalism was originally a left-wing and Republican ideology. After the period of "boulangisme" and the Dreyfus Affair, nationalism became a trait of the right-wing. Right-wing nationalists sought to define and defend a "true" national identity from elements deemed to be corrupting that identity. Some were supremacists who, in accordance with Social Darwinism, applied the concept of "survival of the fittest" to nations and races. Right-wing nationalism was influenced by romantic nationalism, in which the state derives its political legitimacy from the organic unity of those it governs. This generally includes, the language, race, culture, religion and customs of the "nation", all of which were "born" within its culture. Linked with right-wing nationalism is cultural conservatism, which supports the preservation of the heritage of a nation or culture, and often sees deviations from cultural norms as an existential threat.
Natural law and traditionalism.
Right-wing politics typically justifies a hierarchical society on the basis of natural law or tradition.
Traditionalism was advocated by a group of U.S. university professors (labeled the "New Conservatives" by the popular press) who rejected the concepts of individualism, liberalism, modernity, and social progress, seeking instead to promote what they identified as cultural and educational renewal and a revived interest in what T. S. Eliot referred to as "the permanent things" (concepts perceived by traditionalists as truths that endure from age to age alongside basic institutions of western society such as the church, the family, the state, and business).
Populism.
Right-wing populism is a combination of ethno-nationalism with anti-elitism, using populist rhetoric to provide a radical critique of existing political institutions. According to Margaret Canovan, a right-wing populist is "...a charismatic leader, using the tactics of politicians’ populism to go past the politicians and intellectual elite and appeal to the reactionary sentiments of the populace, often buttressing his claim to speak for the people by the use of referendums."
In Europe, right-wing populism often takes the form of distrust of the European Union, and of politicians in general, combined with anti-immigrant rhetoric, and a call for a return to traditional, national values. In the United States, the Tea Party movement states that the core beliefs for membership are an opposition to illegal immigration, a strong national military force, the right to individual gun ownership, cutting taxes, reducing government spending, and balancing the budget.
Religion.
Government support for an established religion was associated with the original French "right wing." Joseph de Maistre argued for the indirect authority of the Pope over temporal matters. According to Maistre, only governments founded upon a Christian constitution, implicit in the customs and institutions of all European societies but especially in Catholic European monarchies, could avoid the disorder and bloodshed that followed the implementation of rationalist political programs, as in the French Revolution. The Church of England was established by Henry VIII. Some churchmen are given seats in the House of Lords but are considered politically neutral, rather than right or left wing.
Religious fundamentalists frequently feel that governments should enact laws supporting their religious tenets. The Christian right is a major force in North America. They generally support laws upholding what they consider religious values, such as opposition to abortion, contraception, sex outside marriage, and to same-sex marriage, and reject scientific positions on evolution and other matters where science disagrees with the Bible. Outside the West, other religious and ethnic groups are considered right-wing. In India, Hindu nationalism is sometimes considered a part of the Right. The Hindu nationalist movement has attracted privileged groups fearing encroachment on their dominant positions, and also "plebeian" and impoverished groups seeking recognition around a majoritarian rhetoric of cultural pride, order, and national strength. Many Islamist groups have been called "right wing" including the Great Union Party, and the Combatant Clergy Association/Association of Militant Clergy and the Islamic Society of Engineers of Iran.
The term "family values" has been used as a buzzword by right-wing parties such as the Republican Party in the United States, the Family First Party in Australia, the Conservative party in the United Kingdom and the Bharatiya Janata Party in India to describe support for traditional families, and opposition to the changes the modern world has made in how families live. Right-wing supporters of "family values" may oppose abortion, euthanasia, homosexuality, divorce, teenage pregnancy and adultery.

</doc>
<doc id="56524" url="https://en.wikipedia.org/wiki?curid=56524" title="Fats">
Fats

Fats or FATS may refer to:
Persons with the nickname:
FATS:

</doc>
<doc id="56525" url="https://en.wikipedia.org/wiki?curid=56525" title="Triglyceride">
Triglyceride

A triglyceride (TG, triacylglycerol, TAG, or triacylglyceride) is an ester derived from glycerol and three fatty acids ("tri-" + "glyceride"). Triglycerides are the main constituent of body fat in humans and animals, as well as vegetable fat. They are also present in the blood to enable the bidirectional transference of adipose fat and blood glucose from the liver, and are a major component of human skin oils.
There are many different types of triglyceride, with the main division being between saturated and unsaturated types. Saturated fats are "saturated" with hydrogen – all available places where hydrogen atoms could be bonded to carbon atoms are occupied. These have a higher melting point and are more likely to be solid at room temperature. Unsaturated fats have double bonds between some of the carbon atoms, reducing the number of places where hydrogen atoms can bond to carbon atoms. These have a lower melting point and are more likely to be liquid at room temperature.
Chemical structure.
Triglycerides are formed by combining glycerol with three fatty acid molecules. Alcohols have a hydroxyl (HO-) group. Organic acids have a carboxyl (-COOH) group. Alcohols and organic acids join to form esters. The glycerol molecule has three hydroxyl (HO-) groups. Each fatty acid has a carboxyl group (-COOH). In triglycerides, the hydroxyl groups of the glycerol join the carboxyl groups of the fatty acid to form ester bonds:
The three fatty acids (RCO2H, R'CO2H, R"CO2H in the above equation) are usually different, but many kinds of triglycerides are known. The chain lengths of the fatty acids in naturally occurring triglycerides vary, but most contain 16, 18, or 20 carbon atoms. Natural fatty acids found in plants and animals are typically composed of only even numbers of carbon atoms, reflecting the pathway for their biosynthesis from the two-carbon building-block acetyl CoA. Bacteria, however, possess the ability to synthesise odd- and branched-chain fatty acids. As a result, ruminant animal fat contains odd-numbered fatty acids, such as 15, due to the action of bacteria in the rumen. Many fatty acids are unsaturated, some are polyunsaturated, e.g., those derived from linoleic acid.
Most natural fats contain a complex mixture of individual triglycerides. Because of this, they melt over a broad range of temperatures. Cocoa butter is unusual in that it is composed of only a few triglycerides, derived from palmitic, oleic, and stearic acids in the 1-, 2-, and 3-positions of glycerol, respectively.
Homotriglycerides.
The simplest triglycerides are those where the three fatty acids are identical. Their names indicate the fatty acid: stearin derived from stearic acid, palmitin derived from palmitic acid, etc. These compounds can be obtained as three forms or polymorphs: ,α-, β-, and β'-. These forms differ in terms of their melting points.
Metabolism.
The pancreatic lipase acts at the ester bond, hydrolysing the bond and "releasing" the fatty acid. In triglyceride form, lipids cannot be absorbed by the duodenum. Fatty acids, monoglycerides (one glycerol, one fatty acid), and some diglycerides are absorbed by the duodenum, once the triglycerides have been broken down.
In the intestine, following the secretion of lipases and bile, triglycerides are split into monoacylglycerol and free fatty acids in a process called lipolysis. They are subsequently moved to absorptive enterocyte cells lining the intestines. The triglycerides are rebuilt in the enterocytes from their fragments and packaged together with cholesterol and proteins to form chylomicrons. These are excreted from the cells and collected by the lymph system and transported to the large vessels near the heart before being mixed into the blood. Various tissues can capture the chylomicrons, releasing the triglycerides to be used as a source of energy. Liver cells can synthesize and store triglycerides. When the body requires fatty acids as an energy source, the hormone glucagon signals the breakdown of the triglycerides by hormone-sensitive lipase to release free fatty acids. As the brain cannot utilize fatty acids as an energy source (unless converted to a ketone), the glycerol component of triglycerides can be converted into glucose, via gluconeogenesis by conversion into dihydroxyacetone phosphate and then into glyceraldehyde 3-phosphate, for brain fuel when it is broken down. Fat cells may also be broken down for that reason, if the brain's needs ever outweigh the body's.
Triglycerides cannot pass through cell membranes freely. Special enzymes on the walls of blood vessels called lipoprotein lipases must break down triglycerides into free fatty acids and glycerol. Fatty acids can then be taken up by cells via the fatty acid transporter (FAT).
Triglycerides, as major components of very-low-density lipoprotein (VLDL) and chylomicrons, play an important role in metabolism as energy sources and transporters of dietary fat. They contain more than twice as much energy (approximately 9 kcal/g or 38 kJ/g ) as carbohydrates (approximately 4 kcal/g or 17 kJ/g ).
Role in disease.
In the human body, high levels of triglycerides in the bloodstream have been linked to atherosclerosis and, by extension, the risk of heart disease and stroke. However, the relative negative impact of raised levels of triglycerides compared to that of LDL:HDL ratios is as yet unknown. The risk can be partly accounted for by a strong inverse relationship between triglyceride level and HDL-cholesterol level.
Guidelines.
The National Cholesterol Education Program has set guidelines for triglyceride levels:
These levels are tested after fasting 8 to 12 hours. Triglyceride levels remain temporarily higher for a period after eating.
The American Heart Association recommends an optimal triglyceride level of 100 mg/dL (1.1 mmol/L) or lower to improve heart health.
Reducing triglyceride levels.
Diets high in refined carbohydrates, with carbohydrates accounting for more than 60% of the total energy intake, can increase triglyceride levels. Of note is how the correlation is stronger for those with higher BMI (28+) and insulin resistance (more common among overweight and obese) is a primary suspect cause of this phenomenon of carbohydrate-induced hypertriglyceridemia.
There is evidence that carbohydrate consumption causing a high glycemic index can cause insulin overproduction and increase triglyceride levels in women.
Adverse changes associated with carbohydrate intake, including triglyceride levels, are stronger risk factors for heart disease in women than in men.
Triglyceride levels are also reduced by moderate exercise and by consuming omega-3 fatty acids from fish, flax seed oil, and other sources.
Carnitine has the ability to lower blood triglyceride levels. In some cases, fibrates have been used to bring down triglycerides substantially. AstraZeneca has developed Epanova (omega-3-carboxylic acids) to treat high triglycerides.
Heavy alcohol consumption can elevate triglycerides levels.
VASCEPA is an ethyl ester of eicosapentaenoic acid (EPA) indicated as an adjunct to diet to reduce triglyceride (TG) levels in adult patients with severe (≥ 500 mg/dL) hypertriglyceridemia.
Industrial uses.
Linseed oil and related oils are important components of useful products used in oil paints and related coatings. Linseed oil is rich in di- and triunsaturated fatty acid components, which tend to harden in the presence of oxygen. This heat-producing hardening process is peculiar to these so-called "drying oils". It is caused by a polymerization process that begins with oxygen molecules attacking the carbon backbone.
Triglycerides are also split into their components via transesterification during the manufacture of biodiesel. The resulting fatty acid esters can be used as fuel in diesel engines. The glycerin has many uses, such as in the manufacture of food and in the production of pharmaceuticals.
Staining.
Staining for fatty acids, triglycerides, lipoproteins, and other lipids is done through the use of lysochromes (fat-soluble dyes). These dyes can allow the qualification of a certain fat of interest by staining the material a specific color. Some examples: Sudan IV, Oil Red O, and Sudan Black B.

</doc>
<doc id="56526" url="https://en.wikipedia.org/wiki?curid=56526" title="Diabetic ketoacidosis">
Diabetic ketoacidosis

Diabetic ketoacidosis (DKA) is a potentially life-threatening complication in people with diabetes mellitus. It happens predominantly in those with type 1 diabetes, but it can occur in those with type 2 diabetes under certain circumstances. DKA results from a shortage of insulin; in response the body switches to burning fatty acids and producing acidic ketone bodies that cause most of the symptoms and complications.
DKA may be the first symptom of previously undiagnosed diabetes, but it may also occur in people known to have diabetes as a result of a variety of causes, such as intercurrent illness or poor compliance with insulin therapy. Vomiting, dehydration, deep gasping breathing, confusion and occasionally coma are typical symptoms. DKA is diagnosed with blood and urine tests; it is distinguished from other, rarer forms of ketoacidosis by the presence of high blood sugar levels. Treatment involves intravenous fluids to correct dehydration, insulin to suppress the production of ketone bodies, treatment for any underlying causes such as infections, and close observation to prevent and identify complications.
DKA is a medical emergency, and without treatment it can lead to death. DKA was first described in 1886; until the introduction of insulin therapy in the 1920s, it was almost universally fatal. It now carries a mortality of less than 1% with adequate and timely treatment.
Signs and symptoms.
The symptoms of an episode of diabetic ketoacidosis usually evolve over the period of about 24 hours. Predominant symptoms are nausea and vomiting, pronounced thirst, excessive urine production and abdominal pain that may be severe. Those who measure their glucose levels themselves may notice hyperglycemia (high blood sugar levels). In severe DKA, breathing becomes labored and of a deep, gasping character (a state referred to as "Kussmaul respiration"). The abdomen may be tender to the point that an acute abdomen may be suspected, such as acute pancreatitis, appendicitis or gastrointestinal perforation. Coffee ground vomiting (vomiting of altered blood) occurs in a minority of people; this tends to originate from erosion of the esophagus. In severe DKA, there may be confusion, lethargy, stupor or even coma (a marked decrease in the level of consciousness).
On physical examination there is usually clinical evidence of dehydration, such as a dry mouth and decreased skin turgor. If the dehydration is profound enough to cause a decrease in the circulating blood volume, tachycardia (a fast heart rate) and low blood pressure may be observed. Often, a "ketotic" odor is present, which is often described as "fruity", often compared to the smell of pear drops whose scent is a ketone. If Kussmaul respiration is present, this is reflected in an increased respiratory rate.
Small children with DKA are relatively prone to cerebral edema (swelling of the brain tissue), which may cause headache, coma, loss of the pupillary light reflex, and progress to death. It occurs in 0.3–1.0% of children with DKA, and has been described in young adults, but is overall very rare in adults. It carries a 20–50% mortality.
Cause.
DKA most frequently occurs in those who already have diabetes, but it may also be the first presentation in someone who had not previously been known to be diabetic. There is often a particular underlying problem that has led to the DKA episode; this may be intercurrent illness (pneumonia, influenza, gastroenteritis, a urinary tract infection), pregnancy, inadequate insulin administration (e.g. defective insulin pen device), myocardial infarction (heart attack), stroke or the use of cocaine. Young people with recurrent episodes of DKA may have an underlying eating disorder, or may be using insufficient insulin for fear that it will cause weight gain.
Diabetic ketoacidosis may occur in those previously known to have diabetes mellitus type 2 or in those who on further investigations turn out to have features of type 2 diabetes (e.g. obesity, strong family history); this is more common in African, African-American and Hispanic people. Their condition is then labeled "ketosis-prone type 2 diabetes".
Drugs in the gliflozin class (SGLT2 inhibitors), which are generally used for type 2 diabetes, have been associated with diabetic ketoacidosis with remarkably low blood sugars ("euglycemic DKA"). This may be because they were being used in people with type 1 diabetes, but in those with type 2 diabetes it may be as a result of an increase in glucagon levels.
Mechanism.
Diabetic ketoacidosis arises because of a lack of insulin in the body. The lack of insulin and corresponding elevation of glucagon leads to increased release of glucose by the liver (a process that is normally suppressed by insulin) from glycogen via glycogenolysis and also through gluconeogenesis. High glucose levels spill over into the urine, taking water and solutes (such as sodium and potassium) along with it in a process known as osmotic diuresis. This leads to polyuria, dehydration, and compensatory thirst and polydipsia. The absence of insulin also leads to the release of free fatty acids from adipose tissue (lipolysis), which are converted through a process called beta oxidation, again in the liver, into ketone bodies (acetoacetate and β-hydroxybutyrate). β-Hydroxybutyrate can serve as an energy source in the absence of insulin-mediated glucose delivery, and is a protective mechanism in case of starvation. The ketone bodies, however, have a low pKa and therefore turn the blood acidic (metabolic acidosis). The body initially buffers the change with the bicarbonate buffering system, but this system is quickly overwhelmed and other mechanisms must work to compensate for the acidosis. One such mechanism is hyperventilation to lower the blood carbon dioxide levels (a form of compensatory respiratory alkalosis). This hyperventilation, in its extreme form, may be observed as Kussmaul respiration.
In various situations such as infection, insulin demands rise but are not matched by the failing pancreas. Blood sugars rise, dehydration ensues, and resistance to the normal effects of insulin increases further by way of a vicious circle.
As a result of the above mechanisms, the average adult with DKA has a total body water shortage of about 6 liters (or 100 mL/kg), in addition to substantial shortages in sodium, potassium, chloride, phosphate, magnesium and calcium. Glucose levels usually exceed 13.8 mmol/L or 250 mg/dL.
DKA is common in type 1 diabetes as this form of diabetes is associated with an absolute lack of insulin production by the islets of Langerhans. In type 2 diabetes, insulin production is present but is insufficient to meet the body's requirements as a result of end-organ insulin resistance. Usually, these amounts of insulin are sufficient to suppress ketogenesis. If DKA occurs in someone with type 2 diabetes, their condition is called "ketosis-prone type 2 diabetes". The exact mechanism for this phenomenon is unclear, but there is evidence both of impaired insulin secretion and insulin action. Once the condition has been treated, insulin production resumes and often the person may be able to resume diet or tablet treatment as normally recommended in type 2 diabetes.
The clinical state of DKA is associated, in addition to the above, with the release of various counterregulatory hormones such as glucagon and adrenaline as well as cytokines, the latter of which leads to increased markers of inflammation, even in the absence of infection.
Cerebral edema, which is the most dangerous DKA complication, is probably the result of a number of factors. Some authorities suggest that it is the result from overvigorous fluid replacement, but the complication may develop before treatment has been commenced. It is more likely in those with more severe DKA, and in the first episode of DKA. Likely factors in the development of cerebral edema are dehydration, acidosis and low carbon dioxide levels; in addition, the increased level of inflammation and coagulation may, together with these factors, lead to decreased blood flow to parts of the brain, which then swells up once fluid replacement has been commenced. The swelling of brain tissue leads to raised intracranial pressure ultimately leading to death.
Diagnosis.
Investigations.
Diabetic ketoacidosis may be diagnosed when the combination of hyperglycemia (high blood sugars), ketones in the blood or on urinalysis and acidosis are demonstrated. In about 10% of cases the blood sugar is not significantly elevated ("euglycemic diabetic ketoacidosis").
Arterial blood gas measurement is usually performed to demonstrate the acidosis; this requires taking a blood sample from an artery. Subsequent measurements (to ensure treatment is effective), may be taken from a normal blood test taken from a vein, as there is little difference between the arterial and the venous pH. Ketones can be measured in the urine (acetoacetate) and blood (β-hydroxybutyrate). When compared with urine acetoacetate testing, capillary blood β-hydroxybutyrate determination can reduce the need of admission, shorten the duration of hospital admission and potentially reduce the costs of hospital care. At very high levels, capillary blood ketone measurement becomes imprecise.
In addition to the above, blood samples are usually taken to measure urea and creatinine (measures of kidney function, which may be impaired in DKA as a result of dehydration) and electrolytes. Furthermore, markers of infection (complete blood count, C-reactive protein) and acute pancreatitis (amylase and lipase) may be measured. Given the need to exclude infection, chest radiography and urinalysis are usually performed.
If cerebral edema is suspected because of confusion, recurrent vomiting or other symptoms, computed tomography may be performed to assess its severity and to exclude other causes such as stroke.
Criteria.
Diabetic ketoacidosis is distinguished from other diabetic emergencies by the presence of large amounts of ketones in blood and urine, and marked metabolic acidosis. Hyperosmolar hyperglycemic state (HHS, sometimes labeled "hyperosmolar non-ketotic state" or HONK) is much more common in type 2 diabetes and features increased plasma osmolarity (above 320 mosm/kg) due to profound dehydration and concentration of the blood; mild acidosis and ketonemia may occur in this state, but not to the extent observed in DKA. There is a degree of overlap between DKA and HHS, as in DKA the osmolarity may also be increased.
Ketoacidosis is not always the result of diabetes. It may also result from alcohol excess and from starvation; in both states the glucose level is normal or low. Metabolic acidosis may occur in people with diabetes for other reasons, such as poisoning with ethylene glycol or paraldehyde.
The American Diabetes Association categorizes DKA in adults into one of three stages of severity:
A 2004 statement by the European Society for Paediatric Endocrinology and the Lawson Wilkins Pediatric Endocrine Society (for children) uses slightly different cutoffs, where mild DKA is defined by pH 7.20–7.30 (bicarbonate 10–15 mmol/l), moderate DKA by pH 7.1–7.2 (bicarbonate 5–10) and severe DKA by pH<7.1 (bicarbonate below 5).
Prevention.
Attacks of DKA can be prevented in those known to have diabetes to an extent by adherence to "sick day rules"; these are clear-cut instructions to person on how to treat themselves when unwell. Instructions include advice on how much extra insulin to take when sugar levels appear uncontrolled, an easily digestible diet rich in salt and carbohydrates, means to suppress fever and treat infection, and recommendations when to call for medical help.
People with diabetes can monitor their own ketone levels when unwell and seek help if they are elevated.
Management.
The main aims in the treatment of diabetic ketoacidosis are replacing the lost fluids and electrolytes while suppressing the high blood sugars and ketone production with insulin. Admission to an intensive care unit or similar high-dependency area or ward for close observation may be necessary.
Fluid replacement.
The amount of fluid replaced depends on the estimated degree of dehydration. If dehydration is so severe as to cause shock (severely decreased blood pressure with insufficient blood supply to the body's organs), or a depressed level of consciousness, rapid infusion of saline (1 liter for adults, 10 ml/kg in repeated doses for children) is recommended to restore circulating volume. Slower rehydration based on calculated water and sodium shortage may be possible if the dehydration is moderate, and again saline is the recommended fluid. Very mild ketoacidosis with no associated vomiting and mild dehydration may be treated with oral rehydration and subcutaneous rather than intravenous insulin under observation for signs of deterioration.
A special but unusual consideration is cardiogenic shock, where the blood pressure is decreased not due to dehydration but due to inability of the heart to pump blood through the blood vessels. This situation requires ICU admission, monitoring of the central venous pressure (which requires the insertion of a central venous catheter in a large upper body vein), and the administration of medication that increases the heart pumping action and blood pressure.
Insulin.
Some guidelines recommend a bolus (initial large dose) of insulin of 0.1 unit of insulin per kilogram of body weight. This can be administered immediately after the potassium level is known to be higher than 3.3 mmol/l; if the level is any lower, administering insulin could lead to a dangerously low potassium level (see below). Other guidelines recommend delaying the initiation of insulin until fluids have been administered. It is possible to use rapid acting insulin analogs injections under the skin for mild or moderate cases.
In general, insulin is given at 0.1 unit/kg per hour to reduce the blood sugars and suppress ketone production. Guidelines differ as to which dose to use when blood sugar levels start falling; some recommend reducing the dose of insulin once glucose falls below 16.6 mmol/l (300 mg/dl) but other recommend infusing glucose in addition to saline to allow for ongoing infusion of higher doses of insulin.
Potassium.
Potassium levels can fluctuate severely during the treatment of DKA, because insulin decreases potassium levels in the blood by redistributing it into cells. A large part of the shifted extracellular potassium would have been lost in urine because of osmotic diuresis. Hypokalemia (low blood potassium concentration) often follows treatment. This increases the risk of dangerous irregularities in the heart rate. Therefore, continuous observation of the heart rate is recommended, as well as repeated measurement of the potassium levels and addition of potassium to the intravenous fluids once levels fall below 5.3 mmol/l. If potassium levels fall below 3.3 mmol/l, insulin administration may need to be interrupted to allow correction of the hypokalemia.
Bicarbonate.
The administration of sodium bicarbonate solution to rapidly improve the acid levels in the blood is controversial. There is little evidence that it improves outcomes beyond standard therapy, and indeed some evidence that while it may improve the acidity of the blood, it may actually worsen acidity inside the body's cells and increase the risk of certain complications. Its use is therefore discouraged, although some guidelines recommend it for extreme acidosis (pH<6.9), and smaller amounts for severe acidosis (pH 6.9–7.0).
Cerebral edema.
Cerebral edema, if associated with coma, often necessitates admission to intensive care, artificial ventilation, and close observation. The administration of fluids is slowed. The ideal treatment of cerebral edema in DKA is not established, but intravenous mannitol and hypertonic saline (3%) are used—as in some other forms of cerebral edema—in an attempt to reduce the swelling.
Resolution.
Resolution of DKA is defined as general improvement in the symptoms, such as the ability to tolerate oral nutrition and fluids, normalization of blood acidity (pH>7.3), and absence of ketones in blood (<1 mmol/l) or urine. Once this has been achieved, insulin may be switched to the usual subcutaneously administrered regimen, one hour after which the intravenous administration can be discontinued.
In people with suspected ketosis-prone type 2 diabetes, determination of antibodies against glutamic acid decarboxylase and islet cells may aid in the decision whether to continue insulin administration long-term (if antibodies are detected), or whether to withdraw insulin and attempt treatment with oral medication as in type 2 diabetes. Generally speaking, routine measurement of C-peptide as a measure of insulin production is not recommended unless there is genuine doubt as to whether someone has type 1 or type 2 diabetes.
Epidemiology.
Diabetic ketoacidosis occurs in 4.6–8.0 per 1000 people with type 1 diabetes annually. In the United States, 135,000 hospital admissions occur annually as a result of DKA, at an estimated cost of $2.4 billion or a quarter to a half the total cost of caring for people with type 1 diabetes. There has been a documented increasing trend to hospital admissions. The risk is increased in those with an ongoing risk factor, such as an eating disorder, and those who cannot afford insulin. About 30% of children with type 1 diabetes receive their diagnosis after an episode of DKA.
History.
The first full description of diabetic ketoacidosis is attributed to Julius Dreschfeld, a German pathologist working in Manchester, United Kingdom. In his description, which he gave in an 1886 lecture at the Royal College of Physicians in London, he drew on reports by Adolph Kussmaul as well as describing the main ketones, acetoacetate and β-hydroxybutyrate, and their chemical determination. The condition remained almost universally fatal until the discovery of insulin in the 1920s; by the 1930s, mortality had fallen to 29%, and by the 1950s it had become less than 10%. The entity of cerebral edema due to DKA was described in 1936 by a team of doctors from Philadelphia.
Numerous research studies since the 1950s have focused on the ideal treatment for diabetic ketoacidosis. A significant proportion of these studies have been conducted at the University of Tennessee Health Science Center and Emory University School of Medicine. Treatment options studied have included high- or low-dose intravenous, subcutaneous or intramuscular (e.g. the "Alberti regime") insulin, phosphate supplementation, need for a loading dose of insulin, and appropriateness of using bicarbonate therapy in moderate DKA. Various questions remain unanswered, such as whether bicarbonate administration in severe DKA makes any real difference to the clinical course, and whether an insulin loading dose is needed in adults.
The entity of ketosis-prone type 2 diabetes was first fully described in 1987 after several preceding case reports. It was initially thought to be a form of maturity onset diabetes of the young, and went through several other descriptive names (such as "idiopathic type 1 diabetes", "Flatbush diabetes", "atypical diabetes" and "type 1.5 diabetes") before the current terminology of "ketosis-prone type 2 diabetes" was adopted.

</doc>
<doc id="56527" url="https://en.wikipedia.org/wiki?curid=56527" title="Galactose">
Galactose

Galactose ("galacto-" + "-ose", "milk sugar"), sometimes abbreviated Gal, is a monosaccharide sugar that is less sweet than glucose and fructose. It is a C-4 epimer of glucose.
Galactan is a polymeric form of galactose found in hemicellulose. Galactan can be converted to galactose by hydrolysis.
Structure and isomerism.
Galactose exists in both open-chain and cyclic form. The open-chain form has a carbonyl at the end of the chain.
Four isomers are cyclic, two of them with a pyranose (six-membered) ring, two with a furanose (five-membered) ring. Galactofuranose occurs in bacteria, fungi and protozoa
, and is recognized by a putative chordate immune lectin intelectin through its exocyclic 1,2-diol. In the cyclic form there are two anomers, named alpha and beta, since the transition from the open-chain form to the cyclic form involves the creation of a new stereocenter at the site of the open-chain carbonyl. In the beta form, the alcohol group is in the equatorial position, whereas in the alpha form, the alcohol group is in the axial position.
Relationship to lactose.
Galactose is a monosaccharide. When combined with glucose (monosaccharide), through a condensation reaction, the result is the disaccharide lactose. The hydrolysis of lactose to glucose and galactose is catalyzed by the enzymes lactase and β-galactosidase. The latter is produced by the "lac" operon in "Escherichia coli".
In nature, lactose is found primarily in milk and milk products. Consequently, various food products made with dairy-derived ingredients, e.g. breads and cereals, can contain lactose. Galactose metabolism, which converts galactose into glucose, is carried out by the three principal enzymes in a mechanism known as the Leloir pathway. The enzymes are listed in the order of the metabolic pathway: galactokinase (GALK), galactose-1-phosphate uridyltransferase (GALT), and UDP-galactose-4’-epimerase (GALE).
In the human body, glucose is changed into galactose via hexoneogenesis to enable the mammary glands to secrete lactose. However, most lactose in breast milk is synthesized from galactose taken up from the blood, and only 35±6% is made from galactose from "de novo" synthesis.
Metabolism.
Glucose is the primary metabolic fuel for humans. It is more stable than galactose and is less susceptible to the formation of nonspecific glycoconjugates, molecules with at least one sugar attached to a protein or lipid. Many speculate that it is for this reason that a pathway for rapid conversion from galactose to glucose has been highly conserved among many species.a 4 b 21 c 22 d 22</ref>
The main pathway of galactose metabolism is the Leloir pathway; humans and other species, however, have been noted to contain several alternate pathways, such as the De Ley Doudoroff pathway. The Leloir pathway consists of the latter stage of a two-part process that converts β-D-galactose to UDP-glucose. The initial stage is the conversion of β-D-galactose to α-D-galactose by the enzyme, mutarotase (GALM). The Leloir pathway then carries out the conversion of α-D-galactose to UDP-glucose via three principal enzymes: Galactokinase (GALK) phosphorylates α-D-galactose to galactose-1-phosphate, or Gal-1-P; Galactose-1-phosphate uridyltransferase (GALT) transfers a UMP group from UDP-glucose to Gal-1-P to form UDP-galactose; and finally, UDP galactose-4’-epimerase (GALE) interconverts UDP-galactose and UDP-glucose, thereby completing the pathway. a 517 b 516 c 519</ref>
Galactosemia is an inability to properly break down galactose due to a genetically inherited mutation in one of the enzymes in the Leloir pathway. As a result, the consumption of even small quantities is harmful to galactosemics.
Sources.
Galactose is found in dairy products, sugar beets, other gums and mucilages. It is also synthesized by the body, where it forms part of glycolipids and glycoproteins in several tissues; and is a by-product from the third-generation ethanol production process (from macroalgae).
Clinical significance.
Chronic systemic exposure of mice, rats, and "Drosophila" to D-galactose causes the acceleration of senescence (aging) and has been used as an aging model.
Two studies have suggested a possible link between galactose in milk and ovarian cancer. Other studies show no correlation, even in the presence of defective galactose metabolism. More recently, pooled analysis done by the Harvard School of Public Health showed no specific correlation between lactose-containing foods and ovarian cancer, and showed statistically insignificant increases in risk for consumption of lactose at ≥30 g/d. More research is necessary to ascertain possible risks.
Some ongoing studies suggest galactose may have a role in treatment of focal segmental glomerulosclerosis (a kidney disease resulting in kidney failure and proteinuria). This effect is likely to be a result of binding of galactose to FSGS factor.
Galactose is a component of the antigens present on blood cells that determine blood type within the ABO blood group system. In O and A antigens, there are two monomers of galactose on the antigens, whereas in the B antigens there are three monomers of galactose.
A disaccharide composed of two units of galactose, galactose-alpha-1,3-galactose (alpha-gal), has been recognized as a potential allergen present in mammal meat. Alpha-gal allergy may be triggered by lone star tick bites.
History.
In 1855, E. O. Erdmann noted that hydrolysis of lactose produced a substance besides glucose. Galactose was first isolated and studied by Louis Pasteur in 1856. He called it "lactose". In 1860, Berthelot renamed it "galactose" or "glucose lactique". In 1894, Emil Fischer and Robert Morrell determined the configuration of galactose.

</doc>
<doc id="56531" url="https://en.wikipedia.org/wiki?curid=56531" title="Retinopathy">
Retinopathy

Retinopathy is persistent or acute damage to the retina of the eye. Ongoing inflammation and vascular remodeling may occur over periods of time where the patient is not fully aware of the extent of the disease. Frequently, retinopathy is an ocular manifestation of systemic disease as seen in diabetes or hypertension. Diabetic retinopathy is the leading cause of blindness in working-aged people.
Pathophysiology.
Causes of retinopathy include but are not limited to: 
Many types of retinopathy are proliferative, most often resulting from neovascularization or blood vessel overgrowth. Angiogenesis is the hallmark precursor that may result in blindness or severe vision loss, particularly if the macula becomes affected.
Retinopathy may more rarely be due to ciliopathic genetic disorders, such as Alström syndrome or Bardet–Biedl syndrome.
Retinopathy is diagnosed by an ophthalmologist during eye examination. Treatment depends on the cause of the disease.
Remote Screening.
Telemedicine programs are available that allow primary care clinics to take images using specially designed retinal imaging equipment which can then be shared electronically with specialists at other locations for review. In 2009, Community Health Center, Inc. implemented a telemedicine retinal screening program for low-income patients with diabetes as part of those patients annual visits at the Federally Qualified Health Center.
Treatment.
Treatment is based on the cause of the retinopathy and may include laser therapy to the retina. In recent years targeting the pathway controlling vessel growth or angiogenesis has been promising. Vascular endothelial growth factor (VEGF) seems to play a vital role in promoting neovascularization. Using anti-VEGF drugs (antibodies to sequester the growth factor), researches have shown significant reduction in the extent of vessel outgrowth. Several anti-VEGF treatments are currently under review in both clinical trials and in preclinical labs.

</doc>
<doc id="56533" url="https://en.wikipedia.org/wiki?curid=56533" title="Diabetic retinopathy">
Diabetic retinopathy

Diabetic retinopathy ([ˌrɛtnˈɑpəθi]), also known as diabetic eye disease, is when damage occurs to the retina due to diabetes. It can eventually lead to blindness.
It is an ocular manifestation of diabetes, a systemic disease, which affects up to 80 percent of all patients who have had diabetes for 20 years or more. Despite these intimidating statistics, research indicates that at least 90% of these new cases could be reduced if there were proper and vigilant treatment and monitoring of the eyes. The longer a person has diabetes, the higher his or her chances of developing diabetic retinopathy. Each year in the United States, diabetic retinopathy accounts for 12% of all new cases of blindness. It is also the leading cause of blindness for people aged 20 to 64 years.
Signs and symptoms.
Diabetic retinopathy often has no early warning signs. Even macular edema, which can cause rapid vision loss, may not have any warning signs for some time. In general, however, a person with macular edema is likely to have blurred vision, making it hard to do things like read or drive. In some cases, the vision will get better or worse during the day.
In the first stage which is called non-proliferative diabetic retinopathy (NPDR) there are no symptoms, the signs are not visible to the eye and patients will have 20/20 vision. The only way to detect NPDR is by fundus photography, in which microaneurysms (microscopic blood-filled bulges in the artery walls) can be seen. If there is reduced vision, fluorescein angiography can be done to see the back of the eye. Narrowing or blocked retinal blood vessels can be seen clearly and this is called retinal ischemia (lack of blood flow).
Macular edema in which blood vessels leak their contents into the macular region can occur at any stage of NPDR. The symptoms of macular edema are blurred vision and darkened or distorted images that are not the same in both eyes. Ten percent (10%) of diabetic patients will have vision loss related to macular edema. Optical Coherence Tomography can show the areas of 
retinal thickening (due to fluid accumulation) of macular edema.
In the second stage, abnormal new blood vessels (neovascularisation) form at the back of the eye as part of "proliferative diabetic retinopathy" (PDR); these can burst and bleed (vitreous hemorrhage) and blur the vision, because these new blood vessels are fragile. The first time this bleeding occurs, it may not be very severe. In most cases, it will leave just a few specks of blood, or spots floating in a person's visual field, though the spots often go away after a few hours.
These spots are often followed within a few days or weeks by a much greater leakage of blood, which blurs the vision. In extreme cases, a person may only be able to tell light from dark in that eye. It may take the blood anywhere from a few days to months or even years to clear from the inside of the eye, and in some cases the blood will not clear. These types of large hemorrhages tend to happen more than once, often during sleep.
On funduscopic exam, a doctor will see cotton wool spots, flame hemorrhages (similar lesions are also caused by the alpha-toxin of "Clostridium novyi"), and dot-blot hemorrhages.
Risk factors.
All people with "diabetes mellitus" are at riskthose with Type I diabetes and those with Type II diabetes. The longer a person has diabetes, the higher their risk of developing some ocular problem. Between 40 to 45 percent of Americans diagnosed with diabetes have some stage of diabetic retinopathy. After 20 years of diabetes, nearly all patients with Type I diabetes and >60% of patients with Type II diabetes have some degree of retinopathy; however, these statistics were published in 2002 using data from four years earlier, limiting the usefulness of the research. The subjects would have been diagnosed with diabetes in the late 1970s, before modern fast acting insulin and home glucose testing.
Prior studies had also assumed a clear glycemic threshold between people at high and low risk of diabetic retinopathy.
However, it has been shown that the widely accepted WHO and American Diabetes Association diagnostic cutoff for diabetes of a fasting plasma glucose ≥ 7.0 mmol/l (126 mg/dl) does not accurately identify diabetic retinopathy among patients. The cohort study included a multi-ethnic, cross-sectional adult population sample in the US, as well as two cross-sectional adult populations in Australia. For the US-based component of the study, the sensitivity was 34.7% and specificity was 86.6%. For patients at similar risk to those in this study (15.8% had diabetic retinopathy), this leads to a positive predictive value of 32.7% and negative predictive value of 87.6%.
Published rates vary between trials, the proposed explanation being differences in study methods and reporting of prevalence rather than incidence values.
During pregnancy, diabetic retinopathy may also be a problem for women with diabetes.
It is recommended that all pregnant women with diabetes have dilated eye examinations each trimester to protect their vision.
People with Down's syndrome, who have extra chromosome 21 material, almost never acquire diabetic retinopathy. This protection appears to be due to the elevated levels of endostatin, an anti-angiogenic protein, derived from collagen XVIII. The collagen XVIII gene is located on chromosome 21.
Pathogenesis.
Diabetic retinopathy is the result of microvascular retinal changes. Hyperglycemia-induced intramural pericyte death and thickening of the basement membrane lead to incompetence of the vascular walls. These damages change the formation of the blood-retinal barrier and also make the retinal blood vessels more permeable. Hypoxia has been implicated as a causative factor in the degradation of the retina and some early investigations have supported this hypothesis.
The pericyte death is caused when "hyperglycemia persistently activates protein kinase C-δ (PKC-δ, encoded by Prkcd) and p38 mitogen-activated protein kinase (MAPK) to increase the expression of a previously unknown target of PKC-δ signaling, Src homology-2 domain–containing phosphatase-1 (SHP-1), a protein tyrosine phosphatase. This signaling cascade leads to PDGF receptor- dephosphorylation and a reduction in downstream signaling from this receptor, resulting in pericyte apoptosis…"
Small blood vessels – such as those in the eye – are especially vulnerable to poor blood sugar (blood glucose) control. An overaccumulation of glucose and/or fructose damages the tiny blood vessels in the retina. During the initial stage, called nonproliferative diabetic retinopathy (NPDR), most people do not notice any change in their vision. Early changes that are reversible and do not threaten central vision are sometimes termed "simplex retinopathy" or "background retinopathy".
Some people develop a condition called macular edema. It occurs when the damaged blood vessels leak fluid and lipids onto the macula, the part of the retina that lets us see detail. The fluid makes the macula swell, which blurs vision.
Proliferative diabetic retinopathy.
As the disease progresses, severe nonproliferative diabetic retinopathy enters an advanced, or proliferative (PDR), stage when blood vessels proliferate (i.e. grow). The lack of oxygen in the retina causes fragile, new, blood vessels to grow along the retina and in the clear, gel-like vitreous humour that fills the inside of the eye. Without timely treatment, these new blood vessels can bleed, cloud vision, and destroy the retina. Fibrovascular proliferation can also cause tractional retinal detachment. The new blood vessels can also grow into the angle of the anterior chamber of the eye and cause neovascular glaucoma.
Nonproliferative diabetic retinopathy shows up as cotton wool spots, or microvascular abnormalities or as superficial retinal hemorrhages. Even so, the advanced proliferative diabetic retinopathy (PDR) can remain asymptomatic for a very long time, and so should be monitored closely with regular checkups.
Diagnosis.
Diabetic retinopathy is detected during an eye examination that includes:
The eye care professional will look at the retina for early signs of the disease, such as:
If macular edema is suspected, FFA and sometimes OCT may be performed.
According to a DRSS user manual, poor quality images (which may apply to other methods) may be caused by cataract, poor dilation, ptosis, external ocular condition, or learning difficulties. There may be artefacts caused by dust, dirt, condensation, or smudge.
Management.
There are three major treatments for diabetic retinopathy, which are very effective in reducing vision loss from this disease. In fact, even people with advanced retinopathy have a 90 percent chance of keeping their vision when they get treatment before the retina is severely damaged. These three treatments are laser surgery, injection of corticosteroids or anti-VEGF agents into the eye, and vitrectomy.
Although these treatments are very successful (in slowing or stopping further vision loss), they do not cure diabetic retinopathy. Caution should be exercised in treatment with laser surgery since it causes a loss of retinal tissue. It is often more prudent to inject triamcinolone or anti-VEGF drugs. In some patients it results in a marked increase of vision, especially if there is an edema of the macula.
Avoiding tobacco use and correction of associated hypertension are important therapeutic measures in the management of diabetic retinopathy.
The best way of addressing diabetic retinopathy is to monitor it vigilantly and achieve euglycemia.
Since 2008 there have been other therapies (e.g. kinase inhibitors and anti-VEGF) drugs available.
Laser photocoagulation.
Laser photocoagulation can be used in two scenarios for the treatment of diabetic retinopathy. It can be used to treat macular edema by creating a Modified Grid at the posterior pole and it can be used for panretinal coagulation for controlling neovascularization. It is widely used for early stages of proliferative retinopathy.
Modified Grid Laser photocoagulation.
A 'C' shaped area around the macula is treated with low intensity small burns. This helps in clearing the macular edema.
Panretinal photocoagulation.
Panretinal photocoagulation, or PRP (also called scatter laser treatment), is used to treat proliferative diabetic retinopathy (PDR). The goal is to create 1,600 - 2,000 burns in the retina with the hope of reducing the retina's oxygen demand, and hence the possibility of ischemia. It is done in multiple sittings.
In treating advanced diabetic retinopathy, the burns are used to destroy the abnormal blood vessels that form in the retina. This has been shown to reduce the risk of severe vision loss for eyes at risk by 50%.
Before using the laser, the ophthalmologist dilates the pupil and applies anaesthetic drops to numb the eye. In some cases, the doctor also may numb the area behind the eye to reduce discomfort. The patient sits facing the laser machine while the doctor holds a special lens on the eye. The physician can use a single spot laser or a pattern scan laser for two dimensional patterns such as squares, rings and arcs. During the procedure, the patient will see flashes of light. These flashes often create an uncomfortable stinging sensation for the patient. After the laser treatment, patients should be advised not to drive for a few hours while the pupils are still dilated. Vision will most likely remain blurry for the rest of the day. Though there should not be much pain in the eye itself, an ice-cream headache like pain may last for hours afterwards.
Patients will lose some of their peripheral vision after this surgery although it may be barely noticeable by the patient. The procedure does however save the center of the patient's sight. Laser surgery may also slightly reduce colour and night vision.
A person with proliferative retinopathy will always be at risk for new bleeding, as well as glaucoma, a complication from the new blood vessels. This means that multiple treatments may be required to protect vision.
Intravitreal triamcinolone acetonide.
Triamcinolone is a long acting steroid preparation. When injected in the vitreous cavity, it decreases the macular edema (thickening of the retina at the macula) caused due to diabetic maculopathy, and results in an increase in visual acuity. The effect of triamcinolone is transient, lasting up to three months, which necessitates repeated injections for maintaining the beneficial effect. Best results of intravitreal Triamcinolone have been found in eyes that have already undergone cataract surgery. Complications of intravitreal injection of triamcinolone include cataract, steroid-induced glaucoma and endophthalmitis.
Intravitreal anti-VEGF drugs.
There are good results from multiple doses of intravitreal injections of anti-VEGF drugs such as bevacizumab. Present recommended treatment for diabetic macular edema is Modified Grid laser photocoagulation combined with multiple injections of anti-VEGF drugs.
Vitrectomy.
Instead of laser surgery, some people require a vitrectomy to restore vision. A vitrectomy is performed when there is a lot of blood in the vitreous. It involves removing the cloudy vitreous and replacing it with a saline solution.
Studies show that people who have a vitrectomy soon after a large hemorrhage are more likely to protect their vision than someone who waits to have the operation. Early vitrectomy is especially effective in people with insulin-dependent diabetes, who may be at greater risk of blindness from a hemorrhage into the eye.
Vitrectomy is often done under local anesthesia. The doctor makes a tiny incision in the sclera, or white of the eye. Next, a small instrument is placed into the eye to remove the vitreous and insert the saline solution into the eye.
Patients may be able to return home soon after the vitrectomy, or may be asked to stay in the hospital overnight. After the operation, the eye will be red and sensitive, and patients usually need to wear an eyepatch for a few days or weeks to protect the eye. Medicated eye drops are also prescribed to protect against infection.
Vitrectomy is frequently combined with other modalities of treatment.
Light Treatment.
Light mask treatment is designed to be worn at night, to deliver a precise dose of light therapy during a patient’s normal hours of sleep. It comes in two parts – a plastic “Pod” part, which is inserted into a soft cushioned Fabric Mask. The Pod contains the light sources which, when worn, emit light into the eyes through closed eyelids. Nothing is inserted into the eyes – the treatment is non-invasive. The mask is programmed to administer the correct dose of light each night as part of a continuing therapy.
The colour of the light has been specifically chosen as the most effective for the treatment of Diabetic Retinopathy. The light may initially appear bright when the mask is first worn, but the eyes adjust within a few minutes as the brain learns to ignore the light, by what is known as the Troxler effect. The light from the mask stops the retina from dark adapting, which is thought to affect Diabetic Retinopathy.
How does it work?
In the human eye an image is projected through the lens to the retina at the back of the eye. There are two sorts of cells in the retina that detect the light (the image) and send a signal to the brain. These cells are called rods and cones. The cones work well during the day when there is a lot of light, but at night time the rods, which are more sensitive to low light levels, take over and dark adapt.
As the rods dark adapt they require more oxygen. In a healthy eye there is just enough oxygen to cope with demand, but in a diabetic person’s eye where circulation is compromised, the retina becomes starved of oxygen, a condition known as hypoxia. The body responds by producing a chemical known as VEGF (Vascular Endothelial Growth Factor) that results in the growth of new blood vessels in the eye to supply extra oxygen. In the diabetic eye these new vessels are weak, which makes the retina thicker. The build-up of fluid is termed Oedema and further reduces the amount of oxygen available, creating a vicious cycle. If the new blood vessels reach the macula (central part of the eye) and there is a build-up of fluid, then a patient’s eyesight, particularly their central vision, is affected. This is known as Macular Oedema.
Light treatment combats this cycle by illuminating the eye overnight through closed eyelids. The colour of the light is specially chosen to be absorbed primarily by the rods without affecting the cones (which would keep people awake), and the brightness is tuned to ensure that the rods do not dark adapt. As the rods do not dark adapt, their oxygen requirements remain at low daytime levels. The effect of this is to slow or stop the production of VEGF, avoid the formation of weak new blood vessels, avoid fluid leakage and oedema and allow the retina to repair itself to the best of its ability.
Research.
C-peptide.
Though not yet commercially available, c-peptide has shown promising results in treatment of diabetic complications incidental to vascular degeneration. Once thought to be a useless byproduct of insulin production, it helps to ameliorate and reverse many symptoms of diabetes.
Stem cell therapy.
Clinical trials are under way or are being populated in preparation for study at medical 
centers in Brazil, Iran and the United States. Current trials involve using the patients 
own stem cells derived from bone marrow and injected into the degenerated areas in an effort 
to regenerate the vascular system.
Blood pressure control.
A Cochrane review examined 15 randomized controlled trials do determine whether interventions that sought to control or reduce blood pressure in diabetics had any effects of diabetic retinopathy. While the results showed that interventions to control or reduce blood pressure had a prevented diabetic retinopathy for up to 4–5 years in diabetics, there was no evidence of any effect of these interventions on progression of diabetic retinopathy, preservation of visual acuity, adverse events, quality of life, and costs.

</doc>
<doc id="56538" url="https://en.wikipedia.org/wiki?curid=56538" title="Rule of thumb">
Rule of thumb

A rule of thumb is a principle with broad application that is not intended to be strictly accurate or reliable for every situation. It is an easily learned and easily applied procedure for approximately calculating or recalling some value, or for making some determination. Compare this to heuristic, a similar concept used in mathematical discourse, psychology, and computer science, particularly in algorithm design.
Origin of the phrase.
The exact origin of the phrase is uncertain. The earliest known citation comes from J. Durham’s "Heaven upon Earth", 1685, ii. 217: "Many profest Christians are like to foolish builders, who build by guess, and by rule of thumb." The phrase also exists in other languages, for example Italian "Regola del pollice", Swedish "tumregel", Norwegian and Danish "tommelfingerregel", sometimes in the variant "rule of fist", for example Finnish "nyrkkisääntö", Estonian "rusikareegel", German "Faustregel" and "Pi mal Daumen", Hungarian "ökölszabály" or Dutch "vuistregel", as well as in Turkish "parmak hesabı", and in Hebrew "כלל אצבע" (rule of finger) and in Persian "قاعده سرانگشتی," which is translated as finger tip's rule. This suggests that it has some antiquity, and does not originate in specifically Germanic language culture.
Thumb as measurement device.
The term is thought to originate with carpenters who used the length of the tip of their thumbs (i.e., inches) rather than rulers for measuring things, cementing its modern use as an imprecise yet reliable and convenient standard. This sense of thumb as a unit of measure also appears in Dutch, in which the word for thumb, "duim", also means inch. The use of a single word or cognate for "inch" and "thumb" is common in many Indo-European languages, for example, inch/thumb; inch/thumb; inch, "pulgar" thumb; inch, "polegar" thumb; inch, "tumme" thumb; inch, "anguli" finger; , inch/thumb, inch/thumb. Also in some other languages such as inch/finger, inch/thumb.
Another possible origin of the phrase comes from measurement, in particular in agricultural fields. The plants need a fairly precise depth to seed properly, whether planted from seed or being replanted, but the depth can sometimes be estimated using the thumb. That is, a "rule (measurement) of thumb". According to Gary Martin, "The origin of the phrase remains unknown. It is likely that it refers to one of the numerous ways that thumbs have been used to estimate things—judging the alignment or distance of an object by holding the thumb in one's eye-line, the temperature of brews of beer, measurement of an inch from the joint to the nail to the tip, or across the thumb, etc. The phrase joins the whole nine yards as one that probably derives from some form of measurement but which is unlikely ever to be definitively pinned down."
Reference to spousal abuse.
It is often claimed that the term's etymological origin lies in a law that limited the maximum thickness of a stick with which it was permissible for a man to beat his wife. English common law before the reign of Charles II permitted a man to give his wife "moderate correction", but no "rule of thumb" (whether called by this name or not) has ever been the law in
England. Such "moderate correction" specifically excluded beatings, allowing the husband only to confine a wife to the household.
Nonetheless, belief in the existence of a "rule of thumb" law to excuse spousal abuse can be traced as far back as 1782, the year that James Gillray published his satirical cartoon "Judge Thumb". The cartoon lambastes Sir Francis Buller, an English judge, for allegedly ruling that a man may legally beat his wife, provided that he used a stick no thicker than his thumb, although there is no other written record of Buller making such a pronouncement. The Massachusetts Body of Liberties adopted in 1641 by the Massachusetts Bay colonists states, “Every married woman shall be free from bodily correction or stripes by her husband, unless it be in his own defense from her assault.” In the United States, legal decisions in Mississippi (1824) and North Carolina (1868 and 1874) make reference to—and reject—an unnamed "old doctrine" or "ancient law" by which a man was allowed to beat his wife with a stick no wider than his thumb.
For example, the 1874 case "State v. Oliver" (North Carolina Reports, Vol. 70, Sec. 60, p. 44) states: "We assume that the old doctrine that a husband had the right to whip his wife, provided that he used a switch no larger than his thumb, is not the law in North Carolina."
In 1976, feminist Del Martin used the phrase "rule of thumb" as a metaphorical reference to describe such a doctrine. She was misinterpreted by many as claiming the doctrine as a direct origin of the phrase and the connection gained currency in 1982, when the U.S. Commission on Civil Rights issued a report on wife abuse, titled "Under the Rule of Thumb".

</doc>
<doc id="56542" url="https://en.wikipedia.org/wiki?curid=56542" title="Hanna-Barbera">
Hanna-Barbera

Hanna-Barbera Productions, Inc. (simply known as Hanna-Barbera and also referred to as H-B Enterprises, H-B Production Company and Hanna-Barbera Cartoons) was an American animation studio that dominated American television animation for 
three decades in the mid-to-late 20th century. It was founded in 1957 by former Metro-Goldwyn-Mayer animation directors William Hanna and Joseph Barbera (creators of "Tom and Jerry") and live-action director George Sidney in partnership with Screen Gems, television arm of Columbia Pictures. Sold to Taft Broadcasting in late 1966, it spent the next two decades as its subsidiary. Hanna-Barbera was not only known for its variety of characters, but for building upon and popularizing the concepts and uses of limited animation. For over 30 years, many successful cartoons were produced, including "The Flintstones", "Yogi Bear", "The Jetsons", "Scooby-Doo" and "The Smurfs". 
In addition to winning seven Academy Awards, Hanna and Barbera won eight Emmy Awards, a Golden Globe Award, a Humanitas Prize and a star on the Hollywood Walk of Fame, among other merits. After its fortunes declined in the mid-eighties when the profitability of Saturday morning cartoons was eclipsed by weekday afternoon syndication, it was purchased from Taft (by then named Great American Broadcasting) in late 1991 by Turner Broadcasting System, who used much of its back catalog to program its new channel, Cartoon Network. After Turner purchased the company, both Hanna and Barbera continued to serve as mentors and creative consultants. Turner merged with Time Warner in 1996 and the studio became a subsidiary of Warner Bros. Animation.
With Hanna's death in 2001, it was absorbed into its parent, and Cartoon Network Studios continued the projects for the channel's output. Barbera continued to work for Warner Bros. Animation until his death in 2006. The studio now exists as an in-name-only company used to market properties and productions associated with the Hanna-Barbera library, specifically its "classic" works. In 2005, the Academy of Television Arts & Sciences honored Hanna and Barbera with a bronze wall sculpture of them and the characters they created.
History.
Melrose, New Mexico native William Hanna and New York City-born Joseph Barbera first met while working at the Metro-Goldwyn-Mayer cartoon studio in 1939. Their first directorial production was the Academy Award-nominated "Puss Gets the Boot" (1940), which served as the basis for the popular "Tom and Jerry" series of short subject theatricals. Hanna and Barbera served as directors and story men of the shorts for over 18 years and Hanna himself provided the screams, yelps and yells for Tom. Seven of the cartoons won the Academy Award for Best Short Subject (Cartoons) between 1943 and 1953, though the trophies were awarded to their producer Fred Quimby, who was not involved in the creative development of the shorts. With Quimby's retirement in 1955, Hanna and Barbera became the producers in charge of the MGM animation studio's output.
Outside of their work on the cartoons, the two men moonlighted on outside projects, including the original title sequences and commercials for the CBS sitcom "I Love Lucy".
Metro-Goldwyn-Mayer decided in early 1957 to close its cartoon studio, as it felt it had acquired a reasonable backlog of shorts for re-release. Hanna and Barbera, contemplating their future while completing the final "Tom and Jerry" and "Droopy" cartoons, began producing animated television commercials. During their last year at MGM, they developed a concept for an animated television program about a dog and cat pair in various misadventures. After they failed to convince to back their venture, live-action director George Sidney, who'd worked with Hanna and Barbera on several of his features, most notably "Anchors Aweigh" in 1945, offered to serve as their business partner and convinced Screen Gems, the television subsidiary of Columbia Pictures, to make a deal with the animation producers. Harry Cohn, head of Columbia Pictures, took an 18% ownership in Hanna and Barbera's new company, "H-B Enterprises", and provided working capital to produce. Screen Gems became the new studio's distributor and its licensing agent, handling merchandizing of the characters from the animated programs.
H-B Enterprises officially opened for business in rented offices on the lot of Kling Studios (formerly Charlie Chaplin Studios) on July 7, 1957, two months after the MGM animation studio closed down. Sidney and several Screen Gems alumni became members of the studio's original board of directors, and much of the former Metro-Goldwyn-Mayer animation staff – including animators Carlo Vinci, Kenneth Muse, Lewis Marshall, Michael Lah, and Ed Barge and layout artists Ed Benedict and Richard Bickenbach – as its production staff. Composer Hoyt Curtin provided the music while many voice artists were on board, such as Daws Butler, Jean Vander Pyl, Paul Winchell, Bea Benaderet, Don Messick, Julie Bennett, Mel Blanc, Penny Singleton, Howard Morris, Janet Waldo, Alan Reed, Lucille Bliss, George O'Hanlon, John Stephenson, Hal Smith, Casey Kasem, Frank Welker, Arnold Stang, Doug Young, Marvin Kaplan, Marty Ingels, Leo De Lyon, Allan Melvin, Tim Matheson, Ted Cassidy and Henry Corden.
Television cartoons: 1957-1969.
Hanna-Barbera was one of the first studios to successfully produce cartoons especially for television. Previously, animated programming on television had consisted primarily of rebroadcasts of theatrical cartoons. Their first animated series for television "The Ruff & Reddy Show", featuring host Jimmy Blaine and several Columbia-owned cartoons as filler, premiered on NBC in December 1957. Next, the studio had its first big hit with "The Huckleberry Hound Show" in 1958, a syndicated series aired in most markets just before primetime. A ratings success, it introduced a new crop of cartoon stars to audiences, in particular Huckleberry Hound and Yogi Bear. The show won an Emmy for Outstanding Achievement in the Field of Children's Programming. Beginning to expand rapidly following the success of the series, several animation industry alumni – in particular former Warner Bros. Cartoons storymen Michael Maltese and Warren Foster, who became Hanna-Barbera's new head writers – joined the staff at this time. By 1959, H-B Enterprises was reincorporated as "Hanna-Barbera Productions", and was slowly becoming a leader in television animation production.
After introducing both, a second syndicated cartoon, "The Quick Draw McGraw Show" and its first and only theatrical series, "Loopy De Loop", in 1959, Hanna-Barbera migrated into network primetime production with the animated ABC sitcom "The Flintstones" in 1960. Loosely based upon the popular live-action Jackie Gleason series "The Honeymooners", yet set in a fictionalized stone age of cavemen and dinosaurs, the show ran for a total of six seasons, becoming a ratings and merchandising success. It was the longest-running animated show in American prime time television history until being beaten out by the FOX mega hit "The Simpsons" in 1996. Hanna-Barbera's first spinoff series "The Yogi Bear Show", first aired syndicated in 1961 and during the early and mid-sixties, the studio produced more new successful prime time and syndicated shows, such as "Top Cat", "The Hanna-Barbera New Cartoon Series" and "The Jetsons". More new animated shows of "The Magilla Gorilla Show", "Jonny Quest", "The Peter Potamus Show", "The Atom Ant/Secret Squirrel Show", "Sinbad Jr. and his Magic Belt" and "Laurel and Hardy" aired.
Several animated television commercials were produced and aired as well, often starring its own characters (notably, the best known ones are the long running series of Fruity and Cocoa Pebbles cereal television ads for Post Foods featuring Barney Rubble going thru a series of schemes and costumes to trick Fred Flintstone in to giving up his Fruity or Cocoa Pebbles cereal to him before its backfires and Fred then gives chase to Barney for taking his Pebbles), and animated the opening credits for the ABC sitcom "Bewitched", in which the animated caricatures of its characters Samantha and Darrin of that show's famous cartoon title would appear as guest stars in a season six episode of "The Flintstones", voiced by both Elizabeth Montgomery and Dick York respectively. Meanwhile, the studio moved off of the Kling lot in 1963 (which by then had been renamed the Red Skelton Studios) into a new location at 3400 Cahuenga Blvd. West in Hollywood, California.
This California contemporary office building was designed by architect Arthur Froehlich. Its ultra-modern design included a sculpted latticework exterior, moat, fountains, and after later additions, a Jetsons-like tower. After the success of "The Atom Ant/Secret Squirrel Show" in 1965, two new Saturday morning series debuted the following year, "Frankenstein, Jr. and The Impossibles", which blended action-adventure with the earlier Hanna-Barbera humor style and "Space Ghost", which featured action-adventure. A number of comedy and action cartoons followed in 1967, among them are "The Space Kidettes", "The Abbott and Costello Cartoon Show", "Birdman and the Galaxy Trio", "The Herculoids", "Shazzan", an adaptation of Marvel Comics' "Fantastic Four", "Moby Dick and Mighty Mightor" and "Samson & Goliath" (also known as "Young Samson").
The Hanna-Barbera and Screen Gems partnership lasted until 1965, when Hanna and Barbera announced the sale of the studio to Taft Broadcasting. Its acquisition of Hanna-Barbera was delayed for a year by a lawsuit from Joan Perry, John Cohn, and Harrison Cohn - the wife and sons of former Columbia Pictures president Harry Cohn - who felt that the cartoon firm had undervalued the Cohns' 18% share in the company when it was sold a few years prior. By December 1966, the litigation had been settled at last and the studio was finally acquired for $12 million by Taft, who would spent 1967 and 1968 folding it into its corporate structure and became its distributor. Both Hanna and Barbera stayed on to run the company. Screen Gems retained licensing and distribution rights to the previous cartoons, as well as the trademarks to the characters from those shows into the seventies and eighties.
In 1968, live-action and animated comedy-action was mixed for its birth of new programs, "The Banana Splits Adventure Hour" and "The New Adventures of Huckleberry Finn", while the successful "Wacky Races", and its spinoffs "The Perils of Penelope Pitstop" and "Dastardly and Muttley in Their Flying Machines", aired on CBS, returned Hanna-Barbera to straight slapstick humor, followed by "Cattanooga Cats" for ABC. Danny Hutton headed the record label Hanna Barbera Records, distributed by Columbia Records. It featured the artists of Louis Prima, Five Americans, Scatman Crothers and the 13th Floor Elevators. Previously, children's records with Yogi Bear and others were released by Colpix Records. Next came in 1969, "Scooby-Doo, Where Are You!", which blended elements of animated comedies, various action shows, "The Many Loves of Dobie Gillis" and "I Love a Mystery". The series centered on four teenagers and a dog solving supernatural mysteries.
The 1970s.
New Saturday morning and prime time cartoons, programs featuring mystery-solving, crime-fighting teenagers with comical pets or mascots and many spinoffs premeried. These series include, "Harlem Globetrotters", "Josie and the Pussycats", "Where's Huddles", "The Pebbles and Bamm-Bamm Show", "Help!... It's the Hair Bear Bunch!", "The Funky Phantom", "The Amazing Chan and the Chan Clan", "Wait Till Your Father Gets Home", "The Flintstone Comedy Hour", "The Roman Holidays", "Sealab 2020", "The New Scooby-Doo Movies", "Josie and the Pussycats in Outer Space", "Speed Buggy", "Butch Cassidy and the Sundance Kids", "Yogi's Gang", "Super Friends", "Goober and the Ghost Chasers", "Inch High, Private Eye", "Jeannie", "The Addams Family", "Hong Kong Phooey", "Devlin", "Partridge Family 2200 A.D." "These Are The Days", "Valley of the Dinosaurs", "Wheelie and the Chopper Bunch", "The Tom and Jerry Show", "The Great Grape Ape Show" and "Captain Caveman and the Teen Angels".
More new shows were "Clue Club", "Jabberjaw", "CB Bears", "The All-New Super Friends Hour", "The All-New Popeye Hour", "Yogi's Space Race", "Challenge of the Super Friends", "The New Fred and Barney Show", "Casper and the Angels", "The New Shmoo", "The Super Globetrotters", "Scooby-Doo and Scrappy-Doo" and "The World's Greatest Super Friends". The majority of American television animation was made by Hanna-Barbera and the only competition came from Filmation, DePatie-Freleng and others that primarily specialize in prime time specials, such as Rankin-Bass, Chuck Jones Enterprises and Lee Mendelson-Bill Meléndez. Filmation lost ground to Hanna-Barbera when "Uncle Croc's Block's" failure led ABC president Fred Silverman to drop Filmation and give H-B the majority of the network's Saturday morning cartoon time. Joe Ruby and Ken Spears left the studio to found Ruby-Spears Enterprises, with Filmways serving as its parent company in 1977.
First foray into live action.
In addition to its animated works, Hanna-Barbera also tried its hand at producing live-action production, though its success in selling such programming was limited by its track record as an animation studio, such as "", "The Hanna-Barbera Happy Hour", "Benji, Zax & the Alien Prince" and "Going Bananas". But perhaps the best known and most notable production out of many of the non-animated projects is the 1977 holiday-drama television film and Emmy-winner "The Gathering", starring Ed Asner and Maureen Stapleton, first aired on ABC. Its live-action department spun off into Solow Production Company, founded by Herbert Franklin Solow, which immediately following the name change, was able to sell the action adventure series "Man from Atlantis" to NBC.
Production process changes.
Hanna-Barbera produced prime-time, weekday afternoon, and Saturday morning cartoons for all three major networks and syndication in the United States from 1957 to 1995. The small budgets that television animation producers had to work within prevented them, and most other producers of American television animation, from working with the full theatrical-quality animation the duo had been known for at MGM. While the budget for a seven-minute "Tom and Jerry" short was about $35,000, Hanna-Barbera was required to produce five-minute "Ruff and Reddy" episodes for no more than $3,000 a piece. To keep within these tighter budgets, Hanna-Barbera modified the concept of limited animation (also called semi-animation) practiced and popularized by the United Productions of America (UPA) studio, which also once had a partnership with Columbia Pictures. Character designs were simplified, and backgrounds and animation cycles (walks, runs, etc.) were regularly re-purposed.
Characters were often broken up into a handful of levels, so that only the parts of the body that needed to be moved at a given time (i.e. a mouth, an arm, a head) would be animated. The rest of the figure would remain on a held animation cel. This allowed a typical 10-minute short to be done with only 1,200 drawings instead of the usual 26,000. Dialogue, music, and sound effects were emphasized over action, leading Chuck Jones—a contemporary who worked for Hanna and Barbera's rivals at Warner Bros. Cartoons when the duo was at MGM, and one who, with his short "The Dover Boys" practically invented many of the concepts in limited animation—to disparagingly refer to the limited television cartoons produced by Hanna-Barbera and others as "illustrated radio". In a story published by "The Saturday Evening Post" in 1961, critics stated that Hanna-Barbera was taking on more work than it could handle and was resorting to shortcuts only a television audience would tolerate. An executive who worked for Walt Disney Productions said, "We don't even consider competition".
Ironically, during the late 1950s and early 1960s, Hanna-Barbera was the only animation studio in Hollywood that was actively hiring, and it picked up a number of Disney artists who were laid off during this period. The studio's solution to the criticism over its quality was to go into features. The studio produced six theatrical features, among them higher-quality versions of its hit television cartoons and adaptations of other material. Hanna-Barbera was also the first animation studio to have their animation work produced overseas. One of these production companies was a subsidiary started by Hanna-Barbera called Fil-Cartoons in the Philippines. Wang Film Productions got its start as an overseas animation facility for Hanna-Barbera in 1978.
Rise and fall: 1981-1991.
Competing animation studios, such as Sunbow Entertainment, Marvel Productions, Filmation, and Rankin/Bass introduced successful syndicated cartoons based upon characters from popular toy lines and action figures. Hanna-Barbera still continued to produce for Saturday mornings but no longer dominated the television animation market. In 1979, Taft bought Worldvision Enterprises, which then throughout the eighties, became the syndication distributor for most of Hanna and Barbera's cartoons, then in 1981, the parent purchased Ruby-Spears from Filmways, in which that studio often would pair its own shows with the Hanna-Barbera programs. During the mid eighties, the studio switched from traditional cel animation to digital ink and paint for some of their shows. At the time, both Hanna-Barbera and Worldvision had their own home video labels (Hanna-Barbera Home Video and Worldvision Home Video) while many of the shows were released by other VHS distributors.
1980 saw the series debuts of "Super Friends", "The Flintstone Comedy Show", "The Fonz and the Happy Days Gang" and "Richie Rich". Brand new programs emerged in 1981, such as "Laverne and Shirley", "Space Stars", "The Kwicky Koala Show" and "Trollkins". Hanna-Barbera's most popular hit show "The Smurfs", based on the comics and stories by Belgian cartoonist and creator Pierre Culliford (known as Peyo) and centering on the society of little blue forest creatures led by Papa Smurf, aired for nine seasons, becoming a ratings success and the top-rated program in eight years. It was the longest-running Saturday-morning cartoon series and the highest for an NBC program since 1970. Fresh animated shows of "Pac-Man", "The Little Rascals", "The Scooby & Scrappy-Doo/Puppy Hour", "Jokebook", "Shirt Tales" and "The Gary Coleman Show" first aired in 1982 while "The Dukes", "Monchhichis", "The New Scooby and Scrappy-Doo Show", and "The Biskitts" came next in 1983.
For 1984, "The New Scooby-Doo Mysteries", "Snorks", "Challenge of the GoBots", "Pink Panther & Sons", and ' made their network and syndicated airings. In 1985, ', "The 13 Ghosts of Scooby-Doo", and the program block "The Funtastic World of Hanna-Barbera", which introduced "Yogi's Treasure Hunt", "Paw Paws", and "Galtar and the Golden Lance" premiered. "", a series exclusively for direct-to-video, about three adventurers traveling in time to biblical events in the past. New cartoons of "Jonny Quest", "Pound Puppies", "The Flintstone Kids", "Foofur" and "Wildfire" all aired in 1986. "Sky Commanders", "Popeye and Son", "A Pup Named Scooby-Doo", "The Completely Mental Misadventures of Ed Grimley", "The New Yogi Bear Show", and "Fantastic Max" were introduced in 1987 and 1988. "The Further Adventures of SuperTed" and "Paddington Bear" debuted in 1989.
Hanna-Barbera was affected by the financial troubles of Taft, which had just been acquired by the American Financial Corporation in 1987 and renamed to "Great American Broadcasting" the following year. Many of the deals were overseen by Charles Mechem. With the rest of the American cartoon industry, it moved away from producing in-house in the seventies and eighties. Its product was outsourced to studios in Australia and Asia, including Wang Film Productions, Cuckoo's Nest Studios, Mr. Big Cartoons, Mook Co., Ltd., Toei Animation and Fil-Cartoons. Its staff responded to a call from Warner Bros. to resurrect its animation department. Tom Ruegger and his colleagues left to develop new programs there. David Kirschner was appointed as new CEO, with Hanna and Barbera remaining as co-chairmen. Less than successful and burdened with debt, Great American put Hanna-Barbera, along with Ruby-Spears, up for sale in 1990.
Turner rebound: 1991-1992.
In November 1991, the Hanna-Barbera studio and library, as well as much of the Ruby-Spears library, were acquired by a 50-50 joint venture between Turner Broadcasting—which by that time had also bought the pre-May 1986 Metro-Goldwyn-Mayer library—and Apollo Investment Fund for $320 million. This was with the intention of launching an all animation based network aimed at children and younger audiences. Turner's president of entertainment Scott Sassa hired Fred Seibert, a former executive for MTV Networks, to head Hanna-Barbera. He immediately filled the gap left by the departure of most of their creative crew during the Great American years with new animators, writers, directors and producers, including Pat Ventura, Craig McCracken, Donovan Cook, Genndy Tartakovsky, David Feiss, Seth MacFarlane, Van Partible, Stewart St. John, and Butch Hartman with new production head Buzz Potamkin.
The studio was renamed "H-B Productions Company" in 1992, changing its name once again to "Hanna-Barbera Cartoons, Inc." a year later, the same year that Turner acquired the remaining interests of Hanna-Barbera from Apollo Investment Fund for $255 million. "Bill and Ted's Excellent Adventures" made its debut on CBS following "The Adventures of Don Coyote and Sancho Panda", "Tom and Jerry Kids", "Wake, Rattle, and Roll" (known as "Jump, Rattle, and Roll"), "Rick Moranis in Gravedale High" and ' in 1990. Next came "The Pirates of Dark Water" then "Yo Yogi!", "Young Robin Hood", "Fish Police", "Capitol Critters" and a second "Addams Family" series in 1991 and 1992. New shows of ', "The New Adventures of Captain Planet", "" and "2 Stupid Dogs" made their premieres in 1993, then "Dumb and Dumber" in 1995.
Partnership with Cartoon Network and dissolution: 1992-2001.
In 1992, Turner launched Cartoon Network to broadcast its huge library of animated classics, of which Hanna-Barbera was the core contributor. As a result, several cartoons, especially the Hanna-Barbera ones, were rebroadcast. In 1994, Turner Broadcasting refocused the studio to produce new shows exclusively for the Turner-owned networks and then in 1995, the studio produced "What a Cartoon!" (also known as "World Premiere Toons"), an animation showcase series led by Fred Seibert, founder of Frederator Studios, featuring new creator driven cartoon shorts developed by its in-house staff. Several original series emerged from the project, giving the company their first smash hits since "The Smurfs" and the first show based on a "What a Cartoon" short was Genndy Tartakovsky's "Dexter's Laboratory". This spawned a multitude of new programs for the network known as "Cartoon Cartoons" while in 1996, regular new Hanna-Barbera shows "Cave Kids" and "The Real Adventures of Jonny Quest" premiered on Cartoon Network. In the early 2000s, "" featuring "Tom and Jerry" first aired.
Following the Turner and Time Warner merger, Hanna-Barbera was absorbed into Warner Bros. Animation in 2001 and the Hanna-Barbera name began to disappear from newer shows by the studio in favor of the Cartoon Network Studios label. This came in handy with shows that were produced outside the company, but Cartoon Network had a hand in producing as well as shows the studio continued to produce. Hanna died of throat cancer on March 22, 2001, ending the decades-long partnership of 60 years in animation with Barbera, who would since then, move on to work for Warner Bros. Animation on new television shows of "What's New, Scooby-Doo?", "Shaggy & Scooby-Doo Get a Clue!" and "Tom and Jerry Tales" until his passing on December 18, 2006. As of 2016, Hanna-Barbera Productions is an in-name-only unit of Warner Bros. Animation, which administers the rights to its catalog and characters.
Shared cinematic universe: 2018.
Warner Bros. announced plans for a shared universe of traditional-animated films based on various Hanna-Barbera characters, starting with "S.C.O.O.B.", a reboot of the "Scooby-Doo" film series, scheduled for September 21, 2018 in the United States.
Sound effects.
Besides its world famous cartoon shows and characters, Hanna-Barbera was also noted for their large library of sound effects. Besides cartoon-style sound effects (such as ricochets, slide whistles and more), they also had familiar sounds used for transportation, household items, the elements, and more. When Hanna and Barbera started their studio in 1957, they created a handful of sound effects, and had limited choices. They also took some sounds from the then-defunct Metro-Goldwyn Mayer animation studio and by 1958, they began to expand and began adding more sound effects to their library. Besides creating a lot of their own effects, they also collected sound effects from other movie and cartoon studios, such as Universal Pictures, Warner Bros. Animation, and even Disney. Some of their famous sound effects included a rapid bongo drum take used for when a character's feet were scrambling before taking off, a "KaBONG" sound produced on a guitar for when Quick Draw McGraw, in his Zorro-style "El Kabong" crime fighting guise, would smash a guitar over a villain's head, the sound of a car's brake drum combined with a bulb horn for when Fred Flintstone would drop his bowling ball onto his foot, an automobile's tires squealing with a "skipping" effect added for when someone would slide to a sudden stop, a bass-drum-and-cymbal combination called the "Boom Crash" for when someone would fall down or smack into an object, a xylophone being struck rapidly on the same note for a tip-toeing effect, and a violin being plucked with the tuning pegs being raised to simulate something like pulling out a cat's whisker.
The cartoons also used Castle Thunder, a thunderclap sound effect that was commonly used in movies and television shows from the 1940s to the 1980s. Other common sounds such as Peeong (a frying pan hitting sound with a doppler effect) and Bilp were used regularly in all of its cartoons. Starting in the 1960s, other cartoon studios began using the sound effects, including Nickelodeon Animation Studio, Universal Animation Studios, Disney Television Animation, Film Roman, MGM Animation, Cartoon Network Studios, DiC Entertainment, Hasbro Studios, Warner Bros. Animation and many others. By the 21st century, almost every animation studio was using the sound effects. Like Hanna-Barbera was in the 90s, they are used sparingly, while some cartoons and non-animated series like Warner Bros. Animation's "Krypto the Superdog", Nelvana's "The Magic School Bus", A&E's "Parking Wars", Disney's "Bonkers" and Spümcø's "Ren & Stimpy "Adult Party Cartoon"" make heavy use of the classic sound effects, mostly for a retro feel. Some Hanna-Barbera sounds show up in various sound libraries such as Valentino and Audio Network. Hanna-Barbera Records (the studio's short-lived record division) released a set of LP records in the late 1960s entitled Hanna-Barbera's Drop-Ins, which contained quite a few of the classic sound effects.
This LP set was only available for radio and television stations and other production studios. In 1973, and again in 1986, Hanna-Barbera released a second sound effect record set; a seven-LP set entitled The Hanna-Barbera Library of Sounds, which, like the previous set, contained several of the classic sound effects. Like the previous set, this was only available to production companies and radio/TV stations. The 1986 version was also available as a two compact-disc set. In 1993, the last president of the studio, Fred Seibert recalled his early production experiences with early LP releases of the studio's effects, and commissioned Sound Ideas to release a four-CD set entitled The Hanna-Barbera Sound FX Library, featuring nearly all of the original H-B sound effects used from 1957 to 1992, a more vast collection compared to the early LP releases (including the sounds H-B had borrowed from other studios).
The sound effects were digitally remastered, so they would sound better on new digital soundtracks. A fifth CD was added in 1996, entitled Hanna-Barbera Lost Treasures, and featured more sound effects, including sounds from Space Ghost and The Impossibles. Also in 1994, Rhino Records released a CD containing some of Hanna-Barbera's famous sound effects, titled simply as Hanna-Barbera Cartoon Sound FX, and also included some answering-machine messages and birthday greetings and short stories starring classic Hanna-Barbera characters, and was hosted by Fred Flintstone. In 1996, it was reissued with the Hanna-Barbera's Pic-A-Nic Basket of Cartoon Classics CD set, which also contained three other CDs of Hanna-Barbera TV theme songs and background music and songs from The Flintstones. Here, the CD was relabeled as The Greatest Cartoon Sound Effects Ever. In the 1980s, Hanna-Barbera slowly began to cease using their trademark sound effects. This was especially true with the action cartoons of the time such as "Sky Commanders". By the 1990s, with cartoons shows, such as "Fish Police" and "", the sound effects were virtually nonexistent, being replaced with newer, digitally recorded sounds (mostly from Sound Ideas), as well as the Looney Tunes sound library by Treg Brown.
A few early 1990s cartoons continued to use the sound effects, such as "Tom & Jerry Kids" and "The Addams Family". By 1996, each television series from the studio typically had its own set of sound effects, including some selected from the classic Hanna-Barbera sound library, as well as some new ones and various sounds from Disney and Warner Bros. cartoons (this was especially true of "Dexter's Laboratory" and "Cow and Chicken"). Several of the classic Hanna-Barbera sound effects still pop up from time to time in many of Cartoon Network Studios' productions. However, on the recent Warner Bros. produced "Scooby-Doo" shows ("What's New, Scooby-Doo?", "Shaggy & Scooby-Doo Get a Clue!", "Scooby-Doo! Mystery Incorporated", "Be Cool, Scooby-Doo!"), the Hanna-Barbera sound effects are very rarely used.
References.
Notes
Bibliography

</doc>
<doc id="56549" url="https://en.wikipedia.org/wiki?curid=56549" title="Beta cell">
Beta cell

Beta cells (β cells) are a type of cell found in the pancreatic islets of the pancreas. They make up 65-80% of the cells in the islets.
Function.
The primary function of a beta cell is to store and release insulin. Insulin is a hormone that brings about effects which reduce blood glucose concentration. Beta cells can respond quickly to spikes in blood glucose concentrations by secreting some of their stored insulin while simultaneously producing more.
Control of insulin secretion.
Voltage-gated calcium channels and ATP-sensitive potassium ion channels are embedded in the cell surface membrane of beta cells. These ATP-sensitive potassium ion channels are normally open and the calcium ion channels are normally closed. Potassium ions diffuse out of the cell, down their concentration gradient, making the inside of the cell more negative with respect to the outside (as potassium ions carry a positive charge). At rest, this creates a potential difference across the cell surface membrane of -70mV.
When the glucose concentration outside the cell is high, glucose molecules move into the cell by facilitated diffusion, down its concentration gradient through the GLUT2 transporter. Since beta cells use glucokinase to catalyze the first step of glycolysis, metabolism only occurs around physiological blood glucose levels and above. Metabolism of the glucose produces ATP, which increases the ATP to ADP ratio.
The ATP-sensitive potassium ion channels close when this ratio rises. This means that potassium ions can no longer diffuse out of the cell. As a result, the potential difference across the membrane becomes more positive (as potassium ions accumulate inside the cell). This change in potential difference opens the voltage-gated calcium channels, which allows calcium ions from outside the cell to diffuse in down their concentration gradient. When the calcium ions enter the cell, they cause vesicles containing insulin to move to, and fuse with, the cell surface membrane, releasing insulin by exocytosis.
Pathology.
Diabetes mellitus can be experimentally induced for research purposes by streptozotocin or alloxan, which are specifically toxic to beta cells.
Artificial Engineering Applications.
There is much research being conducted that attempts to artificially reconfigure beta cells in order to use them in clinical applications:
Type 1 Diabetes.
Type 1 Diabetes is caused by a auto-immune mediated destruction of the insulin producing beta cells in the body. The destruction of these cells reduces the body’s ability to respond to glucose levels in the body, therefore making it nearly impossible to properly regulate glucose and glucagon levels in the bloodstream. This can cause the patient to experience hypoglycemia, which leads to other adverse short-term and long-term conditions. 
While it has been shown that the symptoms of diabetes can be successfully controlled, with methods such as regular doses of insulin and sustaining a proper diet. These methods, however, can be tedious and cumbersome to continuously perform on a daily basis. Since Type 1 diabetes is caused by damage sustained to the beta cells, the most effective solution would be to investigate solutions to repair damaged beta cells or artificially develop and regenerate beta cells in vivo or in the body. 
Research has shown the beta-cells can be differentiated from human pancreas progenitor cells. These differentiated beta cell, however, often lack much of the structure and markers that beta cells need to perform their necessary functions. Examples of the anomalies that arise from beta cells differentiated from progenitor cells include a failure to react to environments with high glucose concentrations, an inability to produce necessary beta cell markers, and abnormally express glucagon along with insulin. 
In order to successfully re-create functional insulin producing beta cell, studies have shown that manipulating cell-signal pathways in early stem cell development will lead to those stem cells differentiating into viable beta cells. Two key signal pathways have been shown to play a vital role in the differentiation of stem cells into beta cells: the BMP4 pathway and the kinase C. Targeted manipulation of these two pathways has shown that it is possible to induce beta cell differentiation from stem cell. These variations of artificial beta cells have shown greater levels of success in replicating the functionality of natural beta cells, although the replication has not been perfectly re-created yet. 
Many studies have shown that it is possible to regenerate beta cells in vivo in some animal models. Research in mice studies have shown that beta cells can often regenerate to the original quantity number after the beta cells have undergone some sort of stress test, such as the intentional destruction of the beta cells in the mice subject or once the auto-immune response has concluded. While these studies have conclusive results in mice, beta cells in human subjects may not possess this same level of versatility. Investigation of beta cells following acute onset of Type 1 diabetes has shown little to none proliferation of newly synthesized beta cells, which suggests that the results seen in the mice models would not occur in human subjects either. 
It appears that the much work has to be done in the field of regenerating beta cells. Just as the discovery of creating insulin through the use of recombinant DNA, the ability to artificially create stem cells that would differentiate into beta cells would prove to be an invaluable resource to patients suffering from Type 1 diabetics. An unlimited amount of beta cells produced artificially would provide therapy to many of the patients who are affected by Type 1 diabetes.

</doc>
<doc id="56551" url="https://en.wikipedia.org/wiki?curid=56551" title="Vocational education">
Vocational education

Vocational education is education that prepares people to work in a trade, in a craft, as a technician, or in support roles in professions such as engineering, accountancy, nursing, medicine, architecture, or law. Craft vocations are usually based on manual or practical activities and are traditionally non-academic but related to a specific trade or occupation. Vocational education is sometimes referred to as "career education" or "technical education". 
Vocational education can take place at the secondary, post-secondary, further education, and higher education level; and can interact with the apprenticeship system. At the post-secondary level, vocational education is often provided by a highly specialized institute of technology/polytechnic, or by a university, or by a local community college.
Vocational education internationally.
Australia.
In Australia vocational education and training is mostly post-secondary and provided through the vocational education and training (VET) system by registered training organisations. However some senior schools do offer school-based apprenticeships and traineeships for students in years 10, 11 and 12. There were 24 Technical Colleges in Australia but now only 4 independent Trade Colleges remain with two in Queensland; one in Brisbane (Australian Trade College) and one on the Gold Coast (Australian Industry Trade College) and one in Adelaide and Perth. This system encompasses both public, TAFE, and private providers in a national training framework consisting of the Australian Quality Training Framework, Australian Qualifications Framework and Industry Training Packages which define the assessment standards for the different vocational qualifications.
Australia’s apprenticeship system includes both traditional apprenticeships in traditional trades and "traineeships" in other more service-oriented occupations. Both involve a legal contract between the employer and the apprentice and provide a combination of school-based and workplace training. Apprenticeships typically last three to four years, traineeships only one to two years. Apprentices and trainees receive a wage which increases as they progress.
Since the states and territories are responsible for most public delivery and all regulation of providers, a central concept of the system is "national recognition" whereby the assessments and awards of any one registered training organisation must be recognised by all others and the decisions of any state or territory training authority must be recognised by the other states and territories. This allows national portability of qualifications and units of competency.
A crucial feature of the training package (which accounts for about 60% of publicly funded training and almost all apprenticeship training) is that the content of the vocational qualifications is theoretically defined by industry and not by government or training providers. A Training Package is "owned" by one of 11 Industry Skills Councils which are responsible for developing and reviewing the qualifications.
The National Centre for Vocational Education Research or NCVER is a not-for-profit company owned by the federal, state and territory ministers responsible for training. It is responsible for collecting, managing, analysing, evaluating and communicating research and statistics about vocational education and training (VET).
The boundaries between Vocational education and tertiary education are becoming more blurred. A number of vocational training providers such as Melbourne Polytechnic, BHI and WAI are now offering specialised bachelor's degrees in specific areas not being adequately provided by Universities. Such Applied Courses include in the areas of Equine studies, Winemaking and viticulture, aquaculture, Information Technology, Music, Illustration, Culinary Management and many more.
Vocational education in Australia is sometimes mistaken for skills assessment or recognised prior learning (RPL). It is not uncommon for universities to offer RPL for some of their vocational education, however it is now the same. Get Qualified Australia have been offering RPL for several years now, however they do not offer vocational education.
Commonwealth of Independent States.
The largest and the most unified system of vocational education was created in the Soviet Union with the Professional`no-tehnicheskoye uchilische and Tehnikum. But it became less effective with the transition of the economies of post-Soviet countries to a market economy.
European Union.
Education and training is the responsibility of Member States, but the single European labour market makes some cooperation on education imperative, including on vocational education and training. The 'Copenhagen process', based on the open method of cooperation between Member States, was launched in 2002 in order to help make vocational education and training better and more attractive to learners throughout Europe. The process is based on mutually agreed priorities that are reviewed periodically. Much of the activity is monitored by Cedefop, the European Centre for the Development of Vocational Training.
Finland.
In Finland, vocational education belongs to secondary education. After the nine-year comprehensive school, almost all students choose to go to either a "lukio" (high school), which is an institution preparing students for tertiary education, or to a vocational school. Both forms of secondary education last three years, and give a formal qualification to enter university or "ammattikorkeakoulu", i.e. Finnish polytechnics. In certain fields (e.g. the police school, air traffic control personnel training), the entrance requirements of vocational schools include completion of the "lukio", thus causing the students to complete their secondary education twice.
The education in vocational school is free, and the students from low-income families are eligible for a state student grant. The curriculum is primarily vocational, and the academic part of the curriculum is adapted to the needs of a given course. The vocational schools are mostly maintained by municipalities.
After completing secondary education, one can enter higher vocational schools ("ammattikorkeakoulu", or "AMK") or universities.
It is also possible for a student to choose both lukio and vocational schooling. The education in such cases last usually from 3 to 4 years.
German-language areas.
Vocational education is an important part of the education systems in Austria, Germany, Liechtenstein and Switzerland (including the French and the Italian speaking parts of the country) and one element of the German model.
For example, in Germany a law (the "Berufsausbildungsgesetz") was passed in 1969 which regulated and unified the vocational training system and codified the shared responsibility of the state, the unions, associations and chambers of trade and industry. The system is very popular in modern Germany: in 2001, two thirds of young people aged under 22 began an apprenticeship, and 78% of them completed it, meaning that approximately 51% of all young people under 22 have completed an apprenticeship. One in three companies offered apprenticeships in 2003; in 2004 the government signed a pledge with industrial unions that all companies except very small ones must take on apprentices.
The vocational education systems in the other German speaking countries are very similar to the German system and a vocational qualification from one country is generally also recognized in the other states within this area.
Hong Kong.
In Hong Kong, vocational education is usually for post-secondary 6 students. The Hong Kong Institute of Vocational Education (IVE) provides training in nine different vocational fields, namely: Applied Science; Business Administration; Child Education and Community Services; Construction; Design; Printing, Textiles and Clothing; Hotel, Service and Tourism Studies; Information Technology; Electrical and Electronic Engineering; and Mechanical, Manufacturing and Industrial Engineering.
Hungary.
Normally at the end of elementary school (at age 14) students are directed to one of three types of upper secondary education: one academic track (gymnasium) and two vocational tracks. Vocational secondary schools (szakközépiskola) provide four years of general education and also prepare students for the maturata. These schools combine general education with some specific subjects, referred to as pre-vocational education and career orientation. At that point many students enrol in a post-secondary VET programme often at the same institution, to obtain a vocational qualification, although they may also seek entry to tertiary education.
Vocational training schools (szakiskola) initially provide two years of general education, combined with some pre-vocational education and career orientation, they then choose an occupation, and then receive two or three years of vocational education and training focusing on that occupation – such as bricklayer. Students do not obtain the maturata but a vocational qualification at the end of a successfully completed programme. Demand for vocational training schools, both from the labour market and among students, has declined while it has increased for upper secondary schools delivering the maturata.
India.
Vocational training in India is provided on a full-time as well as part-time basis. Full-time programs are generally offered through I.T.I.s Industrial training institutes. The nodal agency for granting the recognition to the I.T.I.s is NCVT, which is under the Min. of labour, Govt. of India.
In December 2011, under the aegis of UGC and AICTE, Tata Institute of Social Sciences (TISS) set up the School of Vocational Education (SVE) to provide immediate and defined intervention to improve the skill levels of millions of youth, through appropriate Vocational Training Programs. TISS- SVE has now rolled out the three years Bachelor Of Vocational Education program newly introduced by the University Grant Commission (UGC). This is a Work Integrated Training Program (WITP) which enable students to learn the skills by engaging in on-the-job training at company / industry along with classroom theoretical training. TISS SVE offers courses beginning with 'Diploma' and leading to 'Bachelor of Vocational Degree' (B.Voc). Currently B.Voc is being offered in 20 vocations across different sectors & industries e.g. Healthcare, Hospitality, Travel & Tourism, BFSI, HR & Sales, Dialysis Technology etc.
Part-time programs are offered through state technical education boards or universities who also offer full-time courses. Vocational training has been successful in India only in industrial training institutes and that too in engineering trades. There are many private institutes in India which offer courses in vocational training and finishing, but most of them have not been recognized by the Government. India is a pioneer in vocational training in Film & Television, and Information Technology.AAFT, Audio Production & Recording ILM Academy. Maharashtra State Government also offers vocational Diplomas in various Trades .
Vocational Higher Secondary schools are under MHRD in India. All the state governments runs vocational schools. In Kerala, 389 vocational schools are there with 42 different courses. Commerce & Business, Tourism, Agriculture, Automobile, Air conditioning, Live stock management, Lab Technician are some prominent courses. The students get reservation and preference in PSC appointments
Japan.
Japanese vocational schools are known as . They are part of Japan's higher education system. They are two-year schools that many students study at after finishing high school (although it is not always required that students graduate from high school). Some have a wide range of majors, others only a few majors. Some examples are computer technology, fashion, and English.
South Korea.
Vocational high schools offer programmes in five fields: agriculture, technology/engineering, commerce/business, maritime/fishery, and home economics. In principle, all students in the first year of high school (10th grade) follow a common national curriculum, In the second and third years (11th and 12th grades) students are offered courses relevant to their specialisation. In some programmes, students may participate in workplace training through co-operation between schools and local employers. The government is now piloting Vocational Meister Schools in which workplace training is an important part of the programme. Around half of all vocational high schools are private. Private and public schools operate according to similar rules; for example, they charge the same fees for high school education, with an exemption for poorer families.
The number of students in vocational high schools has decreased, from about half of students in 1995 down to about one-quarter today. To make vocational high schools more attractive, in April 2007 the Korean government changed the name of vocational high schools into professional high schools. With the change of the name the government also facilitated the entry of vocational high school graduates to colleges and universities.
Most vocational high school students continue into tertiary education; in 2007 43% transferred to junior colleges and 25% to university. At tertiary level, vocational education and training is provided in junior colleges (two- and three-year programmes) and at polytechnic colleges. Education at junior colleges and in two-year programmes in polytechnic colleges leads to an Industrial associate degree. Polytechnics also provide one-year programmes for craftsmen and master craftsmen and short programmes for employed workers. The requirements for admission to these institutions are in principle the same as those in the rest of tertiary sector (on the basis of the College Scholastic Aptitude Test) but candidates with vocational qualifications are given priority in the admission process. Junior colleges have expanded rapidly in response to demand and in 2006 enrolled around 27% of all tertiary students.
95% of junior college students are in private institutions. Fees charged by private colleges are approximately twice those of public institutions. Polytechnic colleges are state-run institutions under the responsibility of the Ministry of Labour; government funding keeps student fees much lower than those charged by other tertiary institutions. Around 5% of students are enrolled in polytechnic colleges.
Malaysia.
Skills training are no longer depicted as second-class education in Malaysia. There are numerous vocational education centres here including vocational schools (high schools to train skilled students), technic schools (high schools to train future engineers) and vocational colleges all of them under the Ministry of Education. Then there are 33 polytechnics and 86 community colleges under the Ministry of Higher Education; 10 MARA Advanced Skills Colleges, 13 MARA Skills Institutes, 286 GIATMARAs under Majlis Amanah Rakyat (MARA) and 15 National Youth Skills Institutes under Ministry of Youth and Sports. The first vocational institute in Malaysia is the Industrial Training Institute of Kuala Lumpur established in 1964 under the Manpower Department. Other institutes under the same department including 8 Advanced Technology Training Centres, one Centre for Instructor and Advanced Skill Training, one Japan-Malaysia Technical Institute and the other 21 ITIs.
Mexico.
In Mexico, both federal and state governments are responsible for the administration of vocational education. Federal schools are funded by the federal budget, in addition to their own funding sources. The state governments are responsible for the management of decentralised institutions, such as the State Centres for Scientific and Technological Studies (CECyTE) and Institutes of Training for Work (ICAT). These institutions are funded 50% from the federal budget and 50% from the state budget. The state governments also manage and fund "decentralised institutions of the federation", such as CONALEP schools. These educational centers work with classes of occupations like of workers, of welder, of electrical, of automotive mechanic, of dressmakers, of typewriter use classes, etc. with the same schedule of real secondaries and with special books oriented to low-class people and with supercutted content of real secondary schools. Name of this establishements always is "Secundaria Técnica Industrial" and a name or a simply number in case of secondary school level and "Colegio de Bachilleres" ("COBA"), "Centro de Bachillerato Tecnológico Industrial y de Servicios" ("Cbtis") and "CONALEP" in case of preparatory school level, and a simply number (except "CONALEP", in this case, there is only one by city or settlement and are not put any name more than "CONALEP"), and always are abandoned by the SEP by giving lower priority against real schools, being in very precarious conditions well. There are certain public and in rare cases very low-budget private universities which that preparatories are just vocational, the most famous example is the National Polytechnic Institute. Some private schools of very low budget are also vocationals of secondary or preparatory level. In 2004 there were rumors within the government in Mexico that this classification of schools finally going to disappear, but finally did not happen.
Compulsory education (including primary and lower secondary education) finishes at the age of 15 and about half of those aged 15-to-19 are enrolled full-time or part-time in education. All programmes at upper secondary level require the payment of a tuition fee.
The upper secondary vocational education system in Mexico includes over a dozen subsystems (administrative units within the Upper Secondary Education Undersecretariat of the Ministry of Public Education, responsible for vocational programmes) which differ from each other to varying degrees in content, administration, and target group. The large number of school types and corresponding administrative units within the Ministry of Public Education makes the institutional landscape of vocational education and training complex by international standards.
Vocational education and training provided under the Upper Secondary Education Under secretariat includes three main types of programme:
The Netherlands.
Nearly all of those leaving lower secondary school enter upper secondary education, and around 50% of them follow one of four vocational programmes; technology, economics, agricultural, personal/social services & health care. These programmes vary from 1 to 4 years (by level; only level 2, 3 and 4 diplomas are considered formal ‘start qualifications’ for successfully entering the labour market). The programmes can be attended in either of two pathways. One either involving a minimum of 20% of school time (apprenticeship pathway; BBL-BeroepsBegeleidende Leerweg) or the other, involving a maximum of 80% schooltime (BOL -BeroepsOpleidende Leerweg). The remaining time in both cases is apprenticeship/work in a company. So in effect, students have a choice out of 32 trajectories, leading to over 600 professional qualifications.
BBL-Apprentices usually receive a wage negotiated in collective agreements. Employers taking on these apprentices receive a subsidy in the form of a tax reduction on the wages of the apprentice. (WVA-Wet vermindering afdracht).
Level 4 graduates of senior secondary VET may go directly to institutes for Higher Profession Education and Training (HBO-Hoger beroepsonderwijs), after which entering university is a possibility.
The social partners participate actively in the development of policy. As of January 1, 2012 they formed a foundation for Co operation Vocational Education and Entrepreneurship (St. SBB – stichting Samenwerking Beroepsonderwijs Bedrijfsleven; www.s-bb.nl). Its responsibility is to advise the Minister on the development of the national vocational education and training system, based on the full consensus of the constituent members (the representative organisations of schools and of entrepreneurship and their centres of expertise). Special topics are Qualification & Examination, Apprenticeships (BPV-Beroepspraktijkvorming) and (labourmarket) Efficiency of VET.
The Centres of Expertices are linked to the four vocational education programmes provided in senior secondary VET on the content of VET programmes and on trends and future skill needs.
The Local County Vocational Training (MBO Raad www.mboraad.nl) represents the VET schools in this foundation and advise on the quality, operations and provision of VET.
New Zealand.
New Zealand is served by 11 Industry Training Organisations (ITO). The unique element is that ITOs purchase training as well as set standards and aggregate industry opinion about skills in the labour market. Industry Training, as organised by ITOs, has expanded from apprenticeships to a more true lifelong learning situation with, for example, over 10% of trainees aged 50 or over. Moreover, much of the training is generic. This challenges the prevailing idea of vocational education and the standard layperson view that it focuses on apprenticeships.
One source for information in New Zealand is the Industry Training Federation. Another is the Ministry of Education.
Polytechnics, Private Training Establishments, Wananga and others also deliver vocational training, amongst other areas.
Norway.
Nearly all those leaving lower secondary school enter upper secondary education, and around half follow one of nine vocational programmes. These programmes typically involve two years in school followed by two years of apprenticeship in a company. The first year provides general education alongside introductory knowledge of the vocational area. During the second year, courses become more trade-specific.
Apprentices receive a wage negotiated in collective agreements ranging between 30% and 80% of the wage of a qualified worker; the percentage increasing over the apprenticeship period. Employers taking on apprentices receive a subsidy, equivalent to the cost of one year in school.
After the two years vocational school programme some students opt for a third year in the ‘general’ programme as an alternative to an apprenticeship. Both apprenticeship and a third year of practical training in school lead to the same vocational qualifications. Upper secondary VET graduates may go directly to Vocational Technical Colleges, while those who wish to enter university need to take a supplementary year of education.
The social partners participate actively in the development of policy. The National Council for Vocational Education and Training advises the Minister on the development of the national vocational education and training system. The Advisory Councils for Vocational Education and Training are linked to the nine vocational education programmes provided in upper secondary education and advise on the content of VET programmes and on trends and future skill needs. The National Curriculum groups assist in deciding the contents of the vocational training within the specific occupations. The Local County Vocational Training Committees advise on the quality, provision of VET and career guidance.
Paraguay.
In Paraguay, vocational education is known as "Bachillerato Técnico" and is part of the secondary education system. These schools combine general education with some specific subjects, referred to as pre-vocational education and career orientation. After nine years of "Educación Escolar Básica" (Primary School), the student can choose to go to either a "Bachillerato Técnico" (Vocational School) or a "Bachillerato Científico" (High School). Both forms of secondary education last three years, and are usually located in the same campus called "Colegio".
After completing secondary education, one can enter to the universities. It is also possible for a student to choose both Técnico and Científico schooling.
Sri Lanka.
Vocational training from Agricultural subjects to ICT related subjects are available in Sri Lanka. 
In 2005 the Ministry of Vocational and Technical Training (MVTT) introduced the National Vocational Qualifications (NVQ) framework which was an important milestone for the education, economic and social development of Sri Lanka. The NVQ framework consists of seven levels of instruction. NVQ levels 1 to 4 are for craftsmen designation and successful candidates are issued with National certificates. NVQ levels 5 and 6 are Diploma level, whereas Level 7 is for degree equivalent qualification.
Training courses are provided by many institutions island wide. All training providers (public and private) must obtain institutional registration and course accreditation from the Tertiary and Vocational Education Commission (TVEC).In order to obtain registration institutions must satisfy specific criteria: infrastructure, basic services, tools and equipment, quality of instruction and staff, based on curriculum and syllabus, and quality of management and monitoring systems.
Government Ministries and Agencies involved in Vocational Training are The Ministry of Vocational and Technical Training (MVTT), The Tertiary and Vocational Education Commission (TVEC), The National Apprentice and Industrial Training Authority (NAITA), The Department of Technical Education and Training (DTET), The Vocational Training Authority (VTA) and the National Youth Services Council (NYSC).
Sweden.
Nearly all of those leaving compulsory schooling immediately enter upper secondary schools, and most complete their upper secondary education in three years. Upper secondary education is divided into 13 vocationally oriented and 4 academic national programmes. Slightly more than half of all students follow vocational programmes. All programmes offer broad general education and basic eligibility to continue studies at the post-secondary level. In addition, there are local programmes specially designed to meet local needs and ‘individual’ programmes.
A 1992 school reform extended vocational upper secondary programmes by one year, aligning them with three years of general upper secondary education, increasing their general education content, and making core subjects compulsory in all programmes. The core subjects (which occupy around one-third of total teaching time in both vocational and academic programmes) include English, artistic activities, physical education and health, mathematics, natural science, social studies, Swedish or Swedish as a second language, and religious studies. In addition to the core subjects, students pursue optional courses, subjects which are specific to each programme and a special project.
Vocational programmes include 15 weeks of workplace training (Arbetsplatsförlagd utbildning – APU) over the three-year period. Schools are responsible for arranging workplace training and verifying its quality. Most municipalities have advisory bodies: programme councils (programmråd) and vocational councils (yrkesråd) composed of employers’ and employees’ representatives from the locality. The councils advise schools on matters such as provision of workplace training courses, equipment purchase and training of supervisors in APU.
Switzerland.
Nearly two thirds of those entering upper secondary education enter the vocational education and training system. At this level, vocational education and training is mainly provided through the ‘dual system’. Students spend some of their time in a vocational school; some of their time doing an apprenticeship at a host company; and for most programmes, students attend industry courses at an industry training centre to develop complementary practical skills relating to the occupation at hand. Common patterns are for students to spend one- two days per week at the vocational school and three-four days doing the apprenticeship at the host company; alternatively they alternate between some weeks attending classes at the vocational school and some weeks attending industry courses at an industry training centre. A different pattern is to begin the programme with most of the time devoted to in-school education and gradually diminishing the amount of in-school education in favour of more in-company training.
Switzerland draws a distinction between vocational education and training (VET) programmes at upper-secondary level, and professional education and training (PET) programmes, which take place at tertiary B level. In 2007, more than half of the population aged 25–64 had a VET or PET qualification as their highest level of education. In addition, universities of applied sciences (Fachhochschulen) offer vocational education at tertiary A level. Pathways enable people to shift from one part of the education system to another.
Turkey.
Students in Turkey may choose vocational high schools after completing the 8-year-long compulsory primary and secondary education. Vocational high school graduates may pursue two year-long polytechnics or may continue with a related tertiary degree.
According to a survey by OECD, 38% of 15-year-old students attend vocational study programmes that are offered by "Anatolian vocational", "Anatolian technical", and "technical high schools".
Municipalities in Turkey also offer vocational training. The metropolitan municipality of Istanbul, the most populous city in Turkey, offers year long free vocational programs in a wide range of topics through ISMEK, an umbrella organization formed under the municipality.
United Kingdom.
The first "Trades School" in the UK was "Stanley Technical Trades School" (now Harris Academy South Norwood) which was designed, built and set up by William Stanley. The initial idea was thought of in 1901, and the school opened in 1907.
The system of vocational education in the UK initially developed independently of the state, with bodies such as the RSA and City & Guilds setting examinations for technical subjects. The Education Act 1944 made provision for a Tripartite System of grammar schools, secondary technical schools and secondary modern schools, but by 1975 only 0.5% of British senior pupils were in technical schools, compared to two-thirds of the equivalent German age group.
Successive recent British Governments have made attempts to promote and expand vocational education. In the 1970s, the Business And Technology Education Council was founded to confer further and higher education awards, particularly to further education colleges in the United Kingdom. In the 1980s and 1990s, the Conservative Government promoted the Youth Training Scheme, National Vocational Qualifications and General National Vocational Qualifications. However, youth training was marginalised as the proportion of young people staying on in full-time education increased.
In 1994, publicly funded Modern Apprenticeships were introduced to provide "quality training on a work-based (educational) route". Numbers of apprentices have grown in recent years and the Department for Children, Schools and Families has stated its intention to make apprenticeships a "mainstream" part of England's education system.
In the UK some higher technician engineering positions that require 4-5 year apprenticeship require academic study to HNC / HND or higher City & Guilds level. Apprenticeships are increasingly recognised as the gold standard for work-based training. There are three levels of Apprenticeship available for those aged 16 and over:
Apprentices work towards work-based learning qualifications such as a Level 2 Competence Qualification, Functional Skills and, in most cases, a relevant knowledge-based qualification.
Apprentices work towards work-based learning such as a Level 3 Competence Qualification, Functional Skills and, in most cases, a relevant knowledgebased qualification.
Apprentices work towards work-based learning qualifications such as a Level 4 and 5 Competence Qualification, Functional Skills and, in some cases, a knowledge-based qualification such as a Foundation Degree.

</doc>
<doc id="56552" url="https://en.wikipedia.org/wiki?curid=56552" title="Jet lag">
Jet lag

Jet lag, medically referred to as desynchronosis and rarely as circadian dysrhythmia, is a physiological condition which results from alterations to the body's circadian rhythms resulting from rapid long-distance trans-meridian (east–west or west–east) travel on high-speed aircraft. For example, someone travelling from New York to California feels as if the time were three hours later than local time. Jet lag was previously classified as one of the circadian rhythm sleep disorders.
The condition of jet lag may last several days before the traveller is fully adjusted to the new time zone; a recovery period of one day per time zone crossed is a suggested guideline. Jet lag is especially an issue for airline pilots, crew, and frequent travellers. Airlines have regulations aimed at combating pilot fatigue caused by jet lag.
The term "jet lag" is used because before the arrival of passenger jet aircraft, it was uncommon to travel far and fast enough to cause jet lag. Trips by propeller-driven aircraft and train were slower and of more limited distance than jet flights, and thus did not contribute widely to the problem.
Cause.
Jet lag is a chronobiological problem, similar to issues often induced by shift work and the circadian rhythm sleep disorders. When travelling across a number of time zones, the body clock (circadian rhythm) will be out of synchronisation with the destination time, as it experiences daylight and darkness contrary to the rhythms to which it has grown accustomed. The body's natural pattern is upset, as the rhythms that dictate times for eating, sleeping, hormone regulation, body temperature variations, and other functions no longer correspond to the environment, nor to each other, in some cases. To the degree that the body cannot immediately realign these rhythms, it is jet lagged.
The speed at which the body adjusts to the new schedule depends on the individual as well as the direction of travel; some people may require several days to adjust to a new time zone, while others experience little disruption.
Crossing the International Date Line does not in itself contribute to jet lag, as the guide for calculating jet lag is the number of time zones crossed, with a maximum possible time difference of plus or minus 12 hours. If the time difference between two locations is greater than 12 hours, one must subtract that number from 24. For example, the time zone GMT+14 will be at the same time of day as GMT−10, though the former is one day ahead of the latter.
Jet lag is linked only to the trans-meridian (west–east or east–west) distance travelled. A ten-hour flight between Europe and southern Africa does not cause jet lag, as the direction of travel is primarily north–south. A five-hour flight between the Pacific and Atlantic coasts of the United States may well result in jet lag.
Double desynchronisation.
There are two separate processes related to biological timing: circadian oscillators and homeostasis. The circadian system is located in the suprachiasmatic nucleus (SCN) in the hypothalamus of the brain. The other process is homeostatic sleep propensity, which is a function of the amount of time elapsed since the last adequate sleep episode.
The human body has a master clock in the SCN and also peripheral oscillators in tissues. The SCN's role is to send signals to peripheral oscillators, which synchronise them for physiological functions. The SCN responds to light information sent from the retina. It is hypothesised that peripheral oscillators respond to internal signals such as hormones, food intake, and "nervous stimuli".
The implication of independent internal clocks may explain some of the symptoms of jet lag. People who travel across several time zones can, within a few days, adapt their sleep-wake cycles with light from the environment. However, their skeletal muscles, liver, lungs and other organs will adapt at different rates. This internal biological de-synchronisation is exacerbated as the body is not in sync with the environment—a "double desynchronisation", which has implications for health and mood.
Symptoms.
The symptoms of jet lag can be quite varied, depending on the amount of time zone alteration, time of day, and individual differences. Sleep disturbance occurs, with poor sleep upon arrival and/or sleep disruptions such as trouble falling asleep (when flying east), early awakening (when flying west), and trouble remaining asleep. Cognitive effects include poorer performance on mental tasks and concentration; increased fatigue, headaches, and irritability; and problems with digestion, including indigestion, changes in the frequency of defecation and consistency of faeces, and reduced interest in and enjoyment of food. The symptoms are caused by a circadian rhythm that is out of sync with the day-night cycle of the destination, as well as the possibility of internal desynchronisation. Jet lag has been measured with simple analogue scales, but a study has shown that these are relatively blunt for assessing all the problems associated with jet lag. The Liverpool Jet Lag Questionnaire was developed to measure all the symptoms of jet lag at several times of day, and this dedicated measurement tool has been used to assess jet lag in athletes.
Jet lag may require a change of three time zones or more to occur, though some individuals can be affected by as little as a single time zone or the single-hour shift to or from daylight saving time. Symptoms and consequences of jet lag can be a significant concern for athletes travelling east or west to competitions, as performance is often dependent on a combination of physical and mental characteristics that are impacted by jet lag.
Travel fatigue.
Travel fatigue is general fatigue, disorientation, and headache caused by a disruption in routine, time spent in a cramped space with little chance to move around, a low-oxygen environment, and dehydration caused by dry air and limited food and drink. It does not necessarily involve the shift in circadian rhythms that cause jet lag. Travel fatigue can occur without crossing time zones, and it often disappears after a single day accompanied by a night of good quality sleep.
Management.
Light is the strongest stimulus for realigning a person's sleep-wake schedule, and careful control of exposure to and avoidance of bright light to the eyes can speed adjustment to a new time zone. The hormone melatonin is produced in dim light and darkness in humans, and it is eliminated by light.
Direction of travel.
North–south flights that do not cross time zones do not cause jet lag. However, crossing of the Arctic Ocean or even the North Pole (often the shortest route between northeast Europe and Alaska or the Canadian West Coast and East Asia) does cause a significant time change. Jet travel from Alaska to northeast Europe causes a pattern of jet lag very similar to an eastward flight at lower latitudes. It can be teased from Baseball statistics that west-east travel affects performance more than east-west travel.
In general, adjustment to the new time zone is easier for east–west travel than for west–east. A westward adjustment takes, in days, approximately half the number of time zones crossed; for eastward travel, adjusting to the new time zone takes, in days, approximately two-thirds the number of time zones crossed.
Management after travelling east.
Travelling east causes more problems than travelling west because the body clock has to be advanced, which is harder than delaying it. Most people have an endogenous circadian rhythm that is longer than 24 hours, so lengthening a day is less troublesome than shortening it. Equally important, the necessary exposure to light to realign the body clock does not tie in with the day/night cycle at the destination.
Travelling east by six to nine time zones causes the biggest problems, as it is desirable to avoid light in the mornings. Waterhouse et al. recommend:
Travelling by 10 hours or more is usually best managed by assuming it is a 14-hour westward transition and delaying the body clock. A customised jet lag program can be obtained from an online jet lag calculator. These programs consider the sleep pattern of the user, the number of time zones crossed, and the direction of travel. The efficacy of these jet lag calculators has not been documented.
Management when travelling west.
Travelling west causes fewer problems than travelling east, and it is usually sufficient to seek exposure to light during the day and avoid it at night.
Methods.
Timed light exposure can be effective to help people match their circadian rhythms with the expected cycle at their destination; it requires strict adherence to timing. Light therapy is a popular method used by professional athletes to reduce jet lag. Special glasses, usually battery-driven, provide light to the eyes, thus inhibiting the production of melatonin in the brain. Timed correctly, the light may contribute to an advance or delay of the circadian phase to that which will be needed at the destination. The glasses may be used on the plane or even before users leave their departure city.
Timed melatonin administration may be effective in reducing jet lag symptoms. The benefit of using melatonin is likely to be greater for eastward flights than for westward ones because for most people it is easier to delay than to advance the circadian rhythm. There remain issues regarding the appropriate timing of melatonin use in addition to the legality of the substance in certain countries. How effective it may actually be is also questionable. For athletes, anti-doping agencies may prohibit or limit its use.
Timing of exercise and food consumption have also been suggested as remedies, though their applicability in humans and practicality for most travellers are not certain, and no firm guidelines exist. There are very little data supporting the use of diet to adjust to jet lag. While there are data supporting the use of exercise, the intensity of exercise that may be required is significant, and possibly difficult to maintain for non-athletes. These strategies may be used both before departure and after landing. Individuals may differ in their susceptibility to jet lag and in how quickly they can adjust to new sleep-wake schedules.
Short-acting sleep medications can be used to improve sleep quality and timing, and stimulating substances such as caffeine can be used to promote wakefulness, though research results on their success at adapting to jet lag are inconsistent.
For time changes of fewer than three hours, jet lag is unlikely to be a concern, and if travel is for short periods (three days or fewer) retaining a "home schedule" may be better for most people. Sleeping on the plane is only advised if it is within the destination's normal sleep time.
Mental health implications.
Jet lag may affect the mental health of vulnerable individuals. When travelling across time zones, there is a "phase-shift of body temperature, rapid-eye-movement sleep, melatonin production, and other circadian rhythms". A 2002 Israeli study found that relapse of major affective and psychotic disorders occurred more frequently when seven or more time zones had been crossed in the past week than when three or fewer had been crossed. Although significant disruptions of circadian rhythms had been documented as affecting individuals with bipolar disorder, an Australian team studied suicide statistics from 1971 to 2001 to determine whether the one-hour shifts involved in daylight saving time had an effect. They found increased incidence of male suicide after the commencement of daylight saving time but not after returning to standard time.

</doc>
<doc id="56556" url="https://en.wikipedia.org/wiki?curid=56556" title="Ketone bodies">
Ketone bodies

Ketone bodies are three water-soluble molecules (acetoacetate, beta-hydroxybutyrate, and their spontaneous breakdown product, acetone) that are produced by the liver from fatty acids during periods of low food intake (fasting), carbohydrate restrictive diets, starvation, prolonged intense exercise, or in untreated (or inadequately treated) type 1 diabetes mellitus. These ketone bodies are readily picked up by the extra-hepatic tissues, and converted into acetyl-CoA which then enters the citric acid cycle and is oxidized in the mitochondria for energy. In the brain, ketone bodies are also used to make acetyl-CoA into long-chain fatty acids. The latter cannot be obtained from the blood, because they cannot pass through the blood–brain barrier.
Ketone bodies are produced by the liver under the circumstances listed above (i.e. fasting, starving, low carbohydrate diets, prolonged exercise and untreated type 1 diabetes mellitus) as a result of intense gluconeogenesis, which is the production of glucose from non-carbohydrate sources (not including fatty acids). They are therefore always released into the blood by the liver together with newly produced glucose, after the liver glycogen stores have been depleted. (These glycogen stores are depleted after only 24 hours of fasting.)
Acetoacetate consists of two acetyl-CoA molecules (without their -CoAs, or coenzyme A) combined in tandem. Beta-hydroxybutyrate is a reduced form of acetoacetate, in which the ketone group is converted into an alcohol (or hydroxyl) group (see illustration on the right). Both are 4-carbon molecules, that can readily be converted back into acetyl-CoA by most tissues of the body, with the notable exception of the liver. Acetone is the decarboxylated form of acetoacetate which cannot be converted back into acetyl-CoA except via detoxification in the liver where it is converted into lactic acid, which can, in turn, be oxidized into pyruvic acid, and only then into acetyl-CoA.
Ketone bodies have a characteristic smell, which can easily be detected in the breath of persons in ketosis and ketoacidosis. It is often described as fruity or like nail polish remover (which usually contains acetone or ethyl acetate).
Apart from the three endogenous ketone bodies, acetone, acetoacetic acid, and "beta"-hydroxybutyric acid, other ketone bodies like "beta"-ketopentanoate and "beta"-hydroxypentanoate may be created as a result of the metabolism of synthetic triglycerides, such as triheptanoin.
Production.
Fats stored in adipose tissue are released from the fat cells into the blood as free fatty acids and glycerol when insulin levels are low and glucagon and epinephrine levels in the blood are high. This occurs between meals, during fasting, starvation and strenuous exercise, when blood glucose levels are likely to fall. Fatty acids are very high energy fuels, and are taken up by all metabolizing cells which have mitochondria. This is because fatty acids can only be metabolized in the mitochondria. Red blood cells do not contain mitochondria and are therefore entirely dependent on glycolysis (the fermentation of glucose into lactic acid) for their energy requirements. In all other tissues the fatty acids that enter the metabolizing cells are combined with co-enzyme A to form acyl-CoA chains. These are transferred into the mitochondria of the cells, where they are broken down into acetyl-CoA units by a sequence of reactions known as β-oxidation.
The acetyl-CoA produced by β-oxidation enters the citric acid cycle in the mitochondrion by combining with oxaloacetate to form citrate. This results in the complete combustion of the acetyl group of acetyl-CoA (see diagram above, on the right) to CO2 and water. The energy released in this process is captured in the form of 1 GTP and 11 ATP molecules per acetyl group (or acetic acid molecule) oxidized. This is the fate of acetyl-CoA wherever β-oxidation of fatty acids occurs, except under certain circumstances in the liver. In the liver oxaloacetate is wholly or partially diverted into the gluconeogenic pathway during fasting, starvation, a low carbohydrate diet, prolonged strenuous exercise, and in uncontrolled type 1 diabetes mellitus. Under these circumstances oxaloacetate is hydrogenated to malate which is then removed from the mitochondrion to be converted into glucose in the cytoplasm of the liver cells, from where it is released into the blood. In the liver, therefore, oxaloacetate is unavailable for condensation with acetyl-CoA when significant gluconeogenesis has been stimulated by low (or absent) insulin and high glucagon concentrations in the blood. Under these circumstances acetyl-CoA is diverted to the formation of acetoacetate and beta-hydroxybutyrate. Acetoacetate, beta-hydroxybutyrate, and their spontaneous breakdown product, acetone, are frequently, but confusingly, known as ketone bodies (as they are not "bodies" at all, but water-soluble chemical substances). The ketone bodies are released by the liver into the blood. All cells with mitochondria can take ketone bodies up from the blood and reconvert them into acetyl-CoA, which can then be used as fuel in their citric acid cycles, as no other tissue can divert its oxaloacetate into the gluconeogenic pathway in the way that the liver does this. Unlike free fatty acids, ketone bodies can cross the blood-brain barrier and are therefore available as fuel for the cells of the central nervous system, acting as a substitute for glucose, on which these cells normally survive. The occurrence of high levels of ketone bodies in the blood during starvation, a low carbohydrate diet, prolonged heavy exercise and uncontrolled type 1 diabetes mellitus is known as ketosis, and in its extreme form in out-of-control type 1 diabetes mellitus, as ketoacidosis.
Acetoacetate has a highly characteristic smell, for the people who can detect this smell, which occurs in the breath and urine during ketosis. On the other hand, most people can smell acetone, whose "sweet & fruity" odor also characterizes the breath of persons in ketosis or, especially, ketoacidosis.
Uses in the heart, brain and muscle (but not the liver).
Ketone bodies can be used for energy. Ketone bodies are transported from the liver to other tissues, where acetoacetate and "beta"-hydroxybutyrate can be reconverted to acetyl-CoA to produce energy, via the citric acid cycle. Ketone bodies cannot be used by the liver for energy, because the liver lacks the enzyme β-ketoacyl-CoA transferase, also called thiophorase. Acetone in low concentrations is taken up by the liver and undergoes detoxification through the methylglyoxal pathway which ends with lactate. Acetone in high concentrations due to prolonged fasting or a ketogenic diet is absorbed by cells other than those in the liver and enters a different pathway via 1,2-propanediol. Though the pathway follows a different series of steps requiring ATP, 1,2-propanediol can be turned into pyruvate.
The heart preferentially utilizes fatty acids for energy under normal physiologic conditions. However, under ketotic conditions, the heart can effectively utilize ketone bodies for energy.
The brain gets a portion of its energy from ketone bodies when glucose is less available (e.g., during fasting, strenuous exercise, low carbohydrate, ketogenic diet and in neonates). In the event of low blood glucose, most other tissues have additional energy sources besides ketone bodies (such as fatty acids), but the brain likely has an obligatory requirement for some glucose. After the diet has been changed to lower blood glucose for 3 days, the brain gets 25% of its energy from ketone bodies. After about 4 days, this goes up to 70% (during the initial stages the brain does not burn ketones, since they are an important substrate for lipid synthesis in the brain). Furthermore, ketones produced from omega-3 fatty acids may reduce cognitive deterioration in old age.
Ketosis and ketoacidosis.
In normal individuals, there is a constant production of ketone bodies by the liver and their utilization by extrahepatic tissues. The concentration of ketone bodies in blood is maintained around . Their excretion in urine is very low and undetectable by routine urine tests (Rothera's test).
When the rate of synthesis of ketone bodies exceeds the rate of utilization, their concentration in blood increases; this is known as "ketonemia". This is followed by "ketonuria" – excretion of ketone bodies in urine. The overall picture of ketonemia and ketonuria is commonly referred as ketosis. The smell of acetoacetate and/or acetone in breath is a common feature in ketosis.
When a type 1 diabetic suffers a biological stress event (infection, heart attack, or physical trauma), or fails to administer enough insulin they may enter the pathological state of hyperglycemic ketoacidosis. Under these circumstances, the low or absent insulin levels in the blood, combined with the inappropriately high glucagon concentrations, induce the liver to produce glucose at an inappropriately increased rate, causing acetyl-CoA resulting from the beta-oxidation of fatty acids, to be converted into ketones bodies. The resulting very high levels of ketone bodies lower the pH of the blood plasma which reflexively triggers the kidneys to excrete a very acid urine. The high levels of glucose and ketones in the blood also spill, passively, into the urine (the ability of the renal tubules to reabsorb glucose and ketones from the tubular fluid, being overwhelmed by the high volumes of these substances being filtered into the tubular fluid). The resulting osmotic diuresis of glucose causes the removal of water and electrolytes from the blood resulting in potentially fatal dehydration.
Individuals who follow a low-carbohydrate diet will also develop ketosis. This induced ketosis is sometimes called nutritional ketosis, but the level of ketone body concentrations are on the order of whereas the pathological ketoacidosis is .
Impact upon pH.
Both acetoacetic acid and "beta"-hydroxybutyric acid are acidic, and, if levels of these ketone bodies are too high, the pH of the blood drops, resulting in ketoacidosis, a complication of untreated Type I diabetes, and sometimes in end stage Type II (see diabetic ketoacidosis).

</doc>
<doc id="56557" url="https://en.wikipedia.org/wiki?curid=56557" title="Blood glucose monitoring">
Blood glucose monitoring

Blood glucose monitoring is a way of testing the concentration of glucose in the blood (glycemia). Particularly important in the care of diabetes mellitus, a blood glucose test is performed by piercing the skin (typically, on the finger) to draw blood, then applying the blood to a chemically active disposable 'test-strip'. Different manufacturers use different technology, but most systems measure an electrical characteristic, and use this to determine the glucose level in the blood. The test is usually referred to as capillary blood glucose.
Healthcare professionals advise patients with diabetes on the appropriate monitoring regimen for their condition. Most people with Type 2 diabetes test at least once per day. Diabetics who use insulin (all Type 1 diabetes and many Type 2s) usually test their blood sugar more often (3 to 10 times per day), both to assess the effectiveness of their prior insulin dose and to help determine their next insulin dose.
Improved technology for measuring blood glucose is rapidly changing the standards of care for all diabetic people.
Purpose.
Blood glucose monitoring reveals individual patterns of blood glucose changes, and helps in the planning of meals, activities, and at what time of day to take medications.
Also, testing allows for quick response to high blood sugar (hyperglycemia) or low blood sugar (hypoglycemia). This might include diet adjustments, exercise, and insulin (as instructed by the health care provider).
Blood glucose meters.
A blood glucose meter is an electronic device for measuring the blood glucose level. A relatively small drop of blood is placed on a disposable test strip which interfaces with a digital meter. Within several seconds, the level of blood glucose will be shown on the digital display.
Needing only a small drop of blood for the meter means that the time and effort required for testing is reduced and the compliance of diabetic people to their testing regimens is improved. Although the cost of using blood glucose meters seems high, it is believed to be a cost benefit relative to the avoided medical costs of the complications of diabetes.
Recent advances include:
Continuous glucose monitoring.
A continuous glucose monitor (CGM) determines glucose levels on a continuous basis (every few minutes). A typical system consists of:
Continuous glucose monitors measure the glucose level of interstitial fluid. Shortcomings of CGM systems due to this fact are:
Patients therefore require traditional fingerstick measurements for calibration (typically twice per day) and are often advised to use fingerstick measurements to confirm hypo- or hyperglycemia before taking corrective action.
The lag time discussed above has been reported to be about 5 minutes. Anecdotally, some users of the various systems report lag times of up to 10–15 minutes. This lag time is insignificant when blood sugar levels are relatively consistent. However, blood sugar levels, when changing rapidly, may read in the normal range on a CGM system while in reality the patient is already experiencing symptoms of an out-of-range blood glucose value and may require treatment. Patients using CGM are therefore advised to consider both the absolute value of the blood glucose level given by the system as well as any trend in the blood glucose levels. For example, a patient using CGM with a blood glucose of 100 mg/dl on their CGM system might take no action if their blood glucose has been consistent for several readings, while a patient with the same blood glucose level but whose blood glucose has been dropping steeply in a short period of time might be advised to perform a fingerstick test to check for hypoglycemia.
Continuous monitoring allows examination of how the blood glucose level reacts to insulin, exercise, food, and other factors. The additional data can be useful for setting correct insulin dosing ratios for food intake and correction of hyperglycemia. Monitoring during periods when blood glucose levels are not typically checked (e.g. overnight) can help to identify problems in insulin dosing (such as basal levels for insulin pump users or long-acting insulin levels for patients taking injections). Monitors may also be equipped with alarms to alert patients of hyperglycemia or hypoglycemia so that a patient can take corrective action(s) (after fingerstick testing, if necessary) even in cases where they do not feel symptoms of either condition. While the technology has its limitations, studies have demonstrated that patients with continuous sensors experience less hyperglycemia and also reduce their glycosylated hemoglobin levels.
Currently, continuous blood glucose monitoring is not automatically covered by health insurance in the United States in the same way that most other diabetic supplies are covered (e.g. standard glucose testing supplies, insulin, and even insulin pumps). However, an increasing number of insurance companies do cover continuous glucose monitoring supplies (both the receiver and disposable sensors) on a case-by-case basis if the patient and doctor show a specific need. The lack of insurance coverage is exacerbated by the fact that disposable sensors must be frequently replaced. Some sensors have been U.S. Food and Drug Administration (FDA) approved for 7- and 3-day use, though some patients wear sensors for longer than the recommended period) and the receiving meters likewise have finite lifetimes (less than 2 years and as little as 6 months). This is one factor in the slow uptake in the use of sensors that have been marketed in the United States.
The principles, history and recent developments of operation of electrochemical glucose biosensors are discussed in a chemical review by Joseph Wang.
Popular CGM systems as of May 2015 include:
Glucose sensing bio-implants.
Investigations on the use of test strips have shown that the required self-injury acts as a psychological barrier restraining the patients from sufficient glucose control. As a result, secondary diseases are caused by excessive glucose levels. A significant improvement of diabetes therapy might be achieved with an implantable sensor that would continuously monitor blood sugar levels within the body and transmit the measured data outside. The burden of regular blood testing would be taken from the patient, who would instead follow the course of their glucose levels on an intelligent device like a laptop or a smart phone.
Glucose concentrations do not necessarily have to be measured in blood vessels, but may also be determined in the interstitial fluid, where the same levels prevail – with a time lag of a few minutes – due to its connection with the capillary system. However, the enzymatic glucose detection scheme used in single-use test strips is not directly suitable for implants. One main problem is caused by the varying supply of oxygen, by which glucose is converted to glucono lactone and HO by glucose oxidase. Since the implantation of a sensor into the body is accompanied by growth of encapsulation tissue, the diffusion of oxygen to the reaction zone is continuously diminished. This decreasing oxygen availability causes the sensor reading to drift, requiring frequent re-calibration using finger-sticks and test strips.
One approach to achieving long-term glucose sensing is to measure and compensate for the changing local oxygen concentration. Other approaches replace the troublesome glucose oxidase reaction with a reversible sensing reaction, known as an affinity assay. This scheme was originally put forward by Schultz & Sims in 1978. A number of different affinity assays have been investigated, with fluorescent assays proving most common. MEMS technology has recently allowed for smaller and more convenient alternatives to fluorescent detection, via measurement of viscosity. Investigation of affinity-based sensors has shown that encapsulation by body tissue does not cause a drift of the sensor signal, but only a time lag of the signal compared to the direct measurement in blood.
Non-invasive technologies.
Some new technologies to monitor blood glucose levels will not require access to blood to read the glucose level. Non-invasive technologies include near IR detection, ultrasound and dielectric spectroscopy. These may free the person with diabetes from finger sticks to supply the drop of blood for blood glucose analysis.
Most of the non-invasive methods under development are continuous glucose monitoring methods and offer the advantage of providing additional information to the subject between the conventional finger stick, blood glucose measurements and over time periods where no finger stick measurements are available (i.e. while the subject is sleeping).
Effectiveness.
For patients with diabetes mellitus type 2, the importance of monitoring and the optimal frequency of monitoring are not clear. A 2011 study found no evidence that blood glucose monitoring leads to better patient outcomes in actual practice. One randomized controlled trial found that self-monitoring of blood glucose did not improve glycosylated hemoglobin (HbA1c) among "reasonably well controlled non-insulin treated patients with type 2 diabetes". However a recent meta-analysis of 47 randomized controlled trials encompassing 7677 patients showed that self-care management intervention improves glycemic control in diabetics, with an estimated 0.36% (95% CI, 0.21-0.51) reduction in their glycosylated hemoglobin values. Furthermore, a recent study showed that patients described as being "Uncontrolled Diabetics" (defined in this study by HbA1C levels >8%) showed a statistically significant decrease in the HbA1C levels after a 90-day period of seven-point self-monitoring of blood glucose (SMBG) with a relative risk reduction (RRR) of 0.18% (95% CI, 0.86-2.64%, p<.001). Regardless of lab values or other numerical parameters, the purpose of the clinician is to improve quality of life and patient outcomes in diabetic patients. A recent study included 12 randomized controlled trials and evaluated outcomes in 3259 patients. The authors concluded through a qualitative analysis that SMBG on quality of life showed no effect on patient satisfaction or the patients' health-related quality of life. Furthermore, the same study identified that patients with type 2 diabetes mellitus diagnosed greater than one year prior to initiation of SMBG, who were not on insulin, experienced a statistically significant reduction in their HbA1C of 0.3% (95% CI, -0.4 - -0.1) at six months follow up, but a statistically insignificant reduction of 0.1% (95% CI, -0.3 – 0.04) at twelve months follow up. Conversely, newly diagnosed patients experienced a statistically significant reduction of 0.5% (95% CI, -0.9 – -0.1) at 12 months follow up. A recent study found that a treatment strategy of intensively lowering blood sugar levels (below 6%) in patients with additional cardiovascular disease risk factors poses more harm than benefit. For type 2 diabetics who are not on insulin, exercise and diet are the best tools. Blood glucose monitoring is, in that case, simply a tool to evaluate the success of diet and exercise. Insulin-dependent type 2 diabetics need to monitor their blood sugar as frequently as type 1 diabetics.
Blood glucose monitoring recommendations.
The National Institute for Health and Clinical Excellence (NICE), UK released updated diabetes recommendations on 30 May 2008, which recommend that self-monitoring of plasma glucose levels for people with newly diagnosed type 2 diabetes must be integrated into a structured self-management education process.
The recommendations have been updated in August 2015 for children and young adults with type 1 diabetes. See: NICE Guideline for Continuous Blood Glucose Monitoring. 

</doc>
<doc id="56558" url="https://en.wikipedia.org/wiki?curid=56558" title="Blood pressure">
Blood pressure

Blood pressure (BP) is the pressure exerted by circulating blood upon the walls of blood vessels. When used without further specification, "blood pressure" usually refers to the arterial pressure in the systemic circulation. It is usually measured at a person's upper arm. Blood pressure is usually expressed in terms of the systolic (maximum) pressure over diastolic (minimum) pressure and is measured in millimeters of mercury (mm Hg). It is one of the vital signs along with respiratory rate, heart rate, oxygen saturation, and body temperature. Normal resting blood pressure in an adult is approximately 120/80 mm Hg.
Blood pressure varies depending on situation, activity, and disease states. It is regulated by the nervous and endocrine systems. Blood pressure that is low due to a disease state is called hypotension, and pressure that is consistently high is hypertension. Both have many causes which can range from mild to severe. Both may be of sudden onset or of long duration. Long term hypertension is a risk factor for many diseases, including kidney failure, heart disease, and stroke. Long term hypertension is more common than long term hypotension in Western countries. Long term hypertension often goes undetected because of infrequent monitoring and the absence of symptoms.
Classification.
Systemic arterial pressure.
The table presented here shows the classification of blood pressure adopted by the American Heart Association for adults who are 18 years and older. It assumes the values are a result of averaging resting blood pressure readings measured at two or more visits to the doctor.
In the UK, clinic blood pressures are usually categorised into three groups; low (90/60 or lower), normal (between 90/60 and 139/89), and high (140/90 or higher).
Blood pressure fluctuates from minute to minute and normally shows a circadian rhythm over a 24-hour period, with highest readings in the early morning and evenings and lowest readings at night. Loss of the normal fall in blood pressure at night is associated with a greater future risk of cardiovascular disease and there is evidence that night-time blood pressure is a stronger predictor of cardiovascular events than day-time blood pressure.
Various factors, such as age and sex, influence a person's blood pressure and variations in it. In children, the normal ranges are lower than for adults and depend on height. Reference blood pressure values have been developed for children in different countries, based on the distribution of blood pressure in children of these countries. As adults age, systolic pressure tends to rise and diastolic tends to fall. In the elderly, systolic blood pressure tends to be above the normal adult range, thought to be largely because of reduced flexibility of the arteries. Also, an individual's blood pressure varies with exercise, emotional reactions, sleep, digestion and time of day (circadian rhythm).
Differences between left and right arm blood pressure measurements tend to be random and average to nearly zero if enough measurements are taken. However, in a small percentage of cases there is a consistent difference greater than 10 mm Hg which may need further investigation, e.g. for obstructive arterial disease.
The risk of cardiovascular disease increases progressively above 115/75 mm Hg. In the past, hypertension was only diagnosed if secondary signs of high arterial pressure were present, along with a prolonged high systolic pressure reading over several visits. Regarding hypotension, in practice blood pressure is considered too low only if noticeable symptoms are present.
Clinical trials demonstrate that people who maintain arterial pressures at the low end of these pressure ranges have much better long term cardiovascular health. The principal medical debate concerns the aggressiveness and relative value of methods used to lower pressures into this range for those who do not maintain such pressure on their own. Elevations, more commonly seen in older people, though often considered normal, are associated with increased morbidity and mortality.
Mean arterial pressure.
The mean arterial pressure (MAP) is the average over a cardiac cycle and is determined by the cardiac output (CO), systemic vascular resistance (SVR), and central venous pressure (CVP),
MAP can be approximately determined from measurements of the systolic pressure formula_2  and the diastolic pressure formula_3 
Pulse pressure.
The pulse pressure is the difference between the measured systolic and diastolic pressures,
The up and down fluctuation of the arterial pressure results from the pulsatile nature of the cardiac output, i.e. the heartbeat. Pulse pressure is determined by the interaction of the stroke volume of the heart, the compliance (ability to expand) of the arterial system—largely attributable to the aorta and large elastic arteries—and the resistance to flow in the arterial tree. By expanding under pressure, the aorta absorbs some of the force of the blood surge from the heart during a heartbeat. In this way, the pulse pressure is reduced from what it would be if the aorta were not compliant. The loss of arterial compliance that occurs with aging explains the elevated pulse pressures found in elderly patients.
Systemic venous pressure.
Blood pressure generally refers to the arterial pressure in the systemic circulation. However, measurement of pressures in the venous system and the pulmonary vessels plays an important role in intensive care medicine but requires invasive measurement of pressure using a catheter.
Venous pressure is the vascular pressure in a vein or in the atria of the heart. It is much less than arterial pressure, with common values of 5 mm Hg in the right atrium and 8 mm Hg in the left atrium.
Variants of venous pressure include:
Pulmonary pressure.
Normally, the pressure in the pulmonary artery is about 15 mm Hg at rest.
Increased blood pressure in the capillaries of the lung cause pulmonary hypertension, leading to interstitial edema if the pressure increases to above 20 mm Hg, and to pulmonary edema at pressures above 25 mm Hg.
Disorders.
Disorders of blood pressure control include: high blood pressure, low blood pressure, and blood pressure that shows excessive or maladaptive fluctuation.
High.
Arterial hypertension can be an indicator of other problems and may have long-term adverse effects. Sometimes it can be an acute problem, for example hypertensive emergency.
Levels of arterial pressure put mechanical stress on the arterial walls. Higher pressures increase heart workload and progression of unhealthy tissue growth (atheroma) that develops within the walls of arteries. The higher the pressure, the more stress that is present and the more atheroma tend to progress and the heart muscle tends to thicken, enlarge and become weaker over time.
Persistent hypertension is one of the risk factors for strokes, heart attacks, heart failure and arterial aneurysms, and is the leading cause of chronic kidney failure. Even moderate elevation of arterial pressure leads to shortened life expectancy. At severely high pressures, mean arterial pressures 50% or more above average, a person can expect to live no more than a few years unless appropriately treated.
In the past, most attention was paid to diastolic pressure; but nowadays it is recognised that both high systolic pressure and high pulse pressure (the numerical difference between systolic and diastolic pressures) are also risk factors. In some cases, it appears that a decrease in excessive diastolic pressure can actually increase risk, due probably to the increased difference between systolic and diastolic pressures (see the article on pulse pressure). If systolic blood pressure is elevated (>140) with a normal diastolic blood pressure (<90), it is called "isolated systolic hypertension" and may present a health concern.
For those with heart valve regurgitation, a change in its severity may be associated with a change in diastolic pressure. In a study of people with heart valve regurgitation that compared measurements 2 weeks apart for each person, there was an increased severity of aortic and mitral regurgitation when diastolic blood pressure increased, whereas when diastolic blood pressure decreased, there was a decreased severity.
Low.
Blood pressure that is too low is known as hypotension. Hypotension is a medical concern if it causes signs or symptoms, such as dizziness, fainting, or in extreme cases, shock.
When arterial pressure and blood flow decrease beyond a certain point, the perfusion of the brain becomes critically decreased (i.e., the blood supply is not sufficient), causing lightheadedness, dizziness, weakness or fainting.
Sometimes the arterial pressure drops significantly when a patient stands up from sitting. This is known as orthostatic hypotension (postural hypotension); gravity reduces the rate of blood return from the body veins below the heart back to the heart, thus reducing stroke volume and cardiac output.
When people are healthy, the veins below their heart quickly constrict and the heart rate increases to minimize and compensate for the gravity effect. This is carried out involuntarily by the autonomic nervous system. The system usually requires a few seconds to fully adjust and if the compensations are too slow or inadequate, the individual will suffer reduced blood flow to the brain, dizziness and potential blackout. Increases in G-loading, such as routinely experienced by aerobatic or combat pilots 'pulling Gs', greatly increases this effect. Repositioning the body perpendicular to gravity largely eliminates the problem.
Other causes of low arterial pressure include:
Shock is a complex condition which leads to critically decreased perfusion. The usual mechanisms are loss of blood volume, pooling of blood within the veins reducing adequate return to the heart and/or low effective heart pumping. Low arterial pressure, especially low pulse pressure, is a sign of shock and contributes to and reflects decreased perfusion.
If there is a significant difference in the pressure from one arm to the other, that may indicate a narrowing (for example, due to aortic coarctation, aortic dissection, thrombosis or embolism) of an artery.
Fluctuating blood pressure.
Normal fluctuation in blood pressure is adaptive and necessary. Fluctuations in pressure that are significantly greater than the norm are associated with greater white matter hyperintensity, a finding consistent with reduced local cerebral blood flow and a heightened risk of cerebrovascular disease. Within both high and low blood pressure groups, a greater degree of fluctuation was found to correlate with an increase in cerebrovascular disease compared to those with less variability, suggesting the consideration of the clinical management of blood pressure fluctuations, even among normotensive older adults. Older individuals and those who had received blood pressure medications were more likely to exhibit larger fluctuations in pressure.
Physiology.
During each heartbeat, blood pressure varies between a maximum (systolic) and a minimum (diastolic) pressure. The blood pressure in the circulation is principally due to the pumping action of the heart. Differences in mean blood pressure are responsible for blood flow from one location to another in the circulation. The rate of mean blood flow depends on both blood pressure and the resistance to flow presented by the blood vessels. Mean blood pressure decreases as the circulating blood moves away from the heart through arteries and capillaries due to viscous losses of energy. Mean blood pressure drops over the whole circulation, although most of the fall occurs along the small arteries and arterioles. Gravity affects blood pressure via hydrostatic forces (e.g., during standing), and valves in veins, breathing, and pumping from contraction of skeletal muscles also influence blood pressure in veins.
Hemodynamics.
There are many physical factors that influence arterial pressure. Each of these may in turn be influenced by physiological factors, such as: diet, exercise, disease, drugs or alcohol, stress, and obesity.
Some physical factors are:
In practice, each individual's autonomic nervous system responds to and regulates all these interacting factors so that, although the above issues are important, the actual arterial pressure response of a given individual varies widely because of both split-second and slow-moving responses of the nervous system and end organs. These responses are very effective in changing the variables and resulting blood pressure from moment to moment.
Moreover, blood pressure is the result of cardiac output increased by peripheral resistance: "blood pressure = cardiac output X peripheral resistance". As a result, an abnormal change in blood pressure is often an indication of a problem affecting the heart's output, the blood vessels' resistance, or both. Thus, knowing the patient's blood pressure is critical to assess any pathology related to output and resistance.
Regulation.
The endogenous regulation of arterial pressure is not completely understood, but the following mechanisms of regulating arterial pressure have been well-characterized:
These different mechanisms are not necessarily independent of each other, as indicated by the link between the RAS and aldosterone release. When blood pressure falls many physiological cascades commence in order to return the blood pressure to a more appropriate level.
Currently, the RAS is targeted pharmacologically by ACE inhibitors and angiotensin II receptor antagonists. The aldosterone system is directly targeted by spironolactone, an aldosterone antagonist. The fluid retention may be targeted by diuretics; the antihypertensive effect of diuretics is due to its effect on blood volume. Generally, the baroreceptor reflex is not targeted in hypertension because if blocked, individuals may suffer from orthostatic hypotension and fainting.
Measurement.
Arterial pressure is most commonly measured via a sphygmomanometer, which historically used the height of a column of mercury to reflect the circulating pressure. Blood pressure values are generally reported in millimetres of mercury (mm Hg), though aneroid and electronic devices do not contain mercury.
For each heartbeat, blood pressure varies between systolic and diastolic pressures. Systolic pressure is peak pressure in the arteries, which occurs near the end of the cardiac cycle when the ventricles are contracting. Diastolic pressure is minimum pressure in the arteries, which occurs near the beginning of the cardiac cycle when the ventricles are filled with blood. An example of normal measured values for a resting, healthy adult human is 120 mm Hg systolic and 80 mm Hg diastolic (written as 120/80 mm Hg, and spoken as "one-twenty over eighty").
Systolic and diastolic arterial blood pressures are not static but undergo natural variations from one heartbeat to another and throughout the day (in a circadian rhythm). They also change in response to stress, nutritional factors, drugs, disease, exercise, and momentarily from standing up. Sometimes the variations are large. Hypertension refers to arterial pressure being abnormally high, as opposed to hypotension, when it is abnormally low. Along with body temperature, respiratory rate, and pulse rate, blood pressure is one of the four main vital signs routinely monitored by medical professionals and healthcare providers.
Measuring pressure invasively, by penetrating the arterial wall to take the measurement, is much less common and usually restricted to a hospital setting.
Noninvasive.
The noninvasive auscultatory and oscillometric measurements are simpler and quicker than invasive measurements, require less expertise, have virtually no complications, are less unpleasant and less painful for the patient. However, noninvasive methods may yield somewhat lower accuracy and small systematic differences in numerical results. Noninvasive measurement methods are more commonly used for routine examinations and monitoring.
Palpation.
A minimum systolic value can be roughly estimated by palpation, most often used in emergency situations, but should be used with caution. It has been estimated that, using 50% percentiles, carotid, femoral and radial pulses are present in patients with a systolic blood pressure > 70 mm Hg, carotid and femoral pulses alone in patients with systolic blood pressure of > 50 mm Hg, and only a carotid pulse in patients with a systolic blood pressure of > 40 mm Hg.
A more accurate value of systolic blood pressure can be obtained with a sphygmomanometer and palpating the radial pulse. The diastolic blood pressure cannot be estimated by this method. The American Heart Association recommends that palpation be used to get an estimate before using the auscultatory method.
Auscultatory.
The auscultatory method (from the Latin word for "listening") uses a stethoscope and a sphygmomanometer. This comprises an inflatable ("Riva-Rocci") cuff placed around the upper arm at roughly the same vertical height as the heart, attached to a mercury or aneroid manometer. The mercury manometer, considered the gold standard, measures the height of a column of mercury, giving an absolute result without need for calibration and, consequently, not subject to the errors and drift of calibration which affect other methods. The use of mercury manometers is often required in clinical trials and for the clinical measurement of hypertension in high-risk patients, such as pregnant women.
A cuff of appropriate size is fitted smoothly and also snugly, then inflated manually by repeatedly squeezing a rubber bulb until the artery is completely occluded. It is important that the cuff size is correct: undersized cuffs record too high a pressure; oversized cuffs may yield too low a pressure. Usually three or four cuff sizes should be available to allow measurements in arms of different size. Listening with the stethoscope to the brachial artery at the antecubital area of the elbow, the examiner slowly releases the pressure in the cuff. When blood just starts to flow in the artery, the turbulent flow creates a "whooshing" or pounding (first Korotkoff sound). The pressure at which this sound is first heard is the systolic blood pressure. The cuff pressure is further released until no sound can be heard (fifth Korotkoff sound), at the diastolic arterial pressure.
The auscultatory method is the predominant method of clinical measurement.
Oscillometric.
The oscillometric method was first demonstrated in 1876 and involves the observation of oscillations in the sphygmomanometer cuff pressure which are caused by the oscillations of blood flow, i.e., the pulse. The electronic version of this method is sometimes used in long-term measurements and general practice. It uses a sphygmomanometer cuff, like the auscultatory method, but with an electronic pressure sensor (transducer) to observe cuff pressure oscillations, electronics to automatically interpret them, and automatic inflation and deflation of the cuff. The pressure sensor should be calibrated periodically to maintain accuracy.
Oscillometric measurement requires less skill than the auscultatory technique and may be suitable for use by untrained staff and for automated patient home monitoring. As for the auscultatory technique it is important that the cuff size is appropriate for the arm. There are some single cuff devices that may be used for arms of differing sizes, although experience with these is limited.
The cuff is inflated to a pressure initially in excess of the systolic arterial pressure and then reduced to below diastolic pressure over a period of about 30 seconds. When blood flow is nil (cuff pressure exceeding systolic pressure) or unimpeded (cuff pressure below diastolic pressure), cuff pressure will be essentially constant. When blood flow is present, but restricted, the cuff pressure, which is monitored by the pressure sensor, will vary periodically in synchrony with the cyclic expansion and contraction of the brachial artery, i.e., it will oscillate.
Over the deflation period, the recorded pressure waveform forms a signal known as the cuff deflation curve. A bandpass filter is utilized to extract the oscillometric pulses from the cuff deflation curve. Over the deflation period, the extracted oscillometric pulses form a signal known as the oscillometric waveform (OMW). The amplitude of the oscillometric pulses increases to a maximum and then decreases with further deflation. A variety of analysis algorithms can be employed in order to estimate the systolic, diastolic, and mean arterial pressure.
Oscillometric monitors may produce inaccurate readings in patients with heart and circulation problems, which include arteriosclerosis, arrhythmia, preeclampsia, pulsus alternans, and pulsus paradoxus.
In practice the different methods do not give identical results; an algorithm and experimentally obtained coefficients are used to adjust the oscillometric results to give readings which match the auscultatory results as well as possible. Some equipment uses computer-aided analysis of the instantaneous arterial pressure waveform to determine the systolic, mean, and diastolic points. Since many oscillometric devices have not been validated, caution must be given as most are not suitable in clinical and acute care settings.
Recently, several coefficient-free oscillometric algorithms have developed for estimation of blood pressure. These algorithms do not rely on experimentally obtained coefficients and have been shown to provide more accurate and robust estimation of blood pressure. These algorithms are based on finding the fundamental relationship between the oscillometric waveform and the BP using modeling and learning approaches.
The term NIBP, for non-invasive blood pressure, is often used to describe oscillometric monitoring equipment.
Continuous noninvasive techniques (CNAP).
Continuous Noninvasive Arterial Pressure (CNAP) is the method of measuring arterial blood pressure in real-time without any interruptions and without cannulating the human body. CNAP combines the advantages of the following two clinical “gold standards”: it measures blood pressure continuously in real-time like the invasive arterial catheter system and it is noninvasive like the standard upper arm sphygmomanometer. Latest developments in this field show promising results in terms of accuracy, ease of use and clinical acceptance.
Non-occlusive techniques: The Pulse Wave Velocity (PWV) principle.
Since the 1990s a novel family of techniques based on the so-called pulse wave velocity (PWV) principle have been developed. These techniques rely on the fact that the velocity at which an arterial pressure pulse travels along the arterial tree depends, among others, on the underlying blood pressure. Accordingly, after a calibration maneuver, these techniques provide indirect estimates of blood pressure by translating PWV values into blood pressure values.
The main advantage of these techniques is that it is possible to measure PWV values of a subject continuously (beat-by-beat), without medical supervision, and without the need of inflating brachial cuffs. PWV-based techniques are still in the research domain and are not adapted to clinical settings.
Ambulatory and home monitoring.
Ambulatory blood pressure devices take readings regularly (e.g. every half-hour throughout the day and night). They have been used to exclude measurement problems like white-coat hypertension and provide more reliable estimates of usual blood pressure and cardiovascular risk. Blood pressure readings outside of a clinical setting are usually slightly lower in the majority of people; however studies that quantified the risks from hypertension and the benefits of lowering blood pressure have mostly been based on readings in a clinical environment. Use of ambulatory measurements is not widespread but guidelines developed by the UK National Institute for Health and Care Excellence and the British Hypertension Society recommended that 24-hour ambulatory blood pressure monitoring should be used for diagnosis of hypertension. Health economic analysis suggested that this approach would be cost effective compared with repeated clinic measurements.
Home monitoring is a cheap and simple alternative to ambulatory blood pressure monitoring, although it does not usually allow assessment of blood pressure during sleep which may be a disadvantage. Automatic self-contained blood pressure monitors are available at reasonable prices, however measurements may not be accurate in patients with atrial fibrillation or other arrhythmias such as frequent ectopic beats. Home monitoring may be used to improve hypertension management and to monitor the effects of lifestyle changes and medication related to blood pressure. Compared to ambulatory blood pressure measurements, home monitoring has been found to be an effective and lower cost alternative, but ambulatory monitoring is more accurate than both clinic and home monitoring in diagnosing hypertension.
When measuring blood pressure in the home, an accurate reading requires that one not drink coffee, smoke cigarettes, or engage in strenuous exercise for 30 minutes before taking the reading. A full bladder may have a small effect on blood pressure readings; if the urge to urinate arises, one should do so before the reading. For 5 minutes before the reading, one should sit upright in a chair with one's feet flat on the floor and with limbs uncrossed. The blood pressure cuff should always be against bare skin, as readings taken over a shirt sleeve are less accurate. The same arm should be used for all measurements. During the reading, the arm that is used should be relaxed and kept at heart level, for example by resting it on a table.
Since blood pressure varies throughout the day, home measurements should be taken at the same time of day. A Joint Scientific Statement From the American Heart Association, American Society of Hypertension, and Preventive Cardiovascular Nurses Association on home monitoring in 2008 recommended that 2 to 3 readings should be taken in the morning (after awakening, before washing/dressing, taking breakfast/drink or taking medication) and another 2 to 3 readings at night, each day over a period of 1 week. It was also recommended that the readings from the first day should be discarded and that a total of ≥12 readings (i.e. at least two readings per day for the remaining 6 days of the week) should be used for making clinical decisions.
White-coat hypertension.
For some patients, blood pressure measurements taken in a doctor's office may not correctly characterize their typical blood pressure. In up to 25% of patients, the office measurement is higher than their typical blood pressure. This type of error is called white-coat hypertension (WCH) and can result from anxiety related to an examination by a health care professional. White coat hypertension can also occur because, in a clinical setting, patients are seldom given the opportunity to rest for five minutes before blood pressure readings are taken. The misdiagnosis of hypertension for these patients can result in needless and possibly harmful medication. WCH can be reduced (but not eliminated) with automated blood pressure measurements over 15 to 20 minutes in a quiet part of the office or clinic. In some cases a lower blood pressure reading occurs at the doctor's - this has been termed 'masked hypertension'.
Invasive.
Arterial blood pressure (BP) is most accurately measured invasively through an arterial line. Invasive arterial pressure measurement with intravascular cannulae involves direct measurement of arterial pressure by placing a cannula needle in an artery (usually radial, femoral, dorsalis pedis or brachial).
The cannula must be connected to a sterile, fluid-filled system, which is connected to an electronic pressure transducer. The advantage of this system is that pressure is constantly monitored beat-by-beat, and a waveform (a graph of pressure against time) can be displayed. This invasive technique is regularly employed in human and veterinary intensive care medicine, anesthesiology, and for research purposes.
Cannulation for invasive vascular pressure monitoring is infrequently associated with complications such as thrombosis, infection, and bleeding. Patients with invasive arterial monitoring require very close supervision, as there is a danger of severe bleeding if the line becomes disconnected. It is generally reserved for patients where rapid variations in arterial pressure are anticipated.
Invasive vascular pressure monitors are pressure monitoring systems designed to acquire pressure information for display and processing. There are a variety of invasive vascular pressure monitors for trauma, critical care, and operating room applications. These include single pressure, dual pressure, and multi-parameter (i.e. pressure / temperature). The monitors can be used for measurement and follow-up of arterial, central venous, pulmonary arterial, left atrial, right atrial, femoral arterial, umbilical venous, umbilical arterial, and intracranial pressures.
Fetal blood pressure.
In pregnancy, it is the fetal heart and not the mother's heart that builds up the fetal blood pressure to drive its blood through the fetal circulation.
The blood pressure in the fetal aorta is approximately 30 mm Hg at 20 weeks of gestation, and increases to approximately 45 mm Hg at 40 weeks of gestation.<br>
The average blood pressure for full-term infants:<br>
Systolic 65–95 mm Hg<br>Diastolic 30–60 mm Hg

</doc>
<doc id="56561" url="https://en.wikipedia.org/wiki?curid=56561" title="Anesthesia">
Anesthesia

In the practice of medicine, especially surgery, and dentistry, anesthesia (or anaesthesia) is an induced, temporary state with one or more of the following characteristics: analgesia (relief from or prevention of pain), paralysis (extreme muscle relaxation), amnesia (loss of memory), and unconsciousness. An anesthetic is an agent that causes anaesthesia. A patient under the effects of anesthesia is anesthetized. An anesthesiologist (US) or anaesthetist (UK) is a physician who performs anesthesia. A Certified Registered Nurse Anesthetist is an advanced practice nurse who performs anesthesia.
Anesthesia enables the painless performance of medical procedures that would cause severe or intolerable pain to an unanesthetized patient. Three broad categories of anaesthesia exist:
In preparing for a medical procedure, an anesthesiologist chooses and determines the doses of one or more drugs to achieve the types and degree of anesthesia characteristics appropriate for the type of procedure and the particular patient. The types of drugs used include
general anesthetics, hypnotics, sedatives, neuromuscular-blocking drugs, narcotic, and analgesics.
There are both major and minor risks of anesthesia. Examples of major risks include death, heart attack and pulmonary embolism whereas minor risks can include postoperative nausea and vomiting and hospital readmission. The likelihood of a complication occurring is proportional to the relative risk of a variety of factors related to the patient's health, the complexity of the surgery being performed and the type of anesthetic. Of these factors, the person's health prior to surgery (stratified by the ASA physical status classification system) has the greatest bearing on the probability of a complication occurring. Patients typically wake within minutes of an anesthetic being terminated and regain their senses within hours. One exception is a condition called long-term post-operative cognitive dysfunction, characterized by persistent confusion lasting weeks or months, which is more common in those undergoing cardiac surgery and in the elderly.
Medical uses.
The purpose of anesthesia can be distilled down to three basic goals or end points:
Different types of anesthesia (which are discussed in the following sections) effect the endpoints differently. Regional anesthesia, for instance effects analgesia, benzodiazepine-type sedatives (used in twilight sleep) favor amnesia and general anesthetics can effect all of the endpoints. The goal of anesthesia is to achieve the endpoints required for the given surgical procedure with the least risk to the patient. 
To achieve the goals of anesthesia, drugs act on different but interconnected parts of the nervous system. Hypnosis, for instance, is generated through actions on the nuclei in the brain and is similar to the activation of sleep. The effect is to make people less aware and less reactive to noxious stimuli.
Loss of memory (amnesia) is created by action of drugs on multiple (but specific) regions of the brain. Memories are created as either declarative or non-declarative memories in several stages (short-term, long-term, long-lasting) the strength of which is determined by the strength of connections between neurons termed synaptic plasticity. Each anesthetic produces amnesia through unique effects on memory formation at variable doses. Inhalational anesthetics will reliably produce amnesia through general suppression of the nuclei at doses below those required for loss of consciousness. Drugs like midazolam produce amnesia through different pathways by blocking the formation of long-term memories.
Tied closely to the concepts of amnesia and hypnosis is the concept of consciousness. Consciousness is the higher order process that synthesizes information. For instance, the "sun" conjures up feelings, memories and a sensation of warmth rather than a description of a round, orange warm ball seen in the sky for part of a 24‑hour cycle. Likewise, a person can have dreams (a state of subjective consciousness) during anesthetic or have consciousness of the procedure despite having no indication of it under anesthetic. It is estimated that 22% of people dream during general anesthesia and 1 or 2 cases per 1000 have some consciousness termed "awareness during general anesthesia".
Techniques.
Anesthesia is unique, in that it is not a direct means of treatment, rather it allows others to do things that may treat, diagnose, or cure an ailment which would otherwise be painful or complicated. The best anesthetic, therefore is the one with the lowest risk to the patient that still achieves the endpoints required to complete the procedure. The first stage of an anesthetic is the pre-operative risk assessment made up of the medical history, physical examination and lab tests. Diagnosing a person's pre-operative physical status allows the clinician to minimize anesthetic risks. A well completed medical history will arrive at the correct diagnosis 56% of the time which increases to 73% with a physical examination. Lab tests help in diagnosis but only in 3% of cases, underscoring the need for a full history and physical examination prior to anesthetics. Incorrect pre-operative assessments or preparations are the root cause of 11% of all adverse anesthetic events.
One part of the risk assessment is based on the patients' health. The American Society of Anesthesiologists have developed a six-tier scale which stratifies the pre-operative physical state of the patient called the ASA physical status. The scale assesses a high-order of risk as the patient's general health relates to an anesthetic.
The more detailed pre-operative medical history aims to discover genetic disorders (such as malignant hyperthermia or pseudocholinesterase deficiency), habits (tobacco, drug and alcohol use), physical attributes (such as obesity or a difficult airway) and any coexisting diseases (especially cardiac and respiratory diseases) that might impact the anesthetic. The physical examination helps quantify the impact of anything found in the medical history in addition to lab tests.
Aside from the generalities of the patients health assessment, an evaluation of the specific factors as they relate to the surgery also need to be considered for anesthesia. For instance, anesthesia during childbirth must consider not only the mother but the baby. Cancers and tumors that occupy the lungs or throat create special challenges to general anesthesia. After determining the health of the person undergoing anesthetic and the endpoints that are required to complete the procedure, the type of anesthetic can be selected. Choice of surgical method and anaesthetic technique aims to reduce risk of complications, shorten time needed for recovery and minimise the surgical stress response.
General anesthesia.
Anesthesia is the combination of the endpoints (discussed above) which are reached by drugs acting on different but overlapping sites in the central nervous system. General anesthesia (as opposed to sedation or regional anesthesia) has three main goals: lack of movement (paralysis), unconsciousness, and blunting of the stress response. In the early days of anesthesia, anesthetics could reliably achieve the first two, allowing surgeons to perform necessary procedures, but many patients died because the extremes of blood pressure and pulse caused by the surgical insult were ultimately harmful. Eventually, the need for blunting of the surgical stress response was identified by Harvey Cushing, who injected local anesthetic prior to hernia repairs. This led to the development of other drugs that could blunt the response leading to lower surgical mortality rates.
The most common approach to reach the endpoints of general anesthesia is through the use of inhaled general anesthetics. Each has its own potency which is correlated to its solubility in oil. This relationship exists because the drugs bind directly to cavities in proteins of the central nervous system, although several theories of general anaesthetic action have been described. Inhalational anesthetics are thought to exact their effects on different parts of the central nervous system. For instance, the immobilizing effect of inhaled anesthetics results from an effect on the spinal cord whereas sedation, hypnosis and amnesia involve sites in the brain. The potency of an inhalational anesthetic is quantified by its minimum alveolar concentration or MAC. The MAC is the percentage dose of anaesthetic that will prevent a response to painful stimulus in 50% of subjects. The higher the MAC, generally, the less potent the anesthetic.
[[File:Anesthesia medications.JPG|thumb|Syringes prepared with medications that are expected to be used during an operation under general anesthesia maintained by sevoflurane gas:
Equipment.
The core instrument in an inhalational anesthetic delivery system is an anesthetic machine. It has vaporizers, ventilators, an anesthetic breathing circuit, waste gas scavenging system and pressure gauges. The purpose of the anesthetic machine is to provide anesthetic gas at a constant pressure, oxygen for breathing and to remove carbon dioxide or other waste anesthetic gases. Since inhalational aenesthetics are inflammable, various checklists have been developed to confirm that the machine is ready for use, that the safety features are active and the electrical hazards are removed. Intravenous anesthetic is delivered either by bolus doses or an infusion pump. There are also many smaller instruments used in airway management and monitoring the patient. The common thread to modern machinery in this field is the use of fail-safe systems that decrease the odds of catastrophic misuse of the machine.
Monitoring.
Patients under general anesthesia must undergo continuous physiological monitoring to ensure safety. In the US, the American Society of Anesthesiologists (ASA) have established minimum monitoring guidelines for patients receiving general anesthesia, regional anesthesia, or sedation. This includes electrocardiography (ECG), heart rate, blood pressure, inspired and expired gases, oxygen saturation of the blood (pulse oximetry), and temperature. In the UK the Association of Anaesthetists (AAGBI) have set minimum monitoring guidelines for general and regional anesthesia. For minor surgery, this generally includes monitoring of heart rate, oxygen saturation, blood pressure, and inspired and expired concentrations for oxygen, carbon dioxide, and inhalational anesthetic agents. For more invasive surgery, monitoring may also include temperature, urine output, blood pressure, central venous pressure, pulmonary artery pressure and pulmonary artery occlusion pressure, cardiac output, cerebral activity, and neuromuscular function. In addition, the operating room environment must be monitored for ambient temperature and humidity, as well as for accumulation of exhaled inhalational anesthetic agents, which might be deleterious to the health of operating room personnel.
Sedation.
Sedation (also referred to as "dissociative anesthesia" or "twilight anesthesia") creates hypnotic, sedative, anxiolytic, amnesic, anticonvulsant, and centrally produced muscle-relaxing properties. From the perspective of the person giving the sedation, the patient will appear sleepy, relaxed and forgetful, allowing unpleasant procedures to be more easily completed. Sedatives such as benzodiazepines are usually given with pain relievers (such as narcotics, or local anesthetics or both) because they don't, by themselves, provide significant pain relief.
From the perspective of the person receiving sedative, the effect is a feeling of general relaxation, amnesia (loss of memory) and time passing quickly. Many drugs can produce a sedative effect including benzodiazepines, propofol, thiopental, ketamine and inhaled general anesthetics. The advantage of sedation over a general anesthetic is that it generally does not require support of the airway or breathing (no tracheal intubation or mechanical ventilation) and can have less of an effect on the cardiovascular system which may add to a greater margin of safety in some patients.
Regional anesthesia.
When pain is blocked from a part of the body using local anesthetics, it is generally referred to as regional anesthesia. There are many types of regional anesthesia either by injecting into the tissue itself, a vein that feeds the area or around a nerve trunk that supplies sensation to the area. The latter are called nerve blocks and are divided into peripheral or central nerve blocks.
The following are the types of regional anesthesia:
Nerve blocks.
When local anesthetic is injected around a larger diameter nerve that transmits sensation from an entire region it is referred to as a nerve block. Nerve blocks are commonly used in dentistry, when the mandibular nerve is blocked for procedures on the lower teeth. With larger diameter nerves (such as the interscalene block for upper limbs or psoas compartment block for lower limbs) the nerve and position of the needle is localized with ultrasound or electrical stimulation. The use of ultrasound may reduce complication rates and improve quality, performance time, and time to onset of blocks. Because of the large amount of local anesthetic required to affect the nerve, the maximum dose of local anesethetic has to be considered. Nerve blocks are also used as a continuous infusion, following major surgery such as knee, hip and shoulder replacement surgery, and may be associated with lower complications. Nerve blocks are also associated with a lower risk of neurologic complications when compared to neuraxial blocks.
Spinal, epidural and caudal anesthesia.
Central neuraxial anesthesia is the injection of local anesthetic around the spinal cord to provide analgesia in the abdomen, pelvis or lower extremities. It is divided into either spinal (injection into the subarachnoid space), epidural (injection outside of the subarachnoid space into the epidural space) and caudal (injection into the cauda equina or tail end of the spinal cord). Spinal and epidural are the most commonly used forms of central neuraxial blockade.
Spinal anesthesia is a "one-shot" injection that provides rapid onset and profound sensory anesthesia with lower doses of anesethetic, and is usually associated with neuromuscular blockade (loss of muscle control). Epidural anesthesia uses larger doses of anesthetic infused through an indwelling catheter which allows the anesthetic to be augmented should the effects begin to dissipate. Epidural anesethesia does not typically affect muscle control.
Because central neuraxial blockade causes arterial and vasodilation, a drop in blood pressure is common. This drop is largely dictated by the venous side of the circulatory system which holds 75% of the circulating blood volume. The physiologic effects are much greater when the block is placed above the 5th thoracic vertebra. An ineffective block is most often due to inadequate anxiolysis or sedation rather than a failure of the block itself.
Acute pain management.
Pain that is well managed during and immediately after surgery improves the health of patients (by decreasing physiologic stress) and the potential for chronic pain. Nociception (pain sensation) is not hard-wired into the body. Instead, it is a dynamic process wherein persistent painful stimuli can sensitize the system and either make pain management difficult or promote the development of chronic pain. For this reason, preemptive acute pain management may reduce both acute and chronic pain and is tailored to the surgery, the environment in which it is given (in-patient/out-patient) and the individual patient.
Pain management is classified into either pre-emptive or on-demand. On-demand pain medications typically include either opioid or non-steroidal anti-inflammatory drugs but can also make use of novel approaches such as inhaled nitrous oxide or ketamine. On demand drugs can be administered by a clinician ("as needed drug orders") or by the patient using patient-controlled analgesia (PCA). PCA has been shown to provide slightly better pain control and increased patient satisfaction when compared with conventional methods. Common preemptive approaches include epidural neuraxial blockade or nerve blocks. One review which looked at pain control after abdominal aortic surgery found that epidural blockade provides better pain relief (especially during movement) in the period up to three postoperative days. It reduces the duration of postoperative tracheal intubation by roughly half. The occurrence of prolonged postoperative mechanical ventilation and myocardial infarction is also reduced by epidural analgesia.
Risks and complications.
Risks and complications as they relate to anesthesia are classified as either morbidity (a disease or disorder that results from anesthesia) or mortality (death that results from anesthesia). Attempting to quantify how anesthesia contributes to morbidity and mortality can be difficult because a person's health prior to surgery and the complexity of the surgical procedure can also contribute to the risks.
Prior to anesthetic in the early 19th century, the physiologic stress from surgery caused significant complications and many deaths from shock. The faster the surgery was, the lower the rate of complications (leading to reports of very quick amputations). The advent of anesthesia allowed more complicated and life-saving surgery to be completed, decreased the physiologic stress of the surgery, but added an element of risk. It was two years after the introduction of ether anesthetics that the first death directly related to anesthetic was reported.
Morbidity can be major (myocardial infarction, pneumonia, pulmonary embolism, renal failure/insufficiency, postoperative cognitive dysfunction and allergy) or minor (minor nausea, vomiting, readmission). There is usually overlap in the contributing factors that lead to morbidity and mortality between the health of the patient, the surgery being performed and the anesthetic. To understand the relative risk of each contributing factor, consider that the rate of deaths totally attributed to the patient's health is 1:870. Compare that to the rate of deaths totally attributed to surgical factors (1:2860) or anesthesia alone (1:185,056) illustrating that the single greatest factor in anesthetic mortality is the health of the patient. These statistics can also be compared to the first such study on mortality in anesthesia from 1954, which reported a rate of death from all causes at 1:75 and a rate attributed to anesthesia alone at 1:2680. Direct comparisons between mortality statistics cannot reliably be made over time and across countries because of differences in the stratification of risk factors, however, there is evidence that anesthetics have made a significant improvement in safety but to what degree is uncertain.
Rather than stating a flat rate of morbidity or mortality, many factors are reported as contributing to the relative risk of the procedure and anesthetic combined. For instance, an operation on a person who is between the ages of 60–79 years old places the patient at 2.32 times greater risk than someone less than 60 years old. Having an ASA score of 3, 4 or 5 places the person at 10.65 times greater risk than someone with an ASA score of 1 or 2. Other variables include age greater than 80 (3.29 times risk compared to those under 60), gender (females have a lower risk of 0.77), urgency of the procedure (emergencies have a 4.44 times greater risk), experience of the person completing the procedure (less than 8 years experience and/or less than 600 cases have a 1.06 times greater risk) and the type of anesthetic (regional anesthetics are lower risk than general anesthetics). Obstetrical, the very young and the very old are all at greater risk of complication so extra precautions may need to be taken.
Recovery.
The immediate time after anesthesia is called emergence. Emergence from general anesthesia or sedation requires careful monitoring because there is still a risk of complication. Nausea and vomiting are reported at 9.8% but will vary with the type of anesthetic and procedure. There is a need for airway support in 6.8%, there can be urinary retention (more common in those over 50 years of age) and hypotension in 2.7%. Hypothermia, shivering and confusion are also common in the immediate post-operative period because of the lack of muscle movement (and subsequent lack of heat production) during the procedure.
Postoperative cognitive dysfunction (also known as "POCD" and post-anesthetic confusion) is a disturbance in cognition after surgery. It may also be variably used to describe emergence delirium (immediate post-operative confusion) and early cognitive dysfunction (diminished cognitive function in the first post-operative week). Although the three entities (delirium, early POCD and long-term POCD) are separate, the presence of delirium post-operatively predicts the presence of early POCD. There does not appear to be an association between delirium or early POCD and long-term POCD. According to a recent study conducted at the David Geffen School of Medicine at UCLA, the brain navigates its way through a series of activity clusters, or "hubs" on its way back to consciousness. Dr. Andrew Hudson, an assistant professor in anesthesiology states, "Recovery from anesthesia is not simply the result of the anesthetic 'wearing off,' but also of the brain finding its way back through a maze of possible activity states to those that allow conscious experience. Put simply, the brain reboots itself."
Long-term postoperative cognitive dysfunction is a subtle deterioration in cognitive function, that can last for weeks, months, or longer. Most commonly, relatives of the person report a lack of attention, memory and loss of interest in activities previously dear to the person (such as crosswords). In a similar way, people in the workforce may report an inability to complete tasks at the same speed they could previously. There is good evidence that POCD occurs after cardiac surgery and the major reason for its occurrence is the formation of microemboli. POCD also appears to occur in non-cardiac surgery. Its causes in non-cardiac surgery are less clear but older age is a risk factor for its occurrence.
History.
The first attempts at general anesthesia were probably herbal remedies administered in prehistory. Alcohol is one of the oldest known sedatives and it was used in ancient Mesopotamia thousands of years ago. The Sumerians are said to have cultivated and harvested the opium poppy ("Papaver somniferum") in lower Mesopotamia as early as 3400 BC.
The ancient Egyptians had some surgical instruments, as well as crude analgesics and sedatives, including possibly an extract prepared from the mandrake fruit. Bian Que (Chinese: 扁鹊, Wade–Giles: "Pien Ch'iao", c. 300 BC) was a legendary Chinese internist and surgeon who reportedly used general anesthesia for surgical procedures.
Throughout Europe, Asia, and the Americas a variety of "Solanum" species containing potent tropane alkaloids were used for anesthesia. In 13th century Italy, Theodoric Borgognoni used similar mixtures along with opiates to induce unconsciousness, and treatment with the combined alkaloids proved a mainstay of anesthesia until the nineteenth century. Local anesthetics were used in Inca civilization where shamans chewed coca leaves and performed operations on the skull while spitting into the wounds they had inflicted to anesthetize. Cocaine was later isolated and became the first effective local anesthetic. It was first used in 1859 by Karl Koller, at the suggestion of Sigmund Freud, in eye surgery in 1884. German surgeon August Bier (1861–1949) was the first to use cocaine for intrathecal anesthesia in 1898. Romanian surgeon Nicolae Racoviceanu-Piteşti (1860–1942) was the first to use opioids for intrathecal analgesia; he presented his experience in Paris in 1901.
Early Arab writings mention anesthesia by inhalation. This idea was the basis of the "soporific sponge" ("sleep sponge"), introduced by the Salerno school of medicine in the late twelfth century and by Ugo Borgognoni (1180–1258) in the thirteenth century. The sponge was promoted and described by Ugo's son and fellow surgeon, Theodoric Borgognoni (1205–1298). In this anesthetic method, a sponge was soaked in a dissolved solution of opium, mandragora, hemlock juice, and other substances. The sponge was then dried and stored; just before surgery the sponge was moistened and then held under the patient's nose. When all went well, the fumes rendered the patient unconscious.
The most famous anesthetic, ether, may have been synthesized as early as the 8th century, but it took many centuries for its anesthetic importance to be appreciated, even though the 16th century physician and polymath Paracelsus noted that chickens made to breathe it not only fell asleep but also felt no pain. By the early 19th century, ether was being used by humans, but only as a recreational drug.
Meanwhile, in 1772, English scientist Joseph Priestley discovered the gas nitrous oxide. Initially, people thought this gas to be lethal, even in small doses, like some other nitrogen oxides. However, in 1799, British chemist and inventor Humphry Davy decided to find out by experimenting on himself. To his astonishment he found that nitrous oxide made him laugh, so he nicknamed it laughing gas. Davy wrote about the potential anesthetic properties of nitrous oxide, but nobody at that time pursued the matter any further.
American physician Crawford W. Long noticed that his friends felt no pain when they injured themselves while staggering around under the influence of ether. He immediately thought of its potential in surgery. Conveniently, a participant in one of those "ether frolics", a student named James Venable, had two small tumors he wanted excised. But fearing the pain of surgery, Venable kept putting the operation off. Hence, Long suggested that he have his operation while under the influence of ether. Venable agreed, and on 30 March 1842 he underwent a painless operation. However, Long did not announce his discovery until 1849.
Horace Wells conducted the first public demonstration of the inhalational anesthetic at the Massachusetts General Hospital in Boston in 1845. However, the nitrous oxide was improperly administered and the patient cried out in pain.
On October 16, 1846, Boston dentist William Thomas Green Morton gave a successful demonstration using diethyl ether to medical students at the same venue. Morton, who was unaware of Long's previous work, was invited to the Massachusetts General Hospital to demonstrate his new technique for painless surgery. After Morton had induced anesthesia, surgeon John Collins Warren removed a tumor from the neck of Edward Gilbert Abbott. This occurred in the surgical amphitheater now called the Ether Dome. The previously skeptical Warren was impressed and stated, "Gentlemen, this is no humbug." In a letter to Morton shortly thereafter, physician and writer Oliver Wendell Holmes, Sr. proposed naming the state produced "anesthesia", and the procedure an "anesthetic".
Morton at first attempted to hide the actual nature of his anesthetic substance, referring to it as Letheon. He received a US patent for his substance, but news of the successful anesthetic spread quickly by late 1846. Respected surgeons in Europe including Liston, Dieffenbach, Pirogov, and Syme quickly undertook numerous operations with ether. An American-born physician, Boott, encouraged London dentist James Robinson to perform a dental procedure on a Miss Lonsdale. This was the first case of an operator-anesthetist. On the same day, 19 December 1846, in Dumfries Royal Infirmary, Scotland, a Dr. Scott used ether for a surgical procedure. The first use of anesthesia in the Southern Hemisphere took place in Launceston, Tasmania, that same year. Drawbacks with ether such as excessive vomiting and its explosive flammability led to its replacement in England with chloroform.
Discovered in 1831 by an American physician Samuel Guthrie (1782–1848), and independently a few months later by Frenchman Eugène Soubeiran (1797–1859) and Justus von Liebig (1803–73) in Germany, chloroform was named and chemically characterised in 1834 by Jean-Baptiste Dumas (1800–84). Its anaesthetic properties were noted early in 1847 by Marie-Jean-Pierre Flourens (1794–1867). The use of chloroform in anesthesia is linked to James Young Simpson, who, in a wide-ranging study of organic compounds, found chloroform's efficacy on 4 November 1847. Its use spread quickly and gained royal approval in 1853 when John Snow gave it to Queen Victoria during the birth of Prince Leopold. Unfortunately, though free of ether's flammability and consequent explosion hazard, chloroform is not as safe pharmacologically, especially when administered by an untrained practitioner (medical students, nurses, and occasionally members of the public were often pressed into giving anesthetics at this time). This led to many deaths from the use of chloroform that (with hindsight) might have been preventable. The first fatality directly attributed to chloroform anesthesia was recorded on 28 January 1848 after the death of Hannah Greener.
John Snow of London published articles from May 1848 onwards "On Narcotism by the Inhalation of Vapours" in the London Medical Gazette. Snow also involved himself in the production of equipment needed for the administration of inhalational anesthetics, the forerunner of today's anesthesia machines.
Of these first famous anesthetics, only nitrous oxide is still widely used today, with chloroform and ether having been replaced by safer but sometimes more expensive general anesthetics, and cocaine by more effective local anesthetics with less abuse potential.
Society and culture.
Almost all healthcare providers use anesthesia to some degree, however most health professions have their own field of specialists in the field including medicine, nursing and dentistry.
Doctors specializing in perioperative care, development of an anesthetic plan, and the administration of anesthetics are known in the US as "anesthesiologists" and in the UK, Canada, Australia, and NZ as "anaesthetists" or "anaesthesiologists". All anesthetics in the UK, Australia, New Zealand, Hong Kong and Japan are administered by doctors. Nurse anesthetists also administer anesthesia in 109 nations. In the US, 35% of anesthetics are provided by physicians in solo practice, about 55% are provided by anesthesia care teams (ACTs) with anesthesiologists medically directing anesthesiologist assistants or certified registered nurse anesthetists (CRNAs), and about 10% are provided by CRNAs in solo practice. There can also be anesthesiologist assistants (US) or physician assistant (anaesthesia) (UK) who assist with anesthesia.
Special populations.
There are many circumstances when anesthesia needs to be altered for special circumstances due to the procedure (such as in cardiac surgery, cardiothoracic anesthesiology or neurosurgery), the patient (such as in pediatric anesthesia, geriatric, bariatric or obstetrical anesthesia) or special circumstances (such as in trauma, prehospital care, robotic surgery or extreme environments).

</doc>
<doc id="56565" url="https://en.wikipedia.org/wiki?curid=56565" title="Circadian rhythm">
Circadian rhythm

A circadian rhythm is any biological process that displays an endogenous, entrainable oscillation of about 24 hours. These 24-hour rhythms are driven by a circadian clock, and they have been widely observed in plants, animals, fungi, and cyanobacteria.
The term "circadian" comes from the Latin "circa", meaning "around" (or "approximately"), and "diēm", meaning "day". The formal study of biological temporal rhythms, such as daily, tidal, weekly, seasonal, and annual rhythms, is called chronobiology. Circadian rhythms should not be confused with diurnal rhythms, which are oscillations "exactly" every 24 hours.
Although circadian rhythms are endogenous ("built-in", self-sustained), they are adjusted (entrained) to the local environment by external cues called zeitgebers (from German, "time giver"), which include light, temperature and redox cycles.
History.
The earliest recorded account of a circadian process dates from the 4th century B.C.E., when Androsthenes, a ship captain serving under Alexander the Great, described diurnal leaf movements of the tamarind tree. The observation of a circadian or diurnal process in humans is mentioned in Chinese medical texts dated to around the 13th century, including the "Noon and Midnight Manual" and the "Mnemonic Rhyme to Aid in the Selection of Acu-points According to the Diurnal Cycle, the Day of the Month and the Season of the Year".
The first recorded observation of an endogenous circadian oscillation was by the French scientist Jean-Jacques d'Ortous de Mairan in 1729. He noted that 24-hour patterns in the movement of the leaves of the plant "Mimosa pudica" continued even when the plants were kept in constant darkness, in the first experiment to attempt to distinguish an endogenous clock from responses to daily stimuli.
In 1896, Patrick and Gilbert observed that during a prolonged period of sleep deprivation, sleepiness increases and decreases with a period of approximately 24 hours. In 1918, J.S. Szymanski showed that animals are capable of maintaining 24-hour activity patterns in the absence of external cues such as light and changes in temperature. In the early 20th century, circadian rhythms were noticed in the rhythmic feeding times of bees. Extensive experiments were done by Auguste Forel, Ingeborg Beling, and Oskar Wahl to see whether this rhythm was due to an endogenous clock. Ron Konopka and Seymour Benzer isolated the first clock mutant in "Drosophila" in the early 1970s and mapped the "period" gene, the first discovered genetic determinant of behavioral rhythmicity. Joseph Takahashi discovered the first mammalian circadian clock mutation ("clockΔ19") using mice in 1994. However, recent studies show that deletion of "clock" does not lead to a behavioral phenotype (the animals still have normal circadian rhythms), which questions its importance in rhythm generation.
The term "circadian" was coined by Franz Halberg in the 1950s.
Criteria.
To be called circadian, a biological rhythm must meet these three general criteria: 
Origin.
Circadian rhythms allow organisms to anticipate and prepare for precise and regular environmental changes. They thus enable organisms to best capitalize on environmental resources (e.g. light and food) compared to those that cannot predict such availability. It has therefore been suggested that circadian rhythms put organisms at a selective advantage in evolutionary terms. However, rhythmicity appears to be as important in regulating and coordinating "internal" metabolic processes, as in coordinating with the "environment". This is suggested by the maintenance (heritability) of circadian rhythms in fruit flies after several hundred generations in constant laboratory conditions, as well as in creatures in constant darkness in the wild, and by the experimental elimination of behavioral, but not physiological, circadian rhythms in quail.
What drove circadian rhythms to evolve has been an enigmatic question. Previous hypotheses emphasized that photosensitive proteins and circadian rhythms may have originated together in the earliest cells, with the purpose of protecting replicating DNA from high levels of damaging ultraviolet radiation during the daytime. As a result, replication was relegated to the dark. However, evidence for this is lacking, since the simplest organisms with a circadian rhythm, the cyanobacteria, do the opposite of this - they divide more in the daytime. Recent studies instead highlight the importance of co-evolution of redox proteins with circadian oscillators in all three kingdoms of life following the Great Oxidation Event approximately 2.3 billion years ago. The current view is that circadian changes in environmental oxygen levels and the production of reactive oxygen species (ROS) in the presence of daylight are likely to have driven a need to evolve circadian rhythms to preempt, and therefore counteract, damaging redox reactions on a daily basis.
The simplest known circadian clock is that of the prokaryotic cyanobacteria. Recent research has demonstrated that the circadian clock of "Synechococcus elongatus" can be reconstituted "in vitro" with just the three proteins (KaiA, KaiB, KaiC) of their central oscillator. This clock has been shown to sustain a 22-hour rhythm over several days upon the addition of ATP. Previous explanations of the prokaryotic circadian timekeeper were dependent upon a DNA transcription/translation feedback mechanism.
A defect in the human homologue of the "Drosophila" "period" gene was identified as a cause of the sleep disorder FASPS (Familial advanced sleep phase syndrome), underscoring the conserved nature of the molecular circadian clock through evolution. Many more genetic components of the biological clock are now known. Their interactions result in an interlocked feedback loop of gene products resulting in periodic fluctuations that the cells of the body interpret as a specific time of the day.
It is now known that the molecular circadian clock can function within a single cell; i.e., it is cell-autonomous. This was shown by Gene Block in isolated mollusk BRNs. At the same time, different cells may communicate with each other resulting in a synchronised output of electrical signaling. These may interface with endocrine glands of the brain to result in periodic release of hormones. The receptors for these hormones may be located far across the body and synchronise the peripheral clocks of various organs. Thus, the information of the time of the day as relayed by the eyes travels to the clock in the brain, and, through that, clocks in the rest of the body may be synchronised. This is how the timing of, for example, sleep/wake, body temperature, thirst, and appetite are coordinately controlled by the biological clock.
Importance in animals.
Circadian rhythmicity is present in the sleeping and feeding patterns of animals, including human beings. There are also clear patterns of core body temperature, brain wave activity, hormone production, cell regeneration, and other biological activities. In addition, photoperiodism, the physiological reaction of organisms to the length of day or night, is vital to both plants and animals, and the circadian system plays a role in the measurement and interpretation of day length.
Impact of circadian disruption.
Mutations or deletions of clock gene in mice have demonstrated the importance of body clocks to ensure the proper timing of cellular/metabolic events; clock-mutant mice are hyperphagic and obese, and have altered glucose metabolism. In mice, deletion of the Rev-ErbA alpha clock gene facilitates diet-induced obesity and changes the balance between glucose and lipid utilization predisposing to diabetes. However, it is not clear whether there is a strong association between clock gene polymorphisms in humans and the susceptibility to develop the metabolic syndrome.
Impact of light–dark cycle.
The rhythm is linked to the light–dark cycle. Animals, including humans, kept in total darkness for extended periods eventually function with a free-running rhythm. Their sleep cycle is pushed back or forward each "day", depending on whether their "day", their endogenous period, is shorter or longer than 24 hours. The environmental cues that reset the rhythms each day are called "zeitgebers" (from the German, "time-givers"). Totally blind subterranean mammals (e.g., blind mole rat "Spalax" sp.) are able to maintain their endogenous clocks in the apparent absence of external stimuli. Although they lack image-forming eyes, their photoreceptors (which detect light) are still functional; they do surface periodically as well.
Free-running organisms that normally have one or two consolidated sleep episodes will still have them when in an environment shielded from external cues, but the rhythm is, of course, not entrained to the 24-hour light–dark cycle in nature. The sleep–wake rhythm may, in these circumstances, become out of phase with other circadian or ultradian rhythms such as metabolic, hormonal, CNS electrical, or neurotransmitter rhythms.
Recent research has influenced the design of spacecraft environments, as systems that mimic the light–dark cycle have been found to be highly beneficial to astronauts.
Arctic animals.
Norwegian researchers at the University of Tromsø have shown that some Arctic animals (ptarmigan, reindeer) show circadian rhythms only in the parts of the year that have daily sunrises and sunsets. In one study of reindeer, animals at 70 degrees North showed circadian rhythms in the autumn, winter and spring, but not in the summer. Reindeer on Svalbard at 78 degrees North showed such rhythms only in autumn and spring. The researchers suspect that other Arctic animals as well may not show circadian rhythms in the constant light of summer and the constant dark of winter.
A 2006 study in northern Alaska found that day-living ground squirrels and nocturnal porcupines strictly maintain their circadian rhythms through 82 days and nights of sunshine. The researchers speculate that these two rodents notice that the apparent distance between the sun and the horizon is shortest once a day, and, thus, a sufficient signal to entrain (adjust) by.
Butterfly migration.
The navigation of the fall migration of the Eastern North American monarch butterfly ("Danaus plexippus") to their overwintering grounds in central Mexico uses a time-compensated sun compass that depends upon a circadian clock in their antennae.
In plants.
Plant circadian rhythms tell the plant what season it is and when to flower for the best chance of attracting pollinators. Behaviors showing rhythms include leaf movement, growth, germination, stomatal/gas exchange, enzyme activity, photosynthetic activity, and fragrance emission, among others. Circadian rhythms occur as a plant entrains to synchronize with the light cycle of its surrounding environment. These rhythms are endogenously generated and self-sustaining and are relatively constant over a range of ambient temperatures. Important features include two interacting transcription-translation feedback loops: proteins containing PAS domains, which facilitate protein-protein interactions; and several photoreceptors that fine-tune the clock to different light conditions. Anticipation of changes in the environment allows appropriate changes in a plant's physiological state, conferring an adaptive advantage. A better understanding of plant circadian rhythms has applications in agriculture, such as helping farmers stagger crop harvests to extend crop availability and securing against massive losses due to weather.
Light is the signal by which plants synchronize their internal clocks to their environment and is sensed by a wide variety of photoreceptors. Red and blue light are absorbed through several phytochromes and cryptochromes. One phytochrome, phyA, is the main phytochrome in seedlings grown in the dark but rapidly degrades in light to produce Cry1. Phytochromes B–E are more stable with phyB, the main phytochrome in seedlings grown in the light. The cryptochrome (cry) gene is also a light-sensitive component of the circadian clock and is thought to be involved both as a photoreceptor and as part of the clock's endogenous pacemaker mechanism. Cryptochromes 1–2 (involved in blue–UVA) help to maintain the period length in the clock through a whole range of light conditions.
The central oscillator generates a self-sustaining rhythm and is driven by two interacting feedback loops that are active at different times of day. The morning loop consists of CCA1 (Circadian and Clock-Associated 1) and LHY (Late Elongated Hypocotyl), which encode closely related MYB transcription factors that regulate circadian rhythms in "Arabidopsis", as well as PRR 7 and 9 (Pseudo-Response Regulators.) The evening loop consists of GI (Gigantea) and ELF4, both involved in regulation of flowering time genes. When CCA1 and LHY are overexpressed (under constant light or dark conditions), plants become arrhythmic, and mRNA signals reduce, contributing to a negative feedback loop. Gene expression of CCA1 and LHY oscillates and peaks in the early morning, whereas TOC1 gene expression oscillates and peaks in the early evening. While it was previously hypothesised that these three genes model a negative feedback loop in which over-expressed CCA1 and LHY repress TOC1 and over-expressed TOC1 is a positive regulator of CCA1 and LHY, it was shown in 2012 by Andrew Millar and others that TOC1 in fact serves as a repressor not only of CCA1, LHY, and PRR7 and 9 in the morning loop but also of GI and ELF4 in the evening loop. This finding and further computational modeling of TOC1 gene functions and interactions suggest a reframing of the plant circadian clock as a triple negative-component repressilator model rather than the positive/negative-element feedback loop characterizing the clock in mammals.
Biological clock in mammals.
The primary circadian "clock" in mammals is located in the suprachiasmatic nucleus (or nuclei) (SCN), a pair of distinct groups of cells located in the hypothalamus. Destruction of the SCN results in the complete absence of a regular sleep–wake rhythm. The SCN receives information about illumination through the eyes. The retina of the eye contains "classical" photoreceptors ("rods" and "cones"), which are used for conventional vision. But the retina also contains specialized ganglion cells that are directly photosensitive, and project directly to the SCN, where they help in the entrainment (synchronization) of this master circadian clock.
These cells contain the photopigment melanopsin and their signals follow a pathway called the retinohypothalamic tract, leading to the SCN. If cells from the SCN are removed and cultured, they maintain their own rhythm in the absence of external cues.
The SCN takes the information on the lengths of the day and night from the retina, interprets it, and passes it on to the pineal gland, a tiny structure shaped like a pine cone and located on the epithalamus. In response, the pineal secretes the hormone melatonin. Secretion of melatonin peaks at night and ebbs during the day and its presence provides information about night-length.
Several studies have indicated that pineal melatonin feeds back on SCN rhythmicity to modulate circadian patterns of activity and other processes. However, the nature and system-level significance of this feedback are unknown.
The circadian rhythms of humans can be entrained to slightly shorter and longer periods than the Earth's 24 hours. Researchers at Harvard have shown that human subjects can at least be entrained to a 23.5-hour cycle and a 24.65-hour cycle (the latter being the natural solar day-night cycle on the planet Mars).
Humans.
Early research into circadian rhythms suggested that most people preferred a day closer to 25 hours when isolated from external stimuli like daylight and timekeeping. However, this research was faulty because it failed to shield the participants from artificial light. Although subjects were shielded from time cues (like clocks) and daylight, the researchers were not aware of the phase-delaying effects of indoor electric lights. The subjects were allowed to turn on light when they were awake and to turn it off when they wanted to sleep. Electric light in the evening delayed their circadian phase. A more stringent study conducted in 1999 by Harvard University estimated the natural human rhythm to be closer to 24 hours, 11 minutes: much closer to the solar day but still not perfectly in sync.
Biological markers and effects.
The classic phase markers for measuring the timing of a mammal's circadian rhythm are:
For temperature studies, subjects must remain awake but calm and semi-reclined in near darkness while their rectal temperatures are taken continuously. Though variation is great among normal chronotypes, the average human adult's temperature reaches its minimum at about 05:00 (5 a.m.), about two hours before habitual wake time. Baehr et al. found that, in young adults, the daily body temperature minimum occurred at about 04:00 (4 a.m.) for morning types but at about 06:00 (6 a.m.) for evening types. This minimum occurred at approximately the middle of the eight-hour sleep period for morning types, but closer to waking in evening types.
Melatonin is absent from the system or undetectably low during daytime. Its onset in dim light, "dim-light melatonin onset" (DLMO), at roughly 21:00 (9 p.m.) can be measured in the blood or the saliva. Its major metabolite can also be measured in morning urine. Both DLMO and the midpoint (in time) of the presence of the hormone in the blood or saliva have been used as circadian markers. However, newer research indicates that the melatonin "offset" may be the more reliable marker. Benloucif et al. found that melatonin phase markers were more stable and more highly correlated with the timing of sleep than the core temperature minimum. They found that both sleep offset and melatonin offset are more strongly correlated with phase markers than the onset of sleep. In addition, the declining phase of the melatonin levels is more reliable and stable than the termination of melatonin synthesis.
Other physiological changes that occur according to a circadian rhythm include heart rate and many cellular processes "including oxidative stress, cell metabolism, immune and inflammatory responses, epigenetic modification, hypoxia/hyperoxia response pathways, endoplasmic reticular stress, autophagy, and regulation of the stem cell environment. In a study of young men, it was found that the heart rate reaches its lowest average rate during sleep, and it's highest average rate shortly after waking. 
In contradiction to previous studies, it has been found that there is no effect of body temperature on performance on psychological tests. This is likely due to evolutionary pressures for higher cognitive function compared to the other areas of function examined in previous studies.
Outside the "master clock".
More-or-less independent circadian rhythms are found in many organs and cells in the body outside the suprachiasmatic nuclei (SCN), the "master clock". These clocks, called peripheral oscillators, are found in the adrenal gland, oesophagus, lungs, liver, pancreas, spleen, thymus, and skin. Though oscillators in the skin respond to light, a systemic influence has not been proven. There is also some evidence that the olfactory bulb and prostate may experience oscillations when cultured, suggesting that these structures may also be weak oscillators.
Furthermore, liver cells, for example, appear to respond to feeding rather than to light. Cells from many parts of the body appear to have free-running rhythms.
Light and the biological clock.
Light resets the biological clock in accordance with the phase response curve (PRC). Depending on the timing, light can advance or delay the circadian rhythm. Both the PRC and the required illuminance vary from species to species and lower light levels are required to reset the clocks in nocturnal rodents than in humans.
Enforced longer cycles.
Studies by Nathaniel Kleitman in 1938 and by Derk-Jan Dijk and Charles Czeisler in the 1990s put human subjects on enforced 28-hour sleep–wake cycles, in constant dim light and with other time cues suppressed, for over a month. Because normal people cannot entrain to a 28-hour day in dim light if at all, this is referred to as a forced desynchrony protocol. Sleep and wake episodes are uncoupled from the endogenous circadian period of about 24.18 hours and researchers are allowed to assess the effects of circadian phase on aspects of sleep and wakefulness including sleep latency and other functions.
Human health.
Timing of medical treatment in coordination with the body clock may significantly increase efficacy and reduce drug toxicity or adverse reactions.
A number of studies have concluded that a short period of sleep during the day, a power-nap, does not have any measurable effect on normal circadian rhythms but can decrease stress and improve productivity.
Health problems can result from a disturbance to the circadian rhythm. Circadian rhythms also play a part in the reticular activating system, which is crucial for maintaining a state of consciousness. A reversal in the sleep–wake cycle may be a sign or complication of uremia, azotemia or acute renal failure.
Studies have also shown that light has a direct effect on human health because of the way it influences the circadian rhythms.
Circadian Lighting.
According to Mark Rea, lighting with regards to circadian health is very different from stimuli that affect the visual system; in brief, the light energy needed to affect the circadian system is non-visual and generally requires more energy than the visual system. Additionally, the light arriving at the eye must be defined in terms of not only intensity, distribution, duration and temporal patterns but spectrum as well.
Obesity and diabetes.
Obesity and diabetes are associated with lifestyle and genetic factors. Among those factors, disruption of the circadian clockwork and/or misalignment of the circadian timing system with the external environment (e.g., light-dark cycle) might play a role in the development of metabolic disorders.
Shift-work or chronic jet-lag have profound consequences on circadian and metabolic events in the body. Animals that are forced to eat during their resting period show increased body mass and altered expression of clock and metabolic genes. In humans, shift-work that favors irregular eating times is associated with altered insulin sensitivity and higher body mass. Shift-work also leads to increased metabolic risks for cardio-metabolic syndrome, hypertension, inflammation.
Airline pilots.
Due to the work nature of airline pilots, who often cross several timezones and regions of sunlight and darkness in one day, and spend many hours awake both day and night, they are often unable to maintain sleep patterns that correspond to the natural human circadian rhythm; this situation can easily lead to fatigue. The NTSB cites this as contributing to many accidents and has conducted several research studies in order to find methods of combating fatigue in pilots.
Disruption.
Disruption to rhythms usually has a negative effect. Many travellers have experienced the condition known as jet lag, with its associated symptoms of fatigue, disorientation, and insomnia.
A number of other disorders, for example bipolar disorder and some sleep disorders such as delayed sleep phase disorder (DSPD), are associated with irregular or pathological functioning of circadian rhythms.
Disruption to rhythms in the longer term is believed to have significant adverse health consequences on peripheral organs outside the brain, in particular in the development or exacerbation of cardiovascular disease. Blue LED lighting suppresses melatonin production five times more than the orange-yellow high-pressure sodium (HPS) light; a metal halide lamp, which is white light, suppresses melatonin at a rate more than three times greater than HPS. Depression symptoms from long term nighttime light exposure can be undone by returning to a normal cycle.
Effect of drugs.
Studies conducted on both animals and humans show major bidirectional relationships between the circadian system and abusive drugs. It is indicated that these abusive drugs affect the central circadian pacemaker. Individuals suffering from substance abuse display disrupted rhythms. These disrupted rhythms can increase the risk for substance abuse and relapse. It is possible that genetic and/or environmental disturbances to the normal sleep and wake cycle can increase the susceptibility to addiction.
It is difficult to determine if a disturbance in the circadian rhythm is at fault for an increase in prevalence for substance abuse or if other environmental factors such as stress are to blame.
Changes to the circadian rhythm and sleep occur once an individual begins abusing drugs and alcohol. Once an individual chooses to stop using drugs and alcohol, the circadian rhythm continues to be disrupted.
The stabilization of sleep and the circadian rhythm might possibly help to reduce the vulnerability to addiction and reduce the chances of relapse.
Circadian rhythms and clock genes expressed in brain regions outside the suprachiasmatic nucleus may significantly influence the effects produced by drugs such as cocaine. Moreover, genetic manipulations of clock genes profoundly affect cocaine's actions.

</doc>
<doc id="56566" url="https://en.wikipedia.org/wiki?curid=56566" title="Chronobiology">
Chronobiology

Chronobiology is a field of biology that examines periodic (cyclic) phenomena in living organisms and their adaptation to solar- and lunar-related rhythms. These cycles are known as biological rhythms. Chronobiology comes from the ancient Greek χρόνος ("chrónos", meaning "time"), and biology, which pertains to the study, or science, of life. The related terms "chronomics" and "chronome" have been used in some cases to describe either the molecular mechanisms involved in chronobiological phenomena or the more quantitative aspects of chronobiology, particularly where comparison of cycles between organisms is required.
Chronobiological studies include but are not limited to comparative anatomy, physiology, genetics, molecular biology and behavior of organisms within biological rhythms mechanics. Other aspects include development, reproduction, ecology and evolution.
Description.
The variations of the timing and duration of biological activity in living organisms occur for many essential biological processes. These occur (a) in animals (eating, sleeping, mating, hibernating, migration, cellular regeneration, etc.), (b) in plants (leaf movements, photosynthetic reactions, etc.), and in microbial organisms such as fungi and protozoa. They have even been found in bacteria, especially among the cyanobacteria (aka blue-green algae, see bacterial circadian rhythms). The most important rhythm in chronobiology is the circadian rhythm, a roughly 24-hour cycle shown by physiological processes in all these organisms. The term "circadian" comes from the Latin "circa", meaning "around" and "dies", "day", meaning "approximately a day." It is regulated by circadian clocks.
The circadian rhythm can further be broken down into routine cycles during the 24-hour day:
While circadian rhythms are defined as endogenously regulated, other biological cycles may be regulated by exogenous signals. In some cases, multi-trophic systems may exhibit rhythms driven by the circadian clock of one of the members (which may also be influenced or reset by external factors). The endogenous plant cycles may regulate the activity of the bacterium by controlling availability of plant-produced photosynthate.
Many other important cycles are also studied, including:
Within each cycle, the time period during which the process is more active is called the "acrophase". When the process is less active, the cycle is in its "bathyphase" or "trough" phase. The particular moment of highest activity is the "peak" or "maximum"; the lowest point is the "nadir". How high (or low) the process gets is measured by the "amplitude".
History.
A circadian cycle was first observed in the 18th century in the movement of plant leaves by the French scientist Jean-Jacques d'Ortous de Mairan. In 1751 Swedish botanist and naturalist Carl Linnaeus (Carl von Linné) designed a flower clock using certain species of flowering plants. By arranging the selected species in a circular pattern, he designed a clock that indicated the time of day by the flowers that were open at each given hour. For example, among members of the daisy family, he used the hawk's beard plant which opened its flowers at 6:30 am and the hawkbit which did not open its flowers until 7 am. 
The 1960 symposium at Cold Spring Harbor Laboratory laid the groundwork for the field of chronobiology.
It was also in 1960 that Patricia DeCoursey invented the phase response curve, one of the major tools used in the field since.
Franz Halberg of the University of Minnesota, who coined the word "circadian", is widely considered the "father of American chronobiology." However, it was Colin Pittendrigh and not Halberg who was elected to lead the "Society for Research in Biological Rhythms" in the 1970s. Halberg wanted more emphasis on the human and medical issues while Pittendrigh had his background more in evolution and ecology. With Pittendrigh as leader, the Society members did basic research on all types of organisms, plants as well as animals. More recently it has been difficult to get funding for such research on any other organisms than mice, rats, humans and fruit flies.
Recent developments.
More recently, light therapy and melatonin administration have been explored by Dr. Alfred J. Lewy (OHSU), Dr. Josephine Arendt (University of Surrey, UK) and other researchers as a means to reset animal and human circadian rhythms. Additionally, the presence of low-level light at night accelerates circadian re-entrainment of hamsters of all ages by 50%; this is thought to be related to simulation of moonlight.
Humans can be morning people or evening people; these variations are called chronotypes for which there are various assessment tools and biological markers.
In the second half of 20th century, substantial contributions and formalizations have been made by Europeans such as Jürgen Aschoff and Colin Pittendrigh, who pursued different but complementary views on the phenomenon of entrainment of the circadian system by light (parametric, continuous, tonic, gradual vs. nonparametric, discrete, phasic, instantaneous, respectively; see this historical article, subscription required).
There is also a food-entrainable biological clock, which is not confined to the suprachiasmatic nucleus. The location of this clock has been disputed. Working with mice, however, Fuller "et al." concluded that the food-entrainable clock seems to be located in the dorsomedial hypothalamus. During restricted feeding, it takes over control of such functions as activity timing, increasing the chances of the animal successfully locating food resources.
Other fields.
Chronobiology is an interdisciplinary field of investigation. It interacts with medical and other research fields such as sleep medicine, endocrinology, geriatrics, sports medicine, space medicine and photoperiodism.
In spite of the similarity of the name to legitimate biological rhythms, the theory and practice of biorhythms is a classic example of pseudoscience. It attempts to describe a set of cyclic variations in human behavior based on a person's birth date. It is not a part of chronobiology.

</doc>
<doc id="56567" url="https://en.wikipedia.org/wiki?curid=56567" title="Hyperbolic function">
Hyperbolic function

In mathematics, hyperbolic functions are analogs of the ordinary trigonometric, or circular functions. The basic hyperbolic functions are the hyperbolic sine "sinh" ( or ), and the hyperbolic cosine "cosh" (), from which are derived the hyperbolic tangent "tanh" ( or ), hyperbolic cosecant "csch" or "cosech" ( or ), hyperbolic secant "sech" ( or ), and hyperbolic cotangent "coth" ( or ), corresponding to the derived trigonometric functions. The inverse hyperbolic functions are the area hyperbolic sine "arsinh" (also called "asinh" or sometimes "arcsinh") and so on.
Just as the points (cos "t", sin "t") form a circle with a unit radius, the points (cosh "t", sinh "t") form the right half of the equilateral hyperbola. The hyperbolic functions take a real argument called a hyperbolic angle. The size of a hyperbolic angle is twice the area of its hyperbolic sector. The hyperbolic functions may be defined in terms of the legs of a right triangle covering this sector.
Hyperbolic functions occur in many linear differential equations, for example the equation defining a catenary, of some cubic equations, in calculations of angles and distances in hyperbolic geometry and of Laplace's equation in Cartesian coordinates. Laplace's equations are important in many areas of physics, including electromagnetic theory, heat transfer, fluid dynamics, and special relativity.
In complex analysis, the hyperbolic functions arise as the imaginary parts of sine and cosine. When considered defined by a complex variable, the hyperbolic functions are rational functions of exponentials, and are hence meromorphic.
Hyperbolic functions were introduced in the 1760s independently by Vincenzo Riccati and Johann Heinrich Lambert. Riccati used "Sc." and "Cc." ("circulare") to refer to circular functions and "Sh." and "Ch." ("[cosinus hyperbolico") to refer to hyperbolic functions. Lambert adopted the names but altered the abbreviations to what they are today. The abbreviations "sh" and "ch" are still used in some other languages, like French and Russian.
Standard analytic expressions.
The hyperbolic functions are:
Hyperbolic functions can be introduced via imaginary circular angles:
where "i" is the imaginary unit with the property that .
The complex forms in the definitions above derive from Euler's formula.
Special meanings.
Hyperbolic cosine.
It can be shown that the area under the curve of cosh ("x") over a finite interval is always equal to the arc length corresponding to that interval:
Hyperbolic tangent.
The hyperbolic tangent is the solution to the differential equation formula_20 with f(0)=0 and the nonlinear boundary value problem:
Useful relations.
Odd and even functions:
Hence:
It can be seen that cosh "x" and sech "x" are even functions; the others are odd functions.
Hyperbolic sine and cosine satisfy: 
the last which is similar to the Pythagorean trigonometric identity.
One also has
for the other functions.
Sums of arguments.
particularly
Also:
Subtraction formulas.
Also:
Source.
Second derivatives.
The second derivatives of sinh and cosh are the same function:
All functions with this property are linear combinations of sinh and cosh, notably the exponential functions formula_51 and formula_52, and the zero function formula_53.
Standard integrals.
formula_54
The following integrals can be proved using hyperbolic substitution:
formula_55
where "C" is the constant of integration.
Taylor series expressions.
It is possible to express the above functions as Taylor series:
The function sinh "x" has a Taylor series expression with only odd exponents for "x". Thus it is an odd function, that is, −sinh "x" = sinh(−"x"), and sinh 0 = 0.
The function cosh "x" has a Taylor series expression with only even exponents for "x". Thus it is an even function, that is, symmetric with respect to the "y"-axis. The sum of the sinh and cosh series is the infinite series expression of the exponential function.
where:
Comparison with circular functions.
The hyperbolic functions represent an expansion of trigonometry beyond the circular functions. Both types depend on an argument, either circular angle or hyperbolic angle.
Since the area of a circular sector with radius "r" and angle "u" is formula_61 it will be equal to "u" when "r" = square root of 2. In the diagram such a circle is tangent to the hyperbola "xy" = 1 at (1,1). The yellow sector depicts an area and angle magnitude. Similarly, the yellow and red sectors together depict an area and hyperbolic angle magnitude.
The legs of the two right triangles with hypotenuse on the ray defining the angles are of length √2 times the circular and hyperbolic functions.
Mellon Haskell of University of California, Berkeley described the basis of hyperbolic functions in areas of hyperbolic sectors in an 1895 article in Bulletin of the American Mathematical Society (see External links). He refers to the hyperbolic angle as an invariant measure with respect to the squeeze mapping just as circular angle is invariant under rotation.
Identities.
The hyperbolic functions satisfy many identities, all of them similar in form to the trigonometric identities. In fact, Osborn's rule states that one can convert any trigonometric identity into a hyperbolic identity by expanding it completely in terms of integral powers of sines and cosines, changing sine to sinh and cosine to cosh, and switching the sign of every term which contains a product of 2, 6, 10, 14, ... sinhs. This yields for example the addition theorems
the "double argument formulas"
and the "half-argument formulas"
The derivative of sinh "x" is cosh "x" and the derivative of cosh "x" is sinh "x"; this is similar to trigonometric functions, albeit the sign is different (i.e., the derivative of cos "x" is −sin "x").
The Gudermannian function gives a direct relationship between the circular functions and the hyperbolic ones that does not involve complex numbers.
The graph of the function "a" cosh("x"/"a") is the catenary, the curve formed by a uniform flexible chain hanging freely between two fixed points under uniform gravity.
Relationship to the exponential function.
From the definitions of the hyperbolic sine and cosine, we can derive the following identities:
and
These expressions are analogous to the expressions for sine and cosine, based on Euler's formula, as sums of complex exponentials.
Hyperbolic functions for complex numbers.
Since the exponential function can be defined for any complex argument, we can extend the definitions of the hyperbolic functions also to complex arguments. The functions sinh "z" and cosh "z" are then holomorphic.
Relationships to ordinary trigonometric functions are given by Euler's formula for complex numbers:
so:
Thus, hyperbolic functions are periodic with respect to the imaginary component, with period formula_72 (formula_73 for hyperbolic tangent and cotangent).

</doc>
<doc id="56568" url="https://en.wikipedia.org/wiki?curid=56568" title="Pleiades">
Pleiades

In astronomy, the Pleiades ( or ), or Seven Sisters (Messier 45 or M45), is an open star cluster containing middle-aged hot B-type stars located in the constellation of Taurus. It is among the nearest star clusters to Earth and is the cluster most obvious to the naked eye in the night sky. The celestial entity has several meanings in different cultures and traditions.
The cluster is dominated by hot blue and extremely luminous stars that have formed within the last 100 million years. Dust that forms a faint reflection nebulosity around the brightest stars was thought at first to be left over from the formation of the cluster (hence the alternative name Maia Nebula after the star Maia), but is now known to be an unrelated dust cloud in the interstellar medium, through which the stars are currently passing. Computer simulations have shown that the Pleiades was probably formed from a compact configuration that resembled the Orion Nebula. Astronomers estimate that the cluster will survive for about another 250 million years, after which it will disperse due to gravitational interactions with its galactic neighborhood.
Origin of name.
The name of the Pleiades comes from Ancient Greek. It probably derives from "plein" ('to sail') because of the cluster's importance in delimiting the sailing season in the Mediterranean Sea: 'the season of navigation began with their heliacal rising'. However, the name was later mythologised as the name of seven divine sisters, whose name was imagined to derive from that of their mother Pleione, effectively meaning 'daughters of Pleione'. In reality, the name of the star-cluster almost certainly came first, and Pleione was invented to explain it.
Observational history.
The Pleiades are a prominent sight in winter in the Northern Hemisphere, and have been known since antiquity to cultures all around the world, including the Celts, Māori, Aboriginal Australians, the Persians, the Arabs (who called them "Thurayya"), the Chinese, the Japanese, the Maya, the Aztec, the Sioux and the Cherokee. In Hinduism, the Pleiades are known as Krittika and are associated with the war-god Kartikeya (Murugan, Skanda), who derives his name from them. The god is raised by the six Krittika sisters, also known as the Matrikas. He is said to have developed a face for each of them.
The Babylonian star catalogues name the Pleiades MUL.MUL or "star of stars", and they head the list of stars along the ecliptic, reflecting the fact that they were close to the point of vernal equinox around the 23rd century BC. The Ancient Egyptians may have used the names "Followers" and "Ennead" in the prognosis texts of the Calendar of Lucky and Unlucky Days of papyrus Cairo 86637. The earliest known depiction of the Pleiades is likely a bronze age artifact known as the Nebra sky disk, dated to approximately 1600 BC. Some Greek astronomers considered them to be a distinct constellation, and they are mentioned by Hesiod, and in Homer's "Iliad" and "Odyssey". They are also mentioned three times in the Bible (Job 9:9 and 38:31, as well as Amos 5:8). Some scholars of Islam suggested that the Pleiades (ath-thurayya) are the star mentioned in the sura (chapter) Najm of the Quran.
In Japan, the constellation is mentioned under the name Mutsuraboshi ("six stars") in the 8th century Kojiki and Manyosyu documents. The constellation is also known in Japan as Subaru (“unite”) and is depicted in the six-star logo and name of the Subaru automobile company. The Persian equivalent is Nahid (pronounced "Naheed").
The rising of the Pleiades is mentioned in the Ancient Greek text "Geoponica". The Greeks oriented the Hecatompedon temple of 550 BC and the Parthenon of 438 BC to their rising. The rising of the Pleiades before dawn (usually at the beginning of June) has long been regarded as the start of the new year in Māori culture, with the star group being known as "Matariki". The rising of Matariki is celebrated as a midwinter festival in New Zealand. In Hawaiian culture the cluster is known as the Makali'i and their rising shortly after sunset marks the beginning of Makahiki, a 4-month time of peace in honor of the god Lono.
Galileo Galilei was the first astronomer to view the Pleiades through a telescope. He thereby discovered that the cluster contains many stars too dim to be seen with the naked eye. He published his observations, including a sketch of the Pleiades showing 36 stars, in his treatise "Sidereus Nuncius" in March 1610.
The Pleiades have long been known to be a physically related group of stars rather than any chance alignment. The Reverend John Michell calculated in 1767 that the probability of a chance alignment of so many bright stars was only 1 in 500,000, and so correctly surmised that the Pleiades and many other clusters of stars must be physically related. When studies were first made of the stars' proper motions, it was found that they are all moving in the same direction across the sky, at the same rate, further demonstrating that they were related.
Charles Messier measured the position of the cluster and included it as M45 in his catalogue of comet-like objects, published in 1771. Along with the Orion Nebula and the Praesepe cluster, Messier's inclusion of the Pleiades has been noted as curious, as most of Messier's objects were much fainter and more easily confused with comets—something that seems scarcely possible for the Pleiades. One possibility is that Messier simply wanted to have a larger catalogue than his scientific rival Lacaille, whose 1755 catalogue contained 42 objects, and so he added some bright, well-known objects to boost his list.
Edme-Sébastien Jeaurat then drew in 1782 a map of 64 stars of the Pleiades from his observations in 1779, which he published in 1786.
Distance.
The distance to the Pleiades can be used as an important first step to calibrate the cosmic distance ladder. As the cluster is so close to the Earth, its distance is relatively easy to measure and has been estimated by many methods. Accurate knowledge of the distance allows astronomers to plot a Hertzsprung-Russell diagram for the cluster, which, when compared to those plotted for clusters whose distance is not known, allows their distances to be estimated. Other methods can then extend the distance scale from open clusters to galaxies and clusters of galaxies, and a cosmic distance ladder can be constructed. Ultimately astronomers' understanding of the age and future evolution of the universe is influenced by their knowledge of the distance to the Pleiades. Yet some authors argue that the controversy over the distance to the Pleiades discussed below is a red herring, since the cosmic distance ladder can (presently) rely on a suite of other nearby clusters where consensus exists regarding the distances as established by Hipparcos and independent means (e.g., the Hyades, Coma Berenices cluster, etc.).
Measurements of the distance have elicited much controversy. Results prior to the launch of the Hipparcos satellite generally found that the Pleiades were about 135 parsecs away from Earth. Data from Hipparcos yielded a surprising result, namely a distance of only 118 parsecs by measuring the parallax of stars in the cluster—a technique that should yield the most direct and accurate results. Later work consistently argued that the Hipparcos distance measurement for the Pleiades was erroneous. In particular, distances derived to the cluster via the Hubble Space Telescope and infrared color-magnitude diagram fitting favor a distance between 135–140 pc; a dynamical distance from optical interferometric observations of the Pleiad double Atlas favors a distance of 133-137 pc. However, the author of the 2007–2009 catalog of revised Hipparcos parallaxes reasserted that the distance to the Pleiades is ~120 pc, and challenged the dissenting evidence. Recently, Francis and Anderson proposed that a systematic effect on Hipparcos parallax errors for stars in clusters biases calculation using the weighted mean, and gave a Hipparcos parallax distance of 126 pc, and photometric distance 132 pc based on stars in the AB Doradus, Tucana-Horologium, and Beta Pictoris moving groups, which are all similar in age and composition to the Pleiades. Those authors note that the difference between these results can be attributed to random error.
The latest result (August, 2014) used very long baseline radio interferometry (VLBI) to determine a distance of 136.2 ± 1.2 pc, thereby claiming "that the "Hipparcos" measured distance to the Pleiades cluster is in error."
Composition.
The cluster core radius is about 8 light years and tidal radius is about 43 light years. The cluster contains over 1,000 statistically confirmed members, although this figure excludes unresolved binary stars. It is dominated by young, hot blue stars, up to 14 of which can be seen with the naked eye depending on local observing conditions. The arrangement of the brightest stars is somewhat similar to Ursa Major and Ursa Minor. The total mass contained in the cluster is estimated to be about 800 solar masses.
The cluster contains many brown dwarfs, which are objects with less than about 8% of the Sun's mass, not heavy enough for nuclear fusion reactions to start in their cores and become proper stars. They may constitute up to 25% of the total population of the cluster, although they contribute less than 2% of the total mass. Astronomers have made great efforts to find and analyse brown dwarfs in the Pleiades and other young clusters, because they are still relatively bright and observable, while brown dwarfs in older clusters have faded and are much more difficult to study.
Age and future evolution.
Ages for star clusters can be estimated by comparing the Hertzsprung-Russell diagram for the cluster with theoretical models of stellar evolution. Using this technique, ages for the Pleiades of between 75 and 150 million years have been estimated. The wide spread in estimated ages is a result of uncertainties in stellar evolution models, which include factors such as convective overshoot, in which a convective zone within a star penetrates an otherwise non-convective zone, resulting in higher apparent ages.
Another way of estimating the age of the cluster is by looking at the lowest-mass objects. In normal main sequence stars, lithium is rapidly destroyed in nuclear fusion reactions. Brown dwarfs can retain their lithium, however. Due to lithium's very low ignition temperature of 2.5 million kelvin, the highest-mass brown dwarfs will burn it eventually, and so determining the highest mass of brown dwarfs still containing lithium in the cluster can give an idea of its age. Applying this technique to the Pleiades gives an age of about 115 million years.
The cluster is slowly moving in the direction of the feet of what is currently the constellation of Orion. Like most open clusters, the Pleiades will not stay gravitationally bound forever. Some component stars will be ejected after close encounters with other stars; others will be stripped by tidal gravitational fields. Calculations suggest that the cluster will take about 250 million years to disperse, with gravitational interactions with giant molecular clouds and the spiral arms of our galaxy also hastening its demise.
Reflection nebulosity.
Under ideal observing conditions, some hint of nebulosity may be seen around the cluster, and this shows up in long-exposure photographs. It is a reflection nebula, caused by dust reflecting the blue light of the hot, young stars.
It was formerly thought that the dust was left over from the formation of the cluster, but at the age of about 100 million years generally accepted for the cluster, almost all the dust originally present would have been dispersed by radiation pressure. Instead, it seems that the cluster is simply passing through a particularly dusty region of the interstellar medium.
Studies show that the dust responsible for the nebulosity is not uniformly distributed, but is concentrated mainly in two layers along the line of sight to the cluster. These layers may have been formed by deceleration due to radiation pressure as the dust has moved towards the stars.
Brightest stars.
The nine brightest stars of the Pleiades are named for the Seven Sisters of Greek mythology: Sterope, Merope, Electra, Maia, Taygeta, Celaeno, and Alcyone, along with their parents Atlas and Pleione. As daughters of Atlas, the Hyades were sisters of the Pleiades. The English name of the cluster itself is of Greek origin (Πλειάδες), though of uncertain etymology. Suggested derivations include: from πλεῖν "plein", "to sail," making the Pleiades the "sailing ones"; from πλέος "pleos", "full, many"; or from πελειάδες "peleiades", "flock of doves." The following table gives details of the brightest stars in the cluster:
Possible planets.
Analyzing deep-infrared images obtained by the Spitzer Space Telescope and Gemini North telescope, astronomers discovered that one of the cluster's stars – HD 23514, which has a mass and luminosity a bit greater than that of the Sun, is surrounded by an extraordinary number of hot dust particles. This could be evidence for planet formation around HD 23514.

</doc>
<doc id="56569" url="https://en.wikipedia.org/wiki?curid=56569" title="Ashgabat">
Ashgabat

Ashgabat (, ; ; ), known as Poltoratsk () between 1919 and 1927, is the capital and the largest city of Turkmenistan in Central Asia, situated between the Karakum Desert and the Kopet Dag mountain range. The 2001 census estimated a population of 695,300, while the 2009 census estimated a population of 1 million, primarily Turkmen people, with ethnic minorities of Russians, Armenians, and Azerbaijanis.
The Karakum Canal runs through the city, carrying waters from the Amu Darya from east to west.
Names.
Ashgabat is called "Aşgabat" in Turkmen, ("Ashkhabad") in Russian, and "Ešq-ābād" () in Persian. Before 1991, the city was usually spelled Ashkabad in English, a transliteration of the Russian form, which was itself from the original Persian form. It has also been variously spelled Ashkhabat and Ashgabad. From 1919 until 1927 the city was renamed Poltoratsk after a local revolutionary.
The name in Persian means "city of love" or "city of devotion". Some Turkmen scholars insist that the name goes back to the Parthian era, 3rd century BC, deriving from the name of the founder of the Parthian Empire, Arsaces I of Parthia, in Persian Ashk-Abad (the city of "Ashk"/Arsaces).
History.
Ashgabat is a relatively young city, having been founded in 1881 as a fortification and named after the nearby settlement of Askhabad (lit. "beloved city" in Turkmen). Located not far from the site of Nisa, the ancient capital of the Parthian Empire, it grew on the ruins of the Silk Road city of Konjikala, first mentioned as a wine-producing village in the 2nd century BC and leveled by an earthquake in the 1st century BC (a precursor of the 1948 Ashgabat earthquake). Konjikala was rebuilt because of its advantageous location on the Silk Road and it flourished until its destruction by Mongols in the 13th century. After that it survived as a small village until Russians took over in the 19th century.
A part of Persia until the Battle of Geok Tepe, Askhabad was ceded to the Russian Empire under the terms of the Akhal Treaty. Russia developed the area as it was close to the border of British-influenced Persia. It was regarded as a pleasant town with European style buildings, shops, and hotels. In 1908, the first Bahá'í House of Worship was built in Askhabat. It was badly damaged in the 1948 earthquake and finally demolished in 1963. The community of the Bahá'í Faith in Turkmenistan was largely based in Ashgabat.
Soviet rule was established in Ashgabat in December 1917. However, in July 1918, a coalition of Mensheviks, Social Revolutionaries, and Tsarist former officers of the Imperial Russian Army revolted against the Bolshevik rule emanating from Tashkent and established the Ashkhabad Executive Committee. After receiving some support (but even more promises) from General Malleson, the British withdrew in April 1919 and the Tashkent Soviet resumed control of the city.
In 1919, the city was renamed Poltoratsk (), after Pavel Poltoratsky, the Chairman of the Soviet of National Economy of the Turkestan Autonomous Soviet Socialist Republic. When the Turkmen SSR was established in 1924, Poltoratsk became its capital. The original name (in the form of "Ashkhabad") was restored in 1927. From this period onward, the city experienced rapid growth and industrialisation, although severely disrupted by a major earthquake on October 6, 1948. An estimated 7.3 on the Richter scale, the earthquake killed 110-176,000 (⅔ of the population of the city), although the official number announced by Soviet news was only 40,000.
In July 2003, all the names of streets in Ashgabat were replaced by serial numbers except nine major highways, some named after Saparmurat Niyazov, his father and mother. The Central Palace area is designated 2000 to symbolize the beginning of the 21st century. The rest of the streets have larger or smaller four-digit numerical names.
In 2013, the city was included in the "Guinness Book of Records" as the world's highest concentration of white marble buildings.
Ashgabat milestones:
Districts.
Ashgabat is divided into the following districts:
In 2013, in the city of Ashgabat formed districts:
Architecture.
First Baha'i Temple in the world.
When Ashgabat was under Russian rule, the number of Bahá'ís in the city rose to over 1,000, and a Bahá'í community was established, with its own schools, medical facilities, cemetery. The community elected one of the first Bahá'í local administrative institutions. In 1908 the Bahá'í community completed the construction of the first Bahá'í House of Worship, sometimes referred to by its Arabic name of "mašriqu-l-'aḏkār" (), where people of all religions may worship God without denominational restrictions. The building was designed under the guidance of `Abdu'l-Bahá by Ustad' Ali-Akbar Banna Yazdi who also wrote a history of the Baha'is in Ashgabat.
The House of Worship itself was surrounded by gardens with four buildings at the four corners of the gardens: a school, a hostel where travelling Bahá'ís were entertained, a small hospital, and a building for groundskeepers.
Under the Soviet policy towards religion, the Bahá'ís, strictly adhering to their principle of obedience to legal government, abandoned these properties in 1928. For the decade between 1938 and 1948, when it was seriously damaged by the earthquake, it was an art gallery. It was demolished in 1963.
After 1991.
After exiting the Soviet Union, the city gained many high-rise residential buildings. Modern construction techniques allows high-rise development (mainly 12-storeys) with relatively good protection against earthquakes. Primarily consisting of residential towers, the first floor is typically given a shopping area and a service department. Many of the buildings are made of white marble. The Arch of Neutrality was dismantled and re-erected in its original form in the south of the capital. Turkmenistan Tower, at a height of 211 meters, is the tallest building in the country.
Ashgabat is primarily a government and administrative centre. The business centre of Ashgabat is on the Archabil highway. Construction of several ministries and departments, teaching and research and cultural centres is complete. Development of office buildings and public spaces along the avenue continues.
Economy.
The principal industries are cotton textiles and metal working. It is a major stop on the Trans-Caspian railway. A large percentage of the employment in Ashgabat is provided by the state institutions; such as the ministries, undersecretariats, and other administrative bodies of the Turkmenistan government. There are also many foreign citizens working as diplomats or clerks in the embassies of their respective countries. Ashgabat lends its name to the Ashgabat agreement, signed by India, Oman, Iran, Turkmenistan, Uzbekistan and Kazakhstan, for creating an international transport and transit corridor facilitating transportation of goods between Central Asia and the Persian Gulf.
Industry.
More than 43 large and 128 medium-sized industrial enterprises along with over 1,700 small industrial facilities are located in Ashgabat and its suburbs. The most important are “Ashneftemash”, “Turkmenkabel”, “Turkmenbashi Textile Complex” etc.
Shopping.
Both locals and visitors go to Altyn Asyr Bazaar in Choganly, where myriads of items, including traditional fabrics and hand-woven carpets, can be bought. Modern shopping areas are mostly found in central streets, including the modern Turkish mall Ýimpaş and shopping centers Paýtagt and Aşgabat. The local residents like traditional bazaars: Russian bazaar, Teke bazaar, Daşoguz bazaar, Mir bazaar, Jennet bazaar, etc.
Transportation.
The city is served by the Ashgabat International Airport. Turkmenistan Airlines has its headquarters in the city. Ashgabat offers air service to and from all the major cities of the Turkmenistan, as well as some destinations in Asia and Europe, especially in countries that are members of the CIS. Ashgabat is served by the following foreign airlines: Belavia, Lufthansa, Turkish Airlines, S7 Airlines, flydubai, China Southern Airlines and Uzbekistan Airways.
The Trans-Caspian Railway (Turkmenbashi - Balkanabat - Bereket - Ashgabat - Mary - Türkmenabat) runs through Ashgabat from east to west. Since 2006 there as also been a train line towards the north, the Trans Karakum railway. In May 2009 the restoration of Ashgabat railway station was completed.
In Ashgabat there are two intercity bus stations, one located near the Teke Bazaar, the second at the old airport. There are daily buses to Archman, Dashoguz and Turkmenabat. The new International Passenger Bus Terminal of Ashgabat was commissioned in September 5, 2014.
Public transport in the city consists mainly of buses. More than 60 bus lines cover a total range of more than with 700 buses running on urban routes. Currently the city primarily uses Mercedes-Benz and Hyunda buses. Bus timetables and detailed schematic map of the route are at every stop. Distances between stops are about 300–500 meters. From October 19, 1964 to December 31, 2011 the city also had the Ashgabat trolleybus system. At the beginning of the twentieth century narrow-gauge railway operated by steam-power, connecting the city with the suburbs Firyuza.
On 18 October 2006, the Ashgabat Cable Car opened, connecting the city with the foothills of the Kopetdag.
In 2016 was opened Ashgabat Monorail, the first monorail in the Central Asia.
Science and education.
Ashgabat is the most important educational center of Turkmenistan with a large number of places of education. Turkmen State University was founded in 1950: the main university building is located in Saparmurat Turkmenbashi Avenue. The Turkmen State Medical University is situated in Ashgabat also: it reports to the Ministry of Health and the medical industry of Turkmenistan. Other prominent institutions are the Turkmen State Institute of Economics and Management, a main business school founded in 1980, as well as the Turkmen State Institute of Architecture and Construction and The National Institute of Sports and Tourism of Turkmenistan. There is only one foreign university - International Turkmen-Turkish University.
Climate.
The Kopet-Dag mountain range is about to the south, and Ashgabat's northern boundary touches the Kara-Kum desert. Because of this Ashgabat has an arid climate with hot, dry summers and cool, short winters. The average high temperature in July is . Nighttimes in the summer are warm, with an average minimum temperature in July of . The average January high temperature is , and the average low temperature is . The highest temperature ever recorded in Ashgabat is , recorded in June 1995. A low temperature of was recorded in January 1969. Snow is infrequent in the area. Annual precipitation is only ; March and April are the wettest months.
Notable buildings.
Museums include the Turkmen Fine Arts Museum and Turkmen Carpet Museum, noted for their impressive collection of woven carpets as well as a Turkmen history museum and the Ashgabat National Museum of History, which displays artifacts dating back to the Parthian and Persian civilizations. The Academy of Sciences of Turkmenistan is an important institute of higher learning. Ashgabat was also home to the Arch of Neutrality, a 250-foot-tall tripod crowned by a golden statue of late president Saparmurat Niyazov (also known as Turkmenbashi, or leader of all Turkmen). The 50-foot-high statue, which rotated in order to always face the sun during daylight hours, was removed on August 26, 2010 after Niyazov’s successor, current President Gurbanguly Berdimuhamedov, made it clear earlier in the year that the statue was going to be taken out of Ashgabat’s parliament square. In 2011 a Monument to the Constitution was built, the total height - 185 meters, makes it the second tallest building in Turkmenistan.
Alem Cultural and Entertainment Center was recognised by "Guinness World Records" as the world's tallest Ferris wheel in an enclosed space. The Ashgabat Flagpole is the fourth tallest free-standing flagpole in the world, standing at tall. The Ashgabat Fountain is the worlds greatest number of fountain pools in a public place. Ashgabat also features Turkmenistan Tower which is the tallest tower in Turkmenistan, the decorative octagonal Star of Oguzkhan is recognized as the world's largest architectural image of the star and entered in the Guinness World Records.
Parks and squares.
Ashgabat has many parks and open spaces mainly established in the early years of the Independence and well maintained and expanded thereafter. The most important of these parks are: the Botanical Garden, Güneş, Turkmen-Turkish friendship, Independence. The oldest city park - Ashgabat, was founded in 1887. In the center of Ashgabat is the Inspiration Alley, an art-park complex which is a favorite place for many locals. The amusement park World of Turkmenbashi Tales is a local equivalent to Disneyland. Squares: 10 Years of Turkmenistan Independence, Magtymguly, Eternal Flame, Zelili, Chyrchyk, Garashsyzlyk, March 8, Gerogly, Dolphin, 15 years of Independence, Ruhyýet, 10 ýyl Abadançylyk.
Halk Hakydasy Memorial Complex.
Halk Hakydasy Memorial Complex was opened in 2014 in remembrance of those killed in Battle of Geok Tepe, World War II and to commemorate of the victims of the 1948 Ashgabat earthquake. It is located in south-western part of the city.
Cinemas.
Ashgabat has several cinemas. In 2011, Aşgabat Cinema, the first 3D cinema in Turkmenistan, opened in Ashgabat. The Watan and Turkmenistan theaters were reconstructed.
Sports.
The main sporting venues in Ashgabat are the Olympic Stadium, Ashgabat Stadium, the National Olympic ice rink, Sports complex for winter sports and the Olympic water sports complex.
Ashgabat has been chosen as the host city of the V Asian Indoor Games and Martial Arts, and was also the first city in Central Asia to host the Asian Indoor Games. In 2010, an Olympic Village was built in the south of the city. It is aimed to be completed by 2015, at a cost of $5 billion.
The city's professional football clubs Altyn Asyr, FC Ashgabat, HTTU Aşgabat and FC Hazyna play in the Ýokary Liga, the top flight of Turkmenistan.
International relations.
Twin towns and sister cities.
Ashgabat is twinned with:

</doc>
<doc id="56571" url="https://en.wikipedia.org/wiki?curid=56571" title="Guignol">
Guignol

Guignol is the main character in a French puppet show which has come to bear his name. It represents the workers in the silk industry of France.
Although often thought of as children's entertainment, Guignol's sharp wit and linguistic verve have always been appreciated by adults as well, as shown by the motto of a prominent Lyon troupe: "Guignol amuses children… and witty adults".
Laurent Mourguet, Guignol's creator, was born into a family of modest silk weavers on March 3, 1769. The certificate of his marriage to Jeanne Esterle in 1788 shows he was unable to read. When hard times fell on the silk trade during the French Revolution, he became a peddler, and in 1797 started to practice dentistry, which in those days was simply the pulling of teeth. The service was free; the money was made from the medicines sold afterward to ease the pain. To attract patients, he started setting up a puppet show in front of his dentist's chair.
His first shows featured Polichinelle, a character borrowed from the Italian commedia dell'arte who in England would become Punch. By 1804 the success was such that he gave up dentistry altogether and became a professional puppeteer, creating his own scenarios drawing on the concerns of his working-class audience and improvising references to the news of the day. He developed characters closer to the daily lives of his Lyon audience, first Gnafron, a wine-loving cobbler, and in 1808 Guignol. Other characters, including Guignol's wife Madelon and the gendarme Flageolet soon followed, but these are never much more than foils for the two heroes.
Although nominally a silkweaver like much of his original audience, Guignol's profession changes, as does his marital status; he can be in turn valet, peddler, carpenter, shoemaker, or unemployed; at times he is Madelon's husband, at times her smitten suitor according to requirements of the scenario. What remain constant are his poverty, but more importantly his good humor and his sense of justice. The use in French of "guignol" as an insult meaning "buffoon" is a curious misnomer, as Guignol is clever, courageous and generous; his inevitable victory is always the triumph of good over evil. 
Sixteen of Mourguet's children and grandchildren continued his tradition, and many of the companies performing today can trace their heritage back to him. According to the era, the region, or the performers, Guignol's original caustic satire has often been watered down to simple children's fare, and has even been used to parody grand opera, but his original spirit still survives in his hometown of Lyon, where both traditional and original contemporary performances are an integral part of local culture. In addition to his social satire, Guignol has become an important protector of the local dialect, the "parler lyonnais".

</doc>
<doc id="56573" url="https://en.wikipedia.org/wiki?curid=56573" title="Messier">
Messier

Messier can refer to:

</doc>
<doc id="56574" url="https://en.wikipedia.org/wiki?curid=56574" title="Maria Edgeworth">
Maria Edgeworth

Maria Edgeworth (1 January 1768 – 22 May 1849) was a prolific Anglo-Irish writer of adults' and children's literature. She was one of the first realist writers in children's literature and was a significant figure in the evolution of the novel in Europe. She held advanced views, for a woman of her time, on estate management, politics and education, and corresponded with some of the leading literary and economic writers, including Sir Walter Scott and David Ricardo.
Life.
Early life.
Maria Edgeworth was born at Black Bourton, Oxfordshire. She was the second child of Richard Lovell Edgeworth (who eventually fathered 22 children by four wives) and Anna Maria Edgeworth ("née" Elers); Maria was thus an aunt of Francis Ysidro Edgeworth. She spent her early years with her mother's family in England, until her mother's death when Maria was five. When her father married his second wife Honora Sneyd in 1773, she went with him to his estate, Edgeworthstown, in County Longford, Ireland.
Maria was sent to Mrs. Lattafière's school in Derby after Honora fell ill in 1775. When Honora died in 1780 and Maria's father married Honora's sister Elizabeth (considered somewhat shocking in that time's moral climate), Maria transferred to Mrs. Devis's school in London. Her father's attention became fully focused on her in 1781 when she nearly lost her sight to an eye infection. Returning home at the age of 14, she took charge of her many younger siblings and was home-tutored in law, Irish economics and politics, science, and literature by her father. She also started her lifelong correspondences with learned men, mainly members of the Lunar Society.
She became her father's assistant in managing the Edgeworthstown estate, which had become run-down during the family's 1777–1782 absence; she would live and write there for the rest of her life. With their bond strengthened, Maria and her father began a lifelong academic collaboration "of which she was the more able and nimble mind." Present at Edgeworthstown was an extended family, servants and tenants. She observed and recorded the details of daily Irish life, later drawing on this experience for her novels about the Irish. She also mixed with the Anglo-Irish gentry, particularly Kitty Pakenham (later the wife of Arthur Wellesley, 1st Duke of Wellington), Lady Moira, and her aunt Margaret Ruxton of Black Castle. Margaret supplied her with the novels of Anne Radcliffe and William Godwin and encouraged her in her writing.
Travels.
In 1798 Richard married Frances Beaufort, daughter of Daniel Augustus Beaufort, who instigated the idea of travelling to England and the European continent. Frances, a year younger than Maria, became her lifelong confidante. The family travelled first to London in 1800.
In 1802 the Edgeworths toured the English midlands. They then travelled to the continent, first to Brussels and then to Consulate France (during the Peace of Amiens, a brief lull in the Napoleonic Wars). They met all the notables, and Maria received a marriage proposal from a Swedish courtier, Count Edelcrantz. Her letter on the subject seems very cool, but her stepmother assures us in the Augustus Hare "Life and Letters" that Maria loved him very much and did not get over the affair quickly. They came home to Ireland in 1803 on the eve of the resumption of the wars and Maria returned to writing. "Tales of Fashionable Life", "The Absentee" and "Ormond" are novels of Irish life. Edgeworth was an extremely popular author who was compared with her contemporary writers Jane Austen and Sir Walter Scott. She initially earned more than them, and used her income to help her siblings.
On a visit to London in 1813, where she was received as a literary lion, Maria met Lord Byron (whom she disliked) and Humphry Davy. She entered into a long correspondence with the ultra-Tory Sir Walter Scott after the publication of "Waverley" in 1814, in which he gratefully acknowledged her influence, and they formed a lasting friendship. She visited him in Scotland at Abbotsford House in 1823, where he took her on a tour of the area. The next year, Sir Walter visited Edgeworthstown. When passing through the village, one of the party wrote, "We found neither mud hovels nor naked peasantry, but snug cottages and smiles all about." A counterview was provided by another visitor who stated that the residents of Edgeworthstown treated Edgeworth with contempt, refusing even to feign politeness.
Later life.
Richard Edgeworth was comparatively fair and forgiving in his dealings with his tenants and was actively involved in the estate's management. After debating the issue with the economist David Ricardo, Maria came to believe that better management and the further application of science to agriculture would raise food production and lower prices. Both Richard and Maria were also in favour of Catholic Emancipation, enfranchisement for Catholics without property restrictions (although he admitted it was against his own interest), agricultural reform and increased educational opportunities for women. She particularly worked hard to improve the living standards of the poor in Edgeworthstown. In trying to improve conditions in the village she provided schools for the local children of all denominations.
After her father's death in 1817 she edited his memoirs, and extended them with her biographical comments. She was an active writer to the last.
She worked for the relief of the famine-stricken Irish peasants during the Irish Potato Famine. She wrote "Orlandino" for the benefit of the Relieve Fund. Her letters to the Quaker Relief Committee provide a vivid account of the desperate plight facing the tenants in Edgeworthstown, the extreme conditions under which they lived, and the struggle to obtain whatever aid and assistance she could to alleviate their plight. Through her efforts she received gifts for the poor from America.
During the Irish Famine Edgeworth insisted that only those of her tenants who had paid their rent in full would receive relief. Edgeworth also punished those of her tenants who voted against her Tory preferences.
With the election of William Rowan Hamilton to president of the Royal Irish Academy, Maria became a dominant source of advice for Hamilton, particularly on the issue of literature in Ireland. She suggested that women should be allowed to participate in events held by the academy. For her guidance and help, Hamilton made Edgeworth an honorary member of the Royal Irish Academy in 1837, following in the footsteps of Louisa Beaufort, a former member of the academy and a relative of hers.
After a visit to see her relations in Trim, Maria, now in her eighties, began to feel heart pains and died suddenly of a heart attack in Edgeworthstown on 22 May 1849.
Views.
Though Maria Edgeworth spent most of her childhood in England, her life in Ireland had a profound impact on both her thinking and views surrounding her Irish culture. Fauske and Kaufman conclude, " used her fiction to address the inherent problems of acts delineated by religious, national, racial, class based, sexual, and gendered identities." Edgeworth used works such "Castle Rackrent" and "Harrington" to express her feelings on controversial issues.
Ireland.
In her works, Edgeworth created a nostalgic past of Ireland in an attempt to celebrate Irish culture.
Suvendrini Perera said Edgeworth's novels traced "the gradual anglicanization of feudal Irish society." Edgeworth's goal in her works was to show the Irish as equal to the English, and therefore warranting equal, though not separate, status.
"Essay on Irish Bulls" rejects an English stereotype of Irishmen and portrays them accurately in realistic, everyday settings. This is a common theme in her Irish works, combating the caricatured Irish with accurate representations. In her work Edgeworth also places focus on the linguistic differences between Irish and English societies, as a foil to how dynamic and intricate Irish society was in spite of English stereotypes.
Edgeworth's writing of Ireland, especially her early Irish tales, offer an important rearticulation of Burkean local attachment and philosophical cosmopolitanism to produce an understanding of the nation as neither tightly bordered (like nations based on historical premises such as blood or inheritance) or not borderless (like those based on rational notions of universal inclusion). Edgeworth used her writing to reconsider the meaning of the denomination "Anglo-Irish", and through her interrogation she reinterpreted both cosmopolitan and national definitions of belonging so as to reconstitute "Anglo-Irish" less as a category than as an ongoing mediation between borders. In Edgeworth's Irish novels, education is the key to both individual and national improvement, according to Edgeworth, "it is the foundation of the well-governed estate and the foundation of the well-governed nation". More specifically, a slow process of education instills transnational understanding in the Irish people while retaining the bonds of local attachment by which the nation is secured. The centrality of education not only suggests Edgeworth's wish for a rooted yet cosmopolitan or transnational judgment, but also distinguishes her writing from constructions of national identity as national character, linking her through to earlier cosmopolitan constructions of universal human subjects. By claiming national difference as anchored in education, culture rather than nature, Edgeworth gives to national identity a sociocultural foundation, and thereby opens a space in which change can happen.
Social.
Maria agreed with the Act of Union, but thought that it should not be passed against the wishes of the Irish people. Concerning education, she thought boys and girls should be educated equally and together, drawing upon Rousseau's ideas.
She believed a woman should only marry someone who suits her in "character, temper, and understanding." Becoming an old maid was preferable to an incompatible union.
The story "Vivian" from "Tales of Fashionable Life" and "Patronage" attack eighteenth-century English Whig governance of Ireland as corrupt and unrepresentative.
Edgeworth strove for the self-realization of women and stressed the importance of the individual. She also wanted greater participation in politics by middle class women. Her work "Helen" clearly demonstrates this point in the passage:
"Women are now so highly cultivated, and political subjects are at present of so much importance, of such high interest, to all human creatures who live together in society, you can hardly expect, Helen, that you, as a rational being, can go through the world as it now is, without forming any opinion on points of public importance. You cannot, I conceive, satisfy yourself with the common namby-pamby little missy phrase, 'ladies have nothing to do with politics'."
She sympathised with Catholics and supported gradual, though not immediate, Catholic Emancipation.
Education.
To help illustrate the care that must be taken in teaching children and to emphasise the necessity of properly directing and managing their attentiveness, Maria Edgeworth drew several comparisons with non-European peoples. In her 1798 book "Practical Education" she maintained that unnecessarily causing fatigue should be a great concern of educators. In making the point that any mode of instruction that tired the attention was hurtful to children, her reasoning was that people can pay attention only to one thing at a time, and because children can appear resistant to repetition, teachers naturally should vary things. However, educators should always be mindful of the fact that, "while variety relieves the mind, the objects which are varied must not all be entirely new, for novelty and variety when joined, fatigue the mind" as Edgeworth states. The teaching of children needed to follow carefully considered methods, needed to evidence concern for appropriateness and proper sequencing, and needed to be guided by consideration from forms of teaching that would be empowering and enabling, not fatiguing or disabling. In Edgeworth's work, the attention of the child appears as a key site for pedagogical work and interventions.
Work.
Edgeworth's early literary efforts have often been considered melodramatic rather than realistic. Recent scholarship, however, has uncovered the importance of Edgeworth's previously unpublished juvenilia manuscript, "The Double Disguise" (1786). In particular, "The Double Disguise" signals Edgeworth's turn toward realism and is now considered a seminal regional narrative predating "Castle Rackrent" (1800). In addition, Edgeworth wrote many children's novels that conveyed moral lessons to their audience (often in partnership with her friend Louise Swanton Belloc, a French writer, translator, and advocate for the education of women and children, whose many translations of Edgeworth's works were largely responsible for her popularity in France). One of her schoolgirl novels features a villain who wore a mask made from the skin of a dead man's face. Edgeworth's first published work was "Letters for Literary Ladies" in 1795. Her work, "An Essay on the Noble Science of Self-Justification" (1795) is written for a female audience in which she convinces women that the fair sex is endowed with an art of self-justification and women should use their gifts to continually challenge the force and power of men, especially their husbands, with wit and intelligence. It humorously and satirically explores the feminine argumentative method. This was followed in 1796 by her first children's book, "The Parent's Assistant", which included Edgeworth's celebrated short story "The Purple Jar". "The Parent's Assistant" was influenced by her father's work and perspectives on children's education.
Mr. Edgeworth, a well-known author and inventor, encouraged his daughter's career. At the height of her creative endeavours, Maria wrote, "Seriously it was to please my Father I first exerted myself to write, to please him I continued." Though the impetus for Maria's works, Mr. Edgeworth has been criticised for his insistence on approving and editing her work. The tales in "The Parent's Assistant" were approved by her father before he would allow them to be read to her younger siblings. It is speculated that her stepmother and siblings also helped in the editing process of Edgeworth's work.
"Practical Education" (1798) is a progressive work on education that combines the ideas of Locke and Rousseau with scientific inquiry. Edgeworth asserts that "learning should be a positive experience and that the discipline of education is more important during the formative years than the acquisition of knowledge." The system attempted to "adapt both the curriculum and methods of teaching to the needs of the child; the endeavour to explain moral habits and the learning process through associationism; and most important, the effort to entrust the child with the responsibility for his own mental culture." The ultimate goal of Edgeworth's system was to create an independent thinker who understands the consequences of their actions.
Her first novel, "Castle Rackrent" (1800) was written and submitted for anonymous publication in 1800 without her father's knowledge. It was an immediate success and firmly established Edgeworth's appeal. The book is a satire on Anglo-Irish landlords, before the year 1782, showing the need for more responsible management by the Irish landowning class. The story follows four generations of an Irish landholding family, the Rackrents. It is narrated by an Irish catholic worker on the estate, named Thady Quirk, and portrayed the rise of the catholic-Irish middle class.
"Belinda" (1801), a 3-volume work published in London, was Maria Edgeworth's first full-length novel. It dealt with love, courtship, and marriage, dramatising the conflicts within her "own personality and environment; conflicts between reason and feeling, restraint and individual freedom, and society and free spirit." "Belinda" was also notable for its controversial depiction of interracial marriage between an African servant and an English farm-girl. Later editions of the novel, however, removed these sections.
"Tales of Fashionable Life" (1809 and 1812) is a 2-series collection of short stories which often focus on the life of a woman. The second series was particularly well received in England, making her the most commercially successful novelist of her age. After this, Edgeworth was regarded as the preeminent woman writer in England alongside Jane Austen.
Following an anti-Semitic remark in "The Absentee", Edgeworth received a letter from an American Jewish woman named Rachel Mordecai in 1815 complaining about Edgeworth's depiction of Jews. In response, "Harrington" (1817) was written as an apology to the Jewish community. The novel was a fictitious autobiography about overcoming antisemitism and includes one of the first sympathetic Jewish characters in an English novel.
"Helen" (1834) is Maria Edgeworth's final novel, the only one she wrote after her father's death. She chose to write a novel focused on the characters and situation, rather than moral lessons. In a letter to her publisher, Maria wrote, "I have been reproached for making "my moral" in some stories too prominent. I am sensible of the inconvenience of this both to reader and writer & have taken much pains to avoid it in "Helen"." Her novel is also set in England, a conscious choice as Edgeworth found Ireland too troubling for a fictitious work in the political climate of the 1830s.
Style and purpose.
Having come to her literary maturity at a time when the ubiquitous and unvarying stated defence of the novel was its educative power, Maria Edgeworth was among the few authors who truly espoused the educator's role. Her novels are morally and socially didactic in the extreme. A close analysis of the alterations which Edgeworth's style underwent when it was pressed into the service of overt didacticism should serve to illuminate the relationship between prose technique and didactic purpose in her work. The convention which Maria Edgeworth has adopted and worked to death is basic to the eighteenth-century novel, but its roots like in the drama, tracing at least to the Renaissance separation of high and low characters by their forms of speech. Throughout the eighteenth-century drama, and most noticeably in the sentimental comedy, the separation becomes more and more a means of moral judgment as well as social identification. The only coherent reason for Edgeworth's acceptance is the appeal of didactic moralism. In the first place, she is willing to suspend judgment wherever the service of the moral is the result. Everything else may go, so long as the lesson is enforced. the lesson might be a warning against moral impropriety, as in Miss Milner's story, or against social injustice, as in "The Absentee". Furthermore, the whole reliance on positive exemplars had been justified long before by Steele, who argued that the stage must supply perfect heroes since its examples are imitated and since simple natures are incapable of making the necessary deductions from the negative exemplars of satire.
The characteristic of Edgeworth is to connect an identifiable strain of formal realism, both philosophical and rhetorical, and therefore display an objective interest in human nature and the way it manifests itself in social custom. One would expect this from Edgeworth, an author whose didacticism often has struck modern readers as either gendered liability, technical regression, or familial obligation. Critics have responded to Edgeworth's eccentricities by attributing them to something more deep-seated, temperamental, and psychological. In their various, often insightful representation, Edgeworth's fondness for the real, the strange, and the pedagogically useful verges on the relentless, the obsessive, and the instinctive. There is an alternative literary answer to explain Edgeworth's cultural roots and ideological aims which shifts focus away from Edgeworth's familial, psychological, and cultural predicaments to the formal paradigms by which her work has been judged. Rather than locating Edgeworth's early romances of real life exclusively within the traditions of eighteenth-century children's literature or domestic realism, they can be read primarily as responses to late eighteenth-century debates over the relation between history and romance, because the genre attempts to mediate between the two differentiating itself from other kinds of factual fiction. Edgeworth's romances of real life operate in the same discursive field but do not attempt to traverse between self-denied antinomies. In fact, they usually make the opposite claim.
Edgeworth's repeated self-effacement needs to be seen in the context of the times, where learning in women was often disapproved of and even riduculed, such as the satirical poem of the Rev. Richard Polwhele, "The Unsex'd Females" (1798).
Legacy.
During the period 1800–1814 (when Walter Scott's "Waverley" was published) Edgeworth was the most celebrated and successful living English novelist. Her reputation equalled that of Fanny Burney (Madame d'Arblay) (1752–1840) earlier, in a time that saw a number of other women writers including Elizabeth Hamilton, Amelia Opie, Hannah More, Elizabeth Inchbald. Her only potential male competitor prior to Scott was William Godwin. She was certainly well received by the critics and literary figures of her time. Croker (1780–1857) compared her work to "Don Quixote" and "Gil Blas" and to the work of Henry Fielding, while Francis Jeffrey (1773–1850) called her work 'perfect'.
The Ulster Gaelic Society, established in 1830, succeeded in a single publication in its history, namely the translation into Irish of two stories by Maria Edgeworth: Tomás Ó Fiannachtaigh translated "Forgive and Forget" and "Rosanna" into Irish in the 1830s.

</doc>
<doc id="56575" url="https://en.wikipedia.org/wiki?curid=56575" title="Castle Rackrent">
Castle Rackrent

Castle Rackrent, a short novel by Maria Edgeworth published in 1800, is often regarded as the first historical novel, the first regional novel in English, the first Anglo-Irish novel, the first Big House novel and the first saga novel.
It is also widely regarded as the first novel to use the device of a narrator who is both unreliable and an observer of, rather than a player in, the actions he chronicles. Kirkpatrick suggests that it "both borrows from and originates a variety of literary genres and subgenres without neatly fitting into any one of them". William Butler Yeats pronounced "Castle Rackrent" "one of the most inspired chronicles written in English".
Shortly before its publication, an introduction, glossary and footnotes, written in the voice of an English narrator, were added to the original text to blunt the negative impact the Edgeworths feared the book might have on English enthusiasm for the Act of Union 1800.
The novel is one of the few of Edgeworth's novels which her father did not 'edit'.
Plot summary.
The novel is set prior to the Constitution of 1782 and tells the story of four generations of Rackrent heirs through their steward, Thady Quirk. The heirs are: the dissipated spendthrift Sir Patrick O'Shaughlin, the litigious Sir Murtagh Rackrent, the cruel husband and gambling absentee Sir Kit Rackrent, and the generous but improvident Sir Condy Rackrent. Their sequential mismanagement of the estate is resolved through the machinations—and to the benefit—of the narrator's astute son, Jason Quirk.
Themes and style.
It satirises Anglo-Irish landlords and their overall mismanagement of the estates they owned at a time when the English and Irish parliaments were working towards formalising their union through the Acts of Union. Through this and other works, Edgeworth is credited with serving the political, national interests of Ireland and the United Kingdom the way Sir Walter Scott did for Scotland.
It is a dialogic novel, comprising a preface and conclusion by an editor bookending a first person narrative proper. It also has a glossary (which was a last-minute addition).

</doc>
<doc id="56576" url="https://en.wikipedia.org/wiki?curid=56576" title="Humphrey B. Bear">
Humphrey B. Bear

Humphrey B Bear is an Australian children's television series and its fictional character namesake is an icon of Australian children's television. "Humphrey B Bear" was first broadcast on Adelaide's NWS-9 on Monday, 24 May 1965. The show became one of the most successful programs for pre-schoolers in Australia. The part of Humphrey was played by Edwin Duryea, an actor, singer and dancer whose human identity was never revealed.
The character of Humphrey is a tall, shaggy brown bear with a large, glossy nose, straw boater, tartan waist-coat and oversized yellow bow-tie. His television show always features a companion who assists and narrates Humphrey's various adventures in the "magic forest" including his brightly coloured tree house. The show is shot on television studio set. In the early days the character was known as Bear Bear and was named Humphrey B Bear as the result of an on air competition. Note that there is no full-stop after the B in Humphrey's middle name.
Television show.
The show has won Logies for Best Children's Series and the Humphrey character has received national awards and commendations, including a special "Citizen of the Year" Award at the 1994 Australia Day celebrations. "Humphrey B Bear" has viewers all over the world thanks to the United States version of his show shown on PBS in America and the versions shown on Galavision.
Each episode of Humphrey is designed to entertain and educate its audience as they join in the fun with the character of Humphrey B Bear. Humphrey enjoys exploring and pretending. He likes playing, singing, dancing and being with his friends.
The writers of "Humphrey" including Anthony O'Donohue (also long time host of the show) attempt to set up each show as a new adventure for Humphrey that parallels the needs, fears and fun of the average four-year-old child. The character of Humphrey B Bear explores life as they do, trying to reinforce their self-esteem and showing them it's all right to make mistakes (after all everyone does). The series attempts to show that it is not always necessary to be the best at everything, but that it's more important to simply take part.
On 14 February 2007 it was reported that the Nine Network would record a new "Here's Humphrey" series for the first time since 2003.
In April 2009, Banksia Productions, the company that owned the rights to the character, was wound up by the Supreme Court over a $50,000 debt.
In February 2012, Imagination Ventures, the philanthropic enterprise of media company Imagination Entertainment, purchased the assets of Banksia Productions and the rights to the character from the administrator.
In May 2012 Humphrey was announced as the official 'Ambassabear' for the Women & Children's Hospital Foundation and he was introduced to a new generation of children. His first major fundraising effort saw the release of a limited edition gift set featuring a Humphrey plush doll & DVD with all proceeds supporting the hospitals Kids FUNd program. Since then, Humphrey has reappeared across Australia featuring in live shows including school performances, community events and birthday parties.
In July 2013 Humphrey returned to national TV screens on Community Television stations in Sydney, Melbourne, Brisbane, Adelaide & Perth.
Humphrey B Bear celebrated his 50th Anniversary in 2015. 
Humphrey B Bear 55 languages.
1. English
2. German
3. Spanish
4. French
5. Italian
6. Portuguese
7. Polish
8. Czech
9. Slovak
10. Slovenian
11. Hungarian
12. Danish
13. Dutch
14. Japanese
15. Korean
16. Chinese
17. Greek
18. Thai
19. Hebrew 
20. Bosnian
21. Croatian
22. Serbian
23. Malay
24. Indonesian
25. Arabic
26. Persian
27. Urdu
28. Finnish
29. Swedish
30. Turkish
31. Latvian
32. Lithuanian
33. Russian
34. Bulgarian
35. Hindi
36. Malayalam
37. Bengali
38. Tamil
39. Telugu
40. Kannada
41. Armenian
42. Romanian
43. Ukrainian
44. Vietnamese
45. Welsh
46. Georgian
47. Galician
48. Swahili
49. Icelandic
50. Catalan
51. Norwegian
52. Punjabi
53. Albanian
54. Serbo-Croatian
55. Tagalog 

</doc>
<doc id="56577" url="https://en.wikipedia.org/wiki?curid=56577" title="The Absentee">
The Absentee

The Absentee is a novel by Maria Edgeworth, published in 1812 in "Tales of Fashionable Life", that expresses the systemic evils of the absentee landlord class of Anglo-Irish and the desperate condition of the Irish peasantry. 
Just before coming of age, Lord Colambre, the sensitive hero of the novel, finds that his mother Lady Clonbrony's attempts to buy her way into the high society of London are only ridiculed, while his father, Lord Clonbrony, is in serious debt as a result of his wife's lifestyle. His mother wishes him to marry an heiress, Miss Broadhurst, who is a friend of Grace Nugent. However, Colambre has already fallen in love with his cousin, Grace Nugent, who lives with the family as a companion to Lady Clonbrony. Worried that his mother will pressure him into a marriage with someone he does not love, Colambre decides to leave the London social scene and visit his ancestral home in County Wicklow in Ireland.
Upon arriving in Dublin, Colambre becomes good friends with Sir James Brooke, who is a good influence on Colambre and warns him against the schemes of some new arrivals on the Dublin social scene: Lady Dashfort and her widowed daughter, Lady Isobel. It is generally known that Lady Dashfort is looking to ensnare a new, rich Irish peer for her equally unscrupulous daughter, and by any means necessary. Despite a pointed warning from Sir James, Colambre falls under the influence of the persuasive Lady Dashfort, who wishes to secure him as the next husband for Lady Isobel. Chance intelligence from a former maid in the Clonbrony household reveals to Lady Dashfort that Lord Colambre is, in fact, in love with his cousin, Grace Nugent. To discourage the match, Lady Dashfort slyly lets slip that Grace was born out of wedlock, and is therefore illegitimate. This is confirmed by letter by his mother, who while a social climber and generally frivolous, is very loving to Grace and has never told her about her parentage. Colambre is heart broken and feels he can never love a woman with such a heritage. 
He visits his family estate and discovers that his father's agents are oppressing the local peasantry and probably cheating his father as well. He reveals himself to the evil agents, and there is a race back to London, Colambre trying to stop his father from signing documents that would ruin some of the good peasants, the agent's agent trying to get the papers signed.
Colambre makes it back just in time to stop his father from ruining the people, and he then assists his father in paying off his debts, on condition that the Clonbrony family return to live in Ireland. 
The final section concerns Colambre's love for Grace and how it is discovered that she is both legitimate and an heiress. 
There are many turns of plot and lots of information about Ireland as well as Irish dialect and details of shallow London fashionable life, and the egregious results of the propertied classes treating their Irish lands as a resource to be exploited rather than as a relationship among classes and with the land.

</doc>
<doc id="56578" url="https://en.wikipedia.org/wiki?curid=56578" title="Frances Burney">
Frances Burney

Frances Burney (13 June 1752 – 6 January 1840), also known as Fanny Burney and after her marriage as Madame d'Arblay, was an English novelist, diarist and playwright. She was born in Lynn Regis, now King's Lynn, England, on 13 June 1752, to musical historian Dr. Charles Burney (1726–1814) and Esther Sleepe Burney (1725–1762). The third of six children, she was self-educated and began writing what she called her "scribblings" at the age of ten. In 1793, aged 42, she married a French exile, General Alexandre D'Arblay. Their only son, Alexander, was born in 1794. After a lengthy writing career, and travels that took her to France for more than ten years, she settled in Bath, England, where she died on 6 January 1840.
Overview of Burney's career.
Frances Burney was a novelist, diarist and playwright. She wrote in all four novels, eight plays, one biography and twenty volumes of journals and letters. She has gained critical respect in her own right, but also foreshadows such novelists of manners with a satirical bent as Jane Austen and Thackeray. She published her first novel, "Evelina", anonymously in 1778. When the book's authorship was revealed, it brought her almost immediate fame due to its unique narrative and comic strengths. She followed it with "Cecilia" in 1782, "Camilla" in 1796 and "The Wanderer" in 1814. All Burney's novels explore the lives of English aristocrats, and satirise their social pretensions and personal foibles, with an eye to larger questions such as the politics of female identity. With one exception, Burney never succeeded in having her plays performed, largely due to objections from her father, who thought that publicity from such an effort would be damaging to her reputation. The exception was "Edwy and Elgiva", which unfortunately was not well received by the public and closed after the first night's performance.
Although her novels were hugely popular during her lifetime, Burney's reputation as a writer of fiction suffered after her death at the hands of biographers and critics who felt that the extensive diaries, published posthumously in 1841, offered a more interesting and accurate portrait of 18th-century life. Today critics are returning to her novels and plays with renewed interest in her outlook on the social lives and struggles of women in a predominantly male-oriented culture. Scholars continue to value Burney's diaries as well for their candid depictions of English society in her time.
Throughout her career as a writer, her wit and talent for satirical caricature were widely acknowledged: literary figures such as Dr Samuel Johnson, Edmund Burke, Hester Thrale and David Garrick were among her admirers. Her early novels were read and enjoyed by Jane Austen, whose own title "Pride and Prejudice" derives from the final pages of "Cecilia". William Makepeace Thackeray is reported to have drawn on the first-person account of the Battle of Waterloo, recorded in her diaries, while writing "Vanity Fair".
Frances Burney's early career was deeply affected by her relationship with her father, and by the critical attentions of their family friend Samuel Crisp. Both encouraged her writing, but also employed their influence in a critical fashion, dissuading her from publishing or performing her dramatic comedies because they felt that working in the genre was inappropriate for a lady. Many feminist critics thus see her as an author whose natural talent for satire was somewhat stifled by the social pressures exerted on female authors of the age. But Burney persisted in writing despite the setbacks. When her comedies were poorly received, she returned to novel writing, and later tried her hand at tragedy. She supported both herself and her family with the proceeds of her later novels, "Camilla" and "The Wanderer".
Family life.
Frances was the third child in a family of six. Her elder siblings were Esther (Hetty) (1749–1832) and James (1750–1821), the younger Susanna Elizabeth (1755–1800), Charles (1757–1817) and Charlotte Ann (1761–1838). Of her brothers, James became an admiral and sailed with Captain James Cook on his second and third voyages. The younger Charles Burney became a well-known classical scholar. Her younger sister, Susanna, married in 1781 Molesworth Phillips, an officer in the Royal Marines who had sailed in Captain Cook's last expedition; she left a journal that is a principal eye-witness account of the Gordon Riots. Her younger half-sister, Sarah Burney (1772–1844), also became a novelist, publishing seven works of fiction of her own. Esther Sleepe Burney also bore two other boys, both named Charles, who died in infancy in 1752 and 1754.
Burney scholar Margaret Anne Doody has investigated conflicts within the Burney family that affected Burney's writing and her personal life. Doody alleged that one strain was an incestuous relationship between her brother James and their half-sister Sarah in 1798–1803, but there is no direct evidence for this and it is hard to square with Frances's affection and financial assistance to Sarah in later life.
Frances Burney’s mother, described by historians as a woman of “warmth and intelligence,” was the daughter of a French refugee named Dubois and had been brought up a Catholic. This French heritage influenced Frances Burney’s self-perception in later life, possibly contributing to her attraction and subsequent marriage to Alexandre D’Arblay. Esther Burney died when Frances was ten years old, in 1762, a loss which Frances felt throughout her life.
Frances's father, Charles Burney, was noted for his personal charm, and even more for his talents as a musician, a musicologist, a composer and a man of letters. In 1760 he moved his family to London, a decision that improved their access to the cultured elements of English society, and as a consequence their own social standing. They lived in the midst of an artistically inclined social circle that gathered round Charles at their home in Poland Street in Soho.
In 1766 Charles Burney eloped to marry for a second time, to Elizabeth Allen, the wealthy widow of a King’s Lynn wine merchant. Allen had three children of her own, and several years after the marriage the two families merged into one. This new domestic situation was unfortunately fraught with tension. The Burney children found their new stepmother overbearing and quick to anger, and they took refuge from the situation by making fun of the woman behind her back. However, their collective unhappiness served in some respects to bring them closer to one another. In 1774 the family moved again to what had been the house of Isaac Newton in St Martin's Street, Westminster, London.
Education.
Frances' sisters Esther and Susanna were favoured over Frances by their father, for what he perceived as their superior attractiveness and intelligence. At the age of eight, Frances had not yet learned the alphabet, and some scholars suggest that Burney suffered from a form of dyslexia. By the age of ten, however, she had begun to write for her own amusement. Esther and Susanna were sent by their father to be educated in Paris, while at home Frances educated herself by reading from the family collection, including Plutarch's "Lives", works by Shakespeare, histories, sermons, poetry, plays, novels and courtesy books. She drew on this material, along with her journals, when writing her first novels. Scholars who have looked into the extent of Burney’s reading and self-education find a child who was unusually precocious and ambitious, working hard to overcome a childhood disability.
A critical aspect of Frances's literary education was her relationship with a Burney family friend, the "cultivated "littérateur"" Samuel Crisp. He encouraged Burney’s writing by soliciting frequent journal-letters from her that recounted to him the goings-on in her family and social circle in London. Frances paid her first formal visit to Crisp at Chessington Hall in Surrey in 1766. Dr Burney had first made Crisp's acquaintance in about 1745 at the house of Charles Cavendish Fulke Greville. Crisp's play "Virginia", staged by David Garrick in 1754 at the request of the Countess of Coventry (née Maria Gunning), had been unsuccessful, and Crisp had retired to Chessington Hall, where he frequently entertained Dr Burney and his family.
Journal-diaries and "The History of Caroline Evelyn".
The first entry in her journal was made on 27 March 1768, addressed to "Miss Nobody". It was to extend over 72 years. A talented storyteller with a strong sense of character, Burney often wrote these "journal-diaries" as a form of correspondence with family and friends, recounting to them events from her life and her observations upon them. Her diary contains the record of her extensive reading in her father's library, as well the visits and behaviour of the various important arts personalities who came to their home. Frances and her sister Susanna were particularly close, and it was to this sister that Frances would correspond throughout her adult life, in the form of such journal-letters.
Burney was fifteen by the time her father remarried in 1767. Entries in her diaries suggest that she was beginning to feel pressure to give up her writing, as something "unladylike" that "might vex Mrs. Allen." Feeling that she had transgressed what was proper, she burnt that same year her first manuscript, "The History of Caroline Evelyn", which she had written in secret. Despite this repudiation of writing, Frances kept up her diaries and in them wrote an account of the emotions that led up to that dramatic act. She eventually recouped some of the effort that went into the first manuscript by using it as a foundation for her first novel, "Evelina", which follows the life of the fictional Caroline Evelyn's daughter.
In keeping with this sense of impropriety that Burney felt towards her own writing, she savagely edited earlier parts of her diaries in later life, destroying much of the material. Editors Lars Troide and Joyce Hemlow recovered some of this obscured material while researching their late 20th-century editions of the journals and letters.
"Evelina".
Frances Burney's first novel, "Evelina or the History of a Young Lady's Entrance into the World", was published anonymously in 1778, without her father's knowledge or permission, by Thomas Lowndes, who voiced his interest after reading its first volume and agreed to publish it upon receipt of the finished work. The novel had been rejected by a previous publisher, Robert Dodsley, who refused to print an anonymous work. Burney, who worked as her father's amanuensis, had copied the manuscript in a "disguised hand" to prevent any identification of the book with the Burneys, thinking that her own handwriting might be recognised by a publisher. It was unthinkable at the time that a young woman would deliberately put herself into the public eye by writing, and Burney's second attempt to publish the work involved the collusion of her eldest brother, who posed as its author to Lowndes. Inexperienced at negotiating with a publisher, Burney only received twenty guineas as payment for the manuscript.
The novel was a critical success, receiving praise from respected individuals, including the statesman Edmund Burke and literary critic Dr Johnson. It was admired for its comic view of wealthy English society, and for its realistic portrayal of working-class London dialects. It was even discussed by some characters in another epistolary novel of the period: Elizabeth Blower's "The Parsonage House" (1780). Burney's father read public reviews of the novel before learning that the author was his own daughter. Although the act of publication was radical for a woman at that time and of her age, he was impressed by the favourable reactions to the book and largely supported her. Certainly, he saw social advantages to having a successful published writer in the family, and was pleased that Frances had achieved recognition through her work.
Critical reception.
Written in epistolary form, "Evelina" portrays the English upper middle class from the perspective of a 17-year-old woman who has reached marriageable age. A Bildungsroman ahead of its time, "Evelina" pushed boundaries since in the 18th century, female protagonists were "relatively rare" in that genre. This comic and witty novel is ultimately a satire of the kind of oppressive masculine values that shaped a young woman's life in the 18th century, as well as of other forms of social hypocrisy. "Encyclopædia Britannica" describes "Evelina" as a "landmark in the development of the novel of manners".
In choosing to narrate the novel through a series of letters written by the protagonist, Burney made use of her own previous writing experience to recount the protagonist's views and experiences to the reader. This tactic has won praise from critics, past and present, for the direct access to events and characters that it allows to the reader, and for the narrative sophistication that it demonstrates in reversing the roles of narrator and heroine. The authors of "Women in World History" argue that she draws attention to difficulties faced by women in the 18th century, especially those surrounding questions of romance and marriage. She is described as a "shrewd observer of her times and a clever recorder of its charms and its follies". What critics have consistently found unique and interesting about her writing is the introduction and careful treatment of a female protagonist, complete with character flaws, "who must make her way in a hostile world." These are recognisable also as features of Jane Austen's writing, and show Burney's influence on the later author's work.
As testament to its popularity, the novel went through four immediate editions. In 1971 it was still considered a classic by the writers of "Encyclopædia Britannica", which stated that "addressed to the young, the novel has a quality perennially young."
Hester Thrale and Streatham.
The novel brought Frances Burney to the attention of patron of the arts Hester Thrale, who invited the young author to visit her home in Streatham. The house was a centre for literary and political conversation. Though shy by nature, Frances impressed those she met, including Dr Johnson, who would remain her friend and correspondent throughout the period of her visits, from 1779 to 1783. Mrs Thrale wrote to Dr Burney on 22 July, stating that: "Mr. Johnson returned home full of the Prayes of the Book I had lent him, and protesting that there were passages in it which might do honour to Richardson: we talk of it for ever, and he feels ardent after the dénouement; he could not get rid of the Rogue, he said." Dr Johnson's best compliments were eagerly transcribed in Frances's diary. Sojourns at Streatham occupied months at a time, and on several occasions the guests, including Frances Burney, made trips to Brighton and to Bath. As with other notable events, these experiences were recorded in letters to her family.
"The Witlings".
In 1779, encouraged by the public's warm reception of comic material in "Evelina", and with offers of help from Arthur Murphy and Richard Brinsley Sheridan, Burney began to write a dramatic comedy called "The Witlings".
The play satirised a wide segment of London society, including the literary world and its pretensions. It was not published at the time because Burney's father and the family friend Samuel Crisp thought it would offend some of the public by seeming to mock the Bluestockings, and because they had reservations about the propriety of a woman writing comedy. The play tells the story of Celia and Beaufort, lovers kept apart by their families due to "economic insufficiency".
Burney's plays came to light again in 1945 when her papers were acquired by the Berg Collection of the New York Public Library. A complete edition was published in Montreal in 1995, edited by Peter Sabor, Geoffrey Sill, and Stewart Cooke.
"Cecilia".
In 1782 she published "Cecilia, or Memoirs of an Heiress", written partly at Chessington Hall and after much discussion with Mr Crisp. The publishers, Thomas Payne and Thomas Cadell, paid Frances £250 for her novel, printed 2000 copies of the first edition, and reprinted it at least twice within a year.
The plot of "Cecilia" revolves around the heroine, Cecilia Beverley, whose inheritance from her uncle comes with the stipulation that she find a husband who will accept her name. Beset on all sides by would-be suitors, the beautiful and intelligent Cecilia's heart is captivated by a man whose family's pride in its birth and ancestry would forbid the only son-and-heir's change of name. This young man finally persuades Cecilia, against all her good judgement, to agree to marry him secretly, so that their union – and, thus, the change of name – can be presented to the family as a "fait accompli". The work received praise for the mature tone of its ironic third-person narration, but was viewed as less spontaneous than her first work, and as weighed down by the author's self-conscious awareness of her audience. Some critics claim to have found the narration intrusive, while some of her friends found the writing too closely modelled on Johnson's. Edmund Burke greatly admired the novel, but moderated his praise with a criticism of the enormous array of characters and tangled, convoluted plots.
Jane Austen seems to have been inspired by a sentence in "Cecilia" to name her famous novel "Pride and Prejudice":
“The whole of this unfortunate business," said Dr Lyster, "has been the result of pride and prejudice.”
The Royal Court.
In 1775 Frances Burney turned down a marriage proposal from one Thomas Barlow, a man whom she had met only once. Her side of the Barlow courtship is amusingly told in her journal. During the period 1782–85 she enjoyed the rewards of her successes as a novelist; she was received at fashionable literary gatherings throughout London. In 1781 Samuel Crisp died. In 1784 Dr Johnson died, and that year also saw the failure of her romance with a clergyman, George Owen Cambridge. She was 33 years old.
In 1785, thanks to her association with Mary Granville Delany, a woman known in both literary and royal circles, Frances travelled to the court of King George III and Queen Charlotte, where the Queen offered her the post of "Keeper of the Robes", with a salary of £200 per annum. Frances hesitated in taking the office, not wishing to be separated from her family, and especially resistant to any employment that would restrict the free use of her time in writing. However, unmarried at 34, she felt constrained to accept and thought that improved social status and income might allow her greater freedom to write. Having accepted the post in 1786, she developed a warm relationship with the queen and princesses that lasted into her later years, yet her anxieties proved to be accurate: the position exhausted her and left her little writing time. Her unhappiness was intensified by a poor relationship with her colleague Elizabeth Schwellenburg, co-Keeper of the Robes, who has been described as "a peevish old person of uncertain temper and impaired health, swaddled in the buckram of backstairs etiquette."
During her years in court, Burney continued to produce her journals. To her friends and to Susanna, she recounted her life in court as well as significant political events, including the public trial of Warren Hastings for "official misconduct in India". She also recorded the speeches of Edmund Burke at the trial. She was courted by an official of the royal household, Colonel Stephen Digby, but he eventually married another woman of greater wealth. The disappointment, combined with the other frustrations of her office, contributed to her failing health at this time. In 1790 she prevailed on her father (whose own career had taken a new turn when he was appointed organist at Chelsea Hospital in 1783) to request that she be released from the post, which she was. She returned to her father's house in Chelsea, but continued to receive a yearly pension of £100. She maintained a friendship with the royal family and received letters from the princesses from 1818 until 1840.
Marriage.
In 1790–91 Burney wrote four blank-verse tragedies: "Hubert de Vere", "The Siege of Pevensey", "Elberta" and "Edwy and Elgiva". Only the last was performed. Although it was one of a profusion of paintings and literary works about the early English king Eadwig to appear in the later 18th century, it met with public failure, opening in London in March for only one night.
The French Revolution began in 1789 and Burney was among the many literate English figures who sympathized with its early ideals of equality and social justice. During this period Frances became acquainted with a group of French exiles known as "Constitutionalists", who had fled to England in August 1791 and were living at Juniper Hall, near Mickleham, where Frances's sister Susanna lived. She quickly became close to General Alexandre D'Arblay, an artillery officer who had been adjutant-general to Lafayette, a hero of the French Revolution whose political views lay between those of Royalist and of Republicans. D'Arblay taught her French and introduced her to the writer Germaine de Staël.
Burney's father disapproved of the alliance because of Alexandre's poverty, his Catholicism, and his ambiguous social status as an émigré, but in spite of this they were married on 28 July 1793. The same year she produced her pamphlet "Brief Reflections relative to the Emigrant French Clergy". This short work was similar to other pamphlets produced by French sympathisers in England, calling for financial support for the revolutionary cause. It is noteworthy for the way that Burney employed her rhetorical skills in the name of tolerance and human compassion. On 18 December 1794, Frances gave birth to their son Alexander (died 19 January 1837). Her sister Charlotte's remarriage in 1798 to the pamphleteer Ralph Broome caused her and her father further consternation, as did the move by her sister Susanna and penurious brother-in-law Molesworth Phillips and their family to Ireland in 1796.
"Camilla".
The struggling young couple were saved from poverty in 1796 by the publication of Frances's "courtesy novel" "Camilla, or a Picture of Youth", a story of frustrated love and impoverishment. The first edition sold out; she made £1000 on the novel and sold the copyright for another £1000. This money was sufficient to allow them to build a house in Westhumble, which they called Camilla Cottage. Their life at this time was, by all accounts, a happy one, but the illness and death in 1800 of Frances's sister and close friend Susanna cast a shadow and brought to an end a lifelong correspondence that had been the motive and basis for most of Burney's journal writing. However, she resumed her journal writing at the request of her husband, for the benefit of her son.
Comedies.
In the period 1797–1801 Burney wrote three comedies that were not to be published in her lifetime: "Love and Fashion", "A Busy Day" and "The Woman Hater". The last is partly a reworking of subject-matter from "The Witlings", but with the satirical elements toned down and more emphasis placed on reforming her characters' faults. The play, first performed in December 2007 at the Orange Tree Theatre in Richmond, UK, retains one of the central characters, Lady Smatter – an absent-minded but inveterate quoter of poetry, perhaps meant as a comic rendering of a Bluestocking. All the other characters in "The Woman Hater" differ from those in "The Witlings".
Life in France: revolution and mastectomy.
In 1801 D'Arblay was offered service with the government of Napoleon Bonaparte in France, and in 1802 Burney and her son followed him to Paris, where they expected to remain for a year. The outbreak of the war between France and England overtook their visit, and they remained for ten years altogether. Although the conditions of their time in France left her isolated from her family, Burney was supportive of her husband's decision to move to Passy, outside Paris.
In August 1810 Burney developed pains in her breast, which her husband suspected could be due to breast cancer. Through her royal network of acquaintances she was eventually treated by several leading physicians and finally, a year later, on 30 September 1811, she underwent a mastectomy performed by "7 men in black, Dr. Larrey, M. Dubois, Dr. Moreau, Dr. Aumont, Dr. Ribe, & a pupil of Dr. Larrey, & another of M. Dubois". The operation was performed in the manner of a battlefield operation under the command of M. Dubois, then "accoucheur" (midwife or obstetrician) to the Empress Marie Louise, Duchess of Parma, and considered to be the best doctor in France. Burney was later able to describe the operation in detail, since she was conscious through most of it, as it took place before the development of anaesthetics. 
I mounted, therefore, unbidden, the Bed stead – & M. Dubois placed me upon the Mattress, & spread a cambric handkerchief upon my face. It was transparent, however, & I saw, through it, that the Bed stead was instantly surrounded by the 7 men & my nurse. I refused to be held; but when, Bright through the cambric, I saw the glitter of polished Steel – I closed my Eyes. I would not trust to convulsive fear the sight of the terrible incision. Yet – when the dreadful steel was plunged into the breast – cutting through veins – arteries – flesh – nerves – I needed no injunctions not to restrain my cries. I began a scream that lasted unintermittingly during the whole time of the incision – & I almost marvel that it rings not in my Ears still? so excruciating was the agony. When the wound was made, & the instrument was withdrawn, the pain seemed undiminished, for the air that suddenly rushed into those delicate parts felt like a mass of minute but sharp & forked poniards, that were tearing the edges of the wound. I concluded the operation was over – Oh no! presently the terrible cutting was renewed – & worse than ever, to separate the bottom, the foundation of this dreadful gland from the parts to which it adhered – Again all description would be baffled – yet again all was not over, – Dr. Larry rested but his own hand, & – Oh heaven! – I then felt the knife (rack)ling against the breast bone – scraping it! 
She sent her first-person account of this experience months later to her sister Esther without rereading it, and it remains one of the most compelling early accounts of a mastectomy. It is impossible to know today whether the breast removed was indeed cancerous or whether she suffered from mastopathy. She survived and returned to England in 1812 to visit her ailing father and to avoid young Alexander's conscription into the French army, while still in recovery from her own illness.
Charles Burney died in 1814. In 1815 Napoleon escaped from Elba. D'Arblay was then serving with the King's Guard, and he became involved in the military actions that followed. After her father's death, Burney joined her wounded husband at Trèves (Trier), and together they returned to Bath in England. Burney wrote an account of this experience and of her Paris years in her Waterloo Journal, written between 1818 and 1832. D'Arblay was rewarded with promotion to lieutenant-general but died shortly afterwards of cancer, in 1818.
"The Wanderer" and "Memoirs of Dr. Burney".
Burney published her fourth novel, "The Wanderer: Or, Female Difficulties", a few days before Charles Burney's death. Described as "a story of love and misalliance set in the French Revolution", it criticises the English treatment of foreigners during the war years. It also pillories the hypocritical social curbs put on women in general – as the heroine tries one means after another to earn an honest penny – as well as the elaborate class criteria for social inclusion or exclusion. That strong social message sits uneasily within a strange structure that might be called a melodramatic proto-mystery novel with elements of the picaresque. The heroine is no scalliwag, in fact a bit too innocent for modern taste, but she is wilful and for obscure reasons refuses to reveal her name or origin. So as she darts about the South of England as a fugitive, she arouses suspicions that it is not always easy to agree with the author are unfair or unjustified. There are a dismaying number of coincidental meetings of characters.
Some parallels of plot and attitude have been drawn between "The Wanderer" and early novels of Helen Craik, which she could have read in the 1790s.
Burney made £1500 from the first run, but the work disappointed her followers and it did not go into a second English printing, although it met her immediate financial needs. Critics felt it lacked the insight of her earlier novels. It remains interesting today for the social opinions that it conveys and for some flashes of Burney's humour and discernment of character. It was reprinted with an introduction by the novelist Margaret Drabble in the "Mothers of the Novel" series.
After her husband’s death, Burney moved to London to be nearer to her son, who was a fellow at Christ's College. In homage to her father she gathered and in 1832 published, in three volumes, the "Memoirs of Doctor Burney". The memoirs were written in a panegyric style, praising her father's accomplishments and character, and she cannibalised many of her own personal writings from years before to produce them. Always protective of her father and the family's reputation, she deliberately destroyed evidence of facts that were painful or unflattering, and was soundly criticised by her contemporaries and later by historians for doing so. Otherwise, she lived essentially in retirement, outliving her son, who died in 1837, and her sister Charlotte Broome, who died in 1838. While in Bath, Burney received visits from younger members of the Burney family, who found her a fascinating storyteller with a talent for imitating the personalities that she described. She continued to write often to members of her family.
Frances Burney died on 6 January 1840. She was buried with her son and her husband in Walcot cemetery in Bath. A gravestone was later erected in the churchyard of St Swithin's across the road. There is a Royal Society of Arts blue plaque to record her period of residence at 11 Bolton Street, Mayfair.

</doc>
<doc id="56579" url="https://en.wikipedia.org/wiki?curid=56579" title="Achondroplasia">
Achondroplasia

Achondroplasia is a common cause of dwarfism. It occurs as a sporadic mutation in approximately 80% of cases (associated with advanced paternal age) or it may be inherited as an autosomal dominant genetic disorder.
People with achondroplasia have short stature, with an average adult height of for males and for females. Achondroplastic adults are known to be as short as . If both parents of a child have achondroplasia, and both parents pass on the mutant gene, then it is very unlikely that the homozygous child will live past a few months of its life. The prevalence is approximately 1 in 25,000.
Causes.
Achondroplasia is caused by a mutation in fibroblast growth factor receptor 3 (FGFR3). In normal development FGFR3 has a negative regulatory effect on bone growth. In achondroplasia, the mutated form of the receptor is constitutively active and this leads to severely shortened bones. The effect is genetically dominant, with one mutant copy of the FGFR3 gene being sufficient to cause achondroplasia, while two copies of the mutant gene are invariably fatal (recessive lethal) before or shortly after birth (known as a lethal allele). A person with achondroplasia thus has a 50% chance of passing dwarfism to each of their offspring. People with achondroplasia can be born to parents that do not have the condition due to spontaneous mutation.
New gene mutations leading to achondroplasia are associated with a father older than the age of 35. Studies have demonstrated that new gene mutations for achondroplasia are exclusively inherited from the father and occur during spermatogenesis; it is theorized that oogenesis has some regulatory mechanism that prevents the mutation occurring in females.
There are two other syndromes with a genetic basis similar to achondroplasia: hypochondroplasia and thanatophoric dysplasia.
Diagnosis.
Achondroplasia can be detected before birth by the use of prenatal ultrasound. A DNA test can be performed before birth to detect homozygosity, wherein two copies of the mutant gene are inherited, a lethal condition leading to stillbirths. Clinical features include megalocephaly, short limbs, prominent forehead, thoracolumbar kyphosis and mid-facial hypoplasia. Complications like dental malocclusion, hydrocephalus and repeated otitis media can be observed. The risk of death in infancy is increased due to the likelihood of compression of the spinal cord with or without upper airway obstruction.
Radiologic findings.
A skeletal survey is useful to confirm the diagnosis of achondroplasia. The skull is large, with a narrow foramen magnum, and relatively small skull base. The vertebral bodies are short and flattened with relatively large intervertebral disk height, and there is congenitally narrowed spinal canal. The iliac wings are small and squared, with a narrow sciatic notch and horizontal acetabular roof. The tubular bones are short and thick with metaphyseal cupping and flaring and irregular growth plates. Fibular overgrowth is present. The hand is broad with short metacarpals and phalanges, and a trident configuration. The ribs are short with cupped anterior ends. If the radiographic features are not classic, a search for a different diagnosis should be entertained. Because of the extremely deformed bone structure, people with achondroplasia are often "double jointed". 
The diagnosis can be made by fetal ultrasound by progressive discordance between the femur length and biparietal diameter by age. The trident hand configuration can be seen if the fingers are fully extended."
Another distinct characteristic of the syndrome is thoracolumbar gibbus in infancy.
Treatment.
There is no known cure for achondroplasia even though the cause of the mutation in the growth factor receptor has been found. Although used by those without achondroplasia to aid in growth, human growth hormone does not help people with achondroplasia. However, if desired, the controversial surgery of limb-lengthening will lengthen the legs and arms of someone with achondroplasia.
Usually, the best results appear within the first and second year of therapy. After the second year of growth hormone therapy, beneficial bone growth decreases. Therefore, GH therapy is not a satisfactory long term treatment.
Gene based therapy may possibly serve as a future treatment option. BioMarin Pharmaceutical Inc. announced in 2012 the initiation of a Phase 1 study in healthy volunteers for vosoritide (BMN-111), an analog of C-type Natriuretic Peptide (CNP), for the treatment of achondroplasia. In June of 2015, BioMarin announced positive results of their Phase 2 study, stating that 10 children experienced a mean increase of 50% in their annualized growth velocity.
Epidemiology.
Achondroplasia is one of 19 congenital conditions with similar presentations, such as osteogenesis imperfecta, multiple epiphyseal dysplasia tarda, achondrogenesis, osteopetrosis, and thanatophoric dysplasia. This makes estimates of prevalence difficult, with changing and subjective diagnostic criteria over time. One detailed and long-running study in the Netherlands found that the prevalence determined at birth was only 1.3 per 100,000 live births. However, another study at the same time found a rate of 1 per 10,000.
Other animals.
Based on their disproportionate dwarfism, some dog breeds traditionally have been classified as "achondroplastic." This is the case for the dachshund, basset hound, corgi and bulldog breeds. Data from whole genome association studies in short-limbed dogs reveal a strong association of this trait with a retro-gene coding for fibroblast growth factor 4 (FGF4). Therefore, it seems unlikely that dogs and humans are achondroplastic for the same reasons. However, histological studies in some achondroplastic dog breeds have shown altered cell patterns in cartilage that are very similar to those observed in humans exhibiting achondroplasia.
A similar form of achondroplasia was found in a litter of piglets from a phenotypically normal Danish sow. The dwarfism was inherted dominant in the offspring from this litter. The piglets were born phenotypically normal but became more and more symptomatic as they reached maturity. This involved a mutation of the protein Collagen, type X, alpha 1, encoded by the COL10A1 gene. In humans a similar mutation (G595E) has been associated with Schmid metaphyseal chondrodysplasia (SMCD), a relatively mild skeletal disorder that is also associated with dwarfism.
The now-extinct Ancon sheep was created by humans through the selective breeding of common domestic sheep with achondroplasia. The average-sized torso combined with the relatively smaller legs produced by achondroplasia was valued for making affected sheep less likely to escape without affecting the amount of wool or meat each sheep produced.

</doc>
<doc id="56582" url="https://en.wikipedia.org/wiki?curid=56582" title="Khabarovsk">
Khabarovsk

Khabarovsk (; ) is the largest city and the administrative center of Khabarovsk Krai, Russia, located from the Chinese border, at the confluence of the Amur and Ussuri Rivers, about north of Vladivostok. The city also became the administrative center of the Far Eastern Federal District of Russia in 2002. It is the second largest city in the Russian Far East, after Vladivostok. As of the 2010 Census, its population was 577,441.
History.
Earliest history of the region.
The lands near the confluence of the Ussuri and the Amur Rivers, where today's Khabarovsk stands, have been populated for many centuries by Tungusic people, probably related to the Jurchens of the past and/or the Nanais of the present day. Chinese expeditions reached this area as early as the first half of the 15th century, when the fleets of the Ming eunuch Yishiha sailed several times from Jilin City all the way to Tyr on the lower Amur.
17th-century Russian explorers.
In the mid-17th century, the Amur Valley became the scene of hostilities between the Russian Cossacks, trying to expand into the region and to collect tribute from the natives, and the rising Manchu Qing Dynasty, intent on securing the region for itself.
Khabarov's Achansk.
The Russian explorers and raiders of the 1650s set up a number of more or less fortified camps ("ostrogs") on the Amur; most of them were in use for only a few months, and later destroyed. It is usually thought that the first such camp in the general area of today's Khabarovsk was the fortified winter camp named Achansk () or Achansky gorodok (), built by the Cossacks of Yerofey Khabarov in September 1651 after they had sailed to the area from the upper Amur. The fort was named after the local tribe whom Khabarov's people called "Achans". Already on October 8 the fort was unsuccessfully attacked by joint forces of Achans and Duchers (who had good reasons to hate the Cossacks, due to their rather heavy-handed tribute-extraction tactics), while many Russians were away fishing. In late November, Khabarov's people undertook a three-day campaign against the local chief Zhakshur (Жакшур) (whose name is also known in a more Russian version, Zaksor (Заксор)), collecting a large amount of tribute and announcing that the locals were now subjects of the Russian Czar. Similar campaign was waged later in winter against the Ducher chief Nechiga (Нечига), farther away from Achansk.
On March 24 (or 26), 1652, Fort Achansk was attacked by Manchu cavalry, led by Ninguta's commander Haise, reinforced by Ducher auxiliaries, but the Cossacks stood their ground in a day-long battle and even managed to seize the attackers' supply train. Once the ice on the Amur broke in the spring of 1652, Khabarov's people destroyed their fort and sailed away.
The exact location of Khabarov's Achansk has long been a subject for the debate among Russian historians and geographers. A number of locations, both upstream and downstream of today's Khabarovsk, have been proposed since Richard Maack, one of the first Russian scholars to visit the region, identified Achansk in 1859 with the ruins on Cape Kyrma, which is located on the southern (Chinese) shore of the Amur, upstream of Khabarovsk. The most widely accepted point of view is probably that of B.P. Polevoy, who believed that Khabarov's Achansk was located in the Nanai village later known as Odzhal-Bolon (), located on the left bank of the Amur, closer to Amursk than to Khabarovsk. One of his arguments was that both Khabarov's Achan (sometimes also spelled by the explorer as Otshchan, Отщан), and Wuzhala (乌扎拉) of the Chinese records of the 1652 engagement are based on the name of the Nanai clan "Odzhal" (Оджал), corresponding to the 20th-century name of the village as well. (The name of the clan was also written as "Uzala", as in the name of its best known member, Dersu Uzala).
B.P. Polevoy's view appeared to gain wide support among the Russian geographer community; petitioned by the Amur Branch of the Russian Geographical Society, the Russian Government renamed the village of Odzhal to Achan in 1977, to celebrate its connection with Khabarov's raid.
As to the Cape Kyrma ruins, thought by Maack to be the remains of Achansk, B.P. Polevoy identified them as the remains of another "ostrog" - namely, Kosogorsky Ostrog, where Onufriy Stepanov stayed a few years later.
Qing Empire.
After the Treaty of Nerchinsk (1689), the area became an uncontested part of the Qing Empire for the next century and a half. Modern historical maps of the Qing period published in China mark the site of future Khabarovsk as Boli (). All of the middle and lower Amur region was nominally part of the Jilin Province, run first out of Ninguta and later out of Jilin City.
French Jesuits who sailed along the Ussury and the Amur in 1709 prepared the first more or less precise map of the region. According to them, the indigenous Nanai people were living on the Ussury and on the Amur down to the mouth of the Dondon River (i.e., in the region including the site of the future Khabarovsk). These people were known to the Chinese as "Yupi Dazi" ("Fish skin Tartars").
From Khabarovka to Khabarovsk.
In 1858, the area was ceded to Russia under the Treaty of Aigun. The Russians founded the military outpost of Khabarovka (), named after a Russian explorer Yerofey Khabarov. The post later became an important industrial center for the region. Town status was granted in 1880; in 1893, it was given its present name.
In 1894, a department of Russian Geographical Society was formed in Khabarovsk and began initiating the foundation of libraries, theaters, and museums in the city. Since then, Khabarovsk's cultural life has flourished. Much of the local indigenous history has been well preserved in the Regional Lore Museum and Natural History Museum and in places like near the Nanai settlement of Sikhachi-Alyan, where cliff drawings from more than 13,000 years ago can be found. The Khabarovsk Art Museum exhibits a rare collection of old Russian icons.
In 1916, Khabarovsk Bridge across the Amur was completed, allowing Trans-Siberian trains to cross the river without using ferries (or temporary rail tracks over the frozen river in winter).
The Soviet years.
After the defeat of Japan in World War II, Khabarovsk was the site of the Khabarovsk War Crime Trials, in which twelve former members of the Japanese Kwantung Army and Unit 731 were put on trial for the manufacture and use of biological weapons during World War II.
Chinese Emperor Puyi, captured by Soviet troops in Manchuria, was relocated to Khabarovsk and lived there from 1945 up to 1950, when he was returned to China.
On November 5, 1956, the first phase of the city tram was commissioned. The Khabarovsk television studio began broadcasting in 1960. On 1 September 1967, the Khabarovsk Institute of Physical Education, now the Far Eastern State Academy of Physical Culture, opened. On January 14, 1971 Khabarovsk was awarded the Order of October Revolution. 1975 saw the opening of the first stage of the urban trolley. In 1976 the city hosted an international ice hockey tournament with the ball for the prize of the newspaper "Sovietskaya Rossia". In 1981 the Bandy World Championship was played in the city.
Russian Federation.
In 1996, Khabarovsk held its first mayoral elections. Paul D. Filippov, whose candidacy was supported by Governor Viktor Ishayev, was defeated. In 1998, reconstruction of the central square of Khabarovsk was completed. In May 2000, President of Russia, Vladimir Putin, decreed that new federal districts be formed, and Khabarovsk became the center of the Far Eastern Federal District.
In 2006, the Center for Cardiovascular Surgery, a high-tech medical center, was constructed according to a Russian national health project. In 2008, the train station was completely renovated, and the adjacent square was reconstructed to include fountains and an underground passage. In 2009, Khabarovsk hosted the EU-Russia summit. In 2010, the city hosted a meeting of the Great Circle of Ussuri Cossacks. On November 3, 2012, Khabarovsk was awarded the honorary title of "City of Military Glory".
Administrative and municipal status.
Khabarovsk is the administrative center of the krai and, within the framework of administrative divisions, it also serves as the administrative center of Khabarovsky District, even though it is not a part of it. As an administrative division, it is incorporated separately as the city of krai significance of Khabarovsk—an administrative unit with the status equal to that of the districts. As a municipal division, the city of krai significance of Khabarovsk is incorporated as Khabarovsk Urban Okrug.
Climate.
Khabarovsk experiences a monsoonal dry-winter humid continental climate (Köppen climate classification "Dwb").
The average annual precipitation is , mainly concentrated in the summer. In a few years, November to March hardly receive any precipitation. The driest year was 2001 with only of precipitation and the wettest was 1981 when of precipitation fell. The wettest month was August 1981 with a total precipitation of . Snowfall is common, though light, with an average maximum snow height of .
The city's extreme climate sees average highs and lows vary by around per year. The average temperature in January is and the average for July is . Extremes have ranged from in January 2011 to in June 2010.
Economy.
Primary industries include iron processing, steel milling, petroleum refining, flour milling, pharmaceutical industry, meat packing and manufacturing of various types of heavy and light machinery.
Transportation.
The city is located along the Trans-Siberian Railway. Rail distance from Moscow is ; it is a principal railway center.
Khabarovsk is served by the Khabarovsk Novy Airport with international flights to East Asia, Southeast Asia, European Russia, and Central Asia. It is also served by the Trans-Siberian Railway, the Trans-Siberian Highway (M58 and M60 Highways) and the Amur River and Ussuri River waterways.
Public transport includes: tram - 8 routes; trolleybus - 4 routes; bus and fixed-route taxi (marshrutka - approximately 100 routes).
Education.
There are the following institutions of higher education in Khabarovsk:
Tourism.
Visitors to the picturesque city of Khabarovsk are likely to enjoy walking the broad Amursky Boulevard with its many vibrant shops and perhaps visit the local market. The city's five districts stretch for along the Amur River.
Recently, there have been many renovations in the city's central part, rebuilding with historical perspective. A popular attraction for visitors is a walking tour from the Lenin Square to Utyos on Amur via Muravyov-Amursky Street, where visitors can find traditional Russian cuisine restaurants and shops with souvenirs. There are many night clubs and pubs in this area.
In Wintertime ice sculptures are on display on the cities squares and parks. Artists come from as far as Harbin in China.
Unlike Vladivostok, the city has never been closed to foreigners, despite it being the headquarters of the Far East Military District, and retains its historically international flavour. Once the capital of the Soviet Far East (from 1926 to 1938), since the demise of the Soviet Union, it has experienced an increased Asian presence. It is estimated that over one million Chinese travel to and through Khabarovsk yearly, and foreign investment by Japanese and Korean corporations has grown in recent years. The city has a multi-story shopping mall and about a dozen hotels.
Military.
The headquarters of the Russian Eastern Military District is located at 15 Serysheva Street. There is also an air base located to the east of the city.
Sports.
International events.
The city was a host to the 1981 Bandy World Championship. It also hosted the 2015 Bandy World Championship, which was visited by Prime Minister Dmitry Medvedev21 teams were expected,[http://translate.google.co.uk/translate?hl=en&sl=ru&tl=en&u=http%3A%2F%2Fitar-tass.com%2Fsport%2F1281154&sandbox=1 which would have been 4 more than the record-making 17 from the 2014 tournament. In the end, China was the only newcomer, while Canada and Ukraine withdrew, the latter for political reasons.
Twin towns and sister cities.
Khabarovsk is twinned with:

</doc>
<doc id="56590" url="https://en.wikipedia.org/wiki?curid=56590" title="New General Catalogue">
New General Catalogue

The New General Catalogue of Nebulae and Clusters of Stars (abbreviated as NGC) is a well-known catalogue of deep-sky objects compiled by John Louis Emil Dreyer in 1888 as a new version of John Herschel's "General Catalogue of Nebulae and Clusters of Stars". The NGC contains 7,840 objects, known as the NGC objects. It is one of the largest comprehensive catalogues, as it includes all types of deep space objects and is not confined to, for example, galaxies. Dreyer also published two supplements to the NGC in 1895 and 1908, known as the Index Catalogues, describing a further 5,386 astronomical objects.
Objects in the sky of the southern hemisphere are catalogued somewhat less thoroughly, but many were observed by John Herschel or James Dunlop. The NGC had many errors, but a serious if not complete attempt to eliminate them was initiated by the NGC/IC Project in 1993, after partial attempts with the "Revised New General Catalogue" (RNGC) by Jack W. Sulentic and William G. Tifft in 1973, and "NGC2000.0" by Roger W. Sinnott in 1988. The "Revised New General Catalogue and Index Catalogue" was compiled in 2009 by Wolfgang Steinicke.
Original catalogue.
The original "New General Catalogue" was compiled during the 1880s by John Louis Emil Dreyer using observations from William Herschel and his son John, among others. Dreyer had already published a supplement to Herschel's "General Catalogue of Nebulae and Clusters" (GC), containing about 1,000 new objects. In 1886, he suggested building a second supplement to the "General Catalogue", but the Royal Astronomical Society asked Dreyer to compile a new version instead. This led to the publication of the "New General Catalogue" in the "Memoirs of the Royal Astronomical Society" in 1888.
Assembling the NGC was a challenge, as Dreyer had to deal with many contradicting and unclear reports, made with a variety of telescopes with apertures ranging from 2 to 72 inches. While he did check some himself, the sheer number of objects meant Dreyer had to accept them as published by others for the purpose of his compilation. Dreyer was a careful transcriber and made few errors himself, but the catalogue nonetheless contained several errors (mostly relating to position and descriptions). He was very thorough in his referencing, which allowed future astronomers to review the original references and publish corrections to the original NGC.
"Index Catalogue".
The first major update to the NGC is the Index Catalogue of Nebulae and Clusters of Stars (abbreviated as IC), published in two parts by Dreyer in 1895 (IC I, containing 1,520 objects) and 1908 (IC II, containing 3,866 objects). It serves as a supplement to the NGC, and contains an additional 5,386 objects, collectively known as the IC objects. It summarizes the discoveries of galaxies, clusters and nebulae between 1888 and 1907, most of them made possible by photography. A list of corrections to the IC was published in 1912.
"Revised New General Catalogue".
The Revised New Catalogue of Nonstellar Astronomical Objects (abbreviated as RNGC) was compiled by Jack W. Sulentic and William G. Tifft in the early 1970s, and was published in 1973, as an update to the NGC. However, because the update had to be completed in just three summers, it failed to incorporate several previously-published corrections to the NGC data (including corrections published by Dreyer himself), and even introduced new errors.
"NGC 2000.0".
NGC 2000.0 (also known as the Complete New General Catalog and Index Catalog of Nebulae and Star Clusters) is a 1988 compilation of the NGC and IC made by Roger W. Sinnott, using the J2000.0 coordinates. It incorporates several corrections and errata made by astronomers over the years. However, it too ignored the original publications and favoured modern (but erroneous) corrections.
NGC/IC Project.
The NGC/IC Project is a collaboration formed in 1993. It aims to identify all NGC and IC objects, and collect images and basic astronomical data on them.
"Revised New General Catalogue and Index Catalogue".
The Revised New General Catalogue and Index Catalogue (abbreviated as RNGC/IC) is a compilation made by Wolfgang Steinicke in 2009. It is considered one of the most comprehensive and authoritative treatments of the NGC and IC catalogues.

</doc>
<doc id="56597" url="https://en.wikipedia.org/wiki?curid=56597" title="Antananarivo">
Antananarivo

Antananarivo ( or ; ), then temporarily French Tananarive ( or ; ), also known by its French colonial shorthand form Tana, is the capital and largest city in Madagascar. The larger urban area surrounding the city, known as Antananarivo-Renivohitra ("Antananarivo-Mother Hill" or "Antananarivo-Capital"), is the capital of Analamanga region. The city is located above the sea level in the center of the island, and has been the island's largest population center since at least the 18th century.
Antananarivo was historically the capital of the Merina people, who continue to form the majority of the city's estimated 1,300,000 (2013) inhabitants, as well as the surrounding urban areas which in all have a total metropolitan population approaching three million. All 18 Malagasy ethnic groups, as well as residents of Chinese, Indian, European and other origins, are well represented in the city.
Antananarivo is the political, economic, educational and cultural heart of Madagascar. The Presidency, National Assembly, Senate and Supreme Court are located here, as are 21 diplomatic missions and the headquarters of many national and international businesses and NGOs. Antananarivo also hosts the largest number of universities, nightclubs, art venues, medical services and other social service institutions of any city on the island. Several national and local sports teams, including the championship-winning national rugby team, the Makis, and several basketball and football teams, are based in Antananarivo.
Antananarivo was founded from about 1610 to 1625, when the Merina king Andrianjaka (1612–1630) expelled the Vazimba inhabitants of the village of Analamanga at the highest meeting point of two forested ridges rising above the surrounding highland plains. Declaring it the site of his capital, Andrianjaka built a "rova" (fortified royal dwelling) that expanded to become the royal palaces of the Kingdom of Imerina. According to oral history, he deployed a garrison of 1,000 soldiers to capture and guard the site; the hill and its city retained the name Analamanga until the reign of King Andriamasinavalona (1675–1710), who renamed it Antananarivo ("City of the Thousand") in honor of Andrianjaka's soldiers. The city served as the capital of the Kingdom of Imerina from its founding until 1710, when Imerina split into four warring quadrants. Antananarivo was declared the capital of the southern quadrant; it remained thus until King Andrianampoinimerina of Ambohimanga captured the province and restored its role as capital of a united Kingdom of Imerina in 1794. His diplomatic and military successes extended Imerina far beyond its traditional borders, bringing the lands of neighboring ethnic groups under Merina control. These conquests were continued under his son, Radama I, whose control ultimately extended over two thirds of the island, leading him to be considered the King of Madagascar by European diplomats, with Antananarivo as the island's capital. Antananarivo remained the island's capital after Madagascar was colonized by the French in 1897 and remained thus after independence in 1960. The French killed off many of the original inhabitants of the island and made French the native language.
Antananarivo has expanded gradually from the royal palaces at its center, which dominate every view from their location at the peak of a curving ridge above the surrounding Betsimitatatra plains. In the 17th century, the plains were transformed into paddy fields to meet the population's need for rice; they were covered with housing developments as the city's population grew rapidly in the 20th century. Around the palaces, which were destroyed in a 1995 fire but have since been partially reconstructed, lies the historic district that was formerly populated by members of the "andriana" (noble class); many of their homes are preserved. The Analakely valley at the base of the ridge was the site of a Friday market established in the 18th century that, until being discontinued in 1997 due to traffic congestion, was considered the largest open air market in the world. This neighborhood was further developed under French rule and continues to serve as the capital's economic heart. The city is managed by the "Commune Urbaine d'Antananarivo" (CUA) under the direction of its President of the Special Delegation, Ny Havana Andriamanjato, appointed in March 2014. Limited funds and mismanagement have hampered consecutive CUA efforts to manage overcrowding and traffic, waste management, pollution, security, public water and electricity, and other challenges linked to explosive population growth. Major historic landmarks and attractions in the city include the reconstructed royal palaces and the Andafiavaratra Palace, the tomb of Rainiharo, Tsimbazaza Zoo, Mahamasina Stadium, Lake Anosy, four 19th-century martyr cathedrals, and the Museum of Art and Archaeology.
Etymology.
Antananarivo was originally the site of a town called "Analamanga", meaning "Blue Forest" in the central highlands dialect of the Malagasy language. Analamanga was established by a community of Vazimba, the island's first occupants. Andrianjaka (approximately 1612–1630), king of the Merina people who migrated to the region from the southeast coast, seized the location as the site of his capital city. According to oral history, he deployed a garrison of 1,000 soldiers to successfully capture and guard the site. The hill and its city retained the name Analamanga until the reign of King Andriamasinavalona (1675–1710), who renamed it "Antananarivo" ("City of the Thousand") in honor of Andrianjaka's soldiers.
History.
Kingdom of Imerina.
Unlike most capital cities in southern Africa, Antananarivo was already a major city before the colonial era. After expelling the Vazimba who inhabited the town at the peak of Analamanga hill, Andrianjaka chose the site for his "rova" (fortified royal compound), which expanded over time to enclose the royal palaces and the tombs of Merina royalty. The city was established in around 1610 or 1625 according to varying accounts. Early Merina kings used "fanampoana" (statute labor) to construct a massive system of irrigated paddy fields and dikes around the city to provide adequate rice for the growing population. These paddy fields, of which the largest is called the Betsimitatatra, continue to produce rice.
Successive Merina sovereigns ruled over the Kingdom of Imerina from Analamanga through King Andriamasinavalona's reign. This sovereign gave the growing city its current name; he established the Andohalo town square outside the town gate, where all successive sovereigns delivered their royal speeches and announcements to the public, and assigned the names of numerous locations within the city based on the names of similar sites in the nearby village of Antananarivokely. Andriamasinavalona designated specific territories for the "hova" (commoners) and each "andriana" (noble) subcaste, both within the neighborhoods of Antananarivo and in the countryside surrounding the capital. These territorial divisions were strictly enforced; members of subcastes were required to live within their designated territories and were not authorized to stay for extended periods in the territories reserved for others. Numerous "fady" (taboos), including injunctions against the construction of wooden houses by non-nobles and the presence of swine within the city limits, were imposed.
Upon Andriamasinavalona's death in 1710, Imerina split into four warring quadrants and Antananarivo was made the capital of the southern district. During the 77-year civil war that followed, the eastern district's capital at Ambohimanga rose in prominence. The last king of Ambohimanga, Andrianampoinimerina, successfully conquered Antananarivo in 1793; he reunited the provinces of Imerina, ending the civil war. He moved the kingdom's political capital back to Antananarivo in 1794, and declared Ambohimanga the kingdom's spiritual capital, a role it still maintains. Andrianampoinimerina created a large marketplace in Analakely, establishing the city's economic center.
Kingdom of Madagascar.
By the time Andrianampoinimerina's son Radama I had ascended the throne upon his father's death in 1810, Antananarivo was the largest and most economically important city on the island, with a population of over 80,000 inhabitants. Radama opened the city to the first European settlers, artisan missionaries of the London Missionary Society (LMS) who arrived in 1820 and opened the city's first public schools. James Cameron introduced brickmaking to the island and created Lake Anosy to generate hydraulic power for industrial manufacturing. Radama established a military training ground on a flat plain called Mahamasina at the base of Analamanga near the lake. Radama's subjugation of other Malagasy ethnic groups brought nearly two thirds of the island under his control. The British diplomats who concluded trade treaties with Radama recognized him as the "ruler of Madagascar", a position he and his successors claimed despite never managing to impose their authority over the larger portion of the island's south. Thereafter, Merina sovereigns declared Antananarivo the capital of the entire island.
Radama's successor Ranavalona I invited a shipwrecked craftsman named Jean Laborde to construct the tomb of Prime Minister Rainiharo, and Manjakamiadana (built 1839–1841), the largest palace at the Rova. Laborde also produced a wide range of industrial products at factories in the highland village Mantasoa and a foundry in the Antananarivo neighborhood Isoraka. Ranavalona oversaw improvements to the city's infrastructure, including the construction of the city's two largest staircases at Antaninarenina and Ambondrona, which connect "la ville moyenne" ("the middle town") to the central marketplace at Analakely. In 1867, following a series of fires in the capital, Queen Ranavalona II issued a royal decree that permitted the use of stone and brick construction in buildings other than tombs. LMS missionaries' first brick house was built in 1869; it bore a blend of English, Creole and Malagasy design and served as a model for a new style of house that rapidly spread throughout the capital and across the highlands. Termed the "trano gasy" ("Malagasy house"), it is typically a two-story, brick building with four columns on the front that support a wooden veranda. In the latter third of the 19th century, these houses quickly replaced most of the traditional wooden houses of the city's aristocratic class. The growing number of Christians in Imerina prompted the construction of stone churches throughout the highlands, as well as four memorial cathedrals on key sites of martyrdom among early Malagasy Christians under the reign of Ranavalona I.
Until the mid 19th century, the city remained largely concentrated around the Rova of Antananarivo on the highest peak, an area today referred to as "la haute ville" or "la haute" ("upper town"). As the population grew, the city expanded to the west; by the late 19th century it extended to the northern hilltop neighborhood of Andohalo, an area of low prestige until British missionaries made it their preferred residential district and built one of the city's memorial churches here from 1863 to 1872. From 1864 to 1894, Prime Minister Rainilaiarivony governed Madagascar alongside three successive queens, Rasoherina, Ranavalona II and Ranavalona III, effecting policies that further transformed the city. In 1881, he reinstated mandatory universal education first introduced in 1820 under Radama I, requiring the construction of numerous schools and colleges, including teacher training colleges staffed by missionaries and the nation's first pharmacy (1862), medical college and modern hospital (1865). Rainilaiarivony built the Andafiavaratra Palace in 1873 as his residence and office at a site near the royal palace.
French Madagascar.
The French military invaded Antananarivo in September 1894, prompting the queen's surrender after a cannon shell blasted a hole through a building at the Rova, causing major casualties. The damage was never repaired. Andohalo square was remodeled to feature a gazebo, walkways and planted landscaping. Claiming the island as a colony, the French administration retained Antananarivo as its capital and transcribed its name as Tananarive. They chose Antaninarenina as the site for the French Governor General's Residency; upon independence it was renamed Ambohitsorohitra Palace and converted into presidential offices. Under the French, tunnels were constructed through two of the city's largest hills, connecting disparate districts and facilitating the town's expansion. Streets were laid with cobblestones and later paved; sewer systems and electricity infrastructure were introduced. Water, previously obtained from springs at the foot of the hill, was brought from the Ikopa River.
This period saw a major expansion of "la ville moyenne", which spread along the lower hilltops and slopes of the city centered around the French Residency. Modern urban planning was applied in "la ville basse" ("lower town"), which expanded from the base of the city's central hills into the surrounding rice fields. Major boulevards like "Avenue de l'Indépendance", planned commercial areas like the arcades lining either side of the Avenue, large parks, city squares and other landmark features were built. A railway system connecting Soarano station at one end of the "Avenue de l'Indépendance" in Antananarive with Toamasina and Fianarantsoa was established in 1897. Beyond these planned spaces, neighborhoods densely populated by working class Malagasy expanded without state oversight or control.
The city expanded rapidly after World War II; by 1950 its population had grown to 175,000. Roads connecting Antananarivo to surrounding towns were expanded and paved. The first international airport was constructed at Arivonimamo, outside the city; this was replaced in 1967 with Ivato International Airport approximately from the city center. The University of Antananarivo was constructed in the Ankatso neighborhood and the Museum of Ethnology and Paleontology was also built. A city plan written in 1956 created suburban zones where large houses and gardens were established for the wealthy. In 1959, severe floods in "la ville basse" prompted the building of large scale embankments along the edges of the Betsimitatatra rice fields and the establishment of new ministerial complexes on newly drained land in the Anosy neighborhood.
Post-independence.
After independence in 1960, the pace of growth increased further. The city's population reached 1.4 million by the end of the 20th century; in 2013, it was estimated at nearly 2.1 million. Uncontrolled urban sprawl has challenged the city's infrastructure, producing shortages of clean water and electricity, sanitation and public health problems, and heavy traffic congestion. There are more than 5,000 church buildings in the city and its suburbs, including an Anglican and a Roman Catholic cathedral. Antananarivo is the see city of Madagascar's Roman Catholic Archdiocese. The city has repeatedly been the site of large demonstrations and violent political clashes, including the 1972 "rotaka" that brought down president Philibert Tsiranana and the 2009 Malagasy political crisis, which resulted in Andry Rajoelina replacing Marc Ravalomanana as head of state.
Geography.
Antananarivo is situated approximately above sea level in the central highlands region of Madagascar, at 18.55' South and 47.32' East. The city is located centrally along the north-south axis of the country, and east of center along the east-west axis. It is from the east coast and from the west coast. The city occupies a commanding position on the summit and slopes of a long, narrow, rocky ridge extending north and south for about and rising to about above the extensive rice fields to the west.
The official boundaries of the city of Antananarivo encompass an urban area of approximately . It was founded above sea level at the apex of three hill ranges that converge in a Y form, above the surrounding Betsimitatatra paddy fields and the grassy plains beyond. The city gradually spread out from this central point to cover the hillsides; by the late 19th century it had expanding to the flat terrain at the base of the hills. These plains are susceptible to flooding during the rainy season; they are drained by the Ikopa River, which skirts the capital to the south and west. The western slopes and plains, being best protected from cyclone winds originating over the Indian Ocean, were settled before those to the east.
Greater Antananarivo is a continuous, urbanized area spreading beyond the city's official boundaries for north to south between Ambohimanarina and Ankadimbahoaka, and west to east between the Ikopa River dike and Tsiadana. The population of the greater Antananarivo area was estimated at 3 million people in 2012; it is expected to rise to 6 million by 2030.
Climate.
Under the Köppen-Geiger climate classification system, Antananarivo has a subtropical highland climate (Cwb) characterized by mild, dry winters and warm, rainy summers. The city receives nearly all of its average annual rainfall between November and April. Frosts are rare in the city; they are more common at higher elevations. Mean temperatures range from to .
Cityscape.
Antananarivo encompasses three ridges that intersect at their highest point. The Manjakamiadana royal palace is located at the summit of these hills and is visible from every part of the city and the surrounding hills. The Manjakamiadina was the largest structures within the rova of Antananarivo; its stone casing is the only remnant of the royal residences that survived a 1995 fire at the site. For 25 years, the roofless shell dominated the skyline; its west wall collapsed in 2004. In 2009, the stone casing had been fully restored and the building was re-roofed. It is illuminated at night. Conservation and reconstruction work at the site is ongoing. The city skyline is a jumble of colorful, historic houses and churches. More recent residential and commercial buildings and family rice fields occupy lower terrain throughout the capital. The Betsimitatatra and other rice fields surround the city.
The city's neighborhoods emerge from historic ethnic, religious and caste divisions. The assignment of certain neighborhoods to particular noble sub-castes under the Kingdom of Imerina established divisions; the highest ranking nobles were typically assigned to neighborhoods closest to the royal palace and were required to live in higher elevation portions of the city. During and after French colonization, expansion of the city continued to reflect these divisions. Today, the calm and quiet "haute ville" is mainly residential and viewed as a prestigious area in which to live; many of the city's wealthiest and most influential Malagasy families live there. The part of "la haute" closest to the Rova contains much of the city's pre-colonial heritage and is considered its historic part. It includes the royal palace, Andafiavaratra Palacethe former residence of Prime Minister Rainilaiarivony, Andohalothe principal town square until 1897, a cathedral near Andohalo built to commemorate early Malagasy Christian martyrs, the city's most intact historic entrance gate and the 19th-century houses of Merina nobles.
Under the Kingdom of Madagascar, the commoner class ("hova") settled at the periphery of the noble districts, gradually spreading along the slopes of the lower hills during the late 19th century. This "ville moyenne" became increasingly populous under French colonial authority, which targeted them for redesign and development. Today, the neighborhoods in the "ville moyenne" are densely populated and lively, containing residences, historic sites and businesses. The neighborhood of Antaninarenina contains the historic Hôtel Colbert, numerous jewelers' shops and other luxury goods stores, and administrative offices. In addition to Antaninarenina, the principal neighborhoods of "la ville moyenne" are Ankadifotsy on the eastern hills and Ambatonakanga and Isoraka to the west, all of which are largely residential. Isoraka has developed lively nightlife, with houses converted to upscale restaurants and inns. Isoraka also houses the tomb of Prime Minister Rainiharo (1833–1852), whose sons and later Prime Ministers Rainivoninahitriniony and Rainilaiarivony are buried with him. Bordering these neighborhoods are the commercial areas of Besarety and Andravoahangy.
The commercial center of town, Analakely, is located on the valley floor between these two "ville moyenne" hill ranges. King Andrianampoinimerina established the city's first marketplace on the grounds today occupied by the market's tile-roofed pavilions, constructed in the 1930s. Andrianampoinimerina decreed Friday ("Zoma") as market day, when merchants would erect stalls shaded with white parasols, which extended throughout the valley forming what has been called the largest open air marketplace in the world. The market caused traffic congestion and safety hazards prompting government officials to divide and relocate the Friday merchants to several other districts in 1997. The city's other main commercial and administrative neighborhoods, which spread out from Analakely and extend into the adjacent plain, were established by the French, who drained and filled in the extant rice fields and swampland to create much of the area's current design and infrastructure. The "Avenue de l'Indépendance" runs from the gardens of Ambohijatovo south of the market pavilions, through Analakely to the city's railroad station at Soarano. To the west of Soarano lies the dense commercial district of Tsaralalana; it is the only district to be built on a grid and is the center of the city's South Asian community. Behoririka, to the east of Soarano, is built around a lake of the same name and abuts the sprawling Andravoahangy district at the eastern edge of the city. Antanimena borders Soarano and Behoririka to the north. A tunnel built by the French in the early 20th century cuts through the hillside; it connects Ambohijatovo with Ambanidia and other residential areas in the south of the city.
Since pre-colonial times the lower classes, including those descended from the slave class ("andevo") and rural migrants, have occupied the flood-prone lower districts bordering the Betsimitatatra rice fields to the west of the city. This area is connected to Analakely by a tunnel constructed by the French in the early 20th century. The tunnel opens toward Lake Anosy and the national Supreme Court buildings, and provides access to the residential neighborhood of Mahamasina and its stadium. The bordering neighborhood of Anosy was developed in the 1950s to house most of the national ministries and the Senate. Anosy, the planned residential district of "Soixante-Sept Hectares" (often abbreviated to "67") and the neighborhood of Isotry are among the city's most densely populated, crime ridden and impoverished neighborhoods. Approximately 40 percent of inhabitants with electricity in their homes in the "ville basse" obtain it illegally by splicing into city power lines. In these areas, houses are more vulnerable to fires, flooding and landslides, which are often triggered by the annual cyclone season.
Architecture.
Before the mid-19th century, all houses and marketplaces in Antananarivo, and throughout Madagascar, were constructed of woods, grasses, reeds and other plant-based materials viewed as appropriate for structures used by the living. Only family tombs were built from stone, an inert material viewed as appropriate to use for the dead. British missionaries introduced brick-making to the island in the 1820s, and French industrialist Jean Laborde used stone and brick to build his factories over the next few decades. It was not until the royal edict on construction materials was lifted in the 1860s that stone was used to encase the royal palace. Many aristocrats, inspired by the royal palace and the two-story, brick houses with wrapped verandas and divided interior spaces built by British missionaries, copied the British model for their own large homes in the "haute ville". The model, known as "trano gasy" ("Malagasy house"), rapidly spread throughout the central highlands of Madagascar, where it remains the predominant house construction style.
Since 1993, the "Commune urbaine d'Antananarivo" (CUA) has increasingly sought to protect and restore the city's architectural and cultural heritage. In 2005, CUA authorities partnered with the city planners of the Île-de-France to develop the "Plan VertPlan Bleu" strategy for creating a classification system for "Zones de Protection du Patrimoine Architectural, Urbain et Paysager", areas of the city benefiting from legal protection and financial support for their historic and cultural heritage. The plan, which is being implemented by the "Institut des Métiers de la Ville", prevents the destruction of historic buildings and other structures, and establishes construction codes that ensure new structures follow historic aesthetics. It also provides for awareness raising campaigns in favor of historic preservation and undertakes projects to restore dilapidated historic buildings and sites. Under this plan, 19th-century sites, like the Ambatondrafandrana tribunal and the second residence of Rainilaiarivony, have been renovated.
Demographics.
Antananarivo has been the largest city on the island since at least the late 18th century, when its population was estimated at 15,000. By 1810, the population had grown to 80,000 before declining dramatically between 1829 and 1842 during the reigns of Radama I and especially Ranavalona I. Because of a combination of war, forced labor, disease and harsh measures of justice, the population of Imerina fell from 750,000 to 130,000 during this period. In the final years of the Kingdom of Imerina, the population had recovered to between 50,000 and 75,000; most of the population were slaves who were largely captured in provincial military campaigns. In 1950, Antananarivo's population was around 175,000. By the late 1990s the population of the metropolitan area had reached 1.4 million, and - while the city itself now has a population (2013) of about 1,300,000 - with suburbs lying outside the city limits it had grown to almost 2.1 million in 2013. The metropolitan area is thus home to 10 percent of the island's residents. Rural migration to the capital propels this growth; the city's population exceeds that of the other five provincial capitals combined.
As the historic capital of Imerina, Antananarivo is centrally located in the homeland of the Merina people, who comprise about 24 percent of the population and are the largest Malagasy ethnic group. The city's history as the island's major center for politics, culture and trade has ensured a cosmopolitan mix of ethnic groups from across the island and overseas. Most Antananarivo residents have strong ties to their "tanindrazana" (ancestral village), where the extended family and typically a family tomb or burial place is located; many older residents leave the city upon retirement to return to their rural area of origin.
Crime.
Despite ongoing efforts by the Ministry of Domestic Security, crime has worsened in Antananarivo since 2009. Between 1994 and 1998, the city had an average of eight to twelve police officers for every 10,000 inhabitants; large cities should typically have closer to fifteen. Under the mayorship of Marc Ravalomanana (1998–2001), street lights were installed or repaired throughout the city to improve night-time safety. He increased the number of police officers on the streets, leading to a drop in crime. , the city lacks a comprehensive strategy for reducing crime. The recent increase in crime and the inadequate response from the CUA has prompted the growth of private security firms in the city.
Economy.
Agriculture is the mainstay of the Malagasy economy. Land is used for the cultivation of rice and other crops, raising of zebu and other livestock, the fabrication of bricks and other traditional livelihoods. In Antananarivo, access to land is guaranteed and protected by law for every resident of the city. The CUA manages requests to lease or purchase land, but demand dramatically outstrips supply and much of the unallocated land fails to meet the requisite criteria for parceling, such as land where floodwater runoff is diverted. Much of this marginal land has been illegally occupied and developed by land-seeking residents, creating shantytown slums in pockets throughout the lower portions of the city. This uncontrolled development poses sanitation and safety risks to residents in these areas.
Industry accounts for around 13 percent of Madagascar's gross domestic product (GDP) and is largely concentrated in Antananarivo. Key industries include soap production, food and tobacco processing, brewing, textiles, and leather manufacturing, providing employment to around 5.5 percent of the workforce. The city's extensive infrastructure and its role as the economic center of the country make it a favorable location for large businesses. Business owners are drivers of growth for the city; in 2010, 60 percent of all new buildings in the country were located in Antananarivo, most of which were built for commercial purposes. Unemployment and poverty are also growing, fueled in part by an inadequately skilled and unprofessional workforce and the lack of a comprehensive national strategy for economic development since 2009. Formal sector job growth has not kept pace with population growth, and many residents earn their livelihood in the informal sector as street vendors and laborers. Under Ravalomanana, construction in the capital increased sharply; twelve new supermarkets were constructed in two years.
The residents of urban areasin particular Antananarivohave been hardest hit by economic downturns and economic policy shifts. The national economic crisis in the mid-1970s and early 1980s, and the World Bank's imposition of a structural adjustment program lowered living standards for the average resident of the city. The end of state subsidies, rapid inflation, higher taxes, widespread impoverishment and the decline of the middle class were especially evident in Antananarivo, as was the growing wealth of a tiny political and economic elite in the city. In 2007, two thirds of Antananarivo residents had access to electricity, while ten percent of households owned a scooter, car or other motor vehicle. Running water was installed in fewer than 25 percent of homes, small restaurants and businesses in 2007, necessitating the collection of water from household wells or neighborhood pumps and the use of outdoor pit toilets detached from the main building. In 2007, 60 percent of households were using shared public latrines. Most homes use charcoal for daily cooking; stocks of charcoal and rice are kept in the kitchen. The average city household spends just under half of its budget on food. Owing to its increasingly high cost, consumption of meat by city residents has sharply declined since the 1970s; the urban poor eat meat on holidays only once or twice a year.
Culture.
In Antananarivo and throughout the highlands, Merina and Betsileo families practice the "famadihana", an ancestor reburial ceremony. This ceremony typically occurs five to seven years after the death of a relative and is celebrated by removing the relative's "lamba"-wrapped remains from the family tomb, rewrapping it with fresh silk shrouds and returning it to the tomb. Relatives, friends and neighbors are invited to take part in the music, dancing and feasting that accompanies the event. The famadihana is costly; many families sacrifice higher living standards to set aside money for the ceremony.
Historic sites and museums.
The tangible and intangible cultural heritage of Antananarivo is extensive and highly significant to regional and national populations. The city has numerous monuments, historic buildings, sites of significance and traditions related to the customs and history of the central highlands people. The city skyline is dominated by the Rova of Antananarivo, which was destroyed in a 1995 fire but are undergoing reconstruction. The nearby Andafiavaratra Palace was the home of 19th century Prime Minister Rainilaiarivony and currently contains a museum featuring historic artifacts of the Kingdom of Imerina, including items saved from the fire at the Rova. Downhill from the palaces is Andohalo square, where Merina kings and queens delivered speeches to the public. Tsimbazaza Zoo displays many of the island's unique animal species and a complete skeleton of the now-extinct elephant bird. Other historic buildings include the Ambatondrafandrana tribunal where Ranavalona I dispensed judgement, the second residence of Rainilaiarivony with its indigenous medicinal plant garden, the recently renovated Soarano railroad station, four late 19th century memorial churches built to commemorate early Malagasy Christian martyrs, the tomb of Prime Minister Rainiharo, and the early 20th century pavilions of the Analakely market. Open air markets include Le Pochard and the artisan market at Andravoahangy. The Museum of Art and Archaeology in the Isoraka neighborhood features exhibits on the history and cultures of Madagascar's diverse ethnic groups.
Arts.
The arts scene in Antananarivo is the largest and most vibrant in the country. Madagascar's diverse music is reflected in the many concerts, cabarets, dance clubs and other musical venues throughout Antananarivo. In the dry season, outdoor concerts are regularly held in venues including the Antsahamanitra amphitheater and Mahamasina Stadium. Concerts and night clubs are attended mainly by young people of the middle to upper classes who can afford the entrance fees. More affordable are performances of traditional "vakindrazana" or Malagasy operettas at Isotry Theater and "hira gasy" at the city's outdoor "cheminots" theater or "Alliance française"; these performances are more popular with older and rural audiences than among urban youth. Nightlife is the most animated in the "ville moyenne" neighborhoods of Antaninarenina, Tsaralalana, Behoririka, Mahamasina and Andohalo.
The "Palais des Sports" in the Mahamasina neighborhood is the country's only indoor performance space built to international standards. It was built in 1995 by the Government of China; it regularly hosts concerts, dance and other arts performances, expositions and novelty events like monster truck rallies. The city lacks a dedicated classical music performance space, and concerts by international artists are infrequent. Performances of classical, jazz and other foreign musical genres, modern and contemporary dance, theater and other arts occur at cultural arts centers funded by foreign governments or private entities. Among the best-known of these are the "Centre Culturel Albert Camus" and "Alliance française d'Antananarivo", both funded by the French government. the "Cercle Germano-Malgache", a branch of the Goethe-Institut funded by the German government; The American Center is funded by the United States government. Antananarivo has two dedicated cinemas, the Rex and the Ritz, both of which were built in the colonial era. These venues do not show international releases but occasionally screen Malagasy films or are used for private events and religious services.
Sports.
Rugby Union is considered the national sport of Madagascar. The national rugby team is nicknamed the Makis after the local word for the indigenous ring-tailed lemur. The team trains and plays domestic matches at Maki Stadium in Antananarivo. Constructed in 2012, the stadium has a capacity of 15,000 and houses a gym and administrative offices for the team. It replaces their former home, Malacam Stadium, which had a capacity of approximately 3,000 that was regularly exceeded by the number of attendees. Several soccer teams are also based in Antananarivo; AS Adema Analamanga and Ajesaia are associated with the Analamanga region; USCA Foot is associated with the CUA and the AS Saint Michel has been affiliated since 1948 with the historic secondary school of the same name. All four teams train and play local games in Mahamasina Municipal Stadium, the largest sporting venue in the country. The men's basketball teams Challenger and SOE ("Équipe du Stade olympique de l'Emyrne") are based in Antananarivo and play in the "Palais des Sports" at Mahamasina.
Government.
Antananarivo is the capital of Madagascar and the federal governance structures, including the Senate, National Assembly, the Supreme Court and the presidential office are housed there. The main presidential offices are located south of the city. The nationwide move toward decentralization beginning in the mid-1990s produced several laws, including the "Loi no. 94-009" of 26 April 1995 and the "Decret 96–168" of 6 March 1996, which provided Antananarivo with a distinctive status. They also defined additional governance roles for the city, making it the administrative seat of the Analamanga region, the district of Antananarivo-Renivohitra and the "Commune Urbaine d'Antananarivo" (CUA, Antananarivo city proper). The city hosts the diplomatic missions of 21 countries.
The CUA is divided into six numbered "arrondissements" (administrative sub-districts); it has historically been administered by an elected mayor and associated staff. Since the 2009 political crisis, in which the former mayor of Antananarivo, Andry Rajoelina, unconstitutionally seized power as head of state, the CUA has been administered by a "délégation spéciale" (special delegation) composed of a president and "de facto" mayor with the support of two vice presidents, all of whom are appointed by the President. The position of President of the Special Delegation has been held by Ny Havana Andriamanjato since March 2014.
The mayoral administration of the CUA is empowered to govern the city with "de jure" autonomy; a wide range of mechanisms have been established to facilitate governance, although they are of limited effectiveness. An urban master plan guides major policies for city management but personnel within the mayoral office commonly lack the urban planning and management ability to effectively implement the plan in response to long-term and immediate needs. This challenge is compounded by the high turnover rate of mayors and staff that frequently disrupts initiatives begun by previous CUA administrations. A mayor under former president Didier Ratsiraka created "red zones"; areas where public gathering and protests were prohibited. On 28 June 2001, Ravalomanana abolished these areas, liberalizing freedom of assembly.
Antananarivo has suffered from debt and mismanagement. The CUA estimated in 2012 that the cost of running the city to international standards would reach annually, while annual revenues average around $12 million. In good years, the CUA is able to reserve $1–2 million to spend on city improvement projects. By 2008, the city's treasury had accumulated 8.2 billion Malagasy "ariary"approximately in debts under previous mayors. In 2008, water was cut off at public pumps and there were regular brownouts of city's street lights because of 3.3 million ariary of unpaid debts to the Jirama public utilities company by the City of Antananarivo. In response, then-mayor Rajoelina undertook an audit that identified and sought to address long-standing procedural irregularities and corruption in the city's administration. The CUA continues to be challenged by a shortage of revenues relative to its expenses caused by the high cost of retaining the large number of CUA personnel, weak structures for managing revenues from public rents and inadequate collection of tax revenues from city residents and businesses.
Twin towns and sister cities.
Antananarivo has established sister city agreements with four cities. The city was twinned with Yerevan, Armenia in 1981. The city is also twinned with Vorkuta, Russia; Suzhou, China; and Montreal, Canada. A sister city relationship between Antananarivo and Nice, France, established in 1962, is not currently active.
Education.
Most of Madagascar's public and private universities are located in Antananarivo. This includes the country's oldest higher education institute, the College of Medicine established under the Merina monarchy and the University of Antananarivo, established under the French colonial administration. The city hosts many private pre-primary, primary and secondary schools and the national network of public schools. The city houses a French international school, "Lycée Français de Tananarive".
The nation's most prestigious dance school, "K'art Antanimena", is located in Antananarivo. Other major dance schools based in the city include " Le Club de Danse de l'Université Catholique de Madagascar", "Club de danse Kera arts'space à Antanimena" and "Le Club Mills".
Health and sanitation.
In general, availability and quality of health care is better in Antananarivo than elsewhere in Madagascar, although it remains inadequate across the country relative to that in more developed countries. One of Madagascar's two medical schools is located in Antananarivo; most medical technicians and specialists are trained there. Neonatal and antenatal care is significantly better in Antananarivo than elsewhere on the island. Despite the presence of facilities and trained personnel, the high cost of health care places it beyond the reach of most residents of Antananarivo. Pharmaceuticals are imported, making them particularly unaffordable; traditional herbal medicines remain popular and are readily available in local markets frequented by most of the population.
The large population in Antananarivo and the high density of its residential zones pose challenges to public health, sanitation and access to clean drinking water. Processing and disposal of industrial and residential waste is inadequate. Waste water is often discharged directly into the city's waterways. Air pollution from vehicle exhausts, residential coal-burning stoves and other sources is worsening. While the city has set up clean water pumps, they remain inadequate and are not distributed according to population density, worsening access in the poorest and most populous parts of the city. Antananarivo is one of the two urban areas in Madagascar where bubonic plague is endemic.
These problems were diminished but not eliminated under the mayoral administration of Marc Ravalomanana, who prioritized sanitation, security and public administration. He obtained funds from international donors to establish garbage collection and disposal systems, restore dilapidated infrastructure such as roads and marketplaces, and replant public gardens. To improve sanitation in the city, he constructed public latrines in densely populated and highly frequented areas.
Transport and communications.
The majority of the city's residents move about Antananarivo on foot. The CUA sets and enforces rules that govern a system of 2,400 franchised private minibuses running on eighty-two numbered routes throughout the city. An additional 2,000 minibuses managed by the Ministry of Transportation run along eight lines into the neighboring suburbs. These interlinked bus systems served around 700,000 passengers each day. These minibuses often fail to meet safety standards or air quality requirements and are typically overcrowded with passengers and their cargo. Police and "gendarmes" assist in regulating traffic at peak periods in the morning and evening, or around special events and holidays. Private licensed and unlicensed taxis are common; most vehicles are older Renaults or Citroens. Newer vehicles congregate near hotels and other locales frequented by foreigners willing or able to pay higher prices for better services.
The city is encircled by a ring road and connected by direct "routes nationales" (national highways) to Mahajanga, Toliara, Antsirabe, Fianarantsoa and Toamasina. Branches and feeder roads from these major highways connect the city to the national road network. Antananarivo is connected by train to Toamasina to the east and Manakara to the southeast via Antsirabe and Fianarantsoa. The city's principal railway station is centrally located at Soarano at one end of the "Avenue de l'Indépendance". Ivato International Airport is located approximately from the center of the city, connecting Antananarivoto to all national airports. Ivato is the hub of the national airline Air Madagascar, and is the only airport on the island hosting long-haul carriers. Direct flights connect Antananarivo to cities in South Africa, Europe and Asia.
Government television and radio broadcasting centers, and the headquarters of numerous private stations are located in Antananarivo. Eighty percent of households in Antananarivo own a radio; the medium is popular across social classes. Stations like "Fenon'ny Merina" appeal to Merina listeners of all ages by playing traditional and contemporary music of the highlands region. Youth-oriented stations play a blend of Western artists and Malagasy performers of Western genres, as well as fusion and coastal musical styles. Evangelical broadcasts and daily international and local news are available in Malagasy, French and English. Forty percent of Antananarivo residents own a television receiver. All major Malagasy newspapers are printed in the city and are widely available. Communications services in Antananarivo are the best in the country. Internet and mobile telephone networks are readily available and affordable, although disruptions in service occur periodically. The national postal service is headquartered in Antananarivo, and private international shipping companies like FedEx, DHL Express and United Parcel Service provide services to the city.

</doc>
<doc id="56598" url="https://en.wikipedia.org/wiki?curid=56598" title="Henry Bergh">
Henry Bergh

Henry Bergh (August 29, 1813 – March 12, 1888) founded the American Society for the Prevention of Cruelty to Animals (ASPCA) in April, 1866, three days after the first effective legislation against animal cruelty in the United States was passed into law by the New York State Legislature. Bergh also prompted the formation, in 1874, of the Massachusetts Society for the Prevention of Cruelty to Children (MSPCC).
Biography.
Bergh was born in New York City and studied at Columbia College, after which he worked in his fathers' shipyard. After the shipyard was sold, Bergh received a share of the inheritance and set forth on a lengthy journey throughout Western Europe with his young bride, Catherine Matilda Taylor.
In 1862, Bergh was appointed secretary and acting vice-consul to the American legation in St. Petersburg, Russia by then President Abraham Lincoln. The severity of the climate obliged him to resign in 1864, and he traveled extensively in Europe and the Orient.
On returning to the United States, Bergh resolved to work on behalf of animal welfare. Cruelties witnessed in Europe first suggested his mission. Alone, in the face of indifference, opposition, and ridicule, he began working as a speaker and lecturer, but most of all in the street and the courtroom, and before the legislature. His cause gained friends and rapidly increased in influence. The legislature passed the laws prepared by him, and on 10 April 1866 the ASPCA was legally organized, with Bergh as president.
The association moved steadily forward, and by August was in a flourishing condition financially, having received a valuable property from Bergh and his wife. In 1871 a Parisian, Louis Bonard, who lived with extreme simplicity in New York, died and left $150,000 to the Society, which permitted a move to larger quarters, better adapted to its work, a building at the corner of 4th Avenue and 22nd Street.
During 1873 Bergh made a lecturing tour in the western U.S., which resulted in the formation of several societies similar to that in New York. He spoke before the Evangelical Alliance and Episcopal convention, and was the means of having a new canon confirmed, to the effect that Protestant Episcopal clergyman should at least once a year preach a sermon on cruelty and mercy to animals.
One of the outgrowths of his work was an ambulance corps for removing disabled animals from the street, and a derrick to rescue them from excavations into which they had fallen. He also originated an ingenious invention which substitutes artificial for live pigeons as marks for sportsmen's guns.
When Bergh began his work, no state or territory of the United States contained any statute relating to the protection of animals from cruelty. By 1886, 39 states had adopted substantially the original laws procured by him from the legislature of New York.
In 1874, Bergh was approached by a Methodist missionary named Etta Agnell Wheeler, who sought help rescuing a child named Mary Ellen Wilson from her cruel abuser, Mary Connolly. After Mary Ellen's story was heard, and she was subsequently rescued through Bergh's efforts, other complaints came in to Bergh. In response, Bergh himself, along with Elbridge T. Gerry and John D. Wright, formed the New York Society for the Prevention of Cruelty to Children (NYSPCC) in 1875. Over the coming years, other SPCC organizations were formed, such as the Massachusetts organization in 1888, the Massachusetts Society for the Prevention of Cruelty to Children (MSPCC).
He died on March 12, 1888, in New York City. Poet Henry Wadsworth Longfellow eulogized Bergh as "among the noblest in the land...friend to every friendless beast." Henry Bergh is interred at Green-Wood Cemetery in Brooklyn, New York.
Legacy.
In the spring of 2006 at Green-Wood Cemetery, while making preparations to honor Bergh, the ASPCA discovered that his wife was also in that mausoleum. On May 6, substantive ceremonies were held before a large audience which was allowed to bring their pets into the cemetery - including dogs, for the first time in over a century. The NYPD Emerald Society bagpipers and ASPCA HLE Agents were there also. After a walk to Bergh's tomb, the bas-relief statue was revealed that now rests in front. At the same time as these ceremonies, in the cemetery's large chapel building an exhibit was opened celebrating the history of the ASPCA and Henry Bergh.

</doc>
<doc id="56601" url="https://en.wikipedia.org/wiki?curid=56601" title="Fuzzy set">
Fuzzy set

In mathematics, fuzzy sets are sets whose elements have degrees of membership. Fuzzy sets were introduced by Lotfi A. Zadeh and Dieter Klaua in 1965 as an extension of the classical notion of set.
At the same time, defined a more general kind of structure called an "L"-relation, which he studied in an abstract algebraic context. Fuzzy relations, which are used now in different areas, such as linguistics decision-making and clustering , are special cases of "L"-relations when "L" is the unit interval 1.
In classical set theory, the membership of elements in a set is assessed in binary terms according to a bivalent condition — an element either belongs or does not belong to the set. By contrast, fuzzy set theory permits the gradual assessment of the membership of elements in a set; this is described with the aid of a membership function valued in the real unit interval [0, 1]. Fuzzy sets generalize classical sets, since the indicator functions of classical sets are special cases of the membership functions of fuzzy sets, if the latter only take values 0 or 1. In fuzzy set theory, classical bivalent sets are usually called "crisp" sets. The fuzzy set theory
can be used in a wide range of domains in which information is incomplete or imprecise, 
such as bioinformatics.
Definition.
A fuzzy set is a pair formula_1 where formula_2 is a set and formula_3
For each formula_4 the value formula_5 is called the grade of membership of formula_6 in formula_7 For a finite set formula_8 the fuzzy set formula_1 is often denoted by formula_10
Let formula_11 Then formula_6 is called not included in the fuzzy set formula_13 if , formula_6 is called fully included if , and formula_6 is called a fuzzy member if 
The set formula_16 is called the support of formula_13 and the set formula_18 is called its kernel or core. The function formula_19 is called the membership function of the fuzzy set formula_20
Sometimes, more general variants of the notion of fuzzy set are used, with membership functions taking values in a (fixed or variable) algebra or structure formula_21 of a given kind; usually it is required that formula_21 be at least a poset or lattice. These are usually called "L"-fuzzy sets, to distinguish them from those valued over the unit interval. The usual membership functions with values in are then called [0, 1-valued membership functions. These kinds of generalizations were first considered in 1967 by Joseph Goguen, who was a student of Zadeh.
Fuzzy logic.
As an extension of the case of multi-valued logic, valuations (formula_23) of propositional variables (formula_24) into a set of membership degrees (formula_25) can be thought of as membership functions mapping predicates into fuzzy sets (or more formally, into an ordered set of fuzzy pairs, called a fuzzy relation). With these valuations, many-valued logic can be extended to allow for fuzzy premises from which graded conclusions may be drawn.
This extension is sometimes called "fuzzy logic in the narrow sense" as opposed to "fuzzy logic in the wider sense," which originated in the engineering fields of automated control and knowledge engineering, and which encompasses many topics involving fuzzy sets and "approximated reasoning."
Industrial applications of fuzzy sets in the context of "fuzzy logic in the wider sense" can be found at fuzzy logic.
Fuzzy number.
A fuzzy number is a convex, normalized fuzzy set formula_26
whose membership function is at least segmentally continuous and has the functional value formula_27 at at least one element.
This can be likened to the funfair game "guess your weight," where someone guesses the contestant's weight, with closer guesses being more correct, and where the guesser "wins" if he or she guesses near enough to the contestant's weight, with the actual weight being completely correct (mapping to 1 by the membership function).
Fuzzy interval.
A fuzzy interval is an uncertain set formula_26 with a mean interval whose elements possess the membership function value formula_27. As in fuzzy numbers, the membership function must be convex, normalized, at least segmentally continuous.
Fuzzy categories.
The use of set membership as a key components of category theory can be generalized to fuzzy sets. This approach which initiated in 1968 shortly after the introduction of fuzzy set theory led to the development of "Goguen categories" in the 21st century.
Fuzzy relation equation.
The fuzzy relation equation is an equation of the form A · R = B, where A and B are fuzzy sets, R is a fuzzy relation, and A · R stands for the composition of A with R.
Entropy.
Let A be a fuzzy variable with a continuous membership function. Then its entropy is 
Where 
Extensions.
There are many mathematical constructions similar to or more general than fuzzy sets. Since fuzzy sets were introduced in 1965, a lot of new mathematical constructions and theories treating imprecision, inexactness, ambiguity, and uncertainty have been developed. Some of these constructions and theories are extensions of fuzzy set theory, while others try to mathematically model imprecision and uncertainty in a different way (; ; Deschrijver and Kerre, 2003).
The diversity of such constructions and corresponding theories includes:
While most of the above can be generally categorized as truth-based extensions to fuzzy sets, bipolar fuzzy set theory presents a philosophically and logically different, equilibrium-based generalization of fuzzy sets.

</doc>
<doc id="56602" url="https://en.wikipedia.org/wiki?curid=56602" title="Astana">
Astana

Astana (, ; ), is the capital of Kazakhstan. It is located on the Ishim River in the north portion of Kazakhstan, within Akmola Region, though administrated separately from the region as a city with special status. The 2014 census reported a population of 835,153 within the city, making it the second largest city in Kazakhstan.
Founded in 1830 as the settlement of "Akmoly" () or "Akmolinsky prikaz" (), it served as a defensive fortification for the Siberian Cossacks. In 1832, the settlement was granted a town status and renamed "Akmolinsk" (). On 20 March 1961, the city was renamed to "Tselinograd" () to mark the city's evolution as a cultural and administrative centre of the Virgin Lands Campaign. In 1992, it was renamed "Akmola" (), the modified original name meaning "a white grave". On 10 December 1997, Akmola replaced Almaty to become the capital of Kazakhstan. On 6 May 1998, it was renamed Astana, which means "the capital" in Kazakh.
Astana is a planned city, like Brasilia in Brazil, Canberra in Australia, and Washington, D.C. in the United States. The master plan of Astana was designed by Japanese architect Kisho Kurokawa. As the seat of the Government of Kazakhstan, Astana is the site of the Parliament House, the Supreme Court, the Ak Orda Presidential Palace and numerous government departments and agencies. It is home to many futuristic buildings, hotels and skyscrapers. Astana is a centre for sport, having been set to host the Expo 2017. Astana also has extensive healthcare and education systems.
History.
The settlement of "Akmoly", also known as "Akmolinsky prikaz", was established on the Ishim River in 1830 as the seat of an okrug by a unit of the Siberian Cossacks headed by Fyodor Shubin. The name was possibly given after a local landmark—"Akmola" literally means "a white grave" in Kazakh—although this theory is not universally accepted. In 1832, the settlement was granted town status and named "Akmolinsk". The fairly advantageous position of the town was clear as early as 1863 in an abstract from the Geographic and Statistical Dictionary of the Russian Empire. It describes how picket roads and lines connected this geographic centre to Kargaly in the East, Aktau fort in the South and through Atbasar to Kokchetav in the West. In 1838, at the height of the great national and liberation movement headed by Kenesary Khan, Akmolinsk fortress was burned. After the repression of the liberation movement, the fortress was rebuilt. On 16 July 1863, Akmolinsk was officially declared an uyezd town. During the rapid development of the Russian capitalist market, the huge Saryarka areas were actively exploited by the colonial administration. To draft Regulation governing the Kazakh steppe the Government of the Russian Empire formed Steppe Commission in 1865. On 21 October 1868, Tsar Alexander II signed a draft Regulation on governing Turgay, Ural, Akmolinsk and Semipalatinsk Oblasts. In 1869, Akmolinsk external district and department were cancelled, and Akmolinsk became the centre of the newly established Akmolinsk Oblast. In 1879, Major General Dubelt proposed to build a railway between Tyumen and Akmolinsk to the Ministry of Communications of Russia. In the course of the first 30 years of its existence, the population of Akmola numbered a trifle more than 2,000 people. However, over the next 30 years the city's population increased by three times according to volosts and settlements of the Akmolinsk Oblast. In 1893, Akmolinsk was an uyezd with a 6,428 strong population, 3 churches, 5 schools and colleges and 3 factories.
During World War II, Akmolinsk served as a route for the transport of engineering tools and equipment from evacuated plants in the Ukrainian SSR, Byelorussian SSR, and Russian SFSR located in the oblasts of the Kazakh SSR. Local industries were appointed to respond to war needs, assisting the country to provide the battle and home fronts with all materials needed. In the post-war years, Akmolinsk became a beacon of economic revival in the west of the Soviet Union ruined by the war. Additionally, many Russian-Germans were resettled here after being deported under Joseph Stalin rule.
In the 1950s, Northern Kazakh SSR oblasts became a territory of the Virgin Lands Campaign led by Nikita Khrushchev, in order to turn the region into a second grain producer for the Soviet Union. In December 1960, Central Committee made a resolution to create the Tselinniy Krai, which comprised five regions of the Northern Kazakh SSR oblasts. Akmolinsk Oblast was ceased to exist as a separate administrative entity. Its districts were directly subordinated to the new krai administration, and Akmolinsk became the krai capital, as well as the administrative seat of the new Virgin Lands economic region. On 14 March 1961, Khrushchev proposed to rename the city to name corresponding to its role in the Virgin Lands Campaign. On 20 March 1961, the Supreme Soviet of the Kazakh SSR renamed Akmolinsk to "Tselinograd". On 24 April 1961, the region was reconstituted as "Tselinograd Oblast". In the 1960s, Tselinograd was completely transformed. In 1963, work on the first three new high-rise housing districts began. In addition, the city received s number of new monumental public buildings, including the Virgin Lands Palace, a Palace of Youth, a House of Soviets, a new airport, and seceral sports venues. In 1971, the Tselinniy Krai was abolished and Tselinograd became the centre of the oblast.
After the dissolution of the Soviet Union and the consequent independence of Kazakhstan, the city's original form was restored in the modified form "Akmola". On 6 July 1994, the Supreme Council of Kazakhstan accepted the decree "On the transfer of the capital of Kazakhstan". After the capital of Kazakhstan was moved to Akmola on 10 December 1997, the city was consequently renamed Astana in 1998. On 10 June 1998, Astana presented as the capital internationally. On 16 July 1999, Astana was awarded the medal and title of the City of Peace by UNESCO.
Geography.
Topography.
Astana is located in central Kazakhstan on the Ishim River in a very flat, semi-arid steppe region which covers most of the country's territory. It is at 51° 10′ north latitude and 71° 26′ east longitude, and the 50th parallel north passes through the southern parts of the city. The city encompasses . The elevation of Astana is above sea level. Astana is in a spacious steppe landscape, in the transitional area between the north of Kazakhstan and the extremely thinly settled national centre, because of the Ishim River. The older boroughs lie north of the river, whilst the new boroughs are located south of the Ishim.
Climate.
Astana is the second coldest capital city in the world after Ulaanbaatar, Mongolia, a position formerly held by Canada's capital, Ottawa, until Astana attained capital city status in 1997. Astana has an extreme continental climate with warm summers (featuring occasional brief rain showers) and long, very cold, dry winters. Summer temperatures occasionally reach while is not unusual between mid-December and early March. The city also holds the record for the lowest air temperature ever recorded in Kazakhstan (). Typically, the city's river is frozen over between the second week of November and the beginning of April. Astana has a well-deserved reputation among Kazakhs for its frequent high winds, the effects of which are felt particularly strongly on the fast-developing but relatively exposed Left Bank area of the city.
Overall, Astana has a humid continental climate (Köppen climate classification "Dfb"), bordering on a semi-arid climate (Köppen climate classification "BSk"). The average annual temperature in Astana is . January is the coldest month with an average temperature of . July is the hottest month with an average temperature of .
Demographics.
As of 4 September 2014, Astana has a population density of 958 people per km2 and a population of about 835,153, of which Kazakhs, Russians, Ukrainians, Tatars and Germans make up 65.2%, 23.8%, 2.9%, 1.7%, 1.5% respectively. Other ethnic groups make up 4.9% of Astana's population.
In 1999, Astana had a population of 281,000. The ethnic mix was about 30% Kazakh and 70% Russian, Ukrainian and German.
By 2007, Astana's population has more than doubled since becoming the capital, to over 600,000, and it is estimated to top 1 million by 2030. Migrant workers – legal and illegal – have been attracted from across Kazakhstan and neighbouring states such as Uzbekistan and Kyrgyzstan, and Astana is a magnet for young professionals seeking to build a career. This has changed the city's demographics, bringing more ethnic Kazakhs to a city that formerly had a Slav majority. Astana's ethnic Kazakh population has risen to some 60%, up from 17% in 1989.
Many argue that a drive to attract ethnic Kazakhs northward was the key factor in shifting the capital, which was officially put down to lack of space for expansion in the former capital, Almaty, and its location in an earthquake zone.
According to preliminary figures, Astana had 700,000 inhabitants in late 2007. According to the 1999 Census, 40.5% of the population is Russian, 5.7% Ukrainian, 3.0% German, 2.6% Tatar, 1.8% Belarusian and 0.8% Polish. But at 41.8%, Kazakhs outnumbered Russians and were forming the largest ethnic group, while Ingush and Korean each accounted for 0.6%. Others, mostly Uzbeks, accounted for 3.8%.
Economy.
Astana's economy is based on trade, industrial production, transport, communication and construction. The city’s industrial production is mainly focused on producing building materials, foodstuff and mechanical engineering.
Astana is the headquarters of state-owned corporations such as Samruk-Kazyna, Kazakhstan Temir Zholy, KazMunayGas, KazTransOil, Kazatomprom, KEGOC and Kazakhtelecom.
The shift of the capital has given a powerful boost to Astana’s economic development. The city’s high economic growth rate has attracted numerous investors. In the 16 years since Astana became the capital, the volume of investments has increased by almost 30 times, the gross regional product has increased by 90 times, and industrial output has increased by 11 times. The city’s Gross Regional Product makes up about 8.5 percent of the republic's Gross domestic product.
The Astana – New City special economic zone was established in 2001 to develop industry and increase the attractiveness of the city to investors. The SEZ plans to commission five projects worth 20 billion KZT (around $108 million) in the Industrial Park #1 in 2015. The projects include construction of a plant for production of diesel engines, a fast food complex, temporary storage warehouses and a business centre, a furniture factory, and production of military and civil engineering machinery.
Astana's administration is promoting the development of small and medium-sized businesses through the cooperation of the Sovereign Welfare Fund Samruk-Kazyna and National Economic Chamber. Support is provided by a special program of crediting. As a result, the number of small and medium-sized businesses increased by 13.7% to over 96,000 compared to the previous year as of July 1, 2015. In addition, the number of people employed in small and medium-sized business increased by 17.8% to over 234,000 people as of April 1, 2015.
Cityscape.
Astana is subdivided into three districts. Almaty District was created on 6 May 1998 by presidential decree. The district's territory encompasses an area of with a population of 375,938 people. The district has five villages. Yesil District was created on 5 August 2008 by presidential decree. The district's territory encompasses an area of with a population of 119,929 people. Saryarka District was created on 6 May 1998 by presidential decree. The district's territory encompasses an area of with a population of 339,286 people.
In April 1998, the Government of Kazakhstan asked architects and urban planners of international renown to participate in a design competition for the new capital. On 6 October 1998, Japanese architect Kisho Kurokawa was awarded the First Prize. Summary of Kurokawa's Proposal, since the 1960s, pleaded for the Paradigm shift from the age of the machine principle to the age of life principle. His work is the embodiment of Metabolism and Symbiosis, which are the two most important concepts of the age of life principle. Kurokawa's proposal aimed to preserve and redevelop the existing city, and create a new city at the south and the east sides of the Ishim River, enabling the Symbiosis of the History and the Future.
North of the railway line, which crosses Astana in an east-west direction, are industrial and poorer residential areas. Between the railway line and the Ishim river is the city centre, where at present intense building activity is occurring. To the west and east are more elevated residential areas with parks and the new area of government administration to the south of the Ishim River. Here many large building projects are under way; for example, the construction of a diplomatic quarter, and a variety of different government buildings. By 2030, these quarters are to be completed. Astana's current chief planner, Vladimir Laptev, wants to build a Berlin in a Eurasian style. He has stated that a purely administrative capital such as Canberra is not one of his goals.
Sport.
The city has a variety of sporting teams. The major association football team is the FC Astana of the Kazakhstan Premier League. Founded in 2009, Astana won two league titles, two Kazakhstan Cups and two Kazakhstan Super Cups. Their home ground is the Astana Arena, which is also serves as a home for the Kazakhstan national football team and the FC Bayterek. The FC Bayterek is a member of the Kazakhstan First Division. They were founded in 2012, to develop youth football. The FC Astana-1964 is based in the Kazhymukan Munaitpasov Stadium and plays in the Astana Municipal Football League. The club's most successful years were 2000s, when they won 3 league titles.
Astana is home for several professional ice hockey teams. The Barys Astana, a founding member of the Kontinental Hockey League in 2008 and based in the Barys Arena. The Nomad Astana and the HC Astana are play in the Kazakhstan Hockey Championship and based in the Kazakhstan Sports Palace. The Snezhnye Barsy of the Junior Hockey League is a junior team of the Barys Astana. Astana annually hosts the President of the Republic of Kazakhstan's Cup ice hockey tournament.
The Astana Pro Team, founded in 2007, participates in the UCI World Tour. The team is one of the most successful cycling teams of recent years, winning several grand tours. The BC Astana of the VTB United League and the Kazakhstan Basketball League is the only professional basketball team in Astana. They are the most successful basketball team in Kazakhstan with three Kazakhstan Basketball League titles and four Kazakhstan Basketball Cups. Their home arena is the Saryarka Velodrome, which is mainly used for track cycling events. The Saryarka Velodrome hosted the UCI Track Cycling World Cup stage in 2011. The Astana Presidential Sports Club was founded in 2012, to combine the main sports teams in Astana. The organization is supported by Sovereign Wealth Fund Samruk-Kazyna. The 2011 Asian Winter Games were partly held in the capital. The Alau Ice Palace, hosted the 2015 World Sprint Speed Skating Championships. The President's Cup tennis tournament is annually held at the Daulet National Tennis Centre.
Education.
Astana schools enrolls about 103,000 students across 83 schools, including 71 state schools and 12 private schools. The Miras International School, established 1999, is the first private high school in Astana. The Haileybury Astana private school was established in 2011 as offshoot from the Haileybury and Imperial Service College, an independent school in England. The Astana Kazakh-Turkish High Schools are run by the International KATEV foundation. They include Kazakh-Turkish High Boarding Schools for gifted boys and girls, separately and the Nur-Orda International School. Astana hosts two Nazarbayev Intellectual Schools (NIS), including School of Physics and Mathematics and International Baccalaureate world school. The QSI International School of Astana is an international school that provides an American curriculum to its students. The school is a branch of the Quality Schools International that started in the Middle East.
Astana has many universities and junior colleges. academic year, Astana had a total enrollment of 53,561 students in its 14 higher educational institutions, a 10% increase from the prior year. The L.N.Gumilyov Eurasian National University is the biggest university in Astana with 16,558 students and 1,678 academic staff. It was founded as the result of merging the Akmola Civil Engineering Institute and Akmola Pedagogical Institute on 23 May 1996. The oldest university in Astana is the S.Seifullin Kazakh Agro Technical University founded in 1957. The Nazarbayev University is an autonomous research university, partnered with many of top universities of the world. The Kazakh University of Economics, Finance and International Trade is an economic institution in Astana. The Kazakh Humanities and Law Institute is a law university founded by initiative of Ministry of Justice in 1994. The Astana Medical University is the only medical school in Astana. The Kazakh National University of Arts is the premier music school and has provided Astana with highly qualified professional specialists in the field of Arts.
Transport.
Public transport in Astana consists of buses and marshrutkas. Over 720,000 people use public transport daily. There are over 40 bus lines served by more than 1000 vehicles, with over 3000 people working in the public transport sector. Just like buses, marshrutkas have their own predefined routes and work on a shared basis. There are nine marshrutka routes in total. In 2011, Akimat of Astana established a company to implement a series of changes and programmes in the metropolis known as the "New transport system of Astana". As the part of these programmes, Bus rapid transit (BRT) lines are expected to start operating in Astana in 2016. Astana Light Metro is a proposed light rail system. Astana also has air taxi service.
Astana International Airport , located south-east of the city centre, is the main gateway for the city's domestic and international civilian air traffic. It is the second busiest airport in Kazakhstan, with 2,960,181 passengers passing through it in 2014. The airport hosts 13 airlines operating regular passenger flights inside the country and internationally. Air Astana maintains its second largest hub at the airport. An expected 50% increase of passenger traffic by 2017 has spurred construction of a new terminal with an area of about 40,000 sq. m.
Astana Railway Station is the city's main railway station and serves approximately 7,000 people each day. Tulpar Talgo is a daily express train to Almaty. Short-term plans include construction of a new railway station in the industrial district; in the vicinity of CHPP-3 a new terminal will be erected for freight cars.
Astana is located in the centre of the country, serving as a well-positioned transport node for rail and automotive networks. M-36 Chelyabinsk-Almaty and A-343 Astana-Petropavlovsk highways are routed through the city. The strategic geographical positioning of Astana allows the city to serve as a transport and reload centre for cargoes formed at adjacent stations in the area.
Twin towns and sister cities.
Astana maintains official partnerships with 18 cities. Astana's twin towns and sister cities are:

</doc>
<doc id="56605" url="https://en.wikipedia.org/wiki?curid=56605" title="Inuit throat singing">
Inuit throat singing

Inuit throat singing, or katajjaq, is a form of musical performance uniquely found among the Inuit. (An analogous form called "rekuhkara" was once practiced among the Ainu of Hokkaidō, Japan.) The Inuit performers are usually women who sing only duets in a kind of entertaining contest to see who can outlast the other. However, at least one notable performer, Tanya Tagaq, performs throat singing as a solo artist and as a collaborator with non-throat singing musicians such as Icelandic singer-songwriter Björk. The musical duo Tudjaat performed a mixture of traditional throat singing and pop music.
New World terms.
The name for throat singing in Canada varies with the geography:
History.
Originally, katajjaq was a form of entertainment among Inuit women while men were away on hunting trips, and it was a regarded more as a type of vocal or breathing game in the Inuit culture rather than a form of music.
Performance.
Two women face each other usually in a standing position and holding each other's arms. Sometimes they will do some kind of dance movements while singing (e.g., balancing from right to left). One singer leads by setting a short rhythmic pattern, which she repeats leaving brief silent intervals between each repetition. The other singer fills in the gap with another rhythmic pattern. The sounds used include voiced sounds as well as unvoiced ones, both through inhalation or exhalation. The first to run out of breath or be unable to maintain the pace of the other singer will start to laugh or simply stop and will thus be eliminated from the game. It generally lasts between one and three minutes. The winner is the singer who beats the largest number of people.
At one time, the lips of the two women almost touched, so that one singer used the mouth cavity of the other as a resonator, but this is less common in present day. Often, the singing is accompanied by a shuffling in rhythm from one foot to the other. The sounds may be actual words or nonsense syllables or created during exhalation.
"The old woman who teaches the children singing songs corrects sloppy intonation of contours, poorly meshed phase displacements, and vague rhythms exactly like a Western vocal coach."
Recognition.
In 2014, Nunavik throat singing ("katajjaniq") became the first cultural item to be given the intangible cultural heritage designation by the government of the province of Quebec, Canada.

</doc>
