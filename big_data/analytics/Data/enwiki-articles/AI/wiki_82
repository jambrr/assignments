<doc id="63811" url="https://en.wikipedia.org/wiki?curid=63811" title="Kitniyot">
Kitniyot

Kitniyot, (, "qit'niyyot") ("legumes") is a Hebrew word meaning legumes. During the Passover holiday, the word kitniyot takes on a broader meaning to include the category of foods that may not be eaten during Passover by Jews following traditional Ashkenazi laws and customs. Long-standing tradition in other communities and recent rulings have given support in certain cases for variation from this practice.
Kitniyot according to the Passover tradition includes legumes, but also grains and seeds. Examples include rice, corn, sunflower seeds, sesame seeds, soy beans, peas, and lentils.
Laws and customs.
The Halakhic argument (the argument according to Jewish law and tradition) against eating kitniyot during Passover is an extension of the prohibition on leaven (chametz), which originated in early medieval France and later flourished in high medieval Ashkenazi (Rhineland) Germany.
The Torah () prohibits Jews from eating chametz during Passover. Chametz is only leaven made from the "five grains": wheat, spelt, barley, "shibbolet shu'al" (two-rowed barley, according to Maimonides; oats according to Rashi) or rye. There are additional rabbinic prohibitions against eating these grains in any form other than matzo.
Among Ashkenazi Jews, the custom ("minhag") during Passover is to refrain from not only products of the five grains but also other grains and legumes. Traditions of what is considered kitniyot vary from community to community but generally include maize (North American corn), as well as rice, peas, lentils, and beans. Many also include other legumes, such as peanuts and soy, in this prohibition. The Chayei Adam considers potatoes not to be kitniyot, and decided that because potatoes were unknown in the time when the prohibition was created they could not have been included in the prohibition (Sha'arei Teshuvah 453:1). This opinion is followed today by nearly all Ashkenazi authorities. Sephardi Jews typically do not observe the ban on kitniyot, albeit some groups do abstain from the use of dried pulses during Passover.
History.
The origins of this practice is not clear, though two common theories are that these items are often made into products resembling chametz (e.g. cornbread), or that these items were normally stored in the same sacks as the five grains and people worried that they might become contaminated with chametz. It is also possible that crop rotation would result in the forbidden chametz grains growing in the same fields, and being mixed in with the kitniyot. Those authorities concerned with these three issues suggested that by avoiding eating kitniyot, people would be better able to avoid chametz. Vilna Gaon (Hagaos HaGra, ibid.) proposes a different source for this custom. The Gemara in Pesachim (40b) notes that Rava objected to the workers of the Exilarch cooking a food called "chasisi" on Pesach, since it was wont to be confused with chametz. Tosafot understand that "chasisi" are lentils, and thus, argues Vilna Gaon, establishes the basis for the concern for kitniyot. Rabbi David Golinkin in the Responsa of the Masorati (Conservative) Movement cites Rabbenu Manoah (Provence, ca. 1265) who wrote an opinion in his commentary on Maimonides (Laws of Festivals and Holidays 5:1) that "It is not proper to eat kitniyot on holidays because it is written (in ) that ‘you shall rejoice in your festivals’ and there is no joy in eating dishes made from kitniyot". Lentils were a food of mourners.
Jewish law is quite stringent about the prohibition against chametz in the house during Passover, even in small amounts. Thus a tradition developed to avoid these products altogether.
Even where the prohibition against kitniyot was practiced, some poskim opposed it, among them Rabbi Yeruham of 14th century Provence. Others, including Rav Moshe Feinstein did not advocate abandoning the custom, but he opposed expanding the list of forbidden kitniyot 
Sephardic and Yemenite Jews eat kitniyot on Passover, and some Ashkenazi Jews in Israel who are married to Sephardic Jews adopt the Sephardic custom.
Orthodox Rabbi David Bar-Hayim at 'Beth HaWaad' beth din of Machon Shilo and Conservative Rabbi David Golinkin of the Schechter Institute of Jewish Studies are among the rabbis who assert that consuming kitniyot is permissible for Ashkenazim in Israel. According to "The Forward", some Israelis are choosing a more permissive rabbinical interpretation of kitniyot, which allows for the consumption of a wider range of formerly banned items.
Maxwell House coffee hired the Joseph Jacobs advertising firm in the 1930s to market to a Jewish demographic. The agency hired a rabbi to research coffee, resulting in a determination that the coffee bean is more like a berry than a bean, thus making it kosher for Passover.
American Judaism and Kitniyot.
While most Conservative Jews observe the tradition of avoiding "kitniyot" during Passover, the Committee on Jewish Law and Standards, an authoritative body in Conservative Judaism, issued two responsa in December 2015 that said it was now permissible to eat these previously prohibited foods throughout the world. These responsa were based on a 1989 responsa by the Responsa Committee of the Israeli Conservative Movement that permitted Conservative Jews in Israel to eat "kitniyot".
Reform Jewish authorities, such as the Responsa Committee of the Reform Jewish Movement for the principal organization of Reform rabbis in the United States and Canada, have also ruled in favor of permitting kitniyot. Reform Judiasm first formally permitted eating "kitniyot" during Passover in the 19th century.
Some Orthodox rabbis, such as the "Machon Shilo" institute's David Bar-Hayim, have argued that the prohibition of "kitniyot", while appropriate in Eastern Europe where the Askenazi tradition began, should not apply to the United States or Israel. However, the Union of Orthodox Jewish Congregations of America and other Orthodox organizations still maintain that the prohibition is binding on all Ashenazic jews worldwide. The Orthodox Union maintains a kitniyot hechsher intended for non-Ashkenazic Jews who consume "kitniyot" on Passover.
While eating kitniyot has become more common in Israel, due in large part to the influence of Sephardic Jewish food customs, it is not yet clear whether Conservative and Reform Jews in America will embrace the new rulings or continue to refrain from kitniyot.

</doc>
<doc id="63813" url="https://en.wikipedia.org/wiki?curid=63813" title="Judenrat">
Judenrat

Judenrat (plural: Judenräte; German for "Jewish council") was a widely used administrative agency imposed by Nazi Germany during World War II, predominantly within the ghettos in Nazi-occupied Europe, and the Jewish ghettos in German-occupied Poland. The Nazi German administration required Jews to form a "Judenrat" in every community across the occupied territories.
The "Judenrat" constituted a form of self-enforcing intermediary, used by the Nazi administration to control larger Jewish communities in occupied areas. The Germans also implemented the name Jewish Council of Elders ("Jüdischen Ältestenrat" or "Ältestenrat der Juden") in some ghettos, as in the Łódź Ghetto, and in Theresienstadt or in the Bergen-Belsen concentration camp. While the history of the term "Judenrat" itself is unclear, Jewish communities themselves had established councils for self-government as far back as the Medieval Era. While the Hebrew term of "Kahal" (קהל) or "Kehillah" (קהילה) was used by the Jewish community, German authorities generally tended to use the term "Judenräte".
Nazi considerations of Jewish legal status.
The structure and missions of the "Judenräte" under the Nazi regime varied widely, often depending upon whether meant for a single ghetto, a city or a whole region. Jurisdiction over a whole country, as in Nazi Germany, was maintained by "Reichsvereinigung der Juden in Deutschland" (Reich's Association of the Jews in Germany) established on 4 July 1939.
In the beginning of April 1933, shortly after the National Socialist government took power, a report by a German governmental commission was presented on fighting the Jews. This report recommended the creation of a recognized 'Association of Jews in Germany' ("Verband der Juden in Deutschland"), to which all Jews in Germany would be forced to associate. Then, appointed by the Reichskanzler, a German People's Ward was to assume responsibility of this group. As the leading Jewish organization, it was envisioned that this association would have a 25-member council called the "Judenrat". However, the report was not officially acted upon.
The Israeli historian Dan Michman found it likely that the commission, which considered the legal status and interactions of Jews and non-Jews before their emancipation, reached back to the Medieval Era for the term "Judenräte". This illuminates the apparent intent to make the Jewish emancipation and assimilation invalid, and so return Jews to the status they held during the Medieval Era.
Occupied territories.
The first actual "Judenräte" were established in occupied Poland by Reinhard Heydrich's orders on 21 September 1939, soon after the end of the German assault on Poland and later the occupied territories of the Soviet Union.
The "Judenräte" were to serve as a means to enforce the occupation force's anti-Jewish regulations and laws in the western and central areas of Poland, and had no authority of their own. Ideally, a local "Judenrat" was to include Rabbis and other influential people of their local Jewish community. Thus, enforcement of laws could be better facilitated by the German authorities by using established Jewish authority figures and personages, while undermining external influences.
Further "Judenräte" were established on 18 November 1939, upon the orders of Hans Frank, head of the Generalgouvernment. These councils were to have 12 members for Jewish communities of 10,000 or less, and up to 24 members for larger Jewish communities. Jewish communities were to elect their own councils, and by the end of 1939 were to have selected an executive and assistant executive as well. Results were to be presented to the German city or county controlling officer for recognition. While theoretically democratic, in reality the councils were often determined by the occupiers. While the German occupiers only minimally involved themselves in the voting, those whom the Germans first chose often refused participation to avoid becoming exploited by the occupiers. As a rule, therefore, the traditional speaker of the community was named and elected, preserving the community continuity.
Missions and duties.
The Nazis systematically sought to weaken the resistance potential and opportunities of the Jews of Eastern Europe. The early "Judenräte" were foremost to report numbers of their Jewish populations, clear residences and turn them over, present workers for forced labour, confiscate valuables, and collect tribute and turn these over. Failure to comply would incur the risk of collective punishments or other measures. Later tasks of the "Judenräte" included turning over community members for deportation.
Through these occupation measures, and the simultaneous prevention of government services, the Jewish communities suffered serious shortages. For this reason, early "Judenräte" attempted to establish replacement service institutions of their own. They tried to organize food distribution, aid stations, old age homes, orphanages and schools. At the same time, given their restricted circumstances and remaining options, they attempted to work against the occupier's forced measures and to win time. One way was to delay transfer and implementation of orders and to try playing conflicting demands of competing German interests against each other. They presented their efforts as indispensable for the Germans in managing the Jewish community, in order to improve the resources of the Jews and to move the Germans to repeal collective punishments.
This had, however, very limited positive results. The generally-difficult situations presented often led to perceived unfair actions, such as personality preferences, sycophancy, and protectionism of a few over the rest of the community. Thus, the members of the community quickly became highly critical of, or even outright opposed their "Judenrat".
Ghetto situation.
"Judenräte" were responsible for the internal administration of ghettos, standing between the Nazi occupiers and their Jewish communities. In general, the "Judenräte" represented the elite from their Jewish communities. Often, a "Judenrat" had a group for internal security and control, a Jewish "Ordnungspolizei". They also attempted to manage the government services normally found in a city such as those named above. However, the requirements of the Nazis to deliver community members to forced labor, deportation or Nazi concentration camps placed them in the position of helping the occupiers. To resist such actions or orders was to risk summary execution or inclusion in the next concentration camp shipment, with a quick replacement.
In a number of cases, such as the Minsk ghetto and the Łachwa ghetto, "Judenräte" cooperated with the resistance movement. In other cases, "Judenräte" cooperated with the Nazis.
The role of the "Judenräte" in the Holocaust.
Hannah Arendt stated in her 1963 book "Eichmann in Jerusalem" that without the assistance of the "Judenräte", the registration of the Jews, their concentration in ghettos and, later, their active assistance in the Jews' deportation to extermination camps, many fewer Jews would have perished because the Germans would have encountered considerable difficulties in drawing up lists of Jews. In occupied Europe, the Nazis entrusted Jewish officials with the task of making such lists of Jews along with information about the property they owned. The "Judenräte" also directed the Jewish police to assist the Germans in catching Jews and loading them onto transport trains leaving for Nazi concentration camps.
In her book, Arendt wrote that: "To a Jew, this role of the Jewish leaders in the destruction of their own people is undoubtedly the darkest chapter of the whole dark story. [...] In the matter of cooperation, there was no distinction between the highly assimilated Jewish communities of Central and Western Europe and the Yiddish-speaking masses of the East. In Amsterdam as in Warsaw, in Berlin as in Budapest, Jewish officials could be trusted to compile the lists of persons and of their property..."
Arendt's view has been challenged by other historians of the Holocaust, including Isaiah Trunk in his book "Judenrat: The Jewish Councils in Eastern Europe Under Nazi Occupation" (1972). Summarising Trunk's research, Holocaust scholar Michael Berenbaum has written: "In the final analysis, the Judenräte had no influence on the frightful outcome of the Holocaust; the Nazi extermination machine was alone responsible for the tragedy, and the Jews in the occupied territories, most especially Poland, were far too powerless to prevent it."

</doc>
<doc id="63816" url="https://en.wikipedia.org/wiki?curid=63816" title="Huntington Beach, California">
Huntington Beach, California

Huntington Beach is a seaside city in Orange County in Southern California. The city is named after American businessman Henry E. Huntington. The population was 189,992 during the 2010 census, making it the most populous beach city in Orange County and the seventh most populous city in the Los Angeles-Long Beach-Anaheim MSA. Its estimated 2014 population was 200,809. It is bordered by the Pacific Ocean on the southwest, by Seal Beach on the northwest, by Costa Mesa on the east, by Newport Beach on the southeast, by Westminster on the north, and by Fountain Valley on the northeast.
Huntington Beach (locally initialized "HB") is known for its long stretch of sandy beach, mild climate, excellent surfing, and beach culture. The ocean waves are enhanced by a natural effect caused by the edge-diffraction of open ocean swells around Santa Catalina Island. Swells generated predominantly from the North Pacific in winter and from a combination of Southern Hemisphere storms and hurricanes in the summer focus on Huntington Beach, creating consistent surf all year long, hence the nickname "Surf City".
History.
The area was originally occupied by the Tongva people. European settlement can be traced to a Spanish soldier, Manuel Nieto, who in 1784 received a Spanish land grant of , Rancho Los Nietos, as a reward for his military service and to encourage settlement in Alta California. Nieto's western area was reduced in 1790 because of a dispute with the Mission San Gabriel, but he retained thousands of acres stretching from the hills north of Whittier, Fullerton and Brea, south to the Pacific Ocean, and from today's Los Angeles River on the west, to the Santa Ana River on the east.
The main thoroughfare of Huntington Beach, Beach Boulevard, was originally a cattle route for the main industry of the Rancho. Since its time as a parcel of the enormous Spanish land grant, Huntington Beach has undergone many incarnations. One time it was known as Shell Beach, the town of Smeltzer, and then Gospel Swamp for the revival meetings that were held in the marshland where the community college Golden West College can currently be found. Later it became known as Fairview and then Pacific City, as it developed into a tourist destination. In order to secure access to the Red Car lines that used to criss-cross Los Angeles and ended in Long Beach, Pacific City ceded enormous power to railroad magnate Henry E. Huntington, and thus became a city whose name has been written into corporate sponsorship, and like much of the history of Southern California, boosterism.
Huntington Beach was incorporated on February 17, 1909 during the tenure of its first mayor, Ed Manning. Its original developer was "Huntington Beach Company" (formerly the West Coast Land and Water Company), a real-estate development firm owned by Henry Huntington. The Huntington Beach Company is still a major land-owner in the city, and still owns most of the local mineral rights. The company is now wholly owned by the Chevron Corporation.
An interesting hiccup in the settlement of the district occurred when an encyclopedia company gave away free parcels of land, with the purchase of a whole set for $126, in the Huntington Beach area that it had acquired cheaply. The lucky buyers got more than they had bargained for when oil was discovered in the area, and enormous development of the oil reserves followed. Though many of the old reserves are depleted, and the price of land for housing has pushed many of the rigs off the landscape, oil pumps can still be found to dot the city.
Huntington Beach was primarily agricultural in its early years with crops such as celery and sugar beets. Holly Sugar was a major employer with a large processing plant in the city that was later converted to an oil refinery.
The city's first high school, Huntington Beach High School, located on Main Street, was built in 1906. The school's team, the Oilers, is named after the city's original natural resource.
Meadowlark Airport, a small general aviation airport, existed in Huntington Beach from the 1940s until 1989.
Geography.
According to the United States Census Bureau, the city has a total area of . of it is land and of it (16.10%) is water.
The entire city of Huntington Beach lies in area codes 657 and 714, except for small parts of Huntington Harbour (along with Sunset Beach, the community adjacent to Huntington Harbour), which is in the 562 Area Code.
Climate.
Huntington Beach has a borderline semi-arid/Mediterranean climate (Köppen climate classification "BSh/Csb"). The climate is generally sunny, dry and cool, although evenings can be excessively damp. In the morning and evening, there are often strong breezes that can reach . Ocean water temperatures average to . In the summer, temperatures rarely exceed . In the winter, temperatures rarely fall below , even on clear nights. There are about of rain, almost all in mid-winter. Frost occurs only rarely on the coldest winter nights. The area is annually affected by a marine layer caused by the cool air of the Pacific Ocean meeting the warm air over the land. This results in overcast and foggy conditions in May and June.
Natural resources.
Construction of any kind on the beach is prohibited without a vote of the people, allowing Huntington Beach to retain its natural connection to the ocean rather than having the view obstructed by residential and commercial developments.
Between Downtown Huntington Beach and Huntington Harbour lies a large marshy wetland, much of which is protected within the Bolsa Chica Ecological Reserve. A $110 million restoration of the wetlands was completed in 2006. The Reserve is popular with bird watchers and photographers.
South of Downtown, the Talbert, Brookhurst and Magnolia Marshes, which lie across the street from Huntington State Beach, had restoration completed in 2010.
The northern and southern beaches (Bolsa Chica State Beach and Huntington State Beach, respectively) are state parks. Only the central beach (Huntington City Beach) is maintained by the city. Camping and RVs are permitted here, and popular campsites for the Fourth of July and the Surfing Championships must be reserved many months in advance. Bolsa Chica State Beach is actually a sand bar fronting the Bolsa Bay and Bolsa Chica State Ecological Reserve.
The Orange County run Sunset Marina Park next to is part of Anaheim Bay. It is suitable for light craft, and includes a marina, launching ramp, basic services, a picnic area and a few restaurants. The park is in Seal Beach, but is only reachable from Huntington Harbour. The Sunset/Huntington Harbour area is patrolled by the Orange County Sheriff's Harbor Patrol.
The harbor entrance for Anaheim Bay is sometimes restricted by the United States Navy, which loads ships with munitions at the Seal Beach Naval Weapons Station to the north of the main channel.
Demographics.
2010.
The 2010 United States Census reported that Huntington Beach had a population of 189,992. The population density was 5,959.1 people per square mile (2,300.8/km²). The racial makeup of Huntington Beach was 145,661 (76.7%) White, 1,813 (1.0%) African American, 992 (0.5%) Native American, 21,070 (11.1%) Asian, 635 (0.3%) Pacific Islander, 11,193 (5.9%) from other races, and 8,628 (4.5%) from two or more races. Hispanic or Latino of any race were 32,411 persons (17.1%). Non-Hispanic Whites were 67.2% of the population in 2010, compared to 90.8% in 1970.
The Census reported that 189,102 people (99.5% of the population) lived in households, 487 (0.3%) lived in non-institutionalized group quarters, and 403 (0.2%) were institutionalized.
There were 74,285 households, out of which 21,922 (29.5%) had children under the age of 18 living in them, 36,729 (49.4%) were opposite-sex married couples living together, 7,685 (10.3%) had a female householder with no husband present, 3,804 (5.1%) had a male householder with no wife present. There were 4,386 (5.9%) unmarried opposite-sex partnerships, and 504 (0.7%) same-sex married couples or partnerships. 18,489 households (24.9%) were made up of individuals and 6,527 (8.8%) had someone living alone who was 65 years of age or older. The average household size was 2.55. There were 48,218 families (64.9% of all households); the average family size was 3.07.
The population was spread out with 39,128 people (20.6%) under the age of 18, 15,906 people (8.4%) aged 18 to 24, 54,024 people (28.4%) aged 25 to 44, 53,978 people (28.4%) aged 45 to 64, and 26,956 people (14.2%) who were 65 years of age or older. The median age was 40.2 years. For every 100 females there were 98.5 males. For every 100 females age 18 and over, there were 96.6 males.
There were 78,003 housing units at an average density of 2,446.5 per square mile (944.6/km²), of which 44,914 (60.5%) were owner-occupied, and 29,371 (39.5%) were occupied by renters. The homeowner vacancy rate was 1.1%; the rental vacancy rate was 5.4%. 115,470 people (60.8% of the population) lived in owner-occupied housing units and 73,632 people (38.8%) lived in rental housing units.
During 20092013, Huntington Beach had a median household income of $81,389, with 8.9% of the population living below the federal poverty line.
2000.
At the 2000 census The population density was 7,183.6 inhabitants per square mile (2,773.9/km²). There were 75,662 housing units at an average density of 2,866.8 per square mile (1,107.0/km²). The racial makeup of the city was 79.2% White, 0.8% Black or African American, 0.7% Native American, 9.3% Asian, 0.2% Pacific Islander, 5.8% from other races, and 3.9% from two or more races. 14.7% of the population were Hispanic or Latino of any race.
There were 73,657 households out of which 29.0% had children under the age of 18 living with them, 50.7% were married couples living together, 9.6% had a female householder with no husband present, and 35.2% were non-families. 24.3% of all households were made up of individuals and 6.7% had someone living alone who was 65 years of age or older. The average household size was 2.56 and the average family size was 3.08.
In the city the population was spread out with 22.2% under the age of 18, 8.4% from 18 to 24, 34.9% from 25 to 44, 24.0% from 45 to 64, and 10.4% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 100.4 males. For every 100 females age 18 and over, there were 98.6 males.
The median income for a household in the city was $76,527, and the median income for a family was $94,597. Adult males had a median income of $50,021 versus $33,041 for adult females. The per capita income for the city was $40,183. About 5.1% of families and 7.8% of the population were below the poverty line, including 11.2% of those under age 18 and 4.4% of those age 65 or over.
Economy.
Huntington Beach sits above a large natural fault structure containing oil. Although the oil is mostly depleted, extraction continues at a slow rate, and still provides significant local income. There are only two off-shore extraction facilities left, however, and the day is not far off when oil production in the city will cease and tourism will replace it as the primary revenue source for resident industry.
The city is discussing closing off Main Street to cars from PCH through the retail shopping and restaurant areas, making it a pedestrian zone only. Other shopping centers include Bella Terra, built on the former Huntington Center site, and Old World Village, a German-themed center.
Huntington Beach has an off-shore oil terminus for the tankers that support the Alaska Pipeline. The terminus pipes run inland to a refinery in Santa Fe Springs. Huntington Beach also has the Gothard-Talbert terminus for the Orange County portion of the pipeline running from the Chevron El Segundo refinery.
Several hotels have been constructed on the inland side of Pacific Coast Highway (State Route 1) within view of the beach, just southeast of the pier.
Huntington Beach contains a major installation of Boeing, formerly McDonnell-Douglas. A number of installations on the Boeing campus were originally constructed to service the Apollo Program, most notably the production of the S-IVB upper stage for the Saturn IB and Saturn V rockets, and some nearby telephone poles are still marked "Apollo Dedicated Mission Control Line."
Huntington Beach is also home to the headquarters of Cambro Manufacturing, an international foodservice equipment company, with two manufacturing facilities in the city.
Huntington Beach contains a small industrial district in its northwest corner, near the borders with Westminster and Seal Beach.
Surf City USA trademarks.
While Huntington Beach retains its 15-year trademark of Surf City Huntington Beach, the Huntington Beach Conference and Visitors Bureau filed four applications to register the "Surf City USA" trademark in November 2004. The idea was to market the city by creating an authentic brand based on Southern California's beach culture and active outdoor lifestyle while at the same time creating a family of product licensees who operate like a franchise family producing a revenue stream that could also be dedicated to promoting the brand and city. A ruling by the U.S. Patent and Trademark Office released on May 12, 2006 awarded three trademark registrations to the Bureau; nine additional trademark registrations have been granted since this time and ten other Surf City USA trademarks are now under consideration. One of the first products the Bureau developed to promote its brand was the Surf City USA Beach Cruiser by Felt Bicycles in 2006. The product has sold out every year in markets worldwide and created demand for a second rental bicycle model that will be marketed to resort locations across the globe starting in 2009. The Bureau now has dozens of other licensed products on the market from Surf City USA soft drinks to clothing to glassware. As of April 2008, the Bureau had more than 20 licensing partners with over 50 different products being prepared to enter the market over the next 18 months. Four of the Bureau's registrations of the trademark are now on the principal register and the remaining ten trademark applications are expected to follow. The Bureau is actively considering registration of the Surf City USA trademark in several different countries and anticipates a growing market for its branded products overseas in coming years.
An ongoing dispute between Huntington Beach and Santa Cruz, California over the trademark garnered positive national publicity in 2007 when a law firm representing Huntington Beach sent a cease-and-desist letter to a Santa Cruz T-shirt vendor. A settlement was reached in January, 2008, which allows the Huntington Beach Conference and Visitors Bureau to retain the trademark.
Tourism.
The downtown district includes an active art center, a colorful shopping district, and the International Surfing Museum. This district was also the home of the Golden Bear from 1929 to 1986. Originally a fine dining restaurant opened by Harry Bakre in 1929, the Golden Bear became a nightclub in 1963 and hosted famous-name entertainment until it was demolished in 1986. The list of artists who performed there includes BB King, Janis Joplin, Steve Martin, Charles Bukowski, The Ramones and Stevie Ray Vaughan. The Huntington Beach Pier stretches from Main Street into the Pacific Ocean. At the end of the pier is a Ruby's Diner.
The Surf Theatre, which was located one block north of the pier, gained fame in the 1960s and 1970s for showing independent surf films such as "The Endless Summer" and "Five Summer Stories". The Surf Theatre was owned and operated by Hugh Larry Thomas from 1961 until it was demolished in 1989. A newer version of The Surf Theatre is now closed, but the Huntington Beach International Surfing Museum has preserved its memory with ongoing screenings of surfing movies once shown at a Huntington Beach theater and the original metal SURF sign. Another surfing-related attraction in Huntington Beach is the Surfing Walk of Fame.
Top employers.
According to Huntington Beach's 2014 Comprehensive Annual Financial Report, the top employers in the city are:
BJ's Restaurant & Brewery is also based in Huntington Beach.
Arts and culture.
Special events.
Many of the events at Huntington Beach are focused around the beach during the summer. The U.S. Open of Surfing is featured on the south side of the pier. Huntington Beach was a stop on the AVP beach volleyball tour. A biathlon (swim/run) hosted by the Bolsa Chica & Huntington State Beach Lifeguards takes place in July, early at dawn. The race begins at the Santa Ana River Jetties and ends at Warner Avenue, Bolsa Chica State Beach. Huntington Beach Junior Lifeguard day camps are held which teaches pre-adolescents and adolescents ocean swimming, running, and first-aid medical knowledge.
In addition to the beach-focused events, the Fourth of July parade has been held since 1904. The SoCal Independent Film Festival takes place every September.
During the winter the annual Cruise of Lights Boat Tour is held in the Huntington Harbour neighborhood. This is a parade of colorful lighted boats as well as boat tours to view the decorated homes. In February of each year since 1996, the Surf City USA marathon is held with over 20,000 runners. The annual Kite Festival is held just north of the pier in late February.
Huntington Beach hosts car shows such as the Beachcruiser Meet and a Concours d'Elegance. The Beachcruiser Meet is held in March, attracting over 250 classic cars displayed along Main Street and the Pier parking lot. A Concours d'Elegance is held at Central Park in June and benefits the public library. An informal "Donut Derelicts" car show occurs every Saturday morning at the intersection of Adams and Magnolia Street.
Surf City Nights is held every Tuesday night during the entire year. The Tuesday Surf City Nights is a community-spirited event that features a farmer's market, unique entertainment, food, kiddie rides and a carnival atmosphere. Surf City Nights and the Downtown Huntington Beach Art Walk are presented by the Huntington Beach Downtown Business Improvement District (HBDBID) and the City of Huntington Beach. The Tuesday night Surf City Nights event takes place in the first three blocks of Main Street from Pacific Coast Highway to Orange Avenue.
Sports.
Huntington Beach is the site of the world surfing championships, held in the summer every year. The city is often referred to as "Surf City" because of this high profile event, its history and culture of surfing. It is often called the "Surfing Capital of the World", not for the height of the waves, but rather for the consistent quality of surf. Gordon Duane established the city's first surf shop, Gordie's Surfboards, in 1955.
Huntington Beach's Ocean View Little League won the 2011 Little League World Series championship, beating Japan 2-1.
Surf and beaches.
George Freeth was the first person to surf in Huntington Beach with a demonstration on June 20, 1914. Freeth had been demonstrating surfing in southern California as a promotion for the city by Henry E. Huntington. Duke Kahanamoku started surfing in Huntington Beach in 1925 and helped popularize the sport. The first surfboard shop, which was located underneath the Huntington Beach Pier, opened in 1956 by Gordie Duane.
Apart from sponsored surf events, Huntington Beach has some of the best surf breaks in the State of California and that of the United States. Huntington Beach has four different facing beaches: Northwest, West, Southwest, and South. Northwest consists of Bolsa Chica State Beach with a length of , the West consist of "The Cliffs" or "Dog Beach", Southwest is considered everything north of the pier which is operated by the City of Huntington Beach. South consists in everything south of the pier which primarily focuses on Huntington State Beach (2.2 Miles), which almost faces true South.
Bolsa Chica State Beach is operated by the State of California, Dept. Parks & Recreation, and the Bolsa Chica State Beach Lifeguards. The beach is very narrow and the sand is very coarse. Bolsa Chica tends to have better surf with NW/W swells during the winter season. During the summer months the beach picks up south/southwest swells at a very steep angle. Due to the bottom of the beach, surf at Bolsa Chica tends to be slowed down and refined to soft shoulders. Longboards are the best option for surfing in the Bolsa Chica area.
"The Cliffs" or "Dog Beach" is also another popular surf spot. This segment of Huntington Beach obtains these names because dogs are allowed around the cliff area. Beach is very restricted and often is submerged with high tides. Surf at this location tends to be even bigger than Bolsa Chica during the winter and often better. During the summer most of the South/Southwest swells slide right by and often break poorly. The best option is to take out a longboard, but shortboards will do at times. Dolphins have also been sighted in this area.
Just north and south of the Huntington Beach Pier are some well defined sandbars that shift throughout the year with the different swells. Southside of the Pier is often a popular destination during the summer for good surf, but the Northside can be just as well during the winter. Around the Pier it all depends on the swell and the sandbars. Shortboard is your best option for surfing around the Pier.
South Huntington Beach, also known as Huntington State Beach, is where all the south swells impact the coastline. Huntington State Beach is operated by the State of California, Department of Parks & Recreation, and Huntington State Beach Lifeguards. This beach is very wide with plenty of sand. Sandbars dramatically shift during the spring, summer and fall seasons, thus creating excellent surf conditions with a combination South/West/Northwest swell. Due to the Santa Ana River jetties located at the southernmost end of the beach, large sandbars extend across and upcoast, forcing swells to break extremely fast and hollow. Best seasons for surfing at this beach is the summer and fall. The best option for surfing in this area is a shortboard.
Huntington Beach is also a popular destination for kite surfing, and this sport can be viewed on the beach northwest of the pier.
Huntington Beach is the host city of the National Professional Paintball League Super 7 Paintball Championships. The NPPL holds its first event of the year traditionally between the dates of March 23 through March 26.
Huntington Beach also hosts the annual Surf City USA Marathon and Half-Marathon, which is usually held on the first Sunday of February.
Parks and recreation.
Huntington Beach has a large central park, known as Huntington Central Park. Central Park is located between Gothard and Edwards Streets to the east and west, and Slater and Ellis Avenues to the north and south. Dedicated on June 15, 1974, Huntington Central Park is the largest city owned park in Orange County with nearly . The park is vegetated with xeric (low water use) plants, and inhabited by native wildlife. Thick forests encircling the park are supplemented with Australian trees, particularly Blue Gum Eucalyptus, a high water use plant.
The Huntington Beach Public Library is located in Central Park in a notable building designed by Richard Neutra and Dion Neutra. It houses almost a half-million volumes, as well as a theater, gift shop and fountains. The library was founded as a Carnegie library in 1914, and has been continuously supported by the city and local activists, with new buildings and active branches at Banning, Oak View, Main Street, and Graham. The library has significant local historical materials and has a special genealogical reference collection. It is independent of the state and county library systems.
The park is also home of Huntington Central Park Equestrian Center, a top class boarding facility that also offers horse rentals to the public, with guided trail rides through the park. There is also a "mud park" available for kids. The world's second oldest disc golf course is available in the park, as are two small dining areas, a sports complex for adult use, and the Shipley Nature Center.
The Bolsa Chica Wetlands, which are diminishing rapidly due to development, contains numerous trails and scenic routes. The wetlands themselves have recently been connected with the ocean again, in effort to maintain its previous, unaltered conditions.
Government.
Local government.
The following table shows the current and past mayors of Huntington Beach:
According to the city's most recent Comprehensive Annual Financial Report, the city's various funds had $295.6 million in revenues, $287.7 million in expenditures, $1,046.6 million in total assets, $202.8 million in total liabilities, and $87.1 million in cash and investments.
The structure of the management and coordination of city services is:
Politics.
In the California State Senate, Huntington Beach is in . In the California State Assembly, it is split between , and .
In the United States House of Representatives, Huntington Beach is in .
As of June 1, 2010, the city has 127,660 registered voters. 45.8% are registered Republicans, 28.5% are registered Democrats, 20.7% are unaffiliated, and the remainder are registered with third parties.
Education.
Huntington Beach is the home of Golden West College, which offers two-year associates of arts degrees and transfer programs to four-year universities.
Huntington Beach is in the Huntington Beach Union High School District, which includes Edison High School, Huntington Beach High School, Marina High School, and Ocean View High School in the city of Huntington Beach, Fountain Valley High School in the city of Fountain Valley, and Westminster High School in the city of Westminster.
The district also has an alternative school, Valley Vista High School, and an independent study school, Coast High School.
Huntington Beach High School, which is the district's flagship school, celebrated its 100-year anniversary in 2006.
The city has two elementary school districts: Huntington Beach City School District with 9 schools and Ocean View School District with 15. A small part of the city is served by the Fountain Valley School District.
Huntington Beach is also home to The Pegasus School, a nationally recognized blue ribbon school.
Brethren Christian Junior/Senior High School is a private independent school with about 400 students living within of the school.
Huntington Christian School is a private K-8 school in the city
Grace Lutheran school is a private K-8 school in the city.
Lycée International de Los Angeles previously had its Orange County campus in Huntington Beach.
Media.
The city was featured in the TruTV series "Ocean Force: Huntington Beach". Also, the city is mentioned in the Beach Boys song Surfin' Safari, in Jan and Dean's Surf Route 101 and in Surfer Joe by The Surfaris.
Live cameras are set up at the Huntington Beach Pier and shown on screens at the California-themed Hollister apparel stores. The store pays the city for the cameras, with the money used to fund marine safety equipment. The cameras are also used by lifeguards.
The public television station KOCE-TV operates from the Golden West College campus, in conjunction with the Golden West College Media Arts program.
Two weekly newspapers cover Huntington Beach: The "Huntington Beach Independent" and The Wave Section of "The Orange County Register".
Safety.
Fire protection in Huntington Beach is provided by the Huntington Beach Fire Department. Law enforcement is provided by the Huntington Beach Police Department. Huntington Beach Marine Safety Officers and its seasonal lifeguards are recognized as some of the best in the world with a top notch safety record. It has an active Community Emergency Response Team training program, that trains citizens as Disaster Service Workers certified by Federal Emergency Management Agency (FEMA) as a part of a free program run by the fire department's Office of Emergency Services.
Emergency services are also provided at State Beach locations. Peace Officers and lifeguards can be found at Bolsa Chica and Huntington State Beach. Such services consist of: aquatic rescues, boat rescues, first aid and law enforcement. All services are provided by the State of California, Dept. Parks & Recreation .
In 1926, the Santa Ana River dam failed, and flash-flooded its entire delta. The southern oceanic terminus of this delta is now a settled area of Huntington Beach. The distant dam is still functional, but silting up, which is expected to reduce its storage volume, and therefore its effectiveness at flood-prevention. The flood and dam-endangered areas are protected by a levee, but lenders require expensive flood insurance in the delta. There have been serious discussions to eliminate the need for flood insurance and this requirement has already been waived in some areas and may one day no longer be considered a credible threat.
Since it is a seaside city, Huntington Beach has had tsunami warnings, storm surge (its pier has been rebuilt three times), sewage spills, tornadoes and waterspouts. The cold offshore current prevents hurricanes. The Pier that was rebuilt in the 1990s was engineered to withstand severe storms or earthquakes.
Large fractions of the settled delta are in earthquake liquefaction zones above known active faults. Most of the local faults are named after city streets.
Many residents (and even city hall) live within sight and sound of active oil extraction and drilling operations. These occasionally spew oil, causing expensive clean-ups. Large parts of the developed land have been contaminated by heavy metals from the water separated from oil.
The local oil has such extreme mercury contamination that metallic mercury is regularly drained from oil pipelines and equipment. Oil operations increase when the price of oil rises. Some oil fields have been approved for development. The worst-polluted areas have been reclaimed as parks. At least one Superfund site, too contaminated to be a park, is at the junction of Magnolia and Hamilton streets, near Edison High School.
Sister cities.
Huntington Beach has the following sister city relationships, according to the Huntington Beach Sister City Association:

</doc>
<doc id="63824" url="https://en.wikipedia.org/wiki?curid=63824" title="Spicule">
Spicule

Spicules are any of various small needle-like anatomical structures occurring in organisms 
Spicule may also refer to: 

</doc>
<doc id="63829" url="https://en.wikipedia.org/wiki?curid=63829" title="SRAM">
SRAM

SRAM may refer to:

</doc>
<doc id="63831" url="https://en.wikipedia.org/wiki?curid=63831" title="Benalla">
Benalla

Benalla 
is a small city located on the Broken River in the High Country north-eastern region of Victoria, Australia, about north east of the state capital Melbourne. At the the population was 9,328.
It is the administrative centre for the Rural City of Benalla local government area.
History.
Prior to the European settlement of Australia, the Benalla region was populated by the Taungurong people, an Indigenous Australian people.
It was first sighted by Europeans during an expedition of Hamilton Hume and William Hovell in 1824, when the area, first named "Swampy" was noted that agricultural settlement. The expedition was followed by that of Major Thomas Mitchell in 1834.
Reverend Joseph Docker settled in 1838 creating a pastoral run called "Benalta Run", said to be from an Aboriginal word for musk duck. An attack by indigenous people on the camp of sheep herders George and William Faithful became known as the Faithful Massacre; eight settlers were killed in the incident. Following the massacre in 1839 a police station was established and the name of the settlement became Broken River.
The post office opened on 1 December 1844 originally named Broken River
A bridge was built over the Broken River in 1847 and the following year the town was surveyed. In 1861 it was proclaimed a town.
It was proclaimed a city in 1965.
Geography.
Benalla is situated on a mostly flat floodplain of the Broken River catchment situated directly to the north and west of the Great Dividing Range. Lake Benalla is an artificial lake created in 1973 from the Broken River as an ornamental feature for the centre of the city. Broken river forms a green belt along the north-south spine of the city. There are three major crossings of the river at Benalla. The main street in the Central Business District is Bridge Street East.
Another large artificial lake, Lake Mokoan is 7 kilometres to the north east. To the south of the freeway is the heavily forested Reef Hills State Park.
Government.
Benalla is the seat of local government and administrative headquarters for the Rural City of Benalla.
In the Victorian Legislative Assembly, it is represented by the Electoral district of Euroa.
In the Parliament of Australia, it is represented by the Division of Indi in the Australian House of Representatives.
Economy.
Industries include agricultural support services, tourism, a medium density fibreboard factory, Thales Australia ammunition factory and aviation.
As a service economy for the region, Benalla has many large retailers, including a Coles, Woolworths, Target Country, Aldi and a Mitre 10 Home & Trade.
Education.
Benalla has two major secondary schools, Benalla College (which has two campuses), FCJ College and a primary school Australian Christian College - Hume. McCristal's College was a private grammar school that also existed in Benalla.
The Goulburn Ovens Institute of TAFE has a campus in Benalla which includes the "Benalla Performing Arts and Convention Centre" opened in 2004 by Lynne Kosky MP, the then Minister of Education and Training. The campus includes GRADA, a regional academy of dramatic art offering courses in Acting, Dance and Production.
Culture.
Benalla's cultural facilities include the Benalla Performing Arts and Convention Centre which includes a cinema and theatre. The city also has a major art gallery which forms a landmark perched over Lake Benalla on the site of the original police station.
The Rose Festival is an annual local garden festival dating from 1967.
Sport and recreation.
The town has an Australian rules football team (Benalla Saints) competing in the Goulburn Valley Football League and a team (Benalla All Blacks) competing in the Ovens & King Football League.
Benalla has a horse racing club, the Benalla Racing Club, which schedules around eleven race meetings a year including the Benalla Cup meeting in early October.
Golfers play at the Benalla Golf Club on Mansfield Road, which celebrated its centenary in 2003 or at the course of the Golden Vale Golf Club on Golden Vale Road, Benalla.
Benalla is also the closest major centre to Winton Motor Raceway, a privately owned motor racing circuit which holds motor racing event at all levels of domestic competition, including V8 Supercar.
Benalla Gardens Oval is the home of the Benalla & District Cricket Association. The ground has hosted touring teams since the 19th century. In the Rural City of Benalla there are numerous cricket grounds.
Benalla is also home to the Benalla Bandits Baseball Club who compete in the North East Baseball Association, The team plays out of Racecourse Reserve, Benalla.[http://www.benallabandits.baseball.com.au/db/Clubdisplay.asp?ID=3082]
Benalla is home to the Gliding Club of Victoria at the State Gliding Centre located on the Benalla airfield. This club is the longest continuous operating gliding club in Australia and has played host for the World Gliding Competition in 1987 and 2016. Many of the club's members travel from Europe each summer to enjoy the warm weather and ideal soaring conditions of the region.
There is a park and walking track that circumnavigates Lake Benalla, featuring a ceramic sculpture community that was created as part of an employment project for local artists.
Heritage.
The following sites are National Trust sites.
Another heritage site is Lake Benalla - the site of the former Police Station. The listed Police Members were Corp. Thomas Whitwell, Troopers John , Patrick Monahan, Thomas Cornwark and Dismounted Trooper Edward Beech; these officers were Gazetted on 30 April 1839. Benalla Police is Victoria's longest serving.
Media.
Benalla has a local newspaper, the Benalla Ensign, which is published weekly.
Infrastructure.
Health services are provided by Benalla Health, which operates the Benalla & District Memorial Hospital.
Transport.
Road transport and the motor vehicle is the main form of transport. The Hume Freeway (National Highway M31) bypasses Benalla to the south, while the Midland Highway (A300) runs through the city centre. The road system is also the main form of public transport. Benalla Bus Lines run a service every hour on each of two routes, servicing the west and east sides of the city. Its main terminal is at the ANZ Bank in Nunn St.
Rail transport includes both passenger rail and freight rail. The city's only station is Benalla railway station which is on the North East railway line. The Albury V/Line rail service stops at Benalla as does the twice dailyNSW TrainLink XPT service to and from Sydney.
Benalla Airport YBLA (BLN) began life as a major RAAF training base during World War II and now also serves as the home of the Gliding Club of Victoria as well as a ballooning & ultralight centre and the Benalla Aviation Museum.
Utilities.
Water is supplied by North East Water. The main water supply is Loombah Weir and McCall Say Reservoir in the Ryan's Creek Catchment approximately 13 kilometres south of the city with a total 1800 megalitre capacity.

</doc>
<doc id="63832" url="https://en.wikipedia.org/wiki?curid=63832" title="History of California before 1900">
History of California before 1900

Human history in California begins with indigenous Americans first arriving in California some 13,000-15,000 years ago. Exploration and settlement by Europeans along the coasts and in the inland valleys began in the 16th century. California was acquired by the United States under the terms of the 1848 Treaty of Guadalupe Hidalgo following the defeat of Mexico in the Mexican–American War.
Native American Settlement
American westward expansion intensified with the California Gold Rush, beginning in 1849. California joined the Union as a free state in 1850, due to the Compromise of 1850. By the end of the 19th century, California was still largely rural and agricultural, but had a population of about 1.4 million
The most commonly accepted model of migration to the New World is that peoples from Asia crossed the Bering land bridge to the Americas some 16,500 years ago.
The remains of Arlington Springs Man on Santa Rosa Island are among the traces of a very early habitation, dated to the Wisconsin glaciation (the most recent ice age) about 13,000 years ago. In all, some 30 tribes or culture groups lived in what is now California, gathered into perhaps six different language family groups. These groups included the early-arriving Hokan family (winding up in the mountainous far north and Colorado River basin in the south) and the recently arrived Uto-Aztecan of the desert southeast. This cultural diversity was among the densest in North America, and was likely the result of a series of migrations and invasions during the last 10,000-15,000 years. At the time of the first European contact, Native American tribes included the Chumash, Maidu, Miwok, Modoc, Mohave, Ohlone, Pomo, Serrano, Shasta, Tataviam, Tongva, Wintu and Yurok.
Tribes adapted to California's many climates. Coastal tribes were a major source of trading beads, produced from mussel shells using stone tools. Tribes in California's broad Central Valley and the surrounding foothills developed an early agriculture, burning the grasslands to encourage growth of edible wild plants, especially oak trees. The acorns from these trees were pounded into a powder, and the acidic tannin leached out to make edible flour. Tribes living in the mountains of the north and east relied heavily on salmon and game hunting, and used California's volcanic legacy by collecting and shaping obsidian for themselves and for trade. The deserts of the southeast were home to tribes who learned to thrive in that harsh environment by making careful use of local plants and living in oases and along water courses. The indigenous people practiced various forms of forest gardening in the forests, grasslands, mixed woodlands, and wetlands, ensuring that desired food and medicine plants continued to be available. The Native Americans controlled fire on a regional scale to create a low-intensity fire ecology which prevented larger, catastrophic fires and sustained a low-density "wild" agriculture in loose rotation. By burning underbrush and grass, the Native Americans revitalized patches of land whose regrowth provided fresh shoots to attract food animals. A form of fire-stick farming was used to clear areas of old growth to encourage new in a repeated cycle; a primitive permaculture.
The relative strength of the tribes was dynamic, as the more successful expanded their territories and less successful tribes contracted. Slave-trading and war among tribes alternated with periods of relative peace. The total population of Native California is estimated, by the time of extensive European contact in the 18th century, to have been perhaps 300,000. Before Europeans landed in North America, about one-third of all natives in what is now the United States were living in the area that is now California.
European exploration (1530–1765).
The first European explorers, flying the flags of Spain and of England, sailed along the coast of California from the early 16th century to the mid-18th century, but no European settlements were established. The most important colonial power, Spain, focused attention on its imperial centers in Mexico and Peru. Confident of Spanish claims to all lands touching the Pacific Ocean (including California), Spain sent an exploring party sailing along the California coastline. The California seen by these ship-bound explorers was one of hilly grasslands and wooded canyons, with few apparent resources or natural ports to attract colonists.
The other colonial states of the era, with their interest on more densely populated areas, paid limited attention to this distant part of the world. It was not until the middle of the 18th century that both Russian and British explorers and fur traders began establishing stations on the coast.
Hernán Cortés.
Around 1530, Nuño Beltrán de Guzmán (president of New Spain) was told by an Indian slave of the Seven Cities of Cibola that had streets paved with gold and silver. About the same time Hernán Cortés was attracted by stories of a wonderful country far to the northwest, populated by Amazonish women and abounding with gold, pearls and gems. The Spaniards conjectured that these places may be one and the same.
An expedition in 1533 discovered a bay, most likely that of La Paz, before experiencing difficulties and returning. Cortés accompanied expeditions in 1534 and 1535 without finding the sought-after city.
On May 3, 1535, Cortés claimed "Santa Cruz Island" (now known as the Baja California Peninsula) and laid out and founded the city that was to become La Paz later that spring.
Francisco de Ulloa.
In July 1539, moved by the renewal of those stories, Cortés sent Francisco de Ulloa out with three small vessels. He made it to the mouth of the Colorado River, then sailed around the peninsula as far as Cedros Island.
The account of this voyage marks the first-recorded application of the name "California". It can be traced to the fifth volume of a chivalric romance, "Amadis de Gallia", arranged by Garci Rodríguez de Montalvo and first printed around 1510, in which a character travels through an island called "California".
Juan Rodríguez Cabrillo.
Juan Rodríguez Cabrillo is believed to be the first European to explore the California coast. He was either of Portuguese or Spanish background, although his origins remain unclear. He was a soldier, crossbowman, and navigator who sailed for the Spanish Crown. In June 1542 Cabrillo led an expedition in two ships of his own design and construction from the west coast of what is now Mexico. He landed on September 28 at San Diego Bay, claiming what he thought was the Island of California for Spain.
Cabrillo and his crew landed on San Miguel Island, one of the Channel Islands, then continued north in an attempt to discover a supposed coastal route to the mainland of Asia. Cabrillo may have sailed as far north as Point Reyes (north of San Francisco), but died as the result of an accident during this voyage; the remainder of the expedition, which may have reached as far north as the Rogue River in today's southern Oregon, was led by Bartolomé Ferrer.
Sir Francis Drake.
On June 7, 1579, the English explorer Sir Francis Drake saw an excellent harbor, on a land mass that he called "Nova Albion" and claimed for England. The accepted location for Drake's port is at Drake's Cove in Drakes Bay which has been named a National Historic Landmark. There was no English follow-up. Subsequent English maps name the land above Baja California, New Granada, New Mexico and Florida "Nova Albion". Drake held the first Protestant Christian service at Nova Albion.
Sebastián Vizcaíno.
In 1602 the Spaniard Sebastián Vizcaíno explored California's coastline as far north as Monterey Bay, where he put ashore. He ventured inland south along the coast and recorded a visit to what is likely Carmel Bay. His major contributions to the state's history were the glowing reports of the Monterey area as an anchorage and as land suitable for settlement, as well as the detailed charts he made of the coastal waters (which were used for nearly 200 years).
European exploration (1765–1821).
British seafaring Captain James Cook, midway through his third and final voyage of exploration in 1778, sailed along the west coast of North America aboard the , mapping the coast from California all the way to the Bering Strait. In 1786 Jean-François de Galaup, comte de Lapérouse, led a group of scientists and artists on a voyage of exploration ordered by Louis XVI and were welcomed in Monterey. They compiled an account of the Californian mission system, the land and the people. Traders, whalers and scientific missions followed in the next decades.
Spanish colonization and governance (1697–1821).
In 1697 the Jesuit missionary Juan María de Salvatierra established Misión de Nuestra Señora de Loreto Conchó, the first permanent mission on the Baja California Peninsula. Spanish control over the peninsula, including missions, was gradually extended, first in the region around Loreto, then to the south in the Cape region, and finally to the north across the northern boundary of present-day Baja California Sur. A total of 30 Spanish missions in Baja California were established.
During the last quarter of the 18th century, the first Spanish settlements were established in what later became the Las Californias Province of the Viceroyalty of New Spain. Reacting to interest by the Russian Empire and, later, Great Britain in the fur-bearing animals of the Pacific north coast, Spain further extended the series of Catholic missions, accompanied by troops and establishing ranches, along the southern and central coast of California. These missions were intended to demonstrate the claim of the Spanish Empire to what is now California. By 1823, 21 Spanish missions had been established in Alta California. Operations were based out of the naval base at San Blas and included not only the establishment and supply of missions in California, but a series of exploration expeditions to the Pacific Northwest and Alaska.
The first quarter of the 19th century showed the continuation of the slow colonization of the southern and central California coast by Spanish missionaries, ranchers and troops. By 1820 Spanish influence was marked by the chain of missions reaching from Loreto, north to San Diego, to just north of today's San Francisco Bay Area, and extended inland approximately from the missions. Outside of this zone, perhaps 200,000 to 250,000 Native Americans were continuing to lead traditional lives. The Adams–Onís Treaty, signed in 1819, set the northern boundary of the Spanish claims at the 42nd parallel, effectively creating today's northern boundary between California and Oregon.
First Spanish colonies.
Spain had maintained a number of missions and presidios in New Spain since 1519. The Crown laid claim to the north coastal provinces of California in 1542. Excluding Santa Fe in New Mexico, settlement of northern New Spain was slow for the next 155 years. Settlements in Loreto, Baja California Sur, were established in 1697, but it was not until the threat of incursion by Russian fur traders and potentially settlers, coming down from Alaska in 1765, that Spain, under King Charles III, felt development of more northern installations was necessary.
By then, the Spanish Empire was engaged in the political aftermath of the Seven Years' War, and colonial priorities in far away California afforded only a minimal effort. Alta California was to be settled by Franciscan monks, protected by troops in the California missions. Between 1774 and 1791, the Crown sent forth a number of expeditions to further explore and settle Alta California and the Pacific Northwest.
Portolá expedition.
In May 1768, the Spanish Inspector General ("Visitador") José de Gálvez planned a four-prong expedition to settle Alta California, two by sea and two by land, which Gaspar de Portolá volunteered to command.
The Portolá land expedition arrived at the site of present-day San Diego on June 29, 1769, where it established the Presidio of San Diego. Eager to press on to Monterey Bay, de Portolá and his group, consisting of Father Juan Crespí, 63 leather-jacket soldiers and a hundred mules, headed north on July 14. They reached the present-day site of Los Angeles on August 2, Santa Monica on August 3, Santa Barbara on August 19, San Simeon on September 13, and the mouth of the Salinas River on October 1. Although they were looking for Monterey Bay, the group failed to recognize it when they reached it.
On October 31, de Portolá's explorers became the first Europeans known to view San Francisco Bay. Ironically, the Manila Galleons had sailed along this coast for almost 200 years by then, without noticing the bay. The group returned to San Diego in 1770.
De Portolá was the first governor of Las Californias.
Junípero Serra.
Junípero Serra was a Majorcan Franciscan who founded the first Alta California Spanish missions. After King Carlos III ordered the Jesuits expelled from New Spain on February 3, 1768, Serra was named "Father Presidente".
Serra founded San Diego de Alcalá in 1769. Later that year, Serra, Governor de Portolá and a small group of men moved north, up the Pacific Coast. They reached Monterey in 1770, where Serra founded the second Alta California mission, San Carlos Borromeo.
Alta California missions.
The California missions comprise a series of religious outposts established by Spanish Catholic Dominicans, Jesuits, and Franciscans, to spread the Christian doctrine among the local Native Americans, but with the primary benefit to Spain of confirming historic claims to the territory. The missions introduced European livestock, fruits, vegetables, agricultural industry, along with invasive species of plants into the California regions. The labor supply for the missions was supplied by the forcible relocation of the Native Americans and keeping them in peonage.
Most missions were small, with normally two Franciscans and six to eight soldiers in residence. All of these buildings were built largely by the forced labor of unpaid native people, under Franciscan supervision. In addition to the "presidio" (royal fort) and "pueblo" (town), the "misión" was one of the three major agencies employed by the Spanish crown in an attempt to consolidate its colonial territories. None of these missions were completely self-supporting, requiring continued (albeit modest) financial support.
Starting with the onset of the Mexican War of Independence in 1810, this support largely disappeared, and the missions and their converts were left on their own. By 1827, the Mexican government passed the General Law of Expulsion, which exiled Spanish-born people, decimating the clergy in California. Some of the missions were then nationalized by the Mexican government and sold off. It was not until after statehood that the US Supreme Court restored some missions to the orders that owned them.
In order to facilitate overland travel, the mission settlements were situated approximately apart, so that they were separated by one day's long ride on horseback along the el Camino Real, Spanish for "the Royal Road", though often referred to today as the "King's Highway", and also known as the "California Mission Trail". Tradition has it that the "padres" sprinkled mustard seeds along the trail in order to mark it with bright yellow flowers. Later El Camino Viejo, another more direct route from Los Angeles to Mission San José and San Francisco Bay, developed along the western edge of the San Joaquin Valley. Heavy freight movement over long distances was practical only via water, but soldiers, settlers and other travelers and merchandise on horses, mules, or "carretas" (ox carts), and herds of animals used these routes.
Four "presidios", strategically placed along the California coast and organized into separate military districts, served to protect the missions and other Spanish settlements in Upper California.
A number of mission structures survive today or have been rebuilt, and many have congregations established since the beginning of the 20th century. The highway and missions became for many a romantic symbol of an idyllic and peaceful past. The Mission Revival style was an architectural movement that drew its inspiration from this idealized view of California's past.
Ranchos.
The Spanish encouraged settlement with large land grants called "ranchos", where cattle and sheep were raised. The California missions were secularized following Mexican independence, with the passing of the Mexican secularization act of 1833 and the division of the extensive former mission lands into more ranchos. Cow hides (at roughly $1 each) and fat (known as tallow, used to make candles as well as soaps) were the primary exports of California until the mid-19th century.
The owners of these ranchos styled themselves after the Dons in Spain. The rancho workers were primarily Native Americans, many of them former residents of the missions who had learned to speak Spanish and ride horses. Some ranchos, such as Rancho El Escorpión and Rancho Little Temecula, were land grants directly to Native Americans.
Administrative divisions.
In 1773 a boundary between the Baja California missions (whose control had been passed to the Dominicans) and the Franciscan missions of Alta California was set by Francisco Palóu. Due to the growth of the Hispanic population in Alta California by 1804, the province of Las Californias, then a part of the Commandancy General of the Internal Provinces, was divided into two separate territorial administrations following Palóu's division between the Dominican and Franciscan missions. Governor Diego de Borica is credited with defining Alta California and Baja California's official borders. The Baja California Peninsula became the territory of ' (""), also referred to at times as ' (""). The northern part became ', also alternatively called ' (""). Because the eastern boundaries of Alta California Province were not defined, it included Nevada, Utah and parts of Arizona, New Mexico, western Colorado and southwestern Wyoming. The province bordered on the east with the Spanish settlements in Arizona and the province of Nuevo México, with the Sierra Nevada or Colorado River serving as the de facto border.
Russian colonization.
Part of Spain's motivation to settle upper Las Californias was to forestall Russian colonization and British incursion into their territory. In the early 19th century, fur trappers with the Russian-American Company of the tsarist Russian Empire explored down the West Coast from trading settlements in Alaska, hunting for sea otter pelts as far south as San Diego. In August 1812, the Russian-American Company set up a fortified trading post at Fort Ross, near present-day Bodega Bay on the Sonoma Coast of Northern California, north of San Francisco on land claimed, but not occupied, by the British Empire. This colony was active until the Russians departed in 1841.
In 1836 El Presidio de Sonoma, or "Sonoma Barracks", was established by General Mariano Guadalupe Vallejo, the Comandante of the northern frontier of Alta California. It was established as a part of Mexico's strategy to halt Russian incursions into the region, as the Mission San Francisco de Solano (Sonoma Mission) was for the Spanish.
California under Mexican rule (1821–1846).
General.
Substantial changes occurred during the second quarter of the 19th century. The victory in the Mexican War of Independence from Spain in 1821 marked the end of a European power ruling California; the missions faded in importance under Mexican control, while ranching and trade increased. 
As the successor state to the Viceroyalty of New Spain, Mexico automatically included the provinces of Alta California and Baja California as territories. With the establishment of a republican government in 1823, Alta California Territory, like many northern territories, was not recognized as one of the constituent states of Mexico because of its small population. The 1824 Constitution of Mexico refers to Alta California as a "territory".
In 1831 a small group made up of the more wealthy citizens of Alta California got together and petitioned Governor Manuel Victoria asking for democratic reforms. The previous governor, José María de Echeandía, was more popular, so the leading wealthy citizens suggested to Echeandía that Victoria's stay as governor would be coming to an abrupt end soon. They built up a small army, marched into Los Angeles, and "captured" the town. Victoria gathered a small army and went to fight the upstart army, leading it himself. He met the opposing army on December 5, 1831, at Cahuenga Pass. In the Battle of Cahuenga Pass Victoria was wounded and resigned the governorship of Alta California. The previous governor, Echeandía, took the job, which he did until José Figueroa took over in 1833.
The Mexican Congress passed the General Law of Expulsion in 1827. This law declared all persons born in Spain to be "illegal immigrants" and ordered them to leave the new country of Mexico. Many of the missionary clergy were Spanish and left. Next, the Mexican Congress passed "An Act for the Secularization of the Missions of California" on August 17, 1833. Mission San Juan Capistrano was the very first to feel the effects of this legislation the following year. The Franciscans soon thereafter abandoned the missions, taking with them most everything of value, after which the locals typically plundered the mission buildings for construction materials.
In 1836, Mexico repealed the 1824 federalist constitution and adopted a more centralist political organization (under the "Siete Leyes") that reunited Alta and Baja California in a single California Department ("Departamento de las Californias"). The change, however, had little practical effect in far-off Alta California. The capital of Alta California Territory remained Monterey, as it had been since the 1769 Portola expedition first established an Alta California government, and the local political structures were unchanged. 
In September 1835, Nicolás Gutiérrez was appointed as interim governor of California in January 1836, to be replaced by Mariano Chico in April, but he was very unpopular. Thinking a revolt was coming, Chico returned to Mexico to gather troops, but was reprimanded for leaving his post. Gutierrez, the military commandant, re-assumed the governorship, but he too was unpopular. Senior members of Alta California's legislature Juan Bautista Alvarado and José Castro, with support from Mariano Guadalupe Vallejo, Comandante of the Fourth Military District and Director of Colonization of the Northern Frontier, and assistance from a group of Americans led by Isaac Graham, staged a revolt in November 1836 and forced Gutierrez to relinquish power. The Americans wanted Californian independence, but Alvarado instead preferred staying part of Mexico, albeit with greater autonomy.
In 1840, Graham allegedly began agitating for a Texas-style revolution in California, in March issuing a notice for a planned horse race that was loosely construed into being a plot for revolt. Alvarado notified Vallejo of the situation, and in April the Californian military began arresting American and English immigrants, eventually detaining about 100 in the Presidio of Monterey. At the time, there were fewer than 400 foreigners from all nations in the department. Vallejo returned to Monterey and ordered Castro to take 47 of the prisoners to San Blas by ship, to be deported to their home countries. Under pressure from British and American diplomats, President Anastasio Bustamante released the remaining prisoners and began a court martial against Castro. Also assisting in the release of those caught up in the Graham Affair was American traveler Thomas J. Farnham. In 1841, Graham and 18 of his associates returned to Monterey, with new passports issued by the Mexican federal government.
Also in 1841, political leaders in the United States were declaring their doctrine of Manifest Destiny, and Californios grew increasingly concerned over their intentions. Vallejo conferred with Castro and Alvarado recommending that Mexico send military reinforcements to enforce their military control of California.
In response, Mexican president Antonio López de Santa Anna sent Brigadier General Manuel Micheltorena and 300 men to California in January 1842. Micheltorena was to assume the governorship and the position of commandant general. In October, before Micheltorena reached Monterey, American Commodore Thomas ap Catesby Jones mistakenly thought that war had broken out between the United States and Mexico. He sailed into Monterey Bay and demanded the surrender of the Presidio of Monterey. Micheltorena's force was still in the south, and the Monterey presidio was undermanned. As such, Alvarado reluctantly surrendered, and retired to Rancho El Alisal. The next day Commodore Jones learned of his mistake, but Alvarado declined to return and instead referred the commodore to Micheltorena.
Micheltorena eventually made it to Monterey, but was unable to control his troops, a number of whom were convicts. This fomented rumors of a revolt, and by 1844, Alvarado himself became associated with the malcontents and an order was given by Micheltorena for his arrest. His detention, however, was short-lived as Micheltorena was under orders to organize a large contingent in preparation for war against the United States. All hands would be required for the task at hand.
This turned out to backfire on him, as on November 14, 1844, a group of Californios led by Manuel Castro revolted against Mexican authority. José Castro and Alvarado commanded the troops. There was no actual fighting, however; a truce was negotiated and Micheltorena agreed to dismiss his convict troops. However, Micheltorena reneged on the deal and fighting broke out this time. The rebels won the Battle of Providencia in February 1845 at the Los Angeles River and Micheltorena and his troops left California.
Pío Pico was installed as governor in Los Angeles, and José Castro became commandant general. Later, Alvarado was elected to the Mexican Congress. He prepared to move to Mexico City, but Pico declined funding for the transfer, and relations between the northern part of Alta California, with the increased presence of Americans, and the southern part, where the Spanish-speaking Californios dominated, became more tense. 
John C. Frémont arrived in Monterey at the beginning of 1846. Afraid of foreign aggression, Castro assembled his militia, with Alvarado second in command, but Frémont went north to Oregon instead. An unstable political situation in Mexico strained relations among the Californios, and it seemed that civil war would break out between north and south.
By 1846, Alta California had a Spanish-speaking population of under 10,000, tiny even compared to the sparse population of states in the rest of northern Mexico. The Californios consisted of about 800 families, mostly concentrated on large ranchos. About 1,300 American citizens and a very mixed group of about 500 Europeans, scattered mostly from Monterey to Sacramento, dominated trading as the Californios dominated ranching. In terms of adult males, the two groups were about equal, but the American citizens were more recent arrivals.
Other nationalities.
The Russian-American Company established Fort Ross in 1812 as its southernmost colony in North America, intended to provide Russian posts farther north with agricultural goods. When this need was filled by a deal between the RAC and the Hudson's Bay Company for produce from Fort Vancouver on the Columbia River and other installations, the fort's intent was derailed, although it remained in Russian hands until 1841, and for the duration had a small population of Russians and other nationalities from the Russian Empire.
In this period, American and British traders began entering California in search of beaver. Using the Siskiyou Trail, Old Spanish Trail, and later, the California Trail, these trading parties arrived in California, often without the knowledge or approval of the Mexican authorities, and laid the foundation for the arrival of later Gold Rush era Forty-Niners, farmers and ranchers.
In 1840, the American adventurer, writer and lawyer Richard Henry Dana, Jr., wrote of his experiences aboard ship off California in the 1830s in "Two Years Before the Mast".
The leader of a French scientific expedition to California, Eugène Duflot de Mofras, wrote in 1840, "...it is evident that California will belong to whatever nation chooses to send there a man-of-war and two hundred men." In 1841, General Vallejo wrote Governor Alvarado that "...there is no doubt that France is intriguing to become mistress of California", but a series of troubled French governments did not uphold French interests in the area. During disagreements with Mexicans, the German-Swiss francophile John Sutter threatened to raise the French flag over California and place himself and his settlement, New Helvetia, under French protection.
American interest and immigrants.
Although a small number of American traders and trappers had lived in California since the early 1830s, the first organized overland party of American immigrants was the Bartleson–Bidwell Party of 1841. With mules and on foot, this pioneering group groped its way across the continent using the still untested California Trail. Also in 1841, an overland exploratory party of the United States Exploring Expedition came down the Siskiyou Trail from the Pacific Northwest. In 1844, Caleb Greenwood guided the first settlers to take wagons over the Sierra Nevada. In 1846, the misfortunes of the Donner Party earned notoriety as they struggled to enter California.
California under American rule (beginning 1846).
Population.
The non-Indian population of California in 1840 was about 8,000, as confirmed by the California 1850 U.S. Census, which asked everyone their place of birth. The Indian population is unknown but has been variously estimated at about 30,000 to 150,000 in 1840. The population in 1850, the first U.S. census, does not count the Indian population and omits San Francisco, the largest city, as well as the counties of Santa Clara and Contra Costa, all of whose tabulations were lost before they could be included in the totals. Some estimates can be obtained from the "Alta Californian" newspapers published in San Francisco in 1850. A corrected California 1850 Census would go from 92,597 (the uncorrected "official number") to over 120,000. The 1850 U.S. Census, the first census that included the names and sex of everyone in a family, showed only 7,019 females, with 4,165 non-Indian females older than 15 in the state. To this should be added about 1,300 women older than 15 from San Francisco, Santa Clara, and Contra Costa counties whose censuses were lost and not included in the totals. There were less than 10,000 females in a total California population (not including Indians who were not counted) of about 120,000 residents in 1850. About 3.0% of the Gold Rush "Argonauts" before 1850 were female or about 3,500 female Gold Rushers, compared to about 115,000 male California Gold Rushers.
By California's 1852 "special" State Census, the population had already increased to about 200,000, of which about 10% or 20,000 were female. Competition by 1852 had decreased the steamship fare via Panama to about $200. Many of the new and successful California residents sent off for their wives, sweethearts and families to join them in California. After 1850 the Panama Railroad (completed 1855) was already working its way across the Isthmus of Panama, making it ever easier to get to and from California in about 40 days. Additional thousands came via the California Trail, but this took longer—about 120 to 160 days. The "normal" male to female ratio of about one to one would not arrive until the 1950 census. California for over a century was short on females. The gold rush element continued to grow until the end of the Gold Rush in the 1880s.
Bear Flag Revolt and American conquest.
After the United States declared war on Mexico on May 13, 1846, it took almost two months (mid-July 1846) for definite word of war to get to California. Upon hearing rumors of war, U.S. consul Thomas O. Larkin, stationed in Monterey, tried to keep peace between the Americans and the small Mexican military garrison commanded by José Castro. American army captain John C. Frémont, with about 60 well-armed men, had entered California in December 1845 and was making a slow march to Oregon when they received word that war between Mexico and the U.S. was imminent.
On June 15, 1846, some 30 non-Mexican settlers, mostly Americans, staged a revolt, seized the small Mexican garrison in Sonoma, and captured Mexican general Mariano Vallejo. They raised the "Bear Flag" of the California Republic over Sonoma. The so-called California Republic lasted one week until the U.S. Army, led by Frémont, took over on June 23. The California state flag today is based on this original Bear Flag, and continues to contain the words "California Republic".
Commodore John Drake Sloat, on hearing of imminent war and the revolt in Sonoma, ordered his naval forces to occupy Yerba Buena (present San Francisco) on July 7 and raise the American flag. On July 15, Sloat transferred his command to Commodore Robert F. Stockton, a much more aggressive leader. Commodore Stockton put Frémont's forces under his command. Frémont's "California Battalion" swelled to about 160 men with the addition of volunteers recruited from American settlements, and on July 19 he entered Monterey in a joint operation with some of Stockton's sailors and marines. The official word had been received — the Mexican–American War was on. The American forces easily took over the north of California; within days, they controlled Monterey, San Francisco, Sonoma, and Sutter's Fort.
In Southern California, Mexican General José Castro and Governor Pío Pico fled from Los Angeles. When Stockton's forces entered Los Angeles unresisted on August 13, 1846, the nearly bloodless conquest of California seemed complete. Stockton, however, left too small a force (36 men) in Los Angeles, and the Californios, acting on their own and without help from Mexico, led by José María Flores, forced the small American garrison to retire in late September.
Two hundred reinforcements were sent by Stockton, led by US Navy Captain William Mervine, but were repulsed in the Battle of Dominguez Rancho, October 7–9, 1846, near San Pedro, where 14 US Marines were killed. Meanwhile, General Kearny with a much reduced squadron of 100 dragoons finally reached California after a grueling march across New Mexico, Arizona, and the Sonoran Desert. On December 6, 1846, they fought the Battle of San Pasqual near San Diego, where 18 of Kearny's troop were killed—the largest number of American casualties lost in battle in California.
Stockton rescued Kearny's surrounded forces and, with their combined force, they moved northward from San Diego. Entering the present-day Orange County area on January 8, they linked up with Frémont's northern force. With the combined American forces totaling 660 troops, they fought the Californios in the Battle of Rio San Gabriel. The next day, January 9, 1847, they fought the Battle of La Mesa. Three days later, on January 12, 1847, the last significant body of Californios surrendered to American forces. That marked the end of the war in California. On January 13, 1847, the Treaty of Cahuenga was signed.
On January 28, 1847, Army lieutenant William Tecumseh Sherman and his army unit arrived in Monterey, as American forces continued to stream into California. On March 15, 1847, Col. Jonathan D. Stevenson's Seventh Regiment of New York Volunteers of about 900 men began to arrive. All of these troops were still in California when gold was discovered in January 1848.
The Treaty of Guadalupe Hidalgo, signed on February 2, 1848, marked the end of the Mexican–American War. In that treaty, the United States agreed to pay Mexico $18,250,000; Mexico formally ceded California (and other northern territories) to the United States; and the first international boundary was drawn between the U.S. and Mexico by treaty. The previous boundary had been negotiated in 1819 between Spain and the United States in the Adams–Onís Treaty, which established the present border between California and Oregon. San Diego Bay is one of the few natural harbors in California south of San Francisco, and to claim this strategic asset the southern border was slanted to include the entire bay in California.
Gold Rush.
In January 1848, gold was discovered at Sutter's Mill in the Sierra Nevada foothills about 40 miles east of Sacramento – beginning the California Gold Rush, which had the most extensive impact on population growth of the state of any era.
The miners and merchants settled in towns along what is now California State Highway 49, and settlements sprang up along the Siskiyou Trail as gold was discovered elsewhere in California (notably in Siskiyou County). The nearest deep-water seaport was San Francisco Bay, and San Francisco became the home for bankers who financed exploration for gold.
The Gold Rush brought the world to California. By 1855, some 300,000 "Forty-Niners" had arrived from every continent; many soon left, of course—some rich, most not very rich. A precipitous drop in the Native American population occurred in the decade after the discovery of gold.
Statehood: 1849–1850.
In 1847–49, California was run by the U.S. military; local government continued to be run by "alcaldes" (mayors) in most places, but now some were Americans. Bennett C. Riley, the last military governor, called a constitutional convention to meet in Monterey in September 1849. Its 48 delegates were mostly pre-1846 American settlers; eight were Californios. They unanimously outlawed slavery and set up a state government that operated for 10 months before California was given official statehood by Congress on September 9, 1850, as part of the Compromise of 1850. After Monterey, the state capital was variously San Jose (1850–1851), Vallejo (1852–1853) and Benicia (1853–1854), until Sacramento was finally selected in 1854.
Californios (dissatisfied with inequitable taxes and land laws) and pro-slavery Southerners in lightly populated, rural Southern California attempted three times in the 1850s to achieve a separate statehood or territorial status separate from Northern California. The last attempt, the Pico Act of 1859, was passed by the California State Legislature, signed by the state governor, approved overwhelmingly by voters in the proposed "Territory of Colorado" and sent to Washington, D.C., with a strong advocate in Senator Milton Latham. However, the secession crisis in 1860 led to the proposal never coming to a vote.
The Civil War.
Because of the distance factor, California played a minor role in the American Civil War. Although some settlers sympathized with the Confederacy, they were not allowed to organize, and their newspapers were closed down. Former Senator William M. Gwin, a Confederate sympathizer, was arrested and fled to Europe. Powerful capitalists dominated Californian politics through their control of mines, shipping, and finance. They controlled the state through the new Republican Party. Nearly all the men who volunteered as soldiers stayed in the West to guard facilities, suppress secessionists or fight the Indians. Some 2,350 men in the California Column marched east across Arizona in 1862 to expel the Confederates from Arizona and New Mexico. The California Column then spent most of the remainder of the war fighting hostile Indians in the area.
Labor.
In his maiden speech before the United States Senate, California Senator David C. Broderick stated, "There is no place in the Union, no place on earth, where labor is so honored and so well rewarded..." as in California. Early immigrants to California came with skills in many trades, and some had come from places where workers were being organized. California's labor movements began in San Francisco, the only large city in California for decades and once the center of trade-unionism west of the Rockies. Los Angeles remained an open-shop stronghold for half a century until unions from the north collaborated to make California a union state.
Because of San Francisco's relative isolation, skilled workers could make demands that their counterparts on the East Coast could not. Printers first attempted to organize in 1850, teamsters, draymen, lightermen, riggers and stevedores in 1851, bakers and bricklayers in 1852, caulkers, carpenters, plasterers, brickmasons, blacksmiths and shipwrights in 1853 and musicians in 1856. Although these efforts required several starts to become stabilized, they did earn better pay and working conditions and began the long efforts of state labor legislation. Between 1850 and 1870, legislation made provisions for payment of wages, the mechanic's lien and the eight-hour workday.
It was said that during the last half of the 19th century more of San Francisco's workers enjoyed an eight-hour workday than any other American city. The molders' and boilermakers' strike of 1864 was called in opposition to a newly formed iron-works employers association which threatened a one thousand dollar a day fine on any employer who granted the strikers' demands and had wired for strikebreakers across the country. The San Francisco Trades Union, the city's first central labor body, sent a delegation to meet a boatload of strikebreakers at Panama and educated them. They arrived in San Francisco as enrolled union members.
After the Civil War ended in 1865, California continued to grow rapidly. Independent miners were largely displaced by large corporate mining operations. Railroads began to be built, and both the railroad companies and the mining companies began to hire large numbers of laborers. The decisive event was the opening of the transcontinental railroad in 1869; six days by train brought a traveler from Chicago to San Francisco, compared to six months by ship. The era of comparative protection for California labor ended with the arrival of the railroad. For decades after, labor oppressed Chinese immigrant workers and politicians pushed anti-Chinese legislation.
Importation of slaves or so-called "contract" labor was fought by miners and city workers and made illegal through legislation in 1852.
The first statewide federated labor body was the Mechanics' State Council that championed the eight-hour day against the employers' 1867 "Ten Hour League". The Council affiliated with the National Labor Union, America's first national union effort. By 1872 Chinese workers comprised half of all factory workers in San Francisco and were paid wages far below white workers. "The Chinese must Go!" was the slogan of Denis Kearney, a prominent labor leader in San Francisco. He appeared on the scene in 1877 and led sandlot vigilantes that roamed the city beating Chinese and wrecking their businesses.
Twice the seamen of the West Coast had tried to organize a union, but were defeated. In 1875, the Seaman's Protective Association was established and began the struggle for higher wages and better conditions on ships. The effort was joined by Henry George, editor of the "San Francisco Post". The legislative struggle to enforce laws against brutal ship's captains and the requirement that two-thirds of sailors be Americans was proposed, and the effort was carried for thirty years by Andrew Furuseth and the Sailors' Union of the Pacific after 1908, and the International Seamen's Union of America. The "Coast's Seamen's Journal" was founded in 1887, for years the most important labor journal in California.
Concurrently, waterfront organizing led to the Maritime Federation of the Pacific.
"See: History of California 1900 to present."
Labor politics and the rise of Nativism.
Thousands of Chinese men arrived in California to work as laborers, recruited by industry as low-wage workers. Over time, conflicts in the gold fields and cities created prejudices between white and Chinese laborers. During the decade-long depression after the transcontinental railroad was completed, white workers began to lay blame on the Chinese laborers. Many Chinese were expelled from the mine fields. Some returned to China after the Central Pacific was built. Those who stayed mostly moved to the Chinatown in San Francisco and a few other cities, where they were relatively safe from violent attacks they suffered elsewhere.
From 1850 through 1900, anti-Chinese nativist sentiment resulted in the passage of innumerable laws, many of which remained in effect well into the middle of the 20th century. The most flagrant episode was probably the creation and ratification of a new state constitution in 1879. Thanks to vigorous lobbying by the anti-Chinese Workingmen's Party, led by Denis Kearney (an immigrant from Ireland), Article XIX, Section 4 forbade corporations from hiring Chinese "coolies", and empowered all California cities and counties to completely expel Chinese persons or to limit where they could reside. The law was repealed in 1952.
The 1879 constitutional convention also dispatched a message to Congress pleading for strong immigration restrictions, which led to the passage of the Chinese Exclusion Act in 1882. The act was upheld by the U.S. Supreme Court in 1889, and it would not be repealed by Congress until 1943. Similar sentiments led to the development of the Gentlemen's Agreement with Japan, by which Japan voluntarily agreed to restrict emigration to the United States. California also passed an Alien Land Act which barred aliens, especially Asians, from holding title to land. Because it was difficult for people born in Asia to obtain U.S. citizenship until the 1960s, land ownership titles were held by their American-born children, who were full citizens. The law was overturned by the California Supreme Court as unconstitutional in 1952.
In 1886, when a Chinese laundry owner challenged the constitutionality of a San Francisco ordinance clearly designed to drive Chinese laundries out of business, the U.S. Supreme Court ruled in his favor, and in doing so, laid the theoretical foundation for modern equal protection constitutional law. See "Yick Wo v. Hopkins", 118 U.S. 356 (1886). Meanwhile, even with severe restrictions on Asian immigration, tensions between unskilled workers and wealthy landowners persisted up to and through the Great Depression. Novelist Jack London writes of the struggles of workers in the city of Oakland in his visionary classic "The Valley of the Moon", a title evoking the pristine situation of Sonoma County between sea and mountains, redwoods and oaks, fog and sunshine.
Rise of the railroads.
The Big Four were the famous railroad tycoons who built the Central Pacific Railroad, (C.P.R.R.), which formed the western portion of the first transcontinental railroad in the United States. They were Leland Stanford, (1824–1893), Collis Potter Huntington (1821–1900), Mark Hopkins (1813–1878), and Charles Crocker (1822–1888). The establishment of America's transcontinental rail lines permanently linked California to the rest of the country, and the far-reaching transportation systems that grew out of them during the century that followed contributed immeasurably to the state's unrivaled social, political, and economic development.
The Big Four dominated California's economy and politics in the 1880s and 1890s, and Collis P. Huntington became one of the most hated man in California. One typical California textbook argues: 
Huntington, however, defended himself: 
Late developments.
1898 saw the founding of the League of California Cities, an association intended to fight city government corruption, coordinate strategies for cities facing issues such as electrification, and to lobby the state government on behalf of cities.

</doc>
<doc id="63833" url="https://en.wikipedia.org/wiki?curid=63833" title="Government of California">
Government of California

The government of California is the governmental structure of the state of California as established by the California Constitution. It is composed of three branches: the executive, consisting of the Governor of California and the other constitutionally elected and appointed officers and offices; the legislative, consisting of the California State Legislature, which includes the Assembly and the Senate; and the judicial, consisting of the Supreme Court of California and lower courts. There is also local government, consisting of counties, cities, special districts, and school districts, as well as government entities and offices that operate independently on a constitutional, statutory, or common law basis. The state also allows direct participation of the electorate by initiative, referendum, recall and ratification.
Executive branch.
California's elected executive officers are:
All offices are elected separately to concurrent four-year terms, and each officer may be elected to an office a maximum of two times. The Governor has the powers and responsibilities to: sign or veto laws passed by the Legislature, including a line item veto; appoint judges, subject to ratification by the electorate; propose a state budget; give the annual State of the State address; command the state militia; and grant pardons for any crime, except cases involving impeachment by the Legislature. The Lieutenant Governor is the President of the California Senate and acts as the governor when the Governor is unable to execute the office, including whenever the Governor leaves the state. The Governor and Lieutenant Governor also serve as "ex officio" members of the University of California Board of Regents and of the California State University Board of Trustees. Regulatory activity is published in the "California Regulatory Notice Register" and the general and permanent rules and regulations are codified in the "California Code of Regulations".
State agencies.
State government is organized into many departments, of which most are grouped together into several huge Cabinet-level agencies. These agencies are sometimes informally referred to as "superagencies", especially by government officials, to distinguish them from the general usage of the term "government agency." The Cabinet-level agencies (superagencies) are the:
The independently elected officers run separate departments not grouped within the superagencies, and there are other Cabinet-level departments:
Independent entities.
There are many government entities and offices that are under neither executive, legislative, judicial, or local control, but operate independently on a constitutional, statutory, or common law basis.
Examples include the:
Legislative branch.
The California State Legislature is the state legislature. It is a bicameral body consisting of the California State Assembly, the lower house with 80 members, and the California State Senate, the upper house with 40 members. Members of the Assembly serve two-year terms; members of the Senate serve four-year terms, with half of the seats up for election on alternate (two year) election cycles.
The Speaker of the California State Assembly presides over the State Assembly. The Lieutenant Governor is the "ex officio" President of the Senate and may break a tied vote, and the President pro tempore of the California State Senate is elected by the majority party caucus. The Legislature meets in the California State Capitol in Sacramento. Its session laws are published in the "California Statutes" and codified into the 29 "California Codes".
Direct democracy.
The state also allows direct participation of the electorate by initiative, referendum, recall and ratification.
Judicial branch.
The Judiciary of California interprets and applies the law, and is defined under the Constitution, law, and regulations. The judiciary has a hierarchical structure with the Supreme Court at the apex. The Superior Courts are the primary trial courts, and the Courts of Appeal are the primary appellate courts. The Judicial Council is the rule-making arm of the judiciary.
The California Supreme Court consists of the Chief Justice of California and six Associate Justices. The Court has original jurisdiction in a variety of cases, including habeas corpus proceedings, and has discretionary authority to review all the decisions of the California Courts of Appeal, as well as mandatory review responsibility for cases where the death penalty has been imposed. The Courts of Appeal are the intermediate appellate courts. The state is geographically divided into six appellate districts. Notably, all published California appellate decisions are binding on all Superior Courts, regardless of appellate district.
The California superior courts are the courts of general jurisdiction that hear and decide any civil or criminal action which is not specially designated to be heard before some other court or governmental agency. As mandated by the Constitution, each of the 58 counties has a superior court. The superior courts also have appellate divisions (superior court judges sitting as appellate judges) which hear appeals from decisions of other superior court judges (or commissioners, or judges pro tem) in cases previously heard by inferior courts, such as infractions, misdemeanors, and "limited civil" actions (actions where the amount in controversy is below $25,000).
Local government.
California is divided into counties which are legal subdivisions of the state. There are 58 counties, about 482 California cities, about 1,102 school districts, and about 3,400 special districts. School districts, which are independent of cities and counties, handle public education. Special Districts deliver specific public programs and public facilities to constituents, and are defined as "any agency of the state for the local performance of governmental or proprietary functions within limited boundaries." Counties and incorporated cities may promulgate local ordinances, which are usually codified in county or city codes, respectively, and are misdemeanor crimes unless otherwise specified as infractions.

</doc>
<doc id="63834" url="https://en.wikipedia.org/wiki?curid=63834" title="Echuca">
Echuca

Echuca ( ) is a town located on the banks of the Murray River and Campaspe River in Victoria, Australia. The border town of Moama is on the northern side of the Murray River in New South Wales. Echuca is the administrative centre and largest settlement in the Shire of Campaspe. As of the 2011 census, Echuca had a population of 13,708.
Echuca, an Aboriginal name meaning "Meeting of the Waters" is indicative of the role rivers have played in the town's existence. Echuca is situated close to the junction of the Goulburn, Campaspe and Murray Rivers. Its position at the closest point of the Murray to Melbourne contributed to its development as a thriving river port city during the 19th century.
History.
Foundation.
Echuca was founded by one of the most enterprising characters of the early colonial days, an ex-convict named Henry Hopwood. In 1850 he bought a small punt which operated across the Murray River near the Campaspe junction. The relatively small settlement known as "Hopwood's Ferry" became Echuca as the town grew. The Post Office known as Hopwoods Punt opened around 1854 and was renamed Echuca on 1 January 1855.
While the settlers at Echuca treated the local Aborigines with relative kindness, their way of life was irrevocably changed by their relationship with the Europeans. Having already been decimated by smallpox in the late 1820s, in the 1850s many Aborigines developed a taste for European luxuries such as bread, tobacco and alcohol. They were relegated to the role of fringe-dwellers, living on the banks of the Murray, and occasionally entering into the European economy as fishermen and farm labourers, and by selling the possum rugs which they crafted.
Australia's inland port.
By the 1870s Echuca had risen to prominence as Australia's largest inland port. Being the point of shortest distance between the Murray River and the major city of Melbourne, Echuca was both a key river port and railway junction. Steam-driven paddleboats would arrive at the 400-metre long redgum Echuca Wharf, unloading it to be transported by rail to Melbourne. Wool, wheat, other grains, livestock and timber were the most common cargoes. The wharf has been listed as a Heritage Place on the Australian National Heritage List.
This industrial boom led to a rapidly expanding population, at one stage in excess of 15,000, with more than a hundred pubs (hotels) rumoured to exist in the Echuca district at one time. An iron bridge was constructed over the Murray River in 1878 by the NSW Railways Department.
Decline.
The expansion of the railways from Melbourne to most parts of Victoria, as well as improvements to roads and fickle river conditions all combined to lessen Echuca's importance, and by the 1890s the paddlesteamer fleet was in decline. An economic depression and the collapse of several banks virtually ended Echuca's role as a major economic centre, and her population began to disperse.
Governance.
Echuca is the administrative centre for the Shire of Campaspe Local Government Area.
At state level, Echuca is represented by the Electoral district of Murray Plains.
At federal level, Echuca is represented by the Division of Murray.
Economy.
The main industry in Echuca is tourism. Tourism earns about $250 million a year for the Echuca economy. Visitors are attracted to the town by its warm climate, the Murray River, recreational attractions, and historical features, some of which have come to public awareness by the Nancy Cato novel "All the Rivers Run" which was made into a TV miniseries. These include the Port of Echuca which has the world's largest fleet of operating paddle steamers. 
Echuca is also a major regional service economy.
Agriculture is very important to the region and dairy, wheat, sheep, pig, and cattle farms are all within close proximity.
Culture.
Paddle steamers.
The port is home to the largest paddle steamer collection in the world, which includes the world's oldest operating wooden hulled paddle steamer, the PS "Adelaide" built in 1866. There are several historic vessels operating out of Echuca on a daily commercial basis such as PS "Pevensey" (built 1911), PS "Alexander Arbuthnot" (built 1923), PS "Adelaide" (built 1866) operating from the wharf and the PS "Emmylou" (built 1980 with a steam engine in use from 1906), PS "Canberra" (built 1913) and PV "Pride of the Murray" (built 1924 as a logging barge "C24") operating from Riverboat Dock, a short distance downstream from the main wharf. These vessels conduct between 4-6 1hour cruises daily, while the PS "Emmylou offers" 1.5 hour lunch cruises twice daily and 2 x 1hour cruises daily, and in peak seasons 2-3hour dinner cruising and 1,2 & 3 night accommodated cruises for up to 18 passengers. There are also a number of privately owned paddle steamers in Echuca. As well as the paddle steamers there are numerous houseboats, many of which can be hired. The MV "Mary Ann" (built 1981) operates as a cruising restaurant in busier times.
The Port of Echuca is also restoring the PV "Success" to full working order. When operational, it will be added to the fleet of paddle steamers at Echuca Wharf.
Events and festivals.
Annual activities include the "Club Marine Southern 80" waterski race, the largest waterski race in the world (February), the "Riverboats Music Festival" (February), the "Echuca Moama Weddings Expo" (May), the "Steam Rally Echuca" (Long weekend June) and the "Echuca Moama Winter Blues Festival" (July). 
In popular culture.
In 1984 the Australian television mini-series, "All the Rivers Run", based on a novel by Nancy Cato and starring Sigrid Thornton and John Waters, was filmed in and around Echuca. The local Paddle Steamers "PS Pevensey" and "PS Emmylou" featured in the mini-series as the PS "Philadelphia" and PS "Providence" respectively. The airing of this series around Australia and internationally revitalised Echuca's tourism economy. In 1985, parts of the Australian telemovie "My Brother Tom" (based on the book by James Aldridge) was filmed in Echuca.
Restaurants and dining.
Echuca is renowned for its variety of restaurants and eating services available. International cuisines are all easily accessible in the town including Thai, Chinese, Italian, Indian and Greek. Another major aspect of Echuca's tourism is the well known wharf-side restaurant "Oscar W's", currently closed for renovations but a popular attraction for rural weddings and fine dining due to its allocation of a 2013 AGFG Chef's Hat. 
Transport.
Echuca is connected over the Murray River to Moama by the Echuca-Moama Road Rail Bridge. This historically significant bridge has riveted iron spans supported on cast iron pillars. Trains no long run on this bridge; a dedicated rail bridge has been constructed next to the old bridge, which now only carries road vehicles.
Echuca-Moama Transit runs 3 services hourly to Echuca East, South & the town of Moama. The terminus is the Old Echuca Post Office on Hare Street. At the moment they are testing a service to 24 Lane and streets on the way to the lane which are near the Rich River Golf Club. V/Line operates the Echuca line rail service from the local station to Melbourne, via Bendigo. Echuca Airport is also located outside the town. 
Media.
Newspaper.
Riverine Herald, produced by McPherson Media Group, is published 3 days a week; it includes local and national news.
Radio.
Community radio station, EMFM, broadcasts in Echuca on the frequency of 104.7FM. They currently broadcast at a power of 1 kW.
Television.
Television stations such as ABC, SBS, Prime7, WIN and SC Ten as well as digital multi-channels are broadcast into Echuca from other regions.
Retailers.
Echuca has many large retailers, including a Big W, Coles, Liquorland, Safeway Supermarket and Liquor (now Woolworths, and BWS), Coles Express, Caltex Woolworths, Aldi, Target Country, Dan Murphy's, Dick Smith, Cotton On, The Reject Shop, and Bunnings Warehouse, in addition to the many range of shops such as book shops, music stores, food stores and more.
Sport.
The town has an Australian Rules football team competing in the Goulburn Valley Football League and a team Echuca United competing in the Murray Football League.
The most popular participation sport in Echuca is Australian Rules football and netball. The local team is called the Murray Bombers. Association Football, or soccer and hockey are also played.
Echuca has a horse racing club, the Echuca Racing Club, which schedules around twelve race meetings a year including the Echuca Cup meeting in March.
Echuca Harness Racing Club conducts regular meetings at its racetrack in the town.
Golfers play at the Echuca Back Nine Golf Course on Eyre and McKenzie Streets.
Water sports:
In 2006 the Inaugural Barry Beehag race was established in honour of Barry Beehag, a founding and life member of the Moama Water Sports Club.
Sister city.
Echuca's sister city was Whitehorse, Yukon, Canada. However, Whitehorse ceased the special relationship in 2008. When asked why the relationship ended, she said "It's not me, it's Echuca"

</doc>
<doc id="63835" url="https://en.wikipedia.org/wiki?curid=63835" title="Tyers, Victoria">
Tyers, Victoria

Tyers is a small town in Victoria, Australia. It is east of Melbourne, north-west of Traralgon and located in the City of Latrobe. It was known until 1852 as "Boola Boola", after which it was named after the surveyor and explorer Charles Tyers. At the , Tyers had a population of 864.
Tyers Post Office opened on 11 September 1882 and is now owned by United Fuels.
The town in conjunction with neighbouring Traralgon has an Australian Rules football team Traralgon-Tyers United competing in the North Gippsland Football League.
The Tyers Arts Festival is an annual event.

</doc>
<doc id="63837" url="https://en.wikipedia.org/wiki?curid=63837" title="Diplura">
Diplura

The order Diplura is one of the four groups of hexapods, alongside insects, springtails and Protura. They are sometimes called "two-pronged bristletails". Around 800 species have been described, of which around 70 occur in North America, 12 in Great Britain and two in Australia.
Anatomy.
Diplurans are mostly long, although some species of "Japyx" may reach . They have no eyes and, apart from the darkened cerci in some species, they are unpigmented. They have long antennae with 10 or more bead-like segments projecting forward from the head, and a pair of cerci projecting backwards from the last of the 11 abdominal somites. These cerci may be long and filamentous or short and pincer-like, leading to occasional confusion with earwigs. These cerci give the group its name, from the Greek "diplo" ("two") and "uros" ("tail"). Some diplurans have the ability to shed their cerci if necessary (autotomy); of all terrestrial arthropods, only diplurans have the ability to regenerate these lost appendages over a series of moults. Moulting occurs up to 30 times throughout the life of a dipluran, which is estimated to last up to one year. The abdomens of diplurans bear eversible vesicles, which seem to absorb moisture from the environment and help with the animal's water balance.
Ecology.
Diplurans are common in moist soil, leaf litter or humus, but are rarely seen because of their size and subterranean lifestyles. They have biting mouthparts and feed on a variety of live prey and dead organic matter. Members of the family Japygidae are mainly predatory and use their pincer-like cerci to capture prey, including springtails, isopods, small myriapods, insect larvae, and even other diplurans, while members of the family Campodeidae feed on soil fungi, mites, springtails, and other small soil invertebrates, as well as detritus. Those species with long cerci are herbivorous.
Like other non-insect hexapods, diplurans have external fertilisation. Males lay up to 200 spermatophores a week, which are held off the ground by a short stalk and probably only remain viable for about two days. The female collects the spermatophore with her genital opening, and later lays eggs in a cavity in the ground. The hatchlings do not undergo metamorphosis, but resemble the adults, apart from their smaller size, lesser number of setae and their lack of reproductive organs.
Relatives.
The relationships among the four groups of hexapods are not resolved, but most recent studies argue against a monophyletic Entognatha. The fossil record of the Diplura is sparse, but one apparent dipluran dates from the Carboniferous. This early dipluran, "Testajapyx", had compound eyes, and mouthparts that more closely resembled those of true insects than those of modern diplurans do.

</doc>
<doc id="63838" url="https://en.wikipedia.org/wiki?curid=63838" title="Traralgon">
Traralgon

Traralgon is a city located in the east of the Latrobe Valley in the Gippsland region of Victoria, Australia. The urban population of Traralgon at the 2011 Census was 24,590. It is the largest and fastest growing city in the greater Latrobe Valley urban area, which has a population of more than 75,000 and is administered by the City of Latrobe.
The origin of the name Traralgon is uncertain. It is popularly believed to be derived from words from the Gunai language: "tarra" meaning "river" and "algon" meaning "little fish". However, these words are not reflected in modern linguists' knowledge of the Gunai language, where, for example, the word for river is "wun wun" or "wurn wurn".
History.
The Gippsland region was originally inhabited by the indigenous Gunai people for a period in excess of 2,000 years.
The area around Traralgon was first settled by Europeans in the 1840s soon after being explored by Count Paweł Strzelecki on his return from the Snowy Mountains where he named Australia's highest peak, Mount Kosciuszko. Due to the Latrobe Valley having relatively high rainfall, the land is very fertile, and farming was quickly established. As with much of central and western Gippsland, this was mainly dairy farming.
The township was established in the early 1860s, the first Post Office opening on 1 January 1861.
In 1877 the railway line from Melbourne was completed with a railway station at Traralgon giving the town a major economic boost.
Traralgon was part of the area administered by the Rosedale Roads Board, before the Shire of Traralgon was established in 1879. In the latter part of the 19th century the Shire grew strongly.
It was not until the 1930s however that Traralgon began to move away from a farming based economy. In 1936 Australian Paper Manufacturers established a paper mill at Maryvale, around from Traralgon.
Queen Elizabeth II and Prince Philip, Duke of Edinburgh visited on 3 March 1954. The president of the Shire of Traralgon, Cr Clem Little met and welcomed the Queen, who was flown by the RAAF from Sale. She returned to Melbourne by train.
In 1960 Traralgon's most famous son Sir Macfarlane Burnet jointly won the Nobel Prize for Physiology and Medicine.
In 1961 Traralgon formed its own borough, the Borough of Traralgon following a decade of lobbying to separate the urban areas of Traralgon from the Shire.
Traralgon was proclaimed a city in 1964.
The old town hall and mechanics institute was finally demolished in 1973.
Further development resulted from the expansion of the power generation industry following World War II, particularly through the now defunct SEC. This included large expansions at Yallourn and Hazelwood Power Stations and the construction of the massive Loy Yang Power Station in the 1970s and 1980s.
The first Loy Yang power station was completed in 1985.
An Australian Securities and Investments Commission (ASIC) information processing centre was established in the early 1990s, at the time employing around 400 people.
The City of Traralgon and Shire of Traralgon continued a separate existence until they were amalgamated into the Shire of Latrobe in 1994.
Completion of the Loy Yang power stations, extensive voluntary departures from the electricity industry and privatisation of the Victorian electricity industry in the early 1990s had devastating effects on the economy of the Latrobe Valley. Traralgon, with a more diversified economy, suffered to a lesser extent than the neighbouring towns of Morwell and Moe both of which relied almost exclusively on the power stations for their livelihood.
Traralgon grew strongly in the mid 2000s, with a figure of 2.7% making it the largest and fastest growing city in the Latrobe Valley.
Geography.
Traralgon is situated on expansive flat land in the Traralgon Creek valley catchment between the Great Dividing Range in the north and the Strzelecki Ranges in the south. The Traralgon Creek runs through the city's centre and its green belt separates its eastern and western suburban areas. The urban area is also hemmed between large open cut mines to the north west and south east.
Urban Structure.
Traralgon is part of the Latrobe Valley tri-city urban area, a small area of industry and agricultural land separates it from neighbouring Morwell. Traralgon together with adjacent Morwell forms an urban area with an estimated population of 40,851 as at June 2014. In recent years the population has grown from 36,829 in June 2004 reaching a peak of 40,911 in 2012 and declining since. Greater Traralgon includes localities such as Traralgon, the suburb of Traralgon East and the relatively sparsely populated satellite localities of Hazelwood and Traralgon South to the south, and Tyers and Glengarry to the north.
The Traralgon central business district is centred around Seymour and Franklin Streets and includes an indoor shopping mall – Stockland Traralgon, however commercial and light industry sprawl along most of the eastern stretch of the Princes Highway. Notable heritage buildings include the Post Office and Courthouse erected in 1886 and Ryans Hotel erected in 1914, both in Franklin Street.
Economy.
The economy is primarily driven by primary industry, natural resources and secondary industry including coal mining, processing and fossil-fuel power generation for the National Electricity Market. Along with electricity production, Traralgon benefits from the mining for oil and natural gas in the nearby Bass Strait fields.
A significant forestry industry operates including logging of both plantation and natural forest timber, The largest paper mill in Australia is located nearby in Maryvale and provides local employment for over 2000 people.
The local agriculture industry is involved in the production of wool and dairy products, as well as vegetable growing.
The tertiary sector of the economy is also important for employment with major government administration offices for the Australian Securities and Investments Commission (ASIC) and health services.
Schools.
Traralgon features a number of primary and secondary schools, including state, catholic and independent schools.
The local primary schools include Grey Street Primary School (formerly Traralgon Primary School), Kosciuszko Street Primary School, Liddiard Road Primary School, Stockdale Road Primary School, St Michaels Primary School, St Gabriels Primary School, Flinders Christian Community College (FCCC) and St Pauls Anglican Grammar School. Flinders Christian Community College and St Paul's Anglican Grammar School are also secondary schools. In addition Traralgon has the Latrobe Special Developmental School catering for students from 5 to 18 years of age with an intellectual disability.
The local government secondary school, Traralgon College, has two campuses, the junior campus (years 7–9) located on Liddiard Rd in Traralgon's east, with the senior campus (years 10–12) on Grey St in Traralgon's west. There is also a Catholic secondary school, Lavalla Catholic College. Lavalla has two campuses in Traralgon's West end, and a third campus in Newborough, Moe. The junior campus, St Paul's, neighbours Traralgon College's senior campus on Grey St. The senior campus, Kildare, is located in Kosciuszko St. Flinders Christian Community College (FCCC) on Liddiard Rd is a P–12 school.
A number of Traralgon families also send their children to the three independent Anglican grammar schools in the region, two of which are about 40 minutes drive from Traralgon: St. Paul's Anglican Grammar School, which has a campus in Traralgon as well as Warragul, or Gippsland Grammar School in Sale.
Culture.
Sport.
Australian rules football is popular. The are two senior clubs, the Traralgon Maroons (which briefly competed in the Victorian Football League between 1996–1997) currently competing in the Gippsland Football League and Traralgon-Tyers United competing in the North Gippsland Football League. There is also a junior league, Traralgon and District Junior Football League, with most games played from the West End Sporting Complex.
Cricket is also popular, with a local league, the Traralgon and District Cricket Association (TDCA) operating.
Soccer is popular with two senior clubs in the Gippsland Soccer League(GSL) – Traralgon Olympians and Traralgon City.
There is a local basketball league, the Traralgon Basketball Association with a stadium at the Traralgon Sports Complex.
The local baseball team is the Traralgon Redsox. www.traralgon.baseball.com.au
Traralgon has a horse racing club, the Latrobe Valley Racing Club, which schedules two race meetings a year including the Cup meeting in December.
The Traralgon Greyhound Racing Club holds regular meetings at Glenview Park.
Golfers play at the course of the Traralgon Golf Club on the Princes Highway.
The Traralgon Harriers are a running club that runs 5 or 6 km races every Thursday night and also organise Victoria's oldest marathon, the Traralgon Marathon, held every June.
The Latrobe Valley Cycling club hold road and track racing events on most weeks throughout the year.
Traralgon Pistol Club and Traralgon small bore rifle Club also located in the town with a healthy membership at both clubs.
Entertainment.
The entertainment precinct which spans Kay, Grey and Franklin Streets attracts people from surrounding towns to several nightclubs, bars and restaurants located there.
Local media.
Newspapers.
The twice weekly "Latrobe Valley Express" newspaper is delivered to all homes on Monday and Thursday nights, in Traralgon, Morwell and Moe. Smaller,weekly papers the "Traralgon Journal", "Moe and Narracan News", along with the "Morwell and Churchill Advertiser" are delivered to all homes on Monday nights with "The Latrobe Valley Express". The "Traralgon Record" newspaper has been digitised from 1886 to 1932 as part of the Australian Newspapers Digitisation Program.
Melbourne Newspapers such as "The Weekly Times", "The Age" and the "Herald Sun" and national newspapers like "The Australian" and "The Australian Financial Review" are also available.
Television.
The three main commercial television networks (Seven, Nine and Ten) are all re-broadcast in the Latrobe Valley by their regional affiliates – Prime7 (Seven), WIN Television (Nine) and Southern Cross Ten (Ten). The area was the first in Australia to receive its own regional television station, GLV-10 Gippsland (now Southern Cross Ten), when it launched on 9 December 1961.
WIN Gippsland provides a 30-minute local news bulletin on weeknights and Southern Cross Ten airs short local news updates on weekdays. All three commercial stations also carry local advertising. Most Melbourne channels (Seven, Nine and Ten) can also be received in analogue and more clearly in digital in Traralgon with a suitable roof-top antenna.
New channels broadcast by the commercial networks in addition to the ones listed above are available on the digital service called Freeview (Australia) to viewers in Traralgon and the Gippsland \ Latrobe Valley region. These channels include One HD, Eleven, 7Two, 7mate, GEM and GO!.
Both national public broadcasters, the Australian Broadcasting Corporation (including channels ABC1, ABC2, ABC3 & ABC News 24) and Special Broadcasting Service (including SBS One & SBS Two), are also broadcast to the Latrobe Valley.
Subscription television service formerly Austar, now Foxtel (circa 2014) is available via satellite.
Radio.
There are two radio stations with studios located in Traralgon — TR FM and GOLD 1242, both owned by ACE Radio. The FM station is broadcast along with the television channels from Mt Tassie while GOLD 1242 is broadcast from an AM transmitter near Sale. Warragul radio stations Star FM and 3GG also service this region. Most Australian Broadcasting Corporation stations are rebroadcast locally and available in Traralgon, along with 774 ABC Melbourne which is able to be received directly from Melbourne.
Transport.
Road transport and the motor vehicle is the main form of transport. The Princes Highway runs through the city and close to the CBD which received heavy regional traffic (although a Traralgon Bypass road is undergoing planning). The Hyland Highway also originates at Traralgon.
Rail transport includes both passenger rail and freight rail. The city's only station is Traralgon railway station which is on the Orbost railway line. Both the Traralgon V/Line rail service and the Bairnsdale V/Line rail service stop there. Traralgon is currently the terminus for VLocity trains with a two way hourly service. Travel time to Flinders Street Station ranges at approximately 109 minutes during peak travel times. Victoria's electronic ticketing system, Myki, was implemented on rail services between Traralgon and Melbourne on 8 July 2013.
Latrobe Valley Buslines provides local services around Traralgon and other cities in the Latrobe Valley.
Latrobe Valley Airport is located close to Traralgon in nearby Morwell and provides general aviation.
Traralgon has a minimal bicycle infrastructure, with few segregated cycle facilities. An exception is the 63-kilomtre-long Gippsland Plains Rail Trail which connects Traralgon to Stratford via Cowwarr, Heyfield, Tinamba and Maffra.

</doc>
<doc id="63844" url="https://en.wikipedia.org/wiki?curid=63844" title="Protura">
Protura

The Protura, or proturans, and sometimes nicknamed coneheads, are very small (<2 mm long), soil-dwelling animals, so inconspicuous they were not noticed until the 20th century. The Protura constitute an order of hexapods that were previously regarded as insects, and sometimes treated as a class in their own right. Some evidence indicates the Protura are basal to all other hexapods, although not all researchers consider them Hexapoda, rendering the monophyly of Hexapoda unsettled. Uniquely among hexapods, proturans show anamorphic development, whereby body segments are added during moults. Szeptycki (2007) lists a total of 731 described species worldwide, in seven families, nearly 300 of which are contained in a single genus, "Eosentomon".
Morphology.
Proturans have no eyes, wings, or antennae, and lack pigmentation: they are usually white or pale brown. The sensory function of the antennae is fulfilled by the first of three pairs of five-segmented legs, which are held up, pointing forward and have many tarsal sensilla and sensory hairs. The head is conical, and bears two pseudoculi with unknown function. The body is elongated and cylindrical, with a postanal telson at the end. The mouthparts are entognathous (enclosed within the head capsule) and consist of thin mandibles and maxillae. There are no cerci at the end of the abdomen, which gives the group their name, from the Greek "proto-" (meaning "first", in this case implying primitive), and "ura", meaning "tail". The first three abdominal segments bear limb-like appendages called "styli". The genitalia are internal and the genital opening lies between the eleventh segment and the telson of the adult. Members of Eosentomoidea possess spiracles and a simple tracheal system, while those in the Acerentomoidea lack these structures and perform gas exchange by diffusion.
Ecology.
Proturans live chiefly in soil, mosses, and leaf litter of moist temperate forests that are not too acidic; they have also been found beneath rocks or under the bark of trees, as well as in animal burrows. They are generally restricted to the uppermost , but have been found as deep as . Although they are sometimes considered uncommon, they are probably often overlooked because of their small size: densities of over 90,000 individuals per square metre have been measured.
The diet of proturans is not yet sufficiently observed, but they feed on mycorrhizal fungi, dead Acari, and mushroom powder in culture, and are thought to feed on decaying vegetable matter and fungi in the wild. The styliform mouthparts suggest the Protura are fluid feeders, with evidence that some species suck out the contents of fungal hyphae.
Proturans which live near the soil surface generally have one generation per year and have longer legs, while those that live deeper have shorter legs and reproduce less seasonally, although some migratory species move to deeper layers for the winter and shallower layers for the summer.
Development.
The larva has 9 abdominal segments, but the number increases through moulting until the full adult number of 12 is reached. Further moults may occur, but do not add any more body segments, and it is not known whether the adults continue to moult through their lives. Eggs have only been observed in a few species. Five developmental stages follow: the prelarva hatches from the egg and has only weakly developed mouthparts and 9 abdominal segments; larva I follows and has fully developed mouthparts; larva II has ten abdominal segments; maturus junior has 12 abdominal segments and is followed by the adult. The family Acerentomidae differs in having an extra preimago stage, with partially developed genitalia, between the maturus junior and the adult.
History.
Proturans were first discovered in the early 20th century, when Filippo Silvestri and Antonio Berlese discovered the animals independently. The first species to be described was "Acerentomon doderoi", published in 1907 by Silvestri, based on material from near Syracuse, New York.
Impact on Humans.
Proturans aide in decomposition by helping in the breakdown of the leaf litter and recycling organic nutrients back into the soil. By aiding in this process proturans play a role in soil formation and general composition, which can be vital in soil restoration. 

</doc>
<doc id="63847" url="https://en.wikipedia.org/wiki?curid=63847" title="Formaldehyde">
Formaldehyde

Formaldehyde is a naturally-occurring organic compound with the formula CH2O. It is the simplest aldehyde and is also known by its systematic name methanal. The common name of this substance comes from its similarity and relation to formic acid.
Formaldehyde is an important precursor to many other materials and chemical compounds. In 1996, the installed capacity for the production of formaldehyde was estimated to be 8.7 million tons per year. It is mainly used in the production of industrial resins, e.g., for particle board and coatings.
In view of its widespread use, toxicity, and volatility, formaldehyde poses a significant danger to human health. In 2011, the US National Toxicology Program described formaldehyde as "known to be a human carcinogen".
Forms of formaldehyde.
Formaldehyde is more complicated than many simple carbon compounds in that it adopts several different forms. As a gas, formaldehyde is colorless and has a characteristic pungent, irritating odor. Upon condensation, the gas converts to various other forms of formaldehyde (with different chemical formulas) that are of more practical value. One important derivative is the cyclic trimer metaformaldehyde or 1,3,5-trioxane with the formula (CH2O)3. There is also a linear polymer called paraformaldehyde. These compounds have similar chemical properties and are often used interchangeably.
When dissolved in water, formaldehyde also forms a hydrate, methanediol, with the formula H2C(OH)2. This compound also exists in equilibrium with various oligomers (short polymers), depending on the concentration and temperature. A saturated water solution, of about 40% formaldehyde by volume or 37% by mass, is called "100% formalin". A small amount of stabilizer, such as methanol, is usually added to suppress oxidation and polymerization. A typical commercial grade formalin may contain 10–12% methanol in addition to various metallic impurities.
Occurrence.
Processes in the upper atmosphere contribute up to 90% of the total formaldehyde in the environment. Formaldehyde is an intermediate in the oxidation (or combustion) of methane, as well as of other carbon compounds, e.g. in forest fires, automobile exhaust, and tobacco smoke. When produced in the atmosphere by the action of sunlight and oxygen on atmospheric methane and other hydrocarbons, it becomes part of smog. Formaldehyde has also been detected in outer space (see below).
Formaldehyde and its adducts are ubiquitous in living organisms. It is formed in the metabolism of endogenous amino acids and is found in the bloodstream of humans and other primates at concentrations of approximately 0.1 millimolar. Experiments in which animals are exposed to an atmosphere containing isotopically labeled formaldehyde have demonstrated that even in deliberately exposed animals, the majority of formaldehyde-DNA adducts found in non-respiratory tissues are derived from endogenously produced formaldehyde.
Formaldehyde does not accumulate in the environment, because it is broken down within a few hours by sunlight or by bacteria present in soil or water. Humans metabolize formaldehyde quickly, so it does not accumulate, converting it to formic acid in the body.
Interstellar formaldehyde.
Formaldehyde was the first polyatomic organic molecule detected in the interstellar medium. Since its initial detection in 1969, it has been observed in many regions of the galaxy. Because of the widespread interest in interstellar formaldehyde, it has recently been extensively studied, yielding new extragalactic sources. A proposed mechanism for the formation is the hydrogenation of CO ice, shown below.
Formaldehyde appears to be a useful probe for astrochemists due to its low reactivity in the gas phase and to the fact that the 110←111 and 211←212 K-doublet transitions are rather clear.
On 11 August 2014, astronomers released studies, using the Atacama Large Millimeter/Submillimeter Array (ALMA) for the first time, that detailed the distribution of HCN, HNC, H2CO, and dust inside the comae of comets C/2012 F6 (Lemmon) and C/2012 S1 (ISON).
Synthesis and industrial production.
History.
Formaldehyde was first reported in 1859 by the Russian chemist Aleksandr Butlerov (1828–86) and was conclusively identified in 1869 by August Wilhelm von Hofmann.
Industry.
Formaldehyde is produced industrially by the catalytic oxidation of methanol. The most common catalysts are silver metal or a mixture of an iron and molybdenum or vanadium oxides. In the commonly used formox process, methanol and oxygen react at ca. 250–400 °C in presence of iron oxide in combination with molybdenum and/or vanadium to produce formaldehyde according to the chemical equation:
The silver-based catalyst usually operates at a higher temperature, about 650 °C. Two chemical reactions on it simultaneously produce formaldehyde: that shown above and the dehydrogenation reaction:
In principle, formaldehyde could be generated by oxidation of methane, but this route is not industrially viable because the methanol is more easily oxidized than methane.
Organic chemistry.
Formaldehyde is a building block in the synthesis of many other compounds of specialised and industrial significance. It exhibits most of the chemical properties of other aldehydes but is more reactive. For example, it is more readily oxidized by atmospheric oxygen into formic acid (formic acid is found in ppm levels in commercial formaldehyde). Formaldehyde is a good electrophile, participating in electrophilic aromatic substitution reactions with aromatic compounds, and can undergo electrophilic addition reactions with alkenes and aromatics. Formaldehyde undergoes a Cannizzaro reaction in the presence of basic catalysts to produce formic acid and methanol.
Examples of organic synthetic applications.
Condensation with acetaldehyde affords pentaerythritol, a chemical necessary in synthesizing PETN, a high explosive. Condensation with phenols gives phenol-formaldehyde resins. With 4-substituted phenols one obtains calixarenes.
When combined with hydrogen sulfide, it forms trithiane.
Formaldehyde can be reduced to methylamine via reductive amination. Methylamine can then be used in other synthetic processes using reductive amination to yield secondary amines.
It is first reacted with ammonia to form an imine and water. 
Then this is reduced using LiAlH4 via an Sn2 reaction or by catalytic hydrogenation to produce the amine.
Uses.
Industrial applications.
Formaldehyde is a common precursor to more complex compounds and materials. In approximate order of decreasing consumption, products generated from formaldehyde include urea formaldehyde resin, melamine resin, phenol formaldehyde resin, polyoxymethylene plastics, 1,4-butanediol, and methylene diphenyl diisocyanate. The textile industry uses formaldehyde-based resins as finishers to make fabrics crease-resistant. Formaldehyde-based materials are key to the manufacture of automobiles, and used to make components for the transmission, electrical system, engine block, door panels, axles and brake shoes. The value of sales of formaldehyde and derivative products was over $145 billion in 2003, about 1.2% of the gross domestic product (GDP) of the United States and Canada. Including indirect employment, over 4 million people work in the formaldehyde industry across approximately 11,900 plants in the U.S. and Canada.
When treated with phenol, urea, or melamine, formaldehyde produces, respectively, hard thermoset phenol formaldehyde resin, urea formaldehyde resin, and melamine resin. These polymers are common permanent adhesives used in plywood and carpeting. It is used as the wet-strength resin added to sanitary paper products such as (listed in increasing concentrations injected into the paper machine headstock chest) facial tissue, table napkins, and roll towels. They are also foamed to make insulation, or cast into moulded products. Production of formaldehyde resins accounts for more than half of formaldehyde consumption.
Formaldehyde is also a precursor to polyfunctional alcohols such as pentaerythritol, which is used to make paints and explosives. Other formaldehyde derivatives include methylene diphenyl diisocyanate, an important component in polyurethane paints and foams, and hexamine, which is used in phenol-formaldehyde resins as well as the explosive RDX. Formaldehyde has been found as a contaminant in several bath products, at levels from 54–610 ppm: it is thought to arise from the breakdown of preservatives in the products, most frequently diazolidinyl urea. Since 2006, formaldehyde (methylene glycol) is also used in hair smoothing treatments in order to straighten wavy/curly hair and make hair less prone to frizz under high humid weather. OSHA Oregon has reported these treatments as unsafe for human health.
Disinfectant and biocide.
An aqueous solution of formaldehyde can be useful as a disinfectant as it kills most bacteria and fungi (including their spores). Formaldehyde solutions are applied topically in medicine to dry the skin, such as in the treatment of warts. Many aquarists use formaldehyde as a treatment for the parasites "Ichthyophthirius multifiliis" and "Cryptocaryon irritans".
Formaldehyde is used to inactivate bacterial products for toxoid vaccines (vaccines that use an inactive bacterial toxin to produce immunity). It is also used to kill unwanted viruses and bacteria that might contaminate the vaccine during production. Urinary tract infections are also often treated using a derivative of formaldehyde (methenamine), a method often chosen because it prevents overuse of antibiotics and the resultant development of bacterial resistance to them. In an acid environment methenamine is converted in the kidneys to formaldehyde, which then has an antibacterial effect in the urinary tract. Some topical creams, cosmetics and personal hygiene products contain derivatives of formaldehyde as the active ingredients that prevent the growth of potentially harmful bacteria.
Tissue fixative and embalming agent.
Formaldehyde preserves or fixes tissue or cells by a mixture of reversible (short exposure time and low temperatures) and irreversible (long exposure time and higher temperatures) cross-linking of primary amino groups in proteins with other nearby nitrogen atoms in protein or DNA through a -CH2- linkage. This is exploited in ChIP-on-chip or ChIP-sequencing genomics experiments, where DNA-binding proteins are cross-linked to their cognate binding sites on the chromosome and analyzed to determine what genes are regulated by the proteins. Formaldehyde is also used as a denaturing agent in RNA gel electrophoresis, preventing RNA from forming secondary structures. A solution of 4% formaldehyde fixes pathology tissue specimens at about one mm per hour at room temperature.
Formaldehyde solutions are used as a fixative for microscopy and histology because of formaldehyde's ability to perform the Mannich reaction, although the percentage formaldehyde used may vary based on the method of analysis. Additionally, the methanol used to stabilize formaldehyde may interfere with the ability to properly fix tissue or cells, and therefore commercial formaldehyde preparations are available that are packaged in glass ampules under an inert gas to prevent the use of contaminating methanol for stabilization. Formaldehyde-based solutions are also used in embalming to disinfect and temporarily preserve human and animal remains. It is the ability of formaldehyde to fix the tissue that produces the tell-tale firmness of flesh in an embalmed body. In post mortem examinations a procedure known as the "sink test" involves placing the lungs of an animal in an aqueous solution of formaldehyde; if the lungs float it suggests the animal was probably breathing or able to breathe at the time of death.
Although formaldehyde solutions are commonly used as a biological preserving medium, usually for smaller specimens, it delays, but does not prevent, decay. This method of fixation does not preserve nucleic acids, thus preventing, for example, genetic analysis of the first discovered "Dendrogramma" specimens.
Several European countries restrict the use of formaldehyde, including the import of formaldehyde-treated products and embalming. Starting September 2007, the European Union banned the use of formaldehyde due to its carcinogenic properties as a biocide (including embalming) under the Biocidal Products Directive (98/8/EC). Countries with a strong tradition of embalming corpses, such as Ireland and other colder-weather countries, have raised concerns. Despite reports to the contrary, no decision on the inclusion of formaldehyde on Annex I of the Biocidal Products Directive for product-type 22 (embalming and taxidermist fluids) had been made .
Drug testing.
Formaldehyde, along with 18 M (concentrated) sulfuric acid makes Marquis reagent which can be used to identify alkaloids and other compounds.
Photography.
In photography, formaldehyde is used in low concentrations for process C-41 (color negative film) stabilizer in the final wash step, as well as in the process E-6 pre-bleach step, to make it unnecessary in the final wash.
Safety.
Formaldehyde is highly toxic to all animals, regardless of method of intake. Ingestion of 30 mL (1 oz.) of a solution containing 37% formaldehyde has been reported to cause death in an adult human. Water solution of formaldehyde is very corrosive and its ingestion can cause severe injury to the upper gastrointestinal tract.
Occupational exposure to formaldehyde by inhalation is mainly from three types of sources: thermal or chemical decomposition of formaldehyde-based resins, formaldehyde emission from aqueous solutions (for example, embalming fluids), and the production of formaldehyde resulting from the combustion of a variety of organic compounds (for example, exhaust gases). Formaldehyde can be toxic, allergenic, and carcinogenic. Because formaldehyde resins are used in many construction materials it is one of the more common indoor air pollutants. At concentrations above 0.1 ppm in air formaldehyde can irritate the eyes and mucous membranes, resulting in watery eyes. Formaldehyde inhaled at this concentration may cause headaches, a burning sensation in the throat, and difficulty breathing, and can trigger or aggravate asthma symptoms.
A 1988 Canadian study of houses with urea-formaldehyde foam insulation found that formaldehyde levels as low as 0.046 ppm were positively correlated with eye and nasal irritation.
A recent review of studies has shown a strong association between exposure to formaldehyde and the development of childhood asthma.
The primary exposure concern is for the workers in the industries producing or using formaldehyde.
The formaldehyde theory of carcinogenesis was proposed in 1978. In 1987 the U.S. EPA classified it as a "probable human carcinogen", and after more studies the WHO International Agency for Research on Cancer (IARC) in 1995 also classified it as a "probable human carcinogen". Further information and evaluation of all known data led the IARC to reclassify formaldehyde as a "known human carcinogen" associated with nasal sinus cancer and nasopharyngeal cancer. Recent studies have also shown a positive correlation between exposure to formaldehyde and the development of leukemia, particularly myeloid leukemia. Nasopharyngeal and sinonasal cancers are relatively rare, with a combined annual incidence in the United States of < 4,000 cases. About 25,000 cases of myeloid leukemia occur in the United States each year. Workplace exposure to inhaled chemicals is among the most important risk factors for sinonasal cancers. Professionals exposed to formaldehyde in their occupation, such as funeral industry workers and embalmers, showed an increased risk of leukemia and brain cancer compared with the general population. Other factors are important in determining individual risk for the development of leukemia or nasopharyngeal cancer.
In the residential environment, formaldehyde exposure comes from a number of different routes; formaldehyde can off-gas from wood products, such as plywood or particle board, but it is produced by paints, varnishes, floor finishes, and cigarette smoking as well.
The United States Environmental Protection Agency (EPA) allows no more than 0.016 ppm formaldehyde in the air in new buildings constructed for that agency. A U.S. Environmental Protection Agency study found a new home measured 0.076 ppm when brand new and 0.045 ppm after 30 days. The Federal Emergency Management Agency (FEMA) has also announced limits on the formaldehyde levels in trailers purchased by that agency. The EPA recommends the use of "exterior-grade" pressed-wood products with phenol instead of urea resin to limit formaldehyde exposure, since pressed-wood products containing formaldehyde resins are often a significant source of formaldehyde in homes.
For most people, irritation from formaldehyde is temporary and reversible, though formaldehyde can cause allergies and is part of the standard patch test series. In 2005–06, it was the seventh-most-prevalent allergen in patch tests (9.0%). People with formaldehyde allergy are advised to avoid formaldehyde releasers as well ("e.g.", Quaternium-15, imidazolidinyl urea, and diazolidinyl urea). People who suffer allergic reactions to formaldehyde tend to display lesions on the skin in the areas that have had direct contact with the substance, such as the neck or thighs (often due to formaldehyde released from permanent press finished clothing) or dermatitis on the face (typically from cosmetics). Formaldehyde has been banned in cosmetics in both Sweden and Japan. The eyes are most sensitive to formaldehyde exposure: The lowest level at which many people can begin to smell formaldehyde is about 0.05 ppm and the highest level is 1 ppm. The maximum concentration value at the workplace is 0.3 ppm. In controlled chamber studies, individuals begin to sense eye irritation at about 0.5 ppm; 5 to 20 percent report eye irritation at 0.5 to 1 ppm; and greater certainty for sensory irritation occurred at 1 ppm and above. While some agencies have used a level as low as 0.1 ppm as a threshold for irritation, the expert panel found that a level of 0.3 ppm would protect against nearly all irritation. In fact, the expert panel found that a level of 1.0 ppm would avoid eye irritation—the most sensitive endpoint—in 75–95% of all people exposed.
Formaldehyde levels in building environments are affected by a number of factors. These include the potency of formaldehyde-emitting products present, the ratio of the surface area of emitting materials to volume of space, environmental factors, product age, interactions with other materials, and ventilation condition. Formaldehyde emits from a variety of construction materials, furnishings, and consumer products. The three products that emit the highest concentrations are medium density fiberboard, hardwood plywood, and particle board. Environmental factors such as temperature and relative humidity can elevate levels because formaldehyde has a high vapor pressure. Formaldehyde levels from building materials are the highest when a building first opens because materials would have less time to off-gas. Formaldehyde levels decrease over time as the sources suppress.
Formaldehyde levels in air can be sampled and tested in several ways, including impinger, treated sorbent, and passive monitors. The National Institute for Occupational Safety and Health (NIOSH) has measurement methods numbered 2016, 2541, 3500, and 3800.
Studies on the interactions between formaldehyde and proteins at the molecular level have been reported on the effects of the body’s carrier protein, serum albumin. The binding of formaldehyde loosens the skeletal structure of albumin and exposure of aromatic ring amino acids in the internal hydrophobic region. Symptoms may affect personal awareness, making one feel tired or fatigued.
Formaldehyde inhalation has also shown to cause oxidative stress and inflammation in animals. Mice studied over an exposure to a high dose of formaldehyde (3ppm), showed increased levels of NO levels in plasma. This result suggests that FA inhalation either decreased NO production or increased NO scavenging, which may be an anti-stress mechanism in the body. Formaldehyde inhalation changes the sensitivity of immune system, which influences oxidative stress.
In June 2011, the twelfth edition of the National Toxicology Program (NTP) Report on Carcinogens (RoC) changed the listing status of formaldehyde from "reasonably anticipated to be a human carcinogen" to "known to be a human carcinogen". Concurrently, a National Academy of Sciences (NAS) committee was convened and issued an independent review of the draft United States Environmental Protection Agency IRIS assessment of formaldehyde, providing a comprehensive health effects assessment and quantitative estimates of human risks of adverse effects.
International bans.
There are several web articles claiming that formaldehyde has been banned from manufacture or import into the European Union (EU) under REACH (Registration, Evaluation, Authorization, and restriction of Chemical substances) legislation. This appears to be misinformation, as official EU chemical databases contradict these claims as of February 19, 2010. This misconception has gained some ground. Formaldehyde is not listed in the Annex I of Regulation (EC) No 689/2008 (export and import of dangerous chemicals regulation), nor on a priority list for risk assessment. However, formaldehyde is banned from use in certain applications (preservatives for liquid-cooling and processing systems, slimicides, metalworking-fluid preservatives, and antifouling products) under the Biocidal Products Directive. In the EU, the maximum allowed concentration of formaldehyde in finished products is 0.2%, and any product that exceeds 0.05% has to include a warning that the product contains formaldehyde.
In the United States, a bill was passed in Congress on July 7, 2010, regarding the use of formaldehyde in hardwood plywood, particle board, and medium density fiberboard. The bill limited the allowable amount of formaldehyde emissions from these wood products to .09 ppm, a standard which companies were required to meet by January 2013.
Formaldehyde was declared a toxic substance by the 1999 Canadian Environmental Protection Act.
Formaldehyde issues in trailers.
Hurricanes Katrina and Rita.
In the U.S. the Federal Emergency Management Agency (FEMA) provided travel trailers, recreational park trailers and manufactured homes starting in 2006 for habitation by residents of the U.S. gulf coast displaced by Hurricane Katrina and Hurricane Rita. Some of the people who moved into the FEMA trailers complained of breathing difficulties, nosebleeds, and persistent headaches. Formaldehyde-catalyzed resins were used in the production of these homes.
The United States Centers For Disease Control and Prevention (CDC) performed indoor air quality testing for formaldehyde in some of the units. On February 14, 2008, the CDC announced that potentially hazardous levels of formaldehyde were found in many of the travel trailers and manufactured homes provided by the agency. The CDC's preliminary evaluation of a scientifically established random sample of 519 travel trailers and manufactured homes tested between December 21, 2007, and January 23, 2008 (2+ years after manufacture), showed average levels of formaldehyde in all units of about 0.077 parts per million (ppm). Long-term exposure to levels in this range can be linked to an increased risk of cancer and, at levels above this range, there can also be a risk of respiratory illness. These levels are higher than expected in indoor air, where levels are commonly in the range of 0.01–0.02 ppm, and are higher than the Agency for Toxic Substance Disease Registry (ATSDR, division of the CDC) Minimal Risk Level (MRL) of 0.008 ppm. Levels measured ranged from 0.003 ppm to 0.59 ppm.
FEMA, which requested the testing by the CDC, said it would work aggressively to relocate all residents of the temporary housing as soon as possible. Lawsuits were filed against FEMA trailer manufacturers as a result of the exposures. As of 2012, U.S. District Judge Kurt D. Engelhardt of New Orleans approved a $42.6 million class-action lawsuit settlement for the plaintiffs, who included roughly 55,000 residents of Louisiana, Mississippi, Alabama and Texas. The defendants included two dozen manufacturers who built mobile homes for the Federal Emergency Management Agency (FEMA), including Gulf Stream Coach Inc., Forest River Inc., Vanguard LLC and Monaco Coach Corp. A separate $5.1 million settlement dealt with claims against FEMA contractors including Shaw Environmental Inc., Bechtel Corp., Fluor Enterprises Inc. and CH2M Hill Constructors Inc., who were responsible for installing and maintaining the units.
Iowa floods of 2008.
Also in the U.S., problems arose in trailers again provided by FEMA to residents displaced by the Iowa floods of 2008. Several months after moving to the trailers, occupants reported violent coughing, headaches, as well as asthma, bronchitis, and other problems. Tests showed that in some trailers, levels of formaldehyde exceeded the limits recommended by the U.S. Environmental Protection Agency and American Lung Association. The associated publicity has resulted in additional testing to begin in November.
Contaminant in food.
Scandals have broken in both the 2005 Indonesia food scare and 2007 Vietnam food scare regarding the addition of formaldehyde to foods to extend shelf life. In 2011, after a four-year absence, Indonesian authorities found foods with formaldehyde being sold in markets in a number of regions across the country. Besides using formaldehyde, they also used borax but not in combination. In August 2011, at least at two Carrefour supermarkets, the Central Jakarta Livestock and Fishery Sub-Department found a sweet glutinous rice drink (cendol) contained 10 parts per million of formaldehyde. In 2014, the owner of two noodle factories in Bogor, Indonesia; was arrested for using formaldehyde in noodles. 50 kg of formaldehyde was confiscated. Foods known to be contaminated include noodles, salted fish, and tofu; chicken and beer are also rumored to be contaminated. In some places, such as China, formaldehyde is still used illegally as a preservative in foods, which exposes people to formaldehyde ingestion. In humans, the ingestion of formaldehyde has been shown to cause vomiting, abdominal pain, dizziness, and in extreme cases can cause death. Testing for formaldehyde is by blood and/or urine by gas chromatography-mass spectrometry. Other methods include infrared detection, gas detector tubes, etc., of which HPLC is the most sensitive. In the early 1900s, it was frequently added by US milk plants to milk bottles as a method of pasteurization due to the lack of knowledge regarding formaldehyde's toxicity.
In 2011 in Nakhon Ratchasima, Thailand, truckloads of rotten chicken were exposed to formaldehyde in which "a large network," including 11 slaughterhouses run by a criminal gang, were implicated. In 2012, 1 billion rupiah (almost USD100,000) of fish imported from Pakistan to Batam, Indonesia, were found laced with formaldehyde.
Formalin use in foods is a crucial problem in Bangladesh currently. Local stores and supermarkets often sell fruits, fishes, and vegetables that have been treated with formalin to keep them fresh. However, in 2015, a "Formalin Control Bill" was passed in the Parliament of Bangladesh with a provision of life-term imprisonment as the maximum punishment and in addition 20,00,000 BDT as fine but not less than 5,00,000 BDT for importing, production or hoarding of formalin without license.
Treatment.
PhotoPlasma technology.
This technology captures the air pollutant, then decompose to harmless elements rapidly such as CO2 and H2O. It can eliminate indoor formaldehyde and other VOC effectively. Also, it can reduce odor, bacteria & virus (H5N1 viruses, Listeria monocytogenes, E.coil 0157 and Surface bacteria), mold, fumes, smoke, and other airborne impurities

</doc>
<doc id="63852" url="https://en.wikipedia.org/wiki?curid=63852" title="Chosen-plaintext attack">
Chosen-plaintext attack

A chosen-plaintext attack (CPA) is an attack model for cryptanalysis which presumes that the attacker can obtain the ciphertexts for arbitrary plaintexts. The goal of the attack is to gain information which reduces the security of the encryption scheme.
Introduction.
In a chosen-plaintext attack the adversary can adaptively ask for the ciphertexts of arbitrary messages. This is formalized by allowing the adversary to interact with an encryption oracle, viewed as a black box.
This appears, at first glance, to be an unrealistic model; as it is unlikely that an attacker could persuade a human cryptographer to encrypt large amounts of plaintexts of the attacker's choosing. However, modern cryptography is implemented in software or hardware and is used for a diverse range of applications; for many cases, a chosen-plaintext attack is often very feasible. Chosen-plaintext attacks become extremely important in the context of public key cryptography, where the encryption key is public and so attackers can encrypt any plaintext they choose.
In the worst case, a chosen-plaintext attack could reveal the scheme's secret key. For some chosen-plaintext attacks, only a small part of the plaintext needs to be chosen by the attacker: such attacks are known as plaintext injection attacks.
Forms of chosen-plaintext attacks.
There are two forms of chosen-plaintext attacks:
Chosen-plaintext attacks in practice.
In World War II US Navy cryptoanalysts discovered that Japan was planning to attack a location referred to as "AF". They believed that "AF" might be Midway Island, because other locations in the Hawaiian Islands had codewords that began with "A". To prove their hypothesis that "AF" corresponded to "Midway Island" they asked the US forces at Midway to send a plaintext message about low supplies. The Japanese intercepted the message and immediately reported to their superiors that "AF" was low on water, confirming the Navy's hypothesis and allowing them to position their force to win the battle.
Also during World War II, Allied codebreakers at Bletchley Park would sometimes ask the Royal Air Force to lay mines at a position that didn't have any abbreviations or alternatives in the German naval system's grid reference. The hope was that the Germans, seeing the mines, would use an Enigma machine to encrypt a warning message about the mines and an "all clear" message after they were removed, giving the allies enough information about the message to break the German naval Enigma. This process of "planting" a known-plaintext was called "gardening". Allied codebreakers also helped craft messages sent by double agent Joan Pujol Garcia, whose encrypted radio reports were received in Madrid, manually decrypted, and then re-encrypted with an Enigma machine for transmission to Berlin. This helped the codebreakers decrypt the code used on the second leg, having supplied the original text.
Relation to other attacks.
A chosen-plaintext attack is more powerful than known-plaintext attack, because the attacker can obtain many pairs of plaintexts and ciphertexts, instead of only one pair, and therefore has more data for cryptanalysis. Therefore, any cipher that prevents chosen-plaintext attacks is also secure against known-plaintext and ciphertext-only attacks.
However, a chosen-plaintext attack is less powerful than a chosen-ciphertext attack, where the attacker can obtain the plaintexts of arbitrary ciphertexts. A CCA-attacker can sometimes break a CPA-secure system.

</doc>
<doc id="63853" url="https://en.wikipedia.org/wiki?curid=63853" title="Tomsk">
Tomsk

Tomsk () is a city and the administrative center of Tomsk Oblast, Russia, located on the Tom River. One of the oldest towns in Siberia, Tomsk celebrated its 400th anniversary in 2004. Population: 
History.
Tomsk originated with a decree from Tsar Boris Godunov in 1604 after , the Tatar duke of , asked for the Tsar's protection against Kirghiz bandits. The Tsar sent 200 Cossacks under the command of and Gavriil Ivanovich Pisemsky to construct a fortress on the bank of the Tom River, overlooking what would become the city of Tomsk. Toian ceded the land for the fortress to the Tsar.
In 1804 the Imperial Russian government selected Tomsk as the seat of the new Tomsk Governorate, which would include the modern cities of Novosibirsk, Kemerovo, and Krasnoyarsk, as well as the territories now in Eastern Kazakhstan. The new status brought development and the city grew quickly.
The discovery of gold in 1830 brought further development to Tomsk in the 19th century; however, when in the 1890s the Trans-Siberian Railway bypassed the city in favor of the village of Novonikolayevsk (Novosibirsk), development began to move south to connect with the railway. In time, Novosibirsk would surpass Tomsk in importance.
In the mid-19th century one fifth of the city's residents were exiles. However, within a few years, the city would be reinvented as the educational center of Siberia with the establishment of Tomsk State University (founded in 1880) and Tomsk Polytechnic University (founded in 1896). By World War II, every twelfth resident of the city was a student, giving rise to the city's informal name - the "Siberian Athens".
After the October Revolution of 1917 the city became a notable center of the White movement, led by Anatoly Pepelyayev and Maria Bochkareva, among others. After the victory of the Red Army in the 1920s, Soviet authorities incorporated Tomsk into the West Siberian Krai and later into Novosibirsk Oblast.
Like many Siberian cities, Tomsk became the new home for many factories relocated out of the war zone from 1941. The resulting growth of the city led the Soviet government to establish the new Tomsk Oblast, with Tomsk serving as the administrative center.
During the Cold War Tomsk became one of many designated closed cities, which outsiders and, in particular, foreigners, could not visit. In 1949 matters went a stage further with the establishment of a secret city, known as "Tomsk-7" (or sometimes simply as "Postbox 5") north-west of Tomsk; the new settlement became the home of the Tomsk Nuclear Plant (subsequently renamed the Sibirskaya Nuclear Power Plant), the Soviet Union's first industrial-scale nuclear-power station. Tomsk-7 received municipal status in 1956 and was renamed Seversk in 1992.
Administrative and municipal status.
Tomsk serves as the administrative center of the oblast and, within the framework of administrative divisions, it also serves as the administrative center of Tomsky District, even though it is not a part of it. As an administrative division, it is, together with seven rural localities, incorporated separately as Tomsk City Under Oblast Jurisdiction—an administrative unit with the status equal to that of the districts. As a municipal division, Tomsk City Under Oblast Jurisdiction is incorporated as Tomsk Urban Okrug.
City divisions.
Tomsk is divided into four city districts: Kirovsky, Leninsky, Oktyabrsky, and Sovetsky.
Climate.
Tomsk has a humid continental climate (Köppen climate classification "Dfb") barely escaping a subarctic classification. The annual average temperature is . Winters are severe and lengthy, and the lowest recorded temperature was in January 1931. However, the average temperature in January is between and . The average temperature in July is . The total annual rainfall is . In 2006, Tomsk experienced what might have been its first recorded winds of hurricane force, which toppled trees and damaged houses.
Politics.
Tomsk is governed by a mayor and a 33-member Duma. The current mayor, appointed in 2013, is Ivan Klyain, a member of The United Russia party.
Of the 33 members, 16 are elected from the eight double mandate districts while 17 are chosen from party lists.
In the October 2005 local elections, United Russia was expected to cruise to a solid victory; however, the Pensioners Party put up a strong showing. The final count was (proportional representation):
Economy.
Energy generation.
Tomsk has the oldest electrical grid in Siberia. There are three powerstations in the city:
Tomsk consumes more electric energy than it produces. The bulk of the city's electric and thermal energy is produced by the GRES-2 (281 MWt) and TEC-3 (140 MWt) powerplants, belonging to Tomskenergo Inc. Tomsk supplements its energy needs with electricity generated at Seversk.
Transportation.
Road network:
There is a commercial and passenger port on the Tom River.
The city is served by the Bogashevo Airport.
Railways.
Tomsk is a small railway center that is situated on the Tayga—Bely Yar line (Tomsk branch) of the Trans-Siberian Railway
The main line of the Trans-Siberian railway, built in 1896, passes south of Tomsk and bypasses Tomsk. Access from Tomsk to the Trans-Siberian railway is available via the town of Tayga. A regional rail line links Tomsk with Tayga.
The Tomsk Railway existed as an independent entity until 1961. At the present time, the Tomsk line belongs to the West-Siberian Railway, branch of Russian Railways Corp.. Trains link Tomsk to Anapa, Asino, Barnaul, Bely Yar, Moscow, Novokuznetsk, Novosibirsk, Sochi, and Tayga.
Public transportation.
The main part of inner-city and suburban transportation is provided by "marshrutkas" (routed taxis), mainly PAZ) minibuses, which serve about forty routes.
Additionally, the city has eleven proper bus routes, eight trolleybus lines (built in 1967), and five tram lines (constructed in 1949). Private taxis are also readily available.
Air transportation.
Tomsk Bogashevo Airport is served by the following airlines:
The airport is also served by charter flights operated by UTair and Alrosa Mirny Air Enterprise
Education.
Tomsk has a number of prominent institutions of higher education, including:
A large number of educational institutions in the city have contributed to making Tomsk a major center for Russia's IT industry. Tomsk was one of the first cities in Russia to gain access to the Internet, which became available in the early 1990s owing to grants received by universities and scientific cooperation.
Culture.
Tomsk has many local cultural institutions including several drama theaters as well as a children's theater and a puppet theater. Major concert venues in the city include the Conservatory Concert hall and the Tomsk Palace of Sport. The city also boasts cultural centers dedicated to German, Polish and Tatar languages and culture.
One of the city's prominent theaters was destroyed in an act of terrorism in 1905. The Korolevsky Theater (built in 1884–85) was being used by a group of communist revolutionaries when the theater was attacked and set on fire by members of the Black Hundred, a hard-line nationalist organization. Those who escaped the flames were gunned down by Black Hundred members waiting outside the theater. Estimates put the number of casualties between 200 and 1000.
There are a number of museums in Tomsk devoted to various subjects, most notably art, local history and wood carving. There is also a Museum of Oppression, housed in a former KGB dungeon. Tomsk State University has a number of small museums with exhibits on archaeology, paleontology, zoology, as well as a herbarium and a botanical garden
As in many other cities in the former Soviet Union, the revolutionary government destroyed a number of old churches in the city including two that had existed since the 17th century. However, Tomsk managed to save some of its churches by transforming them into machine shops, warehouses, archives, and even residential buildings. Since the end of the communist era some of the churches have been renovated and returned to their congregations.
Tomsk is well known for its intricate "gingerbread" decoration of traditional wooden houses in the area. However, the number of old homes in this style is decreasing due to redevelopment or some of them catching fire, as the structures have little to no fire protection.
Trud (Labor) Stadium, in central Tomsk is the base for matches with the FC Tom Tomsk, the city's professional football club. The team's 2004 promotion to the Russian Premier League gave local fans a chance to see some of the nation's best teams play at the city's own stadium.
Tomsk has many local media outlets including the "TV2" television station, shut down by the authorities and turned into an internet TV medium, the radio stations "Radio Siberia" and "Echo of Moscow in Tomsk" along with several newspapers ("Tomskaya Nedelya, Krasnoye Znamya" and "Vechernii Tomsk").
In April 2006 Tomsk received international media attention as the venue of a major summit on economic cooperation, held in the city between Russian President Vladimir Putin and German Chancellor Angela Merkel.
Tomsk was the name given by children's author Elizabeth Beresford to one of her fictional characters The Wombles, all of whom are named after places.
International relations.
Tomsk is the only non-capital member of the Asian Network of Major Cities 21.
Twin towns and sister cities.
Tomsk is twinned with:

</doc>
<doc id="63855" url="https://en.wikipedia.org/wiki?curid=63855" title="Generalitat">
Generalitat

Generalitat (, , literally in English 'Generality') is the name of the systems of government of two of the present Spanish autonomous communities: Catalonia and Valencia. The term is also used for the government of the semi-autonomous "comarca" of Val d'Aran, the "Generalitat a l'Aran".
"Generalitat" refers to all three branches of government, not simply the executive. For example, the Catalan executive is, officially, the "Government of the Generalitat of Catalonia" ("Govern de la Generalitat de Catalunya": cf. Government of the Kingdom of Spain, "Gobierno del Reino de España"), while those of the community of Valencia and the Val d'Aran are known as the "Council of the Valencian Generalitat" ("Consell de la Generalitat Valenciana") and the "Síndic" respectively.
The name "Generalitat" dates back to the 13th century, to the medieval courts of the ancient Principality of Catalonia and the Kingdom of Valencia respectively. The term originally referred to a delegation of members of the "Corts", who oversaw the implementation of the decisions of the "Corts" between sessions, and is derived from the Catalan "Diputació del General (de Catalunya)". The Catalan and Valencian "Generalitats" were both abolished by the Nueva Planta decrees, signed by Philip V of Spain at the start of the eighteenth century, and only reinstated after the death of Franco in 1975, although in Catalonia it also had a brief existence during the Second Spanish Republic. The "Generalitat a l'Aran" was legally created by the 2006 modification of the Statute of Autonomy of Catalonia, although the Val d'Aran had also enjoyed considerable autonomy within Catalonia under the 1979 Statute of Autonomy.

</doc>
<doc id="63857" url="https://en.wikipedia.org/wiki?curid=63857" title="Philip V of Spain">
Philip V of Spain

Philip V (, , ; 19 December 1683 – 9 July 1746) was King of Spain from 1 November 1700 to 15 January 1724, when he abdicated in favour of his son Louis, and from 6 September 1724, when he assumed the throne again upon his son's death, to his own death 9 July 1746.
Before his reign, Philip occupied an exalted place in the royal family of France as a grandson of King Louis XIV. His father, Louis, the Grand Dauphin, had the strongest genealogical claim to the throne of Spain when it became vacant in 1700. However, since the Grand Dauphin and Philip's older brother, Louis, Duke of Burgundy, could not be displaced from their place in the succession to the French throne, King Charles II of Spain named Philip as his heir in his will. It was well known that the union of France and Spain under one monarch would upset the balance of power in Europe, such that other European powers would take steps to prevent it. Indeed, Philip's accession in Spain provoked the 14-year War of the Spanish Succession, which continued until the Treaty of Utrecht forbade any future possibility of unifying the French and Spanish thrones.
Philip was the first member of the House of Bourbon to rule as king of Spain. The sum of his two reigns, 45 years and 21 days, is the longest in modern Spanish history.
Early years.
Philip was born at the Palace of Versailles in France the second son of Louis, Grand Dauphin, the heir apparent to the throne of France, and his wife Maria Anna Victoria of Bavaria, "Dauphine Victoire". He was a younger brother of Louis, Duke of Burgundy, the father of Louis XV of France. At birth, Philip was created Duke of Anjou, a traditional title for younger sons in the French royal family. He would be known by this name until he became the king of Spain. Since Philip's older brother, the Duke of Burgundy, was second in line to the French throne after his father, there was little expectation that either he or his younger brother Charles, Duke of Berry, would ever rule over France.
Philip was tutored with his brothers by François Fénelon, Archbishop of Cambrai. The three were also educated by Paul de Beauvilliers.
Claims to the Spanish throne.
In 1700 the King Charles II of Spain died childless. His will named the 16-year-old Philip, grandson of Charles' half-sister Maria Theresa of Spain, the first wife of Louis XIV, as his successor. Upon any possible refusal, the crown of Spain would be offered next to Philip's younger brother, the Duke of Berry, then to the Archduke Charles of Austria, later Holy Roman Emperor Charles VI. Philip had the better genealogical claim to the Spanish throne, because his Spanish grandmother and great-grandmother were older than the ancestors of the Archduke Charles of Austria. However, the Austrian branch claimed that Philip's grandmother had renounced the Spanish throne for herself and her descendants as part of her marriage contract. This was countered by the French branch's claim that it was on the basis of a dowry that had never been paid.
After a long Royal Council meeting in France at which the Dauphin spoke up in favour of his son's rights, it was agreed that Philip would ascend the throne, but would forever renounce his claim to the throne of France for himself and his descendants.
After the Royal Council decided to accept the provisions of the will of Charles II naming Philip king of Spain, the Spanish ambassador was called in and introduced to his new king. The ambassador, along with his son, knelt before Philip and made a long speech in Spanish which Philip did not understand, although Louis XIV (the son and husband of Spanish princesses) did. Philip only later learned to speak Spanish.
First marriage.
On 2 November 1701 Philip married the 13-year-old Maria Luisa of Savoy, as chosen by his grandfather. She was the daughter of Victor Amadeus II, Duke of Savoy, and Philip's second cousin Anne Marie d'Orléans, also the parents of the Duchess of Burgundy, Philip's sister-in-law. There was a proxy ceremony at Turin, the capital of the Duchy of Savoy, and another one at Versailles on 11 September.
As queen of Spain, Maria Luisa proved very popular with her subjects. She served as regent for her husband on several occasions. Her most successful term was when Philip was away touring his Italian domains for nine months in 1702. In 1714, she died at the age of 26 from tuberculosis, a devastating emotional blow to her husband.
War of the Spanish Succession.
The actions of Louis XIV heightened the fears of the English, the Dutch and the Austrians, among others. In February 1701, Louis XIV caused the "Parlement" of Paris (a court) to register a decree that if Philip's elder brother, the "Petit Dauphin" Louis, died without an heir, then Philip would surrender the throne of Spain for the succession to the throne of France, ensuring dynastic continuity in Europe's greatest land power.
However, a second act of the French king "justified a hostile interpretation": pursuant to a treaty with Spain, Louis occupied several towns in the Spanish Netherlands (modern Belgium and Nord-Pas-de-Calais). This was the spark that ignited the powder keg created by the unresolved issues of the War of the League of Augsburg (1689–97) and the acceptance of the Spanish inheritance by Louis XIV for his grandson.
Almost immediately the War of the Spanish Succession began. Concern among other European powers that Spain and France united under a single Bourbon monarch would upset the balance of power pitted powerful France and weak Spain against the Grand Alliance of England, the Netherlands and Austria.
Inside Spain, the Crown of Castile supported Philip of France. On the other hand, the majority of the nobility of the Crown of Aragon supported Charles of Austria, son of Holy Roman Emperor Leopold I and claimant to the Spanish throne by right of his grandmother Maria Anna of Spain. Charles was even hailed as King of Aragon under the name Charles III.
The war was centred in Spain and west-central Europe (especially the Low Countries), with other important fighting in Germany and Italy. Prince Eugene of Savoy and the Duke of Marlborough distinguished themselves as military commanders in the Low Countries. In colonial North America, the conflict became known to the English colonists who fought against French and Spanish forces as Queen Anne's War. Over the course of the fighting, some 400,000 people were killed.
It was with this war as a backdrop that, beginning in 1707, Philip issued the Nueva Planta decrees, which centralized Spanish rule under the Castilian political and administrative model and in the process abolished the charters of all independently administered kingdoms within Spain—most notably the Crown of Aragon, which was supporting Charles VI in the conflict—except for the Kingdom of Navarre and the rest of the Basque region, who had supported Philip in the war for the Spanish throne, and retained their semi-autonomous self-government. The policy of centralization had as model the French State under Louis XIV and was strongly supported by politicians such as Joseph de Solís and the Sardinian-born political philosopher Vicente Bacallar.
At one point in 1712 Philip was offered the choice of renouncing the throne of Spain so that he could be made heir of France, but he refused.
Philip decided to relinquish his right of succession to France under one condition: the introduction of semi-Salic law in Spain. Under this law, the succession to the Spanish crown was limited to his entire male line before it could pass to any female, a condition of his renunciation made clear to the allies during the preliminaries of the Treaties of Utrecht. It was not until this was successfully accomplished (10 May 1713) that Spain and Great Britain made their own peace terms at the second Treaty of Utrecht (annexing the new law to the Treaty). By the terms of the Treaty of Utrecht that concluded the war, Spain was forced to cede Minorca and Gibraltar to Great Britain; the Spanish Netherlands, Naples, Milan, and Sardinia to the Austrian Habsburgs; and Sicily and parts of Milan to Savoy.
These losses greatly diminished the Spanish Empire in Europe, which had already been in decline. Throughout his reign, Philip sought to reverse the decline of Spanish power. Trying to overturn the terms of the Treaty of Utrecht, he attempted to re-establish Spanish claims in Italy, triggering the War of the Quadruple Alliance (1718-1720) in which Spain fought a coalition of four major powers. Phillip V was forced to sue for peace.
Second marriage.
Shortly after the death of Queen Maria Luisa in 1714, the King decided to marry again. His second wife was Elisabeth of Parma, daughter of Odoardo Farnese, Hereditary Prince of Parma, and Dorothea Sophie of the Palatinate. At the age of twenty-one, on 24 December 1714, she was married by proxy in Parma. The marriage was arranged by Cardinal Alberoni, with the concurrence of the Princesse des Ursins, the "Camarera mayor de Palacio" ("chief of the household") of the king of Spain.
Abdication.
On 14 January 1724, Philip abdicated the throne to his eldest son, the seventeen-year-old Louis, for reasons still subject to debate. One theory suggests that Philip V, who exhibited many elements of mental instability during his reign, did not wish to reign due to his increasing mental decline.
A second theory puts the abdication in context of the Bourbon dynasty. The French royal family recently had lost many legitimate agnates to diseases. Indeed, Philip V's abdication occurred just over a month after the death of the Duke of Orléans, who had been regent for Louis XV of France. The lack of an heir made another continental war of succession a possibility. Philip V was a legitimate descendant of Louis XIV, but matters were complicated by the Treaty of Utrecht, which forbade a union of the French and Spanish crowns. The theory supposes that Philip V hoped that by abdicating the Spanish crown he could circumvent the Treaty and succeed to the French throne.
In any case, Louis died on 31 August 1724 in Madrid of smallpox, having reigned only seven months and leaving no issue. Philip was forced to return to the Spanish throne as his younger son, the later Ferdinand VI, was not yet of age.
Later reign.
Philip helped his Bourbon relatives to make territorial gains in the War of the Polish Succession and the War of the Austrian Succession by reconquering Naples and Sicily from Austria and Oran from the Ottomans. Finally, at the end of his reign Spanish forces also successfully defended their American territories from a large British invasion during the War of Jenkins' Ear.
During Philip's reign, Spain began to recover from the stagnation it had suffered during the twilight of the Spanish Habsburg dynasty. Although the population of Spain grew, the financial and taxation systems were archaic and the treasury ran deficits. The king employed thousands of highly paid retainers at his palaces—not to rule the country but to look after the royal family. The army and bureaucracy went months without pay and only the shipments of silver from the New World kept the system going. Spain suspended payments on its debt in 1739—effectively declaring bankruptcy.
Death.
Philip was afflicted by fits of manic depression and increasingly fell victim to a deep melancholia. His second wife, Elizabeth Farnese, completely dominated her passive husband. She bore him further sons, including another successor, Charles III of Spain. Beginning in August 1737 his affliction was eased by the castrato singer Farinelli, who, became the ""Musico de Camara" of Their Majesties." Farinelli would sing eight or nine arias for the king and queen every night, usually with a trio of musicians.
Philip died on 9 July 1746 in El Escorial, in Madrid, but was buried in his favorite Royal Palace of La Granja de San Ildefonso, near Segovia. Ferdinand VI of Spain, his son by his first queen Maria Luisa of Savoy, succeeded him.
Issue.
Philip married his double-second cousin Maria Luisa of Savoy (17 September 1688 – 14 February 1714) on 3 November 1701 and they had 4 sons:
He married Elisabeth Farnese (25 October 1692 – 11 July 1766) on 24 December 1714, they had 6 children:
Legacy.
Historians have not been kind to the king. Lynch says Philip V advanced the government only marginally over that of his predecessors and was more of a liability than the incapacitated Charles II. When a conflict came up between the interests of Spain and France, he usually favored France. However Philip did make some reforms in government, and strengthened the central authorities relative to the provinces. Merit became more important, although most senior positions still went to the landed aristocracy. Below the elite level, the inefficiency and corruption that had existed under Charles II was as widespread as ever. The reforms started by Philip V culminated in much more important reforms of Charles III. The economy, on the whole, improved over the previous half-century, with greater productivity, and fewer famines and epidemics.
To commemorate the indignities the city of Xàtiva suffered after Philip's victory in the Battle of Almansa in the War of the Spanish Succession, in which he ordered the city to be burned and renamed "San Felipe", the portrait of the monarch hangs upside down in the local museum of L'Almodí.
All legitimate agnatic descendants of Louis XIV alive today are descended from Philip V.

</doc>
<doc id="63860" url="https://en.wikipedia.org/wiki?curid=63860" title="Picture archiving and communication system">
Picture archiving and communication system

A picture archiving and communication system (PACS) is a medical imaging technology which provides economical storage and convenient access to images from multiple modalities (source machine types). Electronic images and reports are transmitted digitally via PACS; this eliminates the need to manually file, retrieve, or transport film jackets. The universal format for PACS image storage and transfer is DICOM (Digital Imaging and Communications in Medicine). Non-image data, such as scanned documents, may be incorporated using consumer industry standard formats like PDF (Portable Document Format), once encapsulated in DICOM. A PACS consists of four major components: The imaging modalities such as X-ray plain film (PF), computed tomography (CT) and magnetic resonance imaging (MRI), a secured network for the transmission of patient information, workstations for interpreting and reviewing images, and archives for the storage and retrieval of images and reports. Combined with available and emerging web technology, PACS has the ability to deliver timely and efficient access to images, interpretations, and related data. PACS breaks down the physical and time barriers associated with traditional film-based image retrieval, distribution, and display.
Types of images.
Most PACSs handle images from various medical imaging instruments, including ultrasound (US), magnetic resonance (MR), Nuclear Medicine imaging, positron emission tomography (PET), computed tomography (CT), endoscopy (ES), mammograms (MG), digital radiography (DR), computed radiography (CR), Histopathology, ophthalmology, etc. Additional types of image formats are always being added. Clinical areas beyond radiology; cardiology, oncology, gastroenterology, and even the laboratory are creating medical images that can be incorporated into PACS. (see DICOM Application areas).
Uses.
PACS has four main uses:
PACS is offered by virtually all the major medical imaging equipment manufacturers, medical IT companies and many independent software companies. Basic PACS software can be found free on the Internet.
Architecture.
The architecture is the physical implementation of required functionality, or what one sees from the outside. There are different views, depending on the user. A radiologist typically sees a viewing station, a technologist a QA workstation, while a PACS administrator might spend most of their time in the climate-controlled computer room. The composite view is rather different for the various vendors.
Typically a PACS consists of a multitude of devices. The first step in typical PACS systems is the modality. Modalities are typically computed tomography (CT), ultrasound, nuclear medicine, positron emission tomography (PET), and magnetic resonance imaging (MRI). Depending on the facility's workflow most modalities send to a quality assurance (QA) workstation or sometimes called a PACS gateway. The QA workstation is a checkpoint to make sure patient demographics are correct as well as other important attributes of a study. If the study information is correct the images are passed to the archive for storage. The central storage device (archive) stores images and in some cases reports, measurements and other information that resides with the images. The next step in the PACS workflow is the reading workstations. The reading workstation is where the radiologist reviews the patient's study and formulates their diagnosis. Normally tied to the reading workstation is a reporting package that assists the radiologist with dictating the final report. Reporting software is optional and there are various ways in which doctors prefer to dictate their report. Ancillary to the workflow mentioned, there is normally CD/DVD authoring software used to burn patient studies for distribution to patients or referring physicians. The diagram above shows a typical workflow in most imaging centers and hospitals. Note that this section does not cover integration to a Radiology Information System, Hospital Information System and other such front-end system that relates to the PACS workflow.
More and more PACS include web-based interfaces to utilize the internet or a Wide Area Network as their means of communication, usually via VPN (Virtual Private Network) or SSL (Secure Sockets Layer). The clients side software may use ActiveX, JavaScript and/or a Java Applet. More robust PACS clients are full applications which can utilize the full resources of the computer they are executing on and are unaffected by the frequent unattended Web Browser and Java updates. As the need for distribution of images and reports becomes more widespread there is a push for PACS systems to support DICOM part 18 of the DICOM standard. Web Access to DICOM Objects (WADO) creates the necessary standard to expose images and reports over the web through truly portable medium. Without stepping outside the focus of the PACS architecture, WADO becomes the solution to cross platform capability and can increase the distribution of images and reports to referring physicians and patients.
PACS image backup is a critical, but sometimes overlooked, part of the PACS Architecture (see below). HIPAA requires that backup copies of patient images be made in case of image loss from the PACS. There are several methods of backing up the images, but they typically involve automatically sending copies of the images to a separate computer for storage, preferably off-site.
Querying (C-FIND) and Image (Instance) Retrieval (C-MOVE and C-GET).
The communication with the PACS server is done through DICOM messages that are similar to DICOM image "headers", but with different attributes. A query (C-FIND) is performed as follows:
Images (and other composite instances like Presentation States and Structured Reports) are then retrieved from a PACS server through either a C-MOVE or C-GET request, using the DICOM network protocol. Retrieval can be performed at the Study, Series or Image (instance) level. The C-MOVE request specifies where the retrieved instances should be sent (using separate C-STORE messages on one or more separate connections) with an identifier known as the destination Application Entity Title (AE Title). For a C-MOVE to work, the server must be configured with mapping of the AE Title to a TCP/IP address and port, and as a consequence the server must know in advance all the AE Titles that it will ever be requested to send images to. A C-GET, on the other hand, performs the C-STORE operations on the same connection as the request, and hence does not require that the "server" know the "client" TCP/IP address and port, and hence also works more easily through firewalls and with network address translation, environments in which the incoming TCP C-STORE connections required for C-MOVE may not get through. The difference between C-MOVE and C-GET is somewhat analogous to the difference between active and passive FTP. C-MOVE is most commonly used within enterprises and facilities, whereas C-GET is more practical between enterprises.
In addition to the traditional DICOM network services, particularly for cross-enterprise use, DICOM (and IHE) define other retrieval mechanisms, including WADO, WADO-WS and most recently WADO-RS.
Image archival and backup.
Digital medical images are typically stored locally on a PACS for retrieval. It is important (and required in the USA by the Security Rule's Administrative Safeguards section of HIPAA) that facilities have a means of recovering images in the event of an error or disaster.
While each facility is different, the goal in image back-up is to make it automatic and as easy to administer as possible. The hope is that the copies won't ever be needed, but, as with other disaster recovery and business continuity planning, they need to be available if needed.
Ideally, copies of images should be streamed off-site as they are created. (If using the Internet, the Security Rule's Technical Safeguards section of HIPAA requires that the images be encrypted during transmission.) Depending on upload bandwidth and image volume, this may not be practical if the back-up system cannot be configured to tune bandwidth usage and frequency of back-ups. Other options include removable media (hard drives, DVDs or other media that can hold many patients' images) that is physically transferred off-site. The content of these copies must be protected via encryption from exposure to unauthorized personnel or stiff penalties can be assessed.
Images may be stored both locally and remotely on off-line media such as tape or optical media, or partially or exclusively on hard disks ("spinning") media. The latter is becoming more common. The hard drives may be configured and attached to the PACS server in various ways, either as Direct-Attached Storage (DAS), Network-attached storage (NAS), or via a Storage Area Network (SAN).
However the storage is attached, the drives themselves are usually configured as a Redundant Array of Inexpensive (or Independent) Discs RAID, which may be configured to provide appropriate combination of faster disk access or protection against the failure of one (or even two) discs in the physical RAID array. Typically, failed drives may be physically replaced (hot swapping) without interruption of service. Since costs of computers has fallen, some sites opt for fully redundant Archives, rather than just protecting the drives through RAID. Further, RAIDs are fragile and can be rendered useless by one erroneous hit on the controller.
Data stored on disk may also be backed up to tape or optical media or copied, in real time, to a slower, inexpensive disc in another machine at another location. Some sites make two such backups and remove them from the site on a rotating basis.
In the event that it is necessary to reconstruct a PACS partially or completely from the back-up images, some means of rapidly transferring all of its images back to the PACS is required, preferably whilst the PACS continues to receive and provide current images.
The back-up infrastructure may also be capable of supporting the migration of images to a new PACS. Due to the high volume of images that need
to be archived many rad centers are migrating their systems to a Cloud-based PACS.
Integration.
A full PACS should provide a single point of access for images and their associated data. That is, it should support all digital modalities, in all departments, throughout the enterprise.
However, until PACS penetration is complete, individual islands of digital imaging not yet connected to a central PACS may exist. These may take the form of a localized, modality-specific network of modalities, workstations and storage (a so-called "mini-PACS"), or may consist of a small cluster of modalities directly connected to reading workstations without long term storage or management. Such systems are also often not connected to the departmental information system. Historically, Ultrasound, Nuclear Medicine and Cardiology Cath Labs are often departments that adopt such an approach.
More recently, Full Field digital mammography (FFDM) has taken a similar approach, largely because of the large image size, highly specialized reading workflow and display requirements, and intervention by regulators. The rapid deployment of FFDM in the US following the DMIST study has led to the integration of Digital Mammography and PACS becoming more commonplace.
All PACS, whether they span the entire enterprise or are localized within a department, should also interface with existing hospital information systems: Hospital information system (HIS) and Radiology Information System (RIS).
There are several data flowing into PACS as inputs for next procedures and back to HIS as results corresponding inputs:
In: Patient Identification and Orders for examination. These data are sent from HIS to RIS via integration interface, in most of hospital, via HL7 protocol. Patient ID and Orders will be sent to Modality (CT,MR,etc) via DICOM protocol (Worklist). Images will be created after images scanning and then forwarded to PACS Server. Diagnosis Report is created based on the images retrieved for presenting from PACS Server by physician/radiologist and then saved to RIS System.<br>
Out: Diagnosis Report and Images created accordingly. Diagnosis Report is sent back to HIS via HL7 usually and Images are sent back to HIS via DICOM usually if there is a DICOM Viewer integrated with HIS in hospitals (In most of cases, Clinical Physician gets reminder of Diagnosis Report coming and then queries images from PACS Server).
Interfacing between multiple systems provides a more consistent and more reliable dataset:
An interface can also improve workflow patterns:
Recognition of the importance of integration has led a number of suppliers to develop fully integrated RIS/PACS. These may offer a number of advanced features:
Acceptance testing.
The PACS installation process is complicated requiring time, resources, planning, and testing. Installation is not complete until the acceptance test is passed. Acceptance testing of a new installation is a vital step to assure user compliance, functionality, and especially clinical safety. Take for example the Therac-25, a radiation medical device involved in accidents in which patients were given massive overdoses of radiation, due to unverified software control.
The acceptance test determines whether the PACS is ready for clinical use and marks the warranty timeline while serving as a payment milestone. The test process varies in time requirements depending on facility size but contract condition of 30-day time limit is not unusual. It requires detailed planning and development of testing criteria prior to writing the contract. It is a joint process requiring defined test protocols and benchmarks.
Testing uncovers deficiencies. A study determined that the most frequently cited deficiencies were the most costly components. Failures ranked from most-to-least common are: Workstation; HIS/RIS/ACS broker interfaces; RIS; Computer Monitors; Web-based image distribution system; Modality interfaces; Archive devices; Maintenance; Training; Network; DICOM; Teleradiology; Security; Film digitizer.
History.
The principles of PACS were first discussed at meetings of radiologists in 1982. Various people are credited with the coinage of the term "PACS". Cardiovascular radiologist Dr Andre Duerinckx reported in 1983 that he had first used the term in 1981. Dr Samuel Dwyer, though, credits Dr Judith M. Prewitt for introducing the term.
Dr Harold Glass, a medical physicist working in London in the early 1990s secured UK Government funding and managed the project over many years which transformed Hammersmith Hospital in London as the first filmless hospital in the United Kingdom. Dr Glass died a few months after the project came live but is credited with being one of the pioneers of PACS.
The first large-scale PACS installation was in 1982 at the University of Kansas, Kansas City. This first installation became more of a teaching experience of what not to do rather than what to do in a PACS installation.
Regulatory concerns.
In the US PACS are classified as Medical Devices, and hence if for sale are regulated by the USFDA. In general they are subject to Class 2 controls and hence require a 510(k), though individual PACS components may be subject to less stringent general controls. Some specific applications, such as the use for primary mammography interpretation, are additionally regulated within the scope of the Mammography Quality Standards Act.
The Society for Imaging Informatics in Medicine (SIIM) is the worldwide professional and trade organization that provides an annual meeting and a peer-reviewed journal to promote research and education about PACS and related digital topics.

</doc>
<doc id="63861" url="https://en.wikipedia.org/wiki?curid=63861" title="Valencia">
Valencia

Valencia (; ), officially València (), is the capital of the autonomous community of Valencia and the third largest city in Spain after Madrid and Barcelona, with around 800,000 inhabitants in the administrative centre. Its urban area extends beyond the administrative city limits with a population of around 1.5 million people. Valencia is Spain's third largest metropolitan area, with a population ranging from 1.7 to 2.5 million. The Port of Valencia is the 5th busiest container port in Europe and the busiest container port on the Mediterranean Sea. The city is ranked at Gamma in the Globalization and World Cities Research Network.
Valencia was founded as a Roman colony in 138 BC. The city is situated on the banks of the Turia, on the east coast of the Iberian Peninsula, fronting the Gulf of Valencia on the Mediterranean Sea. Its historic centre is one of the largest in Spain, with approximately 169 hectares; this heritage of ancient monuments, views and cultural attractions makes Valencia one of the country's most popular tourist destinations. 
Valencia is integrated into an industrial area on the "Costa del Azahar" (Orange Blossom Coast). Valencia's main festival is the "Falles". The traditional Spanish dish, "paella", originated in Valencia.
Name.
The original Latin name of the city was Valentia (Latin pronunciation: ), meaning "strength", or "valour", the city being named according to the Roman practice of recognising the valour of former Roman soldiers after a war. The Roman historian Livy explains that the founding of Valentia in the 2nd century BC was due to the settling of the Roman soldiers who fought against an Iberian rebel, Viriatus.
During the rule of the Muslim kingdoms in Spain, it had the nickname "Medina bu-Tarab" ('City of Joy') according to a transliteration, or "Medina at-Turab" (, 'City of Sands') according to another, since it was located on the banks of the River Turia. It is not clear if the term "Balansiyya" () was reserved for the entire Taifa of Valencia or also designated the city.
By gradual sound changes, "Valentia" has become "Valencia" (i.e. before a pausa or nasal sound) or (after a continuant) in Castilian and "València" in Valencian. In Valencian, the grave accent <è> contrasts with the acute accent <é> —but the word "València" is an exception to this rule. It is spelled according to Catalan etymology, though its pronunciation is closer to Vulgar Latin.
Geography.
Location.
Valencia stands on the banks of the Turia River, located on the eastern coast of the Iberian Peninsula and the western part of the Mediterranean Sea, fronting the Gulf of Valencia. At its founding by the Romans, it stood on a river island in the Turia, from the sea. The Albufera, a freshwater lagoon and estuary about south of the city, is one of the largest lakes in Spain. The City Council bought the lake from the Crown of Spain for 1,072,980 pesetas in 1911, and today it forms the main portion of the "Parc Natural de l'Albufera" (Albufera Nature Reserve), with a surface area of . In 1986, because of its cultural, historical, and ecological value, the "Generalitat Valenciana" declared it a natural park.
Climate.
Valencia has a relatively dry subtropical Mediterranean climate (Köppen climate classification "Csa") with very mild winters and long warm to hot summers.
Its average annual temperature is . during the day and at night. 
In the coldest month – January, the maximum temperature typically during the day ranges from , the minimum temperature typically at night ranges from . In the warmest month – August, the maximum temperature during the day typically ranges from , about at night. Generally, temperatures similar to those experienced in the northern part of Europe in summer last about 8 months, from April to November. March is transitional, the temperature often exceeds , with an average temperature of during the day and at night. December, January and February are the coldest months, with average temperatures around during the day and at night. Valencia has one of the mildest winters in Europe, owing to its southern location on the Mediterranean Sea and the Foehn phenomenon. The January average is comparable to temperatures expected for May and September in the major cities of northern Europe.
Sunshine duration hours are 2,696 per year, from 155 (average nearly 5 hours of sunshine duration at day) in December to 315 (average above 10 hours of sunshine duration at day) in July. The average temperature of the sea is during winters and during summers. Average relative humidity is 60% in April to 68% in August.
Economy.
Valencia enjoyed strong economic growth over the last decade, much of it spurred by tourism and the construction industry, with concurrent development and expansion of telecommunications and transport. The city's economy is service-oriented, as nearly 84% of the working population is employed in service sector occupations. However, the city still maintains an important industrial base, with 5.5% of the population employed in this sector. Agricultural activities are still carried on in the municipality, even though of relatively minor importance with only 1.9% of the working population and 3973 hectares planted mostly in orchards and citrus groves.
Since the onset of the crisis (2008), Valencia has been among the Spanish regions most affected by it and has not been able to slow down a growing unemployment rate, growing government debt, etc. Severe spending cuts have been introduced by the city authorities.
In 2009, Valencia was the 29th fastest improving European city. Its influence in commerce, education, entertainment, media, fashion, science and the arts contributes to its status as one of the world's "Gamma"-rank global cities.
The large factory of Ford Motor Company lies in a suburb of the city, Almussafes.
The Valencia metropolitan area had a GDP amounting to $52.7 billion, and $28,141 per capita.
Port.
Valencia's port is the biggest on the Mediterranean western coast, the first of Spain in container traffic and the second of Spain in total traffic, handling 20% of Spain's exports. The main exports are foodstuffs and beverages. Other exports include oranges, furniture, ceramic tiles, fans, textiles and iron products. Valencia's manufacturing sector focuses on metallurgy, chemicals, textiles, shipbuilding and brewing. Small and medium-sized industries are an important part of the local economy, and before the current crisis unemployment was lower than the Spanish average.
Valencia's port underwent radical changes to accommodate the 32nd America's Cup in 2007. It was divided into two parts—one was unchanged while the other section was modified for the America's Cup festivities. The two sections remain divided by a wall that projects far into the water to maintain clean water for the America's Cup side.
Transport.
Public transport is provided by the "Ferrocarrils de la Generalitat Valenciana" (FGV), which operates the Metrovalencia and other rail and bus services. The "Estació del Nord" (North Station) is the main railway terminus in Valencia. A new temporary station, "Estación de València-Joaquín Sorolla", has been built on land adjacent to this terminus to accommodate high speed AVE trains to and from Madrid, Barcelona, Seville and Alicante. Valencia Airport is situated west of Valencia city centre. Alicante Airport is situated about south of Valencia.
The City of Valencia also makes available a bicycle sharing system named Valenbisi to both visitors and residents. As of 13 October 2012, the system has 2750 bikes distributed over 250 stations all throughout the city.
Valencia also has a Metro and Tram system.
Tourism.
Starting in the mid-1990s, Valencia, formerly an industrial centre, saw rapid development that expanded its cultural and touristic possibilities, and transformed it into a newly vibrant city. Many local landmarks were restored, including the ancient Towers of the medieval city ("Serrano" Towers and "Quart" Towers), and the San Miguel de los Reyes monastery (:es:Monasterio de San Miguel de los Reyes), which now holds a conservation library. Whole sections of the old city, for example the Carmen Quarter, have been extensively renovated. The "Paseo Marítimo", a  long palm tree-lined promenade was constructed along the beaches of the north side of the port "(Playa Las Arenas, Playa Cabañal and Playa de la Malvarrosa").
The city has numerous convention centres and venues for trade events, among them the Feria Valencia Convention and Exhibition Centre "(Institución Ferial de Valencia)" and the "Palau de congres" (Conference Palace), and several 5-star hotels to accommodate business travelers.
In its long history, Valencia has acquired many local traditions and festivals, among them the "Falles", which were declared Celebrations of International Touristic Interest "(Fiestas de Interés Turístico Internacional)" on 25 January 1965, and the Water Tribunal of Valencia "(Tribunal de las Aguas de Valencia)", which was declared an intangible cultural heritage of humanity "(Patrimonio Cultural Inmaterial de la Humanidad") in 2009. In addition to these Valencia has hosted world-class events that helped shape the city's reputation and put it in the international spotlight, e.g., the Regional Exhibition of 1909, the 32nd and the 33rd America's Cup competitions, the European Grand Prix of Formula One auto racing, the Valencia Open 500 tennis tournament, and the Global Champions Tour of equestrian sports.
The 2007 America's Cup yachting races were held at Valencia in June and July 2007 and attracted huge crowds. According to official data from the organising committee, as many as 150,000 visitors flocked to Valencia's port each day during the two weeks of events. 
Demographics.
The third largest city in Spain and the 24th most populous municipality in the European Union, Valencia has a population of 809,267 within its administrative limits on a land area of . The urban area of Valencia extending beyond the administrative city limits has a population of between 1,561,000 and 1,564,145. 1,705,742 or 2,300,000 or 2,516,818 people live in the Valencia metropolitan area. Between 2007 and 2008 there was a 14% increase in the foreign born population with the largest numeric increases by country being from Bolivia, Romania and Italy.
One notable demographic change in Valencia in the last decade has been the growth in the foreign born population, which rose from 1.5% in the year 2000 to 9.1% in 2009, a trend that has also occurred in the two larger cities of Madrid and Barcelona. The main countries of origin were Ecuador, Bolivia, Colombia, Morocco and Romania.
Culture.
Valencia is known internationally for the Falles "(Las Fallas)", a local festival held in March, and for "paella valenciana", traditional Valencian ceramics, intricate traditional dress, and the architecture of the City of Arts and Sciences designed by Santiago Calatrava and Félix Candela.
La Tomatina, an annual tomato fight, draws crowds to the nearby town of Buñol in August. There are also a number of well-preserved traditional Catholic festivities throughout the year. Holy Week celebrations in Valencia are considered some of the most colourful in Spain. Valencia has a metro system, the Metrovalencia (Valencia Metro).
Valencia was once a venue for the Formula One European Grand Prix, first hosting the event on 24 August 2008. The city was axed at the beginning of the grand prix season 2013.
The University of Valencia (officially "Universitat de València Estudi General") was founded in 1499, being one of the oldest surviving universities in Spain, and the oldest university in the Valencian Community. It was listed as one of the four leading Spanish universities in the 2011 Shanghai Academic Ranking of World Universities.
In 2012, Berklee College of Music opened a new campus at the Palau de les Arts Reina Sofia providing focus on the music of the region through its Mediterranean Music Institute. Since 2003, Valencia also hosts the music courses of Musikeon, the leading musical institution in the Spanish-speaking world.
Languages.
Valencia is a bilingual city: Valencian and Spanish are the two official languages. Spanish is official in all of Spain, whereas Valencian is official in the Valencian Country, as well as in Catalonia and the Balearic Islands, where it receives the name of Catalan. Despite the differentiated denomination, the distinct dialectal traits and political tension between Catalonia and the Valencian Country, Catalan and Valencian are mutually intelligible and are considered two varieties of the same language.
Valencian has been historically repressed in favour of Spanish. The effects have been more noticeable in the city proper, whereas the language has remained active in the rural and metropolitan areas. After the Castille-Aragon unification, a Spanish-speaking elite established itself in the city. In more recent history, the establishment of Franco's military and administrative apparatus in Valencia further excluded Valencian from public life. Valencian recovered its official status, prestige and use in education after the transition to democracy in 1978. However, due to industrialisation in recent decades, Valencia has attracted immigration from other regions in Spain, and hence there is also a demographic factor for its declining social use. Due to a combination of these reasons, Valencia has become the bastion of anti-Catalan blaverism, which celebrates Valencian as merely folkloric, but rejects the existing standard which was adapted from Catalan orthography.
Spanish is currently the predominant language in the city proper but, thanks to the education system, most Valencians have basic knowledge of both Spanish and Valencian, and either can be used in the city. Valencia is therefore the second biggest Catalan-speaking city after Barcelona. Institutional buildings and streets are named in Valencian. The city is also home to many pro-Valencian political and civil organisations. Furthermore, education entirely in Valencian is offered in more than 70 state-owned schools in the city, as well as by the University of Valencia across all disciplines.
Food.
Valencia is famous for its gastronomic culture. Typical dishes include "paella", a simmered rice dish with seafood or meat (chicken and rabbit), "fartons", "bunyols", the Spanish omelette, "pinchos", "rosquilletas" and squid "(calamares)".
Valencia is also the birthplace of the cold "xufa" beverage known as "orxata", popular in many parts of the world including the Americas.
History.
Roman Valentia.
Valencia is one of the oldest cities in Spain, founded in the Roman period under the name (Valentia Edetanorum es) on the site of a former Iberian town, by the river Turia in the province of Edetania.
About two thousand Roman colonists were settled there in 138 BC during the rule of consul Decimus Junius Brutus Galaico. The Roman historian Florus says that Brutus transferred the soldiers who had fought under him to that province. This was a typical Roman city in its conception, as it was located in a strategic location near the sea on a river island crossed by the Via Augusta, the imperial road that connected the province to Rome, the capital of the empire. The centre of the city was located in the present-day neighbourhood of the Plaza de la Virgen. Here was the forum and the crossing of the Cardo Maximus and the Decumanus Maximus, which remain the two main axes of the city. The Cardo corresponds to the existing Calle de Salvador, Almoina, and the Decumanus corresponds to Calle de los Caballeros.
Pompey razed Valentia to the ground in 75 BC to punish it for its loyalty to Sertorius. It was rebuilt around fifty years later with large infrastructure projects, and by the mid-first century, experienced rapid urban growth. Pomponius Mela called it one of the principal cities of the Tarraconensis province. Valencia suffered a new period of decline in the third century, but an early Christian community arose there during the latter years of the Roman Empire, in the fourth century.
Middle Ages.
A few centuries later, coinciding with the first waves of the invading Germanic peoples (Suevi, Vandals and Alans, and later the Visigoths) and the power vacuum left by the demise of the Roman imperial administration, the church assumed the reins of power in the city and replaced the old Roman temples with religious buildings. With the Byzantine invasion of the southwestern Iberian peninsula in 554 the city acquired strategic importance. After the expulsion of the Byzantines in 625, Visigothic military contingents were posted there and the ancient Roman amphitheatre was fortified. Little is known of its history for nearly a hundred years; although this period is only scarcely documented by archeology, excavations suggest that there was little development of the city. During Visigothic times Valencia was an episcopal See of the Catholic Church, albeit a suffragan diocese subordinate to the archdiocese of Toledo, comprising the ancient Roman province of Carthaginensis in Hispania.
The city had surrendered without a fight to the invading Moors (Berbers and Arabs) by 714 AD, and the cathedral of Saint Vincent was turned into a mosque. Abd al-Rahman I, the first emir of Cordoba, ordered the city destroyed in 755 during his wars against other nobility, but several years later his son, Abdullah, had a form of autonomous rule over the province of Valencia. Among his administrative acts he ordered the building of a luxurious palace, the Russafa, on the outskirts of the city in the neighbourhood of the same name. So far no remains have been found. Also at this time Valencia received the name "Medina al-Turab" (City of Sand). When Islamic culture settled in, Valencia, then called "Balansiyya", prospered from the 10th century, due to a booming trade in paper, silk, leather, ceramics, glass and silver-work. The architectural legacy of this period is abundant in Valencia and can still be appreciated today in the remnants of the old walls, the "Baños del Almirante" bath house, Portal de Valldigna street and even the Cathedral and the tower, "El Micalet" "(El Miguelete)", which was the minaret of the old mosque.
After the death of Almanzor and the unrest that followed, Muslim Al-Andalus disintegrated into numerous small states known as taifas, one of which was the Taifa of Valencia, which existed for four distinct periods: 1010 – 1065, 1075 – 1099, 1145 – 1147, and 1229 – 1238.
Balansiyya had a rebirth of sorts with the beginning of the Taifa of Valencia kingdom in the 11th century. The town grew, and during the reign of Abd al-Aziz a new city wall was built, remains of which are preserved throughout the Old City "(Ciutat Vella)" today. The Castilian nobleman Rodrigo Diaz de Vivar, known as "El Cid", who was intent on possessing his own principality on the Mediterranean, entered the province in command of a combined Christian and Moorish army and besieged the city beginning in 1092. By the time the siege ended in May 1094, he had carved out his own fiefdom—which he ruled from 15 June 1094 to July 1099. This victory was immortalised in the "Lay of the Cid". During his rule, he converted nine mosques into churches and installed the French monk Jérôme as bishop of the See of Valencia. "El Cid" was killed in July 1099 while defending the city from an Almoravid siege, whereupon his wife Ximena Díaz ruled in his place for two years.
The city remained in the hands of Christian troops until 1102, when the Almoravids retook the city and restored the Muslim religion. Although the self-styled 'Emperor of All Spain', Alfonso VI of León and Castile, drove them from the city, he was not strong enough to hold it. The Christians set it afire before abandoning it, and the Almoravid Masdali took possession on 5 May 1109. The event was commemorated in a poem by Ibn Khafaja in which he thanked Yusuf ibn Tashfin for the city's liberation. The declining power of the Almoravids coincided with the rise of a new dynasty in North Africa, the Almohads, who seized control of the peninsula from the year 1145, although their entry into Valencia was deterred by Ibn Mardanis, King of Valencia and Murcia until 1171, at which time the city finally fell to the North Africans. The two Muslim dynasties would rule Valencia for more than a century.
In 1238, King James I of Aragon, with an army composed of Aragonese, Catalans, Navarrese and crusaders from the Order of Calatrava, laid siege to Valencia and on 28 September obtained a surrender. Fifty thousand Moors were forced to leave. Poets such as Ibn al-Abbar and Ibn Amira mourned this exile from their beloved Valencia. After the Christian victory and the expulsion of the Muslim population the city was divided between those who had participated in the conquest, according to the testimony in the " Llibre del Repartiment" (Book of Distribution). James I granted the city new charters of law, the Furs of Valencia, which later were extended to the whole kingdom of Valencia. Thenceforth the city entered a new historical stage in which a new society and a new language developed, forming the basis of the character of the Valencian people as they are known today.
On 9 October, King James, followed by his retinue and army, took possession of the city. The principal mosque was purified and the Mass was celebrated. James incorporated city and territory into the newly formed Kingdom of Valencia (continuum of the previous state), one of the kingdoms forming the Crown of Aragon, and permitted all people that lived in the city, Jews, Muslims and Christians, to stay there and live as citizens of the kingdom.
According to historical data on the capitulation of the city, the kingdom of Valencia had a population of 120,000 Muslims, 65,000 Christians and 2,000 Jews, who by the terms of the capitulation and its covenants were mostly allowed to remain on their land. According to the Arab historian Hussein Mones of the University of Cairo, these were the words King Zayyan spoke to James I when he surrendered the keys to the city:
The city went through serious troubles in the mid-fourteenth century. On the one hand were the decimation of the population by the Black Death of 1348 and subsequent years of epidemics — and on the other, the series of wars and riots that followed. Among these were the War of the Union, a citizen revolt against the excesses of the monarchy, led by Valencia as the capital of the kingdom — and the war with Castile, which forced the hurried raising of a new wall to resist Castilian attacks in 1363 and 1364. In these years the coexistence of the three communities that occupied the city—Christian, Jewish and Muslim — was quite contentious. The Jews who occupied the area around the waterfront had progressed economically and socially, and their quarter gradually expanded its boundaries at the expense of neighbouring parishes. Meanwhile, Muslims who remained in the city after the conquest were entrenched in a Moorish neighbourhood next to the present-day market Mosen Sorel. In 1391 an uncontrolled mob attacked the Jewish quarter, causing its virtual disappearance and leading to the forced conversion of its surviving members to Christianity. The Muslim quarter was attacked during a similar tumult among the populace in 1456, but the consequences were minor.
Golden Age of Valencia.
The 15th century was a time of Islamic economic expansion, known as the Valencian Golden Age, in which culture and the arts flourished. Concurrent population growth made Valencia the most populous city in the Crown of Aragon. Local industry, led by textile production, reached a great development, and a financial institution, the "Canvi de Taula", was created to support municipal banking operations; Valencian bankers lent funds to Queen Isabella I of Castile for Columbus's voyage in 1492. At the end of the century the Silk Exchange "(Llotja de la Seda)" building was erected as the city became a commercial emporium that attracted merchants from all over Europe.
This boom was reflected in the growth of artistic and cultural pursuits. Some of the most emblematic buildings of the city were built during this period, including the Serranos Towers (1392), the Lonja (1482), the Miguelete and the Chapel of the Kings of the Convent of Santo Domingo. In painting and sculpture, Flemish and Italian trends had an influence on artists such as Lluís Dalmau, Peris Gonçal and Damià Forment. Literature flourished with the patronage of the court of Alfonso the Magnanimous, supporting authors like Ausiàs March, Roiç de Corella, and Isabel de Villena. By 1460 Joanot Martorell wrote "Tirant lo Blanch", an innovative novel of chivalry that influenced many later writers, from Cervantes to Shakespeare. Ausiàs March was one of the first poets to use the everyday language Valencian, instead of the troubadour language, Occitan. Also around this time, between 1499 and 1502, the University of Valencia was founded under the parsimonious name of " Estudio General" ("studium generale", place of general studies).
Valencia was one of the most influential cities on the Mediterranean in the 15th and 16th centuries. The first printing press in the Iberian Peninsula was located in Valencia and Lambert Palmart and his associates began to print in 1473. This was due to the manager of the Valencian factory of the Great Trading Company of Ravensburg in Swabia. The second printed Bible in a Romance language, the Valencian Bible attributed to Bonifaci Ferrer, was printed in Valencia circa 1478.
Early Modern.
Following the discovery of the Americas, the European economy was oriented towards the Atlantic to the detriment of the Mediterranean trade. Despite the dynastic union of Aragon with Castile, the conquest and exploitation of America was the exclusive domain of Castile. The Valencians, like the Catalans, Aragonese and Majorcans, were prohibited participation in the cross-Atlantic commerce.
Faced with this loss of business, Valencia suffered a severe economic crisis. This manifested early in 1519–1523 when the artisan guilds known as the Germanies revolted against the government of the Habsburg king Charles I in Valencia, now part of the Crown of Aragon, with most of the fighting done in 1521. The revolt was an anti-monarchist, anti-feudal autonomist movement inspired by the Italian republics, and a social revolt against the nobility who had fled the city before an epidemic of plague in 1519. It also bore a strong anti-Islamic aspect, as rebels rioted against Aragon's population of mudéjars and imposed forced conversions to Christianity.
The vicereine Germaine of Foix brutally repressed the uprising and its leaders, and this accelerated the authoritarian centralisation of the government of Charles I. Queen Germaine favoured harsh treatment of the "agermanats". She is thought to have signed the death warrants of 100 former rebels personally, and sources indicate that as many as 800 executions may have occurred. The "agermanats" are comparable to the "comuneros" of neighbouring Castile, who fought a similar revolt against Charles from 1520–1522.
The crisis deepened during the 17th century with the expulsion in 1609 of the Jews and the Moriscos, descendants of the Muslim population that converted to Christianity under threat of exile from Ferdinand and Isabella in 1502. From 1609 through 1614, the Spanish government systematically forced Moriscos to leave the kingdom for Muslim North Africa. They were concentrated in the former Kingdom of Aragon, where they constituted a fifth of the population, and the Valencia area specifically, where they were roughly a third of the total population. The expulsion caused the financial ruin of some of the nobility and the bankruptcy of the Taula de Canvi in 1613. The Crown endeavoured to compensate the nobles, who had lost much of their agricultural labour force; this harmed the economy of the city for generations to come. Later, during the so-called Catalan Revolt (1640–1652), Valencia contributed to the cause of Philip IV with militias and money, resulting in a period of further economic hardship exacerbated by the arrival of troops from other parts of Spain.
The decline of the city reached its nadir with the War of Spanish Succession (1702–1709) that marked the end of the political and legal independence of the Kingdom of Valencia. During the War of the Spanish Succession, Valencia sided with Charles of Austria. On 24 January 1706, Charles Mordaunt, 3rd Earl of Peterborough, 1st Earl of Monmouth, led a handful of English cavalrymen into the city after riding south from Barcelona, capturing the nearby fortress at Sagunt, and bluffing the Spanish Bourbon army into withdrawal.
The English held the city for 16 months and defeated several attempts to expel them. English soldiers advanced as far as Requena on the road to Madrid. After the victory of the Bourbons at the Battle of Almansa on 25 April 1707, the English army evacuated Valencia and Philip V ordered the repeal of the privileges of Valencia as punishment for the kingdom's support of Charles of Austria. By the Nueva Planta decrees "(Decretos de Nueva Planta)" the ancient Charters of Valencia were abolished and the city was governed by the Castilian Charter. The Bourbon forces burned important cities like Xativa, where pictures of the Spanish Bourbons in public places are hung upside down as a protest to this day. The capital of the Kingdom of Valencia was moved to Orihuela, an outrage to the citizens of Valencia. Philip ordered the Cortes to meet with the Viceroy of Valencia, Cardinal Luis de Belluga, who opposed the change of capital because of the proximity of Orihuela, a religious, cultural and now political centre, to Murcia (capital of another viceroyalty and his diocese). Because of his hatred of the city of Orihuela, which had bombarded and looted Valencia during the War of Succession, the cardinal resigned the viceroyalty in protest against the actions of Philip, who finally relented and returned the capital to Valencia.
With the abolition of the charters of Valencia and most of its institutions, and the conformation of the kingdom and its capital to the laws and customs of Castile, top civil officials were no longer elected, but instead were appointed directly from Madrid, the king's court city, the offices often filled by foreign aristocrats. Valencia had to become accustomed to being an occupied city, living with the presence of troops quartered in the Citadel near the convent of Santo Domingo and in other buildings such as the Lonja, which served as a barracks until 1762.
The Valencian economy recovered during the 18th century with the rising manufacture of woven silk and ceramic tiles. The Palau de Justícia is an example of the affluence manifested in the most prosperous times of Bourbon rule (1758–1802) during the rule of Charles III. The 18th century was the age of the Enlightenment in Europe, and its humanistic ideals influenced such men as Gregory Maians and Perez Bayer in Valencia, who maintained correspondence with the leading French and German thinkers of the time. In this atmosphere of the exaltation of ideas the Economic Society of Friends of the Country "(Societat Econòmica d'Amics del País") was founded in 1776; it introduced numerous improvements in agriculture and industry and promoted various cultural, civic, and economic institutions in Valencia.
Late modern and contemporary.
The 19th century began with Spain embroiled in wars with France, Portugal, and England—but the War of Independence most affected the Valencian territories and the capital city. The repercussions of the French Revolution were still felt when Napoleon's armies invaded the Iberian Peninsula. The Valencian people rose in arms against them on 23 May 1808, aroused by such characters as Vicent Doménech el Palleter.
The mutineers seized the Citadel, a Supreme Junta government took over, and on 26–28 June, Napoleon's Marshal Moncey attacked the city with a column of 9,000 French imperial troops in the First Battle of Valencia. He failed to take the city in two assaults and retreated to Madrid. Marshal Suchet began a long siege of the city in October 1811, and after intense bombardment forced it to surrender on 8 January 1812. After the capitulation, the French instituted reforms in Valencia, which became the capital of Spain when the Bonapartist pretender to the throne, José I (Joseph Bonaparte, Napoleon's elder brother), moved the Court there in the summer of 1812. The disaster of the Battle of Vitoria on 21 June 1813 obliged Suchet to quit Valencia, and the French troops withdrew in July.
During the Napoleonic invasion, the Valencians had sent representatives to the Cortes of Cádiz, where a liberal, anti-seigneurial national constitution was drafted. Ferdinand VII became king after the victorious end of the Peninsular War, which freed Spain from Napoleonic domination. When he returned on 24 March 1814 from exile in France, the Cortes requested that he respect the liberal Constitution of 1812, which seriously limited royal powers.
Ferdinand refused and went to Valencia instead of Madrid. Here, on 17 April, General Elio invited the King to reclaim his absolute rights and put his troops at the King's disposition. The king abolished the Constitution of 1812. He followed this act by dissolving the two chambers of the Spanish Parliament on 10 May. Thus began six years (1814–1820) of absolutist rule, but the constitution was reinstated during the Trienio Liberal, a period of three years of liberal government in Spain from 1820–1823.
A fervent follower of the absolutist cause, Elío had played an important role in the repression of the supporters of the Constitution of 1812. For this, he was arrested in 1820 and executed in 1822 by garroting. Conflict between absolutists and liberals continued, and in the period of conservative rule called the Ominous Decade (1823–1833), which followed the Trienio Liberal, there was ruthless repression by government forces and the Catholic Inquisition. The last victim of the Inquisition was Gaietà Ripoli, a teacher accused of being a deist and a Mason who was hanged in Valencia in 1824.
On the death of King Ferdinand VII in 1833, Baldomero Espartero became one of the most ardent defenders of the hereditary rights of his daughter, Isabella II. On the outbreak of the First Carlist War, the government sent him to the front, where he severely defeated the Carlists in many encounters. He was associated with the radical, or progressive, wing of Spanish liberalism and became its symbol and champion after taking credit for the victory over the Carlists in 1839.
During the regency of Maria Cristina, Espartero ruled Spain for two years as its 18th Prime Minister from 16 September 1840 to 21 May 1841. Under his progressive government the old regime was tenuously reconciled to his liberal policies. During this period of upheaval in the provinces he declared that all the estates of the Church, its congregations, and its religious orders were national property—though in Valencia, most of this property was subsequently acquired by the local bourgeoisie. City life in Valencia carried on in a revolutionary climate, with frequent clashes between liberals and republicans, and the constant threat of reprisals by the Carlist troops of General Cabrera.
The reign of Isabella II as an adult (1843–1868) was a period of relative stability and growth for Valencia. Services and infrastructure—including municipal water supply, paved roads, and gas distribution—were substantially improved, and a large-scale construction project was initiated at the port. Gas lighting was introduced in 1840, and soon after a public works project began to pave the streets with cobblestones, a task that took several years because of the lack of council funds.
The public water supply network was completed in 1850, and in 1858 the architects Sebastián Monleón Estellés, Antonino Sancho, and Timoteo Calvo drafted a general expansion project for the city that included demolishing its ancient walls (a second version was printed in 1868). Neither proposed project received final approval, but they did serve as a guide, though not closely followed, for future growth. By 1860 the municipality had 140,416 inhabitants, and beginning in 1866 the ancient city walls were almost entirely demolished to facilitate urban expansion. Electricity was introduced to Valencia in 1882.
During the Cantonal Revolution of 1873, a cantonalist uprising that took place during the First Spanish Republic, the city was consolidated with most of the nearby cities in the Federal Canton of Valencia (proclaimed on 19 July and dissolved on 7 August). It did not have the revolutionary fervor of the movement in cities like Alcoy, as it was initiated by the bourgeoisie, but the Madrid government sent General Martinez-Campos to stifle the rebellion by force of arms and subjected Valencia to an intense bombardment. The city surrendered on 7 August; Alfonso XII was proclaimed king on 29 December 1874, and arrived in Valencia on 11 January 1875 on his way to Madrid, marking the end of the first republic. Despite the Bourbon restoration, the roughly even balance between conservatives and liberals in the government was sustained in Valencia until the granting of universal male suffrage in 1890, after which the Republicans, led by Vicente Blasco Ibáñez, gained considerably more of the popular vote.
During the second half of the 19th century the bourgeoisie encouraged the development of the city and its environs; land-owners were enriched by the introduction of the orange crop and the expansion of vineyards and other crops. This economic boom corresponded with a revival of local traditions and of the Valencian language, which had been ruthlessly suppressed from the time of Philip V. Around 1870, the Valencian Renaissance, a movement committed to the revival of the Valencian language and traditions, began to gain ascendancy. In its early stages the movement inclined to the romanticism of the poet Teodor Llorente, and resisted the more assertive remonstrances of Constantine Llombart, founder of the still extant cultural society, "Lo Rat Penat", which is dedicated to the promotion and dissemination of the Valencian language and culture.
In 1894 the "Círculo de Bellas Artes de Valencia" (Circle of Fine Arts in Valencia) was founded.
During the 20th century Valencia remained the third most populous city of Spain as its population tripled, rising from 213,550 inhabitants in 1900 to 739,014 in 2000. Valencia was also third in industrial and economic development; notable milestones include urban expansion of the city in the latter 1800s, the creation of the Banco de Valencia in 1900, construction of the Central and Columbus markets, and the construction of the Gare du Nord railway station, completed in 1921. The new century was marked in Valencia with a major event, the Valencian regional exhibition of 1909 "(La Exposición Regional Valenciana de 1909"), which emulated the national and universal expositions held in other cities. This production was promoted by the "Ateneo Mercantil de Valencia" (Mercantile Athenaeum of Valencia), especially by its chairman, Tomás Trénor y Palavicino, and had the support of the Government and the Crown; it was officially inaugurated by King Alfonso XIII himself.
In the early 20th century Valencia was an industrialised city. The silk industry had disappeared, but there was a large production of hides and skins, wood, metals and foodstuffs, this last with substantial exports, particularly of wine and citrus. Small businesses predominated, but with the rapid mechanisation of industry larger companies were being formed. The best expression of this dynamic was in the regional exhibitions, including that of 1909 held next to the pedestrian avenue "L'Albereda" ("Paseo de la Alameda"), which depicted the progress of agriculture and industry. Among the most architecturally successful buildings of the era were those designed in the Art Nouveau style, such as the North Station "(Gare du Nord)" and the Central and Columbus markets.
Industrial workers began to organise in increasing numbers to demand better living conditions. The Republican party of Blasco Ibáñez responded to these demands and gained enormous popular support, dominating the ruling council between 1901 and 1923.
World War I (1914–1918) greatly affected the Valencian economy, causing the collapse of its citrus exports. The establishment of the dictatorship of Primo de Rivera in 1923 tempered social unrest for some years, but not the growing political radicalisation of the working classes. The labor movement gradually consolidated its union organisation, while the conservative factions rallied around the Valencian Regional Right.
The Republic (1931–1939) opened the way for democratic participation and the increased politicisation of citizens, especially in response to the rise of Conservative Front power in 1933. This climate marked the elections of 1936, won by the Popular Front political coalition, which promoted the fervor of the masses. The military uprising of 18 July failed to triumph in Valencia. For some months there was a revolutionary atmosphere, gradually neutralised by the government.
The inevitable march to civil war and the combat in Madrid resulted in the removal of the capital of the Republic to Valencia. On 6 November 1936 the city became the capital of Republican Spain under the control of the prime minister Manuel Azana; the government moved to the Palau de Benicarló, its ministries occupying various other buildings. The city was heavily bombarded by air and sea, necessitating the construction of over two hundred bomb shelters to protect the population. On 13 January 1937 the city was first shelled by a vessel of the Fascist Italian Navy, which was blockading the port by the order of Benito Mussolini. The bombardment intensified and inflicted massive destruction on several occasions; by the end of the war the city had survived 442 bombardments, leaving 2,831 dead and 847 wounded, although it is estimated that the death toll was higher, as the data given are those recognised by Francisco Franco's government. The Republican government passed to Juan Negrín on 17 May 1937 and on 31 October of that year moved to Barcelona. On 30 March 1939 Valencia surrendered and the Nationalist troops entered the city. The postwar years were a time of hardship for Valencians. During Franco's regime speaking or teaching Valencian was prohibited; in a significant reversal it is now compulsory for every schoolchild in Valencia.
The dictatorship of Franco forbade political parties and began a harsh ideological and cultural repression countenanced and sometimes even led by the Church. The financial markets were destabilised, causing a severe economic crisis that led to rationing. A black market in rationed goods existed for over a decade. The Francoist administrations of Valencia silenced publicity of the catastrophic consequences of the floods of 1949 with the attendant dozens of deaths, but could not do the same after the even more tragic flood of 1957 when the river Turia overflowed its banks again, killing many Valencians (officially, eighty-one died; the actual figure is not known). To prevent further disasters, the river was eventually diverted to a new course. The old river bed was abandoned for years, and successive Francoist mayors proposed making it a motorway, but that option was finally rejected with the advent of democracy and fervent neighbourhood protests. The river was divided in two at the western city limits "(Plan Sur de Valencia"), and diverted southwards along a new course that skirts the city, before meeting the Mediterranean. The old course of the river continues, dry, through the city centre, almost to the sea. The old riverbed is now a verdant sunken park called the 'Garden of the Turia' "(Jardí del Túria or Jardín del Turia)" that allows cyclists and pedestrians to traverse much of the city without the use of roads; overhead bridges carry motor traffic across the park.
The economy began to recover in the early 1960s, and the city experienced explosive population growth through immigration spurred by the jobs created with the implementation of major urban projects and infrastructure improvements. With the advent of democracy in Spain, the ancient kingdom of Valencia was established as a new autonomous entity, the Valencian Community, the Statute of Autonomy of 1982 designating Valencia as its capital. On the night of 23 February 1981, shortly after Antonio Tejero had stormed Congress, the Captain General of the Third Military Region, Jaime Milans del Bosch, rose up in Valencia, put tanks on the streets, declared a state of emergency and tried to convince other senior military figures to support the coup. After the televised message of King Juan Carlos I, those in the military who had not yet aligned themselves decided to remain loyal to the government, and the coup failed. Despite this lack of support, Milans del Bosch only surrendered at 5 a.m. on the next day, 24 February.
Valencia has experienced a surge in its cultural development during the last thirty years, exemplified by exhibitions and performances at such iconic institutions as the "Palau de la Música", the "Palacio de Congresos", the Metro, the City of Arts and Sciences "(Ciutat de les Arts i les Ciències)", the Valencian Museum of Enlightenment and Modernity "(Museo Valenciano de la Ilustracion y la Modernidad)", and the Institute of Modern Art "(Instituto Valenciano de Arte Moderno)". The various productions of Santiago Calatrava, a renowned structural engineer, architect, and sculptor and of the architect Félix Candela have contributed to Valencia's international reputation. These public works and the ongoing rehabilitation of the Old City "(Ciutat Vella)" have helped improve the city's livability and tourism is continually increasing.
The Valencia Metro derailment occurred on 3 July 2006 at 1 pm. CEST (1100 UTC) between Jesús and Plaça d'Espanya stations on Line 1 of the Metrovalencia mass transit system. 43 people were killed and more than ten were seriously injured. It was not immediately clear what caused the crash. Both the Valencian government spokesman Vicente Rambla and Mayor Rita Barberá called the accident a "fortuitous" event. However, the trade union CC.OO. accused the authorities of "rushing" to say anything but admit that Line 1 is in a state of "constant deterioration" with a "failure to carry out maintenance".
In March 2012, the newspaper "El Mundo" published a story according to which FGV had instructed employees who were to testify at the crash commission investigation, providing a set of possible questions and guidelines to prepare the answers. In April 2013, the television program Salvados questioned the official version of the incident as there were indications that the Valencian Government had tried to downplay the accident, which coincided with the visit of the pope to Valencia, or even to hide evidence, as the book of train breakdowns was never found. The day after the broadcast of this report, which received extensive media coverage, several voices called for the reopening of the investigation. The investigation was effectively reopened and the accident is currently under re-examination.
On 9 July 2006, during Mass at Valencia's Cathedral, Our Lady of the Forsaken Basilica, Pope Benedict XVI used, at the World Day of Families, the "Santo Caliz", a 1st-century Middle-Eastern artifact that some Catholics believe is the Holy Grail. It was supposedly brought to that church by Emperor Valerian in the 3rd century, after having been brought by St. Peter to Rome from Jerusalem. The "Santo Caliz" (Holy Chalice) is a simple, small stone cup. Its base was added in Medieval Times and consists of fine gold, alabaster and gem stones.
Valencia was selected in 2003 to host the historic America's Cup yacht race, the first European city ever to do so. The America's Cup matches took place in summer 2007. On 3 July 2007, Alinghi defeated Team New Zealand and successfully defended the America's Cup. Twenty-two days later, on 25 July 2007, the leaders of the Alinghi syndicate, holder of the America's Cup, officially announced that Valencia would be the host city for the 33rd America's Cup, held in June 2009.
Since 1991 the City Council has been governed by the People's Party of Spain "(Partido Popular)" (PP) and Mayor Rita Barberá Nolla who became mayor by a pact made with the Valencian Union. She is a member of the National Council of the People's Party and a Representative in the Valencian regional Parliament "(Corts Valencianes)". She turned down an offer to become a national deputy at the 2008 Spanish General Election.
Main sights.
Major monuments include Valencia Cathedral, the "Torres de Serrans", the "Torres de Quart" (:es:Torres de Quart), the "Llotja de la Seda" (declared a World Heritage Site by UNESCO in 1996), and the "Ciutat de les Arts i les Ciències" (City of Arts and Sciences), an entertainment-based cultural and architectural complex designed by Santiago Calatrava and Félix Candela. The "Museu de Belles Arts de València" houses a large collection of paintings from the 14th to the 18th centuries, including works by Velázquez, El Greco, and Goya, as well as an important series of engravings by Piranesi. The "Institut Valencià d'Art Modern" (Valencian Institute of Modern Art) houses both permanent collections and temporary exhibitions of contemporary art and photography.
Architecture.
The ancient winding streets of the Barrio del Carmen contain buildings dating to Roman and Arabic times. The Cathedral, built between the 13th and 15th centuries, is primarily of Gothic style but contains elements of Baroque and Romanesque architecture. Beside the Cathedral is the Gothic Basilica of the Virgin "(Basílica De La Virgen De Los Desamparados)". The 15th-century "Serrano" and "Quart" towers are part of what was once the wall surrounding the city.
UNESCO has recognised the Silk Exchange market "(La Llotja de la Seda)", erected in early Valencian Gothic style, as a World Heritage Site. The modernist Central Market ("Mercado Central") is one of the largest in Europe. The main railway station "Estación Del Norte" is built in modernisme (the Spanish version of Art Nouveau) style.
World-renowned (and city-born) architect Santiago Calatrava produced the futuristic City of Arts and Sciences "(Ciutat de les Arts i les Ciències)", which contains an opera house/performing arts centre, a science museum, an IMAX cinema/planetarium, an oceanographic park and other structures such as a long covered walkway and restaurants. Calatrava is also responsible for the bridge named after him in the centre of the city. The Music Palace "(Palau De La Música) (:es:Palau de la Musica)" is another noteworthy example of modern architecture in Valencia.
The cathedral.
The Valencia Cathedral was called "Iglesia Mayor" in the early days of the "Reconquista", then "Iglesia de la Seo" ("Seo" is from the Latin "sedes", i.e., (archiepiscopal) See), and by virtue of the papal concession of 16 October 1866, it was called the "Basilica Metropolitana". It is situated in the centre of the ancient Roman city where some believe the temple of Diana stood. In Gothic times, it seems to have been dedicated to the Holy Saviour; the Cid dedicated it to the Blessed Virgin; King James I of Aragon did likewise, leaving in the main chapel the image of the Blessed Virgin, which he carried with him and is reputed to be the one now preserved in the sacristy. The Moorish mosque, which had been converted into a Christian Church by the conqueror, was deemed unworthy of the title of the cathedral of Valencia, and in 1262 Bishop Andrés de Albalat laid the cornerstone of the new Gothic building, with three naves; these reach only to the choir of the present building. Bishop Vidal de Blanes built the chapter hall, and James I added the tower, called "El Miguelete" because it was blessed on St. Michael's day in 1418. The tower is about high and is topped with a belfry (1660–1736).
In the 15th century the dome was added and the naves extended back of the choir, uniting the building to the tower and forming a main entrance. Archbishop Luis Alfonso de los Cameros began the building of the main chapel in 1674; the walls were decorated with marbles and bronzes in the Baroque style of that period. At the beginning of the 18th century the German Conrad Rudolphus built the façade of the main entrance. The other two doors lead into the transept; one, that of the Apostles in pure pointed Gothic, dates from the 14th century, the other is that of the Paláu. The additions made to the back of the cathedral detract from its height. The 18th-century restoration rounded the pointed arches, covered the Gothic columns with Corinthian pillars, and redecorated the walls. The dome has no lantern, its plain ceiling being pierced by two large side windows. There are four chapels on either side, besides that at the end and those that open into the choir, the transept, and the sanctuary. It contains many paintings by eminent artists. A silver reredos, which was behind the altar, was carried away in the war of 1808, and converted into coin to meet the expenses of the campaign. There are two paintings by Francisco Goya in the San Francesco chapel. Behind the Chapel of the Blessed Sacrament is a small Renaissance chapel built by Calixtus III. Beside the cathedral is the chapel dedicated to the Our Lady of the Forsaken "(Virgen de los desamparados or Mare de Déu dels Desamparats)".
The "Tribunal de las Aguas" (Water Court), a court dating from Moorish times that hears and mediates in matters relating to irrigation water, sits at noon every Thursday outside the "Puerta de Apostoles" (Portal of the Apostles).
Hospital.
In 1409, a hospital was founded and placed under the patronage of Santa María de los Inocentes; to this was attached a confraternity devoted to recovering the bodies of the unfriended dead in the city and within a radius of around it. At the end of the 15th century this confraternity separated from the hospital, and continued its work under the name of "Cofradia para el ámparo de los desamparados". King Philip IV of Spain and the Duke of Arcos suggested the building of the new chapel, and in 1647 the Viceroy, Conde de Oropesa, who had been preserved from the bubonic plague, insisted on carrying out their project. The Blessed Virgin was proclaimed patroness of the city under the title of "Virgen de los desamparados" (Virgin of the Forsaken), and Archbishop Pedro de Urbina, on 31 June 1652, laid the cornerstone of the new chapel of this name. The archiepiscopal palace, a grain market in the time of the Moors, is simple in design, with an inside cloister and a handsome chapel. In 1357, the arch that connects it with the cathedral was built. Inside the council chamber are preserved the portraits of all the prelates of Valencia.
Medieval churches.
"El Templo" (the Temple), the ancient church of the Knights Templar, which passed into the hands of the Order of Montesa and was rebuilt in the reigns of Ferdinand VI and Charles III; the former convent of the Dominicans, at one time the headquarters of the "Capital General", the cloister of which has a beautiful Gothic wing and the chapter room, large columns imitating palm trees; the "Colegio del Corpus Christi", which is devoted to the Blessed Sacrament, and in which perpetual adoration is carried on; the Jesuit college, which was destroyed in 1868 by the revolutionary Committee of the Popular Front, but later rebuilt; and the "Colegio de San Juan" (also of the Society), the former college of the nobles, now a provincial institute for secondary instruction.
Squares and gardens.
The largest plaza in Valencia is the "Plaza del Ayuntamiento"; it is home to the City Hall "(Ayuntamiento)" on its western side and the central post office "(Edificio de Correos)" on its eastern side, a cinema that shows classic movies, and many restaurants and bars. The plaza is triangular in shape, with a large cement lot at the southern end, normally surrounded by flower vendors. It serves as ground zero during the Les Falles when the fireworks of the "Mascletà" can be heard every afternoon. There is a large fountain at the northern end.
The "Plaça de la Mare de Déu" contains the Basilica of the Virgin and the Turia fountain, and is a popular spot for locals and tourists. Around the corner is the Plaça de la Reina, with the Cathedral, orange trees, and many bars and restaurants.
The Turia River was diverted in the 1960s, after severe flooding, and the old riverbed is now the Turia gardens, which contain a children's playground, a fountain, and sports fields. The "Palau de la Música" is adjacent to the Turia gardens and the City of Arts and Sciences lies at one end. The Valencia Bioparc is a zoo, also located in the Turia riverbed.
Other gardens in Valencia include:
Sport.
Football.
Valencia is also internationally famous for its football club, Valencia C.F., which won the Spanish league in 2002 and 2004 (the year it also won the UEFA Cup), for a total of six times, and was a UEFA Champions League runner-up in 2000 and 2001. The club is currently owned by Peter Lim, a Singaporean businessman who bought the club in 2014. The team's stadium is the Mestalla; its city rival Levante UD also plays in the highest division after gaining promotion in 2010, their stadium is Estadi Ciutat de València. From the year 2011 there has been a third team in the city, Huracán Valencia, who play their games in Municipal de Manises, in the Segunda División B.
American Football.
Valencia is the only city in Spain with two American football teams in LNFA Serie A, the national first division: Valencia Firebats and Valencia Giants. The Firebats have been national champions three times and have represented Valencia and Spain in the European playoffs since 2005. Both teams share the Jardín del Turia stadium.
Motor sports.
Once a year between 2008–2012 the European Formula One Grand Prix took place in the Valencia Street Circuit. Valencia is among with Barcelona, Porto and Monte Carlo the only European cities ever to host Formula One World Championship Grands Prix on public roads in the middle of cities. The final race in 2012 European Grand Prix saw an extremely popular winner, since home driver Fernando Alonso won for Ferrari in spite of starting halfway down the field. The Valencian Community motorcycle Grand Prix "(Gran Premi de la Comunitat Valenciana de motociclisme)" is part of the Grand Prix motorcycle racing season at the Circuit Ricardo Tormo (also known as "Circuit de Valencia"). Periodically the Spanish round of the Deutsche Tourenwagen Masters touring car racing Championship (DTM) is held in Valencia.
Rugby League.
Valencia is also the home of the Asociación Española de Rugby League, who are the governing body for Rugby League in Spain. The city plays host to a number of clubs playing the sport and to date has hosted all the countries home international matches. In 2015 Valencia hosted their first match in the Rugby League European Federation C competition, which was a qualifier for the 2017 Rugby League World Cup. Spain won the fixture 40-30
Twin towns and sister cities.
Valencia is twinned with:

</doc>
<doc id="63863" url="https://en.wikipedia.org/wiki?curid=63863" title="Verilog">
Verilog

Verilog, standardized as IEEE 1364, is a hardware description language (HDL) used to model electronic systems. It is most commonly used in the design and verification of digital circuits at the register-transfer level of abstraction. It is also used in the verification of analog circuits and mixed-signal circuits, as well as in the design of genetic circuits.
Overview.
Hardware description languages such as Verilog differ from software programming languages because they include ways of describing the propagation time and signal strengths (sensitivity). There are two types of assignment operators; a blocking assignment (=), and a non-blocking (<=) assignment. The non-blocking assignment allows designers to describe a state-machine update without needing to declare and use temporary storage variables. Since these concepts are part of Verilog's language semantics, designers could quickly write descriptions of large circuits in a relatively compact and concise form. At the time of Verilog's introduction (1984), Verilog represented a tremendous productivity improvement for circuit designers who were already using graphical schematic capture software and specially written software programs to document and simulate electronic circuits.
The designers of Verilog wanted a language with syntax similar to the C programming language, which was already widely used in engineering software development. Like C, Verilog is case-sensitive and has a basic preprocessor (though less sophisticated than that of ANSI C/C++). Its control flow keywords (if/else, for, while, case, etc.) are equivalent, and its operator precedence is compatible with C. Syntactic differences include: required bit-widths for variable declarations, demarcation of procedural blocks (Verilog uses begin/end instead of curly braces {}), and many other minor differences. Verilog requires that variables be given a definite size. In C these sizes are assumed from the 'type' of the variable (for instance an integer type may be 8 bits).
A Verilog design consists of a hierarchy of modules. Modules encapsulate "design hierarchy", and communicate with other modules through a set of declared input, output, and bidirectional ports. Internally, a module can contain any combination of the following: net/variable declarations (wire, reg, integer, etc.), concurrent and sequential statement blocks, and instances of other modules (sub-hierarchies). Sequential statements are placed inside a begin/end block and executed in sequential order within the block. However, the blocks themselves are executed concurrently, making Verilog a dataflow language.
Verilog's concept of 'wire' consists of both signal values (4-state: "1, 0, floating, undefined") and signal strengths (strong, weak, etc.). This system allows abstract modeling of shared signal lines, where multiple sources drive a common net. When a wire has multiple drivers, the wire's (readable) value is resolved by a function of the source drivers and their strengths.
A subset of statements in the Verilog language are synthesizable. Verilog modules that conform to a synthesizable coding style, known as RTL (register-transfer level), can be physically realized by synthesis software. Synthesis software algorithmically transforms the (abstract) Verilog source into a netlist, a logically equivalent description consisting only of elementary logic primitives (AND, OR, NOT, flip-flops, etc.) that are available in a specific FPGA or VLSI technology. Further manipulations to the netlist ultimately lead to a circuit fabrication blueprint (such as a photo mask set for an ASIC or a bitstream file for an FPGA).
History.
Beginning.
Verilog was one of the first modern hardware description languages to be invented. It was created by Prabhu Goel and Phil Moorby between late 1983 and early 1984. The wording for this process was "Automated Integrated Design Systems" (later renamed to Gateway Design Automation in 1985) as a hardware modeling language. Gateway Design Automation was purchased by Cadence Design Systems in 1990. Cadence now has full proprietary rights to Gateway's Verilog and the Verilog-XL, the HDL-simulator that would become the de facto standard (of Verilog logic simulators) for the next decade. Originally, Verilog was only intended to describe and allow simulation, the automated synthesis of subsets of the language to physically realizable structures (gates etc) was developed after the language had achieved widespread usage.
Verilog is a portmanteau of the words "verification" and "logic".
Verilog-95.
With the increasing success of VHDL at the time, Cadence decided to make the language available for open standardization. Cadence transferred Verilog into the public domain under the Open Verilog International (OVI) (now known as Accellera) organization. Verilog was later submitted to IEEE and became IEEE Standard 1364-1995, commonly referred to as Verilog-95.
In the same time frame Cadence initiated the creation of Verilog-A to put standards support behind its analog simulator Spectre. Verilog-A was never intended to be a standalone language and is a subset of Verilog-AMS which encompassed Verilog-95.
Verilog 2001.
Extensions to Verilog-95 were submitted back to IEEE to cover the deficiencies that users had found in the original Verilog standard. These extensions became IEEE Standard 1364-2001 known as Verilog-2001.
Verilog-2001 is a significant upgrade from Verilog-95. First, it adds explicit support for (2's complement) signed nets and variables. Previously, code authors had to perform signed operations using awkward bit-level manipulations (for example, the carry-out bit of a simple 8-bit addition required an explicit description of the Boolean algebra to determine its correct value). The same function under Verilog-2001 can be more succinctly described by one of the built-in operators: +, -, /, *, Â»>. A generate/endgenerate construct (similar to VHDL's generate/endgenerate) allows Verilog-2001 to control instance and statement instantiation through normal decision operators (case/if/else). Using generate/endgenerate, Verilog-2001 can instantiate an array of instances, with control over the connectivity of the individual instances. File I/O has been improved by several new system tasks. And finally, a few syntax additions were introduced to improve code readability (e.g. always, @*, named parameter override, C-style function/task/module header declaration).
Verilog-2001 is the version of Verilog supported by the majority of commercial EDA software packages.
Verilog 2005.
Not to be confused with SystemVerilog, "Verilog 2005" (IEEE Standard 1364-2005) consists of minor corrections, spec clarifications, and a few new language features (such as the uwire keyword).
A separate part of the Verilog standard, Verilog-AMS, attempts to integrate analog and mixed signal modeling with traditional Verilog.
SystemVerilog.
SystemVerilog is a superset of Verilog-2005, with many new features and capabilities to aid design verification and design modeling. As of 2009, the SystemVerilog and Verilog language standards were merged into SystemVerilog 2009 (IEEE Standard 1800-2009).
The advent of hardware verification languages such as OpenVera, and Verisity's e language encouraged the development of Superlog by Co-Design Automation Inc (acquired by Synopsys). The foundations of Superlog and Vera were donated to Accellera, which later became the IEEE standard P1800-2005: SystemVerilog.
Example.
A simple example of two flip-flops follows:
The "<=" operator in Verilog is another aspect of its being a hardware description language as opposed to a normal procedural language. This is known as a "non-blocking" assignment. Its action doesn't register until after the always block has executed. This means that the order of the assignments is irrelevant and will produce the same result: flop1 and flop2 will swap values every clock.
The other assignment operator, "=", is referred to as a blocking assignment. When "=" assignment is used, for the purposes of logic, the target variable is updated immediately. In the above example, had the statements used the "=" blocking operator instead of "<=", flop1 and flop2 would not have been swapped. Instead, as in traditional programming, the compiler would understand to simply set flop1 equal to flop2 (and subsequently ignore the redundant logic to set flop2 equal to flop1).
An example counter circuit follows:
An example of delays:
The always clause above illustrates the other type of method of use, i.e. it executes whenever any of the entities in the list (the b or e) changes. When one of these changes, a is immediately assigned a new value, and due to the blocking assignment, "b" is assigned a new value afterward (taking into account the new value of a). After a delay of 5 time units, c is assigned the value of b and the value of c ^ e is tucked away in an invisible store. Then after 6 more time units, d is assigned the value that was tucked away.
Signals that are driven from within a process (an initial or always block) must be of type reg. Signals that are driven from outside a process must be of type wire. The keyword reg does not necessarily imply a hardware register.
Definition of constants.
The definition of constants in Verilog supports the addition of a width parameter. The basic syntax is:
<"Width in bits">'<"base letter"><"number">
Examples:
Synthesizeable constructs.
There are several statements in Verilog that have no analog in real hardware, e.g. $display. Consequently, much of the language can not be used to describe hardware. The examples presented here are the classic subset of the language that has a direct mapping to real gates.
The next interesting structure is a transparent latch; it will pass the input to the output when the gate signal is set for "pass-through", and captures the input and stores it upon transition of the gate signal to "hold". The output will remain stable regardless of the input signal while the gate is set to "hold". In the example below the "pass-through" level of the gate would be when the value of the if clause is true, i.e. gate = 1. This is read "if gate is true, the din is fed to latch_out continuously." Once the if clause is false, the last value at latch_out will remain and is independent of the value of din.
The flip-flop is the next significant template; in Verilog, the D-flop is the simplest, and it can be modeled as:
The significant thing to notice in the example is the use of the non-blocking assignment. A basic rule of thumb is to use <= when there is a posedge or negedge statement within the always clause.
A variant of the D-flop is one with an asynchronous reset; there is a convention that the reset state will be the first if clause within the statement.
The next variant is including both an asynchronous reset and asynchronous set condition; again the convention comes into play, i.e. the reset term is followed by the set term.
Note: If this model is used to model a Set/Reset flip flop then simulation errors can result. Consider the following test sequence of events. 1) reset goes high 2) clk goes high 3) set goes high 4) clk goes high again 5) reset goes low followed by 6) set going low. Assume no setup and hold violations.
In this example the always @ statement would first execute when the rising edge of reset occurs which would place q to a value of 0. The next time the always block executes would be the rising edge of clk which again would keep q at a value of 0. The always block then executes when set goes high which because reset is high forces q to remain at 0. This condition may or may not be correct depending on the actual flip flop. However, this is not the main problem with this model. Notice that when reset goes low, that set is still high. In a real flip flop this will cause the output to go to a 1. However, in this model it will not occur because the always block is triggered by rising edges of set and reset - not levels. A different approach may be necessary for set/reset flip flops.
The final basic variant is one that implements a D-flop with a mux feeding its input. The mux has a d-input and feedback from the flop itself. This allows a gated load function.
Note that there are no "initial" blocks mentioned in this description. There is a split between FPGA and ASIC synthesis tools on this structure. FPGA tools allow initial blocks where reg values are established instead of using a "reset" signal. ASIC synthesis tools don't support such a statement. The reason is that an FPGA's initial state is something that is downloaded into the memory tables of the FPGA. An ASIC is an actual hardware implementation.
Initial and always.
There are two separate ways of declaring a Verilog process. These are the always and the initial keywords. The always keyword indicates a free-running process. The initial keyword indicates a process executes exactly once. Both constructs begin execution at simulator time 0, and both execute until the end of the block. Once an always block has reached its end, it is rescheduled (again). It is a common misconception to believe that an initial block will execute before an always block. In fact, it is better to think of the initial-block as a special-case of the always-block, one which terminates after it completes for the first time.
These are the classic uses for these two keywords, but there are two significant additional uses. The most common of these is an always keyword without the @(...) sensitivity list. It is possible to use always as shown below:
The always keyword acts similar to the "C" construct while(1) {..} in the sense that it will execute forever.
The other interesting exception is the use of the initial keyword with the addition of the forever keyword.
The example below is functionally identical to the always example above.
Fork/join.
The fork/join pair are used by Verilog to create parallel processes. All statements (or blocks) between a fork/join pair begin execution simultaneously upon execution flow hitting the fork. Execution continues after the join upon completion of the longest running statement or block between the fork and join.
The way the above is written, it is possible to have either the sequences "ABC" or "BAC" print out. The order of simulation between the first $write and the second $write depends on the simulator implementation, and may purposefully be randomized by the simulator. This allows the simulation to contain both accidental race conditions as well as intentional non-deterministic behavior.
Notice that VHDL cannot dynamically spawn multiple processes like Verilog.
Race conditions.
The order of execution isn't always guaranteed within Verilog. This can best be illustrated by a classic example. Consider the code snippet below:
What will be printed out for the values of a and b? Depending on the order of execution of the initial blocks, it could be zero and zero, or alternately zero and some other arbitrary uninitialized value. The $display statement will always execute after both assignment blocks have completed, due to the #1 delay.
Operators.
Note: These operators are "not" shown in order of precedence.
Four-valued logic.
The IEEE 1364 standard defines a four-valued logic with four states: 0, 1, Z (high impedance), and X (unknown logic value). For the competing VHDL, a dedicated standard for multi-valued logic exists as IEEE 1164 with nine levels.
System tasks.
System tasks are available to handle simple I/O and various design measurement functions during simulation. All system tasks are prefixed with $ to distinguish them from user tasks and functions. This section presents a short list of the most frequently used tasks. It is by no means a comprehensive list.
Program Language Interface (PLI).
The PLI provides a programmer with a mechanism to transfer control from Verilog to a program function written in C language. It is officially deprecated by IEEE Std 1364-2005 in favor of the newer Verilog Procedural Interface, which completely replaces the PLI.
The PLI (now VPI) enables Verilog to cooperate with other programs written in the C language such as test harnesses, instruction set simulators of a microcontroller, debuggers, and so on. For example, it provides the C functions codice_1 and codice_2 which are used to write and read the argument of the current Verilog task or function, respectively.
Simulation software.
For information on Verilog simulators, see the list of Verilog simulators.

</doc>
<doc id="63864" url="https://en.wikipedia.org/wiki?curid=63864" title="DICOM">
DICOM

Digital Imaging and Communications in Medicine (DICOM) is a standard for handling, storing, printing, and transmitting information in medical imaging. It includes a file format definition and a network communications protocol. The communication protocol is an application protocol that uses TCP/IP to communicate between systems. DICOM files can be exchanged between two entities that are capable of receiving image and patient data in DICOM format. The National Electrical Manufacturers Association (NEMA) holds the copyright to this standard. It was developed by the DICOM Standards Committee, whose members are also partly members of NEMA.
DICOM enables the integration of scanners, servers, workstations, printers, and network hardware from multiple manufacturers into a picture archiving and communication system (PACS). The different devices come with DICOM conformance statements which clearly state which DICOM classes they support. DICOM has been widely adopted by hospitals and is making inroads in smaller applications like dentists' and doctors' offices.
DICOM is known as NEMA standard PS3, and as ISO standard 12052:2006 "Health informatics -- Digital imaging and communication in medicine (DICOM) including workflow and data management".
Parts of the standard.
The DICOM standard is divided into related but independent parts. The links below are to the chunked HTML representation of the current version; as the standard is updated the content at these links remains valid. Alternative formats as well as the DocBook source of the standard text, and additions to the standard (Supplements and Change Proposals), are available through the DICOM Web site and are also indexed on the DICOM status page.
History.
DICOM is the a standard developed by American College of Radiology (ACR) and National Electrical Manufacturers Association (NEMA).
In the beginning of the 1980s, it was very difficult for anyone other than manufacturers of computed tomography or magnetic resonance imaging devices to decode the images that the machines generated. Radiologists and medical physicists wanted to use the images for dose-planning for radiation therapy. ACR and NEMA joined forces and formed a standard committee in 1983. Their first standard, ACR/NEMA 300, was released in 1985. Very soon after its release, it became clear that improvements were needed. The text was vague and had internal contradictions.
In 1988 the second version was released. This version gained more acceptance among vendors. The image transmission was specified as over a dedicated 2 pair cable (EIA-485). The first demonstration of ACR/NEMA V2.0 interconnectivity technology was held at Georgetown University, May 21–23, 1990. Six companies participated in this event, DeJarnette Research Systems, General Electric Medical Systems, Merge Technologies, Siemens Medical Systems, Vortech (acquired by Kodak that same year) and 3M. Commercial equipment supporting ACR/NEMA 2.0 was presented at the annual meeting of the Radiological Society of North America (RSNA) in 1990 by these same vendors. Many soon realized that the second version also needed improvement. Several extensions to ACR/NEMA 2.0 were created, like Papyrus (developed by the University Hospital of Geneva, Switzerland) and SPI (Standard Product Interconnect), driven by Siemens Medical Systems and Philips Medical Systems.
The first large-scale deployment of ACR/NEMA technology was made in 1992 by the US Army and Air Force, as part of the MDIS (Medical Diagnostic Imaging Support) program based at f Ft. Detrick, Maryland. Loral Aerospace and Siemens Medical Systems led a consortium of companies in deploying the first US military PACS (Picture Archiving and Communications System) at all major Army and Air Force medical treatment facilities and teleradiology nodes at a large number of US military clinics. DeJarnette Research Systems and Merge Technologies provided the modality gateway interfaces from third party imaging modalities to the Siemens SPI network. The Veterans Administration and the Navy also purchased systems off this contract.
In 1993 the third version of the standard was released. Its name was then changed to "DICOM". New service classes were defined, network support added and the Conformance Statement was introduced. Officially, the latest version of the standard is still 3.0. It has been constantly updated and extended since 1993, but most changes are forward and backward compatible, except in rare cases where the original specification was not interoperable or conflicted with another standard. The standard should be referenced without specification of the date of release of a particular edition, except when specific conformance requirements are invoked that depend on a particular change (e.g., to reference a retired feature).
While the DICOM standard has achieved a near universal level of acceptance amongst medical imaging equipment vendors and healthcare IT organizations, the standard has its limitations. DICOM is a standard directed at addressing technical interoperability issues in medical imaging. It is not a framework or architecture for achieving a useful clinical workflow. The Integrating the Healthcare Enterprise (IHE) initiative layered on top of DICOM (and HL-7) defines profiles to select features from these standards to implement transactions for specific medical imaging interoperability use cases.
Though always Internet compatible and based on transport over TCP, over time there has been an increasing need to support port 80 http transport to make use easier within the web browser. Most recently, a family of DICOM RESTful web services have been defined to allow mobile device friendly access to DICOM objects and services, which include WADO-RS, STOW-RS and QIDO-RS, which together constitute the DICOMweb initiative,
Derivations.
There are some derivations from the DICOM standard into other application areas. These include:
Data format.
DICOM differs from some, but not all, data formats in that it groups information into data sets. That means that a file of a chest x-ray image, for example, actually contains the patient ID within the file, so that the image can never be separated from this information by mistake. This is similar to the way that image formats such as JPEG can also have embedded tags to identify and otherwise describe the image.
A DICOM data object consists of a number of attributes, including items such as name, ID, etc., and also one special attribute containing the image pixel data (i.e. logically, the main object has no "header" as such, being merely a list of attributes, including the pixel data). A single DICOM object can have only one attribute containing pixel data. For many modalities, this corresponds to a single image. However, the attribute may contain multiple "frames", allowing storage of cine loops or other multi-frame data. Another example is NM data, where an NM image, by definition, is a multi-dimensional multi-frame image. In these cases, three- or four-dimensional data can be encapsulated in a single DICOM object. Pixel data can be compressed using a variety of standards, including JPEG, Lossless JPEG, JPEG 2000, and Run-length encoding (RLE). LZW (zip) compression can be used for the whole data set (not just the pixel data), but this has rarely been implemented.
DICOM uses three different Data Element encoding schemes. With Explicit Value Representation (VR) Data Elements, for VRs that are not OB, OW, OF, SQ, UT, or UN, the format for each Data Element is: GROUP (2 bytes) ELEMENT (2 bytes) VR (2 bytes) LengthInByte (2 bytes) Data (variable length). For the other Explicit Data Elements or Implicit Data Elements, see section 7.1 of Part 5 of the DICOM Standard.
The same basic format is used for all applications, including network and file usage, but when written to a file, usually a true "header" (containing copies of a few key attributes and details of the application which wrote it) is added.
Image display.
To promote identical grayscale image display on different monitors and consistent hard-copy images from various printers, the DICOM committee developed a lookup table to display digitally assigned pixel values. To use the DICOM grayscale standard display function (GSDF), images must be viewed (or printed) on devices that have this lookup curve or on devices that have been calibrated to the GSDF curve.
Value representations.
See Table 6.2-1 of PS 3.5.
In addition to a Value Representation, each attribute also has a Value Multiplicity to indicate the number of data elements contained in the attribute. For character string value representations, if more than one data element is being encoded, the successive data elements are separated by the backslash character "\".
Services.
DICOM consists of many different services, most of which involve transmission of data over a network, and the file format below is a later and relatively minor addition to the standard.
Store.
The DICOM Store service is used to send images or other persistent objects (structured reports, etc.) to a picture archiving and communication system (PACS) or workstation.
Storage commitment.
The DICOM storage commitment service is used to confirm that an image has been permanently stored by a device (either on redundant disks or on backup media, e.g. burnt to a CD). The Service Class User (SCU: similar to a client), a modality or workstation, etc., uses the confirmation from the Service Class Provider (SCP: similar to a server), an archive station for instance, to make sure that it is safe to delete the images locally.
Query/Retrieve.
This enables a workstation to find lists of images or other such objects and then retrieve them from a picture archiving and communication system.
Modality worklist.
A modality is the way or mode in which something exists or is done. You might often see it used with reference to diagnostic modality, which is the way in which a disease or illness is diagnosed by a doctor.
Modality performed procedure step.
A complementary service to Modality Worklist, this enables the modality to send a report about a performed examination including data about the images acquired, beginning time, end time, and duration of a study, dose delivered, etc.
It helps give the radiology department a more precise handle on resource (acquisition station) use. Also known as MPPS, this service allows a modality to better coordinate with image storage servers by giving the server a list of objects to send before or while actually sending such objects.
Printing.
The DICOM Printing service is used to send images to a DICOM Printer, normally to print an "X-Ray" film. There is a standard calibration (defined in DICOM Part 14) to help ensure consistency between various display devices, including hard copy printout.
Off-line media (files).
The off-line media files correspond to Part 10 of the DICOM standard. It describes how to store medical imaging information on removable media. Except for the data set containing, for example, an image and demography, it's also mandatory to include the File Meta Information.
DICOM restricts the filenames on DICOM media to 8 characters (some systems wrongly use 8.3, but this does not conform to the standard). No information must be extracted from these names (PS3.10 Section 6.2.3.2). This is a common source of problems with media created by developers who did not read the specifications carefully. This is a historical requirement to maintain compatibility with older existing systems. It also mandates the presence of a media directory, the DICOMDIR file, which provides index and summary information for all the DICOM files on the media.
The DICOMDIR information provides substantially greater information about each file than any filename could, so there is less need for meaningful file names.
DICOM files typically have a .dcm file extension if they are not part of a DICOM media (which requires them to be without extension).
The MIME type for DICOM files is defined by RFC 3240 as application/dicom.
The Uniform Type Identifier type for DICOM files is org.nema.dicom.
There is also an ongoing media exchange test and "connectathon" process for CD media and network operation that is organized by the IHE organization.
Application areas.
All of the Defined Terms for Modality are listed in Section C.7.3.1.1.1 of PS 3.3.
Port numbers over IP.
DICOM have reserved the following TCP and UDP port numbers by the Internet Assigned Numbers Authority (IANA):
The standard recommends but does not require the use of these port numbers.
Disadvantages.
According to a paper presented at an international symposium in 2008, the DICOM standard has problems related to data entry. "A major disadvantage of the DICOM Standard is the possibility for entering probably too many optional fields. This disadvantage is mostly showing in inconsistency of filling all the fields with the data. Some image objects are often incomplete because some fields are left blank and some are filled with incorrect data."
HL7.
DICOM is a standard for handling, storing, printing, and transmitting information in medical imaging. The communication protocol is an application protocol that uses TCP/IP to communicate between systems. DICOM files can be exchanged between two entities that are capable of receiving image and patient data in DICOM format. The National Electrical Manufacturers Association (NEMA) holds the copyright to this standard. It was developed by the DICOM Standards Committee, whose members are also partly members of NEMA.
Health Level Seven (HL7), is a non-profit organization involved in the development of international healthcare informatics interoperability standards. "HL7" also refers to some of the specific standards created by the organization (e.g., HL7 v2.x, v3.0, HL7 RIM). The HL7 Strategic Initiatives document is a business plan for our products and services and was designed specifically to meet the business needs of its members and stakeholders. Derived from collaborative efforts with its members, government and non-government agencies and other standards development organizations, the Strategic Initiatives are five high-level organizational strategies that are supported by a detailed tactical plan with clearly defined objectives, milestones, and metrics for success.
Both of the standards are focused on the data exchange and the data compatibility. Among many standards for the syntax, HL7 and DICOM are most successful. However, everything could not be handled by HL7 solely. DICOM is good for radiology images, but, other clinical images are already handled by other ‘lighter’ data formats like JPEG, TIFF. So, it is not realistic to use only one standard for every area of clinical information.
Opening the HL7 and DICOM standards in order to foster the integrated use of persistent health information objects is proposed as a step towards the creation of the health information infrastructure.
IHE.
Integrating the Healthcare Enterprise (IHE) was founded in 1997 by members of the Radiological Society of North America (RSNA) and the Healthcare Information and Management Systems Society for the purpose of improving interoperability between information systems. The IHE initiative was charged with the task of using existing standards of health care data communication such as DICOM and HL7 to improve exchange of medical information beyond the radiology department at the hospital level or health systems level. Just as radiologists were confronted in the past with imaging connectivity incompatibilities, entire health systems are continually faced with the task of connecting multiple disparate information systems in which the only reliable communications pathway is the paper printout.
The IHE working group is a panel made up of industry representatives from medical informatics and imaging vendors as well as medical professionals. Their primary focus is to develop a common information model of medical information exchange. The devised IHE technical framework consists of a common lexicon that defines specific medical information transactions using the existing standards of medical information exchange (DICOM and HL7). The specifics of these transactions have been worked out in great detail so that vendors have been free to independently develop solutions to meet the goals of the technical framework. In the year 2001 to 2002, 30 companies took part in the testing and implementation of the IHE demonstrations.

</doc>
<doc id="63866" url="https://en.wikipedia.org/wiki?curid=63866" title="Palermo Technical Impact Hazard Scale">
Palermo Technical Impact Hazard Scale

The Palermo Technical Impact Hazard Scale is a logarithmic scale used by astronomers to rate the potential hazard of impact of a near-earth object (NEO). It combines two types of data—probability of impact, and estimated kinetic yield—into a single "hazard" value. A rating of 0 means the hazard is equivalent to the background hazard (defined as the average risk posed by objects of the same size or larger over the years until the date of the potential impact). A rating of +2 would indicate the hazard is 100 times greater than a random background event. Scale values less than −2 reflect events for which there are no likely consequences, while Palermo Scale values between −2 and 0 indicate situations that merit careful monitoring. A similar but less complex scale is the Torino Scale, which is used for simpler descriptions in the non-scientific media.
Scale.
The scale compares the likelihood of the detected potential impact with the average risk posed by objects of the same size or larger over the years until the date of the potential impact. This average risk from random impacts is known as the background risk. The Palermo Scale value, "P", is defined by the equation:
where
The background impact frequency is defined for this purpose as:
where the energy threshold E is measured in megatons, yr is the unit of T divided by one year.
Positive rating.
The near-Earth object was the first near-Earth object detected by NASA's latest NEO program to be given a positive rating on the scale of 0.06, indicating a higher-than-background threat. The value was subsequently lowered after more measurements were taken and 2002 NT7 is no longer considered to pose any risk, and was removed from the Sentry Risk Table on 1 August 2002.
For a brief period in late December 2004, asteroid (then known only by its provisional designation ) held the record for Palermo scale values, with a value of 1.10 for a possible collision in the year 2029. The 1.10 value indicated that a collision with this object was considered to be almost 12.6 times more likely than a random background event: 1 in 37 instead of 1 in 472. With further observations, the possibility of a 2029 impact was eliminated. As of 2013 a maximum Palermo rating of −3.32 applies, due to a possible event in 2068.
In September 2002, the highest Palermo rating was that of asteroid (29075) 1950 DA, with a value of 0.17 for a possible collision in the year 2880. In August 2014, the Palermo rating for (29075) 1950 DA was reduced to −1.81.
References.
The primary reference for the Palermo Technical Scale is "Quantifying the risk posed by potential Earth impacts" by Chesley et al., Icarus 159, 423-432 (2002).

</doc>
<doc id="63867" url="https://en.wikipedia.org/wiki?curid=63867" title="Martorell">
Martorell

Martorell () is a municipality that forms part of the Baix Llobregat comarca, in Catalonia, Spain, primarily known for its medieval Devil's bridge. It lies at the confluence of the Llobregat and Anoia rivers.
It has three railway stations - one on the RENFE line from Manresa to Sant Vicenç de Calders (via Barcelona and Vilafranca del Penedès) called "Martorell", and three on the FGC line from Barcelona to Manresa called "Martorell-Vila", "Martorell-Enllaç" and "Martorell-Central".
Martorell is home to the SEAT corporate headquarters and automobile factory , where the Audi Q3 is manufactured.

</doc>
<doc id="63869" url="https://en.wikipedia.org/wiki?curid=63869" title="(89959) 2002 NT7">
(89959) 2002 NT7

Further observations of the object quickly re-rated the threat lower. As of July 25, 2002, the hazard rating on the Palermo scale had been lowered to -0.25. However, the discovery of an object with an initial Palermo hazard rating of 0.06 was a historical event for the NEO observation program.
It is now known that on January 13, 2019 the asteroid will safely pass from the Earth.
On January 30, 2020 the asteroid will pass from 2 Pallas.

</doc>
<doc id="63871" url="https://en.wikipedia.org/wiki?curid=63871" title="Polytechnic University of Catalonia">
Polytechnic University of Catalonia

Polytechnic University of Catalonia (, UPC, ), currently referred to as BarcelonaTech and commonly named just as UPC, is the largest engineering university in Catalonia, Spain—albeit encompassing other disciplines such as mathematics and architecture.
UPC's objectives are based on internationalization, as it is Spain's technical university with the highest number of international PhD students and Spain's university with the highest number of international master's degree students. UPC is a university aiming at achieving the highest degree of engineering/technical excellence and has bilateral agreements with several top-ranked European universities.
UPC is a member of the Top Industrial Managers for Europe network, which allows for student exchanges between leading European engineering schools. It is also a member of several university federations, including the Conference of European Schools for Advanced Engineering Education and Research (CESAER) and UNITECH.
The university was founded in March 1971 as the "Universitat Politècnica de Barcelona" through the merger of engineering and architecture schools originally founded during the 19th century. it has 25 schools in Catalonia located in the cities of Barcelona, Castelldefels, Manresa, Sant Cugat del Vallès, Terrassa, Igualada, Vilanova i la Geltrú and Mataró. UPC has about 30,000 students and 2,500 professors and researchers.
UPC Research Centers.
The UPC has a number of research centres.
Science Fiction Award.
From 1991-2010, the Board of Trustees at UPC organized and awarded an annual Science Fiction Award. Currently the award is presented bi-annually.
Previous winners include:

</doc>
<doc id="63872" url="https://en.wikipedia.org/wiki?curid=63872" title="Pompeu Fabra University">
Pompeu Fabra University

Pompeu Fabra University (; ) is a public university in Barcelona, Catalonia, Spain. Founded in 1990, it is named after the Catalan philologist Pompeu Fabra. According to Times Higher Education it is one of the 7 fastest-rising young universities in the world.
Organization.
UPF offers its studies around three areas of knowledge focused on the human being: the social sciences and humanities, the health and life sciences, and the ITC and communication sciences.
Teaching is organized in seven faculties or schools: Humanities, Health and Life Sciences, Economics, Political and Social Sciences, Communication, Law, Translation and Interpretation, and one polytechnic school.
Research is organized in eight departments: Economics and Business, Law, Political and Social Sciences, Humanities, Experimental Sciences and Health, Information Technologies and Communication, Communication, Translation, Language Sciences; and four university research institutes: University Institute of Culture, Jaume Vicens i Vives University Institute of History, University Institute for Applied Linguistics and the Centre for Neuro-Robotics and Autonomous Systems (N-RAS, founded in 2012).
The University also has four affiliated centers (International Trade Business School -ESCI-, Elisava School of Design, University School of Business Studies of the Maresme -EUM-), Mar University School of Nursing -EUIM-, two interuniversity postgraduate platforms (Institut Barcelona d'Estudis Internacionals -IBEI- and Barcelona Graduate School of Economics -Barcelona GSE-), and its own Continuing Education Institute.
Research.
In order to promote research and transfer activities undertaken by university researchers and provide them with greater international visibility, the University is developing the UPF Research Park in the fields of social sciences, humanities, communication and information technologies. The UPF Research Park, which develops its activity at Ciutadella and Poblenou campuses, coordinates its activities in the fields of health and life sciences with the Barcelona Biomedical Research Park (PRBB), located at Mar campus.
UPF has also been participating in a set of institutions and centers specializing in teaching, research and transfer that have their own legal personality and which comprise the UPF Group, andw hich often exist in collaboration with other institutions and universities Thus, in the field of research and transfer, plus the three science parks include the Municipal Institute of Medical Research (IMIM) - Hospital del Mar, Institute of Evolutionary Biology (IBE) (CSIC-UPF), the Centre for Genomic Regulation (CRG), the Institute of Territorial Studies (IET), the Research Centre for International Economics (CREI) and Fundació Barcelona Media (FBM).
Governance.
Enric Argullol served as rector from the founding until June 2001, followed by M. Rosa Virós i Galtier (2001-2005) and Josep Joan Moreso (2005-2013). The current rector is Jaume Casals.
Campuses.
The UPF is located in three separate campuses, each associated to its own area of knowledge:
International rankings.
The position of the UPF is presented in the following international rankings: Times Higher Education (THE), Quacquarelli Symonds (QS), the one published by Shanghai University (ARWU) and SCimago Institutions Ranking (Scimago). 

</doc>
<doc id="63873" url="https://en.wikipedia.org/wiki?curid=63873" title="Pompeu Fabra">
Pompeu Fabra

Pompeu Fabra i Poch () (Gràcia, Barcelona, 20 February 1868 - Prada de Conflent, 25 December 1948) was a Spanish engineer and grammarian. He was the main author of the normative reform of contemporary Catalan language.
Life.
Pompeu Fabra was born in Gràcia, which at that time was still separate from Barcelona, in 1868. He was the last of twelve children born to Josep Fabra i Roca and his wife Carolina Poch i Martí. When Pompeu was six, the family moved to Barcelona.
From a fairly young age Fabra dedicated himself to the study of the Catalan language. Through the journal and publishing house "L'Avenç", he participated in a campaign to reform Catalan orthography between 1890-92. He published "Tractat d'ortografia catalana" with the writer and publisher Jaume Massó i Torrents and Joaquim Casas i Carbó, a famous lawyer and writer, in 1904.
Despite his personal interest in linguistics, Fabra studied industrial engineering in Barcelona and in 1902 accepted a chair of chemistry position at the School of Engineering in Bilbao. During his tenure in Bilbao, Fabra participated actively in the First International Congress of the Catalan Language held in 1906. This event gave him a certain prestige in the field of Catalan linguistics. In 1911, he returned to Barcelona to become a professor ("catedràtic") of Catalan — a position created by the "diputació" (local government) of Barcelona — and a member of the department of philology at the newly created Institut d'Estudis Catalans, of which he would later become president. In 1912 he published his "Gramática de la lengua catalana" (in Spanish).
The Institute published the "Normes ortogràfiques" in 1913, the "Diccionari ortogràfic" in 1917, and its official "Gramàtica catalana" in 1918. That same year, Fabra also edited the textbook "Curs mitjà de gramàtica catalana," published by l'Associació Protectora de l'Ensenyança Catalana. His "Converses filològiques," first published in the newspaper "La Publicitat," were later collected as "Popular Barcino." Probably his most famous work was the "Diccionari General de la Llengua Catalana" (1932), the first edition of which later became the Institute's official dictionary.
In 1932, owing to his scientific prestige, he was unanimously named a professor ("catedràtic") of the Republican "Universitat Autònoma de Barcelona" (not to be confused with the later Universitat Autònoma de Barcelona created in the 1960s during the Francoist régime). The following year he was named President of the University's governing council, which resulted in his imprisonment in 1934 following the "events of 6 October" when troops of the Second Spanish Republic put down a Catalan government uprising led by Lluis Companys.
Fabra was reinstated to his faculty position after the elections of February 1936, but the Spanish Civil War began in July of that year, and he had to flee his country when Barcelona was being invaded by the Francoist army. By 1939 he was in exile in France where he endured many hardships. He lived in Paris and Montpellier, where he presided over the "Jocs Florals" literary competition in 1946. He eventually moved to Prada de Conflent in the Catalan-speaking area of France, where he died on 25 December 1948. At some point during the exile he made his will in Andorra, so that it would be done in a country where Catalan was the official language.
Legacy.
Every year, his tomb in the Cuixà monastery near Prada is visited by thousands of Catalans.
The Universitat Pompeu Fabra in Barcelona bears his name.

</doc>
<doc id="63876" url="https://en.wikipedia.org/wiki?curid=63876" title="History of the United States">
History of the United States

The date of the start of the history of the United States is a subject of debate among historians. Older textbooks start with the arrival of Christopher Columbus in 3 August 1492 and emphasize the European background, or they start around 1600 and emphasize the American frontier. In recent decades American schools and universities typically have shifted back in time to include more on the colonial period and much more on the prehistory of the Native peoples.
Indigenous people lived in what is now the United States for thousands of years before European colonists began to arrive, mostly from England, after 1600. The Spanish had small settlements in Florida and the Southwest, and the French along the Mississippi River and the Gulf Coast. By the 1770s, thirteen British colonies contained two and a half million people along the Atlantic coast east of the Appalachian Mountains. In the 1760s, the British government imposed a series of new taxes while rejecting the American argument that any new taxes had to be approved by the people (see Stamp Act 1765). Tax resistance, especially the Boston Tea Party (1774), led to punitive laws (the Intolerable Acts) by Parliament designed to end self-government in Massachusetts. American Patriots (as they called themselves) adhered to a political ideology called republicanism that emphasized civic duty, virtue, and opposition to corruption, fancy luxuries and aristocracy.
All thirteen colonies united in a Congress that called on them to write new state constitutions. After armed conflict began in Massachusetts, Patriots drove the royal officials out of every colony and assembled in mass meetings and conventions. Those Patriot governments in the colonies unanimously empowered their delegates to Congress to declare independence. In 1776, Congress declared that there was a new, independent nation, the United States of America, not just a collection of disparate colonies. With large-scale military and financial support from France and military leadership by General George Washington, the American Patriots rebelled against British rule and succeeded in the Revolutionary War.
The peace treaty of 1783 gave the new nation the land east of the Mississippi River (except Florida and Canada, and Spain disputed the Mississippi Territory until 1795) and confirmed Great Britain's recognition of the United States as a nation. The central government established by the Articles of Confederation proved ineffectual at providing stability, as it had no authority to collect taxes and had no executive officer. Congress called a convention to meet secretly in Philadelphia in 1787 to revise the Articles of Confederation. It wrote a new Constitution, which was adopted in 1789. In 1791, a Bill of Rights was added to guarantee inalienable rights. With Washington as the Union's first president and Alexander Hamilton his chief political and financial adviser, a strong central government was created. When Thomas Jefferson became president he purchased the Louisiana Territory from France, doubling the size of the United States. A second and final war with Britain was fought in 1812.
Encouraged by the notion of Manifest Destiny, federal territory expanded all the way to the Pacific. The U.S. always was large in terms of area, but its population was small, only 4 million in 1790. Population growth was rapid, reaching 7.2 million in 1810, 32 million in 1860, 76 million in 1900, 132 million in 1940, and 321 million in 2015. Economic growth in terms of overall GDP was even faster. However the nation's military strength was quite limited in peacetime before 1940. The expansion was driven by a quest for inexpensive land for yeoman farmers and slave owners. The expansion of slavery was increasingly controversial and fueled political and constitutional battles, which were resolved by compromises. Slavery was abolished in all states north of the Mason–Dixon line by 1804, but the South continued to profit off the institution, producing high-value cotton exports to feed increasing high demand in Europe. The 1860 presidential election of Republican Abraham Lincoln was on a platform of ending the expansion of slavery and putting it on a path to extinction.
Seven cotton-based deep South slave states seceded and later founded the Confederacy months before Lincoln's inauguration. No nation ever recognized the Confederacy, but it opened the war by attacking Fort Sumter in 1861. A surge of nationalist outrage in the North fueled a long, intense American Civil War (1861-1865). It was fought largely in the South as the overwhelming material and manpower advantages of the North proved decisive in a long war. The war's result was restoration of the Union, the impoverishment of the South, and the abolition of slavery. In the Reconstruction era (1863–1877), legal and voting rights were extended to the freed slave. The national government emerged much stronger, and because of the Fourteenth Amendment, it gained the explicit duty to protect individual rights. However, when white Democrats regained their power in the South during the 1870s, often by paramilitary suppression of voting, they passed Jim Crow laws to maintain white supremacy, and new disfranchising constitutions that prevented most African Americans and many poor whites from voting, a situation that continued for decades until gains of the civil rights movement in the 1960s and passage of federal legislation to enforce constitutional rights.
The United States became the world's leading industrial power at the turn of the 20th century due to an outburst of entrepreneurship in the Northeast and Midwest and the arrival of millions of immigrant workers and farmers from Europe. The national railroad network was completed with the work of Chinese immigrants and large-scale mining and factories industrialized the Northeast and Midwest. Mass dissatisfaction with corruption, inefficiency and traditional politics stimulated the Progressive movement, from the 1890s to 1920s, which led to many social and political reforms. In 1920, the 19th Amendment to the Constitution guaranteed women's suffrage (right to vote). This followed the 16th and 17th amendments in 1913, which established the first national income tax and direct election of US senators to Congress. Initially neutral during World War I, the US declared war on Germany in 1917 and later funded the Allied victory the following year.
After a prosperous decade in the 1920s, the Wall Street Crash of 1929 marked the onset of the decade-long world-wide Great Depression. Democratic President Franklin D. Roosevelt ended the Republican dominance of the White House and implemented his New Deal programs for relief, recovery, and reform. The New Deal, which defined modern American liberalism, included relief for the unemployed, support for farmers, Social Security and a minimum wage. After the Japanese attack on Pearl Harbor on December 7, 1941, the United States later entered World War II along with Britain, the Soviet Union, China, and the smaller Allies. The U.S. financed the Allied war effort and helped defeat Nazi Germany in Europe and defeated Imperial Japan in the Pacific War. However, the American use of newly invented atomic bombs on Japanese cities remains controversial in the present day.
The United States and the Soviet Union emerged as rival superpowers after World War II. During the Cold War, the US and the USSR confronted each other indirectly in the arms race, the Space Race, proxy wars, and propaganda campaigns. US foreign policy during the Cold War was built around the support of Western Europe and Japan along with the policy of "containment" or stopping the spread of communism. The US joined the wars in Korea and Vietnam to try to stop its spread. In the 1960s, in large part due to the strength of the civil rights movement, another wave of social reforms were enacted by enforcing the constitutional rights of voting and freedom of movement to African-Americans and other racial minorities. Native American activism also rose. The Cold War ended when the Soviet Union officially dissolved in 1991, leaving the United States as the world's only superpower. As the 21st century began, international conflict centered around the Middle East following the September 11 attacks by Al-Qaeda on the United States in 2001. In 2008, the United States had its worst economic crisis since the Great Depression, which has been followed by slower than usual rates of economic growth during the 2010s.
Pre-Columbian era.
It is not definitively known how or when the Native Americans first settled the Americas and the present-day United States. The prevailing theory proposes that people migrated from Eurasia across Beringia, a land bridge that connected Siberia to present-day Alaska during the Ice Age, and then spread southward throughout the Americas and possibly going as far south as the Antarctic peninsula. This migration may have begun as early as 30,000 years ago and continued through to about 10,000+ years ago, when the land bridge became submerged by the rising sea level caused by the ending of the last glacial period. These early inhabitants, called Paleoamericans, soon diversified into many hundreds of culturally distinct nations and tribes.
The pre-Columbian era incorporates all period subdivisions in the history and prehistory of the Americas before the appearance of significant European influences on the American continents, spanning the time of the original settlement in the Upper Paleolithic period to European colonization during the Early Modern period. While technically referring to the era before Christopher Columbus' voyages of 1492 to 1504, in practice the term usually includes the history of American indigenous cultures until they were conquered or significantly influenced by Europeans, even if this happened decades or even centuries after Columbus' initial landing.
Native development prior to European contact.
Native American cultures are not normally included in characterizations of advanced stone age cultures as "Neolithic," which is a category that more often includes only the cultures in Eurasia, Africa, and other regions. The archaeological periods used are the classifications of archaeological periods and cultures established in Gordon Willey and Philip Phillips' 1958 book "Method and Theory in American Archaeology". They divided the archaeological record in the Americas into five phases; see Archaeology of the Americas.
The Clovis culture, a megafauna hunting culture, is primarily identified by use of fluted spear points. Artifacts from this culture were first excavated in 1932 near Clovis, New Mexico. The Clovis culture ranged over much of North America and also appeared in South America. The culture is identified by the distinctive Clovis point, a flaked flint spear-point with a notched flute, by which it was inserted into a shaft. Dating of Clovis materials has been by association with animal bones and by the use of carbon dating methods. Recent reexaminations of Clovis materials using improved carbon-dating methods produced results of 11,050 and 10,800 radiocarbon years B.P. (roughly 9100 to 8850 BCE).
Numerous Paleoindian cultures occupied North America, with some arrayed around the Great Plains and Great Lakes of the modern United States of America and Canada, as well as adjacent areas to the West and Southwest. According to the oral histories of many of the indigenous peoples of the Americas, they have been living on this continent since their genesis, described by a wide range of traditional creation stories. Other tribes have stories that recount migrations across long tracts of land and a great river, believed to be the Mississippi River. Genetic and linguistic data connect the indigenous people of this continent with ancient northeast Asians. Archeological and linguistic data has enabled scholars to discover some of the migrations within the Americas.
The Folsom Tradition was characterized by use of Folsom points as projectile tips, and activities known from kill sites, where slaughter and butchering of bison took place. Folsom tools were left behind between 9000 BCE and 8000 BCE.
Na-Dené-speaking peoples entered North America starting around 8000 BCE, reaching the Pacific Northwest by 5000 BCE, and from there migrating along the Pacific Coast and into the interior. Linguists, anthropologists and archeologists believe their ancestors comprised a separate migration into North America, later than the first Paleo-Indians. They migrated into Alaska and northern Canada, south along the Pacific Coast, into the interior of Canada, and south to the Great Plains and the American Southwest.
They were the earliest ancestors of the Athabascan- speaking peoples, including the present-day and historical Navajo and Apache. They constructed large multi-family dwellings in their villages, which were used seasonally. People did not live there year round, but for the summer to hunt and fish, and to gather food supplies for the winter. The Oshara Tradition people lived from 5500 BCE to 600 CE. They were part of the Southwestern Archaic Tradition centered in north-central New Mexico, the San Juan Basin, the Rio Grande Valley, southern Colorado, and southeastern Utah.
Since the 1990s, archeologists have explored and dated eleven Middle Archaic sites in present-day Louisiana and Florida at which early cultures built complexes with multiple earthwork mounds; they were societies of hunter-gatherers rather than the settled agriculturalists believed necessary according to the theory of Neolithic Revolution to sustain such large villages over long periods. The prime example is Watson Brake in northern Louisiana, whose 11-mound complex is dated to 3500 BCE, making it the oldest, dated site in the Americas for such complex construction. It is nearly 2,000 years older than the Poverty Point site. Construction of the mounds went on for 500 years until was abandoned about 2800 BCE, probably due to changing environmental conditions.
Poverty Point culture is a Late Archaic archaeological culture that inhabited the area of the lower Mississippi Valley and surrounding Gulf Coast. The culture thrived from 2200 BCE to 700 BCE, during the Late Archaic period. Evidence of this culture has been found at more than 100 sites, from the major complex at Poverty Point, Louisiana (a UNESCO World Heritage Site) across a range to the Jaketown Site near Belzoni, Mississippi.
Poverty Point is a complex of six major earthwork concentric rings, with additional platform mounds at the site. Artifacts show the people traded with other Native Americans located from Georgia to the Great Lakes region. This is one among numerous mound sites of complex indigenous cultures throughout the Mississippi and Ohio valleys. They were one of several succeeding cultures often referred to as mound builders.
The Woodland period of North American pre-Columbian cultures refers to the time period from roughly 1000 BCE to 1,000 CE in the eastern part of North America. The term "Woodland" was coined in the 1930s and refers to prehistoric sites dated between the Archaic period and the Mississippian cultures. The Hopewell tradition is the term for the common aspects of the Native American culture that flourished along rivers in the northeastern and midwestern United States from 200 BCE to 500 CE.
The indigenous peoples of the Pacific Northwest Coast were of many nations and tribal affiliations, each with distinctive cultural and political identities, but they shared certain beliefs, traditions and practices, such as the centrality of salmon as a resource and spiritual symbol. Their gift-giving feast, potlatch, is a highly complex event where people gather in order to commemorate a special events. These events, such as, the raising of a Totem pole or the appointment or election of a new chief. The most famous artistic feature of the culture is the Totem pole, with carvings of animals and other characters to commemorate cultural beliefs, legends, and notable events.
The Hopewell tradition was not a single culture or society, but a widely dispersed set of related populations, who were connected by a common network of trade routes, known as the Hopewell Exchange System. At its greatest extent, the Hopewell exchange system ran from the Southeastern United States into the southeastern Canadian shores of Lake Ontario. Within this area, societies participated in a high degree of exchange; most activity was conducted along the waterways that served as their major transportation routes. The Hopewell exchange system traded materials from all over the United States.
Colonial period.
After a period of exploration sponsored by major European nations, the first successful English settlement was established in 1607. Europeans brought horses, cattle, and hogs to the Americas and, in turn, took back to Europe maize, turkeys, potatoes, tobacco, beans, and squash. Many explorers and early settlers died after being exposed to new diseases in the Americas. The effects of new Eurasian diseases carried by the colonists, especially smallpox and measles, were much worse for the Native Americans, as they had no immunity to them. They suffered epidemics and died in very large numbers, usually before large-scale European settlement began. Their societies were disrupted and hollowed out by the scale of deaths.
Spanish, Dutch, and French colonization.
Spanish explorers were the first Europeans with Christopher Columbus' second expedition, to reach Puerto Rico on November 19, 1493; others reached Florida in 1513. Spanish expeditions quickly reached the Appalachian Mountains, the Mississippi River, the Grand Canyon and the Great Plains. In 1540, Hernando de Soto undertook an extensive exploration of the Southeast.
In 1540, Francisco Vásquez de Coronado explored from Arizona to central Kansas. Small Spanish settlements eventually grew to become important cities, such as San Antonio, Texas; Albuquerque, New Mexico; Tucson, Arizona; Los Angeles, California; and San Francisco, California.
New Netherland was a 17th-century Dutch colony centered on present-day New York City and the Hudson River Valley; the Dutch traded furs with the Native Americans to the north. The colony served as a barrier to expansion from New England. Despite being Calvinists and building the Reformed Church in America, the Dutch were tolerant of other religions and cultures.
The colony, which was taken over by Britain in 1664, left an enduring legacy on American cultural and political life. This includes secular broad-mindedness and mercantile pragmatism in the city as well as rural traditionalism in the countryside (typified by the story of Rip Van Winkle). Notable Americans of Dutch descent include Martin Van Buren, Theodore Roosevelt, Franklin D. Roosevelt, Eleanor Roosevelt and the Frelinghuysens.
New France was the area colonized by France from 1534 to 1763. There were few permanent settlers outside Quebec and Acadia, but the French had far-reaching trading relationships with Native Americans throughout the Great Lakes and Midwest. French villages along the Mississippi and Illinois rivers were based in farming communities that served as a granary for Gulf Coast settlements. The French established plantations in Louisiana along with settling New Orleans, Mobile and Biloxi.
The Wabanaki Confederacy were military allies of New France through the four French and Indian Wars while the British colonies were allied with the Iroquois Confederacy. During the French and Indian War – the North American theater of the Seven Years' War – New England fought successfully against French Acadia. The British removed Acadians from Acadia (Nova Scotia) and replaced them with New England Planters. Eventually, some Acadians resettled in Louisiana, where they developed a distinctive rural Cajun culture that still exists. They became American citizens in 1803 with the Louisiana Purchase. Other French villages along the Mississippi and Illinois rivers were absorbed when the Americans started arriving after 1770, or settlers moved west to escape them. French influence and language in New Orleans, Louisiana and the Gulf Coast was more enduring; New Orleans was notable for its large population of free people of color before the Civil War.
British colonization.
The strip of land along the eastern seacoast was settled primarily by English colonists in the 17th century along with much smaller numbers of Dutch and Swedes. Colonial America was defined by a severe labor shortage that employed forms of unfree labor such as slavery and indentured servitude and by a British policy of benign neglect (salutary neglect). Over half of all European immigrants to Colonial America arrived as indentured servants. Salutary neglect permitted the development of an American spirit distinct from that of its European founders.
The first successful English colony, Jamestown, was established in 1607 on the James River in Virginia. Jamestown languished for decades until a new wave of settlers arrived in the late 17th century and established commercial agriculture based on tobacco. Between the late 1610s and the Revolution, the British shipped an estimated 50,000 convicts to their American colonies. A severe instance of conflict was the 1622 Powhatan uprising in Virginia in which Native Americans killed hundreds of English settlers. The largest conflicts between Native Americans and English settlers in the 17th century were King Philip's War in New England and the Yamasee War in South Carolina.
New England was initially settled primarily by Puritans. The Pilgrims established a settlement in 1620 at Plymouth Colony, which was followed by the establishment of the Massachusetts Bay Colony in 1630. The Middle Colonies, consisting of the present-day states of New York, New Jersey, Pennsylvania, and Delaware, were characterized by a large degree of diversity. The first attempted English settlement south of Virginia was the Province of Carolina, with Georgia Colony – the last of the Thirteen Colonies – established in 1733.
The colonies were characterized by religious diversity, with many Congregationalists in New England, German and Dutch Reformed in the Middle Colonies, Catholics in Maryland, and Scots-Irish Presbyterians on the frontier. Sephardic Jews were among early settlers in cities of New England and the South. Many immigrants arrived as religious refugees: French Huguenots settled in New York, Virginia and the Carolinas. Many royal officials and merchants were Anglicans.
Religiosity expanded greatly after the First Great Awakening, a religious revival in the 1740s led by preachers such as Jonathan Edwards and George Whitefield. American Evangelicals affected by the Awakening added a new emphasis on divine outpourings of the Holy Spirit and conversions that implanted within new believers an intense love for God. Revivals encapsulated those hallmarks and carried the newly created evangelicalism into the early republic, setting the stage for the Second Great Awakening beginning in the late 1790s. In the early stages, evangelicals in the South such as Methodists and Baptists preached for religious freedom and abolition of slavery; they converted many slaves and recognized some as preachers.
Each of the 13 American colonies had a slightly different governmental structure. Typically, a colony was ruled by a governor appointed from London who controlled the executive administration and relied upon a locally elected legislature to vote taxes and make laws. By the 18th century, the American colonies were growing very rapidly as a result of low death rates along with ample supplies of land and food. The colonies were richer than most parts of Britain, and attracted a steady flow of immigrants, especially teenagers who arrived as indentured servants.
The tobacco and rice plantations imported African slaves for labor from the British colonies in the West Indies, and by the 1770s African slaves comprised a fifth of the American population. The question of independence from Britain did not arise as long as the colonies needed British military support against the French and Spanish powers. Those threats were gone by 1765. London regarded the American colonies as existing for the benefit of the mother country. This policy is known as mercantilism.
18th century.
An upper-class, with wealth based on large plantations operated by slave labor, and holding significant political power and even control over the churches, emerged in South Carolina and Virginia. A unique class system operated in upstate New York, where Dutch tenant farmers rented land from very wealthy Dutch proprietors, such as the Rensselaer family. The other colonies were more equalitarian, with Pennsylvania being representative. By the mid-18th century Pennsylvania was basically a middle-class colony with limited deference to its small upper-class. A writer in the "Pennsylvania Journal" in 1756 summed it up:
The People of this Province are generally of the middling Sort, and at present pretty much upon a Level. They are chiefly industrious Farmers, Artificers or Men in Trade; they enjoy in are fond of Freedom, and the "meanest among them" thinks he has a right to Civility from the greatest.
Political integration and autonomy.
The French and Indian War (1754–63) was a watershed event in the political development of the colonies. It was also part of the larger Seven Years' War. The influence of the main rivals of the British Crown in the colonies and Canada, the French and North American Indians, was significantly reduced with the territory of the Thirteen Colonies expanding into New France both in Canada and the Louisiana Territory. Moreover, the war effort resulted in greater political integration of the colonies, as reflected in the Albany Congress and symbolized by Benjamin Franklin's call for the colonies to "Join or Die". Franklin was a man of many inventions – one of which was the concept of a United States of America, which emerged after 1765 and was realized in July 1776.
Following Britain's acquisition of French territory in North America, King George III issued the Royal Proclamation of 1763 with the goal of organizing the new North American empire and protecting the native Indians from colonial expansion into western lands beyond the Appalachian Mountains. In ensuing years, strains developed in the relations between the colonists and the Crown. The British Parliament passed the Stamp Act of 1765, imposing a tax on the colonies without going through the colonial legislatures. The issue was drawn: did Parliament have this right to tax Americans who were not represented in it? Crying "No taxation without representation", the colonists refused to pay the taxes as tensions escalated in the late 1760s and early 1770s.
The Boston Tea Party in 1773 was a direct action by activists in the town of Boston to protest against the new tax on tea. Parliament quickly responded the next year with the Coercive Acts, stripping Massachusetts of its historic right of self-government and putting it under army rule, which sparked outrage and resistance in all thirteen colonies. Patriot leaders from all 13 colonies convened the First Continental Congress to coordinate their resistance to the Coercive Acts. The Congress called for a boycott of British trade, published a list of rights and grievances, and petitioned the king for redress of those grievances. The appeal to the Crown had no effect, and so the Second Continental Congress was convened in 1775 to organize the defense of the colonies against the British Army.
Ordinary folk became insurgents against the British even though they were unfamiliar with the ideological rationales being offered. They held very strongly a sense of "rights" that they felt the British were deliberately violating – rights that stressed local autonomy, fair dealing, and government by consent. They were highly sensitive to the issue of tyranny, which they saw manifested in the arrival in Boston of the British Army to punish the Bostonians. This heightened their sense of violated rights, leading to rage and demands for revenge. They had faith that God was on their side.
The American Revolutionary War began at Concord and Lexington in April 1775 when the British tried to seize ammunition supplies and arrest the Patriot leaders.
In terms of political values, the Americans were largely united on a concept called Republicanism, that rejected aristocracy and emphasized civic duty and a fear of corruption. For the Founding Fathers, according to one team of historians, "republicanism represented more than a particular form of government. It was a way of life, a core ideology, an uncompromising commitment to liberty, and a total rejection of aristocracy."
American Revolution.
The Thirteen Colonies began a rebellion against British rule in 1775 and proclaimed their independence in 1776 as the United States of America. In the American Revolutionary War (1775–83) the American captured the British invasion army at Saratoga in 1777, secured the Northeast and encouraged the French to make a military alliance with the United States. France brought in Spain and the Netherlands, thus balancing the military and naval forces on each side as Britain had no allies.
General George Washington (1732–99) proved an excellent organizer and administrator, who worked successfully with Congress and the state governors, selecting and mentoring his senior officers, supporting and training his troops, and maintaining an idealistic Republican Army. His biggest challenge was logistics, since neither Congress nor the states had the funding to provide adequately for the equipment, , clothing, paychecks, or even the food supply of the soldiers.
As a battlefield tactician, Washington was often outmaneuvered by his British counterparts. As a strategist, however, he had a better idea of how to win the war than they did. The British sent four invasion armies. Washington's strategy forced the first army out of Boston in 1776, and was responsible for the surrender of the second and third armies at Saratoga (1777) and Yorktown (1781). He limited the British control to New York City and a few places while keeping Patriot control of the great majority of the population.
The Loyalists, whom the British counted upon too heavily, comprised about 20% of the population but never were well organized. As the war ended, Washington watched proudly as the final British army quietly sailed out of New York City in November 1783, taking the Loyalist leadership with them. Washington astonished the world when, instead of seizing power for himself, he retired quietly to his farm in Virginia. Political scientist Seymour Martin Lipset observes, "The United States was the first major colony successfully to revolt against colonial rule. In this sense, it was the first 'new nation'."
On July 4, 1776, the Second Continental Congress, meeting in Philadelphia, declared the independence of "the United States of America" in the Declaration of Independence. July 4 is celebrated as the nation's birthday. The new nation was founded on Enlightenment ideals of liberalism in what Thomas Jefferson called the unalienable rights to "life, liberty and the pursuit of happiness", and dedicated strongly to republican principles. Republicanism emphasized the people are sovereign (not hereditary kings), demanded civic duty, feared corruption, and rejected any aristocracy.
Early years of the republic.
Confederation and Constitution.
In the 1780s the national government was able to settle the issue of the western territories, which were ceded by the states to Congress and became territories. With the migration of settlers to the Northwest, soon they became states. Nationalists worried that the new nation was too fragile to withstand an international war, or even internal revolts such as the Shays' Rebellion of 1786 in Massachusetts.
Nationalists – most of them war veterans – organized in every state and convinced Congress to call the Philadelphia Convention in 1787. The delegates from every state wrote a new Constitution that created a much more powerful and efficient central government, one with a strong president, and powers of taxation. The new government reflected the prevailing republican ideals of guarantees of individual liberty and of constraining the power of government through a system of separation of powers.
The Congress was given authority to ban the international slave trade after 20 years (which it did in 1807). A compromise gave the South Congressional apportionment out of proportion to its free population by allowing it to include three-fifths of the number of slaves in each state's total population. This provision increased the political power of southern representatives in Congress, especially as slavery was extended into the Deep South through removal of Native Americans and transportation of slaves by an extensive domestic trade.
To assuage the Anti-Federalists who feared a too-powerful national government, the nation adopted the United States Bill of Rights in 1791. Comprising the first ten amendments of the Constitution, it guaranteed individual liberties such as freedom of speech and religious practice, jury trials, and stated that citizens and states had reserved rights (which were not specified).
The new Chief Executive.
George Washington – a renowned hero of the American Revolutionary War, commander-in-chief of the Continental Army, and president of the Constitutional Convention – became the first President of the United States under the new Constitution in 1789. The national capital moved from New York to Philadelphia and finally settled in Washington DC in 1800.
The major accomplishments of the Washington Administration were creating a strong national government that was recognized without question by all Americans. His government, following the vigorous leadership of Treasury Secretary Alexander Hamilton, assumed the debts of the states (the debt holders received federal bonds), created the Bank of the United States to stabilize the financial system, and set up a uniform system of tariffs (taxes on imports) and other taxes to pay off the debt and provide a financial infrastructure. To support his programs Hamilton created a new political party – the first in the world based on voters – the Federalist Party.
Thomas Jefferson and James Madison formed an opposition Republican Party (usually called the Democratic-Republican Party by political scientists). Hamilton and Washington presented the country in 1794 with the Jay Treaty that reestablished good relations with Britain. The Jeffersonians vehemently protested, and the voters aligned behind one party or the other, thus setting up the First Party System. Federalists promoted business, financial and commercial interests and wanted more trade with Britain. Republicans accused the Federalists of plans to establish a monarchy, turn the rich into a ruling class, and making the United States a pawn of the British. The treaty passed, but politics became intensely heated.
The Whiskey Rebellion in 1794, when western settlers protested against a federal tax on liquor, was the first serious test of the federal government. Washington called out the state militia and personally led an army, as the insurgents melted away and the power of the national government was firmly established.
Washington refused to serve more than two terms – setting a precedent – and in his famous farewell address, he extolled the benefits of federal government and importance of ethics and morality while warning against foreign alliances and the formation of political parties.
John Adams, a Federalist, defeated Jefferson in the 1796 election. War loomed with France and the Federalists used the opportunity to try to silence the Republicans with the Alien and Sedition Acts, build up a large army with Hamilton at the head, and prepare for a French invasion. However, the Federalists became divided after Adams sent a successful peace mission to France that ended the Quasi-War of 1798.
Slavery.
During the first two decades after the Revolutionary War, there were dramatic changes in the status of slavery among the states and an increase in the number of freed blacks. Inspired by revolutionary ideals of the equality of men and influenced by their lesser economic reliance on slavery, northern states abolished slavery.
States of the Upper South made manumission easier, resulting in an increase in the proportion of free blacks in the Upper South (as a percentage of the total non-white population) from less than one percent in 1792 to more than 10 percent by 1810. By that date, a total of 13.5 percent of all blacks in the United States were free. After that date, with the demand for slaves on the rise because of the Deep South's expanding cotton cultivation, the number of manumissions declined sharply; and an internal U.S. slave trade became an important source of wealth for many planters and traders.
In 1809, president James Madison severed the U.S.A.'s involvement with the Atlantic slave trade.
19th century.
Jeffersonian Republican Era.
Thomas Jefferson defeated Adams for the presidency in the 1800 election. Jefferson's major achievement as president was the Louisiana Purchase in 1803, which provided U.S. settlers with vast potential for expansion west of the Mississippi River.
Jefferson, a scientist himself, supported expeditions to explore and map the new domain, most notably the Lewis and Clark Expedition. Jefferson believed deeply in republicanism and argued it should be based on the independent yeoman farmer and planter; he distrusted cities, factories and banks. He also distrusted the federal government and judges, and tried to weaken the judiciary. However he met his match in John Marshall, a Federalist from Virginia. Although the Constitution specified a Supreme Court, its functions were vague until Marshall, the Chief Justice (1801–35), defined them, especially the power to overturn acts of Congress or states that violated the Constitution, first enunciated in 1803 in "Marbury v. Madison".
War of 1812.
Americans were increasingly angry at the British violation of American ships' neutral rights in order to hurt France, the impressment (seizure) of 10,000 American sailors needed by the Royal Navy to fight Napoleon, and British support for hostile Indians attacking American settlers in the Midwest. They may also have desired to annex all or part of British North America. Despite strong opposition from the Northeast, especially from Federalists who did not want to disrupt trade with Britain, Congress declared war in June 18, 1812.
The war was frustrating for both sides. Both sides tried to invade the other and were repulsed. The American high command remained incompetent until the last year. The American militia proved ineffective because the soldiers were reluctant to leave home and efforts to invade Canada repeatedly failed. The British blockade ruined American commerce, bankrupted the Treasury, and further angered New Englanders, who smuggled supplies to Britain. The Americans under General William Henry Harrison finally gained naval control of Lake Erie and defeated the Indians under Tecumseh in Canada, while Andrew Jackson ended the Indian threat in the Southeast. The Indian threat to expansion into the Midwest was permanently ended. The British invaded and occupied much of Maine.
The British raided and burned Washington, but were repelled at Baltimore in 1814 – where the "Star Spangled Banner" was written to celebrate the American success. In upstate New York a major British invasion of New York State was turned back. Finally in early 1815 Andrew Jackson decisively defeated a major British invasion at the Battle of New Orleans, making him the most famous war hero.
With Napoleon (apparently) gone, the causes of the war had evaporated and both sides agreed to a peace that left the prewar boundaries intact. Americans claimed victory in February 18, 1815 as news came almost simultaneously of Jackson's victory of New Orleans and the peace treaty that left the prewar boundaries in place. Americans swelled with pride at success in the "second war of independence"; the naysayers of the antiwar Federalist Party were put to shame and it never recovered. The Indians were the big losers; they never gained the independent nationhood Britain had promised and no longer posed a serious threat as settlers poured into the Midwest.
Era of Good Feelings.
As strong opponents of the war, the Federalists held the Hartford Convention in 1814 that hinted at disunion. National euphoria after the victory at New Orleans ruined the prestige of the Federalists and they no longer played a significant role. President Madison and most Republicans realized they were foolish to let the Bank of the United States close down, for its absence greatly hindered the financing of the war. So, with the assistance of foreign bankers, they chartered the Second Bank of the United States in 1816.
The Republicans also imposed tariffs designed to protect the infant industries that had been created when Britain was blockading the U.S. With the collapse of the Federalists as a party, the adoption of many Federalist principles by the Republicans, and the systematic policy of President James Monroe in his two terms (1817–25) to downplay partisanship, the nation entered an Era of Good Feelings, with far less partisanship than before (or after), and closed out the First Party System.
The Monroe Doctrine, expressed in 1823, proclaimed the United States' opinion that European powers should no longer colonize or interfere in the Americas. This was a defining moment in the foreign policy of the United States. The Monroe Doctrine was adopted in response to American and British fears over Russian and French expansion into the Western Hemisphere.
In 1832, President Andrew Jackson, 7th President of the United States, ran for a second term under the slogan "Jackson and no bank" and didn't renew the charter of the Second Bank of the United States of America. Jackson was convinced that central banking was used by the elite to take advantage of the average American.
Indian removal.
In 1830, Congress passed the Indian Removal Act, which authorized the president to negotiate treaties that exchanged Native American tribal lands in the eastern states for lands west of the Mississippi River. Its goal was primarily to remove Native Americans, including the Five Civilized Tribes, from the American Southeast; they occupied land that settlers wanted. Jacksonian Democrats demanded the forcible removal of native populations who refused to acknowledge state laws to reservations in the West; Whigs and religious leaders opposed the move as inhumane. Thousands of deaths resulted from the relocations, as seen in the Cherokee Trail of Tears. Many of the Seminole Indians in Florida refused to move west; they fought the Army for years in the Seminole Wars.
Second Party System.
After the First Party System of Federalists and Republicans withered away in the 1820s, the stage was set for the emergence of a new party system based on very well organized local parties that appealed for the votes of (almost) all adult white men.
The former Jeffersonian party split into factions. They split over the choice of a successor to President James Monroe, and the party faction that supported many of the old Jeffersonian principles, led by Andrew Jackson and Martin Van Buren, became the Democratic Party. As Norton explains the transformation in 1828:
Jacksonians believed the people's will had finally prevailed. Through a lavishly financed coalition of state parties, political leaders, and newspaper editors, a popular movement had elected the president. The Democrats became the nation's first well-organized national party...and tight party organization became the hallmark of nineteenth-century American politics.
Opposing factions led by Henry Clay helped form the Whig Party. The Democratic Party had a small but decisive advantage over the Whigs until the 1850s, when the Whigs fell apart over the issue of slavery.
Behind the platforms issued by state and national parties stood a widely shared political outlook that characterized the Democrats:
The Democrats represented a wide range of views but shared a fundamental commitment to the Jeffersonian concept of an agrarian society. They viewed the central government as the enemy of individual liberty. The 1824 "corrupt bargain" had strengthened their suspicion of Washington politics...Jacksonians feared the concentration of economic and political power. They believed that government intervention in the economy benefited special-interest groups and created corporate monopolies that favored the rich. They sought to restore the independence of the individual--the artisan and the ordinary farmer--by ending federal support of banks and corporations and restricting the use of paper currency, which they distrusted. Their definition of the proper role of government tended to be negative, and Jackson's political power was largely expressed in negative acts. He exercised the veto more than all previous presidents combined. Jackson and his supporters also opposed reform as a movement. Reformers eager to turn their programs into legislation called for a more active government. But Democrats tended to oppose programs like educational reform mid the establishment of a public education system. They believed, for instance, that public schools restricted individual liberty by interfering with parental responsibility and undermined freedom of religion by replacing church schools. Nor did Jackson share reformers' humanitarian concerns. He had no sympathy for American Indians, initiating the removal of the Cherokees along the Trail of Tears.
Second Great Awakening.
The Second Great Awakening was a Protestant revival movement that affected the entire nation during the early 19th century and led to rapid church growth. The movement began around 1790, gained momentum by 1800, and, after 1820 membership rose rapidly among Baptist and Methodist congregations, whose preachers led the movement. It was past its peak by the 1840s.
It enrolled millions of new members in existing evangelical denominations and led to the formation of new denominations. Many converts believed that the Awakening heralded a new millennial age. The Second Great Awakening stimulated the establishment of many reform movements – including abolitionism and temperance designed to remove the evils of society before the anticipated Second Coming of Jesus Christ.
Abolitionism.
After 1840 the growing abolitionist movement redefined itself as a crusade against the sin of slave ownership. It mobilized support (especially among religious women in the Northeast affected by the Second Great Awakening). William Lloyd Garrison published the most influential of the many anti-slavery newspapers, "The Liberator", while Frederick Douglass, an ex-slave, began writing for that newspaper around 1840 and started his own abolitionist newspaper "North Star" in 1847. The great majority of anti-slavery activists, such as Abraham Lincoln, rejected Garrison's theology and held that slavery was an unfortunate social evil, not a sin.
Westward expansion and Manifest Destiny.
The American colonies and the new nation grew very rapidly in population and area, as pioneers pushed the frontier of settlement west. The process finally ended around 1890–1912 as the last major farmlands and ranch lands were settled. Native American tribes in some places resisted militarily, but they were overwhelmed by settlers and the army and after 1830 were relocated to reservations in the west. The highly influential "Frontier Thesis" argues that the frontier shaped the national character, with its boldness, violence, innovation, individualism, and democracy.
Recent historians have emphasized the multicultural nature of the frontier. Enormous popular attention in the media focuses on the "Wild West" of the second half of the 19th century. As defined by Hine and Faragher, "frontier history tells the story of the creation and defense of communities, the use of the land, the development of markets, and the formation of states". They explain, "It is a tale of conquest, but also one of survival, persistence, and the merging of peoples and cultures that gave birth and continuing life to America."
Through wars and treaties, establishment of law and order, building farms, ranches, and towns, marking trails and digging mines, and pulling in great migrations of foreigners, the United States expanded from coast to coast fulfilling the dreams of Manifest Destiny. As the American frontier passed into history, the myths of the west in fiction and film took firm hold in the imagination of Americans and foreigners alike. America is exceptional in choosing its iconic self-image. "No other nation," says David Murdoch, "has taken a time and place from its past and produced a construct of the imagination equal to America's creation of the West."
From the early 1830s to 1869, the Oregon Trail and its many offshoots were used by over 300,000 settlers. '49ers (in the California Gold Rush), ranchers, farmers, and entrepreneurs and their families headed to California, Oregon, and other points in the far west. Wagon-trains took five or six months on foot; after 1869, the trip took 6 days by rail.
Manifest Destiny was the belief that American settlers were destined to expand across the continent. This concept was born out of "A sense of mission to redeem the Old World by high example ... generated by the potentialities of a new earth for building a new heaven." Manifest Destiny was rejected by modernizers, especially the Whigs like Henry Clay and Abraham Lincoln who wanted to build cities and factories – not more farms. Democrats strongly favored expansion, and they won the key election of 1844. After a bitter debate in Congress the Republic of Texas was annexed in 1845, which Mexico had warned meant war.
War broke out in 1846, with the homefront polarized as Whigs opposed and Democrats supported the war. The U.S. army, using regulars and large numbers of volunteers, won the Mexican–American War (1846–48). The 1848 Treaty of Guadalupe Hidalgo made peace. Mexico recognized the annexation of Texas and ceded its claims in the Southwest (especially California and New Mexico).
The Hispanic residents were given full citizenship and the Mexican Indians became American Indians. Simultaneously gold was discovered, pulling over 100,000 men to northern California in a matter of months in the California Gold Rush. Not only did the then president James K. Polk expand America's border to the Republic of Texas and a fraction of Mexico but he also annexed the north western frontier known as the Oregon Country, which was renamed the Oregon Territory.
Divisions between North and South.
The central issue after 1848 was the expansion of slavery, pitting the anti-slavery elements that were a majority in the North, against the pro-slavery elements that overwhelmingly dominated the white South. A small number of very active Northerners were abolitionists who declared that ownership of slaves was a sin (in terms of Protestant theology) and demanded its immediate abolition. Much larger numbers were against the expansion of slavery, seeking to put it on the path to extinction so that America would be committed to free land (as in low-cost farms owned and cultivated by a family), free labor (no slaves), and free speech (as opposed to censorship rampant in the South). Southern whites insisted that slavery was of economic, social, and cultural benefit to all whites (and even to the slaves themselves), and denounced all anti-slavery spokesmen as "abolitionists."
Religious activists split on slavery, with the Methodists and Baptists dividing into northern and southern denominations. In the North, the Methodists, Congregationalists, and Quakers included many abolitionists, especially among women activists. (The Catholic, Episcopal and Lutheran denominations largely ignored the slavery issue.)
The issue of slavery in the new territories was seemingly settled by the Compromise of 1850, brokered by Whig Henry Clay and Democrat Stephen Douglas; the Compromise included the admission of California as a free state. The point of contention was the Fugitive Slave Act, which increased federal enforcement and required even free states to cooperate in turning over fugitive slaves to their owners. Abolitionists pounced on the Act to attack slavery, as in the best-selling anti-slavery novel "Uncle Tom's Cabin" by Harriet Beecher Stowe.
The Compromise of 1820 was repealed in 1854 with the Kansas–Nebraska Act, promoted by Senator Douglas in the name of "popular sovereignty" and democracy. It permitted voters to decide on slavery in each territory, and allowed Douglas to say he was neutral on the slavery issue. Anti-slavery forces rose in anger and alarm, forming the new Republican Party. Pro- and anti- contingents rushed to Kansas to vote slavery up or down, resulting in a miniature civil war called Bleeding Kansas. By the late 1850s, the young Republican Party dominated nearly all northern states and thus the electoral college. It insisted that slavery would never be allowed to expand (and thus would slowly die out).
The Southern slavery-based societies had become wealthy based on their cotton and other agricultural commodity production, and some particularly profited from the internal slave trade. Northern cities such as Boston and New York, and regional industries, were tied economically to slavery by banking, shipping, and manufacturing, including textile mills. By 1860, there were four million slaves in the South, nearly eight times as many as there were nationwide in 1790. The plantations were highly profitable, because of the heavy European demand for raw cotton. Most of the profits were invested in new lands and in purchasing more slaves (largely drawn from the declining tobacco regions).
For 50 of the nation's first 72 years, a slaveholder served as President of the United States and, during that period, only slaveholding presidents were re-elected to second terms. In addition, southern states benefited by their increased apportionment in Congress due to the partial counting of slaves in their populations.
Slave rebellions were planned or actually took place – including by Gabriel Prosser (1800), Denmark Vesey (1822), Nat Turner (1831), and John Brown (1859) – but they only involved dozens of people and all failed. They caused fear in the white South, which imposed tighter slave oversight and reduced the rights of free blacks. The Fugitive Slave Act of 1850 required the states to cooperate with slave owners when attempting to recover escaped slaves, which outraged Northerners. Formerly, an escaped slave, having reached a non-slave state, was presumed to have attained sanctuary and freedom. The Supreme Court's 1857 decision in "Dred Scott v. Sandford" ruled that the Missouri Compromise was unconstitutional; angry Republicans said this decision threatened to make slavery a national institution.
After Abraham Lincoln won the 1860 election, seven Southern states seceded from the union and set up a new nation, the Confederate States of America (C.S.A.), on February 8, 1861. It attacked Fort Sumter, a U.S. Army fort in South Carolina, thus igniting the war. When Lincoln called for troops to suppress the Confederacy in April 1861, four more states seceded and joined the Confederacy. A few of the (northernmost) "slave states" did not secede and became known as the border states; these were Delaware, Maryland, Kentucky, and Missouri.
During the war, the northwestern portion of Virginia seceded from the C.S.A. and became the new Union state of West Virginia. West Virginia is usually grouped with the border states.
Civil War.
The Civil War began on April 12, 1861, when Confederate forces attacked a U.S. military installation at Fort Sumter in South Carolina. In response to the attack, on April 15, Lincoln called on the states to send detachments totaling 75,000 troops to recapture forts, protect the capital, and "preserve the Union", which in his view still existed intact despite the actions of the seceding states. The two armies had their first major clash at the First Battle of Bull Run, ending in a Union defeat, but, more importantly, proved to both the Union and Confederacy that the war would be much longer and bloodier than originally anticipated.
The war soon divided into two theaters: Eastern and Western. In the western theater, the Union was quite successful, with major battles, such as Perryville and Shiloh, producing strategic Union victories and destroying major Confederate operations.
Warfare in the Eastern theater started poorly for the Union as the Confederates won at Manassas Junction (Bull Run), just outside Washington. Major General George B. McClellan was put in charge of the Union armies. After reorganizing the new Army of the Potomac, McClellan failed to capture the Confederate capital of Richmond, Virginia in his Peninsula Campaign and retreated after attacks from newly appointed Confederate General Robert E. Lee.
Feeling confident in his army after defeating the Union at Second Bull Run, Lee embarked on an invasion of the north that was stopped by McClellan at the bloody Battle of Antietam. Despite this, McClellan was relieved from command for refusing to pursue Lee's crippled army. The next commander, General Ambrose Burnside, suffered a humiliating defeat by Lee's smaller army at the Battle of Fredericksburg late in 1862, causing yet another change in commanders. Lee won again at the Battle of Chancellorsville in May 1863, while losing his top aide, Stonewall Jackson. But Lee pushed too hard and ignored the Union threat in the west. Lee invaded Pennsylvania in search of supplies and to cause war-weariness in the North. In perhaps the turning point of the war, Lee's army was badly beaten at the Battle of Gettysburg, July 1–3, 1863, and barely made it back to Virginia.
Simultaneously on July 4, 1863, Union forces under the command of General Ulysses S. Grant gained control of the Mississippi River at the Battle of Vicksburg, thereby splitting the Confederacy. Lincoln made General Grant commander of all Union armies.
The last two years of the war were bloody for both sides, with Grant launching a war of attrition against General Lee's Army of Northern Virginia. This war of attrition was divided into three main campaigns. The first of these, the Overland Campaign forced Lee to retreat into the city of Petersburg where Grant launched his second major offensive, the Richmond-Petersburg Campaign in which he besieged Petersburg. After a near ten-month siege, Petersburg surrendered. However, the defense of Fort Gregg allowed Lee to move his army out of Petersburg. Grant pursued and launched the final, Appomattox Campaign which resulted in Lee surrendering his Army of Northern Virginia on April 9, 1865, at Appomattox Court House. Other Confederate armies followed suit and the war ended with no postwar insurgency.
Based on 1860 census figures, about 8% of all white males aged 13 to 43 died in the war, including 6% from the North and 18% from the South, establishing the American Civil War as the deadliest war in American history. Its legacy includes ending slavery in the United States, restoring the Union, and strengthening the role of the federal government.
Emancipation.
The Emancipation Proclamation was an executive order issued by President Abraham Lincoln on January 1, 1863. In a single stroke it changed the legal status, as recognized by the U.S. government, of 3 million slaves in designated areas of the Confederacy from "slave" to "free." It had the practical effect that as soon as a slave escaped the control of the Confederate government, by running away or through advances of federal troops, the slave became legally and actually free. The owners were never compensated. Plantation owners, realizing that emancipation would destroy their economic system, sometimes moved their slaves as far as possible out of reach of the Union army. By June 1865, the Union Army controlled all of the Confederacy and liberated all of the designated slaves. Large numbers moved into camps run by the Freedmen's Bureau, where they were given food, shelter, medical care, and arrangements for their employment were made.
The severe dislocations of war and Reconstruction had a large negative impact on the black population, with a large amount of sickness and death.
Reconstruction.
Reconstruction lasted from Lincoln's Emancipation Proclamation of January 1, 1863 to the Compromise of 1877.
The major issues faced by Lincoln were the status of the ex-slaves (called "Freedmen"), the loyalty and civil rights of ex-rebels, the status of the 11 ex-Confederate states, the powers of the federal government needed to prevent a future civil war, and the question of whether Congress or the President would make the major decisions.
The severe threats of starvation and displacement of the unemployed Freedmen were met by the first major federal relief agency, the Freedmen's Bureau, operated by the Army.
Three "Reconstruction Amendments" were passed to expand civil rights for black Americans: the Thirteenth Amendment outlawed slavery; the Fourteenth Amendment guaranteed equal rights for all and citizenship for blacks; the Fifteenth Amendment prevented race from being used to disfranchise men.
Ex-Confederates remained in control of most Southern states for over two years, but that changed when the Radical Republicans gained control of Congress in the 1866 elections. President Andrew Johnson, who sought easy terms for reunions with ex-rebels, was virtually powerless; he escaped by one vote removal through impeachment. Congress enfranchised black men and temporarily stripped many ex-Confederate leaders of the right to hold office. New Republican governments came to power based on a coalition of Freedmen made up of Carpetbaggers (new arrivals from the North), and Scalawags (native white Southerners). They were backed by the US Army. Opponents said they were corrupt and violated the rights of whites.
State by state they lost power to a conservative-Democratic coalition, which gained control of the entire South by 1877. In response to Radical Reconstruction, the Ku Klux Klan (KKK) emerged in 1867 as a white-supremacist organization opposed to black civil rights and Republican rule. President Ulysses Grant's vigorous enforcement of the Ku Klux Klan Act of 1870 shut down the Klan, and it disbanded. Paramilitary groups, such as the White League and Red Shirts emerged about 1874 that worked openly to use intimidation and violence to suppress black voting to regain white political power in states across the South during the 1870s. Rable described them as the military arm of the Democratic Party.
Reconstruction ended after the disputed 1876 election. The Compromise of 1877 gave Republican candidate Rutherford B. Hayes the White House. The federal government withdrew its troops from the South, and Southern Democrats took control of every Southern state. . From 1890 to 1908, southern states effectively disfranchised most black voters and many poor whites by making voter registration more difficult through poll taxes, literacy tests, and other arbitrary devices. They passed segregation laws and imposed second-class status on blacks in a system known as Jim Crow that lasted until the successes of the Civil Rights movement in 1964-65.
Deeply religious Southerners saw the hand of God in history, which demonstrated His wrath at their sinfulness, or His rewards for their suffering. Historian Wilson Fallin has examined the sermons of white and black Baptist preachers after the War. Southern white preachers said:
God had chastised them and given them a special mission – to maintain orthodoxy, strict biblicism, personal piety, and traditional race relations. Slavery, they insisted, had not been sinful. Rather, emancipation was a historical tragedy and the end of Reconstruction was a clear sign of God's favor.
In sharp contrast, Black preachers interpreted the Civil War as:
God's gift of freedom. They appreciated opportunities to exercise their independence, to worship in their own way, to affirm their worth and dignity, and to proclaim the fatherhood of God and the brotherhood of man. Most of all, they could form their own churches, associations, and conventions. These institutions offered self-help and racial uplift, and provided places where the gospel of liberation could be proclaimed. As a result, black preachers continued to insist that God would protect and help him; God would be their rock in a stormy land.
The West and the Gilded Age.
The latter half of the nineteenth century was marked by the rapid development and settlement of the far West, first by wagon trains and riverboats and then aided by the completion of the transcontinental railroad. Large numbers of European immigrants (especially from Germany and Scandinavia) took up low-cost or free farms in the Prairie States. Mining for silver and copper opened up the Mountain West. The United States Army fought frequent small-scale wars with Native Americans as settlers encroached on their traditional lands. Gradually the US purchased the Native American tribal lands and extinguished their claims, forcing most tribes onto subsidized reservations. According to the U.S. Bureau of the Census (1894), from 1789 to 1894:
The Indian wars under the government of the United States have been more than 40 in number. They have cost the lives of about 19,000 white men, women and children, including those killed in individual combats, and the lives of about 30,000 Indians. The actual number of killed and wounded Indians must be very much higher than the given... Fifty percent additional would be a safe estimate...
The "Gilded Age" was a term that Mark Twain used to describe the period of the late 19th century when there had been a dramatic expansion of American wealth and prosperity. Reform of the Age included the Civil Service Act, which mandated a competitive examination for applicants for government jobs. Other important legislation included the Interstate Commerce Act, which ended railroads' discrimination against small shippers, and the Sherman Antitrust Act, which outlawed monopolies in business. Twain believed that this age was corrupted by such elements as land speculators, scandalous politics, and unethical business practices. Since the days of Charles A. Beard and Matthew Josephson, some historians have argued that the United States was effectively plutocratic for at least part of the Gilded Age and Progressive Era. As financiers and industrialists such as J.P. Morgan and John D. Rockefeller began to amass vast fortunes, many US observers were concerned that the nation was losing its pioneering egalitarian spirit.
By 1890 American industrial production and per capita income exceeded those of all other world nations. In response to heavy debts and decreasing farm prices, wheat and cotton farmers joined the Populist Party. An unprecedented wave of immigration from Europe served to both provide the labor for American industry and create diverse communities in previously undeveloped areas. From 1880 to 1914, peak years of immigration, more than 22 million people migrated to the United States. Most were unskilled workers who quickly found jobs in mines, mills, factories. Many immigrants were craftsmen (especially from Britain and Germany) bringing human skills, and others were farmers (especially from Germany and Scandinavia) who purchased inexpensive land on the Prairies from railroads who sent agents to Europe. Poverty, growing inequality and dangerous working conditions, along with socialist and anarchist ideas diffusing from European immigrants, led to the rise of the labor movement, which often included violent strikes.
Skilled workers banded together to control their crafts and raise wages by forming labor unions in industrial areas of the Northeast. Before the 1930s few factory workers joined the unions in the labor movement. Samuel Gompers led the American Federation of Labor 1886-1924, coordinating multiple unions. Industrial growth was very rapid, led by John D. Rockefeller in oil and Andrew Carnegie in steel; both became leaders of philanthropy, giving away their fortunes to create the modern system of hospitals, universities, libraries, and foundations.
A severe nationwide depression broke out in 1893; it was called the Panic of 1893 and impacted farmers, workers, and businessmen who saw prices, wages, and profits fall. Many railroads went bankrupt. The resultant political reaction fell on the Democratic Party, whose leader President Grover Cleveland shouldered much of the blame. Labor unrest involved numerous strikes, most notably the violent Pullman Strike of 1894, which was shut down by federal troops under Cleveland's orders. The Populist Party gained strength among cotton and wheat farmers, as well as coal miners, but was overtaken by the even more popular Free Silver movement, which demanded using silver to enlarge the money supply, leading to inflation that the silverites promised would end the depression.
The financial, railroad, and business communities fought back hard, arguing that only the gold standard would save the economy. In the most intense election in the nation's history, conservative Republican William McKinley defeated silverite William Jennings Bryan, who ran on the Democratic, Populist, and Silver Republican tickets. Bryan swept the South and West, but McKinley ran up landslides among the middle class, industrial workers, cities, and among upscale farmers in the Midwest.
Prosperity returned under McKinley, the gold standard was enacted, and the tariff was raised. By 1900 the US had the strongest economy on the globe. Apart from two short recessions (in 1907 and 1920) the overall economy remained prosperous and growing until 1929. Republicans, citing McKinley's policies, took the credit.
20th century.
Progressive Era.
Dissatisfaction on the part of the growing middle class with the corruption and inefficiency of politics as usual, and the failure to deal with increasingly important urban and industrial problems, led to the dynamic Progressive Movement starting in the 1890s. In every major city and state, and at the national level as well, and in education, medicine, and industry, the progressives called for the modernization and reform of decrepit institutions, the elimination of corruption in politics, and the introduction of efficiency as a criterion for change. Leading politicians from both parties, most notably Theodore Roosevelt, Charles Evans Hughes, and Robert LaFollette on the Republican side, and William Jennings Bryan and Woodrow Wilson on the Democratic side, took up the cause of progressive reform. Women became especially involved in demands for woman suffrage, prohibition, and better schools; their most prominent leader was Jane Addams of Chicago. "Muckraking" journalists such as Upton Sinclair, Lincoln Steffens and Jacob Riis exposed corruption in business and government along with rampant inner city poverty. Progressives implemented anti-trust laws and regulated such industries of meat-packing, drugs, and railroads. Four new constitutional amendments – the Sixteenth through Nineteenth – resulted from progressive activism, bringing the federal income tax, direct election of Senators, prohibition, and woman suffrage. The Progressive Movement lasted through the 1920s; the most active period was 1900–18.
Imperialism.
The United States emerged as a world economic and military power after 1890. The main episode was the Spanish–American War, which began when Spain refused American demands to reform its oppressive policies in Cuba. The "splendid little war", as one official called it, involved a series of quick American victories on land and at sea. At the Treaty of Paris peace conference the United States acquired the Philippines, Puerto Rico, and Guam.
Cuba became an independent country, under close American tutelage. Although the war itself was widely popular, the peace terms proved controversial. William Jennings Bryan led his Democratic Party in opposition to control of the Philippines, which he denounced as imperialism unbecoming to American democracy. President William McKinley defended the acquisition and was riding high as the nation had returned to prosperity and felt triumphant in the war. McKinley easily defeated Bryan in a rematch in the 1900 presidential election.
After defeating an insurrection by Filipino nationalists, the United States engaged in a large-scale program to modernize the economy of the Philippines and dramatically upgrade the public health facilities. By 1908, however, Americans lost interest in an empire and turned their international attention to the Caribbean, especially the building of the Panama Canal. In 1912 when Arizona became the final mainland state, the American Frontier came to an end. The canal opened in 1914 and increased trade with Japan and the rest of the Far East. A key innovation was the Open Door Policy, whereby the imperial powers were given equal access to Chinese business, with not one of them allowed to take control of China.
World War I.
As World War I raged in Europe from 1914, President Woodrow Wilson took full control of foreign policy, declaring neutrality but warning Germany that resumption of unrestricted submarine warfare against American ships supplying goods to Allied nations would mean war. Germany decided to take the risk and try to win by cutting off supplies to Britain; the U.S. declared war in April 1917. American money, food, and munitions arrived quickly, but troops had to be drafted and trained; by summer 1918 American soldiers under General John J. Pershing arrived at the rate of 10,000 a day, while Germany was unable to replace its losses.
The result was Allied victory in November 1918. President Wilson demanded Germany depose the Kaiser and accept his terms, the Fourteen Points. Wilson dominated the 1919 Paris Peace Conference but Germany was treated harshly by the Allies in the Treaty of Versailles (1919) as Wilson put all his hopes in the new League of Nations. Wilson refused to compromise with Senate Republicans over the issue of Congressional power to declare war, and the Senate rejected the Treaty and the League.
Women's suffrage.
The women's suffrage movement began with the June 1848 National Convention of the Liberty Party. Presidential candidate Gerrit Smith argued for and established women's suffrage as a party plank. One month later, his cousin Elizabeth Cady Stanton joined with Lucretia Mott and other women to organize the Seneca Falls Convention, featuring the Declaration of Sentiments demanding equal rights for women, and the right to vote. Many of these activists became politically aware during the abolitionist movement. The women's rights campaign during "first-wave feminism" was led by Stanton, Lucy Stone and Susan B. Anthony, among many others. Stone and Paulina Wright Davis organized the prominent and influential National Women's Rights Convention in 1850. The movement reorganized after the Civil War, gaining experienced campaigners, many of whom had worked for prohibition in the Women's Christian Temperance Union. By the end of the 19th century a few western states had granted women full voting rights, though women had made significant legal victories, gaining rights in areas such as property and child custody.
Around 1912 the feminist movement, which had grown sluggish, began to reawaken, putting an emphasis on its demands for equality and arguing that the corruption of American politics demanded purification by women because men could not do that job. Protests became increasingly common as suffragette Alice Paul led parades through the capital and major cities. Paul split from the large National American Woman Suffrage Association (NAWSA), which favored a more moderate approach and supported the Democratic Party and Woodrow Wilson, led by Carrie Chapman Catt, and formed the more militant National Woman's Party. Suffragists were arrested during their "Silent Sentinels" pickets at the White House, the first time such a tactic was used, and were taken as political prisoners.
The old anti-suffragist argument that only men could fight a war, and therefore only men deserve the right to vote, was refuted by the enthusiastic participation of tens of thousands of American women on the home front in World War I. Across the world, grateful nations gave women the right to vote. Furthermore, most of the Western states had already given the women the right to vote in state and national elections, and the representatives from those states, including the first woman Jeannette Rankin of Montana, demonstrated that woman suffrage was a success. The main resistance came from the south, where white leaders were worried about the threat of black women voting. Congress passed the Nineteenth Amendment in 1919, and women could vote in 1920.
NAWSA became the League of Women Voters, and the National Woman's Party began lobbying for full equality and the Equal Rights Amendment, which would pass Congress during the second wave of the women's movement in 1972. Politicians responded to the new electorate by emphasizing issues of special interest to women, especially prohibition, child health, and world peace. The main surge of women voting came in 1928, when the big-city machines realized they needed the support of women to elect Al Smith, a Catholic from New York City. Meanwhile, Protestants mobilized women to support Prohibition and vote for Republican Herbert Hoover.
Roaring Twenties and the Great Depression.
In the 1920s the U.S. grew steadily in stature as an economic and military world power. The United States Senate did not ratify the Treaty of Versailles imposed by its Allies on the defeated Central Powers; instead, the United States chose to pursue unilateralism. The aftershock of Russia's October Revolution resulted in real fears of Communism in the United States, leading to a Red Scare and the deportation of aliens considered subversive.
While public health facilities grew rapidly in the Progressive Era, and hospitals and medical schools were modernized, the nation in 1918 lost 675,000 lives to the Spanish flu pandemic.
In 1920, the manufacture, sale, import and export of alcohol were prohibited by the Eighteenth Amendment, Prohibition. The result was that in cities illegal alcohol became a big business, largely controlled by racketeers. The second Ku Klux Klan grew rapidly in 1922-25, then collapsed. Immigration laws were passed to strictly limit the number of new entries. The 1920s were called the Roaring Twenties due to the great economic prosperity during this period. Jazz became popular among the younger generation, and thus the decade was also called the Jazz Age.
The Great Depression (1929–39) and the New Deal (1933–36) were decisive moments in American political, economic, and social history that reshaped the nation.
During the 1920s, the nation enjoyed widespread prosperity, albeit with a weakness in agriculture. A financial bubble was fueled by an inflated stock market, which later led to the Stock Market Crash on October 29, 1929. This, along with many other economic factors, triggered a worldwide depression known as the Great Depression. During this time, the United States experienced deflation as prices fell, unemployment soared from 3% in 1929 to 25% in 1933, farm prices fell by half, and manufacturing output plunged by one-third.
In 1932, Democratic presidential nominee Franklin D. Roosevelt promised "a New Deal for the American people", coining the enduring label for his domestic policies. The desperate economic situation, along with the substantial Democratic victories in the 1932 elections, gave Roosevelt unusual influence over Congress in the "First Hundred Days" of his administration. He used his leverage to win rapid passage of a series of measures to create welfare programs and regulate the banking system, stock market, industry, and agriculture, along with many other government efforts to end the Great Depression and reform the American economy. The New Deal regulated much of the economy, especially the financial sector. It provided relief to the unemployed through numerous programs, such as the Works Progress Administration (WPA) and (for young men) the Civilian Conservation Corps. Large scale spending projects designed to provide high paying jobs and rebuild the infrastructure were under the purview of the Public Works Administration. Roosevelt turned left in 1935–36, building up labor unions through the Wagner Act. Unions became a powerful element of the merging New Deal Coalition, which won reelection for Roosevelt in 1936, 1940, and 1944 by mobilizing union members, blue collar workers, relief recipients, big city machines, ethnic, and religious groups (especially Catholics and Jews) and the white South, along with blacks in the North (where they could vote). Some of the programs were dropped in the 1940s when the conservatives regained power in Congress through the Conservative Coalition. Of special importance is the Social Security program, begun in 1935.
World War II.
In the Depression years, the United States remained focused on domestic concerns while democracy declined across the world and many countries fell under the control of dictators. Imperial Japan asserted dominance in East Asia and in the Pacific. Nazi Germany and Fascist Italy militarized too and threatened conquests, while Britain and France attempted appeasement to avert another war in Europe. US legislation in the Neutrality Acts sought to avoid foreign conflicts; however, policy clashed with increasing anti-Nazi feelings following the German invasion of Poland in September 1939 that started World War II. Roosevelt positioned the US as the "Arsenal of Democracy", pledging full-scale financial and munitions support for the Allies – but no military personnel. Japan tried to neutralize America's power in the Pacific by attacking Pearl Harbor on December 7, 1941, which catalyzed American support to enter the war and seek revenge.
The main contributions of the US to the Allied war effort comprised money, industrial output, food, petroleum, technological innovation, and (especially 1944–45), military personnel. Much of the focus in Washington was maximizing the economic output of the nation. The overall result was a dramatic increase in GDP, the export of vast quantities of supplies to the Allies and to American forces overseas, the end of unemployment, and a rise in civilian consumption even as 40% of the GDP went to the war effort. This was achieved by tens of millions of workers moving from low-productivity occupations to high efficiency jobs, improvements in productivity through better technology and management, and the move into the active labor force of students, retired people, housewives, and the unemployed, and an increase in hours worked.
It was exhausting; leisure activities declined sharply. People tolerated the extra work because of patriotism, the pay, and the confidence that it was only "for the duration", and life would return to normal as soon as the war was won. Most durable goods became unavailable, and meat, clothing, and gasoline were tightly rationed. In industrial areas housing was in short supply as people doubled up and lived in cramped quarters. Prices and wages were controlled, and Americans saved a high portion of their incomes, which led to renewed growth after the war instead of a return to depression.
The Allies – the US, Britain, and the Soviet Union, China, as well as Poland, Canada and other countries – fought the Axis powers of Germany, Italy, and Japan. The Allies saw Germany as the main threat and gave highest priority to Europe. The US dominated the war against Japan and stopped Japanese expansion in the Pacific in 1942. After losing Pearl Harbor and in the Philippines to the Japanese, and drawing the Battle of the Coral Sea (May 1942), the American Navy inflicted a decisive blow at Midway (June 1942). American ground forces assisted in the North African Campaign that eventually concluded with the collapse of Mussolini's fascist government in 1943, as Italy switched to the Allied side. A more significant European front was opened on D-Day, June 6, 1944, in which American and Allied forces invaded Nazi-occupied France from Britain.
On the home front, mobilization of the US economy was managed by Roosevelt's War Production Board. The wartime production boom led to full employment, wiping out this vestige of the Great Depression. Indeed, labor shortages encouraged industry to look for new sources of workers, finding new roles for women and blacks.
However, the fervor also inspired anti-Japanese sentiment, which was handled by removing everyone of Japanese descent from the West Coast war zone. Research and development took flight as well, best seen in the Manhattan Project, a secret effort to harness nuclear fission to produce highly destructive atomic bombs.
The Allies pushed the Germans out of France but faced an unexpected counterattack at the Battle of the Bulge in December. The final German effort failed, and, as Allied armies in East and West were converging on Berlin, the Nazis hurriedly tried to kill the last remaining Jews. The western front stopped short, leaving Berlin to the Soviets as the Nazi regime formally capitulated in May 1945, ending the war in Europe. Over in the Pacific, the US implemented an island hopping strategy toward Tokyo, establishing airfields for bombing runs against mainland Japan from the Mariana Islands and achieving hard-fought victories at Iwo Jima and Okinawa in 1945. Bloodied at Okinawa, the U.S. prepared to invade Japan's home islands when B-29s dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki, forcing the empire's surrender in a matter of days and thus ending World War II. The US occupied Japan (and part of Germany), sending Douglas MacArthur to restructure the Japanese economy and political system along American lines. During the war, Roosevelt coined the term "Four Powers" to refer four major Allies of World War II, the United States, the United Kingdom, the Soviet Union and China, which later became the foundation of the United Nations Security Council.
Though the nation lost more than 400,000 military personnel, the mainland prospered untouched by the devastation of war that inflicted a heavy toll on Europe and Asia.
Participation in postwar foreign affairs marked the end of predominant American isolationism. The awesome threat of nuclear weapons inspired both optimism and fear. Nuclear weapons were never used after 1945, as both sides drew back from the brink and a "long peace" characterized the Cold War years, starting with the Truman Doctrine in May 22, 1947. There were, however, regional wars in Korea and Vietnam.
The Cold War, counterculture, and civil rights.
Following World War II, the United States emerged as one of the two dominant superpowers, the USSR being the other. The U.S. Senate on a bipartisan vote approved U.S. participation in the United Nations (UN), which marked a turn away from the traditional isolationism of the U.S. and toward increased international involvement.
The primary American goal of 1945–48 was to rescue Europe from the devastation of World War II and to contain the expansion of Communism, represented by the Soviet Union. The Truman Doctrine of 1947 provided military and economic aid to Greece and Turkey to counteract the threat of Communist expansion in the Balkans. In 1948, the United States replaced piecemeal financial aid programs with a comprehensive Marshall Plan, which pumped money into the economy of Western Europe, and removed trade barriers, while modernizing the managerial practices of businesses and governments.
The Plan's $13 billion budget was in the context of a US GDP of $258 billion in 1948 and was in addition to the $12 billion in American aid given to Europe between the end of the war and the start of the Marshall Plan. Soviet head of state Joseph Stalin prevented his satellite states from participating, and from that point on, Eastern Europe, with inefficient centralized economies, fell further and further behind Western Europe in terms of economic development and prosperity. In 1949, the United States, rejecting the long-standing policy of no military alliances in peacetime, formed the North Atlantic Treaty Organization (NATO) alliance, which continues into the 21st century. In response the Soviets formed the Warsaw Pact of communist states.
In August 1949 the Soviets tested their first nuclear weapon, thereby escalating the risk of warfare. Indeed, the threat of mutually assured destruction prevented both powers from going too far, and resulted in proxy wars, especially in Korea and Vietnam, in which the two sides did not directly confront each other. Within the United States, the Cold War prompted concerns about Communist influence. The unexpected leapfrogging of American technology by the Soviets in 1957 with Sputnik, the first Earth satellite, began the Space Race, won by the Americans as Apollo 11 landed astronauts on the moon in 1969. The angst about the weaknesses of American education led to large-scale federal support for science education and research.
In the decades after World War II, the United States became a global influence in economic, political, military, cultural, and technological affairs. Beginning in the 1950s, middle-class culture became obsessed with consumer goods. White Americans made up nearly 90% of the population in 1950.
In 1960, the charismatic politician John F. Kennedy was elected as the first and – thus far – only Roman Catholic President of the United States. The Kennedy family brought a new life and vigor to the atmosphere of the White House. His time in office was marked by such notable events as the acceleration of the United States' role in the Space Race, escalation of the American role in the Vietnam War, the Cuban missile crisis, the Bay of Pigs Invasion, the jailing of Martin Luther King, Jr. during the Birmingham campaign, and the appointment of his brother Robert F. Kennedy to his Cabinet as Attorney General. Kennedy was assassinated in Dallas, Texas, on November 22, 1963, leaving the nation in profound shock.
Climax of liberalism.
The climax of liberalism came in the mid-1960s with the success of President Lyndon B. Johnson (1963–69) in securing congressional passage of his Great Society programs. They included civil rights, the end of segregation, Medicare, extension of welfare, federal aid to education at all levels, subsidies for the arts and humanities, environmental activism, and a series of programs designed to wipe out poverty. As recent historians have explained:
Gradually, liberal intellectuals crafted a new vision for achieving economic and social justice. The liberalism of the early 1960s contained no hint of radicalism, little disposition to revive new deal era crusades against concentrated economic power, and no intention to fast and class passions or redistribute wealth or restructure existing institutions. Internationally it was strongly anti-Communist. It aimed to defend the free world, to encourage economic growth at home, and to ensure that the resulting plenty was fairly distributed. Their agenda-much influenced by Keynesian economic theory-envisioned massive public expenditure that would speed economic growth, thus providing the public resources to fund larger welfare, housing, health, and educational programs.
Johnson was rewarded with an electoral landslide in 1964 against conservative Barry Goldwater, which broke the decades-long control of Congress by the Conservative coalition. However, the Republicans bounced back in 1966 and elected Richard Nixon in 1968. Nixon largely continued the New Deal and Great Society programs he inherited; conservative reaction would come with the election of Ronald Reagan in 1980. Meanwhile, the American people completed a great migration from farms into the cities and experienced a period of sustained economic expansion.
Civil Rights Movement.
Starting in the late 1950s, institutionalized racism across the United States, but especially in the South, was increasingly challenged by the growing Civil Rights movement. The activism of African-American leaders Rosa Parks and Martin Luther King, Jr. led to the Montgomery Bus Boycott, which launched the movement. For years African Americans would struggle with violence against them but would achieve great steps toward equality with Supreme Court decisions, including "Brown v. Board of Education" and "Loving v. Virginia", the Civil Rights Act of 1964, the Voting Rights Act of 1965, and the Fair Housing Act of 1968, which ended the Jim Crow laws that legalized racial segregation between whites and blacks.
Martin Luther King, Jr., who had won the Nobel Peace Prize for his efforts to achieve equality of the races, was assassinated in 1968. Following his death others led the movement, most notably King's widow, Coretta Scott King, who was also active, like her husband, in the Opposition to the Vietnam War, and in the Women's Liberation Movement. There were 164 riots in 128 American cities in the first nine months of 1967. Black Power emerged during the late 1960s and early 1970s. The decade would ultimately bring about positive strides toward integration, especially in government service, sports, and entertainment. Native Americans turned to the federal courts to fight for their land rights. They held protests highlighting the federal government's failure to honor treaties. One of the most outspoken Native American groups was the American Indian Movement (AIM). In the 1960s, Cesar Chavez began organizing poorly paid Mexican-American farm workers in California. He led a five-year-long strike by grape pickers. Then Chávez formed the nation's first successful union of farm workers. His United Farm Workers of America (UFW) faltered after a few years but after Chavez died in 1993 he became an iconic "folk saint" in the pantheon of Mexican Americans.
The Women's Movement.
A new consciousness of the inequality of American women began sweeping the nation, starting with the 1963 publication of Betty Friedan's best-seller, "The Feminine Mystique", which explained how many housewives felt trapped and unfulfilled, assaulted American culture for its creation of the notion that women could only find fulfillment through their roles as wives, mothers, and keepers of the home, and argued that women were just as able as men to do every type of job. In 1966 Friedan and others established the National Organization for Women, or NOW, to act for women as the NAACP did for African Americans.
Protests began, and the new Women's Liberation Movement grew in size and power, gained much media attention, and, by 1968, had replaced the Civil Rights Movement as the US's main social revolution. Marches, parades, rallies, boycotts, and pickets brought out thousands, sometimes millions. There were striking gains for women in medicine, law, and business, while only a few were elected to office. The Movement was split into factions by political ideology early on, however (with NOW on the left, the Women's Equity Action League (WEAL) on the right, the National Women's Political Caucus (NWPC) in the center, and more radical groups formed by younger women on the far left). The proposed Equal Rights Amendment to the Constitution, passed by Congress in 1972 was defeated by a conservative coalition mobilized by Phyllis Schlafly. They argued that it degraded the position of the housewife and made young women susceptible to the military draft.
However, many federal laws (i.e., those equalizing pay, employment, education, employment opportunities, and credit; ending pregnancy discrimination; and requiring NASA, the Military Academies, and other organizations to admit women), state laws (i.e., those ending spousal abuse and marital rape), Supreme Court rulings (i.e. ruling that the equal protection clause of the Fourteenth Amendment applied to women), and state ERAs established women's equal status under the law, and social custom and consciousness began to change, accepting women's equality. The controversial issue of abortion, deemed by the Supreme Court as a fundamental right in "Roe v. Wade" (1973), is still a point of debate today.
The Counterculture Revolution and Cold War Détente.
Amid the Cold War, the United States entered the Vietnam War, whose growing unpopularity fed already existing social movements, including those among women, minorities, and young people. President Lyndon B. Johnson's Great Society social programs and numerous rulings by the Warren Court added to the wide range of social reform during the 1960s and 1970s. Feminism and the environmental movement became political forces, and progress continued toward civil rights for all Americans. The Counterculture Revolution swept through the nation and much of the western world in the late sixties and early seventies, further dividing Americans in a "culture war" but also bringing forth more liberated social views.
Johnson was succeeded in 1969 by Republican Richard Nixon, who attempted to gradually turn the war over to the South Vietnamese forces. He negotiated the peace treaty in 1973 which secured the release of POWs and led to the withdrawal of U.S. troops. The war had cost the lives of 58,000 American troops. Nixon manipulated the fierce distrust between the Soviet Union and China to the advantage of the United States, achieving "détente" (relaxation; ease of tension) with both parties.
The Watergate scandal, involving Nixon's cover-up of his operatives' break-in into the Democratic National Committee headquarters at the Watergate office complex destroyed his political base, sent many aides to prison, and forced Nixon's resignation on August 9, 1974. He was succeeded by Vice President Gerald Ford. The Fall of Saigon ended the Vietnam War and resulted in North and South Vietnam being reunited. Communist victories in neighboring Cambodia and Laos occurred in the same year.
The OPEC oil embargo marked a long-term economic transition since, for the first time, energy prices skyrocketed, and American factories faced serious competition from foreign automobiles, clothing, electronics, and consumer goods. By the late 1970s the economy suffered an energy crisis, slow economic growth, high unemployment, and very high inflation coupled with high interest rates (the term stagflation was coined). Since economists agreed on the wisdom of deregulation, many of the New Deal era regulations were ended, such as in transportation, banking, and telecommunications.
Jimmy Carter, running as someone who was not a part of the Washington political establishment, was elected president in 1976. On the world stage, Carter brokered the Camp David Accords between Israel and Egypt. In 1979, Iranian students stormed the US embassy in Tehran and took 66 Americans hostage, resulting in the Iran hostage crisis. With the hostage crisis and continuing stagflation, Carter lost the 1980 election to the Republican Ronald Reagan. On January 20, 1981, minutes after Carter's term in office ended, the remaining U.S. captives held at the U.S. embassy in Iran were released, ending the 444-day hostage crisis.
Close of the 20th century.
Ronald Reagan produced a major realignment with his 1980 and 1984 landslide elections. Reagan's economic policies (dubbed "Reaganomics") and the implementation of the Economic Recovery Tax Act of 1981 lowered the top marginal tax rate from 70% to 28% over the course of seven years. Reagan continued to downsize government taxation and regulation. The US experienced a recession in 1982, but the negative indicators reversed, with the inflation rate decreasing from 11% to 2%, the unemployment rate decreasing from 10.8% in December 1982 to 7.5% in November 1984, and the economic growth rate increasing from 4.5% to 7.2%.
Reagan ordered a buildup of the US military, incurring additional budget deficits. Reagan introduced a complicated missile defense system known as the Strategic Defense Initiative (SDI) (dubbed "Star Wars" by opponents) in which, theoretically, the U.S. could shoot down missiles with laser systems in space. The Soviets reacted harshly because they thought it violated the 1972 Anti-Ballistic Missile Treaty, and would upset the balance of power by giving the U.S. a major military advantage. For years Soviet leader Mikhail Gorbachev argued vehemently against SDI. However, by the late 1980s he decided the system would never work and should not be used to block disarmament deals with the U.S. Historians argue how great an impact the SDI threat had on the Soviets – whether it was enough to force Gorbachev to initiate radical reforms, or whether the deterioration of the Soviet economy alone forced the reforms. There is agreement that the Soviets realized they were well behind the Americans in military technology, that to try to catch up would be very expensive, and that the military expenses were already a very heavy burden slowing down their economy.
Reagan's Invasion of Grenada and bombing of Libya were popular in the US, though his backing of the Contras rebels was mired in the controversy over the Iran–Contra affair that revealed Reagan's poor management style.
Reagan met four times with Soviet leader Mikhail Gorbachev, who ascended to power in 1985, and their summit conferences led to the signing of the Intermediate-Range Nuclear Forces Treaty. Gorbachev tried to save Communism in the Soviet Union first by ending the expensive arms race with America, then by shedding the East European empire in 1989. The Soviet Union collapsed on Christmas Day 1991, ending the US–Soviet Cold War.
The United States emerged as the world's sole remaining superpower and continued to intervene in international affairs during the 1990s, including the 1991 Gulf War against Iraq. Following his election in 1992, President Bill Clinton oversaw one of the longest periods of economic expansion and unprecedented gains in securities values, a side effect of the digital revolution and new business opportunities created by the Internet. He also worked with the Republican Congress to pass the first balanced federal budget in 30 years.
In 1998, Clinton was impeached by the House of Representatives on charges of lying about a sexual relationship with White House intern Monica Lewinsky. He was acquitted by the Senate. The failure of impeachment and the Democratic gains in the 1998 election forced House Speaker Newt Gingrich, a Republican, to resign from Congress.
The GOP expanded its base throughout the South after 1968 (excepting 1976), largely due to its strength among socially conservative white Evangelical Protestants and traditionalist Roman Catholics, added to its traditional strength in the business community and suburbs. As white Democrats in the South lost dominance of the Democratic Party in the 1990s, the region took on the two-party apparatus which characterized most of the nation. The Republican Party's central leader by 1980 was Ronald Reagan, whose conservative policies called for reduced government spending and regulation, lower taxes, and a strong anti-Soviet foreign policy. His iconic status in the party persists into the 21st century, as practically all GOP leaders acknowledge his stature. Social scientists Theodore Caplow et al. argue, "The Republican party, nationally, moved from right-center toward the center in 1940s and 1950s, then moved right again in the 1970s and 1980s." They add: "The Democratic party, nationally, moved from left-center toward the center in the 1940s and 1950s, then moved further toward the right-center in the 1970s and 1980s."
The presidential election in 2000 between George W. Bush and Al Gore was one of the closest in US history and helped lay the seeds for political polarization to come. The vote in the decisive state of Florida was extremely close and produced a dramatic dispute over the counting of votes. The US Supreme Court in "Bush v. Gore" ended the recount with a 5–4 vote. That meant Bush, then in the lead, carried Florida and the election. Including 2000, the Democrats outpolled the Republicans in the national vote in every election from 1992 to 2012, except for 2004.
21st century.
9/11 and the War on Terror.
On September 11, 2001 ("9/11"), the United States was struck by a terrorist attack when 19 al-Qaeda hijackers commandeered four airliners to be used in suicide attacks and intentionally crashed two into both twin towers of the World Trade Center and the third into the Pentagon, killing 2,937 victims — 206 aboard the three airliners, 2,606 who were in the World Trade Center and on the ground, and 125 who were in the Pentagon. The fourth plane was re-taken by the passengers and crew of the aircraft. While they were not able to land the plane safely, they were able to re-take control of the aircraft and crash it into an empty field in Pennsylvania, killing all 44 people including the four terrorists on board, thereby saving whatever target the terrorists were aiming for. All in all, a total of 2,977 victims perished in the attacks. In response, President George W. Bush on September 20 announced a "War on Terror". On October 7, 2001, the United States and NATO then invaded Afghanistan to oust the Taliban regime, which had provided safe haven to al-Qaeda and its leader Osama bin Laden.
The federal government established new domestic efforts to prevent future attacks. The controversial USA PATRIOT Act increased the government's power to monitor communications and removed legal restrictions on information sharing between federal law enforcement and intelligence services. A cabinet-level agency called the Department of Homeland Security was created to lead and coordinate federal counter-terrorism activities. Some of these anti-terrorism efforts, particularly the US government's handling of detainees at the prison at Guantanamo Bay, led to allegations against the US government of human rights violations.
In 2003, from March 19 to May 1, the United States launched an invasion of Iraq, which led to the collapse of the Iraq government and the eventual capture of Iraqi dictator Saddam Hussein, with whom the US had long-standing tense relations. The reasons for the invasion cited by the Bush administration included the spreading of democracy, the elimination of weapons of mass destruction (a key demand of the UN as well, though later investigations found parts of the intelligence reports to be inaccurate), and the liberation of the Iraqi people. Despite some initial successes early in the invasion, the continued Iraq War fueled international protests and gradually saw domestic support decline as many people began to question whether or not the invasion was worth the cost. In 2007, after years of violence by the Iraqi insurgency, President Bush deployed more troops in a strategy dubbed "the surge". While the death toll decreased, the political stability of Iraq remained in doubt.
In 2008, the unpopularity of President Bush and the Iraq war, along with the 2008 financial crisis, led to the election of Barack Obama, the first African-American President of the United States. After his election, Obama reluctantly continued the war effort in Iraq until August 31, 2010, when he declared that combat operations had ended. However, 50,000 American soldiers and military personnel were kept in Iraq to assist Iraqi forces, help protect withdrawing forces, and work on counter-terrorism until December 15, 2011, when the war was declared formally over and the last troops left the country. At the same time, Obama increased American involvement in Afghanistan, starting a surge strategy using an additional 30,000 troops, while proposing to begin withdrawing troops sometime in December 2014. With regards to Guantanamo Bay, President Obama forbade torture but in general retained Bush's policy regarding the Guantanamo detainees, while also proposing that the prison eventually be closed.
In May 2011, after nearly a decade in hiding, the founder and leader of Al Qaeda, Osama bin Laden, was killed in Pakistan in a raid conducted by US naval special forces acting under President Obama's direct orders. While Al Qaeda was near collapse in Afghanistan, affiliated organizations continued to operate in Yemen and other remote areas as the CIA used drones to hunt down and remove its leadership.
The Boston Marathon Bombing was a bombing incident, followed by subsequent related shootings, that occurred when two pressure cooker bombs exploded during the Boston Marathon on April 15, 2013. The bombs exploded about 12 seconds and 210 yards (190 m) apart at 2:49 pm EDT, near the marathon's finish line on Boylston Street. They killed 3 people and injured an estimated 264 others.
The Islamic State of Iraq and the Levant - formerly known as Al-Qaeda in Iraq - rose to prominence in September 2014. In addition to taking control of much of Western Iraq and Eastern Syria, ISIS also beheaded three journalists, two American and one British. These events lead to a major military offensive by the USA and its allies in the region.
On December 28, 2014, President Obama officially ended the combat mission in Afghanistan and promised a withdrawal of all remaining troops at the end of 2016 with the exception of the embassy guards.
The Great Recession.
In September 2008, the United States, and most of Europe, entered the longest post–World War II recession, often called the "Great Recession." Multiple overlapping crises were involved, especially the housing market crisis, a subprime mortgage crisis, soaring oil prices, an automotive industry crisis, rising unemployment, and the worst financial crisis since the Great Depression. The financial crisis threatened the stability of the entire economy in September 2008 when Lehman Brothers failed and other giant banks were in grave danger. Starting in October the federal government lent $245 billion to financial institutions through the Troubled Asset Relief Program which was passed by bipartisan majorities and signed by Bush.
Following his election victory by a wide electoral margin in November 2008, Bush's successor - Barack Obama - signed into law the American Recovery and Reinvestment Act of 2009, which was a $787 billion economic stimulus aimed at helping the economy recover from the deepening recession. Obama, like Bush, took steps to rescue the auto industry and prevent future economic meltdowns. These included a bailout of General Motors and Chrysler, putting ownership temporarily in the hands of the government, and the "cash for clunkers" program which temporarily boosted new car sales.
The recession officially ended in June 2009, and the economy slowly began to expand once again. The unemployment rate peaked at 10.1% in October 2009 after surging from 4.7% in November 2007, and returned to 5.0% as of October 2015. However, overall economic growth has remained weaker in the 2010s compared to expansions in previous decades.
Recent events.
From 2009 to 2010, the 111th Congress passed major legislation such as the Patient Protection and Affordable Care Act, the Dodd–Frank Wall Street Reform and Consumer Protection Act and the Don't Ask, Don't Tell Repeal Act, which were signed into law by President Obama. Following the 2010 midterm elections, which resulted in a Republican-controlled House of Representatives and a Democratic-controlled Senate, Congress presided over a period of elevated gridlock and heated debates over whether or not raise the debt ceiling, extend tax cuts for citizens making over $250,000 annually, and many other key issues. These ongoing debates led to President Obama signing the Budget Control Act of 2011. In the Fall of 2012, Mitt Romney challenged Barack Obama for the Presidency. Following Obama's reelection in November 2012, Congress passed the American Taxpayer Relief Act of 2012 - which resulted in an increase in taxes primarily on those earning the most money. Congressional gridlock continued as Congressional Republicans' call for the repeal of the Patient Protection and Affordable Care Act - popularly known as "Obamacare" - along with other various demands, resulted in the first government shutdown since the Clinton administration and almost led to the first default on U.S. debt since the 19th century. As a result of growing public frustration with both parties in Congress since the beginning of the decade, Congressional approval ratings fell to record lows, with only 11% of Americans approving as of October 2013.
Other major events that have occurred during the 2010s include the rise of new political movements, such as the conservative Tea Party movement and the liberal Occupy movement. There was also unusually severe weather during the early part of the decade. In 2012, over half the country experienced record drought and Hurricane Sandy caused massive damage to coastal areas of New York and New Jersey.
The ongoing debate over the issue of rights for the LGBT community, most notably that of same-sex marriage, began to shift in favor of same-sex couples, and has been reflected in dozens of polls released in the early part of the decade. In 2012, President Obama becoming the first president to openly support same-sex marriage, and the 2013 Supreme Court decision in the case of United States v. Windsor provided for federal recognition of same-sex unions. In June 2015, the United States Supreme Court legalized gay marriage nationally in the case of Obergefell v. Hodges.
Political debate has continued over issues such as tax reform, immigration reform, income inequality and US foreign policy in the Middle East, particularly with regards to global terrorism, the rise of the Islamic State of Iraq and the Levant, and an accompanying climate of Islamophobia.
In the 2016 presidential election, the Republicans have focused most of their attack on the Obama administration. Senator Marco Rubio, for example in the GOP debates, argues that "Barack Obama is undertaking a systematic effort to change this country,” citing Obamacare, the $800 billion stimulus, the Dodd-Frank financial reform bill and the nuclear deal with Iran. "POLITICO"'s reporter comments:
But whether or not you like what Obama has done, and none of the Republican candidates do, Rubio is correct that he has done an awful lot, transforming U.S. policy not only on health care, economics, financial regulation and Iran, but also on energy, education, taxation, gay rights, Iraq, Cuba and much more.

</doc>
<doc id="63879" url="https://en.wikipedia.org/wiki?curid=63879" title="Initial public offering">
Initial public offering

Initial public offering (IPO) or stock market launch is a type of public offering in which shares of a company usually are sold to institutional investors that in turn, sell to the general public, on a securities exchange, for the first time. Through this process, a privately held company transforms into a public company. Initial public offerings are mostly used by companies to raise the expansion of capital, possibly to monetize the investments of early private investors, and to become publicly traded enterprises. A company selling shares is never required to repay the capital to its public investors. After the IPO, when shares trade freely in the open market, money passes between public investors. Although IPO offers many advantages, there are also significant disadvantages, chief among these are the costs associated with the process and the requirement to disclose certain information that could prove helpful to competitors. The IPO process is colloquially known as going public.
Details of the proposed offering are disclosed to potential purchasers in the form of a lengthy document known as a prospectus. Most companies undertake an IPO with the assistance of an investment banking firm acting in the capacity of an underwriter. Underwriters provide several services, including help with correctly assessing the value of shares (share price) and establishing a public market for shares (initial sale). Alternative methods such as the dutch auction have also been explored. In terms of size and public participation, the most notable example of this method is the Google IPO. China has recently emerged as a major IPO market, with several of the largest IPOs taking place in that country.
History.
The earliest form of a company which issued public shares was the "publicani" during the Roman Republic. Like modern joint-stock companies, the "publicani" were legal bodies independent of their members whose ownership was divided into shares, or "parties". There is evidence that these shares were sold to public investors and traded in a type of over-the-counter market in the Forum, near the Temple of Castor and Pollux. The shares fluctuated in value, encouraging the activity of speculators, or "quaestors". Mere evidence remains of the prices for which "partes" were sold, the nature of initial public offerings, or a description of stock market behavior. "Publicanis" lost favor with the fall of the Republic and the rise of the Empire.
The first modern IPO occurred in March 1602 when the Dutch East India Company offered shares of the company to the public in order to raise capital. All the shares were tradable, and the shareholders received receipts for the purchase. A share certificate documenting payment and ownership such as we know today was not issued but ownership was instead entered in the company's share register. In the United States, the first IPO was the public offering of Bank of North America around 1783.
Advantages and disadvantages.
Advantages.
When a company lists its securities on a public exchange, the money paid by the investing public for the newly issued shares goes directly to the company (primary offering) as well as to any early private investors who opt to sell all or a portion of their holdings (secondary offering) as part of the larger IPO. An IPO, therefore, allows a company to tap into a wide pool of potential investors to provide itself with capital for future growth, repayment of debt, or working capital. A company selling common shares is never required to repay the capital to its public investors. Those investors must endure the unpredictable nature of the open market to price and trade their shares. After the IPO, when shares trade freely in the open market, money passes between public investors. For early private investors who choose to sell shares as part of the IPO process, the IPO represents an opportunity to monetize their investment. After the IPO, once shares trade in the open market, investors holding large blocks of shares can either sell those shares piecemeal in the open market, or sell a large block of shares directly to the public, at a fixed price, through a secondary market offering. This type of offering is not dilutive, since no new shares are being created.
Once a company is listed, it is able to issue additional common shares in a number of different ways, one of which is the follow-on offering. This method provides capital for various corporate purposes through the issuance of equity (see stock dilution) without incurring any debt. This ability to quickly raise potentially large amounts of capital from the marketplace is a key reason many companies seek to go public.
An IPO accords several benefits to the previously private company:
Disadvantages.
There are several disadvantages to completing an initial public offering:
Procedure.
IPO procedures are governed by different laws in different countries. In the United States, IPOs are regulated by the United States Securities and Exchange Commission under the Securities Act of 1933. In the United Kingdom, the UK Listing Authority reviews and approves prospectuses and operates the listing regime.
Advance planning.
Planning is crucial to a successful IPO. One book suggests the following 7 advance planning steps: 
Retention of underwriters.
IPOs generally involve one or more investment banks known as "underwriters". The company offering its shares, called the "issuer", enters into a contract with a lead underwriter to sell its shares to the public. The underwriter then approaches investors with offers to sell those shares.
A large IPO is usually underwritten by a "syndicate" of investment banks, the largest of which take the position of "lead underwriter". Upon selling the shares, the underwriters retain a portion of the proceeds as their fee. This fee is called an underwriting spread. The spread is calculated as a discount from the price of the shares sold (called the gross spread). Components of an underwriting spread in an initial public offering (IPO) typically include the following (on a per share basis): Manager's fee, Underwriting fee—earned by members of the syndicate, and the Concession—earned by the broker-dealer selling the shares. The Manager would be entitled to the entire underwriting spread. A member of the syndicate is entitled to the underwriting fee and the concession. A broker dealer who is not a member of the syndicate but sells shares would receive only the concession, while the member of the syndicate who provided the shares to that broker dealer would retain the underwriting fee. Usually, the managing/lead underwriter, also known as the bookrunner, typically the underwriter selling the largest proportions of the IPO, takes the highest portion of the gross spread, up to 8% in some cases.
Multinational IPOs may have many syndicates to deal with differing legal requirements in both the issuer's domestic market and other regions. For example, an issuer based in the E.U. may be represented by the main selling syndicate in its domestic market, Europe, in addition to separate syndicates or selling groups for US/Canada and for Asia. Usually, the lead underwriter in the main selling group is also the lead bank in the other selling groups.
Because of the wide array of legal requirements and because it is an expensive process, IPOs also typically involve one or more law firms with major practices in securities law, such as the Magic Circle firms of London and the white shoe firms of New York City.
Financial historians Richard Sylla and Robert E. Wright have shown that before 1860 most early U.S. corporations sold shares in themselves directly to the public without the aid of intermediaries like investment banks. The direct public offering or DPO, as they term it, was not done by auction but rather at a share price set by the issuing corporation. In this sense, it is the same as the fixed price public offers that were the traditional IPO method in most non-US countries in the early 1990s. The DPO eliminated the agency problem associated with offerings intermediated by investment banks. There has recently been a movement based on crowd funding to revive the popularity of Direct Public Offerings.
Allocation and pricing.
The sale (allocation and pricing) of shares in an IPO may take several forms. Common methods include:
Public offerings are sold to both institutional investors and retail clients of the underwriters. A licensed securities salesperson (Registered Representative in the USA and Canada) selling shares of a public offering to his clients is paid a portion of the selling concession (the fee paid by the issuer to the underwriter) rather than by his client. In some situations, when the IPO is not a "hot" issue (undersubscribed), and where the salesperson is the client's advisor, it is possible that the financial incentives of the advisor and client may not be aligned.
The issuer usually allows the underwriters an option to increase the size of the offering by up to 15% under certain circumstance known as the greenshoe or overallotment option. This option is always exercised when the offering is considered a "hot" issue, by virtue of being oversubscribed.
In the USA, clients are given a preliminary prospectus, known as a red herring prospectus, during the initial quiet period. The red herring prospectus is so named because of a bold red warning statement printed on its front cover. The warning states that the offering information is incomplete, and may be changed. The actual wording can vary, although most roughly follow the format exhibited on the Facebook IPO red herring. During the quiet period, the shares cannot be offered for sale. Brokers can, however, take indications of interest from their clients. At the time of the stock launch, after the Registration Statement has become effective, indications of interest can be converted to buy orders, at the discretion of the buyer. Sales can only be made through a final prospectus cleared by the Securities and Exchange Commission.
The Final step in preparing and filing the final IPO prospectus is for the issuer to retain one of the major financial "printers", who print (and today, also electronically file with the SEC) the registration statement on Form S-1. Typically, preparation of the final prospectus is actually performed at the printer, where in one of their multiple conference rooms the issuer, issuer's counsel (attorneys), underwriter's counsel (attorneys), the lead underwriter(s), and the issuer's accountants/auditors make final edits and proofreading, concluding with the filing of the final prospectus by the financial printer with the Securities and Exchange Commission.
Before legal actions initiated by New York Attorney General Eliot Spitzer, which later became known as the Global Settlement enforcement agreement, some large investment firms had initiated favorable research coverage of companies in an effort to aid corporate finance departments and retail divisions engaged in the marketing of new issues. The central issue in that enforcement agreement had been judged in court previously. It involved the conflict of interest between the investment banking and analysis departments of ten of the largest investment firms in the United States. The investment firms involved in the settlement had all engaged in actions and practices that had allowed the inappropriate influence of their research analysts by their investment bankers seeking lucrative fees. A typical violation addressed by the settlement was the case of CSFB and Salomon Smith Barney, which were alleged to have engaged in inappropriate spinning of "hot" IPOs and issued fraudulent research reports in violation of various sections within the Securities Exchange Act of 1934.
Pricing.
A company planning an IPO typically appoints a lead manager, known as a bookrunner, to help it arrive at an appropriate price at which the shares should be issued. There are two primary ways in which the price of an IPO can be determined. Either the company, with the help of its lead managers, fixes a price ("fixed price method"), or the price can be determined through analysis of confidential investor demand data compiled by the bookrunner ("book building").
Historically, many IPOs have been underpriced. The effect of underpricing an IPO is to generate additional interest in the stock when it first becomes publicly traded. Flipping, or quickly selling shares for a profit, can lead to significant gains for investors who were allocated shares of the IPO at the offering price. However, underpricing an IPO results in lost potential capital for the issuer. One extreme example is theglobe.com IPO which helped fuel the IPO "mania" of the late 1990s internet era. Underwritten by Bear Stearns on November 13, 1998, the IPO was priced at $9 per share. The share price quickly increased 1000% on the opening day of trading, to a high of $97. Selling pressure from institutional flipping eventually drove the stock back down, and it closed the day at $63. Although the company did raise about $30 million from the offering, it is estimated that with the level of demand for the offering and the volume of trading that took place they might have left upwards of $200 million on the table.
The danger of overpricing is also an important consideration. If a stock is offered to the public at a higher price than the market will pay, the underwriters may have trouble meeting their commitments to sell shares. Even if they sell all of the issued shares, the stock may fall in value on the first day of trading. If so, the stock may lose its marketability and hence even more of its value. This could result in losses for investors, many of whom being the most favored clients of the underwriters. Perhaps the best known example of this is the Facebook IPO in 2012.
Underwriters, therefore, take many factors into consideration when pricing an IPO, and attempt to reach an offering price that is low enough to stimulate interest in the stock, but high enough to raise an adequate amount of capital for the company. When pricing an IPO, underwriters use a variety of key performance indicators and non-GAAP measures. The process of determining an optimal price usually involves the underwriters ("syndicate") arranging share purchase commitments from leading institutional investors.
Some researchers (Friesen & Swift, 2009) believe that the underpricing of IPOs is less a deliberate act on the part of issuers and/or underwriters, and more the result of an over-reaction on the part of investors (Friesen & Swift, 2009). One potential method for determining underpricing is through the use of IPO underpricing algorithms.
Dutch auction.
A Dutch auction allows shares of an initial public offering to be allocated based only on price aggressiveness, with all successful bidders paying the same price per share. One version of the Dutch auction is OpenIPO, which is based on an auction system designed by Nobel Memorial Prize-winning economist William Vickrey. This auction method ranks bids from highest to lowest, then accepts the highest bids that allow all shares to be sold, with all winning bidders paying the same price. It is similar to the model used to auction Treasury bills, notes, and bonds since the 1990s. Before this, Treasury bills were auctioned through a discriminatory or pay-what-you-bid auction, in which the various winning bidders each paid the price (or yield) they bid, and thus the various winning bidders did not all pay the same price. Both discriminatory and uniform price or "Dutch" auctions have been used for IPOs in many countries, although only uniform price auctions have been used so far in the US. Large IPO auctions include Japan Tobacco, Singapore Telecom, BAA Plc and Google (ordered by size of proceeds).
A variation of the Dutch Auction has been used to take a number of U.S. companies public including Morningstar, Interactive Brokers Group, Overstock.com, Ravenswood Winery, Clean Energy Fuels, and Boston Beer Company. In 2004, Google used the Dutch Auction system for its Initial Public Offering. Traditional U.S. investment banks have shown resistance to the idea of using an auction process to engage in public securities offerings. The auction method allows for equal access to the allocation of shares and eliminates the favorable treatment accorded important clients by the underwriters in conventional IPOs. In the face of this resistance, the Dutch Auction is still a little used method in U.S. public offerings, although there have been hundreds of auction IPOs in other countries.
In determining the success or failure of a Dutch Auction, one must consider competing objectives. If the objective is to reduce risk, a traditional IPO may be more effective because the underwriter manages the process, rather than leaving the outcome in part to random chance in terms of who chooses to bid or what strategy each bidder chooses to follow. From the viewpoint of the investor, the Dutch Auction allows everyone equal access. Moreover, some forms of the Dutch Auction allow the underwriter to be more active in coordinating bids and even communicating general auction trends to some bidders during the bidding period. Some have also argued that a uniform price auction is more effective at price discovery, although the theory behind this is based on the assumption of independent private values (that the value of IPO shares to each bidder is entirely independent of their value to others, even though the shares will shortly be traded on the aftermarket). Theory that incorporates assumptions more appropriate to IPOs does not find that sealed bid auctions are an effective form of price discovery, although possibly some modified form of auction might give a better result.
In addition to the extensive international evidence that auctions have not been popular for IPOs, there is no U.S. evidence to indicate that the Dutch Auction fares any better than the traditional IPO in an unwelcoming market environment. A Dutch Auction IPO by WhiteGlove Health, Inc., announced in May 2011 was postponed in September of that year, after several failed attempts to price. An article in the "Wall Street Journal" cited the reasons as "broader stock-market volatility and uncertainty about the global economy have made investors wary of investing in new stocks".
Quiet period.
Under American securities law, there are two time windows commonly referred to as "quiet periods" during an IPO's history. The first and the one linked above is the period of time following the filing of the company's S-1 but before SEC staff declare the registration statement effective. During this time, issuers, company insiders, analysts, and other parties are legally restricted in their ability to discuss or promote the upcoming IPO (U.S. Securities and Exchange Commission, 2005).
The other "quiet period" refers to a period of 40 calendar days following an IPO's first day of public trading. During this time, insiders and any underwriters involved in the IPO are restricted from issuing any earnings forecasts or research reports for the company. Regulatory changes enacted by the SEC as part of the Global Settlement enlarged the "quiet period" from 25 days to 40 days on July 9, 2002. When the quiet period is over, generally the underwriters will initiate research coverage on the firm. For a company with less than $1B in revenue, this quiet period was reduced to 25 days by the JOBS act of 2012. Additionally, the NASDAQ and NYSE have approved a rule mandating a 10-day quiet period after a follow-on Offering and a 15-day quiet period both before and after expiration of a "lock-up agreement" for a securities offering.
Delivery of shares.
Not all IPOs are eligible for delivery settlement through the DTC system, which would then either require the physical delivery of the stock certificates to the clearing agent bank's custodian, or a delivery versus payment (DVP) arrangement with the selling group brokerage firm.
Stag profit (flipping).
"Stag profit" is a situation in the stock market before and immediately after a company's Initial public offering (or any new issue of shares). A "stag" is a party or individual who subscribes to the new issue expecting the price of the stock to rise immediately upon the start of trading. Thus, stag profit is the financial gain accumulated by the party or individual resulting from the value of the shares rising. This term is more popular in the United Kingdom than in the United States. In the US, such investors are usually called flippers, because they get shares in the offering and then immediately turn around "flipping" or selling them on the first day of trading.
Largest IPO markets.
Prior to 2009, the United States was the leading issuer of IPOs in terms of total value. Since that time, however, China (Shanghai, Shenzhen and Hong Kong) has been the leading issuer, raising $73 billion (almost double the amount of money raised on the New York Stock Exchange and NASDAQ combined) up to the end of November 2011. The Hong Kong Stock Exchange raised $30.9 billion in 2011 as the top course for the third year in a row, while New York raised $30.7 billion.

</doc>
<doc id="63880" url="https://en.wikipedia.org/wiki?curid=63880" title="Acarnania">
Acarnania

Acarnania () is a region of west-central Greece that lies along the Ionian Sea, west of Aetolia, with the Achelous River for a boundary, and north of the gulf of Calydon, which is the entrance to the Gulf of Corinth. Today it forms the western part of the regional unit of Aetolia-Acarnania. The capital and principal city in ancient times was Stratos. The north side of Acarnania of the Corinthian Gulf was considered part of the region of Epirus.
Acarnania's foundation in Greek mythology was traditionally ascribed to Acarnan, son of Alcmaeon.
History.
Classical.
In the 7th century BC, Greek influence in the region became prominent when Corinth settled Anactorium, Sollium and Leucas, and Kefalonia settled Astacus. Settlements in Alyzeia, Coronta, Limnaia, Medion, Oeniadae, Palaerus, Phoitiai and Stratus are also mentioned by Thucydides, this latter city being the seat of a loose confederation of Acarnanian powers that was maintained until the late 1st century BC.
Because it is located strategically on the maritime route to Italy, Acarnania was involved in many wars. In the 5th century BC, the Corinthians were forced out of their Acarnanian settlements by Athens. In the 4th century BC, c.390 BC, the cities of Acarnania surrendered to the Spartans under King Agesilaus, and continued to be Spartan allies until joining the Second Athenian Empire in 375 BC. The Acarnanians later sided with the Boeotians in their fight against Sparta, and with Athens against Philip II of Macedon at Chaeronea.
Acarnania thereafter came under Macedonian rule. In 314 BC, at the behest of the Macedonian king Cassander, the settlements of Acarnania lying near the Aetolian border were conglomerated into fewer, larger settlements. Still, border conflicts with the Aetolians were frequent, and led to Acarnania's territory being partitioned between Aetolia and Epirus, c.250 BC. After the fall of the king of Epirus, the Acarnanian territory that had been given to Epirus regained its independence, and gained Leucas from Epirus, which became the capital of the region.
Acarnania allied itself with Philip V of Macedon against Rome in 200 BC, although it lost Leucas because of this, and the city of Thyrreion was appointed the new capital.
In the 1st century BC, Acarnania suffered greatly at the hands of pirates, and in Rome's civil wars. Afterwards, the towns and settlements of Acarnania fell under the rule of Nicopolis.
Byzantine.
When the Byzantine Empire broke up (1204), Acarnania passed to the Despotate of Epirus and in 1348 it was conquered by Serbia. Then in 1480 it fell to the Ottoman Empire. Since 1832 it has been part of Greece.
Geography.
Acarnania is composed of three main regions: 1) a rocky coastline, 2) a rugged strip of mountain range that follows the coastline, and 3) plains lying between these mountains and the Achelous River.

</doc>
